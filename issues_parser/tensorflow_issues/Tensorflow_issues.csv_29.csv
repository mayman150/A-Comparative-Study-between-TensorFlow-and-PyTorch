Issue Number,Issue Title,Issue Body
37709,Tensorflow documentation on Image Captioning has non existing methods.,"## URL(s) with the issue:
I was running Image captioning example given in tensorflow website as it is in Colab. I found out that the documentation made a mention about ""**image_features_extract_model**"" which was not defined anywhere earlier. Neither could I find any method related to that on Google.

The lines that caused the error is given below:

```
# Get unique images
encode_train = sorted(set(img_name_vector))

# Feel free to change batch_size according to your system configuration
image_dataset = tf.data.Dataset.from_tensor_slices(encode_train)
image_dataset = image_dataset.map(
  load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(16)

for img, path in image_dataset:
  batch_features = image_features_extract_model(img)
  batch_features = tf.reshape(batch_features,
                              (batch_features.shape[0], -1, batch_features.shape[3]))

  for bf, p in zip(batch_features, path):
    path_of_feature = p.numpy().decode(""utf-8"")
    np.save(path_of_feature, bf.numpy())

```
The original documetation can be found at the following url:
[https://www.tensorflow.org/tutorials/text/image_captioning](url)

I was confused whether i should report this as a bug or documentation error. I went with the latter.


Is the link to the source code correct?
Yes
The original documetation can be found at the following url:
[https://www.tensorflow.org/tutorials/text/image_captioning](url)

"
37708,applications.resnet.ResNet50 means ResNet50 or ResNet34,"## URL(s) with the issue:

https://www.tensorflow.org/api_docs/python/tf/keras/applications/ResNet50

https://www.tensorflow.org/api_docs/python/tf/keras/applications/ResNet50V2

## Description of issue (what needs changing):

TF provides two type of ResNet models. The first is ResNet50 which is implemented by the following code:

https://github.com/keras-team/keras-applications/blob/master/keras_applications/resnet_common.py#L423-L441

where, `stack1` is **basic** version of residual function:
https://github.com/keras-team/keras-applications/blob/master/keras_applications/resnet_common.py#L64-L127

And the second is ResNet50V2 which is implemented by the following code:

https://github.com/keras-team/keras-applications/blob/b34c10628a0ab436542e9160f98de72b49084bbe/keras_applications/resnet_common.py#L483-L501

where, `stack2` is **bottleneck** version of residual function:
https://github.com/keras-team/keras-applications/blob/master/keras_applications/resnet_common.py#L175-192

The original [paper](https://arxiv.org/pdf/1512.03385.pdf) lists different type of ResNet in Table 1.

By the original  definition, the `ResNet50` should be 34-layer ResNet in the Table 1.

From the implementation by `pytorch`: 

https://github.com/pytorch/vision/blob/cc43e0a98368055d7a661651a2b9dbf28a19e533/torchvision/models/resnet.py#L244-L266

They claim the first one is ResNet34.

So I suggest that the `ResNet50` should change its name.



"
37706,problem with batch processing for tflite in android java,"java.lang.IllegalStateException: Internal error: Unexpected failure when preparing tensor allocations: tensorflow/lite/kernels/reshape.cc:66 num_input_elements != num_output_elements (800 != 400)
    Node number 0 (RESHAPE) failed to prepare.
  
        at org.tensorflow.lite.NativeInterpreterWrapper.allocateTensors(Native Method)
        at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:162)
        at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:275)
        at org.tensorflow.lite.Interpreter.run(Interpreter.java:249)
        at id.unify.gait_sample_app.gait.GaitInferenceManager.getRawScore(GaitInferenceManager.java:55)
        at id.unify.gait_sample_app.gait.Gait.score(Gait.java:160)
        at id.unify.gait_sample_app.ui.main.MainFragment$2.onChanged(MainFragment.java:127)
        at id.unify.gait_sample_app.ui.main.MainFragment$2.onChanged(MainFragment.java:115)
        at androidx.lifecycle.LiveData.considerNotify(LiveData.java:113)
        at androidx.lifecycle.LiveData.dispatchingValue(LiveData.java:131)
        at androidx.lifecycle.LiveData.setValue(LiveData.java:289)
        at androidx.lifecycle.MutableLiveData.setValue(MutableLiveData.java:33)
        at androidx.lifecycle.LiveData$1.run(LiveData.java:91)
        at android.os.Handler.handleCallback(Handler.java:751)
        at android.os.Handler.dispatchMessage(Handler.java:95)
        at android.os.Looper.loop(Looper.java:154)
        at android.app.ActivityThread.main(ActivityThread.java:6776)
        at java.lang.reflect.Method.invoke(Native Method)
        at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:1520)
        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:1410)


It works with one single input with the dimension [1,1,4,100]
But crashing when trying to process multiple inputs. For example [2,1,4,100]
// dimension [batchsize, 1, 4, 100]
float[][][][] modelInput = convertWalkCycleTo4DFloatArray(walkCycles);
modelOutput = new float[batch.size()][1001];
model.resizeInput(0, [batchsize,1,4, 100]);
model.run(modelInput, modelOutput);

I check method getInputTensor, and clearly the resizing has been successful.
This same tflite model can process inputs in batch in iOS and python
"
37705,TFDS tests fail with tf-nightly,"**System information** 
- TensorFlow version: - `tf-nightly` 
- Python version: - 3.6

**Describe the current behavior**
Tensorflow-dataset tests fail with tf-nightly while it works fine with TF 1.15 and TF 2.1

**Describe the expected behavior**
Tests should pass.

**Standalone code to reproduce the issue** 
[Colab Link](https://colab.research.google.com/drive/1kdqmjjp-Omg3GfKO4FthubegCnJUrNqf#scrollTo=xB6MPLOCrtQ7)

More Info: https://github.com/tensorflow/datasets/issues/1670
"
37703,Compiling TF 2.2.0-rc0 with bazel 2.0.0 fails (MacOS),"**System information** 

- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): MacOS 10.15
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.2.0-rc0
- Python version: python3 3.7.7
- Bazel 2.0.0
- GCC/Compiler version (if compiling from source): Xcode 11.3.1
- CUDA/cuDNN version: - GPU model and memory: None

**Describe the current behavior**
1. GitClone TF, checkout version 2.2.0-rc0
2. ./configure with standard/default options
3. run compilation as indicated by manual
Result: Compilation stops unsuccessful moments after it starts (log below)

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=130
INFO: Reading rc options for 'build' from /Users/feranick/Desktop/tensorflow/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /Users/feranick/Desktop/tensorflow/.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=v2
INFO: Reading rc options for 'build' from /Users/feranick/Desktop/tensorflow/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/opt/local/bin/python3 --action_env PYTHON_LIB_PATH=/opt/local/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages --python_path=/opt/local/bin/python3 --config=xla --action_env TF_CONFIGURE_IOS=0
INFO: Found applicable config definition build:v2 in file /Users/feranick/Desktop/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:xla in file /Users/feranick/Desktop/tensorflow/.bazelrc: --action_env=TF_ENABLE_XLA=1 --define=with_xla_support=true
INFO: Found applicable config definition build:opt in file /Users/feranick/Desktop/tensorflow/.tf_configure.bazelrc: --copt=-march=native --copt=-Wno-sign-compare --host_copt=-march=native --define with_default_optimizations=true
INFO: Found applicable config definition build:v2 in file /Users/feranick/Desktop/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:macos in file /Users/feranick/Desktop/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14
INFO: Call stack for the definition of repository 'io_bazel_rules_closure' which is a http_archive (rule definition at /private/var/tmp/_bazel_feranick/50b852099a3bf3aaa184abce166f8e34/external/bazel_tools/tools/build_defs/repo/http.bzl:292:16):
 - /Users/feranick/Desktop/tensorflow/WORKSPACE:5:1
ERROR: An error occurred during the fetch of repository 'io_bazel_rules_closure':
   Traceback (most recent call last):
	File ""/private/var/tmp/_bazel_feranick/50b852099a3bf3aaa184abce166f8e34/external/bazel_tools/tools/build_defs/repo/http.bzl"", line 72
		_get_auth(ctx, all_urls)
	File ""/private/var/tmp/_bazel_feranick/50b852099a3bf3aaa184abce166f8e34/external/bazel_tools/tools/build_defs/repo/http.bzl"", line 52, in _get_auth
		read_netrc(ctx, netrcfile)
	File ""/private/var/tmp/_bazel_feranick/50b852099a3bf3aaa184abce166f8e34/external/bazel_tools/tools/build_defs/repo/utils.bzl"", line 219, in read_netrc
		ctx.read(filename)
java.io.FileNotFoundException: /Users/feranick/.netrc (No such file or directory)
ERROR: no such package '@io_bazel_rules_closure//closure': Traceback (most recent call last):
	File ""/private/var/tmp/_bazel_feranick/50b852099a3bf3aaa184abce166f8e34/external/bazel_tools/tools/build_defs/repo/http.bzl"", line 72
		_get_auth(ctx, all_urls)
	File ""/private/var/tmp/_bazel_feranick/50b852099a3bf3aaa184abce166f8e34/external/bazel_tools/tools/build_defs/repo/http.bzl"", line 52, in _get_auth
		read_netrc(ctx, netrcfile)
	File ""/private/var/tmp/_bazel_feranick/50b852099a3bf3aaa184abce166f8e34/external/bazel_tools/tools/build_defs/repo/utils.bzl"", line 219, in read_netrc
		ctx.read(filename)
java.io.FileNotFoundException: /Users/feranick/.netrc (No such file or directory)
ERROR: no such package '@io_bazel_rules_closure//closure': Traceback (most recent call last):
	File ""/private/var/tmp/_bazel_feranick/50b852099a3bf3aaa184abce166f8e34/external/bazel_tools/tools/build_defs/repo/http.bzl"", line 72
		_get_auth(ctx, all_urls)
	File ""/private/var/tmp/_bazel_feranick/50b852099a3bf3aaa184abce166f8e34/external/bazel_tools/tools/build_defs/repo/http.bzl"", line 52, in _get_auth
		read_netrc(ctx, netrcfile)
	File ""/private/var/tmp/_bazel_feranick/50b852099a3bf3aaa184abce166f8e34/external/bazel_tools/tools/build_defs/repo/utils.bzl"", line 219, in read_netrc
		ctx.read(filename)
java.io.FileNotFoundException: /Users/feranick/.netrc (No such file or directory)
INFO: Elapsed time: 2.296s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded)"
37702,Building TF 2.2.0-rc0 with Bazel 1.2.1 fails ,"Summary: According to the release notes, TF 2.2.0-rc0 can be compiled with bazel 1.2.1 (the MIN version). However, when attempting this, it fails. Compilation is successful with Bazel 2.0.0. Compiling with 2.0.1 fails as well (Max seems to be set at 2.0.0)

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04, MacOS
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 2.2rc0
- **Python version**: 3.6-3.7
- **Bazel version (if compiling from source)**: 1.2.1
- **Exact command to reproduce**:
1. Install bazel 1.2.1
2. GitClone TF and checkout 2.2.0-rc0
3. compile as indicated by the manual. compilation will fail immediately with bazel 1.2.1 (according to the release notes for TF 2.2.0-rc0, that is the minimum version required) but compiles successfully with bazel 2.0.0
"
37701,Backport #31378 to 1.15,"Since a `pipenv check` when using TF 1.15.2 now yields:
```
37524: tensorflow <2.0 resolved (1.15.2 installed)!
Tensorflow 2.0 fixes a potential security vulnerability where decoding variant tensors from proto could result in heap out of bounds memory access.
```
Can a 1.15.3 be made with #31378 incorporated?"
37700,Pre trained Resnet model with batch size 1,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Atomic Pi
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 1.5
- Python version: 3.6.9
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory: 2GB RAM, 16GB eMMC



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**

II want to use pretrained ResNet model for image classification. The model I used  requires batch size of 64. Using a batch size of 64 has made Atomic Pi go out of memory.

The model used is from this git repoistory:


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
 Error Log:
https://github.com/tensorflow/models/tree/master/official/r1/resnet
Killed
makefile:2: recipe for target 'default' failed
make: *** [default] Error 137
"
37695,2.1.0 build error due to pybind11,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux CentOS 7.7.1908
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.1.0
- Python version: 3.7.5
- Installed using virtualenv? pip? conda?:  
- Bazel version (if compiling from source): 0.27.1
- GCC/Compiler version (if compiling from source): 7.4.0
- CUDA/cuDNN version: none (CPU only build)
- GPU model and memory:

Building tensorflow 2.1.0 results in compile errors due to pybind11.  This is a build for CPU-only use without any dependency on CUDA libraries.  Example error (out of ~630):
```
bazel-out/host/bin/external/local_config_python/python_include/pybind11/detail/common.h:302:12: error: multiple definition of 'enum class pybind11::return_value_policy'
 enum class return_value_policy : uint8_t {
            ^~~~~~~~~~~~~~~~~~~
In file included from external/pybind11/include/pybind11/pytypes.h:12:0,
                 from external/pybind11/include/pybind11/cast.h:13,
                 from external/pybind11/include/pybind11/attr.h:13,
                 from external/pybind11/include/pybind11/pybind11.h:49,
                 from tensorflow/python/framework/op_def_registry.cc:16:
external/pybind11/include/pybind11/detail/common.h:302:12: note: previous definition here
 enum class return_value_policy : uint8_t {
            ^~~~~~~~~~~~~~~~~~~
```
Build steps:

```
python3  -m venv py37-env
source py37-env/bin/activate
pip install -I --no-cache-dir ""numpy==1.17.2""
pip install -I --no-cache-dir ""pybind11==2.3.0""
pip install -I --no-cache-dir six wheel setuptools mock 'future>=0.17.1'
pip install -I --no-cache-dir keras_applications --no-deps
pip install -I --no-cache-dir keras_preprocessing --no-deps

# Run to try and keep bazel from using the wrong python
export PYTHON_BIN_PATH=`which python3`
export PYTHON_LIB_PATH=`python -c ""import sys ; print(sys.path[-1])""`
export PYTHONPATH=$PYTHON_LIB_PATH
export TF_NEED_OPENCL_SYCL=0 
export TF_NEED_COMPUTECPP=0 
export TF_NEED_OPENCL=0 
export TF_CUDA_CLANG=0
export TF_DOWNLOAD_CLANG=0
export CC_OPT_FLAGS=""-march=sandybridge -mtune=intel  -Wno-sign-compare""
export TF_NEED_CUDA=0
export TF_NEED_TENSORRT=0
export TF_NEED_ROCM=0
export TF_SET_ANDROID_WORKSPACE=0
export TF_ENABLE_XLA=0
export USE_DEFAULT_PYTHON_LIB_PATH=1

./configure

time bazel build  --verbose_failures  \
  --config=opt \
  --config=mkl \
  --config=numa \
  --config=v2 \
  --linkopt=""-Wl,-rpath=/share/pkg.7/gcc/7.4.0/install/lib64"" \
  --linkopt=""-L/share/pkg.7/gcc/7.4.0/install/lib64""   \
  --host_linkopt=""-Wl,-rpath=/share/pkg.7/gcc/7.4.0/install/lib64"" \
  --host_linkopt=""-L/share/pkg.7/gcc/7.4.0/install/lib64""  \
  //tensorflow/tools/pip_package:build_pip_package   
```


[bazel37.zip](https://github.com/tensorflow/tensorflow/files/4350233/bazel37.zip)
"
37693,CUDA_ERROR_LAUNCH_TIMEOUT when using NCCL with MultiWorkerMirroredStrategy on multi-node systems,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): Based on https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras but using bigger dataset and Resnet
- OS Platform and Distribution (e.g.,Linux Ubuntu 16.04): RHEL 7
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.1.0
- Python version: 3.7.4
- Bazel version (if compiling from source): 0.29.1
- GCC/Compiler version (if compiling from source): GCC 8.3.0
- CUDA/cuDNN version: CUDA/10.1.243, cuDNN/7.6.4.38, NCCL/2.4.8
- GPU model and memory:Tesla K80

**Describe the current behavior**

Running the standard training loop results in a CUDA_ERROR_LAUNCH_TIMEOUT when using NCCL.

**Describe the expected behavior**

No error.

**Standalone code to reproduce the issue** 

```
import tensorflow as tf
import tensorflow_datasets as tfds
from slurm_utils import set_tf_config
from slurm_cluster_resolver import SlurmClusterResolver

tfds.disable_progress_bar()

BUFFER_SIZE = 10000
BATCH_SIZE = 32


def make_datasets_unbatched():
    def preprocess(image, label):
        image = tf.image.convert_image_dtype(image, tf.float32)
        image = tf.image.resize_with_pad(image, 299, 299)
        image = image - [123.68, 116.78, 103.94]
        return image, label

    datasets, info = tfds.load(name='stanford_dogs',
                               with_info=True,
                               as_supervised=True)

    return {
        'train':
        datasets['train'].map(preprocess).cache().shuffle(BUFFER_SIZE),
        'test': datasets['test'].map(preprocess)
    }, info


def build_and_compile_cnn_model(num_classes):
    model = tf.keras.applications.InceptionV3(weights=None,
                                              classes=num_classes)
    model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,
                  optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),
                  metrics=['accuracy'])
    return model


resolver = SlurmClusterResolver()
set_tf_config(resolver)
strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy(
    tf.distribute.experimental.CollectiveCommunication.NCCL,
    cluster_resolver=resolver)

# Here the batch size scales up by number of workers since
# `tf.data.Dataset.batch` expects the global batch size.
GLOBAL_BATCH_SIZE = BATCH_SIZE * strategy.num_replicas_in_sync
with strategy.scope():
    # Creation of dataset, and model building/compiling need to be within
    # `strategy.scope()`.
    options = tf.data.Options()
    options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA
    datasets, info = make_datasets_unbatched()
    for split in datasets:
        datasets[split] = datasets[split].batch(
            GLOBAL_BATCH_SIZE).with_options(options)
    model = build_and_compile_cnn_model(info.features['label'].num_classes)

train_steps = info.splits['train'].num_examples // GLOBAL_BATCH_SIZE
test_steps = info.splits['test'].num_examples // GLOBAL_BATCH_SIZE
print(""Have %s examples -> %s batches of %s"" %
      (info.splits['train'].num_examples, train_steps, GLOBAL_BATCH_SIZE))

model.fit(x=datasets['train'].repeat(),
          epochs=1,
          steps_per_epoch=train_steps,
          verbose=2)
```

Note: `SlurmClusterResolver` is the one that got recently included to TF and `set_tf_config` is:

```
def set_tf_config(cluster_resolver, environment=None):
    """"""Set the TF_CONFIG env variable from the given cluster resolver""""""
    cfg = {
        'cluster': cluster_resolver.cluster_spec().as_dict(),
        'task': {
            'type': cluster_resolver.get_task_info()[0],
            'index': cluster_resolver.get_task_info()[1],
        },
        'rpc_layer': cluster_resolver.rpc_layer,
    }
    if environment:
        cfg['environment'] = environment
    os.environ['TF_CONFIG'] = json.dumps(cfg)
    print(""Set TF_CONFIG="" + os.environ['TF_CONFIG'])
```

**Other info / logs**

This happens everytime when using more than 1 node.

```
Set TF_CONFIG={""cluster"": {""worker"": [""taurusi2107:8888"", ""taurusi2108:8888""]}, ""task"": {""type"": ""worker"", ""index"": 1}, ""rpc_layer"": ""grpc""}
Have 12000 examples -> 46 batches of 256
WARNING:tensorflow:`eval_fn` is not passed in. The `worker_fn` will be used if an ""evaluator"" task exists in the cluster.
WARNING:tensorflow:`eval_fn` is not passed in. The `worker_fn` will be used if an ""evaluator"" task exists in the cluster.
WARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.
WARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.
WARNING:tensorflow:ModelCheckpoint callback is not provided. Workers will need to restart training if any fails.
WARNING:tensorflow:ModelCheckpoint callback is not provided. Workers will need to restart training if any fails.
Train for 46 steps
Have 12000 examples -> 46 batches of 256
WARNING:tensorflow:`eval_fn` is not passed in. The `worker_fn` will be used if an ""evaluator"" task exists in the cluster.
WARNING:tensorflow:`eval_fn` is not passed in. The `worker_fn` will be used if an ""evaluator"" task exists in the cluster.
WARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.
WARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.
WARNING:tensorflow:ModelCheckpoint callback is not provided. Workers will need to restart training if any fails.
WARNING:tensorflow:ModelCheckpoint callback is not provided. Workers will need to restart training if any fails.
Train for 46 steps
2020-03-18 16:51:46.733598: E tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_TIMEOUT: the launch timed out and was terminated
2020-03-18 16:51:46.733598: E tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_TIMEOUT: the launch timed out and was terminated
2020-03-18 16:51:46.733599: E tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_TIMEOUT: the launch timed out and was terminated
2020-03-18 16:51:46.733602: E tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_TIMEOUT: the launch timed out and was terminated
2020-03-18 16:51:46.733657: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:273] Unexpected Event status: 1
2020-03-18 16:51:46.733656: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:273] Unexpected Event status: 1
2020-03-18 16:51:46.733662: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:273] Unexpected Event status: 1
2020-03-18 16:51:46.733671: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:273] Unexpected Event status: 1
[taurusi2108:15936] *** Process received signal ***
2020-03-18 16:51:47.705311: E tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_TIMEOUT: the launch timed out and was terminated
2020-03-18 16:51:47.705311: E tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_TIMEOUT: the launch timed out and was terminated
2020-03-18 16:51:47.705349: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:273] Unexpected Event status: 1
2020-03-18 16:51:47.705311: E tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_TIMEOUT: the launch timed out and was terminated
2020-03-18 16:51:47.705359: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:273] Unexpected Event status: 1
[taurusi2107:31475] *** Process received signal ***
2020-03-18 16:51:47.705372: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:273] Unexpected Event status: 1
2020-03-18 16:51:47.705326: E tensorflow/stream_executor/cuda/cuda_driver.cc:818] failed to free device memory at 0x1d8c005800; result: CUDA_ERROR_LAUNCH_TIMEOUT: the launch timed out and was terminated
[taurusi2107:31475] Signal: Aborted (6)
[taurusi2107:31475] Signal code:  (-6)
2020-03-18 16:51:47.705358: E tensorflow/stream_executor/stream.cc:332] Error recording event in stream: Error recording CUDA event: CUDA_ERROR_LAUNCH_TIMEOUT: the launch timed out and was terminated; not marking stream as bad, as the Event object may be at fault. Monitor for further errors.
2020-03-18 16:51:47.705412: E tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_TIMEOUT: the launch timed out and was terminated
2020-03-18 16:51:47.705421: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:273] Unexpected Event status: 1
srun: error: taurusi2107: task 0: Aborted (core dumped)
srun: error: taurusi2108: task 1: Aborted (core dumped)

```
"
37692,shape asserts to check internal code correctness,"**System information**
- TensorFlow version (you are using): 2.1
- Are you willing to contribute it (Yes/No): No

**Describe the feature and the current behavior/state.**

`tf.debugging.assert_shapes` throws `tf.errors.InvalidArgumentError` or `ValueError`. This is unsuitable for use as an assertion of internal code correctness.

**Will this change the current api? How?**

Some way of adding an assertion that mirrors the way `assert` works in python. In particular, it should
  * throw an exception that shouldn't typically be caught (analogous to `AssertionError`)
  * be possible to turn it off via the in built `__debug__` flag

This could be a flag in `tf.debugging.assert_shapes`, or a separate function

**Who will benefit with this feature?**

Developers that build on top of tensorflow and want to check the correctness of shapes within their code, as opposed to checking user input."
37690,"Can I use TensorFlow Multi-worker training with two machines, which one has GPUs, the other only has CPU?","<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>

- TensorFlow version : 2.1.0

I have two machines, machine1 has GPUs and machine2 only has CPUs. I want to know if they can use Multi-worker training in Tensorflow, that is, during the distributed training, machine1 uses GPUs and machine2 uses CPUs.

I followed this tutorial to experiment:
https://tensorflow.google.cn/tutorials/distribute/multi_worker_with_keras?hl=en

But there are some error:
> tensorflow.python.framework.errors_impl.InternalError: Collective Op CollectiveBcastSend: Broadcast(1) is assigned to device /job:worker/replica:0/task:0/device:GPU:0 with type GPU and group_key 1 but that group has type CPU [Op:CollectiveBcastSend]

when I set machine1(has GPUs) not to use GPUs:
```
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
```
my code run successfully.

I want to know: Can I use machine1's GPUs and machine2's CPUs to do distributed learning?

"
37689,spurious error:  failed call to cuInit: UNKNOWN ERROR,"ubuntu 18.04, CUDA 10.1, TF 2.1, python 3.6.5

on a machine *without* a GPU, the following code emits ""error:  failed call to cuInit: UNKNOWN ERROR"".  of course that should fail!  you shouldn't have even tried.  printing that requires extra logic when parsing log files to check whether jobs succeeded.

```
Python 3.6.5 (default, Apr  1 2018, 05:46:30) 
[GCC 7.3.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
2020-03-18 08:16:50.221103: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/.singularity.d/libs
2020-03-18 08:16:50.221260: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/.singularity.d/libs
2020-03-18 08:16:50.221275: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
>>> msg = tf.constant('Hello, TensorFlow!')
2020-03-18 08:16:55.455153: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/.singularity.d/libs
2020-03-18 08:16:55.455184: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)
2020-03-18 08:16:55.455223: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (h10u02.int.janelia.org): /proc/driver/nvidia/version does not exist
2020-03-18 08:16:55.455545: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-03-18 08:16:55.468119: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2099935000 Hz
2020-03-18 08:16:55.469505: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x49b71e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-03-18 08:16:55.469532: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
```"
37688,Tensorflow lite inference crashes in Android development,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution ：Linux
- TensorFlow installed from (source or binary):
- Tensorflow version: 1.12
- Target platform: Arm64 with Android kernel 3.18

**Describe the problem**
This problems happens when using teilte in Android APP platform. My input is 4D tensors with 3 RGB images. 

I convert the bitmap arrays for the byte buffer arrays.

**Please provide the exact sequence of commands/steps when you ran into the problem**

```
    private void convertBitmapToByteBuffer(ArrayList<Bitmap> bitmaps) {
        //System.out.println(bitmaps.size());
        for (int i = 0; i < 3; i++) {
            ByteBuffer imgData = ByteBuffer.allocateDirect(1
                    * getImageSizeX()
                    * getImageSizeY()
                    * 3
                    * getNumBytesPerChannel())
                    .order(ByteOrder.nativeOrder());
            bitmaps.get(i).getPixels(intValues, 0, bitmaps.get(i).getWidth(), 0, 0, bitmaps.get(i).getWidth(), bitmaps.get(i).getHeight());
            // Convert the image to floating point.
            //System.out.println(intValues.length);
            int pixel = 0;
            for (int j = 0; j < getImageSizeX(); j++) {
                for (int k = 0; k < getImageSizeY(); k++) {
                    final int val = intValues[pixel];
                    pixel++;
                    addPixelValueByData(val, imgData);

                }
            }
            imgDatas.add(imgData);

        }
    }
```

Then run the inference based on TensorFlow lite interpreter:
```
   public float[] runMultipleScaleInference(ArrayList<Bitmap> bitmaps) {
        convertBitmapToByteBuffer(bitmaps);
        //System.out.println(imgDatas.size());
        //Object[] inputs = new Object[]{imgDatas, pitchArray};

        //Object[] inputs = new Object[]{imgDatas};
        
        int size = imgDatas.size(); //It is 3 frames currently, imgDatas is the byte-buffer array to store the bitmap
        Object[][] inputsArray = new Object[size][];
        for (int i = 0; i < imgDatas.size(); i ++) {
            Object[] inputs = new Object[]{imgDatas.get(i)};
            inputsArray[i] = inputs;
        }
        Map<Integer, Object> outputs = new HashMap();
        outputs.put(0, probArray);

        tflite.runForMultipleInputsOutputs(inputsArray, outputs);
        return getNormalizedProbability();


    }
```


it crashes in ""tflite.runForMultipleInputsOutputs(inputsArray, outputs)"" with the stack trace log:

> E/AndroidRuntime: FATAL EXCEPTION: pool-1-multi_scale-fingering-1
>     Process: cn.findpiano.piano.ai.demo, PID: 4566
>     java.lang.NullPointerException: Attempt to invoke virtual method 'void org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(java.lang.Object[], java.util.Map)' on a null object reference
>         at cn.findpiano.piano.ai.recognizer.MultiScaleFingeringRecognizer.runMultipleScaleInference(MultiScaleFingeringRecognizer.java:198)
>         at cn.findpiano.recognizer.core.VoteRecognitionJob$Task.run(VoteRecognitionJob.java:76)
>         at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1162)
>         at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:636)
>         at java.lang.Thread.run(Thread.java:764)

I file this bug issue to know what is the correct pose to inference the 4D-tensors with bitmap arrays in tensorflow-lite in Android?

Thanks & Regards!"
37686,The Problem with Distributed inference on multi-GPUs with tf.distribute.MirroredStrategy() strategy,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
- TensorFlow installed from (source or
binary): binary (install from pip) 
- TensorFlow version (use command below): 2.1.0
- Python version: 3.6.8
 - Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from
source): 
- CUDA/cuDNN version: Cuda Toolkit 10.1 / cuDNN 7.6.4
- GPU model and memory: 2 Titan V

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I have tried to custom distributed inference on multi-GPUs (i.e 2 GPUs) follow the tutorial on page https://www.tensorflow.org/tutorials/distribute/save_and_load by using my model and `tf.distribute.MirroredStrategy()` strategy. In particular when I ran my bellow code
```
# Here is my code

DEFAULT_FUNCTION_KEY = ""serving_default""
data = tf.data.Dataset.from_tensor_slices(np.random.rand(32*100, 416, 416, 3).astype('float32')).batch(32)

# load model and do inference on 1 GPU
loaded = tf.saved_model.load('./model')
inference_func = loaded.signatures[DEFAULT_FUNCTION_KEY]

total_time = 0.0
for batch in data:
    begin = time.time()
    inference_func(batch)
    total_time += time.time() - begin
print('Total time on 1 GPU: ', total_time)

# load model and do inference in a distributed manner
mirrored_strategy = tf.distribute.MirroredStrategy()
with mirrored_strategy.scope():
    model = tf.saved_model.load('./model')
    inference_func = model.signatures[DEFAULT_FUNCTION_KEY]

    dist_predict_dataset = mirrored_strategy.experimental_distribute_dataset(data)

    total_time = 0.0
    for batch in dist_predict_dataset:
        begin = time.time()
        mirrored_strategy.run(inference_func, args=(batch,))
        total_time += time.time() - begin
    print('Total time on 2 GPUs: ', total_time)
```
*_Note: The above code is customed from your bellow sample code in the tutorial_
```
# Here is your sample code in the tutorial

DEFAULT_FUNCTION_KEY = ""serving_default""
loaded = tf.saved_model.load(saved_model_path)
inference_func = loaded.signatures[DEFAULT_FUNCTION_KEY]

predict_dataset = eval_dataset.map(lambda image, label: image)
for batch in predict_dataset.take(1):
  print(inference_func(batch))

another_strategy = tf.distribute.MirroredStrategy()
with another_strategy.scope():
  loaded = tf.saved_model.load(saved_model_path)
  inference_func = loaded.signatures[DEFAULT_FUNCTION_KEY]

  dist_predict_dataset = another_strategy.experimental_distribute_dataset(
      predict_dataset)

  # Calling the function in a distributed manner
  for batch in dist_predict_dataset:
    another_strategy.run(inference_func,args=(batch,))
```
and compared the total inference time of the model between 1 GPU and 2 GPUs with the same inputs. Unfortunately, I realized that the performance on 2 GPUs is **not** faster than on 1 GPU (about total time as well as the time of an iterator). It seems that the inference process executed on 2 GPUs **sequentially** (**not** **parallel as I expected**).

**Describe the expected behavior**
Please let me know if there are any problems here and show me how to modify the code in order to run **distributed inference on multi-GPUs parallel** with the best performance. Thanks so much for your help

**Standalone code to reproduce the issue** 
Files to reproduce the test case in [example.zip](https://github.com/tensorflow/tensorflow/files/4348380/example.zip)

**Other info / logs** 

"
37685,Can subjoin one keras.layers operation?,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): v2.1.0
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**
    I meet problem when i trying to spilt one layer, i need something like r**everse operation of  Concatenate**, that can **spilt  shape  [b,w,h,C]   to  [b,w,c,A]and[b,w,h,B]**, which C==A+B

**Will this change the current api? How?**
  It won't have any inpact influence on current api.

**Who will benefit with this feature?**
    Since that Tensorflow2.0 become easy to hand on, it will be more popular in acedemia if more easy and comfortable api are provided. 

**Any Other info.**
"
37683,SparseCategoricalCrossentropy not working with custom Model,"I tried to do a custom model in Colab

```
%tensorflow_version 2.x
import tensorflow as tf
import tensorflow.keras as keras
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0
x_train = x_train[...,None]
x_test = x_test[...,None]

class MyModel(keras.Model):
  def __init__(self):
    super(MyModel, self).__init__()
    self.conv1 = keras.layers.Conv2D(32, 3, activation='relu')
    self.flatten = keras.layers.Flatten()
    self.d1 = keras.layers.Dense(128, activation='relu')
    self.d2 = keras.layers.Dense(10, activation='softmax')

  def call(self, x):
    x = self.conv1(x)
    x = self.flatten(x)
    x = self.d1(x)
    return self.d2(x)

model = MyModel()

model(keras.layers.Input(( 28, 28, 1)))

model.compile(optimizer=keras.optimizers.Adam(learning_rate= 1e-3), loss=keras.losses.SparseCategoricalCrossentropy(from_logits= True), metrics = [keras.metrics.Accuracy()])

model.fit(x = x_train, y = y_train, batch_size= 32, epochs= 10)
```

Tried training the regular MNIST data and when I do model.fit
I get the following

```
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-11-2f67866b9e8a> in <module>()
----> 1 model.fit(x = x_train, y = y_train, batch_size= 32, epochs= 10)

29 frames
/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/tensor_shape.py in assert_is_compatible_with(self, other)
   1108     """"""
   1109     if not self.is_compatible_with(other):
-> 1110       raise ValueError(""Shapes %s and %s are incompatible"" % (self, other))
   1111 
   1112   def most_specific_compatible_shape(self, other):

ValueError: Shapes (32, 10) and (32, 1) are incompatible
```

I thought that I might need to define an argmax somewhere in my model if is not supported, however the other keras.losses.sparse_categorical_crossentropy() does support it.

```
loss = keras.losses.sparse_categorical_crossentropy(y_true=y_train[:10], y_pred=model(x_train[:10]), from_logits= True, axis = -1)
loss
```
Gives me this output
```
<tf.Tensor: shape=(10,), dtype=float32, numpy=
array([2.3041558, 2.304716 , 2.2958994, 2.3044436, 2.2858677, 2.308184 ,
       2.2969985, 2.3054423, 2.3005517, 2.3033297], dtype=float32)>
```

Any reason why? I was just testing the integration of custom models and the functional API."
37681,Getting std::bad_alloc in Android - StyleTransfer,"Hello, I've followed the examples/styletransfer repository. When I build&run the example everything worked with no errors. After that I changed the code a little bit to run my custom model. The model has these values;

custommodel.tflite {
input [1, 320, 320, 3] float32
output [1, 320, 320, 3] float32
} 

When I run it everything works well, too. The result of trained model is showing up in a imageview in about 75~100 ms. But quality did not satisfied me. So I tried to run with model 640x640, here its values;

custommodel_two.tflite {
input [1, 640, 640, 3] float32
output [1, 640, 640, 3] float32
}

When I run the application, it crashed with errors;

using NNAPI:
	`Conv size is too large, not enough memory`

using CPU/GPU:
	`A/libc: /usr/local/google/buildbot/src/android/ndk-release-r17/external/libcxx/../../external/libcxxabi/src/abort_message.cpp:73: abort_message: assertion ""terminating with uncaught exception of type std::bad_alloc: std::bad_alloc"" failed`

`A/libc: Fatal signal 6 (SIGABRT), code -6 (SI_TKILL) in tid 27666 (AsyncTask #1), pid 27614 (.astyletransfer)`

And here is the call stack of methods that getting crash: 
`-NativeInterpreterWrapper.java`
`--(line 156) run(this.interpreterHandle, this.errorHandle);`
`---private static native void run(long var0, long var2);`

I tried with LG-G6, Samsung S7, Nexus5, Pixel (Emulator) both x86&x64 architectures. Also changed thread numbers: 1 - 4 - 7 - 12 but no luck.

Using these versions:

`implementation 'org.tensorflow:tensorflow-lite:2.1.0'`
`implementation 'org.tensorflow:tensorflow-lite-gpu:0.0.0-nightly'`
`implementation 'org.tensorflow:tensorflow-lite-support:0.0.0-nightly'`

So I wonder, what could be wrong with this ? 

Thanks."
37680,Guided Backprop Gradcam with TF 2.0 for Transfer Learning,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow):  
Yes

- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): 
Centos 7

- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): 
Tensorflow 2.0 from source

- Python version: - Bazel
version (if compiling from source):
Python 3.6

- GCC/Compiler version (if compiling from
source): 
- CUDA/cuDNN version: - GPU model and memory:
Cuda 10.0, Titan V 12gb

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I am trying to do gradient visualization using gradcam with guided backpropagation. I can do it on VGG16, but when I add layers to VGG16, I get an error that the layer is not found. 

**Describe the expected behavior**
I want to visualize activation layers using gradcam with guided guided backprop. 

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

Here's the Colab code with both the working example using just VGG16 and the broken example using VGG16 with added layers. 

https://colab.research.google.com/drive/1098Hp2icvleIQelkaLmPoIqAKuahs7JH

I'm attaching an image of a cat which is needed to run the colab. 

![cat 3](https://user-images.githubusercontent.com/36546688/76920921-ef21cf00-6889-11ea-8465-9b061a8f44c7.jpg)


**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

Here's the traceback:
```

Tensor(""block5_conv3_6/Identity:0"", shape=(None, 14, 14, 512), dtype=float32)
---------------------------------------------------------------------------
AssertionError                            Traceback (most recent call last)
<ipython-input-7-511b9293dd65> in <module>()
     60 # Get the score for target class
     61 with tf.GradientTape() as tape:
---> 62     conv_outputs, predictions = grad_model(np.array([img]))
     63     loss = predictions[:, 1]
     64 print('Prediction shape:', predictions.get_shape())

2 frames
/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)
    889           with base_layer_utils.autocast_context_manager(
    890               self._compute_dtype):
--> 891             outputs = self.call(cast_inputs, *args, **kwargs)
    892           self._handle_activity_regularization(inputs, outputs)
    893           self._set_mask_metadata(inputs, outputs, input_masks)

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/network.py in call(self, inputs, training, mask)
    706     return self._run_internal_graph(
    707         inputs, training=training, mask=mask,
--> 708         convert_kwargs_to_constants=base_layer_utils.call_context().saving)
    709 
    710   def compute_output_shape(self, input_shape):

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/network.py in _run_internal_graph(self, inputs, training, mask, convert_kwargs_to_constants)
    868     output_shapes = []
    869     for x in self.outputs:
--> 870       assert str(id(x)) in tensor_dict, 'Could not compute output ' + str(x)
    871       tensor = tensor_dict[str(id(x))]
    872       output_shapes.append(x.shape)

AssertionError: Could not compute output Tensor(""block5_conv3_6/Identity:0"", shape=(None, 14, 14, 512), dtype=float32)

```"
37678,Cannot create feature_column from sparse tensor of feature counts,"A common modeling pattern is to use sparse tensors to represent feature counts. For example, in a bag-of-words model, the input is a document represented by a tensor of token counts — the indices are token IDs and the values are their corresponding counts in the document.

Tensorflow's premade Estimators consume data via [feature_columns](https://www.tensorflow.org/api_docs/python/tf/feature_column). Currently, however, there is no way to create a feature_column directly from a sparse tensor.


**System information**
- TensorFlow version: all
- Are you willing to contribute it (Yes/No): maybe

**Will this change the current api? How?**
Yes, this change will add support to construct a feature_column directly from a sparse tensor.

**Who will benefit with this feature?**
Anyone who wants to use premade Estimators with feature data in sparse tensor form.
"
37676,tf2.1 tf.nn.ctc_loss slower!,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code : yes 
- OS Platform and Distribution: centos 7, not Distribution
- TensorFlow installed from docker: docker pull nvcr.io/nvidia/tensorflow:20.02-tf2-py3 .tensorflow version is 2.1.0

**Describe the current behavior**

Just run the forward algorithm and use watch -n 0.2 nvidia-smi to watch the GPU utilization rate always stay at 86% ~ 95%. However, after calculating tf.nn.ctc_loss, the GPU usage jitter is drastically from 0% to 85%. Seeing the decline in gpu utilization is particularly severe, personally guess that this tf.nn.ctc_loss is implemented by cpu, will there be a switch between gpu memory and memory when calculating loss?

**Describe the expected behavior**

Calculate the loss and update gradient normally, the GPU usage rate remains at 85%. Currently, the performance of calculating the loss using tf.nn.ctc_loss of tf2.1 does not meet expectations.
"
37675,TFRecord dataset reader causes excessive page faults,"<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):  Yes
- OS Platform and Distribution (e.g.,Linux Ubuntu 16.04): Ubuntu 14.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: 
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.0.0
- Python version: 2.7
- Bazel version (if compiling from source): 0.24.1
- GCC/Compiler version (if compiling from source): 7
- CUDA/cuDNN version: 10.0/7.5
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
tf.data.TFRecordDataset causes excessive page faults, especially when compression is used. We were able to tame the page faults in other parts of the graph by setting `TF_CPU_ALLOCATOR_USE_BFC=1`, but tf.data.TFRecordDataset doesn't seem to honor the allocator.

**Describe the expected behavior**
I expect, after setting `TF_CPU_ALLOCATOR_USE_BFC=1`, CPU memory allocations to be handled by the bfc allocator. There should not be large amounts of page faults because the tensorflow runtime manages memory allocation itself.


**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

We have an input_fn that's essentially:
```
train_dataset = tf.data.TFRecordDataset(
    filenames,
    compression_type=""ZLIB"",
    buffer_size=100 * 1024 * 1024,
    num_parallel_reads=16)
train_dataset = train_dataset.map(
    map_func=lambda x: (tf.io.parse_single_example(x, features), {}), 
    num_parallel_calls=num_parallel_calls)
train_dataset = train_dataset.batch(4)
train_dataset = train_dataset.prefetch(1)
```
Each record is about 8MB compressed, and 250MB decompressed.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

Flamegraph: https://drive.google.com/file/d/15LqZBBDov9Sikr9yt6OjMrVcw9IsebRk/view?usp=sharing

It's clear from the flamegraph that `tensorflow::io::ZlibInputStream::ReadBytesFromCache` and `tensorflow::io::BufferedInputStream::ReadNBytes` are dominated by page faults. `tensorflow::example::FastParseSingleExample` was also dominated by page faults when `TF_CPU_ALLOCATOR_USE_BFC=1` was not specified (not shown here,) but not when `TF_CPU_ALLOCATOR_USE_BFC=1` is specified (shown here.)

One source of page faults seems to be this line: https://github.com/tensorflow/tensorflow/blob/v2.0.0/tensorflow/core/lib/io/zlib_inputstream.cc#L175, according to the flamegraph."
37673,tf.Keras BatchNormalization layer causing impossible loss/accuracy in GAN training,"**System information** 
- Have I written custom code: yes
- OS Platform and Distribution: Windows 10, version 1809, os build 17763.1098
- Mobile device if the issue happens on mobile device: N/A
- TensorFlow installed from:  binary
- TensorFlow version: 2.0.0
- Python version: Python 3.7.6
- Bazel version: N/A
- GCC/Compiler version: N/A
- CUDA/cuDNN version: 10.1, V10.1.105
- GPU model and memory: GeForce RTX 2080 Ti, 11GB

I've been getting unusual losses and accuracies when training GANs with batch normalization layers in the discriminator using tf.keras. GANs have an optimal objective function value of log(4), which occurs when the discriminator is completely unable to discern real samples from fakes and hence predicts 0.5 for all samples. When I include BatchNormalization layers in my discriminator, both the generator and the discriminator achieve near perfect scores (high accuracy, low loss), which is impossible in an adversarial setting.

Without BatchNorm:
[This figure](https://i.stack.imgur.com/4F7l8.png) shows the losses (y) per epoch (x) when BN is not used. Note that occasional values below the theoretical minimum are due to the training being an iterative process. [This figure](https://i.stack.imgur.com/YGGCt.png) shows the accuracies when BN is not used, which settle at about 50% each. Both of these figures show reasonable values.

With BatchNorm:
[This figure](https://i.stack.imgur.com/HRzyc.png) shows the losses (y) per epoch (x) when BN is used. See how the GAN objective, which shouldn't fall below log(4), approaches 0. [This figure](https://i.stack.imgur.com/jS5XN.png) shows the accuracies when BN is used, with both approaching 100%. GANs are adversarial; the generator and discriminator can't both have 100% accuracy.

I suspect this has something to do with setting `model.trainable = False`.

Standalone code to reproduce and visualize can be found [here](https://gist.github.com/ConorLazarou/584af3f87a9a14503b9714580c567dab); set `BATCHNORM_MOMENTUM` to `0.9` to enable batchnorm or `None` to disable it

Update: It seems that BatchNorm in the generator also causes this problem, but has been harder to reproduce."
37671,Encoding images as TF_STRING Tensor in the C API,"TF Version : 1.15.0
OS : Windows 10 64-bit
Compiler : MSVC 2017


I'm attempting to load a TF SavedModel and run inference on it using the [C API](https://www.tensorflow.org/install/lang_c) for TF version 1.15.0.

**Essential outlay**:
Input Tensor(s) : 'encoded_image_string_tensor:0'
Output Tensor(s) [_not exhaustive_] : ['detection_boxes:0' , 'detection_scores:0', 'detection_classes:0']

While there's some documentation in the API header that describes how TF_Tensors of type TF_STRING are encoded, I can't seem to find any concrete examples/illustrations which is probably why I keep running into an error when attempting to encode an image.

I picked up some parts from [this](https://stackoverflow.com/questions/41138822/how-to-create-a-string-type-tensor-in-tensorflow-c-api) unchecked answer on StackOverflow to get started:
```
// char* image (contains a pointer to the image)
// const unsigned int imageSize (contains the size of the image)

std::vector<int64_t> inputDims = { static_cast<int64_t>(TF_DataTypeSize(TF_UINT64)) + static_cast<int64_t>(imageSize) };
size_t encodedSize = TF_StringEncodedSize(imageSize);
size_t totalSize = TF_DataTypeSize(TF_UINT64) + encodedSize;
char* encodedInput = new char[totalSize];
for (size_t i = 0; i < TF_DataTypeSize(TF_UINT64); i++)
  encodedInput[i] = 0;

TF_StringEncode((const char*)image.data, imageSize, encodedInput + 8, encodedSize, status);
if (TF_GetCode(status) == TF_OK) {
  std::cerr << ""Failed to encode image\n""; // The code enters this block and TF_Message(status) returns nothing to the output stream
  std::cerr << TF_Message(status) << std::endl;
  return false;
}
	
TF_Tensor* input = TF_NewTensor(TF_STRING, inputDims.data(), inputDims.size(), encodedInput, totalSize, NULL, 0);

```
Is there any guide on how to encode images as TF_STRING type tensors?

Thanks!




Please use [Netron](https://lutzroeder.github.io/netron/) to view the model if necessary
[saved_model.zip](https://github.com/tensorflow/tensorflow/files/4344883/saved_model.zip)

  "
37670,AutoGraph could not transform function,"I have tried to reproduce https://www.tensorflow.org/guide/function , and got a ""Please report this to the TensorFlow team."" message:

```
#!/usr/bin/env python
from __future__ import absolute_import, division, print_function, unicode_literals
import tensorflow as tf
import os
assert os.getenv(""AUTOGRAPH_VERBOSITY"") == ""10""
@tf.function
def add(a, b):
  return a + b
add(tf.ones([2, 2]), tf.ones([2, 2]))
```

output:

> 2020-03-17 18:06:18.294500: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.2
> 2020-03-17 18:06:19.371349: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
> 2020-03-17 18:06:19.384766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
> 2020-03-17 18:06:19.385191: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
> pciBusID: 0000:01:00.0 name: GeForce GTX 1060 6GB computeCapability: 6.1
> coreClock: 1.7715GHz coreCount: 10 deviceMemorySize: 5.93GiB deviceMemoryBandwidth: 178.99GiB/s
> 2020-03-17 18:06:19.385217: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.2
> 2020-03-17 18:06:19.386622: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
> 2020-03-17 18:06:19.387892: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
> 2020-03-17 18:06:19.388198: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
> 2020-03-17 18:06:19.389675: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
> 2020-03-17 18:06:19.390453: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
> 2020-03-17 18:06:19.393493: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
> 2020-03-17 18:06:19.393632: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
> 2020-03-17 18:06:19.394206: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
> 2020-03-17 18:06:19.394571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
> 2020-03-17 18:06:19.394880: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
> 2020-03-17 18:06:19.414984: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3301330000 Hz
> 2020-03-17 18:06:19.415262: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55714b447370 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
> 2020-03-17 18:06:19.415294: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
> 2020-03-17 18:06:19.415474: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
> 2020-03-17 18:06:19.416213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
> pciBusID: 0000:01:00.0 name: GeForce GTX 1060 6GB computeCapability: 6.1
> coreClock: 1.7715GHz coreCount: 10 deviceMemorySize: 5.93GiB deviceMemoryBandwidth: 178.99GiB/s
> 2020-03-17 18:06:19.416246: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.2
> 2020-03-17 18:06:19.416275: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
> 2020-03-17 18:06:19.416299: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
> 2020-03-17 18:06:19.416319: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
> 2020-03-17 18:06:19.416337: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
> 2020-03-17 18:06:19.416369: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
> 2020-03-17 18:06:19.416392: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
> 2020-03-17 18:06:19.416469: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
> 2020-03-17 18:06:19.417223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
> 2020-03-17 18:06:19.417977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
> 2020-03-17 18:06:19.418016: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.2
> 2020-03-17 18:06:19.888411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
> 2020-03-17 18:06:19.888453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
> 2020-03-17 18:06:19.888461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
> 2020-03-17 18:06:19.888673: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
> 2020-03-17 18:06:19.889087: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
> 2020-03-17 18:06:19.889446: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
> 2020-03-17 18:06:19.889799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5327 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1)
> 2020-03-17 18:06:19.891138: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55715b807340 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
> 2020-03-17 18:06:19.891155: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1060 6GB, Compute Capability 6.1
> WARNING:tensorflow:AutoGraph could not transform <function add at 0x7f2cdacf68b0> and will run it as-is.
> Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
> Cause: Bad argument number for Name: 3, expecting 4
> 
> 



**System information** 
- Have I written custom code: No
- OS Platform and Distribution: Arch Linux
- TensorFlow installed from: pacman -S python-tensorflow-cuda
- TensorFlow version (use command below): GIT_VERSION=""unknown"" VERSION=2.1.0
- Python version: 3.8.2
- CUDA/cuDNN version: Output of nvcc --version :
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Wed_Oct_23_19:24:38_PDT_2019
Cuda compilation tools, release 10.2, V10.2.89
- GPU model and memory: GeForce GTX 1060 6GB"
37669,Scatter nd add has legacy docstrings from scatter nd,"
## URL(s) with the issue:
https://www.tensorflow.org/api_docs/python/tf/tensor_scatter_nd_add

## Description of issue (what needs changing):
These sentences: 
> `indices` is an integer tensor containing indices into a new tensor of shape `shape`. The last dimension of `indices` can be at most the rank of `shape`:

Seem to be direct copy-paste from the docs of [`scatter_nd`](https://www.tensorflow.org/api_docs/python/tf/scatter_nd). However, there is no `shape` args in `scatter_nd_add`.

### Clear description

The docs should instead refer to `tensor.shape`.

### Correct links

Is the link to the source code correct? There is no link (that's another issue though I guess), only to the tf v1

### Parameters defined

Are all parameters defined and formatted correctly? Yes 

### Returns defined

Are return values defined? Yes

### Raises listed and defined

Are the errors defined? No errors raised apparently

### Usage example

Is there a usage example? Yes

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content? No, but there are some in `scatter_nd`, I guess it's enough

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style

Not right now
"
37667,Inconsistently sized samples with TimeseriesGenerator,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): **Yes**
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): **Win 10**
- TensorFlow installed from (source or
binary): **Binary** 
- TensorFlow version (use command below): **v2.1.0**
- Python version: **3.6.10**

**Describe the current behavior**
`tensorflow.keras.preprocessing.sequence.TimeseriesGenerator` generates inconsistently sized samples depending on parameters passed to `length, batch_size`. Ends up throwing input shape errors when passed into a model such as LSTM.

**Describe the expected behavior**
Each sample should be of size `(batch_size, length, n_features), (batch_size,)`.

**Standalone code to reproduce the issue** 
```
import numpy as np
from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator

def GenerateData(TIMESTEPS, BATCHSIZE, N_FEATURES, N_SAMPLES):
    """"""
    Generates batches of one-step forward samples (x_1,...,x_n), (y_n+1)
    Args: TIMESTEPS (int) Number of past observations
          BATCHSIZE (int) Number of samples in each batch
          N_FEATURES (int) Number of features in dataset
          N_SAMPLES (int) Length of dataset

    Each generated sample should be shape (BATCHSIZE, TIMESTEPS, N_FEATURES), (BATCHSIZE,)
    """"""
    # Dummy multivariate series
    dummy_x = np.random.rand(N_SAMPLES, N_FEATURES)
    dummy_y = np.array([x[0] for x in dummy_x]) # Predict future values of first column
    print(f'Data X Shape: {dummy_x.shape}, Data Y Shape: {dummy_y.shape}')

    generator = TimeseriesGenerator(data=dummy_x, targets=dummy_y,
                                    length=TIMESTEPS,
                                    batch_size=BATCHSIZE,
                                    sampling_rate=1,
                                    stride=1
                                   )

    # Check whether each sample is shaped correctly
    for n in range(len(generator)):
        x,y = generator[n]
        if x.shape != (BATCHSIZE, TIMESTEPS, N_FEATURES):
            print(f'Check index {n}.')
```

**Tests:**
```
[In]
GenerateData(TIMESTEPS=5, BATCHSIZE=2, N_FEATURES=5, N_SAMPLES=1000)
[Out]
Data X Shape: (1000, 5), Data Y Shape: (1000,)
Check index 497.
Index 497 shapes: (1, 5, 5), (1,)

[In]
GenerateData(TIMESTEPS=5, BATCHSIZE=2, N_FEATURES=5, N_SAMPLES=1001)
[Out]
Data X Shape: (1001, 5), Data Y Shape: (1001,)

[In]
GenerateData(TIMESTEPS=6, BATCHSIZE=2, N_FEATURES=5, N_SAMPLES=1001)
[Out]
Data X Shape: (1001, 5), Data Y Shape: (1001,)
Check index 497.
Index 497 shapes: (1, 6, 5), (1,)

[In]
GenerateData(TIMESTEPS=6, BATCHSIZE=32, N_FEATURES=5, N_SAMPLES=1001)
[Out]
Data X Shape: (1001, 5), Data Y Shape: (1001,)
Check index 31.
Index 31 shapes: (3, 6, 5), (3,)
```"
37666,enable_mixed_precision_graph_rewrite error,"tensorflow  1.14 and ubuntu 18.04
 
I'm trying the mixed precision training using the `tf.train.experimental.enable_mixed_precision_graph_rewrite`. 
By adding the wrapper of `enable_mixed_precision_graph_rewrite` to the `dnn_optimizer` in the [census wide-n-deep model](https://github.com/baidu-research/tensorflow-allreduce/blob/master/tensorflow/examples/learn/wide_n_deep_tutorial.py#L147), I find the tensorflow internal error of `ValueError: Tensor(""current_loss_scale/Read/ReadVariableOp:0"", shape=(), dtype=float32) must be from the same graph as Tensor(""head/weighted_loss/Sum:0"", shape=(), dtype=float32)`

```
    m = tf.estimator.DNNLinearCombinedClassifier(
        model_dir=model_dir,
        linear_feature_columns=crossed_columns,
        dnn_feature_columns=deep_columns,
        dnn_hidden_units=[100, 50])
```
is changed to
```
    m = tf.estimator.DNNLinearCombinedClassifier(
        model_dir=model_dir,
        linear_feature_columns=crossed_columns,
        dnn_feature_columns=deep_columns,
        dnn_optimizer=tf.train.experimental.enable_mixed_precision_graph_rewrite(
              tf.compat.v1.train.GradientDescentOptimizer(0.05)),
        dnn_hidden_units=[100, 50])
```
Maybe it's a compatible error of estimator and enable_mixed_precision_graph_rewrite, please give some help, thanks.
"
42787,Support Arabic and RTL in Tensorflow documentation,"As suggested by @lamberta, I am creating this issue to gather information about the extent to which Tensorflow website supports Arabic and RTL (Right to left) layout in general. 

In fact, I started translating two of Tensorflow's tutorials into Arabic with the following two PRs:
* https://github.com/tensorflow/docs-l10n/pull/121
* https://github.com/tensorflow/docs-l10n/pull/122

Knowing that Google Colab, like jupyter notebooks, supports html tags, I used them to ensure that the RTL text is displayed correctly, while keeping the LTR (left to right) layout for everything else in the tutorial, since the code needs to be LTR. Which results in a correct page layout as you can see in the following two notebooks rendering from the above two PRs:

* https://colab.research.google.com/github/abjed/docs-l10n/blob/ar-quickstart/site/ar/tutorials/quickstart/beginner.ipynb
* https://colab.research.google.com/github/abjed/docs-l10n/blob/ar-quickstart-advanced/site/ar/tutorials/quickstart/advanced.ipynb

Opening these notebooks in https://nbviewer.jupyter.org/ , which renders the notebook to html,  shows that the RTL layout defined by wrapping the Arabic text with `<div dir=""rtl""></div>` works as intended. As you can see in the following link:

* https://nbviewer.jupyter.org/github/abjed/docs-l10n/blob/ar-quickstart/site/ar/tutorials/quickstart/beginner.ipynb

So, my questions, are: 

1. Does the pipeline that generates the tutorials from the notebooks preserves these HTML tags, and displays them correctly (we might need to do an experiment)?
2. If not is there an alternative to support Arabic (RTL) properly? 

Thanks. "
37662,dimension lost by using tf_trt,"I use:
OS: ubuntu 18.04
cuda: 10.0
cudnn: 7.6.3
python:3.6
tensorflow-gpu:1.15
GPU: nvidia jetson xavier kit
memory: 32G

the source code line is [https://github.com/nwojke/deep_sort/blob/280b8bdb255f223813ff4a8679f3e1321b08cdfc/tools/generate_detections.py#L71](url)
the tf model is [https://drive.google.com/open?id=1bB66hP9voDXuoBoaCcKYY7a8IYzMMs4P](url)
old code : 
```
74    def __init__(self, checkpoint_filename, input_name=""images"",
75                output_name=""features""):
76        self.session = tf.Session()
77        with tf.gfile.GFile(checkpoint_filename, ""rb"") as file_handle:
78             graph_def = tf.GraphDef()
79             graph_def.ParseFromString(file_handle.read())
80         tf.import_graph_def(graph_def, name=""net"")
81         self.input_var = tf.get_default_graph().get_tensor_by_name(
82             ""net/%s:0"" % input_name)
83         self.output_var = tf.get_default_graph().get_tensor_by_name(
84             ""net/%s:0"" % output_name)
85 
86         assert len(self.output_var.get_shape()) == 2
87         assert len(self.input_var.get_shape()) == 4
88         self.feature_dim = self.output_var.get_shape().as_list()[-1]
89         self.image_shape = self.input_var.get_shape().as_list()[1:]
```
new code with tf_trt : 
```
91    def __init__(self, checkpoint_filename, input_name=""images"",
92                 output_name=""features""):
93        self.session = tf.Session()
94        with tf.gfile.GFile(checkpoint_filename, ""rb"") as file_handle:
95            graph_def = tf.GraphDef()
96            graph_def.ParseFromString(file_handle.read())
97        converter = trt.TrtGraphConverter(input_graph_def=graph_def, nodes_blacklist=[""images:0"", ""features:0""])
98        trt_graph = converter.convert()
99        tf.import_graph_def(trt_graph, name=""net"")
100       self.input_var = tf.get_default_graph().get_tensor_by_name(
101           ""net/%s:0"" % input_name)
102       self.output_var = tf.get_default_graph().get_tensor_by_name(
103           ""net/%s:0"" % output_name)
104
105       assert len(self.output_var.get_shape()) == 2
106       assert len(self.input_var.get_shape()) == 4
107       self.feature_dim = self.output_var.get_shape().as_list()[-1]
108        self.image_shape = self.input_var.get_shape().as_list()[1:]
```
error is follow : 
```
Traceback (most recent call last):
  File ""tools/generate_detections.py"", line 235, in <module>
    main()
  File ""tools/generate_detections.py"", line 229, in main
    encoder = create_box_encoder(args.model, batch_size=32)
  File ""tools/generate_detections.py"", line 120, in create_box_encoder
    image_encoder = ImageEncoder(model_filename, input_name, output_name)
  File ""tools/generate_detections.py"", line 105, in __init__
    assert len(self.output_var.get_shape()) == 2
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/tensor_shape.py"", line 827, in __len__
    raise ValueError(""Cannot take the length of shape with unknown rank."")
ValueError: Cannot take the length of shape with unknown rank.
```

then i print input and output tensor : 
```
print(self.input_var)
print(self.output_var)
```
the result is :
old code : 
```
Tensor(""net/images:0"",  shape=(?, 128, 64, 3), dtype=uint8)
Tensor(""net/features:0"", shape=(?, 128), dtype=float32)
```
new code :
```
Tensor(""net/images:0"",  shape=(?, 128, 64, 3), dtype=uint8)
Tensor(""net/features:0"", dtype=float32)
```
from above comparison, can found that new code lost tensor ""net/features:0"" dimension. please give me some advise, thank you
"
37661,"use tf_trt to optimize model, but cost too much time and too much memory consumed ","I use:
OS: ubuntu 18.04
cuda: 10.0
cudnn: 7.6.3
python:3.6
tensorflow-gpu:1.15
GPU: nvidia jetson xavier kit
memory: 32G

source code line is [https://github.com/YunYang1994/tensorflow-yolov3/blob/eb02b0731dfb1c2614e216c619ac7b22db57d994/core/utils.py#L126](url)
and changed as follows : 
```
    converter = trt.TrtGraphConverter(input_graph_def=frozen_graph_def,\
            nodes_blacklist=return_elements,\
            is_dynamic_op=True,\
            precision_mode=trt.TrtPrecisionMode.FP16,\
            max_workspace_size_bytes=1*10**9,\
            max_batch_size=10
            )
    trt_graph = converter.convert()
    with graph.as_default():
        return_elements = tf.import_graph_def(trt_graph,
                                              return_elements=return_elements)
```
the result fps is ok, detection fps improve from 5 to 15, but which cost too much time and memory. usually i need to wait for 15 minutes to get the model loaded, besides memory cost too much and just 1G surplus (total 32G), sometimes no enough memory to run the program and program  is killed itself.
then i saved converted model as follows:
```
    # save optimized graph
    with tf.gfile.GFile(""/home/xavier/python_ws/models/optimized_yolov3_f16.pb"", ""wb"") as f:
        f.write(trt_graph.SerializeToString())
```
and load the optimized model as follows : 
```
    with tf.gfile.FastGFile(pb_file, 'rb') as f:
        frozen_graph_def = tf.GraphDef()
        frozen_graph_def.ParseFromString(f.read())

    with graph.as_default():
        return_elements = tf.import_graph_def(frozen_graph_def,
                                              return_elements=return_elements)
```
but the result is as previous, and the problem dont get improved, how can i to solve the problem ?"
37660,Table not initialized with TF-TRT,"**System information**
Centos 7
TITAN Xp

CUDA 10
Tensorflow 1.15.0
Python 2.7

**Describe the current behavior**
I want to convert my model to TRT-INT8, however, when i get into converter.calibrate function, i get the error:
File ""/usr/lib64/python2.7/site-packages/tensorflow_core/python/compiler/tensorrt/trt_convert.py"", line 612, in calibrate
    fetches, feed_dict=feed_dict_fn() if feed_dict_fn else None)
  File ""/usr/lib64/python2.7/site-packages/tensorflow_core/python/client/session.py"", line 956, in run
    run_metadata_ptr)
  File ""/usr/lib64/python2.7/site-packages/tensorflow_core/python/client/session.py"", line 1180, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/usr/lib64/python2.7/site-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run
    run_metadata)
  File ""/usr/lib64/python2.7/site-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call
    raise type(e)(node_def, op, message)
**FailedPreconditionError: Table not initialized.**
         **[[node index_to_string_Lookup (defined at usr/lib64/python2.7/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]**

Node index_to_string_Lookup is a output node of my model.

I googled this problem and get the an suggest to add sess.run(tf.tables_initializer()), so i change the calibrate func by add calibration_sess.run(tf.tables_initializer()):
```
with session.Session(
  graph=self._calibration_graph,
  config=self._session_config) as calibration_sess:
  calibration_sess.run(tf.tables_initializer())
   for _ in range(num_runs):
     calibration_sess.run(
        fetches, feed_dict=feed_dict_fn() if feed_dict_fn else None)
```
but i failed, how can i slove this problem?
"
37659,Stateful Keras RNN Conversion,"**System information**
- Mac OSX
- 2.2.0.dev20200316


**Command used to run the converter or code if you’re using the Python API**
https://colab.research.google.com/drive/1H7EWTn9lQZ18R6DDBWJtJUxxX3XIVd2K


**The output from the converter invocation**

```
ValueError: Input 0 of node sequential_3/gru_3/AssignVariableOp was passed float from sequential_3/gru_3/Read/ReadVariableOp/resource:0 incompatible with expected resource.
```


**Any other info / logs**
I am trying to make predictions using an RNN model that maintains state across forward pass of batches of unit size and consecutive time samples. 
"
37656,Get different results in eager and graph mode when I use tf.keras.Reduction.NONE on Loss object.,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): 
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Ubuntu
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): 
- Python version: - Bazel
version (if compiling from source):2.2.0
- GCC/Compiler version (if compiling from
source): 
- CUDA/cuDNN version: - GPU model and memory:


[Colab example](https://colab.research.google.com/drive/1VWVty280phZLVsmB91aW6GqdQoEgDCdP)


Related [addons](https://github.com/tensorflow/addons/issues/1320)"
37654,Subclass of `tf.keras.Model` returns an empty list by `model.losses` ,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow):  yes, as follows

```
import tensorflow as tf
from tensorflow import keras

class MyModel(keras.Model):
    def __init__(self, **kwargs):
        super(MyModel, self).__init__(**kwargs)
    def call(self, inputs):
        self.add_loss(tf.reduce_mean(tf.square(inputs)))
        return inputs

x = tf.placeholder(tf.float32, [None, 5])
model = MyModel()
model(x)

model.losses  # returns []
model._losses # returns [<tf.Tensor 'my_model/Mean:0' shape=() dtype=float32>]
```

- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): macOS Catalina, 10.15.3
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): 1.12.0
- Python version: Python 2.7.17 |Anaconda, Inc.| (default, Oct 21 2019, 14:10:59)
[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)] on darwin

**Describe the current behavior**

The current returned value of model.losses does not contain elements in model._losses

**Describe the expected behavior**

As we can see in the code of `Network.losses`, it should return 

```
list(set(relevant_conditional_losses + unconditional_losses + self._losses))
```

If it does not contain tensors in model._losses, `model.add_loss` will not take any effects."
37653,Memory Leak in tf.data.Dataset.from_generator,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): No
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04):  Ubuntu 18.04.3 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
- TensorFlow installed from (source or
binary): binary
- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de 2.1.0
- Python version: Python 3.6.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from
source): 
- CUDA/cuDNN version: 
CUDA Version: 10.1
cudnn-10.1
- GPU model and memory:
TITAN RTX
24190MiB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
`tf.data.Dataset.from_generator` leaks memory after each call even if followed by `gc.collect()`.

**Describe the expected behavior**
Memory should be released when no reference exists for the dataset.

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```
import gc
import os

os.environ[""CUDA_VISIBLE_DEVICES""] = ""-1""
import tensorflow as tf
import tracemalloc
import linecache


def display_top(snapshot, key_type='lineno', limit=3):
    snapshot = snapshot.filter_traces((
        tracemalloc.Filter(False, ""<frozen importlib._bootstrap>""),
        tracemalloc.Filter(False, ""<unknown>""),
    ))
    top_stats = snapshot.statistics(key_type)

    print(""Top %s lines"" % limit)
    for index, stat in enumerate(top_stats[:limit], 1):
        frame = stat.traceback[0]
        # replace ""/path/to/module/file.py"" with ""module/file.py""
        filename = os.sep.join(frame.filename.split(os.sep)[-2:])
        print(""#%s: %s:%s: %.1f KiB""
              % (index, filename, frame.lineno, stat.size / 1024))
        line = linecache.getline(frame.filename, frame.lineno).strip()
        if line:
            print('    %s' % line)

    other = top_stats[limit:]
    if other:
        size = sum(stat.size for stat in other)
        print(""%s other: %.1f KiB"" % (len(other), size / 1024))
    total = sum(stat.size for stat in top_stats)
    print(""Total allocated size: %.1f KiB"" % (total / 1024))


def generator():
    yield tf.zeros(2, 3)


tracemalloc.start()
for i in range(1000):
    dataset = tf.data.Dataset.from_generator(generator, output_types=tf.int32, output_shapes=[None])
    del dataset
    gc.collect()
    snapshot = tracemalloc.take_snapshot()
    display_top(snapshot)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

```
Top 3 lines
#1: python3.6/_weakrefset.py:84: 159.5 KiB
    self.data.add(ref(item, self._remove))
#2: python3.6/_weakrefset.py:37: 38.2 KiB
    self.data = set()
#3: python3.6/_weakrefset.py:48: 32.4 KiB
    self._iterating = set()
461 other: 306.4 KiB
Total allocated size: 536.4 KiB
Top 3 lines
#1: python3.6/_weakrefset.py:84: 159.5 KiB
    self.data.add(ref(item, self._remove))
#2: python3.6/_weakrefset.py:37: 38.2 KiB
    self.data = set()
#3: python3.6/_weakrefset.py:48: 32.4 KiB
    self._iterating = set()
516 other: 343.1 KiB
Total allocated size: 573.1 KiB

...

Top 3 lines
#1: python3.6/weakref.py:335: 257.8 KiB
    self = ref.__new__(type, ob, callback)
#2: debug/tf_dataset_memory_leak.py:45: 189.7 KiB
    dataset = tf.data.Dataset.from_generator(generator, output_types=tf.int32, output_shapes=[None])
#3: ops/script_ops.py:257: 174.7 KiB
    return ""pyfunc_%d"" % uid
519 other: 2423.3 KiB
Total allocated size: 3045.5 KiB
```

It leaks 3MB in 1000 calls. In [some real projects](https://github.com/hankcs/HanLP/issues/1437), it can leak as much as 5GB and keeps increasing."
37652,Predict API does not work with VarLenFeature when batch inputs from different size,"
_I thought this [issue](https://github.com/tensorflow/serving/issues/1574)  was related to tensorflow / serving repo , but they told me it belongs to this repo, and hoped that put it here to discuss, so I created this issue_

-------------


**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): No
- OS Platform and Distribution (e.g.,Linux Ubuntu 16.04):  MacOS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: 
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.1.0
- Python version: 2.7.13
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling fromsource): 
- CUDA/cuDNN version: 
- GPU model and memory: 

**Describe the current behavior**

Predict API is not compatible with batch variable length inputs. Everything is ok when the input is just one instance, or multiple instances with the same length of a var length feature.

ps: Classify API works pretty good in this case.

I tried to generate the exact same model through Estimator, and tested the above situation through the Classify API, everything was perfect. But since TensorFlow 2.0, Predict API is the default and only signature of keras model. I really want to solve this problem, instead of switching back to using Estimator or custom signature. This problem has troubled me for a while, thank you very much for your help :)

**Describe the expected behavior**

Predict API should be as compatible with variable length input features as Classify API

### Source code / logs

Here is a simple code to reproduce this, which will output a model and serving from it.

[code]
```python
import tensorflow as tf

# generate dummy dataset 
def serialize_example(val, label):
    features = {
      'color': tf.train.Feature(bytes_list=tf.train.BytesList(value=val)),
      'label': tf.train.Feature(int64_list=tf.train.Int64List(value=[label]))
    }
    example_proto = tf.train.Example(features=tf.train.Features(feature=features))
    return example_proto.SerializeToString()

tfrecord_writer = tf.io.TFRecordWriter('./color.tfrecord')
for val, label in [([b'G', b'R'], 1), ([b'B'], 1), ([b'B', b'G'], 0), ([b'R'], 1)]:
    tfrecord_writer.write(serialize_example(val, label))
tfrecord_writer.close()

# load the data generate above
def parse(example_proto):
    feature_description = {
        'color': tf.io.VarLenFeature(tf.string) ,           # ** VarLenFeature **
        'label': tf.io.FixedLenFeature([], tf.int64)        
    }
    parsed_features = tf.io.parse_single_example(example_proto, feature_description)
    labels = parsed_features.pop('label')
    return parsed_features, labels
    
dataset = tf.data.TFRecordDataset('./color.tfrecord').map(parse).repeat(5).batch(2)

# feature column & inputs.
color_cat = tf.feature_column.categorical_column_with_vocabulary_list(
                    key='color', vocabulary_list=[""R"", ""G"", ""B""])    

color_emb = tf.feature_column.embedding_column(color_cat, dimension=4, combiner='mean')

inputs = {
    'color': tf.keras.layers.Input(name='color', shape=(None, ), sparse=True, dtype=tf.string)    
}

# build model
deep = tf.keras.layers.DenseFeatures([color_emb, ])(inputs)
output = tf.keras.layers.Dense(1, activation='sigmoid', name='output')(deep)
model = tf.keras.Model(inputs, output)
model.compile(optimizer='adam', loss='binary_crossentropy')

model.summary()

model.fit(dataset, epochs=5)
model.save('./dummy_model', save_format='tf')
```

[output log]
```
Model: ""model""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
color (InputLayer)           [(None, None)]            0         
_________________________________________________________________
dense_features (DenseFeature (None, 4)                 12        
_________________________________________________________________
output (Dense)               (None, 1)                 5         
=================================================================
Total params: 17
Trainable params: 17
Non-trainable params: 0
_________________________________________________________________
Epoch 1/5
10/10 [==============================] - 1s 119ms/step - loss: 0.7157
Epoch 2/5
10/10 [==============================] - 0s 4ms/step - loss: 0.7045
Epoch 3/5
10/10 [==============================] - 0s 4ms/step - loss: 0.6977
Epoch 4/5
10/10 [==============================] - 0s 5ms/step - loss: 0.6911
Epoch 5/5
10/10 [==============================] - 0s 5ms/step - loss: 0.6847
WARNING:tensorflow:From /Users/felix/Envs/tf2/lib/python2.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling __init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
INFO:tensorflow:Assets written to: ./dummy_model/assets
```

[saved_model signature]
```
$ saved_model_cli show --dir ./ --all
--------------------------------------------------------------------------
MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:

signature_def['__saved_model_init_op']:
  The given SavedModel SignatureDef contains the following input(s):
  The given SavedModel SignatureDef contains the following output(s):
    outputs['__saved_model_init_op'] tensor_info:
        dtype: DT_INVALID
        shape: unknown_rank
        name: NoOp
  Method name is:

signature_def['serving_default']:
  The given SavedModel SignatureDef contains the following input(s):
    inputs['color'] tensor_info:
        dtype: DT_STRING
        shape: (-1, -1)
        name: serving_default_color:0
  The given SavedModel SignatureDef contains the following output(s):
    outputs['output'] tensor_info:
        dtype: DT_FLOAT
        shape: (-1, 1)
        name: StatefulPartitionedCall_8:0
  Method name is: tensorflow/serving/predict
```
### Exact Steps to Reproduce
1. let me say there are two examples with the same shape , these work pretty good
```
curl -XPOST 0.0.0.0:8501/v1/models/dummy_model:predict -d '
{
  ""inputs"": {
    ""color"": [
      [""R""],
      [""G""]
    ]
  }
}'
----- response ----
{
    ""outputs"": [
        [
            0.370285
        ],
        [
            0.49326694
        ]
    ]
}

====================================================
curl -XPOST 0.0.0.0:8501/v1/models/dummy_model:predict -d '
{
  ""inputs"": {
    ""color"": [
      [""R"", ""G""],
      [""G"", ""B""]
    ]
  }
}'
------- response ---------
{
    ""outputs"": [
        [
            0.430707693
        ],
        [
            0.558493555
        ]
    ]
}
```
2. batch examples with different shape , does not work as expected
```
curl -XPOST 0.0.0.0:8501/v1/models/dummy_model:predict -d '
{
  ""inputs"": {
    ""color"": [
      [""R""],
      [""G"", ""B""]
    ]
  }
}'
-------- response -------

{ ""error"": ""Encountered list at unexpected size: 2 at level: 1 expected size: 1"" }

```
3.  ""instances"" key also not works

```
curl -XPOST 0.0.0.0:8501/v1/models/dummy_model:predict -d '
{
  ""instances"": [
    {""color"": [""R""]},
    {""color"": [""G"", ""B""]}
  ]
}'

--------- response -----------
{ ""error"": ""Failed to process element: 1 key: color of \'instances\' list. Error: Invalid argument: Expecting tensor size: 1 but got: 2"" }

```"
42786,Add CI for notebook formatting with nbfmt,"Previewing notebook diffs in GitHub can be difficult. We wrote [nbfmt.py](https://github.com/tensorflow/docs/blob/master/tools/nbfmt.py) to normalize the formatting for notebooks—alpha sort JSON keys, set indentation, etc.

After some successful manual tests (https://github.com/tensorflow/docs-l10n/pull/114, https://github.com/tensorflow/docs/pull/1498), the next step is to add it to the CI for new pull requests.
"
37650,Profiling information is not captured in tensorflow 2.0 version.,"I wanted to collect profiling information using current master tensorflow branch though the code for profiling is present inside Keras model. Still when I try to visualize the model in tensorboard its not collecting the profiling information.

Before the start of the test the message is thrown that the Profiler session started but when we load the logs to the tensorboard it shows empty profiling information.
profiler_session.cc:225] Profiler session started."
37649,Can't disable TensorFlow logs,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow):  Yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04):  Windows 10
- TensorFlow installed from (source or
binary):  pip
- TensorFlow version (use command below): 2.1.0
- Python version: 3.7.6
- CUDA/cuDNN version: 10.1
- GPU model and memory: 2080 Super, 8gb

**Describe the current behavior**
Can't prevent logging, on either cpu or gpu.

**Describe the expected behavior**
Should be able to disable logs.

**Standalone code to reproduce the issue** 
```
import os, logging
import tensorflow as tf

# One of these should prevent logs
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
logging.disable(logging.WARNING)
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)
logging.getLogger('tensorflow').setLevel(logging.FATAL)
tf.get_logger().setLevel(logging.ERROR)
tf.autograph.set_verbosity(1)

x = tf.constant([[1.0]])
tf.matmul(x, x)
```

Output:
```
2020-03-16 14:23:41.863992: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-03-16 14:23:43.322241: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-03-16 14:23:43.368176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:91:00.0 name: GeForce RTX 2080 SUPER computeCapability: 7.5
coreClock: 1.815GHz coreCount: 48 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 462.00GiB/s
2020-03-16 14:23:43.377139: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-03-16 14:23:43.384321: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-03-16 14:23:43.391462: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll 
2020-03-16 14:23:43.396430: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-03-16 14:23:43.403926: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-03-16 14:23:43.410194: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-03-16 14:23:43.422736: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-03-16 14:23:43.426995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-16 14:23:43.430185: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2020-03-16 14:23:43.437794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:
pciBusID: 0000:91:00.0 name: GeForce RTX 2080 SUPER computeCapability: 7.5
coreClock: 1.815GHz coreCount: 48 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 462.00GiB/s
2020-03-16 14:23:43.445464: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-03-16 14:23:43.449487: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-03-16 14:23:43.453326: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-03-16 14:23:43.457145: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-03-16 14:23:43.461076: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-03-16 14:23:43.464880: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-03-16 14:23:43.468782: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-03-16 14:23:43.473079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-16 14:23:44.093908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-16 14:23:44.098926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0
2020-03-16 14:23:44.101402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N
2020-03-16 14:23:44.105271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6265 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 SUPER, pci 
bus id: 0000:91:00.0, compute capability: 7.5)
2020-03-16 14:23:44.115422: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
```"
37645,AttributeError: module 'tensorflow.python.framework.op_def_registry' has no attribute 'register_op_list',"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): 
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): 
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): 
- Python version: - Bazel
version (if compiling from source):
- GCC/Compiler version (if compiling from
source): 
- CUDA/cuDNN version: - GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
37643,Could not use TPU provided by Google Collab with custom training,"I try to use TPU provided by Google Collab with custom training.
ANN-architecture - Transformer, with batch_size=128. I tested with GPU and all works fine. I wanted to speed up process and use larger batch. I modified code for TPU  but with TPU i got ""Your session crashed for an unknown reason"". I cant get it how to catch errors and etc.
Can you help me cause I cant train ANN with TPU.

Tensorflow version: 2.1.0 (also i used ""%tensorflow_version 2.x"" in collab notebook)

Warnings from logs:
> 2020-03-16 16:22:04.297929: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 780573800 exceeds 10% of system memory. 

> 2020-03-16 16:22:03.324150: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected


Preprocessing code
```
def _read_and_batch_from_files(input_arr, target_arr, shuffle=True, shuffle_val=20):

  dataset = tf.data.Dataset.from_tensor_slices((input_arr, target_arr))
  if shuffle:
    dataset = dataset.shuffle(buffer_size=6000, seed=shuffle_val,
                              reshuffle_each_iteration=True)
  else:
    dataset = dataset.batch(base_model_conf_obj.batch_size)
  dataset = dataset.repeat()
  return dataset
 
input_arr_test = np.load('/content/gdrive/My Drive/for_ds/x_test_tok.npy', allow_pickle=True)
target_arr_test = np.load('/content/gdrive/My Drive/for_ds/y_test_tok.npy', allow_pickle=True)
# i used this just for test before use init training/test files
train_dataset =  _read_and_batch_from_files(input_arr_test, target_arr_test, 
                                            shuffle=True, shuffle_val=20)
```

Initialize TPU-strategy
```
class SingleDeviceStrategy(object):
  def __enter__(self, *args, **kwargs):
    pass

  def __exit__(self, *args, **kwargs):
    pass

  def scope(self):
    return self

  def experimental_distribute_dataset(self, dataset):
    return dataset

  def experimental_run_v2(self, func, args, kwargs):
    return func(*args, **kwargs)

  def reduce(self, reduction_type, distributed_data, axis):  # pylint: disable=unused-argument
    return distributed_data

def connect_to_tpu(tpu=None):
  if tpu:
    cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu)
    tf.config.experimental_connect_to_host(cluster_resolver.get_master())
    tf.tpu.experimental.initialize_tpu_system(cluster_resolver)
    strategy = tf.distribute.experimental.TPUStrategy(cluster_resolver)
    return strategy, ""/task:1"" if os.environ.get(""COLAB_TPU_ADDR"") else ""/job:worker""
  return SingleDeviceStrategy(), """"
```

Training procedure
```
worker_tpu = 'grpc://' + os.environ['COLAB_TPU_ADDR']
d_strat, device = connect_to_tpu(worker_tpu)
with d_strat.scope():
  dataset_iter = iter(d_strat.experimental_distribute_dataset(train_dataset))
  for epoch in range(starting_epoch, num_epochs):
    start = time.time()
    inp, tar = next(dataset_iter)
    def tpu_step(inp, tar):
      tar_inp = tar[:, :-1]
      tar_real = tar[:, 1:]
      enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)
      with tf.GradientTape() as tape:
        predictions, _ = transformer(inp, tar_inp,
                                        True,
                                        enc_padding_mask,
                                        combined_mask,
                                        dec_padding_mask)
        loss = loss_function(tar_real, predictions)
        loss_ce = loss * (1.0 / base_model_conf.batch_size)
      variables = transformer.trainable_variables
      gradients = tape.gradient(loss_ce, variables)
      gradients = [(tf.clip_by_value(grad, -1.0, 1.0))
                        for grad in gradients]
      train_loss.update_state(loss_ce)
      train_op = optimizer.apply_gradients(zip(gradients, variables))
      with tf.control_dependencies([train_op]):
        return tf.cast(optimizer.iterations, tf.float32)

    @tf.function
    def train_step(inp, tar):
      distributed_metric = d_strat.experimental_run_v2(tpu_step, args=[inp, tar])
      step = d_strat.reduce(tf.distribute.ReduceOp.MEAN, distributed_metric, axis=None)
      return step

    step = tf.cast(train_step(inp, tar), tf.int32)
    train_loss.reset_states()
    train_loss_res = train_loss.result().numpy()
    print('Epoch {} Loss {:.4f}'.format(epoch + 1, train_loss_res,))
    print('Time taken for train 1 epoch: {} secs\n'.format(time.time() - start))
    ckpt_save_path = ckpt_manager.save()
    print('Saving checkpoint for epoch {} at {}'.format(epoch + 1, ckpt_save_path))
    print('Time taken for test 1 epoch: {} secs\n'.format(time.time() - start))
```"
37642,Error importing tensorflow,"Everything seemed to install OK,   MacOS Catalina 10.15.3, Python 3.7.6, but the code failed  on its first line :
       import tensorflow as tf
 with error message:
ModuleNotFoundError: No module named 'tensorflow.python.tools' 

tensorflow version 2.1.0 installed today with pip3 version 20.0.2, details in attached file

[junk.txt](https://github.com/tensorflow/tensorflow/files/4339257/junk.txt)

"
37640,Sparce Tensor wrong exeption Message when passing argument with wrong Type,"System information

    Have I written custom code (as opposed to using a stock
    example script provided in TensorFlow): No
    OS Platform and Distribution (e.g.,
    Linux Ubuntu 16.04): Linux Mint 19.3 (ubuntu)
    TensorFlow installed from (source or
    binary): binatry
    TensorFlow version (use command below): both tf-nightly and tf-2.1
    Python version: 3.8 and 3.6

**Describe the current behavior**
when passing an int32 tensor to Sparce Tensor
last Error displayed is:
```
ValueError: Unable to create eager SparseTensor. Check that your shape is correctly defined. Eager SparseTensors don't support unknown dimesions.
got shape:
    [4 4 4 4]
```
when looking back in stack trace, the right error is raced:

`ValueError: Tensor conversion requested dtype int64 for Tensor with dtype int32: <tf.Tensor: shape=(4,), dtype=int32, numpy=array([4, 4, 4, 4], dtype=int32)>`


**Describe the expected behavior**
one of the following:
1) conversion should not fail
2) last Error should be:
expected int64 tensor for shape argument got int32 tensor

**Standalone code to reproduce the issue** 
```
import tensorflow as tf

indices = tf.cast([[1,1,1,1],[1,3,1,1]],dtype=tf.int64)
shape = tf.cast([4,4,4,4],dtype=tf.int64)

heat_map = tf.SparseTensor(indices = indices, values = tf.ones(tf.shape(indices)[0]), dense_shape = shape)

indices = tf.cast([[1,1,1,1],[1,3,1,1]],dtype=tf.int64)
shape = tf.cast([4,4,4,4],dtype=tf.int32)

heat_map = tf.SparseTensor(indices = indices, values = tf.ones(tf.shape(indices)[0]), dense_shape = shape)
```


**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

```
Traceback (most recent call last):
  File ""/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow/python/framework/sparse_tensor.py"", line 142, in __init__
    dense_shape, name=""dense_shape"", dtype=dtypes.int64)
  File ""/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1317, in convert_to_tensor
    (dtype.name, value.dtype.name, value))
ValueError: Tensor conversion requested dtype int64 for Tensor with dtype int32: <tf.Tensor: shape=(4,), dtype=int32, numpy=array([4, 4, 4, 4], dtype=int32)>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/bhb/.vscode/extensions/ms-python.python-2020.2.64397/pythonFiles/ptvsd_launcher.py"", line 48, in <module>
    main(ptvsdArgs)
  File ""/home/bhb/.vscode/extensions/ms-python.python-2020.2.64397/pythonFiles/lib/python/old_ptvsd/ptvsd/__main__.py"", line 432, in main
    run()
  File ""/home/bhb/.vscode/extensions/ms-python.python-2020.2.64397/pythonFiles/lib/python/old_ptvsd/ptvsd/__main__.py"", line 316, in run_file
    runpy.run_path(target, run_name='__main__')
  File ""/usr/lib/python3.6/runpy.py"", line 263, in run_path
    pkg_name=pkg_name, script_name=fname)
  File ""/usr/lib/python3.6/runpy.py"", line 96, in _run_module_code
    mod_name, mod_spec, pkg_name, script_name)
  File ""/usr/lib/python3.6/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/test_sparce_tensor.py"", line 11, in <module>
    heat_map = tf.SparseTensor(indices = indices, values = tf.ones(tf.shape(indices)[0]), dense_shape = shape)
  File ""/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow/python/framework/sparse_tensor.py"", line 148, in __init__
    ""got shape:\n    {}"".format(dense_shape))
ValueError: Unable to create eager SparseTensor. Check that your shape is correctly defined. Eager SparseTensors don't support unknown dimesions.
got shape:
    [4 4 4 4]
Beendet
```
"
37639,TFLite build - missing interpreter_wrapper.i,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): amazonlinux
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:NA
- TensorFlow installed from (source or binary):binary
- TensorFlow version:2.1.0
- Python version:3.6.9
- Installed using virtualenv? pip? conda?:pip
- Bazel version (if compiling from source):2.0.0
- GCC/Compiler version (if compiling from source):7.2.1
- CUDA/cuDNN version:NA
- GPU model and memory:NA

**Describe the problem**
Running sh ./tensorflow/lite/tools/pip_package/build_pip_package.sh results in:
...
swig -python -c++ -I/root/tensorflow/tensorflow/lite/tools/pip_package/../../../.. -module interpreter_wrapper -outdir tflite_runtime -o interpreter_wrapper/interpreter_wrapper_wrap.cpp interpreter_wrapper/interpreter_wrapper.i
Unable to find file 'interpreter_wrapper/interpreter_wrapper.i'.
error: command 'swig' failed with exit status 1

**Provide the exact sequence of commands / steps that you executed before running into the problem**
Trying to build Tensorflow lite for AWS Lambda in amazonlinux.
Dockerfile:
FROM amazonlinux

WORKDIR /tflite

RUN yum groupinstall -y development
RUN yum install -y python3.7
RUN yum install -y python3-devel
RUN pip3 install numpy wheel
RUN git clone https://github.com/tensorflow/tensorflow.git
RUN sh ./tensorflow/tensorflow/lite/tools/pip_package/build_pip_package.sh


**Any other info / logs**
I am a total newb at compiling, so I apologise in advance for missing obvious info/logs.
The issue happens when `setup.py bdist bdist_wheel` is executed. I am afraid I cant figure out why the .i file is not there, or is not getting generated.
Do I need to generate them separately?

Thanks
"
37638,[2.x] SparseTensor shape becomes <unknown> after some operations if using tf.function,"With tf.function, if an argument `x` of a function is a 2-d `tf.SparseTensor`, its shape is `(None, None)`. However, after some operations such as `tf.sparse.transpose` and `tf.sparse.reduce_sum`, the shapes of the resulting tensors become `<unknown>`.

Please refer to this [script](https://colab.research.google.com/drive/17DqrrFVZePJlJsfymrRCXNGBMNPNKeqd) for reproduction.
"
37637,Segmentation fault when using Cloud TPU,"**System information** 
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian GNU/Linux 9.12 (stretch)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): preinstalled by Google Cloud Platform
- TensorFlow version (use command below): v1.15.0-rc3-22-g590d6ee
- Python version: Python 2.7.13 (default, Sep 26 2018, 18:42:22) [GCC 6.3.0 20170516] on linux2
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: ?
- GPU model and memory: TPU (provided by Google Cloud), version v3-8

**Describe the current behavior**
I request a VM and corresponding TPU using `ctpu up --zone=europe-west4-a --tpu-size=v3-8 --name europe4 --tf-version=1.15 --machine-type=n1-standard-2 --project my-project`
After connecting to it, and I start training a translation model using `t2t-trainer   --model=transformer   --hparams_set=transformer_tpu   --problem=translate_ende_wmt32k_packed   --train_steps=10   --eval_steps=3   --data_dir=gs://my-project/data   --output_dir=gs://my-project/training/tmp   --use_tpu=True   --cloud_tpu_name=europe4 --tpu_num_shards=8   --schedule=train` (this is the command specified in the [tutorial](https://cloud.google.com/tpu/docs/tutorials/transformer?hl=en#train_a_language_model_on_a_pod)).
But the training does not start, the command is aborted due to an segmentation fault:

```
my-user@europe4:~$ t2t-trainer   --model=transformer   --hparams_set=transformer_tpu   --problem=translate_ende_wmt32k_packed   --train_steps=10   --eval_steps=3   --data_dir=gs://my-project/data   --output_dir=gs://my-project/training/tmp   --use_tpu=True   --cloud_tpu_name=europe4 --tpu_num_shards=8   --schedule=train

WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/expert_utils.py:68: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/adafactor.py:27: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/multistep_optimizer.py:32: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/mesh_tensorflow/ops.py:4237: The name tf.train.CheckpointSaverListener is deprecated. Please use tf.estimator.CheckpointSaverListener instead.

WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/mesh_tensorflow/ops.py:4260: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.

WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensor2tensor/models/research/neural_stack.py:38: The name tf.nn.rnn_cell.RNNCell is deprecated. Please use tf.compat.v1.nn.rnn_cell.RNNCell instead.

WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensor2tensor/rl/gym_utils.py:235: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/trainer_lib.py:111: The name tf.OptimizerOptions is deprecated. Please use tf.compat.v1.OptimizerOptions instead.

WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.

WARNING:tensorflow:From /usr/local/bin/t2t-trainer:32: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.

WARNING:tensorflow:From /usr/local/bin/t2t-trainer:32: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.

WARNING:tensorflow:From /usr/local/bin/t2t-trainer:33: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/hparams_lib.py:49: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.

W0316 12:49:12.574630 140506290238912 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/hparams_lib.py:49: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.

WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/trainer_lib.py:839: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

W0316 12:49:12.673067 140506290238912 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/trainer_lib.py:839: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/trainer_lib.py:116: The name tf.GraphOptions is deprecated. Please use tf.compat.v1.GraphOptions instead.

W0316 12:49:12.675126 140506290238912 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/trainer_lib.py:116: The name tf.GraphOptions is deprecated. Please use tf.compat.v1.GraphOptions instead.

WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/trainer_lib.py:129: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.

W0316 12:49:12.675529 140506290238912 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/trainer_lib.py:129: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.

I0316 12:49:12.683859 140506290238912 discovery.py:271] URL being requested: GET https://www.googleapis.com/discovery/v1/apis/tpu/v1alpha1/rest
I0316 12:49:12.725476 140506290238912 discovery.py:867] URL being requested: GET https://tpu.googleapis.com/v1alpha1/projects/my-project/locations/europe-west4-a/nodes/europe4?alt=json
I0316 12:49:12.725781 140506290238912 transport.py:157] Attempting refresh to obtain initial access_token
I0316 12:49:12.812311 140506290238912 discovery.py:271] URL being requested: GET https://www.googleapis.com/discovery/v1/apis/tpu/v1alpha1/rest
I0316 12:49:12.851186 140506290238912 discovery.py:867] URL being requested: GET https://tpu.googleapis.com/v1alpha1/projects/my-project/locations/europe-west4-a/nodes/europe4?alt=json
I0316 12:49:12.851486 140506290238912 transport.py:157] Attempting refresh to obtain initial access_token
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/text_encoder.py:940: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.

W0316 12:49:12.991070 140506290238912 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/text_encoder.py:940: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.

WARNING:tensorflow:Estimator's model_fn (<function wrapping_model_fn at 0x7fc9fc26f398>) includes params argument, but params are not passed to Estimator.
W0316 12:49:13.249932 140506290238912 estimator.py:1984] Estimator's model_fn (<function wrapping_model_fn at 0x7fc9fc26f398>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:Using config: {'_save_checkpoints_secs': None, '_num_ps_replicas': 0, '_keep_checkpoint_max': 20, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=2, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2), '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc9fc006510>, '_model_dir': 'gs://my-project/training/tmp', '_protocol': None, '_save_checkpoints_steps': 1000, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': gpu_options {
  per_process_gpu_memory_fraction: 0.95
}
allow_soft_placement: true
graph_options {
}
cluster_def {
  job {
    name: ""worker""
    tasks {
      key: 0
      value: ""10.240.1.18:8470""
    }
  }
}
isolate_session_state: true
, 'use_tpu': True, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7fc9fd129250>, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': None, '_experimental_max_worker_delay_secs': None, '_evaluation_master': u'grpc://10.240.1.18:8470', '_eval_distribute': None, '_train_distribute': None, '_master': u'grpc://10.240.1.18:8470'}
I0316 12:49:13.251069 140506290238912 estimator.py:209] Using config: {'_save_checkpoints_secs': None, '_num_ps_replicas': 0, '_keep_checkpoint_max': 20, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=2, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2), '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc9fc006510>, '_model_dir': 'gs://my-project/training/tmp', '_protocol': None, '_save_checkpoints_steps': 1000, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': gpu_options {
  per_process_gpu_memory_fraction: 0.95
}
allow_soft_placement: true
graph_options {
}
cluster_def {
  job {
    name: ""worker""
    tasks {
      key: 0
      value: ""10.240.1.18:8470""
    }
  }
}
isolate_session_state: true
, 'use_tpu': True, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7fc9fd129250>, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': None, '_experimental_max_worker_delay_secs': None, '_evaluation_master': u'grpc://10.240.1.18:8470', '_eval_distribute': None, '_train_distribute': None, '_master': u'grpc://10.240.1.18:8470'}
INFO:tensorflow:_TPUContext: eval_on_tpu True
I0316 12:49:13.252732 140506290238912 tpu_context.py:209] _TPUContext: eval_on_tpu True
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensor2tensor/bin/t2t_trainer.py:328: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.

W0316 12:49:13.368489 140506290238912 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/bin/t2t_trainer.py:328: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.

INFO:tensorflow:Querying Tensorflow master (grpc://10.240.1.18:8470) for TPU system metadata.
I0316 12:49:14.371850 140506290238912 tpu_system_metadata.py:78] Querying Tensorflow master (grpc://10.240.1.18:8470) for TPU system metadata.
2020-03-16 12:49:14.373167: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:356] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
INFO:tensorflow:Found TPU system:
I0316 12:49:14.384757 140506290238912 tpu_system_metadata.py:148] Found TPU system:
INFO:tensorflow:*** Num TPU Cores: 8
I0316 12:49:14.385152 140506290238912 tpu_system_metadata.py:149] *** Num TPU Cores: 8
INFO:tensorflow:*** Num TPU Workers: 1
I0316 12:49:14.385714 140506290238912 tpu_system_metadata.py:150] *** Num TPU Workers: 1
INFO:tensorflow:*** Num TPU Cores Per Worker: 8
I0316 12:49:14.385898 140506290238912 tpu_system_metadata.py:152] *** Num TPU Cores Per Worker: 8
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 18153004822558697212)
I0316 12:49:14.386076 140506290238912 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 18153004822558697212)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 3131077452827063453)
I0316 12:49:14.386504 140506290238912 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 3131077452827063453)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 285863435827645433)
I0316 12:49:14.386677 140506290238912 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 285863435827645433)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 7574921377020815195)
I0316 12:49:14.386845 140506290238912 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 7574921377020815195)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 6156291304405420504)
I0316 12:49:14.387026 140506290238912 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 6156291304405420504)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 2147180529096251620)
I0316 12:49:14.387211 140506290238912 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 2147180529096251620)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 16404941304364531224)
I0316 12:49:14.387377 140506290238912 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 16404941304364531224)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 4697263980141791991)
I0316 12:49:14.387541 140506290238912 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 4697263980141791991)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 15388571662384413779)
I0316 12:49:14.387706 140506290238912 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 15388571662384413779)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 15368005949461242606)
I0316 12:49:14.387868 140506290238912 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 15368005949461242606)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 2717797883427288239)
I0316 12:49:14.388044 140506290238912 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 2717797883427288239)
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/training_util.py:236: initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0316 12:49:14.393487 140506290238912 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/training_util.py:236: initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
INFO:tensorflow:Calling model_fn.
I0316 12:49:14.414323 140506290238912 estimator.py:1145] Calling model_fn.
INFO:tensorflow:num_partitions = 1 partition_id = 0
I0316 12:49:14.414944 140506290238912 problem.py:826] num_partitions = 1 partition_id = 0
INFO:tensorflow:Reading data files from gs://my-project/data/translate_ende_wmt32k_packed-train*
I0316 12:49:14.415206 140506290238912 problem.py:644] Reading data files from gs://my-project/data/translate_ende_wmt32k_packed-train*
INFO:tensorflow:partition: 0 num_data_files: 100
I0316 12:49:14.476078 140506290238912 problem.py:670] partition: 0 num_data_files: 100
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:680: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0316 12:49:14.479042 140506290238912 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:680: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/data_reader.py:275: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.
Instructions for updating:
Use eager execution and: 
`tf.data.TFRecordDataset(path)`
W0316 12:49:14.603265 140506290238912 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/data_reader.py:275: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.
Instructions for updating:
Use eager execution and: 
`tf.data.TFRecordDataset(path)`
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/data_reader.py:37: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0316 12:49:14.820894 140506290238912 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/data_reader.py:37: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/data_reader.py:417: output_shapes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_shapes(dataset)`.
W0316 12:49:14.870455 140506290238912 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/data_reader.py:417: output_shapes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_shapes(dataset)`.
INFO:tensorflow:Setting T2TModel mode to 'train'
I0316 12:49:14.991553 140506290238912 t2t_model.py:2248] Setting T2TModel mode to 'train'
INFO:tensorflow:Using variable initializer: uniform_unit_scaling
I0316 12:49:15.940623 140506290238912 api.py:255] Using variable initializer: uniform_unit_scaling
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/autograph/converters/directives.py:117: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

W0316 12:49:15.987256 140506290238912 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/autograph/converters/directives.py:117: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/autograph/impl/api.py:255: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0316 12:49:16.365370 140506290238912 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/autograph/impl/api.py:255: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_33288_512.bottom
I0316 12:49:16.533937 140506290238912 t2t_model.py:2248] Transforming feature 'inputs' with symbol_modality_33288_512.bottom
INFO:tensorflow:Transforming feature 'inputs_position' with identity_modality.bottom
I0316 12:49:16.568705 140506290238912 t2t_model.py:2248] Transforming feature 'inputs_position' with identity_modality.bottom
INFO:tensorflow:Transforming feature 'inputs_segmentation' with identity_modality.bottom
I0316 12:49:16.570141 140506290238912 t2t_model.py:2248] Transforming feature 'inputs_segmentation' with identity_modality.bottom
INFO:tensorflow:Transforming feature 'targets' with symbol_modality_33288_512.targets_bottom
I0316 12:49:16.571368 140506290238912 t2t_model.py:2248] Transforming feature 'targets' with symbol_modality_33288_512.targets_bottom
INFO:tensorflow:Transforming feature 'targets_position' with identity_modality.bottom
I0316 12:49:16.598011 140506290238912 t2t_model.py:2248] Transforming feature 'targets_position' with identity_modality.bottom
INFO:tensorflow:Transforming feature 'targets_segmentation' with identity_modality.bottom
I0316 12:49:16.599239 140506290238912 t2t_model.py:2248] Transforming feature 'targets_segmentation' with identity_modality.bottom
INFO:tensorflow:Building model body
I0316 12:49:16.600420 140506290238912 t2t_model.py:2248] Building model body
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:96: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
W0316 12:49:16.674422 140506290238912 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:96: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/common_layers.py:3077: The name tf.layers.Dense is deprecated. Please use tf.compat.v1.layers.Dense instead.

W0316 12:49:16.710041 140506290238912 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/common_layers.py:3077: The name tf.layers.Dense is deprecated. Please use tf.compat.v1.layers.Dense instead.

Segmentation fault
```


**Describe the expected behavior**
The training should start. This worked 2 weeks ago.

**Standalone code to reproduce the issue** 
Request a VM and TPU using `ctpu up --zone=europe-west4-a --tpu-size=v3-8 --name europe4 --tf-version=1.15 --machine-type=n1-standard-2 --project my-project`
Then, generate the data using `t2t-datagen --problem=translate_ende_wmt32k_packed --data_dir=${DATA_DIR} --tmp_dir=${TMP_DIR}`
Finally, start the training using `t2t-trainer --model=transformer --hparams_set=transformer_tpu --problem=translate_ende_wmt32k_packed --eval_steps=3 --data_dir=${DATA_DIR} --output_dir=${MODEL_DIR}/translate_ende --use_tpu=True --cloud_tpu_name=${TPU_NAME} --train_steps=10` 
Both steps are copied from the tutorial: https://cloud.google.com/tpu/docs/tutorials/transformer?hl=en#train_a_language_model_on_a_single_or_a_pod

This did work 2 weeks ago, I'm not sure what changed in the meantime.
Training using only a CPU works fine."
37635,Class type changes after saving and loading,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: 
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.1.0
- Python version: 3.8.1
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
Creating a model containing a certain layer class (in my case `tf.keras.layers.BatchNormalization`) changes after saving and loading the model.

Before loading it is of type 
```python
tensorflow.python.keras.layers.normalization_v2.BatchNormalization
```

Which is the same as `tf.keras.layers.BatchNormalization`, but after loading it is of type:

```python
tensorflow.python.keras.layers.normalization.BatchNormalization
```

Which is not the same.

**Describe the expected behavior**
Expected behavior is that the type of the layer remains unchanged after saving and loading.

**Standalone code to reproduce the issue** 
```python
import tensorflow as tf

model = tf.keras.Sequential([
	tf.keras.layers.BatchNormalization()
])
model.build(input_shape=(1,))
model.save('/tmp/model.h5')

loaded_model = tf.keras.models.load_model('/tmp/model.h5')

# True
print(isinstance(model.layers[0], tf.keras.layers.BatchNormalization))

# False
print(isinstance(loaded_model.layers[0], tf.keras.layers.BatchNormalization))

# AttributeError: module 'tensorflow' has no attribute 'python'
import tensorflow.python.keras.layers.normalization
print(isinstance(loaded_model.layers[0], tensorflow.python.keras.layers.normalization.BatchNormalization))
```

**Other info / logs** Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
The reason I want to do this is because I want to freeze updating of the batch normalization weights, which can be done by setting `layer.training = False`. My goal is to do something like this:
```python
for l in model.layers:
    if isinstance(l, tf.keras.layers.BatchNormalization):
        l.training = False
```"
37633,set_shape is not loaded from saved model,"**System information** 
- TensorFlow version (use command below): 2.1.0
- Python version: 3.6.10

**Describe the current behavior**
When loading a saved keras model that contains .set_shape on a tensor, this is not loaded.

``` python
import tensorflow as tf

inp = tf.keras.Input((None, 3))
inp.set_shape((None, 2, 3))
x = tf.keras.layers.Dense(3)(inp)

model = tf.keras.Model(inp, x)
model.summary()

model.save(""test.h5"")
loaded = tf.keras.models.load_model(""test.h5"")
loaded.summary()
```

model.summary():
```
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, None, 3)]         0         
_________________________________________________________________
dense (Dense)                (None, 2, 3)              12        
=================================================================
```

loaded.summary():

```
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, None, 3)]         0         
_________________________________________________________________
dense (Dense)                (None, None, 3)           12        
=================================================================
```
--> Shape is not identical!
"
37630,"TFRecordDataset is loaded into memory entirely, yielding out-of-memory","

**System information** 
System information

Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): complex_model_m_gpu tier on the nightly docker image of tf
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: /
TensorFlow installed from (source or
binary): - TensorFlow version (use command below): Nightly
Python version: - 3.6.9
version (if compiling from source): /
GCC/Compiler version (if compiling from
source): /
CUDA/cuDNN version: - GPU model and memory: Using K80 GPU's

**Describe the current behavior**
I previously loaded my images as npz bytestrings into a TFRecord, together with the label of the image. I would then convert the image and label to the expected format using TFRecordDataset mappings onto `tf.py_function()`s for training . 

I now try to do the formatting beforehand. This yields TFRecords that are much larger. I therefore use the `GZIP` compression. At runtime though, it seems the entire TFRecord is loaded into memory, making the training crash after some time. I even split the TFRecords into smaller partitions, but this makes no difference. How should this be tackled and/or is this normal behavior?


![image](https://user-images.githubusercontent.com/39876179/76743276-ab887180-6772-11ea-9017-5de8f0683a36.png)
"
37629,Build TF 2.1.0 with RHEL6/RHEL7,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (Linux Redhat 6):
- TensorFlow installed from (source ):
- TensorFlow version:  2.1.0
- Python version:   3.7.2
- Bazel version (if compiling from source):   0.28.1
- GCC/Compiler version (if compiling from source):    7.4.0

**Describe the problem**
Not able to build TF 2.1.0 on RHEL6 and RHEL7

**Provide the exact sequence of commands / steps that you executed before running into the problem**

./configure
bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package

**Any other info / logs**

ERROR: /servers/scratch03/niraj/tf-2.1/tensorflow-2.1.0/tensorflow/compiler/tf2tensorrt/BUILD:524:1: SWIGing tensorflow/compiler/tf2tensorrt/utils/py_utils.i failed (Exit 1)
/home/niraj/.cache/bazel/_bazel_niraj/install/efb644d4834d79efdfe4de9f85220414/_embedded_binaries/process-wrapper: /usr/lib64/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by /home/niraj/.cache/bazel/_bazel_niraj/install/efb644d4834d79efdfe4de9f85220414/_embedded_binaries/process-wrapper)
/home/niraj/.cache/bazel/_bazel_niraj/install/efb644d4834d79efdfe4de9f85220414/_embedded_binaries/process-wrapper: /usr/lib64/libstdc++.so.6: version `GLIBCXX_3.4.18' not found (required by /home/niraj/.cache/bazel/_bazel_niraj/install/efb644d4834d79efdfe4de9f85220414/_embedded_binaries/process-wrapper)
"
37628,ESP32 tensor allocation in PSRAM,"I'm using the Arduino TensorFlowLite library with an ESP32, and after testing some simple models successfully, i'm trying to load '[Optimized models for common mobile and edge use cases](https://www.tensorflow.org/lite/models)'. 
Model size is limited by the ESP32's standard 4MB FLASH, and tensor allocation by its default 520KB RAM. However, the maximum tensor pool size that can be allocated seems to be around 95*1024B; hitting the limit of ESP.getMaxAllocHeap()
Now, many dev boards (e.g. ESP32-CAM) have 4-8MB external PSRAM. As far as i can see, this is only available via dedicated allocation functions. Can the TensorFlowLite library be expanded to allow tensor allocation in PSRAM? Espressif has an example of how to handle this in the [esp32-camera](https://github.com/espressif/esp32-camera/blob/9f99b1b03ccfbd1937c3aee96f563af9df1e0ba6/driver/camera.c#L253) repo. Thanks for considering this.
"
37627,[Proposal] use numpy.asarray_chkfinite in tf.keras.backend.cast_to_floatx,"Maybe we can use `numpy.asarray_chkfinite` instead of `numpy.asarray` in `tf.keras.backend.cast_to_floatx`?

```python
@keras_export('keras.backend.cast_to_floatx')
def cast_to_floatx(x):
  if isinstance(x, (ops.Tensor,
                    variables_module.Variable,
                    sparse_tensor.SparseTensor)):
    return math_ops.cast(x, dtype=floatx())
  return np.asarray(x, dtype=floatx())
```

It can help prevent user pass value which contains None, `inf`, `np.nan` or `np.inf` as input.

related to issue #37196

"
37626,[tflite][java] has_rank_one_input_condition error when use runForMultipleInputsOutputs(),"I obtain an error when use two inputs in runForMultipleInputsOutputs().

**System information** 
- Custom code
- Android API 29
- Android simulator
- Used libraries:
-- org.tensorflow:tensorflow-lite:2.1.0
-- org.tensorflow:tensorflow-lite-gpu:2.1.0
-- org.tensorflow:tensorflow-lite-support:0.0.0-nightly

- Used model information
[The model tolite file](https://github.com/tensorflow/tensorflow/files/4336843/classifier_lstm2.tflite.zip)

[{'name': 'input_1', 'index': 0, 'shape': array([ 1, 10], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0)}, {'name': 'input_2', 'index': 1, 'shape': array([1, 2], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0)}]

```
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 10)]         0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 10, 256)      15616       input_1[0][0]                    
__________________________________________________________________________________________________
input_2 (InputLayer)            [(None, 2)]          0                                            
__________________________________________________________________________________________________
lstm_1 (LSTM)                   (None, 256)          525312      embedding_1[0][0]                
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 258)          0           input_2[0][0]                    
                                                                 lstm_1[0][0]                     
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 61)           15799       concatenate[0][0]                
==================================================================================================
```

**The error**
```
java.lang.IllegalArgumentException: Internal error: Failed to run on the given Interpreter: tensorflow/lite/kernels/select.cc:80 data->has_rank_one_input_condition was not true.
Node number 23 (SELECT) failed to prepare.
Node number 19 (WHILE) failed to invoke.
```

**The code**

```
MappedByteBuffer tfliteModelCaption = FileUtil.loadMappedFile(activity, ""classifier_caption.tflite"");
Interpreter.Options options = new Interpreter.Options();
Interpreter tflite = new Interpreter(tfliteModelCaption, options);
float[][] inputString = new float[1][10];
inputString[0][9] = 4;
float[][] inputData = new float[1][2];
inputData[0][0] = 0;
inputData[0][1] = 1;
Object[] inputArray = {inputString, inputData};
Map<Integer, Object> outputMap = new HashMap<>();
outputMap.put(0, new float[1][61]);
tflite.runForMultipleInputsOutputs(inputArray, outputMap);
tflite.close();
float[] result = ((float[][]) outputMap.get(0))[0];
textViewAge.setText(""Test: "" + Arrays.toString(result));
```

The error seems to means the shape of the inputs does not fit the model input, but I checked it many time and for me it looks the same. I create a similar model with only one input (no input_2)  and I can use it without error.




"
37625,source code about the libhexagon_interface.so,"Hello, 
TFlite heagon delegate is based on Hexagon nn.
I have got the hexagon nn SDK from Qualcomm, but I can not build the ""libhexagon_interface.so"".
Google add 4 fucntions in libhexagon_interface:
```
void hexagon_nn_global_teardown(void);
void hexagon_nn_global_init(void);
bool hexagon_nn_is_device_supported();
int hexagon_nn_hexagon_interface_version(void);
```

Could you please share the source code of the foure functions  and the ""android.min"" for building libhexagon_interface.so ? "
37623,Building tensorflow lite for Android (C++) undefined reference error,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>


**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04, MacOS 10.15.3
- TensorFlow installed from (source or binary): source
- TensorFlow version: latest
- Python version: 2.7.17
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source): 2.2.0
- GCC/Compiler version (if compiling from source): 7.5.0
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

I want to build tensorflow lite in android with C++, so I followed the [document](https://www.tensorflow.org/lite/guide/build_arm64)
Build works fine, but when I load libtensorflowlite.a into an Android and build, undefined reference of default libraries apperas.
At first, undefined std::__cxx11::string... error happened, so I added a compiler flag(-D_GLIBCXX_USE_CXX11_ABI=0).
But other undefined error still happens.

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
CMakeLists.txt
```
CMAKE_MINIMUM_REQUIRED(VERSION 3.3)
project(tflite)

add_library(tflite INTERFACE)

set (TFLITE_PATH ${CMAKE_CURRENT_SOURCE_DIR})
set (TFLITE_LIB_PATH ""${TFLITE_PATH}/${CMAKE_ANDROID_ARCH_ABI}"")
set (TFLITE_INCLUDE_PATH ""${TFLITE_PATH}/include"")

target_link_libraries(
        tflite
        INTERFACE
        ""${TFLITE_LIB_PATH}/libtensorflow-lite.a""
)

target_include_directories(
        tflite
        INTERFACE
        ""${TFLITE_INCLUDE_PATH}""
        ""${TFLITE_INCLUDE_PATH}/tensorflow""
        ""${TFLITE_INCLUDE_PATH}/tensorflow/thirdparty""
)
```

Error log
```
Build command failed.
Error while executing process /Users/yonggyulee/Library/Android/sdk/cmake/3.6.4111459/bin/cmake with arguments {--build /Users/yonggyulee/Downloads/cppinclude-a4125304137c01ff2f171981e6cdaab051d36d47/app/.cxx/cmake/debug/arm64-v8a --target cpp-test}
[1/4] Building CXX object src/main/cpp/cpp_test/CMakeFiles/cpp-test.dir/src/TestClass.cpp.o
[2/4] Building CXX object src/main/cpp/cpp_test/CMakeFiles/cpp-test.dir/src/LoadModel.cpp.o
[3/4] Building CXX object src/main/cpp/cpp_test/CMakeFiles/cpp-test.dir/src/tftest.cpp.o
[4/4] Linking CXX shared library ../../../../build/intermediates/cmake/debug/obj/arm64-v8a/libcpp-test.so
FAILED: : && /Users/yonggyulee/Library/Android/sdk/ndk/20.0.5594570/toolchains/llvm/prebuilt/darwin-x86_64/bin/clang++  --target=aarch64-none-linux-android24 --gcc-toolchain=/Users/yonggyulee/Library/Android/sdk/ndk/20.0.5594570/toolchains/llvm/prebuilt/darwin-x86_64 --sysroot=/Users/yonggyulee/Library/Android/sdk/ndk/20.0.5594570/toolchains/llvm/prebuilt/darwin-x86_64/sysroot -fPIC -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -fno-addrsig -Wa,--noexecstack -Wformat -Werror=format-security   -O0 -fno-limit-debug-info  -Wl,--exclude-libs,libgcc.a -Wl,--exclude-libs,libatomic.a -static-libstdc++ -Wl,--build-id -Wl,--warn-shared-textrel -Wl,--fatal-warnings -Wl,--no-undefined -Qunused-arguments -Wl,-z,noexecstack -shared -Wl,-soname,libcpp-test.so -o ../../../../build/intermediates/cmake/debug/obj/arm64-v8a/libcpp-test.so src/main/cpp/cpp_test/CMakeFiles/cpp-test.dir/src/TestClass.cpp.o src/main/cpp/cpp_test/CMakeFiles/cpp-test.dir/src/LoadModel.cpp.o src/main/cpp/cpp_test/CMakeFiles/cpp-test.dir/src/tftest.cpp.o  ../../../../src/main/cpp/cpp_test/tflite/arm64-v8a/libtensorflow-lite.a -latomic -lm && :
../../../../src/main/cpp/cpp_test/tflite/arm64-v8a/libtensorflow-lite.a(model.o): In function `tflite::FlatBufferModel::GetMinimumRuntime() const':
model.cc:(.text+0x51c): undefined reference to `std::string::_Rep::_S_empty_rep_storage'
model.cc:(.text+0x574): undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(char const*, unsigned long, std::allocator<char> const&)'
model.cc:(.text+0x580): undefined reference to `std::string::compare(char const*) const'
model.cc:(.text+0x58c): undefined reference to `std::string::_Rep::_S_empty_rep_storage'
model.cc:(.text+0x604): undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(char const*, std::allocator<char> const&)'
model.cc:(.text+0x624): undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(char const*, std::allocator<char> const&)'
model.cc:(.text+0x704): undefined reference to `std::string::_Rep::_M_destroy(std::allocator<char> const&)'
model.cc:(.text+0x748): undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(char const*, unsigned long, std::allocator<char> const&)'
../../../../src/main/cpp/cpp_test/tflite/arm64-v8a/libtensorflow-lite.a(allocation.o): In function `tflite::FileCopyAllocation::FileCopyAllocation(char const*, tflite::ErrorReporter*)':
allocation.cc:(.text+0x130): undefined reference to `__fxstat'
../../../../src/main/cpp/cpp_test/tflite/arm64-v8a/libtensorflow-lite.a(subgraph.o): In function `tflite::Subgraph::ReserveNodes(int)':
subgraph.cc:(.text+0x51c): undefined reference to `std::__throw_length_error(char const*)'
../../../../src/main/cpp/cpp_test/tflite/arm64-v8a/libtensorflow-lite.a(subgraph.o): In function `tflite::Subgraph::PrepareOpsStartingAt(int, int*)':
subgraph.cc:(.text+0xee0): undefined reference to `std::__throw_length_error(char const*)'
../../../../src/main/cpp/cpp_test/tflite/arm64-v8a/libtensorflow-lite.a(subgraph.o): In function `tflite::Subgraph::Invoke()':
subgraph.cc:(.text+0x32b4): undefined reference to `std::__throw_length_error(char const*)'
../../../../src/main/cpp/cpp_test/tflite/arm64-v8a/libtensorflow-lite.a(subgraph.o): In function `std::vector<std::pair<TfLiteNode, TfLiteRegistration>, std::allocator<std::pair<TfLiteNode, TfLiteRegistration> > >::_M_default_append(unsigned long)':
subgraph.cc:(.text._ZNSt6vectorISt4pairI10TfLiteNode18TfLiteRegistrationESaIS3_EE17_M_default_appendEm[_ZNSt6vectorISt4pairI10TfLiteNode18TfLiteRegistrationESaIS3_EE17_M_default_appendEm]+0x214): undefined reference to `std::__throw_length_error(char const*)'
../../../../src/main/cpp/cpp_test/tflite/arm64-v8a/libtensorflow-lite.a(subgraph.o): In function `std::vector<TfLiteTensor, std::allocator<TfLiteTensor> >::_M_default_append(unsigned long)':
subgraph.cc:(.text._ZNSt6vectorI12TfLiteTensorSaIS0_EE17_M_default_appendEm[_ZNSt6vectorI12TfLiteTensorSaIS0_EE17_M_default_appendEm]+0x240): undefined reference to `std::__throw_length_error(char const*)'
../../../../src/main/cpp/cpp_test/tflite/arm64-v8a/libtensorflow-lite.a(graph_info.o):graph_info.cc:(.text._ZNSt6vectorIiSaIiEE14_M_fill_insertEN9__gnu_cxx17__normal_iteratorIPiS1_EEmRKi[_ZNSt6vectorIiSaIiEE14_M_fill_insertEN9__gnu_cxx17__normal_iteratorIPiS1_EEmRKi]+0x5c0): more undefined references to `std::__throw_length_error(char const*)' follow
../../../../src/main/cpp/cpp_test/tflite/arm64-v8a/libtensorflow-lite.a(minimal_logging_default.o): In function `tflite::logging_internal::MinimalLogger::LogFormatted(tflite::LogSeverity, char const*, std::__va_list)':
minimal_logging_default.cc:(.text+0x3c): undefined reference to `__fprintf_chk'
minimal_logging_default.cc:(.text+0x60): undefined reference to `__vfprintf_chk'
../../../../src/main/cpp/cpp_test/tflite/arm64-v8a/libtensorflow-lite.a(nnapi_delegate_disabled.o): In function `tflite::StatefulNnApiDelegate::StatefulNnApiDelegate()':
nnapi_delegate_disabled.cc:(.text+0x34): undefined reference to `std::string::_Rep::_S_empty_rep_storage'
nnapi_delegate_disabled.cc:(.text+0x44): undefined reference to `std::string::_Rep::_S_empty_rep_storage'
../../../../src/main/cpp/cpp_test/tflite/arm64-v8a/libtensorflow-lite.a(nnapi_delegate_disabled.o): In function `tflite::StatefulNnApiDelegate::Data::~Data()':
nnapi_delegate_disabled.cc:(.text+0x1c4): undefined reference to `std::string::_Rep::_S_empty_rep_storage'
nnapi_delegate_disabled.cc:(.text+0x1cc): undefined reference to `std::string::_Rep::_S_empty_rep_storage'
nnapi_delegate_disabled.cc:(.text+0x1e0): undefined reference to `std::string::_Rep::_S_empty_rep_storage'
../../../../src/main/cpp/cpp_test/tflite/arm64-v8a/libtensorflow-lite.a(nnapi_delegate_disabled.o):nnapi_delegate_disabled.cc:(.text+0x1f4): more undefined references to `std::string::_Rep::_S_empty_rep_storage' follow
../../../../src/main/cpp/cpp_test/tflite/arm64-v8a/libtensorflow-lite.a(nnapi_delegate_disabled.o): In function `tflite::StatefulNnApiDelegate::Data::~Data()':
nnapi_delegate_disabled.cc:(.text+0x254): undefined reference to `std::string::_Rep::_M_destroy(std::allocator<char> const&)'
nnapi_delegate_disabled.cc:(.text+0x288): undefined reference to `std::string::_Rep::_M_destroy(std::allocator<char> const&)'
nnapi_delegate_disabled.cc:(.text+0x2bc): undefined reference to `std::string::_Rep::_M_destroy(std::allocator<char> const&)'
../../../../src/main/cpp/cpp_test/tflite/arm64-v8a/libtensorflow-lite.a(arena_planner.o): In function `tflite::ArenaPlanner::CreateTensorAllocationVector(int, int)':
arena_planner.cc:(.text+0x19e8): undefined reference to `std::_Rb_tree_increment(std::_Rb_tree_node_base const*)'
arena_planner.cc:(.text+0x1a3c): undefined reference to `std::_Rb_tree_increment(std::_Rb_tree_node_base const*)'
../../../../src/main/cpp/cpp_test/tflite/arm64-v8a/libtensorflow-lite.a(arena_planner.o): In function `std::vector<tflite::ArenaAllocWithUsageInterval, std::allocator<tflite::ArenaAllocWithUsageInterval> >::_M_default_append(unsigned long)':
arena_planner.cc:(.text._ZNSt6vectorIN6tflite27ArenaAllocWithUsageIntervalESaIS1_EE17_M_default_appendEm[_ZNSt6vectorIN6tflite27ArenaAllocWithUsageIntervalESaIS1_EE17_M_default_appendEm]+0x1a8): undefined reference to `std::__throw_length_error(char const*)'
../../../../src/main/cpp/cpp_test/tflite/arm64-v8a/libtensorflow-lite.a(arena_planner.o): In function `std::pair<std::_Rb_tree_iterator<int>, bool> std::_Rb_tree<int, int, std::_Identity<int>, std::less<int>, std::allocator<int> >::_M_insert_unique<int const&>(int const&)':
arena_planner.cc:(.text._ZNSt8_Rb_treeIiiSt9_IdentityIiESt4lessIiESaIiEE16_M_insert_uniqueIRKiEESt4pairISt17_Rb_tree_iteratorIiEbEOT_[_ZNSt8_Rb_treeIiiSt9_IdentityIiESt4lessIiESaIiEE16_M_insert_uniqueIRKiEESt4pairISt17_Rb_tree_iteratorIiEbEOT_]+0xa8): undefined reference to `std::_Rb_tree_decrement(std::_Rb_tree_node_base*)'
arena_planner.cc:(.text._ZNSt8_Rb_treeIiiSt9_IdentityIiESt4lessIiESaIiEE16_M_insert_uniqueIRKiEESt4pairISt17_Rb_tree_iteratorIiEbEOT_[_ZNSt8_Rb_treeIiiSt9_IdentityIiESt4lessIiESaIiEE16_M_insert_uniqueIRKiEESt4pairISt17_Rb_tree_iteratorIiEbEOT_]+0xf8): undefined reference to `std::_Rb_tree_insert_and_rebalance(bool, std::_Rb_tree_node_base*, std::_Rb_tree_node_base*, std::_Rb_tree_node_base&)'
../../../../src/main/cpp/cpp_test/tflite/arm64-v8a/libtensorflow-lite.a(simple_memory_arena.o): In function `tflite::SimpleMemoryArena::Allocate(TfLiteContext*, unsigned long, unsigned long, int, int, int, tflite::ArenaAllocWithUsageInterval*)':
simple_memory_arena.cc:(.text+0x15c): undefined reference to `std::__detail::_List_node_base::_M_hook(std::__detail::_List_node_base*)'
../../../../src/main/cpp/cpp_test/tflite/arm64-v8a/libtensorflow-lite.a(simple_memory_arena.o): In function `tflite::SimpleMemoryArena::Deallocate(TfLiteContext*, tflite::ArenaAllocWithUsageInterval const&)':
simple_memory_arena.cc:(.text+0x228): undefined reference to `std::__detail::_List_node_base::_M_unhook()'
clang++: error: linker command failed with exit code 1 (use -v to see invocation)
ninja: build stopped: subcommand failed.
```


"
37622,grpc+verbs fail with tensorflow/core/common_runtime/process_state.cc:128] Check failed: 0 == cpu_allocators_.size() (0 vs. 1),"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): 
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04):  centos 7
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below):  r1.15 from source
- Python version: - Bazel
version (if compiling from source): python 3.6.8, bazel 0.26.1
- GCC/Compiler version (if compiling from
source):  gcc version 7.3.1
- CUDA/cuDNN version: - GPU model and memory: CPU only

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Using grpc+verbs and getting the following error:
2020-03-15 21:08:10.425600: F tensorflow/core/common_runtime/process_state.cc:128] Check failed: 0 == cpu_allocators_.size() (0 vs. 1)AddCPUAllocVisitor must be called prior to first call to ProcessState::GetCPUAllocator
Aborted

**Describe the expected behavior**
Should run without errors
**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
37621,conv2d calculation results are inconsistent with pytorch,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): 
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): 
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): 
- Python version: 3.6.5
- CUDA/cuDNN version: - GPU model and memory:10.1

**Describe the current behavior**
For some specific data, the calculation results of tensorflow and pytorch are inconsistent
**Describe the expected behavior**
The calculation results of tensorflow and pytorch are consistent or the difference is small
**Standalone code to reproduce the issue** 

        if target_interface == 'conv1':
            weights_torch = torch.from_numpy(np.full((11, 11, 3, 1), 1, np.float64).transpose((3, 2, 0, 1)))
            output_pytorch_cpu = torch.from_numpy(
                F.conv2d(torch.from_numpy(input_pytorch.numpy().transpose((0, 3, 1, 2))), weights_torch, padding=0,
                         stride=4).numpy().transpose((0, 2, 3, 1)))
**Other info / logs** 
tensorflow_output:
31.42857361,31.4285183,31.42857361
69.24489594,69.24489594,59.3673439
100.89792633,100.89792633,100.89792633
133.26530457,133.26530457,133.26530457
60.22449875,60.22449875,60.22449875
187.46939087,187.46939087,187.46939087
205.918396,205.918396,205.918396
96.42860413,96.42860413,96.42860413
61.42854309,61.42854309,61.42854309
148.89811707,148.89811707,148.89811707
96.28572083,96.28572083,96.28572083
83.02045441,83.02045441,83.02045441
87.89794922,87.89794922,87.89794922
135.12240601,135.12240601,135.12240601


pytorch_output
31.428574,31.428518,31.428574
59.367344,69.244896,69.244896
100.89793,100.89793,100.89793
133.2653,133.2653,133.2653
60.2245,60.2245,60.2245
187.46939,187.46939,187.46939
205.9184,205.9184,205.9184
96.428604,96.428604,96.428604
61.428543,61.428543,61.428543
148.89812,148.89812,148.89812
96.28572,96.28572,96.28572
83.020454,83.020454,83.020454
87.89795,87.89795,87.89795
135.1224,135.1224,135.1224

"
37620,ModelCheckpoint does not save the model when `_is_graph_network` is False,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): **Yes**
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): `tensorflow/tensorflow:2.1.0-gpu-py3`

**Describe the current behavior**
When using tf.keras.callbacks.ModelCheckpoint it implies that when save_weights_only is False it will save the model using model.save, however it does not.
Due to the code in set_model that checks `model._is_graph_network` save_weights_only becomes True for my usecase.
https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/callbacks.py#L920-L923

**Describe the expected behavior**
When `save_weights_only=False` the network should be saved using `model.save` instead of `model.save_weights`.
It is not clear to me what the `_is_graph_network` variable is influenced by and how one would make it True. At the very least this is a documentation issue where the documentation implies that settings `save_weights_only` will save the model using `model.save` when this is not true.

Additionally, if I run `model.save` outside of the callback it succeeds, therefore there is no reason why the callback should not be able to do the same."
37618,num_replicas_in_sync not equel to my gpus.,"strategy = tf.distribute.MirroredStrategy()
print('Number of devices: {}'.format(strategy.num_replicas_in_sync))

i have 4x2080Ti
but when i run this code, i got :
Number of devices: 1

and training a model have warning:
WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.

and no gpu in used

tensorflow 2.1.0
keras 2.3.1"
37617,No documentation on how to convert Session.run calls to tf.function calls,"## URL(s) with the issue:

* https://www.tensorflow.org/guide/migrate#1_replace_v1sessionrun_calls

## Description of issue (what needs changing):

There is no information provided to the end-user on how to convert simple `Session.run` calls into `tf.function` calls for TensorFlow 2. For people who are only interested in running saved models and not building their own architectures, the lack of information makes it difficult to fully migrate away from TensorFlow 1.x.

### Clear description

If I am doing a SavedModel-based system with TensorFlow 1.x (I was provided the model, I did not make the model), there should be a direct explanation of how to convert `Session.run` calls into more modern `tf.function` calls. Here is an example of the code I'm trying to convert to TensorFlow 2, but I can't complete the conversion because of a lack of documentation for this use case:

```python
with tf.Session(graph=tf.Graph()) as sess:
    tf.saved_model.loader.load(sess, [""serve""], path_to_model)
    cap = cv2.VideoCapture(camera_id)
    ret, frame = cap.read()
    ret, encoded = cv2.imencode("".jpg"", frame)
    inferred = sess.run([""detection_scores:0"", ""detection_boxes:0""], feed_dict={
        ""encoded_image_string_tensor:0"": [encoded.tobytes(),]
    })
```

Essentially, I'm looking for a piece of documentation with code equivalency for these sort of examples.

### Correct links

***Not applicable***

### Parameters defined

***Not applicable***

### Returns defined

***Not applicable***

### Raises listed and defined

***Not applicable***

### Usage example

***Not applicable***

### Request visuals, if applicable

***Not applicable***

### Submit a pull request?

I can't submit a pull request because of the lack of documentation on the issue at hand. I could, however, submit a pull request to resolve the problem once I know how to resolve the problem.
"
37615,TF saved model Assertion Error ( Called a function referencing variables which have been deleted ),"I am facing an issue . When returning a ```tf.saved_model.load``` object inside a function and then try to use it, it is not working. 

I am having a file ```sample.py``` 
```
#### sample.py

import tensorflow as tf
def load_model(model_dir):

    # Load Model
    loaded = tf.saved_model.load(model_dir)
    model = loaded.signatures['serving_default']
    print(""Model Loaded"")
    return model

```

When I am executing ```main.py```

```
from sample import load_model

model_dir = 'som_path of a saved model'
model1 = load_model(model_dir)
```

If I print model.variables I am getting following error

```
AssertionError: Called a function referencing variables which have been deleted. This likely means that function-local variables were created and not referenced elsewhere in the program. This is generally a mistake; consider storing variables in an object attribute on first call.

```

But. If load the model with same code inside the function, but not using the function it works fine

```
#### main.py
loaded = tf.saved_model.load(model_dir)
model = loaded.signatures['serving_default']
```
If I print model.variables, its working as expected. "
37614,Bazel build tensorflow1.15.2 error,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu1~18.04.1
- TensorFlow installed from (source or binary): source
- TensorFlow version: 1.15.2
- Python version: 3.6.8
- Bazel version (if compiling from source): 0.24.1 
- GCC/Compiler version (if compiling from source): gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0
- CUDA/cuDNN version: cuda10.0

### Tensorflow build by bazel:
> bazel  build  //tensorflow/tools/pip_package:build_pip_package

**Describe the problem**
```
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=109
INFO: Reading rc options for 'build' from /data1/home/other/ttensorflow/previos/ttensorflow/.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --copt=-w --config=v1
INFO: Reading rc options for 'build' from /data1/home/other/ttensorflow/previos/ttensorflow/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/usr/local/bin/python --action_env PYTHON_LIB_PATH=/usr/local/lib/python3.6/dist-packages --python_path=/usr/local/bin/python --config=xla --action_env TF_CONFIGURE_IOS=0
INFO: Found applicable config definition build:v1 in file /data1/home/other/ttensorflow/previos/ttensorflow/.bazelrc: --define=tf_api_version=1 --action_env=TF2_BEHAVIOR=0
INFO: Found applicable config definition build:xla in file /data1/home/other/ttensorflow/previos/ttensorflow/.bazelrc: --action_env=TF_ENABLE_XLA=1 --define=with_xla_support=true
INFO: Found applicable config definition build:xla in file /data1/home/other/ttensorflow/previos/ttensorflow/.tf_configure.bazelrc: --define with_xla_support=true
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:21:12: Label '//tensorflow/python/keras:applications/__init__.py' crosses boundary of subpackage 'tensorflow/python/keras/applications' (perhaps you meant to put the colon here: '//tensorflow/python/keras/applications:__init__.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:21:12: Label '//tensorflow/python/keras:applications/densenet.py' crosses boundary of subpackage 'tensorflow/python/keras/applications' (perhaps you meant to put the colon here: '//tensorflow/python/keras/applications:densenet.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:21:12: Label '//tensorflow/python/keras:applications/imagenet_utils.py' crosses boundary of subpackage 'tensorflow/python/keras/applications' (perhaps you meant to put the colon here: '//tensorflow/python/keras/applications:imagenet_utils.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:21:12: Label '//tensorflow/python/keras:applications/inception_resnet_v2.py' crosses boundary of subpackage 'tensorflow/python/keras/applications' (perhaps you meant to put the colon here: '//tensorflow/python/keras/applications:inception_resnet_v2.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:21:12: Label '//tensorflow/python/keras:applications/inception_v3.py' crosses boundary of subpackage 'tensorflow/python/keras/applications' (perhaps you meant to put the colon here: '//tensorflow/python/keras/applications:inception_v3.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:21:12: Label '//tensorflow/python/keras:applications/mobilenet.py' crosses boundary of subpackage 'tensorflow/python/keras/applications' (perhaps you meant to put the colon here: '//tensorflow/python/keras/applications:mobilenet.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:21:12: Label '//tensorflow/python/keras:applications/mobilenet_v2.py' crosses boundary of subpackage 'tensorflow/python/keras/applications' (perhaps you meant to put the colon here: '//tensorflow/python/keras/applications:mobilenet_v2.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:21:12: Label '//tensorflow/python/keras:applications/nasnet.py' crosses boundary of subpackage 'tensorflow/python/keras/applications' (perhaps you meant to put the colon here: '//tensorflow/python/keras/applications:nasnet.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:21:12: Label '//tensorflow/python/keras:applications/resnet.py' crosses boundary of subpackage 'tensorflow/python/keras/applications' (perhaps you meant to put the colon here: '//tensorflow/python/keras/applications:resnet.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:21:12: Label '//tensorflow/python/keras:applications/resnet_v2.py' crosses boundary of subpackage 'tensorflow/python/keras/applications' (perhaps you meant to put the colon here: '//tensorflow/python/keras/applications:resnet_v2.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:21:12: Label '//tensorflow/python/keras:applications/vgg16.py' crosses boundary of subpackage 'tensorflow/python/keras/applications' (perhaps you meant to put the colon here: '//tensorflow/python/keras/applications:vgg16.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:21:12: Label '//tensorflow/python/keras:applications/vgg19.py' crosses boundary of subpackage 'tensorflow/python/keras/applications' (perhaps you meant to put the colon here: '//tensorflow/python/keras/applications:vgg19.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:21:12: Label '//tensorflow/python/keras:applications/xception.py' crosses boundary of subpackage 'tensorflow/python/keras/applications' (perhaps you meant to put the colon here: '//tensorflow/python/keras/applications:xception.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:21:12: Label '//tensorflow/python/keras:datasets/__init__.py' crosses boundary of subpackage 'tensorflow/python/keras/datasets' (perhaps you meant to put the colon here: '//tensorflow/python/keras/datasets:__init__.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:21:12: Label '//tensorflow/python/keras:datasets/boston_housing.py' crosses boundary of subpackage 'tensorflow/python/keras/datasets' (perhaps you meant to put the colon here: '//tensorflow/python/keras/datasets:boston_housing.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:21:12: Label '//tensorflow/python/keras:datasets/cifar.py' crosses boundary of subpackage 'tensorflow/python/keras/datasets' (perhaps you meant to put the colon here: '//tensorflow/python/keras/datasets:cifar.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:21:12: Label '//tensorflow/python/keras:datasets/cifar10.py' crosses boundary of subpackage 'tensorflow/python/keras/datasets' (perhaps you meant to put the colon here: '//tensorflow/python/keras/datasets:cifar10.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:21:12: Label '//tensorflow/python/keras:datasets/cifar100.py' crosses boundary of subpackage 'tensorflow/python/keras/datasets' (perhaps you meant to put the colon here: '//tensorflow/python/keras/datasets:cifar100.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:21:12: Label '//tensorflow/python/keras:datasets/fashion_mnist.py' crosses boundary of subpackage 'tensorflow/python/keras/datasets' (perhaps you meant to put the colon here: '//tensorflow/python/keras/datasets:fashion_mnist.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:21:12: Label '//tensorflow/python/keras:datasets/imdb.py' crosses boundary of subpackage 'tensorflow/python/keras/datasets' (perhaps you meant to put the colon here: '//tensorflow/python/keras/datasets:imdb.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:21:12: Label '//tensorflow/python/keras:datasets/mnist.py' crosses boundary of subpackage 'tensorflow/python/keras/datasets' (perhaps you meant to put the colon here: '//tensorflow/python/keras/datasets:mnist.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:21:12: Label '//tensorflow/python/keras:datasets/reuters.py' crosses boundary of subpackage 'tensorflow/python/keras/datasets' (perhaps you meant to put the colon here: '//tensorflow/python/keras/datasets:reuters.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:21:12: Label '//tensorflow/python/keras:preprocessing/__init__.py' crosses boundary of subpackage 'tensorflow/python/keras/preprocessing' (perhaps you meant to put the colon here: '//tensorflow/python/keras/preprocessing:__init__.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:21:12: Label '//tensorflow/python/keras:preprocessing/image.py' crosses boundary of subpackage 'tensorflow/python/keras/preprocessing' (perhaps you meant to put the colon here: '//tensorflow/python/keras/preprocessing:image.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:21:12: Label '//tensorflow/python/keras:preprocessing/sequence.py' crosses boundary of subpackage 'tensorflow/python/keras/preprocessing' (perhaps you meant to put the colon here: '//tensorflow/python/keras/preprocessing:sequence.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:21:12: Label '//tensorflow/python/keras:preprocessing/text.py' crosses boundary of subpackage 'tensorflow/python/keras/preprocessing' (perhaps you meant to put the colon here: '//tensorflow/python/keras/preprocessing:text.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:21:12: Label '//tensorflow/python/keras:utils/__init__.py' crosses boundary of subpackage 'tensorflow/python/keras/utils' (perhaps you meant to put the colon here: '//tensorflow/python/keras/utils:__init__.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:21:12: Label '//tensorflow/python/keras:utils/multi_gpu_utils.py' crosses boundary of subpackage 'tensorflow/python/keras/utils' (perhaps you meant to put the colon here: '//tensorflow/python/keras/utils:multi_gpu_utils.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:21:12: Label '//tensorflow/python/keras:utils/np_utils.py' crosses boundary of subpackage 'tensorflow/python/keras/utils' (perhaps you meant to put the colon here: '//tensorflow/python/keras/utils:np_utils.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:21:12: Label '//tensorflow/python/keras:utils/vis_utils.py' crosses boundary of subpackage 'tensorflow/python/keras/utils' (perhaps you meant to put the colon here: '//tensorflow/python/keras/utils:vis_utils.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:21:12: Label '//tensorflow/python/keras:wrappers/__init__.py' crosses boundary of subpackage 'tensorflow/python/keras/wrappers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/wrappers:__init__.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:21:12: Label '//tensorflow/python/keras:wrappers/scikit_learn.py' crosses boundary of subpackage 'tensorflow/python/keras/wrappers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/wrappers:scikit_learn.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:140:12: Label '//tensorflow/python/keras:engine/base_layer_utils.py' crosses boundary of subpackage 'tensorflow/python/keras/engine' (perhaps you meant to put the colon here: '//tensorflow/python/keras/engine:base_layer_utils.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:162:12: Label '//tensorflow/python/keras:engine/__init__.py' crosses boundary of subpackage 'tensorflow/python/keras/engine' (perhaps you meant to put the colon here: '//tensorflow/python/keras/engine:__init__.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:162:12: Label '//tensorflow/python/keras:engine/input_layer.py' crosses boundary of subpackage 'tensorflow/python/keras/engine' (perhaps you meant to put the colon here: '//tensorflow/python/keras/engine:input_layer.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:162:12: Label '//tensorflow/python/keras:engine/network.py' crosses boundary of subpackage 'tensorflow/python/keras/engine' (perhaps you meant to put the colon here: '//tensorflow/python/keras/engine:network.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:162:12: Label '//tensorflow/python/keras:engine/node.py' crosses boundary of subpackage 'tensorflow/python/keras/engine' (perhaps you meant to put the colon here: '//tensorflow/python/keras/engine:node.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:162:12: Label '//tensorflow/python/keras:engine/partial_batch_padding_handler.py' crosses boundary of subpackage 'tensorflow/python/keras/engine' (perhaps you meant to put the colon here: '//tensorflow/python/keras/engine:partial_batch_padding_handler.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:162:12: Label '//tensorflow/python/keras:engine/saving.py' crosses boundary of subpackage 'tensorflow/python/keras/engine' (perhaps you meant to put the colon here: '//tensorflow/python/keras/engine:saving.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:162:12: Label '//tensorflow/python/keras:engine/sequential.py' crosses boundary of subpackage 'tensorflow/python/keras/engine' (perhaps you meant to put the colon here: '//tensorflow/python/keras/engine:sequential.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:162:12: Label '//tensorflow/python/keras:engine/training.py' crosses boundary of subpackage 'tensorflow/python/keras/engine' (perhaps you meant to put the colon here: '//tensorflow/python/keras/engine:training.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:162:12: Label '//tensorflow/python/keras:engine/training_arrays.py' crosses boundary of subpackage 'tensorflow/python/keras/engine' (perhaps you meant to put the colon here: '//tensorflow/python/keras/engine:training_arrays.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:162:12: Label '//tensorflow/python/keras:engine/training_distributed.py' crosses boundary of subpackage 'tensorflow/python/keras/engine' (perhaps you meant to put the colon here: '//tensorflow/python/keras/engine:training_distributed.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:162:12: Label '//tensorflow/python/keras:engine/training_eager.py' crosses boundary of subpackage 'tensorflow/python/keras/engine' (perhaps you meant to put the colon here: '//tensorflow/python/keras/engine:training_eager.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:162:12: Label '//tensorflow/python/keras:engine/training_generator.py' crosses boundary of subpackage 'tensorflow/python/keras/engine' (perhaps you meant to put the colon here: '//tensorflow/python/keras/engine:training_generator.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:162:12: Label '//tensorflow/python/keras:engine/training_utils.py' crosses boundary of subpackage 'tensorflow/python/keras/engine' (perhaps you meant to put the colon here: '//tensorflow/python/keras/engine:training_utils.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:162:12: Label '//tensorflow/python/keras:engine/training_v2.py' crosses boundary of subpackage 'tensorflow/python/keras/engine' (perhaps you meant to put the colon here: '//tensorflow/python/keras/engine:training_v2.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:162:12: Label '//tensorflow/python/keras:engine/training_v2_utils.py' crosses boundary of subpackage 'tensorflow/python/keras/engine' (perhaps you meant to put the colon here: '//tensorflow/python/keras/engine:training_v2_utils.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:162:12: Label '//tensorflow/python/keras:utils/metrics_utils.py' crosses boundary of subpackage 'tensorflow/python/keras/utils' (perhaps you meant to put the colon here: '//tensorflow/python/keras/utils:metrics_utils.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:222:12: Label '//tensorflow/python/keras:engine/data_adapter.py' crosses boundary of subpackage 'tensorflow/python/keras/engine' (perhaps you meant to put the colon here: '//tensorflow/python/keras/engine:data_adapter.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:234:12: Label '//tensorflow/python/keras:engine/input_spec.py' crosses boundary of subpackage 'tensorflow/python/keras/engine' (perhaps you meant to put the colon here: '//tensorflow/python/keras/engine:input_spec.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:248:12: Label '//tensorflow/python/keras:engine/base_layer.py' crosses boundary of subpackage 'tensorflow/python/keras/engine' (perhaps you meant to put the colon here: '//tensorflow/python/keras/engine:base_layer.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:277:12: Label '//tensorflow/python/keras:engine/base_preprocessing_layer.py' crosses boundary of subpackage 'tensorflow/python/keras/engine' (perhaps you meant to put the colon here: '//tensorflow/python/keras/engine:base_preprocessing_layer.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:277:12: Label '//tensorflow/python/keras:engine/base_preprocessing_layer_v1.py' crosses boundary of subpackage 'tensorflow/python/keras/engine' (perhaps you meant to put the colon here: '//tensorflow/python/keras/engine:base_preprocessing_layer_v1.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:294:12: Label '//tensorflow/python/keras:saving/__init__.py' crosses boundary of subpackage 'tensorflow/python/keras/saving' (perhaps you meant to put the colon here: '//tensorflow/python/keras/saving:__init__.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:294:12: Label '//tensorflow/python/keras:saving/hdf5_format.py' crosses boundary of subpackage 'tensorflow/python/keras/saving' (perhaps you meant to put the colon here: '//tensorflow/python/keras/saving:hdf5_format.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:294:12: Label '//tensorflow/python/keras:saving/model_config.py' crosses boundary of subpackage 'tensorflow/python/keras/saving' (perhaps you meant to put the colon here: '//tensorflow/python/keras/saving:model_config.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:294:12: Label '//tensorflow/python/keras:saving/save.py' crosses boundary of subpackage 'tensorflow/python/keras/saving' (perhaps you meant to put the colon here: '//tensorflow/python/keras/saving:save.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:294:12: Label '//tensorflow/python/keras:saving/saved_model/constants.py' crosses boundary of subpackage 'tensorflow/python/keras/saving' (perhaps you meant to put the colon here: '//tensorflow/python/keras/saving:saved_model/constants.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:294:12: Label '//tensorflow/python/keras:saving/saved_model/load.py' crosses boundary of subpackage 'tensorflow/python/keras/saving' (perhaps you meant to put the colon here: '//tensorflow/python/keras/saving:saved_model/load.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:294:12: Label '//tensorflow/python/keras:saving/saved_model/save.py' crosses boundary of subpackage 'tensorflow/python/keras/saving' (perhaps you meant to put the colon here: '//tensorflow/python/keras/saving:saved_model/save.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:294:12: Label '//tensorflow/python/keras:saving/saved_model/serialized_attributes.py' crosses boundary of subpackage 'tensorflow/python/keras/saving' (perhaps you meant to put the colon here: '//tensorflow/python/keras/saving:saved_model/serialized_attributes.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:294:12: Label '//tensorflow/python/keras:saving/saved_model/utils.py' crosses boundary of subpackage 'tensorflow/python/keras/saving' (perhaps you meant to put the colon here: '//tensorflow/python/keras/saving:saved_model/utils.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:294:12: Label '//tensorflow/python/keras:saving/saved_model_experimental.py' crosses boundary of subpackage 'tensorflow/python/keras/saving' (perhaps you meant to put the colon here: '//tensorflow/python/keras/saving:saved_model_experimental.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:294:12: Label '//tensorflow/python/keras:saving/saving_utils.py' crosses boundary of subpackage 'tensorflow/python/keras/saving' (perhaps you meant to put the colon here: '//tensorflow/python/keras/saving:saving_utils.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:429:12: Label '//tensorflow/python/keras:utils/conv_utils.py' crosses boundary of subpackage 'tensorflow/python/keras/utils' (perhaps you meant to put the colon here: '//tensorflow/python/keras/utils:conv_utils.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:429:12: Label '//tensorflow/python/keras:utils/data_utils.py' crosses boundary of subpackage 'tensorflow/python/keras/utils' (perhaps you meant to put the colon here: '//tensorflow/python/keras/utils:data_utils.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:429:12: Label '//tensorflow/python/keras:utils/io_utils.py' crosses boundary of subpackage 'tensorflow/python/keras/utils' (perhaps you meant to put the colon here: '//tensorflow/python/keras/utils:io_utils.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:429:12: Label '//tensorflow/python/keras:utils/losses_utils.py' crosses boundary of subpackage 'tensorflow/python/keras/utils' (perhaps you meant to put the colon here: '//tensorflow/python/keras/utils:losses_utils.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:444:12: Label '//tensorflow/python/keras:utils/tf_utils.py' crosses boundary of subpackage 'tensorflow/python/keras/utils' (perhaps you meant to put the colon here: '//tensorflow/python/keras/utils:tf_utils.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:464:12: Label '//tensorflow/python/keras:layers/__init__.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:__init__.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:464:12: Label '//tensorflow/python/keras:layers/advanced_activations.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:advanced_activations.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:464:12: Label '//tensorflow/python/keras:layers/convolutional.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:convolutional.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:464:12: Label '//tensorflow/python/keras:layers/convolutional_recurrent.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:convolutional_recurrent.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:464:12: Label '//tensorflow/python/keras:layers/core.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:core.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:464:12: Label '//tensorflow/python/keras:layers/cudnn_recurrent.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:cudnn_recurrent.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:464:12: Label '//tensorflow/python/keras:layers/dense_attention.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:dense_attention.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:464:12: Label '//tensorflow/python/keras:layers/embeddings.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:embeddings.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:464:12: Label '//tensorflow/python/keras:layers/kernelized.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:kernelized.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:464:12: Label '//tensorflow/python/keras:layers/local.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:local.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:464:12: Label '//tensorflow/python/keras:layers/merge.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:merge.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:464:12: Label '//tensorflow/python/keras:layers/noise.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:noise.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:464:12: Label '//tensorflow/python/keras:layers/normalization.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:normalization.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:464:12: Label '//tensorflow/python/keras:layers/normalization_v2.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:normalization_v2.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:464:12: Label '//tensorflow/python/keras:layers/pooling.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:pooling.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:464:12: Label '//tensorflow/python/keras:layers/preprocessing/normalization.py' crosses boundary of subpackage 'tensorflow/python/keras/layers/preprocessing' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers/preprocessing:normalization.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:464:12: Label '//tensorflow/python/keras:layers/preprocessing/normalization_v1.py' crosses boundary of subpackage 'tensorflow/python/keras/layers/preprocessing' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers/preprocessing:normalization_v1.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:464:12: Label '//tensorflow/python/keras:layers/recurrent.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:recurrent.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:464:12: Label '//tensorflow/python/keras:layers/recurrent_v2.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:recurrent_v2.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:464:12: Label '//tensorflow/python/keras:layers/rnn_cell_wrapper_v2.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:rnn_cell_wrapper_v2.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:464:12: Label '//tensorflow/python/keras:layers/wrappers.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:wrappers.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:464:12: Label '//tensorflow/python/keras:utils/kernelized_utils.py' crosses boundary of subpackage 'tensorflow/python/keras/utils' (perhaps you meant to put the colon here: '//tensorflow/python/keras/utils:kernelized_utils.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:464:12: Label '//tensorflow/python/keras:utils/layer_utils.py' crosses boundary of subpackage 'tensorflow/python/keras/utils' (perhaps you meant to put the colon here: '//tensorflow/python/keras/utils:layer_utils.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:518:12: Label '//tensorflow/python/keras:layers/preprocessing/preprocessing_test_utils.py' crosses boundary of subpackage 'tensorflow/python/keras/layers/preprocessing' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers/preprocessing:preprocessing_test_utils.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:529:12: Label '//tensorflow/python/keras:layers/serialization.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:serialization.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:542:12: Label '//tensorflow/python/keras:utils/generic_utils.py' crosses boundary of subpackage 'tensorflow/python/keras/utils' (perhaps you meant to put the colon here: '//tensorflow/python/keras/utils:generic_utils.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:554:12: Label '//tensorflow/python/keras:utils/mode_keys.py' crosses boundary of subpackage 'tensorflow/python/keras/utils' (perhaps you meant to put the colon here: '//tensorflow/python/keras/utils:mode_keys.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:603:1: Label '//tensorflow/python/keras:engine/data_adapter_test.py' crosses boundary of subpackage 'tensorflow/python/keras/engine' (perhaps you meant to put the colon here: '//tensorflow/python/keras/engine:data_adapter_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:730:1: Label '//tensorflow/python/keras:applications/applications_test.py' crosses boundary of subpackage 'tensorflow/python/keras/applications' (perhaps you meant to put the colon here: '//tensorflow/python/keras/applications:applications_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:742:1: Label '//tensorflow/python/keras:layers/advanced_activations_test.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:advanced_activations_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:753:1: Label '//tensorflow/python/keras:layers/tensorflow_op_layer_test.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:tensorflow_op_layer_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:769:1: Label '//tensorflow/python/keras:layers/convolutional_recurrent_test.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:convolutional_recurrent_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:783:1: Label '//tensorflow/python/keras:layers/convolutional_test.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:convolutional_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:797:1: Label '//tensorflow/python/keras:layers/convolutional_transpose_test.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:convolutional_transpose_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:810:1: Label '//tensorflow/python/keras:layers/cudnn_recurrent_test.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:cudnn_recurrent_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:827:1: Label '//tensorflow/python/keras:engine/base_preprocessing_layer_test.py' crosses boundary of subpackage 'tensorflow/python/keras/engine' (perhaps you meant to put the colon here: '//tensorflow/python/keras/engine:base_preprocessing_layer_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:841:1: Label '//tensorflow/python/keras:layers/pooling_test.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:pooling_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:857:1: Label '//tensorflow/python/keras:layers/core_test.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:core_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:870:1: Label '//tensorflow/python/keras:layers/subclassed_layers_test.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:subclassed_layers_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:883:1: Label '//tensorflow/python/keras:layers/dense_attention_test.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:dense_attention_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:895:1: Label '//tensorflow/python/keras:layers/embeddings_test.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:embeddings_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:907:1: Label '//tensorflow/python/keras:layers/local_test.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:local_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:921:1: Label '//tensorflow/python/keras:layers/merge_test.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:merge_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:933:1: Label '//tensorflow/python/keras:layers/noise_test.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:noise_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:944:1: Label '//tensorflow/python/keras:layers/normalization_test.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:normalization_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:961:1: Label '//tensorflow/python/keras:layers/preprocessing/normalization_test.py' crosses boundary of subpackage 'tensorflow/python/keras/layers/preprocessing' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers/preprocessing:normalization_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:974:1: Label '//tensorflow/python/keras:layers/simplernn_test.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:simplernn_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:988:1: Label '//tensorflow/python/keras:layers/gru_test.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:gru_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1002:1: Label '//tensorflow/python/keras:layers/lstm_test.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:lstm_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1019:1: Label '//tensorflow/python/keras:layers/recurrent_test.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:recurrent_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1032:1: Label '//tensorflow/python/keras:layers/recurrent_v2_test.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:recurrent_v2_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1046:1: Label '//tensorflow/python/keras:layers/separable_convolutional_test.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:separable_convolutional_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1059:1: Label '//tensorflow/python/keras:layers/lstm_v2_test.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:lstm_v2_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1074:1: Label '//tensorflow/python/keras:layers/gru_v2_test.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:gru_v2_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1089:1: Label '//tensorflow/python/keras:layers/serialization_test.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:serialization_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1100:1: Label '//tensorflow/python/keras:layers/kernelized_test.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:kernelized_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1126:1: Label '//tensorflow/python/keras:layers/wrappers_test.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:wrappers_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1143:1: Label '//tensorflow/python/keras:layers/rnn_cell_wrapper_v2_test.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:rnn_cell_wrapper_v2_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1159:1: Label '//tensorflow/python/keras:layers/time_distributed_learning_phase_test.py' crosses boundary of subpackage 'tensorflow/python/keras/layers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/layers:time_distributed_learning_phase_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1174:1: Label '//tensorflow/python/keras:wrappers/scikit_learn_test.py' crosses boundary of subpackage 'tensorflow/python/keras/wrappers' (perhaps you meant to put the colon here: '//tensorflow/python/keras/wrappers:scikit_learn_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1187:1: Label '//tensorflow/python/keras:utils/data_utils_test.py' crosses boundary of subpackage 'tensorflow/python/keras/utils' (perhaps you meant to put the colon here: '//tensorflow/python/keras/utils:data_utils_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1207:1: Label '//tensorflow/python/keras:utils/generic_utils_test.py' crosses boundary of subpackage 'tensorflow/python/keras/utils' (perhaps you meant to put the colon here: '//tensorflow/python/keras/utils:generic_utils_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1218:1: Label '//tensorflow/python/keras:utils/tf_utils_test.py' crosses boundary of subpackage 'tensorflow/python/keras/utils' (perhaps you meant to put the colon here: '//tensorflow/python/keras/utils:tf_utils_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1228:1: Label '//tensorflow/python/keras:utils/composite_tensor_support_test.py' crosses boundary of subpackage 'tensorflow/python/keras/utils' (perhaps you meant to put the colon here: '//tensorflow/python/keras/utils:composite_tensor_support_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1251:1: Label '//tensorflow/python/keras:utils/io_utils_test.py' crosses boundary of subpackage 'tensorflow/python/keras/utils' (perhaps you meant to put the colon here: '//tensorflow/python/keras/utils:io_utils_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1267:1: Label '//tensorflow/python/keras:utils/np_utils_test.py' crosses boundary of subpackage 'tensorflow/python/keras/utils' (perhaps you meant to put the colon here: '//tensorflow/python/keras/utils:np_utils_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1279:1: Label '//tensorflow/python/keras:utils/kernelized_utils_test.py' crosses boundary of subpackage 'tensorflow/python/keras/utils' (perhaps you meant to put the colon here: '//tensorflow/python/keras/utils:kernelized_utils_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1291:1: Label '//tensorflow/python/keras:utils/multi_gpu_utils_test.py' crosses boundary of subpackage 'tensorflow/python/keras/utils' (perhaps you meant to put the colon here: '//tensorflow/python/keras/utils:multi_gpu_utils_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1307:1: Label '//tensorflow/python/keras:engine/training_gpu_test.py' crosses boundary of subpackage 'tensorflow/python/keras/engine' (perhaps you meant to put the colon here: '//tensorflow/python/keras/engine:training_gpu_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1323:1: Label '//tensorflow/python/keras:utils/vis_utils_test.py' crosses boundary of subpackage 'tensorflow/python/keras/utils' (perhaps you meant to put the colon here: '//tensorflow/python/keras/utils:vis_utils_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1335:1: Label '//tensorflow/python/keras:utils/conv_utils_test.py' crosses boundary of subpackage 'tensorflow/python/keras/utils' (perhaps you meant to put the colon here: '//tensorflow/python/keras/utils:conv_utils_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1347:1: Label '//tensorflow/python/keras:preprocessing/image_test.py' crosses boundary of subpackage 'tensorflow/python/keras/preprocessing' (perhaps you meant to put the colon here: '//tensorflow/python/keras/preprocessing:image_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1359:1: Label '//tensorflow/python/keras:preprocessing/sequence_test.py' crosses boundary of subpackage 'tensorflow/python/keras/preprocessing' (perhaps you meant to put the colon here: '//tensorflow/python/keras/preprocessing:sequence_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1371:1: Label '//tensorflow/python/keras:preprocessing/text_test.py' crosses boundary of subpackage 'tensorflow/python/keras/preprocessing' (perhaps you meant to put the colon here: '//tensorflow/python/keras/preprocessing:text_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1413:1: Label '//tensorflow/python/keras:engine/correctness_test.py' crosses boundary of subpackage 'tensorflow/python/keras/engine' (perhaps you meant to put the colon here: '//tensorflow/python/keras/engine:correctness_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1430:1: Label '//tensorflow/python/keras:engine/input_spec_test.py' crosses boundary of subpackage 'tensorflow/python/keras/engine' (perhaps you meant to put the colon here: '//tensorflow/python/keras/engine:input_spec_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1444:1: Label '//tensorflow/python/keras:engine/training_test.py' crosses boundary of subpackage 'tensorflow/python/keras/engine' (perhaps you meant to put the colon here: '//tensorflow/python/keras/engine:training_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1462:1: Label '//tensorflow/python/keras:engine/training_dataset_test.py' crosses boundary of subpackage 'tensorflow/python/keras/engine' (perhaps you meant to put the colon here: '//tensorflow/python/keras/engine:training_dataset_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1478:1: Label '//tensorflow/python/keras:engine/training_arrays_test.py' crosses boundary of subpackage 'tensorflow/python/keras/engine' (perhaps you meant to put the colon here: '//tensorflow/python/keras/engine:training_arrays_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1497:1: Label '//tensorflow/python/keras:engine/training_generator_test.py' crosses boundary of subpackage 'tensorflow/python/keras/engine' (perhaps you meant to put the colon here: '//tensorflow/python/keras/engine:training_generator_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1515:1: Label '//tensorflow/python/keras:engine/training_integration_test.py' crosses boundary of subpackage 'tensorflow/python/keras/engine' (perhaps you meant to put the colon here: '//tensorflow/python/keras/engine:training_integration_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1532:1: Label '//tensorflow/python/keras:engine/feature_columns_integration_test.py' crosses boundary of subpackage 'tensorflow/python/keras/engine' (perhaps you meant to put the colon here: '//tensorflow/python/keras/engine:feature_columns_integration_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1549:1: Label '//tensorflow/python/keras:engine/training_eager_test.py' crosses boundary of subpackage 'tensorflow/python/keras/engine' (perhaps you meant to put the colon here: '//tensorflow/python/keras/engine:training_eager_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1566:1: Label '//tensorflow/python/keras:engine/training_utils_test.py' crosses boundary of subpackage 'tensorflow/python/keras/engine' (perhaps you meant to put the colon here: '//tensorflow/python/keras/engine:training_utils_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1641:1: Label '//tensorflow/python/keras:engine/network_test.py' crosses boundary of subpackage 'tensorflow/python/keras/engine' (perhaps you meant to put the colon here: '//tensorflow/python/keras/engine:network_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1658:1: Label '//tensorflow/python/keras:engine/base_layer_test.py' crosses boundary of subpackage 'tensorflow/python/keras/engine' (perhaps you meant to put the colon here: '//tensorflow/python/keras/engine:base_layer_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1675:1: Label '//tensorflow/python/keras:engine/control_flow_test.py' crosses boundary of subpackage 'tensorflow/python/keras/engine' (perhaps you meant to put the colon here: '//tensorflow/python/keras/engine:control_flow_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1691:1: Label '//tensorflow/python/keras:saving/hdf5_format_test.py' crosses boundary of subpackage 'tensorflow/python/keras/saving' (perhaps you meant to put the colon here: '//tensorflow/python/keras/saving:hdf5_format_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1707:1: Label '//tensorflow/python/keras:engine/sequential_test.py' crosses boundary of subpackage 'tensorflow/python/keras/engine' (perhaps you meant to put the colon here: '//tensorflow/python/keras/engine:sequential_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1776:1: Label '//tensorflow/python/keras:saving/save_test.py' crosses boundary of subpackage 'tensorflow/python/keras/saving' (perhaps you meant to put the colon here: '//tensorflow/python/keras/saving:save_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1789:1: Label '//tensorflow/python/keras:saving/saved_model_experimental_test.py' crosses boundary of subpackage 'tensorflow/python/keras/saving' (perhaps you meant to put the colon here: '//tensorflow/python/keras/saving:saved_model_experimental_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1806:1: Label '//tensorflow/python/keras:saving/saved_model/saved_model_test.py' crosses boundary of subpackage 'tensorflow/python/keras/saving' (perhaps you meant to put the colon here: '//tensorflow/python/keras/saving:saved_model/saved_model_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1822:1: Label '//tensorflow/python/keras:saving/saving_utils_test.py' crosses boundary of subpackage 'tensorflow/python/keras/saving' (perhaps you meant to put the colon here: '//tensorflow/python/keras/saving:saving_utils_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1835:1: Label '//tensorflow/python/keras:utils/metrics_utils_test.py' crosses boundary of subpackage 'tensorflow/python/keras/utils' (perhaps you meant to put the colon here: '//tensorflow/python/keras/utils:metrics_utils_test.py'?)
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1582:1: Target '//tensorflow/python/keras:keras' contains an error and its package is in error and referenced by '//tensorflow/python/keras:model_subclassing_test_util'
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/python/keras/BUILD:1582:1: Target '//tensorflow/python/keras:model_subclassing_test_util.py' contains an error and its package is in error and referenced by '//tensorflow/python/keras:model_subclassing_test_util'
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/tools/pip_package/BUILD:233:1: Target '//tensorflow/python/keras:model_subclassing_test_util' contains an error and its package is in error and referenced by '//tensorflow/tools/pip_package:build_pip_package'
ERROR: /data1/home/other/ttensorflow/previos/ttensorflow/tensorflow/tools/pip_package/BUILD:233:1: Target '//tensorflow/python/keras:preprocessing_test_utils' contains an error and its package is in error and referenced by '//tensorflow/tools/pip_package:build_pip_package'
ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: Analysis failed
INFO: Elapsed time: 0.145s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (10 packages loaded, 129 targets configured)
    currently loading: tensorflow/core/kernels ... (9 packages)
    Fetching @local_config_cc; Restarting.
    Fetching @local_config_sycl; fetching
    Fetching @swig; Restarting.
```

**Provide the exact sequence of commands / steps that you executed before running into the problem**
```
bazel  build  //tensorflow/tools/pip_package:build_pip_package
```

### Could you give me some advice? Thank you!"
37613,How to use our own tflite model ?,"This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.
"
37612,Not able to import tensorflow ,"**System information**
(tensorflow_cpu) C:\Users\Rakes>conda list
# packages in environment at C:\Users\Rakes\.conda\envs\tensorflow_cpu:
#
# Name                    Version                   Build  Channel
absl-py                   0.9.0                    pypi_0    pypi
astor                     0.8.1                    pypi_0    pypi
blas                      1.0                         mkl
ca-certificates           2020.1.1                      0
cachetools                4.0.0                    pypi_0    pypi
certifi                   2019.11.28               pypi_0    pypi
chardet                   3.0.4                    pypi_0    pypi
gast                      0.2.2                    pypi_0    pypi
google-auth               1.11.3                   pypi_0    pypi
google-auth-oauthlib      0.4.1                    pypi_0    pypi
google-pasta              0.2.0                    pypi_0    pypi
grpcio                    1.27.2                   pypi_0    pypi
h5py                      2.10.0                   pypi_0    pypi
icc_rt                    2019.0.0             h0cc432a_1
idna                      2.9                      pypi_0    pypi
intel-openmp              2020.0                      166
keras-applications        1.0.8                    pypi_0    pypi
keras-preprocessing       1.1.0                    pypi_0    pypi
markdown                  3.2.1                    pypi_0    pypi
mkl                       2020.0                      166
mkl-service               2.3.0            py37hb782905_0
mkl_fft                   1.0.15           py37h14836fe_0
mkl_random                1.1.0            py37h675688f_0
numpy                     1.18.1                   pypi_0    pypi
numpy-base                1.18.1           py37hc3f5095_1
oauthlib                  3.1.0                    pypi_0    pypi
openssl                   1.1.1d               he774522_4
opt-einsum                3.2.0                    pypi_0    pypi
pip                       20.0.2                   py37_1
protobuf                  3.11.3                   pypi_0    pypi
pyasn1                    0.4.8                    pypi_0    pypi
pyasn1-modules            0.2.8                    pypi_0    pypi
python                    3.7.6                h60c2a47_2
requests                  2.23.0                   pypi_0    pypi
requests-oauthlib         1.3.0                    pypi_0    pypi
rsa                       4.0                      pypi_0    pypi
scipy                     1.4.1                    pypi_0    pypi
setuptools                46.0.0                   pypi_0    pypi
six                       1.14.0                   py37_0
sqlite                    3.31.1               he774522_0
tensorboard               2.1.1                    pypi_0    pypi
tensorflow                2.1.0                    pypi_0    pypi
tensorflow-cpu            2.1.0                    pypi_0    pypi
tensorflow-estimator      2.1.0                    pypi_0    pypi
termcolor                 1.1.0                    pypi_0    pypi
urllib3                   1.25.8                   pypi_0    pypi
vc                        14.1                 h0510ff6_4
vs2015_runtime            14.16.27012          hf0eaf9b_1
werkzeug                  1.0.0                    pypi_0    pypi
wheel                     0.34.2                   pypi_0    pypi
wincertstore              0.2                      py37_0
wrapt                     1.12.1                   pypi_0    pypi

(tensorflow_cpu) C:\Users\Rakes>conda info

     active environment : tensorflow_cpu
    active env location : C:\Users\Rakes\.conda\envs\tensorflow_cpu
            shell level : 2
       user config file : C:\Users\Rakes\.condarc
 populated config files : C:\Users\Rakes\.condarc
          conda version : 4.8.2
    conda-build version : 3.17.6
         python version : 3.7.1.final.0
       virtual packages :
       base environment : C:\ProgramData\Anaconda3  (read only)
           channel URLs : https://repo.anaconda.com/pkgs/main/win-64
                          https://repo.anaconda.com/pkgs/main/noarch
                          https://repo.anaconda.com/pkgs/r/win-64
                          https://repo.anaconda.com/pkgs/r/noarch
                          https://repo.anaconda.com/pkgs/msys2/win-64
                          https://repo.anaconda.com/pkgs/msys2/noarch
          package cache : C:\ProgramData\Anaconda3\pkgs
                          C:\Users\Rakes\.conda\pkgs
                          C:\Users\Rakes\AppData\Local\conda\conda\pkgs
       envs directories : C:\Users\Rakes\.conda\envs
                          C:\ProgramData\Anaconda3\envs
                          C:\Users\Rakes\AppData\Local\conda\conda\envs
               platform : win-64
             user-agent : conda/4.8.2 requests/2.21.0 CPython/3.7.1 Windows/10 Windows/10.0.18362
          administrator : False
             netrc file : None
           offline mode : False


Commands used to install tensorflow pip install --upgrade tensorflow

### **Import TensorFlow not working **

`(tensorflow_cpu) C:\Users\Rakes>python -c ""import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))""
Traceback (most recent call last):
  File ""C:\Users\Rakes\.conda\envs\tensorflow_cpu\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Rakes\.conda\envs\tensorflow_cpu\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Rakes\.conda\envs\tensorflow_cpu\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\Rakes\.conda\envs\tensorflow_cpu\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\Rakes\.conda\envs\tensorflow_cpu\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""C:\Users\Rakes\.conda\envs\tensorflow_cpu\lib\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""C:\Users\Rakes\.conda\envs\tensorflow_cpu\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\Rakes\.conda\envs\tensorflow_cpu\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\Rakes\.conda\envs\tensorflow_cpu\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\Rakes\.conda\envs\tensorflow_cpu\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\Rakes\.conda\envs\tensorflow_cpu\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\Rakes\.conda\envs\tensorflow_cpu\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\Rakes\.conda\envs\tensorflow_cpu\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Rakes\.conda\envs\tensorflow_cpu\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Rakes\.conda\envs\tensorflow_cpu\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\Rakes\.conda\envs\tensorflow_cpu\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\Rakes\.conda\envs\tensorflow_cpu\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.`"
37611,"Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. [Op:Conv2D]","Tensorflow version: 2.0
CUDA version: 10.2

I'm trying to run a CNN network on a set of images in PyCharm IDE.
However, when I run the following code:

history = model.fit_generator(
   ...:     train_data_gen,
   ...:     epochs=epochs,
   ...:     validation_data=val_data_gen,)

 I get this error:

   ...: 
Epoch 1/80
2020-03-15 17:14:52.332052: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2020-03-15 17:14:52.346548: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
Traceback (most recent call last):
  File ""/home/adisha512/env/dl/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3326, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-18-5e082c56bdc2>"", line 4, in <module>
    validation_data=val_data_gen,)
  File ""/home/adisha512/env/dl/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py"", line 1297, in fit_generator
    steps_name='steps_per_epoch')
  File ""/home/adisha512/env/dl/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_generator.py"", line 265, in model_iteration
    batch_outs = batch_function(*batch_data)
  File ""/home/adisha512/env/dl/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py"", line 973, in train_on_batch
    class_weight=class_weight, reset_metrics=reset_metrics)
  File ""/home/adisha512/env/dl/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py"", line 264, in train_on_batch
    output_loss_metrics=model._output_loss_metrics)
  File ""/home/adisha512/env/dl/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_eager.py"", line 311, in train_on_batch
    output_loss_metrics=output_loss_metrics))
  File ""/home/adisha512/env/dl/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_eager.py"", line 252, in _process_single_batch
    training=training))
  File ""/home/adisha512/env/dl/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_eager.py"", line 127, in _model_loss
    outs = model(inputs, **kwargs)
  File ""/home/adisha512/env/dl/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 891, in __call__
    outputs = self.call(cast_inputs, *args, **kwargs)
  File ""/home/adisha512/env/dl/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/sequential.py"", line 256, in call
    return super(Sequential, self).call(inputs, training=training, mask=mask)
  File ""/home/adisha512/env/dl/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py"", line 708, in call
    convert_kwargs_to_constants=base_layer_utils.call_context().saving)
  File ""/home/adisha512/env/dl/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py"", line 860, in _run_internal_graph
    output_tensors = layer(computed_tensors, **kwargs)
  File ""/home/adisha512/env/dl/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 891, in __call__
    outputs = self.call(cast_inputs, *args, **kwargs)
  File ""/home/adisha512/env/dl/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/convolutional.py"", line 197, in call
    outputs = self._convolution_op(inputs, self.kernel)
  File ""/home/adisha512/env/dl/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_ops.py"", line 1134, in __call__
    return self.conv_op(inp, filter)
  File ""/home/adisha512/env/dl/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_ops.py"", line 639, in __call__
    return self.call(inp, filter)
  File ""/home/adisha512/env/dl/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_ops.py"", line 238, in __call__
    name=self.name)
  File ""/home/adisha512/env/dl/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_ops.py"", line 2010, in conv2d
    name=name)
  File ""/home/adisha512/env/dl/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1031, in conv2d
    data_format=data_format, dilations=dilations, name=name, ctx=_ctx)
  File ""/home/adisha512/env/dl/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1130, in conv2d_eager_fallback
    ctx=_ctx, name=name)
  File ""/home/adisha512/env/dl/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py"", line 67, in quick_execute
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. [Op:Conv2D]


Here's my complete code:

```bash
from __future__ import absolute_import, division, print_function, unicode_literals
import os
import numpy as np
import glob
import shutil
from IPython.display import display
from PIL import Image
import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator
_URL = ""https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz""

zip_file = tf.keras.utils.get_file(origin=_URL,
                                   fname=""flower_photos.tgz"",
                                   extract=True)

base_dir = os.path.join(os.path.dirname(zip_file), 'flower_photos')

classes = ['roses', 'daisy', 'dandelion', 'sunflowers', 'tulips']
print(base_dir)

for cl in classes:
  img_path = os.path.join(base_dir, cl)
  images = glob.glob(img_path + '/*.jpg')
  print(""{}: {} Images"".format(cl, len(images)))
  train, val = images[:round(len(images)*0.8)], images[round(len(images)*0.8):]
  for t in train:
    if not os.path.exists(os.path.join(base_dir, 'train', cl)):
      os.makedirs(os.path.join(base_dir, 'train', cl))
    shutil.move(t, os.path.join(base_dir, 'train', cl))

  for v in val:
    if not os.path.exists(os.path.join(base_dir, 'val', cl)):
      os.makedirs(os.path.join(base_dir, 'val', cl))
    shutil.move(v, os.path.join(base_dir, 'val', cl))


train_dir = os.path.join(base_dir, 'train')
val_dir = os.path.join(base_dir, 'val')

batch_size = 16
IMG_SHAPE = 150

image_gen_train = ImageDataGenerator(
      rescale=1./255,
      rotation_range=40,
      width_shift_range=0.2,
      height_shift_range=0.2,
      shear_range=0.2,
      zoom_range=0.2,
      horizontal_flip=True,
      fill_mode='nearest')


train_data_gen = image_gen_train.flow_from_directory(batch_size= batch_size,
                                                     directory=train_dir,
                                                     shuffle=True,
                                                     target_size=(IMG_SHAPE,IMG_SHAPE),
                                                     class_mode='categorical')

image_gen_val = ImageDataGenerator(rescale=1/255)
val_data_gen = image_gen_val.flow_from_directory(batch_size = batch_size,
                                                 directory=val_dir,
                                                 target_size=(IMG_SHAPE, IMG_SHAPE),
                                                 class_mode='categorical')

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),

    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),

    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),

    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(1024, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(5, activation='softmax')

])

model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])

model.summary()

epochs = 80

import tensorflow as tf
config = tf.compat.v1.ConfigProto()
config.gpu_options.allow_growth = True

tf.compat.v1.Session(config=config)

history = model.fit_generator(
    train_data_gen,
    epochs=epochs,
    validation_data=val_data_gen,)
```


### Can anyone please suggest me what to do here
"
37610,Generated docs for TF 2.1 and TF 2.2 are missing information present in the source docs,"## URL(s) with the issue:

The issue affects many pages, here is one example:
- TF 2.2: https://www.tensorflow.org/versions/r2.2/api_docs/python/tf/keras/optimizers/schedules/ExponentialDecay
- TF 2.1: https://www.tensorflow.org/versions/r2.1/api_docs/python/tf/keras/optimizers/schedules/ExponentialDecay
- TF 2.0: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/optimizers/schedules/ExponentialDecay

## Description of issue (what needs changing):
The generated docs for TF 2.1 and TF 2.2 is missing important information. Notably, the whole documentation of `__init__` method containing information like detailed learning rate computation
```python
def decayed_learning_rate(step):
  return initial_learning_rate * decay_rate ^ (step / decay_steps)
```
is missing in TF 2.1 and TF 2.2. However, the information is still present in the source, see 
https://github.com/tensorflow/tensorflow/blob/3c1e8c03419266bb6ba379d303d3e03a380617a8/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py#L64-L134

## Further examples
For example Adam optimizer is also affected, see
- TF 2.2: https://www.tensorflow.org/versions/r2.2/api_docs/python/tf/keras/optimizers/Adam
- TF 2.0: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/optimizers/Adam
The TF 2.0 version contains a lot of math describing how Adam works, which is not present in TF 2.2 docs."
37608,need custom implementations: NonMaxSuppressionV5,"**System information**
- Linux Ubuntu 18.04
- TensorFlow installed from binary
- TensorFlow 2.1


**Provide the text output from tflite_convert**

```
Here is a list of operators for which you will need custom implementations: NonMaxSuppressionV5.
```
"
37607,Lots of links are Broken.,"## URL(s) with the issue:  
https://github.com/tensorflow/docs/blob/r2.0/site/en/api_docs/python/index.md
## Description of the issue (what needs changing):
There are lots of links are broken, some of them are:
https://github.com/tensorflow/docs/blob/r2.0/site/en/api_docs/python/tf/dtypes/DType
https://github.com/tensorflow/docs/blob/r2.0/site/en/api_docs/python/tf/data/experimental/get_structure
https://github.com/tensorflow/docs/blob/r2.0/site/en/api_docs/python/tf/debugging/assert_same_float_dtype
https://github.com/tensorflow/docs/blob/r2.0/site/en/api_docs/python/tf/estimator/ModeKeys
https://github.com/tensorflow/docs/blob/r2.0/site/en/api_docs/python/tf/fill

### Clear description
There are lots of the link is broken in r2.0/site/en/api_docs/python/index.md. when someone clicks on these links it's showing 404 ERROR.

## Solution 
When I checked  https://www.tensorflow.org/versions/r2.0/api_docs/python . I found out every links
are correct. For example
* tf.DType link is broken in Github but working fine in TensorFlow website
As the numbers of broken links are big. I'll suggest adding a message like
"" Our TensorFlow 2.0 RC docs is moved to https://www.tensorflow.org/versions/r2.0/api_docs/python. Kindly checkout there""
I have seen this type of message in some of the TensorFlow docs.
## Pull Request
Hey, @dynamicwebpaige , @lamberta, @MarkDaoust  . Please assign me for doing this. I'll love to address this issue.
"
37606,Loaded runtime CuDNN library: 7.5.1 but source was compiled with: 7.6.5,"

Constructing simple LSTM model, feed arbitrary stuff, then I get the error:

> tensorflow.python.framework.errors_impl.UnknownError: Fail to find the dnn implementation. [Op:CudnnRNN]

I traced the error above a couple of lines, and I see it started with the error you see in the title.

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): 
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04):  Win10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below):  2.1 and 2.2 nightly, same.
- Python version: - 3.7
version (if compiling from source):
- GCC/Compiler version (if compiling from
source): 
- CUDA/cuDNN version: - GPU model and memory: Cuda 10.1, CuDNN 7.6, exactly as recommended in installation guide.

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
37602,Mixed Precision with tf.distribute,"It doesn't appear that mixed precision currently works with tf.distribute. Are there plans to add this soon?
"
37601,TF Lite ESP32 make License issue,"

**System information**
- Windows 10
-tensorflow cloned from git directly

**Describe the problem**
While trying to use make i get an issue with License:
```
C:\>make -f tensorflow/lite/micro/tools/make/Makefile TARGET=esp generate_hello_world_esp_project
make: *** No rule to make target 'LICENSE', needed by 'tensorflow/lite/micro/tools/make/gen/esp_xtensa-esp32/prj/hello_world/esp-idf/LICENSE'.  Stop.
```

**Provide the exact sequence of commands / steps that you executed before running into the problem**

Using the batch file provided by esp32 i setup the path variables:

```
Using Python in C:\Program Files\Python36\
Python 3.6.8
Using Git in C:\Program Files\Git\cmd\
git version 2.21.0.windows.1
Setting IDF_PATH: C:\Esp_IDF_Release_4_0\esp-idf

Adding ESP-IDF tools to PATH...
    C:\Esp_IDF_Release_4_0\.espressif\tools\xtensa-esp32-elf\esp-2019r2-8.2.0\xtensa-esp32-elf\bin
    C:\Esp_IDF_Release_4_0\.espressif\tools\xtensa-esp32s2-elf\esp-2019r2-8.2.0\xtensa-esp32s2-elf\bin
    C:\Esp_IDF_Release_4_0\.espressif\tools\esp32ulp-elf\2.28.51-esp-20191205\esp32ulp-elf-binutils\bin
    C:\Esp_IDF_Release_4_0\.espressif\tools\esp32s2ulp-elf\2.28.51-esp-20191205\esp32s2ulp-elf-binutils\bin
    C:\Esp_IDF_Release_4_0\.espressif\tools\cmake\3.13.4\bin
    C:\Esp_IDF_Release_4_0\.espressif\tools\openocd-esp32\v0.10.0-esp32-20191114\openocd-esp32\bin
    C:\Esp_IDF_Release_4_0\.espressif\tools\ninja\1.9.0\
    C:\Esp_IDF_Release_4_0\.espressif\tools\idf-exe\1.0.1\
    C:\Esp_IDF_Release_4_0\.espressif\tools\ccache\3.7\
    C:\Esp_IDF_Release_4_0\.espressif\python_env\idf4.2_py3.6_env\Scripts
    C:\Esp_IDF_Release_4_0\esp-idf\tools

Checking if Python packages are up to date...
Python requirements from C:\Esp_IDF_Release_4_0\esp-idf\requirements.txt are satisfied.

Done! You can now compile ESP-IDF projects.
Go to the project directory and run:

  idf.py build
```


**Any other info / logs**


make is working

idf.py --version
ESP-IDF v4.2-dev-701-g0ae960f2f

I made sure tensorflow folder is on c:/
"
37600,Output 0 of type variant does not match declared output type int64 for node node IteratorGetNext,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Standard setup for gcp kubeflow and notebook as in https://www.tensorflow.org/tfx/tutorials/tfx/cloud-ai-platform-pipelines

Trying a pipeline with keras model to estimator method. Similar to the one in https://github.com/tensorflow/tfx/blob/r0.21/tfx/examples/iris/iris_utils.py, but for a simple autoencoder for 1 feature.

**Current behavior**
When the pipeline tries to save checkpoint I get the error:
https://github.com/tensorflow/tfx/blob/r0.21/tfx/examples/iris/iris_utils.py

Output 0 of type variant does not match declared output type int64 for node node IteratorGetNext"
37598,2.2.0-rc1 aarch64 crosscompile build failed,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: ARM64 development board
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.2.0-rc1
- Python version: 3.8
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source): 2.0.0
- GCC/Compiler version (if compiling from source): buildroot
- CUDA/cuDNN version: none
- GPU model and memory: none

**Describe the problem**

Build failing due to missing value for mandatory attribute 'toolchain_config' in 'cc_toolchain' rule.

Followed the instructurons from [tensorflow-aarch64-crossbuild](https://github.com/xifengcun/tensorflow-aarch64-crossbuild) and update the changes as [tensorflow-2.2.0-rc1-aarch64-crossbuild](https://gist.github.com/openedev/7f7cb16af644d09f11fc49f42cbc2de9)

**Provide the exact sequence of commands / steps that you executed before running into the problem**

Below is my sample makefile

PYTHON_TENSORFLOW_CONF_ENV += \
        PYTHON_BIN_PATH=$(HOST_DIR)/bin/python3 \
        PYTHON_LIB_PATH=$(HOST_DIR)/lib/python3.8/site-packages \
        TF_NEED_OPENCL_SYCL=y \
        HOST_CXX_COMPILER=$(HOST_DIR)/bin/aarch64-buildroot-linux-gnu-g++ \
        HOST_C_COMPILER=$(HOST_DIR)/bin/aarch64-buildroot-linux-gnu-gcc \
        TF_NEED_COMPUTECPP=N \
        TF_NEED_OPENCL_SYCL=N \
        TF_NEED_ROCM=N \
        TF_NEED_CUDA=N \
        TF_DOWNLOAD_CLANG=N \
        CC_OPT_FLAGS=""-march=armv8-a"" \
        TF_SET_ANDROID_WORKSPACE=N

define PYTHON_TENSORFLOW_CONFIGURE_CMDS
        (cd $(@D); \
                export PATH=$(HOST_DIR)/bin:$(PATH); \
                $(PYTHON_TENSORFLOW_CONF_ENV) \
                $(SHELL) ./configure \
        )
endef

define PYTHON_TENSORFLOW_BUILD_CMDS
        (cd $(@D); \
                $(HOST_DIR)/bin/bazel build --crosstool_top=//aarch64-compiler:toolchain --cpu=aarch64 --config=opt //tensorflow/tools/pip_package:build_pip_package \
        )
endef

**Any other info / logs**

(cd /mnt/br/output/build/python-tensorflow-2.2.0-rc0; /mnt/br/output/host/bin/bazel build --crosstool_top=//aarch64-compiler:toolchain --cpu=aarch64 --config=opt //tensorflow/tools/pip_package:build_pip_package )
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=91
INFO: Reading rc options for 'build' from /mnt/br/output/build/python-tensorflow-2.2.0-rc0/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /mnt/br/output/build/python-tensorflow-2.2.0-rc0/.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=v2
INFO: Reading rc options for 'build' from /mnt/br/output/build/python-tensorflow-2.2.0-rc0/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/mnt/br/output/host/bin/python3 --action_env PYTHON_LIB_PATH=/mnt/br/output/host/lib/python3.8/site-packages --python_path=/mnt/br/output/host/bin/python3 --config=xla --action_env TF_CONFIGURE_IOS=0
INFO: Found applicable config definition build:v2 in file /mnt/br/output/build/python-tensorflow-2.2.0-rc0/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:xla in file /mnt/br/output/build/python-tensorflow-2.2.0-rc0/.bazelrc: --action_env=TF_ENABLE_XLA=1 --define=with_xla_support=true
INFO: Found applicable config definition build:opt in file /mnt/br/output/build/python-tensorflow-2.2.0-rc0/.tf_configure.bazelrc: --copt=-march=armv8-a --host_copt=-march=native --define with_default_optimizations=true
INFO: Found applicable config definition build:linux in file /mnt/br/output/build/python-tensorflow-2.2.0-rc0/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels
INFO: Found applicable config definition build:dynamic_kernels in file /mnt/br/output/build/python-tensorflow-2.2.0-rc0/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS
ERROR: /mnt/br/output/build/python-tensorflow-2.2.0-rc0/aarch64-compiler/BUILD:15:1: //aarch64-compiler:cc-compiler-aarch64: missing value for mandatory attribute 'toolchain_config' in 'cc_toolchain' rule
INFO: Call stack for the definition of repository 'lmdb' which is a tf_http_archive (rule definition at /mnt/br/output/build/python-tensorflow-2.2.0-rc0/third_party/repo.bzl:134:19):
 - /mnt/br/output/build/python-tensorflow-2.2.0-rc0/tensorflow/workspace.bzl:618:5
 - /mnt/br/output/build/python-tensorflow-2.2.0-rc0/WORKSPACE:19:1
ERROR: /mnt/br/output/build/python-tensorflow-2.2.0-rc0/aarch64-compiler/BUILD:15:1: Target '//aarch64-compiler:aarch64_linux_all_files' contains an error and its package is in error and referenced by '//aarch64-compiler:cc-compiler-aarch64'
ERROR: /mnt/br/output/build/python-tensorflow-2.2.0-rc0/aarch64-compiler/BUILD:15:1: Target '//aarch64-compiler:empty' contains an error and its package is in error and referenced by '//aarch64-compiler:cc-compiler-aarch64'
ERROR: /mnt/br/output/build/python-tensorflow-2.2.0-rc0/aarch64-compiler/BUILD:3:1: Target '//aarch64-compiler:cc-compiler-aarch64' contains an error and its package is in error and referenced by '//aarch64-compiler:toolchain'
ERROR: /root/.cache/bazel/_bazel_root/e6c5c285cc2a992859afbeeed0c80f12/external/bazel_tools/src/tools/launcher/BUILD:9:1: every rule of type cc_binary implicitly depends upon the target '//aarch64-compiler:toolchain', but this target could not be found because of: Target '//aarch64-compiler:toolchain' contains an error and its package is in error
ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: Analysis failed
INFO: Elapsed time: 0.151s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (1 packages loaded, 0 targets configured)
"
37597,TF Lite OpenCL Input Tensors Same Address,"This is already fixed in master (https://github.com/tensorflow/tensorflow/commit/8685cf97d568855f3e7cf194d7e370bb71c51c73#diff-49796db7c3f71b9c25c7837d9ee16abf), however I thought it's appropriate to report it nonetheless if anyone else encounters it.

Before the fix, the inputs of a model with three or more inputs were not copied correctly because some of them shared the same memory address in the context of OpenCL."
37595,ERROR: /workspace/tensorflow/python/BUILD:7451:1: C++ compilation of rule '//tensorflow/python:_pywrap_tf_cluster.so' failed (Exit 1),"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04.3 LTS (on Amazon EC2)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.0
- Python version: Python 3.7
- Installed using virtualenv? pip? conda?: no use
- Bazel version (if compiling from source): I don't know.
- GCC/Compiler version (if compiling from source):I don't know.
- CUDA/cuDNN version:I don't know.
- GPU model and memory:I don't know.



**Describe the problem**
I try to build.

```
git clone https://github.com/tensorflow/tensorflow.git
cd tensorflow
git checkout -b r2.0
CI_DOCKER_EXTRA_PARAMS=""-e CI_BUILD_PYTHON=python3 -e CROSSTOOL_PYTHON_INCLUDE_PATH=/usr/include/python3.4"" sudo tensorflow/tools/ci_build/ci_build.sh PI-PYTHON37 tensorflow/tools/ci_build/pi/build_raspberry_pi.sh PI_ONE
```

**Provide the exact sequence of commands / steps that you executed before running into the problem**

build error.

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

```
ERROR: /workspace/tensorflow/python/BUILD:7451:1: C++ compilation of rule '//tensorflow/python:_pywrap_tf_cluster.so' failed (Exit 1)
In file included from /usr/include/python2.7/Python.h:8:0,
                 from external/pybind11/include/pybind11/detail/common.h:112,
                 from external/pybind11/include/pybind11/pytypes.h:12,
                 from external/pybind11/include/pybind11/cast.h:13,
                 from external/pybind11/include/pybind11/attr.h:13,
                 from external/pybind11/include/pybind11/pybind11.h:44,
                 from tensorflow/python/grappler/cluster_wrapper.cc:27:
/usr/include/python2.7/pyconfig.h:24:54: fatal error: arm-linux-gnueabihf/python2.7/pyconfig.h: No such file or directory
 #  include <arm-linux-gnueabihf/python2.7/pyconfig.h>
                                                      ^
compilation terminated.
INFO: Elapsed time: 4748.612s, Critical Path: 227.38s
INFO: 2139 processes: 2139 local.
FAILED: Build did NOT complete successfully
FAILED: Build did NOT complete successfully
```"
37594,ERROR: C:/tensorflow/tensorflow/core/kernels/BUILD:7897:1: C++ compilation of rule '//tensorflow/core/kernels:mkl_conv_op' failed (Exit 2),"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 10 x64
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
- TensorFlow installed from (source or binary): git
- TensorFlow version: r 2.2
- Python version: 3.7
- Installed using virtualenv? pip? conda?: conda intel 3.7
- Bazel version (if compiling from source): 2.0
- GCC/Compiler version (if compiling from source): VS 2019
- CUDA/cuDNN version: 10.2
- GPU model and memory: Nvidia 1070 ti



**Describe the problem**
build error
**Provide the exact sequence of commands / steps that you executed before running into the problem**
bazel --output_base=c:/bazel/output_dir/ build --config=mkl --config=opt --config=cuda -- //tensorflow/tools/pip_package:build_pip_package

**Any other info / logs**
ERROR: C:/tensorflow/tensorflow/core/kernels/BUILD:7897:1: C++ compilation of rule '//tensorflow/core/kernels:mkl_conv_op' failed (Exit 2)
.\tensorflow/core/util/mkl_util.h(1263): error C2131: expression did not evaluate to a constant
.\tensorflow/core/util/mkl_util.h(1262): note: failure was caused by a read of a variable outside its lifetime
.\tensorflow/core/util/mkl_util.h(1262): note: see usage of 'dim'
.\tensorflow/core/util/mkl_util.h(1264): error C2131: expression did not evaluate to a constant
.\tensorflow/core/util/mkl_util.h(1262): note: failure was caused by a read of a variable outside its lifetime
.\tensorflow/core/util/mkl_util.h(1262): note: see usage of 'dim'
.\tensorflow/core/util/mkl_util.h(1266): error C3863: array type 'dnnl_dim_t [kNumDims]' is not assignable
.\tensorflow/core/util/mkl_util.h(1267): error C3863: array type 'dnnl_dim_t [kNumDims]' is not assignable
.\tensorflow/core/kernels/mkl_conv_ops.h(157): error C2679: binary '=': no operator found which takes a right-hand operand of type 'std::vector<long,std::allocator<long>>' (or there is no acceptable conversion)
C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC\Tools\MSVC\14.24.28314\include\vector(1176): note: could be 'std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>>::operator =(std::initializer_list<_Ty>)'
        with
        [
            _Ty=dnnl::memory::dim
        ]
C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC\Tools\MSVC\14.24.28314\include\vector(1168): note: or       'std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>>::operator =(const std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &)'
C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC\Tools\MSVC\14.24.28314\include\vector(665): note: or       'std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>>::operator =(std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &&) noexcept(<expr>)'
.\tensorflow/core/kernels/mkl_conv_ops.h(157): note: while trying to match the argument list '(dnnl::memory::dims, std::vector<long,std::allocator<long>>)'
.\tensorflow/core/kernels/mkl_conv_ops.h(182): error C2679: binary '=': no operator found which takes a right-hand operand of type 'std::vector<long,std::allocator<long>>' (or there is no acceptable conversion)
C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC\Tools\MSVC\14.24.28314\include\vector(1176): note: could be 'std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>>::operator =(std::initializer_list<_Ty>)'
        with
        [
            _Ty=dnnl::memory::dim
        ]
C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC\Tools\MSVC\14.24.28314\include\vector(1168): note: or       'std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>>::operator =(const std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &)'
C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC\Tools\MSVC\14.24.28314\include\vector(665): note: or       'std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>>::operator =(std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &&) noexcept(<expr>)'
.\tensorflow/core/kernels/mkl_conv_ops.h(182): note: while trying to match the argument list '(dnnl::memory::dims, std::vector<long,std::allocator<long>>)'
.\tensorflow/core/kernels/mkl_conv_ops.h(246): error C2679: binary '=': no operator found which takes a right-hand operand of type 'std::vector<long,std::allocator<long>>' (or there is no acceptable conversion)
C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC\Tools\MSVC\14.24.28314\include\vector(1176): note: could be 'std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>>::operator =(std::initializer_list<_Ty>)'
        with
        [
            _Ty=dnnl::memory::dim
        ]
C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC\Tools\MSVC\14.24.28314\include\vector(1168): note: or       'std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>>::operator =(const std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &)'
C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC\Tools\MSVC\14.24.28314\include\vector(665): note: or       'std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>>::operator =(std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &&) noexcept(<expr>)'
.\tensorflow/core/kernels/mkl_conv_ops.h(246): note: while trying to match the argument list '(dnnl::memory::dims, std::vector<long,std::allocator<long>>)'
.\tensorflow/core/kernels/mkl_conv_ops.h(254): error C2679: binary '=': no operator found which takes a right-hand operand of type 'std::vector<long,std::allocator<long>>' (or there is no acceptable conversion)
C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC\Tools\MSVC\14.24.28314\include\vector(1176): note: could be 'std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>>::operator =(std::initializer_list<_Ty>)'
        with
        [
            _Ty=dnnl::memory::dim
        ]
C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC\Tools\MSVC\14.24.28314\include\vector(1168): note: or       'std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>>::operator =(const std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &)'
C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC\Tools\MSVC\14.24.28314\include\vector(665): note: or       'std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>>::operator =(std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &&) noexcept(<expr>)'
.\tensorflow/core/kernels/mkl_conv_ops.h(254): note: while trying to match the argument list '(dnnl::memory::dims, std::vector<long,std::allocator<long>>)'
.\tensorflow/core/kernels/mkl_conv_ops.h(283): error C2679: binary '=': no operator found which takes a right-hand operand of type 'std::vector<long,std::allocator<long>>' (or there is no acceptable conversion)
C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC\Tools\MSVC\14.24.28314\include\vector(1176): note: could be 'std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>>::operator =(std::initializer_list<_Ty>)'
        with
        [
            _Ty=dnnl::memory::dim
        ]
C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC\Tools\MSVC\14.24.28314\include\vector(1168): note: or       'std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>>::operator =(const std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &)'
C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC\Tools\MSVC\14.24.28314\include\vector(665): note: or       'std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>>::operator =(std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &&) noexcept(<expr>)'
.\tensorflow/core/kernels/mkl_conv_ops.h(283): note: while trying to match the argument list '(dnnl::memory::dims, std::vector<long,std::allocator<long>>)'
.\tensorflow/core/kernels/mkl_conv_ops.h(474): error C2679: binary '=': no operator found which takes a right-hand operand of type 'std::vector<long,std::allocator<long>>' (or there is no acceptable conversion)
C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC\Tools\MSVC\14.24.28314\include\vector(1176): note: could be 'std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>>::operator =(std::initializer_list<_Ty>)'
        with
        [
            _Ty=dnnl::memory::dim
        ]
C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC\Tools\MSVC\14.24.28314\include\vector(1168): note: or       'std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>>::operator =(const std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &)'
C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC\Tools\MSVC\14.24.28314\include\vector(665): note: or       'std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>>::operator =(std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &&) noexcept'
.\tensorflow/core/kernels/mkl_conv_ops.h(474): note: while trying to match the argument list '(dnnl::memory::dims, std::vector<long,std::allocator<long>>)'
.\tensorflow/core/kernels/mkl_conv_ops.h(482): error C2679: binary '=': no operator found which takes a right-hand operand of type 'std::vector<long,std::allocator<long>>' (or there is no acceptable conversion)
C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC\Tools\MSVC\14.24.28314\include\vector(1176): note: could be 'std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>>::operator =(std::initializer_list<_Ty>)'
        with
        [
            _Ty=dnnl::memory::dim
        ]
C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC\Tools\MSVC\14.24.28314\include\vector(1168): note: or       'std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>>::operator =(const std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &)'
C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC\Tools\MSVC\14.24.28314\include\vector(665): note: or       'std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>>::operator =(std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &&) noexcept'
.\tensorflow/core/kernels/mkl_conv_ops.h(482): note: while trying to match the argument list '(dnnl::memory::dims, std::vector<long,std::allocator<long>>)'
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 2360.878s, Critical Path: 182.60s
INFO: 3346 processes: 3346 local.
FAILED: Build did NOT complete successfully
"
37593,"bug in C++ API ""AddSymbolicGradients""","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): Yes 
- OS Platform and Distribution: CentOS Linux 7.4
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: Unknown
- TensorFlow installed from (source or binary):source 
- TensorFlow version (use command below): TF 2.0
- Python version:3.7 
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from
source): 8.3
- CUDA/cuDNN version: None
- GPU model and memory: None

**Describe the current behavior**
I build a graph, then call `AddSymbolicGradients` to generate gradients, but I found the order of generated gradients does not match inputs. My inputs are `[a,b]`, but the generated gradients are `[b_grad, a_grad]`
**Describe the expected behavior**
gradients order match inputs. Gradients of inputs `[a,b]` should be `[a_grad, b_grad]`

**My work to solve the problem** 
I checked the code in tensorflow/cc/framework/gradients.cc [L532](https://github.com/tensorflow/tensorflow/blob/07112a5c7e233989652ecac3184f0dd640e1462b/tensorflow/cc/framework/gradients.cc#L532) 
```c++
    size_t dx_index = 0;
    for (const Edge* e : n->in_edges()) {
      if (e->IsControlEdge()) continue;
      if (dx_index == dx.size()) {
        return errors::Internal(
            ""Invalid gradient output index: "", dx_index, "" size: "", dx.size());
      }
      TF_RETURN_IF_ERROR(
          BackpropAlongEdge(dx[dx_index++], {e->src(), e->src_output()}));
    }
```
I think `dx_index` in code should be `e->dst_input()`, because `in_edges() `returns a `unordered_set` which order is not match `dx`, the input index of edge is `dst_input()`.The right code may be:
```c++
for (const Edge* e : n->in_edges()) {
      if (e->IsControlEdge()) continue;
      int dx_index = e->dst_input();
      if (dx_index >= dx.size()) {
        return errors::Internal(""Invalid gradient output index: "", dx_index, "" size: "", dx.size());
      }
      TF_RETURN_IF_ERROR(BackpropAlongEdge(dx[dx_index], {e->src(), e->src_output()}));
    }
```

After I modified the code, my program seems works fine.
"
37591,Example given in tf.image.rgb_to_yub is contadicting with the description.,"## URL(s) with the issue:
https://www.tensorflow.org/api_docs/python/tf/image/rgb_to_yuv?version=nightly

## Description of issue (what needs changing):
(1) The example image `x` has pixel values which are not in the range of [0,1]. So, it can't be fed to `rgb_to_yuv` directly without scaling it.
(2) Users of the API need example which is close to practical scenario. In this case, nobody wants to see the values changed by the function but they want correct implementation and pre-processing example.

### Submit a pull request? 
Yes

"
37590,#AttributeError: 'ImageDataGenerator' object has no attribute 'shape',"Hi everyone I am still getting used to using Keras. When I run the code below I get an error:
**AttributeError: 'ImageDataGenerator' object has no attribute 'shape'**
I haven't found any answer online even on stack overflow. Any help will be appreciated.


import os
import random
import cv2
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf
from tensorflow.python import keras
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from functools import partial
from tensorflow.keras.callbacks import TensorBoard
from time import time

path = os.path.join(os.getcwd(), 'histopathologic-cancer-detection')
path_totrain = os.path.join(path, 'train')
path_tolabels = os.path.join(path, 'train_labels.csv')
files = np.asarray(os.listdir(path_totrain))
image_paths = np.asarray([os.path.join(path_totrain, pic)
                          for pic in os.listdir(path_totrain)])


def rest_graph(seed=42):
    tf.compat.v1.reset_default_graph()
    tf.keras.backend.clear_session()
    tf.compat.v1.set_random_seed(seed)
    np.random.seed(seed)


def read_pic(X):
    img = cv2.imread(X)
    rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    return rgb_img


rest_graph()

df_labels = pd.read_csv(path_tolabels, usecols=['label'])
labels = df_labels.values
positive_indices = list(df_labels[df_labels.label == 1].index)
negative_indices = list(df_labels[df_labels.label == 0].index)
size = len(files)

#Distribution of data
per_pos, per_neg = len(positive_indices)/size, len(negative_indices)/size
df_labels.hist()
plt.show()

#visualisation of pictures
ran_neg_ind = random.sample(negative_indices, 4)
ran_pos_ind = random.sample(positive_indices, 4)
ran_positive_pics = files[ran_pos_ind]
ran_negative_pics = files[ran_neg_ind]
PathRanPosPics = [os.path.join(path_totrain, pic) for pic in ran_positive_pics]
PathRanNegPics = [os.path.join(path_totrain, pic) for pic in ran_negative_pics]

fig, axs = plt.subplots(2, 4, figsize=[15, 4])
fig.suptitle('Histopathologic scans of lymph node', fontweight='bold')
for i in range(4):
    axs[0, i].imshow(read_pic(PathRanNegPics[i]))
    axs[0, i].set_title('Positive Example', fontweight='bold')

    axs[1, i].imshow(read_pic(PathRanNegPics[i]))
    axs[1, i].set_title('Negative Example', fontweight='bold')
plt.show()

arr = np.c_[image_paths, labels]
train_df = pd.DataFrame(arr, columns=['Image', 'label'])


#Splitting data into train and test set
train_set, valid_set = train_test_split(train_df, test_size=0.2)

Datagen = ImageDataGenerator(rescale=1./255)
train_gen = Datagen.flow_from_dataframe(train_set, directory=None, x_col='Image',
                                        y_col='label', 
                                        target_size=(96, 96),
                                        batch_size=128, class_mode='binary')
valDatgen = ImageDataGenerator(rescale=1./255)
val_gen = valDatgen.flow_from_dataframe(valid_set, x_col='Image', y_col='label',
                                        target_size=(96, 96), batch_size=128,
                                        class_mode='binary')

#creating model
Defaultconv2D = partial(keras.layers.Conv2D, kernel_size=3,
                        strides=1, padding='SAME', use_bias=False)


class ResidualUnit(keras.layers.Layer):
    def __init__(self, filters, strides, activation='relu', **kwargs):
        super().__init__(**kwargs)
        self.activation = keras.activations.get(activation)
        self.main_layers = [
            Defaultconv2D(filters=filters, strides=strides),
            keras.layers.BatchNormalization(),
            self.activation,
            Defaultconv2D(filters=filters),
            keras.layers.BatchNormalization()
        ]

        self.skip_layer = []
        if strides > 1:
            self.skip_layer = [
                Defaultconv2D(filters=filters, kernel_size=1, strides=strides),
                keras.layers.BatchNormalization()
            ]

    def call(self, inputs, **kwargs):
        z = inputs
        for layer in self.main_layers:
            z = layer(z)
        skip_z = inputs
        for layer in self.skip_layer:
            skip_z = layer(skip_z)
        return self.activation(z + skip_z)

model = keras.Sequential()
model.add(Defaultconv2D(filters=32, activation='relu', input_shape=[96, 96, 3]))
model.add(Defaultconv2D(filters=32, activation='relu'))
model.add(keras.layers.MaxPool2D(pool_size=3, strides=2, padding='SAME'))
prev_filter = 32
for filters in [64]*5 + [128]*6 + [256]*4:
    strides = 1 if prev_filter == filters else 2
    model.add(ResidualUnit(filters=filters, strides=strides))
    prev_filter = filters
model.add(keras.layers.GlobalAvgPool2D())
model.add(keras.layers.Flatten())
model.add(keras.layers.Dense(1, activation='softmax'))
print(model.summary())
model.compile(optimizer='Adam', loss='binary_crossentropy',
                        metrics=['accuracy'])
history = model.fit_generator(train_gen, epochs=10, validation_data=valDatgen)






"
37587,EarlyStopping Callback not working with Multiple Callbacks,"**System information** 
- Have I written custom code  
- OS Platform and Distribution: *Google Colab*
- TensorFlow version: *2.1.0*
- Keras: *2.2.4-tf*
- Python version: *3* 
- CUDA/cuDNN version: No GPU but happens also with it

**Describe the current behavior**
When a CustomCallback  uses `model.predict` or `model.evaluate` as part of `on_epoch_end`,  to for example, track a custom evaluation metric on an test dataset, `model.stop_training` is reset to False even if it was previously set to True by Early Stopping. Training does not stop. Current workaround is putting EarlyStopping as the last callback of the list.

**Describe the expected behavior**
Regardless the order in which callbacks are called, if one of the sets the model to stop training it should stop even if a later callback resets the stop flag.

**Standalone code to reproduce the issue** 
Check this colab with the full example: https://colab.research.google.com/drive/1lw943Ggwkp_wvGxVX-5XqaEJ5qXmrHlA

In short:
```
class MyCallback(keras.callbacks.Callback):
    def __init__(self, test_data):
        super(MyCallback, self).__init__()
        self.test_data = test_data

    def on_epoch_end(self, epoch, logs=None):
        print(f""\n--------- pre-predict stop_training={self.model.stop_training}\n"")
        #The problem is in the prediction: if commented ES works fine
        predictions = self.model.predict(self.test_data.batch(512))
        print(f""\n--------- post-predict stop_training={self.model.stop_training}\n"")
```
```
es = keras.callbacks.EarlyStopping(patience=2)
myc = MyCallback(test_data)

#This causes EarlyStop not to stop
my_callbacks = [es, myc]
#Either of these works fine
#my_callbacks = [myc, es]
#my_callbacks = [es]
...
model.fit(train_data.batch(512),
          validation_data=validation_data.batch(512),
          epochs=100,
          callbacks=my_callbacks,
          verbose=1)
```

This issue is refered also in the keras repository: https://github.com/keras-team/keras/issues/13381

Some thoughts: I'm not sure if the correct solution would be to discourage the use of predict or evaluate inside a training loop since there may be some other side effects of running one of those to the model.

Anyway, I'm opening the issue and submitting a pull request to fix this.
"
37584,tf.linalg.triangular_solve segfaults instead of broadcasting,"**System information** 
- Have I written custom code: no
- OS Platform and Distribution: Linux Ubuntu 18.04
- TensorFlow installed from: pip install tensorflow
- TensorFlow version: v2.1.0-rc2-17-ge5bf8de 2.1.0
- Python version: 3.7.6

**Describe the current behavior**

`tf.linalg.triangular_solve` segfaults when the shapes don't match *and* tf.linalg.triangular_solve hasn't been run before (if it has successfully been run before, it raises an InvalidArgumentError instead).

**Describe the expected behavior**

Not to segfault. Ideally, to broadcast!

**Standalone code to reproduce the issue**

```python
import numpy as np
import tensorflow as tf

shape1 = (3, 3)
shape2 = (1, 3, 3)

# works either way around
if np.random.rand() < 0.5: shape1, shape2 = shape2, shape1

LA = tf.convert_to_tensor(np.tril(np.random.randn(*shape1)))
B = tf.convert_to_tensor(np.random.randn(*shape2))

segfault = True
if segfault:
    tf.linalg.triangular_solve(LA, B, lower=True)  # segfaults
else:
    tf.linalg.triangular_solve(tf.squeeze(LA), tf.squeeze(B), lower=True)  # works fine
    tf.linalg.triangular_solve(LA, B, lower=True)  # raises InvalidArgumentError
```

May be related to #25391"
37581,"tf.keras.Model.fit() training fails, custom training loop succeeds for identical model, optimizer, and loss function","### System information 
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: 
Yes, but can reproduce with (almost) stock example script

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
MacOS Mojave and CentOS 7

- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:
N/A

- **TensorFlow installed from (source or binary)**:
binary

- **TensorFlow version (use command below)**:
v2.1.0-rc2-17-ge5bf8de 2.1.0

- **Python version**:
3.7.4

- **Bazel version (if compiling from source)**:
N/A

- **GCC/Compiler version (if compiling from source)**:
N/A

- **CUDA/cuDNN version**:
10.1, but have also validated on CPU

- **GPU model and memory**:
GeForce RTX 2080TI

- **Exact command to reproduce**:
See script below.

### Describe the problem
When training the same model with the same data, loss function, and optimizer, significantly different performance is obtained when using the built in training loops from tf.keras.Model.fit() versus implementing the training loop manually. This is clear by comparing the output of these two cases for the VAE example code provided at [Writing custom layers and models](https://www.tensorflow.org/guide/keras/custom_layers_and_models), which is reproduced below with minimal alterations. The issue becomes more clear when using a BinaryCrossentropy loss rather than MSE loss, and I have also reproduced it with custom loss functions. Obviously, the ability of users to detect the bug will depend on the data, loss function, optimizer, and extent of training. However, it should be possible to obtain the same performance between a simple custom training loop and the fit() method, as advertised in the documentation at the link above. Additionally, it is concerning that the recommended option (i.e. the fit() method) performs more poorly to the alternative, even with many more iterations (I have tried many, many iterations). Perhaps the fit() method is implementing additional loss terms not easily exposed to the user that are modifying the optimization landscape and subsequently the convergence behavior? The results are robust across multiple runs and (presumably) different random number seeds.

### Source code / logs
A script to reproduce is provided, making use of the dsprites data set through tensorflow_datasets. This example is likely not minimal, but it consistently reproduces the bug. Image reproductions with the trained VAE models are also included for the two training cases

```python

import tensorflow as tf
from tensorflow.keras import layers
import tensorflow_datasets as tfds
import numpy as np
import matplotlib.pyplot as plt

class Sampling(layers.Layer):
  """"""Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.""""""

  def call(self, inputs):
    z_mean, z_log_var = inputs
    batch = tf.shape(z_mean)[0]
    dim = tf.shape(z_mean)[1]
    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))
    return z_mean + tf.exp(0.5 * z_log_var) * epsilon


class Encoder(layers.Layer):
  """"""Maps MNIST digits to a triplet (z_mean, z_log_var, z).""""""

  def __init__(self,
               latent_dim=32,
               intermediate_dim=64,
               name='encoder',
               **kwargs):
    super(Encoder, self).__init__(name=name, **kwargs)
    self.dense_proj = layers.Dense(intermediate_dim, activation='relu')
    self.dense_mean = layers.Dense(latent_dim)
    self.dense_log_var = layers.Dense(latent_dim)
    self.sampling = Sampling()

  def call(self, inputs):
    x = self.dense_proj(inputs)
    z_mean = self.dense_mean(x)
    z_log_var = self.dense_log_var(x)
    z = self.sampling((z_mean, z_log_var))
    return z_mean, z_log_var, z


class Decoder(layers.Layer):
  """"""Converts z, the encoded digit vector, back into a readable digit.""""""

  def __init__(self,
               original_dim,
               intermediate_dim=64,
               name='decoder',
               **kwargs):
    super(Decoder, self).__init__(name=name, **kwargs)
    self.dense_proj = layers.Dense(intermediate_dim, activation='relu')
    self.dense_output = layers.Dense(original_dim, activation='sigmoid')

  def call(self, inputs):
    x = self.dense_proj(inputs)
    return self.dense_output(x)


class VariationalAutoEncoder(tf.keras.Model):
  """"""Combines the encoder and decoder into an end-to-end model for training.""""""

  def __init__(self,
               original_dim,
               intermediate_dim=64,
               latent_dim=32,
               name='autoencoder',
               **kwargs):
    super(VariationalAutoEncoder, self).__init__(name=name, **kwargs)
    self.original_dim = original_dim
    self.encoder = Encoder(latent_dim=latent_dim,
                           intermediate_dim=intermediate_dim)
    self.decoder = Decoder(original_dim, intermediate_dim=intermediate_dim)

  def call(self, inputs):
    z_mean, z_log_var, z = self.encoder(inputs)
    reconstructed = self.decoder(z)
    # Add KL divergence regularization loss.
    kl_loss = - 0.5 * tf.reduce_mean(
        z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1)
    self.add_loss(kl_loss)
    return reconstructed


def plotRecons(model, dat, savePlot=None):
  """"""Plots reconstructions of provided images.
  """"""
  fig, ax = plt.subplots(len(list(dat)), 2)
  for i, im in enumerate(dat):
    ax[i,0].imshow(im[:,:,0], cmap='gray_r', vmin=0.0, vmax=1.0)
    thisrecon = model(tf.cast(tf.reshape(im, (1,4096)), 'float32'))
    thisrecon = np.reshape(thisrecon, (64,64))
    randomIm = np.random.random(thisrecon.shape)
    #thisrecon = np.array((thisrecon > randomIm), dtype=int)
    ax[i,1].imshow(thisrecon, cmap='gray_r', vmin=0.0, vmax=1.0)
    ax[i,0].tick_params(axis='both', which='both',
                        left=False, right=False, bottom=False, top=False,
                        labelleft=False, labelbottom=False,
                        labelright=False, labeltop=False)
    ax[i,1].tick_params(axis='both', which='both',
                        left=False, right=False, bottom=False, top=False,
                        labelleft=False, labelbottom=False,
                        labelright=False, labeltop=False)

  fig.tight_layout()
  if savePlot is not None:
    fig.savefig(savePlot)
  plt.show()


def trainCustom(train_dataset, epochs=2, original_dim=4096):
  vae = VariationalAutoEncoder(original_dim, 64, 32)
  
  optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)
  #loss_fn = tf.keras.losses.MeanSquaredError()
  loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=False,
                                               reduction=tf.keras.losses.Reduction.SUM)

  # Iterate over epochs.
  for epoch in range(epochs):
    print('Start of epoch %d' % (epoch,))
  
    # Iterate over the batches of the dataset.
    for step, x_batch_train in enumerate(train_dataset):
      with tf.GradientTape() as tape:
        reconstructed = vae(x_batch_train)
        # Compute reconstruction loss
        loss = loss_fn(x_batch_train, reconstructed)
        loss += sum(vae.losses)  # Add KLD regularization loss
  
      grads = tape.gradient(loss, vae.trainable_weights)
      optimizer.apply_gradients(zip(grads, vae.trainable_weights))
  
      if step % 1000 == 0:
        print('step %s: mean loss = %s' % (step, loss))
  
  return vae


def trainBuiltIn(train_dataset, epochs=2, original_dim=4096):
  vae = VariationalAutoEncoder(original_dim, 64, 32)
  
  optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)
  
  vae.compile(optimizer, #loss=tf.keras.losses.MeanSquaredError())
              loss=tf.keras.losses.BinaryCrossentropy(from_logits=False,
                                                      reduction=tf.keras.losses.Reduction.SUM))

  zipdata = tf.data.Dataset.zip((train_dataset, train_dataset))

  vae.fit(zipdata, epochs=epochs)

  return vae


def main():

  def flatImFromDict(adict):
    return tf.squeeze(tf.reshape(tf.cast(adict['image'], 'float32'), (-1, 4096)))

  trainDataRaw = tfds.load(""dsprites"", split=""train"")
  trainData = trainDataRaw.map(flatImFromDict)
  trainData = trainData.shuffle(buffer_size=64).batch(64, drop_remainder=True)
  plotData = [tf.cast(adict['image'], 'float32') for i, adict in enumerate(trainDataRaw) if i<5]

  #First test custom, well-controlled loop
  vaeCustom = trainCustom(trainData, epochs=2)
  plotRecons(vaeCustom, plotData, savePlot='recons_custom.png')

  #Next look at build in loops with fit function
  vaeBuiltIn = trainBuiltIn(trainData, epochs=2)
  plotRecons(vaeBuiltIn, plotData, savePlot='recons_built-in.png')


if __name__==""__main__"":
  main()

```

![recons_built-in_CrossEntropy](https://user-images.githubusercontent.com/7297977/76646659-b7d1bc00-6531-11ea-9e4d-8d280531121a.png)
![recons_custom_CrossEntropy](https://user-images.githubusercontent.com/7297977/76646661-b86a5280-6531-11ea-916a-4ae20c4b78a8.png)
"
37580,tf.train.FloatList() on a tensor takes too long,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: any
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 2.1.x, 1.5.x
- **Python version**: 3.7
- **Bazel version (if compiling from source)**: any
- **GCC/Compiler version (if compiling from source)**: any
- **CUDA/cuDNN version**: any
- **GPU model and memory**: any
- **Exact command to reproduce**: `tf.train.FloatList(value=tf.zeros(int(1e6)))`

### Describe the problem

Compare the execution time of those two lines:
```
feature = tf.train.FloatList(value=tf.zeros(int(1e6)).numpy())
```
```
feature = tf.train.FloatList(value=tf.zeros(int(1e6)))
```

The first one runs as it should, the second one takes ages to complete. (I guess something tries iterating over the tensor in the second case)

N.B. this is not specific to `FloatList` - its rather numpy vs Tensor value, evaluation something (I don't quite grasp the internals).

"
37577,log(diag_part(x)) vs diag_part(log(x)) difference with Cholesky gradients,"
**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Mac OS Mojave 10.14.5
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: -
- TensorFlow installed from (source or
binary): binary (by pip)
- TensorFlow version (use command below): 2.1.0
- Python version: 3.6.6
- Bazel
version (if compiling from source): -
- GCC/Compiler version (if compiling from
source): -
- CUDA/cuDNN version: - (running on CPU)
- GPU model and memory: - (running on CPU)

**Describe the current behavior**
Gradients of a variable, whose loss depends on the logarithm of the diagonal of its Cholesky decomposition (`tf.linalg.cholesky()`), can fail depending on the ordering of the `tf.math.log()` and `tf.linalg.diag_part()` operations. `tf.linalg.diag_part(tf.math.log(L))` results in NaN gradients, `tf.math.log(tf.linalg.diag_part(L))` runs as expected (where `L` is the Cholesky decomposition). 

**Describe the expected behavior**
`tf.math.log(tf.linalg.diag_part(L))` and `tf.linalg.diag_part(tf.math.log(L))` should both give rise to the same (correct) gradients. the order of these ops shouldn't matter

**Standalone code to reproduce the issue** 
```
import numpy as np
import tensorflow as tf


LR = 0.01
X = tf.random.normal([100, 10], 0., 1.)
LOG2PI = 1.8378770664093453
WITH_BUG = True
N_ITERS = 100


def gaussian_pdf(samples, mean, covariance):
    n = tf.cast(tf.shape(samples)[1], tf.float32)
    L = tf.linalg.cholesky(covariance)
    alpha = tf.linalg.cholesky_solve(L, tf.transpose(samples - mean))
    data_fit = -0.5 * tf.reduce_sum(tf.transpose(alpha) * (samples - mean), -1)
    regulariser_bug = -0.5 * tf.reduce_sum(tf.linalg.diag_part(tf.math.log(L)), axis=-1)
    regulariser_fine = -0.5 * tf.reduce_sum(tf.math.log(tf.linalg.diag_part(L)), axis=-1)
    regulariser = regulariser_bug if WITH_BUG else regulariser_fine
    normaliser = -n * 0.5 * LOG2PI
    return data_fit + regulariser + normaliser


def loss(x, mu, sigma):
    ll = gaussian_pdf(x, mu, sigma)
    return -tf.reduce_mean(ll)


cov_np = np.random.normal(size=(10, 10), scale=0.001) + np.eye(10) * 2.
cov_var = tf.Variable(cov_np, dtype=tf.float32)
mean_var = tf.Variable([3.] * 10, dtype=tf.float32)


def train(x):
    with tf.GradientTape() as t:
        nll = loss(x, mean_var, cov_var)
    dm, dsig = t.gradient(nll, [mean_var, cov_var])
    dm_avg, dcov_avg = tf.reduce_mean(dm).numpy(), tf.reduce_mean(dsig).numpy()
    print(f'Avg grads: mu: {dm_avg}, cov: {dcov_avg}')
    mean_var.assign_sub(LR * dm)
    cov_var.assign_sub(LR * dsig)


for _ in range(N_ITERS):
    print(f'Negative log-likelihood: {loss(X, mean_var, cov_var).numpy()}')
    train(X)
```"
37576,Add Octave Convolution Layers to tensorflow keras layers,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>

**System information**
- TensorFlow version (you are using): TF 2.1
- Are you willing to contribute it (Yes/No): Yes. And the code change is ready.

**Describe the feature and the current behavior/state.**
_Feature:_
[Drop an Octave: Reducing Spatial Redundancy in Convolutional Neural Networks with Octave Convolution](http://openaccess.thecvf.com/content_ICCV_2019/papers/Chen_Drop_an_Octave_Reducing_Spatial_Redundancy_in_Convolutional_Neural_Networks_ICCV_2019_paper.pdf)

_Main idea:_
Decompose the feature maps of the convolutional layers into features of different spatial frequencies which will enlarge the receptive field and reduce the FLOPs and memory cost.

Add an implementation of octave convolution layers (OctConv1D, OctConv2D, OctConv3D) and octave transposed convolution layers (OctConv2DTranspose, OctConv3DTranspose) that inherit from an abstract OctConv layer which, in turn, inherits from tf.keras.layers.Layer (same hierarchy as the already existing convolutional layers).
An octave_add function that takes as input the output of an OctConvND layer (list of two tensors one for  high frequencies and the other for low frequencies) and a tf.keras.layer like Dropout, MaxpoolingND, etc which will be applied on the inputs. The output is the list of the two resulting tensors

The backbone of the implementation is based on the following [github repository](https://github.com/CyberZHG/keras-octave-conv) (MIT and ""Anti 996"" licensed) by @CyberZHG

The original code has been substantially modified:
 - migration from keras to tf.keras
 - implementation of an abstract OctaveConv layer to emulate the hierarchy of the already existing Conv layers in TensorFlow
 - implementation of the 3D octave convolution layer OctConv3D and the transposed octave convolution layers OctConv2DTranspose, OctConv3DTranspose
 - bug fixes (for instance, in the original implementation setting the trainable attribute of the octave convolution layers to False wouldn't freeze the learnable weights)

_Sample use case of the layers OctConvLayers:_

```
l1 = Input(shape=(28,28, 1))
l2 = OctaveConv2D(32, (3, 3), activation='relu', low_freq_ratio=0.25)(l1_input) # takes a single input tensor and outputs a list of 2 output tensors (low_freq_ratio > 0)
l3 = octave_add(l2, MaxPooling2D(pool_size=(2, 2)))
l4 = octave_add(l3, Dropout(0.2))
l5 = OctaveConv2D(32, (3, 3), activation='relu', low_freq_ratio=0)(l4) # takes a list of 2 tensors and outputs a tensor (low_freq_ratio = 0)
l6 = Flatten()(l5) # l5 is a tensor so no need to use octave_add
```

_Current Behavior:_
Currently tensorflow doesn't have any implementation of the octave convolution layers.

_Why we need this api:_
The ""vanilla"" ConvND/ConvNDTranpose layers can be directly replaced by the OctConvND/OctConvNDTranspose layers and simple experiments that will be provided show that models using octave convolutions consistently give better performances than their vanilla versions.
Also, using octave convolutions will reduce the FLOPs and the memory cost.

**Will this change the current api? How?**
No, it won't change the current api.
It will add 6 new classes to tf.keras.layers (1 abstract, 3 OctConvND and 2 OctConvNDTranspose)

**Who will benefit with this feature?**
TensorFlow users who are seeking to improve the performances and computational costs of their model with a direct replacement of the vanilla convolutions without any adjustments in the network architecture.

**Any Other info.**"
37575,Keras model fit with class_weight fails on TPU but not on GPU,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow):  yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04):  Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: Colab
- TensorFlow installed from (source or
binary): Colab
- TensorFlow version (use command below): 2.x in Colab
- Python version: Colab
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source): 
- CUDA/cuDNN version: Colab
- GPU model and memory: Colab

**Describe the current behavior**
If I use the `class_weight` argument during model.fit(...) with a TPU, I get the following error:
![image](https://user-images.githubusercontent.com/36116534/76622564-07b08300-6532-11ea-81a3-2027161014dc.png)

If I change the runtime type to GPU, the model fits fine.  

**Describe the expected behavior**
Defining  `class_weight` on TPU should not fail if it works on the GPU.
"
37573,tf.data.experimental.ignore_errors unintuitive behavior,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Mac OS 10.14
- TensorFlow installed from (source or
binary): pip install tensorflow
- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de410 2.1.0
- Python version: 3.7.4

**Describe the current behavior**

When applying tf.data.experimental.ignore_errors() to a dataset which has been limited by take(), the error ignoring is applied before the take(). I.e., dataset.map(potential_error_source).take(N).apply(ignore_errors) always returns N elements. This is unintuitive, because according to the documentation ""produce a dataset that contains the same elements as the input, but silently drops any elements that caused an error.""

**Describe the expected behavior**

Expected behavior would be that dataset.map(potential_error_source).take(N).apply(ignore_errors) takes N elements, and then skips those that caused the error, i.e., resulting in <N elements in case there were errors. If that is not intended or cannot be implemented, at least the documentation should be updated to reflect that ignore_errors takes effect already at the point where the errors are raised.

**Standalone code to reproduce the issue** 

```
def generate():
         for i in range(1000):
             yield i

def map_fn(x):
    # raise assertion error for uneven numbers
    with tf.control_dependencies([tf.debugging.assert_equal(x % 2, 0)]):
         return x

dataset = tf.data.Dataset.from_generator(generate,output_types=tf.dtypes.int32).take(100)
len(list(iter(dataset)))
len(list(iter(dataset)))
# returns 100
dataset = tf.data.Dataset.from_generator(generate,output_types=tf.dtypes.int32).map(map_fn).take(100).apply(tf.data.experimental.ignore_errors())
len(list(iter(dataset)))
# returns 100
```
"
37572,cc_toolchain_suite '@androidndk//:toolchain-libcpp' does not contain a toolchain for cpu 'k8',"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): Source
- Python version: 3.7
- Bazel version (if compiling from source): 2.0.0

**Describe the problem**
I was trying to build tensorflow [camera demo](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android#building-the-demo-with-tensorflow-from-source) application using bazel.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
1.) I cloned the repo using.
`git clone --recurse-submodules https://github.com/tensorflow/tensorflow.git
` 

2.) Downloaded ndk [14b, 20b ](https://developer.android.com/ndk/downloads/older_releases.html#ndk-14b-downloads)(tried both)

3.) Build android-sdk 26.0.1

4.) configured `./WORKSPACE` using `./configure` and specified above mentioned ndk and sdk paths. Also, I specified API levels to their default values.

5.) Then I tried 

`bazel build --cxxopt='--std=c++11' -c opt //tensorflow/examples/android:tensorflow_demo
`

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

ERROR: 

`/home/unreal/.cache/bazel/_bazel_unreal/6de5222c143ce19677cab557a9a28cd8/external/androidndk/BUILD.bazel:41:1: in cc_toolchain_suite rule @androidndk//:toolchain-libcpp: cc_toolchain_suite '@androidndk//:toolchain-libcpp' does not contain a toolchain for cpu 'k8'
ERROR: Analysis of target '//tensorflow/examples/android:tensorflow_demo' failed; build aborted: Analysis of target '@androidndk//:toolchain-libcpp' failed; build aborted
INFO: Elapsed time: 2.946s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (107 packages loaded, 8813 targets configured)`

It seems like I am missing something for ndk bundle that I downloaded. [Here](https://docs.bazel.build/versions/master/android-ndk.html#integration-with-platforms-and-toolchains) there is something `register_toolchains(""@androidndk//:all"")` in WORKSPACE, but I don't know what I am missing. 
"
37571,Two errors were raised when using mirrored strategy.,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): 
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
- TensorFlow installed from (source or
binary): using conda
- TensorFlow version (use command below): 2.1.0
- Python version: 3.7.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from
source): 
- CUDA/cuDNN version: 10.1.243 / 7.6.5
- GPU model and memory: Tesla T4 16GB


```
TypeError: An op outside of the function building code is being passed
a ""Graph"" tensor. It is possible to have Graph tensors
leak out of the function building context by including a
tf.init_scope in your function building code.
For example, the following function will fail:
  @tf.function
  def has_init_scope():
    my_constant = tf.constant(1.)
    with tf.init_scope():
      added = my_constant * 2
The graph tensor has name: Dec_VAE_VDraw_Var/Identity:0

During handling of the above exception, another exception occurred:
...
_SymbolicException: Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'Dec_VAE_VDraw_Var/Identity:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'Dec_VAE_VDraw_Mean/Identity:0' shape=(None, 128) dtype=float32>]

```
reproducible notebook files:
https://drive.google.com/file/d/1DzES68HT3-7dlrpH6oo13Q9MgybdjcGm/view?usp=sharing

When i didn't use mirrored strategy and added experimental_tf_function = False as an argument to model.compile, the errors were not raised.

It would be glad if you would help me to solve this errors.


"
37570,"Load a TF model from memory, not file (C/C++)","**System information**
- TensorFlow version (you are using): 1.12.0
- Are you willing to contribute it (Yes/No): Yes, if possible.
- C/C++ interface.

**Describe the feature and the current behavior/state.**

We'd like to load model data from memory without file access.

We're using TF in a satellite data processing system. One of the requirements dictates that file access is not allowed, we can only load from memory. Of course the model is stored somewhere, but that is very much outside the parts we can reach from where we run, we can only receive the bytestream of that file in a memory block.

To meet this requirement, we privately patched version 1.12.0 of TF. Because we like living on the edge, we're also using the C++ (unstable) interface, so we're tied rather hard to this version at the moment. We realise that implementation of this feature request will require changes to our code, but will also make it a lot easier to move to the current version, especially now that the C interface seems to be stable (although statements in different parts on the site are inconsistent).

**Will this change the current api? How?**

This would be an _addition_ to the current interface. I don't see how the external interfaces would need to change, although internally the file loaders may want to use this new interface. 

**Who will benefit with this feature?**

Besides us, this may also be useful for the Java interface, as apache interfaces usually don't like files either. 

**Any Other info.**

None."
37569,error while converting from custom SSD_mobilenet to TFLITE,"**System information**
- OS Platform : windows 10
- TensorFlow installed from : anazonda tf-14


```
Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CONCATENATION, CONV_2D, DEPTHWISE_CONV_2D, LOGISTIC, RESHAPE. Here is a list of operators for which you will need custom implementations: TFLite_Detection_PostProcess.
```

using the file : 
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/python/tflite_convert.py

and command as : python tflite_convert.py --graph_def_file=D:\models\research\object_detection\ava_tflite\tflite_graph.pb --output_file=D:\models\research\object_detection\ava_tflite\tf_output --output_format=TFLITE --input_arrays=normalized_input_image_tensor --input_shapes=1,600,600,3 --inference_type=FLOAT --output_arrays=""TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3"" --allow_customs_ops=False



ERROR OUTPUT: 

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CONCATENATION, CONV_2D, DEPTHWISE_CONV_2D, LOGISTIC, RESHAPE. Here is a list of operators for which you will need custom implementations: TFLite_Detection_PostProcess.
Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\envs\tfgpu14\Scripts\toco_from_protos-script.py"", line 10, in <module>
    sys.exit(main())
  File ""C:\ProgramData\Anaconda3\envs\tfgpu14\lib\site-packages\tensorflow\lite\toco\python\toco_from_protos.py"", line 59, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""C:\ProgramData\Anaconda3\envs\tfgpu14\lib\site-packages\tensorflow\python\platform\app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""C:\ProgramData\Anaconda3\envs\tfgpu14\lib\site-packages\absl\app.py"", line 299, in run
    _run_main(main, args)
  File ""C:\ProgramData\Anaconda3\envs\tfgpu14\lib\site-packages\absl\app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""C:\ProgramData\Anaconda3\envs\tfgpu14\lib\site-packages\tensorflow\lite\toco\python\toco_from_protos.py"", line 33, in execute
    output_str = tensorflow_wrap_toco.TocoConvert(model_str, toco_str, input_str)
Exception: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CONCATENATION, CONV_2D, DEPTHWISE_CONV_2D, LOGISTIC, RESHAPE. Here is a list of operators for which you will need custom implementations: TFLite_Detection_PostProcess.
"
37568,ValueError: Cannot use 'loss/head_conv_0_0' as input to 'Merge_2/MergeSummary' because 'loss/head_conv_0_0' is in a while loop,"I try to create my own neural network with several outputs (it follows that there are several target vectors); these target vectors dynamically change during training and depend on the predictions of the neural network. I wrote about this neural network earlier in #37468.

**System information**

- OS Platform and Distribution: Debian GNU/Linux 9.11 (stretch)
- TensorFlow version: 2.1.0

The program works fine when I run it on CPU. But when running on TPU, it prints an error:
`ValueError: Cannot use 'loss/head_conv_0_0' as input to 'Merge_2/MergeSummary' because 'loss/head_conv_0_0' is in a while loop. See info log for more details.`

What could be the reason of the error?

Here is the complete code:
```
import tensorflow.compat.v1 as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Conv2D, Activation, Input, BatchNormalization, Layer
from tensorflow.core.protobuf import rewriter_config_pb2
import numpy as np
import tensorflow_datasets as tfds

height = 5
width = 5
use_tpu = True
train_batch_size = 8 * 8 if use_tpu else 1
steps = 20000
learning_rate = 1e-4
iterations_per_loop = 100
log_step_count_steps = 100
use_async_checkpointing = False
if use_async_checkpointing:
    save_checkpoints_steps = None
else:
    save_checkpoints_steps = max(500, iterations_per_loop)
model_dir=""gs://my_storage/model""
data_dir=""gs://my_storage/datasets""
tpu = ""grpc://10.3.101.2:8470""
gcp_project = ""my_project""
tpu_zone = ""us-central1""

if use_tpu:
    tpu_cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(
                                tpu, zone=tpu_zone, project=gcp_project)
    master = tpu_cluster_resolver.get_master()
else:
    tpu_cluster_resolver = None
    master = None

class Conv2d:
    def __init__(self, x, filters, kernel_size, name, strides=(1, 1), padding='same', activation='relu', reuse=True):
        with tf.variable_scope(name, reuse=reuse):
            self.name = name
            self.x = Conv2D(filters, kernel_size, strides=strides, padding=padding, name=name)(x)
            bn_name = name + '_bn'
            self.x = BatchNormalization(scale=False,
                                        name=bn_name)(self.x)
            ac_name = name + '_ac'
            self.x = Activation(activation=activation, name=ac_name)(self.x)

class OutputLayer(Layer):
    def __init__(self, name, **kwargs):
        super(OutputLayer, self).__init__(name=name, **kwargs)

    def call(self, inputs):
        return inputs

def make_input_fn(dataset_fn, params):

    def input_fn(params):
        x_train = dataset_fn()[0][""train""]
        batch_size = params[""batch_size""]
        y_true = tf.random.uniform(
                    shape=(8*batch_size, 32*32*8,), minval=0.0, maxval=1.0, dtype=tf.dtypes.float32, seed=7777)

        def preprocess(x, y):
            x = tf.cast(x, tf.float32) * (1. / 255)
            labels_dic = {}
            for h in range(height):
                for w in range(width):
                    labels_dic[""head_conv_{}_{}"".format(h, w)] = y_true
            return x, labels_dic

        dataset = (x_train
                    .map(preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)
                    .repeat()
                    .shuffle(128, seed=7777, reshuffle_each_iteration=True)
                    .batch(8*batch_size, drop_remainder=True)
                    .prefetch(-1))
        return dataset

    return input_fn

def get_model(features, input_shape, reuse):
    with tf.variable_scope('model', reuse=reuse):
        inputs = Input(shape=input_shape)
        seqs = []
        n_filters = 8
        for h in range(height):
            seq = []
            for w in range(width):
                if seq == []:
                   if h==0 and w==0: 
                        seq.append(Conv2d(inputs, n_filters, (3, 3), name=""conv_{}_{}"".format(h, w), reuse=reuse))
                   else:
                        seq.append(Conv2d(seqs[-1][0].x, n_filters, (3, 3), name=""conv_{}_{}"".format(h, w), reuse=reuse))
                else:
                    seq.append(Conv2d(seq[-1].x, n_filters, (3, 3), name=""conv_{}_{}"".format(h, w), reuse=reuse))
            seqs.append(seq)
        tmp = np.array([x for x in [seq for seq in seqs]]).ravel()
        outputs = []
        heads = []
        for x in tmp:
            outputs.append(OutputLayer(name=""output_""+x.name)(x.x))
            heads.append(tf.estimator.RegressionHead(label_dimension=32*32*8, name=""head_""+x.name))

        model = Model(inputs=inputs, outputs=outputs)
        head = tf.estimator.MultiHead(heads)
        opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)
        metrics = ['accuracy']
        model.compile(loss='mean_squared_error',
                          optimizer=opt,
                          metrics=metrics)
        model.summary()
    return model, head

def model_fn(features, labels, mode, params):
    batch_size = 8 * params['batch_size']

    model, head = get_model(features, params['input_shape'], reuse=False)
    logits_train = model(features)
    logits_train_dic = {}
    i = 0
    for h in range(height):
        for w in range(width):
            logits_train[i] = tf.reshape(logits_train[i], (batch_size, 32*32*8,))
            logits_train_dic[""head_conv_{}_{}"".format(h, w)] = logits_train[i]
            i += 1
    pred_classes = tf.argmax(logits_train, axis=1)
    if mode == tf.estimator.ModeKeys.PREDICT:
        return tf.estimator.tpu.TPUEstimatorSpec(mode, predictions=pred_classes)

    new_labels = {}
    for key in labels:
        new_labels[key] = labels[key][0]
    loss = 0.0
    for key in logits_train_dic:
        logit_train = logits_train_dic[key]
        loss += tf.square(labels[key]-logit_train)
    loss_op = tf.reduce_mean(loss)
    optimizer = tf.train.AdamOptimizer(learning_rate=params['learning_rate'])
    if params['use_tpu']:
        optimizer = tf.tpu.CrossShardOptimizer(optimizer)
    train_op_fn = lambda loss_op: optimizer.minimize(
                                  loss_op,
                                  global_step=tf.train.get_global_step())
                
    estim_specs = head.create_estimator_spec(
                  features={""x"": features},
                  labels=new_labels,
                  mode=mode,
                  logits=logits_train_dic,
                  train_op_fn=train_op_fn)
    return estim_specs

tf.logging.set_verbosity(tf.logging.INFO)
tf.disable_v2_behavior()

dataset_fn = lambda: tfds.load(
            name='cifar10',
            with_info=True,
            as_supervised=True,
            try_gcs=True,
            data_dir=data_dir)
info = dataset_fn()[1]
n_samples = info.splits['train'].get_proto().statistics.num_examples
n_classes = info.features['label'].num_classes
train_shape = info.features['image'].shape
tf.config.set_soft_device_placement(True)

config = tf.estimator.tpu.RunConfig(
              master=master,
              model_dir=model_dir,
              save_checkpoints_steps=save_checkpoints_steps,
              log_step_count_steps=log_step_count_steps,
              session_config=tf.ConfigProto(
                  graph_options=tf.GraphOptions(
                      rewrite_options=rewriter_config_pb2.RewriterConfig(
                          disable_meta_optimizer=True))),
              tpu_config=tf.estimator.tpu.TPUConfig(
                  iterations_per_loop=iterations_per_loop,
                  per_host_input_for_training=tf.estimator.tpu.InputPipelineConfig
                  .PER_HOST_V2))

params = {
    'use_tpu': use_tpu,
    'input_shape': train_shape,
    'learning_rate': learning_rate
}

model = tf.estimator.tpu.TPUEstimator(
          model_fn, use_tpu=use_tpu,
          config=config,
          train_batch_size=train_batch_size,
          params=params)
model.train(make_input_fn(dataset_fn, params), steps=steps)
```"
37567,Cumulative decaying sum,"**System information**
- TensorFlow version (you are using): 2.1.0
- Are you willing to contribute it (Yes/No): Yes (with some guidance)



**Describe the feature and the current behavior/state.**

Add a new function `cumsum_decay` which computes the cumulative sum along an axis while multiplying the previous element with a scalar decay factor `p`:

    c_i = x_i + p*c_{i-1}    for i >= 1
    c_i = x_i                for i == 0

Example interface:

    def cumsum_decay(x, p, axis=0, exclusive=False, reverse=False, name=None):

where

* `x, axis, exclusive, reverse, name` are similar to [`tf.math.cumsum`](https://www.tensorflow.org/api_docs/python/tf/math/cumsum),
* `p` is a scalar tensor.

**Will this change the current api? How?**

It will add one function `tf.math.cumsum_decay`.

**Who will benefit with this feature?**

Doing this sort of computation comes up repeatedly, for example see these StackExchange questions:

* [Increasing each element of a tensor by the predecessor in Tensorflow 2.0](https://stackoverflow.com/q/60590333/3767239)
* [Can the cumsum function in NumPy decay while adding?](https://stackoverflow.com/q/28915088/3767239)
* [Parallel or efficient computation of value with momentum](https://cs.stackexchange.com/q/73746/23162)

**Any Other info.**

Since I'm not familiar with the tensorflow core, I cannot judge whether this feature is easy to implement based on the implementation of `cumsum`."
37564,Dose TensorFlow has tf.sparse.segment_max? how to code it by customer?,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using):
- Are you willing to contribute it (Yes/No):



**Describe the feature and the current behavior/state.**

**Will this change the current api? How?**

**Who will benefit with this feature?**

**Any Other info.**
"
37563,large model parallelism on gpu causing oom,"We are using v100 with gpu memory of 32 gb to train wide and deep model of size 12gb, facing the problem of gpu out of memory. 

So we are thinking of the model parallelism to distribute the large model on different gpu, however, all of the current available strategies for model parallelism could not meet our demand.

1. MirroredStrategy 
2. MultiWorkerMirroredStrategy
3. CentralStorageStrategy
4. ParameterServerStrategy
5. TPUStrategy

For MirroredStrategy  and MultiWorkerMirroredStrategy, each variable in the model is mirrored across all the replicas, which means that gpu memory of each card is still in shortage. CentralStorageStrategy and ParameterServerStrategy have great communication cost among cpus and gpus. So my question is for our large ctr model is there any solutions to realize model parallelism"
37562,Successful installation message but still not able to import tensorflow,"<em>Traceback (most recent call last):
  File ""C:\Users\Praveen.prakash\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Praveen.prakash\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Praveen.prakash\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\ProgramData\Anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\ProgramData\Anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 3326, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-1-616800c633ce>"", line 1, in <module>
    import tensorflow as tf
  File ""C:\Users\Praveen.prakash\AppData\Roaming\Python\Python37\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""C:\Users\Praveen.prakash\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\Praveen.prakash\AppData\Roaming\Python\Python37\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\Praveen.prakash\AppData\Roaming\Python\Python37\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\ProgramData\Anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\Praveen.prakash\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\Praveen.prakash\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\Praveen.prakash\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Praveen.prakash\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Praveen.prakash\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\ProgramData\Anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\ProgramData\Anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.</em>"
37561,"When using MirroredStrategy, the training process is stuck","**System information** 
- OS Platform and Distribution: Ubuntu 18.04
- Python version: 3.6.9
- CUDA/cuDNN version: 2x1080 Ti
- Tensorflow version: 2.2.0

**Describe the current behavior**
I built a CRNN model for recognize the text, a CNN-RNN-CTC model, it work well without tf.distribute.Strategy, but when I follow the guide to move the creation and compiling of Keras model inside strategy.scope, It does not start distributed training like the guide. here is the output:
```
2020-03-13 06:19:04.839700: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-03-13 06:19:04.874256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.91GiB deviceMemoryBandwidth: 451.17GiB/s
2020-03-13 06:19:04.875077: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties: 
pciBusID: 0000:02:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2020-03-13 06:19:04.875273: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-13 06:19:04.876811: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-13 06:19:04.878155: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-13 06:19:04.878383: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-13 06:19:04.879998: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-13 06:19:04.881014: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-13 06:19:04.884664: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-13 06:19:04.887439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1
2020-03-13 06:19:04.887722: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-03-13 06:19:04.892905: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3598110000 Hz
2020-03-13 06:19:04.893743: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f1224000b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-03-13 06:19:04.893784: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-03-13 06:19:05.147750: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x59b91e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-03-13 06:19:05.147778: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1
2020-03-13 06:19:05.147788: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): GeForce GTX 1080 Ti, Compute Capability 6.1
2020-03-13 06:19:05.150073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.91GiB deviceMemoryBandwidth: 451.17GiB/s
2020-03-13 06:19:05.150888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties: 
pciBusID: 0000:02:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2020-03-13 06:19:05.150926: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-13 06:19:05.150943: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-13 06:19:05.150958: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-13 06:19:05.150972: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-13 06:19:05.150986: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-13 06:19:05.151000: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-13 06:19:05.151015: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-13 06:19:05.154118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1
2020-03-13 06:19:05.154160: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-13 06:19:05.156174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-13 06:19:05.156195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 1 
2020-03-13 06:19:05.156206: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N Y 
2020-03-13 06:19:05.156214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 1:   Y N 
2020-03-13 06:19:05.158304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9569 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-03-13 06:19:05.159295: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10369 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)
Epoch 1/5
```
The training process seems to be interrupted without any output, but the program runs out of graphics card memory and the program does not exit.

**Describe the expected behavior**
Start training just like without distributed strategy.

**Standalone code to reproduce the issue** 
The full code can be view [here](https://github.com/FLming/CRNN.tf2)
"
37559,TF_FORCE_GPU_ALLOW_GROWTH=false Triggers cuDNN Error,"**System information** 
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **No, using tutorial classification example**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Manjaro (kernel 5.4.18)**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: 
- TensorFlow installed from (source or binary): **conda binary**
- TensorFlow version (use command below): **2.1.0**
- Python version: **3.7.6**
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from
source): 
- CUDA/cuDNN version: **CUDA 10.1 / cuDNN 7.6.5**
- GPU model and memory: **RTX 2070, 8GB**

**Describe the current behavior**

Classification fail to train if `TF_FORCE_GPU_ALLOW_GROWTH` not set to true. It raises: 

`tensorflow.python.framework.errors_impl.UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.`

I suspect cuDNN is asking for more memory after Tensorflow has already allocated all available memory. An easy but hacky fix is to set `TF_FORCE_GPU_ALLOW_GROWTH` to true by default and asking users to set it to false when they need max performance. It makes sense to ensure that the model would always run rather than ensuring that it would run with max efficiency. However, we should address this issue from the core. 

**Describe the expected behavior**

Model would train like when `TF_FORCE_GPU_ALLOW_GROWTH` is set to true. 

**Standalone code to reproduce the issue**

Run classification.ipynb on [the tutorial](https://www.tensorflow.org/tutorials/images/classification) without setting `TF_FORCE_GPU_ALLOW_GROWTH`. 

**Other info / logs** Include any logs or source code that would be helpful to

[error_log.txt](https://github.com/tensorflow/tensorflow/files/4328031/log.txt)
"
37556,TF 2 equivalent for report_tensor_allocations_upon_oom,"What is the TensorFlow 2 equivalent for `report_tensor_allocations_upon_oom` discribed here: https://github.com/tensorflow/tensorflow/issues/17076

How would I use this in eager mode with keras?"
37555,Running CI tests locally for Python 3 files,"**System information**
- Platform: Ubuntu 18.04 on WSL2 
- TensorFlow version: source master@f8396d00c2572845774cce4b737858f264e015b6
- Bazel version (if compiling from source): running CPU Docker container, says 2.0



**Describe the problem**
I'm trying to run CI tests locally. I'm having Python 2/3 issues. I'm using `tensorflow/tensorflow/python/autograph/pyct/static_analysis/` for testing since it has tests (ex `liveness_py3_test.py`) that use Python 3 syntax and have a properly configured `BUILD`.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
```
tensorflow/tools/ci_build/ci_build.sh CPU bazel test --jobs=1 --ram_utilization_factor 30 -- //tensorflow/python/autograph/pyct/static_analysis/... 
```
```
File ""tensorflow/bazel-ci_build-cache/.../tensorflow/python/autograph/pyct/static_analysis/liveness_py3_test.runfiles/org_tensorflow/tensorflow/python/autograph/pyct/static_analysis/liveness_py3_test.py"", line 39                                                                                     

nonlocal nonlocal_a                                                                                                                                                                                                             
                  ^                                                                                                                                                                                       

SyntaxError: invalid syntax 
```


**Any other info / logs**
```
TF_BUILD_INFO = {container_type: ""cpu"", command: ""bazel test --jobs=1 --ram_utilization_factor 30 -- //tensorflow/python/autograph/pyct/static_analysis/..."", source_HEAD: ""f8396d00c2572845774cce4b737858f264e015b6"", source_remote_origin: ""https://github.com/adriangb/tensorflow.git"", OS: ""Linux"", kernel: ""4.19.84-microsoft-standard"", architecture: ""x86_64"", Bazel_version: ""Build label: 2.0.0"", Java_version: ""1.8.0_242"", Python_version: ""2.7.12"", gpp_version: ""g++ (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609""}
```

It seems to me that running CI tests via Docker as per [`CONTRIBUTING.md`](https://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md) is not choosing the Python version correctly. Looking at CI logs, there are other flags being passed such as `--python_path=/usr/bin/python3`.

I'm not sure if this is a bug or `CONTRIBUTING.md` has not been updated for Python 3 transition. If the latter, what invocation options are necessary to get local CI via Docker to behave as the online CI does?"
37548,Keras connectivity metadata is not set correctly in TF 2.2.0rc0,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: N/A
- TensorFlow installed from (source or
binary): binary
- TensorFlow version (use command below): 2.2.0rc0
- Python version: 3.6.10
- Bazel
version (if compiling from source): N/A
- GCC/Compiler version (if compiling from
source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**

If a Keras model is applied to inputs with mismatched (but compatible) shape, the model is applied correctly but none of the Keras connectivity metadata (e.g. `inbound/outbound_nodes` or `keras_history`) is updated.

**Describe the expected behavior**

The Keras connectivity metadata should be updated, so after the model is applied there should be new inbound/outbound nodes for that application, and all the Tensors created by that application should have their keras_history set appropriately (this is the behaviour in TF<=2.1.0).

**Standalone code to reproduce the issue** 

``` python
import tensorflow as tf


for input_shape in [(1,), (1, 1)]:
    print(""input_shape"", input_shape)

    sub_in = tf.keras.Input((1,))
    relu_layer = tf.keras.layers.ReLU()
    sub_out = relu_layer(sub_in)
    submodel = tf.keras.Model(sub_in, sub_out)

    assert len(relu_layer.inbound_nodes) == 1

    inp = tf.keras.Input(input_shape)
    out = submodel(inp)

    assert len(relu_layer.inbound_nodes) == 2
```

The `assert len(relu_layer.inbound_nodes) == 2` condition fails when `input_shape=(1, 1)`, indicating that no new inbound nodes were created when `submodel` was applied to `inp`.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

The issue is that when this function is applied https://github.com/tensorflow/tensorflow/blob/v2.2.0-rc0/tensorflow/python/keras/engine/network.py#L926 it creates new tensors, which do not have a keras_history set. Then this condition evaluates to `False` https://github.com/tensorflow/tensorflow/blob/v2.2.0-rc0/tensorflow/python/keras/engine/base_layer.py#L947, so the `set_connectivity_metadata` function is never called here https://github.com/tensorflow/tensorflow/blob/v2.2.0-rc0/tensorflow/python/keras/engine/base_layer.py#L952."
37546,Android model personalization crash with keras model,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow):  **- no**
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Windows 10/Android
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: Android Emulator
- TensorFlow installed from (source or
binary): binary
- TensorFlow version (use command below): **2.0.0rc0** for generating model and  **org.tensorflow:tensorflow-lite:0.0.0-nightly** on the phone
- Python version: - Bazel
version (if compiling from source): Anaconda version 3.7

I'm fiddling with the example of model personalization on Android. It works great with model generated with https://github.com/tensorflow/examples/blob/master/lite/examples/model_personalization/converter/tfltransfer/tflite_transfer_convert.py but fails to work with model generated with example code given in decription of model_personnalization repo:

import tensorflow as tf
from tensorflow.keras import layers
from tensorflow.keras.regularizers import l2
from tfltransfer import bases
from tfltransfer import heads
from tfltransfer import optimizers
from tfltransfer.tflite_transfer_converter import TFLiteTransferConverter
base = bases.MobileNetV2Base(image_size=224)
head = tf.keras.Sequential([
    layers.Flatten(input_shape=(7, 7, 1280)),
    layers.Dense(
        units=32,
        activation='relu',
        kernel_regularizer=l2(0.01),
        bias_regularizer=l2(0.01)),
    layers.Dense(
        units=4,
        activation='softmax',
        kernel_regularizer=l2(0.01),
        bias_regularizer=l2(0.01)),
])
head.compile(loss='categorical_crossentropy', optimizer='sgd')
converter = TFLiteTransferConverter(4,
                                    base,
                                    heads.KerasModelHead(head),
                                    optimizers.SGD(3e-2),
                                    train_batch_size=20)
converter.convert_and_save('custom_keras_model')

The error is:
> A/libc: Fatal signal 11 (SIGSEGV), code 1 (SEGV_MAPERR), fault addr 0xfffffff4 in tid 22057 (amples.transfer), pid 22057 (amples.transfer)"
37545,tf.tpu.experimental.initialize_tpu_system() throwing error,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock - no
example script provided in TensorFlow): 
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04):  Debian GNU/Linux 9.11 (stretch) (GNU/Linux 4.9.0-11-amd64 x86_64\n)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): '2.2.0-dev20200309'
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from
source): 
- CUDA/cuDNN version: - GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

Here is the tpu config - it is in europe-west4-a:

```
acceleratorType: v3-8
cidrBlock: 10.240.1.16/29
createTime: '2020-03-09T19:38:19.525484434Z'
description: A Cloud TPU created with the ctpu tool.
health: HEALTHY
ipAddress: 10.240.1.18
name: 
network: global/networks/default
networkEndpoints:
- ipAddress: 10.240.1.18
  port: 8470
port: '8470'
schedulingConfig: {}
serviceAccount: 
state: READY
tensorflowVersion: nightly
```

**Describe the current behavior**
```
# Detect hardware, return appropriate distribution strategy
try:
    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.
    print('Running on TPU ', tpu.master())
except:
    tpu = None

if tpu:
    tf.config.experimental_connect_to_cluster(tpu)
    tf.tpu.experimental.initialize_tpu_system(tpu)
    strategy = tf.distribute.experimental.TPUStrategy(tpu)
else:
    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.

print(""REPLICAS: "", strategy.num_replicas_in_sync)
```
results in:
```
ValueError                                Traceback (most recent call last)
<ipython-input-3-b9f7d4f857ca> in <module>
     10 if tpu:
     11     tf.config.experimental_connect_to_cluster(tpu)
---> 12     tf.tpu.experimental.initialize_tpu_system(tpu)
     13     strategy = tf.distribute.experimental.TPUStrategy(tpu)
     14 else:

~/anaconda3/lib/python3.7/site-packages/tensorflow/python/tpu/tpu_strategy_util.py in initialize_tpu_system(cluster_resolver)
    122 
    123   logging.info(""Finished initializing TPU system."")
--> 124   tpu_topology = topology.Topology(serialized=serialized_topology)
    125   _INITIALIZED_TPU_SYSTEMS[tpu_name] = tpu_topology
    126 

~/anaconda3/lib/python3.7/site-packages/tensorflow/python/tpu/topology.py in __init__(self, serialized, mesh_shape, device_coordinates)
     76 
     77     if serialized:
---> 78       self._parse_topology(serialized)
     79     else:
     80       self._mesh_shape = np.asarray(mesh_shape, dtype=np.int32)

~/anaconda3/lib/python3.7/site-packages/tensorflow/python/tpu/topology.py in _parse_topology(self, serialized)
    102     if len(self._mesh_shape) != 3 or any(self._mesh_shape < 1):
    103       raise ValueError(""`mesh_shape` must be a vector of size 3 with positive ""
--> 104                        ""entries; got {}"".format(self._mesh_shape))
    105 
    106     if proto.num_tasks < 0:

ValueError: `mesh_shape` must be a vector of size 3 with positive entries; got [2 2 1 2]
```



**Describe the expected behavior**


**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
37544,Concat op not quantized ,"This issue is related to the concat implementation used for TFlite and TFlite micro.
For uint8 there are no restrictions on having the same scaling/zeropoint in the Input/Output.

But the implementation is not quantized
in concatenation.cc:
// TODO(prabhumk): This is the same as the optimized implementation.
// TODO(prabhumk): The quantized implementation of concatentation isn't fully
// quantized as it takes scale as a floating point value. This should be fixed
// when optimizng this routine further.
inline void ConcatenationWithScaling(const ConcatenationParams& params,
                                     const RuntimeShape* const* input_shapes,
                                     const uint8* const* input_data,
                                     const RuntimeShape& output_shape,
                                     uint8* output_data) {
...
      if (input_zeropoint[i] == output_zeropoint &&
          input_scale[i] == output_scale) {
        memcpy(output_ptr, input_ptr, copy_size);
      } else {
        const float scale = input_scale[i] * inverse_output_scale;
        const float bias = -input_zeropoint[i] * scale;
        for (int j = 0; j < copy_size; ++j) {
          const int32_t value =
              static_cast<int32_t>(std::round(input_ptr[j] * scale + bias)) +
              output_zeropoint;
          output_ptr[j] = static_cast<uint8_t>(
              std::max<int32_t>(std::min<int32_t>(255, value), 0));
        }
      }

**Standalone code to reproduce the issue** 
I have attached a tflite file that includes a concat op with different scaling/zeropoint in the Input/Output.

[concat_1x1x1x2048_requantize_6.zip](https://github.com/tensorflow/tensorflow/files/4325464/concat_1x1x1x2048_requantize_6.zip)


"
37543,"""Another profiler is running"" in TF 2.2.0rc0","**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: N/A
- TensorFlow installed from (source or
binary): binary
- TensorFlow version (use command below): 2.2.0rc0
- Python version: 3.6.10
- Bazel
version (if compiling from source): N/A
- GCC/Compiler version (if compiling from
source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**

""Another profiler is running"" error when using the TensorBoard callback profiling twice with `profile_batch=1` in non-eager mode.

**Describe the expected behavior**

There should be no error.

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
``` python
import tensorflow as tf
import numpy as np

tf.compat.v1.disable_eager_execution()

inp = tf.keras.Input((1,))
out = tf.keras.layers.Dense(units=1)(inp)
model = tf.keras.Model(inp, out)

model.compile(optimizer=tf.optimizers.SGD(1), loss=tf.losses.mse)

model.fit(
    np.zeros((64, 1)),
    np.zeros((64, 1)),
    callbacks=[tf.keras.callbacks.TensorBoard(log_dir=""tmp"", profile_batch=1)],
)

model.fit(
    np.zeros((64, 1)),
    np.zeros((64, 1)),
    callbacks=[tf.keras.callbacks.TensorBoard(log_dir=""tmp"", profile_batch=1)],
)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
```
Traceback (most recent call last):
  File "".../tmp.py"", line 21, in <module>
    callbacks=[tf.keras.callbacks.TensorBoard(log_dir=""tmp"", profile_batch=1)],
  File ""...\lib\site-packages\tensorflow\python\keras\callbacks.py"", line 1736, in __init__
    profiler.warmup()  # Improve the profiling accuracy.
  File ""...\lib\site-packages\tensorflow\python\profiler\profiler_v2.py"", line 124, in warmup
    start('')
  File ""...\lib\site-packages\tensorflow\python\profiler\profiler_v2.py"", line 74, in start
    'Another profiler is running.')
tensorflow.python.framework.errors_impl.AlreadyExistsError: Another profiler is running.
```"
37542,TFLite Inference Run on Android Issues,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**:
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:



### Describe the problem
 Hello I'm new on TFlite in Android. I've got issue when i wanna run my inference. i got problem in data types i don't know actually it does. My output model suppose to be array float but i still got that errors please help me!! Thankyou...

### Errors
![image](https://user-images.githubusercontent.com/36231029/76542439-8d431d00-64b7-11ea-8ee7-dcbba4324ece.png)
E/AndroidRuntime: FATAL EXCEPTION: main
    Process: com.example.katadasartflite, PID: 17681
    java.lang.IllegalArgumentException: DataType error: cannot resolve DataType of kotlin.Unit
        at org.tensorflow.lite.Tensor.dataTypeOf(Tensor.java:319)
        at org.tensorflow.lite.Tensor.throwIfTypeIsIncompatible(Tensor.java:377)
        at org.tensorflow.lite.Tensor.getInputShapeIfDifferent(Tensor.java:282)
        at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:137)
        at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:314)
        at org.tensorflow.lite.Interpreter.run(Interpreter.java:275)
        at com.example.katadasartflite.Classifier.recognizeWord(Classifier.kt:80)
        at com.example.katadasartflite.InferenceModel$initClassifier$1.onClick(InputFragment.kt:51)
        at android.view.View.performClick(View.java:7352)
        at android.widget.TextView.performClick(TextView.java:14177)
        at android.view.View.performClickInternal(View.java:7318)
        at android.view.View.access$3200(View.java:846)
        at android.view.View$PerformClick.run(View.java:27800)
        at android.os.Handler.handleCallback(Handler.java:873)
        at android.os.Handler.dispatchMessage(Handler.java:99)
        at android.os.Looper.loop(Looper.java:214)
        at android.app.ActivityThread.main(ActivityThread.java:7050)
        at java.lang.reflect.Method.invoke(Native Method)
        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:493)
        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:965)
W/System: A resource failed to call close. 



### Source code / logs
    fun recognizeWord() {
        Log.d(""RecognizeWord"",Arrays.toString(tflite.getInputTensor(0).shape()))
        val input = TensorBuffer.createFixedSize(intArrayOf(1,13,4),DataType.FLOAT32).loadArray(inputData)
        Trace.beginSection(""Start Recogize"")
        var outputInference = TensorBuffer.createDynamic(DataType.FLOAT32)
        Trace.beginSection(""Feed"")
        val startTimeForLoadImage = SystemClock.uptimeMillis()
        tflite.run(input,outputInference.intArray)
        val endTimeForReference = SystemClock.uptimeMillis()
        Trace.endSection()

        Log.d(""RecognizeWord"",outputInference.toString())

    }

"
37541,load_model(filename) fails on weight ordering if sublayer .trainable is modified after init,"**System information** 
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS, Darwin-19.3.0-x86_64-i386-64bit, mac version: ('10.15.3', ('', '', ''), 'x86_64')
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v1.12.1-26991-g5a6ae102f0 2.2.0-dev20200311
- Python version: 3.7.6

**Describe the current behavior**

Creating a layer and then setting `layer.trainable = False` (after creation) and then creating a model using that layer and saving that model with `model.save(filename)`, and then loading that model with `tf.keras.models.load_model(filename, custom_objects=...)`, fails because weights ordering for the layer is inconsistent.

**Describe the expected behavior**

I expect to be able to load a model I saved, despite having changed the `trainable` attribute on some layer before compiling and saving. (The `trainable` attribute is documented, with no warning that it must not be mutated, nor is there any runtime warning about this.)

**Standalone code to reproduce the issue** 

```python
import tensorflow as tf
from tensorflow import keras


class LayerWithSublayers(keras.layers.Layer):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.embedding = keras.layers.Embedding(3, 2)
        self.dense = keras.layers.Dense(4)

    def call(self, inputs, **kwargs):
        return self.dense(self.embedding(inputs))


input_ids = keras.Input(shape=(4,), dtype=tf.int32, name='input_ids')
output_layer = LayerWithSublayers()
output_layer.embedding.trainable = False
output = output_layer(input_ids)

model = keras.Model(inputs=[input_ids], outputs=[output])
model.compile(loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])

model_file_name = 'foo.h5'
model.save(filepath=model_file_name)

loaded_model = keras.models.load_model(model_file_name, custom_objects={'LayerWithSublayers': LayerWithSublayers})
```

If I change this to pass `trainable=False` when creating the `keras.layers.Embedding`, then the model loads just fine. So the problem is that the change of `trainable` is not reflected when the model is serialized to HDF5 format.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

Running the above script outputs this traceback:

```
Traceback (most recent call last):
  File ""keras_save_load_h5_nontrainable.py"", line 26, in <module>
    loaded_model = keras.models.load_model(model_file_name, custom_objects={'LayerWithSublayers': LayerWithSublayers})
  File ""/Users/gbr/.pyenv/versions/NLNIGHTLY/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py"", line 184, in load_model
    return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)
  File ""/Users/gbr/.pyenv/versions/NLNIGHTLY/lib/python3.7/site-packages/tensorflow/python/keras/saving/hdf5_format.py"", line 173, in load_model_from_hdf5
    load_weights_from_hdf5_group(f['model_weights'], model.layers)
  File ""/Users/gbr/.pyenv/versions/NLNIGHTLY/lib/python3.7/site-packages/tensorflow/python/keras/saving/hdf5_format.py"", line 704, in load_weights_from_hdf5_group
    K.batch_set_value(weight_value_tuples)
  File ""/Users/gbr/.pyenv/versions/NLNIGHTLY/lib/python3.7/site-packages/tensorflow/python/keras/backend.py"", line 3402, in batch_set_value
    x.assign(np.asarray(value, dtype=dtype(x)))
  File ""/Users/gbr/.pyenv/versions/NLNIGHTLY/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py"", line 842, in assign
    self._shape.assert_is_compatible_with(value_tensor.shape)
  File ""/Users/gbr/.pyenv/versions/NLNIGHTLY/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py"", line 1117, in assert_is_compatible_with
    raise ValueError(""Shapes %s and %s are incompatible"" % (self, other))
ValueError: Shapes (3, 2) and (2, 4) are incompatible
```"
37540,problem load saved model using tensorflow java ,"Hello,

I was using keras to build a simple MLP model, and want to use it for online prediction. Our online system is written in java, so I want to use tensorflow-java lib to load the model in savedmodel format. I saved the keras model using following scripts:
`  model = tf.keras.models.load_model(path)
  tf.saved_model.save(model, 'savedmodel/v1')
`

and write some simple test code to check all the opration nodes:
`   SavedModelBundle b = SavedModelBundle.load(""/Users/jaydone/v1"", ""serve"");
    Iterator<Operation> ops = b.graph().operations();
    Session sess = b.session();
    List<String> opNames = new ArrayList<>();
    while (ops.hasNext()) {
      Operation next = ops.next();
      System.out.println(next.name());
    }`

after running the code above, I get the output 
embedding_1/embeddings
embedding_1/embeddings/Read/ReadVariableOp
dense_1/kernel
dense_1/kernel/Read/ReadVariableOp
dense_1/bias
dense_1/bias/Read/ReadVariableOp
dense_2/kernel
dense_2/kernel/Read/ReadVariableOp
dense_2/bias
dense_2/bias/Read/ReadVariableOp
relevance_output/kernel
relevance_output/kernel/Read/ReadVariableOp
relevance_output/bias
relevance_output/bias/Read/ReadVariableOp
training/SGD/iter
training/SGD/iter/Read/ReadVariableOp
training/SGD/decay
training/SGD/decay/Read/ReadVariableOp
training/SGD/learning_rate
training/SGD/learning_rate/Read/ReadVariableOp
training/SGD/momentum
training/SGD/momentum/Read/ReadVariableOp
total
total/Read/ReadVariableOp
count
count/Read/ReadVariableOp
NoOp
Const
serving_default_albumid_embedding
serving_default_dense_input
serving_default_userid_embedding
StatefulPartitionedCall
saver_filename
StatefulPartitionedCall_1
StatefulPartitionedCall_2

none of them seems to be the output node. 

So how can I identify the output node, maybe I should add some parameters to specify it when saving the model like this ? 
`  tf.saved_model.save(model, 'savedmodel/v1', output=['relevance_output'])
`
Can anyone help me, thanks very much. 

"
37537,Why the loss doesn't decrease in my CNN model?,"Hi All,
I am new to tensorflow, and I find the losses doesn't decrease when train a CNN model on Cifar100 dataset.

Here is the Model code:

```python
network = Sequential([
    layers.Conv2D(64, kernel_size=[3, 3], padding=""same"", activation=tf.nn.relu), # 32x32
    layers.Conv2D(64, kernel_size=[3, 3], padding=""same"", activation=tf.nn.relu),
    layers.MaxPooling2D((2, 2)), # 16x16

    layers.Conv2D(128, kernel_size=[3, 3], padding=""same"", activation=tf.nn.relu),
    layers.Conv2D(128, kernel_size=[3, 3], padding=""same"", activation=tf.nn.relu),
    layers.MaxPooling2D((2, 2)), # 8x8

    layers.Conv2D(256, kernel_size=[3, 3], padding=""same"", activation=tf.nn.relu),
    layers.Conv2D(256, kernel_size=[3, 3], padding=""same"", activation=tf.nn.relu),
    layers.MaxPooling2D((2, 2)), # 4x4

    layers.Conv2D(512, kernel_size=[3, 3], padding=""same"", activation=tf.nn.relu),
    layers.Conv2D(512, kernel_size=[3, 3], padding=""same"", activation=tf.nn.relu),
    layers.MaxPooling2D((2, 2)), # 2x2

    layers.Conv2D(512, kernel_size=[3, 3], padding=""same"", activation=tf.nn.relu),
    layers.Conv2D(512, kernel_size=[3, 3], padding=""same"", activation=tf.nn.relu),
    layers.MaxPooling2D((2, 2)), # 1x1

    layers.Flatten(),

    layers.Dense(256, activation=tf.nn.relu),
    layers.Dense(128, activation=tf.nn.relu),
    layers.Dense(100, activation=None),
])
```

and this is the link for the entire code: https://colab.research.google.com/drive/1kIT_18Z-ymEgzqgG4nh4sZdBkA1bnJdO

and, It will be OK if I use only one Conv2D layer with maxpooling, like this:

```python
network = Sequential([
    layers.Conv2D(64, kernel_size=[3, 3], padding=""same"", activation=tf.nn.relu), # 32x32
    layers.MaxPooling2D((2, 2)), # 16x16

    layers.Conv2D(128, kernel_size=[3, 3], padding=""same"", activation=tf.nn.relu),
    layers.MaxPooling2D((2, 2)), # 8x8

    layers.Conv2D(256, kernel_size=[3, 3], padding=""same"", activation=tf.nn.relu),
    layers.MaxPooling2D((2, 2)), # 4x4

    layers.Conv2D(512, kernel_size=[3, 3], padding=""same"", activation=tf.nn.relu),
    layers.MaxPooling2D((2, 2)), # 2x2

    layers.Conv2D(512, kernel_size=[3, 3], padding=""same"", activation=tf.nn.relu),
    layers.MaxPooling2D((2, 2)), # 1x1

   #xxxxx
])
```

thanks~"
37536,How to use ApplyAdam(C++API)?,"Hi, I has used C++ API, but I got some problem about ApplyAdam:
  ApplyAdam(const ::tensorflow::Scope& scope, ::tensorflow::Input var,
          ::tensorflow::Input m, ::tensorflow::Input v, ::tensorflow::Input
          beta1_power, ::tensorflow::Input beta2_power, ::tensorflow::Input lr,
          ::tensorflow::Input beta1, ::tensorflow::Input beta2,
          ::tensorflow::Input epsilon, ::tensorflow::Input grad);

I do not know beta1_power and beta2_power in adam optimizer."
37534,loading pre-trained resnet-50 for Object Detection Models on TensorFlow 2.0,"## URL(s) with the issue:
https://github.com/tensorflow/models/tree/master/official/vision/detection

## Description of issue (what needs changing):

Hi,
In the ""Train a vanilla ResNet-50 based RetinaNet."" it is said to use the ""path to the pre-trained Resnet-50 checkpoint"". There is no link to any pre-trained model. 
![image](https://user-images.githubusercontent.com/54512903/76514447-2f331d00-6458-11ea-8d63-dd474964f22c.png)

I tried to use the resnet-50 which is in https://github.com/tensorflow/models/tree/master/official/vision/image_classification because it was likely to be a correct implementation as an official one. 
![image](https://user-images.githubusercontent.com/54512903/76515131-5b02d280-6459-11ea-973f-aabff6078c2d.png)
Unfortunately, when I use :
python main.py --strategy_type=one_device --num_gpus=1 --model_dir=""my_models"" --mode=train --config_file=""my_retinanet.yaml""

With this yaml : 
type: 'retinanet'
train: 
  checkpoint:
    path: pretrained_model\home\hongkuny\hongkuny_keras_resnet50_gpu_8_fp32_eager_graph_cfit\checkpoints
    prefix: resnet50\
  train_file_pattern: tfrecords\train.record
eval:
  eval_file_pattern: tfrecords\test.record

I got nothing load because the weight seems to be wrongly named in this file, so it is not matching.

![image](https://user-images.githubusercontent.com/54512903/76515306-a4532200-6459-11ea-90d7-b144b6498151.png)
 
I also tried some other models from the zoo assuming we might load weights from resnet based objects detection models but I got the same probleme. 

I think we might add a link to a correct checkpoint of a compatible pre-trained model in order to avoid roaming around incompatible models. 

regards, 

Swann"
37531,Incorrect number of Total Parameters when Loading a Saved Model with Trainable = False,"[Resume_Classification_Model.zip](https://github.com/tensorflow/tensorflow/files/4324479/Resume_Classification_Model.zip)
**System information** 
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): N/A, as it can be reproduced in Google Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:  N/A
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.1
- Python version: Colab
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source):  N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

This issue is similar to [29535](https://github.com/tensorflow/tensorflow/issues/29535) but now occurring in `Tensorflow Version 2.x`.

**Describe the current behavior**: Value of Total Parameters, when we Load the Saved Model with `Trainable = False` is Double compared to the Actual Total Parameters.

**Describe the expected behavior**: Value of Total Parameters should be same even we use `Trainable = True` or `Trainable = False`

**Standalone code to reproduce the issue** :  Please find the [attached Gist](https://colab.sandbox.google.com/gist/rmothukuru/a454904863d7a0e42b4497d6366a70e0/load_with_freeze_error.ipynb).

Please find the Model, ""Resume_Classification_Model.zip"", attached."
37525,AttributeError: module 'tensorflow' has no attribute 'compat' when importing tensorflow,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.1.0
- Python version: 3.6.8
- Installed using virtualenv? pip? conda?: Installed with poetry
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the problem**
After installing `tensorflow-cpu` 2.1.0, when I try to import it in python I get an error saying `AttributeError: module 'tensorflow' has no attribute 'compat'`. I also tried with the `tensorflow` package but I ran into the same issue.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

I create and activate a virtual env with poetry:
`poetry shell`

I install tensorflow-cpu:
`poetry add tensorflow-cpu`

then I run a python console:
```
python
>> import tensorflow
```
and I get the error

**Any other info / logs**
This is the traceback I get when importing tensorflow:

```
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/luis/.cache/pypoetry/virtualenvs/eae-85aUoSbr-py3.6/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""/home/luis/.cache/pypoetry/virtualenvs/eae-85aUoSbr-py3.6/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 46, in <module>
    from . _api.v2 import compat
  File ""/home/luis/.cache/pypoetry/virtualenvs/eae-85aUoSbr-py3.6/lib/python3.6/site-packages/tensorflow_core/_api/v2/compat/__init__.py"", line 39, in <module>
    from . import v1
  File ""/home/luis/.cache/pypoetry/virtualenvs/eae-85aUoSbr-py3.6/lib/python3.6/site-packages/tensorflow_core/_api/v2/compat/v1/__init__.py"", line 32, in <module>
    from . import compat
  File ""/home/luis/.cache/pypoetry/virtualenvs/eae-85aUoSbr-py3.6/lib/python3.6/site-packages/tensorflow_core/_api/v2/compat/v1/compat/__init__.py"", line 39, in <module>
    from . import v1
  File ""/home/luis/.cache/pypoetry/virtualenvs/eae-85aUoSbr-py3.6/lib/python3.6/site-packages/tensorflow_core/_api/v2/compat/v1/compat/v1/__init__.py"", line 29, in <module>
    from tensorflow._api.v2.compat.v1 import app
  File ""/home/luis/.cache/pypoetry/virtualenvs/eae-85aUoSbr-py3.6/lib/python3.6/site-packages/tensorflow_core/_api/v2/compat/__init__.py"", line 39, in <module>
    from . import v1
  File ""/home/luis/.cache/pypoetry/virtualenvs/eae-85aUoSbr-py3.6/lib/python3.6/site-packages/tensorflow_core/_api/v2/compat/v1/__init__.py"", line 32, in <module>
    from . import compat
  File ""/home/luis/.cache/pypoetry/virtualenvs/eae-85aUoSbr-py3.6/lib/python3.6/site-packages/tensorflow_core/_api/v2/compat/v1/compat/__init__.py"", line 39, in <module>
    from . import v1
  File ""/home/luis/.cache/pypoetry/virtualenvs/eae-85aUoSbr-py3.6/lib/python3.6/site-packages/tensorflow_core/_api/v2/compat/v1/compat/v1/__init__.py"", line 667, in <module>
    from tensorflow_estimator.python.estimator.api._v1 import estimator
  File ""/home/luis/.cache/pypoetry/virtualenvs/eae-85aUoSbr-py3.6/lib/python3.6/site-packages/tensorflow_estimator/__init__.py"", line 10, in <module>
    from tensorflow_estimator._api.v1 import estimator
  File ""/home/luis/.cache/pypoetry/virtualenvs/eae-85aUoSbr-py3.6/lib/python3.6/site-packages/tensorflow_estimator/_api/v1/estimator/__init__.py"", line 10, in <module>
    from tensorflow_estimator._api.v1.estimator import experimental
  File ""/home/luis/.cache/pypoetry/virtualenvs/eae-85aUoSbr-py3.6/lib/python3.6/site-packages/tensorflow_estimator/_api/v1/estimator/experimental/__init__.py"", line 10, in <module>
    from tensorflow_estimator.python.estimator.canned.dnn import dnn_logit_fn_builder
  File ""/home/luis/.cache/pypoetry/virtualenvs/eae-85aUoSbr-py3.6/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/canned/dnn.py"", line 33, in <module>
    from tensorflow_estimator.python.estimator import estimator
  File ""/home/luis/.cache/pypoetry/virtualenvs/eae-85aUoSbr-py3.6/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 53, in <module>
    from tensorflow_estimator.python.estimator import util as estimator_util
  File ""/home/luis/.cache/pypoetry/virtualenvs/eae-85aUoSbr-py3.6/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py"", line 75, in <module>
    class _DatasetInitializerHook(tf.compat.v1.train.SessionRunHook):
AttributeError: module 'tensorflow' has no attribute 'compat'
```"
37523,Cannot build tensorflow from docker image tensorflow/tensorflow:devel-gpu,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**

Base image: [tensorflow/tensorflow:devel-gpu](https://hub.docker.com/layers/tensorflow/tensorflow/devel-gpu/images/sha256-a29a94004f4f9fbf2a3810d4e9fcd2cd4caa5f18c179a7dea7b1b0db6e3fdbde?context=explore)
Image hash: a29a94004f4f9fbf2a3810d4e9fcd2cd4caa5f18c179a7dea7b1b0db6e3fdbde

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version: master
- Python version: v3.6
- Bazel version (if compiling from source): 2.0.0 
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0 
- GPU model and memory: Tesla V100

**Describe the problem**

Docker image [tensorflow/tensorflow:devel-gpu](https://hub.docker.com/layers/tensorflow/tensorflow/devel-gpu/images/sha256-a29a94004f4f9fbf2a3810d4e9fcd2cd4caa5f18c179a7dea7b1b0db6e3fdbde?context=explore) is expected to provide a reliable environment to build tensorflow from source code with bazel. 

However, the bazel build fails in the container from either `docker build` or `docker run`. 

**Provide the exact sequence of commands / steps that you executed before running into the problem**

(1) Make sure the host has nvidia drivers support. 
```
$ nvidia-smi
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 410.104      Driver Version: 410.104      CUDA Version: 10.0     |
|-------------------------------+----------------------+----------------------+
```
```
$ nvcc --version
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2018 NVIDIA Corporation
Built on Sat_Aug_25_21:08:01_CDT_2018
Cuda compilation tools, release 10.0, V10.0.130
```
(2) Download the latest devel-gpu image:
```
$ docker image pull tensorflow/tensorflow:devel-gpu
devel-gpu: Pulling from tensorflow/tensorflow
Digest: sha256:a29a94004f4f9fbf2a3810d4e9fcd2cd4caa5f18c179a7dea7b1b0db6e3fdbde
Status: Image is up to date for tensorflow/tensorflow:devel-gpu
docker.io/tensorflow/tensorflow:devel-gpu
```
(3) Build a new docker image which builds tensorflow
```
$ cat Dockerfile
FROM tensorflow/tensorflow:devel-gpu
WORKDIR /tensorflow_src
RUN bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
```
```
$ docker build .
```

(4) Notice the link error from bazel
```
ImportError: /root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/tensorflow/compiler/tf2tensorrt/_pywrap_py_utils.so: undefined symbol: _ZN10tensorflow8internal10LogMessageC1EPKcii
Target //tensorflow/tools/pip_package:build_pip_package failed to build
```
Full error log could be found at the end. 

(5) Alternative: build from docker container
Instead of running `docker build`, this error can be reproducible from `docker run` and `bazel build` from the container as well.

```
$ docker run -it tensorflow/tensorflow:devel-gpu bash
#  bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
```

(6) Alternative: other devel-gpu images
This error is reproducible to other images from the past week.  

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

```
RROR: /tensorflow_src/tensorflow/python/keras/api/BUILD:103:1: Executing genrule //tensorflow/python/keras/api:keras_python_api_gen failed (Exit 1)
Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py"", line 776, in <module>
    main()
  File ""/root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py"", line 772, in main
    lazy_loading, args.use_relative_imports)
  File ""/root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py"", line 629, in create_api_files
    compat_api_versions, lazy_loading, use_relative_imports)
  File ""/root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py"", line 503, in get_api_init_text
    _, attr = tf_decorator.unwrap(attr)
  File ""/root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/tensorflow/python/util/tf_decorator.py"", line 219, in unwrap
    elif _has_tf_decorator_attr(cur):
  File ""/root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/tensorflow/python/util/tf_decorator.py"", line 124, in _has_tf_decorator_attr
    hasattr(obj, '_tf_decorator') and
  File ""/root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/tensorflow/python/util/lazy_loader.py"", line 62, in __getattr__
    module = self._load()
  File ""/root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/tensorflow/python/util/lazy_loader.py"", line 45, in _load
    module = importlib.import_module(self.__name__)
  File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 994, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 971, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 955, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 658, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 571, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 922, in create_module
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
ImportError: /root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/tensorflow/compiler/tf2tensorrt/_pywrap_py_utils.so: undefined symbol: _ZN10tensorflow8internal10LogMessageC1EPKcii
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
ERROR: /tensorflow_src/tensorflow/tools/pip_package/BUILD:62:1 Executing genrule //tensorflow/python/keras/api:keras_python_api_gen failed (Exit 1)
INFO: Elapsed time: 1622.950s, Critical Path: 719.42s
INFO: 19283 processes: 19283 local.
FAILED: Build did NOT complete successfully
FAILED: Build did NOT complete successfully
```"
37522,Using @tf.function will turn the EagerTensor into Tensor,"This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.
"
37521,Add concatenated_categorical_column in feature column api.,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): TF 2.1
- Are you willing to contribute it (Yes/No): Yes. And the code change is ready.


**Describe the feature and the current behavior/state.**
*Feature:*
Add a new feature column api *concatenated_categorical_column* to concatenate SparseTensors from multiple categorical columns into one SparseTensor.
The id range of each categorical column is [0, num_buckets_0], [0, num_buckets_1] ... [0, num_buckets_n]. The ids will be conflict in the combined sparse id tensor because they all start from 0. In this api, we will add offset in sparse id tensor from each categorical column to avoid this conflict. After concatenation, the id range of the concatenated column is [0, num_bucket_0 + num_bucket_1 + ... + num_bucket_n].
The api definition is as follows
```python
tf.feature_column.concatenated_categorical_column(categorical_columns)

Args:
    categorical_columns: List of categorical columns created by a categorical_column_with_* function.
```

*Current Behavior:*
There is no feature column api to concatenate multiple categorical columns. Users cannot do this transformation with feature column.

*Why we need this api:*
A dataset sometimes contains many categorical features. If we map each categorical feature to an embedding vector separately, we need to create many variables for the embedding tables, one for each categorical feature. Besides the embedding table weights, there is additional overhead to create a variable. **As a result, the size of the model will be very huge if we create many embedding variables even though the size of each embedding table is small, and the performance of embedding lookup may be inefficient.**
![image](https://user-images.githubusercontent.com/18071380/74301254-795bac80-4d8d-11ea-98e3-2632e47df669.png)

In order to reduce the number of variables for the embedding table, we can concatenate the sparse id tensors from multiple categorical feature into a big sparse tensor, and also merge the embedding tables for each categorical feature into one table. However, the id of each categorical feature start from 0. And the same IDs will map to the same embedding vectors by looking up in the merged embedding table. In the following figure, we can see that embedding vectors of ""marital-status"" are the same as ""education"".
![image](https://user-images.githubusercontent.com/18071380/74301128-00f4eb80-4d8d-11ea-97eb-7db2e798ffb2.png)

So, we need to add an offset into IDs of ""marital-status"" so that the ""martial-status"" feature can get its embedding vectors by looking up in the merged embedding table. 
![image](https://user-images.githubusercontent.com/18071380/74301135-06eacc80-4d8d-11ea-9f2b-2a577ed52b0f.png)

**Will this change the current api? How?**
No, we won't change the existed Api. 
We will add a new feature column api *concatenated_categorical_column*.

**Who will benefit with this feature?**
The TensorFlow users who will develop the model with many categorical features and want to map these feature to embedding vectors.

**Any Other info.**
"
37516,Posenet Android Example. TestActivity crashes. Incorrect sample image size. comp:lite type: support,"**Describe the current behavior**
TestActivity Crashes. input image is wrong size. 

**Describe the expected behavior**

Line 209: Posenet.kt
getInterpreter().runForMultipleInputsOutputs(inputArray, outputMap)

inputArray has a direct byte buffer of size 1088659, 
Interpreter/model expects a TensorFlowLite buffer of 792588 bytes

The bitmap being used for this TestActivity is 560X353, while the size of the bitmap during the execution of CameraActivity is 257 x 257, which does correspond to the correct buffer size.   

Exception message:
Cannot convert between a TensorFlowLite buffer with 792588 bytes and a ByteBuffer with 1088652 bytes.

**Solution:**
choose a different sample image matching the constraint of producing a buffer of 792588 bytes, and change TestActivity:drawableToBitmap accordingly

For example, I know an image of 257 x 257 works (via CameraActivity), and then I change
Line 33 in TestActivity:drawableToBitmap to    
val bitmap = Bitmap.createBitmap(257, 257, Bitmap.Config.ARGB_8888)

Even better would be maintaining the ratio of the input image (rather than hardcoding 257 x 257) and fulfilling the constraint of proper number of bytes for the model. Then any image could be tested, while avoiding unappealing stretching and skewing. 
 

"
37515,Tensorflow 2.1 Error “when finalizing GeneratorDataset iterator” - a memory leak?,"**Reopening of issue [#35100](https://github.com/tensorflow/tensorflow/issues/35100),** as more and more people report to still have the same problem:

**Problem description**

I am using TensorFlow 2.1.0 for image classification under Centos Linux. As my image training data set is growing, I have to start using a Generator as I do not have enough RAM to hold all pictures. I have coded the Generator based on this tutorial.

It seems to work fine, until my program all the sudden gets killed without an error message:

```
Epoch 6/30
2020-03-08 13:28:11.361785: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled
43/43 [==============================] - 54s 1s/step - loss: 5.6839 - accuracy: 0.4669
Epoch 7/30
2020-03-08 13:29:05.511813: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled
 7/43 [===>..........................] - ETA: 1:04 - loss: 4.3953 - accuracy: 0.5268Killed
```

Looking at the growing memory consumption with linux's top, I suspect a memory leak?

**What I have tried**

- The suggestion to switch to TF nightly build version. For me it did not help, also downgrading to TF2.0.1 did not help

- There is a discussion suggesting that it is important, that 'steps_per_epoch' and 'batch size' correspond (whatever this exactly means) - I played with it without finding any improvement.

- Trying to narrow down by looking at the size development of all variables in my Generator

**Relevant code snippets**

```
class DataGenerator(tf.keras.utils.Sequence):
    'Generates data for Keras'
    def __init__(self, list_IDs, labels, dir, n_classes):
        'Initialization'
        config = configparser.ConfigParser()
        config.sections()
        config.read('config.ini')

        self.dim = (int(config['Basics']['PicHeight']),int(config['Basics']['PicWidth']))
        self.batch_size = int(config['HyperParameter']['batchsize'])
        self.labels = labels
        self.list_IDs = list_IDs
        self.dir = dir
        self.n_channels = 3
        self.n_classes = n_classes
        self.on_epoch_end()        


    def __len__(self):
        'Denotes the number of batches per epoch'
        return math.floor(len(self.list_IDs) / self.batch_size)

    def __getitem__(self, index):
        'Generate one batch of data'
        # Generate indexes of the batch
        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]

        # Find list of IDs
        list_IDs_temp = [self.list_IDs[k] for k in indexes]

        # Generate data
        X, y = self.__data_generation(list_IDs_temp)

        return X, y, [None]
```

being called by

```
        training_generator = datagenerator.DataGenerator(train_files, labels, dir, len(self.class_names))
        self.model.fit(x=training_generator,
                    use_multiprocessing=False,
                    workers=6, 
                    epochs=self._Epochs, 
                    steps_per_epoch = len(training_generator),
                    callbacks=[LoggingCallback(self.logger.debug)])
```

I have tried running the exact same code under Windows 10, which gives me the following error:

```
Epoch 9/30
2020-03-08 20:49:37.555692: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled
41/41 [==============================] - 75s 2s/step - loss: 2.0167 - accuracy: 0.3133
Epoch 10/30
2020-03-08 20:50:52.986306: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled
 1/41 [..............................] - ETA: 2:36 - loss: 1.6237 - accuracy: 0.39062020-03-08 20:50:57.689373: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at matmul_op.cc:480 : Resource exhausted: OOM when allocating tensor with shape[1279200,322] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
2020-03-08 20:50:57.766163: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Resource exhausted: OOM when allocating tensor with shape[1279200,322] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
         [[{{node MatMul_6}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

 2/41 [>.............................] - ETA: 2:02 - loss: 1.6237 - accuracy: 0.3906Traceback (most recent call last):
  File ""run.py"", line 83, in <module>
    main()
  File ""run.py"", line 70, in main
    accuracy, num_of_classes = train_Posture(unique_name)
  File ""run.py"", line 31, in train_Posture
    acc = neuro.train(picdb, train_ids, test_ids, ""Posture"")
  File ""A:\200307 3rd Try\neuro.py"", line 161, in train
    callbacks=[LoggingCallback(self.logger.debug)])
  File ""C:\Users\Frank\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\keras\engine\training.py"", line 819, in fit
    use_multiprocessing=use_multiprocessing)
  File ""C:\Users\Frank\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py"", line 342, in fit
    total_epochs=epochs)
  File ""C:\Users\Frank\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py"", line 128, in run_one_epoch
    batch_outs = execution_function(iterator)
  File ""C:\Users\Frank\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\keras\engine\training_v2_utils.py"", line 98, in execution_function
    distributed_function(input_fn))
  File ""C:\Users\Frank\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\eager\def_function.py"", line 568, in __call__
    result = self._call(*args, **kwds)
  File ""C:\Users\Frank\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\eager\def_function.py"", line 599, in _call
    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
  File ""C:\Users\Frank\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\eager\function.py"", line 2363, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File ""C:\Users\Frank\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\eager\function.py"", line 1611, in _filtered_call
    self.captured_inputs)
  File ""C:\Users\Frank\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\eager\function.py"", line 1692, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""C:\Users\Frank\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\eager\function.py"", line 545, in call
    ctx=ctx)
  File ""C:\Users\Frank\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\eager\execute.py"", line 67, in quick_execute
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.ResourceExhaustedError:  OOM when allocating tensor with shape[1279200,322] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
         [[node MatMul_6 (defined at A:\200307 3rd Try\neuro.py:161) ]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
 [Op:__inference_distributed_function_764]

Function call stack:
distributed_function

2020-03-08 20:51:00.785175: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled
```"
37513,"""Segmentation fault"" on Amazon deep learning AMI, gpu-compute instance","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): No
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04):  Deep Learning AMI (Amazon Linux) Version 27.0 (ami-0e2a8509db267f072)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): source activate tensorflow2_p36 on AMI
- Python version: - Bazel 3.6
version (if compiling from source):
- GCC/Compiler version (if compiling from
source):  None
- CUDA/cuDNN version: - GPU model and memory:
p3.2xlarge AWS instance.  NVIDIA Tesla V100 15gb. 10.1 cuda, 7.6 cudnn

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

model.fit() just stops randomly with ""segmentation fault"" no other info

**Describe the expected behavior**

No errors or at least more debugging info

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
37512,"InaccessibleTensorError when appending to list, while looping.","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: N/A
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): binary
- Python version: - Bazel
version (if compiling from source): 2.7.15
- GCC/Compiler version (if compiling from
source): 
- CUDA/cuDNN version: - GPU model and memory:  N/A

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I get an `InaccessibleTensorError` when looping over a tensor and appending to a python list, only sometimes. 





**Describe the expected behavior**

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
######################
[codalab link](https://colab.research.google.com/drive/1dMyCJnC9iPieSLEiPgXKWiJhJHftqLtQ)
#######################

Python script:
The error happens at the line `my_list.append(new_vals)`.
```
from __future__ import absolute_import, division, print_function
import tensorflow as tf


def list_each_row_times_two(OG_values):
    my_list = []
    for old_vals in OG_values:
        new_vals = tf.math.multiply(old_vals, 2)
        my_list.append(new_vals) #Fails here
        #tf.print(new_vals) #replace above line with this, it works
    return my_list


if __name__ == '__main__':

    test_func = tf.function(list_each_row_times_two)
    ##########################################
    ########      This works!!   #############
    ##########################################
    _OG_values = []
    for _ in range(3):
        _OG_values.append(tf.random.uniform((2,)))
    new_values = test_func(_OG_values)
    print('We did it!')
    ##########################################
    ########     !!!! DOES NOT WORK!!    #####
    ##########################################
    OG_values = tf.random.uniform((3, 2))
    new_values = test_func(OG_values)
    print('We did it! again!')

```


**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

```
We did it!
Traceback (most recent call last):
  File ""unkown_looping_bug.py"", line 30, in <module>
    new_values = test_func(OG_values)
  File ""/home/philip/ros_ws/src/real_world/venv/local/lib/python2.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 568, in __call__
    result = self._call(*args, **kwds)
  File ""/home/philip/ros_ws/src/real_world/venv/local/lib/python2.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 606, in _call
    results = self._stateful_fn(*args, **kwds)
  File ""/home/philip/ros_ws/src/real_world/venv/local/lib/python2.7/site-packages/tensorflow_core/python/eager/function.py"", line 2362, in __call__
    graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
  File ""/home/philip/ros_ws/src/real_world/venv/local/lib/python2.7/site-packages/tensorflow_core/python/eager/function.py"", line 2703, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/home/philip/ros_ws/src/real_world/venv/local/lib/python2.7/site-packages/tensorflow_core/python/eager/function.py"", line 2593, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/home/philip/ros_ws/src/real_world/venv/local/lib/python2.7/site-packages/tensorflow_core/python/framework/func_graph.py"", line 983, in func_graph_from_py_func
    expand_composites=True)
  File ""/home/philip/ros_ws/src/real_world/venv/local/lib/python2.7/site-packages/tensorflow_core/python/util/nest.py"", line 568, in map_structure
    structure[0], [func(*x) for x in entries],
  File ""/home/philip/ros_ws/src/real_world/venv/local/lib/python2.7/site-packages/tensorflow_core/python/framework/func_graph.py"", line 945, in convert
    x = deps_ctx.mark_as_return(x)
  File ""/home/philip/ros_ws/src/real_world/venv/local/lib/python2.7/site-packages/tensorflow_core/python/framework/auto_control_deps.py"", line 167, in mark_as_return
    tensor = array_ops.identity(tensor)
  File ""/home/philip/ros_ws/src/real_world/venv/local/lib/python2.7/site-packages/tensorflow_core/python/util/dispatch.py"", line 180, in wrapper
    return target(*args, **kwargs)
  File ""/home/philip/ros_ws/src/real_world/venv/local/lib/python2.7/site-packages/tensorflow_core/python/ops/array_ops.py"", line 267, in identity
    ret = gen_array_ops.identity(input, name=name)
  File ""/home/philip/ros_ws/src/real_world/venv/local/lib/python2.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py"", line 3829, in identity
    ""Identity"", input=input, name=name)
  File ""/home/philip/ros_ws/src/real_world/venv/local/lib/python2.7/site-packages/tensorflow_core/python/framework/op_def_library.py"", line 742, in _apply_op_helper
    attrs=attr_protos, op_def=op_def)
  File ""/home/philip/ros_ws/src/real_world/venv/local/lib/python2.7/site-packages/tensorflow_core/python/framework/func_graph.py"", line 591, in _create_op_internal
    inp = self.capture(inp)
  File ""/home/philip/ros_ws/src/real_world/venv/local/lib/python2.7/site-packages/tensorflow_core/python/framework/func_graph.py"", line 641, in capture
    % (tensor, tensor.graph, self))
tensorflow.python.framework.errors_impl.InaccessibleTensorError: The tensor 'Tensor(""Mul:0"", shape=(2,), dtype=float32)' cannot be accessed here: it is defined in another function or code block. Use return values, explicit Python locals or TensorFlow collections to access it. Defined in: FuncGraph(name=while_body_56, id=139762147406480); accessed from: FuncGraph(name=list_each_row_times_two, id=139762146659984).
```
"
37511,Error retrieving regularization losses after adding them to a pretrained model.,"It appears that adding regularization losses to a pre-trained model results in some issue which leads to an error when retrieving the losses. I am having this problem with the TensorFlow 2.2.  Its git version is `v1.12.1-26428-gcb73044`.

The reproducible code is shown below:

```
import tensorflow as tf

class Model(tf.keras.Model):
    def __init__(self):
        super(Model, self).__init__()
        self._model = tf.keras.applications.ResNet101(include_top=False, weights='imagenet')

    def build(self, input_shape=None):
        for layer in self._model.layers:
            if type(layer) == tf.keras.layers.Conv2D:
                layer.add_loss( lambda : tf.keras.regularizers.l2(1e-5)(layer.kernel))

    def call(self, x):
        return self._net(x)


if __name__ == ""__main__"":
    m = Model()
    x = tf.random.uniform(shape=(1,3,512,512))
   m.build()
   print(m.losses)
```
   

The error message is -

 `AttributeError: 'Activation' object has no attribute 'kernel'`

    
"
37510,tf.config.experimental.list_physical_devices('GPU') stopped listing my gpu after update from 2.0.1 to 2.1.0,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): 
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): 
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): 
- Python version: - Bazel
version (if compiling from source):
- GCC/Compiler version (if compiling from
source): 
- CUDA/cuDNN version: - GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I'm using the following lines to set allow growth on TF 2.0 like I used to with tf.config and sessions on TF1:
```python
physical_devices = tf.config.experimental.list_physical_devices('GPU')
assert len(physical_devices) > 0, ""Not enough GPU hardware devices available""
tf.config.experimental.set_memory_growth(physical_devices[0], True)
```
I've updated from 2.0.1 to 2.1.0 (via `pip install`) and suddenly `tf.config.experimental.list_physical_devices('GPU')` stopped listing my GPU as an available device.

**Describe the expected behavior**
When downgrading to 2.0.1 (again via `pip install`) everything works again.

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```python
import tensorflow as tf

physical_devices = tf.config.experimental.list_physical_devices('GPU')
assert len(physical_devices) > 0, ""Not enough GPU hardware devices available""
tf.config.experimental.set_memory_growth(physical_devices[0], True)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
37509,Roadmap link is broken.,"

## URL(s) with the issue:
README.md  Resources's roadmap link is broken.
https://www.tensorflow.org/community/roadmap

## Description of issue (what needs changing):
It is occurred Page not found errer.

"
37508,[TF2.0] How to save model just keep recent 5 models by using keras?,"in eager mode, we can use `CheckpointManager` to save recent 5 models.
```
manager = tf.train.CheckpointManager(checkpoint, directory='./save', checkpoint_name='model.ckpt', max_to_keep=5)
```
but how to save model just keep recent 5 models by using kears? 
( model.complie() , model.fit(), callbacks )"
37506,Tensorflow hexagon tflite benchmark fails with quantized mobilenetv2,"
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.4 LTS
- TensorFlow installed from (source or binary): Source
- TensorFlow version:  Build from: git clone --recurse-submodules https://github.com/tensorflow/tensorflow.git
- Python version: 3.6.9
- Bazel version (if compiling from source): 2.0.0
- GCC/Compiler version (if compiling from source):gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0
- Device: Redmi Note 7 Pro (Hexagon 685 DSP),  Android 10.0; MIUI 11

**Describe the current behavior**
When i try to run the official **quantized mobilenet v2 model** in tflite benchmark  using **hexagon** delegate, it fails with the following error:-

> adb shell /data/local/tmp/benchmark_model_tf15 --graph=/data/local/tmp/mobilenet_v2_1.0_224_quant.tflite --enable_op_profiling=true --use_hexagon=true
> adb: /opt/intel/intelpython27/lib/libcrypto.so.1.0.0: no version information available (required by adb)
> STARTING!
> Min num runs: [50]
> Min runs duration (seconds): [1]
> Max runs duration (seconds): [150]
> Inter-run delay (seconds): [-1]
> Num threads: [1]
> Benchmark name: []
> Output prefix: []
> Min warmup runs: [1]
> Min warmup runs duration (seconds): [0.5]
> Graph: [/data/local/tmp/mobilenet_v2_1.0_224_quant.tflite]
> Input layers: []
> Input shapes: []
> Input value ranges: []
> Use legacy nnapi : [0]
> Allow fp16 : [0]
> Require full delegation : [0]
> Enable op profiling: [1]
> Max profiling buffer entries: [1024]
> CSV File to export profiling data to: []
> Use gpu : [0]
> Allow lower precision in gpu : [1]
> Use Hexagon : [1]
> Hexagon lib path : [/data/local/tmp]
> Hexagon Profiling : [0]
> Use nnapi : [0]
> Use xnnpack : [0]
> Loaded model /data/local/tmp/mobilenet_v2_1.0_224_quant.tflite
> INFO: Initialized TensorFlow Lite runtime.
> loaded libcdsprpc.so
> INFO: Created TensorFlow Lite delegate for Hexagon.
> INFO: Hexagon delegate: 65 nodes delegated out of 65 nodes.
> 
> ----------------
> Timestamp: Wed Mar 11 12:45:53 2020
> 
> 
> Log
> hexagon/src/newnode.c:413:node 2 (Quantize_int32_ref): bad input count 12
> hexagon/src/newnode.c:763:node id=0x2 ctor fail
> 
> ----------------
> ERROR: Failed: Failed to prepare graph.
> . STATE: FAILED_TO_PREPARE_GRAPH
> **ERROR: Node number 65 (TfLiteHexagonDelegate) failed to prepare.**
> 
> ERROR: Restored previous execution plan after delegate application failure.
> Failed to apply Hexagon delegate.
> Benchmarking failed.

All the '.so' files were initially copied to path: /data/local/tmp on device and the delegate was successfully created. I tried adding 'use_nnapi'= true along with use_hexagon option ; but it does not make any difference. 

I followed the instruction to build the hexagon delegate and libraries from the official documentation

> bazel build --config=android_arm64 \
>   tensorflow/lite/experimental/delegates/hexagon/hexagon_nn:libhexagon_interface.so
> adb push bazel-bin/tensorflow/lite/experimental/delegates/hexagon/hexagon_nn/libhexagon_interface.so /data/local/tmp
> adb push libhexagon_nn_skel*.so /data/local/tmp
(32 bit version gave an error, so i used arm64)

Hexagon library: [v1.14](https://storage.cloud.google.com/download.tensorflow.org/tflite/hexagon_nn_skel_v1.14.run)
Model:[ mobilenet_v2_1.0_224_quant](https://storage.googleapis.com/download.tensorflow.org/models/tflite_11_05_08/mobilenet_v2_1.0_224_quant.tgz)

Also does the hexagon model execute a tflite generated by **post-training quantization(full INT8)** ?

When  i tried another  **custom quantized** model(post-training quantization) with int8 inputs and outputs, it shows :  **INFO: Hexagon delegate: 0 nodes delegated out of 158 nodes.**  and seems to fall back to CPU.

**Describe the expected behavior**
The benchmark model should run the quantized model without any problems.

**Other info / logs**
Android NDK: 20, Benchmark tool built from latest source with bazel 2.0

Here are the two models that i have tried to benchmark and the corresponding benchmark library files:-
[hexfiles.zip](https://github.com/tensorflow/tensorflow/files/4317362/hexfiles.zip)
"
37505,Memory leak in model.fit,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): 
minimal working example

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 
windows-server 2016
- TensorFlow installed from (source or binary): 
conda
- TensorFlow version (use command below): 
tf 2.1.0
- Python version: 
3.7
- CUDA/cuDNN version: 
CUDA 10.1
- GPU model and memory:
K80 - 24Gb

**Describe the current behavior**
memory use increases with consecutive training runs, probably related to #35524, #33030, #35124, #35835
side note: I do not understand the warning but this seems to be handled in #37500
**Describe the expected behavior**
memory should stay constant

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```
from tensorflow.keras.datasets import cifar10
import tensorflow.keras.callbacks as callbacks
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import LearningRateScheduler
from tensorflow.keras.optimizers import SGD
from tensorflow.keras.layers import Input, Conv2D, GlobalAveragePooling2D, Activation, Dense
from tensorflow.keras.models import Model
import tensorflow.keras.utils as kutils
import numpy as np
import psutil
import gc 


batch_size = 128
epochs = 5
num_classes = 10


def buildmodel():
    img_input = Input(shape=(32, 32, 3))

    x = Conv2D(16, (3, 3), padding='same')(img_input)
    x = Activation(""relu"")(x)
    x = Conv2D(16, (3, 3), padding='same')(x)
    x = Activation(""relu"")(x)
    x = GlobalAveragePooling2D()(x)
    prediction = Dense(num_classes,activation='softmax', name = 'classifier') (x)  
    model = Model(inputs=img_input, outputs=prediction)
    return model

(trainX, trainY), (testX, testY) = cifar10.load_data()
mean = np.mean(trainX, axis=0)
std = np.std(trainX)

trainX = trainX.astype('float32')
trainX = (trainX - mean) / std
testX = testX.astype('float32')
testX = (testX - mean) / std

trainY = kutils.to_categorical(trainY)
testY = kutils.to_categorical(testY)

generator = ImageDataGenerator()
generator.fit(trainX)
val_generator = ImageDataGenerator()

for i in range(10):
    tf.keras.backend.clear_session()
    model = buildmodel()
    sgd = SGD(lr=0.1, momentum=0.9, nesterov=True)
    model.compile(loss=""categorical_crossentropy"", optimizer=sgd, metrics=[""acc""])
    model.fit(generator.flow(trainX, trainY, batch_size=batch_size), epochs=epochs, validation_data=val_generator.flow(testX, testY, batch_size = batch_size),verbose=0, workers = 20)
    print('memory usesd: ' + str(psutil.virtual_memory().used // 1e6))
    gc.collect()
```

output:
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
memory usesd: 38012.0
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
memory usesd: 38563.0
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
memory usesd: 39288.0
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
memory usesd: 40005.0
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
memory usesd: 40730.0
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
memory usesd: 41490.0
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
memory usesd: 42216.0
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
memory usesd: 42937.0
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
memory usesd: 43659.0
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
memory usesd: 44403.0


"
37504,Fit under TPU strategy fails on cardinality,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Ran on colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: /
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): 2.1.0 (Colab)
- Python version: - 3.6.9
version (if compiling from source): /
- GCC/Compiler version (if compiling from
source): /
- CUDA/cuDNN version: - GPU model and memory: Using the TPU runtime

When running the `fit` function on a model after compiling the model with the TPUStrategy as in [this post on the colab github](https://github.com/googlecolab/colabtools/issues/1056) the cardinality is implicitely calculated.
A TFRecordDataset is used as Dataset for the fit function. 
The error below is raised:

```
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-7-db3ea26a4a48> in <module>()
----> 1 mh.start_training()

8 frames
/content/modelling/NN/ModelHandler.py in start_training(self)
     73                 steps_per_epoch=self.dataloaders[0].amount_of_batches,
     74                 validation_steps=self.dataloaders[1].amount_of_batches,
---> 75                 verbose=1
     76                 )
     77 

/content/modelling/NN/Model.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    312                              validation_steps=validation_steps, validation_freq=validation_freq,
    313                              max_queue_size=max_queue_size, workers=workers,
--> 314                              use_multiprocessing=use_multiprocessing, **kwargs)
    315         return out
    316 

/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    817         max_queue_size=max_queue_size,
    818         workers=workers,
--> 819         use_multiprocessing=use_multiprocessing)
    820 
    821   def evaluate(self,

/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    258           steps_per_epoch,
    259           steps_name='steps_per_epoch',
--> 260           epochs=0)
    261 
    262       steps_per_epoch = (

/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_utils.py in infer_steps_for_dataset(model, dataset, steps, epochs, steps_name)
   1747     return None
   1748 
-> 1749   size = K.get_value(cardinality.cardinality(dataset))
   1750   if size == cardinality.INFINITE and steps is None:
   1751     raise ValueError('When passing an infinitely repeating dataset, you '

/tensorflow-2.1.0/python3.6/tensorflow_core/python/data/experimental/ops/cardinality.py in cardinality(dataset)
     49   """"""
     50 
---> 51   return ged_ops.dataset_cardinality(dataset._variant_tensor)  # pylint: disable=protected-access

/tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/gen_experimental_dataset_ops.py in dataset_cardinality(input_dataset, name)
    663         pass  # Add nodes to the TensorFlow graph.
    664     except _core._NotOkStatusException as e:
--> 665       _ops.raise_from_not_ok_status(e, name)
    666   # Add nodes to the TensorFlow graph.
    667   _, _, _op, _outputs = _op_def_library._apply_op_helper(

/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/ops.py in raise_from_not_ok_status(e, name)
   6604   message = e.message + ("" name: "" + name if name is not None else """")
   6605   # pylint: disable=protected-access
-> 6606   six.raise_from(core._status_to_exception(e.code, message), None)
   6607   # pylint: enable=protected-access
   6608 

/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)

InvalidArgumentError: Unable to parse tensor proto [Op:DatasetCardinality]
```

When calculating the cardinality without calling the TPUStrategy context as shown below, a value of `-2` is yielded:
```
import tensorflow.keras.backend as K
K.get_value(tf.data.experimental.cardinality(ds))
```

"
37501,WARNING:tensorflow:Gradients do not exist for variables,"While training BERT on TPU i am getting these warnings and my precision and recall is zero while accuracy is 100

```
Train for 45205 steps, validate for 206 steps
WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.
WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.
WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.
WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.

```

Here is google colab file i am using
https://colab.research.google.com/drive/1l0Eoram6vJRK5xQBmnCx-eU1e46higlo

updated colab file
https://colab.research.google.com/drive/1D-eKgddRHROG39R2iyqE3qR7w0N0OHAB"
37500,"""WARNING:tensorflow:sample_weight ..."" when training a `keras.Model` with a `Sequence` object","
**System information** 
- OS Platform and Distribution: macOS 10.14.5
- Python version: 3.6

**Describe the current behavior**

Calling `tf.keras.Model.fit(...)` with any `tf.keras.utils.Sequence` object triggers the following warning:

```
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
```

Even when not using `sample_weight`.

**Describe the expected behavior**

Training keras models without sample weights specified or correctly specified should not trigger warnings about  `sample_weight`.

**Standalone code to reproduce the issue** 
```
import tensorflow as tf
import numpy as np


class TestSequence(tf.keras.utils.Sequence):

    def __init__(self, x, y, batch_size):
        self.x, self.y = x, y
        self.batch_size = batch_size

    def __len__(self):
        return len(self.x) // self.batch_size

    def __getitem__(self, idx):
        batch_x = self.x[idx * self.batch_size:(idx + 1) *
        self.batch_size]
        batch_y = self.y[idx * self.batch_size:(idx + 1) *
        self.batch_size]

        return batch_x, batch_y
    

seq = TestSequence(np.ones(10), np.ones(10), 2)

x_in = tf.keras.layers.Input((1,))
x_out = tf.keras.layers.Dense(1)(x_in)
model = tf.keras.Model(x_in, x_out)
model.compile(loss='binary_crossentropy', optimizer='adam')
model.fit(seq)
```
"
37498,Master branch failed to build the debug version,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Centos7.6
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source 
- TensorFlow version: master, commit-id: b45adaf6efeeb8e4acf8517a01f7dc01bdf21db9
- Python version: 3.6
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source): bazel 2.0.0
- GCC/Compiler version (if compiling from source): 8.3



**Describe the problem**
The debug version build failed with the command:
```
bazel build -c dbg //tensorflow/tools/pip_package:build_pip_package
```
Error:
```
external/aws-checksums/source/intel/crc32c_sse42_asm.c: In function 's_crc32c_sse42_clmul_256':
external/aws-checksums/source/intel/crc32c_sse42_asm.c:61:5: error: 'asm' operand has impossible constraints
     asm volatile(""enter_256_%=:""
     ^~~
Target //tensorflow/tools/pip_package:build_pip_package failed to build
```

"
37497,Confusing behavior of GRUCell,"```python
cell = layers.GRUCell(4)
x = tf.random.normal((2, 2, 3))
print(cell.get_initial_state(x)) # returns a single tensor
cell(x[:, 0], [cell.get_initial_state(x)]) # requires and returns a list of tensors
```
Why would `GRUCell.get_initial_state` return a Tensor, while calling `GRUCell` requires a list of Tensor as input? Is this a desired behavior? (code tested in TF2.1)

Furthermore, while `Cell` returns output and state separately, RNN returns the output and states together in a single list.

```python
cell = layers.LSTMCell(4)
x = tf.random.normal((2, 2, 3))
s = cell.get_initial_state(x)
cell_output, state = cell(inputs=x[:, 1], states=s)# works fine
print(cell_output)
print(state)
rnn = layers.RNN(cell, return_state=True, return_sequences=True)
rnn_output, state = rnn(x, initial_state=s)# error: rnn returns the output and states in a single list
```

I'm wondering why `rnn` and `cell` behave differently?"
37496,C-API timeline for TensorFlow 2,"On the Install TensorFlow for C page, it notes that 
 ""There is no libtensorflow support for TensorFlow 2 yet. It is expected in a future release.""

Is there any update on when we can expect the c api for TF2?"
37495,Custom Pearson Correlation Loss Taking Unfeasible Values During Training,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): **Yes**
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): **Windows 10**
- TensorFlow installed from (source or
binary): **Source**
- TensorFlow version (use command below): **TensorFlow 2.1.0**
- Python version: **Python 3.6.10 (Anaconda Distribution)**
- CUDA/cuDNN version: **CUDA 10.1; cuDNN 7.6.5 (Nov 5, 2019)**
- GPU model and memory: **NVIDIA GeForce RTX 2070;  8GB VRAM**

**Describe the current behavior**
Loss values for a custom loss function that computes sample correlations takes on unfeasible values (i.e. 14-15) with certain model architectures; i.e. if hidden layers are too wide.

**Describe the expected behavior**
The correlation function's implementation should bound it to within [-1,1], and the custom loss function takes the negative absolute so it should be within [-1,0].

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```
import tensorflow as tf
from tensorflow.keras import regularizers
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.initializers import he_normal
import tensorflow_probability as tfp

# Data
np.random.seed(42)
data_X = np.random.random_sample((100,6))
data_Y = np.random.random_sample((100,1))

# Feed-forward NN
model = Sequential()

# Input Layer
model.add(Dense(6, activation='linear', input_shape=(6,)))

# Hidden Layers: Arbitrarily wide
model.add(Dense(5000, 
                activation='relu', 
                kernel_initializer=he_normal(), 
                kernel_regularizer=regularizers.l1(10**-3)
                ))
model.add(Dropout(0.3))

# Output Layer; Regression
model.add(Dense(1, activation='sigmoid'))

# Custom Loss Function
def MaxCorrelation(y_true,y_pred):
    """"""
    Goal is to maximize correlation between y_pred, y_true. Same as minimizing the negative.
    """"""
    return -tf.math.abs(tfp.stats.correlation(y_pred,y_true, sample_axis=None, event_axis=None))

# Compilation
model.compile(
            optimizer='adam', 
            loss= MaxCorrelation,
)

# Train the model
history = model.fit(data_X, data_Y,
          epochs=5,
          batch_size = 32,
          verbose=1,
         )
```
**Other info / logs** 
```
OUT: Train on 100 samples
Epoch 1/5
100/100 [==============================] - 0s 2ms/sample - loss: 14.1344
Epoch 2/5
100/100 [==============================] - 0s 90us/sample - loss: 14.0880
Epoch 3/5
100/100 [==============================] - 0s 90us/sample - loss: 13.9630
```

Testing the loss function manually seems to work as intended:
```
import tensorflow.keras.backend as K
Y_Pred = model.predict(data_X).astype(float)
K.eval(MaxCorrelation(data_Y, Y_Pred))
--
OUT: -0.137205319813903
```

My understanding is that for each `batch_size=32`, the model returns 32 samples of scalar values from the output layer which is squashed between (0,1) and the loss MaxCorrelation is evaluated on the 32 predictions vs 32 targets. Thus the losses should still be within the bounds unless some aggregation is happening per epoch (i.e. one of the batch losses tending to infinity?), but even when removing the negative sign the loss is still positive. This issue only seems to persist when the hidden layers are wide/deep enough.

I have also tried replacing the loss function with some of the backend implementations [here](https://stackoverflow.com/questions/46619869/how-to-specify-the-correlation-coefficient-as-the-loss-function-in-keras?rq=1), but similar results."
37494,Importing tensorflow just after installation,"(base) C:\Users\rafra>python -c ""import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))""
Traceback (most recent call last):
  File ""C:\Users\rafra\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\rafra\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\rafra\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\rafra\Anaconda3\lib\imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\rafra\Anaconda3\lib\imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""C:\Users\rafra\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""C:\Users\rafra\Anaconda3\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\rafra\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\rafra\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\rafra\Anaconda3\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\rafra\Anaconda3\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\rafra\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\rafra\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\rafra\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\rafra\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\rafra\Anaconda3\lib\imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\rafra\Anaconda3\lib\imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.
"
37492,"tf.linalg.diag doesn't use ""k"" value","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): no
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): ubuntu 16.04
- TensorFlow installed from (source or
binary): binary
- TensorFlow version (use command below): 2.1.0
- Python version: 3.6
- CUDA/cuDNN version: N/A cpu
- GPU model and memory: N/A cpu

**Describe the current behavior**
```
import tensorflow as tf
import numpy as np
diagonal = np.array([[1, 2, 3],  
                     [4, 5, 6]])
tf.linalg.diag(diagonal, k = 1)
```

responds with

```
<tf.Tensor: shape=(2, 3, 3), dtype=int64, numpy=
array([[[1, 0, 0],
        [0, 2, 0],
        [0, 0, 3]],

       [[4, 0, 0],
        [0, 5, 0],
        [0, 0, 6]]])>
```

**Describe the expected behavior**

According to the docs, it should give me

```
[[[0, 1, 0, 0],  # Output shape: (2, 4, 4)
        [0, 0, 2, 0],
        [0, 0, 0, 3],
        [0, 0, 0, 0]],
       [[0, 4, 0, 0],
        [0, 0, 5, 0],
        [0, 0, 0, 6],
        [0, 0, 0, 0]]]
```

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

https://colab.research.google.com/drive/1Hj6Sks-m_V0gqw6SK9eowpRpIhOlHYXk

This notebook shows that, in fact, the `k` argument appears to be ignored completely.  

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
37488,tf.numpy_function with lambda function is much slower starting from TF 1.15,"**System information** 
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **yes**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Linux Ubuntu 18.04 (our machine), and also COLAB.**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **No**
- TensorFlow installed from (source or binary): **binary**
- TensorFlow version (use command below): **1.14 vs 1.15.2 vs 2.1.0**
- Python version: **3.6.9**
- Bazel version (if compiling from source): **nope**
- GCC/Compiler version (if compiling from source): **nope**
- CUDA/cuDNN version: **10.1 / 7.6.2**
- GPU model and memory: **V100 (our machine) and T4 in COLAB. But the issue is on the CPU side**

**Describe the current behavior**
When using `tf.numpy_function` (or `tf.compat.v1.py_func`) in combination with a lambda function (in order to pass some fixed, non-tensor parameters to it), performance decreased massively from 1.14 to 1.15 onwards. (depending on the problem and the hardware, in my tests between 2x and 8x; the provided code is about 2x slower on a Colab T4 instance, and 4x slower on a V100 machine; some other much more involved code got slowed down up to 8x; but that's mainly because with slower GPUs, the bottleneck may lie elsewhere; I haven't done specific tests using one line only)

**Describe the expected behavior**
The invoked function being quite literally the same, the time should be also virtually identical. And more generally, code shouldn't get slower with a new code version...

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate the problem. If possible, please share a link to Colab/Jupyter/any notebook.

Link to Colab: https://colab.research.google.com/drive/1MZVOBlAY7piqgeKwGzA8goeU3xtPy5gp

The code above runs a full ""training"" pipeline using a keras model, estimators framework, and data generation via numpy_function. All data is created randomly, so the model won't learn anything of course. The main difference is between the line:

`tf.numpy_function(a_slow_numpy_function, [tensor, [x1, y1, x2, y2]], tf.float32)`

and the line

`tf.numpy_function(lambda ex: a_slow_numpy_function(ex, [x1, y1, x2, y2]), [tensor], tf.float32`

Here, tensor is... a tensor, while x1, y1, x2, y2 are integers. Therefore, both lines are valid, in the first one the list is implicitly converted to a tensor (and then to a numpy array), in the second one a temporary function has those parameters as fixed.

Until TF 1.14 both lines produced the same runtime, from TF 1.15 on the second one gets much slower (the first one stays the same).

However, unfortunately I wasn't able to obtain reproducible results by only invoking the line above in a standalone session.

**Other info / logs** 

Logs on the Colab T4 can be seen from the link (for all TF versions 1.14, 1.15, 2.1). The following logs were obtained on our V100 machine:

**TF 1.14, no lambda:**
INFO:tensorflow:loss = 0.2136189, step = 0
INFO:tensorflow:global_step/sec: 32.7136
INFO:tensorflow:loss = 0.03677105, step = 100 (3.057 sec)
INFO:tensorflow:global_step/sec: 38.7334
INFO:tensorflow:loss = 0.038587682, step = 200 (2.581 sec)
INFO:tensorflow:global_step/sec: 38.3866
INFO:tensorflow:loss = 0.037003815, step = 300 (2.605 sec)
INFO:tensorflow:global_step/sec: 38.1023
INFO:tensorflow:loss = 0.037481233, step = 400 (2.625 sec)
INFO:tensorflow:global_step/sec: 27.7657
INFO:tensorflow:loss = 0.03703531, step = 500 (3.602 sec)
INFO:tensorflow:global_step/sec: 38.0632
INFO:tensorflow:loss = 0.03458761, step = 600 (2.627 sec)
INFO:tensorflow:global_step/sec: 36.4805
INFO:tensorflow:loss = 0.03637625, step = 700 (2.741 sec)
INFO:tensorflow:global_step/sec: 35.7584
INFO:tensorflow:loss = 0.036259696, step = 800 (2.797 sec)
INFO:tensorflow:global_step/sec: 36.7052
INFO:tensorflow:loss = 0.036455855, step = 900 (2.725 sec)

**TF 1.14, with lambda:**
INFO:tensorflow:loss = 0.23772891, step = 0
INFO:tensorflow:global_step/sec: 32.9305
INFO:tensorflow:loss = 0.03767074, step = 100 (3.037 sec)
INFO:tensorflow:global_step/sec: 37.3223
INFO:tensorflow:loss = 0.03685203, step = 200 (2.679 sec)
INFO:tensorflow:global_step/sec: 36.7882
INFO:tensorflow:loss = 0.038278855, step = 300 (2.718 sec)
INFO:tensorflow:global_step/sec: 37.7637
INFO:tensorflow:loss = 0.03842716, step = 400 (2.648 sec)
INFO:tensorflow:global_step/sec: 27.7136
INFO:tensorflow:loss = 0.036828667, step = 500 (3.608 sec)
INFO:tensorflow:global_step/sec: 35.5345
INFO:tensorflow:loss = 0.03633987, step = 600 (2.814 sec)
INFO:tensorflow:global_step/sec: 37.1818
INFO:tensorflow:loss = 0.037201233, step = 700 (2.690 sec)
INFO:tensorflow:global_step/sec: 37.2266
INFO:tensorflow:loss = 0.036516882, step = 800 (2.686 sec)
INFO:tensorflow:global_step/sec: 38.3496
INFO:tensorflow:loss = 0.039767925, step = 900 (2.608 sec)

**TF 1.15, no lambda:**
INFO:tensorflow:loss = 0.25934136, step = 0
INFO:tensorflow:global_step/sec: 34.4488
INFO:tensorflow:loss = 0.037474792, step = 100 (2.903 sec)
INFO:tensorflow:global_step/sec: 37.6249
INFO:tensorflow:loss = 0.037868354, step = 200 (2.658 sec)
INFO:tensorflow:global_step/sec: 38.2594
INFO:tensorflow:loss = 0.0373457, step = 300 (2.614 sec)
INFO:tensorflow:global_step/sec: 39.2323
INFO:tensorflow:loss = 0.036336176, step = 400 (2.549 sec)
INFO:tensorflow:global_step/sec: 26.6403
INFO:tensorflow:loss = 0.035495166, step = 500 (3.754 sec)
INFO:tensorflow:global_step/sec: 37.6238
INFO:tensorflow:loss = 0.038571935, step = 600 (2.658 sec)
INFO:tensorflow:global_step/sec: 37.4171
INFO:tensorflow:loss = 0.03556432, step = 700 (2.672 sec)
INFO:tensorflow:global_step/sec: 35.1526
INFO:tensorflow:loss = 0.035202924, step = 800 (2.845 sec)
INFO:tensorflow:global_step/sec: 35.4907
INFO:tensorflow:loss = 0.03740203, step = 900 (2.818 sec)
INFO:tensorflow:Loss for final step: 0.03607688.

**TF 1.15, with lambda:**
INFO:tensorflow:loss = 0.25370103, step = 0
INFO:tensorflow:global_step/sec: 8.59509
INFO:tensorflow:loss = 0.037242886, step = 100 (11.635 sec)
INFO:tensorflow:global_step/sec: 8.02817
INFO:tensorflow:loss = 0.03554675, step = 200 (12.456 sec)
INFO:tensorflow:global_step/sec: 12.4317
INFO:tensorflow:loss = 0.03646993, step = 300 (8.044 sec)
INFO:tensorflow:global_step/sec: 8.62791
INFO:tensorflow:loss = 0.035594724, step = 400 (11.590 sec)
INFO:tensorflow:global_step/sec: 8.80279
INFO:tensorflow:loss = 0.036044836, step = 500 (11.360 sec)
INFO:tensorflow:global_step/sec: 9.01617
INFO:tensorflow:loss = 0.036771618, step = 600 (11.091 sec)
INFO:tensorflow:global_step/sec: 9.50426
INFO:tensorflow:loss = 0.038547777, step = 700 (10.522 sec)
INFO:tensorflow:global_step/sec: 9.18885
INFO:tensorflow:loss = 0.03686235, step = 800 (10.883 sec)"
37485,AssertionError on using model.fit() in tf.distribute.MirroredStrategy,"**System information**
- OS Platform and Distribution: Ubuntu 18.04.4 LTS
- TensorFlow installed from (source or binary):
- TensorFlow version: 2.2.0-dev20200308
- Python version: 3.7.6
- Installed using virtualenv? pip? conda?: pip


**AssertionError on using model.fit() in tf.distribute.MirroredStrategy**

I'm trying to build an LSTM Autoencoder model to make time series prediction on a large dataset(~30 million rows in train data, 16 million rows each in valid and test data). I've followed the [tutorial](https://www.tensorflow.org/tutorials/distribute/keras) in the Tensorflow documentation to distribute my model across available GPUs using MirroredStrategy with HierarchicalCopyAllReduce as follows:

```
with strategy.scope():
    model = tf.keras.Sequential([
        tf.keras.layers.LSTM(32, activation = 'relu', input_shape = (timesteps, features), return_sequences = True),
        tf.keras.layers.LSTM(16, activation = 'relu', return_sequences = False),
        tf.keras.layers.RepeatVector(timesteps),
        tf.keras.layers.LSTM(16, activation = 'relu', return_sequences = True),
        tf.keras.layers.LSTM(32, activation = 'relu', return_sequences = True),
        tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(num_classes, activation = 'softmax'))
    ])

    model.compile(loss = tf.keras.losses.CategoricalCrossentropy(),
                  optimizer = tf.keras.optimizers.Adam(),
                  metrics = ['accuracy'])
```
When I try to fit the model using the following code, I get the following assertion error:

```
model.fit(X_train_tf, y_train_tf, epochs = 12, validation_data = (X_valid_tf, y_valid_tf), verbose = 1, callbacks=callbacks)

---------------------------------------------------------------------------
AssertionError                            Traceback (most recent call last)
<ipython-input-17-96b3da4e4eff> in <module>
----> 1 model.fit(X_train_tf, y_train_tf, epochs = 12, validation_data = (X_valid_tf, y_valid_tf), verbose = 1, callbacks=callbacks)

~/.conda/envs/user/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_v1.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    783         max_queue_size=max_queue_size,
    784         workers=workers,
--> 785         use_multiprocessing=use_multiprocessing)
    786 
    787   def evaluate(self,

~/.conda/envs/user/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_distributed.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)
    617         validation_split=validation_split,
    618         shuffle=shuffle,
--> 619         epochs=epochs)
    620     if not dist_utils.is_distributing_by_cloning(model):
    621       with model._distribution_strategy.scope():

~/.conda/envs/user/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_v1.py in _distribution_standardize_user_data(self, x, y, sample_weight, class_weight, batch_size, validation_split, shuffle, epochs, allow_partial_batch)
   2165         x = ds.batch(batch_size, drop_remainder=drop_remainder)
   2166       else:
-> 2167         assert isinstance(x, dataset_ops.DatasetV2)
   2168         training_utils.validate_dataset_input(x, y, sample_weight,
   2169                                               validation_split)

AssertionError:
```
How should I resolve this error? My train, test and validation data are of tensor type.

Thanks in advance!"
37484,58,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): 
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): 
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): 
- Python version: - Bazel
version (if compiling from source):
- GCC/Compiler version (if compiling from
source): 
- CUDA/cuDNN version: - GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
37482,Benchmark tool,"Is there available ""benchmarking tool"" for TensorFlow Lite for Microcontrollers? "
37480,'third_party/tensorflow/compiler/aot:codegen_test' No such directory found,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/aot/codegen_test.cc

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod

## Description of issue (what needs changing):
// To update the golden file, flip update_golden to true and run the
  // following:
  // bazel test --test_strategy=local \
  //   third_party/tensorflow/compiler/aot:codegen_test
### Clear description

Line 154

I wanted to update the golden file, but the given directory is not present in the third_party library.

For example, why should someone use this method? How is it useful?

### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

See the API guide: https://www.tensorflow.org/community/contribute/docs_ref
on how to write testable usage examples.

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
37479,Excessive memory consumption and preparation runtime of tf.keras.backend.max in custom layer with masking,"**System information**
- Have I written custom code: yes
- OS Platform and Distribution: Linux Ubuntu 18.04
- Mobile device if the issue happens on mobile device: -
- TensorFlow installed from: binary
- TensorFlow version: 2.2.0-dev20200303
- Python version: 3.6.9
- Bazel version: -
- GCC/Compiler version: -
- CUDA/cuDNN version: CPU only
- GPU model and memory: CPU only

**Describe the current behavior**
Memory consumption seems to be proportional to `num_iterations` and thus excessive, most likely being a memory leak. Runtime until seeing the first fit result is also extremely slow: 15 seconds until the first fit call, 55 seconds until seeing the result of the first fit, and the other fits run through in less than a second. Apparently, runtime is due to memory management and not due to the actual max function evaluation.

When using `tf.keras.backend.max` for computing a mask with `tf.stack` in a real setup, memory consumption increases steadily until running out of memory at approx. 30 GB. In contrast, without `compute_mask`, memory consumption doesn't go beyond approx 1 GB.

**Describe the expected behavior**
I would expect memory consumption to be independent of `num_iterations` and thus being much lower, plus preparation runtime being much lower.

**Code to reproduce the issue**
```python
import tensorflow as tf
import numpy as np


batch_size = 100
dim_input = 100
dim_output = 1
num_iterations = 100 # will consume approx. 5 GB RAM when set to 1000


class CustomMask(tf.keras.layers.Layer):
  def __init__(self):
    super(CustomMask, self).__init__()

  def compute_mask(self, inputs, mask=None):
    batch_size = inputs.shape[0]

    batch_maxes = tf.keras.backend.max(inputs, axis=1)

    for batch in range(batch_size):
      for i in range(num_iterations):
        max = tf.keras.backend.max(batch_maxes[batch])

    return None

  def call(self, inputs, mask=None):
    return inputs


model = tf.keras.Sequential()

model.add(tf.keras.layers.Input(batch_input_shape=(batch_size, dim_input)))

model.add(CustomMask())

model.add(tf.keras.layers.Dense(dim_output))

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

training_input = np.zeros([batch_size, dim_input])
training_output = np.zeros([batch_size, dim_output])

model.fit(training_input, training_output, batch_size=batch_size)
```

**Other info / logs**
If my usage of `tf.keras.backend.max` is wrong with regard to memory consumption and / or runtime, please let me know. I need to call it frequently within `compute_mask` for computing a custom mask in conjunction with `tf.stack`. However, the latter does not seem to be the problem, which is why I left it out in the stripped down code.
"
37478,Tensorflow Website not working properly in Firefox,"## Description of issue (what needs changing):
Tensorflow website UI doesn't seem right when opened in Firefox. I'm not sure if it's happening only in my case or not...

### Request visuals, if applicable
![Screenshot_2020-03-10 tf keras callbacks TensorBoard TensorFlow Core v2 1 0](https://user-images.githubusercontent.com/29497701/76317231-de111500-6301-11ea-8654-03cd0d29eeb9.png)
"
37477,Additional mode for loading of segmentation data in tf.keras.preprocessing.image.ImageDataGenerator.flow_from_dataframe(),"**System information**
- TensorFlow version (you are using): 2.1.0
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**

As of now, one has to come around with a workaround to load segmentation data in `tf.keras.preprocessing.image.ImageDataGenerator` to load images and segmentation masks in a generator. A current workaround could look like:
    
    datagen = tf.keras.preprocessing.image.ImageDataGenerator()
    
    df = pd.DataFrame({'images': images,
                       'masks': masks})
    # seed, so that image_generator and mask_generator will rotate and shuffle equivalently
    seed = 42
    image_generator = datagen.flow_from_dataframe(df, 
                                          directory='.', 
                                          x_col='images', 
                                          y_col='masks', 
                                          batch_size=1, 
                                          class_mode=None, 
                                          seed=seed)
    mask_generator = datagen.flow_from_dataframe(df, 
                                         directory='.', 
                                         x_col='masks', 
                                         y_col='images', # Or whatever 
                                         batch_size=1, 
                                         class_mode=None, 
                                         seed=seed)
    
    train_generator = zip(image_generator, mask_generator)
   
    # same for validation data generator

    model.fit(x=train_generator, epochs=EPOCHS, 
                    validation_data=validation_generator, use_multiprocessing=False)

It would be much cleaner, if there would be an option for `class_mode` (e.g. `class_mode='mask'`) that allows you to load the files specified by the paths in `y_col` as images. 

**Will this change the current api? How?**

An additional option for the argument `class_mode` will be added. 

**Who will benefit with this feature?**
Everyone who looks for a simple way to load images and corresponding segmentation data. 

**Any Other info.**
"
37474,Building bazel on OpenSuSE Leap 15.1 fails due to unrecognized option.,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
```
- OS Platform and Distribution:    OpenSuSE Leap 15.1 (x86_64)
- Mobile device                              N/A
- TensorFlow installed from         source
- TensorFlow version:                   0.22.0 (bazel-0.22.0-lp151.2.1.x86_64.rpm, provided in the OpenSuSE repositories)
- Python version:                           2.7.14
- Installed using:                            virtualenv? pip? conda?: Unknown (python is a foreign language for me)
- GPU model and memory:           Intel Corporation HD Graphics 630 (rev 04) (prog-if 00 [VGA controller])
```


**Describe the problem**
Installation fails with the following message:
```
ERROR: Unrecognized option: --experimental_repo_remote_exec
```

**Provide the exact sequence of commands / steps that you executed before running into the problem**
```
- zypper install bazel
- ./configure
```

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

[BazelInstall.log](https://github.com/tensorflow/tensorflow/files/4311797/BazelInstall.log)

"
37473,Tensorflow import error //ImportError: DLL load failed: The specified module could not be found.,"Traceback (most recent call last):
  File ""C:\Users\Research\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 3326, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-7-db26ddd430d7>"", line 1, in <module>
    mnist = tf.keras.mnist
AttributeError: module 'tensorflow' has no attribute 'keras'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Research\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2040, in showtraceback
    stb = value._render_traceback_()
AttributeError: 'AttributeError' object has no attribute '_render_traceback_'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Research\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Research\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Research\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\Research\Anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\Research\Anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Research\Anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 1101, in get_records
    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)
  File ""C:\Users\Research\Anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 319, in wrapped
    return f(*args, **kwargs)
  File ""C:\Users\Research\Anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 353, in _fixed_getinnerframes
    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))
  File ""C:\Users\Research\Anaconda3\lib\inspect.py"", line 1502, in getinnerframes
    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)
  File ""C:\Users\Research\Anaconda3\lib\inspect.py"", line 1460, in getframeinfo
    filename = getsourcefile(frame) or getfile(frame)
  File ""C:\Users\Research\Anaconda3\lib\inspect.py"", line 696, in getsourcefile
    if getattr(getmodule(object, filename), '__loader__', None) is not None:
  File ""C:\Users\Research\Anaconda3\lib\inspect.py"", line 733, in getmodule
    if ismodule(module) and hasattr(module, '__file__'):
  File ""C:\Users\Research\AppData\Roaming\Python\Python37\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\Research\AppData\Roaming\Python\Python37\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\Research\Anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 1006, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 983, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 953, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
  File ""<frozen importlib._bootstrap>"", line 1006, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 983, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 967, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 677, in _load_unlocked
  File ""<frozen importlib._bootstrap_external>"", line 728, in exec_module
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
  File ""C:\Users\Research\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\__init__.py"", line 42, in <module>
    from . _api.v2 import audio
  File ""C:\Users\Research\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\_api\v2\audio\__init__.py"", line 10, in <module>
    from tensorflow.python.ops.gen_audio_ops import decode_wav
  File ""C:\Users\Research\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\ops\gen_audio_ops.py"", line 9, in <module>
    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow
  File ""C:\Users\Research\AppData\Roaming\Python\Python37\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\Research\AppData\Roaming\Python\Python37\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\Research\Anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\Research\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\Research\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\Research\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 3326, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-7-db26ddd430d7>"", line 1, in <module>
    mnist = tf.keras.mnist
AttributeError: module 'tensorflow' has no attribute 'keras'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Research\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2040, in showtraceback
    stb = value._render_traceback_()
AttributeError: 'AttributeError' object has no attribute '_render_traceback_'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Research\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Research\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Research\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\Research\Anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\Research\Anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help."
37472,"Configurable attribute ""srcs"" doesn't match this configuration","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Ubuntu 16.04.2 LTS (GNU/Linux 4.4.0-38-generic aarch64)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.0
- Python version: 2.7
- Installed using virtualenv? pip? conda?: N
- Bazel version (if compiling from source): 2.0.0
- GCC/Compiler version (if compiling from source): 9.1.0
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A



**Describe the problem**
Bazel build failed when I am trying to build the tflite benchmark

**Provide the exact sequence of commands / steps that you executed before running into the problem**

bazel build -c opt tensorflow/lite/tools/benchmark:benchmark_model

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.


INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=133
INFO: Reading rc options for 'build' from /users/Wei_Hao/tensorflow/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /users/Wei_Hao/tensorflow/.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=v2
INFO: Found applicable config definition build:v2 in file /users/Wei_Hao/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:linux in file /users/Wei_Hao/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels
INFO: Found applicable config definition build:dynamic_kernels in file /users/Wei_Hao/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS
ERROR: /users/Wei_Hao/.cache/bazel/_bazel_Wei_Hao/fcdad47d36a19e877fa240235b3a74d1/external/cpuinfo/BUILD.bazel:101:1: Configurable attribute ""srcs"" doesn't match this configuration (would a default condition help?).
Conditions checked:
 @cpuinfo//:linux_x86_64
 @cpuinfo//:macos_x86_64
 @cpuinfo//:android_armv7
 @cpuinfo//:android_arm64
 @cpuinfo//:android_x86
 @cpuinfo//:android_x86_64
 @cpuinfo//:ios_x86_64
 @cpuinfo//:ios_x86
 @cpuinfo//:ios_armv7
 @cpuinfo//:ios_arm64
 @cpuinfo//:ios_arm64e
 @cpuinfo//:watchos_x86_64
 @cpuinfo//:watchos_x86
 @cpuinfo//:watchos_armv7k
 @cpuinfo//:watchos_arm64_32
 @cpuinfo//:emscripten_wasm
ERROR: Analysis of target '//tensorflow/lite/tools/benchmark:benchmark_model' failed; build aborted:

/users/Wei_Hao/.cache/bazel/_bazel_Wei_Hao/fcdad47d36a19e877fa240235b3a74d1/external/cpuinfo/BUILD.bazel:101:1: Configurable attribute ""srcs"" doesn't match this configuration (would a default condition help?).
Conditions checked:
 @cpuinfo//:linux_x86_64
 @cpuinfo//:macos_x86_64
 @cpuinfo//:android_armv7
 @cpuinfo//:android_arm64
 @cpuinfo//:android_x86
 @cpuinfo//:android_x86_64
 @cpuinfo//:ios_x86_64
 @cpuinfo//:ios_x86
 @cpuinfo//:ios_armv7
 @cpuinfo//:ios_arm64
 @cpuinfo//:ios_arm64e
 @cpuinfo//:watchos_x86_64
 @cpuinfo//:watchos_x86
 @cpuinfo//:watchos_armv7k
 @cpuinfo//:watchos_arm64_32
 @cpuinfo//:emscripten_wasm
INFO: Elapsed time: 1.036s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (1 packages loaded, 17 targets configured)
"
37471,TFLite allocate tensors fails: (CONCATENATION) failed to prepare,"**System information** 
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **Yes**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Ubuntu 18.04**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **N/A**
- TensorFlow installed from (source or binary): **binary**
- TensorFlow version (use command below): **v2.1.0-rc2-17-ge5bf8de 2.1.0**
- Python version: **3.6.9**
- Bazel version (if compiling from source): **N/A**
- GCC/Compiler version (if compiling from source): **N/A**
- CUDA/cuDNN version: **N/A**
- GPU model and memory: **N/A**

**Describe the current behavior**

Creating a `tf.keras` model and exporting it to `tflite` causes an error when trying to allocate the tensors for inference. The error is:

> RuntimeError: tensorflow/lite/kernels/concatenation.cc:68 t->dims->size != t0->dims->size (0 != 4)Node number 3 (CONCATENATION) failed to prepare.

**Describe the expected behavior**

The exported model should load without error.

**Standalone code to reproduce the issue** 

Colab gist reproducing the error can be found [here](https://colab.research.google.com/gist/moberweger/9dca6edfdabf996a57dab42ffe044666/untitled0.ipynb#scrollTo=2-Tz7Z1KnVZk)

```
import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Input, Conv2D, Concatenate, Add
from tensorflow.keras.models import Model

if __name__ == '__main__':
    print(tf.version.GIT_VERSION, tf.version.VERSION)
    test_images = np.random.randn(8, 388, 420, 1)

    # model
    m_input = Input(shape=test_images.shape[1:])
    d1 = Conv2D(8, 3, dilation_rate=1, padding='same', use_bias=False)(m_input)
    d2 = Conv2D(8, 3, dilation_rate=2, padding='same', use_bias=False)(m_input)
    d16 = Conv2D(8, 3, dilation_rate=16, padding='same', use_bias=False)(m_input)
    add1 = Add()([d2, d16])
    m_output = Concatenate()([d1, d2, add1])

    model = Model(inputs=m_input, outputs=m_output)
    model.summary()
    model.compile(optimizer='rmsprop', loss='mse')
    pred = model.predict(test_images)
    print(pred.shape)

    # conversion
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    tflite_model = converter.convert()
    with open(""model.tflite"", ""wb"") as fp:
        fp.write(tflite_model)

    # inference
    interpreter = tf.lite.Interpreter(model_path=""model.tflite"")
    input_details = interpreter.get_input_details()
    interpreter.allocate_tensors()
    print(""DONE"")
```

**Other info / logs**
```
RuntimeError                              Traceback (most recent call last)

<ipython-input-3-4adc506bd32d> in <module>()
     31     interpreter = tf.lite.Interpreter(model_path=""model.tflite"")
     32     input_details = interpreter.get_input_details()
---> 33     interpreter.allocate_tensors()
     34     print(""DONE"")

/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/interpreter.py in allocate_tensors(self)
    245   def allocate_tensors(self):
    246     self._ensure_safe()
--> 247     return self._interpreter.AllocateTensors()
    248 
    249   def _safe_to_run(self):

/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py in AllocateTensors(self)
    108 
    109     def AllocateTensors(self):
--> 110         return _tensorflow_wrap_interpreter_wrapper.InterpreterWrapper_AllocateTensors(self)
    111 
    112     def Invoke(self):

RuntimeError: tensorflow/lite/kernels/concatenation.cc:68 t->dims->size != t0->dims->size (0 != 4)Node number 3 (CONCATENATION) failed to prepare.
```
"
37470,Cannot import tensorflow,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 64bit
- TensorFlow installed from (source or binary):
- TensorFlow version: 2.1.0
- Python version: 3.6.4
- Installed using virtualenv? pip? conda?:pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

I used pip install tensorflow to install TensorFlow in my pc. But when I run import TensorFlow as tf ,I get this message

ITraceback (most recent call last):
  File ""C:\Users\bhavs\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\bhavs\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\bhavs\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\bhavs\AppData\Local\Programs\Python\Python36\lib\imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\bhavs\AppData\Local\Programs\Python\Python36\lib\imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<pyshell#0>"", line 1, in <module>
    import tensorflow
  File ""C:\Users\bhavs\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""C:\Users\bhavs\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow_core\__init__.py"", line 42, in <module>
    from . _api.v2 import audio
  File ""C:\Users\bhavs\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow_core\_api\v2\audio\__init__.py"", line 10, in <module>
    from tensorflow.python.ops.gen_audio_ops import decode_wav
  File ""C:\Users\bhavs\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow_core\python\ops\gen_audio_ops.py"", line 9, in <module>
    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow
  File ""C:\Users\bhavs\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\bhavs\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\bhavs\AppData\Local\Programs\Python\Python36\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\bhavs\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\bhavs\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\bhavs\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\bhavs\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\bhavs\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\bhavs\AppData\Local\Programs\Python\Python36\lib\imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\bhavs\AppData\Local\Programs\Python\Python36\lib\imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
"
37468,Neural network with several target vectors to run on TPU,"I try to create my own neural network with several outputs (it follows that there are several target vectors); these target vectors dynamically change during training and depend on the predictions of the neural network. That is, it looks like the following: `y_proba = f(input), y_true = g(y_proba)`, where `input` - input vector, `f` - function of the neural network, `y_proba` - predicted target vector, `g` - function of changing the predicted target vector, `y_true` - target vector.
The problem is that I cannot implement this neural network using Keras and TPUEstimator in TensorFlow 2.1 to run on TPU.
I tried to solve this problem in two ways.

**1. The first way to solve the problem**

I changed the source code of Keras inside TensorFlow to run on CPU and TPU to solve this problem.

Changes to run on CPU in `tensorflow_core/python/keras/engine/training_arrays.py` inside `model_iteration` function:
```
#calling my own function to change ins_batch
batch_outs = f(ins_batch)
```

Changes to run on TPU in `tensorflow_core/python/keras/engine/training_eager.py` inside `_model_loss` function:
```
if targets:
  targets = training_utils.cast_if_floating_dtype_and_mismatch(targets, outs)
#calling my own function to change targets
```

Changes to run on TPU without experimental functions (setting `experimental_run_tf_function=False` when compiling the model as described in [this](https://github.com/tensorflow/tensorflow/issues/33729#issuecomment-562656807)) in `tensorflow_core/python/keras/engine/training_arrays.py` inside `model_iteration` function:
```
actual_inputs = ins()
#calling my own function to change actual_inputs
batch_outs = f(actual_inputs)
```

To run on CPU, I can dynamically change the target vector inside TensorFlow, and the neural network is trained. But adding this feature inside TensorFlow to run on TPU has many nuances and works like magic and I couldn’t train the neural network.

**2. The second way to solve the problem**
I tried to implement my neural network based on `TPUEstimator` using `RegressionHead` and `MultiHead`. To do this, I used examples ([mnasnet](https://github.com/tensorflow/tpu/tree/master/models/official/mnasnet) and [convolutional_network](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/convolutional_network.py)).

This is the part of the program that implements my own neural network using `TPUEstimator`:

```
def get_model(features, input_shape, reuse):
    with tf.variable_scope('model', reuse=reuse):
        seqs = []
        n_filters = 8
        for i in range(n):
            seqs.append(get_conv2d(
                          seqs[-1].get_x(),
                          (3, 3, 8, n_filters),
                          reuse=reuse))
        outputs = []
        heads = []
        for x in seqs:
            outputs.append(OutputLayer(name=""output_""+x.name)(x.get_x()))
            heads.append(tf.estimator.RegressionHead(
                                           label_dimension=32*32*8,
                                           name=""head_""+x.name))
        head = tf.estimator.MultiHead(heads)
    return head, outputs

def model_fn(features, labels, mode, params):
    batch_size = 8 * params['batch_size']

    head, logits_train = get_model(features, params['input_shape'], reuse=False)
    logits_train_dic = {}
    for i in range(n):
        logits_train[i] = tf.reshape(logits_train[i], (batch_size, 32*32*8,))
        logits_train_dic[""head_{}"".format(i)] = logits_train[i]
    pred_classes = tf.argmax(logits_train, axis=1)
    if mode == tf.estimator.ModeKeys.PREDICT:
        return tf.estimator.tpu.TPUEstimatorSpec(mode, predictions=pred_classes)

    new_labels = {}
    for key in labels:
        new_labels[key] = labels[key][0]
    loss = 0.0
    for key in logits_train_dic:
        logit_train = logits_train_dic[key]
        loss += tf.square(labels[key]-logit_train)
    loss_op = tf.reduce_mean(loss)
    optimizer = tf.train.AdamOptimizer(learning_rate=params['learning_rate'])
    if params['use_tpu']:
        optimizer = tf.tpu.CrossShardOptimizer(optimizer)
    train_op_fn = lambda loss_op: optimizer.minimize(
                                  loss_op,
                                  global_step=tf.train.get_global_step())
                
    estim_specs = head.create_estimator_spec(
                  features={""x"": features},
                  labels=new_labels,
                  mode=mode,
                  logits=logits_train_dic,
                  train_op_fn=train_op_fn)
    return estim_specs

model = tf.estimator.tpu.TPUEstimator(
          model_fn, use_tpu=True,
          config=config,
          train_batch_size=train_batch_size,
          params=params)
```
As I understand it, this way of implementing a neural network makes it possible to dynamically change labels (in particular, target vectors).
I implemented the neural network itself using `TPUEstimator`, but I faced with another problem - ""Graph was finalized"" is displayed, but the training of the neural network does not start.

How to implement a neural network with several dynamically changing target vectors, which depend on neural network predictions, on TPU?"
37467,No gradient defined for op,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): 
auto entropy_0 = Xlogy(scope_loss.WithOpName(""xlogy0""), input_labels_var, out_segmentation);
- OS Platform: Windows7
- VS2015
- Python version: 3.6
- Bazel version: 0.26.0
- TensorFlow version: tensorflow 2.0
- CUDA/cuDNN version: Cuda 10.0 && Cudnn 7.4.1
- GPU : Geforce GTX 1070 8GB:

Hey, I got some error when I using op like Concat and Xlogy, which remind me that I have to add C++ gradient. But as https://github.com/tensorflow/tensorflow/issues/19944#issuecomment-556315768 says, the gradient op is existing, so how should I do to use the gradient op?
Thanks !


"
37463,ImportError: No module named builtins,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): 
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
- TensorFlow installed from (source or
binary): Pip3 
- TensorFlow version (use command below): 2.1.0  
- Python version: - Bazel
version (if compiling from source):
- GCC/Compiler version (if compiling from
source): 
- CUDA/cuDNN version: - GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
![Screenshot from 2020-03-10 08-30-00](https://user-images.githubusercontent.com/41910134/76275645-c9089780-62a9-11ea-8798-686a3a8d8412.png)

I am unable to complete the util test.

**Describe the expected behavior**

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

bazel test ${flags} //tensorflow/python/keras


**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
37462,Custom rnn migration to tensorflow 2.x,"I want to migrate tensorflow 1.x code to 2.x. I have tried migration script and refererd migration guide. But still its unclear that how to migrate 
1.place holder with shape such as [x,None,y] . 
2. Convert tf_get_variable with xavier initialization
Please find the stackoverflow post link (not answered)

https://stackoverflow.com/questions/60601770/custom-rnn-migration-to-tensorflow-2-0"
37461,Installation for Python 3.8.1?,"Hey , just wanted to confirm if you now have the support for Python 3.8.1? If not, I want to use tensorflow 1.15, which python version works best with it?

"
37460,map_fn + @tf.function + tf.nn.conv2d throws error when strides to conv2d are supplied in the elems argument for map_fn,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Ubuntu GNU/Linux 18.04, Debian GNU/Linux bullseye/sid x86_64

- TensorFlow installed from (source or
binary): Binary
- TensorFlow version (use command below): 2.0.0, 2.1.0
- Python version: 3.7.3, 3.5.2
- CUDA/cuDNN version: 10.0, ROCm 3.0
- GPU model and memory: Titan V, Radeon VII

**Describe the current behavior**
Supplying the strides for tf.nn.conv2d inside elems when using tf.map_fn leads to the following error ONLY when executing in graph mode/inside @tf.function:

TypeError: len is not well defined for symbolic Tensors. (TensorArrayV2Read_2/TensorListGetItem:0) Please call `x.shape` rather than `len(x)` for shape information.


**Describe the expected behavior**
It should run successfully, as is the case without @tf.function

**Standalone code to reproduce the issue** 
```python
import tensorflow as tf

@tf.function
def g(a,b):
    return tf.map_fn(lambda x: tf.nn.conv2d(tf.expand_dims(x[0],0),x[1],[2,2],""VALID"",""NCHW""), [a,b], dtype = a.dtype, parallel_iterations = 16)

def g2(a,b,s):
    return tf.map_fn(lambda x: tf.nn.conv2d(tf.expand_dims(x[0],0),x[1],x[2],""VALID"",""NCHW""), [a,b,s], dtype = a.dtype, parallel_iterations = 16)

@tf.function
def g3(a,b,s):
    return tf.map_fn(lambda x: tf.nn.conv2d(tf.expand_dims(x[0],0),x[1],x[2],""VALID"",""NCHW""), [a,b,s], dtype = a.dtype, parallel_iterations = 16)

q = tf.random.uniform((16,5,100,100))
r = tf.random.uniform((16,5,5,5,2))
stri = tf.tile(tf.constant([[2,2]]),[16,1])

print(g(q,r).shape) #runs fine
print(g2(q,r,stri).shape) #runs fine
print(g3(q,r,stri).shape) #error
```

**Other info / logs** Include any logs or source code that would be helpful to
### When using TF2.0 + CUDA 10.0 on Titan V
```
Traceback (most recent call last):
  File ""mapfn.py"", line 19, in <module>
    print(g3(q,r,stri))
  File ""/home/ago14/.conda/envs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 457, in __call__
    result = self._call(*args, **kwds)
  File ""/home/ago14/.conda/envs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 503, in _call
    self._initialize(args, kwds, add_initializers_to=initializer_map)
  File ""/home/ago14/.conda/envs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 408, in _initialize
    *args, **kwds))
  File ""/home/ago14/.conda/envs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 1848, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/home/ago14/.conda/envs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2150, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/home/ago14/.conda/envs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2041, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/home/ago14/.conda/envs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py"", line 915, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/home/ago14/.conda/envs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 358, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/home/ago14/.conda/envs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py"", line 905, in wrapper
    raise e.ag_error_metadata.to_exception(e)
TypeError: in converted code:

    mapfn.py:12 g3  *
        return tf.map_fn(lambda x: tf.nn.conv2d(tf.expand_dims(x[0],0),x[1],x[2],""VALID"",""NCHW""), [a,b,s], dtype = a.dtype, parallel_iterations = 16)
    /home/ago14/.conda/envs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/ops/map_fn.py:268 map_fn
        maximum_iterations=n)
    /home/ago14/.conda/envs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py:1913 conv2d_v2
        name=name)
    /home/ago14/.conda/envs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py:2000 conv2d
        strides = _get_sequence(strides, 2, channel_index, ""strides"")
    /home/ago14/.conda/envs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py:68 _get_sequence
        current_n = len(value)
    /home/ago14/.conda/envs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:741 __len__
        ""shape information."".format(self.name))

    TypeError: len is not well defined for symbolic Tensors. (TensorArrayV2Read_2/TensorListGetItem:0) Please call `x.shape` rather than `len(x)` for shape information.
```

### When using TF2.1 + ROCm 3.0 on Radeon VII
```
Traceback (most recent call last):
  File ""mapfn.py"", line 20, in <module>
    print(g3(q,r,stri).shape) #error
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/def_function.py"", line 568, in __call__
    result = self._call(*args, **kwds)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/def_function.py"", line 615, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/def_function.py"", line 497, in _initialize
    *args, **kwds))
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/function.py"", line 2389, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/function.py"", line 2703, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/function.py"", line 2593, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/framework/func_graph.py"", line 978, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/def_function.py"", line 439, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/framework/func_graph.py"", line 968, in wrapper
    raise e.ag_error_metadata.to_exception(e)
TypeError: in converted code:

    mapfn.py:12 g3  *
        return tf.map_fn(lambda x: tf.nn.conv2d(tf.expand_dims(x[0],0),x[1],x[2],""VALID"",""NCHW""), [a,b,s], dtype = a.dtype, parallel_iterations = 16)
    /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/ops/map_fn.py:268 map_fn
        maximum_iterations=n)
    /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/ops/nn_ops.py:1914 conv2d_v2
        name=name)
    /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/ops/nn_ops.py:2001 conv2d
        strides = _get_sequence(strides, 2, channel_index, ""strides"")
    /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/ops/nn_ops.py:69 _get_sequence
        current_n = len(value)
    /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/framework/ops.py:733 __len__
        ""shape information."".format(self.name))

    TypeError: len is not well defined for symbolic Tensors. (TensorArrayV2Read_2/TensorListGetItem:0) Please call `x.shape` rather than `len(x)` for shape information.
```

"
37458,how to extract tflite_hexagon_nn_skel_v1.14.run,"**System information**
- OS Platform and Distribution - Debian based but tried on Ubuntu 18.04 too

Per the instructions here

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/performance/hexagon_delegate.md#step-2-add-hexagon-libraries-to-your-android-app

when I try to run the extractor I'm presented with a colon. I've tried 'yes', 'accept', but nothing works. It just says ""Aborting extraction"" and bails.
```
root@linaro-alip:~/hexagon# ./tflite_hexagon_nn_skel_v1.14.run
Creating directory hexagon_nn_skel_v1.14
Verifying archive integrity...  100%   All good.
Uncompressing Hexagon NN Shared Libs  100%  

:
Aborting extraction.. Done
root@linaro-alip:~/hexagon# 
```
Is there some trick to extracting the files?

"
37457,pip install tensorflow could not find a version,"**System information**
- macOS Catalina version 10.15.3
- pip install tensorflow
- GPU model and memory: Intel Iris Plus Graphics 645 1536 MB

**The problem**
Both `pip install tensorflow` and `pip install tf-nightly` lead to the following error messages:

> ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)

> ERROR: No matching distribution found for tensorflow

"
37456,Ops with SparseTensor on GPU gives result in CPU.,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow):  custom code
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04):  Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
- TensorFlow installed from (source or
binary): binary (conda)
- TensorFlow version (use command below): 2.1.0
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from
source): 
- CUDA/cuDNN version: CUDA 10.1
- GPU model and memory: NVIDIA GTX 1060 6 GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
When executing operations on sparse tensors in the GPU (within a `tf.device` block), the result is stored in the CPU. This is causing a huge slowdown in my program, as the data is being copied around between GPU and GPU multiple times.

I have verified that this occurs with the functions `tf.sparse.sparse_dense_matmul` and `tf.sparse.reduce_sum`. It may also occur with others. Is this the intended behavior? I am missing something?

**Describe the expected behavior**
The result of an operation on a sparse tensor with the GPU should stay in the GPU.

**Standalone code to reproduce the issue** 
See [this Colab notebook](https://colab.research.google.com/drive/1BpG8P8dEzDDmtMBIGgSA2wOMzEm4bCzL).

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

Thanks in advance.
"
37450,tensorflow-gpu 2.0.1 hangs mid-epoch,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): The only modification i have made is that i've forked ReduceLRonPlateau and use this modified version. The only change is that i reduce the weight decay along with the learning rate. Seems highly unlikely this is relevant.

ReduceLRonPlateau
```
 old_lr = float(K.get_value(self.model.optimizer.lr))
                    old_wd = float(K.get_value(self.model.optimizer.weight_decay))
                    if old_lr > self.min_lr:
                        new_lr = old_lr * self.factor
                        new_wd = old_wd * self.factor
                        new_lr = max(new_lr, self.min_lr)
                        K.set_value(self.model.optimizer.weight_decay, new_wd)
                        K.set_value(self.model.optimizer.lr, new_lr)
```

- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04):  Windows 10
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below):  pip
- Python version: - Bazel
version (if compiling from source):  3.6
- GCC/Compiler version (if compiling from
source): 
- CUDA/cuDNN version: - GPU model and memory: 1060 6GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

Upon calling model.fit() TF will hang at seemingly random points. (5 epochs in, mid epoch for example after we've trained on 20% of our batches). I am doing hyper parameter optimization, so sometimes a trial will complete fully, other times it will hang indefinitely. I was having no issues originally when doing a regression problem. This issue only started happenign when i switched to categorical classification.

My output node is 3 units because i have 3 class. Using a softmax function and built in categorical cross entropy. Those are the only changes from when it was working to now.

Tried changing batch size, does not seem to have affect. Not sure if i can see a pattern if certain parameter configurations cause the fit to fail.

I notice the CPU spikes during a stall.

**Describe the expected behavior**

TF does not stall or at least provided some information as to why it is stalled.

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
37449,"Resource temporarily unavailable, ENOMEM on CPU with memory rlimit","**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): yes, trivial example
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Debian buster
- TensorFlow installed from (source or
binary): source
- TensorFlow version (use command below): 2.1.0
- Python version: 3.73
- Bazel version (if compiling from source): ?
- GCC/Compiler version (if compiling from source): 8.3.0
- CUDA/cuDNN version: - GPU model and memory: not relevant

**Describe the current behavior**

The system has 12 GB total physical memory, with /etc/security/limits.conf set to limt per-process max memory to 10 GB as follows:

```
* hard rss 10485760
* hard as 10485760
```
A trivial code example runs out of memory. The last failling syscall obtained with strace is

mmap(NULL, 8392704, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = -1 ENOMEM (Cannot allocate memory)

Looking at mmap invocations from strace confirms that it is indeed allocating close to 10 GB memory before fail. This does not happen when the resource limits are removed. I suspect that it's ignoring the rlimit and trying to allocate all physical memory.

**Describe the expected behavior**

The library should respect the current max memory rlimit (or better yet, not try to allocate all system memory?) or provide some configuration parameter to limit memory (I found none for the CPU-based version).

**Standalone code to reproduce the issue** 

```
from __future__ import absolute_import, division, print_function, unicode_literals

import tensorflow as tf
import numpy as np

tf.config.set_visible_devices([], 'GPU')
model = tf.keras.Sequential([ tf.keras.layers.Dense(units=1, input_shape=[1]) ])
model.compile(optimizer='sgd', loss='mean_squared_error')

xs = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)
ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)

model.fit(xs, ys, epochs=1)
```

**Other info / logs**

Strace output:

```
...
write(1, ""Train on 6 samples\n"", 19Train on 6 samples
)    = 19
ioctl(1, TCGETS, {B38400 opost isig icanon echo ...}) = 0
sched_getaffinity(0, 128, [0, 1, 2, 3, 4, 5, 6, 7]) = 64
sysinfo({uptime=8660, loads=[12896, 10528, 13536], totalram=12518699008, freeram=2526597120, sharedram=950390784, bufferram=1171718144, totalswap=4898942976, freeswap=3857969152, procs=741, totalhigh=0, freehigh=0, mem_unit=1}) = 0
mmap(NULL, 8392704, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = -1 ENOMEM (Cannot allocate memory)
futex(0x7f5ca3c481a0, FUTEX_WAKE_PRIVATE, 2147483647) = 0
write(2, ""terminate called after throwing ""..., 48terminate called after throwing an instance of ') = 48
write(2, ""std::system_error"", 17std::system_error)       = 17
write(2, ""'\n"", 2'
)                      = 2
write(2, ""  what():  "", 11  what():  )             = 11
write(2, ""Resource temporarily unavailable"", 32Resource temporarily unavailable) = 32
write(2, ""\n"", 1
)                       = 1
```
"
37448,"Increase BiasGrad size:  ""BiasGrad requires tensor size <= int32 max""","**System information**
- TensorFlow version (you are using): 2.1.0
- Are you willing to contribute it (Yes/No): No

**Describe the feature and the current behavior/state.**

We've using 3D U-Net on large images (e.g. 512x512x256x4) and have found that when the input size increases above a certain size we get the error:  

```
tensorflow.python.framework.errors_impl.InvalidArgumentError:  BiasGrad requires tensor size <= int32 max
	 [[node BiasAddGrad_3 (defined at testing.py:640) ]] [Op:__inference_distributed_function_2785]
```

I'm pretty sure that this is because the BiasGrad function is using an INT32 datatype and we're declaring more than the datatype can represent as INT32. 

I'd like to request that the datatype be change to something larger-- possible INT64 or at least an unsigned INT32. On CPU we can easily use 100s of GB of RAM for the TensorFlow graph so these are now valid workloads for TF to support.

**Will this change the current api? How?**

No. Other than to change the datatype for BiasGrad to something larger.

**Who will benefit with this feature?**

We've got customers now using 3D networks with very large images (512x512x256x4) and moderately large batch sizes (2-16). The memory footprint for these TF models can fit into CPU memory (~ 1.5 TB) if the datatype is extended to larger integers. 

**Any Other info.**
"
37447,Cross-compile instructions for TFLite XNNPACK delegate on ARM,"Are there any instructions on how to cross-compile the XNNPACK delegate for ARM?


I've tried the following:
export CC=arm-linux-armeabief-gcc
export CPP=arm-linux-armeabief-g++
bazel-2.1.0 build //tensorflow/lite/delegates/xnnpack:xnnpack_delegate

ERROR: /home/andy/.cache/bazel/_bazel_andy/ff7061ef3fb000e53210886b26774f34/external/XNNPACK/BUILD.bazel:1654:1: C++ compilation of rule '@XNNPACK//:sse2_ukernels' failed (Exit 1)
arm-linux-gnueabihf-gcc: error: unrecognized command line option '-msse2'
Target //tensorflow/lite/delegates/xnnpack:xnnpack_delegate failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 26.516s, Critical Path: 14.13s
INFO: 28 processes: 28 local.
FAILED: Build did NOT complete successfully

Ubuntu 14.04 
Bazel 2.1.0
GNU 4.9.3
Targeting Raspberry Pi 3B / Compute Module 3
"
37446,Python crashes when computing max/min of a complex tensor,"**System information** 
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04 
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.1
- Python version: 3.6.8

**Describe the current behavior**
When taking (by mistake) the max value of a tensor with complex dtype, tf crashes python.


**Describe the expected behavior**
Tf should fail gracefully, i.e. throwing an error.

**Standalone code to reproduce the issue** 
```python
import tensorflow as tf
tf.reduce_max(tf.ones((9,), dtype=tf.complex64))
```

**Other info / logs** 
```
2020-03-09 15:40:04.604547: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-03-09 15:40:04.604625: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)
2020-03-09 15:40:04.604723: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (zaccharie-Latitude-7490): /proc/driver/nvidia/version does not exist
2020-03-09 15:40:04.605857: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-03-09 15:40:04.645752: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2112000000 Hz
2020-03-09 15:40:04.647241: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4c32870 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-03-09 15:40:04.647293: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-03-09 15:40:04.671854: F tensorflow/compiler/xla/literal_util.cc:212] C64 element type has no minimum value
[1]    23558 abort (core dumped)  ipython
```

I tried on machine with and without GPU for the same result.
"
37445,Document purpose for tf.keras.preprocessing module,"## URL(s) with the issue:

https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing

## Description of issue (what needs changing):

The module documentation is very terse and only states that it contains ""preprocessing utils"". It does not state the specific purpose.

It would be helpful if it defined the intended use of the `tf.keras.preprocessing` module (_e.g._ to clean up or transform tf.data.Datasets before they are fed to the model).

Also, since the `tf.feature_column` module has similar functionality, it would be nice to describe when to use one or the other, or how they are intended to be used together."
37444,InaccessibleTensorError in graph mode with for loop itteration (different sized tensors) ( tf.image.resize),"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): custom Layer, using tf.image.resize
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04):  Linux Mint 19.3 Cinnamon (Ubuntu based)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: No
- TensorFlow installed from (source or
binary): pip install
 - TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de 2.1.0
- Python version: 3.6.9

Problem:
Not sure if its a bug, or i misused something
but i expected autograph to do a loop unrolling once, and later work with the tensors created in the unrolled loop.

**Describe the current behavior**
in graph mode (tf.function) InaccessibleTensorError is thrown if tf.image.resize is used in loop

**Describe the expected behavior**
should work as in eager mode

**Standalone code to reproduce the issue** 
```
import tensorflow as tf 

def main():
    execute_eager = False
    test_nr = 2
    tf.config.experimental_run_functions_eagerly(execute_eager)
    
    images = tf.constant(100.,shape=[1,10,10,20])
    if execute_eager or test_nr == 1:
        scale = Scaler1()
        out = scale(images)
        print(out)
    if execute_eager or test_nr == 2:
        scale = Scaler2()
        out = scale(images)
        print(out)
    if execute_eager or test_nr == 3:
        scale = Scaler2()
        out = scale(images)
        print(out)

class Scaler1(tf.keras.layers.Layer):
    
    def __init__(self, count = 5, name = ""Scaler"", **kwargs):
        self.count = tf.cast(count, dtype = tf.float32)
        super().__init__(name = name, **kwargs)
        self.sized_images=[]
         
    @tf.function
    def call(self, inputs):
        images = inputs
        
        image_size = tf.cast(tf.shape(images)[1:3], dtype=tf.float32)
                   
        for i in range(int(self.count)):
            scale = image_size * (1 + tf.cast(i, dtype=tf.float32))
            sized_image = tf.image.resize(images, tf.cast(scale + 0.5, dtype = tf.int32))
            self.sized_images.append(sized_image)
        
        return self.sized_images

class Scaler2(tf.keras.layers.Layer):
    
    def __init__(self, count = 5, name = ""Scaler"", **kwargs):
        self.count = tf.cast(count, dtype = tf.float32)
        super().__init__(name = name, **kwargs)
        self.sized_images=[]
         
    @tf.function
    def call(self, inputs):
        images = inputs
        
        image_size = tf.cast(tf.shape(images)[1:3], dtype=tf.float32)
                   
        for i in tf.range(self.count):
            scale = image_size * (1 + tf.cast(i, dtype=tf.float32))
            sized_image = tf.image.resize(images, tf.cast(scale + 0.5, dtype = tf.int32))
            self.sized_images.append(sized_image)
        
        return self.sized_images
    
class Scaler3(tf.keras.layers.Layer):
    
    def __init__(self, count = 5, name = ""Scaler"", **kwargs):
        self.count = tf.cast(count, dtype = tf.float32)
        super().__init__(name = name, **kwargs)
        self.sized_images=[]
         
    @tf.function
    def call(self, inputs):
        images = inputs
        
        image_size = tf.cast(tf.shape(images)[1:3], dtype=tf.float32)
             
        self.sized_images = [tf.image.resize(images, tf.cast(image_size * (1 + i) + 0.5, dtype = tf.int32)) for i in tf.range(self.count)]     
        
        return self.sized_images
    

if __name__ == '__main__':
    main()
```
Traceback:

```
Traceback (most recent call last):
  File ""/home/bhb/.vscode/extensions/ms-python.python-2020.2.64397/pythonFiles/ptvsd_launcher.py"", line 48, in <module>
    main(ptvsdArgs)
  File ""/home/bhb/.vscode/extensions/ms-python.python-2020.2.64397/pythonFiles/lib/python/old_ptvsd/ptvsd/__main__.py"", line 432, in main
    run()
  File ""/home/bhb/.vscode/extensions/ms-python.python-2020.2.64397/pythonFiles/lib/python/old_ptvsd/ptvsd/__main__.py"", line 316, in run_file
    runpy.run_path(target, run_name='__main__')
  File ""/usr/lib/python3.6/runpy.py"", line 263, in run_path
    pkg_name=pkg_name, script_name=fname)
  File ""/usr/lib/python3.6/runpy.py"", line 96, in _run_module_code
    mod_name, mod_spec, pkg_name, script_name)
  File ""/usr/lib/python3.6/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/test_scaling_tensor.py"", line 83, in <module>
    main()
  File ""/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/test_scaling_tensor.py"", line 72, in main
    out = scale(images)
  File ""/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 967, in __call__
    outputs = self.call(cast_inputs, *args, **kwargs)
  File ""/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 579, in __call__
    result = self._call(*args, **kwds)
  File ""/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 626, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File ""/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 506, in _initialize
    *args, **kwds))
  File ""/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 2446, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 2777, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 2667, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py"", line 986, in func_graph_from_py_func
    expand_composites=True)
  File ""/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow/python/util/nest.py"", line 617, in map_structure
    structure[0], [func(*x) for x in entries],
  File ""/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow/python/util/nest.py"", line 617, in <listcomp>
    structure[0], [func(*x) for x in entries],
  File ""/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py"", line 945, in convert
    x = deps_ctx.mark_as_return(x)
  File ""/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow/python/framework/auto_control_deps.py"", line 217, in mark_as_return
    tensor = array_ops.identity(tensor)
  File ""/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py"", line 180, in wrapper
    return target(*args, **kwargs)
  File ""/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py"", line 282, in identity
    ret = gen_array_ops.identity(input, name=name)
  File ""/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 3901, in identity
    ""Identity"", input=input, name=name)
  File ""/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper
    attrs=attr_protos, op_def=op_def)
  File ""/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py"", line 591, in _create_op_internal
    inp = self.capture(inp)
  File ""/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py"", line 641, in capture
    % (tensor, tensor.graph, self))
tensorflow.python.framework.errors_impl.InaccessibleTensorError: The tensor 'Tensor(""resize/ResizeBilinear:0"", shape=(1, None, None, 20), dtype=float32)' cannot be accessed here: it is defined in another function or code block. Use return values, explicit Python locals or TensorFlow collections to access it. Defined in: FuncGraph(name=while_body_32, id=139898298208720); accessed from: FuncGraph(name=call, id=139898299444136).
```"
37441,ValueError: Cannot convert a Tensor of dtype resource to a NumPy array,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow):  Yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04):  N/A, as it can be reproduced in Google Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device:  N/A
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): 2.1
- Python version: - Bazel
version (if compiling from source): N/A
- GCC/Compiler version (if compiling from
source): N/A
- CUDA/cuDNN version: - GPU model and memory: N/A

**Describe the current behavior**: It is resulting in Error, `InvalidArgumentError: Cannot convert a Tensor of dtype resource to a NumPy array.`, while running the First Code but is working fine when `tf.keras.Input` is replaced with `tf.Variable` in the Second Code.

**Describe the expected behavior**: Code should work fine with `tf.keras.Input` as well

**Standalone code to reproduce the issue** 

      **Code with Error:**

import tensorflow as tf

num_uids = 50
#input_uid = tf.keras.layers.Input(shape=(1,), dtype=tf.int32, batch_size = 32)
input_uid = tf.keras.layers.Input(shape=(1,), dtype=tf.int32)
params = tf.Variable(tf.random.normal((num_uids, 9)), trainable=True)

param = tf.gather_nd(params, input_uid)

#input_shared_features = tf.keras.layers.Input(shape=(128,), dtype=tf.float32, batch_size = 32)
input_shared_features = tf.keras.layers.Input(shape=(128,), dtype=tf.float32)
combined = tf.concat([param, input_shared_features], axis=-1)

net = tf.keras.layers.Dense(128)(combined)

      **Working Code:**

import tensorflow as tf

num_uids = 50
input_uid = tf.Variable(tf.ones((32, 1), dtype=tf.int32))
params = tf.Variable(tf.random.normal((num_uids, 9)), trainable=True)

param = tf.gather_nd(params, input_uid)

input_shared_features = tf.Variable(tf.ones((32, 128), dtype=tf.float32))
combined = tf.concat([param, input_shared_features], axis=-1)

net = tf.keras.layers.Dense(128)(combined)

Please find the [Github Gist](https://colab.sandbox.google.com/gist/rmothukuru/b3427c06cab54beed19a381339c932e0/so_59962509.ipynb).

There is a [Stack Overflow Question](https://stackoverflow.com/questions/59962509/valueerror-cannot-convert-a-tensor-of-dtype-resource-to-a-numpy-array) also, associated with this issue."
37440,AutoGraph error with FOR loop in Keras loss,"**System information** 
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10, x64
- TensorFlow installed from (source or binary): Binary (pip)
- TensorFlow version (use command below): TF 2.1.0 as well as TF 2.2.0 (2.2.0.dev20200304)
- Python version: 3.7
- CUDA/cuDNN version: 10.1 / 7.6
- GPU model and memory: Bug appears on several computers with different GPU

**Describe the current behavior**

Error ""**tensorflow.python.framework.errors_impl.OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.**"" when using a FOR loop over a Tensor dimension in a custom Keras loss in AutoGraph mode.

Notice that when running eagerly, the bug does not appear. 
Notice also that using a similar FOR loop in a custom Keras model works both in AutoGraph and Eager modes. The bug is specific to Keras Loss.
As expected, replacing the loop with a call to tf.map_fn works correctly.

**Describe the expected behavior**

The behavior should be the same as running eagerly, without any error.

**Standalone code to reproduce the issue** 

```
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

# Custom loss with a FOR loop. Raises an error in AutoGraph mode. 
# A similar FOR loop in a Keras model works as expected.
class CustomLoss(keras.losses.Loss):
	def call(self, y_true, y_pred):
		x = y_true + y_pred
		for i in tf.range(tf.shape(y_true)[0]): # The error is reaised here.
			x += 1
		return tf.reduce_mean(x)

if __name__ == ""__main__"" :
	data = np.random.random((1000, 3)).astype(np.float32)
	
	inputs = tf.keras.Input(shape=(1000,3))
	outputs = tf.keras.layers.Dense(3)(inputs)
	model = tf.keras.Model(inputs=inputs, outputs=outputs)
	
	model.compile(loss=CustomLoss()) # does NOT work
	# model.compile(loss=CustomLoss(), run_eagerly = True) # works
	
	model.fit(x=data, y=data)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

Log in attachment.
[log.txt](https://github.com/tensorflow/tensorflow/files/4306163/log.txt)
"
37439,"TypeError: '_UserObject' object is not callable,  why tf.saved_model.load() failed?","**System information** 
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): 2.1.0
- Python version: 3.7.4

**Describe the current behavior**
```
Traceback (most recent call last):
  File ""C:/Pyfile/tensorflow2.X/load_model.py"", line 12, in <module>
    print(model(tf.random.normal((1, 3))))
TypeError: '_UserObject' object is not callable
```
**Describe the expected behavior**

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```
import os
import tensorflow as tf

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

class Model(tf.keras.Model):
    def __init__(self):
        super(Model, self).__init__()
        self.d = tf.keras.layers.Dense(2)

    def call(self, x, training=True, mask=None):
        return self.d(x)

model = Model()

# high-level api
# model.predict(tf.random.normal((2, 3)))
# model.save(""save/high"", save_format=""tf"")

# low-level api
tf.saved_model.save(model, 'save/low')

---------------------------------------------

import os
import tensorflow as tf

# high-level api
# model = tf.keras.models.load_model('save/high')

# low-level api
model = tf.saved_model.load('save/low')

print(model(tf.random.normal((1, 3))))   #  error!!!
```
If I user the high-level api to save and load, it runs successfully. If I use tf.saved_mode.save()，it can save successfully with warning
'''
WARNING:tensorflow:Skipping full serialization of Keras model <__main__.Model object at 0x0000028C0515F6D8>, because its inputs are not defined.
2020-03-09 18:20:37.304479: W tensorflow/python/util/util.cc:319] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x0000028C1CB87CC0>, because it is not built.
''' 
then load failed, So what does  '_UserObject' object is not callable mean?  How can I fix this, thanks for any help"
37433,AttributeError: module 'tensorboard' has no attribute 'lazy',"I've been trying to import tensorflow, downloading Anaconda 3, creating virtual environment, use pip install tensorflow, pip install keras and when I try to import tensorflow an error occured  ""Failed to load the native TensorFlow runtime."" then I tried to resolve it by downloading cygwin to update the gcc. After that, another error occured 

```
2020-01-21 16:18:17.197417: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found
2020-01-21 16:18:17.197832: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
```

Tried to solve it by downloading CUDA 10.1 version and now the problem is

```
2020-03-09 14:17:07.528838: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
```

This is a problem because after that all process finished with exit code 1 and print('test') cannot even be processed after this.

System information:
Anaconda 3
Windows 10
Tensorflow 2.1
Inteil Core I5
Gtx 1050 ti
CUDA version 10.1
python version 3.6.1


Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

The errors when I try to import tensorflow:

```
2020-03-09 14:17:07.528838: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
Traceback (most recent call last):
  File ""C:/Users/User/PycharmProjects/tensortest/test.py"", line 1, in <module>
    import tensorflow
  File ""C:\Users\User\Anaconda3\envs\tensortest\lib\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""C:\Users\User\Anaconda3\envs\tensortest\lib\site-packages\tensorflow_core\__init__.py"", line 46, in <module>
    from . _api.v2 import compat
  File ""C:\Users\User\Anaconda3\envs\tensortest\lib\site-packages\tensorflow_core\_api\v2\compat\__init__.py"", line 39, in <module>
    from . import v1
  File ""C:\Users\User\Anaconda3\envs\tensortest\lib\site-packages\tensorflow_core\_api\v2\compat\v1\__init__.py"", line 32, in <module>
    from . import compat
  File ""C:\Users\User\Anaconda3\envs\tensortest\lib\site-packages\tensorflow_core\_api\v2\compat\v1\compat\__init__.py"", line 39, in <module>
    from . import v1
  File ""C:\Users\User\Anaconda3\envs\tensortest\lib\site-packages\tensorflow_core\_api\v2\compat\v1\compat\v1\__init__.py"", line 29, in <module>
    from tensorflow._api.v2.compat.v1 import app
  File ""C:\Users\User\Anaconda3\envs\tensortest\lib\site-packages\tensorflow_core\_api\v2\compat\__init__.py"", line 39, in <module>
    from . import v1
  File ""C:\Users\User\Anaconda3\envs\tensortest\lib\site-packages\tensorflow_core\_api\v2\compat\v1\__init__.py"", line 32, in <module>
    from . import compat
  File ""C:\Users\User\Anaconda3\envs\tensortest\lib\site-packages\tensorflow_core\_api\v2\compat\v1\compat\__init__.py"", line 40, in <module>
    from . import v2
  File ""C:\Users\User\Anaconda3\envs\tensortest\lib\site-packages\tensorflow_core\_api\v2\compat\v1\compat\v2\__init__.py"", line 30, in <module>
    from tensorflow._api.v2.compat.v2 import audio
  File ""C:\Users\User\Anaconda3\envs\tensortest\lib\site-packages\tensorflow_core\_api\v2\compat\v2\__init__.py"", line 33, in <module>
    from . import compat
  File ""C:\Users\User\Anaconda3\envs\tensortest\lib\site-packages\tensorflow_core\_api\v2\compat\v2\compat\__init__.py"", line 40, in <module>
    from . import v2
  File ""C:\Users\User\Anaconda3\envs\tensortest\lib\site-packages\tensorflow_core\_api\v2\compat\v2\compat\v2\__init__.py"", line 320, in <module>
    from tensorboard.summary._tf import summary
  File ""C:\Users\User\Anaconda3\envs\tensortest\lib\site-packages\tensorboard\summary\__init__.py"", line 31, in <module>
    from tensorboard.summary import v2
  File ""C:\Users\User\Anaconda3\envs\tensortest\lib\site-packages\tensorboard\summary\v2.py"", line 24, in <module>
    from tensorboard.plugins.audio.summary_v2 import audio
  File ""C:\Users\User\Anaconda3\envs\tensortest\lib\site-packages\tensorboard\plugins\audio\summary_v2.py"", line 30, in <module>
    from tensorboard.compat import tf2 as tf
  File ""C:\Users\User\Anaconda3\envs\tensortest\lib\site-packages\tensorboard\compat\__init__.py"", line 28, in <module>
    import tensorboard.lazy as _lazy
AttributeError: module 'tensorboard' has no attribute 'lazy'

Process finished with exit code 1
```
"
37432,Encountered unresolved custom op: BatchMatMulV2.,"**System information**
- OS Platform and Distribution (Pop!_OS 19.10):
- TensorFlow installed from (source or binary):python3 -m pip install
- TensorFlow version - 2.2.0-dev20200308
- TensorFlowLite version [0.0.0-nightly](https://bintray.com/google/tensorflow/tensorflow-lite/0.0.0-nightly#)

I was trying to convert a Transformer model to TfLite. It converted successfully with Python using the `converter.experimental_new_converter = True` and `converter.allow_custom_ops = True` but can't run it on android.


**Provide the text output from tflite_convert**

```
java.lang.IllegalArgumentException: Internal error: Failed to run on the given Interpreter: Encountered unresolved custom op: BatchMatMulV2.
2020-03-09 12:09:21.727 6025-6025/com.meiteimayek.transformertest W/System.err: Node number 31 (BatchMatMulV2) failed to prepare.
2020-03-09 12:09:21.727 6025-6025/com.meiteimayek.transformertest W/System.err:     at org.tensorflow.lite.NativeInterpreterWrapper.run(Native Method)
2020-03-09 12:09:21.727 6025-6025/com.meiteimayek.transformertest W/System.err:     at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:152)
2020-03-09 12:09:21.727 6025-6025/com.meiteimayek.transformertest W/System.err:     at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:296)
```

**Standalone code to reproduce the issue** 
```java

import android.app.Activity;
import android.content.res.AssetFileDescriptor;
import android.util.ArrayMap;
import android.util.Log;

import org.tensorflow.lite.Interpreter;

import java.io.FileInputStream;
import java.io.IOException;
import java.nio.ByteBuffer;
import java.nio.ByteOrder;
import java.nio.MappedByteBuffer;
import java.nio.channels.FileChannel;
import java.util.Arrays;
import java.util.Map;

public class Model {
  
  private Interpreter mInterpreter;
  
  public Model(Activity activity) throws IOException {
    float[] inp = {4, 25,  7, 25, 14, 15, 18, 20,  7,  5,  0,  0,  0,  0,  0,  0,  0,
      0,  0,  0,  0,  0,  0,  0};
    
    String name = ""model.tflite"";
    ByteBuffer input = ByteBuffer.allocate(4 * 24);
    ByteBuffer oInput = ByteBuffer.allocate(4 * 23);
    
    input.order(ByteOrder.nativeOrder());
    oInput.order(ByteOrder.nativeOrder());
    
  
    for(float v : inp) {
      input.putFloat(v);
    }
    float[] predicted = new float[1];
    
    oInput.putFloat(1);
    for(int i = 1; i < 23; i++) {
      oInput.putFloat(0);
    }
    Interpreter.Options op = new Interpreter.Options();
    
    mInterpreter = new Interpreter(getModel(activity, name), op);

    Map<Integer, Object> result = new ArrayMap<>();
    result.put(0, predicted);
    mInterpreter.runForMultipleInputsOutputs(new ByteBuffer[]{input, oInput}, result);
    Log.d(""TAG"", ""Model: Output "" + Arrays.toString((float[])result.get(0)));
  }
  
  private MappedByteBuffer getModel(Activity activity, String name) throws IOException {
    AssetFileDescriptor f = activity.getAssets().openFd(name);
    return new FileInputStream(f.getFileDescriptor())
      .getChannel()
      .map(FileChannel.MapMode.READ_ONLY, f.getStartOffset(), f.getDeclaredLength());
  }
}

```

TFlite Model Link - https://drive.google.com/open?id=1URF3USAEkOFaKCCOB7ctl_b2FxTVDWPx
"
37431,"undefined reference error while building Lite for ESP32 ""person_detection"" example","@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win7
- TensorFlow installed from (source or binary): source
- Tensorflow version (commit SHA if source): Latest version
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): ESP32

**Describe the problem**
I git the whole latest tensorflow branch on my WIN7 PC. I intended to use ""Tensorflow Lite for Micro"". I wanted to try the included examples ""Person Detection"" first to make sure everything works out of box. So I followed the readme instruction by running ""make -f tensorflow/lite/micro/tools/make/Makefile TARGET=esp generate_person_detection_esp_project"". According to the Makefile, five 3rd party downloads should be downloaded first. However, I got the MD5 mismatch error for each and every single one of them. So I had to 'hack' the Makefile to disable the MD5 checksum checking and manually downloaded those required 5 downloads and installed in the 'C:\Projects\tensorflow\tensorflow\lite\micro\tools\make\downloads' folder. 
Then the make seemed to run for a few minutes, the stopped at the following error:
[888/894] Building CXX object esp-idf/...core/api/flatbuffer_conversions.cc.obj
cc1plus.exe: warning: command line option '-std=c11' is valid for C/ObjC but not
 for C++
[893/894] Linking CXX executable person_detection.elf
FAILED: person_detection.elf
cmd.exe /C ""cd . && C:\Users\Tianhao\.espressif\tools\xtensa-esp32-elf\esp-2019r
2-8.2.0\xtensa-esp32-elf\bin\xtensa-esp32-elf-g++.exe  -mlongcalls -Wno-frame-ad
dress  -nostdlib @CMakeFiles\person_detection.elf.rsp  -o person_detection.elf
&& cd .""
c:/users/tianhao/.espressif/tools/xtensa-esp32-elf/esp-2019r2-8.2.0/xtensa-esp32
-elf/bin/../lib/gcc/xtensa-esp32-elf/8.2.0/../../../../xtensa-esp32-elf/bin/ld.e
xe: esp-idf/main/libmain.a(main_functions.cc.obj):(.literal.loop+0x14): undefine
d reference to `RespondToDetection(tflite::ErrorReporter*, unsigned char, unsign
ed char)'
c:/users/tianhao/.espressif/tools/xtensa-esp32-elf/esp-2019r2-8.2.0/xtensa-esp32
-elf/bin/../lib/gcc/xtensa-esp32-elf/8.2.0/../../../../xtensa-esp32-elf/bin/ld.e
xe: esp-idf/main/libmain.a(main_functions.cc.obj): in function `loop':
c:\projects\tensorflow\tensorflow\lite\micro\tools\make\gen\esp_xtensa-esp32\prj
\person_detection\esp-idf\build/../main/main_functions.cc:111: undefined referen
ce to `RespondToDetection(tflite::ErrorReporter*, unsigned char, unsigned char)'

collect2.exe: error: ld returned 1 exit status
ninja: build stopped: subcommand failed.
ninja failed with exit code 1

I also attached full log file for reference. Please show me how to fix this problem and get at least the example built and running. Thanks!

[build_log.txt](https://github.com/tensorflow/tensorflow/files/4304902/build_log.txt)

**Please provide the exact sequence of commands/steps when you ran into the problem**

"
37430,MKL Error on Bazel 2.0 (TensorFlow 2.1 latest - nightly),"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 10 x64 18363.693
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
- TensorFlow installed from (source or binary): from git
- TensorFlow version: TF 2.1 latest version
- Python version: 3.7/3.8
- Installed using virtualenv? pip? conda?: no
- Bazel version (if compiling from source): 2.0.0
- GCC/Compiler version (if compiling from source): VS 2019
- CUDA/cuDNN version: 10.2
- GPU model and memory: Nvidia 1070 ti



**Describe the problem**
At the initial stage of the build, an error appears.

C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC\Tools\MSVC\14.24.28314\include\xtr1common(163): note: see reference to class template instantiation 'std::integral_constant<bool,false>' being compiled
C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC\Tools\MSVC\14.24.28314\include\xtr1common(163): note: see reference to class template instantiation 'std::disjunction<_Traits...>' being compiled
ERROR: C:/tensorflow/tensorflow/core/kernels/BUILD:8128:1: C++ compilation of rule '//tensorflow/core/kernels:mkl_aggregate_ops' failed (Exit 2)
.\tensorflow/core/util/mkl_util.h(1253): error C2131: expression did not evaluate to a constant
.\tensorflow/core/util/mkl_util.h(1252): note: failure was caused by a read of a variable outside its lifetime
.\tensorflow/core/util/mkl_util.h(1252): note: see usage of 'dim'
.\tensorflow/core/util/mkl_util.h(1254): error C2131: expression did not evaluate to a constant
.\tensorflow/core/util/mkl_util.h(1252): note: failure was caused by a read of a variable outside its lifetime
.\tensorflow/core/util/mkl_util.h(1252): note: see usage of 'dim'
.\tensorflow/core/util/mkl_util.h(1256): error C3863: array type 'dnnl_dim_t [kNumDims]' is not assignable
.\tensorflow/core/util/mkl_util.h(1257): error C3863: array type 'dnnl_dim_t [kNumDims]' is not assignable
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 2448.446s, Critical Path: 179.48s
INFO: 4686 processes: 4686 local.
FAILED: Build did NOT complete successfully
"
37429,"Wrong Error Massage, when passing wrong datatype to tf.TensorArray","Hi, 
I hope i picked the right issue type, not sure if documentation or implementation was the right category

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): No
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Linux Mint 19.3 (ubuntu)
- TensorFlow installed from (source or
binary): binatry
- TensorFlow version (use command below): both tf-nightly and tf-2.1
- Python version: 3.8 and 3.6

**Describe the current behavior**
tf.TensorArray(dtype=tf.float32, size=tf.cast(5, dtype = tf.float32), dynamic_size=False)

Error: Unreachable

**Describe the expected behavior**
Error: Expected dtype int32 not dtype float32 for size argument

**Standalone code to reproduce the issue** 
'''
tf.TensorArray(dtype=tf.float32, size=tf.cast(5, dtype = tf.float32), dynamic_size=False)
'''"
37428,tf.Graph.get_tensor_by_name does not work as expected in TF2,"**System information** 
- Have I written custom code: yes
- OS Platform and Distribution: Max OSX 10.15.3 (Catalina) 
- Mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version: v2.1.0-rc2-17-ge5bf8de410 2.1.0
- Python version: 3.7.6
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source):  N/A
- CUDA/cuDNN version: - GPU model and memory: N/A

**Describe the current behavior**
`tf.Graph.get_tensor_by_name` returns 'resource' dtype tensors, which do not evaluate as expected in a session. For example, the code below will return something like:

```
array([( 10,), ( 44,), ( 47,), (106,), (111,), ( 98,), ( 58,), (108,),
       (111,), ( 99,), ( 97,), (108,), (104,), (111,), (115,), (116,),
       ( 47,), (114,), (101,), (112,), (108,), (105,), ( 99,), ( 97,),
       ( 58,), ( 48,), ( 47,), (116,), ( 97,), (115,), (107,), ( 58,),
       ( 48,), ( 47,), (100,), (101,), (118,), (105,), ( 99,), (101,),
       ( 58,), ( 67,), ( 80,), ( 85,), ( 58,), ( 48,), ( 18,), (  9,),
       (108,), (111,), ( 99,), ( 97,), (108,), (104,), (111,), (115,),
       (116,), ( 26,), (  1,), (120,), ( 32,), (224,), (167,), (192,),
       (135,), ( 18,), ( 42,), ( 18,), ( 78,), ( 49,), ( 48,), (116,),
       (101,), (110,), (115,), (111,), (114,), (102,), (108,), (111,),
       (119,), ( 51,), ( 86,), ( 97,), (114,), ( 69,), ( 50,), (  4,),
       (  8,), (  3,), ( 18,), (  0,)], dtype=[('resource', 'u1')])
```

**Describe the expected behavior**
Expect v1 compatible code to work as it does in TF1.X. In particular, the code below should return `3`.

**Standalone code to reproduce the issue** 
```python
import tensorflow.compat.v1 as tf
tf.disable_eager_execution()
x = tf.Variable(3, name='x')
y = tf.get_default_graph().get_tensor_by_name('x:0')
with tf.Session() as sess:
  sess.run(y)
```

**Other info / logs** 
- When instantiating a `tf.Variable`:
 ```
WARNING:tensorflow:From /Users/shermes/Projects/tensorflow/venv2/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
```
- From `sess.run` block: 
```
/Users/shermes/Projects/tensorflow/venv2/lib/python3.7/site-packages/tensorflow_core/python/client/session.py:1445: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
```
(This error shows up when using numpy 1.16 as well as 1.17 and 1.18.)


"
37427,Add logging to intermediate layers in TFLite,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 1.15
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**
Currently tflite reuses memory for intermediate to limit its memory footprint on resource constrained devices as discussed [here](https://stackoverflow.com/questions/56885007/visualize-tflite-graph-and-get-intermediate-values-of-a-particular-node). This makes it hard to debug to what is happening at the intermediate layers on the final hardware (especially when using a delegate). The proposal is to add logging functionality to enable visibility into these intermediate layers.

**Will this change the current api? How?**
A candidate proposal is to add an api function to mark all/selected operation outputs as model outputs and then allow them to be inspected in the python interpreter.

**Who will benefit with this feature?**
Any developer trying to debug what is happening on an embedded tflite implementation

**Any Other info.**
"
37426,NotFoundError: No registered 'Identity' OpKernel for 'TPU' devices compatible with node,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Google Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
- TensorFlow installed from (source or
binary): 
- TensorFlow version (use command below): 2.1.0
- Python version: - Bazel
version (if compiling from source):
- GCC/Compiler version (if compiling from
source): 
- CUDA/cuDNN version: - GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Throws error ""No registered 'Identity' OpKernel for 'TPU' devices compatible with node"".
Script uses efficientnet.tfkeras from efficientnet python package 1.1.0 (pip install efficientnet).

**Describe the expected behavior**
Script should start training on TPU.

**Standalone code to reproduce the issue** 
Google Colab:
https://drive.google.com/open?id=1QALjqGEX4z5vTBjRBUbyn5WmElYzMJzR

Public access to GCS bucket is granted.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

Model: ""sequential""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
efficientnet-b0 (Model)      (None, 1280)              4049564   
_________________________________________________________________
dense (Dense)                (None, 120)               153720    
_________________________________________________________________
dense_1 (Dense)              (None, 120)               14520     
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 242       
=================================================================
Total params: 4,218,046
Trainable params: 4,176,030
Non-trainable params: 42,016
_________________________________________________________________
WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.
WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.
[INFO] Modelul este salvat pe disc dupa fiecare epoca in formatul: nume_model_weights-epoca-training_set_accuracy-validation_set_accuracy.hdf5
Train for 17.0 steps, validate for 4.0 steps
Epoch 1/25
 0/17 [..............................] - ETA: 0s
---------------------------------------------------------------------------
NotFoundError                             Traceback (most recent call last)
<ipython-input-1-35a575cce5e2> in <module>()
    165     validation_data=valdataset,
    166     validation_steps=np.ceil(totalVal / BS),
--> 167     epochs=NUM_EPOCHS,
    168     #callbacks=[checkpointer],
    169 )

13 frames
/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)

NotFoundError: No registered 'Identity' OpKernel for 'TPU' devices compatible with node {{node Identity}}
	 (OpKernel was found, but attributes didn't match) Requested Attributes: T=DT_UINT8
	.  Registered:  device='XLA_GPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, ..., DT_HALF, DT_UINT32, DT_UINT64, DT_RESOURCE, DT_VARIANT]
  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, ..., DT_HALF, DT_UINT32, DT_UINT64, DT_RESOURCE, DT_VARIANT]
  device='XLA_TPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_BFLOAT16, DT_UINT32, DT_UINT64, DT_RESOURCE, DT_VARIANT]
  device='XLA_CPU'; T in [DT_UINT8, DT_QUINT8, DT_UINT16, DT_INT8, DT_QINT8, ..., DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128, DT_BOOL, DT_BFLOAT16]
  device='TPU'; T in [DT_INT32, DT_UINT32, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE, DT_BOOL, DT_COMPLEX64, DT_INT64, DT_UINT64]
  device='TPU_SYSTEM'
  device='GPU'; T in [DT_HALF]
  device='GPU'; T in [DT_BFLOAT16]
  device='GPU'; T in [DT_FLOAT]
  device='GPU'; T in [DT_DOUBLE]
  device='GPU'; T in [DT_INT64]
  device='GPU'; T in [DT_UINT16]
  device='GPU'; T in [DT_INT16]
  device='GPU'; T in [DT_UINT8]
  device='GPU'; T in [DT_INT8]
  device='GPU'; T in [DT_COMPLEX64]
  device='GPU'; T in [DT_COMPLEX128]
  device='GPU'; T in [DT_VARIANT]
  device='DEFAULT'; T in [DT_STRING]
  device='DEFAULT'; T in [DT_VARIANT]
  device='DEFAULT'; T in [DT_RESOURCE]
  device='CPU'

	 [[Identity]] [Op:MakeIterator]
"
37423,Failed to build TF 1.14 on Windows with CUDA 10.1,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 14393.0
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: branch r1.14
- Python version: 3.6.8
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source): 0.25.1
- GCC/Compiler version (if compiling from source): MSVC 14.24.28314 (Visual Studio 2019.4)
- CUDA/cuDNN version: 10.1/7.6.5
- GPU model and memory: GTX 1050 4GB

**Describe the problem**

I tried to compile TF 1.14 with CUDA 10.1 on windows several times and always encounter the following failure. There seems to be no related issues in this repo. I searched through the Internet and find nothing helpful. I am very appreciated if someone can help me.

```
H:\workspace\_bazel_cache\3wteafhd\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/util/Memory.h(85): warn
ing: ignoring return value from routine declared with ""nodiscard"" attribute

H:\workspace\_bazel_cache\3wteafhd\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/CwiseBinaryOp.h(105): w
arning: __host__ annotation is ignored on a function(""CwiseBinaryOp"") that is explicitly defaulted on its first declarat
ion

H:\workspace\_bazel_cache\3wteafhd\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/CwiseBinaryOp.h(105): w
arning: __device__ annotation is ignored on a function(""CwiseBinaryOp"") that is explicitly defaulted on its first declar
ation

.\tensorflow/core/kernels/cwise_ops.h(37): warning: type qualifier on return type is meaningless

.\tensorflow/core/kernels/cwise_ops.h(47): warning: type qualifier on return type is meaningless

.\tensorflow/core/kernels/cwise_ops.h(209): warning: __host__ annotation is ignored on a function(""scalar_left"") that is
 explicitly defaulted on its first declaration

.\tensorflow/core/kernels/cwise_ops.h(209): warning: __device__ annotation is ignored on a function(""scalar_left"") that
is explicitly defaulted on its first declaration

.\tensorflow/core/kernels/cwise_ops.h(239): warning: __host__ annotation is ignored on a function(""scalar_right"") that i
s explicitly defaulted on its first declaration

.\tensorflow/core/kernels/cwise_ops.h(239): warning: __device__ annotation is ignored on a function(""scalar_right"") that
 is explicitly defaulted on its first declaration

H:\workspace\_bazel_cache\3wteafhd\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/functors/UnaryFunctors.
h(112): warning: calling a __host__ function(""std::conj<float> "") from a __host__ __device__ function(""Eigen::internal::
scalar_conjugate_op<    ::std::complex<float> > ::operator () const"") is not allowed

H:\workspace\_bazel_cache\3wteafhd\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/Ten
sorExecutor.h(334): error: calling a __host__ function(""std::conj<float> "") from a __device__ function(""Eigen::internal:
:EigenMetaKernelEval< ::Eigen::TensorEvaluator<const  ::Eigen::TensorAssignOp< ::Eigen::TensorMap< ::Eigen::Tensor<    :
:std::complex<float> , (int)1, (int)1, int> , (int)16,  ::Eigen::MakePointer> , const  ::Eigen::TensorCwiseUnaryOp< ::Ei
gen::internal::scalar_conjugate_op<    ::std::complex<float> > , const  ::Eigen::TensorMap< ::Eigen::Tensor<const     ::
std::complex<float> , (int)1, (int)1, int> , (int)16,  ::Eigen::MakePointer> > > ,  ::Eigen::GpuDevice> , int, (bool)0>
::run"") is not allowed

H:\workspace\_bazel_cache\3wteafhd\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/Ten
sorExecutor.h(334): error: identifier ""std::conj<float> "" is undefined in device code

H:\workspace\_bazel_cache\3wteafhd\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/functors/UnaryFunctors.
h(112): warning: calling a __host__ function(""std::conj<double> "") from a __host__ __device__ function(""Eigen::internal:
:scalar_conjugate_op<    ::std::complex<double> > ::operator () const"") is not allowed

H:\workspace\_bazel_cache\3wteafhd\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/Ten
sorExecutor.h(334): error: calling a __host__ function(""std::conj<double> "") from a __device__ function(""Eigen::internal
::EigenMetaKernelEval< ::Eigen::TensorEvaluator<const  ::Eigen::TensorAssignOp< ::Eigen::TensorMap< ::Eigen::Tensor<
::std::complex<double> , (int)1, (int)1, int> , (int)16,  ::Eigen::MakePointer> , const  ::Eigen::TensorCwiseUnaryOp< ::
Eigen::internal::scalar_conjugate_op<    ::std::complex<double> > , const  ::Eigen::TensorMap< ::Eigen::Tensor<const
 ::std::complex<double> , (int)1, (int)1, int> , (int)16,  ::Eigen::MakePointer> > > ,  ::Eigen::GpuDevice> , int, (bool
)0> ::run"") is not allowed

H:\workspace\_bazel_cache\3wteafhd\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/Ten
sorExecutor.h(334): error: identifier ""std::conj<double> "" is undefined in device code

4 errors detected in the compilation of ""C:/Users/ASUS/AppData/Local/Temp/nvcc_inter_files_tmp_dir/cwise_op_gpu_conj.cu.
cpp1.ii"".
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 6617.850s, Critical Path: 192.36s
INFO: 4051 processes: 4051 local.
FAILED: Build did NOT complete successfully
```

**Provide the exact sequence of commands / steps that you executed before running into the problem**

`configure.py` output:
```
WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shut
down"".
You have bazel 0.25.1 installed.
Please specify the location of python. [Default is C:\Program Files\Python36\python.exe]:


Found possible Python library paths:
  C:\Program Files\Python36\lib\site-packages
Please input the desired Python library path to use.  Default is [C:\Program Files\Python36\lib\site-packages]

Do you wish to build TensorFlow with XLA JIT support? [y/N]:
No XLA JIT support will be enabled for TensorFlow.

Do you wish to build TensorFlow with ROCm support? [y/N]:
No ROCm support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: y
CUDA support will be enabled for TensorFlow.

Found CUDA 10.1 in:
    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1/lib/x64
    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1/include
Found cuDNN 7 in:
    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1/lib/x64
    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1/include


Please specify a list of comma-separated CUDA compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size, and that Te
nsorFlow only supports compute capabilities >= 3.5 [Default is: 3.5,7.0]: 6.1


Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is /a
rch:AVX]: /arch:AVX2


Would you like to override eigen strong inline for some C++ compilation to reduce the compilation time? [Y/n]:
Eigen strong inline overridden.

Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .baze
lrc for more details.
        --config=mkl            # Build with MKL support.
        --config=monolithic     # Config for mostly static monolithic build.
        --config=gdr            # Build with GDR support.
        --config=verbs          # Build with libverbs support.
        --config=ngraph         # Build with Intel nGraph support.
        --config=numa           # Build with NUMA support.
        --config=dynamic_kernels        # (Experimental) Build kernels into separate shared objects.
Preconfigured Bazel build configs to DISABLE default on features:
        --config=noaws          # Disable AWS S3 filesystem support.
        --config=nogcp          # Disable GCP support.
        --config=nohdfs         # Disable HDFS support.
        --config=noignite       # Disable Apache Ignite support.
        --config=nokafka        # Disable Apache Kafka support.
        --config=nonccl         # Disable NVIDIA NCCL support.
```
command used to build: `bazel build --config=opt --config=cuda --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package --jobs 2`

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
37418,How to gray images in Android?,"I want to identify the MNIST image on an Android device. How do I modify the following preprocessing code. How to grayscale the image


https://github.com/tensorflow/examples/blob/f812d2c36469823c8784e387f690f43ad9d17683/lite/examples/image_classification/android/app/src/main/java/org/tensorflow/lite/examples/classification/tflite/Classifier.java#L307
```java
    ImageProcessor imageProcessor =
        new ImageProcessor.Builder()
            .add(new ResizeWithCropOrPadOp(cropSize, cropSize))
            .add(new ResizeOp(imageSizeX, imageSizeY, ResizeMethod.NEAREST_NEIGHBOR))
            .add(new Rot90Op(numRoration))
            .add(getPreprocessNormalizeOp())
            .build();
    return imageProcessor.process(inputImageBuffer);
```"
37417,"tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [3,3,3,32] rhs shape= [3,3,1,32] 	 [[{{node save/Assign_78}}]]","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Mint 19.1
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 1.14
- Python version: 3.7
- Installed using virtualenv? pip? conda?: conda
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A



**Describe the problem**
Model: ssd_mobilenet_v2_quantized_300x300_coco.config

I am facing the issue of converting a custom trained model from checkpoint into inference graphs using the following commands:
`python export_tflite_ssd_graph.py \`
`--pipeline_config_path=/training/ssd_mobilenet_v2_quantized_300x300_coco.config \`
`--trained_checkpoint_prefix=/training/model.ckpt-1000 \`
`--output_directory=/inference_graph/ \`
`--add_postprocessing_op=true`

**Following is how my config file looks like:**
 ```
model {
  ssd {
    num_classes: 6
    box_coder {
      faster_rcnn_box_coder {
        y_scale: 10.0
        x_scale: 10.0
        height_scale: 5.0
        width_scale: 5.0
      }
    }
    matcher {
      argmax_matcher {
        matched_threshold: 0.5
        unmatched_threshold: 0.5
        ignore_thresholds: false
        negatives_lower_than_unmatched: true
        force_match_for_each_row: true
      }
    }
    similarity_calculator {
      iou_similarity {
      }
    }
    anchor_generator {
      ssd_anchor_generator {
        num_layers: 6
        min_scale: 0.2
        max_scale: 0.95
        aspect_ratios: 1.0
        aspect_ratios: 2.0
        aspect_ratios: 0.5
        aspect_ratios: 3.0
        aspect_ratios: 0.3333
      }
    }
    image_resizer {
      fixed_shape_resizer {
        height: 300
        width: 300
      }
    }
    box_predictor {
      convolutional_box_predictor {
        min_depth: 0
        max_depth: 0
        num_layers_before_predictor: 0
        use_dropout: false
        dropout_keep_probability: 0.8
        kernel_size: 1
        box_code_size: 4
        apply_sigmoid_to_scores: false
        conv_hyperparams {
          activation: RELU_6,
          regularizer {
            l2_regularizer {
              weight: 0.00004
            }
          }
          initializer {
            truncated_normal_initializer {
              stddev: 0.03
              mean: 0.0
            }
          }
          batch_norm {
            train: true,
            scale: true,
            center: true,
            decay: 0.9997,
            epsilon: 0.001,
          }
        }
      }Following is how my config file looks like:
    }
    feature_extractor {
      type: 'ssd_mobilenet_v2'
      min_depth: 16
      depth_multiplier: 1.0
      conv_hyperparams {
        activation: RELU_6,
        regularizer {
          l2_regularizer {
            weight: 0.00004
          }
        }
        initializer {
          truncated_normal_initializer {
            stddev: 0.03
            mean: 0.0
          }
        }
        batch_norm {
          train: true,
          scale: true,
          center: true,
          decay: 0.9997,
          epsilon: 0.001,
        }
      }
    }
    loss {
      classification_loss {
        weighted_sigmoid {
        }
      }
      localization_loss {
        weighted_smooth_l1 {
        }
      }
      hard_example_miner {
        num_hard_examples: 3000
        iou_threshold: 0.99
        loss_type: CLASSIFICATION
        max_negatives_per_positive: 3
        min_negatives_per_image: 3
      }
      classification_weight: 1.0
      localization_weight: 1.0
    }
    normalize_loss_by_num_matches: true
    post_processing {
      batch_non_max_suppression {
        score_threshold: 1e-8
        iou_threshold: 0.6
        max_detections_per_class: 100
        max_total_detections: 100
      }
      score_converter: SIGMOID
    }
  }
}

train_config: {
  batch_size: 5
  optimizer {
    rms_prop_optimizer: {
      learning_rate: {
        exponential_decay_learning_rate {
          initial_learning_rate: 0.004
          decay_steps: 800720
          decay_factor: 0.95
        }
      }
      momentum_optimizer_value: 0.9
      decay: 0.9
      epsilon: 1.0
    }
  }
  fine_tune_checkpoint: ""/object_detection/ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03/model.ckpt""
  fine_tune_checkpoint_type:  ""detection""
  num_steps: 1000
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
  data_augmentation_options {
    ssd_random_crop {
    }
  }
  data_augmentation_options {
    random_rgb_to_gray {
    }
  }

 data_augmentation_options {
    random_adjust_brightness {
    }
  }

 data_augmentation_options {
    random_adjust_contrast {
    }
  }
  
 data_augmentation_options {
    random_adjust_hue {
    }
  }
  
  
 data_augmentation_options {
    random_adjust_saturation {
    }
  }
  
  
 data_augmentation_options {
    rgb_to_gray {
    }
  }
}

train_input_reader: {
  tf_record_input_reader {
    input_path: ""/object_detection/train.record""
  }
  label_map_path: ""/object_detection/training/labelmap.pbtxt""
}

eval_config: {
  num_examples: 3
  max_evals: 10
}

eval_input_reader: {
  tf_record_input_reader {
    input_path: ""/object_detection/test.record""
  }
  label_map_path: ""/object_detection/training/labelmap.pbtxt""
  shuffle: false
  num_readers: 1
}

graph_rewriter {
  quantization {
    delay: 48000
    weight_bits: 8
    activation_bits: 8
  }
} 
```
**Provide the exact sequence of commands / steps that you executed before running into the problem**
I have added the following lines of code for augmentation in the config file:
 ```
 data_augmentation_options {
    random_rgb_to_gray {
    }
  }

 data_augmentation_options {
    random_adjust_brightness {
    }
  }

 data_augmentation_options {
    random_adjust_contrast {
    }
  }
  
 data_augmentation_options {
    random_adjust_hue {
    }
  }
  
  
 data_augmentation_options {
    random_adjust_saturation {
    }
  }
  
  
 data_augmentation_options {
    rgb_to_gray {
    }
  }

```

**Any other info / logs**
Here is the error, I want to know the cause of the error and that, does addition of augmentation in config  also requires any other change?
 ```
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold
I0307 23:21:08.443011 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold
I0307 23:21:08.443283 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold
I0307 23:21:08.443521 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold
I0307 23:21:08.443677 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold
I0307 23:21:08.443905 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold
I0307 23:21:08.444058 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold
I0307 23:21:08.444283 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold
I0307 23:21:08.444431 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold
I0307 23:21:08.444655 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold
I0307 23:21:08.444802 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold
I0307 23:21:08.445024 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold
I0307 23:21:08.445170 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold
I0307 23:21:08.445389 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold
I0307 23:21:08.445536 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold
I0307 23:21:08.445757 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold
I0307 23:21:08.445903 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold
I0307 23:21:08.446130 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold
I0307 23:21:08.446278 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold
I0307 23:21:08.446502 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold
I0307 23:21:08.446648 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold
I0307 23:21:08.446869 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold
I0307 23:21:08.447014 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold
I0307 23:21:08.447235 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold
I0307 23:21:08.447381 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold
I0307 23:21:08.447600 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold
I0307 23:21:08.447747 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold
I0307 23:21:08.447968 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold
I0307 23:21:08.448114 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold
I0307 23:21:08.448335 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold
I0307 23:21:08.448482 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold
I0307 23:21:08.448699 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold
I0307 23:21:08.448843 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold
I0307 23:21:08.449064 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold
I0307 23:21:08.449210 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold
I0307 23:21:08.449432 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold
I0307 23:21:08.449569 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold
I0307 23:21:08.449709 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold
I0307 23:21:08.449849 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold
I0307 23:21:08.449984 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold
I0307 23:21:08.450125 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold
I0307 23:21:08.450264 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold
I0307 23:21:08.450404 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold
I0307 23:21:08.450541 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold
WARNING:tensorflow:From /root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/object_detection-0.1-py3.6.egg/object_detection/export_tflite_ssd_graph_lib.py:259: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0307 23:21:08.452883 140338966099776 deprecation_wrapper.py:119] From /root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/object_detection-0.1-py3.6.egg/object_detection/export_tflite_ssd_graph_lib.py:259: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From /root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
W0307 23:21:08.877874 140338966099776 deprecation.py:323] From /root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
INFO:tensorflow:Restoring parameters from /home/models/research/object_detection/training/model.ckpt-0
I0307 23:21:09.683899 140338966099776 saver.py:1280] Restoring parameters from /home/models/research/object_detection/training/model.ckpt-0
Traceback (most recent call last):
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1356, in _do_call
    return fn(*args)
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1341, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1429, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [3,3,3,32] rhs shape= [3,3,1,32]
	 [[{{node save/Assign_78}}]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 1286, in restore
    {self.saver_def.filename_tensor_name: save_path})
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 950, in run
    run_metadata_ptr)
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1173, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1350, in _do_run
    run_metadata)
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1370, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [3,3,3,32] rhs shape= [3,3,1,32]
	 [[node save/Assign_78 (defined at /root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/object_detection-0.1-py3.6.egg/object_detection/export_tflite_ssd_graph_lib.py:259) ]]

Errors may have originated from an input operation.
Input Source operations connected to node save/Assign_78:
 FeatureExtractor/MobilenetV2/Conv/weights (defined at /root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/slim-0.1-py3.6.egg/nets/mobilenet/mobilenet.py:277)

Original stack trace for 'save/Assign_78':
  File ""export_tflite_ssd_graph.py"", line 137, in <module>
    tf.app.run(main)
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""export_tflite_ssd_graph.py"", line 133, in main
    FLAGS.max_classes_per_detection)
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/object_detection-0.1-py3.6.egg/object_detection/export_tflite_ssd_graph_lib.py"", line 259, in export_tflite_graph
    saver = tf.train.Saver(**saver_kwargs)
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 825, in __init__
    self.build()
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 837, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 875, in _build
    build_restore=build_restore)
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 508, in _build_internal
    restore_sequentially, reshape)
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 350, in _AddRestoreOps
    assign_ops.append(saveable.restore(saveable_tensors, shapes))
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/training/saving/saveable_object_util.py"", line 72, in restore
    self.op.get_shape().is_fully_defined())
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py"", line 227, in assign
    validate_shape=validate_shape)
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py"", line 66, in assign
    use_locking=use_locking, name=name)
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 788, in _apply_op_helper
    op_def=op_def)
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3616, in create_op
    op_def=op_def)
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 2005, in __init__
    self._traceback = tf_stack.extract_stack()


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""export_tflite_ssd_graph.py"", line 137, in <module>
    tf.app.run(main)
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""export_tflite_ssd_graph.py"", line 133, in main
    FLAGS.max_classes_per_detection)
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/object_detection-0.1-py3.6.egg/object_detection/export_tflite_ssd_graph_lib.py"", line 273, in export_tflite_graph
    initializer_nodes='')
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/tools/freeze_graph.py"", line 151, in freeze_graph_with_def_protos
    saver.restore(sess, input_checkpoint)
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 1322, in restore
    err, ""a mismatch between the current graph and the graph"")
tensorflow.python.framework.errors_impl.InvalidArgumentError: Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:

Assign requires shapes of both tensors to match. lhs shape= [3,3,3,32] rhs shape= [3,3,1,32]
	 [[node save/Assign_78 (defined at /root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/object_detection-0.1-py3.6.egg/object_detection/export_tflite_ssd_graph_lib.py:259) ]]

Errors may have originated from an input operation.
Input Source operations connected to node save/Assign_78:
 FeatureExtractor/MobilenetV2/Conv/weights (defined at /root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/slim-0.1-py3.6.egg/nets/mobilenet/mobilenet.py:277)

Original stack trace for 'save/Assign_78':
  File ""export_tflite_ssd_graph.py"", line 137, in <module>
    tf.app.run(main)
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""export_tflite_ssd_graph.py"", line 133, in main
    FLAGS.max_classes_per_detection)
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/object_detection-0.1-py3.6.egg/object_detection/export_tflite_ssd_graph_lib.py"", line 259, in export_tflite_graph
    saver = tf.train.Saver(**saver_kwargs)
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 825, in __init__
    self.build()
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 837, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 875, in _build
    build_restore=build_restore)
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 508, in _build_internal
    restore_sequentially, reshape)
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 350, in _AddRestoreOps
    assign_ops.append(saveable.restore(saveable_tensors, shapes))
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/training/saving/saveable_object_util.py"", line 72, in restore
    self.op.get_shape().is_fully_defined())
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py"", line 227, in assign
    validate_shape=validate_shape)
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py"", line 66, in assign
    use_locking=use_locking, name=name)
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 788, in _apply_op_helper
    op_def=op_def)
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3616, in create_op
    op_def=op_def)
  File ""/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 2005, in __init__
    self._traceback = tf_stack.extract_stack()
```"
37416,Precision at top_k does not compute the precision *on average* as stated in the API,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:

https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Precision

## Description of issue (what needs changing):
This method does not compute the precision *on average* when top_k is set. This could lead to bad evaluations, especially when the sample_weight is set and used as counts.

### Clear description

To see the issue, it's enough to run 
```
m = tf.keras.metrics.Precision(top_k=2)
m.update_state([0, 0, 1, 1], [1, 1, 1., 1.])

print('Final result: ', m.result().numpy()) # Returns 0 but should return 0.5
```
It always computes the precision according to the given order and returns 0. However it should return 0.5 if it's on average.
"
37415,Tensorflow2.0 is not supporting this code,Tensorflow2.0 is not supporting this `tf.contrib.training.bucket_by_sequence_length` and what can I use instead of this 
37414,"ValueError: No gradients provided for any variable: ['dense_26/kernel:0', 'dense_26/bias:0']","**System information** 
- OS Platform and Distribution: Windows 10

- TensorFlow installed from Anaconda 1.9.12. Channel: default.
Tensorflow Version: 2.1.0

- Python version: 3.7.6

- CUDA/cuDNN version:
cudatoolkit: 10.1.243
cuDNN: 7.6.5

- GPU: NVidia GeForce GTX 1060, 6 GB

**Describe the current behavior**
I've been developing a Relativistic Style GAN, but when I try to train the discriminator, I keep getting ValueError: No gradients provided for any variable. I replaced the generator and discriminator with empty dummies in order to figure out what was causing the problem, but I still got the error.

I suspect the loss function for while but then I recalled a simple functional non-style version of the RaGAN script used to work fine and without errors during training and produced blurry but recognizable results. When I tried that script again, I got this gradient error as well.

I'm stumped at what could be causing this error.

**Standalone code to reproduce the issue** 
I'm new to GitHub and couldn't manage to past the code in a coherent way so here's
a link to the Jupyter Notebook that replicates the problem:
[MyBuggyRelStyle](https://github.com/beardwolf/beardwolf/blob/master/MyBuggyRelStyle.ipynb)

**Other info / logs** Include any logs or source code that would be helpful to
`---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-55-39aabbcfc7eb> in <module>
     20         z = np.random.normal(scale=.25, size=(batch_size, dl_size))
     21         z2 = np.random.normal(scale=.25, size=(batch_size, dl_size))
---> 22         disc_loss.append(disc_train.train_on_batch([data, z, z2], dummy_y))
     23 
     24         gen.trainable = True

~\Anaconda3\envs\deep-learning-gpu\lib\site-packages\tensorflow_core\python\keras\engine\training.py in train_on_batch(self, x, y, sample_weight, class_weight, reset_metrics)
   1076           self, x, y=y, sample_weight=sample_weight,
   1077           class_weight=class_weight, reset_metrics=reset_metrics,
-> 1078           standalone=True)
   1079       outputs = (outputs['total_loss'] + outputs['output_losses'] +
   1080                  outputs['metrics'])

~\Anaconda3\envs\deep-learning-gpu\lib\site-packages\tensorflow_core\python\keras\engine\training_v2_utils.py in train_on_batch(model, x, y, sample_weight, class_weight, reset_metrics, standalone)
    431       y,
    432       sample_weights=sample_weights,
--> 433       output_loss_metrics=model._output_loss_metrics)
    434 
    435   if reset_metrics:

~\Anaconda3\envs\deep-learning-gpu\lib\site-packages\tensorflow_core\python\eager\def_function.py in __call__(self, *args, **kwds)
    566         xla_context.Exit()
    567     else:
--> 568       result = self._call(*args, **kwds)
    569 
    570     if tracing_count == self._get_tracing_count():

~\Anaconda3\envs\deep-learning-gpu\lib\site-packages\tensorflow_core\python\eager\def_function.py in _call(self, *args, **kwds)
    604       # In this case we have not created variables on the first call. So we can
    605       # run the first trace but we should fail if variables are created.
--> 606       results = self._stateful_fn(*args, **kwds)
    607       if self._created_variables:
    608         raise ValueError(""Creating variables on a non-first call to a function""

~\Anaconda3\envs\deep-learning-gpu\lib\site-packages\tensorflow_core\python\eager\function.py in __call__(self, *args, **kwargs)
   2360     """"""Calls a graph function specialized to the inputs.""""""
   2361     with self._lock:
-> 2362       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
   2363     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
   2364 

~\Anaconda3\envs\deep-learning-gpu\lib\site-packages\tensorflow_core\python\eager\function.py in _maybe_define_function(self, args, kwargs)
   2698           and self.input_signature is None
   2699           and call_context_key in self._function_cache.missed):
-> 2700         return self._define_function_with_shape_relaxation(args, kwargs)
   2701 
   2702       self._function_cache.missed.add(call_context_key)

~\Anaconda3\envs\deep-learning-gpu\lib\site-packages\tensorflow_core\python\eager\function.py in _define_function_with_shape_relaxation(self, args, kwargs)
   2630         relaxed_arg_shapes)
   2631     graph_function = self._create_graph_function(
-> 2632         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)
   2633     self._function_cache.arg_relaxed[rank_only_cache_key] = graph_function
   2634 

~\Anaconda3\envs\deep-learning-gpu\lib\site-packages\tensorflow_core\python\eager\function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   2591             arg_names=arg_names,
   2592             override_flat_arg_shapes=override_flat_arg_shapes,
-> 2593             capture_by_value=self._capture_by_value),
   2594         self._function_attributes,
   2595         # Tell the ConcreteFunction to clean up its graph once it goes out of

~\Anaconda3\envs\deep-learning-gpu\lib\site-packages\tensorflow_core\python\framework\func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    976                                           converted_func)
    977 
--> 978       func_outputs = python_func(*func_args, **func_kwargs)
    979 
    980       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

~\Anaconda3\envs\deep-learning-gpu\lib\site-packages\tensorflow_core\python\eager\def_function.py in wrapped_fn(*args, **kwds)
    437         # __wrapped__ allows AutoGraph to swap in a converted function. We give
    438         # the function a weak reference to itself to avoid a reference cycle.
--> 439         return weak_wrapped_fn().__wrapped__(*args, **kwds)
    440     weak_wrapped_fn = weakref.ref(wrapped_fn)
    441 

~\Anaconda3\envs\deep-learning-gpu\lib\site-packages\tensorflow_core\python\framework\func_graph.py in wrapper(*args, **kwargs)
    966           except Exception as e:  # pylint:disable=broad-except
    967             if hasattr(e, ""ag_error_metadata""):
--> 968               raise e.ag_error_metadata.to_exception(e)
    969             else:
    970               raise

ValueError: in converted code:

    C:\Users\Hudson\Anaconda3\envs\deep-learning-gpu\lib\site-packages\tensorflow_core\python\keras\engine\training_eager.py:305 train_on_batch  *
        outs, total_loss, output_losses, masks = (
    C:\Users\Hudson\Anaconda3\envs\deep-learning-gpu\lib\site-packages\tensorflow_core\python\keras\engine\training_eager.py:273 _process_single_batch
        model.optimizer.apply_gradients(zip(grads, trainable_weights))
    C:\Users\Hudson\Anaconda3\envs\deep-learning-gpu\lib\site-packages\tensorflow_core\python\keras\optimizer_v2\optimizer_v2.py:426 apply_gradients
        grads_and_vars = _filter_grads(grads_and_vars)
    C:\Users\Hudson\Anaconda3\envs\deep-learning-gpu\lib\site-packages\tensorflow_core\python\keras\optimizer_v2\optimizer_v2.py:1039 _filter_grads
        ([v.name for _, v in grads_and_vars],))

    ValueError: No gradients provided for any variable: ['dense_26/kernel:0', 'dense_26/bias:0'].
0
1
Python 3 | Idle
MyBuggyRelStyle.ipynb
Ln 22, Col 1
`
"
37413,random output ," the chat i created it doesn't work correctly i guess it keep givin me this kind of result no matter how much time i train it 
 

> python3 ./translate.py  --en_vocab_size=40000 --fr_vocab_size=40000 --data_dir=/home/baba055h_s/ --train_dir=/home/baba055h_s/ --decode
/home/baba055h_s/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:463: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([(""qint8"", np.int8, 1)])
/home/baba055h_s/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:464: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([(""quint8"", np.uint8, 1)])
/home/baba055h_s/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:465: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([(""qint16"", np.int16, 1)])
/home/baba055h_s/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:466: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([(""quint16"", np.uint16, 1)])
/home/baba055h_s/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:467: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([(""qint32"", np.int32, 1)])
WARNING:tensorflow:From /home/baba055h_s/ten3/tensorflow/tensorflow/models/rnn/translate/seq2seq_model.py:188 in __init__.: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.
Instructions for updating:
Please use tf.global_variables instead.
Created model with fresh parameters.
WARNING:tensorflow:From ./translate.py:138 in create_model.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.
Instructions for updating:
Use `tf.global_variables_initializer` instead.
/> hi
sample sample sample sample sample sample sample sample letter-sized letter-sized
>/> what's up
sample sample sample soil soil soil neski neski neski neski

> as you notice the result are random 10 words at least and some words are repeated  like this :""sample sample sample soil soil soil neski neski neski neski""




>>i'm using 
tensorflow 0.12.1
translate script with branch r0.11
prepare data using this script
https://github.com/b0noI/dialog_converter/tree/master
i trained it up to 4000 time and the same thing

see what is that all about is it something wrong with the data i provided
please help me "
37412,Cannot get accuracy for vgg19 in tflite,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu16.04
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:
- **TensorFlow installed from (source or binary)**: pip3(20.02)
- **TensorFlow version (use command below)**: 2.1
- **Python version**: 3.6.9
- **Bazel version (if compiling from source)**:2.0.0
- **GCC/Compiler version (if compiling from source)**: 7.4.0
- **CUDA/cuDNN version**: 10.1
- **GPU model and memory**: 1060 GTX - 6GB
- **Exact command to reproduce**: 
bazel-bin/tensorflow/lite/tools/accuracy/ilsvrc/imagenet_accuracy_eval --model_file=../tensorflow_tests/models/vgg19.tflite --ground_truth_images_path=../val_imagenet/ --ground_truth_labels=ground_truth.txt --model_output_labels=./labels.txt --output_file_path=../vgg19_output_acc.txt --num_images=10

### Describe the problem
I have been running tflite accuracy script as defined [here](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/accuracy/ilsvrc) and I am able to run successfully, but when I am running the script for resnet or mobilenet, I am getting proper accurate results from top1 to top10, but when I am trying same with vgg19, I am not getting the  accuracy instead I am getting all values as zero or very low as below

Top 1, Top 2, Top 3, Top 4, Top 5, Top 6, Top 7, Top 8, Top 9, Top 10
0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000
0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000
0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000
0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000
0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000
0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000
0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000
0.000, 0.000, 0.000, 12.500, 12.500, 12.500, 12.500, 12.500, 12.500, 12.500
0.000, 0.000, 0.000, 11.111, 22.222, 22.222, 22.222, 22.222, 22.222, 22.222

I tried changing the model_labels text file, but it's not working.

do I am making any mistake with vgg19 or what is happening?
Thanks in advance
"
37410,Center Loss in TF 2.0,"I am trying to implement center loss in Tensorflow 2.0 by referring to code in following repositories:

- https://github.com/handongfeng/MNIST-center-loss

- https://github.com/mjDelta/keras-center-loss-MNIST

- https://github.com/Kakoedlinnoeslovo/center_loss

I noticed that some arguments in the method ""self.add_update((self.centers,new_centers),x)"" when creating a custom layer, are deprecated. The code (linked above) does not throw any error, but the centers are never updated when run in Tensorflow 2.0. 

You can find the related description for the problem here:
https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/engine/base_layer.py#L1170-L1259

I am trying to update the weights of the layer after every forward pass so I can use it as tf.Variable which can persist the updated centroids for the next iteration.

Any help on this would be appreciated.
Thanks
"
37409,OperatorNotAllowedInGraphError occur when using tf.function,"**System information**
Python 3.6.9 on Ubuntu 18.04

Using tensorflow 2.1.0-

GPU Hardware: Quadro P6000

**Issue description:**
I try to use a map function to split a string to multiple tensors. with following sample code:
```python
@tf.function
def csv_text_parse(line):
    f0, f1, f2 = tf.strings.split(line, sep=',')
    return f0, f1, f2

csv_text_parse(b'0,2,hello')
```
![image](https://user-images.githubusercontent.com/731496/76136765-2fa27100-6070-11ea-9306-ad3279481df4.png)

but if change the above function to:
```python
@tf.function
def csv_text_parse2(line):
    return tf.strings.split(line, sep=',')
```

the result will be fine. "
37407, Tensorflow2.1.compat.v1 distributed training occasionally goes wrong,"`TaskIndex: 4 | Episode: 1995/100000  | Episode Reward: 52.2229  | Running Time: 7.6459 | EnvStep Time: 0.7538 | Render Time: 0.0000
TaskIndex: 1 | Episode: 1984/100000  | Episode Reward: 2.9837  | Running Time: 7.6459 | EnvStep Time: 1.4454 | Render Time: 0.0000
TaskIndex: 6 | Episode: 1992/100000  | Episode Reward: 8.1637  | Running Time: 7.6850 | EnvStep Time: 1.0630 | Render Time: 0.0000
TaskIndex: 0 | Episode: 2004/100000  | Episode Reward: -60.5018  | Running Time: 5.3829 | EnvStep Time: 2.2781 | Render Time: 0.9659
2020-03-07 09:55:22.138197: I tensorflow/core/202distri0b-03uted-07 09_runtime/worker:55:22..138233: Ic c:t2enso04]rfl Caowncell/coaretion /dreqistriuebuted_rsted untifor meRun/worker.cc:2Grap04]h.
 Cancellation requested for RunGraph.
2020-03-07 09:55:22.138365: I tensorflow/core/distributed_runtime/worker.cc:204] Can202cella0-tio03-07n  09:55:22re.13850que8: Ested  tensorflfor owRu/conGrre/aphdistribu.
ted_runtime/master_session.cc:1911] Cleanup partition error: Unavailable: Stream removed
Additional GRPC error information:
{""created"":""@1583546122.138000000"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Stream removed"",""grpc_status"":2}
2020-03-07 09:55:22.1382029208220-03-: 02020-03-07 09:55:22.139043: I tensorflow20/2c0-03-07 09:55o:20-Ir2e/d tensorflow/core/distributed_runtime/worker.cc:204] Cancellation reques2020ted- fo0r3- 07 09R7u 0n9::55250205.:122.1:39014:2G2 r.I1a 3ptensorfh9l.2o
08: I tensorflow/core/distributed_runtime/worker.cc:204] Cancellation requested for RunGraph.
03-07 09:55:22.w/core/distributed_runtime/worker.cc:204] Cancellation reistrq-03-07 0u138993eis39089: I tensorflow/core/distributed_runtime/worker.cc:204] Cancellation reqt: eb9u:Idu e5 fosted for RunGraph.
5te:tnesod2r_2f.lo1rw3u/9nctoirmee//2wdistributed_runtime/worker.cc:204] Can7ocrkelelr6a:.tion  Ir ctensorflow/core/distributed_ruce:q2un0et4si]tmee d/C wafoornrkc eeRru.nGclcrl:ar Rph.2a
04] Cancellation requested for RunGraph.
tion requested for RunGraph.
unGraph.
2020-03-07 09:55:22.588608: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found
2020-03-07 09:55:22.588719: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
C:\Users\zkx74\Anaconda3\envs\RL\lib\site-packages\pandas_datareader\compat\__init__.py:7: FutureWarning:

pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.`

It can train normally for aobut hundreds episode, and the throw this error message.
I used 1ps and 8 worker on 1CPU+1GPU"
37405,TensorFlow 2.1.0: _FallbackException: This function does not handle the case of the path where all inputs are not already EagerTensors,"I am writing a custom loss function which involves another (already trained) neural network, called model_weight, evaluating predictions on the input of the model I'm currently training:
Code to fully reproduce: [https://colab.research.google.com/gist/adisurtya/387383b8f4e518dbb938ecd1af87b982/37405_full.ipynb](url)

Where the issue is: 
```
def weight(d):
  f = model_weight.predict(d,steps = 1)
  return (f)/(1-f)

myinputs = Input(shape=(1,), dtype = tf.float32)
x = Dense(128, activation='relu')(myinputs)
x2 = Dense(128, activation='relu')(x)
predictions = Dense(1, activation='sigmoid')(x2)
model = Model(inputs=myinputs, outputs=predictions)
model.summary()

def my_loss_wrapper(inputs,val=0):
  x  = inputs
  theta = 0. #starting value
  #theta0 = tf.constant(val, dtype= tf.float32)#target value

  #creating tensor (filled with 1s) with same shape as inputs; multiply by val
  theta0_stack = K.ones_like(x, dtype=tf.float32)*val 

  #combining and reshaping into correct format:
  data = K.stack((x, theta0_stack), axis=-1) 
  data = K.squeeze(data, axis = 1)
  #slice data to 500 entries to match batch_size
  data = K.gather(data, np.arange(500))
  print(data.shape)

  w = weight(data)

  def my_loss(y_true,y_pred):
    t_loss = K.mean(y_true*(y_true - y_pred)**2+(w)**2*(1.-y_true)*(y_true - y_pred)**2)
    return t_loss

  return my_loss

model.compile(optimizer='adam', loss=my_loss_wrapper(myinputs,theta),metrics=['accuracy'])
model.fit(np.array(X_train), y_train, epochs=1, batch_size=500,validation_data=(np.array(X_test), y_test),verbose=1)
```

Getting an error when weight() calls model_weight.predict on ""data"". This function works fine on regular tensors that I initialize with strict values (e.g.

```
tf.Tensor(
[[1 5]
 [2 5]
 [3 5]], shape=(3, 2), dtype=int32))
```
but not on the tensor that includes ""x"" or ""inputs"". Error message when the model tries to compile:

```
_FallbackException                        Traceback (most recent call last)
/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_dataset_ops.py in tensor_dataset(components, output_shapes, name)
   5590         _ctx._context_handle, tld.device_name, ""TensorDataset"", name,
-> 5591         tld.op_callbacks, components, ""output_shapes"", output_shapes)
   5592       return _result

_FallbackException: This function does not handle the case of the path where all inputs are not already EagerTensors.

During handling of the above exception, another exception occurred:

AttributeError                            Traceback (most recent call last)
<ipython-input-19-f74b0047add5> in <module>
      4 
      5 for theta in thetas:
----> 6     model.compile(optimizer='adam', loss=my_loss_wrapper(myinputs,theta),metrics=['accuracy'])
      7     model.fit(np.array(X_train), y_train, epochs=1, batch_size=500,validation_data=(np.array(X_test), y_test),verbose=1)
      8     lvals+=[model.history.history['val_loss']]

<ipython-input-18-3ac14760abd7> in my_loss_wrapper(inputs, val)
     24     print(tf.executing_eagerly())
     25     print(weight(test))
---> 26     w = weight(data)
     27 
     28     def my_loss(y_true,y_pred):

<ipython-input-14-c58e20e1428a> in weight(d)
     27 '''
     28 def weight(d):
---> 29     f = model_weight.predict(d,steps = 1)
     30     return (f)/(1-f)

/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py in predict(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)
   1011         max_queue_size=max_queue_size,
   1012         workers=workers,
-> 1013         use_multiprocessing=use_multiprocessing)
   1014 
   1015   def reset_metrics(self):

/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py in predict(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)
    496         model, ModeKeys.PREDICT, x=x, batch_size=batch_size, verbose=verbose,
    497         steps=steps, callbacks=callbacks, max_queue_size=max_queue_size,
--> 498         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)
    499 
    500 

/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py in _model_iteration(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)
    424           max_queue_size=max_queue_size,
    425           workers=workers,
--> 426           use_multiprocessing=use_multiprocessing)
    427       total_samples = _get_total_number_of_samples(adapter)
    428       use_sample = total_samples is not None

/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py in _process_inputs(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)
    704       max_queue_size=max_queue_size,
    705       workers=workers,
--> 706       use_multiprocessing=use_multiprocessing)
    707 
    708   return adapter

/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/data_adapter.py in __init__(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)
    355     indices_dataset = indices_dataset.flat_map(slice_batch_indices)
    356 
--> 357     dataset = self.slice_inputs(indices_dataset, inputs)
    358 
    359     if shuffle == ""batch"":

/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/data_adapter.py in slice_inputs(self, indices_dataset, inputs)
    381     dataset = dataset_ops.DatasetV2.zip((
    382         indices_dataset,
--> 383         dataset_ops.DatasetV2.from_tensors(inputs).repeat()
    384     ))
    385 

/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py in from_tensors(tensors)
    564       Dataset: A `Dataset`.
    565     """"""
--> 566     return TensorDataset(tensors)
    567 
    568   @staticmethod

/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py in __init__(self, element)
   2769     variant_tensor = gen_dataset_ops.tensor_dataset(
   2770         self._tensors,
-> 2771         output_shapes=structure.get_flat_tensor_shapes(self._structure))
   2772     super(TensorDataset, self).__init__(variant_tensor)
   2773 

/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_dataset_ops.py in tensor_dataset(components, output_shapes, name)
   5594       try:
   5595         return tensor_dataset_eager_fallback(
-> 5596             components, output_shapes=output_shapes, name=name, ctx=_ctx)
   5597       except _core._SymbolicException:
   5598         pass  # Add nodes to the TensorFlow graph.

/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_dataset_ops.py in tensor_dataset_eager_fallback(components, output_shapes, name, ctx)
   5627         ""'tensor_dataset' Op, not %r."" % output_shapes)
   5628   output_shapes = [_execute.make_shape(_s, ""output_shapes"") for _s in output_shapes]
-> 5629   _attr_Toutput_types, components = _execute.convert_to_mixed_eager_tensors(components, ctx)
   5630   _inputs_flat = list(components)
   5631   _attrs = (""Toutput_types"", _attr_Toutput_types, ""output_shapes"",

/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py in convert_to_mixed_eager_tensors(values, ctx)
    281 def convert_to_mixed_eager_tensors(values, ctx):
    282   v = [ops.convert_to_tensor(t, ctx=ctx) for t in values]
--> 283   types = [t._datatype_enum() for t in v]  # pylint: disable=protected-access
    284   return types, v
    285 

/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py in <listcomp>(.0)
    281 def convert_to_mixed_eager_tensors(values, ctx):
    282   v = [ops.convert_to_tensor(t, ctx=ctx) for t in values]
--> 283   types = [t._datatype_enum() for t in v]  # pylint: disable=protected-access
    284   return types, v
    285 

AttributeError: 'Tensor' object has no attribute '_datatype_enum'
```"
37404,TFLite inference throwing error at one of the run,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): Followed official classifier example

- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Android 9

- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: Huawei 9 lite

- TensorFlow version (use command below): 
    implementation 'org.tensorflow:tensorflow-lite:0.0.0-nightly'
    implementation 'org.tensorflow:tensorflow-lite-gpu:0.0.0-nightly'
    implementation 'org.tensorflow:tensorflow-lite-support:0.0.0-nightly'
    implementation 'org.tensorflow:tensorflow-lite-select-tf-ops:0.0.0-nightly'

**Describe the current behavior**
I have a model that has 1 input and 2 outputs. I have written the below code for inference using **run()** rather than **runForMultipleInputsOutputs**. So first I have a query:
Would running it with runForMultipleInputsOutputs() rather than calling run() twice, make it run faster or does runForMultipleInputsOutputs does same internally?

Now I get right inference for first output layer but for the 2nd output inference, I get the below error message.

`java.lang.IllegalArgumentException: Cannot convert between a TensorFlowLite buffer with 32 bytes and a Java Buffer with 8 bytes.`

**Describe the expected behavior**
Should run OK.

**Standalone code to reproduce the issue** 

      ```
       // Initialization Code
       tflite = new Interpreter(tfliteModel, tfliteOptions);

        // Loads labels out from the label file.
        labelsAge = ageLabels; //List

        labelsGender = genderLabels; // List

        // Reads type and shape of input and output tensors, respectively.
        int imageTensorIndex = 0;
        int[] imageShape = tflite.getInputTensor(imageTensorIndex).shape(); // {1, height, width, 3}

        imageSizeY = imageShape[1];
        imageSizeX = imageShape[2];
        DataType imageDataType = tflite.getInputTensor(imageTensorIndex).dataType();

        // Creates the input tensor.
        inputImageBuffer = new TensorImage(imageDataType);

        // For Outputs
        //For Age
        int probabilityAgeTensorIndex = 0; // Age
        int[] probabilityAgeShape = tflite.getOutputTensor(probabilityAgeTensorIndex).shape(); // {1, NUM_CLASSES}
        DataType probabilityAgeDataType = tflite.getOutputTensor(probabilityAgeTensorIndex).dataType();

        // Creates the output tensor and its processor.
        outputProbabilityAgeBuffer = TensorBuffer.createFixedSize(probabilityAgeShape, probabilityAgeDataType);

        // Creates the post processor for the output probability.
        probabilityAgeProcessor = new TensorProcessor.Builder().add(getPostprocessNormalizeOp()).build();

        //For Gender
        int probabilityGenderTensorIndex = 1; // Gender
        int[] probabilityGenderShape = tflite.getOutputTensor(probabilityGenderTensorIndex).shape(); // {1, NUM_CLASSES}
        DataType probabilityGenderDataType = tflite.getOutputTensor(probabilityGenderTensorIndex).dataType();

        // Creates the output tensor and its processor.
        outputProbabilityGenderBuffer = TensorBuffer.createFixedSize(probabilityGenderShape, probabilityGenderDataType);

        // Creates the post processor for the output probability.
        probabilityGenderProcessor = new TensorProcessor.Builder().add(getPostprocessNormalizeOp()).build();


       //********  Inference code ************
        public AgeGenderValues estimateAgeGender(final Bitmap bitmap) {
        // Logs this method so that it can be analyzed with systrace.
        Trace.beginSection(""estimateImage"");

        Trace.beginSection(""loadImage"");
        inputImageBuffer = loadImage(bitmap);
        Trace.endSection();

        // Runs the inference call.
        Trace.beginSection(""ageRunInference "");
        tflite.run(inputImageBuffer.getBuffer(), outputProbabilityAgeBuffer.getBuffer().rewind());
        Trace.endSection();

        Trace.beginSection(""genderRunInference "");
        // ********** ERROR THROWN AT BELOW STATEMENT  **************
        tflite.run(inputImageBuffer.getBuffer(), outputProbabilityGenderBuffer.getBuffer().rewind());
        Trace.endSection();

        // Gets the map of label and probability.
        Map<String, Float> labeledAgeProbability = new TensorLabel(labelsAge, probabilityAgeProcessor.process(outputProbabilityAgeBuffer)).getMapWithFloatValue();
        Map<String, Float> labeledGenderProbability = new TensorLabel(labelsGender, probabilityGenderProcessor.process(outputProbabilityGenderBuffer)).getMapWithFloatValue();
        Trace.endSection();

        AgeGenderValues tmpAgeGenderValues = new AgeGenderValues();
        // Gets top-k results.
        tmpAgeGenderValues.Age = getTopKProbability(labeledAgeProbability);
        tmpAgeGenderValues.Gender = getTopKProbability(labeledGenderProbability);
        return tmpAgeGenderValues;
    }

    ```

Graph


![agegendermultitaskspcnn](https://user-images.githubusercontent.com/7953422/76128759-3bb80f80-602b-11ea-9208-92f5716ad320.png)

"
37401,FasterRCNN_resnet101 .tflite conversion,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab
- TensorFlow installed from (source or binary): binary
- TensorFlow version (or github SHA if from source): pip install tf-nightly


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
import tensorflow as tf
converter = tf.lite.TFLiteConverter.from_saved_model(""/content/trained_m2_data_38000steps_resnet101/saved_model"")

converter.experimental_new_converter = True  # Add this line

tflite_model = converter.convert()
```

**The output from the converter invocation**

```
INFO:tensorflow:Saver not created because there are no variables in the graph to restore
---------------------------------------------------------------------------
ConverterError                            Traceback (most recent call last)
<ipython-input-9-4edb7ba34fed> in <module>()
      4 converter.experimental_new_converter = True  # Add this line
      5 
----> 6 tflite_model = converter.convert()
      7 
      8 '''

2 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
    225       stdout = _try_convert_to_unicode(stdout)
    226       stderr = _try_convert_to_unicode(stderr)
--> 227       raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
    228   finally:
    229     # Must manually cleanup files.

ConverterError: See console for info.
2020-03-06 20:56:59.840264: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:305] Ignored output_format.
2020-03-06 20:56:59.840346: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:308] Ignored drop_control_dependency.
2020-03-06 20:57:00.599028: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
loc(""FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/Pad""): error: 'tfl.pad' op failed to verify that operand 0's rank equals operand 1's size
Traceback (most recent call last):
  File ""/usr/local/bin/toco_from_protos"", line 8, in <module>
    sys.exit(main())
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/lite/toco/python/toco_from_protos.py"", line 93, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/lite/toco/python/toco_from_protos.py"", line 56, in execute
    enable_mlir_converter)
Exception: <unknown>:0: error: loc(""FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/Pad""): 'tfl.pad' op failed to verify that operand 0's rank equals operand 1's size
```

**Also, please include a link to the saved model or GraphDef**

```
https://gist.github.com/dkurt/1fe03728dcb51955c89d30dfe6c11a3d
```

**Failure details**
If the conversion is successful, but the generated model is wrong,
state what is wrong:
- Producing wrong results and/or decrease in accuracy
- Producing correct results, but the model is slower than expected (model generated from old converter)


**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
37399,"InvalidArgumentError: Cannot assign a device for operation conv2d_1/kernel/IsInitialized/VarIsInitializedOp: node conv2d_1/kernel/IsInitialized/VarIsInitializedOp (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1748)  was explicitly assigned to /job:worker/replica:0/task:0/device:TPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0 ]. Make sure the device specification refers to a valid device. 	 [[conv2d_1/kernel/IsInitialized/VarIsInitializedOp]]","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): 
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): 
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): 
- Python version: - Bazel
version (if compiling from source):
- GCC/Compiler version (if compiling from
source): 
- CUDA/cuDNN version: - GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
37397,tf.ragged.map_flat_values with tf.argmax on ragged axis produces wrong operation,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: N/A
- TensorFlow installed from (source or
binary): Pip
 - TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de 2.1.0
- Python version: Python 3.7.4
- Bazel
version (if compiling from source): N/A
- GCC/Compiler version (if compiling from
source): N/A
- CUDA/cuDNN version: V10.1.243
- GPU model and memory: GeForce RTX 2080 8G

**Describe the current behavior**
Using a RaggedTensor flat mapped into tf.argmax and the flattened ragged dimension as the axis to argmax against, the wrong shape/operation results.  [batch, None, N] using map_flat_values(tf.argmax, <tensor>, -2) results in a [batch, None] tensor.

**Describe the expected behavior**
I'd expect to result in a [batch, N] tensor.

**Standalone code to reproduce the issue** 
```
import tensorflow as tf
foo = tf.ragged.constant([[[0,1],[2,3]],[[4,5]],[[6,7]],[[8,9]]], dtype=tf.int64, ragged_rank=1)

# Mapped into the ragged axis (should produce a [4, 2])
bar = tf.ragged.map_flat_values(tf.argmax, foo, -2)
bar
<tf.RaggedTensor [[4, 4], [], [], []]>
bar.shape
TensorShape([4, None])

# Mapped into the non-ragged axis
bar = tf.ragged.map_flat_values(tf.argmax, foo, -1)
bar
<tf.RaggedTensor [[1, 1], [1], [1], [1]]>
# Notice the same shape...
bar.shape
TensorShape([4, None])
```
What I expect is something like this:
```
import tensorflow as tf
foo = tf.ragged.constant([[[0,1],[2,3]],[[4,5]],[[6,7]],[[8,9]]], dtype=tf.int64, ragged_rank=1)
row_splits = foo.row_splits
old_row=row_splits[0]
bar = []
for row in row_splits[1:]:
    bar.append(tf.argmax(foo.values[old_row:row, ...],-2))
    old_row=row
bar = tf.stack(bar)
bar
<tf.Tensor: shape=(4, 2), dtype=int64, numpy=
array([[1, 1],
       [0, 0],
       [0, 0],
       [0, 0]])>
bar.shape
TensorShape([4, 2])
```
"
37393,tf.image.ssim_multiscale broke in tensorflow 2.1.0-rc2,"**System information** 
Python 3.7.6 on Windows 10, x64. 

Using tensorflow 2.1.0-rc2.

GPU Hardware: pciBusID: 0000:01:00.0 name: TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 12.00GiB deviceMemoryBandwidth: 447.48GiB/s

**Describe the current behavior**

Code should print the word 'done'

**Describe the expected behavior**

tensorflow.python.framework.errors_impl.OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.


**Standalone code to reproduce the issue** 
```
import tensorflow as tf
tf.test.gpu_device_name()
print(tf.__version__)

# Build model
img_input = tf.keras.layers.Input(shape=(128, 128, 1))
img_output = tf.keras.layers.Convolution2D(1, 1)(img_input) 
model = tf.keras.models.Model(img_input, img_output)

# Add reconstruction loss 
# Toggle between the next 2 lines of code to see that ssim_multiscale does not work but simple MSE does.
loss = tf.reduce_mean(tf.image.ssim_multiscale(img_input, img_output, 1.0))  # This loss does not
#loss = tf.reduce_mean((img_input - img_output)**2)  # This loss works
model.add_loss(loss)

model.compile(optimizer = tf.keras.optimizers.RMSprop(lr=1e-4), loss = None)  
model.summary()

# The error Iget when using the ssim_multiscale loss is:
#tensorflow.python.framework.errors_impl.OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.
    
print('done')
```

**Other info / logs** 

This problem is present in 1.15.0 and 2.1.0.  This bug is not present in in 1.13.1.

I have tried several image metrics in tf.image including ssim and psnr and they all result in the same error.
"
37390,"More elaborate logging implementation (implementing TFLogSink s, etc.)","**System information**
- TensorFlow version: master
- Are you willing to contribute it: Yes

**Describe the feature and the current behavior/state.**
Currently, logging seems to directly write to `stderr`, if the log messages level fits the current log level.
https://github.com/tensorflow/tensorflow/blob/efff893c709b585da9771cb3a2997321efef36ae/tensorflow/core/platform/default/logging.cc#L259
This is a pity, since the message is lost for other code (I'm currently going thru some hoops to fetch them from `stderr` but the solution is problematic), and in particular, it does not adhere to unified logging approaches, with Python users probably expecting their log message to end up in Python's logging infrastructure. Furthermore, many people seem to search for ways to suppress them, and setting the log level via env vars seems to be not the least confusing approach for many (cf. https://github.com/tensorflow/tensorflow/issues/1258 https://github.com/tensorflow/tensorflow/issues/566).

Taking a look at the source, it seems that conceptionally, more logging infrastructure is planned, but  has not yet been implemented:
https://github.com/tensorflow/tensorflow/blob/47df0000dc3af299cef581811c2ad58f3eda700b/tensorflow/core/platform/default/logging.cc#L40

Therefore the steps seem to be: Implement and use the `TFLogSink` infrastructure, by default adding a logger writing to `stderr`. Implementing a `TFLogSink` which can pass log messages to Python, loaded and added by the Python code, replacing the `stderr` logging. Adding API to to enumerate current log sinks.

Is anyone working on this? In some comments it seems that Google-internal TF might use more elaborate logging infrastructure, is any of this due to be added to open source TF? What are the opinions of the TF team on the issue?

**Will this change the current api? How?**
No. It will add additional possibilities, but not break existing code.
**Who will benefit with this feature?**
People who want finer grained control of logging.
**Any Other info.**
–"
37382,Inconsistent device placement when using nondifferentiable_batch_function and GPU,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): colab.research.google.com
- TensorFlow installed from (source or
binary): - 2.1.0 (latest)
- Python version: Google colab python 3
- CUDA/cuDNN version: Google colab GPU

I'm trying to test the possibility of using `nondifferentiable_batch_function` for inference. Specifically, I need to collect batches and execute them on GPU for better throughput. I'm aware that there are some other approaches (e.g. using tensorflow serving batching) but using a batching function within a graph could be beneficial for my current setup. While experimenting with different approaches I found out that device placement for operations wrapped by batch function could be highly inconsistent. I have managed to execute operations on GPU by wrapping concrete function into batch function and then save the model but other approaches didn't work:
```
signature = (tf.TensorSpec(shape=[None, 3], dtype=tf.float32, name=""x""),)

@tf.function(input_signature=signature)
def run(x):
  with tf.device(""/GPU:0""):
        return tf.nn.relu(tf.matmul(x, tf.random.uniform((3, 1))))

concrete_run = run.get_concrete_function()

@tf.nondifferentiable_batch_function(1, 6, 10)
def batch_run(x):
    return concrete_run(x)

class Model(tf.Module):
    @tf.function(input_signature=signature)
    def run(self, x):
        return batch_run(x)

model = Model()
x = tf.random.uniform((3, 3))

# MatMul and Relu are executed on CPU
model.run(x)

concrete_model_run = model.run.get_concrete_function()

# MatMul and Relu are executed on CPU
concrete_model_run(x)

tf.saved_model.save(model, ""model"", signatures={ ""run"": model.run })
model = tf.saved_model.load(""model"")

# MatMul and Relu are executed on GPU
model.signatures[""run""](x=x)
```
Please find full test there https://colab.research.google.com/drive/1ZcIbnixdcQ2OSabEAlcf5SYYdkoRzYtu

I expected that the use of nondifferentiable_batch_function would be consistent despite the approach. A particular problem that I face right now is that saved model (with GPU placed ops) when loaded by tensorflow serving still executes operations on CPU and I believe that issues are connected.
"
37380,Model customization in iOS,"First of all, thank you all for providing great example for model customization in Android https://github.com/tensorflow/examples/tree/master/lite/examples/model_personalization
It works great and I want to use it right away in my company! 
I have a question about example or support for iOS. Should I hold my breath that it will be available in near future or should I look for some workarounds?
"
37379,"matplotlib.mlab has been removed, update code please","## URL(s) with the issue:

a link to the documentation entry
https://tensorflow.google.cn/tutorials/estimator/boosted_trees_model_understanding

## Description of issue (what needs changing):
A bug I found in ""TensorFlow > Learn > TensorFlow Core > Tutorials > Gradient Boosted Trees: Model understanding"" as below:

matplotlib.mlab has been removed @ version 3.1.0 ""https://matplotlib.org/3.1.0/api/api_changes.html""
but the tutorials still uses _griddata_ class for plotting, i can not get the result follow this.

so would you mind adjust this for correct code? i am a beginner for tensorflow and python, so fix it by myself is difficult for me ,thanks 

"
37376,Hexagon Delegate not working with quantized EfficientNet Lite0,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): 
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Intrinsyc SD820 dev board
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de 2.1.0
- Python version: 3.6.9
- Bazel version (if compiling from source): 1.2.1
- GCC/Compiler version (if compiling from source): 7.4.0
- CUDA/cuDNN version: 
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

The Hexagon DSP Delegate is working well on some Google hosted quantized TFLite models (e.g. MobileNets), using the benchmark_model CLI.  However, when using benchmark_model on the newly released EfficientNet Lite models from the URL below, the DSP Delegate fails to engage (0 nodes delegated):

https://github.com/tensorflow/tpu/blob/master/models/official/efficientnet/lite/README.md

Example benchmark run:
```
$ adb shell benchmark_model \
   --use_hexagon=true \
   --input_layer=images \
   --input_layer_shape=1,224,224,3 \
   --graph=/sdcard/efficientnet-lite0-int8.tflite
             
STARTING!
Min num runs: [50]
Min runs duration (seconds): [1]
Max runs duration (seconds): [150]
Inter-run delay (seconds): [-1]
Num threads: [1]
Benchmark name: []
Output prefix: []
Min warmup runs: [1]
Min warmup runs duration (seconds): [0.5]
Graph: [/sdcard/efficientnet-lite0-int8.tflite]
Input layers: [images]
Input shapes: [1,224,224,3]
Input value ranges: []
Use legacy nnapi : [0]
Allow fp16 : [0]
Require full delegation : [0]
Enable op profiling: [0]
Max profiling buffer entries: [1024]
Use gpu : [0]
Allow lower precision in gpu : [1]
Use Hexagon : [1]
Hexagon lib path : [/data/local/tmp]
Hexagon Profiling : [0]
Use nnapi : [0]
Loaded model efficientnet-lite0-int8.tflite
INFO: Initialized TensorFlow Lite runtime.
remote_handle_control available and used
INFO: Created TensorFlow Lite delegate for Hexagon.
INFO: Hexagon delegate: 0 nodes delegated out of 64 nodes.

Applied Hexagon delegate.
The input model file size (MB): 5.42276
Initialized session in 93.33ms.
Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.
count=9 first=69875 curr=58811 min=58605 max=69875 avg=60623.8 std=3476

Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.
count=50 first=60688 curr=58755 min=58527 max=61817 avg=59263.9 std=711

Average inference timings in us: Warmup: 60623.8, Init: 93330, Inference: 59263.9
Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.
Peak memory footprint (MB): init=2.44922 overall=9.28125
```
At first I thought it was due to the (new?) ""Quantize"" node at the beginning of the EfficientNet Lite0 network, but pointing ""--input_layer"" to the next node doesn't help.

![image](https://user-images.githubusercontent.com/61851501/76033543-54bca580-5ef1-11ea-96df-8f8e826a6181.png)


Is this a DSP Delegate bug, or an issue with post-training quantization vs quantization-aware training?   If so, when can we expect TF2 quantization-aware training and/or DSP Delegate compatible EfficientNet Lite models?

Thanks

**Describe the expected behavior**

Majority of the 64 nodes in the EfficientNet Lite0 quantized model above should have been delegated to the DSP, and the inference time should have been much faster.

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
37370,Element/Coefficient wise Mul  _MklMul,"Occasionally  see that for element/coefficient wise multiplication ( e.g.  scalar*tensor or tensor*tensor) that multiple types of operators are used  ( e.g. Mul and _MklMul) .  My questions are as follows,

1.  Is there any difference between Mul and _MklMul ? 
2. Why  for some Ops Mul is picked and for others _MklMul is picked ? 

Files referring to Ops/Kernels  are as follows:
https://github.com/tensorflow/tensorflow/blob/r1.15/tensorflow/core/ops/math_ops.cc
https://github.com/tensorflow/tensorflow/blob/r1.15/tensorflow/core/kernels/cwise_op_mul_1.cc
https://github.com/tensorflow/tensorflow/blob/r1.15/tensorflow/core/kernels/mkl_cwise_ops_common.cc
"
37369,feature request: add tf_random_seed argument for TPUConfig,"<em>tag:feature_template</em>


**System information**
- TensorFlow version: 1.15 and 2.0
- Are you willing to contribute it (Yes/No): I would like to yet not quite sure how

**Describe the feature and the current behavior/state.**
add `tf_random_seed ` option for `TPUConfig` ([here](https://www.tensorflow.org/api_docs/python/tf/compat/v1/estimator/tpu/TPUConfig)) as for `RunConfig` ([here](https://www.tensorflow.org/api_docs/python/tf/estimator/RunConfig)), so as to control the random seed in tf graph (and also the data sampling process?)

**Will this change the current api? How?**
only one more argument will be added for `TPUConfig`

**Who will benefit with this feature?**
people who want deterministic results on TPU training. 

This feature request comes from the trials to following [this paper](https://arxiv.org/abs/2002.06305): wanna see if bert finetuning also get affected a lot on the other datasets while wanna see the result quickly (on GPU it takes days to train one fold)"
37366,tf_upgrade_v2 fails to deal with set_session,"**System information**  
- Linux Ubuntu 16.04: 
- TensorFlow 2.0
- Python 3.6

I use `tf_upgrade_v2` to convert my script from TF1.14 to 2.0. But the converted script run into an error. 

```
Traceback (most recent call last):
  File ""test_mspeech_origin.py"", line 23, in <module>
    set_session(tf.compat.v1.Session(config=config))
  File ""/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py"", line 400, in set_session
    '`set_session` is not available '
RuntimeError: `set_session` is not available when using TensorFlow 2.0.
```

Finally I changed the code manually to make it work.
```
sess = tf.compat.v1.Session(config)
tf.compat.v1.keras.backend.set_session(sess)
```

Is there anything going with `set_session` when use `tf_upgrade_v2`?"
37365,ResNet models in tf.keras.applications contain a bias term which should not be there.,"Pretrained ResNet models available as part of `tf.keras.applications` include a `bias` weight with all the convolutional layers which is weird. What is even weirder is that the pretrained weights contain `all zeros` for the bias weights, which is definitely a problem. 

ResNet models do not use a bias term because of the use of `batch normalization`. Even the TensorFlow models repository, the [ResNet construction code](https://github.com/tensorflow/models/blob/master/official/vision/image_classification/resnet_model.py) does not contain a bias term in convolutions.

The following code shows the weights in the resnet50 model in `tf.keras.applications` as can be seen the bias terms are all zeros.
```

import tensorflow as tf

model = tf.keras.applications.resnet50.ResNet50(include_top=False, weights='imagenet')
print(model.trainable_variables)
```

A small portion of the output shows the bias terms as all zeros.

```
array([[[[ 1.76406968e-02,  2.18379945e-02,  6.38491847e-03, ...,
          -1.56918354e-02,  1.33828130e-02, -7.58931879e-03],
         [ 6.57748384e-03, -1.13832625e-02, -1.44122150e-02, ...,
           1.07535999e-02,  1.99317057e-02, -5.90330362e-03],
         [ 1.96981058e-02,  6.84878789e-03, -1.30715151e-03, ...,
          -8.99719913e-03,  1.00973761e-02, -1.09837623e-02],
         ...,
         [ 4.02560830e-03, -2.51277094e-03, -1.91410668e-02, ...,
           1.84022412e-02, -1.05592925e-02,  3.84159223e-03],
         [-1.21582337e-02, -2.44973949e-03, -8.21000524e-03, ...,
          -3.52650182e-03,  9.62345582e-03, -1.55217517e-02],
         [-1.57500952e-02, -5.96316298e-03,  4.53999359e-03, ...,
           4.88574570e-03,  4.60040662e-03,  8.99072620e-05]]]],
      dtype=float32)>, <tf.Variable 'conv5_block3_3_conv/bias:0' shape=(2048,) dtype=float32, numpy=array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv5_block3_3_bn/gamma:0' shape=(2048,) dtype=float32, numpy=
array([1.3451786, 1.3965728, 1.4453218, ..., 1.2092956, 1.5969722,
       1.4321095], dtype=float32)>, <tf.Variable 'conv5_block3_3_bn/beta:0' shape=(2048,) dtype=float32, numpy=
array([-1.4512578, -1.6519743, -1.6319023, ..., -1.6061822, -1.7218091,
       -1.9375533], dtype=float32)>]

```

This is definitely an issue which needs to be cleared up as a lot of people are depending upon `tf.keras.applications`."
37364,ConvLSTM2D Mixed Precision casting,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): yes

- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Ubuntu 16.04

- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): 2.1.0



**Describe the current behavior**
Presumably, dtype isn't correctly cast for ConvLSTM2D when using mixed_precision policy. Issue is not present in other convolution layers such as Conv2D.


**Describe the expected behavior**
Filter of the Conv2D op for ConvLSTM2D should be float16 when using 'mixed_float16' mixed_precision policy

**Standalone code to reproduce the issue** 
````
import tensorflow as tf

policy=tf.keras.mixed_precision.experimental.Policy('mixed_float16')
tf.keras.mixed_precision.experimental.set_policy(policy)

x=tf.keras.Input(shape=(1,10,10,3))



clstm1 =  tf.keras.layers.ConvLSTM2D(
    filters=1,
    strides=1,
    kernel_size=1,
    padding='same',
    return_sequences=True)(x)
````

**Other info / logs** 

```
/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/op_def_library.py in _apply_op_helper(op_type_name, name, **keywords)
    502                 ""%s type %s of argument '%s'."" %
    503                 (prefix, dtypes.as_dtype(attrs[input_arg.type_attr]).name,
--> 504                  inferred_from[input_arg.type_attr]))
    505 
    506         types = [values.dtype]

TypeError: Input 'filter' of 'Conv2D' Op has type float32 that does not match type float16 of argument 'input'.
```
"
37363,test issue,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- Tensorflow version (commit SHA if source):
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.):

**Describe the problem**

**Please provide the exact sequence of commands/steps when you ran into the problem**

"
37361,CMSIS-NN kernel is slower than C-reference kernel,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution: Linux Ubuntu 18.04 in WSH on Win10
- TensorFlow installed from (source or binary): source
- Tensorflow version: 4030aa1fe5bdd846301f379d1f1a0e58efbceae4
- Target platform: SparkFun Edge (Cortex M4F)

**Describe the problem**
Since commit 4030aa1fe5bdd846301f379d1f1a0e58efbceae4 the convolutional layers (conv, depthwise_conv) from the C-reference kernel are equally fast as the optimized CMSIS-NN kernel or even faster. Due to the 4x SIMD acceleration it is expected that the CMSIS-NN kernel significantly faster. The issue was NOT introduced by this commit, it just made the issue visible.
To my understanding the root cause is the compiler option '-fno-builtin'. Removing this option from the Makefile (e.g. for the SparkFun edge board in tensorflow/lite/micro/tools/make/targets/apollo3evb_makefile.inc) speeds up the CMSIS-NN kernel by factor of 3-6 while the reference kernel does not change.
Note: in order to let TFL micro use the CMSIS-NN kernel an int8 quantized model must be used. Otherwise, the TFL micro interpreter falls back to the reference kernel, anyway. Unfortunately, I was not able to find an int8 quantized model under tensorflow/lite/micro/examples

**Please provide the exact sequence of commands/steps when you ran into the problem**
1. Create a project <my_project> using an appropriate int8 quanized model. e.g. by copying the tensorflow/lite/micro/examples/hello_world example.
   Replace the model and input data by a model with convolutional layers and int8 quantization!
   
2. Instrument the call to the interpreter with some pin toggling, e.g.
  am_hal_gpio_output_set(38);
  TfLiteStatus invoke_status = interpreter->Invoke();
  am_hal_gpio_output_clear(38);

3. Build the project for the reference kernel, measure execution time:
make -f tensorflow/lite/micro/tools/make/Makefile clean
make -f tensorflow/lite/micro/tools/make/Makefile TARGET=sparkfun_edge <my_project>_bin
--> measure model execution time

4. Build the project for the CMSIS-NN kernel, measure execution time:
make -f tensorflow/lite/micro/tools/make/Makefile clean
make -f tensorflow/lite/micro/tools/make/Makefile TAGS=cmsis-nn TARGET=sparkfun_edge <my_project>_bin
--> measure model execution time

5. Remove '-fno-builtin' option from tensorflow/lite/micro/tools/make/targets/apollo3evb_makefile.inc
(delete the line, not just comment out)

6. Build the project for the reference kernel without '-fno-builtin', measure execution time:
make -f tensorflow/lite/micro/tools/make/Makefile clean
make -f tensorflow/lite/micro/tools/make/Makefile TARGET=sparkfun_edge <my_project>_bin
--> measure model execution time

7. Build the project for the CMSIS-NN kernel without '-fno-builtin', measure execution time:
make -f tensorflow/lite/micro/tools/make/Makefile clean
make -f tensorflow/lite/micro/tools/make/Makefile TAGS=cmsis-nn TARGET=sparkfun_edge <my_project>_bin
--> measure model execution time

The execution times from 4 is not (much) shorter than from 3, eventually it is even longer.
The execution times from 7 is 3-6x times shorter than from 6, which is the expected SIMD acceleration.

"
37360,ERROR:root:Internal Python error in the inspect module.,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**:
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
ERROR:root:Internal Python error in the inspect module.

### Source code / logs
Traceback (most recent call last):
  File ""C:\Users\Snehal.Dahiphale\AppData\Local\Continuum\anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 3326, in run_code
  File ""<ipython-input-17-af47826a3752>"", line 2, in <module>
    hail = tf.constant('Hello World')
AttributeError: module 'tensorflow' has no attribute 'constant'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Snehal.Dahiphale\AppData\Local\Continuum\anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2040, in showtraceback
AttributeError: 'AttributeError' object has no attribute '_render_traceback_'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Snehal.Dahiphale\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Snehal.Dahiphale\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Snehal.Dahiphale\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\Snehal.Dahiphale\AppData\Local\Continuum\anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\Snehal.Dahiphale\AppData\Local\Continuum\anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Snehal.Dahiphale\AppData\Local\Continuum\anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 1101, in get_records
  File ""C:\Users\Snehal.Dahiphale\AppData\Local\Continuum\anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 319, in wrapped
  File ""C:\Users\Snehal.Dahiphale\AppData\Local\Continuum\anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 353, in _fixed_getinnerframes
  File ""C:\Users\Snehal.Dahiphale\AppData\Local\Continuum\anaconda3\lib\inspect.py"", line 1502, in getinnerframes
    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)
  File ""C:\Users\Snehal.Dahiphale\AppData\Local\Continuum\anaconda3\lib\inspect.py"", line 1460, in getframeinfo
    filename = getsourcefile(frame) or getfile(frame)
  File ""C:\Users\Snehal.Dahiphale\AppData\Local\Continuum\anaconda3\lib\inspect.py"", line 696, in getsourcefile
    if getattr(getmodule(object, filename), '__loader__', None) is not None:
  File ""C:\Users\Snehal.Dahiphale\AppData\Local\Continuum\anaconda3\lib\inspect.py"", line 733, in getmodule
    if ismodule(module) and hasattr(module, '__file__'):
  File ""C:\Users\Snehal.Dahiphale\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\Snehal.Dahiphale\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\Snehal.Dahiphale\AppData\Local\Continuum\anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 1006, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 983, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 953, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
  File ""<frozen importlib._bootstrap>"", line 1006, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 983, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 967, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 677, in _load_unlocked
  File ""<frozen importlib._bootstrap_external>"", line 728, in exec_module
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
  File ""C:\Users\Snehal.Dahiphale\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\__init__.py"", line 42, in <module>
    from . _api.v2 import audio
  File ""C:\Users\Snehal.Dahiphale\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\_api\v2\audio\__init__.py"", line 10, in <module>
    from tensorflow.python.ops.gen_audio_ops import decode_wav
  File ""C:\Users\Snehal.Dahiphale\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\ops\gen_audio_ops.py"", line 9, in <module>
    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow
  File ""C:\Users\Snehal.Dahiphale\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\Snehal.Dahiphale\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\Snehal.Dahiphale\AppData\Local\Continuum\anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\Snehal.Dahiphale\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\Snehal.Dahiphale\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\Snehal.Dahiphale\AppData\Local\Continuum\anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 3326, in run_code
  File ""<ipython-input-17-af47826a3752>"", line 2, in <module>
    hail = tf.constant('Hello World')
AttributeError: module 'tensorflow' has no attribute 'constant'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Snehal.Dahiphale\AppData\Local\Continuum\anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2040, in showtraceback
AttributeError: 'AttributeError' object has no attribute '_render_traceback_'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Snehal.Dahiphale\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Snehal.Dahiphale\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Snehal.Dahiphale\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\Snehal.Dahiphale\AppData\Local\Continuum\anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\Snehal.Dahiphale\AppData\Local\Continuum\anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

"
37359,Cannot create interpreter: Op builtin_code out or range: 74. Are you using old TFLite binary with newer model?,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): 
Yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): 
macOS 10.14.4
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
vivo X9 (Android 7.1.2)
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): 
implementation 'org.tensorflow:tensorflow-lite:0.0.0-nightly'

**Describe the current behavior**

I converted a Keras model to tflite on Mac mini with Tensorflow 2.1.0 installed. But I got error when load the tflite model to Tensorflow lite Interpreter in AndroidStudio 3.5.3:
`Cannot create interpreter: Op builtin_code out or range: 74. Are you using old TFLite binary with newer model?Op builtin_code out or range: 82. Are you using old TFLite binary with newer model?Registration failed.`

**Describe the expected behavior**

It should work like loading mobilenet_v1_1.0_224.tflite from Google's example.
Someone help me please. Thanks a lot.

**Standalone code to reproduce the issue** 
Here is my Kotlin codes in AndroidStudio:
init {
        loadModelFile(MainActivity.mainActivity.assets, ""converted_model.tflite"")?.let {
            mInterpreter = Interpreter(it)
        }
}

private fun loadModelFile(assets: AssetManager, modelFilename: String): MappedByteBuffer? {
       val fileDescriptor = assets.openFd(modelFilename)
       val inputStream = FileInputStream(fileDescriptor.fileDescriptor)
       val fileChannel = inputStream.channel
        val startOffset = fileDescriptor.startOffset
        val declaredLength = fileDescriptor.declaredLength
        return fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength)
}

Here is converting codes for Keras model to tflite:

import tensorflow as tf
if __name__ == '__main__':
    model = tf.keras.models.load_model('speech_model251_e_0_step_45500.base.h5')
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    tflite_model = converter.convert()
    open(""converted_model.tflite"", ""wb"").write(tflite_model)

**Other info / logs** 
java.lang.IllegalArgumentException: Internal error: Cannot create interpreter: Op builtin_code out or range: 74. Are you using old TFLite binary with newer model?Op builtin_code out or range: 82. Are you using old TFLite binary with newer model?Registration failed.
        at org.tensorflow.lite.NativeInterpreterWrapper.createInterpreter(Native Method)
        at org.tensorflow.lite.NativeInterpreterWrapper.<init>(NativeInterpreterWrapper.java:73)
        at org.tensorflow.lite.NativeInterpreterWrapper.<init>(NativeInterpreterWrapper.java:52)
        at org.tensorflow.lite.Interpreter.<init>(Interpreter.java:114)"
37358,Anyone have an interest in making ReduceLROnPlateau compatible with weight decay optimizers?,"**System information**
- TensorFlow version (you are using): 2.0, should work with 2.1 too
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**

**Will this change the current api? How?** No

**Who will benefit with this feature?** Those using decoupled weight decay optimizers with reduce LR callback

**Any Other info.**

It has been shown that decoupling weight decay from the learning rate can simply hyper parameter search and leads to better performance.

https://arxiv.org/abs/1711.05101

Tensorflow has implementations for Adam and SGD.

https://www.tensorflow.org/addons/api_docs/python/tfa/optimizers/SGDW

However the docs mention that when we decay the lr, we also need to decay the weight decay itself by the same factor. This is easy to do if we are using our own static schedulers like in the example they provided but i think reduce LR on plateau is still a valid technique and adding the weight decay-decay into this callback is fairly straightforward.

All we would really need to do is check if there is weight decay and if there is, just decay it just the same as with the lr. Existing functionality would remain unchanged and if there is weight decay, it should automatically be decayed anyway with the lr right? even if that is not the case, a simple additional argument ""decay_wd=False"" should suffice.

```
      if self.monitor_op(current, self.best):
        self.best = current
        self.wait = 0
      elif not self.in_cooldown():
        self.wait += 1
        if self.wait >= self.patience:
          old_lr = float(K.get_value(self.model.optimizer.lr))
          old_wd = float(K.get_value(self.model.optimizer.weight_decay))
          if old_lr > self.min_lr:
            new_lr = old_lr * self.factor
            new_wd = old_wd * self.factor
            new_lr = max(new_lr, self.min_lr)
            K.set_value(self.model.optimizer.weight_decay, new_wd)
            K.set_value(self.model.optimizer.lr, new_lr)
            if self.verbose > 0:
              print('\nEpoch %05d: ReduceLROnPlateau reducing learning '
                    'rate to %s.' % (epoch + 1, new_lr))
            self.cooldown_counter = self.cooldown
            self.wait = 0
```
"
37357,pathlib.Path support,"**System information**
- TensorFlow version (you are using):
- Are you willing to contribute it (Yes/No):
Yes

**Describe the feature and the current behavior/state.**
In 3.4 python added the `pathlib` module for handling of file system paths. Currently, the corresponding `pathlib.Path` objects cannot be passed to tensorflow functions directly as they expect strings. 

**Will this change the current api? How?**
Functions that expect a file or directory path would accept both string and `Path` parameters.

**Who will benefit with this feature?**
Anyone using both pathlib and tensorflow.

**Any Other info.**
The (probably incomplete) list of functions that should accept `PathLike` parameters:
```
tf.io.read_file
tf.io.TFRecordWriter
tf.io.write_file
tf.io.write_graph

tf.data.TextLineDataset
tf.data.TFRecordDataset
tf.data.FixedLengthRecordDataset

tf.saved_model.load
tf.saved_model.save
tf.train.Checkpoint
tf.train.CheckpointManager
tf.train.checkpoints_iterator
tf.train.get_checkpoint_state
tf.train.latest_checkpoint
tf.train.list_variables
tf.train.load_checkpoint
tf.train.load_variable

tf.estimator.Estimator

tf.feature_column.categorical_column_with_vocabulary_file
tf.feature_column.embedding_column
tf.feature_column.sequence_categorical_column_with_vocabulary_file
tf.feature_column.shared_embeddings

tf.lookup.TextFileInitializer

tf.summary.create_file_writer

keras.Model.save
keras.Model.save_weights
keras.Model.load_weights
keras.models.load_model
keras.models.save_model
keras.callbacks.CSVLogger
keras.callbacks.ModelCheckpoint
keras.callbacks.TensorBoard

keras.utils.get_file
keras.utils.plot_model
```"
37355,Raspberry Pi 3: ERROR: tensorflow-2.1.0-cp35-none-linux_armv7l.whl is not a supported wheel on this platform.,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Raspbian 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Raspberry Pi 3 Model B+
- TensorFlow installed from (source or binary): binary (.whl): https://storage.googleapis.com/tensorflow/raspberrypi/tensorflow-2.1.0-cp35-none-linux_armv7l.whl
- TensorFlow version: 2.1.0
- Python version: 3.7.3
- Installed using virtualenv? pip? conda?: Tried pip in both venv and system wide.
- Bazel version (if compiling from source): 
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:


```
pi@raspberrypi:~ $ python3.7 --version
Python 3.7.3
pi@raspberrypi:~ $ pip3.7 --version
pip 20.0.2 from /home/pi/.local/lib/python3.7/site-packages/pip (python 3.7)
pi@raspberrypi:~ $ lsb_release -a
No LSB modules are available.
Distributor ID:	Raspbian
Description:	Raspbian GNU/Linux 10 (buster)
Release:	10
Codename:	buster
```

**Describe the problem**
Attempting to install tensorflow for Raspberry Pi 3, using this guide: https://www.tensorflow.org/install/pip
My Raspberry Pi 3 with Raspbian 10 does not seem able to find or install tensorflow==2.1.0. It only finds 1.14.x.

I tried the various steps in the tutorial, and when attempting to install the RPI3 version found at this link: https://storage.googleapis.com/tensorflow/raspberrypi/tensorflow-2.1.0-cp35-none-linux_armv7l.whl
I get this error (same in venv):
```
pi@raspberrypi:~ $ pip3.7 install tensorflow-2.1.0-cp35-none-linux_armv7l.whl --user
ERROR: tensorflow-2.1.0-cp35-none-linux_armv7l.whl is not a supported wheel on this platform.
```
Attempting to install tensorflow defaults to 1.14:
```
pi@raspberrypi:~ $ pip3.7 install tensorflow --user
Looking in indexes: https://pypi.org/simple, https://www.piwheels.org/simple
Collecting tensorflow
  Downloading https://www.piwheels.org/simple/tensorflow/tensorflow-1.14.0-cp37-none-linux_armv7l.whl (79.6 MB)
     |▉                               | 2.1 MB 1.5 MB/s eta 0:00:51^C
ERROR: Operation cancelled by user
```
"
37354,Speed up AES in tf-2.1.0,"hi,
I hava implemented AES encryption in tensorflow,but it is too slow.
I guess there are lots of map_fn operation which make it slowly.But I don't know how to fix it
https://stackoverflow.com/questions/60545000/aes-encryption-in-tensorflow-is-too-slow

```
import tensorflow as tf
import time

def right_shift_and(num, a, b):
    if isinstance(a, int):
        a = tf.constant(a, dtype=tf.int64)
    if isinstance(b, int):
        b = tf.constant(b, dtype=tf.int64)
    a = tf.cast(a, tf.int64)
    b = tf.cast(b, tf.int64)
    return tf.bitwise.bitwise_and(tf.bitwise.right_shift(num, a), b)


def and_left_shift(num, a, b):
    if isinstance(a, int):
        a = tf.constant(a, dtype=tf.int64)
    if isinstance(b, int):
        b = tf.constant(b, dtype=tf.int64)
    a = tf.cast(a, tf.int64)
    b = tf.cast(b, tf.int64)
    return tf.bitwise.left_shift(tf.bitwise.bitwise_and(num, a), b)


def bitwise_and(a, b):
    if isinstance(a, int):
        a = tf.constant(a, dtype=tf.int64)
    if isinstance(b, int):
        b = tf.constant(b, dtype=tf.int64)
    a = tf.cast(a, tf.int64)
    b = tf.cast(b, tf.int64)
    return tf.bitwise.bitwise_and(a, b)


def right_shift(a, b):
    if isinstance(a, int):
        a = tf.constant(a, dtype=tf.int64)
    if isinstance(b, int):
        b = tf.constant(b, dtype=tf.int64)
    a = tf.cast(a, tf.int64)
    b = tf.cast(b, tf.int64)
    return tf.bitwise.right_shift(a, b)


def left_shift(a, b):
    if isinstance(a, int):
        a = tf.constant(a, dtype=tf.int64)
    if isinstance(b, int):
        b = tf.constant(b, dtype=tf.int64)
    a = tf.cast(a, tf.int64)
    b = tf.cast(b, tf.int64)
    return tf.bitwise.left_shift(a, b)


def bitwise_xor(a, b):
    if isinstance(a, int):
        a = tf.constant(a, dtype=tf.int64)
    if isinstance(b, int):
        b = tf.constant(b, dtype=tf.int64)
    a = tf.cast(a, tf.int64)
    b = tf.cast(b, tf.int64)
    return tf.bitwise.bitwise_xor(a, b)


class AES:
    def __init__(self, text, key):
        """"""
        1. KeyExpansion—round keys are derived from the cipher key using Rijndael's key schedule. AES requires a separate 128-bit round key block for each round plus one more.
        2. Initial round key addition:
           add_round_key—each byte of the state is combined with a byte of the round key using bitwise xor.
        3. 9, 11 or 13 rounds:
           sub_bytes—a non-linear substitution step where each byte is replaced with another according to a lookup table.
           shift_rows—a transposition step where the last three rows of the state are shifted cyclically a certain number of steps.
           MixColumns—a linear mixing operation which operates on the columns of the state, combining the four bytes in each column.
           add_round_key
        4. Final round (making 10, 12 or 14 rounds in total):
           sub_bytes
           shift_rows
           add_round_key
           Know more: https://en.wikipedia.org/wiki/Advanced_Encryption_Standard
        """"""

        self.text = text
        self.key = key

    def get_encrypt(self):
        return self.aes_encrypt(self.gen_16_bytes(self.text), self.aes_key_schedule(self.key))

    def get_decrypt(self):
        return self.gen_num(self.aes_decrypt(self.text, self.aes_key_schedule(self.key)))

    @staticmethod
    def sub_word(_4byte_block):
        # https://en.wikipedia.org/wiki/Rijndael_S-box
        S_BOX = [[99, 124, 119, 123, 242, 107, 111, 197, 48, 1, 103, 43, 254, 215, 171, 118],
                 [202, 130, 201, 125, 250, 89, 71, 240, 173, 212, 162, 175, 156, 164, 114, 192],
                 [183, 253, 147, 38, 54, 63, 247, 204, 52, 165, 229, 241, 113, 216, 49, 21],
                 [4, 199, 35, 195, 24, 150, 5, 154, 7, 18, 128, 226, 235, 39, 178, 117],
                 [9, 131, 44, 26, 27, 110, 90, 160, 82, 59, 214, 179, 41, 227, 47, 132],
                 [83, 209, 0, 237, 32, 252, 177, 91, 106, 203, 190, 57, 74, 76, 88, 207],
                 [208, 239, 170, 251, 67, 77, 51, 133, 69, 249, 2, 127, 80, 60, 159, 168],
                 [81, 163, 64, 143, 146, 157, 56, 245, 188, 182, 218, 33, 16, 255, 243, 210],
                 [205, 12, 19, 236, 95, 151, 68, 23, 196, 167, 126, 61, 100, 93, 25, 115],
                 [96, 129, 79, 220, 34, 42, 144, 136, 70, 238, 184, 20, 222, 94, 11, 219],
                 [224, 50, 58, 10, 73, 6, 36, 92, 194, 211, 172, 98, 145, 149, 228, 121],
                 [231, 200, 55, 109, 141, 213, 78, 169, 108, 86, 244, 234, 101, 122, 174, 8],
                 [186, 120, 37, 46, 28, 166, 180, 198, 232, 221, 116, 31, 75, 189, 139, 138],
                 [112, 62, 181, 102, 72, 3, 246, 14, 97, 53, 87, 185, 134, 193, 29, 158],
                 [225, 248, 152, 17, 105, 217, 142, 148, 155, 30, 135, 233, 206, 85, 40, 223],
                 [140, 161, 137, 13, 191, 230, 66, 104, 65, 153, 45, 15, 176, 84, 187, 22]]
        S_BOX_TF = tf.constant(S_BOX, dtype=tf.int64)
        result = tf.constant(0, dtype=tf.int64)
        for position in range(4):
            i = bitwise_and(right_shift(_4byte_block, (position * 8 + 4)), 15)
            j = bitwise_and(right_shift(_4byte_block, position * 8), 15)
            row = tf.gather_nd(S_BOX_TF, tf.expand_dims(i, 0))
            result = bitwise_xor(result, left_shift(tf.gather_nd(row, tf.expand_dims(j, 0)), position * 8))
        return result

    @staticmethod
    def rot_word(_4byte_block):
        return left_shift(bitwise_and(_4byte_block, 16777215), 8) + right_shift(_4byte_block, 24)

    @staticmethod
    def init_w(_16bytes_key, idx):
        if tf.math.equal(idx, tf.constant(0, dtype=tf.int64)):
            return right_shift(_16bytes_key, 96)
        elif tf.math.equal(idx, tf.constant(1, dtype=tf.int64)):
            return right_shift_and(_16bytes_key, 64, 4294967295)
        elif tf.math.equal(idx, tf.constant(2, dtype=tf.int64)):
            return right_shift_and(_16bytes_key, 32, 4294967295)
        elif tf.math.equal(idx, tf.constant(3, dtype=tf.int64)):
            return bitwise_and(_16bytes_key, 4294967295)
        else:
            return tf.constant(0, dtype=tf.int64)

    @staticmethod
    def assign_value(w, src_idx, dst_idx, dst_w):
        if tf.math.equal(src_idx, dst_idx):
            return dst_w
        else:
            return tf.gather_nd(w, tf.expand_dims(src_idx, 0))

    def opera_w(self, idx, w):
        RCon = [16777216, 33554432, 67108864, 134217728, 268435456, 536870912, 1073741824, 2147483648, 452984832,
                905969664]
        RCon_TF = tf.constant(RCon, dtype=tf.int64)
        temp = tf.gather_nd(w, tf.expand_dims(idx - tf.constant(1, dtype=tf.int64), 0))
        if tf.math.equal(idx % 4, tf.constant(0, dtype=tf.int64)):
            temp = bitwise_xor(self.sub_word(self.rot_word(temp)),
                               tf.gather_nd(RCon_TF, tf.expand_dims(idx // 4 - 1, 0)))
        dst_w = bitwise_xor(tf.gather_nd(w, tf.expand_dims(idx - tf.constant(4, dtype=tf.int64), 0)), temp)
        update_w = tf.map_fn(lambda src_idx: self.assign_value(w, src_idx, idx, dst_w),
                             tf.range(tf.constant(44, dtype=tf.int64)))
        idx = idx + tf.constant(1, dtype=tf.int64)
        return idx, update_w

    def gen_key_w(self, w, idx):
        w0 = tf.gather_nd(w, tf.expand_dims(idx * 4, 0))
        w1 = tf.gather_nd(w, tf.expand_dims(idx * 4 + 1, 0))
        w2 = tf.gather_nd(w, tf.expand_dims(idx * 4 + 2, 0))
        w3 = tf.gather_nd(w, tf.expand_dims(idx * 4 + 3, 0))
        key = left_shift(w0, 96) + left_shift(w1, 64) + left_shift(w2, 32) + w3

        return self.gen_16_bytes(key)

    def aes_key_schedule(self, _16bytes_key):
        """"""
        https://en.wikipedia.org/wiki/AES_key_schedule
        TODO: Now the key generator has many left shift operations which would cause index out of boundary,
              but it still works.
        """"""
        w = tf.map_fn(lambda idx: self.init_w(_16bytes_key, idx), tf.range(tf.constant(44, dtype=tf.int64)))
        idx = tf.constant(4, dtype=tf.int64)
        cond = lambda idx, w: tf.math.less(idx, tf.constant(44, dtype=tf.int64))
        body = lambda idx, w: self.opera_w(idx, w)
        w_update = tf.while_loop(cond, body, loop_vars=[idx, w])[1]

        return tf.map_fn(lambda idx: self.gen_key_w(w_update, idx), tf.range(tf.constant(11, dtype=tf.int64)))

    def add_round_key(self, state, round_keys, index):
        return self._16bytes_xor(state, tf.gather_nd(round_keys, tf.expand_dims(tf.constant(index, dtype=tf.int64), 0)))

    @staticmethod
    def _16bytes_xor(_16bytes_1, _16bytes_2):
        return tf.map_fn(lambda i: bitwise_xor(tf.gather_nd(_16bytes_1, tf.expand_dims(i, 0)),
                                               tf.gather_nd(_16bytes_2, tf.expand_dims(i, 0))),
                         tf.range(tf.constant(16, dtype=tf.int64)))

    @staticmethod
    def sub_bytes_map(idx, state):
        # https://en.wikipedia.org/wiki/Rijndael_S-box
        S_BOX = [[99, 124, 119, 123, 242, 107, 111, 197, 48, 1, 103, 43, 254, 215, 171, 118],
                 [202, 130, 201, 125, 250, 89, 71, 240, 173, 212, 162, 175, 156, 164, 114, 192],
                 [183, 253, 147, 38, 54, 63, 247, 204, 52, 165, 229, 241, 113, 216, 49, 21],
                 [4, 199, 35, 195, 24, 150, 5, 154, 7, 18, 128, 226, 235, 39, 178, 117],
                 [9, 131, 44, 26, 27, 110, 90, 160, 82, 59, 214, 179, 41, 227, 47, 132],
                 [83, 209, 0, 237, 32, 252, 177, 91, 106, 203, 190, 57, 74, 76, 88, 207],
                 [208, 239, 170, 251, 67, 77, 51, 133, 69, 249, 2, 127, 80, 60, 159, 168],
                 [81, 163, 64, 143, 146, 157, 56, 245, 188, 182, 218, 33, 16, 255, 243, 210],
                 [205, 12, 19, 236, 95, 151, 68, 23, 196, 167, 126, 61, 100, 93, 25, 115],
                 [96, 129, 79, 220, 34, 42, 144, 136, 70, 238, 184, 20, 222, 94, 11, 219],
                 [224, 50, 58, 10, 73, 6, 36, 92, 194, 211, 172, 98, 145, 149, 228, 121],
                 [231, 200, 55, 109, 141, 213, 78, 169, 108, 86, 244, 234, 101, 122, 174, 8],
                 [186, 120, 37, 46, 28, 166, 180, 198, 232, 221, 116, 31, 75, 189, 139, 138],
                 [112, 62, 181, 102, 72, 3, 246, 14, 97, 53, 87, 185, 134, 193, 29, 158],
                 [225, 248, 152, 17, 105, 217, 142, 148, 155, 30, 135, 233, 206, 85, 40, 223],
                 [140, 161, 137, 13, 191, 230, 66, 104, 65, 153, 45, 15, 176, 84, 187, 22]]
        S_BOX_TF = tf.constant(S_BOX, dtype=tf.int64)
        i = right_shift(tf.gather_nd(state, tf.expand_dims(idx, 0)), 4)
        j = bitwise_and(tf.gather_nd(state, tf.expand_dims(idx, 0)), 15)
        row = tf.gather_nd(S_BOX_TF, tf.expand_dims(i, 0))
        return tf.gather_nd(row, tf.expand_dims(j, 0))

    def sub_bytes(self, state):
        return tf.map_fn(lambda idx: self.sub_bytes_map(idx, state), tf.range(16, dtype=tf.int64))

    @staticmethod
    def sub_bytes_inv_map(idx, state):
        I_S_BOX = [[82, 9, 106, 213, 48, 54, 165, 56, 191, 64, 163, 158, 129, 243, 215, 251],
                   [124, 227, 57, 130, 155, 47, 255, 135, 52, 142, 67, 68, 196, 222, 233, 203],
                   [84, 123, 148, 50, 166, 194, 35, 61, 238, 76, 149, 11, 66, 250, 195, 78],
                   [8, 46, 161, 102, 40, 217, 36, 178, 118, 91, 162, 73, 109, 139, 209, 37],
                   [114, 248, 246, 100, 134, 104, 152, 22, 212, 164, 92, 204, 93, 101, 182, 146],
                   [108, 112, 72, 80, 253, 237, 185, 218, 94, 21, 70, 87, 167, 141, 157, 132],
                   [144, 216, 171, 0, 140, 188, 211, 10, 247, 228, 88, 5, 184, 179, 69, 6],
                   [208, 44, 30, 143, 202, 63, 15, 2, 193, 175, 189, 3, 1, 19, 138, 107],
                   [58, 145, 17, 65, 79, 103, 220, 234, 151, 242, 207, 206, 240, 180, 230, 115],
                   [150, 172, 116, 34, 231, 173, 53, 133, 226, 249, 55, 232, 28, 117, 223, 110],
                   [71, 241, 26, 113, 29, 41, 197, 137, 111, 183, 98, 14, 170, 24, 190, 27],
                   [252, 86, 62, 75, 198, 210, 121, 32, 154, 219, 192, 254, 120, 205, 90, 244],
                   [31, 221, 168, 51, 136, 7, 199, 49, 177, 18, 16, 89, 39, 128, 236, 95],
                   [96, 81, 127, 169, 25, 181, 74, 13, 45, 229, 122, 159, 147, 201, 156, 239],
                   [160, 224, 59, 77, 174, 42, 245, 176, 200, 235, 187, 60, 131, 83, 153, 97],
                   [23, 43, 4, 126, 186, 119, 214, 38, 225, 105, 20, 99, 85, 33, 12, 125]]
        I_S_BOX_TF = tf.constant(I_S_BOX, dtype=tf.int64)
        i = right_shift(tf.gather_nd(state, tf.expand_dims(idx, 0)), 4)
        j = bitwise_and(tf.gather_nd(state, tf.expand_dims(idx, 0)), 15)
        row = tf.gather_nd(I_S_BOX_TF, tf.expand_dims(i, 0))
        return tf.gather_nd(row, tf.expand_dims(j, 0))

    def sub_bytes_inv(self, state):
        return tf.map_fn(lambda idx: self.sub_bytes_inv_map(idx, state), tf.range(16, dtype=tf.int64))

    @staticmethod
    def shift_rows_map(idx, state):
        if tf.math.equal(idx, tf.constant(0, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(0, dtype=tf.int64), 0))
        elif tf.math.equal(idx, tf.constant(1, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(5, dtype=tf.int64), 0))
        elif tf.math.equal(idx, tf.constant(2, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(10, dtype=tf.int64), 0))
        elif tf.math.equal(idx, tf.constant(3, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(15, dtype=tf.int64), 0))
        elif tf.math.equal(idx, tf.constant(4, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(4, dtype=tf.int64), 0))
        elif tf.math.equal(idx, tf.constant(5, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(9, dtype=tf.int64), 0))
        elif tf.math.equal(idx, tf.constant(6, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(14, dtype=tf.int64), 0))
        elif tf.math.equal(idx, tf.constant(7, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(3, dtype=tf.int64), 0))
        elif tf.math.equal(idx, tf.constant(8, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(8, dtype=tf.int64), 0))
        elif tf.math.equal(idx, tf.constant(9, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(13, dtype=tf.int64), 0))
        elif tf.math.equal(idx, tf.constant(10, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(2, dtype=tf.int64), 0))
        elif tf.math.equal(idx, tf.constant(11, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(7, dtype=tf.int64), 0))
        elif tf.math.equal(idx, tf.constant(12, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(12, dtype=tf.int64), 0))
        elif tf.math.equal(idx, tf.constant(13, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(1, dtype=tf.int64), 0))
        elif tf.math.equal(idx, tf.constant(14, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(6, dtype=tf.int64), 0))
        else:
            return tf.gather_nd(state, tf.expand_dims(tf.constant(11, dtype=tf.int64), 0))

    def shift_rows(self, state):
        return tf.map_fn(lambda idx: self.shift_rows_map(idx, state), tf.range(tf.constant(16, dtype=tf.int64)))

    @staticmethod
    def shift_rows_inv_map(idx, state):
        if tf.math.equal(idx, tf.constant(0, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(0, dtype=tf.int64), 0))
        elif tf.math.equal(idx, tf.constant(1, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(13, dtype=tf.int64), 0))
        elif tf.math.equal(idx, tf.constant(2, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(10, dtype=tf.int64), 0))
        elif tf.math.equal(idx, tf.constant(3, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(7, dtype=tf.int64), 0))
        elif tf.math.equal(idx, tf.constant(4, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(4, dtype=tf.int64), 0))
        elif tf.math.equal(idx, tf.constant(5, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(1, dtype=tf.int64), 0))
        elif tf.math.equal(idx, tf.constant(6, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(14, dtype=tf.int64), 0))
        elif tf.math.equal(idx, tf.constant(7, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(11, dtype=tf.int64), 0))
        elif tf.math.equal(idx, tf.constant(8, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(8, dtype=tf.int64), 0))
        elif tf.math.equal(idx, tf.constant(9, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(5, dtype=tf.int64), 0))
        elif tf.math.equal(idx, tf.constant(10, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(2, dtype=tf.int64), 0))
        elif tf.math.equal(idx, tf.constant(11, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(15, dtype=tf.int64), 0))
        elif tf.math.equal(idx, tf.constant(12, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(12, dtype=tf.int64), 0))
        elif tf.math.equal(idx, tf.constant(13, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(9, dtype=tf.int64), 0))
        elif tf.math.equal(idx, tf.constant(14, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(6, dtype=tf.int64), 0))
        else:
            return tf.gather_nd(state, tf.expand_dims(tf.constant(3, dtype=tf.int64), 0))

    def shift_rows_inv(self, state):
        return tf.map_fn(lambda idx: self.shift_rows_inv_map(idx, state), tf.range(tf.constant(16, dtype=tf.int64)))

    @staticmethod
    def bit_length(x):
        bit_len = 0
        while x > 0:
            x = x // 2
            bit_len += 1
        return bit_len

    def mul(self, poly1, poly2):
        result = tf.cast(0, dtype=tf.int64)
        for index in range(self.bit_length(poly2)):
            if tf.math.greater(bitwise_and(poly2, left_shift(1, index)), tf.constant(0, dtype=tf.int64)):
                result = bitwise_xor(result, left_shift(poly1, index))
        return result

    def mod(self, poly, mod=283):
        while self.bit_length(poly) > 8:
            poly = bitwise_xor(poly, left_shift(mod, self.bit_length(poly) - 9))
        return poly

    def opera_matrix_mul(self, row, col, idx, state, state_init, inverse=False):
        # https://en.wikipedia.org/wiki/Rijndael_MixColumns
        if inverse:
            MIX_C = [[14, 11, 13, 9], [9, 14, 11, 13], [13, 9, 14, 11], [11, 13, 9, 14]]
        else:
            MIX_C = [[2, 3, 1, 1], [1, 2, 3, 1], [1, 1, 2, 3], [3, 1, 1, 2]]
        MIX_C_TF = tf.constant(MIX_C, dtype=tf.int64)
        i = tf.gather_nd(MIX_C_TF, tf.expand_dims(row, 0))
        j = tf.gather_nd(i, tf.expand_dims(idx, 0))
        new_state = bitwise_xor(state_init, self.mul(j, tf.gather_nd(state, tf.expand_dims(idx + col * 4, 0))))
        idx = idx + 1
        return idx, new_state

    def matrix_mul_map(self, state, row, col, inverse=False):
        idx = tf.constant(0, dtype=tf.int64)
        s_init = tf.constant(0, dtype=tf.int64)
        cond = lambda idx, s_init: tf.math.less(idx, tf.constant(4, dtype=tf.int64))
        body = lambda idx, s_init: self.opera_matrix_mul(row, col, idx, state, s_init, inverse=inverse)
        s_update = tf.while_loop(cond, body, loop_vars=[idx, s_init])[1]
        return self.mod(s_update)

    def matrix_mul(self, state, inverse=False):
        loop_num = tf.constant(4, dtype=tf.int64)
        return tf.map_fn(
            lambda row: tf.map_fn(lambda col: self.matrix_mul_map(state, row, col, inverse), tf.range(loop_num)),
            tf.range(loop_num))

    @staticmethod
    def exchange_columns(idx, state):
        if tf.math.equal(idx, tf.constant(0, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(0, dtype=tf.int64), 0))
        elif tf.math.equal(idx, tf.constant(1, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(4, dtype=tf.int64), 0))
        elif tf.math.equal(idx, tf.constant(2, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(8, dtype=tf.int64), 0))
        elif tf.math.equal(idx, tf.constant(3, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(12, dtype=tf.int64), 0))
        elif tf.math.equal(idx, tf.constant(4, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(1, dtype=tf.int64), 0))
        elif tf.math.equal(idx, tf.constant(5, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(5, dtype=tf.int64), 0))
        elif tf.math.equal(idx, tf.constant(6, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(9, dtype=tf.int64), 0))
        elif tf.math.equal(idx, tf.constant(7, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(13, dtype=tf.int64), 0))
        elif tf.math.equal(idx, tf.constant(8, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(2, dtype=tf.int64), 0))
        elif tf.math.equal(idx, tf.constant(9, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(6, dtype=tf.int64), 0))
        elif tf.math.equal(idx, tf.constant(10, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(10, dtype=tf.int64), 0))
        elif tf.math.equal(idx, tf.constant(11, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(14, dtype=tf.int64), 0))
        elif tf.math.equal(idx, tf.constant(12, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(3, dtype=tf.int64), 0))
        elif tf.math.equal(idx, tf.constant(13, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(7, dtype=tf.int64), 0))
        elif tf.math.equal(idx, tf.constant(14, dtype=tf.int64)):
            return tf.gather_nd(state, tf.expand_dims(tf.constant(11, dtype=tf.int64), 0))
        else:
            return tf.gather_nd(state, tf.expand_dims(tf.constant(15, dtype=tf.int64), 0))

    def mix_columns(self, state):
        matrix_state = tf.reshape(self.matrix_mul(state), [-1])
        return tf.map_fn(lambda idx: self.exchange_columns(idx, matrix_state),
                         tf.range(tf.constant(16, dtype=tf.int64)))

    def mix_columns_inv(self, state):
        matrix_state = tf.reshape(self.matrix_mul(state, inverse=True), [-1])
        return tf.map_fn(lambda idx: self.exchange_columns(idx, matrix_state),
                         tf.range(tf.constant(16, dtype=tf.int64)))

    @staticmethod
    def gen_16_bytes(num):
        shift_num_list = tf.constant([120, 112, 104, 96, 88, 80, 72, 64, 56, 48, 40, 32, 24, 16, 8, 0], dtype=tf.int64)
        result = tf.map_fn(lambda shift_num: right_shift_and(num, shift_num, 255), shift_num_list)
        return result

    @staticmethod
    def gen_num(_16bytes):
        shift_num = tf.constant([120, 112, 104, 96, 88, 80, 72, 64, 56, 48, 40, 32, 24, 16, 8, 0], dtype=tf.int64)
        result = tf.map_fn(lambda idx: left_shift(tf.gather_nd(_16bytes, tf.expand_dims(idx, 0)),
                                                  tf.gather_nd(shift_num, tf.expand_dims(idx, 0))),
                           tf.range(16, dtype=tf.int64))

        return tf.reduce_sum(result)

    def aes_encrypt(self, plaintext, round_keys):
        state = plaintext
        state = self.add_round_key(state, round_keys, 0)
        for _round in range(1, 10):
            state = self.sub_bytes(state)
            state = self.shift_rows(state)
            state = self.mix_columns(state)
            state = self.add_round_key(state, round_keys, _round)
        state = self.sub_bytes(state)
        state = self.shift_rows(state)
        state = self.add_round_key(state, round_keys, 10)
        return state

    def aes_decrypt(self, cipher_text, round_keys):
        state = cipher_text
        state = self.add_round_key(state, round_keys, 10)
        for _round in range(1, 10):
            state = self.shift_rows_inv(state)
            state = self.sub_bytes_inv(state)
            state = self.add_round_key(state, round_keys, 10 - _round)
            state = self.mix_columns_inv(state)
        state = self.shift_rows_inv(state)
        state = self.sub_bytes_inv(state)
        state = self.add_round_key(state, round_keys, 0)
        return state


start = time.time()
text = tf.constant(215254590896, dtype=tf.int64)
for i in range(10):
  text += tf.constant(1, dtype=tf.int64)
  key = tf.constant(2155745895, dtype=tf.int64)
  cipher_text = AES(text, key).get_encrypt()
  print(cipher_text)
  print(AES(cipher_text, key).get_decrypt())
print(time.time() - start
```

My tensorflow version is 2.1.0

"
37353,nvidia-smi missing from tensorflow:latest-gpu-py3-jupyter docker container (TF 2.1.0),"Hey all,

I just upgraded my codebase to TF 2.1.0 and as such also started using the ""latest"" container instead of the 1.15.x container I was using before.

My pipeline relies on `nvidia-smi` to get information about the memory utilization of the GPUs and other things, but I was disappointed to see that the tool has been seemingly removed from the container in the newer versions.

Can anyone else confirm this? I just get a ""no such file or directory"" and I can't find the binary or symbolic link in `/usr/bin/`.

Thanks!"
37352,TF-TRT is slower than native-TF with 512*512 image,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow):  [EAST ](https://github.com/argman/EAST)model
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04):  Ubuntu 16.04
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below):  1.15.0
- Python version: - Bazel
version (if compiling from source): 0.24.1
- GCC/Compiler version (if compiling from
source): gcc-7.1
- CUDA/cuDNN version: 10.0/7.6.5
- GPU model and memory:Default mode, Tesla V100-sxm2-16gb GPU

**Describe the current behavior**
We test [EAST ](https://github.com/argman/EAST)model using TF-TRT and native-TF on GPU V100.
If image size is 256 * 256，for one inference TF-TRT takes 3ms and native-TF takes 4ms.
If image size is 512 * 512，for one inference TF-TRT takes 5ms and native-TF takes 4.5ms.
If image size is 1024 * 1024，for one inference TF-TRT takes 40ms and native-TF takes 25ms.


**Standalone code to reproduce the issue** 
We upload our [saved_model.pb](https://github.com/lxl910915/Test/blob/master/SavedModel-1024-1024.tar.gz).
Untar it to /tmp/SavedModel-1024-1024.
For running saved_model, the shell is CUDA_VISIBLE_DEVICES=0 python [east_sm.py](https://github.com/lxl910915/Test/blob/master/east_sm.py). One inference costs 25ms.
For running tf-trt, the shell is CUDA_VISIBLE_DEVICES=0 python [east_tftrt.py](https://github.com/lxl910915/Test/blob/master/east_tftrt.py). One inference costs 40ms.

Then, we use nvprof to prof tf-trt `CUDA_VISIBLE_DEVICES=0 nvprof python east_tftrt.py`, and we find that genericReformat::copyPackedKernel occupy 60% time.

```
==33264== NVTX result:
==33264== Warning: Found 198911 invalid range marker(s)
==33264==   Thread ""<unnamed>"" (id = 268433152)
==33264==     Domain ""TensorRT""
==33264==       Range ""<unnamed>""
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  1.57525s     72779  21.644us  7.3260us  850.74us  <unnamed>
 GPU activities:   58.34%  4.46830s     33826  132.10us  2.3030us  2.0179ms  void genericReformat::copyPackedKernel<float, float, bool=0, bool=1, genericReformat::IdentityCoordMapper<int=4>, int=4>(unsigned int, unsigned int, void const *, genericReformat::ArrayN<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayNWithReducedDivisors<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayN, int, int, int, float const *, void*, genericReformat::ArrayN, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayN, int, int, int, float const , int=4)
                   13.70%  1.04961s      5675  184.95us  53.311us  385.95us  trt_volta_scudnn_128x64_relu_interior_nn_v1
                    9.91%  759.32ms      4597  165.18us  55.007us  206.62us  trt_volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1
```
The detal log is [here](https://github.com/lxl910915/Test/blob/master/log.tftrt.op3).

We change minimum_segment_size value:
minimum_segment_size = 200, no TRTEngineop are generated, inference time is 32ms.
minimum_segment_size = 20, inference time is 32ms.
minimum_segment_size = 10, inference time is 40ms.
minimum_segment_size = 3, inference time is 47ms.

But copyPackedKernel takes 60% time in above cases. Then we prof the 256 * 256 image, copyPackedKernel only takes 20% times.
```
==30031== NVTX result:
==30031== Warning: Found 110489 invalid range marker(s)
==30031==   Thread ""<unnamed>"" (id = 3548374784)
==30031==     Domain ""TensorRT""
==30031==       Range ""<unnamed>""
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  1.62226s     54141  29.963us  7.5820us  880.76us  <unnamed>
 GPU activities:   25.34%  103.18ms      3008  34.301us  7.0400us  152.83us  void cudnn::detail::implicit_convolve_sgemm<float, float, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=1>(int, int, int, float const *, int, float*, cudnn::detail::implicit_convolve_sgemm<float, float, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=1>*, kernel_conv_params, int, float, float, int, float, float, int, int)
                   22.51%  91.647ms      2313  39.622us  10.560us  121.47us  trt_volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1
                   21.18%  86.217ms     22902  3.7640us  1.5360us  16.640us  void genericReformat::copyPackedKernel<float, float, bool=0, bool=1, genericReformat::IdentityCoordMapper<int=4>, int=4>(unsigned int, unsigned int, void const *, genericReformat::ArrayN<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayNWithReducedDivisors<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayN, int, int, int, float const *, void*, genericReformat::ArrayN, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayN, int, int, int, float const , int=4)
                    8.89%  36.172ms      2626  13.774us  8.4160us  19.840us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=4, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=4, int=8, int=8, int=1, int=1, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=4, int=1Type>)
```"
37351,tf.where raises ValueError for RaggedTensor arguments,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): no
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): OS X
- TensorFlow installed from (source or
binary): `pip install tensorflow`
- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de410 2.1.0
- Python version: 3.7.4

**Describe the current behavior**
Calling tf.where with a RaggedTensor argument raises `ValueError: TypeError: object of type 'RaggedTensor' has no len()`.

**Describe the expected behavior**
No exception raised. According to https://www.tensorflow.org/api_docs/python/tf/ragged, tf.where is supposed to support RaggedTensor.

**Standalone code to reproduce the issue** 
```
import tensorflow as tf
digits = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])
tf.where(tf.equal(digits, 1), 1, 0)
```

**Other info / logs** 
```
In [4]: tf.where(tf.equal(digits, 1), 1, 0)
---------------------------------------------------------------------------
_FallbackException                        Traceback (most recent call last)
/usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py in select_v2(condition, t, e, name)
   8679         _ctx._context_handle, tld.device_name, ""SelectV2"", name,
-> 8680         tld.op_callbacks, condition, t, e)
   8681       return _result

_FallbackException: This function does not handle the case of the path where all inputs are not already EagerTensors.

During handling of the above exception, another exception occurred:

ValueError                                Traceback (most recent call last)
<ipython-input-4-a793e17a60b8> in <module>
----> 1 tf.where(tf.equal(digits, 1), 1, 0)

/usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py in where_v2(condition, x, y, name)
   3928       return gen_array_ops.where(condition=condition, name=name)
   3929   elif x is not None and y is not None:
-> 3930     return gen_math_ops.select_v2(condition=condition, t=x, e=y, name=name)
   3931   else:
   3932     raise ValueError(""x and y must both be non-None or both be None."")

/usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py in select_v2(condition, t, e, name)
   8683       try:
   8684         return select_v2_eager_fallback(
-> 8685             condition, t, e, name=name, ctx=_ctx)
   8686       except _core._SymbolicException:
   8687         pass  # Add nodes to the TensorFlow graph.

/usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py in select_v2_eager_fallback(condition, t, e, name, ctx)
   8706   _attr_T, _inputs_T = _execute.args_to_matching_eager([t, e], ctx)
   8707   (t, e) = _inputs_T
-> 8708   condition = _ops.convert_to_tensor(condition, _dtypes.bool)
   8709   _inputs_flat = [condition, t, e]
   8710   _attrs = (""T"", _attr_T)

/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py in convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)
   1312
   1313     if ret is None:
-> 1314       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
   1315
   1316     if ret is NotImplemented:

/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py in _constant_tensor_conversion_function(v, dtype, name, as_ref)
    315                                          as_ref=False):
    316   _ = as_ref
--> 317   return constant(v, dtype=dtype, name=name)
    318
    319

/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py in constant(value, dtype, shape, name)
    256   """"""
    257   return _constant_impl(value, dtype, shape, name, verify_shape=False,
--> 258                         allow_broadcast=True)
    259
    260

/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast)
    264   ctx = context.context()
    265   if ctx.executing_eagerly():
--> 266     t = convert_to_eager_tensor(value, ctx, dtype)
    267     if shape is None:
    268       return t

/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py in convert_to_eager_tensor(value, ctx, dtype)
     94       dtype = dtypes.as_dtype(dtype).as_datatype_enum
     95   ctx.ensure_initialized()
---> 96   return ops.EagerTensor(value, ctx.device_name, dtype)
     97
     98

ValueError: TypeError: object of type 'RaggedTensor' has no len()
```"
37347,Quantization problem while reproducing person detection example,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution: Ubuntu 18.04.4 LTS
- Tensorflow version: 1.15
- Target platform: OpenMV Cam H7 (https://openmv.io/products/openmv-cam-h7)

**Problem description**
I am trying to reproduce the person detection example (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/person_detection/training_a_model.md).
The document is not completely updated but with slight modifications I am able to train, freeze and convert the model into TFLite.

Because of the target, I need full integer quantization so, I set the input and output as uint8.

When I try to load the model in the OpenMV, the quantization layer fails with the following error:

> _tensorflow/lite/micro/kernels/quantize.cc:51 input->type == kTfLiteFloat32 || input->type == kTfLiteInt16 was not true._


I guess that the problem is in the post-training quantization, as the output model has an input of uint8 type and afterwards, it has a quantize layer which tries to convert uint8 to int8.


**Post-training quantization**

```
def representative_dataset_gen():
  record_iterator = tf.python_io.tf_record_iterator(path='coco_dataset/val.record-00000-of-00010')
  count = 0
  for string_record in record_iterator:
    example = tf.train.Example()
    example.ParseFromString(string_record)
    a=io.BytesIO(example.features.feature['image/encoded'].bytes_list.value[0])
    image = PIL.Image.open(a)
    image = image.resize((96, 96))
    image = image.convert('L')
    array = np.array(image)
    array = np.expand_dims(array, axis=2)
    array = np.expand_dims(array, axis=0)
    array = ((array / 127.5) - 1.0).astype(np.float32)
    yield([array])
    count += 1
    if count > 300:
        break

converter = tf.lite.TFLiteConverter.from_frozen_graph('frozen.pb',['input'], ['MobilenetV1/Predictions/Reshape_1'])
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.uint8
converter.inference_output_type = tf.uint8
converter.representative_dataset = representative_dataset_gen
 
tflite_quant_model = converter.convert()
open(""quantized.tflite"", ""wb"").write(tflite_quant_model)
```

"
37346,Training of tf.keras.layers.RNN with preceding Reshape using tf.shape fails,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution: Linux Ubuntu 18.04
- Mobile device if the issue happens on mobile device: -
- TensorFlow installed from: binary
- TensorFlow version: 2.2.0-dev20200303
- Python version: 3.6.9
- Bazel version (if compiling from source): -
- GCC/Compiler version (if compiling from source): -
- CUDA/cuDNN version: CPU only
- GPU model and memory: CPU only

**Describe the current behavior**
The model compiles, but training fails.

**Describe the expected behavior**
I would expect training to succeed.

**Code to reproduce the issue**
```python
import tensorflow as tf
import numpy as np

batch_size = 1
num_units = 1
dim_other = 10

# build model
model = tf.keras.Sequential()

model.add(tf.keras.layers.Input(shape=(None, dim_other)))

dim_time_read = tf.shape(model.output)[1]
model.add(tf.keras.layers.Reshape(target_shape=(dim_time_read, dim_other)))

model.add(tf.keras.layers.RNN(cell=tf.keras.layers.GRUCell(units=num_units)))

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# train
training_input1 = np.zeros([batch_size, 1, dim_other])
training_input2 = np.zeros([batch_size, 2, dim_other])
training_output = np.zeros([batch_size, num_units])

model.fit(training_input1, training_output)
model.fit(training_input2, training_output)
```

**Other info / logs**
Apparently, the Reshape layer is not required in this stripped down example. If one leaves it out, training succeeds. However, in my actual setup I need a Reshape layer before the RNN layer due to a preceding Conv2D layer.

The context is training a CRNN with variable length input. Using padding and masking is not an option unfortunately, since tf.keras.layers.Conv2D does currently not support masking.

If my usage of tf.shape is wrong, if there is an alternative or workaround, please let me know.

**Traceback in case of failure:**
```bash
Traceback (most recent call last):
  File ""/home/test/.local/lib/python3.6/site-packages/tensorflow/python/eager/execute.py"", line 60, in quick_execute
    inputs, attrs, num_outputs)
TypeError: An op outside of the function building code is being passed
a ""Graph"" tensor. It is possible to have Graph tensors
leak out of the function building context by including a
tf.init_scope in your function building code.
For example, the following function will fail:
  @tf.function
  def has_init_scope():
    my_constant = tf.constant(1.)
    with tf.init_scope():
      added = my_constant * 2
The graph tensor has name: strided_slice:0

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""test.py"", line 27, in <module>
    model.fit(training_input, training_output)
  File ""/home/test/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 62, in _method_wrapper
    return method(self, *args, **kwargs)
  File ""/home/test/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 775, in fit
    tmp_logs = train_function(iterator)
  File ""/home/test/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 580, in __call__
    result = self._call(*args, **kwds)
  File ""/home/test/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 644, in _call
    return self._stateless_fn(*args, **kwds)
  File ""/home/test/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 2420, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File ""/home/test/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 1665, in _filtered_call
    self.captured_inputs)
  File ""/home/test/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 1746, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""/home/test/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 598, in call
    ctx=ctx)
  File ""/home/test/.local/lib/python3.6/site-packages/tensorflow/python/eager/execute.py"", line 74, in quick_execute
    ""tensors, but found {}"".format(keras_symbolic_tensors))
tensorflow.python.eager.core._SymbolicException: Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'strided_slice:0' shape=() dtype=int32>]

```
"
37345,freebsd build tensor v2.1.0,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
FreeBSD  12.1-RELEASE-p1 FreeBSD 12.1-RELEASE-p1 GENERIC  amd64

- TensorFlow installed from (source or binary):
source, 
- TensorFlow version:
v2.1.0
- Python version:
python --version
Python 3.7.6
- Installed using virtualenv? pip? conda?:
pip
- Bazel version (if compiling from source):
bazel --version
bazel 0.29.0
- GCC/Compiler version (if compiling from source):
gcc --version
gcc (FreeBSD Ports Collection) 9.2.0

- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**
as per https://www.tensorflow.org/install/source

running: bazel build --config=opt --verbose_failures //tensorflow/tools/pip_package:build_pip_package

**Provide the exact sequence of commands / steps that you executed before running into the problem**

```
INFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (0 packages loaded, 0 targets configured).
INFO: Found 1 target...
ERROR: /root/.cache/bazel/_bazel_root/fbc06f9baef46cade6e35d9e4137e37c/external/local_config_mlir/BUILD:1834:1: Linking of rule '@local_config_mlir//:mlir-tblgen' failed (Exit 1)
ld: error: undefined symbol: backtrace
>>> referenced by Signals.cpp
>>>               Signals.o:(PrintStackTraceSignalHandler(void*)) in archive bazel-out/host/bin/external/llvm/libsupport.a

ld: error: undefined symbol: backtrace_symbols_fd
>>> referenced by Signals.cpp
>>>               Signals.o:(PrintStackTraceSignalHandler(void*)) in archive bazel-out/host/bin/external/llvm/libsupport.a
clang: error: linker command failed with exit code 1 (use -v to see invocation)
Target //tensorflow/tools/pip_package:build_pip_package failed to build
ERROR: /opt/tensorflow/tensorflow/python/tools/BUILD:97:1 Linking of rule '@local_config_mlir//:mlir-tblgen' failed (Exit 1)
INFO: Elapsed time: 0.282s, Critical Path: 0.05s
INFO: 1 process: 1 local.
FAILED: Build did NOT complete successfully
```


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
37342,TF2.1 cannot save model trained by distribution strategy while TF2.0 could do,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): 
Yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): 
Ubuntu 16.04

- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): 
TF2.1 and TF2.0

- Python version: - Bazel
version (if compiling from source):
From source

- CUDA/cuDNN version: - GPU model and memory:
CUDA 10.1

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
The model trained under distribution strategy could not be saved in TF2.1 while it could be saved in TF2.0.


**Describe the expected behavior**

**Standalone code to reproduce the issue** 
The exapmle code I copy from another issue [issue ](https://github.com/tensorflow/tensorflow/issues/36477):
```python
import tensorflow as tf

def build_and_compile_model():
    
    input = tf.keras.Input((20,))
    x = tf.keras.layers.BatchNormalization()(input)
    y = tf.keras.layers.Dense(2)
    
    model = tf.keras.Model(inputs=input, outputs=y)
    
    model.compile(
        loss=tf.keras.losses.sparse_categorical_crossentropy,
        optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),
        metrics=['accuracy'])
    
    return model

strategy = tf.distribute.MirroredStrategy()
with strategy.scope():
    model = build_and_compile_model()
model.save('test', save_format='tf')
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
![image](https://user-images.githubusercontent.com/33815430/75964388-1c719300-5f02-11ea-900b-9d7372607abe.png)
#https://github.com/tensorflow/tensorflow/issues/36477


"
37341,cp: cannot stat '/usr/include/x86_64-linux-gnu/NvInferPlugin.h': No such file or directory,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 19

- TensorFlow version: branch r2.1
- Python version: 3.7
- Bazel version (if compiling from source): 0.29
- GCC/Compiler version (if compiling from source): 
hadi@hadi-GL502VSK:~/tensorflow$ gcc --version
gcc (Ubuntu 9.2.1-9ubuntu2) 9.2.1 20191008
Copyright (C) 2019 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

- CUDA/cuDNN version: 10.1
- GPU model and memory: 1070 GTX 8 GB GDDR5

```
hadi@hadi-GL502VSK:~/tensorflow$ bazel build --verbose_failures --config=v2 //tensorflow/tools/pip_package:build_pip_package
WARNING: The following configs were expanded more than once: [v2]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=80
INFO: Reading rc options for 'build' from /home/hadi/tensorflow/.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone --strategy=Genrule=standalone -c opt --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --config=v2
INFO: Reading rc options for 'build' from /home/hadi/tensorflow/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/usr/bin/python3 --action_env PYTHON_LIB_PATH=/usr/local/lib/python3.7/dist-packages --python_path=/usr/bin/python3 --config=xla --config=tensorrt --action_env CUDA_TOOLKIT_PATH=/usr/local/cuda --action_env TF_CUDA_COMPUTE_CAPABILITIES=6.1 --action_env LD_LIBRARY_PATH=/usr/local/cuda-10.1/lib64 --action_env GCC_HOST_COMPILER_PATH=/usr/bin/x86_64-linux-gnu-gcc-9 --config=cuda --action_env TF_CONFIGURE_IOS=0
INFO: Found applicable config definition build:v2 in file /home/hadi/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:xla in file /home/hadi/tensorflow/.tf_configure.bazelrc: --define with_xla_support=true
INFO: Found applicable config definition build:tensorrt in file /home/hadi/tensorflow/.bazelrc: --action_env TF_NEED_TENSORRT=1
INFO: Found applicable config definition build:cuda in file /home/hadi/tensorflow/.bazelrc: --config=using_cuda --define=using_cuda_nvcc=true
INFO: Found applicable config definition build:using_cuda in file /home/hadi/tensorflow/.bazelrc: --define=using_cuda=true --action_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain
INFO: Found applicable config definition build:v2 in file /home/hadi/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
DEBUG: /home/hadi/.cache/bazel/_bazel_hadi/9c22e2cd2b722a33d5eae32d8a25ecc1/external/bazel_tools/tools/cpp/lib_cc_configure.bzl:118:5: 
Auto-Configuration Warning: 'TMP' environment variable is not set, using 'C:\Windows\Temp' as default
INFO: Build options --action_env and --define have changed, discarding analysis cache.
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:abi.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:byte_order.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:context.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:cord.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:cpu_feature_guard.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:cpu_info.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:cuda_libdevice_path.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:demangle.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:env.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:env_time.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:error.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:file_statistics.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:file_system.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:file_system_helper.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:fingerprint.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:grpc_services.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:host_info.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:human_readable_json.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:init_main.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:load_library.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:logger.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:logging.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:macros.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:mem.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:monitoring.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:mutex.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:net.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:notification.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:null_file_system.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:numa.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:numbers.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:platform.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:platform_strings.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:platform_strings_computed.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:prefetch.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:profile_utils/android_armv7a_cpu_utils_helper.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:profile_utils/clock_cycle_profiler.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:profile_utils/cpu_utils.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:profile_utils/i_cpu_utils_helper.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:protobuf.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:protobuf_compiler.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:protobuf_internal.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:regexp.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:rocm_rocdl_path.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:scanner.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:snappy.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:stacktrace.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:stacktrace_handler.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:strcat.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:stream_executor_no_cuda.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:stringpiece.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:subprocess.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:tensor_coding.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:test.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:test_benchmark.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:threadpool.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:threadpool_interface.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:threadpool_options.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:tracing.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:tstring.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:types.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:unbounded_work_queue.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:str_util.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/bfloat16:bfloat16.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/core:arena.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/core:bitmap.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/core:bits.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/core:blocking_counter.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/core:coding.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/core:errors.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/core:notification.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/core:raw_coding.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/core:refcount.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/core:status.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/core:status_test_util.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/core:stringpiece.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/core:threadpool.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/core:threadpool_interface.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/core:threadpool_options.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/gtl:array_slice.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/gtl:cleanup.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/gtl:compactptrset.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/gtl:edit_distance.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/gtl:flatmap.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/gtl:flatrep.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/gtl:flatset.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/gtl:inlined_vector.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/gtl:int_type.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/gtl:iterator_range.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/gtl:manual_constructor.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/gtl:map_util.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/gtl:optional.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/gtl:priority_queue_util.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/gtl:subtle/map_traits.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/gtl:top_n.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/hash:crc32c.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/hash:hash.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:block.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:block_builder.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:buffered_inputstream.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:compression.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:format.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:inputbuffer.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:inputstream_interface.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:iterator.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:path.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:proto_encode_helper.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:random_inputstream.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:record_reader.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:record_writer.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:snappy/snappy_inputbuffer.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:snappy/snappy_outputbuffer.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:table.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:table_builder.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:table_options.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:two_level_iterator.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:zlib_compression_options.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:zlib_inputstream.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:zlib_outputbuffer.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/random:distribution_sampler.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/random:exact_uniform_int.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/random:philox_random.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/random:philox_random_test_utils.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/random:random.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/random:random_distributions.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/random:simple_philox.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/random:weighted_picker.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/strings:base64.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/strings:numbers.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/strings:ordered_code.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/strings:proto_serialization.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/strings:proto_text_util.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/strings:scanner.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/strings:str_util.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/strings:strcat.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/strings:stringprintf.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/math:math_util.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2172:1: in linkstatic attribute of cc_library rule //tensorflow/core:lib_internal: setting 'linkstatic=1' is recommended if there are no object files
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:abi.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:byte_order.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:context.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:cord.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:cpu_feature_guard.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:cpu_info.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:cuda_libdevice_path.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:demangle.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:env.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:env_time.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:error.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:file_statistics.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:file_system.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:file_system_helper.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:fingerprint.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:grpc_services.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:host_info.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:human_readable_json.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:init_main.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:load_library.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:logger.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:logging.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:macros.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:mem.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:monitoring.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:mutex.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:net.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:notification.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:null_file_system.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:numa.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:numbers.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:platform.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:platform_strings.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:platform_strings_computed.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:prefetch.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:profile_utils/android_armv7a_cpu_utils_helper.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:profile_utils/clock_cycle_profiler.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:profile_utils/cpu_utils.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:profile_utils/i_cpu_utils_helper.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:protobuf.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:protobuf_compiler.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:protobuf_internal.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:regexp.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:rocm_rocdl_path.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:scanner.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:snappy.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:stacktrace.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:stacktrace_handler.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:strcat.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:stream_executor_no_cuda.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:stringpiece.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:subprocess.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:tensor_coding.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:test.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:test_benchmark.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:threadpool.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:threadpool_interface.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:threadpool_options.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:tracing.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:tstring.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:types.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:unbounded_work_queue.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:str_util.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/bfloat16:bfloat16.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/core:arena.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/core:bitmap.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/core:bits.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/core:blocking_counter.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/core:coding.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/core:errors.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/core:notification.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/core:raw_coding.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/core:refcount.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/core:status.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/core:status_test_util.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/core:stringpiece.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/core:threadpool.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/core:threadpool_interface.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/core:threadpool_options.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/gtl:array_slice.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/gtl:cleanup.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/gtl:compactptrset.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/gtl:edit_distance.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/gtl:flatmap.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/gtl:flatrep.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/gtl:flatset.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/gtl:inlined_vector.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/gtl:int_type.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/gtl:iterator_range.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/gtl:manual_constructor.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/gtl:map_util.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/gtl:optional.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/gtl:priority_queue_util.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/gtl:subtle/map_traits.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/gtl:top_n.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/hash:crc32c.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/hash:hash.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:block.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:block_builder.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:buffered_inputstream.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:compression.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:format.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:inputbuffer.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:inputstream_interface.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:iterator.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:path.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:proto_encode_helper.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:random_inputstream.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:record_reader.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:record_writer.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:snappy/snappy_inputbuffer.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:snappy/snappy_outputbuffer.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:table.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:table_builder.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:table_options.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:two_level_iterator.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:zlib_compression_options.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:zlib_inputstream.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:zlib_outputbuffer.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/random:distribution_sampler.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/random:exact_uniform_int.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/random:philox_random.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/random:philox_random_test_utils.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/random:random.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/random:random_distributions.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/random:simple_philox.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/random:weighted_picker.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/strings:base64.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/strings:numbers.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/strings:ordered_code.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/strings:proto_serialization.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/strings:proto_text_util.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/strings:scanner.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/strings:str_util.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/strings:strcat.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/strings:stringprintf.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/math:math_util.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:default/monitoring.cc' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:default/stacktrace_handler.cc' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:profile_utils/android_armv7a_cpu_utils_helper.cc' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:profile_utils/clock_cycle_profiler.cc' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:profile_utils/cpu_utils.cc' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2347:12: in srcs attribute of cc_library rule //tensorflow/core:gif_internal: please do not import '//tensorflow/core/platform:gif.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2760:1: in srcs attribute of cc_library rule //tensorflow/core:stream_executor: please do not import '//tensorflow/core/platform:stream_executor.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_cuda_library', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/core/BUILD:2760:1
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2367:12: in srcs attribute of cc_library rule //tensorflow/core:jpeg_internal: please do not import '//tensorflow/core/platform:jpeg.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2650:1: in srcs attribute of cc_library rule //tensorflow/core:framework_internal_impl: please do not import '//tensorflow/core/util/sparse:dim_comparator.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_cuda_library', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/core/BUILD:2650:1
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2650:1: in srcs attribute of cc_library rule //tensorflow/core:framework_internal_impl: please do not import '//tensorflow/core/util/sparse:group_iterator.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_cuda_library', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/core/BUILD:2650:1
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2650:1: in srcs attribute of cc_library rule //tensorflow/core:framework_internal_impl: please do not import '//tensorflow/core/util/sparse:sparse_tensor.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_cuda_library', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/core/BUILD:2650:1
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2650:1: in srcs attribute of cc_library rule //tensorflow/core:framework_internal_impl: please do not import '//tensorflow/core/util/sparse:group_iterator.cc' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_cuda_library', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/core/BUILD:2650:1
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2605:1: in srcs attribute of cc_library rule //tensorflow/core:framework_internal: please do not import '//tensorflow/core/util/sparse:dim_comparator.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_cuda_library', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/core/BUILD:2605:1
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2605:1: in srcs attribute of cc_library rule //tensorflow/core:framework_internal: please do not import '//tensorflow/core/util/sparse:group_iterator.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_cuda_library', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/core/BUILD:2605:1
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2605:1: in srcs attribute of cc_library rule //tensorflow/core:framework_internal: please do not import '//tensorflow/core/util/sparse:sparse_tensor.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_cuda_library', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/core/BUILD:2605:1
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2605:1: in linkstatic attribute of cc_library rule //tensorflow/core:framework_internal: setting 'linkstatic=1' is recommended if there are no object files. Since this rule was created by the macro 'tf_cuda_library', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/core/BUILD:2605:1
WARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2777:12: in srcs attribute of cc_library rule //tensorflow/core:stream_executor_no_cuda: please do not import '//tensorflow/core/platform:stream_executor.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:633:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_checkpoint_reader.so: please do not import '//tensorflow/c:checkpoint_reader.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16
WARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:633:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_checkpoint_reader.so: please do not import '//tensorflow/c:tf_status_helper.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16
WARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:633:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_checkpoint_reader.so: please do not import '//tensorflow/c:c_api.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16
WARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:633:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_checkpoint_reader.so: please do not import '//tensorflow/c:c_api_experimental.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16
WARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:633:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_checkpoint_reader.so: please do not import '//tensorflow/c:tf_attrtype.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16
WARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:633:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_checkpoint_reader.so: please do not import '//tensorflow/c:tf_datatype.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16
WARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:633:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_checkpoint_reader.so: please do not import '//tensorflow/c:tf_file_statistics.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16
WARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:633:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_checkpoint_reader.so: please do not import '//tensorflow/c:tf_status.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16
WARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:633:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_checkpoint_reader.so: please do not import '//tensorflow/c:tf_tensor.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16
WARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:633:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_checkpoint_reader.so: please do not import '//tensorflow/c/eager:c_api.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16
WARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:684:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_toco_api.so: please do not import '//tensorflow/lite/toco/python:toco_python_api.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16
WARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:492:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_quantize_training.so: please do not import '//tensorflow/core:graph/quantize_training.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16
WARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:583:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_scoped_annotation.so: please do not import '//tensorflow/core/platform:annotation.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16
WARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:583:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_scoped_annotation.so: please do not import '//tensorflow/core/profiler/internal:python_scoped_annotation.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16
WARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:667:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_py_exception_registry.so: please do not import '//tensorflow/c:c_api.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16
WARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:667:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_py_exception_registry.so: please do not import '//tensorflow/c:c_api_experimental.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16
WARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:667:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_py_exception_registry.so: please do not import '//tensorflow/c:tf_attrtype.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16
WARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:667:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_py_exception_registry.so: please do not import '//tensorflow/c:tf_datatype.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16
WARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:667:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_py_exception_registry.so: please do not import '//tensorflow/c:tf_file_statistics.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16
WARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:667:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_py_exception_registry.so: please do not import '//tensorflow/c:tf_status.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16
WARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:667:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_py_exception_registry.so: please do not import '//tensorflow/c:tf_tensor.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16
WARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:667:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_py_exception_registry.so: please do not import '//tensorflow/c/eager:c_api.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16
WARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:572:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_stacktrace_handler.so: please do not import '//tensorflow/core/platform:stacktrace_handler.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16
WARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:526:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_util_port.so: please do not import '//tensorflow/core:util/port.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16
WARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:615:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_traceme.so: please do not import '//tensorflow/core/profiler/internal:python_traceme.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16
WARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:615:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_traceme.so: please do not import '//tensorflow/core/profiler/internal:traceme_recorder.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16
WARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:615:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_traceme.so: please do not import '//tensorflow/core/profiler/lib:traceme.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16
WARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:600:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_transform_graph.so: please do not import '//tensorflow/tools/graph_transforms:transform_graph.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16
WARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:600:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_transform_graph.so: please do not import '//tensorflow/tools/graph_transforms:transform_utils.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16
WARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:4127:1: in py_library rule //tensorflow/python:standard_ops: target '//tensorflow/python:standard_ops' depends on deprecated target '//tensorflow/python/ops/distributions:distributions': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.distributions will not receive new features, and will be removed by early 2019. You should update all usage of `tf.distributions` to `tfp.distributions`.
WARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:86:1: in py_library rule //tensorflow/python:no_contrib: target '//tensorflow/python:no_contrib' depends on deprecated target '//tensorflow/python/ops/distributions:distributions': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.distributions will not receive new features, and will be removed by early 2019. You should update all usage of `tf.distributions` to `tfp.distributions`.
INFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (0 packages loaded, 30564 targets configured).
INFO: Found 1 target...
ERROR: /home/hadi/.cache/bazel/_bazel_hadi/9c22e2cd2b722a33d5eae32d8a25ecc1/external/local_config_tensorrt/BUILD:52:1: Executing genrule @local_config_tensorrt//:tensorrt_include failed (Exit 1)
cp: cannot stat '/usr/include/x86_64-linux-gnu/NvInferPlugin.h': No such file or directory
Target //tensorflow/tools/pip_package:build_pip_package failed to build

```

**Describe the problem**
I keep getting the error **cp: cannot stat '/usr/include/x86_64-linux-gnu/NvInferPlugin.h': No such file or directory** when I try to build. I dont know how to get the file


**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Config:
hadi@hadi-GL502VSK:~/tensorflow$ ./configure 
WARNING: Running Bazel server needs to be killed, because the startup options are different.
WARNING: Waiting for server process to terminate (waited 5 seconds, waiting at most 60)
WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"".
You have bazel 0.29.1 installed.
Please specify the location of python. [Default is /usr/bin/python]: /usr/bin/python3


Found possible Python library paths:
  /usr/local/lib/python3.7/dist-packages
  /usr/lib/python3/dist-packages
Please input the desired Python library path to use.  Default is [/usr/local/lib/python3.7/dist-packages]

Do you wish to build TensorFlow with XLA JIT support? [Y/n]: 
XLA JIT support will be enabled for TensorFlow.

Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: 
No OpenCL SYCL support will be enabled for TensorFlow.

Do you wish to build TensorFlow with ROCm support? [y/N]: 
No ROCm support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: y
CUDA support will be enabled for TensorFlow.

Do you wish to build TensorFlow with TensorRT support? [y/N]: y
TensorRT support will be enabled for TensorFlow.

Found CUDA 10.1 in:
    /usr/local/cuda/lib64
    /usr/local/cuda/include
Found cuDNN 7 in:
    /usr/lib/x86_64-linux-gnu
    /usr/include
Found TensorRT 6 in:
    /usr/lib/x86_64-linux-gnu
    /usr/include/x86_64-linux-gnu


Please specify a list of comma-separated CUDA compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only supports compute capabilities >= 3.5 [Default is: 6.1]: 


Do you want to use clang as CUDA compiler? [y/N]: 
nvcc will be used as CUDA compiler.

Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: 


Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native -Wno-sign-compare]: 


Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: 
Not configuring the WORKSPACE for Android builds.

Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details.
	--config=mkl         	# Build with MKL support.
	--config=monolithic  	# Config for mostly static monolithic build.
	--config=ngraph      	# Build with Intel nGraph support.
	--config=numa        	# Build with NUMA support.
	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects.
	--config=v2          	# Build TensorFlow 2.x instead of 1.x.
Preconfigured Bazel build configs to DISABLE default on features:
	--config=noaws       	# Disable AWS S3 filesystem support.
	--config=nogcp       	# Disable GCP support.
	--config=nohdfs      	# Disable HDFS support.
	--config=nonccl      	# Disable NVIDIA NCCL support.
Configuration finished

"
37340,dataset file-based cache uses excessively amount of memory,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): 
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): 
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): 
- Python version: - Bazel
version (if compiling from source):
- GCC/Compiler version (if compiling from
source): 
- CUDA/cuDNN version: - GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
file-based dataset cache increase excessively amount of memory.

**Describe the expected behavior**

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```
  dataset = dataset.interleave(filename_to_dataset, cycle_length=num_parallel_calls,
                               num_parallel_calls=num_parallel_reads)

  dataset = dataset.cache(""cache"")
  dataset = readers._maybe_shuffle_and_repeat(
      dataset, num_epochs, shuffle, shuffle_buffer_size, shuffle_seed)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
37339,ValueError: Could not find matching function to call loaded from the SavedModel.,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): 
- OS Platform and Distribution :  Windows 10
- TensorFlow installed from: pip, tf 2.1.0,  cpu
- Python version:  3.7.4

**build a simple network**
```
import tensorflow as tf
from tensorflow.keras import layers
class Model():
    def __init__(self):
        self.build_model()

    def build_model(self):
        input1 = layers.Input(shape=(5,))
        input2 = layers.Input(shape=(5,))

        out1 = layers.Dense(1)(input1)
        out2 = layers.Dense(1)(input2)
        out = out1 - out2
        out = tf.nn.sigmoid(out)

        self.model = tf.keras.Model(inputs=[input1, input2], outputs=out)

model = Model()
s1 = ""exp\\model""
model.model.save(s1)
model2 = tf.keras.models.load_model(s1)
```

**Test Code**
```
model = Model()
s1 = ""exp\\model""
model.model.save(s1)
model2 = tf.keras.models.load_model(s1)
```

**Error Info**
```
Traceback (most recent call last):
  File ""e:\workspace\work\Study\pytorch_demos\demo5.py"", line 22, in <module>
    model2 = tf.keras.models.load_model(s1)
  File ""C:\Users\Administrator\Anaconda3\Lib\site-packages\tensorflow_core\python\keras\saving\save.py"", line 150, in load_model
    return saved_model_load.load(filepath, compile)
  File ""C:\Users\Administrator\Anaconda3\Lib\site-packages\tensorflow_core\python\keras\saving\saved_model\load.py"", line 89, in load
    model = tf_load.load_internal(path, loader_cls=KerasObjectLoader)
  File ""C:\Users\Administrator\Anaconda3\Lib\site-packages\tensorflow_core\python\saved_model\load.py"", line 552, in load_internal
    export_dir)
  File ""C:\Users\Administrator\Anaconda3\Lib\site-packages\tensorflow_core\python\keras\saving\saved_model\load.py"", line 119, in __init__
    self._finalize()
  File ""C:\Users\Administrator\Anaconda3\Lib\site-packages\tensorflow_core\python\keras\saving\saved_model\load.py"", line 157, in _finalize
    created_layers={layer.name: layer for layer in node.layers})
  File ""C:\Users\Administrator\Anaconda3\Lib\site-packages\tensorflow_core\python\keras\engine\network.py"", line 1903, in reconstruct_from_config
    process_node(layer, node_data)
  File ""C:\Users\Administrator\Anaconda3\Lib\site-packages\tensorflow_core\python\keras\engine\network.py"", line 1851, in process_node
    output_tensors = layer(input_tensors, **kwargs)
  File ""C:\Users\Administrator\Anaconda3\Lib\site-packages\tensorflow_core\python\keras\engine\base_layer.py"", line 773, in __call__
    outputs = call_fn(cast_inputs, *args, **kwargs)
  File ""C:\Users\Administrator\Anaconda3\Lib\site-packages\tensorflow_core\python\keras\saving\saved_model\utils.py"", line 59, in return_outputs_and_add_losses
    outputs, losses = fn(inputs, *args, **kwargs)
  File ""C:\Users\Administrator\Anaconda3\Lib\site-packages\tensorflow_core\python\eager\def_function.py"", line 568, in __call__
    result = self._call(*args, **kwds)
  File ""C:\Users\Administrator\Anaconda3\Lib\site-packages\tensorflow_core\python\eager\def_function.py"", line 615, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File ""C:\Users\Administrator\Anaconda3\Lib\site-packages\tensorflow_core\python\eager\def_function.py"", line 497, in _initialize
    *args, **kwds))
  File ""C:\Users\Administrator\Anaconda3\Lib\site-packages\tensorflow_core\python\eager\function.py"", line 2389, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""C:\Users\Administrator\Anaconda3\Lib\site-packages\tensorflow_core\python\eager\function.py"", line 2703, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""C:\Users\Administrator\Anaconda3\Lib\site-packages\tensorflow_core\python\eager\function.py"", line 2593, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""C:\Users\Administrator\Anaconda3\Lib\site-packages\tensorflow_core\python\framework\func_graph.py"", line 978, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""C:\Users\Administrator\Anaconda3\Lib\site-packages\tensorflow_core\python\eager\def_function.py"", line 439, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""C:\Users\Administrator\Anaconda3\Lib\site-packages\tensorflow_core\python\saved_model\function_deserialization.py"", line 262, in restored_function_body
    ""\n\n"".join(signature_descriptions)))
ValueError: Could not find matching function to call loaded from the SavedModel. Got:
  Positional arguments (1 total):
    * Tensor(""inputs:0"", shape=(None, 1), dtype=float32)
  Keyword arguments: {}

Expected these arguments to match one of the following 1 option(s):

Option 1:
  Positional arguments (1 total):
    * [TensorSpec(shape=(None, 1), dtype=tf.float32, name='inputs/0')]
  Keyword arguments: {}
```

**But removing the line will not cause the error** 
```
# Correct if not using this line
out = tf.nn.sigmoid(out)
```

### *The error is caused when the model is loaded from savedModel file. Model building process is correct.*
"
37338,"ValueError: Input 0 of layer dense_1 is incompatible with the layer: expected axis -1 of input shape to have value 2 but received input with shape [None, 5]","**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): 
- OS Platform and Distribution :  Windows 10
- TensorFlow installed from: pip, tf 2.1.0,  cpu
- Python version: - 3.7.4

**build a simple network**
```
import tensorflow as tf
from tensorflow.keras import layers
class Model():
    def __init__(self):
        self.build_model()

    def build_model(self):
        input1 = layers.Input(shape=5)

        net = tf.keras.models.Sequential([
            layers.Dense(2),
            layers.Dense(1),
        ])

        out1 = net(input1)
        """"""
        out1 = layers.Dense(2)(input1)
        out1 = layers.Dense(1)(out1)
        """"""

        self.model = tf.keras.Model(inputs=input1, outputs=out1)
```

**Test Code**
```
model = Model()
s1 = ""exp\\model""
model.model.save(s1)
model2 = tf.keras.models.load_model(s1)
```

**Error Info**
```
Traceback (most recent call last):
  File ""e:\workspace\work\Study\pytorch_demos\demo5.py"", line 26, in <module>
    model2 = tf.keras.models.load_model(s1)
  File ""C:\Users\Administrator\Anaconda3\Lib\site-packages\tensorflow_core\python\keras\saving\save.py"", line 150, in load_model
    return saved_model_load.load(filepath, compile)
  File ""C:\Users\Administrator\Anaconda3\Lib\site-packages\tensorflow_core\python\keras\saving\saved_model\load.py"", line 89, in load
    model = tf_load.load_internal(path, loader_cls=KerasObjectLoader)
  File ""C:\Users\Administrator\Anaconda3\Lib\site-packages\tensorflow_core\python\saved_model\load.py"", line 552, in load_internal
    export_dir)
  File ""C:\Users\Administrator\Anaconda3\Lib\site-packages\tensorflow_core\python\keras\saving\saved_model\load.py"", line 119, in __init__
    self._finalize()
  File ""C:\Users\Administrator\Anaconda3\Lib\site-packages\tensorflow_core\python\keras\saving\saved_model\load.py"", line 151, in _finalize
    node.add(layer)
  File ""C:\Users\Administrator\Anaconda3\Lib\site-packages\tensorflow_core\python\training\tracking\base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""C:\Users\Administrator\Anaconda3\Lib\site-packages\tensorflow_core\python\keras\engine\sequential.py"", line 203, in add
    output_tensor = layer(self.outputs[0])
  File ""C:\Users\Administrator\Anaconda3\Lib\site-packages\tensorflow_core\python\keras\engine\base_layer.py"", line 737, in __call__
    self.name)
  File ""C:\Users\Administrator\Anaconda3\Lib\site-packages\tensorflow_core\python\keras\engine\input_spec.py"", line 213, in assert_input_compatibility
    ' but received input with shape ' + str(shape))
ValueError: Input 0 of layer dense_1 is incompatible with the layer: expected axis -1 of input shape to have value 2 but received input with shape [None, 5]
```

**But following usage will not cause the error** 
```
# Correct if not using tf.keras.Sequential
out1 = layers.Dense(2)(input1)
out1 = layers.Dense(1)(out1)
```

### *The error is caused when the model is loaded from savedModel file. Model building process is correct.*
"
37337,libmkl_intel.so and libiomp5.so are not being copied for libtensorflow.so build,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.1 (v2.1 tag)
- Python version: 3.7
- Bazel version (if compiling from source): 0.29.1
- GCC/Compiler version (if compiling from source): 7.5.0
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A



**Describe the problem**
When building the targets `//tensorflow:libtensorflow.so` and `//tensorflow:libtensorflow_cc.so` with `--config=mkl` while libtensorflow.so and libtensorflow_cc.so are available under `bazel-bin/tensorflow`, the MKLDNN libs aren't where we'd expect them in eg; `bazel-bin/external` or `bazel-bin/third_party`. Instead, they're in the `_solib_<some suffix>` folder where the suffix is environment specific which makes it hard to retrieve the MKL-DNN libs.

Instead, the build should symlink these libs into a more user friendly dir inside third_party or external.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
I built 2.1 //tensorflow:libtensorflow_cc.so and //tensorflow:libtensorflow.so with `--config=mkl`.
"
37336,Tensorflow fails in building `GRU` models in some cases.,"**System information**  
- Have I written custom code (as opposed to using example directory):  
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Windows 10
- TensorFlow backend (yes / no):  yes
- TensorFlow version:  1.15.0
- Python version:  3.6.9
- CUDA/cuDNN version:  -
- GPU model and memory:  -

**Describe the current behavior**  

**When I directly build a model with layer `GRU`on Tensorflow, I get some variable multiplication errors**, as shown below (raised in `tensorflow_core\python\ops\resource_variable_ops.py line 1229`).  **The error reveals unsatisfactory implementation on Tensorflow in supporting variable multiplication.** 

  ```
<class 'RuntimeError'>, RuntimeError('Variable *= value not supported. Use var.assign(var * value) to modify the variable or var = var * value to get a new Tensor object.',), <traceback object at 0x00000240961ED908>),
  ```

**Similar issues also happen in `LSTM` and `SimpleRNN`**.  For detailed parameters of `GRU`, you can refer to the following code snippet.

## Key insights

The error indicates that **the variable multiplication with format `Variable *= value` is not well supported on TensorFlow. It should be extended to full mode to conduct multiplication.  This caused Tensorflow to be unable to build the model.** 

## Code to reproduce the issue

``` python
import numpy as np
import keras.layers as L
from keras.engine import Model, Input

## Using Tensorflow as Keras backend.
## Input dtype default is float32

#GRU kwargs
kwargs = {
	'units': 2,
  	'dropout': 0.20430343923336958,
  	'recurrent_dropout': 0.7597739154146002,
  	'implementation': 2,
    'reset_after': True,
    'use_bias': True,
    'return_sequences': False,
    'return_state': False,
    'go_backwards': False,
    'stateful': True,
    'unroll': False
}

# SimpleRNN kwargs
# kwargs = {
#		'units': 2,
#  	'dropout': 0.9030407578803185,
#  	'use_bias': True,
#  	'recurrent_dropout': 0.8988069898639027,
#  	'return_sequences': False,
#  	'return_state': False,
#  	'go_backwards': True,
#  	'stateful': True,
#  	'unroll': True
#}


input = (10 * np.random.random((2,10,8)))
layer = L.recurrent.GRU(**kwargs)
#layer = L.recurrent.SimpleRNN(**kwargs)
x = Input(batch_shape=input.shape)
y = layer(x)
bk_model = Model(x, y)
print('finish')
```
"
37335,Tensorflow can run and build model with the corner case `Dense(unit=0)`,"**System information**  
- Have I written custom code (as opposed to using example directory):  
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Windows 10
- TensorFlow backend (yes / no):  yes
- TensorFlow version:  1.15.0
- Python version:  3.6.9
- CUDA/cuDNN version:  -
- GPU model and memory:  -

**Describe the current behavior**  
When I set `Dense (units = 0)`, **TensorFlow can build the model normally**. `units = 0` is an obviously  unreasonable parameter, which should be stopped before building model. But Tensorflow treats it as a normal parameter. The model saved by Tensroflow may lead to potential risk. 
Does unit = 0 have any special effect on TensorFlow? I don't see the corresponding instructions in the documentation. If not,**should Tensorflow set a check for such unreasonable parameters to avoid the risks and incorrect usages in the model?** 

**Code to reproduce the issue**  
```
import numpy as np
import keras.layers as L
import keras.backend as K
from keras.engine import Model, Input

## Using Tensorflow as Keras backend.
## Input dtype default is float32

kwargs={'units': 0}
input = (10 * np.random.random((1,32,32,16)))
layer = L.core.Dense(**kwargs)
x = Input(batch_shape=input.shape)
y = layer(x)
bk_model = Model(x, y)
print('finish')
```
"
37334,Tensorflow can build and even run a model with `Conv2D('Kernel_size=0' )`,"**System information**  
- Have I written custom code (as opposed to using example directory):  
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Win 10 & Linux Ubuntu18.04
- Tensorflow backend (yes/no): yes
- TensorFlow version:1.15.0(CPU)
- Python version: 3.6.9
- CUDA/cuDNN version: -
- GPU model and memory: -

**Describe the current behavior**  
When I build a model with unreasonable parameters  `Conv2D(kernel_size=0)` on TensorFlow, **it can run normally and even generate/save an model** . When I use this model to predict, Tensorflow spend about 5 minutes and still can't return an output.
`Conv2D(kernel_size=0)`  seems like a corner case because **in the convolution operation, it is impossible to calculate with `kernel_size=0`**

Does `kernel_size=0` have some special meaning in Tensorflow? I have not found any description about this case in documents. If no special meaning, **Should Tensorflow set a check for such unreasonable parameters to avoid the risks and incorrect usages in the model?**  

**Code to reproduce the issue**  

```
import os
import numpy as np
import keras.layers as L
from keras.models import load_model
from keras.engine import Model, Input

kwargs = {'filters': 19, 'kernel_size': 0, 'padding': 'valid', 'strides': (2, 4), 'dilation_rate': 1, 'data_format': 'channels_first'}
input = (10 * np.random.random((1,32,32,16)))
layer = L.convolutional.Conv2D(**kwargs)
x = Input(batch_shape=input.shape)
y = layer(x)
bk_model = Model(x, y)
model_path = os.path.join('./', 'model.h5')
bk_model.save(model_path, bk_model)
model = load_model(model_path)
output = model.predict(input)
print('finish')
```"
37333,ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed. (Running Adel Wheat)),"`from alinea.adel.astk_interface import AdelWheat
from alinea.astk.Weather import sample_weather


seq, weather = sample_weather()
wdata = weather.get_weather(seq)

adel = AdelWheat(nsect=2)

g = adel.setup_canopy(100)
adel.grow(g, wdata)`


Getting the error:


(adel) C:\Users\Personal\Desktop\OpenAlea research\adel\example>python test_AdelWheat.py
Traceback (most recent call last):
  File ""test_AdelWheat.py"", line 1, in <module>
    from alinea.adel.astk_interface import AdelWheat
  File ""C:\Users\Personal\Desktop\OpenAlea research\adel\src\alinea\adel\astk_interface.py"", line 6, in <module>
    from alinea.adel.AdelR import setAdel, RunAdel, genGeoAxe, checkAxeDyn, getAxeT, \
  File ""C:\Users\Personal\Desktop\OpenAlea research\adel\src\alinea\adel\AdelR.py"", line 23, in <module>
    import rpy2.robjects as robj
  File ""C:\Users\Personal\.conda\envs\adel\lib\site-packages\rpy2\robjects\__init__.py"", line 16, in <module>
    import rpy2.rinterface as rinterface
  File ""C:\Users\Personal\.conda\envs\adel\lib\site-packages\rpy2\rinterface\__init__.py"", line 92, in <module>
    from rpy2.rinterface._rinterface import (baseenv,
ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed."
37332,TFTRT Int8 calibrate out of memory,"**System information**
CentOS Linux release 7.6.1810 (Core)
TITAN Xp

CUDA Version: 10.0
CUDNN 7
Tensorflow 1.15.0
Python 2.7.5

**Describe the current behavior**
I use tftrt module to calibrate int8 model. I can convert() the model successfully, but when I do calibrate(), the memory increase crazily and use the whole memory, finally i get error:Calibration failed: Internal: Failed to build TensorRT engine

**Code to reproduce the issue**
```
converter = trt.TrtGraphConverter(input_graph_def=original_graph_def,
                                        nodes_blacklist=preserve_nodes,
                                        max_batch_size=1,
                                        max_workspace_size_bytes=(1 << 30) * 4,
                                        precision_mode=""INT8"",
                                        use_calibration=True)

new_graph_def = converter.convert()

new_graph_def = converter.calibrate(fetch_names=fetch_names,
                                          num_runs=1,
                                          feed_dict_fn=lambda: feed_dict)
```

**Other info / logs**
Cuda error in file src/implicit_gemm.cu at line 585: out of memory
Cuda error in file src/implicit_gemm.cu at line 648: out of memory
Cuda error in file src/implicit_gemm.cu at line 585: out of memory
Cuda error in file src/implicit_gemm.cu at line 648: out of memory
2020-03-04 23:13:41.703545: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-04 23:13:42.514483: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:41] DefaultLogger ../builder/cudnnCalibrator.cpp (703) - Cuda Error in add: 2 (out of memory)
2020-03-04 23:13:42.514774: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:41] DefaultLogger FAILED_ALLOCATION: std::exception
2020-03-04 23:13:42.514813: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:41] DefaultLogger ../rtExt/cuda/customWinogradConvActRunner.cpp (330) - Cuda Error in execute: 2 (out of memory)
2020-03-04 23:13:42.514843: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:41] DefaultLogger FAILED_EXECUTION: std::exception
2020-03-04 23:13:42.572025: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-03-04 23:13:43.019708: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:812] Starting calibration thread on device 0, Calibration Resource @ 0x7f6414007820
2020-03-04 23:13:43.021884: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:37] DefaultLogger Half2 support requested on hardware without native FP16 support, performance will be negatively affected.
2020-03-04 23:13:43.181361: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:41] DefaultLogger ../rtSafe/safeContext.cpp (105) - Cudnn Error in initializeCommonContext: 4 (Could not initialize cudnn, please check cudnn installation.)
2020-03-04 23:13:43.182093: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:41] DefaultLogger ../rtSafe/safeContext.cpp (105) - Cudnn Error in initializeCommonContext: 4 (Could not initialize cudnn, please check cudnn installation.)
2020-03-04 23:13:43.182185: E tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:838] Calibration failed: Internal: Failed to build TensorRT engine

"
37331,Headers in /usr/local/include cause build errors on json cpp,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS 10.15.3
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: r1.15
- Python version: 3.7.5
- Installed using virtualenv? pip? conda?: conda
- Bazel version (if compiling from source): 0.26.1
- GCC/Compiler version (if compiling from source): Apple LLVM 11.0
- CUDA/cuDNN version: NA
- GPU model and memory: NA



**Describe the problem**

`jsoncpp` build is not hermetic and uses non-system headers in `/usr/local/include` leading to a build failure if a conflicting version is installed.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

My system has version 1.9.1 of `jsoncpp` installed using homebrew. Tensorflow tries to build 1.8.4 when building from source. By default all libraries in `/usr/local/include` are on the include path. This then triggers a bug in the 1.8.4 code-base which was fixed in this [commit](https://github.com/open-source-parsers/jsoncpp/commit/83cc92161be96d7f2113a3ec9f62109d828e1eec).

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

```
ERROR: /private/var/tmp/_bazel_cjuvekar/e56ef34a0d740df121c6d8bab70f0129/external/jsoncpp_git/BUILD.bazel:5:1: C++ compilation of rule '@jsoncpp_git//:jsoncpp' failed (Exit 1): cc_wrapper.sh failed: error executing command
  (cd /private/var/tmp/_bazel_cjuvekar/e56ef34a0d740df121c6d8bab70f0129/execroot/org_tensorflow && \
  exec env - \
    PATH=/Users/cjuvekar/anaconda3/envs/tf1_15_custom/bin:/Users/cjuvekar/anaconda3/condabin:/Users/cjuvekar/local/bin:/usr/local/bin:/usr/local/sbin:/usr/bin:/bin:/usr/sbin:/sbin:/Library/TeX/texbin:/Users/cjuvekar/.fzf/bin \
    PWD=/proc/self/cwd \
  external/local_config_cc/cc_wrapper.sh -U_FORTIFY_SOURCE -fstack-protector -Wall -Wthread-safety -Wself-assign -fcolor-diagnostics -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/host/bin/external/jsoncpp_git/_objs/jsoncpp/json_value.pic.d '-frandom-seed=bazel-out/host/bin/external/jsoncpp_git/_objs/jsoncpp/json_value.pic.o' -fPIC -iquote external/jsoncpp_git -iquote bazel-out/host/bin/external/jsoncpp_git -isystem external/jsoncpp_git/include -isystem bazel-out/host/bin/external/jsoncpp_git/include -g0 '-march=native' -g0 '-DJSON_USE_EXCEPTION=0' -DJSON_HAS_INT64 -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c external/jsoncpp_git/src/lib_json/json_value.cpp -o bazel-out/host/bin/external/jsoncpp_git/_objs/jsoncpp/json_value.pic.o)
Execution platform: @bazel_tools//platforms:host_platform
In file included from external/jsoncpp_git/src/lib_json/json_value.cpp:7:
In file included from /usr/local/include/json/assertions.h:13:
/usr/local/include/json/config.h:155:9: warning: 'JSON_HAS_INT64' macro redefined [-Wmacro-redefined]
#define JSON_HAS_INT64
        ^
<command line>:5:9: note: previous definition is here
#define JSON_HAS_INT64 1
        ^
external/jsoncpp_git/src/lib_json/json_value.cpp:193:1: error: use of undeclared identifier 'Exception'; did you mean 'std::exception'?
Exception::Exception(JSONCPP_STRING const& msg)
^~~~~~~~~
std::exception
/Library/Developer/CommandLineTools/usr/bin/../include/c++/v1/exception:98:29: note: 'std::exception' declared here
class _LIBCPP_EXCEPTION_ABI exception
                            ^
external/jsoncpp_git/src/lib_json/json_value.cpp:193:12: error: missing return type for function 'Exception'; did you mean the constructor name 'exception'?
Exception::Exception(JSONCPP_STRING const& msg)
           ^~~~~~~~~
           exception
external/jsoncpp_git/src/lib_json/json_value.cpp:193:12: error: cannot define or redeclare 'exception' here because namespace 'Json' does not enclose namespace 'exception'
Exception::Exception(JSONCPP_STRING const& msg)
~~~~~~~~~~~^
external/jsoncpp_git/src/lib_json/json_value.cpp:194:10: error: use of undeclared identifier 'msg'
  : msg_(msg)
         ^
external/jsoncpp_git/src/lib_json/json_value.cpp:196:1: error: use of undeclared identifier 'Exception'; did you mean 'std::exception'?
Exception::~Exception() JSONCPP_NOEXCEPT
^~~~~~~~~
std::exception
/Library/Developer/CommandLineTools/usr/bin/../include/c++/v1/exception:98:29: note: 'std::exception' declared here
class _LIBCPP_EXCEPTION_ABI exception
                            ^
external/jsoncpp_git/src/lib_json/json_value.cpp:196:13: error: expected the class name after '~' to name a destructor
Exception::~Exception() JSONCPP_NOEXCEPT
            ^~~~~~~~~
            exception
external/jsoncpp_git/src/lib_json/json_value.cpp:198:13: error: use of undeclared identifier 'Exception'; did you mean 'std::exception'?
char const* Exception::what() const JSONCPP_NOEXCEPT
            ^~~~~~~~~
            std::exception
/Library/Developer/CommandLineTools/usr/bin/../include/c++/v1/exception:98:29: note: 'std::exception' declared here
class _LIBCPP_EXCEPTION_ABI exception
                            ^
external/jsoncpp_git/src/lib_json/json_value.cpp:198:24: error: cannot define or redeclare 'what' here because namespace 'Json' does not enclose namespace 'exception'
char const* Exception::what() const JSONCPP_NOEXCEPT
            ~~~~~~~~~~~^
external/jsoncpp_git/src/lib_json/json_value.cpp:202:1: error: use of undeclared identifier 'RuntimeError'; did you mean 'std::runtime_error'?
RuntimeError::RuntimeError(JSONCPP_STRING const& msg)
^~~~~~~~~~~~
std::runtime_error
/Library/Developer/CommandLineTools/usr/bin/../include/c++/v1/stdexcept:94:29: note: 'std::runtime_error' declared here
class _LIBCPP_EXCEPTION_ABI runtime_error
                            ^
external/jsoncpp_git/src/lib_json/json_value.cpp:202:15: error: missing return type for function 'RuntimeError'; did you mean the constructor name 'runtime_error'?
RuntimeError::RuntimeError(JSONCPP_STRING const& msg)
              ^~~~~~~~~~~~
              runtime_error
external/jsoncpp_git/src/lib_json/json_value.cpp:202:15: error: cannot define or redeclare 'runtime_error' here because namespace 'Json' does not enclose namespace 'runtime_error'
RuntimeError::RuntimeError(JSONCPP_STRING const& msg)
~~~~~~~~~~~~~~^
external/jsoncpp_git/src/lib_json/json_value.cpp:203:15: error: use of undeclared identifier 'msg'
  : Exception(msg)
              ^
external/jsoncpp_git/src/lib_json/json_value.cpp:205:1: error: use of undeclared identifier 'LogicError'
LogicError::LogicError(JSONCPP_STRING const& msg)
^
external/jsoncpp_git/src/lib_json/json_value.cpp:208:1: error: unknown type name 'JSONCPP_NORETURN'
JSONCPP_NORETURN void throwRuntimeError(JSONCPP_STRING const& msg)
^
external/jsoncpp_git/src/lib_json/json_value.cpp:208:18: error: expected unqualified-id
JSONCPP_NORETURN void throwRuntimeError(JSONCPP_STRING const& msg)
                 ^
external/jsoncpp_git/src/lib_json/json_value.cpp:212:1: error: unknown type name 'JSONCPP_NORETURN'
JSONCPP_NORETURN void throwLogicError(JSONCPP_STRING const& msg)
^
external/jsoncpp_git/src/lib_json/json_value.cpp:212:18: error: expected unqualified-id
JSONCPP_NORETURN void throwLogicError(JSONCPP_STRING const& msg)
                 ^
external/jsoncpp_git/src/lib_json/json_value.cpp:225:8: error: no member named 'CommentInfo' in 'Json::Value'
Value::CommentInfo::CommentInfo() : comment_(0)
~~~~~~~^
external/jsoncpp_git/src/lib_json/json_value.cpp:228:8: error: no member named 'CommentInfo' in 'Json::Value'
Value::CommentInfo::~CommentInfo() {
~~~~~~~^
fatal error: too many errors emitted, stopping now [-ferror-limit=]
1 warning and 20 errors generated.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 374.433s, Critical Path: 113.24s
INFO: 1577 processes: 1577 local.
FAILED: Build did NOT complete successfully
```"
37330,Improve the TFDS Getting Started Documentation ,"## URL(s) with the issue:
https://www.tensorflow.org/datasets/overview

## Description of issue (what needs changing):

 😀I completed step 1 and  went to “https://www.tensorflow.org/datasets/overview” to get started with TFDS. I launched the code lab to continue with the overview. The code lab is a great option to easily run python and tensorflow! 

😑- I completed the first command to install tensorflow and tensorflow-datasets
![image](https://user-images.githubusercontent.com/6283150/75946296-9433b500-5e51-11ea-921e-f44a6fc1573e.png)

The download ran but it was not clear which version of tensorflow was downloaded. The reason I was confused and wanted to know which version was installed is the disclaimer above states version >=1.15 is required.
😑- In the second command, I received an error message after running the python script.
![image](https://user-images.githubusercontent.com/6283150/75946322-a44b9480-5e51-11ea-8874-51a4863093ae.png)

I was not clear if this was just a warning message, or an error due to my current tensorflow version. 

😀Step 2 was delightful!
![image](https://user-images.githubusercontent.com/6283150/75946336-aca3cf80-5e51-11ea-949a-0ca03348d768.png)

Adding in a disclaimer to include citations is great! 😑However, why is it after the download step? This seems out of place and disrupts the developer workflow. 

Next was step 3 to initiate eager execution.
😑Without a baseline on what EE is, I felt required to read the eager execution page before I could move forward. It’s frustrating when a developer guide links out to other documentation, or I feel compelled to read the other pages, because it causes disruption in grasping one concept at a time. This frustration can be a “drop off” point for developers trying to onboard Tensorflow.

![image](https://user-images.githubusercontent.com/6283150/75946528-35227000-5e52-11ea-9312-09405b8e3043.png)

Enable_V2_Behavior is the command run after asking the user to enable eager execution. Why is that? (After reading the eager execution documentation this was clear, but it took time to dig for this info).

😡Step 5 understanding what the tf “load” function does is frustrating.
![image](https://user-images.githubusercontent.com/6283150/75946560-44092280-5e52-11ea-85be-ded98f6365c3.png)

😡I’m strongly encouraged to read the official TensorFlow guide which is over 30 pages of material. I am 5 steps down this getting started guide, and then sent to another page that will reasonably take 4+ focused hours to additionally complete. This is very frustrating when I am trying to just get an overview of tensorflow datasets.

😀Step 5 does a great job here showing an example directly in relation to the above paragraph on versioning! I’m delighted and can move on without needing to read the hyperlink. 
![image](https://user-images.githubusercontent.com/6283150/75946588-54b99880-5e52-11ea-8e80-6ec1f06b684e.png)

😑Step 7 is confusing since it states we can achieve the same output using the DatasetBuilder, but when you run the test it only outputs the ds_train variable, as opposed to building the graph. 
![image](https://user-images.githubusercontent.com/6283150/75946599-5be0a680-5e52-11ea-9cfd-37520abadae3.png)

### What should happen?

I have organized answers to the above friction points in the following groupings:

**Tensorflow Installation**
To identify which version of Tensorflow I installed I ran a grep command in the code lab to output the following:

![image](https://user-images.githubusercontent.com/6283150/75946716-bd087a00-5e52-11ea-95d3-c13f68c33df9.png)

Having something like this ^ output during installation will help users know what is downloaded and executed in the install command. 

**Eager Execution**

A simple way to clarify what eager execution is to write a one sentence definition in the guide. For example:

“TensorFlow's eager execution is an imperative programming environment that evaluates operations immediately, without building graphs: operations return concrete values instead of constructing a computational graph to run later.”

This way I have a quick understanding and don’t feel compelled to read the linked page which is a very long document! :)
I liken this to applications having a tooltip in consumer facing applications. Adding in quick non intrusive explanations to Respect the User keep your users engaged and on the same page. 

Additionally, adding in the following message to define the command, “enable_v2_behavior”, would help clarify that Eager Execution is enabled by default tensorflow 2. 

![image](https://user-images.githubusercontent.com/6283150/75946725-c560b500-5e52-11ea-9229-96f8b71dc895.png)


**Linking to the official guide for Tensorflow Datasets**
![image](https://user-images.githubusercontent.com/6283150/75946747-d3163a80-5e52-11ea-820b-a43d13bbbe76.png)

We need to Respect the User, and provide simplicity when on boarding someone new to TFDS. They have invested time to make it down to the 5th step. If it is imperative the user get a baseline understanding of the Tensorflow API first, then we should put the disclaimer at the top of the overview to go read the guide first before continuing. 

If it is not necessary, then we should summarize the API guide into 3-5 concise pillars of information that is required for the user to understand the rest of the overview. When the user completes the overview, we can encourage them to go deeper and read the rest of the guide. Similarly, an analogy is when loading a website you respect the user by building a light-weight modern site. Performant sites lazy load in images when they are needed to improve performance and minimize how much data your user needs to download, we should apply the same principles to information.  

**DatasetBuilder**
When introducing in the DatasetBuilder we should place this information right after Step 5 (calling .load), to show the two ways to load in datasets side by side. This way the user does not need to scroll back up the documentation and read before Step 6 (plotting the dataset). 



"
37327,Broken Link Inside the Friction Log Google Doc,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue / ## Description of issue (what needs changing):

Inside the Friction Log Document: https://docs.google.com/document/d/1HVG3t-mgGZKU4iMeguTWGejbnQ54qUTXwdCFkA5xHG0/edit

There is a broken link to the ""Bug / Performance"" template:
https://github.com/tensorflow/tensorflow/blob/master/.github/ISSUE_TEMPLATE/00-bug-performance-issue.md

### Correct links

I see there are two templates - 
**Performance:** https://github.com/tensorflow/tensorflow/issues/new?labels=type%3Aperformance&template=80-performance-issue.md

**Bug**: https://github.com/tensorflow/tensorflow/issues/new?labels=type%3Abug&template=00-bug-issue.md

The friction log should update these links in the google doc, 

"
37325,tf.ConfigProto() and tf.estimator.RunConfig  conflict,"I want to use “tf.ConfigProto()” to set the GPU to grow dynamically, and I want to use “ tf.estimator.RunConfig ” to set the number of checkpoints.

config = tf.ConfigProto()
config.gpu_options.allow_growth = True

config = tf.estimator.RunConfig(keep_checkpoint_max = 10)
with tf.train.MonitoredTrainingSession(,,,config=config)
How can I achieve my goal with only one config？


extremely grateful !
Thanks!"
37324,Cannot break while iterating over tensorflow dataset created using `tf.data.Dataset.from_generator`,"
**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): 
Yes
- OS Platform and Distribution (e.g.,
Windows 10
- TensorFlow installed from 
binary
- Tensorflow Version:
2.1

**Describe the current behavior**
The `tensorflow` dataset created from the generator function cannot be used with `break` inside the for loop. On the other hand, the datasets created without a generator do break gracefully. The error `tf.errors.CancelledError` is raised because of cancellation i.e. there is a `break` statement inside for loop.

**Describe the expected behavior**
The tensorflow dataset created using from_generator should exit gracefully when we break the for loop.

**Standalone code to reproduce the issue** 

See the code below:
```python
import numpy as np
import tensorflow as tf


def gen():
    while True:
        yield np.zeros(10, dtype=np.int32)


ds_without_gen = tf.data.Dataset.from_tensor_slices(
    [np.zeros(10, dtype=np.int32)]
).repeat()

ds_from_gen = tf.data.Dataset.from_generator(
    generator=gen, output_types=np.int32
)


# this works normally with break statement
print("">>>>>>>>> ds_without_gen"")
for r in ds_without_gen.as_numpy_iterator():
    print(r)
    break


# this does work but a error is thrown by tensorflow as below
#    W tensorflow/core/kernels/data/generator_dataset_op.cc:103]
#    Error occurred when finalizing GeneratorDataset iterator:
#    Cancelled: Operation was cancelled
print("">>>>>>>>> ds_from_gen"")
for r in ds_from_gen.as_numpy_iterator():
    print(r)
    break

```

The output is:
```txt
2020-03-04 17:39:29.472521: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2020-03-04 17:39:32.463827: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'nvcuda.dll'; dlerror: nvcuda.dll not found
2020-03-04 17:39:32.464110: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)
2020-03-04 17:39:32.469124: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: NXL23343
2020-03-04 17:39:32.469517: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: NXL23343
2020-03-04 17:39:32.469969: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
 ds_without_gen
[0 0 0 0 0 0 0 0 0 0]
 ds_from_gen
[0 0 0 0 0 0 0 0 0 0]
2020-03-04 17:39:32.528149: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled
```


"
37323,Count number of times `tf.function` is traced,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.1
- Are you willing to contribute it (Yes/No): No



**Describe the feature and the current behavior/state.**
I would like to be able to check, inside a function wrapped by `tf.function`, when this function is being retraced. This is useful for testing my functions are compatible with `tf.function`, and will make use of the speed up (and not just make a new graph every time they are called).

An example, with the requested feature would be inserted in `REQUEST`:

```
import my_function
@pytest.mark.unit
@pytest.mark.parametrize('use_tf_function', [True, False])
def test_my_function(use_tf_function):

    def test(arg1, arg2):
        # REQUEST: Check to make sure this is not being retraced many times.
        return my_function(arg1, arg2)

    # Sometimes test in Eager mode for debugging, sometimes test in graph mode.
    test_func = test
    if use_tf_function:
        test_func = tf.function(test_func)

    #####Test 1
    arg1, arg2 = #some setup stuff
    test_func(arg1, arg2)  # create the graph (tracing happens).
    results = test_func(arg1, arg2)  # hopefully tracing does not happen a second time.
    assert results

    #####Test 2
    arg4, arg3 = #some setup stuff
    results = test_func(arg3, arg4)  # hopefully tracing does not happen again (if the inputs are tensors and the shapes do not change)
    assert results
```


**Will this change the current api? How?**
I'm not sure, maybe just add a function, maybe it already exists.

**Who will benefit with this feature?**
Anyone debugging. 

**Any Other info.**
"
37320,Compilation error:  reduction_ops_gpu_complex64.cu.pic.o' was not created,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):macOS 10.13.6
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version:1.5
- Python version:3.6
- Installed using virtualenv? pip? conda?: conda
- Bazel version (if compiling from source):0.9
- GCC/Compiler version (if compiling from source):9.0
- CUDA/cuDNN version:9.2/7.2.1
- GPU model and memory:GTX1070



**Describe the problem**

```
ERROR: /Users/john/Downloads/tensorflow/tensorflow/core/kernels/BUILD:2709:1: output 'tensorflow/core/kernels/_objs/reduction_ops_gpu/tensorflow/core/kernels/reduction_ops_gpu_complex64.cu.pic.o' was not created
ERROR: /Users/john/Downloads/tensorflow/tensorflow/core/kernels/BUILD:2709:1: not all outputs were created or valid
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 2120.730s, Critical Path: 166.64s
FAILED: Build did NOT complete successfully

```

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
37318,TPU software version nightly-2.x now gone and other versions don't work,"**System information**

Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Debian GNU/Linux 9.11
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: N/A
TensorFlow installed from (source or
binary): binary
TensorFlow version (use command below): 2.2.0.dev20200303
Python version: Python 3.7.6
Bazel version (if compiling from source): N/A
GCC/Compiler version (if compiling from
source): N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A

**Describe the problem**

As of about 12PM EST today it seems that ""nightly-2.x"" for the TPU software version is no longer available under ""Create a Cloud TPU."" Unfortunately, this is the only version of the software which worked for my training code, and now nothing works. 

I also tried version 2.1, and I get this error: 

```tensorflow.python.framework.errors_impl.NotFoundError: 'ParallelInterleaveDatasetV3' is neither a type of a primitive operation nor a name of a function registered in binary running on n-de18ad71-w-0. One possible root cause is the client and server binaries are not built with the same version. Please make sure the operation or function is registered in the binary running in this process. [Op:DeleteRandomSeedGenerator]```

To be clear, I'm calling .interleave() in tf.data, not parallel_interleave, but I suppose it's really running ParallelInterleaveDatasetV3 under the hood.

Can you let me know what version of the TPU software we should be using to have the same functionality as the old nightly-2.x?

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
37317,tf-nightly-gpu 1.15.0.dev20190729 is not found,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colabs
- TensorFlow version: 1.15.0.dev20190729


**Describe the problem**

The tf-nightly-gpu==1.15.0.dev20190729 build appears to be missing.  We are releasing our tutorials next week for the summit using this build as listed in google colabs, but we can no longer install. Errors are listed below.  

Example is here: 
https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro/examples/micro_speech/train_speech_model.ipynb

**Provide the exact sequence of commands / steps that you executed before running into the problem**

The command in the google colab is as follows: 
# Replace Colab's default TensorFlow install with a more recent
# build that contains the operations that are needed for training
!pip uninstall -y tensorflow tensorflow_estimator tensorboard
!pip install -q tf-estimator-nightly==1.14.0.dev2019072901 tf-nightly-gpu==1.15.0.dev20190729

Output is: 
ERROR: Could not find a version that satisfies the requirement tf-nightly-gpu==1.15.0.dev20190729 (from versions: 2.2.0.dev20200201, 2.2.0.dev20200202, 2.2.0.dev20200203, 2.2.0.dev20200204, 2.2.0.dev20200205, 2.2.0.dev20200206, 2.2.0.dev20200207, 2.2.0.dev20200208, 2.2.0.dev20200210, 2.2.0.dev20200211, 2.2.0.dev20200212, 2.2.0.dev20200215, 2.2.0.dev20200216, 2.2.0.dev20200217, 2.2.0.dev20200218, 2.2.0.dev20200226, 2.2.0.dev20200227, 2.2.0.dev20200228, 2.2.0.dev20200229, 2.2.0.dev20200301, 2.2.0.dev20200302, 2.2.0.dev20200303, 2.2.0.dev20200304)
ERROR: No matching distribution found for tf-nightly-gpu==1.15.0.dev20190729

**Any other info / logs**
Can we get this build restored please? We do need TensorFlow prior to 2.0 - there's a dependency deprecation in the model conversion at the end of this tutorial that has (to my knowledge) not been addressed yet and we're on somewhat of a time crunch with that summit next week. 

Let me know if you need any more information! Thank you! "
37316,Can't find tensorflow 2.1.0 with python 3.7 and pip,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.1.0
- Python version: 3.7
- Installed using virtualenv? pip? conda?: pip
- CUDA/cuDNN version: 10.1
- GPU model and memory: Unknown

**Describe the problem**
I have a Docker file that is being built to run on a GPU machine in AWS. When I try to pip install tensorflow 2.1.0 I get the error:

> No matching distribution found for tensorflow==2.1.0

**Provide the exact sequence of commands / steps that you executed before running into the problem**
My Docker file is as follows:
```
FROM nvidia/cuda:10.1-cudnn7-runtime-ubuntu18.04

RUN apt -qq -y update \
	&& apt -qq -y upgrade
RUN apt -y install python3.7
RUN apt -y install python3-pip

RUN which python3.7
RUN which pip3

RUN ln -s /usr/bin/python3.7 /usr/bin/python
RUN ln -s /usr/bin/pip3 /usr/bin/pip
RUN python --version
RUN which pip

WORKDIR /usr/src/app
COPY . .
RUN pip3 install tensorflow==2.1.0
ENTRYPOINT [""/usr/src/app/docker-entrypoint.sh""]
CMD [""python"", ""test.py""]
```

**Any other info / logs**
The full error is:
> Collecting tensorflow==2.1.0
  Could not find a version that satisfies the requirement tensorflow==2.1.0 (from -r requirements.txt (line 4)) (from versions: 0.12.1, 1.0.0, 1.0.1, 1.1.0rc0, 1.1.0rc1, 1.1.0rc2, 1.1.0, 1.2.0rc0, 1.2.0rc1, 1.2.0rc2, 1.2.0, 1.2.1, 1.3.0rc0, 1.3.0rc1, 1.3.0rc2, 1.3.0, 1.4.0rc0, 1.4.0rc1, 1.4.0, 1.4.1, 1.5.0rc0, 1.5.0rc1, 1.5.0, 1.5.1, 1.6.0rc0, 1.6.0rc1, 1.6.0, 1.7.0rc0, 1.7.0rc1, 1.7.0, 1.7.1, 1.8.0rc0, 1.8.0rc1, 1.8.0, 1.9.0rc0, 1.9.0rc1, 1.9.0rc2, 1.9.0, 1.10.0rc0, 1.10.0rc1, 1.10.0, 1.10.1, 1.11.0rc0, 1.11.0rc1, 1.11.0rc2, 1.11.0, 1.12.0rc0, 1.12.0rc1, 1.12.0rc2, 1.12.0, 1.12.2, 1.12.3, 1.13.0rc0, 1.13.0rc1, 1.13.0rc2, 1.13.1, 1.13.2, 1.14.0rc0, 1.14.0rc1, 1.14.0, 2.0.0a0, 2.0.0b0, 2.0.0b1)
No matching distribution found for tensorflow==2.1.0 (from -r requirements.txt (line 4))
The command '/bin/sh -c pip3 install --no-cache-dir -r requirements.txt' returned a non-zero code: 1"
37315,test issue,"sdfdssdfdssdsdfsdfsdfsdfdsfsdfsdfsdfsdfsdfdsfsdfsdfsdfdsfsdfsdfsdfsdfsdfdsf load_dynamic return _load(spec)
CUDA/cuDNN version: 434
**Provide the exact sequence"
37313,build and install,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:
- Python version:
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.


sdfdssdfdssdsdfsdfsdfsdfdsfsdfsdfsdfsdfsdfdsfsdfsdfsdfdsfsdfsdfsdfsdfsdfdsf load_dynamic return _load(spec)
CUDA/cuDNN version: 434
**Provide the exact sequence"
37311,Method Chaining in Tensorflow,"I have posted a question about this in stackoverflow. https://stackoverflow.com/questions/60528238/why-no-method-chaining-in-tensorflow

Aka. named parameter idiom. I did a simple Nearest Neighbor algorithm in TF and I ended up writing the whole NN algorithm in one line. You can argue that I should take it apart, but I think this happens often anyways (in coding in general too):

```
tf.math.argmin(tf.math.reduce_sum(tf.math.abs(tf.math.subtract(Xtrain_set, Xtest_row)), axis=1), output_type=tf.int32)

# returns the minimum train set indices for each X predictable row based on L1 (in a for cycle) but this is not important
```

It could be much more readable and simple to write:

**`tf.subtract(Xtrain_set, Xtest_row).abs().reduce_sum(axis=1).argmin(output_type=tf.int32)
`**

I think it really follows the ""Tensor-flow"" thinking too.
Thanks."
37310,test issue,"sdfdssdfdssdsdfsdfsdfsdfdsfsdfsdfsdfsdfsdfdsfsdfsdfsdfdsfsdfsdfsdfsdfsdfdsf load_dynamic return _load(spec)
CUDA/cuDNN version: 434
**Provide the exact sequence"
37309,sdfdssdfdssdsdfsdfsdfsdfdsfsdfsdfsdfsdfsdfdsfsdfsdfsdfdsfsdfsdfsdfsdfsdfdsf load_dynamic return _load(spec) CUDA/cuDNN version: 434 **Provide the exact sequence,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:
- Python version:
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.


sdfdssdfdssdsdfsdfsdfsdfdsfsdfsdfsdfsdfsdfdsfsdfsdfsdfdsfsdfsdfsdfsdfsdfdsf load_dynamic return _load(spec)
CUDA/cuDNN version: 434
**Provide the exact sequence"
37307,gradient of `einsum` is incorrect for complex numbers,"**System information** 
- Attached is a small script reproducing the problem
- OS Platform and Distribution: Ubuntu 18.04 LTS
- TensorFlow installed from pip
- TensorFlow version: v2.1.0-rc2-17-ge5bf8de 2.1.0
- Python version: Python 3.7.5
- Observed both on CPU and GPU

**Describe the current behavior**

The gradient of this `tf.matmul` expression with respect to `p` is computed correctly:

```python
# `h` is an NxN complex128 matrix, `p` is float64 number, and `zero` is a float64 zero
def f(p,h):
    h1 = tf.complex(p,zero) * h
    return tf.abs(tf.reduce_sum(tf.matmul(h,h)))
```

But the value of the following `tf.einsum` expression is the same (and computed correctly), while the gradient with respect to `p` is wrong:

```python
def f(p,h):
    h1 = tf.complex(p,zero) * h
    return tf.abs(tf.reduce_sum(tf.einsum('ab,bc->ac',h,h)))
```

The problem happens only when the matrices are complex.

**Describe the expected behavior**

The two functions should produce the same value (which is working fine), and their gradients with respect to `p` should be the same (which is not happening).

**Standalone code to reproduce the issue** 

https://colab.research.google.com/drive/1FdC-x5Q74NqoLiB6kR7Omtcb5npdrDtx"
37306,Bug with callbacks in tf.keras model,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Ubuntu 19.10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: N/A
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): pip install / tensorflow==2.0
- Python version: - Bazel
version (if compiling from source): 3.7.5
- GCC/Compiler version (if compiling from
source): N/A
- CUDA/cuDNN version: - GPU model and memory: n/A

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
When force stopping a model on training, all the callbacks(on_epoch_end, on_train_end) are called. This does not happen with a keras model.
**Describe the expected behavior**
The other callbacks, namely on_epoch_end and on_train_end aren't supposed to be called.

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
https://colab.research.google.com/drive/1Uu_LPSgdyXAyWubGAQDpbMq8BcUcXqUd

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
37303,tf.data unique leads to negative cardinality,"**System information** 
- **OS** Reproduced on Win 10, not checked on other OS.
- **TensorFlow**: Version 2.1, installed with pip
- **Python version**: 3.6
- **CUDA/cuDNN version:** 10.1
- **GPU model**:  GeForce GTX 1050

**Describe the current behavior**
Cardinalities (evaluated using `tf.data.experimental.cardinality`) become negative after using `ds.apply(tf.data.experimental.unique())`

**Describe the expected behavior**
Cardinalities should not become negative after using `ds.apply(tf.data.experimental.unique())`

**Standalone code to reproduce the issue** 
Running the following
```
ds = tf.data.Dataset.from_tensor_slices([0,1])
unique_ds = ds.apply(tf.data.experimental.unique())
print(tf.data.experimental.cardinality(ds).numpy())
print(tf.data.experimental.cardinality(unique_ds).numpy())
```
Prints these lines
```
2
-2
```
While I would expect it to print
```
2
2
```
"
37302,Add Earlystopping function to train.py of the speech commands API,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): Tensorflow 2.0
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**

As you know, the amount of training epochs is hard coded in the train.py file of the API. the 18000 epochs are perfect if we train the model with the official dataset. 

**Will this change the current api? How?**

Adding a Earlystop function will prevent under or overfitting regardless which dataset will be trained. 

**Who will benefit with this feature?**

I would really apreciate if one of your could emplement a version of train.py with a Early stop flag. 
This would be a plus for the API and of big help for my use case.

**Any Other info.**

If you guys could give me a hint about how to add this feature to the existing API, I'd be happy to share my work.

Thank you very much 

Kind regards
"
37301,CombinedNonMaxSuppression is not whitelisted operator,"Hi! CombinedNonMaxSuppression is not whitelisted operator. Is it possible to add it as a whitelisted operator?

**System information**
- Linux Ubuntu 16.04
- TensorFlow installed from Docker Image
- TensorFlow version 2.1.0


**Provide the text output from tflite_convert**

```
2020-03-04 15:50:57.748145: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
2020-03-04 15:50:57.748972: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-03-04 15:50:57.771173: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize
2020-03-04 15:50:57.771259: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.018ms.
2020-03-04 15:50:57.771283: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.011ms.
2020-03-04 15:50:59.782146: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
2020-03-04 15:50:59.782403: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-03-04 15:51:00.470079: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize
2020-03-04 15:51:00.470148: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 360 nodes (-59), 639 edges (-59), time = 377.824ms.
2020-03-04 15:51:00.470167: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 360 nodes (0), 639 edges (0), time = 39.896ms.
Traceback (most recent call last):
  File ""./to_tf_lite.py"", line 54, in <module>
    app.run(main)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""./to_tf_lite.py"", line 44, in main
    tflite_model = converter.convert()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/lite.py"", line 464, in convert
    **converter_kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/convert.py"", line 457, in toco_convert_impl
    enable_mlir_converter=enable_mlir_converter)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/convert.py"", line 203, in toco_convert_protos
    raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: See console for info.
2020-03-04 15:51:02.143649: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6
2020-03-04 15:51:02.146593: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6
2020-03-04 15:51:03.291126: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Size
2020-03-04 15:51:03.291210: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Size
2020-03-04 15:51:03.291322: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Size
2020-03-04 15:51:03.291357: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Size
2020-03-04 15:51:03.291468: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: CombinedNonMaxSuppression
2020-03-04 15:51:03.297057: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 223 operators, 426 arrays (0 quantized)
2020-03-04 15:51:03.299828: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 223 operators, 426 arrays (0 quantized)
2020-03-04 15:51:03.400832: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 105 operators, 198 arrays (0 quantized)
2020-03-04 15:51:03.402525: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 105 operators, 198 arrays (0 quantized)
2020-03-04 15:51:03.404185: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 105 operators, 198 arrays (0 quantized)
2020-03-04 15:51:03.405338: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 105 operators, 198 arrays (0 quantized)
2020-03-04 15:51:03.406273: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Identify nearest upsample.: 105 operators, 198 arrays (0 quantized)
2020-03-04 15:51:03.407942: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 22151168 bytes, theoretical optimal value: 22151168 bytes.
2020-03-04 15:51:03.408239: I tensorflow/lite/toco/toco_tooling.cc:471] Number of parameters: 8849370
2020-03-04 15:51:03.408888: W tensorflow/lite/toco/tflite/operator.cc:2024] Op CombinedNonMaxSuppression is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-03-04 15:51:03.409165: W tensorflow/lite/toco/tflite/operator.cc:2024] Op CombinedNonMaxSuppression is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-03-04 15:51:03.409257: E tensorflow/lite/toco/toco_tooling.cc:498] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION, CONV_2D, DIV, EXP, EXPAND_DIMS, FILL, LEAKY_RELU, LOGISTIC, MAX_POOL_2D, MUL, PACK, RESHAPE, RESIZE_NEAREST_NEIGHBOR, SHAPE, SPLIT_V, STRIDED_SLICE, SUB. Here is a list of operators for which you will need custom implementations: CombinedNonMaxSuppression.
Traceback (most recent call last):
  File ""/usr/local/bin/toco_from_protos"", line 8, in <module>
    sys.exit(main())
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 93, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 56, in execute
    enable_mlir_converter)
Exception: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION, CONV_2D, DIV, EXP, EXPAND_DIMS, FILL, LEAKY_RELU, LOGISTIC, MAX_POOL_2D, MUL, PACK, RESHAPE, RESIZE_NEAREST_NEIGHBOR, SHAPE, SPLIT_V, STRIDED_SLICE, SUB. Here is a list of operators for which you will need custom implementations: CombinedNonMaxSuppression.
```

**Standalone code to reproduce the issue** 

--

**Any other info / logs**

--"
37300,Crashing introduced when call kernel.matrix with latest nightly build of TF 2.2,"Cross Post from Tensorflow Probability (at request of admins)

https://github.com/tensorflow/probability/issues/829

**System information** 
- OS Platform and Distribution : Windows 10
- TensorFlow installed from : - Binary
TensorFlow version: 2.2 Nightly
- Python version: 3.7.6
- CUDA/cuDNN version: - 10.1
- GPU model and memory:  Nvidia 2070 Max_Q

Using TFP 0.10.0-dev20200304, I have a standard call to create a positive semi-definite kernel e.g.

```
import tensorflow as tf
import tensorflow_probability as tfp
import numpy as np

amplitude = 1.0
length_scale = 1.0
kernel = tfp.math.psd_kernels.ExponentiatedQuadratic(amplitude, length_scale)
t_x = tf.Variable(np.array([[0.0, 0.25]]), dtype=tf.float32)
t_y = tf.Variable(np.array([[0.5, 0.5]]), dtype=tf.float32)
kernel.matrix(t_x, t_y)
```

This works apparently fine with all versions of TF-GPU upto and including GPU 2.2.0-dev20200302.

However, if I upgraded to TF-GPU 2.2.0-dev20200303 and now it crashes the following message :
Process finished with exit code -1073740940 (0xC0000374)

Seems like some incompatibility has been introduced with last nights build.
"
37299,Which NVIDIA GPU to buy for TF with Windows?,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 8.1 & 10 dual-boot
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version: the =last one
- Python version:3.7
- Installed using virtualenv? pip? conda?:pip conda
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:10
- GPU model and memory: That's the question!



**Describe the problem**
Hello, I've tried since some days to use TF with my GPU GeForce GTX 760. It doesn't work because its computing capabilities are 3.0. 
I've even tried to recompile the 1.8 version unsuccessfully.
Well, I've decided to change it. 
The NVIDIA MSI GTX 1050 Ti 4GT OC - 4 Go seems to fit with the requisites but I can read it's not more available on their site.
Is it recommended anywhere?
I will mainly use TF for fractal art.
Below some infos of my PC.
Thanks for your help and patience.
Best regards,
François
Type de processeur	QuadCore Intel Core i5-4670K, 4200 MHz (42 x 100)
Nom de la carte mère	Asus Z87-A  (2 PCI, 2 PCI-E x1, 3 PCI-E x16, 4 DDR3 DIMM, Audio, Video, Gigabit LAN)  3.0 (Gen 3) slots https://www.asus.com/fr/Motherboards/Z87A/
DIMM1: G Skill RipjawsX F3-12800CL9-4GBXL	4 Go DDR3-1600 DDR3 SDRAM  (11-11-11-28 @ 800 MHz)  (10-10-10-27 @ 761 MHz)  (9-9-9-24 @ 685 MHz)  (8-8-8-22 @ 609 MHz)  (7-7-7-19 @ 533 MHz)  (6-6-6-16 @ 457 MHz)
Moniteur	Samsung SyncMaster S24F350  [24"" LCD]  (H4ZM101320)


**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
37298,Cannot load SavedModel involving slice,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: N/A
- TensorFlow installed from (source or
binary): pip
- TensorFlow version (use command below): 2.1.0
- Python version: 3.7.2
- Bazel
version (if compiling from source):
- GCC/Compiler version (if compiling from
source): 
- CUDA/cuDNN version: Cuda 10.1, cuDNN 7.6.3, 
- GPU model and memory: NVIDIA GeForce GTX 1080, 8 GB

**Describe the current behavior**
When importing a SavedModel that contains a slice operation with tf.keras.models.load_model, an exception is thrown:
```
ValueError: Could not find matching function to call loaded from the SavedModel. Got:
  Positional arguments (1 total):
    * Tensor(""inputs:0"", shape=(None, 5, 16), dtype=float32)
  Keyword arguments: {}

Expected these arguments to match one of the following 1 option(s):

Option 1:
  Positional arguments (1 total):
    * [TensorSpec(shape=(None, 5, 16), dtype=tf.float32, name='inputs/0')]
```

**Describe the expected behavior**
The keras model should be importet.

**Standalone code to reproduce the issue** 
```python
import tensorflow as tf

inp = tf.keras.Input((5,16), dtype='float', name='bb')
net = inp[:,3:,:]
net = tf.keras.layers.Conv1D(2,1)(net)

model = tf.keras.Model(inputs=inp, outputs=net)

optimizer = tf.keras.optimizers.Adam()
loss = tf.keras.losses.BinaryCrossentropy()
model.compile(optimizer=optimizer, loss=loss)

model.save('out')

loaded = tf.keras.models.load_model('out')
```


"
37297,build ktrain model with tensorflow 2.1.0 kera version 2.3.1,"I am trying to build a model with ktrain. Howver, I received the following errors:

```
import ktrain
from ktrain import text
```

> WARNING:tensorflow:From c:\users\chth\anaconda3\envs\kg\lib\site-packages\tensorflow_core\python\compat\v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
> Instructions for updating:
> non-resource variables are not supported in the long term
> Using DISABLE_V2_BEHAVIOR with TensorFlow
> using Keras version: 2.2.4-tf

`model = text.sequence_tagger('bilstm-crf', preproc)
`
> pretrained word2vec word embeddings will be used with bilstm-crf
> Loading pretrained word vectors...this may take a few moments...
> Done.
> WARNING:tensorflow:From c:\users\chth\anaconda3\envs\kg\lib\site-packages\tensorflow_core\python\keras\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
> Instructions for updating:
> Call initializer instance with the dtype argument instead of passing it to the constructor
> WARNING:tensorflow:From c:\users\chth\anaconda3\envs\kg\lib\site-packages\tensorflow_core\python\ops\resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
> Instructions for updating:
> If using Keras pass *_constraint arguments to layers.
> WARNING:tensorflow:From c:\users\chth\anaconda3\envs\kg\lib\site-packages\tensorflow_core\python\ops\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
> Instructions for updating:
> Call initializer instance with the dtype argument instead of passing it to the constructor
> WARNING:tensorflow:From c:\users\chth\anaconda3\envs\kg\lib\site-packages\tensorflow_core\python\ops\init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
> Instructions for updating:
> Call initializer instance with the dtype argument instead of passing it to the constructor
> WARNING:tensorflow:From c:\users\chth\anaconda3\envs\kg\lib\site-packages\tensorflow_core\python\ops\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
> Instructions for updating:
> Call initializer instance with the dtype argument instead of passing it to the constructor
> WARNING:tensorflow:AutoGraph could not transform <bound method CRF.viterbi_decoding of <ktrain.text.ner.anago.layers.CRF object at 0x000002E483BAF508>> and will run it as-is.
> Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
> Cause: LIVE_VARS_IN
> WARNING: AutoGraph could not transform <bound method CRF.viterbi_decoding of <ktrain.text.ner.anago.layers.CRF object at 0x000002E483BAF508>> and will run it as-is.
> Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
> Cause: LIVE_VARS_IN

`learner.fit(1e-3, 1)`

> WARNING:tensorflow:From c:\users\chth\anaconda3\envs\kg\lib\site-packages\ktrain\core.py:1185: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
> Instructions for updating:
> Please use Model.fit, which supports generators."
37295,Low efficiency to do the Dequantize,"<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): 
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04):  Centos
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): 
- Python version: - Bazel
version (if compiling from source):
- GCC/Compiler version (if compiling from
source): 
- CUDA/cuDNN version: - GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Refer to this code
https://github.com/tensorflow/tensorflow/blob/c653d96483ef94ff51dbcae752e6377411e7761f/tensorflow/core/kernels/dequantize_op.cc#L131-L135
Even the target output is fp32, the code still doing the cast operation in a single thread for loop.
When the input tensor is large, the efficiency is quite lower.

**Describe the expected behavior**
1. The output is fp32, we needn't to do the cast again.
2. The output is bfloat16, use multi-thread to do the cast.

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
37293,"TF2.x API Docs:  example codes in `tf.Module` raise error, and fix it","## URL(s) with the issue:

https://www.tensorflow.org/api_docs/python/tf/Module

## Description of issue (what needs changing):

I extract the example codes, run it and got Error. It seems caused by inconsistant kwargs name:

```python
 class Dense(tf.Module):
   def __init__(self, in_features, output_features, name=None):
     super(Dense, self).__init__(name=name)
     self.w = tf.Variable(
         tf.random.normal([input_features, output_features]), name='w')
     self.b = tf.Variable(tf.zeros([output_features]), name='b')

   def __call__(self, x):
     y = tf.matmul(x, self.w) + self.b
     return tf.nn.relu(y)


class MLP(tf.Module):
  def __init__(self, input_size, sizes, name=None):
    super(MLP, self).__init__(name=name)
    self.layers = []
    with self.name_scope:
      for size in sizes:
        self.layers.append(Dense(input_size=input_size, output_size=size))
        input_size = size

  @tf.Module.with_name_scope
  def __call__(self, x):
    for layer in self.layers:
      x = layer(x)
    return x

mlp = MLP(input_size=100, sizes=[30, 30])
```

output:
```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-137-269f8996957a> in <module>()
----> 1 mlp = MLP(input_size=100, sizes=[30, 30])

<ipython-input-135-066c337c5b7a> in __init__(self, input_size, sizes, name)
     17    with self.name_scope:
     18      for size in sizes:
---> 19        self.layers.append(Dense(input_size=input_size, output_size=size))
     20        input_size = size
     21 

TypeError: __init__() got an unexpected keyword argument 'input_size'
```


### Submit a pull request?

 I think just need to modify several lines to fix it:

```python
 class Dense(tf.Module):
   def __init__(self, input_size, output_size, name=None):
     super(Dense, self).__init__(name=name)
     self.w = tf.Variable(
         tf.random.normal([input_size, output_size]), name='w')
     self.b = tf.Variable(tf.zeros([output_size]), name='b')

   def __call__(self, x):
     y = tf.matmul(x, self.w) + self.b
     return tf.nn.relu(y)


class MLP(tf.Module):
  def __init__(self, input_size, sizes, name=None):
    super(MLP, self).__init__(name=name)
    self.layers = []
    with self.name_scope:
      for size in sizes:
        self.layers.append(Dense(input_size=input_size, output_size=size))
        input_size = size

  @tf.Module.with_name_scope
  def __call__(self, x):
    for layer in self.layers:
      x = layer(x)
    return x
```

Should I submit a PR to fix this?
"
37291,"My model has tow inputs. when I load SavedModel, how to use Concretefunction?","my model has tow inputs. when I load SavedModel, how to use Concretefunction?
model = tf.saved_model.load('./model_rec')
inference = model.signatures['serving_default']
I tried many ways, but all failed
e.g
outputs  = inference(tf.constant(image_batch,dtype=tf.float32),tf.constant(anchors_batch,dtype=tf.float32))
TypeError: Expected at most 0 positional arguments (and the rest keywords, of ['input_1', 'input_4']),

signature_def['serving_default']:
  The given SavedModel SignatureDef contains the following input(s):
    inputs['input_1'] tensor_info:
        dtype: DT_FLOAT
        shape: (-1, 512, 512, 3)
        name: serving_default_input_1:0
    inputs['input_4'] tensor_info:
        dtype: DT_FLOAT
        shape: (-1, -1, 4)
        name: serving_default_input_4:0"
37290,Wrong NVIDIA driver and CUDA libs versions installed when running GPU setup instructions.,"On Ubuntu 18.04, when running the instructions given [here](https://www.tensorflow.org/install/gpu#ubuntu_1804_cuda_101) the driver version installed is 440 et the CUDA version is 10.2, while the recommended versions are, respectively, 430 and 10.1."
37289,Unable to remove model and release GPU memory,"**System information** 
- Custom code
- Ubuntu 16.04
- TensorFlow installed from source (with pip)
- TensorFlow version v2.0.0
- Python version: 3.6
- CUDA 10.0
- TITAN XP

At first, I tried to load the pre-trained transformer-base model (A) and then add additional word embeddings (dynamic vocabulary) to it. However, it doesn't work (i.e., can't add values to `tf.Variable`)
Instead, I created another model (B) with the size of dynamic vocabulary and set its weights to _existing_ transformer model (A).
Then, I do not need _initial_ model (A), so I want to remove it and clear GPU memory.
I tried such commands but they didn't work as well.
```
# delete not model (B) but only model (A)
tf.keras.backend.clear_session()
del model
gc.collect()
```
According to #36465, I can either use multiprocessing functions... but then I have to remove both model (A) and model (B). So I just want more clear solution.
Thanks."
37288,TypeError: Saw an object that is an instance of a strict subclass of EagerTensor,"I noticed that importing `from tensorflow_core.python.framework.ops import EagerTensor` is a problem when debugging Tensorflow in eager mode.

**System information** 
$ pip freeze | grep tensor
tensorboard==2.1.0
tensorflow==2.1.0
tensorflow-data-validation==0.21.2
tensorflow-datasets==2.0.0
tensorflow-estimator==2.1.0
tensorflow-metadata==0.21.1
tensorflow-serving-api==2.1.0
tensorflow-transform==0.21.0

**Describe the current behavior**
Importing `from tensorflow_core.python.framework.ops import EagerTensor` will throw

> TypeError: Saw an object that is an instance of a strict subclass of EagerTensor, which is not supported.  Item 0 is type: tensorflow.python.framework.ops.EagerTensor

when running the code example below.

**Describe the expected behavior**

No exception when importing `from tensorflow_core.python.framework.ops import EagerTensor` or at least an exception/error message which allows one to track down the issue more easily.

**Standalone code to reproduce the issue** 

```python
from tensorflow import keras
from tensorflow.keras import layers
# noinspection PyUnresolvedReferences
from tensorflow_core.python.framework.ops import EagerTensor


def main():
    model = keras.Sequential()
    model.add(layers.Embedding(1000, 64, input_length=10))

if __name__ == '__main__':
    main()
```

Please let me know if you need additional information."
37286,ModuleNotFoundError: No module named 'tensorflow_datasets',"I try to run

    import tensorflow_datasets as tfds

but got the following error

    ---------------------------------------------------------------------------
    ModuleNotFoundError                       Traceback (most recent call last)
    <ipython-input-1-46a8a2031c9c> in <module>
    ----> 1 import tensorflow_datasets as tfds
    
    ModuleNotFoundError: No module named 'tensorflow_datasets'

I have the tensorflow_datasets installed, below is a snippets of `pip list`

    tensorboard                        2.1.1              
    tensorflow                         2.1.0              
    tensorflow-datasets                2.1.0              
    tensorflow-estimator               2.1.0              
    tensorflow-hub                     0.7.0              
    tensorflow-metadata                0.21.1   

I am running using Ubuntu 16.04 with Anaconda virtual environment. How should I resolve this issue? "
37285,"modify input shape from [?,?,?,3] to [1,640,640,3]","This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.


hello, everyone.

I am using tensorflow.contrib.graph_editor to modify my SSD model. In fact, my model has input shape [?,?,?,3], so many nodes in the graph may not have exact shapes, such as [?,?,?,32] and [?,?,?,64]. So i want to use 'swap_inputs' to swap a new node whose shape is [1,640,640,3] with the input node whose shape is [?,?,?,3]. So how could the change affect all the nodes in the graph whose shape are not exact?"
37284,Cert error for https://download.tensorflow.org/,"
![image](https://user-images.githubusercontent.com/10709657/75855865-232ed600-5e2e-11ea-9391-ce3f23a81fb6.png)

Not sure if this domain is still used. I sent a [PR](https://github.com/tensorflow/docs/pull/1489) for #34460 , but this domain also exists in various places.
For example: `tensorflow/lite/micro/examples/magic_wand/train/README.md`"
37283,How to register a custom op in Python API？,"I just try to implement a zero_out op in tflite, and minimal project load the converted tflite model succesfully, but in python, it failed? How to register a custom op in Python API？
Thanks for your help!"
37282,Android demo application is crushed when I import my .pb file.,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04 / Android Studio 3.5.3
- TensorFlow installed from (source or binary): pip install tensorflow-gpu
- TensorFlow version (or github SHA if from source): Tensorflow 1.14.0


http://seangtkelley.me/blog/2017/12/23/using-custom-yolov2-model-on-android

I tried this link to use YOLO v2 model about android application.

So I trained my network with YOLO v2 with darkflow, and I converted the weight file to .pb file. I imported my .pb file to android demo application that Tensorflow provides about github; tensorflow/tensorflow/examples/android/.

But when I generate apk file to that application with my .pb file, the app is crushed and don't work.

In first I think this problem because I use YOLO v2 that Tensorflow doesn't support. So I try my dataset with SSD_Mobilenetv1 that Tensorflow supports like this link;

https://towardsdatascience.com/detecting-pikachu-on-android-using-tensorflow-object-detection-15464c7a60cd

But there was same error. The application doesn't work and be crushed. I don't know what's error. There's no problem to buile and generate apk in android studio.

How can I solve this problem?"
37280,How to update saved model," I would like to update my pretrained mode, which means the data of model should exist and new data to add."
37278,How can I share the weights between two different dilations cnn layer in tensorflow2.0,"How can I share the weights between two different dilations cnn layer in tensorflow2.0
In tensorflow1.x, I can just use the tf.variable_scope with the tf.AUTO_REUSE
 "
37274,General discussion of tf.image,"Hi,

I was thinking about applying for the GSoC for the topic of expandin tf.image (Adding and standardizing image processing operations in tf.image). It is said that it involves adding operations present in other image processing libraries. I am thinking operations that for example OpenCV has. 

I was looking for example at rotating an image, which is right now just limited to rotate by multiples of 90 degrees (tf.image.rot90). More generally one would like to for example get a rotation matrix and do an affine transform there to get any rotation angle. It seems though that tf.keras.precprocessing.image also has some image processing operations like tf.keras.precprocessing.image.apply_affine_transform that would do that. It seems to me redundant though for having tf.keras.preprocessing.image and tf.image in the end.

Any thoughts on that? 

Anyway if I need a mentor for that from the TF community for the GSoC project, who should I contact you think?"
37273,Can't restore checkpoint! - ValueError: Tensor's shape is not compatible with supplied shape,"**System information**
- OS Platform and Distribution: Google AI Platform
- TensorFlow version: v2.0
- Python version: v3.*
- Machine type: 16 vCPUs, 30 GB RAM
- GPU: 1x NVIDIA Tesla K80

I am training a model to caption images and have mostly used this tutorial: https://www.tensorflow.org/tutorials/text/image_captioning#download_and_prepare_the_ms-coco_dataset

The only thing that is different from this notebook is that I am using a different dataset.

I set up the checkpoints
```
checkpoint_path = ""./checkpoints""
ckpt = tf.train.Checkpoint(encoder=encoder,
                           decoder=decoder,
                           optimizer = optimizer)
ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)
```

And then I use ```ckpt_manager.save()``` every 5 epochs.

I restart my kernel and try to restore using:
```
ckpt.restore(ckpt_manager.latest_checkpoint)

>> <tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f1e76d12ba8>
```

But when I try and make a prediction I get this error:
```
ValueError: Tensor's shape (18859, 256) is not compatible with supplied shape (17128, 256)
```

Can anyone help out?

Thanks"
37272,tf.estimator.SummarySaverHook should support native V2 symbols.,"**System information**
- TensorFlow version (you are using): 2.1
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**
At present when specifying `tf.estimator.SummarySaverHook` in `tf.estimator.EstimatorSpec` when writing a custom `model_fn`, one is bound to use symbols from `tf.compat.v1`. 

This is because, `tf.estimator.SummarySaverHook` needs  `summary_op` as an argument which should be a  tensor or list of tensors.

On the other hand the native V2 api in the form of `tf.summary...` symbols  return a boolean value. 

Therefore it is not possible to use `tf.summary` functions when using `tf.estimator.SummarySaverHook`.

**Will this change the current api? How?**

It will change the API as it will require either a basic change in `tf.summary` or `tf.estimator`

**Who will benefit with this feature?**
It will help people in migrating their codes to native V2 symbols.
"
37269,tf.keras.utils.get_file extraction of zip not working when fname to a full path is used on Windows,"I am following the tensorflow image classification tutorial: https://www.tensorflow.org/tutorials/images/classification

I am unable to unzip the downloaded folder when I use a full path to a location as opposed to using just a fname as shown in the example on Windows. Have not tried on Linux, so don't know if it exists on that platform.

This is my code:
``` 
download_data_loc = os.path.join(os.path.abspath(os.path.pardir),'data\cats_and_dogs.zip')

path_to_zip = tf.keras.utils.get_file(download_data_loc,origin=_URL,extract=True, archive_format='zip')

```
I see the cats_and_dogs.zip folder in following location: C:\Users\abhat\research\Tensorflow_2.0_tutorials\data\cats_and_dogs.zip

But there isn't an unzipped folder in this location.

However, if I use,
``` 
path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)

```
I see the zipped folder as well as the unzipped version in the right location
C:\Users\abhat\.keras\datasets\cats_and_dogs.zip


**System Info:**  
Windows 10 Pro, 64 bit OS.

**Tensorflow version:**
v2.1.0-rc2-17-ge5bf8de410 2.1.0"
37268,Increased Inference time after doing optimization.,"Hello,

I am trying to get an optimized graph by doing quantization and removing redundant nodes from frozen_graph.pb.  os features are

os features:
ubuntu 16.0.4 LTS
nvidia driver version = Driver Version: 440.33.01
cuda version = 10
cuDNN version = 7.4
tensorflow = 1.14.1 (built from source with cuda and tensorRT support)
GPU = NVIDIA Corporation GV100GL [Tesla V100 SXM2 16GB]
Python version: 3.6.8 (pyenv)
- Bazel version: 0.25

I ran the command which has to build the new frozen model for me.
when I tested it in production, Though the size is reduced to around 20MB but inference time is increased from  average 15ms to 26 ms.

the command to produced new optimized graph: 

bazel-bin/tensorflow/tools/graph_transforms/transform_graph \
--in_graph=""/home/ubuntu/test/resnetV150_frozen.pb"" \
--out_graph=""/home/ubuntu/test/optimized_inception_graph.pb"" \
--inputs='image_tensor' \
--outputs='resnet_v1_50/predictions/Reshape_1' \
--transforms='  
 add_default_attributes  
 strip_unused_nodes(type=float, shape=""1,1280,720,3"")  
 remove_nodes(op=Identity, op=CheckNumerics)  
 fold_constants(ignore_errors=true)  
 fold_batch_norms  
 fold_old_batch_norms  
 quantize_weights  
 quantize_nodes  
 strip_unused_nodes 
 sort_by_execution_order'



"
37266,Dataset is not cached after model.predict() call (issue present in TF2.0.0 but not in TF2.1.0),"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): **NO**
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): **issue present on Linux and Windows**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: NA
- TensorFlow installed from (source or
binary): **binary**
- TensorFlow version (use command below): **2.0.0  (no issue with 2.1.0)**
- Python version: Python 3.7.5
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from
source): NA
- CUDA/cuDNN version: CUDA 10.1 / CuDNN 7.6
- GPU model and memory: issue happens with/without GPU

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
The dataset is not correctly put in cache after the first call to predict as it should.
So the 2nd call to predict returns different predictions than the 1st call despite we have used .cache() on the given dataset.
**Describe the expected behavior**
The 2 calls to predict in the code below should return the same predictions and thus the assert should pass.
**Standalone code to reproduce the issue** 
```python
import tensorflow as tf

input_data = tf.keras.layers.Input(name='input_data', shape=(1,), dtype='float32')
dummy_model = tf.keras.models.Model(inputs=input_data, outputs=input_data*2)
ds = tf.data.Dataset.range(10).shuffle(10).batch(1).cache()
#len(list(ds))  # next assert passes if we uncomment this line because it forces the caching of the dataset
assert (dummy_model.predict(ds) == dummy_model.predict(ds)).all()
```
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
37265,Tensorflow import issue after new install ImportError: DLL load failed: The specified module could not be found.,"Python 3.7.6 (tags/v3.7.6:43364a7ae0, Dec 19 2019, 00:42:30) [MSC v.1916 64 bit (AMD64)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tF
Traceback (most recent call last):
  File ""C:\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Python37\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Python37\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Python37\lib\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""C:\Python37\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Python37\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Python37\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Python37\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Python37\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Python37\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Python37\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help."
37264,tf.name_scope does not obey its own documented rules,"**System information** 
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.3 LTS (GNU/Linux 4.14.137+ x86_64)
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.1.0-0-ge5bf8de410
- Python version: 3.6.9 (default, Nov  7 2019, 10:44:02)

\
According to the https://www.tensorflow.org/api_docs/python/tf/name_scope:

> If the scope name already exists, the name will be made unique by appending _n. For example, calling my_op the second time will generate MyOp_1/a, etc.

However, it turned out to be not. Nor did I manage to find any code (inside `tf.name_scope`) that might generate the uniqueness.

``` python
import tensorflow as tf
layer = tf.keras.Input(shape = [None])
def get_shape(layer):
  with tf.name_scope('scope') as scope:
    return tf.shape(layer, name=scope)
get_shape(layer)
get_shape(layer)
```
The first `get_shape(layer)`:
```
<tf.Tensor 'scope:0' shape=(2,) dtype=int32>
```
The second `get_shape(layer)`:
```
Traceback (most recent call last):
  File ""/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/ops.py"", line 1619, in _create_c_op
    c_op = c_api.TF_FinishOperation(op_desc)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Duplicate node name in graph: 'scope'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""<stdin>"", line 3, in get_shape
  File ""/tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/array_ops.py"", line 519, in shape_v2
    return shape(input, name, out_type)
  File ""/tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/array_ops.py"", line 545, in shape
    return shape_internal(input, name, optimize=True, out_type=out_type)
  File ""/tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/array_ops.py"", line 573, in shape_internal
    return gen_array_ops.shape(input, name=name, out_type=out_type)
  File ""/tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/gen_array_ops.py"", line 8234, in shape
    ""Shape"", input=input, out_type=out_type, name=name)
  File ""/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/op_def_library.py"", line 742, in _apply_op_helper
    attrs=attr_protos, op_def=op_def)
  File ""/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/func_graph.py"", line 595, in _create_op_internal
    compute_device)
  File ""/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/ops.py"", line 3322, in _create_op_internal
    op_def=op_def)
  File ""/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/ops.py"", line 1786, in __init__
    control_input_ops)
  File ""/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/ops.py"", line 1622, in _create_c_op
    raise ValueError(str(e))
ValueError: Duplicate node name in graph: 'scope'
```"
37263,LOW GPU HIGH CPU :(,"Hello!
I am using Tensorflow on Docker, Ubuntu.
I have tried many tensorflow docker versions, tried different drivers, tried everything.:

## Sys info
-  Linux 5.3.0-40-generic 18.04.1 Ubuntu x86_64
- Docker 19.03.6, nvdia-smi works, I have all packagages needed
- Tensorflow Docker versions I tried (in some of the the GPU didn't even get recognized..): 
  - latest-gpu-jupyter (Py2, this works okay, but low gpu usage)
  - latest-gpu-py3-jupyter (sometimes bugs out)
  - 2.0.1-gpu-py3-jupyter (sometimes bugs out regarding GPU too)
- NVIDIA-SMI: 440.59, GeForce MX150, 2002MiB

## So what I am trying to DO:
 I load the MINTS dataset and do a **nearest neighbor** algorithm on them. Pretty simple right, I just started using tenforflow, I would love it if it was eating 100% of my GPU not CPU (if that is even possible). This is my code concisely:

```
(Xtr, Ytr), (Xte, Yte) = keras.datasets.cifar10.load_data()
# I convert them to tensors
# I save the whole training set into Xtr (50 000 rows of 3072 int32) to later do the nearest neighbor with them
# Upon ""prediction"" I find the index of Xtr row with lowest L1 distance from X for each X test row (10000 rows of 3072 ints):
with tf.device('/gpu:0'):
    min_distances_index = tf.map_fn(self.reduce_distance, Xte)
# which calls this tf function:
    @tf.function
    def reduce_distance(self, X):
        # X is of shape (3072,1)
        return tf.math.argmin(tf.math.reduce_sum(tf.math.abs(tf.math.subtract(self.Xtr, X)), axis=1), output_type=tf.int32)
# Quite simple and readable I hope!
# Then when I have min distance indices I simply return the Y values from them
```
I use int32 beacause as you saw there is subtraction and then sum, so.. 

## Now
**This takes 30 minutes!**
And this is my system statistic during running:
From htop:
![image](https://user-images.githubusercontent.com/11639734/75797157-05ea0100-5d75-11ea-9c7b-66df992270ab.png)
nvidia-smi:
![image](https://user-images.githubusercontent.com/11639734/75797912-1e0e5000-5d76-11ea-9b23-245cd648f9d3.png)
Jumping between 0% and 20% but on average below 10%

Why? Is this normal? 
Thanks in advance.
"
37262,tensorflow:Saver not created because there are no variables in the graph to restore,"I am a new bee trying to learn Tensorflow from this[ site ](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/install.html#test-tf-models). 
After all installation when I run:
`(tensorflow1) C:\tensorflow1\models\research\object_detection> jupyter notebook object_detection_tutorial.ipynb`
I got this message: ""tensorflow:Saver not created because there are no variables in the graph to restore""

------------------------

### System information
- **Have I written custom code**: NO
- **OS Platform and Distribution: Windows 10_64
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:N/A
- **TensorFlow installed from (source or binary)**: conda install 
- **TensorFlow version (use command below)**: 2.1.0
- **Python version**: 3.7.6
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**:N/A
- **CUDA/cuDNN version**: cudatoolkit =v10.1.243   cudnn  =v7.6.5
- **GPU model and memory**: GeForce 920MX  2GB



Problem:
I get the message 

> 
model_name = 'ssd_mobilenet_v1_coco_2017_11_17'
detection_model = load_model(model_name)


INFO:tensorflow:Saver not created because there are no variables in the graph to restore

tensorflow:Saver not created because there are no variables in the graph to restore
and 
![image](https://user-images.githubusercontent.com/61747889/75795865-ddcac400-5dad-11ea-9fc6-c5e3f545c3d1.png)

finally end up with 
![image](https://user-images.githubusercontent.com/61747889/75796019-0fdc2600-5dae-11ea-8730-e19665de8371.png)

###Final error logs:
---------------------------------------------------------------------------
ResourceExhaustedError                    Traceback (most recent call last)
<ipython-input-21-25f0f9a75087> in <module>
      1 for image_path in TEST_IMAGE_PATHS:
----> 2   show_inference(masking_model, image_path)

<ipython-input-17-e474e557b383> in show_inference(model, image_path)
      4   image_np = np.array(Image.open(image_path))
      5   # Actual detection.
----> 6   output_dict = run_inference_for_single_image(model, image_np)
      7   # Visualization of the results of a detection.
      8   vis_util.visualize_boxes_and_labels_on_image_array(

<ipython-input-16-4110867dcb70> in run_inference_for_single_image(model, image)
      7 
      8   # Run inference
----> 9   output_dict = model(input_tensor)
     10 
     11   # All outputs are batches tensors.

~\Anaconda3\envs\tensorflow1\lib\site-packages\tensorflow_core\python\eager\function.py in __call__(self, *args, **kwargs)
   1549       TypeError: For invalid positional/keyword argument combinations.
   1550     """"""
-> 1551     return self._call_impl(args, kwargs)
   1552 
   1553   def _call_impl(self, args, kwargs, cancellation_manager=None):

~\Anaconda3\envs\tensorflow1\lib\site-packages\tensorflow_core\python\eager\function.py in _call_impl(self, args, kwargs, cancellation_manager)
   1589       raise TypeError(""Keyword arguments {} unknown. Expected {}."".format(
   1590           list(kwargs.keys()), list(self._arg_keywords)))
-> 1591     return self._call_flat(args, self.captured_inputs, cancellation_manager)
   1592 
   1593   def _filtered_call(self, args, kwargs):

~\Anaconda3\envs\tensorflow1\lib\site-packages\tensorflow_core\python\eager\function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1690       # No tape is watching; skip to running the function.
   1691       return self._build_call_outputs(self._inference_function.call(
-> 1692           ctx, args, cancellation_manager=cancellation_manager))
   1693     forward_backward = self._select_forward_and_backward_functions(
   1694         args,

~\Anaconda3\envs\tensorflow1\lib\site-packages\tensorflow_core\python\eager\function.py in call(self, ctx, args, cancellation_manager)
    543               inputs=args,
    544               attrs=(""executor_type"", executor_type, ""config_proto"", config),
--> 545               ctx=ctx)
    546         else:
    547           outputs = execute.execute_with_cancellation(

~\Anaconda3\envs\tensorflow1\lib\site-packages\tensorflow_core\python\eager\execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     65     else:
     66       message = e.message
---> 67     six.raise_from(core._status_to_exception(e.code, message), None)
     68   except TypeError as e:
     69     keras_symbolic_tensors = [

~\Anaconda3\envs\tensorflow1\lib\site-packages\six.py in raise_from(value, from_value)

ResourceExhaustedError: 2 root error(s) found.
  (0) Resource exhausted:  OOM when allocating tensor with shape[1166541600] and type int32 on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[node BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/non_max_suppression/NonMaxSuppressionV2 (defined at <ipython-input-9-f8a3c92a04a4>:11) ]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

	 [[BatchMultiClassNonMaxSuppression/map/while/strided_slice/_170]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

  (1) Resource exhausted:  OOM when allocating tensor with shape[1166541600] and type int32 on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[node BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/non_max_suppression/NonMaxSuppressionV2 (defined at <ipython-input-9-f8a3c92a04a4>:11) ]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

0 successful operations.
0 derived errors ignored. [Op:__inference_pruned_65677]

Function call stack:
pruned -> pruned
"
37261,Giving example on website has no model.predict examples,"First of all, you have a great website to understand the Tensorflow library. I am a newbie. And want to understand the point is: I go through the examples. Except for basic image classification, there is no example : how to feed my own data wich has no label. And I want to get predictions of my own data. example :   https://stackoverflow.com/questions/60389558/how-to-feed-my-own-data-and-evaluate-at-tf-text-classification "
37258,"Got ""KeyError: 'stack/values_0' "" when use custom network layer by tf.keras.layers.Layer","**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): 
- OS Platform and Distribution: Linux Ubuntu 16.04 
- TensorFlow installed from : Anaconda
- Python version: 3.7.3
- CUDA/cuDNN version: 10.0/7.0
- GPU model and memory: 6GB
- Tensorfflow version: 2.0.0

**custom network layer**
``` python
import tensorflow as tf


class ROIPoolingLayer(tf.keras.layers.Layer):
    def __init__(self, pooled_height, pooled_width, **kwargs):
        self.pooled_height = pooled_height
        self.pooled_width = pooled_width
        super(ROIPoolingLayer, self).__init__(**kwargs)

    @staticmethod
    def _pool_roi(feature_map, roi, pooled_height, pooled_width):
        """"""
        Applies ROI Pooling to a single image and a single ROI
        """"""
        # Compute the region of interest
        feature_map_height = int(feature_map.shape[0])
        feature_map_width = int(feature_map.shape[1])

        h_start = tf.cast(feature_map_height * roi[0], dtype=tf.int32)
        w_start = tf.cast(feature_map_width * roi[1], dtype=tf.int32)
        h_end = tf.cast(feature_map_height * roi[2], dtype=tf.int32)
        w_end = tf.cast(feature_map_width * roi[3], dtype=tf.int32)

        region = feature_map[h_start:h_end, w_start:w_end, :]

        # Divide the region into non overlapping areas
        region_height = h_end - h_start
        region_width = w_end - w_start
        h_step = tf.cast(region_height / pooled_height, dtype=tf.int32)
        w_step = tf.cast(region_width / pooled_width, dtype=tf.int32)

        areas = [
            [
                (
                    i * h_step,
                    j * w_step,
                    (i + 1) * h_step if i + 1 < pooled_height else region_height,
                    (j + 1) * w_step if j + 1 < pooled_width else region_width
                )
                for j in range(pooled_width)
            ]
            for i in range(pooled_height)
        ]

        # Take the maximum of each area and stack th result
        def pool_area(x):
            return tf.reduce_max(region[x[0]:x[2], x[1]:x[3], :], axis=[0, 1])

        pooled_features = tf.stack([[pool_area(x) for x in row] for row in areas])

        return pooled_features

    @staticmethod
    def _pool_rois(feature_map, rois, pooled_height, pooled_width):
        """"""
        Applies ROI pooling for a single image and varios ROIs
        """"""
        def curried_pool_roi(roi):
            return ROIPoolingLayer._pool_roi(feature_map, roi, pooled_height, pooled_width)

        pooled_areas = tf.map_fn(curried_pool_roi, rois, dtype=tf.float32)

        return pooled_areas

    def compute_output_shape(self, input_shape):
        """"""
        Returns the shape of the ROI Pooling Layer output
        """"""
        feature_map_shape, rois_shape = input_shape
        assert feature_map_shape[0] == rois_shape[0]
        batch_size = feature_map_shape[0]
        n_rois = rois_shape[1]
        n_channels = feature_map_shape[0]
        return tuple((batch_size, n_rois, self.pooled_height, self.pooled_width, n_channels))

    def get_config(self):
        config = {
            ""pooled_height"": self.pooled_height,
            ""pooled_width"": self.pooled_width
        }
        base_config = super(ROIPoolingLayer, self).get_config()
        return dict(list(base_config.items()) + list(config.items()))

    def call(self, inputs, **kwargs):
        """"""
        Maps the input tensor of the ROI layer to its output
        """"""
        def curried_pool_rois(x):
            return ROIPoolingLayer._pool_rois(x[0], x[1], self.pooled_height, self.pooled_width)

        pooled_areas = tf.map_fn(curried_pool_rois, inputs, dtype=tf.float32)
        if pooled_areas.shape[1] == 1:
            return tf.squeeze(pooled_areas, axis=1)
        return pooled_areas
```

**Test code**
``` python
import numpy as np
import tensorflow as tf
from net.layer.roi_pooling import ROIPoolingLayer

ddef test_for_tf2():
    input_img = tf.keras.Input(shape=(200, 100, 1), batch_size=1, name=""input_img"")
    roi_region = ROIPoolingLayer(3, 7)([input_img, np.asarray([[[0.5, 0.2, 0.7, 0.4], [0.0, 0.0, 1.0, 1.0]]], dtype=np.float32)])
    fc0 = tf.keras.layers.Flatten()(roi_region)
    fc1 = tf.keras.layers.Dense(30, activation=None, name=""pose_ren_outputs"")(fc0)
    model = tf.keras.Model(inputs=input_img, outputs=fc1, name=""Test_model"")
    model.summary()

def main():
    test_for_tf2()


if __name__ == '__main__':
    main()
```


**Error info**
```
Traceback (most recent call last):
  File ""/home/lxz/PycharmProjects/pose-ren-tf2/src/test/roi_pooling_test.py"", line 59, in <module>
    main()
  File ""/home/lxz/PycharmProjects/pose-ren-tf2/src/test/roi_pooling_test.py"", line 55, in main
    test_for_tf2()
  File ""/home/lxz/PycharmProjects/pose-ren-tf2/src/test/roi_pooling_test.py"", line 48, in test_for_tf2
    roi_region = ROIPoolingLayer(3, 7)([input_img, np.asarray([[[0.5, 0.2, 0.7, 0.4], [0.0, 0.0, 1.0, 1.0]]], dtype=np.float32)])
  File ""/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 891, in __call__
    outputs = self.call(cast_inputs, *args, **kwargs)
  File ""/home/lxz/PycharmProjects/pose-ren-tf2/src/net/layer/roi_pooling.py"", line 95, in call
    pooled_areas = tf.map_fn(curried_pool_rois, inputs, dtype=tf.float32)
  File ""/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/map_fn.py"", line 268, in map_fn
    maximum_iterations=n)
  File ""/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/control_flow_ops.py"", line 2714, in while_loop
    loop_vars = body(*loop_vars)
  File ""/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/control_flow_ops.py"", line 2705, in <lambda>
    body = lambda i, lv: (i + 1, orig_body(*lv))
  File ""/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/map_fn.py"", line 257, in compute
    packed_fn_values = fn(packed_values)
  File ""/home/lxz/PycharmProjects/pose-ren-tf2/src/net/layer/roi_pooling.py"", line 93, in curried_pool_rois
    return ROIPoolingLayer._pool_rois(x[0], x[1], self.pooled_height, self.pooled_width)
  File ""/home/lxz/PycharmProjects/pose-ren-tf2/src/net/layer/roi_pooling.py"", line 61, in _pool_rois
    pooled_areas = tf.map_fn(curried_pool_roi, rois, dtype=tf.float32)
  File ""/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/map_fn.py"", line 268, in map_fn
    maximum_iterations=n)
  File ""/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/control_flow_ops.py"", line 2714, in while_loop
    loop_vars = body(*loop_vars)
  File ""/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/control_flow_ops.py"", line 2705, in <lambda>
    body = lambda i, lv: (i + 1, orig_body(*lv))
  File ""/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/map_fn.py"", line 257, in compute
    packed_fn_values = fn(packed_values)
  File ""/home/lxz/PycharmProjects/pose-ren-tf2/src/net/layer/roi_pooling.py"", line 59, in curried_pool_roi
    return ROIPoolingLayer._pool_roi(feature_map, roi, pooled_height, pooled_width)
  File ""/home/lxz/PycharmProjects/pose-ren-tf2/src/net/layer/roi_pooling.py"", line 49, in _pool_roi
    pooled_features = tf.stack([[pool_area(x) for x in row] for row in areas])
  File ""/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py"", line 180, in wrapper
    return target(*args, **kwargs)
  File ""/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py"", line 1165, in stack
    return gen_array_ops.pack(values, axis=axis, name=name)
  File ""/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py"", line 6304, in pack
    ""Pack"", values=values, axis=axis, name=name)
  File ""/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper
    op_def=op_def)
  File ""/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 3360, in create_op
    attrs, op_def, compute_device)
  File ""/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 3429, in _create_op_internal
    op_def=op_def)
  File ""/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 1792, in __init__
    self._control_flow_post_processing()
  File ""/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 1800, in _control_flow_post_processing
    for input_tensor in self.inputs:
  File ""/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 2167, in inputs
    for tf_output in tf_outputs
  File ""/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 2167, in <listcomp>
    for tf_output in tf_outputs
  File ""/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 3801, in _get_tensor_by_tf_output
    op = self._get_operation_by_tf_operation(tf_output.oper)
  File ""/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 3765, in _get_operation_by_tf_operation
    return self._get_operation_by_name_unsafe(op_name)
  File ""/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 3761, in _get_operation_by_name_unsafe
    return self._nodes_by_name[name]
KeyError: 'stack/values_0'
```



"
37257, Blas GEMM launch failed;failed to create cublas handle: CUBLAS_STATUS_INTERNAL_ERROR,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): windows10
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): tensorflow2.0.0
- Python version: python3.7.3
- CUDA/cuDNN version: cuda10.2/cudnn7.6.5
- GPU model and memory:GeForce GTX 1060 6G

You can collect some of this information using our environment capture
error log as blow:
`2020-03-03 20:36:53.881317: E tensorflow/stream_executor/cuda/cuda_blas.cc:238] failed to create cublas handle: CUBLAS_STATUS_INTERNAL_ERROR
2020-03-03 20:36:53.886872: E tensorflow/stream_executor/cuda/cuda_blas.cc:238] failed to create cublas handle: CUBLAS_STATUS_INTERNAL_ERROR
Traceback (most recent call last):
  File ""main.py"", line 69, in <module>
    train()
  File ""main.py"", line 61, in train
    train_epoch(epoch)
  File ""main.py"", line 43, in train_epoch
    out = model(x)
  File ""D:\anaconda3\lib\site-packages\tensorflow_core\python\keras\engine\base_layer.py"", line 891, in __call__
    outputs = self.call(cast_inputs, *args, **kwargs)
  File ""D:\anaconda3\lib\site-packages\tensorflow_core\python\keras\engine\sequential.py"", line 270, in call
    outputs = layer(inputs, **kwargs)
  File ""D:\anaconda3\lib\site-packages\tensorflow_core\python\keras\engine\base_layer.py"", line 891, in __call__
    outputs = self.call(cast_inputs, *args, **kwargs)
  File ""D:\anaconda3\lib\site-packages\tensorflow_core\python\keras\layers\core.py"", line 1056, in call
    outputs = gen_math_ops.mat_mul(inputs, self.kernel)
  File ""D:\anaconda3\lib\site-packages\tensorflow_core\python\ops\gen_math_ops.py"", line 6126, in mat_mul
    _six.raise_from(_core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InternalError: Blas GEMM launch failed : a.shape=(200, 784), b.shape=(784, 512), m=200, n=512, k=784 [Op:MatMul]`
**Describe the current behavior**
two errors:1.failed to create cublas handle. 2.Blas GEMM launch failed
I don't know where there is a problem. this is my first time using a gpu to code. when I thought the installation these cuda and tensorflow well, everyting is ok ,the problem occurs as below.

"
37256,Tensorflow 2.1: How does the metric 'tf.keras.metrics.PrecisionAtRecall' works with multiclass-classification? ,"I am wondering how this metrics works in case of multiclass classification. Does it compute the average between values of precision belonging to each class?

I have a multiclass-classification problem, with three classes. I am interested in calculate the PrecisionAtRecall when the recall value is equal to 0.76, only for a specific class . What I have done was just setting 0.76 in brackets :
'' model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', tf.keras.metrics.PrecisionAtRecall(0.76)], sample_weight_mode='temporal') ''
But I am sure is not the right way.
How can I adjust the metric to reach my goal?
Thanks"
37254,"InvalidArgumentError:  indices[0,4] = 10 is not in [0, 10) 	 [[node model/embedding_2/embedding_lookup (defined at <ipython-input-54-57c88bb5c904>:38) ]] [Op:__inference_distributed_function_20003]  Errors may have originated from an input operation. Input Source operations connected to node model/embedding_2/embedding_lookup:  model/embedding_2/embedding_lookup/19444 (defined at c:\users\naik9\appdata\local\programs\python\python37\lib\contextlib.py:112)  Function call stack: distributed_function","Train on 10240 samples, validate on 1284 samples
Epoch 1/30
   40/10240 [..............................] - ETA: 4:26WARNING:tensorflow:Can save best model only with val_categorical_accuracy available, skipping.
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-55-6d913c48a8e6> in <module>
----> 1 train(model_cnn,'cnn', use_pos, use_meta, use_dep)

<ipython-input-54-57c88bb5c904> in train(model, name, use_pos, use_meta, use_dep)
     36             {'main_input': X_val, 'aux_input': X_val_meta, 'dep_input': X_val_dep},
     37             {'main_output': Y_val}
---> 38         ), callbacks=[tb,csv_logger,checkpoint])
     39     else:
     40       model.fit(

c:\users\n\appdata\local\programs\python\python37\lib\site-packages\tensorflow_core\python\keras\engine\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    817         max_queue_size=max_queue_size,
    818         workers=workers,
--> 819         use_multiprocessing=use_multiprocessing)
    820 
    821   def evaluate(self,

c:\users\n\appdata\local\programs\python\python37\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    340                 mode=ModeKeys.TRAIN,
    341                 training_context=training_context,
--> 342                 total_epochs=epochs)
    343             cbks.make_logs(model, epoch_logs, training_result, ModeKeys.TRAIN)
    344 

c:\users\n\appdata\local\programs\python\python37\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)
    126         step=step, mode=mode, size=current_batch_size) as batch_logs:
    127       try:
--> 128         batch_outs = execution_function(iterator)
    129       except (StopIteration, errors.OutOfRangeError):
    130         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?

c:\users\n\appdata\local\programs\python\python37\lib\site-packages\tensorflow_core\python\keras\engine\training_v2_utils.py in execution_function(input_fn)
     96     # `numpy` translates Tensors to values in Eager mode.
     97     return nest.map_structure(_non_none_constant_value,
---> 98                               distributed_function(input_fn))
     99 
    100   return execution_function

c:\users\n\appdata\local\programs\python\python37\lib\site-packages\tensorflow_core\python\eager\def_function.py in __call__(self, *args, **kwds)
    566         xla_context.Exit()
    567     else:
--> 568       result = self._call(*args, **kwds)
    569 
    570     if tracing_count == self._get_tracing_count():

c:\users\n\appdata\local\programs\python\python37\lib\site-packages\tensorflow_core\python\eager\def_function.py in _call(self, *args, **kwds)
    630         # Lifting succeeded, so variables are initialized and we can run the
    631         # stateless function.
--> 632         return self._stateless_fn(*args, **kwds)
    633     else:
    634       canon_args, canon_kwds = \

c:\users\n\appdata\local\programs\python\python37\lib\site-packages\tensorflow_core\python\eager\function.py in __call__(self, *args, **kwargs)
   2361     with self._lock:
   2362       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
-> 2363     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
   2364 
   2365   @property

c:\users\n\appdata\local\programs\python\python37\lib\site-packages\tensorflow_core\python\eager\function.py in _filtered_call(self, args, kwargs)
   1609          if isinstance(t, (ops.Tensor,
   1610                            resource_variable_ops.BaseResourceVariable))),
-> 1611         self.captured_inputs)
   1612 
   1613   def _call_flat(self, args, captured_inputs, cancellation_manager=None):

c:\users\n\appdata\local\programs\python\python37\lib\site-packages\tensorflow_core\python\eager\function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1690       # No tape is watching; skip to running the function.
   1691       return self._build_call_outputs(self._inference_function.call(
-> 1692           ctx, args, cancellation_manager=cancellation_manager))
   1693     forward_backward = self._select_forward_and_backward_functions(
   1694         args,

c:\users\n\appdata\local\programs\python\python37\lib\site-packages\tensorflow_core\python\eager\function.py in call(self, ctx, args, cancellation_manager)
    543               inputs=args,
    544               attrs=(""executor_type"", executor_type, ""config_proto"", config),
--> 545               ctx=ctx)
    546         else:
    547           outputs = execute.execute_with_cancellation(

c:\users\n\appdata\local\programs\python\python37\lib\site-packages\tensorflow_core\python\eager\execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     65     else:
     66       message = e.message
---> 67     six.raise_from(core._status_to_exception(e.code, message), None)
     68   except TypeError as e:
     69     keras_symbolic_tensors = [

c:\users\n\appdata\local\programs\python\python37\lib\site-packages\six.py in raise_from(value, from_value)

InvalidArgumentError:  indices[0,4] = 10 is not in [0, 10)
	 [[node model/embedding_2/embedding_lookup (defined at <ipython-input-54-57c88bb5c904>:38) ]] [Op:__inference_distributed_function_20003]

Errors may have originated from an input operation.
Input Source operations connected to node model/embedding_2/embedding_lookup:
 model/embedding_2/embedding_lookup/19444 (defined at c:\users\n\appdata\local\programs\python\python37\lib\contextlib.py:112)

Function call stack:
distributed_function"
37253,tf2.1 with gpu can't open cuda 10.2,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  windows 10 (profession)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): 
- TensorFlow version: v2.1.0-rc2-17-ge5bf8de410
- Python version:  3.68
- Installed using virtualenv? pip? conda?:  pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.2 cuda / 7.6 cudnn
- GPU model and memory:  2G



**Describe the problem**

ERROR: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] cannot opened dynamic library cudart64_101.dll

**Provide the exact sequence of commands / steps that you executed before running into the problem**

My computer has windows 10 professional vesion os, and GPU-GTX1050. Then Install the cuda 10.2 and cudnn 7.6 version.  I use Pycharm professional version create a virtual env. Wait a moment, use pip install the tensorflow-2.1-gpu version, successfully. When I test the tensorflow2.1-gpu version, it arises the error ""cannot opened dynamic library cudart64_101.dll"".

How do I resolve? 
Maybe It is something wrong with cuda10.2, therefore ,I search the dir where i install the cuda. I find the directory-bin which has cudart64_102.dll , not cudart64_101.dll. For safely, i copy cudart64_102.dll, and rename , push into the bin directory. 


Then i rerun the tf, it can work...
2020-03-03 16:38:19.699659: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll


**Any other info / logs**

Maybe it is something wrong with cuda10.2 and tensorflow-2.1-gpu.
Tensorflow can't find the cudart64_101.dll. The cuda10.2 has not cudart64_101.dll, but has cudart64_102.dll. Ok, it should be the api.
"
37252,Memory leak activated when setting a seed in TensorFlow 2 (2.0 & 2.1) and using eager execution.,"Firstly, I would like to thank @condnsdmatters for his help in investigating this issue and tracing the problem back to the use of a random state when setting a seed for TensorFlow.


**System information** 
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 2.1.0 (also tested on 2.0.0)
- Python version: Python 3.7.5
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: - GPU model and memory: N/A

**Describe the current behaviour**
When a random seed is set in TensorFlow 2 (2.0 or 2.1) memory usage increases with every call to usage of any random sampling in TensorFlow. We believe that this is due to the use of a Python's `random.Random` random state as a source of randomness and a lack of garbage collection for the results of random sampling. We may see that when a seed is set TensorFlow uses `random.Random` by looking at the [`_set_global_seed`](https://github.com/tensorflow/tensorflow/blob/e5bf8de410005de06a7ff5393fafdf832ef1d4ad/tensorflow/python/eager/context.py#L433) method of an eager execution context.

The reproduction example does not use `tf.random.set_seed` since we have tracked the issue down more narrowly to the sampling of random values and we therefore concentrate on a minimal focussed example in the hope of enabling a faster fix.

See the reproduction below and [our colab notebook](https://colab.research.google.com/drive/1HhVduWlY6Va_KLX2b-SqCGIWLNDy5MFT) for concrete examples of when this occurs. See the note at the end of this post before running the code.

**Describe the expected behaviour**
We would not expect memory usage to grow with the number of calls to random sampling. In the example below we would expect constant memory usage.

**Standalone code to reproduce the issue** 
The code below will show increasing memory usage over time.

```python
import tensorflow as tf
from random import Random
import os
import psutil

MAXINT = 2**32 - 1

def print_memory_usage():
    print(""memory used:"", psutil.Process(os.getpid()).memory_info().rss)
    return psutil.Process(os.getpid()).memory_info().rss

if __name__ == ""__main__"":
    random_state = Random()
    for _ in range(10):
        for _ in range(1000):
            a = random_state.randint(0, MAXINT)
            tf.Variable(a)
        print_memory_usage()
```

Further examples of cases with and without memory leaks are provided in [this colab notebook](https://colab.research.google.com/drive/1HhVduWlY6Va_KLX2b-SqCGIWLNDy5MFT).

**Other info / logs**
If the random integer sampled in the example is cast to a float the memory issue remains. However, if it is cast to a string before being passed to `tf.Variable` then there is no memory issue. This leads us to think that the issue is related to the memory usage as laid out in the C++ code of TensorFlow [here](https://github.com/tensorflow/tensorflow/blob/b87f4a54652d72435a088e5a510ca46e124deccd/tensorflow/c/tf_tensor.cc#L109).

This is an issue with eager execution as defining the loops in a function and decorating it with `tf.function` resolves the memory issue. This then leads us to the more targetted example included below.

```python
from random import Random
from tensorflow.python.framework.constant_op import convert_to_eager_tensor
from tensorflow.python.eager import context
import os
import psutil

MAXINT = 2**32 - 1

def print_memory_usage():
    print(""memory used:"", psutil.Process(os.getpid()).memory_info().rss)
    return psutil.Process(os.getpid()).memory_info().rss


if __name__ == ""__main__"":
    random_state = Random()
    ctx = context.context()
    for _ in range(10):
        for _ in range(1000):
            a = random_state.randint(0, MAXINT)
            convert_to_eager_tensor(a, ctx)

        print_memory_usage()
```

**Note:** Running the code in [the colab notebook](https://colab.research.google.com/drive/1HhVduWlY6Va_KLX2b-SqCGIWLNDy5MFT) provided can lead to inconsistent results due to the cloud execution environment. We suggest running our examples locally when debugging. At the very least the run time should be reset and each example run from a clean starting point before conclusions are drawn."
37251,tensorflow:AutoGraph could not transform ,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow):  Yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04):    windows 10 (profession)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device:  No
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below):  v2.1.0-rc2-17-ge5bf8de410
- Python version: - Bazel
version (if compiling from source):  3.68
- GCC/Compiler version (if compiling from
source):  
- CUDA/cuDNN version:  - GPU model and memory:  10.2cuda/ 7.6cudnn 

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**Standalone code to reproduce the issue**
Here is some code:
 
class MultiHeadAttention(keras.layers.Layer):
    def __init__(self, d_model, num_heads):
        super(MultiHeadAttention, self).__init__()
        self.num_heads = num_heads
        self.d_model = d_model
        assert self.d_model%self.num_heads == 0
        self.depth = self.d_model // self.num_heads
        self.WQ = keras.layers.Dense(self.d_model)
        self.WK = keras.layers.Dense(self.d_model)
        self.WV = keras.layers.Dense(self.d_model)
        self.dense = keras.layers.Dense(self.d_model)
    
    def call(self,q,k,v,mask):
        batch_size = tf.shape(q)[0]
.......


**Other info / logs** 
The main warning: Maybe it is a bug...
WARNING:tensorflow:AutoGraph could not transform <bound method MultiHeadAttention.call of <__main__.MultiHeadAttention object at 0x000001DC2AFC2668>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x000001DD96E9D978>, <gast.gast.Return object at 0x000001DD96E9D9E8>]
WARNING:tensorflow:AutoGraph could not transform <bound method MultiHeadAttention.call of <__main__.MultiHeadAttention object at 0x000001DC2AFC2668>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x000001DD96E9D978>, <gast.gast.Return object at 0x000001DD96E9D9E8>]
WARNING:tensorflow:AutoGraph could not transform <bound method MultiHeadAttention.call of <__main__.MultiHeadAttention object at 0x000001DC2CCBD5C0>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x000001DD96F0FCF8>, <gast.gast.Return object at 0x000001DD96F0FD68>]
WARNING:tensorflow:AutoGraph could not transform <bound method MultiHeadAttention.call of <__main__.MultiHeadAttention object at 0x000001DC2CCBD5C0>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x000001DD96F0FCF8>, <gast.gast.Return object at 0x000001DD96F0FD68>]
WARNING:tensorflow:AutoGraph could not transform <bound method MultiHeadAttention.call of <__main__.MultiHeadAttention object at 0x000001DC2BFDB2E8>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x000001DD96F7E0F0>, <gast.gast.Return object at 0x000001DD96F7E160>]
WARNING:tensorflow:AutoGraph could not transform <bound method MultiHeadAttention.call of <__main__.MultiHeadAttention object at 0x000001DC2BFDB2E8>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x000001DD96F7E0F0>, <gast.gast.Return object at 0x000001DD96F7E160>]
WARNING:tensorflow:AutoGraph could not transform <bound method MultiHeadAttention.call of <__main__.MultiHeadAttention object at 0x000001DC2AA7A208>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x000001DD96FEB470>, <gast.gast.Return object at 0x000001DD96FEB4E0>]
WARNING:tensorflow:AutoGraph could not transform <bound method MultiHeadAttention.call of <__main__.MultiHeadAttention object at 0x000001DC2AA7A208>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x000001DD96FEB470>, <gast.gast.Return object at 0x000001DD96FEB4E0>]
WARNING:tensorflow:AutoGraph could not transform <bound method MultiHeadAttention.call of <__main__.MultiHeadAttention object at 0x000001DC2B1A34A8>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x000001DD970746A0>, <gast.gast.Return object at 0x000001DD97074710>]
WARNING:tensorflow:AutoGraph could not transform <bound method MultiHeadAttention.call of <__main__.MultiHeadAttention object at 0x000001DC2B1A34A8>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x000001DD970746A0>, <gast.gast.Return object at 0x000001DD97074710>]
WARNING:tensorflow:AutoGraph could not transform <bound method MultiHeadAttention.call of <__main__.MultiHeadAttention object at 0x000001DC2BA9EBE0>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x000001DD970C3B38>, <gast.gast.Return object at 0x000001DD970C3BA8>]
WARNING:tensorflow:AutoGraph could not transform <bound method MultiHeadAttention.call of <__main__.MultiHeadAttention object at 0x000001DC2BA9EBE0>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x000001DD970C3B38>, <gast.gast.Return object at 0x000001DD970C3BA8>]
WARNING:tensorflow:AutoGraph could not transform <bound method MultiHeadAttention.call of <__main__.MultiHeadAttention object at 0x000001DC2CD6BC18>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x000001DD9B074EF0>, <gast.gast.Return object at 0x000001DD9B074F60>]
WARNING:tensorflow:AutoGraph could not transform <bound method MultiHeadAttention.call of <__main__.MultiHeadAttention object at 0x000001DC2CD6BC18>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x000001DD9B074EF0>, <gast.gast.Return object at 0x000001DD9B074F60>]
WARNING:tensorflow:AutoGraph could not transform <bound method MultiHeadAttention.call of <__main__.MultiHeadAttention object at 0x000001DC2B1E4CF8>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x000001DD9B0C0390>, <gast.gast.Return object at 0x000001DD9B0C0400>]
WARNING:tensorflow:AutoGraph could not transform <bound method MultiHeadAttention.call of <__main__.MultiHeadAttention object at 0x000001DC2B1E4CF8>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x000001DD9B0C0390>, <gast.gast.Return object at 0x000001DD9B0C0400>]
WARNING:tensorflow:AutoGraph could not transform <bound method MultiHeadAttention.call of <__main__.MultiHeadAttention object at 0x000001DC2AC4AB70>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x000001DD9B130710>, <gast.gast.Return object at 0x000001DD9B130780>]
WARNING:tensorflow:AutoGraph could not transform <bound method MultiHeadAttention.call of <__main__.MultiHeadAttention object at 0x000001DC2AC4AB70>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x000001DD9B130710>, <gast.gast.Return object at 0x000001DD9B130780>]
WARNING:tensorflow:AutoGraph could not transform <bound method MultiHeadAttention.call of <__main__.MultiHeadAttention object at 0x000001DC2B1959B0>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x000001DD9B137BA8>, <gast.gast.Return object at 0x000001DD9B137C18>]
WARNING:tensorflow:AutoGraph could not transform <bound method MultiHeadAttention.call of <__main__.MultiHeadAttention object at 0x000001DC2B1959B0>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x000001DD9B137BA8>, <gast.gast.Return object at 0x000001DD9B137C18>]
WARNING:tensorflow:AutoGraph could not transform <bound method MultiHeadAttention.call of <__main__.MultiHeadAttention object at 0x000001DC2AF24080>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x000001DD9B1EFF28>, <gast.gast.Return object at 0x000001DD9B1EFF98>]
WARNING:tensorflow:AutoGraph could not transform <bound method MultiHeadAttention.call of <__main__.MultiHeadAttention object at 0x000001DC2AF24080>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x000001DD9B1EFF28>, <gast.gast.Return object at 0x000001DD9B1EFF98>]
WARNING:tensorflow:AutoGraph could not transform <bound method MultiHeadAttention.call of <__main__.MultiHeadAttention object at 0x000001DC2BF92048>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x000001DD9B23A400>, <gast.gast.Return object at 0x000001DD9B23A470>]
WARNING:tensorflow:AutoGraph could not transform <bound method MultiHeadAttention.call of <__main__.MultiHeadAttention object at 0x000001DC2BF92048>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x000001DD9B23A400>, <gast.gast.Return object at 0x000001DD9B23A470>]"
37250,Saving model with tf.keras.layers.RNN and stateful=True with save_format='tf' fails,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution: Linux Ubuntu 18.04
- Mobile device if the issue happens on mobile device: -
- TensorFlow installed from: binary
- TensorFlow version: 2.2.0-dev20200228
- Python version: 3.6.9
- Bazel version (if compiling from source): -
- GCC/Compiler version (if compiling from source): -
- CUDA/cuDNN version: CPU only
- GPU model and memory: CPU only

**Describe the current behavior**
Saving a `tf.keras.Sequential` model with `tf.keras.layers.RNN` and `stateful=True` with `save_format=tf` fails.

**Describe the expected behavior**
Saving should succeed.

**Code to reproduce the issue**
```python
import tensorflow as tf

number_of_cells = 2

model = tf.keras.Sequential()

model.add(tf.keras.layers.Input(batch_input_shape=(1, 1, 1)))

cells = []

for _ in range(number_of_cells):
    cells.append(tf.keras.layers.GRUCell(10))

model.add(tf.keras.layers.RNN(cells, stateful=True))

model.compile()

model.save('rnn.tf', save_format='tf')

model2 = tf.keras.models.load_model('rnn.tf')

```

**Other info / logs**
Saving succeeds with `save_format='h5'`.

Traceback in case of failure:
```bash
Traceback (most recent call last):
  File ""test.py"", line 18, in <module>
    model.save('rnn.tf', save_format='tf')
  File ""/home/test/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py"", line 1044, in save
    signatures, options)
  File ""/home/test/.local/lib/python3.6/site-packages/tensorflow/python/keras/saving/save.py"", line 138, in save_model
    signatures, options)
  File ""/home/test/.local/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/save.py"", line 78, in save
    save_lib.save(model, filepath, signatures, options)
  File ""/home/test/.local/lib/python3.6/site-packages/tensorflow/python/saved_model/save.py"", line 951, in save
    obj, export_dir, signatures, options, meta_graph_def)
  File ""/home/test/.local/lib/python3.6/site-packages/tensorflow/python/saved_model/save.py"", line 1027, in _build_meta_graph
    options.namespace_whitelist)
  File ""/home/test/.local/lib/python3.6/site-packages/tensorflow/python/saved_model/save.py"", line 629, in _fill_meta_graph_def
    signatures = _generate_signatures(signature_functions, resource_map)
  File ""/home/test/.local/lib/python3.6/site-packages/tensorflow/python/saved_model/save.py"", line 497, in _generate_signatures
    function, mapped_inputs, resource_map)
  File ""/home/test/.local/lib/python3.6/site-packages/tensorflow/python/saved_model/save.py"", line 449, in _call_function_with_mapped_captures
    resource_map)
  File ""/home/test/.local/lib/python3.6/site-packages/tensorflow/python/saved_model/save.py"", line 372, in _map_captures_to_created_tensors
    ).format(interior))
AssertionError: Tried to export a function which references untracked object Tensor(""2164:0"", shape=(), dtype=resource).TensorFlow objects (e.g. tf.Variable) captured by functions must be tracked by assigning them to an attribute of a tracked object or assigned to an attribute of the main object directly.
```
"
37247,Does BatchMatMul is still not supported in TF1.15?,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):MacOS 10.14
- TensorFlow installed from (source or binary):
- TensorFlow version (or github SHA if from source):TF1.15


**The output from the converter invocation**

```
Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION, CONV_2D, DIV, EQUAL, EXPAND_DIMS, FILL, FLOOR_DIV, FULLY_CONNECTED, GATHER, LOGISTIC, MATRIX_DIAG, MEAN, MUL, PACK, POW, RESHAPE, SELECT, SHAPE, SLICE, SOFTMAX, SPLIT, SQUARED_DIFFERENCE, SQUEEZE, STRIDED_SLICE, SUB, TILE, TRANSPOSE. Here is a list of operators for which you will need custom implementations: BatchMatMul.
Traceback (most recent call last):
  File ""/Users/tianhongzxy/Documents/sakt_tf1.15/venv_sakt_tf/bin/toco_from_protos"", line 8, in <module>
    sys.exit(main())
  File ""/Users/tianhongzxy/Documents/sakt_tf1.15/venv_sakt_tf/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 89, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""/Users/tianhongzxy/Documents/sakt_tf1.15/venv_sakt_tf/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/Users/tianhongzxy/Documents/sakt_tf1.15/venv_sakt_tf/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/Users/tianhongzxy/Documents/sakt_tf1.15/venv_sakt_tf/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/Users/tianhongzxy/Documents/sakt_tf1.15/venv_sakt_tf/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 52, in execute
    enable_mlir_converter)
Exception: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION, CONV_2D, DIV, EQUAL, EXPAND_DIMS, FILL, FLOOR_DIV, FULLY_CONNECTED, GATHER, LOGISTIC, MATRIX_DIAG, MEAN, MUL, PACK, POW, RESHAPE, SELECT, SHAPE, SLICE, SOFTMAX, SPLIT, SQUARED_DIFFERENCE, SQUEEZE, STRIDED_SLICE, SUB, TILE, TRANSPOSE. Here is a list of operators for which you will need custom implementations: BatchMatMul.

```"
37246,Adding support to TensorFlow Lite for more ops,"Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CONCATENATION, CONV_2D, DEPTHWISE_CONV_2D, LOGISTIC, RESHAPE. Here is a list of operators for which you will need custom implementations: TFLite_Detection_PostProcess."
37245,Warning/Error not present when not using the result of write in a TensorArray,"**System information** 
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.1.0
- Python version: 3.6.8

**Describe the current behavior**
When not using the result of a `write` method from a `TensorArray`, I am not getting any warning or error.

**Describe the expected behavior**
According to [the docs of `write`](https://www.tensorflow.org/api_docs/python/tf/TensorArray#write), I should receive a warning or error.
I think it's also important to receive one given I spent quite some time realizing it was not inplace.

**Standalone code to reproduce the issue** 
```python
import tensorflow as tf
@tf.function
def use_tensor_array(x):
    y = tf.TensorArray(x.dtype, tf.shape(x)[0])
    for i in tf.range(tf.shape(x)[0]):
        y.write(i, x[i])
    y = y.stack()
    return y

use_tensor_array(tf.constant([1, 3, 4, 6]))
```

"
37243,Problem with segmentation my dataset  in DeepLab,"I adapted the ""build_convert"" of the PASCAL Dataset to convert my dataset to execute the DeepLab, but all my segmentation tests generate a black image prediction. 

My dataset has images with 140x140 px. (see an example above:)

Original Image
![211789](https://user-images.githubusercontent.com/18166522/75722022-256f2400-5cb8-11ea-9308-0c7637d37cb5.png)

Original Mask
![211789_OriginalMask](https://user-images.githubusercontent.com/18166522/75721512-3d927380-5cb7-11ea-866d-1e16364d073b.png)

Converted Mask
![211789_ConvertedMask](https://user-images.githubusercontent.com/18166522/75721539-4b47f900-5cb7-11ea-9657-8644aa8eb335.png)

Prediction Image (complete black, all prediction pixels are background)
![211789_Prediction](https://user-images.githubusercontent.com/18166522/75721593-69155e00-5cb7-11ea-8580-61f163bf611c.png)

What am I doing wrong?
Could anybody help me with this problem?

Thanks
"
37242,TFLite model not running in spite of using SELECT_TF_OPS for Mean operation,"**System information**
- Android 9/TOCO ran on MAC OS (Tensorflow 2.1.0)

-  implementation 'org.tensorflow:tensorflow-lite:0.0.0-nightly'
    implementation 'org.tensorflow:tensorflow-lite-gpu:0.0.0-nightly'
    implementation 'org.tensorflow:tensorflow-lite-support:0.0.0-nightly'
    implementation 'org.tensorflow:tensorflow-lite-select-tf-ops:0.0.0-nightly'

Toco command (with allow custom ops and to use select tf ops), converted with **tensorflow 2.1.0**:

`toco --input_file=/Users/debasish/Downloads/tfdir/agegendermultitaskspcnn.pb --output_file=/Users/debasish/Downloads/tfdir/agegendermultitaskspcnn.tflite --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --input_arrays=input --output_arrays=ageprob,genderprob --input_shapes=1,227,227,3 --mean_values=117 --std_values=1 --allow_custom_ops --target_ops=TFLITE_BUILTINS,SELECT_TF_OPS`

The model builds OK with this command. But while running on Android at the below statement, I get following error while creating a interpreter.

`        tflite = new Interpreter(tfliteModel, tfliteOptions);`

Error Message:

```
java.lang.IllegalStateException: Internal error: Unexpected failure when preparing tensor allocations: Encountered unresolved custom op: Mean.
    Node number 4 (Mean) failed to prepare
```

Graph
![agegendermultitaskspcnn](https://user-images.githubusercontent.com/7953422/75726912-9db20580-5d09-11ea-94e0-c043e5e7673f.png)

"
37241,Using different version of tensorRT?,"I wasn't sure what type of issue this was, so I'm trying others.

Hi. I'm trying to run tensorflow on a gpu server.

I don't have access rights to installing(changing) packages on the server, and the server has TensorRT-5.1.5 version installed.
But I'm assuming when I import tensorflow 2.0.0, it's failing to find TensorRT v6, and just using cpu instead. Is there a way for the tensorflow to use a different version of TensorRT?

These are the errors I'm getting;

2020-03-02 10:22:52.294562: W tensorflow/stream_executor/platform/default/dso_loader.cc:55<http://dso_loader.cc:55>] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /N/soft/rhel7/deeplearning/Python-3.7.6/lib:/N/soft/rhel7/deeplearning/Python-3.7.6/cuda/lib64:/N/soft/rhel7/deeplearning/TensorRT-5.1.5.0/lib:/N/soft/rhel7/deeplearning/gcc-7.4.0/lib:/N/soft/rhel7/deeplearning/gcc-7.4.0/lib64:/N/soft/rhel7/deeplearning/cuda/lib64:/N/soft/rhel7/deeplearning/Python-3.6.8/lib:/N/soft/rhel7/deeplearning/Python-3.6.8/pytorch/torch/lib64:/N/soft/rhel7/deeplearning/Python-3.6.8/pytorch/torch/lib:/N/soft/rhel7/cuda/10.0/lib64:/N/soft/rhel7/perl/gnu/5.24.1/lib:/N/soft/rhel7/intel/18.0.2/compilers_and_libraries_2018.2.199/linux/compiler/lib/intel64:/N/soft/rhel7/intel/18.0.2/compilers_and_libraries_2018.2.199/linux/ipp/lib/intel64:/N/soft/rhel7/intel/18.0.2/compilers_and_libraries_2018.2.199/linux/compiler/lib/intel64_lin:/N/soft/rhel7/intel/18.0.2/compilers_and_libraries_2018.2.199/linux/mkl/lib/intel64_lin:/N/soft/rhel7/intel/18.0.2/compilers_and_libraries_2018.2.199/linux/tbb/lib/intel64/gcc4.7:/N/soft/rhel7/intel/18.0.2/debugger_2018/iga/lib:/N/soft/rhel7/intel/18.0.2/debugger_2018/libipt/intel64/lib:/N/soft/rhel7/intel/18.0.2/compilers_and_libraries_2018.2.199/linux/daal/lib/intel64_lin
   2020-03-02 10:22:52.295671: W tensorflow/stream_executor/platform/default/dso_loader.cc:55<http://dso_loader.cc:55>] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /N/soft/rhel7/deeplearning/Python-3.7.6/lib:/N/soft/rhel7/deeplearning/Python-3.7.6/cuda/lib64:/N/soft/rhel7/deeplearning/TensorRT-5.1.5.0/lib:/N/soft/rhel7/deeplearning/gcc-7.4.0/lib:/N/soft/rhel7/deeplearning/gcc-7.4.0/lib64:/N/soft/rhel7/deeplearning/cuda/lib64:/N/soft/rhel7/deeplearning/Python-3.6.8/lib:/N/soft/rhel7/deeplearning/Python-3.6.8/pytorch/torch/lib64:/N/soft/rhel7/deeplearning/Python-3.6.8/pytorch/torch/lib:/N/soft/rhel7/cuda/10.0/lib64:/N/soft/rhel7/perl/gnu/5.24.1/lib:/N/soft/rhel7/intel/18.0.2/compilers_and_libraries_2018.2.199/linux/compiler/lib/intel64:/N/soft/rhel7/intel/18.0.2/compilers_and_libraries_2018.2.199/linux/ipp/lib/intel64:/N/soft/rhel7/intel/18.0.2/compilers_and_libraries_2018.2.199/linux/compiler/lib/intel64_lin:/N/soft/rhel7/intel/18.0.2/compilers_and_libraries_2018.2.199/linux/mkl/lib/intel64_lin:/N/soft/rhel7/intel/18.0.2/compilers_and_libraries_2018.2.199/linux/tbb/lib/intel64/gcc4.7:/N/soft/rhel7/intel/18.0.2/debugger_2018/iga/lib:/N/soft/rhel7/intel/18.0.2/debugger_2018/libipt/intel64/lib:/N/soft/rhel7/intel/18.0.2/compilers_and_libraries_2018.2.199/linux/daal/lib/intel64_lin
   2020-03-02 10:22:52.296073: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30<http://py_utils.cc:30>] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly."
37240,How to deserialize from a dict with tf.keras.losses.get,"## URL(s) with the issue:
https://www.tensorflow.org/api_docs/python/tf/keras/losses/get

## Description of issue (what needs changing):
Currently there is no documentation at all.
Its fairly straightforward to use by inputting a string denoting default class name:
ex:
```
identifier = ""categorical_crossentropy""
tf.keras.losses.get(identifier)
```

However, I am having issues with dictionary objects:
ex:
```
identifier = {""class_name"":""categorical_crossentropy"",""config"":{""from_logits"":True}}
tf.keras.losses.get(identifier)
```
Returns:
```
Traceback (most recent call last):
  File "".\main.py"", line 85, in <module>
    loss = tf.keras.losses.get(jsn)
  File ""C:\Users\jopatterson\Documents\autoprime-ml\env\lib\site-packages\tensorflow_core\python\keras\losses.py"", line 1186, in get
    return deserialize(identifier)
  File ""C:\Users\jopatterson\Documents\autoprime-ml\env\lib\site-packages\tensorflow_core\python\keras\losses.py"", line 1175, in deserialize
    printable_module_name='loss function')
  File ""C:\Users\jopatterson\Documents\autoprime-ml\env\lib\site-packages\tensorflow_core\python\keras\utils\generic_utils.py"", line 315, in deserialize_keras_object
    return cls(**cls_config)
TypeError: categorical_crossentropy() missing 2 required positional arguments: 'y_true' and 'y_pred'
```
I believe it is failing because cls is the already initialized loss function, and it is passing cls_config as its input, rather than using them as parameters during initialization.

### Clear description

This is a very useful method for abstract implementations of loss objects.

### Correct links

This is where the issue is occuring, within the `deserialize_keras_object` function:
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/utils/generic_utils.py#L382

### Parameters defined

There currently is no documentation for this, as `identifier` can be a string, dictionary or callable.

### Returns defined

Returns are not defined, but its fairly obvious it returns a loss function.

### Raises listed and defined

No.

### Usage example

No.

### Request visuals, if applicable

No.

### Submit a pull request?

I would do this if I had enough knowledge to do so. Unfortunately I only know how it works with `identifier` as a String."
42781,Community feedback for translated landing pages,"Hello, I was wondering if the TensorFlow tutorial [landing page](https://www.tensorflow.org/tutorials?hl=ko) should be translated by the community. Though I cannot be certain, the page seems to be built from [this source](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/_index.yaml), which is in yaml format. After checking out the TensorFlow website under different language options, namely Korean, Chinese, and Japanese, I found out that none of the languages had a translated landing page. Should this be included in the to-do list of things, or is it somehow handled differently or internally? Thank you.

--------------------

On a similar note, [`_toc.yaml`](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/_toc.yaml) is currently not being translated under any language. It seems like the website is internally/automatically translating it, but some of the translated words remain inconsistent with those used in the actual translated documents. "
37239,tf.keras.experimental.WideDeepModel example has wrong input for constructor,"The tutorial example for tf.keras.experimental.WideDeepModel instantiated the class with first input augment: dnn_model, and second augment: linear_model as shown in :
https://www.tensorflow.org/api_docs/python/tf/keras/experimental/WideDeepModel#example_4

However, the class should be instantiated by linear_model then dnn_model as shown in:
https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/premade/wide_deep.py#L72

Please update the tutorial example.
"
37238,Docs say that sigmoid is mapped to TfLite but the TfLite schema doesn't mention sigmoid,"It lists ```tf.sigmoid``` as mappable to TfLite here: https://www.tensorflow.org/lite/guide/ops_compatibility

But the TfLite schema doesn't mention sigmoid: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/schema/schema.fbs
"
37237,steps_per_epoch not propagating to Keras callbacks in tf-nightly,"This behavior was tested in `tf-nightly==2.2.0.dev20200302` on macOS.

Some of our Keras callbacks rely on accessing `self.params['steps']` in order to take actions based on how far along the process is into the current epoch (e.g., learning rate schedule).  However, it appears that this param is no longer being set properly, even when `mode.fit(steps_per_epoch=...)` is called.

I did some digging, and it looks like the issue can be traced to the way `CallbackList(steps=...)` is being set [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/engine/training.py#L753).  The `DataAdapter` object is an instance of `DatasetAdapter`, which is initialized with the `steps_per_epoch` param and assigns it to `self._user_steps`, but the `get_size()` method always returns `None` [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/engine/data_adapter.py#L704).

Is there a workaround for this?  Ideally, we'd like for callbacks to have access to the `steps_per_epoch` information without having to pass it in to each callback manually.  

You can see an example of how we use this in Horovod in the LearningRateWarmupCallback from the [tensorflow2_keras_mnist.py](https://github.com/horovod/horovod/blob/master/examples/tensorflow2_keras_mnist.py#L77) example.  As you can see in the implementation of that callback [here](https://github.com/horovod/horovod/blob/cff4de331edcd6cabbd807b7010e7432b03fe2b7/horovod/_keras/callbacks.py#L108), we are attempting to access `self.params.get('step')`, which used to get set correctly prior to v2.2.

cc @reedwm @pkanwar23 "
37235,Impossible to install tensorflow on linux from PyPI with pip versions prior to 19,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04 (but affects any linux)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:N/A
- TensorFlow installed from (source or binary): PyPI
- TensorFlow version: 1.15.2
- Python version: 3.6.10
- Installed using virtualenv? pip? conda?: pip version less than 19
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A



**Describe the problem**

Tensorflow 1.15.2 only provides a `manylinux2010` build on [pypi](https://pypi.org/project/tensorflow/1.15.2/#files) and so can't be built with pip versions older than 19. This means it can't be installed it under certain circumstances where pip can't be upgraded; for example using a managed service such as GCP Composer.

This version of manylinux was made usable by pip in [version 19.0](https://pip.pypa.io/en/stable/news/#id209). As far as I'm aware though, pip still supports `manylinux1`, so I would assume it's reasonable to support this for older installs.

Would it be possible to provide a `manylinux1` build on PyPI to circumvent this issue please? I would rather not have to install a version below 1.15.2 as they have a [high severity security issue](https://github.com/advisories/GHSA-977j-xj7q-2jr9)

My assumption is that it's easy to provide this build given the previous minor version used `manylinux1`. Apologies if this is incorrect and there are good reasons not to support this; I couldn't find any relevant issues which addressed this problem so figured it worth raising.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

Trivially reproducible on any linux within a virtualenv. With pip 18.1:

```
$ pip --version
pip 18.1 from /tmp/tensorflow/pip_18_1/lib/python3.6/site-packages/pip (python 3.6)
$ python --version
Python 3.6.10
$ pip install tensorflow==1.15.2
Collecting tensorflow==1.15.2
  Could not find a version that satisfies the requirement tensorflow==1.15.2 (from versions: 0.12.1, 1.0.0, 1.0.1, 1.1.0rc0, 1.1.0rc1, 1.1.0rc2, 1.1.0, 1.2.0rc0, 1.2.0rc1, 1.2.0rc2, 1.2.0, 1.2.1, 1.3.0rc0, 1.3.0rc1, 1.3.0rc2, 1.3.0, 1.4.0rc0, 1.4.0rc1, 1.4.0, 1.4.1, 1.5.0rc0, 1.5.0rc1, 1.5.0, 1.5.1, 1.6.0rc0, 1.6.0rc1, 1.6.0, 1.7.0rc0, 1.7.0rc1, 1.7.0, 1.7.1, 1.8.0rc0, 1.8.0rc1, 1.8.0, 1.9.0rc0, 1.9.0rc1, 1.9.0rc2, 1.9.0, 1.10.0rc0, 1.10.0rc1, 1.10.0, 1.10.1, 1.11.0rc0, 1.11.0rc1, 1.11.0rc2, 1.11.0, 1.12.0rc0, 1.12.0rc1, 1.12.0rc2, 1.12.0, 1.12.2, 1.12.3, 1.13.0rc0, 1.13.0rc1, 1.13.0rc2, 1.13.1, 1.13.2, 1.14.0rc0, 1.14.0rc1, 1.14.0, 2.0.0a0, 2.0.0b0, 2.0.0b1)
No matching distribution found for tensorflow==1.15.2
You are using pip version 18.1, however version 20.0.2 is available.
You should consider upgrading via the 'pip install --upgrade pip' command.
```

With version 19.0 (i.e. what I would expect):

```
$ pip --version
pip 19.0 from /tmp/tensorflow/pip_19_0/lib/python3.6/site-packages/pip (python 3.6)
$ python --version
Python 3.6.10
$ pip install tensorflow==1.15.2
Collecting tensorflow==1.15.2
  Using cached https://files.pythonhosted.org/packages/9a/d9/fd234c7bf68638423fb8e7f44af7fcfce3bcaf416b51e6d902391e47ec43/tensorflow-1.15.2-cp36-cp36m-manylinux2010_x86_64.whl
Collecting numpy<2.0,>=1.16.0 (from tensorflow==1.15.2)
  Downloading https://files.pythonhosted.org/packages/62/20/4d43e141b5bc426ba38274933ef8e76e85c7adea2c321ecf9ebf7421cedf/numpy-1.18.1-cp36-cp36m-manylinux1_x86_64.whl (20.1MB)
    100% |████████████████████████████████| 20.2MB 3.2MB/s 
Collecting six>=1.10.0 (from tensorflow==1.15.2)
  Using cached https://files.pythonhosted.org/packages/65/eb/1f97cb97bfc2390a276969c6fae16075da282f5058082d4cb10c6c5c1dba/six-1.14.0-py2.py3-none-any.whl
Collecting protobuf>=3.6.1 (from tensorflow==1.15.2)
  Using cached https://files.pythonhosted.org/packages/57/02/5432412c162989260fab61fa65e0a490c1872739eb91a659896e4d554b26/protobuf-3.11.3-cp36-cp36m-manylinux1_x86_64.whl
Collecting gast==0.2.2 (from tensorflow==1.15.2)
Collecting absl-py>=0.7.0 (from tensorflow==1.15.2)
Collecting termcolor>=1.1.0 (from tensorflow==1.15.2)
Requirement already satisfied: wheel>=0.26; python_version >= ""3"" in ./pip_19_0/lib/python3.6/site-packages (from tensorflow==1.15.2) (0.34.2)
Collecting astor>=0.6.0 (from tensorflow==1.15.2)
  Using cached https://files.pythonhosted.org/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl
Collecting tensorboard<1.16.0,>=1.15.0 (from tensorflow==1.15.2)
  Using cached https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl
Collecting opt-einsum>=2.3.2 (from tensorflow==1.15.2)
Collecting keras-preprocessing>=1.0.5 (from tensorflow==1.15.2)
  Using cached https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl
Collecting wrapt>=1.11.1 (from tensorflow==1.15.2)
Collecting grpcio>=1.8.6 (from tensorflow==1.15.2)
  Using cached https://files.pythonhosted.org/packages/28/df/1f8a284a5e5819ae07d50bd76996d6f7208afef7533e4896fa1c6445574f/grpcio-1.27.2-cp36-cp36m-manylinux2010_x86_64.whl
Collecting tensorflow-estimator==1.15.1 (from tensorflow==1.15.2)
  Using cached https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl
Collecting google-pasta>=0.1.6 (from tensorflow==1.15.2)
  Using cached https://files.pythonhosted.org/packages/c3/fd/1e86bc4837cc9a3a5faf3db9b1854aa04ad35b5f381f9648fbe81a6f94e4/google_pasta-0.1.8-py3-none-any.whl
Collecting keras-applications>=1.0.8 (from tensorflow==1.15.2)
  Using cached https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl
Requirement already satisfied: setuptools in ./pip_19_0/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow==1.15.2) (45.2.0)
Collecting werkzeug>=0.11.15 (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2)
  Using cached https://files.pythonhosted.org/packages/ba/a5/d6f8a6e71f15364d35678a4ec8a0186f980b3bd2545f40ad51dd26a87fb1/Werkzeug-1.0.0-py2.py3-none-any.whl
Collecting markdown>=2.6.8 (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2)
  Downloading https://files.pythonhosted.org/packages/ab/c4/ba46d44855e6eb1770a12edace5a165a0c6de13349f592b9036257f3c3d3/Markdown-3.2.1-py2.py3-none-any.whl (88kB)
    100% |████████████████████████████████| 92kB 7.9MB/s 
Collecting h5py (from keras-applications>=1.0.8->tensorflow==1.15.2)
  Using cached https://files.pythonhosted.org/packages/60/06/cafdd44889200e5438b897388f3075b52a8ef01f28a17366d91de0fa2d05/h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl
Installing collected packages: numpy, six, protobuf, gast, absl-py, termcolor, astor, grpcio, werkzeug, markdown, tensorboard, opt-einsum, keras-preprocessing, wrapt, tensorflow-estimator, google-pasta, h5py, keras-applications, tensorflow
Successfully installed absl-py-0.9.0 astor-0.8.1 gast-0.2.2 google-pasta-0.1.8 grpcio-1.27.2 h5py-2.10.0 keras-applications-1.0.8 keras-preprocessing-1.1.0 markdown-3.2.1 numpy-1.18.1 opt-einsum-3.1.0 protobuf-3.11.3 six-1.14.0 tensorboard-1.15.0 tensorflow-1.15.2 tensorflow-estimator-1.15.1 termcolor-1.1.0 werkzeug-1.0.0 wrapt-1.12.0
You are using pip version 19.0, however version 20.0.2 is available.
You should consider upgrading via the 'pip install --upgrade pip' command.
```

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
37234,Cloning models loaded from disk (SavedModel) fails,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d382ca 2.0.0
- Python version: 3.7.6
- Bazel version (if compiling from source): -
- GCC/Compiler version (if compiling from source): -
- CUDA/cuDNN version: -
- GPU model and memory: -

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
When loading a simple Keras Sequential model with two Conv2D layers stored in SavedModel format from disk and applying the `tensorflow.keras.models.clone_model()` function, a `TypeError: ('Keyword argument not understood:', 'filters')` is thrown.

**Describe the expected behavior**
I expect the `tensorflow.keras.models.clone_model()` to return a clone of the provided model and not fail with an exception.

**Standalone code to reproduce the issue** 
https://colab.research.google.com/gist/soyers/23ec2b19cffd1e2170cbbf2db72aad6d/cloning-models-loaded-from-disk.ipynb
"
37233,Blas GEMM launch failed,"- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): source and pip
- TensorFlow version: 2.1.0
- Python version: 3.7.3
- Installed using virtualenv? pip? conda?: conda
- Bazel version (if compiling from source): 0.29.1
- GCC/Compiler version (if compiling from source): 7.4.0
- CUDA/cuDNN version: 10.1 / 7.6.4
- GPU model and memory: GTX 1080

On my setup any installation using CUDA 10.1 results in the given error:

    tensorflow.python.framework.errors_impl.InternalError:  Blas GEMM launch failed

I have the same installation on my own computer with a 2080ti, which runs just fine. Also using tensorflow-gpu==2.0.0 works fine. As some mentioned in stackoverflow  (https://stackoverflow.com/questions/58428466/tensorflow-blas-gemm-launch-failed-a-shape-2-128-b-shape-128-44-m-2-n) I just compiled from source with 10.0 and everything runs fine, too. Any ideas on how to compile with 10.1 and TF2.1?

Might be related to #36781

Reproducible with:

    import tensorflow as tf
    print(tf.matmul([[1., 2.],[3., 4.]], [[1., 2.],[3., 4.]]))

Thanks in advance!

"
37232,What does BuiltinOperator Resolver does ? what is custom ops in resolver.,I was trying to run Inference on Tflite Models. I want to know what BuiltinOperator Resolver does ? what are the custom ops in resolver operator
37231,Build TF 1.8 from source on Windows not working,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 8.1 64
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): 1.8
- TensorFlow version: 1.8
- Python version: 3.6
- Installed using virtualenv? pip? conda?: pip & conda
- Bazel version (if compiling from source): 2.1.0
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 9.0 7.1
- GPU model and memory: NVIDIA GeForce GTX 760 compting capabilities 3.0 that's the reason why...



**Describe the problem** Hello, I've followed the instructions on this page: https://www.tensorflow.org/install/source_windows#gpu
And when I enter bazel build --config=v1 //tensorflow/tools/pip_package:build_pip_package

the result is: 
PS P:\anaconda3\tensorflow>
PS P:\anaconda3\tensorflow> bazel build --config=v1 //tensorflow/tools/pip_package:build_pip_package
WARNING: The following rc files are no longer being read, please transfer their contents or import their path into one o
f the standard rc files:
p:\anaconda3\tensorflow/tools/bazel.rc
WARNING: Ignoring JAVA_HOME, because it must point to a JDK, not a JRE.
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=0 --terminal_columns=120
INFO: Options provided by the client:
  'build' options: --python_path=p:/Anaconda3/python.exe
INFO: Reading rc options for 'build' from p:\anaconda3\tensorflow\bazel.rc:
  'build' options: --define framework_shared_object=true --define=use_fast_cpp_protos=true --define=allow_oversize_proto
s=true --define=grpc_no_ares=true --spawn_strategy=standalone --genrule_strategy=standalone -c opt
INFO: Reading rc options for 'build' from p:\anaconda3\tensorflow\.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=p:/Anaconda3/python.exe --action_env PYTHON_LIB_PATH=p:/Anaconda3/lib/si
te-packages --force_python=py3 --host_force_python=py3 --python_path=p:/Anaconda3/python.exe --define with_xla_support=t
rue --define with_gdr_support=true --define with_verbs_support=true --action_env TF_NEED_OPENCL_SYCL=0 --action_env TF_N
EED_CUDA=1 --action_env CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v9.1 --action_env TF_CUDA_V
ERSION=9.1 --action_env CUDNN_INSTALL_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v9.1 --action_env TF_CUDNN
_VERSION=7 --action_env TF_CUDA_COMPUTE_CAPABILITIES=3.0 --action_env TF_CUDA_CLANG=0 --action_env CUDA_PATH=C:/Program
Files/NVIDIA GPU Computing Toolkit/CUDA/v9.1 --action_env CUDA_COMPUTE_CAPABILITIE=None --action_env NO_WHOLE_ARCHIVE_OP
TION=1 --config=win-cuda --define grpc_no_ares=true --copt=-DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK --host_copt=-DGEMMLOWP_
ALLOW_SLOW_SCALAR_FALLBACK --config monolithic --copt=-w --host_copt=-w --verbose_failures
INFO: Found applicable config definition build:win-cuda in file p:\anaconda3\tensorflow\bazel.rc: --define=using_cuda=tr
ue --define=using_cuda_nvcc=true
INFO: Found applicable config definition build:monolithic in file p:\anaconda3\tensorflow\bazel.rc: --define framework_s
hared_object=false
ERROR: Config value v1 is not defined in any .rc file
PS P:\anaconda3\tensorflow>






**Provide the exact sequence of commands / steps that you executed before running into the problem** bazel build --config=v1 //tensorflow/tools/pip_package:build_pip_package

Thanks for your help!
Best regards,
François


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
37230,tf.function second derivative error,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): macOS Mojave 10.14.6
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: N/A
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below):binary  v2.1.0-rc2-17

- Python version:  - Bazel 
version (if compiling from source): Python 3.7.1
- GCC/Compiler version (if compiling from
source): 
- CUDA/cuDNN version: - GPU model and memory:


**Describe the current behavior**
I have a custom function need to use slicing in a for loop. The first-order derivative is working properly but the second-order derivative gives the error. The error only occurs when the function is decorated with tf.function. Below is a simplified code to reproduce the error.

**Describe the expected behavior**

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```
import tensorflow as tf
x =tf.random.uniform([9],minval = -50,maxval = -30,seed = 1,dtype = tf.float32)

@tf.function
def A(x):
    return x[1]

@tf.function
def g(x):

    Z_sum = tf.constant([0.],dtype = tf.float32)

    for i in tf.range(x.shape[0]):
        Z_sum = tf.add(Z_sum, A(x))

    return Z_sum

with tf.GradientTape() as t:
    t.watch(x)
    with tf.GradientTape() as tt:
        tt.watch(x)
        loss = g(x)
    jac = tt.gradient(loss,x)
hess = t.gradient(jac,x)
```
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
~/anaconda3/envs/bys/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py in get_attr(self, name)
   2325       with c_api_util.tf_buffer() as buf:
-> 2326         c_api.TF_OperationGetAttrValueProto(self._c_op, name, buf)
   2327         data = c_api.TF_GetBuffer(buf)

InvalidArgumentError: Operation 'gradients/while_grad/while_grad' has no attr named '_XlaCompile'.

During handling of the above exception, another exception occurred:

ValueError                                Traceback (most recent call last)
~/anaconda3/envs/bys/lib/python3.7/site-packages/tensorflow_core/python/ops/gradients_util.py in _MaybeCompile(scope, op, func, grad_fn)
    330     try:
--> 331       xla_compile = op.get_attr(""_XlaCompile"")
    332       xla_separate_compiled_gradients = op.get_attr(

~/anaconda3/envs/bys/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py in get_attr(self, name)
   2329       # Convert to ValueError for backwards compatibility.
-> 2330       raise ValueError(str(e))
   2331     x = attr_value_pb2.AttrValue()

ValueError: Operation 'gradients/while_grad/while_grad' has no attr named '_XlaCompile'.

During handling of the above exception, another exception occurred:

InvalidArgumentError                      Traceback (most recent call last)
~/anaconda3/envs/bys/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py in get_attr(self, name)
   2325       with c_api_util.tf_buffer() as buf:
-> 2326         c_api.TF_OperationGetAttrValueProto(self._c_op, name, buf)
   2327         data = c_api.TF_GetBuffer(buf)

InvalidArgumentError: Operation 'gradients/TensorListPushBack_grad/TensorListPopBack' has no attr named '_XlaCompile'.

During handling of the above exception, another exception occurred:

ValueError                                Traceback (most recent call last)
~/anaconda3/envs/bys/lib/python3.7/site-packages/tensorflow_core/python/ops/gradients_util.py in _MaybeCompile(scope, op, func, grad_fn)
    330     try:
--> 331       xla_compile = op.get_attr(""_XlaCompile"")
    332       xla_separate_compiled_gradients = op.get_attr(

~/anaconda3/envs/bys/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py in get_attr(self, name)
   2329       # Convert to ValueError for backwards compatibility.
-> 2330       raise ValueError(str(e))
   2331     x = attr_value_pb2.AttrValue()

ValueError: Operation 'gradients/TensorListPushBack_grad/TensorListPopBack' has no attr named '_XlaCompile'.

During handling of the above exception, another exception occurred:

ValueError                                Traceback (most recent call last)
~/anaconda3/envs/bys/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py in _apply_op_helper(op_type_name, name, **keywords)
    467               as_ref=input_arg.is_ref,
--> 468               preferred_dtype=default_dtype)
    469         except TypeError as err:

~/anaconda3/envs/bys/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py in convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)
   1313     if ret is None:
-> 1314       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
   1315 

~/anaconda3/envs/bys/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py in _constant_tensor_conversion_function(v, dtype, name, as_ref)
    316   _ = as_ref
--> 317   return constant(v, dtype=dtype, name=name)
    318 

~/anaconda3/envs/bys/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py in constant(value, dtype, shape, name)
    257   return _constant_impl(value, dtype, shape, name, verify_shape=False,
--> 258                         allow_broadcast=True)
    259 

~/anaconda3/envs/bys/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast)
    295           value, dtype=dtype, shape=shape, verify_shape=verify_shape,
--> 296           allow_broadcast=allow_broadcast))
    297   dtype_value = attr_value_pb2.AttrValue(type=tensor_value.tensor.dtype)

~/anaconda3/envs/bys/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_util.py in make_tensor_proto(values, dtype, shape, verify_shape, allow_broadcast)
    438     if values is None:
--> 439       raise ValueError(""None values not supported."")
    440     # if dtype is provided, forces numpy array to be the type

ValueError: None values not supported.

During handling of the above exception, another exception occurred:

ValueError                                Traceback (most recent call last)
~/anaconda3/envs/bys/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py in _apply_op_helper(op_type_name, name, **keywords)
    481             observed = ops.convert_to_tensor(
--> 482                 values, as_ref=input_arg.is_ref).dtype.name
    483           except ValueError as err:

~/anaconda3/envs/bys/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py in convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)
   1313     if ret is None:
-> 1314       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
   1315 

~/anaconda3/envs/bys/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py in _constant_tensor_conversion_function(v, dtype, name, as_ref)
    316   _ = as_ref
--> 317   return constant(v, dtype=dtype, name=name)
    318 

~/anaconda3/envs/bys/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py in constant(value, dtype, shape, name)
    257   return _constant_impl(value, dtype, shape, name, verify_shape=False,
--> 258                         allow_broadcast=True)
    259 

~/anaconda3/envs/bys/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast)
    295           value, dtype=dtype, shape=shape, verify_shape=verify_shape,
--> 296           allow_broadcast=allow_broadcast))
    297   dtype_value = attr_value_pb2.AttrValue(type=tensor_value.tensor.dtype)

~/anaconda3/envs/bys/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_util.py in make_tensor_proto(values, dtype, shape, verify_shape, allow_broadcast)
    438     if values is None:
--> 439       raise ValueError(""None values not supported."")
    440     # if dtype is provided, forces numpy array to be the type

ValueError: None values not supported.

During handling of the above exception, another exception occurred:

ValueError                                Traceback (most recent call last)
<ipython-input-31-882dac5b0d47> in <module>
     21         tt.watch(x)
     22         loss = g(x)
---> 23     jac = tt.gradient(loss,x)
     24 hess = t.gradient(jac,x)

~/anaconda3/envs/bys/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py in gradient(self, target, sources, output_gradients, unconnected_gradients)
   1027         output_gradients=output_gradients,
   1028         sources_raw=flat_sources_raw,
-> 1029         unconnected_gradients=unconnected_gradients)
   1030 
   1031     if not self._persistent:

~/anaconda3/envs/bys/lib/python3.7/site-packages/tensorflow_core/python/eager/imperative_grad.py in imperative_grad(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)
     75       output_gradients,
     76       sources_raw,
---> 77       compat.as_str(unconnected_gradients.value))

~/anaconda3/envs/bys/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _backward_function_wrapper(*args)
   1254           break
   1255       return backward._call_flat(  # pylint: disable=protected-access
-> 1256           processed_args, remapped_captures)
   1257 
   1258     return _backward_function_wrapper, recorded_outputs

~/anaconda3/envs/bys/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1695         possible_gradient_type,
   1696         executing_eagerly)
-> 1697     forward_function, args_with_tangents = forward_backward.forward()
   1698     if executing_eagerly:
   1699       flat_outputs = forward_function.call(

~/anaconda3/envs/bys/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in forward(self)
   1421     """"""Builds or retrieves a forward function for this call.""""""
   1422     forward_function = self._functions.forward(
-> 1423         self._inference_args, self._input_tangents)
   1424     return forward_function, self._inference_args + self._input_tangents
   1425 

~/anaconda3/envs/bys/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in forward(self, inference_args, input_tangents)
   1183       (self._forward, self._forward_graph, self._backward,
   1184        self._forwardprop_output_indices, self._num_forwardprop_outputs) = (
-> 1185            self._forward_and_backward_functions(inference_args, input_tangents))
   1186     return self._forward
   1187 

~/anaconda3/envs/bys/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _forward_and_backward_functions(self, inference_args, input_tangents)
   1329     outputs = self._func_graph.outputs[:self._num_inference_outputs]
   1330     return self._build_functions_for_outputs(
-> 1331         outputs, inference_args, input_tangents)
   1332 
   1333 

~/anaconda3/envs/bys/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _build_functions_for_outputs(self, outputs, inference_args, input_tangents)
    888             self._func_graph.inputs,
    889             grad_ys=gradients_wrt_outputs,
--> 890             src_graph=self._func_graph)
    891 
    892       captures_from_forward = [

~/anaconda3/envs/bys/lib/python3.7/site-packages/tensorflow_core/python/ops/gradients_util.py in _GradientsHelper(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)
    667                 # functions.
    668                 in_grads = _MaybeCompile(grad_scope, op, func_call,
--> 669                                          lambda: grad_fn(op, *out_grads))
    670               else:
    671                 # For function call ops, we add a 'SymbolicGradient'

~/anaconda3/envs/bys/lib/python3.7/site-packages/tensorflow_core/python/ops/gradients_util.py in _MaybeCompile(scope, op, func, grad_fn)
    334       xla_scope = op.get_attr(""_XlaScope"").decode()
    335     except ValueError:
--> 336       return grad_fn()  # Exit early
    337 
    338   if not xla_compile:

~/anaconda3/envs/bys/lib/python3.7/site-packages/tensorflow_core/python/ops/gradients_util.py in <lambda>()
    667                 # functions.
    668                 in_grads = _MaybeCompile(grad_scope, op, func_call,
--> 669                                          lambda: grad_fn(op, *out_grads))
    670               else:
    671                 # For function call ops, we add a 'SymbolicGradient'

~/anaconda3/envs/bys/lib/python3.7/site-packages/tensorflow_core/python/ops/while_v2.py in _WhileGrad(op, *grads)
    357   body_grad_graph, args = _create_grad_func(
    358       ys, xs, non_none_grads, cond_graph, body_graph,
--> 359       util.unique_grad_fn_name(body_graph.name), op, maximum_iterations)
    360 
    361   if body_grad_graph.while_op_needs_rewrite:

~/anaconda3/envs/bys/lib/python3.7/site-packages/tensorflow_core/python/ops/while_v2.py in _create_grad_func(ys, xs, grads, cond_graph, body_graph, name, while_op, maximum_iterations)
    599       func_graph=_WhileBodyGradFuncGraph(name, cond_graph, body_graph,
    600                                          maximum_iterations, while_op,
--> 601                                          body_graph_inputs, body_graph_outputs))
    602 
    603   # Update the list of outputs with tensors corresponding to the captured

~/anaconda3/envs/bys/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    976                                           converted_func)
    977 
--> 978       func_outputs = python_func(*func_args, **func_kwargs)
    979 
    980       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

~/anaconda3/envs/bys/lib/python3.7/site-packages/tensorflow_core/python/ops/while_v2.py in <lambda>(*args)
    595   grad_func_graph = func_graph_module.func_graph_from_py_func(
    596       name,
--> 597       lambda *args: _grad_fn(ys, xs, args, body_graph),
    598       args, {},
    599       func_graph=_WhileBodyGradFuncGraph(name, cond_graph, body_graph,

~/anaconda3/envs/bys/lib/python3.7/site-packages/tensorflow_core/python/ops/while_v2.py in _grad_fn(ys, xs, args, func_graph)
    655   grad_outs = gradients_util._GradientsHelper(
    656       ys, xs, grad_ys=grad_ys, src_graph=func_graph,
--> 657       unconnected_gradients=""zero"")
    658 
    659   # TODO(b/118712257): Handle the case when grad_outs has None's e.g. when there

~/anaconda3/envs/bys/lib/python3.7/site-packages/tensorflow_core/python/ops/gradients_util.py in _GradientsHelper(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)
    667                 # functions.
    668                 in_grads = _MaybeCompile(grad_scope, op, func_call,
--> 669                                          lambda: grad_fn(op, *out_grads))
    670               else:
    671                 # For function call ops, we add a 'SymbolicGradient'

~/anaconda3/envs/bys/lib/python3.7/site-packages/tensorflow_core/python/ops/gradients_util.py in _MaybeCompile(scope, op, func, grad_fn)
    334       xla_scope = op.get_attr(""_XlaScope"").decode()
    335     except ValueError:
--> 336       return grad_fn()  # Exit early
    337 
    338   if not xla_compile:

~/anaconda3/envs/bys/lib/python3.7/site-packages/tensorflow_core/python/ops/gradients_util.py in <lambda>()
    667                 # functions.
    668                 in_grads = _MaybeCompile(grad_scope, op, func_call,
--> 669                                          lambda: grad_fn(op, *out_grads))
    670               else:
    671                 # For function call ops, we add a 'SymbolicGradient'

~/anaconda3/envs/bys/lib/python3.7/site-packages/tensorflow_core/python/ops/list_ops.py in _PopBackGrad(op, dlist, delement)
    187         element_shape=gen_list_ops.tensor_list_element_shape(
    188             op.outputs[0], shape_type=dtypes.int32))
--> 189   return gen_list_ops.tensor_list_push_back(dlist, delement), None
    190 
    191 

~/anaconda3/envs/bys/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_list_ops.py in tensor_list_push_back(input_handle, tensor, name)
    761   _, _, _op, _outputs = _op_def_library._apply_op_helper(
    762         ""TensorListPushBack"", input_handle=input_handle, tensor=tensor,
--> 763                               name=name)
    764   _result = _outputs[:]
    765   if _execute.must_record_gradient():

~/anaconda3/envs/bys/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py in _apply_op_helper(op_type_name, name, **keywords)
    484             raise ValueError(
    485                 ""Tried to convert '%s' to a tensor and failed. Error: %s"" %
--> 486                 (input_name, err))
    487           prefix = (""Input '%s' of '%s' Op has type %s that does not match"" %
    488                     (input_name, op_type_name, observed))

ValueError: Tried to convert 'tensor' to a tensor and failed. Error: None values not supported.
"
37229,inconsistent default parameters for adagrad optimizer,"**System information** 
TensorFlow 2.1.0 (tested on anaconda package and docker image)

**Describe the current behavior**

The default value for the `initial_accumulator_value` parameter of the Adagrad optimizer is different depending on whether it is passed as a string or as an instance of the optimizer class. This may lead to drastic differences in learning behavior, which is not apparent from the code.

**Describe the expected behavior**

Both variants should use the same default parameters. 

**Standalone code to reproduce the issue** 

```
import tensorflow as tf

model = tf.keras.models.Model()
model.compile(optimizer='adagrad')
model.optimizer.get_config()
# {'name': 'Adagrad', 'learning_rate': 0.001, 'decay': 0.0, 'initial_accumulator_value': 0.0, 'epsilon': 1e-07}

tf.keras.optimizers.Adagrad().get_config()
# {'name': 'Adagrad', 'learning_rate': 0.001, 'decay': 0.0, 'initial_accumulator_value': 0.1, 'epsilon': 1e-07}

```
"
37228,tf.debugging.assert_shapes,"## URL(s) with the issue:
https://www.tensorflow.org/api_docs/python/tf/debugging/assert_shapes

## Description of issue (what needs changing):
The documentation for the `shapes` argument states that is expects a dict, but in fact in many circumstances it is not possible to assemble such a dict because eager tensors are unhashable.
So while it is possible to submit a dict here in GraphMode, Eager expects a list of (key, value) pairs.

It should also state whether `tf.Variable`s can be used as keys.

### Usage example
The usage example seems to confuse the two concepts, and provides a mixup of both in invalid python syntax:
```
tf.assert_shapes([
  (x: ('N', 'Q')),
  (y: ('N', 'D')),
  (param: ('Q',)),
  (scalar: ()),
])
```
*This seems to be fixed already in master*


Further, `tf.assert_shapes` should probably be changed to `tf.debugging.assert_shapes`

### Submit a pull request?
Yes"
37227,tf.expand_dims unable to read proper rank from input tensors,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow):  yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04):  Linux Ubuntu 18.04.3 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: N/A
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): docker tensorflow/tensorflow:2.1.0-gpu-py3
- Python version: - Bazel
version (if compiling from source): Python 3.6.9
- GCC/Compiler version (if compiling from
source): 
- CUDA/cuDNN version: - GPU model and memory: CUDA V10.1.243 - Nvidia Titan RTX


**Describe the current behavior**
I have a custom loss function that maps `tf.expand_dims` across a set of minibatches. When this loss is calculated as part of the `model.fit` function, the rank of the input tensor is not correctly read in the `tf.expand_dims` function call and I get the following exception:
```ValueError: dim 2 not in the interval [-2, 1]. for 'ExpandDims' (op: 'ExpandDims') with input shapes: [?], [] and with computed input tensors: input[1] = <2>.```
If I do not call `tf.expand_dims` and simply print the shape/rank of the input tensor, everything appears consistent. Furthermore, if the input dataset is simply iterated over and the batches are passed directly into the loss function, the exception is not raised.

**Describe the expected behavior**
An error is not raised

**Standalone code to reproduce the issue** 
```python
import numpy as np
import tensorflow as tf

from tensorflow.keras.losses import Loss

MINI_BATCH = 3
SPLITS = 2
BATCH = SPLITS * MINI_BATCH


class CustomLoss(Loss):
    def call(self, labels, outputs):

        @tf.function
        def fxn(inp):
            return tf.expand_dims(inp, 2)
        mapped = tf.map_fn(fxn, labels, dtype=tf.float32)
        return tf.reduce_sum(mapped)

def gen_batches():
    for _ in range(1000):
        outp = np.random.random((BATCH, 64))
        mask = np.random.random((SPLITS, MINI_BATCH, MINI_BATCH)) > .5
        mask = tf.cast(mask, tf.float32)
        yield outp, mask


if __name__ == ""__main__"":
    # Toggle to run as training (throws exception) vs merely iterating and calculating loss
    AS_MODEL = True

    dataset = tf.data.Dataset.from_generator(gen_batches, (tf.float32, tf.float32), output_shapes=([BATCH, 64], [SPLITS, MINI_BATCH, MINI_BATCH]))
    loss = CustomLoss()

    if AS_MODEL:
        inputs = tf.keras.Input(shape=(64,))
        out = inputs + 1
        model = tf.keras.Model(inputs=inputs, outputs=out)
        opt = tf.keras.optimizers.Nadam(.0005)
        model.compile(optimizer=opt, loss=loss)

        # This throws exception
        model.fit(dataset, epochs=1)

    else:
        # This runs fine
        for data in dataset.__iter__():
            tf.print(loss(data[1], data[0])) 
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
```
Traceback (most recent call last):
  File ""deepsee/networks/av/attention/test.py"", line 40, in <module>
    model.compile(optimizer=opt, loss=loss)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py"", line 446, in compile
    self._compile_weights_loss_and_weighted_metrics()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py"", line 1592, in _compile_weights_loss_and_weighted_metrics
    self.total_loss = self._prepare_total_loss(masks)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py"", line 1652, in _prepare_total_loss
    per_sample_losses = loss_fn.call(y_true, y_pred)
  File ""deepsee/networks/av/attention/test.py"", line 17, in call
    mapped = tf.map_fn(fxn, labels, dtype=tf.float32)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/map_fn.py"", line 268, in map_fn
    maximum_iterations=n)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/control_flow_ops.py"", line 2675, in while_loop
    back_prop=back_prop)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/while_v2.py"", line 194, in while_loop
    add_control_dependencies=add_control_dependencies)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py"", line 978, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/while_v2.py"", line 172, in wrapped_body
    outputs = body(*_pack_sequence_as(orig_loop_vars, args))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/map_fn.py"", line 257, in compute
    packed_fn_values = fn(packed_values)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py"", line 568, in __call__
    result = self._call(*args, **kwds)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py"", line 615, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py"", line 497, in _initialize
    *args, **kwds))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py"", line 2389, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py"", line 2703, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py"", line 2593, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py"", line 978, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py"", line 439, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py"", line 968, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: in converted code:

    deepsee/networks/av/attention/test.py:16 fxn  *
        return tf.expand_dims(inp, 2)
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/dispatch.py:180 wrapper
        return target(*args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/array_ops.py:399 expand_dims_v2
        return gen_array_ops.expand_dims(input, axis, name)
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_array_ops.py:2202 expand_dims
        ""ExpandDims"", input=input, dim=axis, name=name)
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py:742 _apply_op_helper
        attrs=attr_protos, op_def=op_def)
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py:595 _create_op_internal
        compute_device)
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:3322 _create_op_internal
        op_def=op_def)
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1786 __init__
        control_input_ops)
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1622 _create_c_op
        raise ValueError(str(e))

    ValueError: dim 2 not in the interval [-2, 1]. for 'ExpandDims' (op: 'ExpandDims') with input shapes: [?], [] and with computed input tensors: input[1] = <2>.
```"
37226,RaggedTensor are converted to Tensors inside exported signature. ,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): `no`
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `Ubuntu 18.04`
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: `no`
- TensorFlow installed from (source or binary): `no`
- TensorFlow version (use command below): `2.0.1`
- Python version: `3.7.3`
- Bazel version (if compiling from source): `-`
- GCC/Compiler version (if compiling from source): `-`
- CUDA/cuDNN version: `-`
- GPU model and memory: `-`

**Describe the current behavior**
As [properly documented](https://www.tensorflow.org/api_docs/python/tf/function#args_2), it is currently possible to pass a possibly nested sequence of [`tf.TensorSpec`](https://www.tensorflow.org/api_docs/python/tf/TensorSpec) objects as a `tf.function` `input_signature` argument.

However, if one attempts to pass a `tf.RaggedTensorSpec` inside an `input_signature` sequence, everything still works, but the `RaggedTensorSpec` gets converted in its ""dense"" `values` + `row_splits` form.
 
**Describe the expected behavior**
I would expect that if one specifies a `tf.RaggedTensorSpec` element inside the `input_signature` sequence it should either be exported as a `tf.RaggedTensorSpec`, or raise an error.

Of course the firs option sounds more desiderable, since it's pretty common to have ragged input sequences. In this case `tf.RaggedTensorSpec` would be also lacking of a `name` argument, but this is easier to solve.

**Standalone code to reproduce the issue** 
[Colab Notebook](https://colab.research.google.com/drive/1mEXNfmIiEU9XNL7niKCC_LRccfW5ZDob)

```python
import tensorflow as tf

class SomeModule(tf.Module):

  @tf.function(input_signature=[
    tf.RaggedTensorSpec(shape=[None, None], dtype=tf.string)
  ])
  def return_ragged_inputs(self, inputs: tf.RaggedTensor):
    return inputs

ragged_inputs = tf.ragged.constant([[""foo""], [""bar""], [""foo"", ""bar""]], dtype=tf.string)

some_module = SomeModule()
return_ragged_inputs_result = some_module.return_ragged_inputs(ragged_inputs)
print(f""ragged_inputs => {ragged_inputs}\n"")
print(""We can use the method with ragged inputs:"")
print(f""return_ragged_inputs => {return_ragged_inputs_result}\n"")
print(""Saving some_module..."")
tf.saved_model.save(some_module, export_dir=""foobar"")
some_module = tf.saved_model.load(""foobar"")
print(f""\nWe can pass and return ragged inputs even by saving and reloading the module, if we use it 'eagerly':"")
print(some_module.return_ragged_inputs(ragged_inputs))
print(""\nBut the graph signature tell us that our exported signature expects tf.Tensor values instead:"")
exported_model_graph_inputs = some_module.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY].inputs
exported_model_graph_outputs = some_module.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY].outputs
print(f""Expected inputs  : {exported_model_graph_inputs}"")
print(f""Expected outputs : {exported_model_graph_outputs}"")
print(""\nThis means we couldn't use the method as we would expect in (e.g.) TensorFlow Serving."")
```

**Other info / logs**
This issue follows up #37049 , as suggested by @gowthamkpr .
"
37222,ModuleNotFoundError: No module named 'utility',"![0](https://user-images.githubusercontent.com/61679488/75651231-4d9c5a00-5c9b-11ea-8054-bc2c8a22a1d1.PNG)

hi
i wanna use '**from utility import lazy_property**' code but i can't
 i think that code for TF1. can you let me know what is the Code that serves the same role in tf2?

If not, please let me know the appropriate code thanks"
37221,The DLL error in importing tensorflow.,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): tensorflow pypi
- TensorFlow version: 2.0.0
- Python version: 3.6.8 with updated pip==20.0.2
- Installed using: pip in virtualenv
- CUDA/cuDNN version: CUDA V10.0.130, cuDNN 7.4.1
- GPU model and memory: GeForce GTX 1660

**Describe the problem**
I got this error when importing TensorFlow.
ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.

NVIDIA driver version is 432.00. I install CUDA 10 and configured cudnn 7.4.1. Also, installed Visual Studio 2017 buildtools. I tried to install from tf-1.12 to tf-2.0, all versions were failed. I checked previous issues about this error, but some guys resolved using conda. If so, couldn't I use pip installer with tensorflow?
"
37220,Cannot get model to work,"It currently fails when trying to fit the model. The 'train_ds' seems to cause it to fail because it is a Batchdataset and not a numpty array. When I convert this to an np.array it fails because it is expecting a ""dense_1_input to have 2 dimensions, but got array with shape ()"". but I have no idea what this means.


`from __future__ import absolute_import, division, print_function, unicode_literals

import tensorflow as tf

from tensorflow import keras

from keras import layers
from keras import regularizers

#maybe not needed
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.layers import LSTM

import tensorflow_docs as tfdocs
import tensorflow_docs.modeling
import tensorflow_docs.plots

from  IPython import display
from matplotlib import pyplot as plt

import numpy as np

import pathlib
import shutil
import tempfile

logdir = pathlib.Path(tempfile.mkdtemp())/""tensorboard_logs""
shutil.rmtree(logdir, ignore_errors=True)

gz = tf.keras.utils.get_file('HIGGS2.csv.gz', 'https://archive.ics.uci.edu/ml/machine-learning-databases/00280/HIGGS.csv.gz')

FEATURES = 28

ds = tf.data.experimental.CsvDataset(gz,[float(),]*(FEATURES+1), compression_type=""GZIP"")


def pack_row(*row):
  label = row[0]
  features = tf.stack(row[1:],1)
  return features, label

packed_ds = ds.batch(10000).map(pack_row).unbatch() #think this does (none, none) but not sure what this means

for features,label in packed_ds.batch(1000).take(1):
  print(features[0])
  plt.hist(features.numpy().flatten(), bins = 101)
print(features[0].shape)

N_VALIDATION = int(1e3)
N_TRAIN = int(1e4)
BUFFER_SIZE = int(1e4)
BATCH_SIZE = 500
STEPS_PER_EPOCH = N_TRAIN//BATCH_SIZE

validate_ds = packed_ds.take(N_VALIDATION).cache()
train_ds = packed_ds.skip(N_VALIDATION).take(N_TRAIN).cache()

print(train_ds)

validate_ds = validate_ds.batch(BATCH_SIZE)
#validate_ds = np.array(validate_ds) #model.fit expects x and y to be numpy array. Seems like you pass a list, it tried to get shape of input by reading ndim attribute of numpy array and failed
train_ds = train_ds.shuffle(BUFFER_SIZE).repeat().batch(BATCH_SIZE)
#train_ds = np.array(train_ds) #model.fit expects x and y to be numpy array. Seems like you pass a list, it tried to get shape of input by reading ndim attribute of numpy array and failed

print(train_ds)



lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(
  0.001,
  decay_steps=STEPS_PER_EPOCH*1000,
  decay_rate=1,
  staircase=False)

def get_optimizer():
  return tf.keras.optimizers.Adam(lr_schedule)

step = np.linspace(0,100000)
lr = lr_schedule(step)
plt.figure(figsize = (8,6))
plt.plot(step/STEPS_PER_EPOCH, lr)
plt.ylim([0,max(plt.ylim())])
plt.xlabel('Epoch')
_ = plt.ylabel('Learning Rate')
#plt.show(block=True)

def get_callbacks(name):
  return [
    tfdocs.modeling.EpochDots(),
    keras.callbacks.EarlyStopping(monitor='val_binary_crossentropy', patience=200),
    keras.callbacks.TensorBoard(logdir/name),
  ]
def compile_and_fit(model, name, optimizer=None, max_epochs=10000):
  if optimizer is None:
    optimizer = get_optimizer()
  model.compile(optimizer=optimizer,
                loss=keras.losses.BinaryCrossentropy(from_logits=True),
                metrics=[
                  keras.losses.BinaryCrossentropy(
                      from_logits=True, name='binary_crossentropy'),
                  'accuracy'])

  model.summary()
  
  history = model.fit(
    np.array(train_ds), #model.fit expects x and y to be numpy array. Seems like you pass a list, it tried to get shape of input by reading ndim attribute of numpy array and failed
    steps_per_epoch = STEPS_PER_EPOCH,
    epochs=max_epochs,
    validation_data=validate_ds,
    callbacks=get_callbacks(name),
    verbose=0)
  return history

size_histories = {}


plotter = tfdocs.plots.HistoryPlotter(metric = 'binary_crossentropy', smoothing_std=10)
#plotter.plot(size_histories)
#plt.ylim([0.5, 0.7])

small_model = Sequential([
    # `input_shape` is only required here so that `.summary` works.
    layers.Dense(16, activation='elu', input_shape=(28,)),
    layers.Dense(16, activation='elu'),
    layers.Dense(1)
])

size_histories['Small'] = compile_and_fit(small_model, 'sizes/Small')`


raceback (most recent call last):
  File ""/Users/jasonrae/.vscode/extensions/ms-python.python-2020.3.64983-dev/pythonFiles/ptvsd_launcher.py"", line 48, in <module>
    main(ptvsdArgs)
  File ""/Users/jasonrae/.vscode/extensions/ms-python.python-2020.3.64983-dev/pythonFiles/lib/python/old_ptvsd/ptvsd/__main__.py"", line 432, in main
    run()
  File ""/Users/jasonrae/.vscode/extensions/ms-python.python-2020.3.64983-dev/pythonFiles/lib/python/old_ptvsd/ptvsd/__main__.py"", line 316, in run_file
    runpy.run_path(target, run_name='__main__')
  File ""/Users/jasonrae/opt/miniconda3/envs/tensorflow/lib/python3.7/runpy.py"", line 263, in run_path
    pkg_name=pkg_name, script_name=fname)
  File ""/Users/jasonrae/opt/miniconda3/envs/tensorflow/lib/python3.7/runpy.py"", line 96, in _run_module_code
    mod_name, mod_spec, pkg_name, script_name)
  File ""/Users/jasonrae/opt/miniconda3/envs/tensorflow/lib/python3.7/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/Users/jasonrae/Documents/Python Files/Higgs1.py"", line 145, in <module>
    size_histories['Small'] = compile_and_fit(small_model, 'sizes/Small')
  File ""/Users/jasonrae/Documents/Python Files/Higgs1.py"", line 120, in compile_and_fit
    verbose=0)
  File ""/Users/jasonrae/opt/miniconda3/envs/tensorflow/lib/python3.7/site-packages/keras/engine/training.py"", line 1154, in fit
    batch_size=batch_size)
  File ""/Users/jasonrae/opt/miniconda3/envs/tensorflow/lib/python3.7/site-packages/keras/engine/training.py"", line 579, in _standardize_user_data
    exception_prefix='input')
  File ""/Users/jasonrae/opt/miniconda3/envs/tensorflow/lib/python3.7/site-packages/keras/engine/training_utils.py"", line 135, in standardize_input_data
    'with shape ' + str(data_shape))
ValueError: Error when checking input: expected dense_1_input to have 2 dimensions, but got array with shape ()
Exception ignored in: <function _MemoryCacheDeleter.__del__ at 0x13e9554d0>
Traceback (most recent call last):
  File ""/Users/jasonrae/opt/miniconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 2944, in __del__
AttributeError: 'NoneType' object has no attribute 'device'
Exception ignored in: <function _MemoryCacheDeleter.__del__ at 0x13e9554d0>
Traceback (most recent call last):
  File ""/Users/jasonrae/opt/miniconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 2944, in __del__
AttributeError: 'NoneType' object has no attribute 'device'
Exception ignored in: <function _RandomSeedGeneratorDeleter.__del__ at 0x13e9557a0>
Traceback (most recent call last):
  File ""/Users/jasonrae/opt/miniconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 3009, in __del__
AttributeError: 'NoneType' object has no attribute 'device'"
37219,Official tutorial (Text classification with an RNN )code running error !!!,"In the official text tutorial of tensorflow: Text classification with an RNN (https://tensorflow.google.cn/tutorials/text/text_classification_rnn),
```
train_dataset = train_dataset.padded_batch(BATCH_SIZE)
test_dataset = test_dataset.padded_batch(BATCH_SIZE)
```
When I run the code there is an error:
```
    train_dataset = train_dataset.padded_batch(BATCH_SIZE)
TypeError: padded_batch() missing 1 required positional argument: 'padded_shapes'
```

My tensorflow version: 2.1.0rc2
My python version: 3.7

What should be the correct answer？


"
37217,Implement support for AV1 / AVIF for image files,"**System information**
- TensorFlow version (you are using): 2.1
- Are you willing to contribute it (Yes/No): Yes; but I have very limited time & have little experience with implementing codecs, thus I could only assist in testing.


**Describe the feature and the current behavior/state.**
In image processing there are scenarios, especially when you deal with higher resolution images, where compression artifacts actually deteriorates your model training sessions. This specifically applies to old image formats like GIF or JPEG. Storing data in, for example, BMP format however drastically increases disk space usage.

I propose the implementation of **AV1 / AVIF for image files**, i.e. adding AVIF format to `tf.io.decode_image`. **AVIF** is a **free, open source format**.

AV1 (see [AV1 wikipedia page](https://en.wikipedia.org/wiki/AV1)) is a next generation video (and image) codec. It is broadly supported by Google, Amazon, Apple, ARM, Cisco, Facebook, IBM, Intel Corporation, Microsoft, Mozilla, Netflix, Nvidia, Samsung Electronics, and others since AV1 is developed and supported by [AOMedia](https://en.wikipedia.org/wiki/Alliance_for_Open_Media), where these and other corporations are contributing to.

AOMedia's main goal is developing royalty-free video and image formats. Hence, long-term support can be expected. 

AVIF (see [AVIF wikipedia entry](https://en.wikipedia.org/wiki/AV1#AV1_Image_File_Format_(AVIF))) is the image file format of the AV1 codec. It has major benefits compared to older formats like JPEG or PNG -> lower file size while still maintaining a significantly better quality.

This [blog post by netflix](https://netflixtechblog.com/avif-for-next-generation-image-coding-b1d75675fe4) demonstrates that AVIF covers little to zero compression artifacts **and** having a lower file size compared to JPEG.

See AVIF defintion: https://aomediacodec.github.io/av1-avif/


**Will this change the current api? How?**
No, just an addition.

**Who will benefit with this feature?**
Everyone interested in image processing. Lower disk usage **and** little to zero compression artifacts benefit everyone in image processing, especially users with an interest for higher resolutions.
"
37216,"Tf 2.1, cause system crash and reboot","**System information** 
* POP_OS 19.10, Kernel: 5.3.0-7629-generic
* Tensorflow: installed using `pip`, `__version__` 2.1.0
* Nvidia_driver: 440.44, Cuda : 10.2 
* GPU: Nvidia GTX 1080Ti , Memory : 11GB

**Describe the current behavior**

Hi 
Just tried to run an example on `TF2.1`, every time right after starting training the system will crash immediately and will reboot (because of crash reboot there is no useful log available on `/var/log/`)

So decide to change my code to a simpler version and using the cifar10 dataset to check that, again system crash happend. this time I switched to `TF1.13.1` and run the same code and no problem, system work properly and at last, print the result.

even tried on other versions `TF1.14`, `1.15` there is no problem (all versions are GPU support)


**Standalone code to reproduce the issue** 
[sample code](https://github.com/pykeras/bugReport/blob/master/sample.py)
"
37215,TFLite Micro: SUB Op Support,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution: Linux 5.5.5 Arch
- TensorFlow installed from: source
- Tensorflow version: 41c6bf7c6215bea9bfb9bf0a9b63f2084e6f3058
- Target platform: OpenMV CAM (STM32H7)

**Describe the problem**

Hello, I trained a simple dogs/cats classification model through transfer learning and then converted it to be run on the [OpenMV CAM](https://openmv.io/): [converted_model.mv1025128.tflite.zip](https://github.com/tensorflow/tensorflow/files/4272695/converted_model.mv1025128.tflite.zip).

It fails to load on the MCU inside the `InitializeRuntimeTensor` function when the SUB tensor is processed (you can see on [netron](https://lutzroeder.github.io/netron/) where SUB is needed).

I found out the SUB op is not supported on tf lite micro, but, since I am quite new to ML, I would like to know if there is a specific reason to this missing support, if it can be *easily* added or if you can suggest a workaround.

Thank you
"
37211, error: the value of ‘j’ is not usable in a constant expression,"
**System information**
- OS Platform and Distribution:  
    16.04.6 LTS (GNU/Linux 4.15.0-60-generic x86_64)

- Mobile device
    not a mobile device
- TensorFlow installed from (source or binary):
    using pip command
- TensorFlow version:
    2.1.0
- Python version:
    3.5.2.
- Installed using virtualenv? pip? conda?:
  using viertualenv
- Bazel version (if compiling from source):
  no
- GCC/Compiler version (if compiling from source):
   5.4.0
- CUDA/cuDNN version:
   no cuda
- GPU model and memory:
    GeForce GT 750M


**Describe the problem**

Tensorflow doesn't compile:

```
g++ -std=c++11 -shared -fPIC -I/home/nickai/evolution/deep-neuroevolution/env/lib/python3.5/site-packages/tensorflow_core/include -I/home/nickai/evolution/deep-neuroevolution/env/lib/python3.5/site-packages/tensorflow_core/include/external/nsync/public -L/home/nickai/evolution/deep-neuroevolution/env/lib/python3.5/site-packages/tensorflow_core -D_GLIBCXX_USE_CXX11_ABI=0 -O2 -DGOOGLE_CUDA=1 .//*.cpp .//ops/*.cpp -ltensorflow_framework -o gym_tensorflow.so
In file included from /home/nickai/evolution/deep-neuroevolution/env/lib/python3.5/site-packages/tensorflow_core/include/unsupported/Eigen/CXX11/Tensor:101:0,
                 from /home/nickai/evolution/deep-neuroevolution/env/lib/python3.5/site-packages/tensorflow_core/include/third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,
                 from /home/nickai/evolution/deep-neuroevolution/env/lib/python3.5/site-packages/tensorflow_core/include/tensorflow/core/framework/numeric_types.h:20,
                 from /home/nickai/evolution/deep-neuroevolution/env/lib/python3.5/site-packages/tensorflow_core/include/tensorflow/core/framework/allocator.h:26,
                 from /home/nickai/evolution/deep-neuroevolution/env/lib/python3.5/site-packages/tensorflow_core/include/tensorflow/core/framework/op_kernel.h:25,
                 from .//ops/indexedmatmul.cpp:8:
/home/nickai/evolution/deep-neuroevolution/env/lib/python3.5/site-packages/tensorflow_core/include/unsupported/Eigen/CXX11/src/Tensor/TensorBlockV2.h: In static member function ‘static IndexType Eigen::internal::TensorBlockIOV2<Scalar, IndexType, NumDims, Layout>::Copy(const Eigen::internal::TensorBlockIOV2<Scalar, IndexType, NumDims, Layout>::Dst&, const Eigen::internal::TensorBlockIOV2<Scalar, IndexType, NumDims, Layout>::Src&, const DimensionsMap&)’:
/home/nickai/evolution/deep-neuroevolution/env/lib/python3.5/site-packages/tensorflow_core/include/unsupported/Eigen/CXX11/src/Tensor/TensorBlockV2.h:998:33: error: the value of ‘j’ is not usable in a constant expression
       if (++it[j].count < it[j].size) {                                \
                                 ^
/home/nickai/evolution/deep-neuroevolution/env/lib/python3.5/site-packages/tensorflow_core/include/unsupported/Eigen/CXX11/src/Tensor/TensorBlockV2.h:1011:7: note: in expansion of macro ‘COPY_INNER_DIM’
       COPY_INNER_DIM(LinCopy::Linear);
       ^

```
This is because you are using some old version of Eigen:
```
(env) nickai@lap:~/evolution/deep-neuroevolution/gpu_implementation/gym_tensorflow$ ls -l /home/nickai/evolution/deep-neuroevolution/env/lib/python3.5/site-packages/tensorflow_core/include/unsupported/Eigen/CXX11/src/Tensor/TensorBlockV2.h
-rw-rw-r-- 1 nickai nickai 48966 mar  1 15:10 /home/nickai/evolution/deep-neuroevolution/env/lib/python3.5/site-packages/tensorflow_core/include/unsupported/Eigen/CXX11/src/Tensor/TensorBlockV2.h
(env) nickai@lap:~/evolution/deep-neuroevolution/gpu_implementation/gym_tensorflow$ 
```
I wonder, why is an ""unsupported"" tree of the Eigen source code appearing inside tensorflow build directory at all?


**Provide the exact sequence of commands / steps that you executed before running into the problem**

I installed tensorflow using this command:

    pip install --upgrade tensorflow

Then I tried to build an app that depends on Tensorflow 
https://github.com/uber-research/deep-neuroevolution/tree/master/gpu_implementation/gym_tensorflow
by exeucting 

    make

But since Tensorflow has some bad code inside its headers (i.e. using old and unsupported Eigen library) my the app I am trying to builid doesn't build.

This is possibly the same issue as reported here: https://github.com/tensorflow/tensorflow/issues/29927

I suspect that to fix this, you have to update Eigen library."
37210,tf.split T value inconsistency,"tf.split raise ValueError when it is used before tf.identity to copy splitted tensors. Error seems related to split num parameter when it is set to None and occurs when split operation outputs more then 2 tensors. 

Code for the model:
        inp = tf.keras.layers.Input(shape=(102,df.shape[1]),dtype = 'float32')
        x0, x1, x2 = tf.split(inp,[66,22,14],axis=1,num=3)
        x00 = tf.identity(x0)
        x11 = tf.identity(x1)
        x22 = tf.identity(x2)

handled by the code:

        inp = tf.keras.layers.Input(shape=(102,df.shape[1]),dtype = 'float64')
        inp_ = tf.identity(inp)
        x0, x1, x2 = tf.split(inp,[66,22,14],axis=1,num=3) 
        x00, x11, x22 = tf.split(inp_,[66,22,14],axis=1,num=3)

Error raised:

ValueError: Inconsistent values for attr 'T' DT_DOUBLE vs. DT_FLOAT while building NodeDef 'split' using Op<name=SplitV; signature=value:T, size_splits:Tlen, split_dim:int32 -> output:num_split*T; attr=num_split:int,min=1; attr=T:type; attr=Tlen:type,default=DT_INT64,allowed=[DT_INT32, DT_INT64]>
"
37209,tensorflow.keras saving weights?,"I have a model that is run on a time series train set trying to predict stock prices. I never save or load the model or the weights but every time i run it with the save hyperparameters it keeps decreasing in accuracy. I don't understand why, is tensorflow.keras saving the weights or something?
"
37207,No module named 'tensorflow.python.tools' in Visual Studio 2017 v15.9.20,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow):  No.
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Windows 10 Pro
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
- TensorFlow installed from (source or
binary): Installed from pip
- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de410 2.1.0
- Python version: 3.7.4
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Within Visual Studio 2017 I am unable to run a python file if I have 'import tensorflow as tf' in the code. If I run [python -c ""import tensorflow as tf; print(tf.__version__);"" it works
**Describe the expected behavior**
I should be able to run the file
**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
Just have a .py file with ""import tensorflow as tf"" and run from within Visual Studio with the python package installed

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

I have python Visual Studio extension version 15.9.18254.1 installed

#34722 is very close to this issue. In that ticket they had a poorly named file. Not sure what VS is doing. This is most likely something within VS but not sure. Maybe an import?

#9778 mentions a Windows error but it is quite a few years old"
37206,"iOS Object Detection with Custom .tflite file: ""Failed to allocate memory for input tensors.""","I am trying to run the sample iOS with a custom .tflite file ([download](https://github.com/tensorflow/tensorflow/files/4271813/custom_tflite_file.zip)) where only one object exists.

When the app loads, it crashes with the error `Failed to create the interpreter with error: Failed to allocate memory for input tensors.`.

Here is a comparison of both .tflite files (left: original, right: custom): 
<img width=""982"" alt=""attributes"" src=""https://user-images.githubusercontent.com/12123471/75626712-3477a880-5bca-11ea-9d23-a2d3c34029dd.png"">

As shown in the image, input tensors exist. What is the reason for this error?


"
37205,Unable to download the TensorFlow using pip in Windows 10,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):   Microsoft Windows 10 Home Single Language |  10.0.18363 N/A Build 18363 |  x64-based PC | 16GB | 4GB 1050Ti Nvidia GC
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on a mobile device: NA
- TensorFlow installed from (source or binary): https://www.tensorflow.org/install/pip?lang=python3
- TensorFlow version:  2.1
- Python version:  3.8.2
- Installed using virtualenv? pip? conda?: virtualenv and pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory: 1050Ti Nvidia 



**Describe the problem**
I have tried to both Virtualenv and pip but won't able to install. What should I do?

"" ERROR: Could not find a version that satisfies the requirement TensorFlow (from versions: none)
ERROR: No matching distribution found for TensorFlow""

**Provide the exact sequence of commands/steps that you executed before running into the problem**

python3 --version   # 3.8.2
pip3 --version           # 20.0.2
virtualenv --version  #  20.0.7

pip3 install -U pip virtualenv

virtualenv --system-site-packages -p python3 ./venv
.\venv\Scripts\activate
pip install --upgrade pip

pip list  # show packages installed within the virtual environment

pip install --upgrade tensorflow

then the error is coming 

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
37204,android mask rcnn,Please provide the code get output mask r-cnn on android. Thanks
37203,Cannot import tensorflow 1.15,"
**System information**
- OS Platform and Distribution (Windows 10 pro):
-Lenovo ideapad 520-15iKB
- TensorFlow installed from (""pip install tensorflow==1.15""):
- TensorFlow version: 1.15 (cpu-only)
- Python version: 3.6.0
- Installed using pip
- GPU model and memory: GeForce 940MX 4GB



**Describe the problem**

i installed tensoflow == 1.15 and i can't import

`Python 3.6.0 (v3.6.0:41df79263a11, Dec 23 2016, 08:06:12) [MSC v.1900 64 bit (AMD64)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow
2020-03-01 03:36:32.916332: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_100.dll'; dlerror: cudart64_100.dll not found
2020-03-01 03:36:32.921892: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Users\Jose\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\__init__.py"", line 99, in <module>
    from tensorflow_core import *
  File ""C:\Users\Jose\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow_core\__init__.py"", line 28, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""C:\Users\Jose\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\Jose\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\Jose\AppData\Local\Programs\Python\Python36\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\Jose\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow_core\python\__init__.py"", line 52, in <module>
    from tensorflow.core.framework.graph_pb2 import *
  File ""C:\Users\Jose\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow_core\core\framework\graph_pb2.py"", line 7, in <module>
    from google.protobuf import descriptor as _descriptor
  File ""C:\Users\Jose\AppData\Local\Programs\Python\Python36\lib\site-packages\google\protobuf\descriptor.py"", line 47, in <module>
    from google.protobuf.pyext import _message
ImportError: DLL load failed: No se encontró el proceso especificado.`

i don't know what is going on, please help me.
"
37202,Print out the user number in Tensorflow,"Dear everyone; 

when users increase. I want to print out that user number and how to value the performance of Tensorflow?

Please give me some of your idea!
Many thank!"
37200,NotImplementedError: Cannot convert a symbolic Tensor (up_sampling2d_5_target:0) to a numpy array,"> import numpy as np
> import tensorflow as tf
> print(np.__version__)
> print(keras.__version__)
> print(tf.__version__)
> 
> 1.17.3
> 2.3.1
> 2.1.0

```

import keras.backend as K
from keras.optimizers import Adam
from keras.losses import binary_crossentropy

## intersection over union
def IoU(y_true, y_pred, eps=1e-6):
    #print(y_true)
    if np.max(y_true) == 0.0:
        return IoU(1-y_true, 1-y_pred) ## empty image; calc IoU of zeros

    intersection = K.sum(y_true * y_pred, axis=[1,2,3])
    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3]) - intersection
    return -K.mean( (intersection + eps) / (union + eps), axis=0)
```

Here the np.max(y_true) bring the problem. 

> NotImplementedError: Cannot convert a symbolic Tensor (up_sampling2d_5_target:0) to a numpy array"
37199,Default type for complex sparse tensor is complex128,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Linux Ubuntu 16.04
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): pip

**Describe the current behavior**
When I instantiate a complex sparse tensor, the default type is complex128, whereas with a float sparse tensor it is float32.

**Describe the expected behavior**
The default type for complex sparse tensor should probably be complex64, since we can't set the type in the tensor creation.

**Standalone code to reproduce the issue** 
```
a = tf.sparse.SparseTensor(indices=[[0, 0],], values=[1.+ 0j], dense_shape=[2, 2])
print(a.dtype)
```
This gives `tf.complex128`.

**Other info / logs** 
This can be circumvented using `numpy` to fix the type of the values but it isn't ideal imho.
"
37198,Docker Tensorflow GPU 5x times slower than TF CPU,"I installed ""tensorflow/tensorflow:nightly-gpu-py3"" (at this moment 9 days old) docker image on my Ubuntu 18.04 with nvidia-driver-435, 8gb RAM, i5-8265U and mx110 video card. 

I executed the following code https://github.com/vadimen/algorithms/blob/master/code2.py . It's running mobileNet SSD from tensorflow examples. It's processing a video.

The code is writing in console the time(FPS) it need for inference. Executed on CPU on local machine it's 5x times faster than on GPU. 

Output is as follows:

2020-02-29 20:09:18.544335: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-02-29 20:09:18.552675: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-29 20:09:18.553295: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1558] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce MX110 computeCapability: 5.0
coreClock: 1.006GHz coreCount: 2 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 37.33GiB/s
2020-02-29 20:09:18.554196: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-02-29 20:09:18.576049: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-02-29 20:09:18.587918: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-02-29 20:09:18.590462: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-02-29 20:09:18.613041: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-02-29 20:09:18.616945: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-02-29 20:09:18.661350: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-02-29 20:09:18.661573: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-29 20:09:18.662435: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-29 20:09:18.663145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Adding visible gpu devices: 0
2020-02-29 20:09:20.104462: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-29 20:09:20.130370: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 1800000000 Hz
2020-02-29 20:09:20.130765: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4bf61c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-29 20:09:20.130803: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-02-29 20:09:20.168110: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-29 20:09:20.168450: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4b85270 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-02-29 20:09:20.168467: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce MX110, Compute Capability 5.0
2020-02-29 20:09:20.169053: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-29 20:09:20.169287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1558] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce MX110 computeCapability: 5.0
coreClock: 1.006GHz coreCount: 2 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 37.33GiB/s
2020-02-29 20:09:20.169336: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-02-29 20:09:20.169350: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-02-29 20:09:20.169364: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-02-29 20:09:20.169379: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-02-29 20:09:20.169394: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-02-29 20:09:20.169414: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-02-29 20:09:20.169432: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-02-29 20:09:20.169502: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-29 20:09:20.169752: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-29 20:09:20.170089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Adding visible gpu devices: 0
2020-02-29 20:09:20.170405: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-02-29 20:09:20.171326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1099] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-02-29 20:09:20.171339: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105]      0 
2020-02-29 20:09:20.171345: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1118] 0:   N 
2020-02-29 20:09:20.171411: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-29 20:09:20.171657: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-29 20:09:20.171889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1244] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1024 MB memory) -> physical GPU (device: 0, name: GeForce MX110, pci bus id: 0000:01:00.0, compute capability: 5.0)
{'detection_classes': TensorShape([None, 100]), 'num_detections': TensorShape([None]), 'detection_boxes': TensorShape([None, 100, 4]), 'detection_scores': TensorShape([None, 100])}
2020-02-29 20:10:47.947871: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-02-29 20:10:49.042241: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-02-29 20:10:49.351873: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.04GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-02-29 20:10:49.389878: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.04GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-02-29 20:10:49.427350: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-02-29 20:10:49.463571: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.05GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-02-29 20:10:49.502225: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.09GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-02-29 20:10:49.539195: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.08GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-02-29 20:10:49.577960: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.15GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-02-29 20:10:49.627041: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.15GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-02-29 20:10:49.706667: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-02-29 20:10:49.761623: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.

I think it's because of not enough memory, my mx110 card has 2GB of memory but output says it's all used.

I tried to limit memory with this but it's still using everything.

`gpus = tf.config.experimental.list_physical_devices('GPU')

tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])`"
37196,Keras saves invalid JSON files containing NaN,"**Describe the current behavior**

JSON saved by Keras contains `NaN` which is invalid according to [RFC 7159](https://tools.ietf.org/html/rfc7159):

> ""Numeric values that cannot be represented in the grammar below (such as Infinity and NaN) are not permitted.""

**Describe the expected behavior**

Keras saves correct JSON format.

**Standalone code to reproduce the issue** 

```
import tensorflow as tf
i = tf.keras.layers.Input((600,600,3))
o = tf.keras.layers.Conv2D(16, (3, 3), padding='same', name='conv0',
       kernel_regularizer=tf.keras.regularizers.l2(1e-2),
       bias_regularizer=tf.keras.regularizers.l2(None),
       kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),
       bias_initializer=tf.keras.initializers.constant(0.0))(i)
model = tf.keras.models.Model(i, o)
with open('repro.json', 'w') as json_file:
    json_file.write(model.to_json())
```

```
~ node
> JSON.parse(require('fs').readFileSync('repro.json', 'utf-8'))
Uncaught SyntaxError: Unexpected token N in JSON at position 861 
```

[repro.zip](https://github.com/tensorflow/tensorflow/files/4270871/repro.zip)

lutzroeder/netron#435
"
37195, ValueError: Dimension 0 in both shapes must be equal,"**System information**
- OS Platform and Distribution: Google AI Platform
- TensorFlow version: v2.0
- Python version: v3.*
- Machine type: 16 vCPUs, 30 GB RAM
- GPU: 1x NVIDIA Tesla K80

I am training a model to caption images and have mostly used this tutorial: https://www.tensorflow.org/tutorials/text/image_captioning#download_and_prepare_the_ms-coco_dataset

The only thing that is different from this notebook is that I am using a different dataset.

When I try and train the model I get the error in the first epoch:

`ValueError: Dimension 0 in both shapes must be equal, but are 10 and 48. Shapes are [10,1] and [48,1]`

I have tried this with many different batch sizes and the error is always in the format:

`ValueError: Dimension 0 in both shapes must be equal, but are 10 and {BATHCH_SIZE}. Shapes are [10,1] and [{BATHCH_SIZE},1]`

I also found a similar issue on github: https://github.com/tensorflow/tensorflow/issues/27862
It is suggested to change the batch size to 48 but that didn't work for me.

Can anyone help out?

Thanks"
37194,Cant run exe file from convert tensorflow to exe,"i have problem for run exe file it been after i deploy script to exe i got application file and run it i got this message in command  i try many things try with command try with auto-py-to-exe it dont solve

![75507237-1b78c700-5a13-11ea-8705-92635f011c90](https://user-images.githubusercontent.com/49858640/75612200-f2ac1b00-5b53-11ea-981e-27aebdbddd33.png)

this time die T-T
Please help me
i use: Python 3.6.9 :: Anaconda, Inc
   tensorflow-gpu==1.9.0
   PyInstaller==4.0.dev0+a1f92c6a08
   Eel==0.11.0"
37193,"""Cannot take the length of shape with unknown rank"" error","**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Ubuntu 18.04.3
- TensorFlow installed from (source or
binary): pip
- TensorFlow version (use command below): tensorflow-addons==0.8.2
tensorflow-estimator==2.1.0
tensorflow-gpu==2.1.0
tensorflow-probability==0.9.0
- Python version: 3.6.9
- CUDA/cuDNN version:  10.1.243 / 7.6.5
- GPU model and memory: Tesla V100-SXM2 32 GB

**Describe the current behavior**
I’m trying to switch from keras to tensorflow.keras (actually only to add TensorBoard callback to model.fit_generator and to be able to profile performance). 
Now I am getting 
```
ValueError                                Traceback (most recent call last)
<ipython-input-6-70f0d0a1e94e> in <module>
…
~/Visual_Z2/ImageNet.py in _doLearning(self, epochCount, learningCallback, otherParams, initialEpochNum)
 #                             self.model.fit_generator
    430                                  validation_steps=testImageCount // self.batchSize,
    431                                  workers=2,
--> 432                                  verbose=2, callbacks=[tensorBoardCallback])
    433             #, summaryCallback])
    434             # Without make_one_shot_iterator - error fused convolution not supported

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py in new_func(*args, **kwargs)
    322               'in a future version' if date is None else ('after %s' % date),
    323               instructions)
--> 324       return func(*args, **kwargs)
    325     return tf_decorator.make_decorator(
    326         func, new_func, 'deprecated',
…
ValueError: in converted code:

    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py:677 map_fn
        batch_size=None)
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py:2469 _standardize_tensors
        exception_prefix='target')
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py:529 standardize_input_data
…
ValueError: Cannot take the length of shape with unknown rank.

```
**Describe the expected behavior**
Everything worked on keras with tensorflow as backend.

**Other info / logs**
I read this can happen because of PyFunction, I really have it, but adding reshape/image.set_shape don't fix the error.
I build input dataset like this

```
def _loadTestImage(imageNum, label):
    imageData = self.imageDataset.getImage(imageNum, 'net', 'test')       # Returns numpy array (227, 227, 3) of floats
    return (imageData, keras.utils.to_categorical(label, num_classes=classCount))

def _tfLoadTestImage(imageNum, label):
    image, label = tf.py_function(_loadTestImage, [imageNum, label], [tf.float32, tf.int32]) 
    # Adding image.set_shape(crop_size + (3, ))
    # or tf.reshape(image, shape=crop_size + (3, ))
    # here doesn’t help
    return image, label

numDs = tf.data.Dataset.from_tensor_slices(imageNums)       # Shuffled indices of images [15, 22, 3, …] 
label_ds = tf.data.Dataset.from_tensor_slices(self.imageNumLabels)
ds = tf.data.Dataset.zip((numDs, label_ds))
ds = ds.repeat()
tfTestDataset = ds.shuffle(buffer_size=max(epochImageCount, 2000))
tfTestDataset = tfTestDataset.map(_tfLoadTestImage, num_parallel_calls=4)
tfTestDataset = tfTestDataset.batch(self.batchSize)
```

The problem looks identical to https://github.com/tensorflow/tensorflow/issues/24520#issuecomment-589119295 so I tried nightly build today (2.2.0-dev20200229) and still getting error, only 

```
ValueError: in user code:

    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:499 train_function  *
        outputs = self.distribute_strategy.experimental_run_v2(
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:856 experimental_run_v2  **
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2112 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2470 _call_for_each_replica
        return fn(*args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:471 train_step  **
        self.compiled_metrics.update_state(y, y_pred, sample_weight)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:348 update_state
        self._build(y_pred, y_true)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:267 _build
        self._metrics, y_true, y_pred)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py:1118 map_structure_up_to
        **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py:1214 map_structure_with_tuple_paths_up_to
        *flat_value_lists)]
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py:1213 <listcomp>
        results = [func(*args, **kwargs) for args in zip(flat_path_list,
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py:1116 <lambda>
        lambda _, *values: func(*values),  # Discards the path arg.
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:377 _get_metric_objects
        return [self._get_metric_object(m, y_t, y_p) for m in metrics]
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:377 <listcomp>
        return [self._get_metric_object(m, y_t, y_p) for m in metrics]
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:398 _get_metric_object
        y_t_rank = len(y_t.shape.as_list())
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py:1173 as_list
        raise ValueError(""as_list() is not defined on an unknown TensorShape."")

    ValueError: as_list() is not defined on an unknown TensorShape.
```"
37191,"Something is wrong with positional encoding,sin and cos should be concatenated.","def positional_encoding(position, d_model):
  angle_rads = get_angles(np.arange(position)[:, np.newaxis],
                          np.arange(d_model)[np.newaxis, :],
                          d_model)
  
  # 将 sin 应用于数组中的偶数索引（indices）；2i
  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])
  
  # 将 cos 应用于数组中的奇数索引；2i+1
  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])
  angle_rads = np.concatenate([angle_rads[:, 0::2] ,angle_rads[:, 1::2]],axis = -1)
  pos_encoding = angle_rads[np.newaxis, ...]
    
  return tf.cast(pos_encoding, dtype=tf.float32)"
37189,Can you guys work on making Tensorflow easier to install?,"Hi.  I spent 2 weeks trying to get Tensorflow up and running on my GPU.  It worked... for that one particular repo.  Now I'm trying another project, and apparently that particular version of Tensorflow gives me the error ""Tensorflow has no attribute 'dimension'"".  

So I tried to open a new environment, re-install tensorflow-gpu, and I'm getting a ""core-dump"" error.

With other packages, I can just type ""pip install"" and it works.  With tensorflow, every single time I have to use or install it I have to spend multiple hours debugging it.  Please, instead of adding new features, work on making Tensorflow able to be installed and used, without errors, by someone without a doctorate in computer science."
37187,guarantees for the logs argument in keras Callbacks,"## URL(s) with the issue:
https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback
https://www.tensorflow.org/guide/keras/custom_callback

## Description of issue (what needs changing):
The documentation for the keras `Callback` base class contains the following generic statement about the `logs` parameter passed to its methods:
```
The logs dictionary that callback methods take as argument will contain keys for quantities relevant to the current batch or epoch.
```
and
```
The logs dict contains the loss value, and all the metrics at the end of a batch or epoch. Example includes the loss and mean absolute error.
```
on the Keras custom callbacks page.

Since python passes objects by reference, the question becomes whether write-access to this logs parameter is allowed and supported. An example use case would be to provide a custom callback that populates the `logs` dictionary with some additional information that than would automatically be displayed in the progress bar and tensorboard, and recorded in history and CSV callbacks. 

Therefore, I think the documentation should clearly state whether 
1) Write-access to the `logs` dict is forbidden (in which case it might be worthwhile to pass a non-writeable dict-like type)
2) Write-access to `logs` is allowed, and will not have any side-effects on any other Callback (i.e. each Callback gets an independent copy)
3) The `logs` dict is writable, and changes to it are visible to any further Callback. This would also require to specify in which order the callbacks are processed.
 "
37186,tensorflow/stream_executor/lib/statusor.cc:34] Attempting to fetch value instead of handling error Internal: failed to get device attribute 13 for device 0: CUDA_ERROR_UNKNOWN: unknown error,"**System information** 
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04):  Windows 10
- TensorFlow installed from (source or
binary): Tried with both pip and conda
- TensorFlow version (use command below): 2.10
- Python version: 3.6
- CUDA/cuDNN version:  CUDA 10.1 , cuDNN 7.6.5
- GPU model and memory: NVIDIA MX250 , 2GB

**Describe the current behavior**
TensorFlow 2.10 gets installed. It is also imported into Python. When I try to list the available GPUs,

`from __future__ import absolute_import, division, print_function, unicode_literals
import tensorflow as tf
print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))`

the following error occurs.
`2020-02-29 18:26:23.596966: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-02-29 18:26:24.237060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:
pciBusID: 0000:02:00.0 name: GeForce MX250 computeCapability: 6.1
coreClock: 1.582GHz coreCount: 3 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 44.76GiB/s
2020-02-29 18:26:24.240888: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-02-29 18:26:24.544030: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-02-29 18:26:24.727079: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-02-29 18:26:24.811098: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-02-29 18:26:24.994088: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-02-29 18:26:25.075048: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-02-29 18:26:25.508640: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-02-29 18:26:25.513010: F tensorflow/stream_executor/lib/statusor.cc:34] Attempting to fetch value instead of handling error Internal: failed to get device attribute 13 for device 0: CUDA_ERROR_UNKNOWN: unknown error`

When it's run inside a Jupyter notebook, the kernel freezes for a while and then restarts.

**Other info / logs** 
![Capture2](https://user-images.githubusercontent.com/5057255/75608230-b95bb700-5b23-11ea-802a-1ce3b7d8c252.PNG)
"
37185,Tensorflow 2.1.0 causing all RAM to be consumed on model.fit,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): 
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Linux Ubuntu 19

- Tensorflow version: 2.1.0cp37
- CUDA/cuDNN version: - GPU model and memory:
1070 GTX 8 GB GDDR5

**Describe the current behavior**
I am using tf.data dataset API. When using model.fit, on the first epoch, I am already consuming 16 GB of RAM when I run with GPU, but when I run with CPU the memory consumption is very small. 

EDIT: tensorflow-cpu actually has the same issue with high memory consumption

Same dataset, same code. This only happens in Tensorflow 2.>

Is this a known issue? What can I do as a temporarily fix?

**Standalone code to reproduce the issue** 
Just a simpel model, with a dataset which loads images:
```
model = models.Sequential()
model.add(Conv2D(4, (9, 9), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(8, (9, 9), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(16, (9, 9), activation='relu'))
model.add(MaxPooling2D((2, 2)))


model.add(Flatten())
model.add(Dense(5, activation='sigmoid'))

model.summary()

model.compile(optimizer='adam', loss=losses.binary_crossentropy, metrics=['accuracy'])

history = model.fit(ds_train,
                    steps_per_epoch=steps_per_epoch,
                    validation_data=ds_val,
                    validation_steps=validation_steps,
                    epochs=10)
```

I should also mention that the images I am using are concatenated images that are 320px * 4 in width and 180 in height
"
37184,Serialization fails for nested models (models containing another model),"Looks like a duplicate of #37158

**System information** 
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):  Custom code, Auto-encoder sample, based on a tutorial:
https://www.pyimagesearch.com/2020/02/17/autoencoders-with-keras-tensorflow-and-deep-learning/

- OS Platform and Distribution 
Windows 10
- TensorFlow installed from (source orbinary): 
pip install tensorflow-gpu
- TensorFlow version (use command below): 
v2.1.0-rc2-17-ge5bf8de410 2.1.0
- Python version:
3.7.6
 - Bazel version (if compiling from source):
not used
- GCC/Compiler version (if compiling from source): 
not used
- CUDA/cuDNN version: - GPU model and memory:
CUDA Version 10.1.243
cudnn-10.1-windows10-x64-v7.6.5.32

**Describe the current behavior**
saving autoencoder throws
`WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002065515D678> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output.
Cause: WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002065515D678> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output.
Cause: INFO:tensorflow:Assets written to: test\assets`

loading the saved model fails with the message
`keras.models.load_model('run/autoencoder/')
Traceback (most recent call last):
  File ""<ipython-input-39-0e89c2f914ad>"", line 1, in <module>
    keras.models.load_model('run/autoencoder/')
  File ""c:\python37\lib\site-packages\tensorflow_core\python\keras\saving\save.py"", line 150, in load_model
    return saved_model_load.load(filepath, compile)
  File ""c:\python37\lib\site-packages\tensorflow_core\python\keras\saving\saved_model\load.py"", line 89, in load
    model = tf_load.load_internal(path, loader_cls=KerasObjectLoader)
  File ""c:\python37\lib\site-packages\tensorflow_core\python\saved_model\load.py"", line 552, in load_internal
    export_dir)
  File ""c:\python37\lib\site-packages\tensorflow_core\python\keras\saving\saved_model\load.py"", line 119, in __init__
    self._finalize()
  File ""c:\python37\lib\site-packages\tensorflow_core\python\keras\saving\saved_model\load.py"", line 157, in _finalize
    created_layers={layer.name: layer for layer in node.layers})
  File ""c:\python37\lib\site-packages\tensorflow_core\python\keras\engine\network.py"", line 1903, in reconstruct_from_config
    process_node(layer, node_data)
  File ""c:\python37\lib\site-packages\tensorflow_core\python\keras\engine\network.py"", line 1851, in process_node
    output_tensors = layer(input_tensors, **kwargs)
  File ""c:\python37\lib\site-packages\tensorflow_core\python\keras\engine\base_layer.py"", line 773, in __call__
    outputs = call_fn(cast_inputs, *args, **kwargs)
  File ""c:\python37\lib\site-packages\tensorflow_core\python\keras\engine\network.py"", line 712, in call
    raise NotImplementedError('When subclassing the Model class, you should'
NotImplementedError: When subclassing the Model class, you should implement a call method.`

saving and loading of encode/decoder models works, but for autoencoder it fails, therefor I suspect that this is related to nested models

**Describe the expected behavior**
save / load cycle works without error message

**Standalone code to reproduce the issue** 

[train_auto_encoder_mnist.py.txt](https://github.com/tensorflow/tensorflow/files/4270255/train_auto_encoder_mnist.py.txt)

Code is based on a tutorial form
https://www.pyimagesearch.com/2020/02/17/autoencoders-with-keras-tensorflow-and-deep-learning/"
37183,Remote monitoring of DL models,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.1.0
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**
An app or a website that lets you remotely monitor your deep learning model's metrics. It can also notify you when your model has completed training or has crashed. I have worked on this before and I wish it could come inbuilt with Tensorflow. You can check out that project [here](https://github.com/CleanPegasus/TensorDash). 

**Will this change the current api? How?**
There will be a few miscellaneous codes added to the tensorflow library.

**Who will benefit with this feature?**
This will benefit the researchers who are training huge models. This will save them a lot of time.

**Any Other info.**
"
37182,Could not find any TF GPUs when I use trt_convert,"I use:
OS: 16.04
cuda: 10.2
cudnn: 7
python:3.6
tensorflow-gpu:2.1
GPU: Titan V - 12GB
I convert model tensorflow to tensorRT:
`from tensorflow.python.compiler.tensorrt import trt_convert as trt`
`input_saved_model_dir = ""./model_tensor/""`
`output_saved_model_dir = ""./model_tensor_rt/""`
`converter = trt.TrtGraphConverterV2(input_saved_model_dir=input_saved_model_dir)`
`converter.convert()`
`converter.save(output_saved_model_dir)`

I still can inference model on tensorflow:
However I cannot convert to tensorRT: 

2020-02-29 17:19:35.901924: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:102]Could not find any TF GPUs

2020-02-29 17:19:35.901927: W tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:726] Can't identify the cuda device. Running on device 0 

2020-02-29 17:19:35.901958: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 5 consisting of 4 nodes by 
StatefulPartitionedCall/X/Y/TRTEngineOp_5.

Thanks"
37181,"tf2.0 when use large input dims in tf.keras.layers.Embedding layer under eager mode, it turns to be very slow","<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow):  yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04):  centos7
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below):  2.0.0
- Python version: - Bazel 
version (if compiling from source): 3.6.8
- GCC/Compiler version (if compiling from
source):  
- CUDA/cuDNN version: - GPU model and memory: CUDA10.0 tesla v100 16G

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
i set the input dims be 10,000,000 when I use tf.keras.layers.Embedding. Under the eager mode(default), mode.fit() is very slow. But when i disable the eager mode, the speed turns to be normal.
**Describe the expected behavior**
it should be no difference if i enable eager mode or not.
**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```
test_input = tf.ones((1000, 1), dtype=tf.int64)
label = tf.ones((1000, 1))
m_input = Input(shape=(1,))
dense = Embedding(5000000, 16,name='embed')(m_input)
dense = Dense(10)(dense)
dense = Dense(5)(dense)
output = Dense(1,'sigmoid')(Flatten()(dense))
model = Model(inputs=[m_input], outputs=[output])
model.compile(""adam"", loss='binary_crossentropy')
model.fit(test_input, label, steps_per_epoch=1000, epochs=1)
```
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

```
when use eager mode, time cost is as follow

1/1000 [..............................] - ETA: 29:49 - loss: 0.7492
2/1000 [..............................] - ETA: 25:54 - loss: 0.7430
3/1000 [..............................] - ETA: 24:58 - loss: 0.7368
4/1000 [..............................] - ETA: 24:21 - loss: 0.7307

disable the eager mode using tf.compat.v1.disable_eager_execution()


 706/1000 [====================>.........] - ETA: 0s - loss: 0.0520
 765/1000 [=====================>........] - ETA: 0s - loss: 0.0484
 819/1000 [=======================>......] - ETA: 0s - loss: 0.0455
 870/1000 [=========================>....] - ETA: 0s - loss: 0.0430
 926/1000 [==========================>...] - ETA: 0s - loss: 0.0406
 984/1000 [============================>.] - ETA: 0s - loss: 0.0384
1000/1000 [==============================] - 2s 2ms/step - loss: 0.0379

```
"
37180,tf.keras.callbacks.TensorBoard  type profiling support for straight Tensorflow,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 1.15
- Are you willing to contribute it (Yes/No):
No sure.


**Describe the feature and the current behavior/state.**

tf.keras.callbacks.TensorBoard has a nice and simple way to  do profiling and  throwing the result up on Tensorboard.  It would be great to have that easy feature also for plain TF (sess.run).  

In addition, I think  the following enhancements will be very useful. 
1.  Ability to aggregate a number of traces.
2.  Backport the range of batch ( instead of just one batch ) from 2.x to 1.5 ?
3.  Linking the  time line traces with graph in both direction, from profile to graph and vice-versa.
4.  The Op names in the graph and profile should exactly match. Currently they are not exactly same ( e.g. out_0/MatMul:_MklMatMul vs out_0/MatMul/(MatMul) ).
5. There seems to be a number of different ways to profile straight TF and Keras. The following are what I am able to  find (so far, not sure if there are more).  Clear, concise and comprehensive documentation will be good.
           - tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE) and tf.compat.v1.summary.FileWriter.add_run_metadata() .  Seems to be graph annotations and does not seem to capture Keras  backprop part.
           -  tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE) and timeline.Timeline() - seems to work with both TF and Keras. However generates  JSON and hence does not get displayed by Tensorbaord. 
           - tf.keras.callbacks.TensorBoard() - only works with Keras and captures only one batch out off all in the epoch. 

**Will this change the current api? How?**
N/A

**Who will benefit with this feature?**
Every user. 
**Any Other info.**
"
37179,"Wrong ""name"" parameter default for Nadam optimizer","## URL(s) with the issue:
https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Nadam

## Description of issue (what needs changing):
Optional name attribute is said to default as ""Adamax"" rather than ""Nadam""

### Clear description

name: Optional name for the operations created when applying gradients. Defaults to ""Adamax"".

### Correct links

https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/optimizer_v2/nadam.py#L33-L238

Source code correctly shows default as name=""Nadam"". Therefore documentation issue.

### Submit a pull request?

Not at the moment"
37178,.prefetch() and .cache() not speeding up tf.data.Dataset pipeline ,"I have a very big dataset so I am training over small chunks using keras.fit. 
For loading chunks in memory I have a generator function which generates a tuple of tensors of variable size which I pass to tf.data.Dataset to create a data pipeline.

```
def extract_XY(list_idx):
    read_files(list_idx)
    append to list X
    process, reshape and convert to tensor X (?,100,100,3)  #? means variable size
    Y = f(X)  
    return X,Y

for i in range(epochs):
    for j in range(chunks):
        x,y = extract_XY(list_idx) #list_idx changes in each loop
        data = tf.data.Dataset.from_tensor_slices((X,Y)).batch(64).cache().prefetch(tf.data.experimental.AUTOTUNE)
        model.fit(data,epochs=2,verbose=1)

```

My training with keras fit works fine but I see no speed up using .cache() or .prefetch()
Can anyone help me understand if I am using them correctly in my case.

Can I make my data-pipeline more efficient i.e., loading next chunk while model is training? any suggestions would be helpfull?
Does using multiprocessing=True in Keras.fit() will help more? or tf.data.Dataset is already taking care of I/O bottleneck.


Thanks in advance!



"
37177,NotImplementedError: Cannot convert a symbolic Tensor (up_sampling2d_5_target_2:0) to a numpy array.,"```
import keras.backend as K
from keras.optimizers import Adam
from keras.losses import binary_crossentropy

## intersection over union
def IoU(y_true, y_pred, eps=1e-6):
    print(y_true)
    if np.max(y_true) == 0.0:
        return IoU(1-y_true, 1-y_pred) ## empty image; calc IoU of zeros
    #if 0 == K.equal(y_true, 0):
    #    y_true = K.switch(0, 1-y_true, y_true)
    #    y_pred = K.switch(0, 1-y_pred, y_pred)
    #    return IoU(1-y_true, 1-y_pred) ## empty image; calc IoU of zeros
        
    intersection = K.sum(y_true * y_pred, axis=[1,2,3])
    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3]) - intersection
    return -K.mean( (intersection + eps) / (union + eps), axis=0)
```


> Tensor(""up_sampling2d_5_target_2:0"", shape=(None, None, None, None), dtype=float32)
> ---------------------------------------------------------------------------
> NotImplementedError                       Traceback (most recent call last)
> <ipython-input-26-466b05eae4fa> in <module>
>      14 
>      15 while True:
> ---> 16     loss_history = fit()
>      17     if np.min([mh.history['val_loss'] for mh in loss_history]) < -0.2:
>      18         break
> 
> <ipython-input-26-466b05eae4fa> in fit()
>       1 def fit():
> ----> 2     seg_model.compile(optimizer=Adam(1e-3, decay=1e-6), loss=IoU, metrics=['binary_accuracy'])
>       3 
>       4     step_count = min(MAX_TRAIN_STEPS, train_df.shape[0]//BATCH_SIZE)
>       5     aug_gen = create_aug_gen(make_image_gen(train_df))
> 
> ~/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py in symbolic_fn_wrapper(*args, **kwargs)
>      73         if _SYMBOLIC_SCOPE.value:
>      74             with get_graph().as_default():
> ---> 75                 return func(*args, **kwargs)
>      76         else:
>      77             return func(*args, **kwargs)
> 
> ~/venv/lib/python3.7/site-packages/keras/engine/training.py in compile(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)
>     227         #                   loss_weight_2 * output_2_loss_fn(...) +
>     228         #                   layer losses.
> --> 229         self.total_loss = self._prepare_total_loss(masks)
>     230 
>     231         # Functions for train, test and predict will
> 
> ~/venv/lib/python3.7/site-packages/keras/engine/training.py in _prepare_total_loss(self, masks)
>     690 
>     691                     output_loss = loss_fn(
> --> 692                         y_true, y_pred, sample_weight=sample_weight)
>     693 
>     694                 if len(self.outputs) > 1:
> 
> ~/venv/lib/python3.7/site-packages/keras/losses.py in __call__(self, y_true, y_pred, sample_weight)
>      69         scope_name = 'lambda' if self.name == '<lambda>' else self.name
>      70         with K.name_scope(scope_name):
> ---> 71             losses = self.call(y_true, y_pred)
>      72             return losses_utils.compute_weighted_loss(
>      73                 losses, sample_weight, reduction=self.reduction)
> 
> ~/venv/lib/python3.7/site-packages/keras/losses.py in call(self, y_true, y_pred)
>     130             Loss values per sample.
>     131         """"""
> --> 132         return self.fn(y_true, y_pred, **self._fn_kwargs)
>     133 
>     134     def get_config(self):
> 
> <ipython-input-24-d1d9fb424ded> in IoU(y_true, y_pred, eps)
>       6 def IoU(y_true, y_pred, eps=1e-6):
>       7     print(y_true)
> ----> 8     if np.max(y_true) == 0.0:
>       9         return IoU(1-y_true, 1-y_pred) ## empty image; calc IoU of zeros
>      10     #if 0 == K.equal(y_true, 0):
> 
> <__array_function__ internals> in amax(*args, **kwargs)
> 
> ~/venv/lib/python3.7/site-packages/numpy/core/fromnumeric.py in amax(a, axis, out, keepdims, initial, where)
>    2619     """"""
>    2620     return _wrapreduction(a, np.maximum, 'max', axis, None, out,
> -> 2621                           keepdims=keepdims, initial=initial, where=where)
>    2622 
>    2623 
> 
> ~/venv/lib/python3.7/site-packages/numpy/core/fromnumeric.py in _wrapreduction(obj, ufunc, method, axis, dtype, out, **kwargs)
>      88                 return reduction(axis=axis, out=out, **passkwargs)
>      89 
> ---> 90     return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
>      91 
>      92 
> 
> ~/venv/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py in __array__(self)
>     734   def __array__(self):
>     735     raise NotImplementedError(""Cannot convert a symbolic Tensor ({}) to a numpy""
> --> 736                               "" array."".format(self.name))
>     737 
>     738   def __len__(self):
> 
> NotImplementedError: Cannot convert a symbolic Tensor (up_sampling2d_5_target_2:0) to a numpy array."
37173,"Null pointer to a converted model using Tensorflow Lite in Android Studio. ""Byte buffer is not a valid flatbuffer model."" Exception","i made a model containing layers of type: Conv3D, MaxPool3D, Flatten, Dense and Batch normalization and converted it to tflite model as follows..

```bash
import tensorflow as tf

converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
                                       tf.lite.OpsSet.SELECT_TF_OPS]
tflite_model = converter.convert()
```

The problem is when i load this converted model in Android Studio it always gives me illegal argument exception saying  **""Byte buffer is not a valid flatbuffer model""** & a null pointer to it

i also, specified this dependency in my build.gradle to add the necessary TF op support.

```bash
dependencies {
    implementation 'org.tensorflow:tensorflow-lite:0.0.0-nightly'
    implementation 'org.tensorflow:tensorflow-lite-select-tf-ops:0.0.0-nightly'
} 
```
Any help?"
37172,module 'tensorflow._api.v1.nn' has no attribute 'seq2seq',"when i execute this command 
python tensorflow/models/rnn/translate/translate.py 


i get 

Preparing WMT data in /home/baba055h_s/
2020-02-28 17:45:29.997997: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-28 17:45:30.002826: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz
2020-02-28 17:45:30.003172: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55c1f9a006a0 executing computations on platform Host. Devices:
2020-02-28 17:45:30.003209: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
Creating 3 layers of 1024 units.
WARNING:tensorflow:From /home/baba055h_s/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/baba055h_s/ten3/tensorflow/tensorflow/models/rnn/translate/seq2seq_model.py:117: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.
WARNING:tensorflow:From /home/baba055h_s/ten3/tensorflow/tensorflow/models/rnn/translate/seq2seq_model.py:122: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.
WARNING:tensorflow:At least two cells provided to MultiRNNCell are the same object and will share weights.
Traceback (most recent call last):
  File ""./translate.py"", line 290, in <module>
    tf.app.run()
  File ""/home/baba055h_s/anaconda3/lib/python3.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""./translate.py"", line 287, in main
    train()
  File ""./translate.py"", line 152, in train
    model = create_model(sess, False)
  File ""./translate.py"", line 131, in create_model
    dtype=dtype)
  File ""/home/baba055h_s/ten3/tensorflow/tensorflow/models/rnn/translate/seq2seq_model.py"", line 168, in __init__
    self.outputs, self.losses = tf.nn.seq2seq.model_with_buckets(
AttributeError: module 'tensorflow._api.v1.nn' has no attribute 'seq2seq'





please can any one help"
37170,Why tensorflow creates gru/while in graph?,I am trying to compute the flop of a GRU model for one step. I understand all results but not the gru/while. Why TensorFlow need to create gru/while in the graph doubling the computations? I also asked this question in StackOverflow (https://stackoverflow.com/questions/60453735/what-tensorflow-keras-will-create-gru-while-in-graph) but have not got any answer yet. 
37169,"tensorflow has no attribute ""assign_add""","i am using tensorflow-GPU 2.0.0 version . I caught a error that tensorflow has no attribute ""assign_add"". could anyone please help me please"
37168,`encode_png` function should be exported from `tf.io` module,"## URL(s) with the issue:
https://www.tensorflow.org/api_docs/python/tf/image/encode_png

## Description of the issue (what needs changing):

Currently, all Image decoding and encoding functions are a part of the `tf.io` module but `encode_png` function is still a part of the `tf.image` module.

## Changes required

Change `tf.image.encode_png`  to `tf.io.encode_png`


### Submit a pull request?
I will be happy to help.
"
37167,[TF 2.1] BUG: set_seed with categorical in a conditional branch in graph mode.,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below):  From source and binary using pip.
- Python version: - Bazel
version (if compiling from source): Python=3.6.9, Bazel=2.0.0
- GCC/Compiler version (if compiling from
source): 8.3.0
- CUDA/cuDNN version: - GPU model and memory:

**Describe the current behavior**
The example containing the bug always returns the first step in `tf.function` with `tf.cond` if we define a seed with `tf.random.set_seed`.
A= tf.Tensor([0 0 0 0 0 0 0 0 0 0 0 0], shape=(12,), dtype=int64)

**Describe the expected behavior**
A= tf.Tensor([0 1 1 0 0 1 1 1 1 0 1 1], shape=(12,), dtype=int64)
A= tf.Tensor([0 0 0 0 0 0 1 1 0 1 1 0], shape=(12,), dtype=int64)
...

**Standalone code to reproduce the issue** 
Bug sample:
```
import tensorflow as tf

tf.random.set_seed(0)

def f1():
    return(tf.random.categorical(tf.math.log([[0.5, 0.5]]), 1))

@tf.function
def body():
    Y = []
    for t in range(12):
        Y.append(
            tf.cond(tf.constant(True),
                    f1,
                    f1)
        )
    return(tf.squeeze(Y))

A = body()

print(""A="", A)
# A= tf.Tensor([0 0 0 0 0 0 0 0 0 0 0 0], shape=(12,), dtype=int64)
```

1. Working sample:
```
import tensorflow as tf

def f1():
    return(tf.random.categorical(tf.math.log([[0.5, 0.5]]), 1))

@tf.function
def body():
    Y = []
    for t in range(12):
        Y.append(
            tf.cond(tf.constant(True),
                    f1,
                    f1)
        )
    return(tf.squeeze(Y))

A = body()

print(""A="", A)
# A= tf.Tensor([0 1 1 0 0 1 1 1 1 0 1 1], shape=(12,), dtype=int64)
```

2. Working sample:
```
import tensorflow as tf

tf.random.set_seed(0)

def f1():
    return(tf.random.categorical(tf.math.log([[0.5, 0.5]]), 1))

@tf.function
def body():
    Y = []
    for t in range(12):
        ret_0 = f1()
        ret_1 = f1()
        
        Y.append(
            tf.cond(tf.constant(True),
                    lambda: ret_0,
                    lambda: ret_1)
        )
    return(tf.squeeze(Y))

A = body()

print(""A="", A)
# A= tf.Tensor([0 0 0 0 0 0 1 1 0 1 1 0], shape=(12,), dtype=int64)
```

"
37164,TensorFlow 2.1.0 Not utilising GPU even though it can see it.  ,"TensorFlow does not utilise the GPU despite being able to see it. When I run a script, task manager does not show any activity on the GPU...

**Recently I have tried:**

Updated NVIDIA driver.

Uninstalled Tensorflow, python 3.7, cuDNN, CUDA, Visual Studio.

Installed Visual Studio.

Installed CUDA 10.1 [cuda_10.1.243_426.00_win10].

Installed cuDNN (and moved the .dll, .h, .lib files) [cudnn-10.1-windows10-x64-v7.6.5.32.zip]

Installed python [python-3.7.4-amd64.exe]

Installed Tensorflow (2.1.0) into a new environment and made a Kernel

**When I run ...**
import tensorflow as tf
tf.test.is_gpu_available(
    cuda_only=False, min_cuda_compute_capability=None
)
**… it returns** 
""true""

**when I run**
""from tensorflow.python.client import device_lib
print(device_lib.list_local_devices())""

**it returns**
 [name: ""/device:CPU:0""
device_type: ""CPU""
memory_limit: 268435456
locality {
}
incarnation: 3456819361691180826
, name: ""/device:GPU:0""
device_type: ""GPU""
memory_limit: 9105744200
locality {
  bus_id: 1
  links {
  }
}
incarnation: 18022178943584354069
physical_device_desc: ""device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5""

However, when I run my script the task manager shows no activation on the GPU.  "
37162,using tensorflow-hub model elmo ensorflow.python.framework.errors_impl.ResourceExhaustedError,"Python 3.6.10 
tensorflow 1.12.0 gpu_py36he68c306_0
tensorflow-base 1.12.0 gpu_py36h8e0ae2d_0
tensorflow-gpu 1.12.0 h0d30ee6_0
tensorflow-hub 0.5.0 pypi_0 pypi cudatoolkit 9.0 h13b8566_0
cudnn 7.6.5  cuda9.0_0

NVIDIA-SMI 418.87.01 Driver Version: 418.87.01 CUDA Version: 10.1
0 Tesla V100-SXM2... Off | 00000000:18:00.0 Off | 0 | | N/A 37C P0 43W / 300W | 11MiB / 32480MiB | 0% Default | +-------------------------------+----------------------+----------------------+ | 1 Tesla V100-SXM2... Off | 00000000:3B:00.0 Off | 0 | | N/A 34C P0 42W / 300W | 11MiB / 32480MiB | 0% Default | +-------------------------------+----------------------+----------------------+ | 2 Tesla V100-SXM2... Off | 00000000:86:00.0 Off | 0 | | N/A 34C P0 43W / 300W | 11MiB / 32480MiB | 0% Default | +-------------------------------+----------------------+----------------------+ | 3 Tesla V100-SXM2... Off | 00000000:AF:00.0 Off | 0 | | N/A 38C P0 43W / 300W | 11MiB / 32480MiB | 0% Default

error: Using TensorFlow backend. /share/nishome/19930072_0/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'. _np_qint8 = np.dtype([(""qint8"", np.int8, 1)]) /share/nishome/19930072_0/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'. _np_quint8 = np.dtype([(""quint8"", np.uint8, 1)]) /share/nishome/19930072_0/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'. _np_qint16 = np.dtype([(""qint16"", np.int16, 1)]) /share/nishome/19930072_0/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'. _np_quint16 = np.dtype([(""quint16"", np.uint16, 1)]) /share/nishome/19930072_0/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'. _np_qint32 = np.dtype([(""qint32"", np.int32, 1)]) /share/nishome/19930072_0/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'. np_resource = np.dtype([(""resource"", np.ubyte, 1)]) INFO:bert_bilstm_softmax.py:running bert_bilstm_softmax.py INFO:root:loading data... INFO:absl:Using /tmp/tfhub_modules to cache modules. INFO:tensorflow:Saver not created because there are no variables in the graph to restore INFO:tensorflow:Saver not created because there are no variables in the graph to restore INFO:tensorflow:Saver not created because there are no variables in the graph to restore INFO:tensorflow:Saver not created because there are no variables in the graph to restore 38 7 (2742, 38, 1024) (392, 38, 1024) (2742, 38, 2) (392, 38, 2)

Layer (type) Output Shape Param #
input_1 (InputLayer) (None, 38, 1024) 0

batch_normalization_1 (Batch (None, 38, 1024) 4096

masking_1 (Masking) (None, 38, 1024) 0

bidirectional_1 (Bidirection (None, 38, 256) 1180672

bidirectional_2 (Bidirection (None, 38, 256) 394240

dropout_1 (Dropout) (None, 38, 256) 0

dense_1 (Dense) (None, 38, 2) 514
Total params: 1,579,522 Trainable params: 1,577,474 Non-trainable params: 2,048

Train on 2742 samples, validate on 392 samples Epoch 1/30 2020-02-28 19:42:36.337714: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA 2020-02-28 19:42:36.787351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53 pciBusID: 0000:18:00.0 totalMemory: 31.72GiB freeMemory: 31.41GiB 2020-02-28 19:42:36.957634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 1 with properties: name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53 pciBusID: 0000:3b:00.0 totalMemory: 31.72GiB freeMemory: 31.41GiB 2020-02-28 19:42:37.143501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 2 with properties: name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53 pciBusID: 0000:86:00.0 totalMemory: 31.72GiB freeMemory: 31.41GiB 2020-02-28 19:42:37.336031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 3 with properties: name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53 pciBusID: 0000:af:00.0 totalMemory: 31.72GiB freeMemory: 31.41GiB 2020-02-28 19:42:37.336143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0, 1, 2, 3 2020-02-28 19:42:41.617032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix: 2020-02-28 19:42:41.617079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988] 0 1 2 3 2020-02-28 19:42:41.617090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0: N Y Y Y 2020-02-28 19:42:41.617122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 1: Y N Y Y 2020-02-28 19:42:41.617132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 2: Y Y N Y 2020-02-28 19:42:41.617158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 3: Y Y Y N 2020-02-28 19:42:41.617526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30472 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:18:00.0, compute capability: 7.0) 2020-02-28 19:42:41.634656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 30472 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0) 2020-02-28 19:42:41.635333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 30472 MB memory) -> physical GPU (device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:86:00.0, compute capability: 7.0) 2020-02-28 19:42:41.635518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 30472 MB memory) -> physical GPU (device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:af:00.0, compute capability: 7.0) 2020-02-28 19:43:06.568339: W tensorflow/core/common_runtime/bfc_allocator.cc:267] Allocator (GPU_0_bfc) ran out of memory trying to allocate 8.94GiB. Current allocation summary follows. 2020-02-28 19:43:06.568442: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (256): Total Chunks: 147, Chunks in use: 145. 36.8KiB allocated for chunks. 36.2KiB in use in bin. 1.1KiB client-requested in use in bin.

2020-02-28 19:43:06.568541: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (65536): Total Chunks: 36, Chunks in use: 36. 2.27MiB allocated for chunks. 2.27MiB in use in bin. 2.25MiB client-requested in use in bin. 2020-02-28 19:43:06.568552: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (131072): Total Chunks: 18, Chunks in use: 18. 2.42MiB allocated for chunks. 2.42MiB in use in bin. 2.38MiB client-requested in use in bin. 2020-02-28 19:43:06.568564: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (262144): Total Chunks: 19, Chunks in use: 18. 5.06MiB allocated for chunks. 4.69MiB in use in bin. 4.69MiB client-requested in use in bin. 2020-02-28 19:43:06.568577: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (524288): Total Chunks: 31, Chunks in use: 28. 16.48MiB allocated for chunks. 14.59MiB in use in bin. 14.59MiB client-requested in use in bin. 2020-02-28 19:43:06.568588: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (1048576): Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin. 2020-02-28 19:43:06.568600: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (2097152): Total Chunks: 7, Chunks in use: 7. 14.00MiB allocated for chunks. 14.00MiB in use in bin. 14.00MiB client-requested in use in bin. 2020-02-28 19:43:06.568611: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (4194304): Total Chunks: 2, Chunks in use: 1. 8.00MiB allocated for chunks. 4.00MiB in use in bin. 4.00MiB client-requested in use in bin. 2020-02-28 19:43:06.568624: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (8388608): Total Chunks: 4, Chunks in use: 4. 32.00MiB allocated for chunks. 32.00MiB in use in bin. 32.00MiB client-requested in use in bin. 2020-02-28 19:43:06.568636: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (16777216): Total Chunks: 5, Chunks in use: 4. 80.00MiB allocated for chunks. 64.00MiB in use in bin. 64.00MiB client-requested in use in bin. 2020-02-28 19:43:06.568648: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (33554432): Total Chunks: 1, Chunks in use: 0. 32.02MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin. 2020-02-28 19:43:06.568661: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (67108864): Total Chunks: 5, Chunks in use: 4. 340.04MiB allocated for chunks. 256.00MiB in use in bin. 256.00MiB client-requested in use in bin. 2020-02-28 19:43:06.568670: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (134217728): Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin. 2020-02-28 19:43:06.568679: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (268435456): Total Chunks: 13, Chunks in use: 7. 29.24GiB allocated for chunks. 18.58GiB in use in bin. 18.58GiB client-requested in use in bin. 2020-02-28 19:43:06.568687: I tensorflow/core/common_runtime/bfc_allocator.cc:613] Bin for 8.94GiB was 256.00MiB, Chunk State: 2020-02-28 19:43:06.568701: I tensorflow/core/common_runtime/bfc_allocator.cc:619] Size: 317.98MiB | Requested Size: 317.98MiB | in_use: 0, prev: Size: 256B | Requested Size: 4B | in_use: 1, next: Size: 317.98MiB | Requested Size: 317.98MiB | in_use: 1 2020-02-28 19:43:06.568712: I tensorflow/core/common_runtime/bfc_allocator.cc:619] Size: 635.96MiB | Requested Size: 623.24MiB | in_use: 0, prev: Size: 317.98MiB | Requested Size: 317.98MiB | in_use: 1, next: Size: 635.96MiB | Requested Size: 635.96MiB | in_use: 1 2020-02-28 19:43:06.568721: I tensorflow/core/common_runtime/bfc_allocator.cc:619] Size: 1.19GiB | Requested Size: 1.17GiB | in_use: 0, prev: Size: 623.24MiB | Requested Size: 623.24MiB | in_use: 1, next: Size: 1.19GiB | Requested Size: 1.19GiB | in_use: 1 2020-02-28 19:43:06.568729: I tensorflow/core/common_runtime/bfc_allocator.cc:619] Size: 1.62GiB | Requested Size: 80.0KiB | in_use: 0, prev: Size: 8.94GiB | Requested Size: 8.94GiB | in_use: 1 2020-02-28 19:43:06.568739: I tensorflow/core/common_runtime/bfc_allocator.cc:619] Size: 2.33GiB | Requested Size: 1.43GiB | in_use: 0, prev: Size: 1.19GiB | Requested Size: 1.19GiB | in_use: 1, next: Size: 2.33GiB | Requested Size: 2.33GiB | in_use: 1 2020-02-28 19:43:06.568776: I tensorflow/core/common_runtime/bfc_allocator.cc:619] Size: 4.57GiB | Requested Size: 4.57GiB | in_use: 0, prev: Size: 2.33GiB | Requested Size: 2.33GiB | in_use: 1, next: Size: 4.57GiB | Requested Size: 4.57GiB | in_use: 1 2020-02-28 19:43:06.568791: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7f566e000000 of size 1280 0x7f568efea100 of size 65536 2020-02-28 19:43:06.570830: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7f568effa100 of size 65536 2020-02-28 19:43:06.570835: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7f568f00a100 of size 65536 2020x7f568f3ea100 of size 524288 2020-02-28 19:43:06.571038: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7f568f46a100 of size 65536 202 2507372544 totalling 2.33GiB 2020-02-28 19:43:06.571302: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 1 Chunks of size 4908048384 totalling 4.57GiB 2020-02-28 19:43:06.571308: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 1 Chunks of size 9602703360 totalling 8.94GiB 2020-02-28 19:43:06.571314: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Sum Total of in-use chunks: 18.97GiB 2020-02-28 19:43:06.571322: I tensorflow/core/common_runtime/bfc_allocator.cc:647] Stats: Limit: 31952542106 InUse: 20365600256 MaxInUse: 20365600256 NumAllocs: 582 MaxAllocSize: 9602703360

2020-02-28 19:43:06.571344: W tensorflow/core/common_runtime/bfc_allocator.cc:271] ****_******___*****______*********_______________**********************************************_____ 2020-02-28 19:43:06.571376: W tensorflow/core/framework/op_kernel.cc:1273] OP_REQUIRES failed at conv_ops.cc:746 : Resource exhausted: OOM when allocating tensor with shape[2742,512,38,45] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc 2020-02-28 19:43:16.573348: W tensorflow/core/common_runtime/bfc_allocator.cc:267] Allocator (GPU_0_bfc) ran out of memory trying to allocate 17.49GiB. Current allocation summary follows. 2020-02-28 19:43:16.573412: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (256): Total Chunks: 147, Chunks in use: 145. 36.8KiB allocated for chunks. 36.2KiB in use in bin. 1.1KiB client-requested in use in bin. 2020-02-28 19:43:16.573425: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (512): Total Chunks: 19, Chunks in use: 17. 9.5KiB allocated for chunks. 8.5KiB in use in bin. 8.5KiB client-requested in use in bin. 2020-02-28 19:43:16.573434: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (1024): Total Chunks: 2, Chunks in use: 2. 2.2KiB allocated for chunks. 2.2KiB in use in bin. 2.0KiB client-requested in use in bin. 2020-02-28 19:43:16.573443: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (2048): Total Chunks: 24, Chunks in use: 22. 48.2KiB allocated for chunks. 44.0KiB in use in bin. 44.0KiB client-requested in use in bin. 2020-02-28 19:43:16.573453: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (4096): Total Chunks: 15, Chunks in use: 15. 60.0KiB allocated for chunks. 60.0KiB in use in bin. 60.0KiB client-requested in use in bin. 2020-02-28 19:43:16.573468: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (8192): Total Chunks: 11, Chunks in use: 6. 111.5KiB allocated for chunks. 53.5KiB in use in bin. 53.4KiB client-requested in use in bin. 2020-02-28 19:43:16.573478: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (16384): Total Chunks: 1, Chunks in use: 0. 16.2KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin. 2020-02-28 19:43:16.573486: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (32768): Total Chunks: 3, Chunks in use: 0. 96.2KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin. 2020-02-28 19:43:16.573494: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (65536): Total Chunks: 36, Chunks in use: 36. 2.27MiB allocated for chunks. 2.27MiB in use in bin. 2.25MiB client-requested in use in bin. 2020-02-28 19:43:16.573503: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (131072): Total Chunks: 17, Chunks in use: 16. 2.24MiB allocated for chunks. 2.00MiB in use in bin. 2.00MiB client-requested in use in bin. 2020-02-28 19:43:16.573512: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (262144): Total Chunks: 18, Chunks in use: 18. 4.69MiB allocated for chunks. 4.69MiB in use in bin. 4.69MiB client-requested in use in bin. 2020-02-28 19:43:16.573520: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (524288): Total Chunks: 30, Chunks in use: 28. 15.60MiB allocated for chunks. 14.59MiB in use in bin. 14.59MiB client-requested in use in bin. 2020-02-28 19:43:16.573528: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (1048576): Total Chunks: 1, Chunks in use: 0. 1.44MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin. 2020-02-28 19:43:16.573537: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (2097152): Total Chunks: 7, Chunks in use: 7. 14.00MiB allocated for chunks. 14.00MiB in use in bin. 14.00MiB client-requested in use in bin. 2020-02-28 19:43:16.573545: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (4194304): Total Chunks: 2, Chunks in use: 1. 8.00MiB allocated for chunks. 4.00MiB in use in bin. 4.00MiB client-requested in use in bin. 2020-02-28 19:43:16.573553: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (8388608): Total Chunks: 4, Chunks in use: 4. 32.00MiB allocated for chunks. 32.00MiB in use in bin. 32.00MiB client-requested in use in bin. 2020-02-28 19:43:16.573562: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (16777216): Total Chunks: 5, Chunks in use: 4. 80.00MiB allocated for chunks. 64.00MiB in use in bin. 64.00MiB client-requested in use in bin. 2020-02-28 19:43:16.573570: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (33554432): Total Chunks: 1, Chunks in use: 0. 32.02MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin. 2020-02-28 19:43:16.573579: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (67108864): Total Chunks: 5, Chunks in use: 4. 340.04MiB allocated for chunks. 256.00MiB in use in bin. 256.00MiB client-requested in use in bin. 2020-02-28 19:43:16.573587: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (134217728): Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin. 2020-02-28 19:43:16.573595: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (268435456): Total Chunks: 12, Chunks in use: 6. 29.24GiB allocated for chunks. 9.64GiB in use in bin. 9.64GiB client-requested in use in bin. 2020-02-28 19:43:16.573604: I tensorflow/core/common_runtime/bfc_allocator.cc:613] Bin for 17.49GiB was 256.00MiB, Chunk State: 2020-02-28 19:43:16.573618: I tensorflow/core/common_runtime/bfc_allocator.cc:619] Size: 317.98MiB | Requested Size: 317.98MiB | in_use: 0, prev: Size: 256B | Requested Size: 4B | in_use: 1, next: Size: 317.98MiB | Requested Size: 317.98MiB | in_use: 1 2020-02-28 19:43:16.573630: I tensorflow/core/common_runtime/bfc_allocator.cc:619] Size: 635.96MiB | Requested Size: 623.24MiB | in_use: 0, prev: Size: 317.98MiB | Requested Size: 317.98MiB | in_use: 1, next: Size: 635.96MiB | Requested Size: 635.96MiB | in_use: 1 2020-02-28 19:43:16.573641: I tensorflow/core/common_runtime/bfc_allocator.cc:619] Size: 1.19GiB | Requested Size: 1.17GiB | in_use: 0, prev: Size: 623.24MiB | Requested Size: 623.24MiB | in_use: 1, next: Size: 1.19GiB | Requested Size: 1.19GiB | in_use: 1 2020-02-28 19:43:16.573650: I tensorflow/core/common_runtime/bfc_allocator.cc:619] Size: 2.33GiB | Requested Size: 1.43GiB | in_use: 0, prev: Size: 1.19GiB | Requested Size: 1.19GiB | in_use: 1, next: Size: 2.33GiB | Requested Size: 2.33GiB | in_use: 1 2020-02-28 19:43:16.573695: I tensorflow/core/common_runtime/bfc_allocator.cc:619] Size: 4.57GiB | Requested Size: 4.57GiB | in_use: 0, prev: Size: 2.33GiB | Requested Size: 2.33GiB | in_use: 1, next: Size: 4.57GiB | Requested Size: 4.57GiB | in_use: 1 2020-02-28 19:43:16.573704: I tensorflow/core/common_runtime/bfc_allocator.cc:619] Size: 10.57GiB | Requested Size: 8.94GiB | in_use: 0, prev: Size: 4.57GiB | Requested Size: 4.57GiB | in_use: 1 2020-02-28 19:43:16.573714: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7f566e000000 of size 1280 2020-02-28 19:43:16.573720: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7f566e000500 of size 256

2020-02-28 19:43:16.576222: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 1 Chunks of size 1024 totalling 1.0KiB 666854400 totalling 635.96MiB 2020-02-28 19:43:16.576352: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 1 Chunks of size 1280360448 totalling 1.19GiB 2020-02-28 19:43:16.576358: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 1 Chunks of size 2507372544 totalling 2.33GiB 2020-02-28 19:43:16.576364: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 1 Chunks of size 4908048384 totalling 4.57GiB 2020-02-28 19:43:16.576371: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Sum Total of in-use chunks: 10.02GiB 2020-02-28 19:43:16.576380: I tensorflow/core/common_runtime/bfc_allocator.cc:647] Stats: Limit: 31952542106 InUse: 10762452480 MaxInUse: 20365600256 NumAllocs: 582 MaxAllocSize: 9602703360

2020-02-28 19:43:16.576403: W tensorflow/core/common_runtime/bfc_allocator.cc:271] ***************______*********_______________****************___________________________________ 2020-02-28 19:43:16.576430: W tensorflow/core/framework/op_kernel.cc:1273] OP_REQUIRES failed at conv_ops.cc:446 : Resource exhausted: OOM when allocating tensor with shape[2742,1024,38,44] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc Traceback (most recent call last): File ""bert_bilstm_softmax.py"", line 321, in model.fit(train_vectors, val_train_labels, epochs=nb_epoch,steps_per_epoch=1,validation_data=[test_vectors, val_test_labels],validation_steps=1) File ""/share/nishome/19930072_0/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/training.py"", line 1039, in fit validation_steps=validation_steps) File ""/share/nishome/19930072_0/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/training_arrays.py"", line 154, in fit_loop outs = f(ins) File ""/share/nishome/19930072_0/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py"", line 2715, in __call return self._call(inputs) File ""/share/nishome/19930072_0/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py"", line 2675, in _call fetched = self._callable_fn(*array_vals) File ""/share/nishome/19930072_0/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1439, in call run_metadata_ptr) File ""/share/nishome/19930072_0/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py"", line 528, in exit c_api.TF_GetCode(self.status.status)) tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[2742,512,38,45] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [[{{node module_apply_default/bilm/CNN/Conv2D_5}} = Conv2D[T=DT_FLOAT, data_format=""NCHW"", dilations=[1, 1, 1, 1], padding=""VALID"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](module_apply_default/bilm/CNN/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, module_apply_default/bilm/CNN/Conv2D_5/ReadVariableOp/_299)]] Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

 [[{{node bidirectional_2/transpose_4/_313}} = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_1962_bidirectional_2/transpose_4"", tensor_type=DT_BOOL, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info."
37161,Latest GPUDelegate from 'org.tensorflow:tensorflow-lite-gpu:0.0.0-nightly' crashes,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow):  No
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): 
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: All devices
- TensorFlow installed from (source or
binary): binary
- TensorFlow version (use command below):  'org.tensorflow:tensorflow-lite-gpu:0.0.0-nightly'
- Python version: - Bazel
version (if compiling from source):
- GCC/Compiler version (if compiling from
source): 
- CUDA/cuDNN version: - GPU model and memory:

**Describe the current behavior**
Android app crashes when using GPUDelegate from the latest nightly build.

**Describe the expected behavior**
It shouldn't crash.

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
```
Process: com.test.app, PID: 16875
    java.lang.UnsatisfiedLinkError: dlopen failed: cannot locate symbol ""_ZTVN6tflite3gpu2cl12SpaceToDepthE"" referenced by ""/data/app/com.test.app-ujX5oxWg44XmBTPZMarXvQ==/base.apk!/lib/arm64-v8a/libtensorflowlite_gpu_jni.so""...
        at java.lang.Runtime.loadLibrary0(Runtime.java:1071)
        at java.lang.Runtime.loadLibrary0(Runtime.java:1007)
        at java.lang.System.loadLibrary(System.java:1667)
```
"
37160,Thread leakage in TF2.1,"**System information** 
Red Hat Enterprise Linux Server release 7.7 (Maipo)

- TensorFlow in docker container (nvcr.io/nvidia/tensorflow:20.01-tf2-py3 and tensorflow/tensorflow:2.1.0-gpu-py3-jupyter): - TensorFlow version: 2.1.0

- Python version: 3.6.9

- CUDA/cuDNN version: - GPU model and memory: CUDA 10.2, libcudnn.so.7, DGX-1 server with 8xTesla V100-SXM2 (32GB)

**Describe the current behavior**

When executing the following jupyter block in TF2.1, we experience thread leakage that results in a crash after around 720 epochs. It seems that with every epoch, 5-6 new threads are created that are never cleaned up.

```
Thistory = []

history = model.fit(trnx, trny, 
          epochs=1000,                   # doesn't seem to make any difference
          batch_size = 1024,            # affects GPU utilization
          validation_split=0.06,        # , (note comma!) # use 6% for validation
          class_weight={0:1, 1:50.0}, # Pay a lot more attention to Class ""1""
         )

Thistory.append(history)
```
When examining the core dump, we see that at the time of the crash approx. 4090 threads have been created and the backtrace of the crashing thread looks like this:

```
(gdb) bt
#0  __GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:51
#1  0x00007fd6d9854801 in __GI_abort () at abort.c:79
#2  0x00007fd6d3d32c02 in __gnu_cxx::__verbose_terminate_handler() () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6
#3  0x00007fd6d3d30ab6 in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6
#4  0x00007fd6d3d30af1 in std::terminate() () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6
#5  0x00007fd6a19ab3de in std::execute_native_thread_routine (__p=0x8f947540) at /dt7-src/libstdc++-v3/src/nonshared11/../c++11/thread.cc:91
#6  0x00007fd6d95fc6db in start_thread (arg=0x7fc6b3fff700) at pthread_create.c:463
#7  0x00007fd6d993588f in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:95
```
Here is the full log of the failing run:

```
Feb 27 16:08:03 bash[4775]: ================
Feb 27 16:08:03 bash[4775]: == TensorFlow ==
Feb 27 16:08:03 bash[4775]: ================
Feb 27 16:08:03 bash[4775]: NVIDIA Release 20.02-tf2 (build 9892252)
Feb 27 16:08:03 bash[4775]: TensorFlow Version 2.1.0
Feb 27 16:08:03 bash[4775]: Container image Copyright (c) 2019, NVIDIA CORPORATION.  All rights reserved.
Feb 27 16:08:03 bash[4775]: Copyright 2017-2019 The TensorFlow Authors.  All rights reserved.
Feb 27 16:08:03 bash[4775]: Various files include modifications (c) NVIDIA CORPORATION.  All rights reserved.
Feb 27 16:08:03 bash[4775]: NVIDIA modifications are covered by the license terms that apply to the underlying project or file
.
Feb 27 16:08:03 bash[4775]: NOTE: Legacy NVIDIA Driver detected.  Compatibility mode ENABLED.
Feb 27 16:08:03 bash[4775]: NOTE: Detected MOFED driver 5.0-0; version automatically updated.
Feb 27 16:08:03 bash[4775]: NOTE: MOFED driver was detected, but nv_peer_mem driver was not detected.
Feb 27 16:08:03 bash[4775]: Multi-node communication performance may be reduced.
Feb 27 16:08:05 bash[4775]: 2020-02-27 16:08:05.294586: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Succes
sfully opened dynamic library libcudart.so.10.2
Feb 27 16:08:06 bash[4775]: 2020-02-27 16:08:06.049185: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Succes
sfully opened dynamic library libnvinfer.so.7
Feb 27 16:08:06 bash[4775]: 2020-02-27 16:08:06.050172: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Succes
sfully opened dynamic library libnvinfer_plugin.so.7
Feb 27 16:08:06 bash[4775]: [I 16:08:06.830 NotebookApp] jupyter_tensorboard extension loaded.
Feb 27 16:08:06 bash[4775]: [I 16:08:06.862 NotebookApp] JupyterLab extension loaded from /usr/local/lib/python3.6/dist-packag
es/jupyterlab
Feb 27 16:08:06 bash[4775]: [I 16:08:06.862 NotebookApp] JupyterLab application directory is /usr/local/share/jupyter/lab
Feb 27 16:08:06 bash[4775]: [I 16:08:06.864 NotebookApp] [Jupytext Server Extension] NotebookApp.contents_manager_class is (a
subclass of) jupytext.TextFileContentsManager already - OK
Feb 27 16:08:06 bash[4775]: [I 16:08:06.865 NotebookApp] Serving notebooks from local directory: /home/xxxxxx
Feb 27 16:08:06 bash[4775]: [I 16:08:06.865 NotebookApp] The Jupyter Notebook is running at:
Feb 27 16:08:06 bash[4775]: [I 16:08:06.865 NotebookApp] http://hostname:8888/
Feb 27 16:08:06 bash[4775]: [I 16:08:06.865 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to
 skip confirmation).
Feb 27 16:08:30 bash[4775]: [W 16:08:30.916 NotebookApp] 404 GET /api/kernels/2a8b1a39-d9f0-48f5-8b4d-7bc1188a06c4/channels?se
ssion_id=7c85bda7cc01423c89e3b2d4652db535 (172.27.68.155): Kernel does not exist: 2a8b1a39-d9f0-48f5-8b4d-7bc1188a06c4
Feb 27 16:08:30 bash[4775]: [W 16:08:30.944 NotebookApp] 404 GET /api/kernels/2a8b1a39-d9f0-48f5-8b4d-7bc1188a06c4/channels?se
ssion_id=7c85bda7cc01423c89e3b2d4652db535 (172.27.68.155) 38.39ms referer=None
Feb 27 16:08:50 bash[4775]: [W 16:08:50.358 NotebookApp] 404 GET /nbconvert/html/Notebooks/custom.css (172.27.68.155): No such
 file or directory: Notebooks/custom.css
Feb 27 16:08:50 bash[4775]: [W 16:08:50.359 NotebookApp] 404 GET /nbconvert/html/Notebooks/custom.css (172.27.68.155) 13.11ms
referer=None
Feb 27 16:08:51 bash[4775]: [I 16:08:51.706 NotebookApp] Kernel started: 5ff3ace7-0cf6-4cd1-8610-1b721b134801
Feb 27 16:08:51 bash[4775]: [W 16:08:51.713 NotebookApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=202002271608
04 (172.27.68.155) 3.03ms referer=http://dls007.idc.ctbto.org:8888/notebooks/Notebooks/20200225A.ipynb
Feb 27 16:08:52 bash[4775]: [IPKernelApp] WARNING | Could not set permissions on /home/xxxxxx/.ipython/profile_default/securit
y
Feb 27 16:08:52 bash[4775]: [IPKernelApp] WARNING | Could not set permissions on /home/xxxxxx/.ipython/profile_default/pid
Feb 27 16:08:52 bash[4775]: [IPKernelApp] WARNING | Could not set permissions on /home/xxxxxx/.ipython/profile_default/securit
y
Feb 27 16:08:52 bash[4775]: [IPKernelApp] WARNING | Could not set permissions on /home/xxxxxx/.ipython/profile_default/pid
Feb 27 16:08:56 bash[4775]: [I 16:08:56.902 NotebookApp] Saving file at /Notebooks/20200225A.ipynb
Feb 27 16:08:56 bash[4775]: [I 16:08:56.903 NotebookApp] Saving 20200225A.ipynb
Feb 27 16:09:07 bash[4775]: [W 16:09:07.039 NotebookApp] 404 GET /api/contents/Notebooks/20200227B.ipynb?type=notebook&content
=0&_=1582819731172 (172.27.68.155): No such file or directory: Notebooks/20200227B.ipynb
Feb 27 16:09:07 bash[4775]: [W 16:09:07.040 NotebookApp] No such file or directory: Notebooks/20200227B.ipynb
Feb 27 16:09:07 bash[4775]: [W 16:09:07.041 NotebookApp] 404 GET /api/contents/Notebooks/20200227B.ipynb?type=notebook&content
=0&_=1582819731172 (172.27.68.155) 1.91ms referer=http://dls007.idc.ctbto.org:8888/notebooks/Notebooks/20200225A.ipynb
Feb 27 16:09:07 bash[4775]: [I 16:09:07.060 NotebookApp] Uploading file to /Notebooks/20200227B.ipynb
Feb 27 16:09:07 bash[4775]: [I 16:09:07.061 NotebookApp] Saving 20200227B.ipynb
Feb 27 16:09:11 bash[4775]: [I 16:09:11.094 NotebookApp] Saving file at /Notebooks/20200227B.ipynb
Feb 27 16:09:11 bash[4775]: [I 16:09:11.095 NotebookApp] Saving 20200227B.ipynb
Feb 27 16:09:13 bash[4775]: 2020-02-27 16:09:13.621022: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Succes
sfully opened dynamic library libcudart.so.10.2
Feb 27 16:09:14 bash[4775]: 2020-02-27 16:09:14.257420: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Succes
sfully opened dynamic library libnvinfer.so.7
Feb 27 16:09:14 bash[4775]: 2020-02-27 16:09:14.258187: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Succes
sfully opened dynamic library libnvinfer_plugin.so.7
Feb 27 16:10:51 bash[4775]: [I 16:10:51.723 NotebookApp] Saving file at /Notebooks/20200227B.ipynb
Feb 27 16:10:51 bash[4775]: [I 16:10:51.723 NotebookApp] Saving 20200227B.ipynb
Feb 27 16:11:44 bash[4775]: 2020-02-27 16:11:44.933864: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Succes
sfully opened dynamic library libcuda.so.1
Feb 27 16:11:45 bash[4775]: 2020-02-27 16:11:45.339561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device
0 with properties:
Feb 27 16:11:45 bash[4775]: pciBusID: 0000:06:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
Feb 27 16:11:45 bash[4775]: coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s
Feb 27 16:11:45 bash[4775]: 2020-02-27 16:11:45.341723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device
1 with properties:
Feb 27 16:11:45 bash[4775]: pciBusID: 0000:07:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
Feb 27 16:11:45 bash[4775]: coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s
Feb 27 16:11:45 bash[4775]: 2020-02-27 16:11:45.343843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device
2 with properties:
Feb 27 16:11:45 bash[4775]: pciBusID: 0000:0a:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
Feb 27 16:11:45 bash[4775]: coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s
Feb 27 16:11:45 bash[4775]: 2020-02-27 16:11:45.346002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device
3 with properties:
Feb 27 16:11:45 bash[4775]: pciBusID: 0000:0b:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
Feb 27 16:11:45 bash[4775]: coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s
Feb 27 16:11:45 bash[4775]: 2020-02-27 16:11:45.348146: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device
4 with properties:
Feb 27 16:11:45 bash[4775]: pciBusID: 0000:85:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
Feb 27 16:11:45 bash[4775]: coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s
Feb 27 16:11:45 bash[4775]: 2020-02-27 16:11:45.350207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device
5 with properties:
Feb 27 16:11:45 bash[4775]: pciBusID: 0000:86:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
Feb 27 16:11:45 bash[4775]: coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s
Feb 27 16:11:45 bash[4775]: 2020-02-27 16:11:45.352268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device
6 with properties:
Feb 27 16:11:45 bash[4775]: pciBusID: 0000:89:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
Feb 27 16:11:45 bash[4775]: coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s
Feb 27 16:11:45 bash[4775]: 2020-02-27 16:11:45.354321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device
7 with properties:
Feb 27 16:11:45 bash[4775]: pciBusID: 0000:8a:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
Feb 27 16:11:45 bash[4775]: coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s
Feb 27 16:11:45 bash[4775]: 2020-02-27 16:11:45.354367: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Succes
sfully opened dynamic library libcudart.so.10.2
Feb 27 16:11:45 bash[4775]: 2020-02-27 16:11:45.354408: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Succes
sfully opened dynamic library libcublas.so.10
Feb 27 16:11:45 bash[4775]: 2020-02-27 16:11:45.359249: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Succes
sfully opened dynamic library libcufft.so.10
Feb 27 16:11:45 bash[4775]: 2020-02-27 16:11:45.362850: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Succes
sfully opened dynamic library libcurand.so.10
Feb 27 16:11:45 bash[4775]: 2020-02-27 16:11:45.373520: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
Feb 27 16:11:45 bash[4775]: 2020-02-27 16:11:45.376601: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
Feb 27 16:11:45 bash[4775]: 2020-02-27 16:11:45.376650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
Feb 27 16:11:45 bash[4775]: 2020-02-27 16:11:45.408041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
Feb 27 16:11:45 bash[4775]: 2020-02-27 16:11:45.420281: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2194960000 Hz
Feb 27 16:11:45 bash[4775]: 2020-02-27 16:11:45.425679: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x49acb80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
Feb 27 16:11:45 bash[4775]: 2020-02-27 16:11:45.425704: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Feb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.086025: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f1428005760 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
Feb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.086061: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
Feb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.086071: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Tesla V100-SXM2-32GB, Compute Capability 7.0
Feb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.086079: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): Tesla V100-SXM2-32GB, Compute Capability 7.0
Feb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.086087: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): Tesla V100-SXM2-32GB, Compute Capability 7.0
Feb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.086096: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (4): Tesla V100-SXM2-32GB, Compute Capability 7.0
Feb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.086125: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (5): Tesla V100-SXM2-32GB, Compute Capability 7.0
Feb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.086151: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (6): Tesla V100-SXM2-32GB, Compute Capability 7.0
Feb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.086181: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (7): Tesla V100-SXM2-32GB, Compute Capability 7.0
Feb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.093006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:
Feb 27 16:11:47 bash[4775]: pciBusID: 0000:06:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
Feb 27 16:11:47 bash[4775]: coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s
Feb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.095291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 1 with properties:
Feb 27 16:11:47 bash[4775]: pciBusID: 0000:07:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
Feb 27 16:11:47 bash[4775]: coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s
Feb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.097537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 2 with properties:
Feb 27 16:11:47 bash[4775]: pciBusID: 0000:0a:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
Feb 27 16:11:47 bash[4775]: coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s
Feb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.099773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 3 with properties:
Feb 27 16:11:47 bash[4775]: pciBusID: 0000:0b:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
Feb 27 16:11:47 bash[4775]: coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s
Feb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.102139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 4 with properties:
Feb 27 16:11:47 bash[4775]: pciBusID: 0000:85:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
Feb 27 16:11:47 bash[4775]: coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s
Feb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.104446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 5 with properties:
Feb 27 16:11:47 bash[4775]: pciBusID: 0000:86:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
Feb 27 16:11:47 bash[4775]: coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s
Feb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.106721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 6 with properties:
Feb 27 16:11:47 bash[4775]: pciBusID: 0000:89:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
Feb 27 16:11:47 bash[4775]: coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s
Feb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.109273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 7 with properties:
Feb 27 16:11:47 bash[4775]: pciBusID: 0000:8a:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
Feb 27 16:11:47 bash[4775]: coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s
Feb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.109329: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.2
Feb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.109349: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
Feb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.109369: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
Feb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.109392: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
Feb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.109409: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
Feb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.109425: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
Feb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.109439: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
Feb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.146520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
Feb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.146574: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.2
Feb 27 16:11:53 bash[4775]: 2020-02-27 16:11:53.978874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
Feb 27 16:11:53 bash[4775]: 2020-02-27 16:11:53.978919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 1 2 3 4 5 6 7
Feb 27 16:11:53 bash[4775]: 2020-02-27 16:11:53.978949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N Y Y Y Y N N N
Feb 27 16:11:53 bash[4775]: 2020-02-27 16:11:53.978960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 1:   Y N Y Y N Y N N
Feb 27 16:11:53 bash[4775]: 2020-02-27 16:11:53.978989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 2:   Y Y N Y N N Y N
Feb 27 16:11:53 bash[4775]: 2020-02-27 16:11:53.978998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 3:   Y Y Y N N N N Y
Feb 27 16:11:53 bash[4775]: 2020-02-27 16:11:53.979028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 4:   Y N N N N Y Y Y
Feb 27 16:11:53 bash[4775]: 2020-02-27 16:11:53.979037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 5:   N Y N N Y N Y Y
Feb 27 16:11:53 bash[4775]: 2020-02-27 16:11:53.979049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 6:   N N Y N Y Y N Y
Feb 27 16:11:53 bash[4775]: 2020-02-27 16:11:53.979058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 7:   N N N Y Y Y Y N
Feb 27 16:11:54 bash[4775]: 2020-02-27 16:11:54.009417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29967 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:06:00.0, compute capability: 7.0)
Feb 27 16:11:54 bash[4775]: 2020-02-27 16:11:54.013256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 29967 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:07:00.0, compute capability: 7.0)
Feb 27 16:11:54 bash[4775]: 2020-02-27 16:11:54.016950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 29967 MB memory) -> physical GPU (device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:0a:00.0, compute capability: 7.0)
Feb 27 16:11:54 bash[4775]: 2020-02-27 16:11:54.020472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 29967 MB memory) -> physical GPU (device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:0b:00.0, compute capability: 7.0)
Feb 27 16:11:54 bash[4775]: 2020-02-27 16:11:54.023913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:4 with 29967 MB memory) -> physical GPU (device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:85:00.0, compute capability: 7.0)
Feb 27 16:11:54 bash[4775]: 2020-02-27 16:11:54.027396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:5 with 29967 MB memory) -> physical GPU (device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:86:00.0, compute capability: 7.0)
Feb 27 16:11:54 bash[4775]: 2020-02-27 16:11:54.030902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:6 with 29967 MB memory) -> physical GPU (device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:89:00.0, compute capability: 7.0)
Feb 27 16:11:54 bash[4775]: 2020-02-27 16:11:54.034514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:7 with 29967 MB memory) -> physical GPU (device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:8a:00.0, compute capability: 7.0)
Feb 27 16:12:48 bash[4775]: 2020-02-27 16:12:48.633652: W tensorflow/core/grappler/optimizers/meta_optimizer.cc:147] TF_ENABLE_AUTO_MIXED_PRECISION has no effect.
Feb 27 16:12:49 bash[4775]: 2020-02-27 16:12:49.700819: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:
Feb 27 16:12:49 bash[4775]: Total processable nodes: 13403
Feb 27 16:12:49 bash[4775]: Recognized nodes available for conversion: 8834
Feb 27 16:12:49 bash[4775]: Total nodes converted: 1104
Feb 27 16:12:49 bash[4775]: Total FP16 Cast ops used (excluding Const and Variable casts): 120
Feb 27 16:12:49 bash[4775]: Whitelisted nodes converted: 272
Feb 27 16:12:49 bash[4775]: Blacklisted nodes blocking conversion: 432
Feb 27 16:12:49 bash[4775]: Nodes blocked from conversion by blacklisted nodes: 1072
Feb 27 16:12:49 bash[4775]: For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
Feb 27 16:12:49 bash[4775]: https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp
Feb 27 16:12:51 bash[4775]: [I 16:12:51.706 NotebookApp] Saving file at /Notebooks/20200227B.ipynb
Feb 27 16:12:51 bash[4775]: [I 16:12:51.707 NotebookApp] Saving 20200227B.ipynb
Feb 27 16:12:52 bash[4775]: 2020-02-27 16:12:52.343735: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
Feb 27 16:12:54 bash[4775]: 2020-02-27 16:12:54.744883: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
Feb 27 16:13:08 bash[4775]: libibverbs: Warning: no userspace device-specific driver found for /sys/class/infiniband_verbs/uverbs3
Feb 27 16:13:08 bash[4775]: libibverbs: Warning: no userspace device-specific driver found for /sys/class/infiniband_verbs/uverbs2
Feb 27 16:13:08 bash[4775]: libibverbs: Warning: no userspace device-specific driver found for /sys/class/infiniband_verbs/uverbs1
Feb 27 16:13:08 bash[4775]: libibverbs: Warning: no userspace device-specific driver found for /sys/class/infiniband_verbs/uverbs0
Feb 27 16:13:21 bash[4775]: 2020-02-27 16:13:21.697661: W tensorflow/core/grappler/optimizers/meta_optimizer.cc:147] TF_ENABLE_AUTO_MIXED_PRECISION has no effect.
Feb 27 16:13:21 bash[4775]: 2020-02-27 16:13:21.877836: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:
Feb 27 16:13:21 bash[4775]: Total processable nodes: 2754
Feb 27 16:13:21 bash[4775]: Recognized nodes available for conversion: 1796
Feb 27 16:13:21 bash[4775]: Total nodes converted: 496
Feb 27 16:13:21 bash[4775]: Total FP16 Cast ops used (excluding Const and Variable casts): 64
Feb 27 16:13:21 bash[4775]: Whitelisted nodes converted: 80
Feb 27 16:13:21 bash[4775]: Blacklisted nodes blocking conversion: 64
Feb 27 16:13:21 bash[4775]: Nodes blocked from conversion by blacklisted nodes: 8
Feb 27 16:13:21 bash[4775]: For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
Feb 27 16:13:21 bash[4775]: https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp
Feb 27 16:13:45 bash[4775]: [I 16:13:45.930 NotebookApp] Kernel interrupted: 5ff3ace7-0cf6-4cd1-8610-1b721b134801
Feb 27 16:14:51 bash[4775]: [I 16:14:51.673 NotebookApp] Saving file at /Notebooks/20200227B.ipynb
Feb 27 16:14:51 bash[4775]: [I 16:14:51.674 NotebookApp] Saving 20200227B.ipynb
Feb 27 16:15:18 bash[4775]: 2020-02-27 16:15:18.903125: W tensorflow/core/grappler/optimizers/meta_optimizer.cc:147] TF_ENABLE_AUTO_MIXED_PRECISION has no effect.
Feb 27 16:15:19 bash[4775]: 2020-02-27 16:15:19.989487: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:
Feb 27 16:15:19 bash[4775]: Total processable nodes: 13403
Feb 27 16:15:19 bash[4775]: Recognized nodes available for conversion: 8834
Feb 27 16:15:19 bash[4775]: Total nodes converted: 1104
Feb 27 16:15:19 bash[4775]: Total FP16 Cast ops used (excluding Const and Variable casts): 120
Feb 27 16:15:19 bash[4775]: Whitelisted nodes converted: 272
Feb 27 16:15:19 bash[4775]: Blacklisted nodes blocking conversion: 432
Feb 27 16:15:19 bash[4775]: Nodes blocked from conversion by blacklisted nodes: 1072
Feb 27 16:15:19 bash[4775]: For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
Feb 27 16:15:19 bash[4775]: https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp
Feb 27 16:15:33 bash[4775]: 2020-02-27 16:15:33.431854: W tensorflow/core/grappler/optimizers/meta_optimizer.cc:147] TF_ENABLE_AUTO_MIXED_PRECISION has no effect.
Feb 27 16:15:33 bash[4775]: 2020-02-27 16:15:33.612105: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:
Feb 27 16:15:33 bash[4775]: Total processable nodes: 2754
Feb 27 16:15:33 bash[4775]: Recognized nodes available for conversion: 1796
Feb 27 16:15:33 bash[4775]: Total nodes converted: 496
Feb 27 16:15:33 bash[4775]: Total FP16 Cast ops used (excluding Const and Variable casts): 64
Feb 27 16:15:33 bash[4775]: Whitelisted nodes converted: 80
Feb 27 16:15:33 bash[4775]: Blacklisted nodes blocking conversion: 64
Feb 27 16:15:33 bash[4775]: Nodes blocked from conversion by blacklisted nodes: 8
Feb 27 16:15:33 bash[4775]: For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
Feb 27 16:15:33 bash[4775]: https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp
Feb 27 16:16:51 bash[4775]: [I 16:16:51.865 NotebookApp] Saving file at /Notebooks/20200227B.ipynb
Feb 27 16:16:51 bash[4775]: [I 16:16:51.865 NotebookApp] Saving 20200227B.ipynb
Feb 27 16:18:51 bash[4775]: [I 16:18:51.884 NotebookApp] Saving file at /Notebooks/20200227B.ipynb
...
Feb 27 18:14:51 bash[4775]: [I 18:14:51.705 NotebookApp] Saving file at /Notebooks/20200227B.ipynb
Feb 27 18:14:51 bash[4775]: [I 18:14:51.706 NotebookApp] Saving 20200227B.ipynb
Feb 27 18:15:09 bash[4775]: terminate called after throwing an instance of 'std::system_error'
Feb 27 18:15:09 bash[4775]: what():  Resource temporarily unavailable
Feb 27 18:16:00 bash[4775]: [I 18:16:00.707 NotebookApp] KernelRestarter: restarting kernel (1/5), keep random ports
Feb 27 18:16:00 bash[4775]: WARNING:root:kernel 5ff3ace7-0cf6-4cd1-8610-1b721b134801 restarted
Feb 27 18:16:01 bash[4775]: [IPKernelApp] WARNING | Could not set permissions on /home/xxxxxx/.ipython/profile_default/security
Feb 27 18:16:01 bash[4775]: [IPKernelApp] WARNING | Could not set permissions on /home/xxxxxx/.ipython/profile_default/pid
Feb 27 18:16:01 bash[4775]: [IPKernelApp] WARNING | Could not set permissions on /home/xxxxxx/.ipython/profile_default/security
Feb 27 18:16:01 bash[4775]: [IPKernelApp] WARNING | Could not set permissions on /home/xxxxxx/.ipython/profile_default/pid
Feb 27 18:16:51 bash[4775]: [I 18:16:51.672 NotebookApp] Saving file at /Notebooks/20200227B.ipynb
Feb 27 18:16:51 bash[4775]: [I 18:16:51.672 NotebookApp] Saving 20200227B.ipynb

```

**Describe the expected behavior**

The notebook runs through 1000 epochs without any problems in TF 2.0. The maximum thread count that is observed with TF2.0 is approx 950.

"
37159,Plotting Data Using model.predict,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): **YES**
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): **MacOS CATALINA**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
- TensorFlow installed from (source or
binary): **BINARY**
- TensorFlow version (use command below): 2.1
- Python version: 3.7.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from
source): 
- CUDA/cuDNN version: 10.2
- GPU model and memory:

**Describe the current behavior**

I am attempting to plot the prediction values .  However predictions is 2-D and the data must be one dimensional. 

Here is the predictions code:
```
#Get predicted price values
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)
print(predictions.shape)

#get root mean squared error
rmse = np.sqrt(((predictions - y_test) ** 2).mean())
print(rmse)

#Plot the data
train = data[:training_data_len]
valid = data[training_data_len:]
valid['Predictions'] = predictions

#Visualize the data
plt.figure(figsize=(16,8))
plt.title('Model')
plt.xlabel('Date', fontsize=18)
plt.ylabel('Close Price USD ($)', fontsize=18)
plt.plot(train['Close'])
plt.plot(valid[['Close', 'Predictions']])
plt.legend(['Train', 'Val', 'Predictions'], loc='lower right')
plt.show()
```
**Describe the expected behavior**

This should just return a graph of the predicted values.  Instead I receive the following error.
```
Traceback (most recent call last):
  File ""/Users/owner/Desktop/algo/predict.py"", line 120, in <module>
    valid['Predictions'] = predictions
  File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3487, in __setitem__
    self._set_item(key, value)
  File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3563, in _set_item
    self._ensure_valid_index(value)
  File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3540, in _ensure_valid_index
    value = Series(value)
  File ""/usr/local/lib/python3.7/site-packages/pandas/core/series.py"", line 314, in __init__
    data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True)
  File ""/usr/local/lib/python3.7/site-packages/pandas/core/internals/construction.py"", line 729, in sanitize_array
    raise Exception(""Data must be 1-dimensional"")
Exception: Data must be 1-dimensional
```

How can I change predictions to make it 1-D?
Thank You,
RRR."
37158,Saving and loading nested models fails,"**EDIT:** I adjusted the bug description the bug appears in a different place than I thought before.

**System information** 
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): unknown 2.1.0 (Installation from conda repository)
- Python version: 3.7.6
- Bazel version (if compiling from source): -
- GCC/Compiler version (if compiling from source): -
- CUDA/cuDNN version: -
- GPU model and memory: -

**Describe the current behavior**
I created a simple nested tensorflow.keras model with an input node and sequential model containing two convolutional layers:
```python
import tensorflow as tf
model_inside = tf.keras.models.Sequential([tf.keras.layers.Conv2D(16, 3, input_shape=(None,None,1)),
                                   tf.keras.layers.Conv2D(2, 1, activation='softmax')])

model_outside_input = tf.keras.Input(shape=(256, 256, 1))
model_outside = model_inside(model_outside_input)

model_outside = tf.keras.models.Model(inputs=model_outside_input, outputs=model_outside)
```
Saving this model to disk in SavedModel format and loading it again results in a `TypeError: list indices must be integers or slices, not NoneType`.
According to my observations this error only occurs with nested models.

**Describe the expected behavior**
I expect the loaded model to be exactly the same as before saving it and loading should not lead to an error.

**Standalone code to reproduce the issue** 
https://colab.research.google.com/drive/1Qu32g7WpH_mVtwEvRToueF_Q8SMNMlf3"
37157,Problem with Himax HM01B0 camera on the Sparkfun Edge board,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution: Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): Cloned from source, but not installed
- TensorFlow version (commit SHA if source): 642708d2121976c8dbc0e8d0ae73fcf1cf027bd8
- Target platform: Sparkfun Edge

I'm trying to run an image classification model on a Sparkfun Edge, starting from the [person_detection](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro/examples/person_detection) example available in this repository. The logic for acquiring and resizing an image from the camera (Himax HM01B0) is included in `himax_driver/HM01B0_optimized.c`. For some reason, if I specify an image size greater than 102x102, the resulting image is padded with zeros in each of its four sides, yet the camera I'm using has a maximum pixel resolution of 320x320, as mentioned in the [official website](https://www.himax.com.tw/products/cmos-image-sensor/image-sensors/hm01b0/). 
Here's what I mean:

### 102x102 image:
![102x102](https://user-images.githubusercontent.com/30210403/75526152-86c19980-5a11-11ea-8bc6-47efdecaa7db.jpg)

### 320x320 image:
![320x320](https://user-images.githubusercontent.com/30210403/75526193-98a33c80-5a11-11ea-9b9f-171d4564e867.jpg)

**Please provide the exact sequence of commands/steps when you ran into the problem**
I simply passed `w=320`, `h=320` and `channels=1` to the function `hm01b0_blocking_read_oneframe_scaled` defined in `himax_driver/HM01B0_optimized.c`, printed each pixel value over the serial port and finally parsed such pixels with a Python script, displaying the resulting image.
"
37156,Tensorflow 2 installation problem in windows 10,"(base) C:\Windows\system32>pip install tensorflow
Collecting tensorflow
  Using cached tensorflow-2.1.0-cp37-cp37m-win_amd64.whl (355.8 MB)
Requirement already satisfied: absl-py>=0.7.0 in c:\programdata\anaconda3\lib\site-packages (from tensorflow) (0.8.1)
Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in c:\programdata\anaconda3\lib\site-packages (from tensorflow) (2.1.0)
Requirement already satisfied: keras-applications>=1.0.8 in c:\programdata\anaconda3\lib\site-packages (from tensorflow) (1.0.8)
Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in c:\programdata\anaconda3\lib\site-packages (from tensorflow) (2.1.0)
Requirement already satisfied: termcolor>=1.1.0 in c:\programdata\anaconda3\lib\site-packages (from tensorflow) (1.1.0)
Requirement already satisfied: wrapt>=1.11.1 in c:\programdata\anaconda3\lib\site-packages (from tensorflow) (1.11.2)
Requirement already satisfied: six>=1.12.0 in c:\programdata\anaconda3\lib\site-packages (from tensorflow) (1.14.0)
Requirement already satisfied: wheel>=0.26; python_version >= ""3"" in c:\programdata\anaconda3\lib\site-packages (from tensorflow) (0.34.2)
Requirement already satisfied: grpcio>=1.8.6 in c:\programdata\anaconda3\lib\site-packages (from tensorflow) (1.25.0)
Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\programdata\anaconda3\lib\site-packages (from tensorflow) (1.18.1)
Requirement already satisfied: scipy==1.4.1; python_version >= ""3"" in c:\programdata\anaconda3\lib\site-packages (from tensorflow) (1.4.1)
Requirement already satisfied: gast==0.2.2 in c:\programdata\anaconda3\lib\site-packages (from tensorflow) (0.2.2)
Requirement already satisfied: google-pasta>=0.1.6 in c:\programdata\anaconda3\lib\site-packages (from tensorflow) (0.1.8)
Requirement already satisfied: protobuf>=3.8.0 in c:\programdata\anaconda3\lib\site-packages (from tensorflow) (3.11.1)
Requirement already satisfied: opt-einsum>=2.3.2 in c:\programdata\anaconda3\lib\site-packages (from tensorflow) (3.1.0)
Requirement already satisfied: astor>=0.6.0 in c:\programdata\anaconda3\lib\site-packages (from tensorflow) (0.8.1)
Requirement already satisfied: keras-preprocessing>=1.1.0 in c:\programdata\anaconda3\lib\site-packages (from tensorflow) (1.1.0)
Requirement already satisfied: h5py in c:\programdata\anaconda3\lib\site-packages (from keras-applications>=1.0.8->tensorflow) (2.10.0)
Requirement already satisfied: requests<3,>=2.21.0 in c:\programdata\anaconda3\lib\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.22.0)
Requirement already satisfied: google-auth<2,>=1.6.3 in c:\programdata\anaconda3\lib\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.9.0)
Requirement already satisfied: markdown>=2.6.8 in c:\programdata\anaconda3\lib\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (3.2.1)
Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\programdata\anaconda3\lib\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.1)
Requirement already satisfied: setuptools>=41.0.0 in c:\programdata\anaconda3\lib\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (45.2.0.post20200210)
Requirement already satisfied: werkzeug>=0.11.15 in c:\programdata\anaconda3\lib\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.0.0)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\programdata\anaconda3\lib\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.25.8)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\programdata\anaconda3\lib\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)
Requirement already satisfied: certifi>=2017.4.17 in c:\programdata\anaconda3\lib\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2019.11.28)
Requirement already satisfied: idna<2.9,>=2.5 in c:\programdata\anaconda3\lib\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.8)
Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\programdata\anaconda3\lib\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.2.7)
Requirement already satisfied: cachetools<3.2,>=2.0.0 in c:\programdata\anaconda3\lib\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.1)
Requirement already satisfied: rsa<4.1,>=3.1.4 in c:\programdata\anaconda3\lib\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0)
Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\programdata\anaconda3\lib\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.3.0)
Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\programdata\anaconda3\lib\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.8)
Requirement already satisfied: oauthlib>=3.0.0 in c:\programdata\anaconda3\lib\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.0)
Installing collected packages: tensorflow
Successfully installed tensorflow-2.1.0

(base) C:\Windows\system32>python
Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)] :: Anaconda, Inc. on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\ProgramData\Anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\ProgramData\Anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\ProgramData\Anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\ProgramData\Anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\ProgramData\Anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.



My System Configuration:
Acer Predator PHP315-51, Intel i5-8300H CPU @ 2.3GHz, 8gb RAM, Windows 10 64-bit, NVIDIA GeForce GTX 1050 Ti GPU.

"
37154,Issues in usage of hexagon delegate in raspi(armv7) and hikey(aarch64).,"I was running label_image.cpp tflite example. I was modifying some of the default parameters and trying to make use of them. I am also trying to make use of hexagon delegate API in raspi, Hikey boards. 

I have few queries in the example.
1. In documentation, it is mentioned the Hexagon Delegate API works in Qualcomm specific processors such as snapdragon 660,835 etc.. If I have development board having Qualcomm mentioned processors with Linux os installed. Could I be able to make use of it ?

2. The Tflite model expects input mean and std deviation to be specified. 
**Is this input mean and std deviation setting varies from model to model?**
**How to know what mean and std deviation to be kept to get better classification results based on model ?**
For Quantized models, We are not using mean and std deviation?
**Why is this only required for float models but not Quantized models ?**

3. what does **allow_fp16** ideally does ? I tried to use this flag but even after setting to true, didn't notice any difference in memory , performance and even interpreter state. 

In documentation, It is mentioned as it does fp16  precision calculations even for fp32. But interpreter tensors are always created in fp32(but not fp16).
**What happens when we use this flag for tflite (float) models ?**
**What happens when we use this flag for Quantized(uint8) models ?**

4. What does **profiling and max_profiling_buffer_entries** do ?
Which value i should keep for max_profiling_buffer_entries ? why is it 1024 ?
I was able to return elapsed times even when i set profiling flag to false and verbose to true.

Please provide, sufficient details in each question to help us in proceeding further.


"
37153,"InvalidArgumentError:  Size 1 must be non-negative, not -21","https://www.kaggle.com/super13579/u-net-base-on-resnet34-transfer-learning-keras

```
fig, m_axs = plt.subplots(20, 2, figsize = (10, 40))
[c_ax.axis('off') for c_ax in m_axs.flatten()]
for (ax1, ax2), c_img_name in zip(m_axs, test_paths):
    c_path = os.path.join(test_image_dir, c_img_name)
    c_img = imread(c_path)
    #print(c_img.shape)
    first_img = np.expand_dims(c_img, 0)/255.0
    #print('a')
    first_seg = fullres_model.predict(first_img)
    #print('b')
    ax1.imshow(first_img[0])
    ax1.set_title('Image')
    ax2.imshow(first_seg[0,:, :, 0])
    ax2.set_title('Prediction')
#fig.savefig('test_predictions.png')
```


> ---------------------------------------------------------------------------
> InvalidArgumentError                      Traceback (most recent call last)
> <ipython-input-54-a91de316977a> in <module>
>       7     first_img = np.expand_dims(c_img, 0)/255.0
>       8     #print('a')
> ----> 9     first_seg = .predict(first_img)
>      10     #print('b')
>      11     ax1.imshow(first_img[0])
> 
> ~/venv/lib/python3.7/site-packages/keras/engine/training.py in predict(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)
>    1460                                             verbose=verbose,
>    1461                                             steps=steps,
> -> 1462                                             callbacks=callbacks)
>    1463 
>    1464     def train_on_batch(self, x, y,
> 
> ~/venv/lib/python3.7/site-packages/keras/engine/training_arrays.py in predict_loop(model, f, ins, batch_size, verbose, steps, callbacks)
>     322             batch_logs = {'batch': batch_index, 'size': len(batch_ids)}
>     323             callbacks._call_batch_hook('predict', 'begin', batch_index, batch_logs)
> --> 324             batch_outs = f(ins_batch)
>     325             batch_outs = to_list(batch_outs)
>     326             if batch_index == 0:
> 
> ~/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py in __call__(self, inputs)
>    3738         value = math_ops.cast(value, tensor.dtype)
>    3739       converted_inputs.append(value)
> -> 3740     outputs = self._graph_fn(*converted_inputs)
>    3741 
>    3742     # EagerTensor.numpy() will often make a copy to ensure memory safety.
> 
> ~/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in __call__(self, *args, **kwargs)
>    1079       TypeError: For invalid positional/keyword argument combinations.
>    1080     """"""
> -> 1081     return self._call_impl(args, kwargs)
>    1082 
>    1083   def _call_impl(self, args, kwargs, cancellation_manager=None):
> 
> ~/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _call_impl(self, args, kwargs, cancellation_manager)
>    1119       raise TypeError(""Keyword arguments {} unknown. Expected {}."".format(
>    1120           list(kwargs.keys()), list(self._arg_keywords)))
> -> 1121     return self._call_flat(args, self.captured_inputs, cancellation_manager)
>    1122 
>    1123   def _filtered_call(self, args, kwargs):
> 
> ~/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
>    1222     if executing_eagerly:
>    1223       flat_outputs = forward_function.call(
> -> 1224           ctx, args, cancellation_manager=cancellation_manager)
>    1225     else:
>    1226       gradient_name = self._delayed_rewrite_functions.register()
> 
> ~/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in call(self, ctx, args, cancellation_manager)
>     509               inputs=args,
>     510               attrs=(""executor_type"", executor_type, ""config_proto"", config),
> --> 511               ctx=ctx)
>     512         else:
>     513           outputs = execute.execute_with_cancellation(
> 
> ~/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
>      65     else:
>      66       message = e.message
> ---> 67     six.raise_from(core._status_to_exception(e.code, message), None)
>      68   except TypeError as e:
>      69     keras_symbolic_tensors = [
> 
> ~/venv/lib/python3.7/site-packages/six.py in raise_from(value, from_value)
> 
> InvalidArgumentError:  Size 1 must be non-negative, not -21
> 	 [[{{node u-resnet34_1/bn_data/batchnorm/mul-1-ReshapeNHWCToNCHW-LayoutOptimizer}}]] [Op:__inference_keras_scratch_graph_62290]
> 
> Function call stack:
> keras_scratch_graph
> fullres_model"
37152,apply_transform not in preprocessing.image,"I have to run this code which import 
`from tensorflow.python.keras.preprocessing.image import apply_transform`
 but I got issue **""ImportError: cannot import name 'apply_transform'""**
In this link https://stackoverflow.com/questions/51311062/cant-import-apply-transform-from-keras-preprocessing-image They told use apply_affine_tensorflow.

I want to scaling image with this code 
```
def scale(mel_spectrogram, scale_factor):
        w = mel_spectrogram.shape[0]
        h = mel_spectrogram.shape[1]
        transform = np.array([[scale_factor, 0, 0], [0, 1, 0], [0, 0, 1]])
        image = mel_spectrogram.astype(np.float64).reshape(w, h)
        scaled_image = apply_transform(image, transform, fill_mode='constant').astype(np.float16)
        # if the result is shorter, shorten the np array as well
        if scale_factor > 1:
            new_length = int(scaled_image.shape[1] / scale_factor)
            scaled_image = scaled_image[:, :new_length, ]
        mel_spectrogram = np.expand_dims(scaled_image.astype(mel_spectrogram.dtype), axis=2)
        return mel_spectrogram

    return mel_sample_loader
```

From : https://github.com/hendriks73/directional_cnns/blob/095b6f524f666005adb138c4e336cf6da1f046e5/directional_cnns/loader.py#L51

How can I deal with it?
"
37151,Run distributed training mnist failed,"My dependencies
```
Python 3.6.8 (default, Aug  7 2019, 17:28:10) 
[GCC 4.8.5 20150623 (Red Hat 4.8.5-39)] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
>>> print(tf.__version__)
2.2.0-dev20200227
```
Here is my code
https://gist.github.com/pingsutw/bd4e1b1b2d4055d4e807abcdd2f0d6f4

I use both `ParameterServerStrategy` and `MultiWorkerMirroredStrategy` all failed.

I can successfully run this tutorial locally.
And I follow this [link](https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras) to run distributed training, but always fails.
Instead of run multiworker locally, I run on 3 machines. 

Below are error messages
```
2020-02-27 21:54:15.735213: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/cloudera/parcels/CDH/lib64:/opt/jdk1.8.0_221/jre/lib/amd64/server
2020-02-27 21:54:15.735272: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)
2020-02-27 21:54:15.735320: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (kevin2): /proc/driver/nvidia/version does not exist
2020-02-27 21:54:15.735784: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-27 21:54:15.849834: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2494140000 Hz
2020-02-27 21:54:15.933775: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fd9c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-27 21:54:15.933870: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-02-27 21:54:16.139575: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job ps -> {0 -> kevin2:38518}
2020-02-27 21:54:16.139650: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job worker -> {0 -> localhost:43854, 1 -> kevin2:36868}
2020-02-27 21:54:16.157359: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:390] Started server with target: grpc://localhost:43854
2020-02-27 21:54:16.157667: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:394] Server already started (target: grpc://localhost:43854)
WARNING:tensorflow:From /yarn/nm/usercache/root/appcache/application_1582468300204_0090/container_1582468300204_0090_01_000003/tf2.zip/tf2/lib64/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
WARNING:tensorflow:From /yarn/nm/usercache/root/appcache/application_1582468300204_0090/container_1582468300204_0090_01_000003/tf2.zip/tf2/lib64/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
WARNING:tensorflow:From /yarn/nm/usercache/root/appcache/application_1582468300204_0090/container_1582468300204_0090_01_000003/tf2.zip/tf2/lib64/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:96: DistributedIteratorV1.initialize (from tensorflow.python.distribute.input_lib) is deprecated and will be removed in a future version.
Instructions for updating:
Use the iterator's `initializer` property instead.
WARNING:tensorflow:From /yarn/nm/usercache/root/appcache/application_1582468300204_0090/container_1582468300204_0090_01_000003/tf2.zip/tf2/lib64/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:96: DistributedIteratorV1.initialize (from tensorflow.python.distribute.input_lib) is deprecated and will be removed in a future version.
Instructions for updating:
Use the iterator's `initializer` property instead.
```"
37149,Structure type Errors in TensorFlow,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow):  **YES**
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): **`Mac OS Catalina`**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
- TensorFlow installed from (source or
binary): **`binary`**
- TensorFlow version (use command below): **`2.1`**
- Python version: **`3.7.2`**
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from
source): 
- CUDA/cuDNN version: **10.2**
- GPU model and memory: **4gb ram**   Graphics:  **Intel HD Graphics 4000 1536 MB**

**Describe the current behavior**
I am attempting to build a stock prediction model using LSTM
Here are a list of my import statements:

```
import requests
import math
import numpy as np
import pandas as pd
import pandas_datareader as web
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import LSTM, Dense
from sklearn.preprocessing import MinMaxScaler
from bs4 import BeautifulSoup
import matplotlib.pyplot as plt
from datetime import datetime, date
```

Here is the code for the model itself:

```

#split the data into x-train and y-train datasets
x_train = []
y_train = []

for i in range(20, len(train_data)):
    x_train.append(train_data[i-20:i, 0])
    y_train.append(train_data[i, 0])

    if i<= 20:
        print(x_train)
        print(y_train)

#convert x-train and y-train to numpy arrays to train models
x_train, y_train = np.array(x_train), np.array(y_train)

#reshape the data, LSTM model expects 3D dataset
x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))

#Build LSTM MODEL
model = tf.keras.Sequential([
    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),
    tf.keras.layers.Dense(25, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

model.compile(loss='mean_squared_error',
              optimizer=tf.keras.optimizers.Adam(1e-4),
              metrics=['accuracy'])

model.fit(x_train, y_train, batch_size=1, epochs=1)

#create testing data set
#creat new array containing scaled values
test_data = scaled_data[training_data_len - 20: , :]

#create the datasets x-test and y-test
x_test=[]
y_test=dataset[training_data_len:, :]
for i in range(20, len(test_data)):
    x_test.append(test_data[i-20:i, 0])

#convert data to numpy array
x_test = np.array(x_test)

#reshape data to 3D
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))

#Get predicted price values
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)

#get root mean squared error
rmse=np.sqrt(np.mean(((predictions- y_test)**2)))
print(rmse)

```
Executing this code returns the error:

```
Traceback (most recent call last):
  File ""/Users/owner/Desktop/algo/predict.py"", line 98, in <module>
    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))
IndexError: tuple index out of range
```
**Describe the expected behavior**
`print(rmse)` should return the average.

I am new to tensorflow and neural programming so I am not completely sure what to do here.
If I try `x_test = np.reshape(x_test, (x_test.shape[0]))`

I get this error:

```
Traceback (most recent call last):
  File ""/Users/owner/Desktop/algo/predict.py"", line 103, in <module>
    predictions = model.predict(x_test)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 1013, in predict
    use_multiprocessing=use_multiprocessing)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 498, in predict
    workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 475, in _model_iteration
    total_epochs=1)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 128, in run_one_epoch
    batch_outs = execution_function(iterator)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py"", line 98, in execution_function
    distributed_function(input_fn))
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 568, in __call__
    result = self._call(*args, **kwds)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 615, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 497, in _initialize
    *args, **kwds))
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2389, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2703, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2593, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py"", line 978, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 439, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py"", line 85, in distributed_function
    per_replica_function, args=args)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py"", line 763, in experimental_run_v2
    return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py"", line 1819, in call_for_each_replica
    return self._call_for_each_replica(fn, args, kwargs)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py"", line 2164, in _call_for_each_replica
    return fn(*args, **kwargs)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py"", line 292, in wrapper
    return func(*args, **kwargs)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py"", line 212, in _predict_on_batch
    result = predict_on_batch(model, x)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py"", line 556, in predict_on_batch
    return predict_on_batch_fn(inputs)  # pylint: disable=not-callable
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 737, in __call__
    self.name)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/input_spec.py"", line 177, in assert_input_compatibility
    str(x.shape.as_list()))
ValueError: Input 0 of layer sequential is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [32, 1]
```

Any help will be greatly appreciated, I am dying to learn what is wrong!
Thankyou,
RRR.

"
37147,Error on ESP32,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution Windows 10):
- TensorFlow installed from (2.x on gogole collab):
- Tensorflow version (same as before):
- Target platform (ESP32):

Hello gentlemen, i'm trying to deploy a simple model (trained with kera tf 2.x on collab) and converted with this:
```
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.experimental_new_quantizer = True
converter.experimental_new_converter = True
tflite_float_model = converter.convert()
```

My idea is to pass as input three values (float) of RGB to recognize the color with a sensor (Flora sensor of adafruit)
When i flash the firmware on my esp32 i got this error on invoke (and some of my serial print)

```
rst:0xc (SW_CPU_RESET),boot:0x13 (SPI_FAST_FLASH_BOOT)
configsip: 0, SPIWP:0xee
clk_drv:0x00,q_drv:0x00,d_drv:0x00,cs0_drv:0x00,hd_drv:0x00,wp_drv:0x00
mode:DIO, clock div:2
load:0x3fff0018,len:4
load:0x3fff001c,len:1044
load:0x40078000,len:8896
load:0x40080400,len:5828
entry 0x400806ac
Loading Tensorflow model....
Color model loaded!
Allocating tensors to memory pool
Tensors size: 14
Input size: 1
No TCS34725 found ... check your connections
Starting inferences...
Input type 1
Input shape 2
abort() was called at PC 0x400dae25 on core 1

Backtrace: 0x4008c49c:0x3ffb1e00 0x4008c6cd:0x3ffb1e20 0x400dae25:0x3ffb1e40 0x400db185:0x3ffb1e90 0x400e174a:0x3ffb1f70 0x400d198a:0x3ffb1f90 0x400e64bd:0x3ffb1fb0 0x40088bd9:0x3ffb1fd0

Rebooting...
ets Jun  8 2016 00:22:57

rst:0xc (SW_CPU_RESET),boot:0x13 (SPI_FAST_FLASH_BOOT)
configsip: 0, SPIWP:0xee
clk_drv:0x00,q_drv:0x00,d_drv:0x00,cs0_drv:0x00,hd_drv:0x00,wp_drv:0x00
mode:DIO, clock div:2
load:0x3fff0018,len:4
load:0x3fff001c,len:1044
load:0x40078000,len:8896
load:0x40080400,len:5828
entry 0x400806ac

--- exit ---
```


Following my code:
```
#include <Arduino.h>
#include <math.h>
#include ""tensorflow/lite/experimental/micro/kernels/all_ops_resolver.h""
#include ""tensorflow/lite/experimental/micro/micro_error_reporter.h""
#include ""tensorflow/lite/experimental/micro/micro_interpreter.h""
#include ""model_data.h""
#include ""Adafruit_TCS34725.h""

// Create a memory pool for the nodes in the network
constexpr int tensor_pool_size = 2 * 2048;
uint8_t tensor_pool[tensor_pool_size];

// Define the model to be used
const tflite::Model *sine_model;

// Define the interpreter
tflite::MicroInterpreter *interpreter;

// Input/Output nodes for the network
TfLiteTensor *input;
TfLiteTensor *output;

Adafruit_TCS34725 tcs = Adafruit_TCS34725(TCS34725_INTEGRATIONTIME_154MS, TCS34725_GAIN_1X);
uint16_t red, green, blue, clear;

bool sensor = false;
// Set up the ESP32's environment.
void setup()
{
	// Start serial at 115200 baud
	Serial.begin(115200);

	// Load the sample sine model
	Serial.println(""Loading Tensorflow model...."");
	sine_model = tflite::GetModel(model_data);
	Serial.println(""Color model loaded!"");

	// Define ops resolver and error reporting
	static tflite::ops::micro::AllOpsResolver resolver;

	static tflite::ErrorReporter *error_reporter;
	static tflite::MicroErrorReporter micro_error;
	error_reporter = &micro_error;

	// Instantiate the interpreter
	static tflite::MicroInterpreter static_interpreter(sine_model, resolver, tensor_pool, tensor_pool_size, error_reporter);

	interpreter = &static_interpreter;

	// Allocate the the model's tensors in the memory pool that was created.
	Serial.println(""Allocating tensors to memory pool"");
	Serial.printf(""Tensors size: %d\n"", interpreter->tensors_size());
	Serial.printf(""Input size: %d\n"", interpreter->inputs_size());

	if (interpreter->AllocateTensors() != kTfLiteOk)
	{
		Serial.println(""There was an error allocating the memory...ooof"");
		while (true)
			;
	}

	if (tcs.begin())
	{
		Serial.println(""Found sensor"");
		sensor = true;
	}
	else
	{
		Serial.println(""No TCS34725 found ... using fake value for Green"");
		sensor = false;
	}

	// Define input and output nodes
	input = interpreter->input(0);
	output = interpreter->output(0);
	Serial.println(""Starting inferences... "");
	Serial.printf(""Input type %d\n"", input->type);
	Serial.printf(""Input shape %d\n"", input->dims->size);

}

// Logic loop for taking user input and outputting the sine
void loop()
{

	if (sensor)
	{
		tcs.setInterrupt(false); // turn on LED
		delay(1);
		tcs.getRawData(&red, &green, &blue, &clear);
		tcs.setInterrupt(true); // turn off LED
		//r,g,b,c
		delay(100);
	}
	else
	{
		red = 688;
		green = 319;
		blue = 290;
		clear = 1228;
	}

	input->data.f[0] = (red / clear);
	input->data.f[1] = (green / clear);
	//input->data.f[2] = (blue / clear);


	Serial.println(interpreter->Invoke());
	if (interpreter->Invoke() != kTfLiteOk)
	{
		Serial.println(""There was an error invoking the interpreter!"");
		while (true) delay(1000);
	}

	// Print the output of the model.
	Serial.print(""Input: "");
	Serial.printf(""%d,%d,%d,%d\n"", red, green, blue, clear);
	Serial.print(""Output: "");
	Serial.println(output->data.f[0]);
	Serial.println("""");
	delay(1000);
}
```

Could you help me? (i can pass the entire project)"
37144,"WARNING:tensorflow:AutoGraph could not transform and will run it as-is. Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.","**System information** 
- Have I written custom code: Yes
- OS Platform and Distribution : Windows 10
- TensorFlow installed from (source or binary): Anaconda
- TensorFlow version (use command below): 2.1.0
- Python version: 3.7.4

**Describe the current behavior**
I'm using anaconda tensorflow, Spyder. When run my custom layers, it shows warning as below: 
```
WARNING:tensorflow:AutoGraph could not transform <bound method GroupSoftmax.call of <__main__.GroupSoftmax object at 0x000002A957B843C8>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: 
WARNING: AutoGraph could not transform <bound method GroupSoftmax.call of <__main__.GroupSoftmax object at 0x000002A957B843C8>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
```
**Describe the method I tried**
I have already tried the solution which others provided: pip install gast==0.2.2
I also re-installed all of the softwares (anaconda, tensorflow, spyder). 
However, these methods doesn't solve my problem.  
Is there any other solution? 

**Standalone code to reproduce the issue** 
```
class GroupSoftmax(layers.Layer):
    def __init__(self, axis=-1, **kwargs):
        super(GroupSoftmax, self).__init__(**kwargs)
        self.supports_masking = True
        self.axis = axis

    def call(self, inputs):
        return tf.divide(inputs, tf.reduce_sum(inputs, axis=self.axis))

    def get_config(self):
        config = {'axis': self.axis}
        base_config = super(GroupSoftmax, self).get_config()
        return dict(list(base_config.items()) + list(config.items()))
    
    @tf_utils.shape_type_conversion
    def compute_output_shape(self, input_shape):
        return input_shape

'''
-----------------network of g-----------------
'''
gModel = tf.keras.Sequential([
# 添加一个有Nodes个神经元的全连接层，“input_shape”为该层接受的输入数据的维度，“activation”指定该层所用的激活函数
layers.Dense(Nodes, activation='sigmoid', input_shape=(60,), use_bias = False),#封装数据应该为（3000，10，6）
# 添加第二个网络层
layers.Dense(Nodes, activation='sigmoid', use_bias = False),
# 添加第3个网络层
layers.Dense(Nodes, activation='sigmoid', use_bias = False),
# 添加第4个网络层
layers.Dense(Nodes, activation='sigmoid', use_bias = False),
# 添加第5个网络层
layers.Dense(Nodes, activation='sigmoid', use_bias = False),
# 添加第6个网络层,改变节点数目
layers.Dense(66, activation='sigmoid', use_bias = False),
# 添加第7个网络层,改变shape
layers.Reshape((11, 6)),
# 添加output网络层,分组softmax
#layers.Dense(6, activation=layers.Softmax(axis=0),input_shape=(11,6), use_bias = False), # [11,6]
#layers.Softmax(axis=0)
GroupSoftmax(axis=0)
])

gModel.summary()   
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
37143,Can I use asymmetrical images as input?,"For instance, an image of 500x3000 pixels."
37141,"ValueError: No gradients provided for any variable in Tensorflow 2.0, WAE","I am a tensorflow2.0 learner who is trying to reproduce the code of Wasserstein AutoEncoder or Adversarial AutoEncoder and do something interesting based on that on my own. My code below is based on[ timsainb/tensorflow2-generative-models](https://github.com/timsainb/tensorflow2-generative-models) with some of modifications.

```
%tensorflow_version 2.x
import tensorflow as tf
import numpy as np
import pandas as pd
import tensorflow_probability as tfp
from tqdm import tqdm
'''Python 3.6.6
   pip install tensorflow==2.0.0b1
   pip install tfp-nightly==0.7.0.dev20190510
   pip install tensorflow_probability==0.8.0rc0 --user --upgrade'''

ds = tfp.distributions
tf.keras.backend.set_floatx('float32') # sets dtype as tf.float32

#%%%
'''Define the network as tf.keras.model object'''

class VAE(tf.keras.Model):
    """"""a VAE class for tensorflow

    Extends:
        tf.keras.Model
    """"""

    def __init__(self, **kwargs):
        super(VAE, self).__init__()
        self.__dict__.update(kwargs)

        self.pad3 = 'same'    

        self.disc = tf.keras.Sequential([
            tf.keras.layers.InputLayer(input_shape=int(self.intrinsic_size/4) * int(self.intrinsic_size/4)),
            tf.keras.layers.Dense(units=32, activation=""relu"", name=""disc1""),
            tf.keras.layers.Dense(units=64, activation=""relu"", name=""disc2""),
            tf.keras.layers.Dense(units=128, activation=""relu"", name=""disc3""),
            tf.keras.layers.Dense(units=1, activation=None)
            ])

        self.enc = tf.keras.Sequential([
            tf.keras.layers.InputLayer(input_shape=self.ipt_shape),        
            tf.keras.layers.Conv2D(filters=self.hidden_layer_sizes[0], kernel_size=5, strides=(2, 2), padding='same', activation=self.activation, name=""conv1""),                 
            tf.keras.layers.BatchNormalization(),            
            tf.keras.layers.Conv2D(filters=self.hidden_layer_sizes[1], kernel_size=5, strides=(2, 2), padding='same', activation=self.activation, name=""conv2""),                                       
            tf.keras.layers.BatchNormalization(),                   
            tf.keras.layers.Conv2D(self.hidden_layer_sizes[2], kernel_size=3, strides=(2, 2), padding='same', activation=self.activation, name=""conv3""),
            tf.keras.layers.BatchNormalization(),                
            tf.keras.layers.Flatten(),
            tf.keras.layers.Dense(units=self.intrinsic_size + self.intrinsic_size * self.intrinsic_size, use_bias=False, name=""lastlayer"") #no activation function                
            ]) 

        self.dec = tf.keras.Sequential([
            tf.keras.layers.Dense(units=self.hidden_layer_sizes[2]*int(self.ipt_shape[0]/4)*int(self.ipt_shape[0]/4), activation=self.activation, name=""revealed""),                
            tf.keras.layers.Reshape(target_shape=(int(self.ipt_shape[0]/4), int(self.ipt_shape[0]/4), self.hidden_layer_sizes[2])),                                     
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.Conv2DTranspose(filters=self.hidden_layer_sizes[1], kernel_size=3, strides=(2, 2), padding='same', activation=self.activation, name=""deconv3""),                                       
            tf.keras.layers.BatchNormalization(),                      
            tf.keras.layers.Conv2DTranspose(filters=self.hidden_layer_sizes[0], kernel_size=5, strides=(2, 2), padding='same', activation=self.activation, name=""deconv2""),
            tf.keras.layers.BatchNormalization(),      
            tf.keras.layers.Conv2DTranspose(filters=1, kernel_size=5, strides=(1, 1), padding='same', activation=""sigmoid"", name=""deconv1"")
            ])

        self.vae_optimizer = tf.keras.optimizers.Adam(self.lr)
        self.disc_optimizer = tf.keras.optimizers.Adam(self.lr)
        self.enc_optimizer = tf.keras.optimizers.Adam(self.lr)


    def encode(self, x):
        mu, sigma = tf.split(self.enc(x), num_or_size_splits=[self.intrinsic_size, self.intrinsic_size * self.intrinsic_size], axis=1)
        return mu, sigma    

    def enc_dist(self, x):
        mu, sigma = self.encode(x)
        M = tf.reshape(sigma, (sigma.shape[0], self.intrinsic_size, self.intrinsic_size))        
        N = ds.MultivariateNormalDiag(loc=np.zeros((sigma.shape[0], self.intrinsic_size)), scale_diag=[1.0]*self.intrinsic_size)              
        eps = tf.expand_dims(tf.cast(N.sample(), tf.float32), -1)
        z = tf.expand_dims(mu, -1) + tf.matmul(M, eps)
        z = tf.squeeze(z)        
        return z

    def discriminate(self, x):
        return self.disc(x) 


    def decode(self, z):
        return self.dec(z) 

    def gradient_penalty(self, x, x_gen):
        epsilon = tf.random.uniform([x.shape[0], 1], 0.0, 1.0)
        x_hat = epsilon * x + (1 - epsilon) * x_gen
        self.x_hat = x_hat
        with tf.GradientTape() as t:
            t.watch(x_hat)
            d_hat = self.discriminate(x_hat)
        gradients = t.gradient(d_hat, x_hat)
        ddx = tf.sqrt(tf.reduce_sum(gradients ** 2, axis=[1]))
        d_regularizer = tf.reduce_mean((ddx - 1.0) ** 2)
        return d_regularizer


    def compute_loss_vae(self, x):   
        vae_loss = []                
        latent_loss = []
        enc_loss = []        
        for _ in range(int(self.num_sampling)):           

            self.z = z = self.enc_dist(x)             

            self.x_recon = x_recon = self.decode(z)
            N = ds.MultivariateNormalDiag(loc=np.zeros((z.shape[0], self.intrinsic_size)), scale_diag=[1.] * self.intrinsic_size)                
            self.z_gen = z_gen = tf.cast(N.sample(), tf.float32)

            self.logits_z = logits_z = self.discriminate(z)
            self.logits_z_gen = logits_z_gen = self.discriminate(z_gen)            


            self.d_regularizer = d_regularizer = self.gradient_penalty(z, z_gen)
            self.wasserstein = wasserstein = tf.reduce_mean(logits_z_gen) - tf.reduce_mean(logits_z) + d_regularizer * self.gradient_penalty_weight

            rec = tf.reduce_mean(tf.reduce_sum(tf.math.square(x - x_recon), axis=0))                      
            enc = -tf.reduce_mean(logits_z)

            vae_loss.append(rec)
            latent_loss.append(wasserstein) 
            enc_loss.append(enc)                     

        self.vae_loss = vae_loss = tf.reduce_mean(vae_loss, axis=0)        
        self.latent_loss = latent_loss = tf.reduce_mean(latent_loss, axis=0)    
        self.enc_loss = enc_loss = tf.reduce_mean(enc_loss, axis=0)
        return (vae_loss, latent_loss, enc_loss)


    def compute_gradients(self, x):               
        with tf.GradientTape() as vae_tape, tf.GradientTape() as disc_tape, tf.GradientTape() as enc_tape:
            vae_loss, latent_loss, enc_loss = self.compute_loss_vae(x)

        self.vae_gradients = vae_gradients = vae_tape.gradient( vae_loss, self.enc.trainable_variables +  self.dec.trainable_variables )            
        self.disc_gradients = disc_gradients = disc_tape.gradient( -latent_loss, self.disc.trainable_variables )
        self.enc_gradients = enc_gradients = enc_tape.gradient(enc_loss, self.enc.trainable_variables )

        return vae_gradients, disc_gradients, enc_gradients



    def apply_gradients_vae(self, vae_gradients, disc_gradients, enc_gradients):        
        self.vae_optimizer.apply_gradients(
            zip(vae_gradients, self.enc.trainable_variables + self.dec.trainable_variables)
        )
        self.disc_optimizer.apply_gradients(
            zip(disc_gradients, self.disc.trainable_variables)
        )       

        self.enc_optimizer.apply_gradients(
            zip(enc_gradients, self.enc.trainable_variables)
        )

    @tf.function
    def train(self, x):
        vae_gradients, disc_gradients, enc_gradients = self.compute_gradients(x)
        self.apply_gradients_vae(vae_gradients, disc_gradients, enc_gradients)


    def fit(self, x):

        losses = pd.DataFrame(columns=['vae_loss', 'disc_loss', 'enc_loss'])
        Vae_loss = Disc_loss = Enc_loss = []

        n_samples, n_height, n_width, n_channel = x.shape


        n_batch = (n_samples - 1) // self.batch_size + 1
        self.n_batch = n_batch

        idx = np.arange(int(n_samples))
        np.random.shuffle(idx)       

        for epoch in range(self.epoch_size):
            print(f"" Epoch: {epoch+1}/{self.epoch_size}"")

            loss = []
            for batch in tqdm(range(self.n_batch), position=0):
                i_start = int(batch * self.batch_size)
                i_end = int((batch + 1) * self.batch_size)
                self.i_start = i_start
                self.i_end = i_end
                self.x_batch = x_batch = x[ idx[ i_start : i_end ] ]  
                self.train(x_batch)


                loss.append(self.compute_loss_vae(x_batch))
                self.loss = loss
            losses.loc[len(losses.T)] = np.mean(loss, axis=0)



            self.Vae_loss = Vae_loss.append(np.mean(loss, axis=0)[0])
            self.Disc_loss = Disc_loss.append(np.mean(loss, axis=0)[1])
            self.Enc_loss = Enc_loss.append(np.mean(loss, axis=0)[2])
            print("" epoch: {}/{} : &\n {}"".format(epoch+1, self.epoch_size, losses))

(X_train_origin, y_train_origin), (X_test_origin, y_test_origin) = tf.keras.datasets.mnist.load_data()


if __name__ == ""__main__"":

    input_shape = (28,28,1)
    num_train = 5000                  
    X_train = X_train_origin[0:num_train]                 
    X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype(""float32"") / 255.0

    model = VAE(
            lr = 1e-3,
            latent_loss_div=1, 
            epoch_size = 2, 
            batch_size = 128,
            ipt_shape = input_shape,
            activation = ""relu"",
            hidden_layer_sizes = (32,64,128),
            intrinsic_size = 16,
            num_sampling = 3,
            gradient_penalty_weight = 10.0,
            prior_c = 0.2,
            )

    model.fit(X_train)
```

However, I always get a ``No gradients provided'' error. Please check the description:

```
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
    704           except Exception as e:  # pylint:disable=broad-except
    705             if hasattr(e, ""ag_error_metadata""):
--> 706               raise e.ag_error_metadata.to_exception(type(e))
    707             else:
    708               raise

ValueError: in converted code:

    <ipython-input-9-8e8f91e623b2>:158 train  *
        self.apply_gradients_vae(vae_gradients, disc_gradients, enc_gradients)
    <ipython-input-9-8e8f91e623b2>:148 apply_gradients_vae
        zip(disc_gradients, self.disc.trainable_variables)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:427 apply_gradients
        grads_and_vars = _filter_grads(grads_and_vars)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:975 _filter_grads
        ([v.name for _, v in grads_and_vars],))

    ValueError: No gradients provided for any variable: ['disc1_4/kernel:0', 'disc1_4/bias:0', 'disc2_4/kernel:0', 'disc2_4/bias:0', 'disc3_4/kernel:0', 'disc3_4/bias:0', 'dense_4/kernel:0', 'dense_4/bias:0'].
```

If I print the gradients of discriminators, it always shows:
`ListWrapper([None, None, None, None, None, None, None, None])`

I know that the issue must be in the discriminator part (because once I remove the apply gradient to discriminator, the code works). However, I don't know how to fix it with discriminator and I've been thinking about it for several days. 

Could you please let me know where I didn't connect the network successfully? Or I stupidly messed up something somewhere?"
37140,Micro_speech example with a different microphone bitrate,"@tensorflow/micro

**System information**
- Windows 10
- TensorFlow installed from Arduino library
- 1.15.0-ALPHA precompiled
- ESP32, Arduino

Following the micro_speech example in the Arduino_TensorFlowLite library, I tried to modify the code so that it could run with my 32 bits per sample I2S microphone.
However, this proved to be a challenge since the audio_provider files require a certain number of samples of a certain size.
What happened, in the end, is that the code was stuck in a loop gathering data.

I'm not sure where to even begin debugging this, but I'm guessing the capture buffer needs to be adjusted in order to accommodate the larger sample size

So far I've modified the arduino_audio_provider.cpp file to be the following
````
#include ""audio_provider.h""
#include <Arduino.h>
#include <driver/i2s.h>
#include ""micro_features_micro_model_settings.h""
const i2s_port_t I2S_PORT = I2S_NUM_0;
#define BUFFER_SIZE 1024
TaskHandle_t audioInputTaskHandle;
namespace {
bool g_is_audio_initialized = false;
// An internal buffer able to fit 16x our sample size
constexpr int kAudioCaptureBufferSize = BUFFER_SIZE * 32;
int32_t g_audio_capture_buffer[BUFFER_SIZE];
// A buffer that holds our output
int16_t g_audio_output_buffer[kMaxAudioSampleSize];
// Mark as volatile so we can check in a while loop to see if
// any samples have arrived yet.
volatile int32_t g_latest_audio_timestamp = 0;
}  // namespace
volatile uint32_t testerino = 0;
volatile bool audioCaptureFlag = 0;
void CaptureSamples( void *) {
  while(1)
  {
    if(audioCaptureFlag)
    {
      // Determine the index, in the history of all samples, of the last sample
      const int32_t start_sample_offset =
          g_latest_audio_timestamp * (kAudioSampleFrequency / 1000);//0
      // Determine the index of this sample in our ring buffer
      const int capture_index = start_sample_offset % kAudioCaptureBufferSize;//0
      size_t bytesRead;
      i2s_read(I2S_PORT, (void*) g_audio_capture_buffer + capture_index, BUFFER_SIZE, &bytesRead, portMAX_DELAY);
      // This is how many bytes of new data we have each time this is called
      const int number_of_samples = bytesRead / 8;
      // Calculate what timestamp the last audio sample represents
      const int32_t time_in_ms =
          g_latest_audio_timestamp +
          (number_of_samples / (kAudioSampleFrequency / 1000)); //6,12
      
      // Read the data to the correct place in our buffer
      // Serial.println(g_latest_audio_timestamp);
      // Serial.println(start_sample_offset);
      Serial.println(capture_index);
      delay(1);
      // for(uint16_t i = 0; i < bytesRead; i++)
        // Serial.printf(""%d, %ld\n"", i, g_audio_capture_buffer[i]);
        // Serial.println(g_audio_capture_buffer[i]);
      
      // PDM.read(g_audio_capture_buffer + capture_index, DEFAULT_PDM_BUFFER_SIZE);
      // This is how we let the outside world know that new audio data has arrived.
      // Serial.print(""latest timestamp: "");
      // Serial.println(bytesRead);
      // Serial.flush();
      // delay(1);
      testerino++;

      g_latest_audio_timestamp = time_in_ms;
    }
    vTaskDelay(1);
  }
}

TfLiteStatus InitAudioRecording(tflite::ErrorReporter* error_reporter) {
    Serial.println(""init audio recording"");
    delay(10);

  // Hook up the callback that will be called with each sample
  // PDM.onReceive(CaptureSamples);
  // Start listening for audio: MONO @ 16KHz with gain at 20
  // PDM.begin(1, kAudioSampleFrequency);
  // PDM.setGain(20);
   // The I2S config as per the example
  const i2s_config_t i2s_config = {
      .mode = i2s_mode_t(I2S_MODE_MASTER | I2S_MODE_RX), // Receive, not transfer
      .sample_rate = 16000,                         // 16KHz
      .bits_per_sample = I2S_BITS_PER_SAMPLE_32BIT, // could only get it to work with 32bits
      .channel_format = I2S_CHANNEL_FMT_ONLY_RIGHT, // although the SEL config should be left, it seems to transmit on right
      .communication_format = i2s_comm_format_t(I2S_COMM_FORMAT_I2S | I2S_COMM_FORMAT_I2S_MSB),
      .intr_alloc_flags = ESP_INTR_FLAG_LEVEL1,     // Interrupt level 1
      .dma_buf_count = 8,                           // number of buffers
      .dma_buf_len = BUFFER_SIZE                              // 32 samples per buffer (minimum)
  };

  // The pin config as per the setup
  const i2s_pin_config_t pin_config = {
      .bck_io_num = 13,   // BCKL
      .ws_io_num = 15,    // LRCL
      .data_out_num = -1, // not used (only for speakers)
      .data_in_num = 32   // DOUT
  };
  esp_err_t err;
  // Configuring the I2S driver and pins.
  // This function must be called before any I2S driver read/write operations.
  err = i2s_driver_install(I2S_PORT, &i2s_config, 0, NULL);
  if (err != ESP_OK) {
    Serial.printf(""Failed installing driver: %d\n"", err);
    while (true);
  }
  err = i2s_set_pin(I2S_PORT, &pin_config);
  if (err != ESP_OK) {
    Serial.printf(""Failed setting pin: %d\n"", err);
    while (true);
  }
  Serial.println(""I2S driver installed."");
  delay(1);
  // uint32_t samples[8];
  // int bytes_read = i2s_pop_sample(I2S_PORT, (char *)&sample, portMAX_DELAY); // no timeout
  // size_t bytes_read;
  // esp_err_t error = i2s_read(I2S_PORT, (char *)samples, 8, &bytes_read, portMAX_DELAY);
  // Serial.println(error == ESP_OK);
  // delay(1);
  // if (bytes_read > 0) {
  //   float mean = 0;
  //   for (int i = 0; i < bytes_read; ++i) {
  //     mean += samples[i];
  //   }
  //   Serial.println(mean);
  // }
  // delay(10);
  // Block until we have our first audio sample
  xTaskCreate(CaptureSamples, ""adc_read_task"", kAudioCaptureBufferSize, NULL, 5, &audioInputTaskHandle);
  audioCaptureFlag = 1;

  while (!g_latest_audio_timestamp) {
  }

  return kTfLiteOk;
}

TfLiteStatus GetAudioSamples(tflite::ErrorReporter* error_reporter,
                             int start_ms, int duration_ms,
                             int* audio_samples_size, int16_t** audio_samples) {
  // Set everything up to start receiving audio
  if (!g_is_audio_initialized) {
    TfLiteStatus init_status = InitAudioRecording(error_reporter);
    if (init_status != kTfLiteOk) {
      return init_status;
    }
    g_is_audio_initialized = true;
  }
  else
  {
    // Serial.println(""task resumed"");
    // Serial.flush();
    // delay(10);
    // xTaskCreate(CaptureSamples, ""adc_read_task"", kAudioCaptureBufferSize, NULL, 1, &audioInputTaskHandle);
    audioCaptureFlag = 1;
    // vTaskResume(audioInputTaskHandle);
  }


  // This next part should only be called when the main thread notices that the
  // latest audio sample data timestamp has changed, so that there's new data
  // in the capture ring buffer. The ring buffer will eventually wrap around and
  // overwrite the data, but the assumption is that the main thread is checking
  // often enough and the buffer is large enough that this call will be made
  // before that happens.

  // Determine the index, in the history of all samples, of the first
  // sample we want
  const int start_offset = start_ms * (kAudioSampleFrequency / 1000);
  // Determine how many samples we want in total
  const int duration_sample_count =
      duration_ms * (kAudioSampleFrequency / 1000);
  // Serial.println(duration_sample_count);
  // delay(10);
  for (int i = 0; i < duration_sample_count; ++i) {
    
    // delay(1);
    // For each sample, transform its index in the history of all samples into
    // its index in g_audio_capture_buffer
    const int capture_index = (start_offset + i) % kAudioCaptureBufferSize;
    
    // Write the sample to the output buffer
    g_audio_output_buffer[i] = ((int16_t*)g_audio_capture_buffer)[capture_index];
    // Serial.printf(""inside loop %d\n"", i);
    // delay(1);
  }
  
  // Serial.printf(""got samples\n"");
  audioCaptureFlag = 0;
  // Serial.println(testerino);
  // delay(10);
  // testerino = 0;
  // vTaskDelete(audioInputTaskHandle);
  
  // Serial.println(""task deleted"");
  // delay(10);


  // Set pointers to provide access to the audio
  *audio_samples_size = kMaxAudioSampleSize;
  *audio_samples = g_audio_output_buffer;

  return kTfLiteOk;
}

int32_t LatestAudioTimestamp() { return g_latest_audio_timestamp; }
```
"
37139,Conda install Tensorflow 2.1 with mkl (avx/avx2 support) not working,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary):  tensorflow 3.1 with mkl binary from Anaconda installation
- TensorFlow version: 3.1.0
- Python version: 3.7.6
- Installed using virtualenv? pip? conda?: conda
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: na
- GPU model and memory: na



I was using tensorflow 2.0 with mkl (avx/avx2 optimization) and has zero problem. I just upgraded to tf 2.1 using Anaconda. After upgrade, tf complains that ""Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2"".

To make sure I upgraded correctly. I uninstalled all tensorflow components, and then do a fresh install using command conda install tensorflow-mkl. The installation succeed but the problem persists.

when I run the same training script, I saw the performance is worse than the 2.0. So, I guess the avx2 is not used in 2.1 




"
37138,Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: no such package '@png_archive//': Traceback (most recent call last):,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Windows 10
- TensorFlow installed from (source or binary): Source
- TensorFlow version:1.13
- Python version: 3.6.7
- Bazel version (if compiling from source):0.21.0
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:10.0
- GPU model and memory: Geforce GTX 1050/4gb



**when i try to build tensorflow from source with below command it arises errors**

`**bazel build --config=opt --config=cuda --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package**
`

```
**C:\Tensorflow_build\tensorflow>bazel build --config=opt --config=cuda --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package
WARNING: The following rc files are no longer being read, please transfer their contents or import their path into one of the standard rc files:
c:\tensorflow_build\tensorflow/.bazelrc
WARNING: The following configs were expanded more than once: [cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.
WARNING: Option 'experimental_shortened_obj_file_path' is deprecated
INFO: Invocation ID: 72078163-23a3-48fa-bd94-3ebfaea84d8b
ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: no such package '@png_archive//': Traceback (most recent call last):
        File ""C:/tensorflow_build/tensorflow/third_party/repo.bzl"", line 106
                _apply_patch(ctx, ctx.attr.patch_file)
        File ""C:/tensorflow_build/tensorflow/third_party/repo.bzl"", line 73, in _apply_patch
                _execute_and_check_ret_code(ctx, cmd)
        File ""C:/tensorflow_build/tensorflow/third_party/repo.bzl"", line 52, in _execute_and_check_ret_code
                fail(""Non-zero return code({1}) when ...))
Non-zero return code(2) when executing 'C:\tools\msys64\usr\bin\bash.exe -l -c ""patch"" ""-p1"" ""-d"" """"C:/users/shahansha c/_bazel_shahansha c/6v547imx/external/png_archive"""" ""-i"" ""C:/tensorflow_build/tensorflow/third_party/png_fix_rpi.patch""':
Stdout:
Stderr: patch: **** Can't change to directory C:/users/shahansha : No such file or directory
INFO: Elapsed time: 6.859s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (5 packages loaded, 338 targets configured)
    Fetching @icu; fetching 5s
    Fetching @grpc; fetching 5s
    Fetching @eigen_archive; fetching 5s
    Fetching @boringssl; fetching 5s
    Fetching @png_archive; fetching 5s
    Fetching @curl; fetching 5s
    Fetching @swig; fetching 5s
    Fetching @nasm; fetching**
```

i have a space in my username :(
may be that is the problem But i dont know how to change it
is there any way to build tensorflow from source when there is a white space in user name (on the path)"
37137,NameError: name 'LSTM' is not defined ,"
**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  **MAC OS CATALINA**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): **I'm pretty sure it is binary**
- TensorFlow version: **2.1.0**
- Python version: **3.7.6**
- Installed using virtualenv? pip? conda?: **pip3**
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: **10.2**
- GPU model and memory:  **Intel HD Graphics 4000 1536 MB** . Memory = **4 GB 1600 MHz DDR3**

**The problem**
I am attempting to build a LSTM model to process and predict datasets.  I have tensorflow installed on my mac and have keras installed.  I have also installed CUDA and some other sequential model libraries I heard would help, but my problem persists.  My program is returning the error

`Traceback (most recent call last):
  File ""/Users/owner/Desktop/algo/predict.py"", line 64, in <module>
    model.add(LSTM(50, return_sequences=True, input_shape=(x_train.shape[1], 1)))
NameError: name 'LSTM' is not defined`

My import statements look like this:

`import requests`
`import math`
`import numpy as np`
`import pandas as pd`
`import pandas_datareader as web`
`import tensorflow as tf`
`from tensorflow import keras`
`from tensorflow.keras import layers`
`from tensorflow.keras.models import Sequential, load_model`
`from sklearn.preprocessing import MinMaxScaler`
`from bs4 import BeautifulSoup`
`import matplotlib.pyplot as plt`
`from datetime import datetime, date`

and the code for the model looks like this:

`#Build LSTM MODEL`
`model = tf.keras.Sequential()`
`model.add(LSTM(50, return_sequences=True, input_shape=(x_train.shape[1], 1)))`
`model.add(LSTM(50, return_sequences=False))`
`model.add(Dense(25))`
`model.add(Dense(1))`
`model.compile(optimizer='adam', loss='mean_squared_error')`

I tried to look for an import statement that could import lstm from tensorflow
something like:
`from tensorflow.keras.models import LSTM`
But I could not find anything.

ThankYou,
RRR.
"
37135,Save and load model neural network,"Hi,
I am a beginner in neural network, I follow a tutorial (https://www.datacamp.com/community/tutorials/cnn-tensorflow-python) for create it.
[tuto.py.tar.gz](https://github.com/tensorflow/tensorflow/files/4262620/tuto.py.tar.gz)
-> It is my soft.

I add some lines to save a model of my network. I have "".meta"" file.
My problem is, how I can use this model on an other soft for predict if I have shirt, coat, ... in my image.





"
37134,"list of operators for which you will need custom implementations: StatelessWhile, TensorListFromTensor, TensorListReserve, TensorListStack, While.","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):16.04
- TensorFlow installed from (source or binary):pip3 install
- TensorFlow version (or github SHA if from source):2.1.0

I  want to convert an RNN model to tflite. The code I used is :
` converter = tf.lite.TFLiteConverter.from_saved_model(fd_path)
    converter.target_spec.supported_ops = [tf.lite.OpsSet.SELECT_TF_OPS]
    tflite_quant_model = converter.convert()`

but I got :

`Some of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: . Here is a list of operators for which you will need custom implementations: StatelessWhile, TensorListFromTensor, TensorListReserve, TensorListStack, While.`


I guess this error may be because I used `tfa.seq2seq.dynamic_decode` in my model. So I try to set:

`converter.experimental_new_converter = True`

and convert it again, but I got a new error:

`Exception: <unknown>:0: error: loc(""TensorArrayV2Write/cond@__inference_Tacotron_model_inference_decoder_while_body_1121_661_frozen""): failed to legalize operation 'tf.If'
`


I can't find any way to resolve this issue, and I want to know does TFlite support convert `dynamic_decode`? can this issue be resolved if I custom implementations: StatelessWhile, TensorListFromTensor, TensorListReserve, TensorListStack, While?
"
37133,How to access intermediate tensors that are used during the application (tf.app) lifecycle,"

Basically, I am running the evaluation script, provided by Tf's Object Detection API, using:

```
python3 object_detection/legacy/eval.py \
    --pipeline_config_path=../../faster_rcnn_resnet101_voc12.pbtxt\
    --checkpoint_dir=../../trainedmodel_voc07 \
    --eval_dir=../../eval_results \
    --run_once=True \
    --alsologtostderr
```

Now, this script outputs the bounding boxes on image along with prediction scores. But what I need is, the metrics calculated.

When I looked into the eval.py, I found that, it returns nothing. It run the evaluation, calculates the metrics but doesn't return it. So, I just changed the code to return the metrics and print it on console.

```
metrics = evaluator.evaluate(
        create_input_dict_fn,
        model_fn,
        eval_config,
        categories,
        FLAGS.checkpoint_dir,
        FLAGS.eval_dir,
        graph_hook_fn=graph_rewriter_fn,
    )
print(metrics)
```

But, as we know, this won't print the values inside the metric. I have tried several things like `metrics.numpy()` which won't work when eager execution is turned off. I have also tried using `metrics.eval()` by creating a session but this just hangs up the PC and does nothing.

Also, `tf.print()` won't work as it runs in graph mode.

Then I found that TF stores summaries of metrics and we can visualize it using tensorboard. That's okay.. but what I wanted to extract values from other tensors?

So, basically, how can I access the intermediate tensors in the script?"
37132,"""Could not append to the internal temporary file"" when writing checkpoints to GCP during TPU training","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Debian GNU/Linux 9.11 
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: N/A
- TensorFlow installed from (source or
binary): binary
 - TensorFlow version (use command below): 2.2.0.dev20200119
- Python version: Python 3.7.6
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from
source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
When training a model for 2 days+ on a TPU pod and saving checkpoints to a GCP bucket, I run into `tensorflow.python.framework.errors_impl.InternalError: Could not append to the internal temporary file. [Op:ReadVariableOp]` when writing checkpoints. This has happened a couple of times and is fixed by acquiring a new pod, so I suspect it is due to running out of space (on the TPU host it seems)? If this is the case, is it possible to diagnose when this is happening and delete old checkpoints to avoid training crashing?

**Describe the expected behavior**
Detect that space on the (TPU host?) is close to full and delete old checkpoints.

**Standalone code to reproduce the issue** 
Standard model run on TPU; wouldn't be reproducible without running a model for > 2 days.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

```
File ""/home/helen/.../estimator.py"", line 233, in train_and_evaluate
    checkpoint.save(os.path.join(output_dir, ""ckpt""))
  File ""/home/helen/anaconda3/envs/.../python3.7/site-packages/tensorflow_core/python/training/tracking/util.py"", line 1927, in save
    file_path = self.write(""%s-%d"" % (file_prefix, checkpoint_number))
  File ""/home/helen/anaconda3/envs/.../python3.7/site-packages/tensorflow_core/python/training/tracking/util.py"", line 1857, in write
    output = self._saver.save(file_prefix=file_prefix)
  File ""/home/helen/anaconda3/envs/.../python3.7/site-packages/tensorflow_core/python/training/tracking/util.py"", line 1187, in save
    file_prefix=file_prefix_tensor, object_graph_tensor=object_graph_tensor)
  File ""/home/helen/anaconda3/envs/.../python3.7/site-packages/tensorflow_core/python/training/tracking/util.py"", line 1135, in _save_cached_when_graph_building
    save_op = saver.save(file_prefix)
  File ""/home/helen/anaconda3/envs/.../python3.7/site-packages/tensorflow_core/python/training/saving/functional_saver.py"", line 250, in save
    sharded_saves.append(saver.save(shard_prefix))
  File ""/home/helen/anaconda3/envs/.../python3.7/site-packages/tensorflow_core/python/training/saving/functional_saver.py"", line 70, in save
    tensors.append(spec.tensor)
  File ""/home/helen/anaconda3/envs/.../python3.7/site-packages/tensorflow_core/python/training/saving/saveable_object.py"", line 55, in tensor
    return self._tensor() if callable(self._tensor) else self._tensor
  File ""/home/helen/anaconda3/envs/.../python3.7/site-packages/tensorflow_core/python/training/saving/saveable_object_util.py"", line 91, in f
    x = v.read_value()
  File ""/home/helen/anaconda3/envs/.../python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py"", line 638, in read_value
    value = self._read_variable_op()
  File ""/home/helen/anaconda3/envs/.../python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py"", line 616, in _read_variable_op
    self._dtype)
  File ""/home/helen/anaconda3/envs/.../python3.7/site-packages/tensorflow_core/python/ops/gen_resource_variable_ops.py"", line 479, in read_variable_op
    _ops.raise_from_not_ok_status(e, name)
  File ""/home/helen/anaconda3/envs/.../python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 6625, in raise_from_not_ok_status
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InternalError: Could not append to the internal temporary file. [Op:ReadVariableOp]
```"
37131,TensorRT 6/7 converter crash with tf 2.1.0,"Test code and steps to reproduce: https://github.com/bioothod/trt_crash_efficientnet
Happens both with `nvcr.io/nvidia/tensorflow:20.02-tf2-py3` and `tensorflow/tensorflow:2.1.0-gpu-py3`.

Stack trace:
```
(gdb) bt
#0  0x00007fff60219560 in tensorflow::Node::name() const () from /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../libtensorflow_framework.so.2
#1  0x00007fff6796af66 in tensorflow::tensorrt::convert::UpdateToEngineNode(std::vector<tensorflow::tensorrt::convert::EngineInfo, std::allocator<tensorflow::tensorrt::convert::EngineInfo> > const&, unsigned long, std::vector<tensorflow::Node*, std::allocator<tensorflow::Node*> > const&, bool, std::string const&, tensorflow::Node**, int*) ()
   from /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
#2  0x00007fff6796cfc5 in tensorflow::tensorrt::convert::CreateTRTNode(tensorflow::tensorrt::convert::ConversionParams const&, std::vector<tensorflow::tensorrt::convert::EngineInfo, std::allocator<tensorflow::tensorrt::convert::EngineInfo> > const&, int, int, tensorflow::Graph*, nvinfer1::IGpuAllocator*, std::vector<tensorflow::Node*, std::allocator<tensorflow::Node*> >*) ()
   from /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
#3  0x00007fff67972041 in tensorflow::tensorrt::convert::ConvertAfterShapes(tensorflow::tensorrt::convert::ConversionParams const&) ()
   from /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
#4  0x00007fff679ac34b in tensorflow::tensorrt::convert::TRTOptimizationPass::Optimize(tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem const&, tensorflow::GraphDef*) ()
   from /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
#5  0x00007fff6a31f937 in tensorflow::grappler::MetaOptimizer::RunOptimizer(tensorflow::grappler::GraphOptimizer*, tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem*, tensorflow::GraphDef*, tensorflow::grappler::MetaOptimizer::GraphOptimizationResult*) () from /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
#6  0x00007fff6a320ccd in tensorflow::grappler::MetaOptimizer::OptimizeGraph(tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem const&, tensorflow::GraphDef*) ()
   from /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
#7  0x00007fff6a322714 in tensorflow::grappler::MetaOptimizer::Optimize(tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem const&, tensorflow::GraphDef*) ()
   from /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
#8  0x00007fff6371cc07 in TF_OptimizeGraph(GCluster, tensorflow::ConfigProto const&, tensorflow::MetaGraphDef const&, bool, std::string const&, bool, TF_Status*) ()
   from /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
#9  0x00007fff637217d6 in _wrap_TF_OptimizeGraph () from /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
#10 0x000000000050a8af in ?? ()
#11 0x000000000050c5b9 in _PyEval_EvalFrameDefault ()
#12 0x0000000000508245 in ?? ()
#13 0x000000000050a080 in ?? ()
#14 0x000000000050aa7d in ?? ()
```"
37130,Half precision training very slow and returning nan loss ,"<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information** 

- OS Platform and Distribution : Win10
- TensorFlow version (use command below): 2.1.0
- Python version: 3.6.8
- CUDA/cuDNN version:  10.1 / 7.6.4
- GPU model and memory: RTX2080ti (11GB)



**Describe the current behavior**

I used the ""mixed_float16"" policy to train the efficientnet model (https://github.com/qubvel/efficientnet), but the training become almost 10 times slower and return nan even if I set a large epsilon.

https://www.tensorflow.org/api_docs/python/tf/keras/mixed_precision/experimental/Policy?hl=en

here are some of the codes to setup mixed float training:
```
from tensorflow.keras.mixed_precision import experimental as mixed_precision
policy = mixed_precision.Policy('mixed_float16')
mixed_precision.set_policy(policy)
K.set_epsilon(1e-3)
```
P.S.: When I trained the densenet121 from (tf.keras.applications) using mixed float16, it runs pretty well. "
37128,AttributeError: module 'tensorflow' has no attribute 'app' in tensorflow 2.1.0,"
**System information** 
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or
binary): source
- TensorFlow version (use command below): V2.1.0
- Python version: 3.7.6
- CUDA/cuDNN version: 10.1/7.6
- GPU model and memory: GTX 1050, 8G

**Describe the current behavior**
I write `FLAGS = tf.compat.v1.flags.FLAGS` in my file, but there is still an error,
`
 FLAGS = tf.compat.v1.app.flags.FLAGS
AttributeError: module 'tensorflow' has no attribute 'app'
`

"
37127,Tensorflow 2.1.0 failed to get convolution algorithm in docker,"ref. https://github.com/tensorflow/tensorflow/issues/27141#issuecomment-591939338


> This problem may cause with tensorflow's docker (2.1.0-gpu-py3) in the below host
> 
> - OS: 5.5.2-1-MANJARO
> - Cuda: 10.1
> - cuddn: 7.6.5
> - docker-compose version 1.25.4
> - docker-version: 19.03.5-ce, build 633a0ea838
> 
> Tensorflow is affected by HOST OS?"
37126,Can i use embedding projector as a stand alone application in my personal/commercial applications ? ,
37123,Unsupported object type float,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Ubuntu 18.10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: N/A
- TensorFlow installed from (source or
binary): binary 
- TensorFlow version (use command below): 2.1.0
- Python version: 3.7.3
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from
source): N/A
- CUDA/cuDNN version: nvcc version 10.1 (V10.1.105)
- GPU model and memory: NVIDIA Quadro P2000 5GB

**Describe the current behavior**
I am loading in a concatenation of two user data sources (one script generated and on read in via `pd.read_csv`).
I paid attention to have both datasources have the same dtypes, column names, etc. 
I concatenate via 
```
fakedata = td.generate_data(40000)
realdata = pd.read_csv(""DS.csv"")
data = fakedata.append(realdata).reset_index()[fakedata.columns]
```
DataFrame structure is as follows:
| firstname | lastname | company | country | email | fake |
| Lorem | ipsum | Loremcorp | USA | lorem.ipsum@sit.amet | 1 |

whereas `data[""fake""]` is the target column having either 0 or 1 as state.
dtypes of the are object and of `data[""fake""]` is `int64`.

train input fn:
```
train_input_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(
    data, data[""fake""], num_epochs=None, shuffle=True
)
```
training:
```
estimator = tf.estimator.DNNClassifier(
    hidden_units=[500, 100],
    feature_columns=[email_feature_column, 
                     firstname_feature_column, 
                     lastname_feature_column, 
                     country_feature_column, 
                     company_feature_column],
    n_classes=2,
    optimizer=tf.keras.optimizers.Adagrad(lr=0.003))

estimator.train(input_fn=train_input_fn, steps=5000)
```
Feature columns are created via the `text_embedding_column` from tfhub.

When I now try to run the code this error keeps happening:
```
Traceback (most recent call last):
  File ""/home/damned/.local/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 1367, in _do_call
    return fn(*args)
  File ""/home/damned/.local/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 1352, in _run_fn
    target_list, run_metadata)
  File ""/home/damned/.local/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 1445, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.InternalError: Unsupported object type float

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""tensorflow_model.py"", line 67, in <module>
    estimator.train(input_fn=train_input_fn, steps=100000)
  File ""/home/damned/.local/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 374, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/home/damned/.local/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1164, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""/home/damned/.local/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1198, in _train_model_default
    saving_listeners)
  File ""/home/damned/.local/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1498, in _train_with_estimator_spec
    any_step_done = True
  File ""/home/damned/.local/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py"", line 885, in __exit__
    self._close_internal(exception_type)
  File ""/home/damned/.local/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py"", line 923, in _close_internal
    self._sess.close()
  File ""/home/damned/.local/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py"", line 1190, in close
    self._sess.close()
  File ""/home/damned/.local/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py"", line 1358, in close
    ignore_live_threads=True)
  File ""/home/damned/.local/lib/python3.7/site-packages/tensorflow_core/python/training/coordinator.py"", line 389, in join
    six.reraise(*self._exc_info_to_raise)
  File ""/usr/lib/python3/dist-packages/six.py"", line 692, in reraise
    raise value.with_traceback(tb)
  File ""/home/damned/.local/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py"", line 94, in _run
    sess.run(enqueue_op, feed_dict=feed_dict)
  File ""/home/damned/.local/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 960, in run
    run_metadata_ptr)
  File ""/home/damned/.local/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 1183, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/damned/.local/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 1361, in _do_run
    run_metadata)
  File ""/home/damned/.local/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 1386, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InternalError: Unsupported object type float
```
even if there is no float in the dataset.

**Describe the expected behavior**
`estimator.train(input_fn=train_input_fn, steps=5000)`
Works as expected and trains."
37122,"What is ""FrameState"" and ""IterationState"" for in tensorflow source code?","This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.

Hello, I am currently looking at tensorflow source code to understand internal functionalities.
I looked up and surfed around to understand what ""Frame"" and ""Iteration"" mean but couldn't. Also, I searched on the web but couldn't find the answer. 

struct ""FrameState"" and struct ""IterationState""
FrameState is for loop and IterationState represents an iteration based on comments.
What is the loop here in this context? I see loop is loop like 'for' or 'while' but where is the loop represented by FrameState? Is it something for handling ""tf.while_loop""? 

PendingCounts is managed in the scope of IterationState, I guess all the nodes have their own pending counts to activate them. Why does pending counts belong to Iteration? Node is considered a independent unit and they can be activated if incoming edges is all given(available). I don't see how this pending counts are related to IterationState.

Thank you in advance!!"
37119,Feature Request: [Keras] Add _keras_history to tensor in Eager Mode,"For some losses such as CRF loss, it's computation does not only rely on `y_true` and `y_pred`, it must access the layer's internal variable.

 In such a situation, `_keras_history` will be greate helpful.  The loss function can use `_keras_history` of `y_pred` to get the layer instance then get the variables. 

But in eager mode, the output tensor does not have `_keras_history`, which makes such losses not easy to implement in Keras without a custom patch to layers or custom models.

related to tensorflow/addons#377"
37118,How to save model by training steps using tf.keras.callbacks.ModelCheckpoint,"My training data is very large, which means it have many training steps each epoch. I want to use `tf.keras.callbacks.ModelCheckpoint` to save a model every `100,000` steps, and save all these models in disk, not rewrite the model files when saving a new one. But I have no idea how to do this after i read the documentation. It seems that this callback is designed to save a model by epoch.

So, do i have to implement a custom callback to save the model by steps?"
37117,module 'tensorflow.python.framework.op_def_registry' has no attribute 'register_op_list',"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- TensorFlow version (or github SHA if from source):


**Provide the text output from tflite_convert**
```
(tfpose) C:\Users\S V J KUMAR\Downloads\tf-pose-estimation-master (1)\tf-pose-estimation-master>python run.py --image=p1.jpg
Traceback (most recent call last):
  File ""run.py"", line 7, in <module>
    from tf_pose import common
  File ""C:\Users\S V J KUMAR\Downloads\tf-pose-estimation-master (1)\tf-pose-estimation-master\tf_pose\__init__.py"", line 5, in <module>
    from tf_pose.runner import infer, Estimator, get_estimator
  File ""C:\Users\S V J KUMAR\Downloads\tf-pose-estimation-master (1)\tf-pose-estimation-master\tf_pose\runner.py"", line 8, in <module>
    from tf_pose import eval
  File ""C:\Users\S V J KUMAR\Downloads\tf-pose-estimation-master (1)\tf-pose-estimation-master\tf_pose\eval.py"", line 13, in <module>
    from tf_pose.estimator import TfPoseEstimator
  File ""C:\Users\S V J KUMAR\Downloads\tf-pose-estimation-master (1)\tf-pose-estimation-master\tf_pose\estimator.py"", line 14, in <module>
    import tensorflow.contrib.tensorrt as trt
  File ""C:\Users\S V J KUMAR\Anaconda3\envs\tfpose\lib\site-packages\tensorflow\contrib\__init__.py"", line 22, in <module>
    from tensorflow.contrib import bayesflow
  File ""C:\Users\S V J KUMAR\Anaconda3\envs\tfpose\lib\site-packages\tensorflow\contrib\bayesflow\__init__.py"", line 24, in <module>
    from tensorflow.contrib.bayesflow.python.ops import csiszar_divergence
  File ""C:\Users\S V J KUMAR\Anaconda3\envs\tfpose\lib\site-packages\tensorflow\contrib\bayesflow\python\ops\csiszar_divergence.py"", line 26, in <module>
    from tensorflow.contrib.bayesflow.python.ops.csiszar_divergence_impl import *
  File ""C:\Users\S V J KUMAR\Anaconda3\envs\tfpose\lib\site-packages\tensorflow\contrib\bayesflow\python\ops\csiszar_divergence_impl.py"", line 43, in <module>
    from tensorflow.contrib import framework as contrib_framework
  File ""C:\Users\S V J KUMAR\Anaconda3\envs\tfpose\lib\site-packages\tensorflow\contrib\framework\__init__.py"", line 93, in <module>
    from tensorflow.contrib.framework.python.ops import *
  File ""C:\Users\S V J KUMAR\Anaconda3\envs\tfpose\lib\site-packages\tensorflow\contrib\framework\python\ops\__init__.py"", line 28, in <module>
    from tensorflow.contrib.framework.python.ops.variables import *
  File ""C:\Users\S V J KUMAR\Anaconda3\envs\tfpose\lib\site-packages\tensorflow\contrib\framework\python\ops\variables.py"", line 26, in <module>
    from tensorflow.contrib.framework.python.ops import gen_variable_ops
  File ""C:\Users\S V J KUMAR\Anaconda3\envs\tfpose\lib\site-packages\tensorflow\contrib\framework\python\ops\gen_variable_ops.py"", line 95, in <module>
    _op_def_lib = _InitOpDefLibrary(b""\nR\n\017ZeroInitializer\022\013\n\003ref\""\001T\200\001\001\032\022\n\noutput_ref\""\001T\200\001\001\""\033\n\001T\022\004type:\020\n\0162\014\001\002\003\t\004\005\006\021\023\026\027\016\230\001\001"")
  File ""C:\Users\S V J KUMAR\Anaconda3\envs\tfpose\lib\site-packages\tensorflow\contrib\framework\python\ops\gen_variable_ops.py"", line 57, in _InitOpDefLibrary
    _op_def_registry.register_op_list(op_list)
AttributeError: module 'tensorflow.python.framework.op_def_registry' has no attribute 'register_op_list'

```

**Standalone code to reproduce the issue** 

import argparse
import logging
import sys
import time
import os

from tf_pose import common
import cv2
import numpy as np
from tf_pose.estimator import TfPoseEstimator
from tf_pose.networks import get_graph_path, model_wh

logger = logging.getLogger('TfPoseEstimatorRun')
logger.handlers.clear()
logger.setLevel(logging.DEBUG)
ch = logging.StreamHandler()
ch.setLevel(logging.DEBUG)
formatter = logging.Formatter('[%(asctime)s] [%(name)s] [%(levelname)s] %(message)s')
ch.setFormatter(formatter)
logger.addHandler(ch)


if __name__ == '__main__':
    os.chdir('..')
    parser = argparse.ArgumentParser(description='tf-pose-estimation run')
    parser.add_argument('--image', type=str, default='./images/p1.jpg')
    parser.add_argument('--model', type=str, default='cmu',
                        help='cmu / mobilenet_thin / mobilenet_v2_large / mobilenet_v2_small')
    parser.add_argument('--resize', type=str, default='0x0',
                        help='if provided, resize images before they are processed. '
                             'default=0x0, Recommends : 432x368 or 656x368 or 1312x736 ')
    parser.add_argument('--resize-out-ratio', type=float, default=4.0,
                        help='if provided, resize heatmaps before they are post-processed. default=1.0')

    args = parser.parse_args()

    w, h = model_wh(args.resize)
    if w == 0 or h == 0:
        e = TfPoseEstimator(get_graph_path(args.model), target_size=(432, 368))
    else:
        e = TfPoseEstimator(get_graph_path(args.model), target_size=(w, h))

    # estimate human poses from a single image !
    image = common.read_imgfile(args.image, None, None)
    if image is None:
        logger.error('Image can not be read, path=%s' % args.image)
        sys.exit(-1)

    t = time.time()
    humans = e.inference(image, resize_to_default=(w > 0 and h > 0), upsample_size=args.resize_out_ratio)
    elapsed = time.time() - t

    logger.info('inference image: %s in %.4f seconds.' % (args.image, elapsed))

    image = TfPoseEstimator.draw_humans(image, humans, imgcopy=False)

    try:
        import matplotlib.pyplot as plt

        fig = plt.figure()
        a = fig.add_subplot(2, 2, 1)
        a.set_title('Result')
        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))

        bgimg = cv2.cvtColor(image.astype(np.uint8), cv2.COLOR_BGR2RGB)
        bgimg = cv2.resize(bgimg, (e.heatMat.shape[1], e.heatMat.shape[0]), interpolation=cv2.INTER_AREA)

        # show network output
        a = fig.add_subplot(2, 2, 2)
        plt.imshow(bgimg, alpha=0.5)
        tmp = np.amax(e.heatMat[:, :, :-1], axis=2)
        plt.imshow(tmp, cmap=plt.cm.gray, alpha=0.5)
        plt.colorbar()

        tmp2 = e.pafMat.transpose((2, 0, 1))
        tmp2_odd = np.amax(np.absolute(tmp2[::2, :, :]), axis=0)
        tmp2_even = np.amax(np.absolute(tmp2[1::2, :, :]), axis=0)

        a = fig.add_subplot(2, 2, 3)
        a.set_title('Vectormap-x')
        # plt.imshow(CocoPose.get_bgimg(inp, target_size=(vectmap.shape[1], vectmap.shape[0])), alpha=0.5)
        plt.imshow(tmp2_odd, cmap=plt.cm.gray, alpha=0.5)
        plt.colorbar()

        a = fig.add_subplot(2, 2, 4)
        a.set_title('Vectormap-y')
        # plt.imshow(CocoPose.get_bgimg(inp, target_size=(vectmap.shape[1], vectmap.shape[0])), alpha=0.5)
        plt.imshow(tmp2_even, cmap=plt.cm.gray, alpha=0.5)
        plt.colorbar()
        plt.show()
    except Exception as e:
        logger.warning('matplitlib error, %s' % e)
        cv2.imshow('result', image)
        cv2.waitKey()




Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

Also, please include a link to a GraphDef or the model if possible.

**Any other info / logs**
i am using openpose code to find the 3D coordinates of a person in 2D image . by the tutorial i found this code and when running this in python 3 . 

any other way for the accomplishment of the objective can also be entertained. 
will be grateful  for the help 
Include any logs or source code that would be helpful to diagnose the problem.
If including tracebacks, please include the full traceback. Large logs and files
should be attached.
"
37116,"How to build Tflite-gpu to use GPU delegate, NNAPI delegate for devices like Hikey (AARCH64)","I was trying to use label_image.cpp example in Tflite. I was unable to make use of delegate options in the example after setting gl_backend, useNNAPI , accel and old accel , hexagon etc.. delegate flags to true. 

Is GPU delegate only restricted to Android and Ios devices ?

If not how to build TFlite with gpu on other devices like host pc for simulation, Hikey(AArch64) and Raspberry Pi(armv7,rpi) ?

Is NNAPI & Hexagon delegate only restricted to Android and Ios devices ?
If not how to build TFlite with NNAPI on other devices like host pc for simulation, Hikey(AArch64) and Raspberry Pi(armv7,rpi) ?

Does devices having snapdragon soc's such as (835,660) which are running in Linux(development boards which dont have Android Os). If yes , how to build with the delegate and increase performance ?

I don't find any Makefile to build with these delegate options enabled. Could you provide steps to build (or) Makefile for making use of these delegate options?"
37113,AttributeError: module 'tensorboard.summary._tf.summary' has no attribute 'FileWriter',"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): 
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04):  Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
- TensorFlow installed from (source or
binary): pip3
 - TensorFlow version (use command below): 2.1.0 
- Python version: - Bazel
version (if compiling from source):
- GCC/Compiler version (if compiling from
source): 
- CUDA/cuDNN version: - GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
2020-02-27 10:37:08.494214: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[       OK ] ModuleTest.testBuiltInName
[ RUN      ] ModuleTest.testCanLoadWithPkgutil
[       OK ] ModuleTest.testCanLoadWithPkgutil
[ RUN      ] ModuleTest.testCompatV2HasCompatV1
[       OK ] ModuleTest.testCompatV2HasCompatV1
[ RUN      ] ModuleTest.testDict
[       OK ] ModuleTest.testDict
[ RUN      ] ModuleTest.testDocString
[       OK ] ModuleTest.testDocString
[ RUN      ] ModuleTest.testName
[       OK ] ModuleTest.testName
[ RUN      ] ModuleTest.testSummaryMerged
[  FAILED  ] ModuleTest.testSummaryMerged
[ RUN      ] ModuleTest.test_session
[  SKIPPED ] ModuleTest.test_session
======================================================================
ERROR: testSummaryMerged (__main__.ModuleTest)
testSummaryMerged (__main__.ModuleTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""module_test.py"", line 79, in testSummaryMerged
    tf.summary.FileWriter
AttributeError: module 'tensorboard.summary._tf.summary' has no attribute 'FileWriter'

----------------------------------------------------------------------
Ran 8 tests in 0.035s
"
37112,"Custom training loop, iteration over Dataset hangs under MultiWorkerMirroredStrategy","**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow):  Yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): TensorFlow 2.0.1 GPU official docker image
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): 2.0.1
- Python version: - Bazel 
version (if compiling from source):
- GCC/Compiler version (if compiling from
source): 
- CUDA/cuDNN version: - GPU model and memory: CUDA 10.1 V100 16G

**Describe the current behavior**
I use the following scheme to iterate over Dataset.
```
for epoch in range(FLAGS.epoch):
        for train_data in train_dataset:
           ...
```
Train stops at the last few batches of the first epoch. I found that documentation https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras  mentions only `keras.fit`
**Describe the expected behavior**
It should be explicitly mentioned, or produce some logs when running in such scenario.
Currently, before the hang, only one line is printed in log.
```
INFO:tensorflow:Collective batch_all_reduce: xxx all-reduces, num_workers = xxx
I0225 cross_device_ops.py:1107] Collective batch_all_reduce: xxx all-reduces, num_workers = xxx
```

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
37111,representative_data_gen input order?,"In tflite post integer quantization, `converter.representative_dataset` is necessary.

However, the documentation never specifies the order of the fed inputs. Are they ordered by lexicographic order of the names, size of shapes or even random order? When multiple inputs are present, it is totally a guessing game.

"
37110,Tflite build error on Android.,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: All of them
- TensorFlow installed from (source or binary): source
- TensorFlow version: r2.2-nightly
- Python version: 3.7.3
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source): 2.0.0
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

I've built a arm64 .so from master (using commit: 001037c4692a09e453777a96a609251cb7c94fac) and I'm including `tensorflow/tensorflow/lite` headers into my Android project. However, I'm getting the following error when I attempt to build my android project: 
```
In file included from ...../distribution/include/tensorflow\tensorflow/lite/core/subgraph.h:27:

...../distribution/include/tensorflow\tensorflow/lite/delegates/nnapi/nnapi_delegate.h:23:10: fatal error: 'absl/types/optional.h' file not found

#include ""absl/types/optional.h""

         ^~~~~~~~~~~~~~~~~~~~~~~
1 error generated.
ninja: build stopped: subcommand failed.
```
Building the project using .so from r2.1 or earlier branches + using headers of the same version works fine.
Also if I attempt using .so build from master but use old headers from `r2.1`, the Android project builds but fails whenever using the tflite interpreter. "
37109,Build from source(python2.7 ubuntu 16.04) has error:  AttributeError: attribute '__doc__' of 'type' objects is not writable,"**System information** 
Linux Ubuntu 16.04): 

- TensorFlow installed from (source or
binary): - TensorFlow version 1.13.2
- Python version: 2.7.12
- Bazel version 0.22.0
- GCC  5.4.0
- CUDA/cuDNN version: - 10.0/7.6.4
cuda-repo-ubuntu1604-10-0-local-10.0.130-410.48_1.0-1_amd64.deb
cuda-repo-ubuntu1604-10-0-local-nvjpeg-update-1_1.0-1_amd64.deb

libcudnn7_7.6.4.38-1+cuda10.0_amd64.deb
libcudnn7-dev_7.6.4.38-1+cuda10.0_amd64.deb
libnvinfer5_5.0.2-1+cuda10.0_amd64.deb
libnvinfer-dev_5.0.2-1+cuda10.0_amd64.deb
libnvinfer-samples_5.0.2-1+cuda10.0_all.deb
tensorrt_5.0.2.6-1+cuda10.0_amd64.deb
./configure    cuda  yes    tensorrt yes

also tried on ubuntu 18.04  
tensorflow 1.15.2
bazel 0.24.1
cuda/cudnn   10.2/7.6.5 same problem
tensorrt  nv-tensorrt-repo-cuda10.2-trt6.0.1.8-ga-20191108
--------------------------------
     return *(float*)&ilane;
                      ^
tensorflow/lite/toco/tflite/import.cc: At global scope:
tensorflow/lite/toco/tflite/import.cc:195:6: warning: 'bool toco::tflite::{anonymous}::Verify(const void*, size_t)' defined but not used [-Wunused-function]
 bool Verify(const void* buf, size_t len) {
      ^
ERROR: /home/weilo/tensorflow-1.13.2/tensorflow/BUILD:579:1: Executing genrule //tensorflow:tf_python_api_gen_v1 failed (Exit 1)
Traceback (most recent call last):
  File ""/home/weilo/.cache/bazel/_bazel_weilo/5dc966cf5c885efffef93d319484bf56/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py"", line 27, in <module>
    from tensorflow.python.tools.api.generator import doc_srcs
  File ""/home/weilo/.cache/bazel/_bazel_weilo/5dc966cf5c885efffef93d319484bf56/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/__init__.py"", line 63, in <module>
    from tensorflow.python.framework.framework_lib import *  # pylint: disable=redefined-builtin
  File ""/home/weilo/.cache/bazel/_bazel_weilo/5dc966cf5c885efffef93d319484bf56/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/framework/framework_lib.py"", line 52, in <module>
    from tensorflow.python.framework.importer import import_graph_def
  File ""/home/weilo/.cache/bazel/_bazel_weilo/5dc966cf5c885efffef93d319484bf56/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/framework/importer.py"", line 28, in <module>
    from tensorflow.python.framework import function
  File ""/home/weilo/.cache/bazel/_bazel_weilo/5dc966cf5c885efffef93d319484bf56/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/framework/function.py"", line 36, in <module>
    from tensorflow.python.ops import resource_variable_ops
  File ""/home/weilo/.cache/bazel/_bazel_weilo/5dc966cf5c885efffef93d319484bf56/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/ops/resource_variable_ops.py"", line 39, in <module>
    from tensorflow.python.ops import variables
  File ""/home/weilo/.cache/bazel/_bazel_weilo/5dc966cf5c885efffef93d319484bf56/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/ops/variables.py"", line 133, in <module>
    ""* `ONLY_FIRST_TOWER`: Deprecated alias for `ONLY_FIRST_REPLICA`.\n  "")
AttributeError: attribute '__doc__' of 'type' objects is not writable
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 16309.185s, Critical Path: 310.76s
INFO: 15104 processes: 15104 local.
FAILED: Build did NOT complete successfully
"
37108,TF 2.0 MultiWorkerMirror strategy hangs for MNIST Keras model training,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow):  yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Red Hat Enterprise Linux Server release 7.4 (Maipo)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): 2.0
- Python version: 3.7  
Bazel version (if compiling from source): 0.26.1 
- GCC/Compiler version (if compiling from
source): GCC 7.3.1
--
- CUDA/cuDNN version: - GPU model and memory: 10.1/7.6  NVIDIA TESLA V100

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I'm using TF 2.0 multi-worker mirror strategy to  train keras mnist model using two nodes. Each node has 6 NVIDIA Tesla V100 GPUs. It hangs after starting the  grpc server.Please see the log for details.
 
**Describe the expected behavior**
It should start synchronous multi-worker training. 

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
Please see the code in attachment.



**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
Please see the log in attachment.

[mnist_multi_node_multi_gpu_py.txt](https://github.com/tensorflow/tensorflow/files/4258761/mnist_multi_node_multi_gpu_py.txt)
[worker0.txt](https://github.com/tensorflow/tensorflow/files/4259179/worker0.txt)
[worker1.txt](https://github.com/tensorflow/tensorflow/files/4259180/worker1.txt)


"
37105,Tensorflow 2.0 uncompatible with guinicorn,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code
- OS Platform and Distribution (e.g.,Linux Ubuntu 18.04): 
- TensorFlow installed from binary
 - TensorFlow version 2.0: 
- Keras Version: tested with 2.3.1 and 2.3.0
- Python version: - 3.6.5
- CUDA/cuDNN version: - GPU model and memory:

**Describe the current behavior**

I have a feed-forward NN and I saved it as .h5 and I can make predictions, but when I set an endpoint using Flask and guinicorn and then I call my model for predictions I get the following message: 
AttributeError: 'gevent._local.local' object has no attribute 'value'

**Describe the expected behavior**
the expected behavior would be that when I made a request

curl -X POST ....
it returned the predictions for my request"
37104,Using Precison metric in compile method raises shape mismatch error,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Windows 10 Home
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: No mobile device
- **TensorFlow installed from (source or binary)**: Installed using Pip command
- **TensorFlow version (use command below)**: 2.1.0
- **Python version**: 3.6.8
- **Bazel version (if compiling from source)**: No
- **GCC/Compiler version (if compiling from source)**: No
- **CUDA/cuDNN version**: No
- **GPU model and memory**: No
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I am trying o implement different training metrics for keras sequential API. However when I try to implement precision method I get an error of shape mismatch. The same thing works when I use sigmoid as activation function instead of softmax. 

I am trying to solve binary classification problem.

Code to create model:
```
def create_model():
    model = tf.keras.Sequential([
    feature_layer,
    tf.keras.layers.Dense(units = 12, activation='relu', use_bias = True, kernel_initializer= 'glorot_normal', bias_initializer = 'zeros', name = 'd1'),
    tf.keras.layers.Dense(units = 6, activation='relu', use_bias = True, kernel_initializer= 'glorot_normal', bias_initializer = 'zeros', name = 'd2'),
    tf.keras.layers.Dense(units = 2, activation='softmax', name = 'out')
    ])
    model.compile(optimizer='adam',
                  loss='sparse_categorical_crossentropy',
                  metrics=[tf.keras.metrics.Precision()])
    return model
```
The same code runs when I try to run with sigmoid activation fuction with 1 output unit and Binary Crossentropy as my loss. 

### Source code / logs
```
Traceback (most recent call last):
  File ""4.py"", line 217, in <module>
    callbacks = ALL_CALLBACKS)
  File ""C:\Users\Aniket\Desktop\Class\class_env\lib\site-packages\tensorflow_core\python\keras\engine\training.py"", line 819, in fit
    use_multiprocessing=use_multiprocessing)
  File ""C:\Users\Aniket\Desktop\Class\class_env\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py"", line 342, in fit
    total_epochs=epochs)
  File ""C:\Users\Aniket\Desktop\Class\class_env\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py"", line 128, in run_one_epoch
    batch_outs = execution_function(iterator)
  File ""C:\Users\Aniket\Desktop\Class\class_env\lib\site-packages\tensorflow_core\python\keras\engine\training_v2_utils.py"", line 98, in execution_function
    distributed_function(input_fn))
  File ""C:\Users\Aniket\Desktop\Class\class_env\lib\site-packages\tensorflow_core\python\eager\def_function.py"", line 568, in __call__
    result = self._call(*args, **kwds)
  File ""C:\Users\Aniket\Desktop\Class\class_env\lib\site-packages\tensorflow_core\python\eager\def_function.py"", line 615, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File ""C:\Users\Aniket\Desktop\Class\class_env\lib\site-packages\tensorflow_core\python\eager\def_function.py"", line 497, in _initialize
    *args, **kwds))
  File ""C:\Users\Aniket\Desktop\Class\class_env\lib\site-packages\tensorflow_core\python\eager\function.py"", line 2389, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""C:\Users\Aniket\Desktop\Class\class_env\lib\site-packages\tensorflow_core\python\eager\function.py"", line 2703, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""C:\Users\Aniket\Desktop\Class\class_env\lib\site-packages\tensorflow_core\python\eager\function.py"", line 2593, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""C:\Users\Aniket\Desktop\Class\class_env\lib\site-packages\tensorflow_core\python\framework\func_graph.py"", line 978, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""C:\Users\Aniket\Desktop\Class\class_env\lib\site-packages\tensorflow_core\python\eager\def_function.py"", line 439, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""C:\Users\Aniket\Desktop\Class\class_env\lib\site-packages\tensorflow_core\python\keras\engine\training_v2_utils.py"", line 85, in distributed_function
    per_replica_function, args=args)
  File ""C:\Users\Aniket\Desktop\Class\class_env\lib\site-packages\tensorflow_core\python\distribute\distribute_lib.py"", line 763, in experimental_run_v2
    return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
  File ""C:\Users\Aniket\Desktop\Class\class_env\lib\site-packages\tensorflow_core\python\distribute\distribute_lib.py"", line 1819, in call_for_each_replica
    return self._call_for_each_replica(fn, args, kwargs)
  File ""C:\Users\Aniket\Desktop\Class\class_env\lib\site-packages\tensorflow_core\python\distribute\distribute_lib.py"", line 2164, in _call_for_each_replica
    return fn(*args, **kwargs)
  File ""C:\Users\Aniket\Desktop\Class\class_env\lib\site-packages\tensorflow_core\python\autograph\impl\api.py"", line 292, in wrapper
    return func(*args, **kwargs)
  File ""C:\Users\Aniket\Desktop\Class\class_env\lib\site-packages\tensorflow_core\python\keras\engine\training_v2_utils.py"", line 433, in train_on_batch
    output_loss_metrics=model._output_loss_metrics)
  File ""C:\Users\Aniket\Desktop\Class\class_env\lib\site-packages\tensorflow_core\python\keras\engine\training_eager.py"", line 316, in train_on_batch
    model, outs, targets, sample_weights=sample_weights, masks=masks)
  File ""C:\Users\Aniket\Desktop\Class\class_env\lib\site-packages\tensorflow_core\python\keras\engine\training_eager.py"", line 74, in _eager_metrics_fn
    skip_target_masks=model._prepare_skip_target_masks())
  File ""C:\Users\Aniket\Desktop\Class\class_env\lib\site-packages\tensorflow_core\python\keras\engine\training.py"", line 2004, in _handle_metrics
    target, output, output_mask))
  File ""C:\Users\Aniket\Desktop\Class\class_env\lib\site-packages\tensorflow_core\python\keras\engine\training.py"", line 1955, in _handle_per_output_metrics
    metric_fn, y_true, y_pred, weights=weights, mask=mask)
  File ""C:\Users\Aniket\Desktop\Class\class_env\lib\site-packages\tensorflow_core\python\keras\engine\training_utils.py"", line 1155, in call_metric_function
    return metric_fn(y_true, y_pred, sample_weight=weights)
  File ""C:\Users\Aniket\Desktop\Class\class_env\lib\site-packages\tensorflow_core\python\keras\metrics.py"", line 196, in __call__
    replica_local_fn, *args, **kwargs)
  File ""C:\Users\Aniket\Desktop\Class\class_env\lib\site-packages\tensorflow_core\python\keras\distribute\distributed_training_utils.py"", line 1135, in call_replica_local_fn
    return fn(*args, **kwargs)
  File ""C:\Users\Aniket\Desktop\Class\class_env\lib\site-packages\tensorflow_core\python\keras\metrics.py"", line 179, in replica_local_fn
    update_op = self.update_state(*args, **kwargs)  # pylint: disable=not-callable
  File ""C:\Users\Aniket\Desktop\Class\class_env\lib\site-packages\tensorflow_core\python\keras\utils\metrics_utils.py"", line 76, in decorated
    update_op = update_state_fn(*args, **kwargs)
  File ""C:\Users\Aniket\Desktop\Class\class_env\lib\site-packages\tensorflow_core\python\keras\metrics.py"", line 1216, in update_state
    sample_weight=sample_weight)
  File ""C:\Users\Aniket\Desktop\Class\class_env\lib\site-packages\tensorflow_core\python\keras\utils\metrics_utils.py"", line 303, in update_confusion_matrix_variables
    y_pred.shape.assert_is_compatible_with(y_true.shape)
  File ""C:\Users\Aniket\Desktop\Class\class_env\lib\site-packages\tensorflow_core\python\framework\tensor_shape.py"", line 1110, in assert_is_compatible_with
    raise ValueError(""Shapes %s and %s are incompatible"" % (self, other))
ValueError: Shapes (None, 2) and (None, 1) are incompatible
```"
37103,Add support for more keras.metrics.* to accept from_logits argument.,"**System information** 
- Have I written custom code: Yes
- OS Platform and Distribution: Linux
- CUDA/cuDNN version: CUDA Version: 10.1
- GPU model and memory: GeForce GTX 1080

**Describe the current behavior**
Currently, in [keras.metrics](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/), all the metrics for binary classification only accept values in the range [0, 1]. This is an issue as all the models in TF2.x tutorials output logits (ranges from [-inf, +inf]) and AVOID using an activation in the last layer such as `sigmoid` (ranges from [0, 1])

Current (preferred way): `keras.layers.Dense(1)                                  # Output range is [-inf, +inf]`
Before (deprecated):      `keras.layers.Dense(1, activation='sigmoid') # Output range is [0,1]`

Now, if my model outputs values in the range [-inf, +inf] as per the current preferred way, I CANNOT use any of the following metrics as they all expect values in the range [0, 1]

```
1. keras.metrics.Precision(name='precision')
2. keras.metrics.BinaryAccuracy(name='accuracy')
3. keras.metrics.Recall(name='recall')
4. keras.metrics.AUC(name='auc')
5. keras.metrics.TruePositives(name='tp')
6. keras.metrics.FalsePositives(name='fp')
7. keras.metrics.TrueNegatives(name='tn')
8. keras.metrics.FalseNegatives(name='fn')
```

However, `tf.keras.metrics.BinaryCrossentropy` is the only metric that accepts both range [-inf, inf] and range[0,1] and this is used in all tutorials. 

The issue is that I want to use all the 8 metrics mentioned above during training, but I cannot. 

**Describe the expected behavior**
Provide an option to have a `from_logits=True` argument in the 8 metrics given above (and other metrics as well)

**Standalone code to reproduce the issue** 

Pip Install: TensorFlow 2.x and Numpy
```
! pip install tensorflow numpy
```

**Code**

```
# INITIALIZE

import tensorflow as tf
import numpy as np
# define dataset
dataset = np.array([[6,148,72,35,0,33.6,0.627,50,1],
[1,85,66,29,0,26.6,0.351,31,0],
[8,183,64,0,0,23.3,0.672,32,1],
[1,89,66,23,94,28.1,0.167,21,0],
[0,137,40,35,168,43.1,2.288,33,1]])
# split into input (X) and output (y) variables
X = dataset[:,0:8]
y = dataset[:,8]
```

```
# WORKS: Model output is in range [0, 1]
# define the keras model
model = tf.keras.models.Sequential([tf.keras.layers.Dense(12, input_dim=8, activation='relu'),
                                    tf.keras.layers.Dense(1, activation='sigmoid')])
# compile the keras model
model.compile(loss=tf.keras.losses.BinaryCrossentropy(),
              optimizer=tf.keras.optimizers.RMSprop(),
              metrics=[tf.keras.metrics.Accuracy(name='accuracy'),
                       tf.keras.metrics.Precision(name='precision'),
                       tf.keras.metrics.TruePositives(name='tp')])
# fit the keras model on the dataset
model.fit(X, y, epochs=10, batch_size=10, verbose=0)
```

```
# DOES NOT WORK: Model output is in range [-inf, inf]
# define the keras model
model = tf.keras.models.Sequential([tf.keras.layers.Dense(12, input_dim=8, activation='relu'),
                                    tf.keras.layers.Dense(1)])
# compile the keras model
model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
              optimizer=tf.keras.optimizers.RMSprop(),
              metrics=[tf.keras.metrics.Accuracy(name='accuracy'),
                       tf.keras.metrics.Precision(name='precision'),
                       tf.keras.metrics.TruePositives(name='tp')])
# fit the keras model on the dataset
model.fit(X, y, epochs=10, batch_size=10, verbose=0)
.
.
.
.
.
.
.
InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument:  assertion failed: [predictions must be <= 1] [Condition x <= y did not hold element-wise:] [x (sequential_8/dense_17/BiasAdd:0) = ] [[22.0911655][62.7297783][35.2793274]...] [y (metrics/precision/Cast_3/x:0) = ] [1]
	 [[{{node metrics/precision/assert_less_equal/Assert/AssertGuard/else/_11/Assert}}]]
	 [[metrics/tp/assert_greater_equal/Assert/AssertGuard/pivot_f/_31/_61]]
  (1) Invalid argument:  assertion failed: [predictions must be <= 1] [Condition x <= y did not hold element-wise:] [x (sequential_8/dense_17/BiasAdd:0) = ] [[22.0911655][62.7297783][35.2793274]...] [y (metrics/precision/Cast_3/x:0) = ] [1]
	 [[{{node metrics/precision/assert_less_equal/Assert/AssertGuard/else/_11/Assert}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_distributed_function_12253]

Function call stack:
distributed_function -> distributed_function
```
"
37102,MUL doesn't work on gpu delegate with error: Dimension can not be reduced to linear,"**System information**

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS 10.14.6
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: iPhone XR, iPhone Xs
TensorFlow installed from (source or binary): installed from source.
TensorFlow version (use command below): 1.14.0
Python version: 3.6
Bazel version (if compiling from source): 1.2.1
GCC/Compiler version (if compiling from source): 4.2.1

**Describe the current behavior**
`Mul` doesn't work with multiple axis while using gpu delegate. (no issue while using cpu).

Tried to create a dummy tflite graph with simply a multiply operation on input of shape of `[1, 1, n, m]` and variable with the same shape. While verifying with TFLite iOS benchmark app with GPU delegate, the benchmark app reports ""failed to apply GPU delegate"" on the mul operation. Note that the model runs fine without gpu delegate.

**Describe the expected behavior**

Mul operation works on gpu delegate and supports multiple axis.

**Code to reproduce the issue**
Here's the dummy model that should reproduce the issue in the TFLite ios benchmark app:
[dummy_model.tflite](https://drive.google.com/file/d/1383fCIA0-Uhlmbo8zR16KW3C6FYDX5un/view?usp=sharing)

**Other info / logs**
```
Graph: [/private/var/containers/Bundle/Application/DD8D26F4-6BC1-4EFB-A444-EA2FB7F411D9/TFLiteBenchmark.app/dummy_model_2.tflite]
Input layers: [input_feature_placeholder]
Input shapes: [1,1,2,80]
Input value ranges: []
Allow fp16 : [0]
Require full delegation : [0]
Enable op profiling: [0]
Max profiling buffer entries: [1024]
CSV File to export profiling data to: []
Use gpu : [1]
Allow lower precision in gpu : [1]
GPU delegate wait type : [aggressive]
Loaded model /private/var/containers/Bundle/Application/DD8D26F4-6BC1-4EFB-A444-EA2FB7F411D9/TFLiteBenchmark.app/dummy_model_2.tflite
2020-02-26 15:16:14.857526-0500 TFLiteBenchmark[444:628154] Initialized TensorFlow Lite runtime.
2020-02-26 15:16:14.857843-0500 TFLiteBenchmark[444:628154] Created TensorFlow Lite delegate for Metal.
2020-02-26 15:16:14.858337-0500 TFLiteBenchmark[444:628154] Metal GPU Frame Capture Enabled
2020-02-26 15:16:14.859181-0500 TFLiteBenchmark[444:628154] Metal API Validation Enabled
2020-02-26 15:16:14.932455-0500 TFLiteBenchmark[444:628154] TfLiteGpuDelegate Prepare: MUL: Dimension can not be reduced to linear.
2020-02-26 15:16:14.932670-0500 TFLiteBenchmark[444:628154] Node number 2 (TfLiteMetalDelegate) failed to prepare.
2020-02-26 15:16:14.932800-0500 TFLiteBenchmark[444:628154] tensorflow/lite/kernels/mul.cc:74 input1->type != input2->type (1 != 10)
2020-02-26 15:16:14.932891-0500 TFLiteBenchmark[444:628154] Node number 1 (MUL) failed to prepare.
Failed to apply GPU delegate.
```"
37100,why is variable not partitioned by default in PS-based distributed training?,"Hello,
We found out when multiple PSes are used, there's always only one PS serving by default, and we need to explicitly set variable partitioning strategy(fix sized partitioner) to make use of every PS. Do we know why this is not the default behavior when PS is used?"
37099,RuntimeError: Inputs and outputs not all float|uint8|int16 types.Node number 2 (ADD) failed to invoke.,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): source
- TensorFlow version (or github SHA if from source): 1.15


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
import numpy as np
import tensorflow as tf
from PIL import Image

interpreter = tf.lite.Interpreter(model_path=""out.tflite"")
interpreter.allocate_tensors()
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()
print(input_details)
[{'name': 'image', 'index': 21904, 'shape': array([  3, 270, 480], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0)}]
print(output_details)
[{'name': 'action', 'index': 7204, 'shape': array([], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0)}]
input_shape = input_details[0]['shape']
input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)
interpreter.set_tensor(input_details[0]['index'], input_data)
interpreter.invoke()
output_data = interpreter.get_tensor(output_details[0]['index'])
print(output_data)
```

**The output from the converter invocation**

```
RuntimeError: Inputs and outputs not all float|uint8|int16 types.Node number 2 (ADD) failed to invoke.
```

**Also, please include a link to the saved model or GraphDef**

```
https://we.tl/t-lWH3XmYihS <-- .pb
https://we.tl/t-Bkid4ThzN1 <-- .tflite
```

**Failure details**
The conversion is successful and I can run inference on the .pb, but I get the following error when I run inference on the tflite file.

```
RuntimeError: Inputs and outputs not all float|uint8|int16 types.Node number 2 (ADD) failed to invoke.
```


**Any other info / logs**

Model trained on pytorch mobilenetV2 arch, converted to onnx, and converted to tensorflow."
37098,model.fit fails when using generator of keras sequence,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): 
- OS Platform and Distribution: Linux Ubuntu 19
- TensorFlow installed from ""pip3 install tensorflow"" (2.1.0)
- Python version: 3.7.5
- CUDA/cuDNN version: - GTX 980 || CUDA 10.1 || cuDNN: 7.65 


**Describe the current behavior**
When using a sequence generator on model.fit I get this error on every epoch:
`Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled`

**Standalone code to reproduce the issue** 

I created a customer generator from the keras sequence class like so (taken from https://blog.ml6.eu/training-and-serving-ml-models-with-tf-keras-3d29b41e066c):

`
```
import ast
import numpy as np
import math
import os
import random

import pandas as pd
from tensorflow.keras.preprocessing.image import img_to_array as img_to_array
from tensorflow.keras.preprocessing.image import load_img as load_img
import tensorflow as tf


def load_image(image_path, size):
    # data augmentation logic such as random rotations can be added here
    return img_to_array(load_img(image_path, target_size=size)) / 255.


class KagglePlanetSequence(tf.keras.utils.Sequence):

```

    def __init__(self, df_path, data_path, im_width, im_height, batch_size, mode='train'):

        self.df = pd.read_csv(df_path)
        self.im_size = (im_width, im_height)
        self.batch_size = batch_size
        self.mode = mode

        # Take labels and a list of image locations in memory
        self.labels = self.df['LABELS'].apply(lambda x: ast.literal_eval(x)).tolist()
        self.image_list = self.df['IMAGE_ID'].apply(lambda x: os.path.join(data_path, x + '.jpg')).tolist()

    def __len__(self):
        return int(np.floor(len(self.df) / self.batch_size))

    def on_epoch_end(self):
        # Shuffles indexes after each epoch
        self.indexes = range(len(self.image_list))
        if self.mode == 'train':
            self.indexes = random.sample(self.indexes, k=len(self.indexes))

    def get_batch_labels(self, idx):
        # Fetch a batch of labels
        return np.asarray(self.labels[idx * self.batch_size: (idx + 1) * self.batch_size], dtype=np.float32)

    def get_batch_features(self, idx):
        # Fetch a batch of images
        batch_images = self.image_list[idx * self.batch_size: (1 + idx) * self.batch_size]
        return np.asarray([load_image(im, self.im_size) for im in batch_images], dtype=np.float32)

    def __getitem__(self, idx):
        batch_x = self.get_batch_features(idx)
        batch_y = self.get_batch_labels(idx)
        return batch_x, batch_y
`
The csv file I load is with a column for the image_ids and one column for the labels in the format: ""[0, 0, 0, 1]""

I initialize the generator

```
BATCH_SIZE = 32
IMG_WIDTH = 320
IMG_HEIGHT = 180

seq = KagglePlanetSequence(CSV_PATH,
                           IMAGES_PATH,
                           im_width=IMG_WIDTH,
                           im_height=IMG_HEIGHT,
                           batch_size=32)

```

I build my model:
```

model = models.Sequential()
model.add(Conv2D(4, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(8, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))

model.add(Flatten())
model.add(Dense(3, activation='sigmoid'))

model.summary()

model.compile(optimizer='adam', loss=losses.categorical_crossentropy, metrics=['accuracy'])
```

I call mode.fit

```
model.fit(seq,
          verbose=1,
          epochs=1,
          workers=4)

```

```
Train for 5 steps
2020-02-26 18:47:43.446662: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-02-26 18:47:43.693552: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
5/5 [==============================] - 2s 323ms/step - loss: 1.2517 - accuracy: 0.4250
**2020-02-26 18:47:44.917946: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled**

```
And I get this error:

`Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled`




"
37094,I have to install TF 1.8!,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows (10 or 8.1)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:1.8
- Python version:3.6
- Installed using virtualenv? pip? conda?:both
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:9.1
- GPU model and memory:NVIDIA GeForce GTX 760



**Describe the problem**
Hello, the computing capabilities of my GPU is 3.0 and TF doesn't work in this case. I've read that it's possible to run the 1.8 version here https://medium.com/@naarkie/using-tensorflow-gpu-on-a-compute-3-0-graphics-card-in-windows-4184f4228fe9
But impossible to find the good package.
I need it to use the Visions of Chaos software (fractal art).
May somebody help me?
Thanks for all.
Best regards,
François
**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
37093,Reading TFRecord through tf.data extremely slow in comparison to Pandas (MWE),"**System information** 
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.3 LTS
- TensorFlow installed from (source or binary): binary pip
- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de 2.1.0
- Python version: Python 3.7.6
- CUDA/cuDNN version: 7.6.4.38-1
- GPU model and memory: Quadro RTX 6000 22752 MB

**Describe the current behavior**

In the example below, first `tf.Data` is used to read data from dummy `TFRecord` files. Then pandas is used to read the same data from serialized `pandas.DataFrame` pickle-files. Both pipelines read chunks of `batch_size=512` elements from the data to the end (in the example, 10 files of 210083x135 floats).

In comparison, the performance of the `tf.Dataset` is very slow. Pandas reads the data  in ~**1.86 s** (~4.52 MB/s) vs `tf.data` in ~**51.3 s** (~0.16 MB/s).

The pipeline (in my understanding) does nothing more than to read the files from disk into batched junks in memory. Please help me understand and resolve this performance gap. 

This issue induces a huge performance hit in my model training, which uses a slightly more complicated pipeline.

**Describe the expected behavior**

Processing TFRecord files should be equally fast if not faster than processing pickle-files with pandas.

**Standalone code to reproduce the issue** 

```
import math
import time
import pandas
import random
import numpy as np
import tensorflow as tf

print(""TensorFlow {}"".format(tf.__version__))

num_features = 130
num_labels = 5
batch_size = 512
win_size = 2048
len_max = 210083

#########################################
# dummy data
#########################################

l1 = len_max
X1, Y1 = (np.ones((l1, num_features), dtype=np.float32), np.zeros((l1, num_labels), dtype=np.float32))

k = 10

#########################################
# create dummy tfrecord file(s)
#########################################

def write_tfrecord(X, Y, fn):
    with tf.Graph().as_default():
        ds = tf.data.Dataset.from_tensor_slices((X, Y))

        sstring = ds.map(lambda *x: 
           tf.reshape(tf.py_function(lambda *v:
               tf.train.Example(features=tf.train.Features(feature={
                   ""features"": tf.train.Feature(float_list=tf.train.FloatList(value=v[0].numpy())),
                   ""label"": tf.train.Feature(float_list=tf.train.FloatList(value=v[1].numpy())),
               })).SerializeToString(), x, tf.string
           ), ())
        )

        writer = tf.data.experimental.TFRecordWriter(fn)
        writer_op = writer.write(sstring)

        sess = tf.compat.v1.Session()
        sess.run(tf.compat.v1.global_variables_initializer())
        sess.run(writer_op)
        sess.close()

files_base_tf = [""./temp3.tfrecord""]

write_tfrecord(X1, Y1, files_base_tf[0])

#########################################
# create dummy pandas pickle file(s)
#########################################

df = pandas.DataFrame(np.concatenate((X1, Y1), axis=1))

files_base_pd = [""./temp3.pkl""]

df.to_pickle(files_base_pd[0])

#########################################
# take k random files as tf.Dataset
#########################################

_files = random.choices(files_base_tf, k=k)

ds_fs = tf.data.Dataset.list_files(_files, shuffle=False, seed=1)
fs_len = 0
for f in ds_fs:
    fs_len += 1
print(""Reading {} tfrecord files..."".format(fs_len))

# prepare the tf.Dataset

def prep_ds_file(file):
    _ds = tf.data.TFRecordDataset(file)
    _ds = _ds.map(lambda x: tf.io.parse_single_example(x, {
        ""features"": tf.io.FixedLenFeature([num_features], tf.float32),
        ""label"": tf.io.FixedLenFeature([num_labels], tf.float32),
    #}), num_parallel_calls=tf.data.experimental.AUTOTUNE)
    }), num_parallel_calls=1)
    #print(_ds)
    
    _ds = _ds.flat_map(lambda v: tf.data.Dataset.from_tensors((v[""features""], v[""label""])))
    #print(_ds)

    _ds = _ds.batch(batch_size, drop_remainder=False)
    print(_ds)
    
    return _ds


def prep_ds(fs):
    _ds = fs.interleave(prep_ds_file, num_parallel_calls=tf.data.experimental.AUTOTUNE)
    print(_ds)

    return _ds


ds = prep_ds(ds_fs)

#########################################
# read/use the tf.Dataset
#########################################

shapes_tf = []

ts = time.perf_counter()
i = 0
for e in ds:
    v = (lambda: [x.numpy() for x in e])()
    #shapes_tf.append([x.shape for x in v])
    i += 1
te = time.perf_counter()
print(""Duration TFRecord ({} rounds): {} s"".format(i, (te - ts)))
print(""Speed: {} MB/s"".format((k*l1*4/1000/1000/(te - ts))))

#########################################
# take k random files as pandas DataFrame
#########################################

_files = random.choices(files_base_pd, k=k)

#########################################
# read/use the pandas DataFrame
#########################################

shapes_pd = []

ts = time.perf_counter()
i = 0
for f in _files:
    df = pandas.read_pickle(f)
    n = math.ceil(len(df.index) / batch_size)
    for b in range(n):
        #print(df.iloc[(b*batch_size):((b+1)*batch_size)].shape)
        v = (lambda: df.iloc[(b*batch_size):((b+1)*batch_size)].to_numpy())()
        #shapes_pd.append(v.shape)
        i += 1
te = time.perf_counter()
print(""Duration Pandas ({} rounds): {} s"".format(i, (te - ts)))
print(""Speed: {} MB/s"".format((k*l1*4/1000/1000/(te - ts))))
```

**Other info / logs**

Output:
```
TensorFlow 2.1.0
Reading 10 tfrecord files...
<BatchDataset shapes: ((None, 130), (None, 5)), types: (tf.float32, tf.float32)>
<ParallelInterleaveDataset shapes: ((None, 130), (None, 5)), types: (tf.float32, tf.float32)>
Duration TFRecord (4110 rounds): 51.2759778869804 s
Speed: 0.1638841489970629 MB/s
Duration Pandas (4110 rounds): 1.8584379029925913 s
Speed: 4.521711479554074 MB/s
```
"
37092,Entity could not be transformed error,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code - YES
- OS Platform and Distribution - Mac OS 10.15.2 Catalina
- TensorFlow installed from (source or
binary): - Conda
- Python version: - 3.6.7
Using CPU

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

Using Tensorflow 2.0.0

**Describe the current behavior**

I am trying to implement custom layers and I keep getting the following errors: 

WARNING:tensorflow:Entity <bound method BinaryConv2D.call of <binary_layers.BinaryConv2D object at 0x1ac37a9d50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: 
WARNING: Entity <bound method BinaryConv2D.call of <binary_layers.BinaryConv2D object at 0x1ac37a9d50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: 
WARNING:tensorflow:Entity <function streak at 0x1ac34def80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: 
WARNING: Entity <function streak at 0x1ac34def80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: 
WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x1ac8e150e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: 
WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x1ac8e150e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: 
Model: ""model_8""

I dont care about the lambda layers as those should be non-trainable. However, I want the bin_conv2d to be trainable and it appears that something is preventing that but I cannot figure out why. I also dont understand the last warning of Entity function initialize_unitialized_variables is. Any help with this would be greatly appreciated.

To give an idea for what I'm trying to do, I generate a binary kernel in bin_conv2d and then element-wise multiply that by each input. I am wrapping everything in TimeDistributed as my inputs are videos and I want the outputs to be evaluated as such. The original implementation of bin_conv2d used the standard convolution and that compiled fine. It seems that once I changed it to be element-multiply it breaks down. The weird thing is that it seems that the binarize function is what breaks when I change the code even though I am not changing that at all.

Here is a link to my [gist](https://gist.github.com/matthewp14/dd77eea3464d39d49c618f4398723ce5)

**Describe the expected behavior**

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

Here is the output when I set 

tf.autograph.set_verbosity(3, True)

INFO:tensorflow:Converted call: <bound method BinaryConv2D.call of <binary_layers.BinaryConv2D object at 0x1ac6957150>>
    args: (<tf.Tensor 'time_distributed_280/Reshape:0' shape=(60, 32, 32, 1) dtype=float32>,)
    kwargs: {}

Converted call: <bound method BinaryConv2D.call of <binary_layers.BinaryConv2D object at 0x1ac6957150>>
    args: (<tf.Tensor 'time_distributed_280/Reshape:0' shape=(60, 32, 32, 1) dtype=float32>,)
    kwargs: {}

INFO:tensorflow:Not whitelisted: <method-wrapper '__call__' of method object at 0x1ac5c17140>: default rule
Not whitelisted: <method-wrapper '__call__' of method object at 0x1ac5c17140>: default rule
INFO:tensorflow:Not whitelisted: <class 'binary_layers.BinaryConv2D'>: default rule
Not whitelisted: <class 'binary_layers.BinaryConv2D'>: default rule
INFO:tensorflow:Not whitelisted: <bound method BinaryConv2D.call of <binary_layers.BinaryConv2D object at 0x1ac6957150>>: default rule
Not whitelisted: <bound method BinaryConv2D.call of <binary_layers.BinaryConv2D object at 0x1ac6957150>>: default rule
INFO:tensorflow:Cache hit for entity <bound method BinaryConv2D.call of <binary_layers.BinaryConv2D object at 0x1ac6957150>> key <code object call at 0x1ac9f12030, file ""/Users/matthew/Desktop/Desktop - Matthew’s MacBook Pro (74)/CUP-Net/src/binary_layers.py"", line 158> subkey (<tensorflow.python.autograph.core.converter.ConversionOptions object at 0x1acb755dd0>, frozenset()): _ConvertedEntityFactoryInfo(tf__call in tmppbrtju_8)
Cache hit for entity <bound method BinaryConv2D.call of <binary_layers.BinaryConv2D object at 0x1ac6957150>> key <code object call at 0x1ac9f12030, file ""/Users/matthew/Desktop/Desktop - Matthew’s MacBook Pro (74)/CUP-Net/src/binary_layers.py"", line 158> subkey (<tensorflow.python.autograph.core.converter.ConversionOptions object at 0x1acb755dd0>, frozenset()): _ConvertedEntityFactoryInfo(tf__call in tmppbrtju_8)
INFO:tensorflow:Error transforming entity <bound method BinaryConv2D.call of <binary_layers.BinaryConv2D object at 0x1ac6957150>>
Traceback (most recent call last):
  File ""/Users/matthew/opt/miniconda3/envs/engs89/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py"", line 506, in converted_call
    converted_f = conversion.convert(target_entity, program_ctx)
  File ""/Users/matthew/opt/miniconda3/envs/engs89/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 324, in convert
    return _instantiate(entity, converted_entity_info, free_nonglobal_var_names)
  File ""/Users/matthew/opt/miniconda3/envs/engs89/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 266, in _instantiate
    factory = converted_entity_info.get_factory()
  File ""/Users/matthew/opt/miniconda3/envs/engs89/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 92, in get_factory
    assert self.module_name in sys.modules
AssertionError
Error transforming entity <bound method BinaryConv2D.call of <binary_layers.BinaryConv2D object at 0x1ac6957150>>
WARNING:tensorflow:Entity <bound method BinaryConv2D.call of <binary_layers.BinaryConv2D object at 0x1ac6957150>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: 
WARNING: Entity <bound method BinaryConv2D.call of <binary_layers.BinaryConv2D object at 0x1ac6957150>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: 
INFO:tensorflow:Converted call: <function streak at 0x1ac9e22320>
    args: (<tf.Tensor 'x:0' shape=(2, 30, 32, 32, 1) dtype=float32>,)
    kwargs: {}

Converted call: <function streak at 0x1ac9e22320>
    args: (<tf.Tensor 'x:0' shape=(2, 30, 32, 32, 1) dtype=float32>,)
    kwargs: {}

INFO:tensorflow:Cache hit for entity <function streak at 0x1ac9e22320> key <code object streak at 0x1ac9f12db0, file ""/Users/matthew/Desktop/Desktop - Matthew’s MacBook Pro (74)/CUP-Net/src/lambda_layers.py"", line 20> subkey (<tensorflow.python.autograph.core.converter.ConversionOptions object at 0x1acb837b50>, frozenset()): _ConvertedEntityFactoryInfo(tf__streak in tmpqw9832gt)
Cache hit for entity <function streak at 0x1ac9e22320> key <code object streak at 0x1ac9f12db0, file ""/Users/matthew/Desktop/Desktop - Matthew’s MacBook Pro (74)/CUP-Net/src/lambda_layers.py"", line 20> subkey (<tensorflow.python.autograph.core.converter.ConversionOptions object at 0x1acb837b50>, frozenset()): _ConvertedEntityFactoryInfo(tf__streak in tmpqw9832gt)
INFO:tensorflow:Error transforming entity <function streak at 0x1ac9e22320>
Traceback (most recent call last):
  File ""/Users/matthew/opt/miniconda3/envs/engs89/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py"", line 506, in converted_call
    converted_f = conversion.convert(target_entity, program_ctx)
  File ""/Users/matthew/opt/miniconda3/envs/engs89/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 324, in convert
    return _instantiate(entity, converted_entity_info, free_nonglobal_var_names)
  File ""/Users/matthew/opt/miniconda3/envs/engs89/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 266, in _instantiate
    factory = converted_entity_info.get_factory()
  File ""/Users/matthew/opt/miniconda3/envs/engs89/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 92, in get_factory
    assert self.module_name in sys.modules
AssertionError
Error transforming entity <function streak at 0x1ac9e22320>
WARNING:tensorflow:Entity <function streak at 0x1ac9e22320> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: 
WARNING: Entity <function streak at 0x1ac9e22320> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: 
Traceback (most recent call last):
  File ""/Users/matthew/opt/miniconda3/envs/engs89/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py"", line 506, in converted_call
    converted_f = conversion.convert(target_entity, program_ctx)
  File ""/Users/matthew/opt/miniconda3/envs/engs89/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 324, in convert
    return _instantiate(entity, converted_entity_info, free_nonglobal_var_names)
  File ""/Users/matthew/opt/miniconda3/envs/engs89/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 266, in _instantiate
    factory = converted_entity_info.get_factory()
  File ""/Users/matthew/opt/miniconda3/envs/engs89/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 92, in get_factory
    assert self.module_name in sys.modules
AssertionError
Traceback (most recent call last):
  File ""/Users/matthew/opt/miniconda3/envs/engs89/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py"", line 506, in converted_call
    converted_f = conversion.convert(target_entity, program_ctx)
  File ""/Users/matthew/opt/miniconda3/envs/engs89/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 324, in convert
    return _instantiate(entity, converted_entity_info, free_nonglobal_var_names)
  File ""/Users/matthew/opt/miniconda3/envs/engs89/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 266, in _instantiate
    factory = converted_entity_info.get_factory()
  File ""/Users/matthew/opt/miniconda3/envs/engs89/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 92, in get_factory
    assert self.module_name in sys.modules
AssertionError
INFO:tensorflow:Converted call: <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x1acd33c320>
    args: ()
    kwargs: {}

Converted call: <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x1acd33c320>
    args: ()
    kwargs: {}

INFO:tensorflow:Cache hit for entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x1acd33c320> key <code object initialize_variables at 0x14d357660, file ""/Users/matthew/opt/miniconda3/envs/engs89/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 603> subkey (<tensorflow.python.autograph.core.converter.ConversionOptions object at 0x1acd3638d0>, frozenset({'initializer_map'})): _ConvertedEntityFactoryInfo(tf__initialize_variables in tmphhcwjhr8)
Cache hit for entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x1acd33c320> key <code object initialize_variables at 0x14d357660, file ""/Users/matthew/opt/miniconda3/envs/engs89/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 603> subkey (<tensorflow.python.autograph.core.converter.ConversionOptions object at 0x1acd3638d0>, frozenset({'initializer_map'})): _ConvertedEntityFactoryInfo(tf__initialize_variables in tmphhcwjhr8)
INFO:tensorflow:Error transforming entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x1acd33c320>
Traceback (most recent call last):
  File ""/Users/matthew/opt/miniconda3/envs/engs89/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py"", line 506, in converted_call
    converted_f = conversion.convert(target_entity, program_ctx)
  File ""/Users/matthew/opt/miniconda3/envs/engs89/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 324, in convert
    return _instantiate(entity, converted_entity_info, free_nonglobal_var_names)
  File ""/Users/matthew/opt/miniconda3/envs/engs89/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 266, in _instantiate
    factory = converted_entity_info.get_factory()
  File ""/Users/matthew/opt/miniconda3/envs/engs89/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 92, in get_factory
    assert self.module_name in sys.modules
AssertionError
Error transforming entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x1acd33c320>
WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x1acd33c320> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: 
WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x1acd33c320> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: 
INFO:tensorflow:Converted call: <function streak at 0x1ac9e22320>
    args: (<tf.Tensor 'x:0' shape=(2, 30, 32, 32, 1) dtype=float32>,)
    kwargs: {}

Converted call: <function streak at 0x1ac9e22320>
    args: (<tf.Tensor 'x:0' shape=(2, 30, 32, 32, 1) dtype=float32>,)
    kwargs: {}

Traceback (most recent call last):
  File ""/Users/matthew/opt/miniconda3/envs/engs89/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py"", line 506, in converted_call
    converted_f = conversion.convert(target_entity, program_ctx)
  File ""/Users/matthew/opt/miniconda3/envs/engs89/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 324, in convert
    return _instantiate(entity, converted_entity_info, free_nonglobal_var_names)
  File ""/Users/matthew/opt/miniconda3/envs/engs89/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 266, in _instantiate
    factory = converted_entity_info.get_factory()
  File ""/Users/matthew/opt/miniconda3/envs/engs89/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 92, in get_factory
    assert self.module_name in sys.modules
AssertionError
Model: ""model_9""
_____________________

INFO:tensorflow:Converted call: <function TensorLikeDataAdapter.__init__.<locals>.permutation at 0x1acd0b20e0>
    args: (<tf.Tensor 'args_0:0' shape=() dtype=int64>,)
    kwargs: {}

Converted call: <function TensorLikeDataAdapter.__init__.<locals>.permutation at 0x1acd0b20e0>
    args: (<tf.Tensor 'args_0:0' shape=() dtype=int64>,)
    kwargs: {}

INFO:tensorflow:Whitelisted: <function TensorLikeDataAdapter.__init__.<locals>.permutation at 0x1acd0b20e0>: DoNotConvert rule for tensorflow
Whitelisted: <function TensorLikeDataAdapter.__init__.<locals>.permutation at 0x1acd0b20e0>: DoNotConvert rule for tensorflow
INFO:tensorflow:Converted call: <function TensorLikeDataAdapter.__init__.<locals>.slice_batch_indices at 0x1acd0b2f80>
    args: (<tf.Tensor 'args_0:0' shape=(16,) dtype=int64>,)
    kwargs: {}

Converted call: <function TensorLikeDataAdapter.__init__.<locals>.slice_batch_indices at 0x1acd0b2f80>
    args: (<tf.Tensor 'args_0:0' shape=(16,) dtype=int64>,)
    kwargs: {}

INFO:tensorflow:Whitelisted: <function TensorLikeDataAdapter.__init__.<locals>.slice_batch_indices at 0x1acd0b2f80>: DoNotConvert rule for tensorflow
Whitelisted: <function TensorLikeDataAdapter.__init__.<locals>.slice_batch_indices at 0x1acd0b2f80>: DoNotConvert rule for tensorflow
INFO:tensorflow:Converted call: <function TensorLikeDataAdapter.__init__.<locals>.grab_batch at 0x1acd0b2440>
    args: (<tf.Tensor 'args_0:0' shape=(2,) dtype=int64>, (<tf.Tensor 'args_1:0' shape=(16, 30, 32, 32, 1) dtype=float32>, <tf.Tensor 'args_2:0' shape=(16, 30, 32, 32, 1) dtype=float32>))
    kwargs: {}

Converted call: <function TensorLikeDataAdapter.__init__.<locals>.grab_batch at 0x1acd0b2440>
    args: (<tf.Tensor 'args_0:0' shape=(2,) dtype=int64>, (<tf.Tensor 'args_1:0' shape=(16, 30, 32, 32, 1) dtype=float32>, <tf.Tensor 'args_2:0' shape=(16, 30, 32, 32, 1) dtype=float32>))
    kwargs: {}

INFO:tensorflow:Whitelisted: <function TensorLikeDataAdapter.__init__.<locals>.grab_batch at 0x1acd0b2440>: DoNotConvert rule for tensorflow
Whitelisted: <function TensorLikeDataAdapter.__init__.<locals>.grab_batch at 0x1acd0b2440>: DoNotConvert rule for tensorflow
Train on 16 samples
Epoch 1/10
WARNING:tensorflow:Gradients do not exist for variables ['time_distributed_280/kernel:0'] when minimizing the loss.
INFO:tensorflow:Converted call: <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x1acd133950>
    args: ()
    kwargs: {}

Converted call: <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x1acd133950>
    args: ()
    kwargs: {}

INFO:tensorflow:Cache hit for entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x1acd133950> key <code object initialize_variables at 0x14d357660, file ""/Users/matthew/opt/miniconda3/envs/engs89/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 603> subkey (<tensorflow.python.autograph.core.converter.ConversionOptions object at 0x1ace7741d0>, frozenset({'initializer_map'})): _ConvertedEntityFactoryInfo(tf__initialize_variables in tmphhcwjhr8)
Cache hit for entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x1acd133950> key <code object initialize_variables at 0x14d357660, file ""/Users/matthew/opt/miniconda3/envs/engs89/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 603> subkey (<tensorflow.python.autograph.core.converter.ConversionOptions object at 0x1ace7741d0>, frozenset({'initializer_map'})): _ConvertedEntityFactoryInfo(tf__initialize_variables in tmphhcwjhr8)
INFO:tensorflow:Error transforming entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x1acd133950>
Traceback (most recent call last):
  File ""/Users/matthew/opt/miniconda3/envs/engs89/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py"", line 506, in converted_call
    converted_f = conversion.convert(target_entity, program_ctx)
  File ""/Users/matthew/opt/miniconda3/envs/engs89/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 324, in convert
    return _instantiate(entity, converted_entity_info, free_nonglobal_var_names)
  File ""/Users/matthew/opt/miniconda3/envs/engs89/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 266, in _instantiate
    factory = converted_entity_info.get_factory()
  File ""/Users/matthew/opt/miniconda3/envs/engs89/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 92, in get_factory
    assert self.module_name in sys.modules
AssertionError
Error transforming entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x1acd133950>
WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x1acd133950> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: 
WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x1acd133950> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: 
Traceback (most recent call last):
  File ""/Users/matthew/opt/miniconda3/envs/engs89/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py"", line 506, in converted_call
    converted_f = conversion.convert(target_entity, program_ctx)
  File ""/Users/matthew/opt/miniconda3/envs/engs89/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 324, in convert
    return _instantiate(entity, converted_entity_info, free_nonglobal_var_names)
  File ""/Users/matthew/opt/miniconda3/envs/engs89/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 266, in _instantiate
    factory = converted_entity_info.get_factory()
  File ""/Users/matthew/opt/miniconda3/envs/engs89/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 92, in get_factory
    assert self.module_name in sys.modules
AssertionError
WARNING:tensorflow:Gradients do not exist for variables ['time_distributed_280/kernel:0'] when minimizing the loss.
"
37091,LookupError when calculating gradient of gradient with RNN on GPU,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Ubuntu 18.04.3 LTS
- TensorFlow installed from (source or
binary): binary (Anaconda/PIP)
 - TensorFlow version (use command below): 
GIT_VERSION v1.12.1-25080-gca585e7
VERSION  2.2.0-dev20200218
- Python version: 3.6.10
- CUDA/cuDNN version: CUDA 10.2, cuDNN 7.6.2
- GPU model and memory: GeForce RTX 2080 Ti, 12GB VRAM


**Describe the current behavior**
When trying to implement a gradient penalty for a WGAN-GP, which requires to calculate a gradient of a tensor, which itself depends on a gradient, the program terminates with a LookupError and tells me 

> LookupError: gradient registry has no entry for: CudnnRNNBackprop

This occurs **only on the GPU version** of Tensorflow and **only if a recurrent layer is used** (GRU or LSTM, doesn't matter). On the CPU, the provided minimum working example runs as expected. The error does not occur when training a ""normal"" model with a recurrent layer on the GPU (no gradient penalty). 

I tried with tensorflow-gpu 2.0 (installed via conda), tensorflow-gpu 2.1 (installed via pip) and tf-nightly-gpu 2.2 (more specific: _2.2.0-dev20200218_) (installed via pip). The error is the same for all GPU versions.

The operation **works with tensorflow-gpu, if the parameter _unroll_ of the GRU-Layer is set to True**. Since this disables the usage of the cuDNN implementation of the GRU-Layer (deviation from default parameters), this does not solve the actual problem, but might indicate that there is just a small bug in the interface to cuDNN.

**Standalone code to reproduce the issue** 
```
# this code does not make much sense, but is shorter than providing a full optimization loop for a WGAN_GP and produces the same error
import tensorflow as tf
import tensorflow.keras as k
import tensorflow.keras.layers as kl
import numpy as np

physical_devices = tf.config.experimental.list_physical_devices('GPU')
tf.config.experimental.set_memory_growth(physical_devices[0], True)

def gradient_penalty(model, input_data):
    # get gradient
    input_data = tf.convert_to_tensor(input_data)
    with tf.GradientTape() as t:
        t.watch(input_data)
        pred = model(input_data)
    grad = t.gradient(pred, [input_data])[0]
    # define gradient penalty
    slopes = tf.sqrt(tf.reduce_sum(tf.square(grad), axis=[1, 2]))
    gp = tf.reduce_mean((slopes - 1.) ** 2)
    return gp

if __name__ == ""__main__"":
    # model with recurrent layer
    model = k.Sequential([kl.InputLayer(input_shape=(50, 20)), kl.GRU(100), kl.Dense(1)])
    # Optimizer
    opt = tf.optimizers.Adam()
    # Dummy data
    data = np.random.normal(0, 1, (8, 50, 20)).astype(np.float32)
    # Optimize
    with tf.GradientTape() as tape:
        gp = gradient_penalty(model=model, input_data=data)
    grad = tape.gradient(gp, model.trainable_variables)
    opt.apply_gradients(zip(grad, model.trainable_variables))

```

**Other info / logs**
Full log:
```
/home/hendrik/anaconda3/envs/MLS22/bin/python /home/hendrik/PycharmProjects/GAN/MinimumMinimumWorkingExample.py
2020-02-26 13:30:08.149540: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-02-26 13:30:08.172329: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-26 13:30:08.172601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1558] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2020-02-26 13:30:08.172716: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-02-26 13:30:08.173554: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-02-26 13:30:08.174413: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-02-26 13:30:08.174551: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-02-26 13:30:08.175425: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-02-26 13:30:08.175952: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-02-26 13:30:08.177916: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-02-26 13:30:08.177978: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-26 13:30:08.178270: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-26 13:30:08.178512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Adding visible gpu devices: 0
2020-02-26 13:30:08.187368: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-26 13:30:08.208283: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3600000000 Hz
2020-02-26 13:30:08.208513: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55cac97d38c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-26 13:30:08.208523: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-02-26 13:30:08.267483: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-26 13:30:08.267804: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55cac97f6830 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-02-26 13:30:08.267814: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5
2020-02-26 13:30:08.267915: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-26 13:30:08.268226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1558] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2020-02-26 13:30:08.268246: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-02-26 13:30:08.268253: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-02-26 13:30:08.268259: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-02-26 13:30:08.268265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-02-26 13:30:08.268271: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-02-26 13:30:08.268276: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-02-26 13:30:08.268282: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-02-26 13:30:08.268308: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-26 13:30:08.268554: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-26 13:30:08.268778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Adding visible gpu devices: 0
2020-02-26 13:30:08.268795: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-02-26 13:30:08.269304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1099] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-02-26 13:30:08.269310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105]      0 
2020-02-26 13:30:08.269314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1118] 0:   N 
2020-02-26 13:30:08.269362: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-26 13:30:08.269613: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-26 13:30:08.269856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1244] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9813 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
2020-02-26 13:30:08.667776: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-02-26 13:30:09.284739: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
Traceback (most recent call last):
  File ""/home/hendrik/PycharmProjects/GAN/MinimumMinimumWorkingExample.py"", line 31, in <module>
    grad = tape.gradient(gp, model.trainable_variables)
  File ""/home/hendrik/anaconda3/envs/MLS22/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py"", line 1048, in gradient
    unconnected_gradients=unconnected_gradients)
  File ""/home/hendrik/anaconda3/envs/MLS22/lib/python3.6/site-packages/tensorflow/python/eager/imperative_grad.py"", line 77, in imperative_grad
    compat.as_str(unconnected_gradients.value))
  File ""/home/hendrik/anaconda3/envs/MLS22/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py"", line 145, in _gradient_function
    grad_fn = ops._gradient_registry.lookup(op_name)  # pylint: disable=protected-access
  File ""/home/hendrik/anaconda3/envs/MLS22/lib/python3.6/site-packages/tensorflow/python/framework/registry.py"", line 97, in lookup
    ""%s registry has no entry for: %s"" % (self._name, name))
LookupError: gradient registry has no entry for: CudnnRNNBackprop

Process finished with exit code 1
```

Thanks in advance for your time!"
37089,Tensorflow Lite Hexagon delegate support for QCOM SDM765G,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): 
- OS Platform and Distribution (
Linux Ubuntu 16.04): 
- Mobile device (OPPO reno3 Pro) if
the issue happens on mobile device: 
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below):  14417096dbebbaf46043972029f4bf721e5364cb
- Python version: - Bazel
version (if compiling from source):
- GCC/Compiler version (if compiling from
source): 
- CUDA/cuDNN version: - GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Hello,
I am using tensorflow based on commit ID: 14417096dbebbaf46043972029f4bf721e5364cb
And I use tflite benchmark_model for testing (tensorflow/lite/tools/benchmark),
benchmark_model run failed when enable TFlite hexagon delegate on my phone.
hexagon delegate is not supportted on my phone.
Could you please help add this CPU in the supportted list?
below is my phone innfo:
```
#adb shell getprop ro.product.device
OP4A9D  

#adb shell getprop ro.board.platform
lito

CPU info :  Qualcomm Technologies, Inc SDM765G 5G
```

And from https://source.codeaurora.org/quic/hexagon_nn/nnlib, 
I see that the latest hexagon_nn version is 0x00021401, Could you please update libhexagon_nn_skel.so  to the latest version ?

thanks very much

"
37088,network_tester test failed with NN with 28x28 px input image but succeded with NN with 14x14 px input,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Ubuntu 16.04
- TensorFlow installed from (source or binary):  source
- Tensorflow version (commit SHA if source): 1881d32ef8e998e6f1a403856dd44acbba2aad7c
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): ESP32, x86

**Describe the problem**
I am implementing the Fashion MNIST classification project on ESP32.
I have successfully implemented NN with input image size 14x14 pixels.
Then I changed only the Input image size to 28x28 in NN without changing the structure of NN and was not able to obtain correct predictions with TFL Micro.
Then I found [network_tester example](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro/examples/network_tester) in the TF repository and decided to use it to test my NN with TFL Micro on x86.

I have refactored original **network_tester example** to:
1. feed the input image to NN as a 2-dimensional array.
2. be able to compare float-type predictions.

I have attached here both .tflite trained models and sources with output results.


**Please provide the exact sequence of commands/steps when you ran into the problem**

1. Be sure all TFL Micro unit tests are succeeded. Run command `make -f tensorflow/lite/micro/tools/make/Makefile test`. Expected result: all tests passed successfully.

2. Unzip `network_tester.zip` file.

3. Replace original `network_tester_test.cc` file in TensorFlow source directory `tensorflow/tensorflow/lite/micro/examples/network_tester/` by file contained in archive.

4. Build a test with 14x14 input NN. See parameters to build in `make_14x14.sh` file.

5. Run test from `tensorflow/lite/micro/tools/make/gen/linux_x86_64/bin` directory. See success.

6. Build a test with 28x28 input NN. See parameters to build in `make_28x28.sh` file.

7. Run test from `tensorflow/lite/micro/tools/make/gen/linux_x86_64/bin` directory. **Test failed**.

All source files added to provided archive.

[network_tester.zip](https://github.com/tensorflow/tensorflow/files/4255010/network_tester.zip)
"
37086,Misleading convert error when no concrete functions are given,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 18.04):
- TensorFlow installed from source:
- TensorFlow version 2.1.0:


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
converter = tf.lite.TFLiteConverter.from_saved_model(model_path)
tflite_model = converter.convert()
```

**The output from the converter invocation**

```
ValueError: This converter can only convert a single ConcreteFunction. Converting multiple functions is under development.
```

**Failure details**
When attempting to convert a model in which no ConcreteFunctions have been defined, the error message implies that there are multiple.

As someone new coming to TF and TFLite, I found this very confusing as to where my concrete functions were being defined. 

Inspecting the code from https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/lite/python/lite.py in the ```convert``` method at line 417 the Value Error is thrown when anything but 1 concrete function is defined in the model (rightly so) but the error message implies that more than one have been defined.

```
if len(self._funcs) != 1:
      raise ValueError(""This converter can only convert a single ""
                       ""ConcreteFunction. Converting multiple functions is ""
                       ""under development."")
```"
37085,Everything's OK... but still can't import,"I'm trying to use TF for some data processing.
So I installed tensorflow with pip.py
and then CUDA and cuDNN.

Windows : 7
Python : 3.6.8
Pip version : 20.0.2
Setuptools version : 45.2.0
Tensorflow : 2.1.0 I think
CUDA : 10.2
cuDNN : 6.0 (I also tried with 7.6.4.38)
Visual Studio : Visual Studio Community, Microsoft Visual C++ Redistributable 14.24, Build Tools

I formerly used the script tensorflow_self_check.py below to know what was wrong, but now when I run it this script says that the import fails but that everything is here.

![040](https://user-images.githubusercontent.com/61496017/75330672-bcd01380-5881-11ea-8cfb-a77a824f7647.png)


and when I import 

![039](https://user-images.githubusercontent.com/61496017/75330642-b3df4200-5881-11ea-9f56-f75aab199613.png)


What do I have to do for the import to be successful now ?


# Copyright 2015 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
""""""A script for testing that TensorFlow is installed correctly on Windows.
The script will attempt to verify your TensorFlow installation, and print
suggestions for how to fix your installation.
""""""

import ctypes
import imp
import sys

def main():
  try:
    import tensorflow as tf
    print(""TensorFlow successfully installed."")
    if tf.test.is_built_with_cuda():
      print(""The installed version of TensorFlow includes GPU support."")
    else:
      print(""The installed version of TensorFlow does not include GPU support."")
    sys.exit(0)
  except ImportError:
    print(""ERROR: Failed to import the TensorFlow module."")

  candidate_explanation = False

  python_version = sys.version_info.major, sys.version_info.minor
  print(""\n- Python version is %d.%d."" % python_version)
  if not (python_version == (3, 5) or python_version == (3, 6)):
    candidate_explanation = True
    print(""- The official distribution of TensorFlow for Windows requires ""
          ""Python version 3.5 or 3.6."")

  try:
    _, pathname, _ = imp.find_module(""tensorflow"")
    print(""\n- TensorFlow is installed at: %s"" % pathname)
  except ImportError:
    candidate_explanation = False
    print(""""""
- No module named TensorFlow is installed in this Python environment. You may
  install it using the command `pip install tensorflow`."""""")

  try:
    msvcp140 = ctypes.WinDLL(""msvcp140.dll"")
  except OSError:
    candidate_explanation = True
    print(""""""
- Could not load 'msvcp140.dll'. TensorFlow requires that this DLL be
  installed in a directory that is named in your %PATH% environment
  variable. You may install this DLL by downloading Microsoft Visual
  C++ 2015 Redistributable Update 3 from this URL:
  https://www.microsoft.com/en-us/download/details.aspx?id=53587"""""")

  try:
    cudart64_80 = ctypes.WinDLL(""cudart64_80.dll"")
  except OSError:
    candidate_explanation = True
    print(""""""
- Could not load 'cudart64_80.dll'. The GPU version of TensorFlow
  requires that this DLL be installed in a directory that is named in
  your %PATH% environment variable. Download and install CUDA 8.0 from
  this URL: https://developer.nvidia.com/cuda-toolkit"""""")

  try:
    nvcuda = ctypes.WinDLL(""nvcuda.dll"")
  except OSError:
    candidate_explanation = True
    print(""""""
- Could not load 'nvcuda.dll'. The GPU version of TensorFlow requires that
  this DLL be installed in a directory that is named in your %PATH%
  environment variable. Typically it is installed in 'C:\Windows\System32'.
  If it is not present, ensure that you have a CUDA-capable GPU with the
  correct driver installed."""""")

  cudnn5_found = False
  try:
    cudnn5 = ctypes.WinDLL(""cudnn64_5.dll"")
    cudnn5_found = True
  except OSError:
    candidate_explanation = True
    print(""""""
- Could not load 'cudnn64_5.dll'. The GPU version of TensorFlow
  requires that this DLL be installed in a directory that is named in
  your %PATH% environment variable. Note that installing cuDNN is a
  separate step from installing CUDA, and it is often found in a
  different directory from the CUDA DLLs. You may install the
  necessary DLL by downloading cuDNN 5.1 from this URL:
  https://developer.nvidia.com/cudnn"""""")

  cudnn6_found = False
  try:
    cudnn = ctypes.WinDLL(""cudnn64_6.dll"")
    cudnn6_found = True
  except OSError:
    candidate_explanation = True

  if not cudnn5_found or not cudnn6_found:
    print()
    if not cudnn5_found and not cudnn6_found:
      print(""- Could not find cuDNN."")
    elif not cudnn5_found:
      print(""- Could not find cuDNN 5.1."")
    else:
      print(""- Could not find cuDNN 6."")
      print(""""""
  The GPU version of TensorFlow requires that the correct cuDNN DLL be installed
  in a directory that is named in your %PATH% environment variable. Note that
  installing cuDNN is a separate step from installing CUDA, and it is often
  found in a different directory from the CUDA DLLs. The correct version of
  cuDNN depends on your version of TensorFlow:

  * TensorFlow 1.2.1 or earlier requires cuDNN 5.1. ('cudnn64_5.dll')
  * TensorFlow 1.3 or later requires cuDNN 6. ('cudnn64_6.dll')

  You may install the necessary DLL by downloading cuDNN from this URL:
  https://developer.nvidia.com/cudnn"""""")

  if not candidate_explanation:
    print(""""""
- All required DLLs appear to be present. Please open an issue on the
  TensorFlow GitHub page: https://github.com/tensorflow/tensorflow/issues"""""")

  sys.exit(-1)

if __name__ == ""__main__"":
  main()"
37084,Reintroduced Typo in tf.keras.layers.Attention docs example,"## URL(s) with the issue:
https://www.tensorflow.org/api_docs/python/tf/keras/layers/Attention

## Description of issue (what needs changing):
Typo was reintroduced in v2.1
See https://github.com/tensorflow/tensorflow/issues/34809 

must be 

```
value_embeddings = token_embedding(value_input)
```

@rabitt"
37079,Cannot use tape.gradient to calculate two networks with one loss simultaneously,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): Yes
- OS Platform and Distribution: Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): 2.1.0
- Python version: 3.7.4
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from
source): none
- CUDA/cuDNN version: none
- GPU model and memory: none

In a minimize problem, Ithe purpose is to minimize a function(loss function) which is calculated by two networks. I try to train two networks with one custom loss function. When calculating the gradient, I found that `tape.gradient(target, sources)` usually use `model.trainable_variables` as source. But in my case, there are two models to be trained simultaneously, they should be updated together. SoI write `sources= pModel.trainable_variables+gModel.trainable_variables ` and use the same way to write `apply_gradients` as below:
```
for i_batch in tf.range(n_batch):
    learning_rate = 0.01
    opt = tf.keras.optimizers.Adam(learning_rate)
    with tf.GradientTape() as tape:
        Loss = calculate_loss(pModel, gModel, V, RP, lam_1, lam_2, i_batch, batchsize)
        #Loss is a custum function, gModel and pModel are two sequential model written by Keras
    d = tape.gradient(target=Loss, sources= pModel.trainable_variables+gModel.trainable_variables)         
    opt.apply_gradients(zip(d, pModel.trainable_variables+gModel.trainable_variables))
```
Can I use `sources= pModel.trainable_variables+gModel.trainable_variables` as sources? Does the simple + work as I think? 
(I tried , it can work but the training results are not good. )"
37078,Documentation issue about tf.math.xlog1py (nightly-only APIs),"## URL(s) with the issue:

https://www.tensorflow.org/api_docs/python/tf/math/xlog1py

## Description of issue (what needs changing):

This documentation describes `tf.math.xlog1py`, shown as a part of ""stable"" version of TF 2.1 but I believe this API has not been released yet. `tf.math.xlog1py` is only available on nightly at this point, added in https://github.com/tensorflow/tensorflow/commit/19986377f2a3c560418f42f2323733564a7303eb (Jan 2020).

FYI: I ran into this issue as I was using `tfp-nightly` which depends on `tf-nightly` (module 'tensorflow_core._api.v2.math' has no attribute 'xlog1py').

The documentation should have not published under ""TensorFlow Core v2.1.0"". Why was it the case? If it was due to a mistake, could we improve on the process so we can have a ""nightly"" doc and a ""stable"" doc?"
37077,Tensorflow Workspace not configured for android build,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): 
- TensorFlow version: 
- Python version: 3.7
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source): 1.2.1
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**
I am trying to build tensorflow lite locally. I am following the steps mentioned here : https://www.tensorflow.org/lite/guide/android
When I run ./configure script in root directory, there should be an option for interactively configuring the ./workspace for android builds. But I don't get that option and I am facing a lot of errors during build time. Is there any way I can know the variables that are required to be set? Or any way to fix this ? 

**Provide the exact sequence of commands / steps that you executed before running into the problem**

C:\Users\nikhil\tensorflow>.\configure                                                                                                                                   Extracting Bazel installation...                                                                                                                                                                           
You have bazel 1.2.1 installed.                                                                                                                                           Please specify the location of python. [Default is C:\Users\nikhil\AppData\Local\Programs\Python\Python37\python.exe]:                                                                                                                                                                                                                                                                                                                                                                                                       Found possible Python library paths:                                                                                                                                        C:\Users\nikhil\AppData\Local\Programs\Python\Python37\lib\site-packages                                                                                               Please input the desired Python library path to use.  Default is [C:\Users\nikhil\AppData\Local\Programs\Python\Python37\lib\site-packages]                                                                                                                                                                                                        Do you wish to build TensorFlow with XLA JIT support? [y/N]:                                                                                                              No XLA JIT support will be enabled for TensorFlow.                                                                                                                                                                                                                                                                                                  Do you wish to build TensorFlow with ROCm support? [y/N]:                                                                                                                 No ROCm support will be enabled for TensorFlow.                                                                                                                                                                                                                                                                                                     Do you wish to build TensorFlow with CUDA support? [y/N]:                                                                                                                 No CUDA support will be enabled for TensorFlow.                                                                                                                                                                                                                                                                                                     Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is /arch:AVX]:                                                                                                                                                                                                                                                                                                                                                                                             Would you like to override eigen strong inline for some C++ compilation to reduce the compilation time? [Y/n]:                                                            
Eigen strong inline overridden.                                                                                                                                                                                                                                                                                                                     Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details.                                     
--config=mkl            # Build with MKL support.                                                                                                                         --config=monolithic     # Config for mostly static monolithic build.                                                                                                      --config=ngraph         # Build with Intel nGraph support.                                                                                                                --config=numa           # Build with NUMA support.                                                                                                                        --config=dynamic_kernels        # (Experimental) Build kernels into separate shared objects.                                                                              --config=v2             # Build TensorFlow 2.x instead of 1.x.                                                                                                    Preconfigured Bazel build configs to DISABLE default on features:                                                                                                                 --config=noaws          # Disable AWS S3 filesystem support.                                                                                                              --config=nogcp          # Disable GCP support.                                                                                                                            --config=nohdfs         # Disable HDFS support.                                                                                                                           --config=nonccl         # Disable NVIDIA NCCL support.                                                                                                            Configuration finished

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
37076,v2.1.0 build fails with TensorRT 6 and 7,"**System information**
- Inside Docker container, base image `ubuntu:bionic`
- Ubuntu 18.04, x86_64
- TensorFlow from-source build, checked out @ tag `v2.1.0`
- Python 3.7.5
- Bazel 0.29.1
- GCC 7.4.0
- CUDA 10.1.243, CuDNN 7
- TensorRT-6.0.1.5
- Quadro GV100 32gb

Trying to build TensorFlow 2.1.0 in the above environment is failing consistently. I have tried TensorRT 6 and 7, CUDA 10.1.243 and 10.2.89, and it always fails with the message below. <em>**If I try the build without TensorRT, it succeeds**</em>.

<b>Build invocation</b>
```
bazel build --jobs=36 --config=opt --config=cuda --config=v2 //tensorflow/tools/pip_package:build_pip_package
```

<b>Error output</b>
```
ERROR: /tensorflow/tensorflow/python/keras/api/BUILD:115:1: Executing genrule //tensorflow/python/keras/api:keras_python_api_gen_compat_v1 failed (Exit 1)
Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_1_keras_python_api_gen_compat_v1.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py"", line 27, in <module>
    from tensorflow.python.tools.api.generator import doc_srcs
  File ""/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_1_keras_python_api_gen_compat_v1.runfiles/org_tensorflow/tensorflow/python/__init__.py"", line 85, in <module>
    from tensorflow.python.ops.standard_ops import *
  File ""/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_1_keras_python_api_gen_compat_v1.runfiles/org_tensorflow/tensorflow/python/ops/standard_ops.py"", line 117, in <module>
    from tensorflow.python.compiler.tensorrt import trt_convert as trt
  File ""/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_1_keras_python_api_gen_compat_v1.runfiles/org_tensorflow/tensorflow/python/compiler/tensorrt/__init__.py"", line 22, in <module>
    from tensorflow.python.compiler.tensorrt import trt_convert as trt
  File ""/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_1_keras_python_api_gen_compat_v1.runfiles/org_tensorflow/tensorflow/python/compiler/tensorrt/trt_convert.py"", line 28, in <module>
    from tensorflow.compiler.tf2tensorrt import wrap_py_utils
  File ""/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_1_keras_python_api_gen_compat_v1.runfiles/org_tensorflow/tensorflow/compiler/tf2tensorrt/wrap_py_utils.py"", line 28, in <module>
    _wrap_py_utils = swig_import_helper()
  File ""/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_1_keras_python_api_gen_compat_v1.runfiles/org_tensorflow/tensorflow/compiler/tf2tensorrt/wrap_py_utils.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_wrap_py_utils', fp, pathname, description)
  File ""/usr/lib/python3.7/imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""/usr/lib/python3.7/imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_1_keras_python_api_gen_compat_v1.runfiles/org_tensorflow/tensorflow/compiler/tf2tensorrt/_wrap_py_utils.so: undefined symbol: _ZN15stream_executor14StreamExecutor18EnablePeerAccessToEPS0_
----------------
Note: The failure of target //tensorflow/python/keras/api:create_tensorflow.python_api_1_keras_python_api_gen_compat_v1 (with exit code 1) may have been caused by the fact that it is a Python 2 program that was built in the host configuration, which uses Python 3. You can change the host configuration (for the entire build) to instead use Python 2 by setting --host_force_python=PY2.

If this error started occurring in Bazel 0.27 and later, it may be because the Python toolchain now enforces that targets analyzed as PY2 and PY3 run under a Python 2 and Python 3 interpreter, respectively. See https://github.com/bazelbuild/bazel/issues/7899 for more information.
----------------
Target //tensorflow/tools/pip_package:build_pip_package failed to build
ERROR: /tensorflow/tensorflow/python/tools/BUILD:80:1 Executing genrule //tensorflow/python/keras/api:keras_python_api_gen failed (Exit 1)
INFO: Elapsed time: 3470.734s, Critical Path: 462.21s
INFO: 26665 processes: 26665 local.
FAILED: Build did NOT complete successfully
```"
37075,Documentation needs to upgrade to Python3,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue: 
https://github.com/tensorflow/tensorflow/blob/master/README.md

## Description of issue (what needs changing):

SInce , PSF has officially stopped it's support for Python2, the documentation needs to be upgraded to Python3.
pip2 -> pip3 
### Clear description


### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

See the API guide: https://www.tensorflow.org/community/contribute/docs_ref
on how to write testable usage examples.

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?
Yes, I'll
Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
37072,Custom object detection API for tensorflow 2.0 not working,"The current Object detection API still has graphs and many code structures which are working only until version 1.15

Everywhere including colab it says support will only be for 2.0

Is there a timeline for the object detection API to be useful for tensorflow 2.0 for us to do custom object detection on our own datasets?


"
37068,"Can't load Keras model with multiple MetaGraphs, can't pass tags","- Have I written custom code: Yes
- OS Platform and Distribution: Amazon Linux AMI 2018.03
- TensorFlow installed from: Preinstalled by Amazon
- TensorFlow version: 1.15.0
- Python version: 3.6
- CUDA/cuDNN version: 
- GPU model and memory: Nvidia Tesla V100

**Describe the current behavior**
When trying to load a saved model using `keras.models.load_model`, an error occurs stating that `tf.saved_model.load requires a 'tags='`. There is also no way to pass tags through the `load_model` function.

**Describe the expected behavior**
Model should load.

**Standalone code to reproduce the issue** 
With `""albert/""` being a path to this model locally: https://tfhub.dev/google/albert_xlarge/3:

```python3
from tensorflow import keras

model = keras.models.load_model(""albert/"")
```

Error:
```
ValueError: Importing a SavedModel with tf.saved_model.load requires a 'tags=' argument if there is more than one MetaGraph. Got 'tags=None', but there are 2 MetaGraphs in the SavedModel with tag sets [['train'], []]. Pass a 'tags=' argument to load this SavedModel.
```


**Other info / logs**
```
File ""albert_entrypoint.py"", line 50, in <module>
    model = keras.models.load_model(MODEL_EXTRACT_DIR)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/save.py"", line 147, in load_model
    return saved_model_load.load(filepath, compile)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/saved_model/load.py"", line 86, in load
    model = tf_load.load_internal(path, loader_cls=KerasObjectLoader)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/load.py"", line 550, in load_internal
    root = load_v1_in_v2.load(export_dir, tags)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/load_v1_in_v2.py"", line 239, in load
    return loader.load(tags=tags)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/load_v1_in_v2.py"", line 168, in load
    meta_graph_def = self.get_meta_graph_def_from_tags(tags)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/load_v1_in_v2.py"", line 80, in get_meta_graph_def_from_tags
    .format(len(self._saved_model.meta_graphs), tag_sets))

ValueError: Importing a SavedModel with tf.saved_model.load requires a 'tags=' argument if there is more than one MetaGraph. Got 'tags=None', but there are 2 MetaGraphs in the SavedModel with tag sets [['train'], []]. Pass a 'tags=' argument to load this SavedModel.
```
"
37067,Usage Documentation Needed for tf.image.yuv_to_rgb,"## URL(s) with the issue:

https://www.tensorflow.org/api_docs/python/tf/image/yuv_to_rgb

## Description of issue (what needs changing):

The tf.image.yuv_to_rgb method specifies a YUV input of shape (H,W,3) and an RGB output of the same shape. It also notes:

> The output is only well defined if the Y value in images are in [0,1], U and V value are in [-0.5,0.5].

However YUV is natively encoded in HxWx1.5 Bytes, with values ranging from 0-255. Considering that multiple YUV-RGB conversion standards exist, it is unclear what pre-processing steps need to be done by a user who wants to pass YUV inputs to his network (https://en.wikipedia.org/wiki/YCbCr#JPEG_conversion).

### Usage example

More documentation on the proper usage of this method would be highly helpful. Specifically:

- An example showing how to pre-process a raw YUV image of size HxWx1.5B to the expected shape of (H,W,3) with normalized values Y: [0,1], UV: [-0.5,0.5].
- An example of how one might append this method to an RGB-trained model to enable it to accept YUV inputs during inference. A likely scenario might be exporting a frozen model to an Android device that natively captures in YUV."
37066,Model class API / predict / gradient update,"## URL(s) with the issue:
https://keras.io/models/model/
and 
https://www.tensorflow.org/api_docs/python/tf/keras/Model#predict

## Description of issue (what needs changing):
Documentation for model predict says ""batch_size: Integer or None. Number of samples per gradient update."", but unless I'm missing something, there are no gradient updates while predicting.

"
37065,Slice of a tensor is created on CPU not GPU when dtype=tf.int16,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Google Colab
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: NA
- **TensorFlow installed from (source or binary)**: NA
- **TensorFlow version (use command below)**: version 2.x
- **Python version**: 3
- **Bazel version (if compiling from source)**: NA
- **GCC/Compiler version (if compiling from source)**: NA
- **CUDA/cuDNN version**: NA
- **GPU model and memory**: Google Colab GPU
- **Exact command to reproduce**: 
https://colab.research.google.com/drive/1gbVxZgaesqxOLuoF-D9yuwOahCNTDcEi

### Describe the problem
When slicing a tensor of dtype tf.int16 on GPU, the operation is created on CPU, not GPU. If the tensor is tf.int32, the operation is created on GPU.

### Source code / logs
https://colab.research.google.com/drive/1gbVxZgaesqxOLuoF-D9yuwOahCNTDcEi
"
37061,tf.keras.Model with nested dictionary inputs fails to serialize/deserialize,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow):  No
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04):  `macOS Catalina 10.15.2 (19C57)`
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): nightly binary (`v1.12.1-25814-g2e81bc66c5 2.2.0-dev20200225`)
- Python version: 3.7.6
- CUDA/cuDNN version: - GPU model and memory: n/a


Note: This is a very recent regression; *the code below works* with both `tensorflow==2.1.0` and `tf-nightly-2.2.0.dev20200219`. Would be nice to get it fixed for 2.2 release.


**Describe the current behavior**
When trying to serialize/deserialize a `tf.keras.Model` that has an inner `tf.keras.Sequential` model, nested input shapes cause an error.

**Describe the expected behavior**
The model serializes/deserializes correctly.

**Standalone code to reproduce the issue** 
```python
from collections import OrderedDict
import tensorflow as tf


batch_size = 3
input_values = (
    OrderedDict((
        ('a', tf.random.uniform((batch_size, 1))),
        ('b', tf.random.uniform((batch_size, 4))),
    )),
    (
        tf.random.uniform((batch_size, 3)),
        tf.random.uniform((batch_size, 4)),
    ),
)

inputs = tf.nest.map_structure(
    lambda x: tf.keras.layers.Input(tf.shape(x)[1:]), input_values)


def create_model(inputs):
    sequential_model = tf.keras.Sequential((
        tf.keras.layers.Lambda(
            lambda x: tf.concat(tf.nest.flatten(x), axis=-1)),
    ))
    out = sequential_model(inputs)
    model = tf.keras.Model(inputs, out)
    return model


model_1 = create_model(inputs[0])
model_2 = create_model(inputs)

# Works
model_1_2 = tf.keras.models.Model.from_config(model_1.get_config())
# Does not work
model_2_2 = tf.keras.models.Model.from_config(model_2.get_config())
```

**Other info / logs**
```
$ python ./tests/test_dict_inputs.py
2020-02-25 19:08:12.872582: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-25 19:08:12.886642: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa017864140 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-25 19:08:12.886660: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Traceback (most recent call last):
  File ""/Users/hartikainen/conda/envs/variational-option-discovery/lib/python3.7/site-packages/tensorflow/python/eager/execute.py"", line 211, in make_shape
    shape = tensor_shape.as_shape(v)
  File ""/Users/hartikainen/conda/envs/variational-option-discovery/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py"", line 1218, in as_shape
    return TensorShape(shape)
  File ""/Users/hartikainen/conda/envs/variational-option-discovery/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py"", line 771, in __init__
    self._dims = [as_dimension(d) for d in dims_iter]
  File ""/Users/hartikainen/conda/envs/variational-option-discovery/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py"", line 771, in <listcomp>
    self._dims = [as_dimension(d) for d in dims_iter]
  File ""/Users/hartikainen/conda/envs/variational-option-discovery/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py"", line 716, in as_dimension
    return Dimension(value)
  File ""/Users/hartikainen/conda/envs/variational-option-discovery/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py"", line 195, in __init__
    self._value = int(value.__index__())
TypeError: 'collections.OrderedDict' object cannot be interpreted as an integer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""./tests/test_dict_inputs.py"", line 37, in <module>
    model_2_2 = tf.keras.models.Model.from_config(model_2.get_config())
  File ""/Users/hartikainen/conda/envs/variational-option-discovery/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py"", line 950, in from_config
    config, custom_objects)
  File ""/Users/hartikainen/conda/envs/variational-option-discovery/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py"", line 1982, in reconstruct_from_config
    process_layer(layer_data)
  File ""/Users/hartikainen/conda/envs/variational-option-discovery/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py"", line 1964, in process_layer
    layer = deserialize_layer(layer_data, custom_objects=custom_objects)
  File ""/Users/hartikainen/conda/envs/variational-option-discovery/lib/python3.7/site-packages/tensorflow/python/keras/layers/serialization.py"", line 109, in deserialize
    printable_module_name='layer')
  File ""/Users/hartikainen/conda/envs/variational-option-discovery/lib/python3.7/site-packages/tensorflow/python/keras/utils/generic_utils.py"", line 373, in deserialize_keras_object
    list(custom_objects.items())))
  File ""/Users/hartikainen/conda/envs/variational-option-discovery/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py"", line 393, in from_config
    model.build(build_input_shape)
  File ""/Users/hartikainen/conda/envs/variational-option-discovery/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py"", line 266, in build
    super(Sequential, self).build(input_shape)
  File ""/Users/hartikainen/conda/envs/variational-option-discovery/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py"", line 647, in build
    x = base_layer_utils.generate_placeholders_from_shape(input_shape)
  File ""/Users/hartikainen/conda/envs/variational-option-discovery/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_utils.py"", line 165, in generate_placeholders_from_shape
    return array_ops.placeholder(shape=shape, dtype=backend.floatx())
  File ""/Users/hartikainen/conda/envs/variational-option-discovery/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py"", line 3006, in placeholder
    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)
  File ""/Users/hartikainen/conda/envs/variational-option-discovery/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 6674, in placeholder
    shape = _execute.make_shape(shape, ""shape"")
  File ""/Users/hartikainen/conda/envs/variational-option-discovery/lib/python3.7/site-packages/tensorflow/python/eager/execute.py"", line 213, in make_shape
    raise TypeError(""Error converting %s to a TensorShape: %s."" % (arg_name, e))
TypeError: Error converting shape to a TensorShape: 'collections.OrderedDict' object cannot be interpreted as an integer.
```
"
37059,TensorFlow 1.8 Issues with GPU availability always returns false,"Hi,

I have been facing issues lately with getting tensorflow to use GPU, I have setup a jupyterhub application on AWS cloud with a P3 type Instance which has cuda and drivers installed also tensorflow python packages, but whenever i check the gpu availability tensorflow returns False
![tensorflow jupyterhub](https://user-images.githubusercontent.com/32424190/75277684-770a4100-57d6-11ea-985c-87b12ba6a645.png)
![nvidia smi](https://user-images.githubusercontent.com/32424190/75277713-89847a80-57d6-11ea-87e1-55718b4602d0.png)
![tensorflow jupyterhub](https://user-images.githubusercontent.com/32424190/75277710-88534d80-57d6-11ea-96ce-dc9b471bbf7b.png)
![Uploading nvidia smi.png…]()

Here is the version information  below:

Nvidia Driver Version: 396.26
CUDA Version 9.2.88
CUDNN_VERSION 7.1.4
Tensorflow : 1.8.0
Tensorflow_gpu : 1.8.0

Here is the compatibility list from Tensorflow website which doesn't point out the cuda and cudnn minor versions only major version https://www.tensorflow.org/install/source#linux

Can someone please help me with this issue, Thanks in advance!
"
37058,TensorFlow 1.8 Issues with GPU availability always returns false,"Hi,

I have been facing issues lately with getting tensorflow to use GPU, I have setup a jupyterhub application on AWS cloud with a P3 type Instance which has cuda and drivers installed also tensorflow python packages, but whenever i check the gpu availability tensorflow returns False

Here is the version information  below:

Nvidia Driver Version: 396.26
CUDA Version 9.2.88
CUDNN_VERSION 7.1.4
Tensorflow : 1.8.0
Tensorflow_gpu : 1.8.0

Here is the compatibility list from Tensorflow website which doesn't point out the cuda and cudnn minor versions only major version https://www.tensorflow.org/install/source#linux

Can someone please help me with this issue, Thanks in advance!
"
37057,MultiWorkerMirroredStrategy OOM - Ubuntu 18.04 ,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): **yes**
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): **Linux Ubuntu 18.04**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
- TensorFlow installed from (source or
binary): **pip install tensorflow==2.1.0** - TensorFlow version (use command below): 
- Python version: **python=3.6.9** - Bazel
version (if compiling from source):
- GCC/Compiler version (if compiling from
source): 
- CUDA/cuDNN version: **10.2** - GPU model and memory: **NVIDIA T4 16GB (g4dn.xlarge) (REPRODUCABLE ON CPU)**

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
When training a trivial model with `MultiWorkerMirroredStrategy` over `cifar10` the memory consumption of all workers grows over time until eventually the system runs out of memory.

Memory consumption grows while `model.fit` is running.

I ran into this issue on the AWS Deep Learning AMI, but was also able to reproduce it with a manually configured AWS Ubuntu 18.04 AMI. Could not reproduce on a Mac laptop.

Note: A more complicated model will run out of memory a lot faster, the toy example I provide for reproduction was deliberately downscaled for simplicity, but takes a few minutes to double RAM consumption.

Cluster setup:
- 4 CPU workers (`CUDA_AVAILABLE_DEVICES=''`) on a **single** g4dn.xlarge instance (was able to reproduce with multiple instances, and with GPU training)
- Using `ray` to run the processes for convenience, not using any of its distributed features

**Describe the expected behavior**
Memory consumption is stable/the system does not run out of memory.

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

https://gist.github.com/maximsmol/ac2aeb5582600cd8b3fc6952cfd040a1
^ the issue requires a multi-worker setup (ips+ports) so it's not possible to provide a notebook

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

The way I track the memory consumption is openning `top` and watch the RES RAM column for the workers. It very visibly grows."
37056,tf.keras.layers.Lambda deserialization fails due to `KeyError: 'name'`,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow):  No
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04):  `macOS Catalina 10.15.2 (19C57)`
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): nightly binary (`v1.12.1-25814-g2e81bc66c5 2.2.0-dev20200225`)
- Python version: 3.7.6
- CUDA/cuDNN version: - GPU model and memory: n/a

**Describe the current behavior**
Trying to serialize and then deserialize a simple `tf.keras.layers.Lambda` results in `KeyError: 'name'`.

**Describe the expected behavior**
No `KeyError: 'name'` exception is thrown and the model is deserialized correctly.

**Standalone code to reproduce the issue** 
```python
import tensorflow as tf


inputs = tf.random.uniform((4, 3))

sequential_model = tf.keras.Sequential((
    tf.keras.layers.Lambda(lambda x: tf.concat(tf.nest.flatten(x), axis=-1)),
))

_ = sequential_model(inputs)

sequential_model_2 = tf.keras.Model.from_config(sequential_model.get_config())
```

**Other info / logs**
```
$ python ./tests/test_lambda_layer_serialization.py
Traceback (most recent call last):
  File ""./tests/test_lambda_layer_serialization.py"", line 12, in <module>
    sequential_model_2 = tf.keras.Model.from_config(sequential_model.get_config())
  File ""/Users/hartikainen/conda/envs/softlearning-tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py"", line 950, in from_config
    config, custom_objects)
  File ""/Users/hartikainen/conda/envs/softlearning-tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py"", line 1987, in reconstruct_from_config
    process_layer(layer_data)
  File ""/Users/hartikainen/conda/envs/softlearning-tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py"", line 1956, in process_layer
    layer_name = layer_data['name']
KeyError: 'name'
```
"
37055,bi test,"sdfdssdfdssdsdfsdfsdfsdfdsfsdfsdfsdfsdfsdfdsfsdfsdfsdfdsfsdfsdfsdfsdfsdfdsf load_dynamic return _load(spec)
CUDA/cuDNN version: 434
**Provide the exact sequence"
37054,TPU scope valuerror,"I want to run this code support TPU
It's my function and [colab:](https://colab.research.google.com/drive/1aysV-1Vur5Wp8BKD64bwWLNNue60MV2-)
```
def build_model(params_path = 'test/params', enc_lstm_units = 128, unroll = True, use_gru=False, optimizer='adam', display_summary=True):
    """"""
    Build keras model

    Parameters:

    params_path (str): Path for saving/loading the params.

    enc_lstm_units (int): Positive integer, dimensionality of the output space.

    unroll (bool): Boolean (default False). If True, the network will be unrolled, else a symbolic loop will be used. Unrolling can speed-up a RNN, although it tends to be more memory-intensive. Unrolling is only suitable for short sequences.

    use_gru (bool): GRU will be used instead of LSTM

    optimizer (str): optimizer to be used

    display_summary (bool): Set to true for verbose information.


    Returns:

    model (keras model): built model object.
    
    params (dict): Generated params (encoding, decoding dicts ..).

    """"""
    # generateing the encoding, decoding dicts
    params = build_params(params_path = params_path)

    input_encoding = params['input_encoding']
    input_decoding = params['input_decoding']
    input_dict_size = params['input_dict_size']
    output_encoding = params['output_encoding']
    output_decoding = params['output_decoding']
    output_dict_size = params['output_dict_size']
    max_input_length = params['max_input_length']
    max_output_length = params['max_output_length']


    if display_summary:
        print('Input encoding', input_encoding)
        print('Input decoding', input_decoding)
        print('Output encoding', output_encoding)
        print('Output decoding', output_decoding)


    # We need to define the max input lengths and max output lengths before training the model.
    # We pad the inputs and outputs to these max lengths
    encoder_input = Input(shape=(max_input_length,))
    decoder_input = Input(shape=(max_output_length,))

    # Need to make the number of hidden units configurable
    encoder = Embedding(input_dict_size, enc_lstm_units, input_length=max_input_length, mask_zero=True)(encoder_input)
    # using concat merge mode since in my experiments it g ave the best results same with unroll
    if not use_gru:
        encoder = Bidirectional(LSTM(enc_lstm_units, return_sequences=True, return_state=True, unroll=unroll), merge_mode='concat')(encoder)
        encoder_outs, forward_h, forward_c, backward_h, backward_c = encoder
        encoder_h = concatenate([forward_h, backward_h])
        encoder_c = concatenate([forward_c, backward_c])
    
    else:
        encoder = Bidirectional(GRU(enc_lstm_units, return_sequences=True, return_state=True, unroll=unroll), merge_mode='concat')(encoder)        
        encoder_outs, forward_h, backward_h= encoder
        encoder_h = concatenate([forward_h, backward_h])
    

    # using 2* enc_lstm_units because we are using concat merge mode
    # cannot use bidirectionals lstm for decoding (obviously!)
    
    decoder = Embedding(output_dict_size, 2 * enc_lstm_units, input_length=max_output_length, mask_zero=True)(decoder_input)

    if not use_gru:
        decoder = LSTM(2 * enc_lstm_units, return_sequences=True, unroll=unroll)(decoder, initial_state=[encoder_h, encoder_c])
    else:
        decoder = GRU(2 * enc_lstm_units, return_sequences=True, unroll=unroll)(decoder, initial_state=encoder_h)


    # luong attention
    attention = dot([decoder, encoder_outs], axes=[2, 2])
    attention = Activation('softmax', name='attention')(attention)

    context = dot([attention, encoder_outs], axes=[2,1])

    decoder_combined_context = concatenate([context, decoder])

    output = TimeDistributed(Dense(enc_lstm_units, activation=""tanh""))(decoder_combined_context)
    output = TimeDistributed(Dense(output_dict_size, activation=""softmax""))(output)

    model = Model(inputs=[encoder_input, decoder_input], outputs=[output])
    
    resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])
    tf.config.experimental_connect_to_cluster(resolver)
    tf.tpu.experimental.initialize_tpu_system(resolver)
    strategy = tf.distribute.experimental.TPUStrategy(resolver) 
    with strategy.scope():
      model = Model(inputs=[encoder_input, decoder_input], outputs=[output])
      model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])

    if display_summary:
        model.summary()
    
    return model, params
```
Error:
```
ValueError                                Traceback (most recent call last)
<ipython-input-6-66476e79d8c4> in <module>()
    501     build_params(input_data = input_data, output_data = output_data, params_path = 'params', max_lenghts=(10, 10))
    502 
--> 503     model, params = build_model(params_path='params')
    504 
    505     input_data, output_data = convert_training_data(input_data, output_data, params)

2 frames
/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py in compile(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)
    398                 'with strategy.scope():\n'
    399                 '  model=_create_model()\n'
--> 400                 '  model.compile(...)'% (v, strategy))
    401 
    402   @trackable.no_automatic_dependency_tracking

ValueError: Variable (<tf.Variable 'embedding_2_1/embeddings:0' shape=(39, 128) dtype=float32>) was not created in the distribution strategy scope of (<tensorflow.python.distribute.tpu_strategy.TPUStrategyV1 object at 0x7f9e623bef98>). It is most likely due to not all layers or the model or optimizer being created outside the distribution strategy scope. Try to make sure your code looks similar to the following.
with strategy.scope():
  model=_create_model()
  model.compile(...)
```"
37053,Cannot wrap GradientTape.batch_jacobian with tf.function on tf.keras model with LSTM cells,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow):  Yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04):  macOS Mojave
- TensorFlow installed from (source or
binary): binary
- TensorFlow version (use command below): 2.1.0
- Python version: 3.7.4

**Describe the current behavior**

The @tf.function wrapper is not able to convert LSTM cells correctly for use in the `batch_jacobian` function (or `jacobian`, tested both). These functions work correctly without the decorator.
```
    ValueError: No converter defined for VariableShape
    name: ""loop_body/VariableShape_2""
    op: ""VariableShape""
    input: ""binary_classification_lstm/lstm/while:10""
    attr {
      key: ""out_type""
      value {
        type: DT_INT32
      }
    } 
```

**Describe the expected behavior**

This should run without throwing an error

**Standalone code to reproduce the issue** 
```
import tensorflow as tf

class BinaryClassificationLSTM(tf.keras.Model):
    def __init__(self, units, name=None):
        super(BinaryClassificationLSTM, self).__init__(name=name)
        self.lstm_layer = tf.keras.layers.LSTM(units, activation='softsign')
        self.dense = tf.keras.layers.Dense(1)
        self.sigmoid = tf.keras.layers.Activation('sigmoid')

    def call(self, x):
        sequence = self.lstm_layer(x)
        logit = self.dense(sequence)
        prob = self.sigmoid(logit)

        return prob
    

@tf.function
def get_jacobian(model, tensor_in):
    with tf.GradientTape() as tape:
        tape.watch(tensor_in)
        predictions = model(tensor_in)
    
    return tape.batch_jacobian(predictions, tensor_in)

inp = tf.zeros((1, 10, 5))
lstm = BinaryClassificationLSTM(10)
jacobian = get_jacobian(lstm, inp)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

```
Traceback (most recent call last):
  File ""test.py"", line 29, in <module>
    jacobian = get_jacobian(lstm, inp)
  File ""/Users/henryprior/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 568, in __call__
    result = self._call(*args, **kwds)
  File ""/Users/henryprior/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 615, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File ""/Users/henryprior/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 497, in _initialize
    *args, **kwds))
  File ""/Users/henryprior/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2389, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/Users/henryprior/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2703, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/Users/henryprior/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2593, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/Users/henryprior/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py"", line 978, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/Users/henryprior/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 439, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/Users/henryprior/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py"", line 968, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: in converted code:

    test.py:24 get_jacobian  *
        return tape.batch_jacobian(predictions, tensor_in)
    /Users/henryprior/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py:1246 batch_jacobian
        sys.exc_info()[2])
    /Users/henryprior/anaconda3/envs/test/lib/python3.7/site-packages/six.py:702 reraise
        raise value.with_traceback(tb)
    /Users/henryprior/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py:1238 batch_jacobian
        parallel_iterations=parallel_iterations)
    /Users/henryprior/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/ops/parallel_for/control_flow_ops.py:189 pfor
        return f()
    /Users/henryprior/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/ops/parallel_for/control_flow_ops.py:183 f
        return _pfor_impl(loop_fn, iters, parallel_iterations=parallel_iterations)
    /Users/henryprior/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/ops/parallel_for/control_flow_ops.py:256 _pfor_impl
        outputs.append(converter.convert(loop_fn_output))
    /Users/henryprior/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/ops/parallel_for/pfor.py:1280 convert
        output = self._convert_helper(y)
    /Users/henryprior/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/ops/parallel_for/pfor.py:1460 _convert_helper
        (y_op.type, y_op, converted_inputs))

    ValueError: No converter defined for VariableShape
    name: ""loop_body/VariableShape_2""
    op: ""VariableShape""
    input: ""binary_classification_lstm/lstm/while:10""
    attr {
      key: ""out_type""
      value {
        type: DT_INT32
      }
    }

    inputs: [WrappedTensor(t=<tf.Tensor 'binary_classification_lstm/lstm/while:10' shape=() dtype=resource>, is_stacked=False, is_sparse_stacked=False)].
    Either add a converter or set --op_conversion_fallback_to_while_loop=True, which may run slower
    Encountered an exception while vectorizing the batch_jacobian computation. Vectorization can be disabled by setting experimental_use_pfor to False.
```"
37052,"Can't convert the model into "".tflite"". I've tried every possible way from APIs to command lines. I tried to change layers as per tflite, but I couldn't understand the working and ended up with errors.","**System information**
- Google Colab
- TensorFlow: 1.15 

**Code link with dataset**
https://github.com/Kiranendra/Project

By trying different types of conversion like from saved model, from Keras model, freeze graphs, I am facing errors like with ""input shape""( is none),  embedding layer. If I change the layer GRU to LSTM then input errors with the decoder output and it goes."
37051,Tensorflow Docker Image with Jupyter Notebook Runs in HTTP,Looks like the official image in [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dockerfiles/dockerfiles/gpu-jupyter.Dockerfile) runs the container as `root` and runs jupyter notebook with `http`. Is there a version that does not run as a `root` and also supports `https` (self signed certs would be fine)? 
37050,tflite | interpreter->AllocateTensors() fails,"**System information** 
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): docker image (nightly)
- TensorFlow version (use command below): TensorFlow 2.2.0-dev20200218

**Describe the current behavior**
In Python (tf.lite.Interpreter), everything works as expected. In C++, however, interpreter->AllocateTensors() fails when using the attached model (see link to minimal example below). Absolutely no clue is given. No error. I have no idea why this happens. I'm not using any custom ops.

**Describe the expected behavior**
The C++ code should give the same result as the python code (tf.lite.Interpreter).

**Standalone code to reproduce the issue** 
[Can be found here](https://drive.google.com/open?id=1kKUP-bIizhWNtA8xt8X3DV1M7h8AJGD_)"
37049,Can't use RaggedTensor in @tf.function input_signature.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): `no`
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `Ubuntu 18.04`
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: `no`
- TensorFlow installed from (source or binary): `no`
- TensorFlow version (use command below): `2.0.1`
- Python version: `3.7.3`
- Bazel version (if compiling from source): `-`
- GCC/Compiler version (if compiling from source): `-`
- CUDA/cuDNN version: `-`
- GPU model and memory: `-`

**Describe the current behavior**
It is not possible to pass a tf.RaggedTensor as a tf.function input signature, and therefore use it with e.g. Tensorflow Serving.

**Describe the expected behavior**
It should be possible to pass a tf.RaggedTensor as a tf.function input signature.

**Code to reproduce the issue**
```python
import tensorflow as tf


class MyModule(tf.Module):
    def __init__(self):
        super(MyModule, self).__init__()
        tf.saved_model.save(
            self,
            ""/tmp/foomodel/001"",
            signatures={
                tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY: self.some_method,
            },
        )

    @tf.function(input_signature=[
        tf.TensorSpec((None, ), dtype=tf.int64),
        tf.RaggedTensorSpec((None, None), dtype=tf.string),
    ])
    def some_method(self, dense, ragged):
        return tf.constant([""foobar""], dtype=tf.string)

m = MyModule()
dense = tf.constant([[1,2]], dtype=tf.int64)
ragged = tf.ragged.constant([[""foo""], [""foo"", ""bar""]], dtype=tf.string)
some_result = m.some_method(dense, ragged)
print(f""some_result => {some_result}"")

#ValueError: Python inputs incompatible with input_signature:
# inputs: (
#    tf.Tensor([[1 2]], shape=(1, 2), dtype=int64),
#    <tf.RaggedTensor [[b'foo'], [b'foo', b'bar']]>)
#  input_signature: (
#    TensorSpec(shape=(None,), dtype=tf.int64, name=None),
#    RaggedTensorSpec(TensorShape([None, None]), tf.string, 1, tf.int64))
```
"
37048,The output of the Conv2D layer in backend TensorFlow is different from that in Theano and CNTK,"## System Information

- CUDA Version 10.1.168
- Python==3.6.8
- numpy==1.14.6
- tensorflow-gpu==1.14.0
- theano==1.0.4
- cntk-gpu==2.7
- gcc== 5.4.0
- Linux version 4.15.0-52-generic

## Description

Hi, I encountered a problem when I used a variant of the AlexNet model for image classification task. The prediction result of backend TensorFlow is different from backend Theano and backend CNTK in  Keras. The input picture is sampled from the CIFAR10 DataSet. 

The outputs ( Top-1 prediction) of three backends are shown below（Prediction label id and  Probability ）:

**TensorFlow**: 2, 0.9999998807907104

**CNTK**:  6,1.0

**Theano**: 6,1.0

It seems that there is something wrong with Tensorflow. Then I put image into the model and recorded the ouputs of each layers to see how this happens. It seems that the outputs on CNTK and Theano are very close, but for Tensorflow, the outputs of a conv2d layer and all the layers after this layer are very different from CNTK and Theano.

The results are attached below.

Theano vs CNTK
![image-20200225181539716](https://user-images.githubusercontent.com/15032308/75246315-7d1a1500-580a-11ea-978e-93224948d974.png)


TensorFlow vs Theano

![image-20200225181451774](https://user-images.githubusercontent.com/15032308/75246369-94f19900-580a-11ea-871e-a401d652fbc4.png)

TensorFlow vs CNTK
![image-20200225181519926](https://user-images.githubusercontent.com/15032308/75246356-8efbb800-580a-11ea-9efe-a8c29708465f.png)


The delta column shows the discrepancy, which is calculated as:
![MAD](https://user-images.githubusercontent.com/15032308/75246389-9f139780-580a-11ea-8c41-ae22458272f7.png)


Based on the results, the deviation seems to be caused by conv2d of tensorflow backend.

## To Reproduce
The code of getting prediction result of each backend  is really simple. 

get_prediction.py :

```python
import os
import sys
import numpy as np
from PIL import Image
bk = sys.argv[1]
os.environ['KERAS_BACKEND'] = bk
os.environ[""CUDA_DEVICE_ORDER""] = ""PCI_BUS_ID""
os.environ[""CUDA_VISIBLE_DEVICES""] = ""0""

import keras
from keras import backend as K
print(""Using backend :{}"".format(K.backend()))


def custom_objects():

    def no_activation(x):
        return x

    def leakyrelu(x):
        import keras.backend as K
        return K.relu(x, alpha=0.01)

    objects = {}
    objects['no_activation'] = no_activation
    objects['leakyrelu'] = leakyrelu
    return objects


def image_resize(x, shape):
    x_return = []
    for x_test in x:
        tmp = np.copy(x_test)
        img = Image.fromarray(tmp.astype('uint8')).convert('RGB')
        img = img.resize(shape, Image.ANTIALIAS)
        x_return.append(np.array(img))
    return np.array(x_return)


base_model = keras.models.load_model(""alexnet-cifar10_origin0-ARep4-ARep6-ARem1-LC6.h5"",custom_objects=custom_objects())
adam = keras.optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0)
base_model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])


imagename = 'cifar10-1042.png'
img = Image.open(imagename)
img = img.resize((32,32), Image.ANTIALIAS)
x_test = np.array(img)
select_data = np.expand_dims(x_test, axis=0)

prediction = base_model.predict(select_data)
pred = np.argsort(prediction[0])
print(pred)
print(f""Prediction of {bk}: {pred[-1]},{prediction[0][pred[-1]]}"")
```

You can run the script like this ():

> python get_prediction.py tensorflow

Change tensorflow to 'theano' and 'cntk'

I provide scripts to get outputs of the middle layers and calculate the difference:
[tensorflow-conv2d.zip](https://github.com/tensorflow/tensorflow/files/4256311/tensorflow-conv2d.zip)

The model used in scripts can be downloads from：https://send.firefox.com/download/c01db9a2b4773d8b/#ME176P7KQp4J6DmB46xBBg
Thanks in advance.



"
37047,Request for documents of tf.compat.v1.profiler.Profiler,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:
https://www.tensorflow.org/api_docs/python/tf/compat/v1/profiler/Profiler?hl=zh-TW

## Description of issue (what needs changing):
The README link for this function is 404, so there is no support for usage. The sample code is not complete either.

### Clear description
![image](https://user-images.githubusercontent.com/33815430/75243362-b64f8680-5804-11ea-8bf6-2888306b1a38.png)
For example
```python
profiler.profile_name_scope(options=(option_builder.ProfileOptionBuilder
          .trainable_variables_parameter()))
```
No declarence of option_builder. It's hard for me to reproduce the result by this sample code.
Could tensorflow provide new support to this function??"
37045,reshuffle_each_iteration=False ignored on validation (tf.dataset + Keras),"When using .shuffle on some `tf.Dataset.from_generator`, it appears that the `reshuffle_each_iteration=False` is ignored by Keras.  
If you run the following example, you would expect to see the train_set and val_set buffer filling at the start of the session, and then you would no longer see it between each epoch. The buffers are large enough to cover more than one epoch and can be refilled in parallel during the epoch.    

However, what seems to happen is that the val_set shuffle buffer is filled at the end of each epoch.  
The terminal shows ""Filling shuffle buffer"" at the end of each epoch.  
You can see that it is specifically the val_set buffer by removing the shuffle on val_set. Doing so, you will no longer see a ""Filling shuffle"" at each epoch, only at the start of the session.  

Additionally, [issue 35100](https://github.com/tensorflow/tensorflow/issues/35100 ) will spam the terminal on this example, with or without shuffle.  

Seen on Win10, with tensorflow 2.10.  
Code to reproduce the problem:  
```
import tensorflow as tf
import numpy as np
import time

def random_gen():
    while True:
        time.sleep(0.01)
        yield (np.random.rand(1,), np.random.rand(1,))

dataset = tf.data.Dataset.from_generator(
        random_gen,
        (tf.float32, tf.float32),
        (tf.TensorShape((None,)), tf.TensorShape((None,))),
    )

train_set =   (dataset
               .shuffle(2000, reshuffle_each_iteration=False)
               .batch(32))
val_set =    (dataset
               .shuffle(2000, reshuffle_each_iteration=False) # Problem is here
               .batch(32))

model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Dense(3))
model.compile(loss='mse', optimizer='adam')

model.fit(x=train_set,
          epochs= 5,
          steps_per_epoch= 10,
          validation_data= val_set,
          validation_steps= 5,
)
```"
37044,Deep Training with Tensorflow,"Hello,

i'm trying to make an experiment about performance with Keras and Tensorflow. I'm interested in training some parts of the networks. In my case, my objective is training some connections (neurons) of certains layers. Is it possible to do that experiment? I know that re-training layers is possible with trainable=True, but I would like to do it in a deeper way, going to the connections (fully connected phase) and filters (convolutional phase)

Thanks,

Javier
"
37043,An error is reported when the nested tf.keras.Model subclass model is converted to a tflite file,"My environment:
tensorflow-gpu 2.1
windows 10
python 3.7

tensorflow is installed using pip

**The following is a simple demo I wrote to illustrate this problem.：**
`
    import tensorflow as tf
    
    @tf.function
    def Hswish(x):
        return x * tf.nn.relu6(x + 3) / 6
    
    tf.keras.utils.get_custom_objects().update({'custom_activation': tf.keras.layers.Activation(Hswish)})
    
    class Conv2d_BN(tf.keras.Model):
        def __init__(self, filters, kernel_size, strides, padding, is_use_bias=True, name=None):
            super(Conv2d_BN, self).__init__(name=name)
            self.conv2d_bn = tf.keras.Sequential([tf.keras.layers.Conv2D(filters, kernel_size, strides=strides,
                                                                   padding=padding, use_bias=is_use_bias, kernel_initializer=tf.ones),
                                                  tf.keras.layers.BatchNormalization()], name=""conv2d_bn"")
    
        def call(self, inputs):
            return self.conv2d_bn(inputs)
    
    class test_model2(tf.keras.Model):
        def __init__(self, layer_name, layer_filters, name=""test_model2""):
            super(test_model2, self).__init__(name=name)
            self.convs = []
            for n, f in zip(layer_name, layer_filters):
                if ""2"" in n:
                    continue
                self.convs.append(Conv2d_BN(filters=f, kernel_size=1, strides=(1,1), padding=""valid"", is_use_bias=False,
                                            name=self.name + n + ""/conv1""))
            self.empty_layer = None
    
        @tf.function
        def call(self, inputs):
            output1 = inputs[0]
            for c_layer in self.convs:
                output1 = c_layer(output1)
    
            output2 = inputs[1]
            for c_layer in self.convs:
                output2 = c_layer(output2)
            if self.empty_layer is None:
                print(""None"")
            return output1, output2
    
    
    layer_name = [""layer1"", ""layer2"", ""layer3"", ""layer4"", ""layer5""]
    layer_filters = [3, 4, 5, 6, 7]
    model = test_model2(layer_name, layer_filters)
    test_input1 = tf.ones((1, 2, 2, 1))
    test_input2 = tf.zeros((1, 2, 2, 1))
    input_list = [test_input1, test_input2]
    test_output1, test_output2 = model(input_list)
    print(test_output1)
    print(test_output2)
    
    model._set_inputs(input_list)
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    tflite_model = converter.convert()
    open(""./save4/converted_model.tflite"", ""wb"").write(tflite_model)
`
**The following is the error message：**
	C:\software\Anaconda3\envs\TF2_1_GPU\python.exe C:/Users/stars_ocean/Desktop/TensorFlow_test_folder/new_tf_模型保存_进阶4.py
	2020-02-25 17:50:15.295174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
	2020-02-25 17:50:17.612336: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
	2020-02-25 17:50:18.876900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
	pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
	coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 104.43GiB/s
	2020-02-25 17:50:18.877178: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
	2020-02-25 17:50:18.886768: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
	2020-02-25 17:50:18.893842: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
	2020-02-25 17:50:18.898386: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
	2020-02-25 17:50:18.905867: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
	2020-02-25 17:50:18.911441: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
	2020-02-25 17:50:18.924981: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
	2020-02-25 17:50:18.925736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
	2020-02-25 17:50:18.926051: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
	2020-02-25 17:50:18.926915: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
	pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
	coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 104.43GiB/s
	2020-02-25 17:50:18.927189: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
	2020-02-25 17:50:18.927331: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
	2020-02-25 17:50:18.927466: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
	2020-02-25 17:50:18.927601: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
	2020-02-25 17:50:18.927736: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
	2020-02-25 17:50:18.927875: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
	2020-02-25 17:50:18.928013: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
	2020-02-25 17:50:18.928571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
	2020-02-25 17:50:19.461309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
	2020-02-25 17:50:19.461461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
	2020-02-25 17:50:19.461550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
	2020-02-25 17:50:19.462190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2985 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
	None
	None
	2020-02-25 17:50:20.090133: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
	2020-02-25 17:50:20.855562: W tensorflow/stream_executor/gpu/redzone_allocator.cc:312] Internal: Invoking GPU asm compilation is supported on Cuda non-Windows platforms only
	Relying on driver to perform ptx compilation. This message will be only logged once.
	2020-02-25 17:50:20.874969: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
	tf.Tensor(
	[[[[89.82026 89.82026 89.82026 89.82026 89.82026 89.82026 89.82026]
	   [89.82026 89.82026 89.82026 89.82026 89.82026 89.82026 89.82026]]

	  [[89.82026 89.82026 89.82026 89.82026 89.82026 89.82026 89.82026]
	   [89.82026 89.82026 89.82026 89.82026 89.82026 89.82026 89.82026]]]], shape=(1, 2, 2, 7), dtype=float32)
	tf.Tensor(
	[[[[0. 0. 0. 0. 0. 0. 0.]
	   [0. 0. 0. 0. 0. 0. 0.]]

	  [[0. 0. 0. 0. 0. 0. 0.]
	   [0. 0. 0. 0. 0. 0. 0.]]]], shape=(1, 2, 2, 7), dtype=float32)
	None
	2020-02-25 17:50:21.348618: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
	2020-02-25 17:50:21.348841: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
	2020-02-25 17:50:21.350171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
	pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
	coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 104.43GiB/s
	2020-02-25 17:50:21.350427: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
	2020-02-25 17:50:21.350557: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
	2020-02-25 17:50:21.350687: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
	2020-02-25 17:50:21.350815: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
	2020-02-25 17:50:21.350943: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
	2020-02-25 17:50:21.351072: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
	2020-02-25 17:50:21.351205: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
	2020-02-25 17:50:21.351611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
	2020-02-25 17:50:21.351751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
	2020-02-25 17:50:21.351889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
	2020-02-25 17:50:21.351976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
	2020-02-25 17:50:21.352364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2985 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
	2020-02-25 17:50:21.378422: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize
	2020-02-25 17:50:21.378569: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: Graph size after: 182 nodes (156), 365 edges (338), time = 7.223ms.
	2020-02-25 17:50:21.378731: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: Graph size after: 182 nodes (0), 365 edges (0), time = 3.522ms.
	2020-02-25 17:50:21.378885: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer4_conv1_1_conv2d_bn_batch_normalization_2_cond_1_true_940
	2020-02-25 17:50:21.379063: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
	2020-02-25 17:50:21.379206: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
	2020-02-25 17:50:21.379345: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer3_conv1_1_conv2d_bn_batch_normalization_1_cond_false_829
	2020-02-25 17:50:21.379524: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
	2020-02-25 17:50:21.379663: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
	2020-02-25 17:50:21.379799: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer1_conv1_1_conv2d_bn_batch_normalization_cond_1_false_811
	2020-02-25 17:50:21.379978: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
	2020-02-25 17:50:21.380119: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
	2020-02-25 17:50:21.380258: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer1_conv1_1_conv2d_bn_batch_normalization_cond_false_764
	2020-02-25 17:50:21.380435: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
	2020-02-25 17:50:21.380575: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
	2020-02-25 17:50:21.380712: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer4_conv1_1_conv2d_bn_batch_normalization_2_cond_false_894
	2020-02-25 17:50:21.380889: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
	2020-02-25 17:50:21.381028: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
	2020-02-25 17:50:21.381166: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer5_conv1_conv2d_bn_batch_normalization_3_cond_1_false_746
	2020-02-25 17:50:21.381344: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
	2020-02-25 17:50:21.381482: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
	2020-02-25 17:50:21.381624: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer4_conv1_conv2d_bn_batch_normalization_2_cond_1_false_674
	2020-02-25 17:50:21.381805: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
	2020-02-25 17:50:21.381943: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
	2020-02-25 17:50:21.382079: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer1_conv1_1_conv2d_bn_batch_normalization_cond_true_763
	2020-02-25 17:50:21.391040: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
	2020-02-25 17:50:21.391189: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
	2020-02-25 17:50:21.391329: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer4_conv1_1_conv2d_bn_batch_normalization_2_cond_true_893
	2020-02-25 17:50:21.391507: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
	2020-02-25 17:50:21.391679: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
	2020-02-25 17:50:21.391817: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer3_conv1_conv2d_bn_batch_normalization_1_cond_true_550
	2020-02-25 17:50:21.391994: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
	2020-02-25 17:50:21.392136: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
	2020-02-25 17:50:21.392274: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer3_conv1_1_conv2d_bn_batch_normalization_1_cond_true_828
	2020-02-25 17:50:21.392453: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
	2020-02-25 17:50:21.392591: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
	2020-02-25 17:50:21.392729: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer5_conv1_1_conv2d_bn_batch_normalization_3_cond_1_true_1005
	2020-02-25 17:50:21.392910: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
	2020-02-25 17:50:21.393057: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
	2020-02-25 17:50:21.393200: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer1_conv1_conv2d_bn_batch_normalization_cond_true_478
	2020-02-25 17:50:21.393374: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
	2020-02-25 17:50:21.393512: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
	2020-02-25 17:50:21.393649: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer1_conv1_conv2d_bn_batch_normalization_cond_1_false_530
	2020-02-25 17:50:21.393827: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
	2020-02-25 17:50:21.393965: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
	2020-02-25 17:50:21.394105: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer1_conv1_1_conv2d_bn_batch_normalization_cond_1_true_810
	2020-02-25 17:50:21.394282: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
	2020-02-25 17:50:21.394423: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
	2020-02-25 17:50:21.394562: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer1_conv1_conv2d_bn_batch_normalization_cond_false_479
	2020-02-25 17:50:21.394740: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
	2020-02-25 17:50:21.406638: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
	2020-02-25 17:50:21.406786: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer3_conv1_conv2d_bn_batch_normalization_1_cond_1_false_602
	2020-02-25 17:50:21.406966: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
	2020-02-25 17:50:21.407107: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
	2020-02-25 17:50:21.407247: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer4_conv1_conv2d_bn_batch_normalization_2_cond_1_true_673
	2020-02-25 17:50:21.407427: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
	2020-02-25 17:50:21.407565: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
	2020-02-25 17:50:21.407703: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer4_conv1_1_conv2d_bn_batch_normalization_2_cond_1_false_941
	2020-02-25 17:50:21.407884: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
	2020-02-25 17:50:21.408027: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
	2020-02-25 17:50:21.408166: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer5_conv1_1_conv2d_bn_batch_normalization_3_cond_true_958
	2020-02-25 17:50:21.408344: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
	2020-02-25 17:50:21.408489: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
	2020-02-25 17:50:21.408634: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer5_conv1_conv2d_bn_batch_normalization_3_cond_false_695
	2020-02-25 17:50:21.408870: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
	2020-02-25 17:50:21.409096: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
	2020-02-25 17:50:21.409238: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer5_conv1_conv2d_bn_batch_normalization_3_cond_true_694
	2020-02-25 17:50:21.409416: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
	2020-02-25 17:50:21.409558: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
	2020-02-25 17:50:21.409696: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer1_conv1_conv2d_bn_batch_normalization_cond_1_true_529
	2020-02-25 17:50:21.409874: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
	2020-02-25 17:50:21.410015: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
	2020-02-25 17:50:21.410154: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer5_conv1_1_conv2d_bn_batch_normalization_3_cond_1_false_1006
	2020-02-25 17:50:21.410340: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
	2020-02-25 17:50:21.410486: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
	2020-02-25 17:50:21.422249: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer5_conv1_conv2d_bn_batch_normalization_3_cond_1_true_745
	2020-02-25 17:50:21.422437: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
	2020-02-25 17:50:21.422581: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
	2020-02-25 17:50:21.422722: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer3_conv1_1_conv2d_bn_batch_normalization_1_cond_1_false_876
	2020-02-25 17:50:21.422905: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
	2020-02-25 17:50:21.423048: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
	2020-02-25 17:50:21.423187: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer4_conv1_conv2d_bn_batch_normalization_2_cond_true_622
	2020-02-25 17:50:21.423366: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
	2020-02-25 17:50:21.423508: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
	2020-02-25 17:50:21.423646: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer5_conv1_1_conv2d_bn_batch_normalization_3_cond_false_959
	2020-02-25 17:50:21.423825: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
	2020-02-25 17:50:21.423965: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
	2020-02-25 17:50:21.424103: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer3_conv1_conv2d_bn_batch_normalization_1_cond_false_551
	2020-02-25 17:50:21.424283: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
	2020-02-25 17:50:21.424425: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
	2020-02-25 17:50:21.424567: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer3_conv1_conv2d_bn_batch_normalization_1_cond_1_true_601
	2020-02-25 17:50:21.424745: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
	2020-02-25 17:50:21.424886: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
	2020-02-25 17:50:21.425024: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer3_conv1_1_conv2d_bn_batch_normalization_1_cond_1_true_875
	2020-02-25 17:50:21.425204: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
	2020-02-25 17:50:21.425344: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
	2020-02-25 17:50:21.425487: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer4_conv1_conv2d_bn_batch_normalization_2_cond_false_623
	2020-02-25 17:50:21.425668: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
	2020-02-25 17:50:21.425810: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
	Traceback (most recent call last):
	  File ""C:/Users/stars_ocean/Desktop/TensorFlow_test_folder/new_tf_模型保存_进阶4.py"", line 57, in <module>
		tflite_model = converter.convert()
	  File ""C:\software\Anaconda3\envs\TF2_1_GPU\lib\site-packages\tensorflow_core\lite\python\lite.py"", line 423, in convert
		self._funcs[0], lower_control_flow=False)
	  File ""C:\software\Anaconda3\envs\TF2_1_GPU\lib\site-packages\tensorflow_core\python\framework\convert_to_constants.py"", line 437, in convert_variables_to_constants_v2
		tensor_data = _get_tensor_data(func)
	  File ""C:\software\Anaconda3\envs\TF2_1_GPU\lib\site-packages\tensorflow_core\python\framework\convert_to_constants.py"", line 209, in _get_tensor_data
		data = val_tensor.numpy()
	AttributeError: 'Tensor' object has no attribute 'numpy'

	Process finished with exit code 1

After debugging, it was found that the problem is that the val_tensor variable at line 209 of convert_to_constants.py is keras_learning_phase, it is not a tensor, so there is no numpy () method.

So in this case, if you want to nest the Model and save it as a tflite file, what should you do?
"
37042,ImportError: DLL load failed: The specified module could not be found. Failed to load the native TensorFlow runtime.,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution: Windows 10
- Mobile device : none
- TensorFlow installed from): through Pycharm package installer
- TensorFlow version: 2.1.0
- Python version: 3.6
- Installed using: pip

I cant import any tensorflow or keras libraries. I get this error. 
I tried importing these:

import tensorflow as tf 
from keras.layers import Dense, Activation, Dropout
from keras.models import Sequential
from keras.utils import to_categorical

Traceback (most recent call last):
  File ""C:\Users\uvide\PycharmProjects\demo\venv\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2019.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""C:\Users\uvide\PycharmProjects\demo\venv\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\uvide\PycharmProjects\demo\venv\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\uvide\Anaconda3\lib\imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\uvide\Anaconda3\lib\imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File ""<input>"", line 1, in <module>
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2019.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_umd.py"", line 197, in runfile
    pydev_imports.execfile(filename, global_vars, local_vars)  # execute the script
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2019.3.3\plugins\python-ce\helpers\pydev\_pydev_imps\_pydev_execfile.py"", line 18, in execfile
    exec(compile(contents+""\n"", file, 'exec'), glob, loc)
  File ""C:/Users/uvide/PycharmProjects/demo/test.py"", line 4, in <module>
    from Potentiostat import Pot
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2019.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""C:\Users\uvide\PycharmProjects\demo\Potentiostat.py"", line 5, in <module>
    from keras.layers import Dense, Activation, Dropout
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2019.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""C:\Users\uvide\PycharmProjects\demo\venv\lib\site-packages\keras\__init__.py"", line 3, in <module>
    from . import utils
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2019.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""C:\Users\uvide\PycharmProjects\demo\venv\lib\site-packages\keras\utils\__init__.py"", line 6, in <module>
    from . import conv_utils
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2019.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""C:\Users\uvide\PycharmProjects\demo\venv\lib\site-packages\keras\utils\conv_utils.py"", line 9, in <module>
    from .. import backend as K
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2019.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""C:\Users\uvide\PycharmProjects\demo\venv\lib\site-packages\keras\backend\__init__.py"", line 1, in <module>
    from .load_backend import epsilon
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2019.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""C:\Users\uvide\PycharmProjects\demo\venv\lib\site-packages\keras\backend\load_backend.py"", line 90, in <module>
    from .tensorflow_backend import *
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2019.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""C:\Users\uvide\PycharmProjects\demo\venv\lib\site-packages\keras\backend\tensorflow_backend.py"", line 5, in <module>
    import tensorflow as tf
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2019.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""C:\Users\uvide\PycharmProjects\demo\venv\lib\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2019.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""C:\Users\uvide\PycharmProjects\demo\venv\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2019.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""C:\Users\uvide\PycharmProjects\demo\venv\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\uvide\PycharmProjects\demo\venv\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\uvide\Anaconda3\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\uvide\PycharmProjects\demo\venv\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2019.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""C:\Users\uvide\PycharmProjects\demo\venv\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\uvide\PycharmProjects\demo\venv\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2019.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""C:\Users\uvide\PycharmProjects\demo\venv\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\uvide\PycharmProjects\demo\venv\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\uvide\Anaconda3\lib\imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\uvide\Anaconda3\lib\imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.
Failed to load the native TensorFlow runtime.
"
37041,Feature suggestion: Ability to add copyright notice to saved model,"A trained TensorFlow model can represent valuable intellectual property, and may sometimes be distributed as a saved model, rather than python code etc. Is there any way of including a copyright notice in a saved model file?

If this is not yet possible, perhaps a comments= argument could be added to model.save().
"
37039,Shape information is lost with DepthwiseConv2D,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): Yes 
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or
binary): source 
- TensorFlow version (use command below): 1.15 
- CUDA/cuDNN version: 10.2
- GPU model and memory: RTX 2060


**Describe the current behavior**

In some cases (use_bias=False, dilation_rate > 1, data_format='channels_first'), the shape information is lost after DepthwiseConv2D. 

**Describe the expected behavior**

It should behave the same way for channels_last and channels_first.
When running the code below, channels_last prints `shape=(?, ?, ?, 32)` and channels_first prints `shape=(?, ?, ?, ?)`. It should be `shape=(?, 32, ?, ?)`

**Standalone code to reproduce the issue** 

[Here for the gist](https://colab.research.google.com/gist/jnd77/84932ac25671f8b5b59acdcb2f0e5afd/untitled1.ipynb) 

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
37038,UnsatisfiedLinkError on nightly build of tensorflow-lite,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Mobile device: Android
- TensorFlow installed from: Gradle (jcenter)

**Describe the current behavior**
On sample project, we ran into UnsatisfiedLinkError ""/lib/arm64/libtensorflowlite_gpu_jni.so"" using nightly build. If we switch to 2.1.0 that doesn't have the problem.
On Android guide to tensorflow-lite it also suggest to use nightly build, and I don't think this is good for production builds.
https://www.tensorflow.org/lite/guide/android

**Describe the expected behavior**
Doesn't run into UnsatisfiedLinkError at runtime.

**Standalone code to reproduce the issue** 
Your sample project

"
37037,tf_sess.run takes long time to excute,"I have using mobilenet coco model ,but it takes 5 seconds to finish the function anyone please help me to solve this  or describe why it takes this much of time

tf_config = tf.ConfigProto()
tf_config.gpu_options.allow_growth = True
tf_sess = tf.Session(config=tf_config)
tf.import_graph_def(trt_graph, name='')

tf_input = tf_sess.graph.get_tensor_by_name(input_names[0] + ':0')
tf_scores = tf_sess.graph.get_tensor_by_name('detection_scores:0')
tf_boxes = tf_sess.graph.get_tensor_by_name('detection_boxes:0')
tf_classes = tf_sess.graph.get_tensor_by_name('detection_classes:0')
tf_num_detections = tf_sess.graph.get_tensor_by_name('num_detections:0')

tf_input.shape.as_list()




def detection(IMAGE_PATH):
    start_time = datetime.datetime.now()


    image = cv2.imread(IMAGE_PATH)
    image = cv2.resize(image, (300, 300))

    scores, boxes, classes, num_detections = tf_sess.run([tf_scores, tf_boxes, tf_classes, tf_num_detections], feed_dict={
    tf_input: image[None, ...]
})
    boxes = boxes[0]  # index by 0 to remove batch dimension
    scores = scores[0]
    classes = classes[0]
    num_detections = int(num_detections[0])

    #print(boxes)
    #print(scores)
    #print(classes)
    #print(num_detections)
    for num in range(num_detections):
       if classes[num]==1:
          print('person')
          #return 'person'
       if classes[num]==62:
          print('chair')
          #return 'chair'
       if classes[num] != 1 and classes[num] != 62 :
          print(classes[num])
    end_time = datetime.datetime.now()
    diff = (end_time - start_time)
    print(diff)


detection(IMAGE_PATH)
"
37036,tf_sess.run takes 5 seconds,"# tf_sess.run very slow 
tf_config = tf.ConfigProto()
tf_config.gpu_options.allow_growth = True
tf_sess = tf.Session(config=tf_config)
tf.import_graph_def(trt_graph, name='')

tf_input = tf_sess.graph.get_tensor_by_name(input_names[0] + ':0')
tf_scores = tf_sess.graph.get_tensor_by_name('detection_scores:0')
tf_boxes = tf_sess.graph.get_tensor_by_name('detection_boxes:0')
tf_classes = tf_sess.graph.get_tensor_by_name('detection_classes:0')
tf_num_detections = tf_sess.graph.get_tensor_by_name('num_detections:0')

tf_input.shape.as_list()




def detection(IMAGE_PATH):
    start_time = datetime.datetime.now()


    image = cv2.imread(IMAGE_PATH)
    image = cv2.resize(image, (300, 300))

    scores, boxes, classes, num_detections = tf_sess.run([tf_scores, tf_boxes, tf_classes, tf_num_detections], feed_dict={
    tf_input: image[None, ...]
})
    boxes = boxes[0]  # index by 0 to remove batch dimension
    scores = scores[0]
    classes = classes[0]
    num_detections = int(num_detections[0])

    #print(boxes)
    #print(scores)
    #print(classes)
    #print(num_detections)
    for num in range(num_detections):
       if classes[num]==1:
          print('person')
          #return 'person'
       if classes[num]==62:
          print('chair')
          #return 'chair'
       if classes[num] != 1 and classes[num] != 62 :
          print(classes[num])
    end_time = datetime.datetime.now()
    diff = (end_time - start_time)
    print(diff)


detection(IMAGE_PATH)


this code takes around 5 seconds.Could it be reduce in timing?"
37035,absl.flags._exceptions.UnparsedFlagAccessError if used flags in tf.TensorSpec,"**System information** 
- Have I written custom code 
Yes: 
- OS Platform and Distribution 
Win10: 
- Mobile device
No: 
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): 
- Python version: 2.1.0

**Standalone code to reproduce the issue** 
code snippets url: https://gitee.com/songhaohao2018/codes/cmunjs6zqbe895y7h0gpa21"
37032,Do you have a plug-in for model encryption?Before generation？,"This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.
"
37029,Hang on out of memory error,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow):  No
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Ubuntu 18.04.3 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): 2.1.0 and nightly, used `tensorflow/tensorflow:2.1.0-gpu-py3` and `tensorflow/tensorflow:nightly-gpu-py3 `
- Python version: - Bazel
version (if compiling from source):
- GCC/Compiler version (if compiling from
source): 
- CUDA/cuDNN version: - GPU model and memory:  P100 and V100
Driver: 440.33.01 
CUDA 10.1 in container

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
TensorFlow hangs when it hits out of memory after it dumps the out of memory message.

**Describe the expected behavior**
TensorFlow should exit on non-zero return code on OOM.

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```python
import tensorflow as tf
from tensorflow.keras import backend as K

import numpy as np


def random_image_generator(batch_size, num_classes, input_shape):
    templates = 2 * num_classes * np.random.random((num_classes,) + input_shape)
    random_data = np.random.normal(loc=0, scale=1., size=input_shape)
    while True:
        y = np.random.randint(0, num_classes, size=(batch_size,))
        x = np.zeros((batch_size,) + input_shape, dtype=np.float32)
        for i in range(batch_size):
            x[i] = templates[y[i]] + random_data
        x_array = np.array(x)
        y_array = tf.keras.utils.to_categorical(y, num_classes)
        yield(x_array, y_array)

def run_model():
    K.set_image_data_format('channels_first')
    image_dim = 5000
    input_shape = (3, image_dim, image_dim)

    num_classes = 15
    batch_size = 1
    model_class = tf.keras.applications.ResNet50
    model = model_class(weights=None, include_top=True, input_shape=input_shape,
                        classes=num_classes)

    model.compile(optimizer='rmsprop', loss='categorical_crossentropy')

    random_generator = random_image_generator(batch_size, num_classes,
                                              input_shape)
    model.fit(random_generator, steps_per_epoch=10,
              epochs=1)

run_model()
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.


This program hangs after dumping the out of memory error on 16GB and 32GB GPUs (P100 and V100 tested). The program use to exit on TensorFlow 1.15. This happens on both the 2.1.0 and nightly containers on Intel x86 systems.

I originally hit this on built-from-source TensorFlow 2.1.0 on ppc64le. On that system, I attached gdb and dumped the stacks. It seems the code is hanging on the three thread stacks noted in the attachment.
[threeThreadStacks.txt](https://github.com/tensorflow/tensorflow/files/4246783/threeThreadStacks.txt)
"
37028,jupyter notebook kernel dies when running a UNet with tensorflow=2.1.0,"**System information** 
- OS - Linux RedHat 8
- conda install tensorflow-gpu - tensorflow version = 2.1.0
- Python version: 3.7.4
- Jupyter Notebook 
- CUDA/cuDNN version: - 10.2
- CPU: AMD Threadripper 3960x
- GPU: 2x RTX Titans
- Memory: 128 GB Corsair 3200MHz

I recently upgraded to tensorflow=2.1.0 from tensorflow=2.0.0 and now my code will not run. Before the first epoch ends I get a message saying 'The kernel appears to have died. It will restart automatically.'. The code is using MirroredStrategy() to distribute the UNet to the GPUs. I don't get this error when I remove MirroredStrategy() and run on a single-gpu. 
Originally I was running my code with tensorflow=2.0.0 using jupyter notebook and it would worked fine except that when I would try to load my model and make a prediction I get an error at `model.predict()` saying `AttributeError: 'Model' object has no attribute 'loss'`. I called `model.summary()` after loading the model and it showed the model was empty. So I upgraded to tensorflow=2.1.0 and called `model.summary()` this time it showed a readout. However I still get the same error `AttributeError: 'Model' object has no attribute 'loss'`
Is there currently an incompatibility with MirroredStrategy() and tensorflow=2.1.0?

```
def get_model(optimizer, loss_metric, metrics, lr=1e-4):
    with tf.device('/job:localhost/replica:0/task:0/device:GPU:0'):
        inputs = Input((sample_width, sample_height, sample_depth, 1))
        conv1 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(inputs)
        conv1 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(conv1)
        pool1 = MaxPooling3D(pool_size=(2, 2, 2))(conv1)
        drop1 = Dropout(0.5)(pool1)
        conv2 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(drop1)
        conv2 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(conv2)
        pool2 = MaxPooling3D(pool_size=(2, 2, 2))(conv2)
        drop2 = Dropout(0.5)(pool2)
        conv3 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(drop2)
        conv3 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(conv3)
        pool3 = MaxPooling3D(pool_size=(2, 2, 2))(conv3)
        drop3 = Dropout(0.3)(pool3)
        conv4 = Conv3D(256, (3, 3, 3), activation='relu', padding='same')(drop3)
        conv4 = Conv3D(256, (3, 3, 3), activation='relu', padding='same')(conv4)
        pool4 = MaxPooling3D(pool_size=(2, 2, 2))(conv4)
        drop4 = Dropout(0.3)(pool4)
        conv5 = Conv3D(512, (3, 3, 3), activation='relu', padding='same')(drop4)
        conv5 = Conv3D(512, (3, 3, 3), activation='relu', padding='same')(conv5)
    with tf.device('/job:localhost/replica:0/task:0/device:GPU:1'): 
        up6 = concatenate([Conv3DTranspose(256, (2, 2, 2), strides=(2, 2, 2), padding='same')(conv5), conv4], axis=4)
        conv6 = Conv3D(256, (3, 3, 3), activation='relu', padding='same')(up6)
        conv6 = Conv3D(256, (3, 3, 3), activation='relu', padding='same')(conv6)
        up7 = concatenate([Conv3DTranspose(128, (2, 2, 2), strides=(2, 2, 2), padding='same')(conv6), conv3], axis=4)
        conv7 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(up7)
        conv7 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(conv7)
        up8 = concatenate([Conv3DTranspose(64, (2, 2, 2), strides=(2, 2, 2), padding='same')(conv7), conv2], axis=4)
        conv8 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(up8)
        conv8 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(conv8)
        up9 = concatenate([Conv3DTranspose(32, (2, 2, 2), strides=(2, 2, 2), padding='same')(conv8), conv1], axis=4)
        conv9 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(up9)
        conv9 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(conv9)
        conv10 = Conv3D(1, (1, 1, 1), activation='sigmoid')(conv9)
        model = Model(inputs=[inputs], outputs=[conv10])
        model.compile(optimizer=optimizer(lr=lr), loss=loss_metric, metrics=metrics)
        return model

smooth = 1.
def dice_coef(y_true, y_pred):
    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)
    intersection = K.sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)
def dice_coef_loss(y_true, y_pred):
    return -dice_coef(y_true, y_pred)

mirrored_strategy = tf.distribute.MirroredStrategy()
with mirrored_strategy.scope():
    model = get_model(optimizer=Adam, loss_metric=dice_coef_loss, metrics=[dice_coef], lr=1e-4)
observe_var = 'dice_coef'
strategy = 'max' # greater dice_coef is better
model_checkpoint = ModelCheckpoint('{epoch:04}model', monitor=observe_var, save_best_only=True)
model.fit(train_x, train_y, batch_size = 2, epochs= 1000, verbose=1, shuffle=True, validation_split=.2, callbacks=[model_checkpoint])
model.save( 'finalmodel')
```
model.summary():
```
Model: ""model""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         multiple                  0         
_________________________________________________________________
conv3d (Conv3D)              multiple                  896       
_________________________________________________________________
conv3d_1 (Conv3D)            multiple                  27680     
_________________________________________________________________
max_pooling3d (MaxPooling3D) multiple                  0         
_________________________________________________________________
dropout (Dropout)            multiple                  0         
_________________________________________________________________
conv3d_2 (Conv3D)            multiple                  55360     
_________________________________________________________________
conv3d_3 (Conv3D)            multiple                  110656    
_________________________________________________________________
max_pooling3d_1 (MaxPooling3 multiple                  0         
_________________________________________________________________
dropout_1 (Dropout)          multiple                  0         
_________________________________________________________________
conv3d_4 (Conv3D)            multiple                  221312    
_________________________________________________________________
conv3d_5 (Conv3D)            multiple                  442496    
_________________________________________________________________
max_pooling3d_2 (MaxPooling3 multiple                  0         
_________________________________________________________________
dropout_2 (Dropout)          multiple                  0         
_________________________________________________________________
conv3d_6 (Conv3D)            multiple                  884992    
_________________________________________________________________
conv3d_7 (Conv3D)            multiple                  1769728   
_________________________________________________________________
max_pooling3d_3 (MaxPooling3 multiple                  0         
_________________________________________________________________
dropout_3 (Dropout)          multiple                  0         
_________________________________________________________________
conv3d_8 (Conv3D)            multiple                  3539456   
_________________________________________________________________
conv3d_9 (Conv3D)            multiple                  7078400   
_________________________________________________________________
conv3d_transpose (Conv3DTran multiple                  1048832   
_________________________________________________________________
concatenate (Concatenate)    multiple                  0         
_________________________________________________________________
conv3d_10 (Conv3D)           multiple                  3539200   
_________________________________________________________________
conv3d_11 (Conv3D)           multiple                  1769728   
_________________________________________________________________
conv3d_transpose_1 (Conv3DTr multiple                  262272    
_________________________________________________________________
concatenate_1 (Concatenate)  multiple                  0         
_________________________________________________________________
conv3d_12 (Conv3D)           multiple                  884864    
_________________________________________________________________
conv3d_13 (Conv3D)           multiple                  442496    
_________________________________________________________________
conv3d_transpose_2 (Conv3DTr multiple                  65600     
_________________________________________________________________
concatenate_2 (Concatenate)  multiple                  0         
_________________________________________________________________
conv3d_14 (Conv3D)           multiple                  221248    
_________________________________________________________________
conv3d_15 (Conv3D)           multiple                  110656    
_________________________________________________________________
conv3d_transpose_3 (Conv3DTr multiple                  16416     
_________________________________________________________________
concatenate_3 (Concatenate)  multiple                  0         
_________________________________________________________________
conv3d_16 (Conv3D)           multiple                  55328     
_________________________________________________________________
conv3d_17 (Conv3D)           multiple                  27680     
_________________________________________________________________
conv3d_18 (Conv3D)           multiple                  33        
=================================================================
Total params: 22,575,329
Trainable params: 22,575,329
Non-trainable params: 0
```
Prediction Code:
```
norm_images='imagedata\'
model = load_model('finalmodel',compile = False)
print(model.summary())
prediction = model.predict(norm_images, verbose = 1)
```
Attribute Error:
```
AttributeError                            Traceback (most recent call last)
<ipython-input-2-06140bdcec2b> in <module>
     75 
     76 print('Predicting the labels')
---> 77 prediction = model.predict(norm_images, verbose = 1)
     78 # prediction = tf.keras.Model.predict(norm_images)
     79 

~\.conda\envs\gputest\lib\site-packages\tensorflow_core\python\keras\engine\training.py in predict(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)
   1011         max_queue_size=max_queue_size,
   1012         workers=workers,
-> 1013         use_multiprocessing=use_multiprocessing)
   1014 
   1015   def reset_metrics(self):

~\.conda\envs\gputest\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py in predict(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)
    496         model, ModeKeys.PREDICT, x=x, batch_size=batch_size, verbose=verbose,
    497         steps=steps, callbacks=callbacks, max_queue_size=max_queue_size,
--> 498         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)
    499 
    500 

~\.conda\envs\gputest\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py in _model_iteration(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)
    424           max_queue_size=max_queue_size,
    425           workers=workers,
--> 426           use_multiprocessing=use_multiprocessing)
    427       total_samples = _get_total_number_of_samples(adapter)
    428       use_sample = total_samples is not None

~\.conda\envs\gputest\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py in _process_inputs(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)
    644     standardize_function = None
    645     x, y, sample_weights = standardize(
--> 646         x, y, sample_weight=sample_weights)
    647   elif adapter_cls is data_adapter.ListsOfScalarsDataAdapter:
    648     standardize_function = standardize

~\.conda\envs\gputest\lib\site-packages\tensorflow_core\python\keras\engine\training.py in _standardize_user_data(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)
   2358     is_compile_called = False
   2359     if not self._is_compiled and self.optimizer:
-> 2360       self._compile_from_inputs(all_inputs, y_input, x, y)
   2361       is_compile_called = True
   2362 

~\.conda\envs\gputest\lib\site-packages\tensorflow_core\python\keras\engine\training.py in _compile_from_inputs(self, all_inputs, target, orig_inputs, orig_target)
   2609     self.compile(
   2610         optimizer=self.optimizer,
-> 2611         loss=self.loss,
   2612         metrics=self._compile_metrics,
   2613         weighted_metrics=self._compile_weighted_metrics,
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
```
"
37027,tf-nightly not updated?,"Just curious, tf-nightly is PyPI is not updated since Feb. 19. What's going on? Can we expect the update any time soon?

Thank you!"
37026,Linearly increasing memory with use_multiprocessing and Keras Sequence,"**System information**
OS: Ubuntu 19.04
CPU: Ryzen 2700X
GPUs: 2 X GTX 1080ti
RAM: 32GB
 
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): 
Yes

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 
Ubuntu 19.04

- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: 
N/A

- TensorFlow installed from (source or binary): 
binary

- TensorFlow version (use command below): 
Current Install: tf-nightly 2.2.0.dev20200218
Occurs On: >= tf 2.0

- Python version: 
3.6.8

- Bazel version (if compiling from source):
N/A

- GCC/Compiler version (if compiling from source): 
N/A

- CUDA/cuDNN version: 
CUDA: 10.1
cuDNN: 7.6.5

- GPU model and memory:
2 X GTX 1080ti

**Describe the current behavior**
When using tf.keras.Sequence base class with 'use_multiprocessing' argument, the memory usage increases linearly every epoch until the program fails with a resource allocation error. I initially noticed this when upgrading to TF2.0. I have identified that the KerasSequenceAdapter has the `should_recreate_iterator` function returning True. If you set this function to return False the memory still increases over epochs but at a drastically slower rate. I plan to continue to debug this behavior and identify the root cause of the problem so that the memory does not increase at every epoch.

Observed Behavior:
- With `should_recreate_iterator` returning True:
    - Workers are not killed after each epoch leaving the total workers at the end of training worker_count**epoch_count
    - Memory usage doubles each epoch at the re-initialization of the KerasSequenceAdapter
- With `should_recreate_iterator` returning False:
    - Workers are reused correctly for each epoch
    - Memory still increases every epoch but at a much lower rate (5-10%) of total memory allocation

**Describe the expected behavior**
X workers should be instantiated to fill a queue of size Y. Once an epoch is complete, those workers should either be re-used for the next epoch or killed and replaced with new workers. The memory should reach its' maximum fill (worker_count * queue_size * batch_size * data_size * 4) and remain at this allocation for the duration of training.

**Standalone code to reproduce the issue** 
I will create a minimal reproducible example in the near future

**Other info / logs**
I have no logs at the moment but am happy to produce them in the near future if it is desired

**Notes**
- I am aware that the expected action for TF.Keras users is to switch to the tf.Dataset API for parallel data processing. I intend to do this at a later date, however, my current data pipeline took a while to get set up and I am not ready to completely re-write it. I am hoping to find a solution for multiprocessing and tf.keras.Sequence in the near term to bridge the gap for people in situations similar to me.
- I chose to open this issue in the TF repo because I am using the TF version of Keras and have no idea if this happens on pure Keras

***My Questions***
- Is there a reason KerasSequenceAdapter's `should_recreate_iterator` function returns True?
"
42785,Portuguese version,"Is it possible to correct some Portuguese notebooks, as they have some typos? I'm a Portuguese native speaker."
37025,Stateful LSTMLite conversion,"**System information**
- Red Hat Enterprise Linux Server release 7.7:
- TensorFlow installed from binary:
- TensorFlow version 1.15:


**Provide the text output from tflite_convert**

```
Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: FULLY_CONNECTED, LOGISTIC, UNIDIRECTIONAL_SEQUENCE_LSTM, UNPACK. Here is a list of operators for which you will need custom implementations: Assign.
Traceback (most recent call last):
  File ""/home/xyz/anaconda3/envs/tf15/bin/toco_from_protos"", line 11, in <module>
    sys.exit(main())
  File ""/home/xyz/anaconda3/envs/tf15/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 89, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""/home/xyz/anaconda3/envs/tf15/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/xyz/anaconda3/envs/tf15/lib/python3.7/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/xyz/anaconda3/envs/tf15/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/home/xyz/anaconda3/envs/tf15/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 52, in execute
    enable_mlir_converter)
Exception: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: FULLY_CONNECTED, LOGISTIC, UNIDIRECTIONAL_SEQUENCE_LSTM, UNPACK. Here is a list of operators for which you will need custom implementations: Assign.
```

**Standalone code to reproduce the issue** 
```python
import os
os.environ['TF_ENABLE_CONTROL_FLOW_V2'] = '1'
import tensorflow as tf
from tensorflow_core.python.keras.models import Model, Sequential
from tensorflow_core.python.keras.layers.core import Dense, Activation, Lambda, Reshape
from tensorflow_core.python.keras.engine.input_layer import Input
from tensorflow_core.python.keras.layers.recurrent import RNN, StackedRNNCells
from tensorflow_core.lite.experimental.examples.lstm.rnn_cell import TFLiteLSTMCell, TfLiteRNNCell
from tensorflow_core.lite.experimental.examples.lstm.rnn import dynamic_rnn
from tensorflow_core.python.ops.rnn_cell_impl import LSTMStateTuple
from tensorflow_core.lite.python.interpreter import Interpreter
from tensorflow_core.python.ops.rnn_cell_impl import MultiRNNCell

def get_state_variables(batch_size, cell):
    # For each layer, get the initial state and make a variable out of it
    # to enable updating its value.
    state_variables = []
    for state_c, state_h in cell.zero_state(batch_size, tf.float32):
        state_variables.append(tf.contrib.rnn.LSTMStateTuple(
            tf.Variable(state_c, trainable=False),
            tf.Variable(state_h, trainable=False)))
    # Return as a tuple, so that it can be fed to dynamic_rnn as an initial state
    return tuple(state_variables)


def get_state_update_op(state_variables, new_states):
    # Add an operation to update the train states with the last state tensors
    update_ops = []
    for state_variable, new_state in zip(state_variables, new_states):
        # Assign the new state to the state variables on this layer
        update_ops.extend([state_variable[0].assign(new_state[0]),
                           state_variable[1].assign(new_state[1])])
    # Return a tuple in order to combine all update_ops into a single operation.
    # The tuple's actual value should not be used.
    return tf.tuple(update_ops)


def buildMultiCell(cells):
    return MultiRNNCell(cells)


def buildRNNLayer(inputs, rnn_cells, initial_state=None):
  """"""Build the lstm layer.

  Args:
    inputs: The input data.
    num_layers: How many LSTM layers do we want.
    num_units: The unmber of hidden units in the LSTM cell.
  """"""
  # Assume the input is sized as [batch, time, input_size], then we're going
  # to transpose to be time-majored.
  transposed_inputs = tf.transpose(inputs, perm=[1, 0, 2])
  outputs, new_state = dynamic_rnn(
      rnn_cells,
      transposed_inputs,
      initial_state=initial_state,
      dtype='float32',
      time_major=True)
  unstacked_outputs = tf.unstack(outputs, axis=0)
  # update_op = get_state_update_op(initial_state, new_state)
  return unstacked_outputs[-1], new_state


def build_rnn_lite(model, state=False):
    tf.reset_default_graph()
    # Construct RNN
    cells = []
    for layer in range(3):
        if model == 'LSTMLite':
            cells.append(TFLiteLSTMCell(192, name='lstm{}'.format(layer)))
        else:
            cells.append(TfLiteRNNCell(192, name='rnn{}'.format(layer)))

    rnn_cells = Lambda(buildMultiCell, name='multicell')(cells)
    states = get_state_variables(1, rnn_cells)
    if state:
        spec_input = Input(shape=(5, 64,), name='rnn_in', batch_size=1)
        x, new_states = Lambda(buildRNNLayer, arguments={'rnn_cells': rnn_cells, 'initial_state': states}, name=model.lower())(spec_input)
        updated_states = Lambda(get_state_update_op, arguments={'new_states': new_states}, name='update_state')(states)
    else:
        spec_input = Input(shape=(5, 64,), name='rnn_in')
        x, new_states = Lambda(buildRNNLayer, arguments={'rnn_cells': rnn_cells}, name=model.lower())(spec_input)
        updated_states = Lambda(get_state_update_op, arguments={'new_states': states}, name='update_state')(states)

    out = Dense(64, activation='sigmoid', name='fin_dense')(x)
    return Model(inputs=spec_input, outputs=[out, updated_states])

model = build_rnn_lite('LSTMLite', True)
```
This now creates a stateful LSTM model which returns the updated states of the LSTM.
```python
###### TF LITE CONVERSION
sess = tf.keras.backend.get_session()
input_tensor = sess.graph.get_tensor_by_name('rnn_in:0')
output_tensor = []
output_tensor.append(sess.graph.get_tensor_by_name('fin_dense/Sigmoid:0'))
all_tensors = [tensor for op in tf.get_default_graph().get_operations() for tensor in op.values()]
# output_tensor = sess.graph.get_tensor_by_name('fin_dense/Sigmoid:0')

# imp_tensor = []
for ten in all_tensors:
    if 'update_state/Assign' in ten.name:
        output_tensor.append(ten)

converter = tf.lite.TFLiteConverter.from_session(sess, [input_tensor], output_tensor)
# Note: It will NOT work without enabling the experimental converter!
# `experimental_new_converter` flag.
converter.experimental_new_converter = True
tflite_seg = converter.convert()
```
The output tensor list throws an error, if only the `fin_dense/Sigmoid:0` tensor is used the model does get converted but behaves as a stateless model therefore the `update_state` needs to be included in the output tensor list.
I am trying to create a stateful LSTMLite model, I was able to get the model to behave as a stateful model as described here [https://stackoverflow.com/questions/59962348/how-to-create-a-stateful-tensorflowlite-rnn-model-in-tf1-15](url) but am unable to convert the model to TFLite.
"
37024,"Convolution operations (such as Conv2d) does not detect corner case 'kernel_size = 0', which leads to an unexpected result.","**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): 
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: -
- TensorFlow installed from (source or
binary):Binary
- TensorFlow version (use command below): 1.15.0 -cpu
- Python version: 3.6.9
- Bazel version (if compiling from source):-
- GCC/Compiler version (if compiling from
source): -
- CUDA/cuDNN version: -
- GPU model and memory:-

**Describe the current behavior**
When I use convolution-related operations, Tensorflow doesn't seem to handle the corner case  'kernel_size = 0' well. The problem can be divided into two parts: 

1) When 'padding = same' is set, **SeparableConv2D \ DepthwiseConv2D\Conv2D \ Conv2DTranspose** takes kernel_size = 0 as a normal value to calculate the padding/crop shape, and finally reports an **Negative-shape error** . For example,  `Conv2DTranspos` reports a  `ValueError: crops cannot be negative for 'conv2d_transpose_1/atrous_conv2d_transpose/BatchToSpaceND' (op: 'BatchToSpaceND') with input shapes: [9,10,10,2], [2], [2,2] and with computed input tensors: input[1] = <3 3>, input[2] = <[-2 0][-2 0]>.`  at `tensorflow_core\python\framework\ops.py line 1610`. The negative value is actually created  in `tensorflow_core\python\ops\nn_ops.py`. For example, the negative value which leads to the padding error of `DepthwiseConv2D` is calculated around line 619 of nn_ops.py). See the following snapshot of `nn_ops.py`. 

![pic1](https://user-images.githubusercontent.com/61384431/75172507-573c3400-5768-11ea-9747-dcd52835118a.jpg)


2) When  'padding=valid' is set, the situation is even worse. **`DepthwiseConv2D` and `SeparableConv2D` can build the model and  even predict. But the outputs are the all-zero matrices. `Conv2D` can also build and save the model, but it seems to get stuck in an infinite loop when predicting. It takes a lot of time and eventually gets no result. **Only `Conv2DTranspose` behaves normally and  reports the following error in `tensorflow_core\python\client\session.py line1470`

``` yaml
tensorflow.python.framework.errors_impl.InvalidArgumentError: Conv2DCustomBackpropInput: Size of out_backprop doesn't match computed: actual = 16, computed = 17 spatial_dim: 1 input: 16 filter: 0 output: 16 stride: 1 dilation: 1
	 [[{{node conv2d_transpose_1_1/atrous_conv2d_transpose/Conv2DBackpropInput}}]]
```

From the description above, we conclude that **Tensorflow seems to lack a critical check whether `kernel_size` is  0 when conducting convolution-related operations, which is a dangerous corner case. This illegal parameter should not be brought into the calculation**, but Tensorflow uses it to build a layer and even uses this layer to process the input and get all zero matrices as output. This should be a logical bug.

**Standalone code to reproduce the issue** 

``` python
import os
import numpy as np
import keras.layers as L
import keras.backend as K
import importlib
from keras.engine import Model, Input

## Using TensorFlow as Keras backend.
## Input dtype default is float32

'''kwargs={'filters': 8, 
  'kernel_size': 0,
  'padding': 'same',
  'strides': 2, 
  'dilation_rate': 1,
  'data_format': 'channels_last'}'''# Conv2d/SeparableConv2D

kwargs={'kernel_size': 0,
  'padding': 'same',
  'strides': 2, 
  'dilation_rate': 1,
  'data_format': 'channels_last'}# DepthwiseConv2d
input = (10 * np.random.random((1,32,32,16)))
layer = L.convolutional.DepthwiseConv2D(**kwargs)# you can use Conv2D\SeparableConv2D\Conv2DTranspose instead of DepthwisConv2D
#layer = L.convolutional.SeparableConv2D(**kwargs)
#layer=L.convolutional.Conv2D(**kwargs)
x = Input(batch_shape=input.shape)
y = layer(x)
bk_model = Model(x, y)
model_path = os.path.join('./', 'model.h5')
bk_model.save(model_path, bk_model)
'''from keras.models import load_model
model = load_model(model_path)
output = model.predict(input)'''
print('finish')
```
"
37023,"RNN unrolled, wrong quantization graph","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): source
- TensorFlow version (or github SHA if from source):
version is 2.2.0-dev20200218, git version is v1.12.1-25080-gca585e7

**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

The problem has appeared on much bigger model, but I can demonstrate it on the MNIST example.
```
import numpy as np
import tensorflow as tf

print(""version is {}, git version is {}"".format(tf.version.VERSION, tf.version.GIT_VERSION))


from model import Model

class SimpleModel(Model):
    def __init__(self):
        super().__init__()
        self.model_name = ""mnist""
        self.train_data = None
        self.test_data = None
        self.calib_data = None
        self.num_calib = 1000
        # (data preprocessing) Normalize the input image so that
        # each pixel value is between 0 to 1.
        self.pre_process = lambda x: x / 255.0

        self._load_data()
        self._set_path()

    def _load_data(self):
        # Load MNIST dataset
        mnist = tf.keras.datasets.mnist

        # _data: (images, labels)
        self.train_data, self.test_data = mnist.load_data()
        self.calib_data = self.pre_process(
            self.train_data[0][0 : self.num_calib].astype(np.float32)
        )

    def train(self):
        cell = tf.keras.layers.GRUCell(3)

        model = tf.keras.models.Sequential([
            tf.keras.layers.Input(shape=(28, 28), name='input'),
            #tf.keras.layers.LSTM(32),
            tf.keras.layers.RNN(cell, unroll=True),
            tf.keras.layers.Flatten(),
            tf.keras.layers.Dense(10, activation=tf.nn.softmax, name='output')
        ])
        model.summary()

        train_images = self.pre_process(self.train_data[0])
        train_labels = self.train_data[1]
        test_images = self.pre_process(self.test_data[0])
        test_labels = self.test_data[1]
        # Train the digit classification model
        model.compile(
            optimizer=""adam"",
            loss=""sparse_categorical_crossentropy"",
            metrics=[""accuracy""],
        )
        model.fit(
            train_images,
            train_labels,
            epochs=1,
            validation_data=(test_images, test_labels),
        )
        # dump SavedModel - ANOTHER BUG HERE!
        #model.save(str(self.savedModel_dir))

        return model

    def eval(self, tflite_model_path: str):
        interpreter = tf.lite.Interpreter(model_path=str(tflite_model_path))
        interpreter.allocate_tensors()

        input_index = interpreter.get_input_details()[0][""index""]
        output_index = interpreter.get_output_details()[0][""index""]

        # (data preprocessing) Normalize the input image so that
        # each pixel value is between 0 to 1.
        test_images = self.pre_process(self.test_data[0])
        test_labels = self.test_data[1]
        # Run predictions on every image in the ""test"" dataset.
        prediction_digits = []
        for test_image in test_images:
            # Pre-processing: add batch dimension and convert to float32 to match with
            # the model's input data format.
            test_image = np.expand_dims(test_image, axis=0).astype(np.float32)
            interpreter.set_tensor(input_index, test_image)

            # Run inference.
            interpreter.invoke()

            # Post-processing: remove batch dimension and find the digit with highest
            # probability.
            output = interpreter.tensor(output_index)
            digit = np.argmax(output()[0])
            prediction_digits.append(digit)

        # Compare prediction results with ground truth labels to calculate accuracy.
        accurate_count = 0
        for index, _ in enumerate(prediction_digits):
            if prediction_digits[index] == test_labels[index]:
                accurate_count += 1
        accuracy = accurate_count * 1.0 / len(prediction_digits)

        return accuracy

    def _get_calib_data_func(self):
        def representative_data_gen():
            for input_value in self.calib_data:
                input_value = np.expand_dims(input_value, axis=0).astype(np.float32)
                yield [input_value]

        return representative_data_gen


if __name__ == ""__main__"":
    temp = SimpleModel()
    model = temp.train()

    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    converter.representative_dataset = temp._get_calib_data_func()

    # save INT8 tflite
    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8,
        tf.lite.OpsSet.SELECT_TF_OPS]
    converter.experimental_new_converter = True
    tflite_model_INT8 = converter.convert()
    open(""lstm_unrolled_int8.tflite"", ""wb"").write(tflite_model_INT8)

    print(""INT8 model eval results: {:f}"".format(temp.eval(""lstm_unrolled_int8"")))

```

**The output from the converter invocation**

```
Traceback (most recent call last):
  File ""/home/elezhe01/work/discovery/int16_crosstest/model/SimpleModelLSTM_self.py"", line 132, in <module>
    print(""INT8 model eval results: {:f}"".format(temp.eval(""lstm_unrolled_int8"")))
  File ""/home/elezhe01/work/discovery/int16_crosstest/model/SimpleModelLSTM_self.py"", line 69, in eval
    interpreter.allocate_tensors()
  File ""/home/elezhe01/.local/lib/python3.6/site-packages/tensorflow/lite/python/interpreter.py"", line 242, in allocate_tensors
    return self._interpreter.AllocateTensors()
  File ""/home/elezhe01/.local/lib/python3.6/site-packages/tensorflow/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py"", line 110, in AllocateTensors
    return _tensorflow_wrap_interpreter_wrapper.InterpreterWrapper_AllocateTensors(self)
RuntimeError: tensorflow/lite/kernels/kernel_util.cc:129 std::abs(input_product_scale - bias_scale) <= 1e-6 * std::min(input_product_scale, bias_scale) was not true.Node number 3 (FULLY_CONNECTED) failed to prepare.
```

**Also, please include a link to the saved model or GraphDef**

```
Another bug: The model with unrolled RNN cell can't be saved - see above
```

**Failure details**

The error above means that the scale of bias is not equal to the scale of activations * the scale of weights as it should be. As far as I can see, after unroll operation the bias is shared, but it should be quantized for each layer separately. 
"
37021,There are no documentations related to decode_predictions() and preprocess_input() in any keras.applications,"## URL(s) with the issue:
[https://www.tensorflow.org/api_docs/python/tf/keras/applications?version=nightly](https://www.tensorflow.org/api_docs/python/tf/keras/applications?version=nightly)


## Description of issue (what needs changing):
The doc corresponding to these two functions must be added in each application model doc.

Are you planning to also submit a pull request to fix the issue? 
Yes, Will mention these issue soon in those PRs.
"
37019,Tensorflow 2.1.0 :  TypeError: __new__() got an unexpected keyword argument 'serialized_options',"I am facing an error while importing tensorflow-2.1.0 (CPU) with Python 3.6 in Ubuntu 18.
 protobuf Version: 3.11.3
Tried many solutions provided in the same Tensorflow GitHub issue pages..But none were useful. 
I dont have any NVIDIA, CUDA etc.. (I dont want to install them as i would like to go with CPU)

Following errors appeared.
---------------------------------
[Mon Feb 24 11:44:52.926212 2020] [wsgi:error] [pid 5520:tid 140127778391808] [remote 127.0.0.1:34372] mod_wsgi (pid=5520): Exception occurred processing WSGI script '/var/www/testnig/service.wsgi'.
[Mon Feb 24 11:44:52.927298 2020] [wsgi:error] [pid 5520:tid 140127778391808] [remote 127.0.0.1:34372] Traceback (most recent call last):
[Mon Feb 24 11:44:52.927347 2020] [wsgi:error] [pid 5520:tid 140127778391808] [remote 127.0.0.1:34372]   File ""/var/www/testnig/service.wsgi"", line 9, in <module>
[Mon Feb 24 11:44:52.927352 2020] [wsgi:error] [pid 5520:tid 140127778391808] [remote 127.0.0.1:34372]     from service import app as application
[Mon Feb 24 11:44:52.927358 2020] [wsgi:error] [pid 5520:tid 140127778391808] [remote 127.0.0.1:34372]   File ""/var/www/testnig/service.py"", line 11, in <module>
[Mon Feb 24 11:44:52.927362 2020] [wsgi:error] [pid 5520:tid 140127778391808] [remote 127.0.0.1:34372]     import classify
[Mon Feb 24 11:44:52.927367 2020] [wsgi:error] [pid 5520:tid 140127778391808] [remote 127.0.0.1:34372]   File ""/var/www/testnig/classify.py"", line 3, in <module>
[Mon Feb 24 11:44:52.927370 2020] [wsgi:error] [pid 5520:tid 140127778391808] [remote 127.0.0.1:34372]     import tensorflow as tf
[Mon Feb 24 11:44:52.927376 2020] [wsgi:error] [pid 5520:tid 140127778391808] [remote 127.0.0.1:34372]   File ""/var/www/testnig/venv/lib/python3.6/site-packages/tensorflow/__init__.py"", line 98, in <module>
[Mon Feb 24 11:44:52.927379 2020] [wsgi:error] [pid 5520:tid 140127778391808] [remote 127.0.0.1:34372]     from tensorflow_core import *
[Mon Feb 24 11:44:52.927384 2020] [wsgi:error] [pid 5520:tid 140127778391808] [remote 127.0.0.1:34372]   File ""/var/www/testnig/venv/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 42, in <module>
[Mon Feb 24 11:44:52.927388 2020] [wsgi:error] [pid 5520:tid 140127778391808] [remote 127.0.0.1:34372]     from . _api.v2 import audio
[Mon Feb 24 11:44:52.927393 2020] [wsgi:error] [pid 5520:tid 140127778391808] [remote 127.0.0.1:34372]   File ""/var/www/testnig/venv/lib/python3.6/site-packages/tensorflow_core/_api/v2/audio/__init__.py"", line 10, in <module>
[Mon Feb 24 11:44:52.927397 2020] [wsgi:error] [pid 5520:tid 140127778391808] [remote 127.0.0.1:34372]     from tensorflow.python.ops.gen_audio_ops import decode_wav
[Mon Feb 24 11:44:52.927402 2020] [wsgi:error] [pid 5520:tid 140127778391808] [remote 127.0.0.1:34372]   File ""/var/www/testnig/venv/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_audio_ops.py"", line 11, in <module>
[Mon Feb 24 11:44:52.927406 2020] [wsgi:error] [pid 5520:tid 140127778391808] [remote 127.0.0.1:34372]     from tensorflow.python.eager import context as _context
[Mon Feb 24 11:44:52.927411 2020] [wsgi:error] [pid 5520:tid 140127778391808] [remote 127.0.0.1:34372]   File ""/var/www/testnig/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/context.py"", line 29, in <module>
[Mon Feb 24 11:44:52.927414 2020] [wsgi:error] [pid 5520:tid 140127778391808] [remote 127.0.0.1:34372]     from tensorflow.core.protobuf import config_pb2
[Mon Feb 24 11:44:52.927420 2020] [wsgi:error] [pid 5520:tid 140127778391808] [remote 127.0.0.1:34372]   File ""/var/www/testnig/venv/lib/python3.6/site-packages/tensorflow_core/core/protobuf/config_pb2.py"", line 16, in <module>
[Mon Feb 24 11:44:52.927423 2020] [wsgi:error] [pid 5520:tid 140127778391808] [remote 127.0.0.1:34372]     from tensorflow.core.framework import cost_graph_pb2 as tensorflow_dot_core_dot_framework_dot_cost__graph__pb2
[Mon Feb 24 11:44:52.927436 2020] [wsgi:error] [pid 5520:tid 140127778391808] [remote 127.0.0.1:34372]   File ""/var/www/testnig/venv/lib/python3.6/site-packages/tensorflow_core/core/framework/cost_graph_pb2.py"", line 16, in <module>
[Mon Feb 24 11:44:52.927440 2020] [wsgi:error] [pid 5520:tid 140127778391808] [remote 127.0.0.1:34372]     from tensorflow.core.framework import tensor_shape_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2
[Mon Feb 24 11:44:52.927445 2020] [wsgi:error] [pid 5520:tid 140127778391808] [remote 127.0.0.1:34372]   File ""/var/www/testnig/venv/lib/python3.6/site-packages/tensorflow_core/core/framework/tensor_shape_pb2.py"", line 23, in <module>
[Mon Feb 24 11:44:52.927449 2020] [wsgi:error] [pid 5520:tid 140127778391808] [remote 127.0.0.1:34372]     serialized_pb=_b('\\n,tensorflow/core/framework/tensor_shape.proto\\x12\\ntensorflow\\""z\\n\\x10TensorShapeProto\\x12-\\n\\x03\\x64im\\x18\\x02 \\x03(\\x0b\\x32 .tensorflow.TensorShapeProto.Dim\\x12\\x14\\n\\x0cunknown_rank\\x18\\x03 \\x01(\\x08\\x1a!\\n\\x03\\x44im\\x12\\x0c\\n\\x04size\\x18\\x01 \\x01(\\x03\\x12\\x0c\\n\\x04name\\x18\\x02 \\x01(\\tBq\\n\\x18org.tensorflow.frameworkB\\x11TensorShapeProtosP\\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\\xf8\\x01\\x01\\x62\\x06proto3')
[Mon Feb 24 11:44:52.927464 2020] [wsgi:error] [pid 5520:tid 140127778391808] [remote **127.0.0.1:34372] **TypeError: __new__() got an unexpected keyword argument *emphasized text*'serialized_options'****

Steps to reproduce : (I am using Apache2, Flask & python3 for NSFW detection). However following are the simplest ways to reproduce. 
 1. In Ubuntu 18, install python 3.6 and create a Virtualenv. Activate Virtualenv
 2. pip3 install tensorflow
 3. Clone or Download GIT --> github.com/minto5050/NSFW-detection 
4. python3 classify.py test_image.jpg

Please let me know if you need any other information"
37015,Error with mkl flag,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Pro 18363.657
- TensorFlow installed from (source or binary):  TF from git 2.1
- Python version: 3.8.1
- Installed using virtualenv? pip? conda?: no
- Bazel version (if compiling from source): 0.29
- CUDA/cuDNN version: 10.2/7.6.5
- GPU model and memory: GF 1070 ti
- CPU model: Intel® Core™ i7-9700K
- VS: 2019



**Describe the problem**
All settings as on the site https://www.tensorflow.org/install/source_windows?hl=ru
My command:
bazel build --config=mkl --config=opt --config=cuda --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package

At the end of the build process I have the following error
ERROR: C:/tensorflow/tensorflow/python/keras/api/BUILD:115:1: Executing genrule //tensorflow/python/keras/api:keras_python_api_gen_compat_v1 failed (Exit 1)
Traceback (most recent call last):
  File ""\\?\C:\Users\Build\AppData\Local\Temp\Bazel.runfiles_ykxci5xn\runfiles\org_tensorflow\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""\\?\C:\Users\Build\AppData\Local\Temp\Bazel.runfiles_ykxci5xn\runfiles\org_tensorflow\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""\\?\C:\Users\Build\AppData\Local\Temp\Bazel.runfiles_ykxci5xn\runfiles\org_tensorflow\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Python38\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Python38\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: ═х эрщфхэ єърчрээ√щ ьюфєы№.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""\\?\C:\Users\Build\AppData\Local\Temp\Bazel.runfiles_ykxci5xn\runfiles\org_tensorflow\tensorflow\python\tools\api\generator\create_python_api.py"", line 27, in <module>
    from tensorflow.python.tools.api.generator import doc_srcs
  File ""\\?\C:\Users\Build\AppData\Local\Temp\Bazel.runfiles_ykxci5xn\runfiles\org_tensorflow\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""\\?\C:\Users\Build\AppData\Local\Temp\Bazel.runfiles_ykxci5xn\runfiles\org_tensorflow\tensorflow\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""\\?\C:\Users\Build\AppData\Local\Temp\Bazel.runfiles_ykxci5xn\runfiles\org_tensorflow\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""\\?\C:\Users\Build\AppData\Local\Temp\Bazel.runfiles_ykxci5xn\runfiles\org_tensorflow\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""\\?\C:\Users\Build\AppData\Local\Temp\Bazel.runfiles_ykxci5xn\runfiles\org_tensorflow\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Python38\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Python38\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: ═х эрщфхэ єърчрээ√щ ьюфєы№.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
ERROR: C:/tensorflow/tensorflow/tools/pip_package/BUILD:223:1 Executing genrule //tensorflow/python/keras/api:keras_python_api_gen_compat_v1 failed (Exit 1)
INFO: Elapsed time: 11991.974s, Critical Path: 9750.03s
INFO: 6217 processes: 6217 local.
FAILED: Build did NOT complete successfully

Without the mkl option, the build completes successfully.
what could be the problem?"
37013,TensorFlow tf.data.Dataset API extremely slow for 3D-shaped pipeline,"**System information** 
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.3 LTS
- TensorFlow installed from (source or binary): binary pip
- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de 2.1.0
- Python version: Python 3.7.6
- CUDA/cuDNN version: 7.6.4.38-1
- GPU model and memory: Quadro RTX 6000 22752 MB

**Describe the current behavior**
In the data pipeline given below, the performance is extremely low. The pipeline produces output of the shape `((128, None, 128), (128, None, 5))` and if either dimension 0 (batching) or dimension 1 (windowing) is removed, the performance is much higher. Unfortunately both batching and windowing are required for efficient and meaningful training.

Additionally, the iteration of the Dataset does not work as expected with 3D output. The shape of the output tensor (loop body at the end: `print([x.shape for x in e])`) is not printed at all. When removing either windowing or batching, the shape is printed as expected. From this I suspect this issue could also be a bug.

Timings for comparison (note: number of time steps / dim 1 (`None`) is avg. 312.5 = 40000 / 128):
- 1x Shape `((128, None, 128), (128, None, 5))`:
**546.8976650238037 s**
- 1000x Shape `((128, 128), (128, 5))` (no windowing):
8.29618239402771 s * 312.5 / 1000 = **2.592556998133659375 s**
Speedup: 210x faster
- 1000x Shape `((None, 128), (None, 5))` (no batching):
65.43172574043274 * 128 / 1000 = **8,37526089477539072 s**
Speedup: 65x faster

**Describe the expected behavior**
It is expected for the performance to scale linearly with the amount of data. The shape of the output data should not have a big negative effect on performance.

**Standalone code to reproduce the issue** 
```
import time
import random
import numpy as np
import tensorflow as tf

print(""TensorFlow {}"".format(tf.__version__))

num_features = 128
num_labels = 5
batch_size = 128
win_size = 2048
len_max = 600000

# create some sample .tfrecord files with different length

l1 = len_max - 44260
X1, Y1 = (np.ones((l1, num_features + 2)), np.zeros((l1, num_labels)))
l2 = len_max - 121340
X2, Y2 = (np.ones((l2, num_features + 2)), np.zeros((l2, num_labels)))

def write_tfrecord(X, Y, fn):
    with tf.Graph().as_default():
        ds = tf.data.Dataset.from_tensor_slices((X, Y))

        sstring = ds.map(lambda *x: 
           tf.reshape(tf.py_function(lambda *v:
               tf.train.Example(features=tf.train.Features(feature={
                   ""features"": tf.train.Feature(float_list=tf.train.FloatList(value=v[0].numpy())),
                   ""label"": tf.train.Feature(float_list=tf.train.FloatList(value=v[1].numpy())),
               })).SerializeToString(), x, tf.string
           ), ())
        )

        writer = tf.data.experimental.TFRecordWriter(fn)
        writer_op = writer.write(sstring)

        sess = tf.compat.v1.Session()
        sess.run(tf.compat.v1.global_variables_initializer())
        sess.run(writer_op)
        sess.close()

files_base = [""./temp1.tfrecord"", ""./temp2.tfrecord""]

write_tfrecord(X1, Y1, files_base[0])
write_tfrecord(X2, Y2, files_base[1])

# take 200 random files as dataset

files = random.choices(files_base, k=200)

ds_fs = tf.data.Dataset.list_files(files, shuffle=True, seed=1)
fs_len = 0
for f in ds_fs:
    fs_len += 1
print(""Reading {} tfrecord files..."".format(fs_len))

# create a StaticHashTable holding the length for trimming

ds_f_len_table = tf.lookup.StaticHashTable(tf.lookup.KeyValueTensorInitializer(
        tf.constant(files_base),
        tf.constant([random.randint(30000, 50000), random.randint(30000, 50000)], dtype=tf.int64)
), -1)

# prepare the Dataset

def prep_ds_file(file):
    _ds = tf.data.TFRecordDataset(file)
    _ds = _ds.map(lambda x: tf.io.parse_single_example(x, {
        ""features"": tf.io.FixedLenFeature([num_features + 2], tf.float32),
        ""label"": tf.io.FixedLenFeature([num_labels], tf.float32),
    }), num_parallel_calls=tf.data.experimental.AUTOTUNE)
    print(_ds)

    _ds = _ds.flat_map(lambda v: tf.data.Dataset.from_tensors((v[""features""][2:], v[""label""])))
    print(_ds)

    _trunc = ds_f_len_table.lookup(file)
    _ds = _ds.take(_trunc)
    print(_ds)
    _num_tsteps = _trunc // batch_size

    ####################################################################################################
    # WINDOWING                                                                                        #
    ####################################################################################################
    _ds = _ds.window(size=_num_tsteps, shift=win_size//2, stride=1, drop_remainder=True)               #
    print(_ds)                                                                                         #
    _ds = _ds.flat_map(lambda x, y: tf.data.Dataset.zip((x.batch(_num_tsteps), y.batch(_num_tsteps)))) #
    print(_ds)                                                                                         #
    ####################################################################################################

    ##################################################
    # BATCHING                                       #
    ##################################################
    _ds = _ds.batch(batch_size, drop_remainder=True) #
    print(_ds)                                       #
    ##################################################

    return _ds


def prep_ds(files):
    _ds = files.flat_map(prep_ds_file)
    print(_ds)
    return _ds


ds = prep_ds(ds_fs)

# read/use the Dataset

ts = time.time()
for e in ds.take(1):
    print([x.shape for x in e])
te = time.time()
print(""Duration: {} s"".format(te - ts))
```
Output:
```
TensorFlow 2.1.0
Reading 200 tfrecord files...
<ParallelMapDataset shapes: {features: (130,), label: (5,)}, types: {features: tf.float32, label: tf.float32}>
<FlatMapDataset shapes: ((128,), (5,)), types: (tf.float32, tf.float32)>
<TakeDataset shapes: ((128,), (5,)), types: (tf.float32, tf.float32)>
<WindowDataset shapes: (DatasetSpec(TensorSpec(shape=(128,), dtype=tf.float32, name=None), TensorShape([])), DatasetSpec(TensorSpec(shape=(5,), dtype=tf.float32, name=None), TensorShape([]))), types: (DatasetSpec(TensorSpec(shape=(128,), dtype=tf.float32, name=None), TensorShape([])), DatasetSpec(TensorSpec(shape=(5,), dtype=tf.float32, name=None), TensorShape([])))>
<FlatMapDataset shapes: ((None, 128), (None, 5)), types: (tf.float32, tf.float32)>
<BatchDataset shapes: ((128, None, 128), (128, None, 5)), types: (tf.float32, tf.float32)>
<FlatMapDataset shapes: ((128, None, 128), (128, None, 5)), types: (tf.float32, tf.float32)>
Duration: 546.8976650238037 s
```"
37012,Not able to perform tflite inferences for batch sizes beyond 1 (COCO SSD MobileNet v1),"
**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): 2.1.0 binary

Basically I imported the COCO SSD mobile net model. I want to perform inference for batch sizes more than 1.

This is my code 

```import numpy as np
import tensorflow as tf

# Load TFLite model and allocate tensors.
interpreter = tf.lite.Interpreter(model_path=""detect.tflite"")
interpreter.allocate_tensors()

# Get input and output tensors.
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# Test model on random input data.
input_shape = input_details[0]['shape']
input_shape=[100,300,300,3]

interpreter.resize_tensor_input(input_details[0]['index'],[100,300,300,3])

print(output_details[0])

interpreter.allocate_tensors()

input_data = np.array(np.random.random_sample(input_shape), dtype=np.uint8)
print(""INPUT SHAPE: "",input_data.shape)
interpreter.set_tensor(input_details[0]['index'],input_data)

interpreter.invoke()

# The function `get_tensor()` returns a copy of the tensor data.
# Use `tensor()` in order to get a pointer to the tensor.
output_data = interpreter.get_tensor(output_details[0]['index'])
print(output_data)
``` 

I ended up getting this error

```{'name': 'TFLite_Detection_PostProcess', 'index': 167, 'shape': array([ 1, 10,  4], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0)}
Traceback (most recent call last):
  File ""tflite.py"", line 20, in <module>
    interpreter.allocate_tensors()
  File ""/home/hrishikesh/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/lite/python/interpreter.py"", line 247, in allocate_tensors
    return self._interpreter.AllocateTensors()
  File ""/home/hrishikesh/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py"", line 110, in AllocateTensors
    return _tensorflow_wrap_interpreter_wrapper.InterpreterWrapper_AllocateTensors(self)
RuntimeError: tensorflow/lite/kernels/reshape.cc:66 num_input_elements != num_output_elements (433200 != 4332)Node number 36 (RESHAPE) failed to prepare.```

"
37011,nanopb needs to be updated to pull in a security fix mentioned in GHSA-gcx3-7m76-287p,"Nanopb is vulnerable to a denial of service, caused by a out of memory condition. By persuading a victim to open a specially crafted file, a remote attacker could exploit this vulnerability to cause the application to crash. Security Advisory link is https://github.com/nanopb/nanopb/security/advisories/GHSA-gcx3-7m76-287p.

Tensorflow has been using nanopb with commit hash ""f8ac463766281625ad710900479130c7fcb4d63b"" which is quite old. nanopb 0.3.6 is nearest release to this commit hash which is affected. 
This bug is raised to address this issue which can be solved by two ways -
1. If TF is tightly dependent on the existing commit of nanopb, we need a patch it with the patch created for 0.3 series mentioned in the advisory. 
2. Update nanopb to the higher version which has the fix.
"
37010,TopK result always sort when k==num_cols,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): No
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): CentOS Linux release 7.5.1804
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: No
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): 2.1.0 using pip install 
- Python version: - Bazel
version (if compiling from source):NA
- GCC/Compiler version (if compiling from
source): NA
- CUDA/cuDNN version: - GPU model and memory:NA

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

top_k op always sort when k == input size

**Describe the expected behavior**
No sort when sorted=False
**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```python
import tensorflow as tf

a = tf.constant([1, 2, 3, 4], dtype=tf.float32)
b = tf.math.top_k(a, k=4, sorted=False)
c = tf.math.top_k(a, k=4, sorted=True)

print(b)
print(c)
```
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
```python
TopKV2(values=<tf.Tensor: shape=(4,), dtype=float32, numpy=array([4., 3., 2., 1.], dtype=float32)>, indices=<tf.Tensor: shape=(4,), dtype=int32, numpy=array([3, 2, 1, 0], dtype=int32)>)
TopKV2(values=<tf.Tensor: shape=(4,), dtype=float32, numpy=array([4., 3., 2., 1.], dtype=float32)>, indices=<tf.Tensor: shape=(4,), dtype=int32, numpy=array([3, 2, 1, 0], dtype=int32)>)
```
The result show b and c are same with the result has been sorted."
37009, Here is a list of operators for which you will need custom implementations: RandomUniform.,"**System information**
- OS Platform and Distribution (MacOS 10.15.3):
- TensorFlow installed from (binary):
- TensorFlow version (1.15.2):


**Provide the text output from tflite_convert**

```

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ARG_MAX, BIDIRECTIONAL_SEQUENCE_LSTM, CAST, FULLY_CONNECTED, GATHER, GREATER_EQUAL, MUL, RESHAPE. Here is a list of operators for which you will need custom implementations: RandomUniform.
Traceback (most recent call last):
  File ""/Users/lidayuan/opt/anaconda3/envs/py371/bin/toco_from_protos"", line 8, in <module>
    sys.exit(main())
  File ""/Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 89, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""/Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 52, in execute
    enable_mlir_converter)
Exception: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ARG_MAX, BIDIRECTIONAL_SEQUENCE_LSTM, CAST, FULLY_CONNECTED, GATHER, GREATER_EQUAL, MUL, RESHAPE. Here is a list of operators for which you will need custom implementations: RandomUniform.

```

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

Also, please include a link to a GraphDef or the model if possible.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem.
If including tracebacks, please include the full traceback. Large logs and files
should be attached.

converter = tf.compat.v1.lite.TFLiteConverter.from_saved_model(""../model"", tag_set=[tf.saved_model.tag_constants.SERVING])
# converter.target_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
#                         tf.lite.OpsSet.SELECT_TF_OPS]
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
                                       tf.lite.OpsSet.SELECT_TF_OPS]

tflite_model = converter.convert()
open(""./result/edison_model.tflite"", ""wb"").write(tflite_model)
"
37008,Here is a list of operators for which you will need custom implementations: RandomUniform.,"**System information**
- OS Platform and Distribution (MacOS 10.15.3 (19D76)):
- TensorFlow installed from ( binary):
- TensorFlow version (1.15.2)


**Provide the text output from tflite_convert**

```
Include any logs or source code that would be helpful to diagnose the problem.
If including tracebacks, please include the full traceback. Large logs and files
should be attached.
Some of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ARG_MAX, BIDIRECTIONAL_SEQUENCE_LSTM, CAST, FULLY_CONNECTED, GATHER, GREATER_EQUAL, MUL, RESHAPE. Here is a list of operators for which you will need custom implementations: RandomUniform.
```

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

Also, please include a link to a GraphDef or the model if possible.

**Any other info / logs**

"
37007,"Unable to implement ""Hello_world"" example on esp32","@tensorflow/micro

**System information**
- Host OS Platform and Distribution : Windows 10
- TensorFlow installed from : installed on esp-idf using `pip install tensorflow`
- Tensorflow version (commit SHA if source):
- Target platform : esp32-devKitC-V4

**Describe the problem**
I have followed [this](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/hello_world/README.md#deploy-to-esp32) guide step-by-step so far
I managed to install the esp-idf and also checked that the env. variables are in PATH (following the guide) but unable to proceed further

**Exact sequence of commands/steps when you ran into the problem**
after doing `pip install tensorflow` (on esp-idf cmd prompt), I entered this command:
`make -f tensorflow/lite/micro/tools/make/Makefile TARGET=esp generate_hello_world_esp_project`

and the output is this:
`'make' is not recognized as an internal or external command,
operable program or batch file.`

I also tried this command:
`cmake -f tensorflow/lite/micro/tools/make/Makefile TARGET=esp generate_hello_world_esp_project`

and this was the error:
`CMake Error: The source directory ""C:/Users/kkulk/Desktop/esp-idf/generate_hello_world_esp_project"" does not exist.
Specify --help for usage, or press the help button on the CMake GUI.`

**I am a complete newbie to esp32, tensorflow and github as well, please let me know what the problem seems to be and if I am overlooking something completely obvious or did something wrong**"
37003,RuntimeError: Encountered unresolved custom op: TensorListFromTensor.Node number 892 (TensorListFromTensor) failed to prepare.,"System information

Google Colaboratory   
Tensorflow 2.1.0     

My tf_keras model can be converted to tf.lite successfully as follows.   
`
efficientdet_model= keras.models.load_model('inference_ckpts/ckpts_B1_image-size- 
640/mbconv_head_anchor-extend_1e-6/csv_10_0.7139_0.8459.h5',      
                                            custom_objects=custom_objects,     
                                            compile=False,    
                        )     

export_dir = ""tf_save/ckpts_B1_image-size-640/mbconv_head_anchor-extend_1e-6/""     

tf.saved_model.save(efficientdet_model, export_dir)      

model_tfsave = tf.saved_model.load(export_dir)     

concrete_func = model_tfsave.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]
     
concrete_func.inputs[1].set_shape([None,511500,4])     

converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])     

converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]     

converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,tf.lite.OpsSet.SELECT_TF_OPS]
     
converter.allow_custom_ops=True     

tflite_model = converter.convert()     

open(""inference_tflite/ckpts_B1_image-size-640/mbconv_head_anchor-extend_1e-6/csv_10_0.7139_0.8459.tflite"", ""wb"").write(tflite_model)    

`

However, I encountered a RuntimeError  in inference when running ""interpreter.allocate_tensors()"" as the following.    
`
interpreter = tf.lite.Interpreter(model_path=""inference_tflite/ckpts_B1_image-size-640/mbconv_head_anchor-extend_1e-6/csv_10_0.7139_0.8459.tflite"")     

interpreter.allocate_tensors()    
`  
Error.    
`RuntimeError                              Traceback (most recent call last)
<ipython-input-23-e8f284b41149> in <module>()
----> 1 interpreter.allocate_tensors()

1 frames
/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/interpreter.py in allocate_tensors(self)
    245   def allocate_tensors(self):
    246     self._ensure_safe()
--> 247     return self._interpreter.AllocateTensors()
    248 
    249   def _safe_to_run(self):

/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py in AllocateTensors(self)
    108 
    109     def AllocateTensors(self):
--> 110         return _tensorflow_wrap_interpreter_wrapper.InterpreterWrapper_AllocateTensors(self)
    111 
    112     def Invoke(self):    

RuntimeError: Encountered unresolved custom op: TensorListFromTensor.Node number 892 (TensorListFromTensor) failed to prepare.`    
    
What should I do for this error?"
37002,[Doc] Laplacian for Deep Dream 2.0,"Hi, i will skip the complete description of the issue because it ' s obvious thing. In the original Deep Dream code you managed to do a very complex code of splits and merges, this code tuned for much better the Deep Dream results. I dont see it in the 2.0 version. 
Also, iam aware of Lucid project, the ""laplace pyramid"" present in Lucid does not seems to resemble the old Deep Dream code. 

My question, Is there anyone who tryied to implement this sucessfully for tf 2.0 ? at last something that can talk with the notebook of Deep Dream for TF 2.0 ? 

Thank you."
37000,Proposal: Modify tf.math.reduce_variance so that it is compatible with ragged tensors,"Sorry for filing this under ""bug"", but the ""feature request"" submission option didn't show up for me. Please correct this if possible (I copied the template by hand from the markdown file).

**System information**
- TensorFlow version (you are using): 2.1, but applies to master branch as of opening time
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**

Currently the variance in the mentioned op is computed as E[(X - E[X])^2]:

https://github.com/tensorflow/tensorflow/blob/c71db95e184447c0008dc007a27d692cd5496d0e/tensorflow/python/ops/math_ops.py#L2112-L2114

Because that requires keepdims == True for the first mean reduction, this is not compatible with ragged tensors. An alternative formulation for the variance could however be E[X**2] - E[X]^2

```
 mean_of_square = reduce_mean(gen_math_ops.square(input_tensor), axis=axis, keepdims=keepdims) 
 square_of_mean = gen_math_ops.square(reduce_mean(input_tensor, axis=axis, keepdims=keepdims)) 
 return mean_of_square - square_of_mean
```

**Will this change the current api? How?**
This might have a reduced numerical stability for Var << Mean, but it could be used at least for ragged tensors in the keepdims == False case. Checking if the tensor is ragged and choosing the implementation based on that would guarantee API stability, but potentially increase maintenance burden later on.

**Who will benefit with this feature?**

Users who want to aggregate statistics over variable-length sequences encoded in ragged tensors.

**Any Other info.**



"
36999,recompute_grad computes gradient incorrectly when the same tensor is passed in multiple argument positions,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Linux 5.5.3-arch1-1
- TensorFlow installed from (source or
binary): binary
- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de 2.1.0
- Python version: 3.7.5
- CUDA/cuDNN version: 10.2/7
- GPU model and memory: 1070 Ti, 8GB

**Describe the current behavior**
Passing the same tensor as two arguments to a function decorated with `recompute_grad` leads to incorrect gradient computation.

**Describe the expected behavior**
The gradient should be computed properly. The `tf.custom_gradient` code uses `experimental_ref`s to deduplicate variables, and doing the same for input tensors will resolve this issue.

**Standalone code to reproduce the issue** 
```
import tensorflow as tf

@tf.recompute_grad
def broken_add(a, b):·
    return a + b·

x = tf.ones(3, dtype=tf.float32)
with tf.GradientTape() as g:
    g.watch(x)
    z = tf.reduce_sum(broken_add(x, x)) 
print(g.gradient(z, x).numpy())
```
This outputs `[4. 4. 4.]` instead of the correct value `[2., 2., 2.]`.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
The following is used to deduplicate variables in `tf.custom_gradient`, and adding the same for input tensors should resolve the issue.
https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/custom_gradient.py#L410-L414"
36998,Keras models train correctly with or without tf.function decorator but this is not correct for custom models,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): 
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): 
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): 
- Python version: - Bazel
version (if compiling from source):
- GCC/Compiler version (if compiling from
source): 
- CUDA/cuDNN version: - GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
36996,[Colab][TF2.x] Socket closed - Error received from peer,"I was trying to train an GAN. Here is the code:
(Full code on Colab: https://colab.research.google.com/drive/1TUKZnOEPT8C8mVJ1iK90n32qT2SiJ6Xo)

```python
with strategy.scope():
    # generator_model
    generator_model = tf.keras.models.Sequential([
        tf.keras.layers.Dense(512, activation='relu', input_shape=noise_shape),
        tf.keras.layers.Dropout(0.1),
        tf.keras.layers.Dense(1024, activation='relu'),
        tf.keras.layers.Dense(784, activation='tanh'),
        tf.keras.layers.Reshape(img_shape)
    ])
    generator_model.compile(optimizer=tf.keras.optimizers.Adam(0.0002, 0.5),
                            loss='binary_crossentropy',
                            metrics=['accuracy'])
    generator_model.summary()

    # discriminator_model
    discriminator_model = tf.keras.models.Sequential([
        tf.keras.layers.Flatten(input_shape=img_shape),
        tf.keras.layers.Dense(1024, activation='relu'),
        tf.keras.layers.Dropout(0.1),
        tf.keras.layers.Dense(512, activation='relu'),
        tf.keras.layers.Dense(1, activation='sigmoid'),
    ])
    discriminator_model.compile(optimizer=tf.keras.optimizers.Adam(0.0002, 0.5),
                                loss='binary_crossentropy')
    discriminator_model.summary()

    # combined_model
    z = tf.keras.layers.Input(shape=noise_shape)
    discriminator_model.trainable = False 
    valid = discriminator_model(generator_model(z)) 
    combined_model = tf.keras.models.Model(z, valid) 
    combined_model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(0.0002, 0.5))
    combined_model.summary()

# train
for epoch in range(10000):
    idx = np.random.randint(0, x_train.shape[0], batch_size)
    imgs = x_train[idx]
    noise = np.random.normal(0, 1, (batch_size, 100))
    gen_imgs = generator_model.predict(noise.astype(np.float32))

    # train discriminator_model
    d_loss_real = discriminator_model.fit(imgs.astype(np.float32), np.ones((batch_size, 1)))
    d_loss_fake = discriminator_model.fit(gen_imgs.astype(np.float32), np.zeros((batch_size, 1)))
    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

    # train combined_model
    noise = np.random.normal(0, 1, (batch_size * 2, 100))
    valid_y = np.array([1] * batch_size * 2)  
    g_loss = combined_model.fit(noise.astype(np.float32), valid_y)
```

When I run, it throws out `Socket closed`.

```python
Train on 128 samples
 32/128 [======>.......................] - ETA: 7s
---------------------------------------------------------------------------
UnavailableError                          Traceback (most recent call last)
<ipython-input-1-5ba8c95500e1> in <module>()
     82 
     83     # train discriminator_model
---> 84     d_loss_real = discriminator_model.fit(imgs.astype(np.float32), np.ones((batch_size, 1)))
     85     d_loss_fake = discriminator_model.fit(gen_imgs.astype(np.float32), np.zeros((batch_size, 1)))
     86     d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

10 frames
/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    817         max_queue_size=max_queue_size,
    818         workers=workers,
--> 819         use_multiprocessing=use_multiprocessing)
    820 
    821   def evaluate(self,

/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    340                 mode=ModeKeys.TRAIN,
    341                 training_context=training_context,
--> 342                 total_epochs=epochs)
    343             cbks.make_logs(model, epoch_logs, training_result, ModeKeys.TRAIN)
    344 

/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)
    126         step=step, mode=mode, size=current_batch_size) as batch_logs:
    127       try:
--> 128         batch_outs = execution_function(iterator)
    129       except (StopIteration, errors.OutOfRangeError):
    130         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?

/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2_utils.py in execution_function(input_fn)
     96     # `numpy` translates Tensors to values in Eager mode.
     97     return nest.map_structure(_non_none_constant_value,
---> 98                               distributed_function(input_fn))
     99 
    100   return execution_function

/tensorflow-2.1.0/python3.6/tensorflow_core/python/util/nest.py in map_structure(func, *structure, **kwargs)
    566 
    567   return pack_sequence_as(
--> 568       structure[0], [func(*x) for x in entries],
    569       expand_composites=expand_composites)
    570 

/tensorflow-2.1.0/python3.6/tensorflow_core/python/util/nest.py in <listcomp>(.0)
    566 
    567   return pack_sequence_as(
--> 568       structure[0], [func(*x) for x in entries],
    569       expand_composites=expand_composites)
    570 

/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2_utils.py in _non_none_constant_value(v)
    128 
    129 def _non_none_constant_value(v):
--> 130   constant_value = tensor_util.constant_value(v)
    131   return constant_value if constant_value is not None else v
    132 

/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/tensor_util.py in constant_value(tensor, partial)
    820   """"""
    821   if isinstance(tensor, ops.EagerTensor):
--> 822     return tensor.numpy()
    823   if not is_tensor(tensor):
    824     return tensor

/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/ops.py in numpy(self)
    940     """"""
    941     # TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.
--> 942     maybe_arr = self._numpy()  # pylint: disable=protected-access
    943     return maybe_arr.copy() if isinstance(maybe_arr, np.ndarray) else maybe_arr
    944 

/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/ops.py in _numpy(self)
    908       return self._numpy_internal()
    909     except core._NotOkStatusException as e:
--> 910       six.raise_from(core._status_to_exception(e.code, e.message), None)
    911 
    912   @property

/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)

UnavailableError: Socket closed
Additional GRPC error information:
{""created"":""@1582482234.677879877"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Socket closed"",""grpc_status"":14}
```
"
36991,How to get integer batch size in Keras model.fit(),"I'm trying to use `model.fit()` on a `Sequential` model consisting of custom layers subclassing `tf.keras.layers.Layer`. Using `GradientTape` where I feed every batch in explicitly works fine (including in graph mode with `tf.function`). Trying to use the high-level Keras API for training,

```py
model.compile(loss=loss_fn, optimizer=""adam"")
model.fit(X_train, y_train)
```

I get a bunch of `ValueError: None values not supported.` for things like

```py
def call(self, x):
    ...
    epsilon = tf.random.normal(x.shape)  # reparametrization trick
    ...
```

since `x.shape[0]` is `None`. So the question is, how do I get an integer batch size when using `model.fit()`? I tried

```py
model.compile(loss=loss_fn, optimizer=""adam"")
model.fit(
    X_train, y_train, batch_size=64, steps_per_epoch=X_train.shape[0] // 64,
)
```

but that makes no difference. `x.shape[0]` remains `None` during graph creation."
36988,Rising a memory on every step,"Hello. I used a MobileNet for Object detection and my model is training by following code:

```py
@tf.function
def train(model, dataset, epochs=50, lr=1e-5, checkpoints=None):
  optimizer = tf.keras.optimizers.Adam(lr=lr)
  for i in range(epochs):
    dataset = dataset.shuffle(1000)
    # training
    for images, boxes, labels in tqdm(dataset, desc='Epoch {} of {}'.format(i + 1, epochs)):
      with tf.GradientTape() as tape:
        localization, classification = model(images, training=True)
        smooth = losses.smooth_l1(boxes, localization)
        focal  = losses.focal(labels, classification)
        loss = smooth * 0.6 + focal * 0.4
      gradients = tape.gradient(loss, model.trainable_variables)
      optimizer.apply_gradients(zip(gradients, model.trainable_variables))
    if checkpoints:
      model.save_weights(checkpoints)
```
But my PC memory is rising on every step.
Can you help me to fix it?"
36987,multi head multi loss model with GradientTape,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/api_docs/python/tf/GradientTape

## Description of issue (what needs changing):
I have model with two head and two loss. I want to optimize my model in the way that each loss propagate separately in it's head branch. 

"
36986,Could not import tensorflow after installing it through anaconda navigator.,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version: 2.1.0
- Python version: 3.7.4
- Installed using virtualenv? pip? conda?: installed using Environments in Anaconda Navigator
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**
ERROR:root:Internal Python error in the inspect module.
Below is the traceback from this internal error.

ERROR:root:Internal Python error in the inspect module.
Below is the traceback from this internal error.



Traceback (most recent call last):
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\abida\Anaconda3\folder\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\abida\Anaconda3\folder\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\abida\Anaconda3\folder\lib\site-packages\IPython\core\interactiveshell.py"", line 3326, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-1-64156d691fe5>"", line 1, in <module>
    import tensorflow as tf
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\abida\Anaconda3\folder\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\abida\Anaconda3\folder\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\abida\Anaconda3\folder\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\abida\Anaconda3\folder\lib\site-packages\IPython\core\interactiveshell.py"", line 2040, in showtraceback
    stb = value._render_traceback_()
AttributeError: 'ImportError' object has no attribute '_render_traceback_'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\abida\Anaconda3\folder\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\abida\Anaconda3\folder\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\abida\Anaconda3\folder\lib\site-packages\IPython\core\ultratb.py"", line 1101, in get_records
    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)
  File ""C:\Users\abida\Anaconda3\folder\lib\site-packages\IPython\core\ultratb.py"", line 319, in wrapped
    return f(*args, **kwargs)
  File ""C:\Users\abida\Anaconda3\folder\lib\site-packages\IPython\core\ultratb.py"", line 353, in _fixed_getinnerframes
    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))
  File ""C:\Users\abida\Anaconda3\folder\lib\inspect.py"", line 1502, in getinnerframes
    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)
  File ""C:\Users\abida\Anaconda3\folder\lib\inspect.py"", line 1460, in getframeinfo
    filename = getsourcefile(frame) or getfile(frame)
  File ""C:\Users\abida\Anaconda3\folder\lib\inspect.py"", line 696, in getsourcefile
    if getattr(getmodule(object, filename), '__loader__', None) is not None:
  File ""C:\Users\abida\Anaconda3\folder\lib\inspect.py"", line 733, in getmodule
    if ismodule(module) and hasattr(module, '__file__'):
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\abida\Anaconda3\folder\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 1006, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 983, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 953, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
  File ""<frozen importlib._bootstrap>"", line 1006, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 983, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 967, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 677, in _load_unlocked
  File ""<frozen importlib._bootstrap_external>"", line 728, in exec_module
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\__init__.py"", line 42, in <module>
    from . _api.v2 import audio
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\_api\v2\audio\__init__.py"", line 10, in <module>
    from tensorflow.python.ops.gen_audio_ops import decode_wav
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\ops\gen_audio_ops.py"", line 9, in <module>
    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\abida\Anaconda3\folder\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\abida\Anaconda3\folder\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\abida\Anaconda3\folder\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\abida\Anaconda3\folder\lib\site-packages\IPython\core\interactiveshell.py"", line 3326, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-1-64156d691fe5>"", line 1, in <module>
    import tensorflow as tf
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\abida\Anaconda3\folder\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\abida\Anaconda3\folder\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\abida\Anaconda3\folder\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\abida\Anaconda3\folder\lib\site-packages\IPython\core\interactiveshell.py"", line 2040, in showtraceback
    stb = value._render_traceback_()
AttributeError: 'ImportError' object has no attribute '_render_traceback_'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\abida\Anaconda3\folder\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\abida\Anaconda3\folder\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
Traceback (most recent call last):
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\abida\Anaconda3\folder\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\abida\Anaconda3\folder\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\abida\Anaconda3\folder\lib\site-packages\IPython\core\interactiveshell.py"", line 3326, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-1-64156d691fe5>"", line 1, in <module>
    import tensorflow as tf
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\abida\Anaconda3\folder\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\abida\Anaconda3\folder\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\abida\Anaconda3\folder\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\abida\Anaconda3\folder\lib\site-packages\IPython\core\interactiveshell.py"", line 2040, in showtraceback
    stb = value._render_traceback_()
AttributeError: 'ImportError' object has no attribute '_render_traceback_'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\abida\Anaconda3\folder\lib\site-packages\IPython\core\interactiveshell.py"", line 3249, in run_ast_nodes
    if (await self.run_code(code, result,  async_=asy)):
  File ""C:\Users\abida\Anaconda3\folder\lib\site-packages\IPython\core\interactiveshell.py"", line 3343, in run_code
    self.showtraceback(running_compiled_code=True)
  File ""C:\Users\abida\Anaconda3\folder\lib\site-packages\IPython\core\interactiveshell.py"", line 2043, in showtraceback
    value, tb, tb_offset=tb_offset)
  File ""C:\Users\abida\Anaconda3\folder\lib\site-packages\IPython\core\ultratb.py"", line 1385, in structured_traceback
    self, etype, value, tb, tb_offset, number_of_lines_of_context)
  File ""C:\Users\abida\Anaconda3\folder\lib\site-packages\IPython\core\ultratb.py"", line 1288, in structured_traceback
    self, etype, value, tb, tb_offset, number_of_lines_of_context
  File ""C:\Users\abida\Anaconda3\folder\lib\site-packages\IPython\core\ultratb.py"", line 1150, in structured_traceback
    formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)
TypeError: can only concatenate str (not ""list"") to str

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\abida\Anaconda3\folder\lib\site-packages\IPython\core\interactiveshell.py"", line 2040, in showtraceback
    stb = value._render_traceback_()
AttributeError: 'TypeError' object has no attribute '_render_traceback_'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\abida\Anaconda3\folder\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\abida\Anaconda3\folder\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\abida\Anaconda3\folder\lib\site-packages\IPython\core\ultratb.py"", line 1101, in get_records
    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)
  File ""C:\Users\abida\Anaconda3\folder\lib\site-packages\IPython\core\ultratb.py"", line 319, in wrapped
    return f(*args, **kwargs)
  File ""C:\Users\abida\Anaconda3\folder\lib\site-packages\IPython\core\ultratb.py"", line 353, in _fixed_getinnerframes
    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))
  File ""C:\Users\abida\Anaconda3\folder\lib\inspect.py"", line 1502, in getinnerframes
    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)
  File ""C:\Users\abida\Anaconda3\folder\lib\inspect.py"", line 1460, in getframeinfo
    filename = getsourcefile(frame) or getfile(frame)
  File ""C:\Users\abida\Anaconda3\folder\lib\inspect.py"", line 696, in getsourcefile
    if getattr(getmodule(object, filename), '__loader__', None) is not None:
  File ""C:\Users\abida\Anaconda3\folder\lib\inspect.py"", line 733, in getmodule
    if ismodule(module) and hasattr(module, '__file__'):
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\abida\Anaconda3\folder\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 1006, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 983, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 953, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
  File ""<frozen importlib._bootstrap>"", line 1006, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 983, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 967, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 677, in _load_unlocked
  File ""<frozen importlib._bootstrap_external>"", line 728, in exec_module
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\__init__.py"", line 42, in <module>
    from . _api.v2 import audio
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\_api\v2\audio\__init__.py"", line 10, in <module>
    from tensorflow.python.ops.gen_audio_ops import decode_wav
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\ops\gen_audio_ops.py"", line 9, in <module>
    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\abida\Anaconda3\folder\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\abida\Anaconda3\folder\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\abida\Anaconda3\folder\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\abida\Anaconda3\folder\lib\site-packages\IPython\core\interactiveshell.py"", line 3326, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-1-64156d691fe5>"", line 1, in <module>
    import tensorflow as tf
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\abida\Anaconda3\folder\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\abida\Anaconda3\folder\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\abida\Anaconda3\folder\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\abida\Anaconda3\folder\lib\site-packages\IPython\core\interactiveshell.py"", line 2040, in showtraceback
    stb = value._render_traceback_()
AttributeError: 'ImportError' object has no attribute '_render_traceback_'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\abida\Anaconda3\folder\lib\site-packages\IPython\core\interactiveshell.py"", line 3249, in run_ast_nodes
    if (await self.run_code(code, result,  async_=asy)):
  File ""C:\Users\abida\Anaconda3\folder\lib\site-packages\IPython\core\interactiveshell.py"", line 3343, in run_code
    self.showtraceback(running_compiled_code=True)
  File ""C:\Users\abida\Anaconda3\folder\lib\site-packages\IPython\core\interactiveshell.py"", line 2043, in showtraceback
    value, tb, tb_offset=tb_offset)
  File ""C:\Users\abida\Anaconda3\folder\lib\site-packages\IPython\core\ultratb.py"", line 1385, in structured_traceback
    self, etype, value, tb, tb_offset, number_of_lines_of_context)
  File ""C:\Users\abida\Anaconda3\folder\lib\site-packages\IPython\core\ultratb.py"", line 1288, in structured_traceback
    self, etype, value, tb, tb_offset, number_of_lines_of_context
  File ""C:\Users\abida\Anaconda3\folder\lib\site-packages\IPython\core\ultratb.py"", line 1150, in structured_traceback
    formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)
TypeError: can only concatenate str (not ""list"") to str

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\abida\Anaconda3\folder\lib\site-packages\IPython\core\interactiveshell.py"", line 2040, in showtraceback
    stb = value._render_traceback_()
AttributeError: 'TypeError' object has no attribute '_render_traceback_'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\abida\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\abida\Anaconda3\folder\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\abida\Anaconda3\folder\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.


---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
~\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow.py in <module>
     57 
---> 58   from tensorflow.python.pywrap_tensorflow_internal import *
     59   from tensorflow.python.pywrap_tensorflow_internal import __version__

~\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py in <module>
     27             return _mod
---> 28     _pywrap_tensorflow_internal = swig_import_helper()
     29     del swig_import_helper

~\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py in swig_import_helper()
     23             try:
---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
     25             finally:

~\Anaconda3\folder\lib\imp.py in load_module(name, file, filename, details)
    241         else:
--> 242             return load_dynamic(name, filename, file)
    243     elif type_ == PKG_DIRECTORY:

~\Anaconda3\folder\lib\imp.py in load_dynamic(name, path, file)
    341             name=name, loader=loader, origin=path)
--> 342         return _load(spec)
    343 

ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:


During handling of the above exception, another exception occurred:

AttributeError                            Traceback (most recent call last)
~\Anaconda3\folder\lib\site-packages\IPython\core\interactiveshell.py in showtraceback(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)
   2039                         # in the engines. This should return a list of strings.
-> 2040                         stb = value._render_traceback_()
   2041                     except Exception:

AttributeError: 'ImportError' object has no attribute '_render_traceback_'

During handling of the above exception, another exception occurred:

TypeError                                 Traceback (most recent call last)
~\Anaconda3\folder\lib\site-packages\IPython\core\interactiveshell.py in run_code(self, code_obj, result, async_)
   3341             if result is not None:
   3342                 result.error_in_exec = sys.exc_info()[1]
-> 3343             self.showtraceback(running_compiled_code=True)
   3344         else:
   3345             outflag = False

~\Anaconda3\folder\lib\site-packages\IPython\core\interactiveshell.py in showtraceback(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)
   2041                     except Exception:
   2042                         stb = self.InteractiveTB.structured_traceback(etype,
-> 2043                                             value, tb, tb_offset=tb_offset)
   2044 
   2045                     self._showtraceback(etype, value, stb)

~\Anaconda3\folder\lib\site-packages\IPython\core\ultratb.py in structured_traceback(self, etype, value, tb, tb_offset, number_of_lines_of_context)
   1383         self.tb = tb
   1384         return FormattedTB.structured_traceback(
-> 1385             self, etype, value, tb, tb_offset, number_of_lines_of_context)
   1386 
   1387 

~\Anaconda3\folder\lib\site-packages\IPython\core\ultratb.py in structured_traceback(self, etype, value, tb, tb_offset, number_of_lines_of_context)
   1286             # Verbose modes need a full traceback
   1287             return VerboseTB.structured_traceback(
-> 1288                 self, etype, value, tb, tb_offset, number_of_lines_of_context
   1289             )
   1290         elif mode == 'Minimal':

~\Anaconda3\folder\lib\site-packages\IPython\core\ultratb.py in structured_traceback(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)
   1148         exception = self.get_parts_of_chained_exception(evalue)
   1149         if exception:
-> 1150             formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)
   1151             etype, evalue, etb = exception
   1152         else:

TypeError: can only concatenate str (not ""list"") to str




**Provide the exact sequence of commands / steps that you executed before running into the problem**

import tensorflow as tf

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
36985,Shape issues in keras.metrics.sparse_top_k_categorical_accuracy with multiple dimensions,"**System information** 
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v1.12.1-24394-gc24d2f9 2.2.0-dev20200210
- Python version: 3.5.2
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
**Describe the expected behavior**
**Standalone code to reproduce the issue** 
When there are multiple dimensions (e.g., for image data), the behavior of tf.metrics.sparse_top_k_categorical_accuracy and tf.metrics.top_k_categorical_accuracy differ from both each other and that of their categorical_crossentropy equivalents.

In particular, as of https://github.com/tensorflow/tensorflow/commit/ddca4b92b4eb4e187716b03f443362c904bdad7e (which was used to fix https://github.com/tensorflow/tensorflow/issues/33825), tf.metrics.sparse_top_k_categorical_accuracy flattens the extra dims (resulting in a different output shape compared to sparse_categorical_crossentropy), while tf.metrics.top_k_categorical_accuracy raises an error saying there must be only 2 dimensions. The docs don't say much about what should be expected.

The flattened shape also causes an error when passing weights to tf.keras.metrics.SparseTopKCategoricalAccuracy.

See minimal repro code here:
https://colab.research.google.com/drive/1DR7SSoj8cpo0Y35swz-dyOX4DCazidPe"
36984,TensorFlow 2.x prevents me using two tf.data.Dataset in multiprocess,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): 
👉
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): 
👉Macos Catalina version 10.15.3 
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
👉No
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): 
👉From binary, 2.0.0 and 2.1.0
- Python version: - Bazel
version (if compiling from source):
👉Python 3.7.4
- GCC/Compiler version (if compiling from
source): 
👉No
- CUDA/cuDNN version: - GPU model and memory:
👉No
You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
👉 In my multiprocess program, I create a Queue for process_communication, but when I use two different tf.data.Dataset in different Process my program gets stuck.

**Describe the expected behavior**
👉 When I replace one of these tf.data.Dataset to a list, everything work ideally.  And this piece of code transfer from TF1.x which also works well.

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```py
import os
from multiprocessing import Process, Queue

import tensorflow as tf


class Trainable(object):
    def __init__(self):
        self.queue = Queue()
        self.valid_handle = tf.data.Dataset.from_tensor_slices([1, 2, 3, 4, 5])  # [1, 2, 3, 4, 5]
        self.train_handle = tf.data.Dataset.from_tensor_slices([1, 2, 3, 4, 5, 6, 7, 8, 9])

    def eval(self, q):
        print('Process to write: %s' % os.getpid())
        tmp = -1
        for parsed_record in self.valid_handle:
            print(parsed_record)
            tmp = parsed_record
        self.queue.put((q + 1, tmp))

    def train(self):
        process = None
        print('Process to read: %s' % os.getpid())
        for context in self.train_handle:
            if process:
                valid_detail = self.queue.get()
                process = None
                print(valid_detail)
                if 8 in valid_detail:
                    print('Early stopping')
                    break

            process = Process(target=self.eval, args=(context.numpy(),))
            process.start()
            if not self.queue.empty():
                valid_detail = self.queue.get()
                process = None
                print(valid_detail)


if __name__ == '__main__':
    model = Trainable()
    model.train()


```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
Here is my question posted on StackOverflow : https://stackoverflow.com/questions/60354870/tensorflow-2-x-prevent-me-using-two-tf-data-dataset-in-multiprocess-why"
36981,`recompute_grad` does not save memory and is incompatible with graph mode,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow):  No.
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04):  Linux Ubuntu 16.04 and Windows 10.
- TensorFlow installed from (source or
binary): from binary (pip install)
- TensorFlow version (use command below): 2.1.0
- Python version: 3.7
- CUDA/cuDNN version: CUDA10.2+CuDNN7.6.5 (Windows), CUDA10.1+CuDNN7.6.5+TensorRT 6 (Ubuntu), 
- GPU model and memory: GeForce GTX 1060 with Max-Q Design, 6GB (Windows) and GeForce GTX 1080 Ti, 12GB (Ubuntu)

**Describe the current behavior**
Using `tf.recompute_grad` to wrap keras layers does not take any effect. I build a DenseNet model and wrap each ""-bn-relu-conv1x1-bn-relu-conv"" block by the function. But I have not seen any GPU memory reduction on both the Windows and Ubuntu platforms. When eager mode is disabled, it throws ""ValueError: Variable <tf.Variable 'batch_normalization/gamma:0' shape=(32,) dtype=float32> has `None` for gradient."", indicating that using `compute_grad` blocks the gradient backpropagation in graph mode.

**Describe the expected behavior**
The function seems to originate from OpenAI's gradient checkpointing (https://github.com/cybertronai/gradient-checkpointing) and is expected to save GPU memory during training. Recently, a tensorflow implementation of efficient DenseNets (https://github.com/joeyearsley/efficient_densenet_tensorflow) also uses this function to perform the gradient checkpointing (they used `tf.contrib.layers.recompute_grad` in tf1 graph mode, not exactly the same environment as our case.)

Please fix the incompatibility bug so that the function can still work with the graph mode. If the function is designed to perform gradient checkpointing, please verify its effectiveness. If it is not supposed to implement efficient DenseNets, please provide the correct and effective implementation.


**Standalone code to reproduce the issue** 
```PYTHON
import os

import tensorflow as tf
import tensorflow_datasets as tfds
from absl import app, flags
from absl.flags import FLAGS
from tensorflow import keras

flags.DEFINE_list(""gpu"",
                  default=None,
                  help=""index of GPU"")
flags.DEFINE_bool(""recompute_grad"",
                  default=False,
                  help=""whether to recompute gradients to save GPU RAM"")
flags.DEFINE_integer(""batch_size"",
                     default=1024,
                     help=""batch size"")
flags.DEFINE_bool(""graph"",
                  default=False,
                  help=""use graph mode instead of eager mode"")


def dense_lenet(inputs):
    net = keras.layers.Conv2D(32, 5, strides=2, use_bias=False, padding=""SAME"")(inputs)

    for _ in range(5):
        def _block(x):
            x = keras.layers.BatchNormalization()(x)
            x = keras.layers.ReLU()(x)
            x = keras.layers.Conv2D(16, 1, use_bias=False, padding=""SAME"")(x)
            x = keras.layers.BatchNormalization()(x)
            x = keras.layers.ReLU()(x)
            x = keras.layers.Conv2D(4, 3, use_bias=False, padding=""SAME"")(x)
            return x
        if FLAGS.recompute_grad:
            _block = tf.recompute_grad(_block)
        net = keras.layers.concatenate([net, _block(net)])

    net = keras.layers.BatchNormalization()(net)
    net = keras.layers.ReLU()(net)
    net = keras.layers.Conv2D(64, 1, use_bias=False, padding=""SAME"")(net)
    net = keras.layers.AveragePooling2D()(net)

    for _ in range(10):
        def _block(x):
            x = keras.layers.BatchNormalization()(x)
            x = keras.layers.ReLU()(x)
            x = keras.layers.Conv2D(32, 1, use_bias=False, padding=""SAME"")(x)
            x = keras.layers.BatchNormalization()(x)
            x = keras.layers.ReLU()(x)
            x = keras.layers.Conv2D(8, 3, use_bias=False, padding=""SAME"")(x)
            return x
        if FLAGS.recompute_grad:
            _block = tf.recompute_grad(_block)
        net = keras.layers.concatenate([net, _block(net)])

    net = keras.layers.BatchNormalization()(net)
    net = keras.layers.ReLU()(net)
    net = keras.layers.Conv2D(128, 1, use_bias=False, padding=""SAME"")(net)
    net = keras.layers.AveragePooling2D()(net)

    for _ in range(10):
        def _block(x):
            x = keras.layers.BatchNormalization()(x)
            x = keras.layers.ReLU()(x)
            x = keras.layers.Conv2D(32, 1, use_bias=False, padding=""SAME"")(x)
            x = keras.layers.BatchNormalization()(x)
            x = keras.layers.ReLU()(x)
            x = keras.layers.Conv2D(8, 3, use_bias=False, padding=""SAME"")(x)
            return x
        if FLAGS.recompute_grad:
            _block = tf.recompute_grad(_block)
        net = keras.layers.concatenate([net, _block(net)])

    net = keras.layers.BatchNormalization()(net)
    net = keras.layers.ReLU()(net)
    net = keras.layers.GlobalAveragePooling2D()(net)

    net = keras.layers.Dense(10)(net)
    net = keras.layers.Softmax()(net)

    return net


def main(_):
    if FLAGS.gpu:
        os.environ[""CUDA_VISIBLE_DEVICES""] = "","".join(map(str, FLAGS.gpu))
    if FLAGS.graph:
        tf.compat.v1.disable_eager_execution()
        tf.compat.v1.keras.backend.set_session(
            session=tf.compat.v1.Session(
                config=tf.compat.v1.ConfigProto(
                    gpu_options=tf.compat.v1.GPUOptions(
                        allow_growth=True
                    )
                )
            )
        )
    else:
        for gpu in tf.config.experimental.list_physical_devices('GPU'):
            tf.config.experimental.set_memory_growth(gpu, True)

    tfds.core.constants.DATA_DIR = ""data""
    dataset_builder = tfds.image.FashionMNIST(version=""3.*.*"")
    dataset_builder.download_and_prepare()
    dataset = dataset_builder.as_dataset(
        split=""train"",
        shuffle_files=True,
        as_supervised=True,
    ).repeat().batch(FLAGS.batch_size)

    inputs = keras.layers.Input((28, 28, 1), batch_size=FLAGS.batch_size)
    model = keras.Model(inputs, dense_lenet(inputs))

    model.compile(
        optimizer='adam',
        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
        metrics=['accuracy']
    )
    model.summary()

    model.fit(
        x=dataset,
        epochs=3,
        steps_per_epoch=60000//FLAGS.batch_size,
    )


if __name__ == ""__main__"":
    app.run(main)
```
"
36980,InternalError: Assigned device '/job:worker/replica:0/task:0/device:TPU:0' does not have registered OpKernel support for _Arg,"when run bert tpu on colab get  error info  :  
InternalError: Assigned device '/job:worker/replica:0/task:0/device:TPU:0' does not have registered OpKernel support for _Arg

here is [my code on colab ](https://colab.research.google.com/drive/1i9ZhGGv8KDv5-VISbwTdCwDqrhh-67pu#scrollTo=xBggqjKaHU9w) You can reproduce this bug through my code
"
36979,AttributeError: 'Tensor' object has no attribute 'numpy',"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow):  yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Linux Fedora 31
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: no
- TensorFlow installed from (source or
binary): binary (anaconda)
- TensorFlow version (use command below): 2.1 
- Python version: 3.7
- Bazel version (if compiling from source): no
- GCC/Compiler version (if compiling from source): no
- CUDA/cuDNN version: 10.1
- GPU model and memory: nvidia 1050 ti

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I can't call `numpy()` of `Tensor` arguments passed to the mapping function given to `tf.data.Dataset` even with `tf.executing_eagerly()` returning `True`:
```
AttributeError: 'Tensor' object has no attribute 'numpy'
```
**Describe the expected behavior**
I'd like to be able to access the `numpy()` property of arguments passed to a mapping function passed to `tf.data.Dataset.map`
**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```python
import tensorflow as tf

def transformer(x):
    x.numpy()
    return x

dataset = tf.data.Dataset.from_tensors([0,1,2])
dataset.map(transformer)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
36978,Converting unsupported operation: IdentityN,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- TensorFlow version (or github SHA if from source):
Google Colab
tensorflow version:'1.15.0'

**Provide the text output from tflite_convert**
File not created
```
# Copy and paste here
```
ConverterError: See console for info.
2020-02-22 12:33:05.427036: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: IdentityN
2020-02-22 12:33:05.427232: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 15 operators, 18 arrays (0 quantized)
2020-02-22 12:33:05.427378: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 15 operators, 18 arrays (0 quantized)
2020-02-22 12:33:05.427577: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 2 operators, 5 arrays (0 quantized)
2020-02-22 12:33:05.427619: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 2 operators, 5 arrays (0 quantized)
2020-02-22 12:33:05.427646: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 2 operators, 5 arrays (0 quantized)
2020-02-22 12:33:05.427684: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 64 bytes, theoretical optimal value: 64 bytes.
2020-02-22 12:33:05.427712: I tensorflow/lite/toco/toco_tooling.cc:439] Estimated count of arithmetic ops: 3 ops, equivalently 1 MACs
2020-02-22 12:33:05.427726: I tensorflow/lite/toco/toco_tooling.cc:454] Number of parameters: 2
2020-02-22 12:33:05.427933: E tensorflow/lite/toco/toco_tooling.cc:481] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: FULLY_CONNECTED. Here is a list of operators for which you will need custom implementations: IdentityN.
Traceback (most recent call last):
  File ""/usr/local/bin/toco_from_protos"", line 8, in <module>
    sys.exit(main())
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 89, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run
    _run_main(main, args)
  File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 52, in execute
    enable_mlir_converter)

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
https://colab.research.google.com/drive/1clPmDDCmcO7my2spTm2H_cj1PRW6YpYk#scrollTo=7x-p-H9A2EB7

x = [-1,0,1,2,3,4]
y = [-3,-1,1,3,5,7]

model = tf.keras.models.Sequential(
    [tf.keras.layers.Dense(units=1,input_shape=[1])]
)
model.compile(optimizer='sgd',loss = 'mean_squared_error')
model.fit(x,y,epochs=100)

import pathlib
#export the Saved Model

export_dir = '/content/model'
tf.saved_model.save(model,export_dir)

converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)
tflite_model = converter.convert()

#Save the model

tflite_model_file = pathlib.Path('foo.tflite')
tflite_model_file.write_bytes(tflite_model)


Also, please include a link to a GraphDef or the model if possible.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem.
If including tracebacks, please include the full traceback. Large logs and files
should be attached.
"
36976,Failed to load the native Tensorflow runtime.,"
**System information**
- OS Platform and Distribution: Windows 10 (x64), i7 - 7th Gen
- TensorFlow installed from (source or binary): installed via pip
- TensorFlow version: 2.1.0 - tensorflow-gpu
- Python version: 3.7.x
- CUDA/cuDNN version: tried with CUDA 10.1, 9.0, 9.2 with respective cuDNNs
- GPU model and memory: GTX 1050ti - 4gb



**Unable to import the tensorflow library after succesfully installing it.**

1. Installed tensorflow-gpu==2.1.0
2. Installed CUDA and cuDNN 
3. Fails to import tensorflow.


**Error Stack Trace:**

> Traceback (most recent call last):
>   File ""C:\Users\ashut\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
>     from tensorflow.python.pywrap_tensorflow_internal import *
>   File ""C:\Users\ashut\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
>     _pywrap_tensorflow_internal = swig_import_helper()
>   File ""C:\Users\ashut\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
>     _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
>   File ""C:\Users\ashut\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 242, in load_module
>     return load_dynamic(name, filename, file)
>   File ""C:\Users\ashut\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 342, in load_dynamic
>     return _load(spec)
> ImportError: DLL load failed: The specified module could not be found.
> 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Users\ashut\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""C:\Users\ashut\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\ashut\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\ashut\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\ashut\AppData\Local\Programs\Python\Python37\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\ashut\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\ashut\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\ashut\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\ashut\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\ashut\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\ashut\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\ashut\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help."
36975,"Hi, I don't know what the problem is... plz help me to find out the bugs","python: 3.7.3
windows 10

Traceback (most recent call last):
  File ""C:\Users\User\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 3296, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-2-946f26bfac6d>"", line 4, in <module>
    print(tf.__version__)
AttributeError: module 'tensorflow' has no attribute '__version__'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\User\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2033, in showtraceback
    stb = value._render_traceback_()
AttributeError: 'AttributeError' object has no attribute '_render_traceback_'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\User\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\User\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\User\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\User\Anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\User\Anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: 지정된 모듈을 찾을 수 없습니다.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\User\Anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 1095, in get_records
    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)
  File ""C:\Users\User\Anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 313, in wrapped
    return f(*args, **kwargs)
  File ""C:\Users\User\Anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 347, in _fixed_getinnerframes
    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))
  File ""C:\Users\User\Anaconda3\lib\inspect.py"", line 1502, in getinnerframes
    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)
  File ""C:\Users\User\Anaconda3\lib\inspect.py"", line 1460, in getframeinfo
    filename = getsourcefile(frame) or getfile(frame)
  File ""C:\Users\User\Anaconda3\lib\inspect.py"", line 696, in getsourcefile
    if getattr(getmodule(object, filename), '__loader__', None) is not None:
  File ""C:\Users\User\Anaconda3\lib\inspect.py"", line 733, in getmodule
    if ismodule(module) and hasattr(module, '__file__'):
  File ""C:\Users\User\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\User\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\User\Anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 1006, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 983, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 953, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
  File ""<frozen importlib._bootstrap>"", line 1006, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 983, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 967, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 677, in _load_unlocked
  File ""<frozen importlib._bootstrap_external>"", line 728, in exec_module
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
  File ""C:\Users\User\Anaconda3\lib\site-packages\tensorflow_core\__init__.py"", line 42, in <module>
    from . _api.v2 import audio
  File ""C:\Users\User\Anaconda3\lib\site-packages\tensorflow_core\_api\v2\audio\__init__.py"", line 10, in <module>
    from tensorflow.python.ops.gen_audio_ops import decode_wav
  File ""C:\Users\User\Anaconda3\lib\site-packages\tensorflow_core\python\ops\gen_audio_ops.py"", line 8, in <module>
    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow
  File ""C:\Users\User\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\User\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\User\Anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\User\Anaconda3\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\User\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\User\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 3296, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-2-946f26bfac6d>"", line 4, in <module>
    print(tf.__version__)
AttributeError: module 'tensorflow' has no attribute '__version__'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\User\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2033, in showtraceback
    stb = value._render_traceback_()
AttributeError: 'AttributeError' object has no attribute '_render_traceback_'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\User\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\User\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\User\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\User\Anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\User\Anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: 지정된 모듈을 찾을 수 없습니다.
"
36974,CUDA broken on docker image tensorflow/tensorflow:devel-gpu,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>




**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian GNU/Linux 9
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Docker Hub
- TensorFlow version: [tensorflow/tensorflow:latest-devel-gpu](https://hub.docker.com/layers/tensorflow/tensorflow/latest-devel-gpu/images/sha256-607098dc1fe31c990b2c54c37bd5c81099cad165232cb0489c35e51689de27c7?context=explore)
- Python version: python3
- Installed using virtualenv? pip? conda?: docker 
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

CUDA is broken on [tensorflow/tensorflow:devel-gpu](https://hub.docker.com/layers/tensorflow/tensorflow/latest-devel-gpu/images/sha256-607098dc1fe31c990b2c54c37bd5c81099cad165232cb0489c35e51689de27c7?context=explore) image. TensorFlow could not recognize the GPUs.


**Provide the exact sequence of commands / steps that you executed before running into the problem**

### Host Server (Debian GNU/Linux 9)

On the host server, CUDA is on 10.1. Tensorflow can detect 8 GPUs.

Run `nvidia-smi` and it shows 
```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 418.87.01    Driver Version: 418.87.01    CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
```

Verify that TensorFlow can see the 8 GPUs.
```
$ pip install tensorflow 
$ python -c 'import tensorflow as tf; print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices(""GPU"")))'

('Num GPUs Available: ', 8)
```



### Inside Container (tensorflow/tensorflow:devel-gpu)

Then, start the container.
```
$ docker run --gpus=all -it tensorflow/tensorflow:latest-devel-gpu-py3
```

In the container, run
```
root@5f3ceeb2248b:/# nvidia-smi
Sat Feb 22 02:06:17 2020
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 418.87.01    Driver Version: 418.87.01    CUDA Version: ERR!     |
|-------------------------------+----------------------+----------------------+
```
Notice that the CUDA version was **ERR!**. It may indicate that the CUDA version is broken. 
Run 
```
$ pip install tensorflow 
$ python -c 'import tensorflow as tf; print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices(""GPU"")))'

2020-02-22 02:11:29.788170: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program
2020-02-22 02:11:29.788245: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.87.1
Num GPUs Available:  0
```

TensorFlow could not see the GPUs.


**Any other info / logs**


"
36973,Can't find docs on SSL support for distributed training,"**Describe the current behavior**

I haven't be able to find documentation on if SSL is used during distributed training with `tf.distribute.Strategy` with gRPC.

**Describe the expected behavior**

I should be able to easily find this information in the documentation, and if it's supported, then I should easily be able to turn SSL on/off in distributed training for when I prefer security vs performance."
36972,Tensorflow Lite Hexagon delegate support for QCOM XR1 - soc_id: 371,"QCOM XR1 (with soc_id:371) is in the same family as Snapdragon 710, Snapdragon 710 is in the list of the supported Socs:

Currently most Qualcomm SoCs are supported, including:

Snapdragon 835 (682 DSP)
Snapdragon 660/820/821 (680 DSP)
Snapdragon 710/845 (685 DSP)
Snapdragon 8150/855 (690 DSP)

we were wondering if XR1 could be added to this list as well, based on my understanding, the only change is to add the soc_id:371 to the supported list. We would be happy to help test/verify it if necessary. DSP acceleration is very important to our use cases, your help is greatly appreciated.

thanks for your support,
-richard"
36970,TensorFlow supports multiple threads/streams on one GPU for training?,"UPDATE:

I found the source code of GPUDevice, it hard-coded max streams to 1, may I know the know reason? 

GPUDevice(const SessionOptions& options, const string& name,
            Bytes memory_limit, const DeviceLocality& locality,
            TfGpuId tf_gpu_id, const string& physical_device_desc,
            Allocator* gpu_allocator, Allocator* cpu_allocator)
      : BaseGPUDevice(options, name, memory_limit, locality, tf_gpu_id,
                      physical_device_desc, gpu_allocator, cpu_allocator,
                      false /* sync every op */, **1 /* max_streams */**) {
    if (options.config.has_gpu_options()) {
      force_gpu_compatible_ =
          options.config.gpu_options().force_gpu_compatible();
    }


=================================================
I am wondering whether TensorFlow(1.x version) supports multi-thread or multi-stream on a single GPU. If not, I am curious the underlying reasons, TF did this on some purposes or some libs like CUDA prevents TF from providing or some other reasons?

I tried to run multiple training ops in TF, i.e. sees.run([train_op1, train_op2],feed_dict={...}), I used the TF timeline to profile each iteration. However, TF timeline always showed that two train ops run sequentially (although timeline is not accurate[1], the wall time of each op suggests sequential running). I also looked at some source code of TF, it looks like the each op are computed by in device->ComputeAsync() or device->Compute(), and the GPU is blocked when computing an op. If I am correct, one GPU can only run a single op each time, which may lower GPU utilization.

Any comments are welcome.

1.https://github.com/tensorflow/tensorflow/issues/1824#issuecomment-244251867"
36968,Gradient checkpointing: Wrap `tf.keras.Model` or `tf.keras.layers.Layer` in `tf.recompute_gradients()`,"I'm implementing gradient checkpointing with my Tensorflow 2.1 project, following the doc here: https://www.tensorflow.org/api_docs/python/tf/recompute_grad

When I try
```code
model = tf.recompute_grad(model)
```
it fails, and likewise with 
```code
model.layer = tf.recompute_grad(model.layer)
```

I see that Keras acts differently because tf.recompute_grad() wraps the function with an inner() call, but what should I do to get it working?"
36967,Unable to build tensorflow benchmark tool for android: undefined reference to `vtable for tflite::gpu::cl::SpaceToDepth',"
**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.4 LTS
- TensorFlow installed from (source or binary): Source
- TensorFlow version:  Build from: git clone --recurse-submodules https://github.com/tensorflow/tensorflow.git
- Python version: 3.6.9
- Bazel version (if compiling from source): 2.0.0
- GCC/Compiler version (if compiling from source):gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0

Here is the bazel workspace configuration:-

> WARNING: Running Bazel server needs to be killed, because the startup options are different.
> WARNING: ignoring LD_PRELOAD in environment.
> You have bazel 2.0.0 installed.
> Please specify the location of python. [Default is /usr/bin/python3]: 
> 
> 
> Found possible Python library paths:
>   /usr/lib/python3/dist-packages
>   /usr/local/lib/python3.6/dist-packages
> Please input the desired Python library path to use.  Default is [/usr/lib/python3/dist-packages]
> 
> Do you wish to build TensorFlow with XLA JIT support? [Y/n]: n
> No XLA JIT support will be enabled for TensorFlow.
> 
> Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: N
> No OpenCL SYCL support will be enabled for TensorFlow.
> 
> Do you wish to build TensorFlow with ROCm support? [y/N]: N
> No ROCm support will be enabled for TensorFlow.
> 
> Do you wish to build TensorFlow with CUDA support? [y/N]: N
> No CUDA support will be enabled for TensorFlow.
> 
> Do you wish to download a fresh release of clang? (Experimental) [y/N]: N
> Clang will not be downloaded.
> 
> Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native -Wno-sign-compare]: 
> 
> 
> Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: y
> Searching for NDK and SDK installations.
> 
> Please specify the home path of the Android NDK to use. [Default is /root/Android/Sdk/ndk-bundle]: /content/tensorflow/android-ndk-r18b
> 
> 
> Please specify the (min) Android NDK API level to use. [Available levels: ['16', '17', '18', '19', '21', '22', '23', '24', '26', '27', '28']] [Default is 21]: 
> 
> 
> Please specify the home path of the Android SDK to use. [Default is /root/Android/Sdk]: /content/Sdk
> 
> 
> Please specify the Android SDK API level to use. [Available levels: ['28']] [Default is 28]: 
> 
> 
> Please specify an Android build tools version to use. [Available versions: ['29.0.0']] [Default is 29.0.0]: 
> 
> 
> Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details.
> 	--config=mkl         	# Build with MKL support.
> 	--config=monolithic  	# Config for mostly static monolithic build.
> 	--config=ngraph      	# Build with Intel nGraph support.
> 	--config=numa        	# Build with NUMA support.
> 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects.
> 	--config=v2          	# Build TensorFlow 2.x instead of 1.x.
> Preconfigured Bazel build configs to DISABLE default on features:
> 	--config=noaws       	# Disable AWS S3 filesystem support.
> 	--config=nogcp       	# Disable GCP support.
> 	--config=nohdfs      	# Disable HDFS support.
> 	--config=nonccl      	# Disable NVIDIA NCCL support.
> Configuration finished`

`
**Describe the problem**
Unable to compile Tflite benchmark tool for android_arm64 platform.It gives the following error:-

```
!bazel build -c opt \
  --config=android_arm64 \
  tensorflow/lite/tools/benchmark:benchmark_model
```
(Also tried argument options plain arm, cxx-opt 14 etc..)
> Compiling tensorflow/lite/delegates/gpu/common/model_builder.cc; 4s local
> ERROR: /content/tensorflow/tensorflow/lite/tools/benchmark/BUILD:22:1: Linking of rule '//tensorflow/lite/tools/benchmark:benchmark_model' failed (Exit 1)
> bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/cl/selectors/libsimple_selectors.a(simple_selectors.o): In function `tflite::gpu::cl::SelectSpaceToDepth(tflite::gpu::SpaceToDepthAttributes const&, tflite::gpu::cl::OperationDef const&, std::__ndk1::unique_ptr<tflite::gpu::cl::GPUOperation, std::__ndk1::default_delete<tflite::gpu::cl::GPUOperation> >*)':
> /proc/self/cwd/tensorflow/lite/delegates/gpu/cl/selectors/simple_selectors.cc:132: undefined reference to `tflite::gpu::cl::CreateSpaceToDepth(tflite::gpu::cl::OperationDef const&, tflite::gpu::SpaceToDepthAttributes const&)'
> bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/cl/selectors/libsimple_selectors.a(simple_selectors.o): In function `std::__ndk1::__unique_if<tflite::gpu::cl::SpaceToDepth>::__unique_single std::__ndk1::make_unique<tflite::gpu::cl::SpaceToDepth, tflite::gpu::cl::SpaceToDepth>(tflite::gpu::cl::SpaceToDepth&&)':
> /proc/self/cwd/external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include/memory:3114: undefined reference to `tflite::gpu::cl::SpaceToDepth::SpaceToDepth(tflite::gpu::cl::SpaceToDepth&&)'
> bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/cl/selectors/libsimple_selectors.a(simple_selectors.o): In function `~SpaceToDepth':
> /proc/self/cwd/./tensorflow/lite/delegates/gpu/cl/kernels/space_to_depth.h:29: undefined reference to `vtable for tflite::gpu::cl::SpaceToDepth'
> /proc/self/cwd/./tensorflow/lite/delegates/gpu/cl/kernels/space_to_depth.h:29: undefined reference to `vtable for tflite::gpu::cl::SpaceToDepth'
> /proc/self/cwd/./tensorflow/lite/delegates/gpu/cl/kernels/space_to_depth.h:29: undefined reference to `vtable for tflite::gpu::cl::SpaceToDepth'
> /proc/self/cwd/./tensorflow/lite/delegates/gpu/cl/kernels/space_to_depth.h:29: undefined reference to `vtable for tflite::gpu::cl::SpaceToDepth'
> clang: error: linker command failed with exit code 1 (use -v to see invocation)
> Target //tensorflow/lite/tools/benchmark:benchmark_model failed to build
> Use --verbose_failures to see the command lines of failed build steps.
> INFO: Elapsed time: 833.996s, Critical Path: 35.28s
> INFO: 1497 processes: 1497 local.
> FAILED: Build did NOT complete successfully

**Provide the exact sequence of commands / steps that you executed before running into the problem**
 Followed the official GitHub: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/benchmark

I tried with NDK 14 and it gave error related to string parsing during compilation. In  18 and 20 NDK versions it gives error related to SpacetoBatch. I tried the compilation in google colab using command line tools for sdk manager for android."
36966,Can't save individual models from Tensorflow 1.x Session Checkpoint,"I have a folder containing 3 files
**model.ckpt.data-00000-of-00001
model.ckpt.index
model.ckpt.meta**

It actually contains 3 models (you can check them on tensorboard)
**InceptionV3
TransformNet
VGG16**

If you want to check it out
https://storage.googleapis.com/download.magenta.tensorflow.org/models/arbitrary_style_transfer.tar.gz

I want to separate each model to **individual .pb frozen models** and want to use them in web after conversion using tensorflowjs-converter

I am using below snippet to get InceptionV3(the last node of Iv3 is Conv/BiasAdd)

```
FileWriter(""__tb"", sess.graph)

  
  frozen_graph_def = tf.graph_util.convert_variables_to_constants(
        sess,
        sess.graph_def,
        ['Conv/BiasAdd']) #Output_nodes

    # Save the frozen graph
  with open('/content/model/IV3.pb', 'wb') as f:
    f.write(frozen_graph_def.SerializeToString())
```

But i don't know how to get **transformer model** after **Conv/BiasAdd** node to the output node.



"
36965,SPLIT_V operator support,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- TensorFlow version (or github SHA if from source):


**Provide the text output from tflite_convert**

```
WARNING:absl:Please consider switching to use new converter by setting experimental_new_converter to true. Old converter (TOCO) is deprecated and flow will be switched on by default to use new converter soon.
Traceback (most recent call last):
  File ""/home/elezhe01/work/scripts/test_gru_cell.py"", line 23, in <module>
    tflite_model = converter.convert()
  File ""/home/elezhe01/.local/lib/python3.6/site-packages/tensorflow/lite/python/lite.py"", line 518, in convert
    self.experimental_new_quantizer)
  File ""/home/elezhe01/.local/lib/python3.6/site-packages/tensorflow/lite/python/lite.py"", line 262, in _calibrate_quantize_model
    inference_output_type, allow_float, enable_mlir_quantizer)
  File ""/home/elezhe01/.local/lib/python3.6/site-packages/tensorflow/lite/python/optimize/calibrator.py"", line 81, in calibrate_and_quantize
    enable_mlir_quantizer)
  File ""/home/elezhe01/.local/lib/python3.6/site-packages/tensorflow/lite/python/optimize/tensorflow_lite_wrap_calibration_wrapper.py"", line 115, in QuantizeModel
    return _tensorflow_lite_wrap_calibration_wrapper.CalibrationWrapper_QuantizeModel(self, *args)
RuntimeError: Quantization not yet supported for op: SPLIT_V
```

**Standalone code to reproduce the issue** 
```
import tensorflow as tf
import numpy as numpy

model = tf.keras.Sequential()

model.add(tf.keras.layers.Input(shape=(1, 1,)))

cell = tf.keras.layers.GRUCell(10)

model.add(tf.keras.layers.RNN(cell, unroll=True))

model.save(""test_gru_cell.h5"", save_format='h5')

def representative_dataset_gen():
    yield [numpy.random.uniform(low=-1, high=1, size=(1,1,1)).astype(numpy.float32)]

converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.representative_dataset = representative_dataset_gen
converter.experimental_new_converter = False

tflite_model = converter.convert()

open(""test_gru_cell.tflite"", 'wb').write(tflite_model)
```
"
36964, doesn't support control flow ops:,"**System information**
- OS Platform and Distribution (MAC 10.15.3 (19D76)):
- TensorFlow installed from (binary):
- TensorFlow version (1.15.0):


**Provide the text output from tflite_convert**

```
# Copy and paste here
```

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

Also, please include a link to a GraphDef or the model if possible.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem.
If including tracebacks, please include the full traceback. Large logs and files
should be attached.
2020-02-22 01:14:04.085039: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-22 01:14:04.094983: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa5fe943ce0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-22 01:14:04.094997: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:From /Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/tensorflow_core/lite/python/convert_saved_model.py:60: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.
W0222 01:14:04.095364 4577779136 deprecation.py:323] From /Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/tensorflow_core/lite/python/convert_saved_model.py:60: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.
INFO:tensorflow:Restoring parameters from ./model/variables/variables
I0222 01:14:04.311928 4577779136 saver.py:1284] Restoring parameters from ./model/variables/variables
INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default'}
I0222 01:14:04.437039 4577779136 convert_saved_model.py:80] The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default'}
INFO:tensorflow:input tensors info: 
I0222 01:14:04.437269 4577779136 convert_saved_model.py:99] input tensors info: 
INFO:tensorflow:Tensor's key in saved_model's tensor_map: word_ids
I0222 01:14:04.437363 4577779136 convert_saved_model.py:41] Tensor's key in saved_model's tensor_map: word_ids
INFO:tensorflow: tensor name: word_ids:0, shape: (-1, 64), type: DT_INT32
I0222 01:14:04.437431 4577779136 convert_saved_model.py:43]  tensor name: word_ids:0, shape: (-1, 64), type: DT_INT32
INFO:tensorflow:Tensor's key in saved_model's tensor_map: labels
I0222 01:14:04.437486 4577779136 convert_saved_model.py:41] Tensor's key in saved_model's tensor_map: labels
INFO:tensorflow: tensor name: labels:0, shape: (-1, 64), type: DT_INT32
I0222 01:14:04.437530 4577779136 convert_saved_model.py:43]  tensor name: labels:0, shape: (-1, 64), type: DT_INT32
INFO:tensorflow:Tensor's key in saved_model's tensor_map: sequence_lengths
I0222 01:14:04.437580 4577779136 convert_saved_model.py:41] Tensor's key in saved_model's tensor_map: sequence_lengths
INFO:tensorflow: tensor name: sequence_lengths:0, shape: (-1), type: DT_INT32
I0222 01:14:04.437623 4577779136 convert_saved_model.py:43]  tensor name: sequence_lengths:0, shape: (-1), type: DT_INT32
INFO:tensorflow:output tensors info: 
I0222 01:14:04.437661 4577779136 convert_saved_model.py:101] output tensors info: 
INFO:tensorflow:Tensor's key in saved_model's tensor_map: labels_softmax_
I0222 01:14:04.437716 4577779136 convert_saved_model.py:41] Tensor's key in saved_model's tensor_map: labels_softmax_
INFO:tensorflow: tensor name: Cast:0, shape: (-1, -1), type: DT_INT32
I0222 01:14:04.437761 4577779136 convert_saved_model.py:43]  tensor name: Cast:0, shape: (-1, -1), type: DT_INT32
INFO:tensorflow:Restoring parameters from ./model/variables/variables
I0222 01:14:04.642255 4577779136 saver.py:1284] Restoring parameters from ./model/variables/variables
2020-02-22 01:14:04.806073: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)
2020-02-22 01:14:04.806140: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-02-22 01:14:04.847576: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:786] Optimization results for grappler item: graph_to_optimize
2020-02-22 01:14:04.847595: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   function_optimizer: function_optimizer did nothing. time = 0.003ms.
2020-02-22 01:14:04.847599: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   function_optimizer: function_optimizer did nothing. time = 0ms.
WARNING:tensorflow:From /Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/tensorflow_core/lite/python/util.py:249: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.convert_variables_to_constants`
W0222 01:14:04.920840 4577779136 deprecation.py:323] From /Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/tensorflow_core/lite/python/util.py:249: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.convert_variables_to_constants`
WARNING:tensorflow:From /Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.extract_sub_graph`
W0222 01:14:04.921000 4577779136 deprecation.py:323] From /Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.extract_sub_graph`
INFO:tensorflow:Froze 8 variables.
I0222 01:14:04.977573 4577779136 graph_util_impl.py:334] Froze 8 variables.
INFO:tensorflow:Converted 8 variables to const ops.
I0222 01:14:05.001580 4577779136 graph_util_impl.py:394] Converted 8 variables to const ops.
2020-02-22 01:14:05.044424: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)
2020-02-22 01:14:05.044509: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-02-22 01:14:05.068744: E tensorflow/core/grappler/grappler_item_builder.cc:650] Fetch node labels doesn't exist in graph
Traceback (most recent call last):
  File ""/Users/lidayuan/opt/anaconda3/envs/py371/bin/tflite_convert"", line 8, in <module>
    sys.exit(main())
  File ""/Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/tensorflow_core/lite/python/tflite_convert.py"", line 515, in main
    app.run(main=run_main, argv=sys.argv[:1])
  File ""/Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/tensorflow_core/lite/python/tflite_convert.py"", line 511, in run_main
    _convert_tf1_model(tflite_flags)
  File ""/Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/tensorflow_core/lite/python/tflite_convert.py"", line 199, in _convert_tf1_model
    output_data = converter.convert()
  File ""/Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/tensorflow_core/lite/python/lite.py"", line 983, in convert
    **converter_kwargs)
  File ""/Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/tensorflow_core/lite/python/convert.py"", line 449, in toco_convert_impl
    enable_mlir_converter=enable_mlir_converter)
  File ""/Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/tensorflow_core/lite/python/convert.py"", line 200, in toco_convert_protos
    raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: See console for info.
2020-02-22 01:14:07.404666: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-02-22 01:14:07.404703: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-02-22 01:14:07.404722: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-02-22 01:14:07.404731: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-02-22 01:14:07.404784: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-02-22 01:14:07.404792: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-02-22 01:14:07.404812: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-02-22 01:14:07.404822: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-02-22 01:14:07.404938: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3
2020-02-22 01:14:07.404951: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2020-02-22 01:14:07.404960: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3
2020-02-22 01:14:07.404965: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2020-02-22 01:14:07.404974: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-02-22 01:14:07.405028: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-02-22 01:14:07.405037: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-02-22 01:14:07.405041: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2020-02-22 01:14:07.405047: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-02-22 01:14:07.405050: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2020-02-22 01:14:07.405065: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3
2020-02-22 01:14:07.405086: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3
2020-02-22 01:14:07.405091: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2020-02-22 01:14:07.405099: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3
2020-02-22 01:14:07.405104: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2020-02-22 01:14:07.405111: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-02-22 01:14:07.405140: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-02-22 01:14:07.405159: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-02-22 01:14:07.405168: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-02-22 01:14:07.405172: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2020-02-22 01:14:07.405178: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-02-22 01:14:07.405182: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2020-02-22 01:14:07.405196: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3
2020-02-22 01:14:07.405204: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-02-22 01:14:07.405211: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-02-22 01:14:07.405228: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-02-22 01:14:07.405249: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-02-22 01:14:07.405266: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-02-22 01:14:07.405274: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-02-22 01:14:07.405287: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-02-22 01:14:07.405300: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-02-22 01:14:07.405324: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-02-22 01:14:07.405337: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-02-22 01:14:07.405351: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-02-22 01:14:07.405362: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: LoopCond
2020-02-22 01:14:07.405388: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: LoopCond
2020-02-22 01:14:07.405399: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit
2020-02-22 01:14:07.405442: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3
2020-02-22 01:14:07.405453: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3
2020-02-22 01:14:07.405466: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit
2020-02-22 01:14:07.405506: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3
2020-02-22 01:14:07.405516: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3
2020-02-22 01:14:07.405535: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3
2020-02-22 01:14:07.405573: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3
2020-02-22 01:14:07.405683: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3
2020-02-22 01:14:07.405704: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3
2020-02-22 01:14:07.410286: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 238 operators, 398 arrays (0 quantized)
2020-02-22 01:14:07.411855: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 228 operators, 382 arrays (0 quantized)
2020-02-22 01:14:07.413998: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 228 operators, 382 arrays (0 quantized)
2020-02-22 01:14:07.414578: W tensorflow/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:88] RandomUniform op outputting ""dropout_1/random_uniform/RandomUniform"" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set ""seed"" or ""seed2"" attr non-zero to fix this
2020-02-22 01:14:07.416732: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 152 operators, 242 arrays (0 quantized)
2020-02-22 01:14:07.417601: W tensorflow/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:88] RandomUniform op outputting ""dropout_1/random_uniform/RandomUniform"" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set ""seed"" or ""seed2"" attr non-zero to fix this
2020-02-22 01:14:07.418410: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 151 operators, 241 arrays (0 quantized)
2020-02-22 01:14:07.418796: W tensorflow/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:88] RandomUniform op outputting ""dropout_1/random_uniform/RandomUniform"" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set ""seed"" or ""seed2"" attr non-zero to fix this
2020-02-22 01:14:07.419965: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 3: 150 operators, 239 arrays (0 quantized)
2020-02-22 01:14:07.420736: W tensorflow/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:88] RandomUniform op outputting ""dropout_1/random_uniform/RandomUniform"" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set ""seed"" or ""seed2"" attr non-zero to fix this
2020-02-22 01:14:07.421508: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 150 operators, 239 arrays (0 quantized)
2020-02-22 01:14:07.422579: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 150 operators, 239 arrays (0 quantized)
2020-02-22 01:14:07.424002: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 231040 bytes, theoretical optimal value: 231040 bytes.
2020-02-22 01:14:07.424390: I tensorflow/lite/toco/toco_tooling.cc:454] Number of parameters: 3808024
2020-02-22 01:14:07.424903: E tensorflow/lite/toco/toco_tooling.cc:481] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

TensorFlow Lite currently doesn't support control flow ops: Enter, Exit, Merge, Switch. We are working on supporting control flow ops, please see github issue at https://github.com/tensorflow/tensorflow/issues/28485. Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, ARG_MAX, CAST, CONCATENATION, FULLY_CONNECTED, GATHER, GREATER_EQUAL, LESS, LOGICAL_AND, LOGISTIC, MAXIMUM, MINIMUM, MUL, PACK, RANGE, REDUCE_MAX, RESHAPE, REVERSE_SEQUENCE, SELECT, SHAPE, SPLIT, STRIDED_SLICE, TANH, TRANSPOSE. Here is a list of operators for which you will need custom implementations: LoopCond, RandomUniform, TensorArrayGatherV3, TensorArrayReadV3, TensorArrayScatterV3, TensorArraySizeV3, TensorArrayV3, TensorArrayWriteV3.
Traceback (most recent call last):
  File ""/Users/lidayuan/opt/anaconda3/envs/py371/bin/toco_from_protos"", line 8, in <module>
    sys.exit(main())
  File ""/Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 89, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""/Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 52, in execute
    enable_mlir_converter)
Exception: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

TensorFlow Lite currently doesn't support control flow ops: Enter, Exit, Merge, Switch. We are working on supporting control flow ops, please see github issue at https://github.com/tensorflow/tensorflow/issues/28485. Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, ARG_MAX, CAST, CONCATENATION, FULLY_CONNECTED, GATHER, GREATER_EQUAL, LESS, LOGICAL_AND, LOGISTIC, MAXIMUM, MINIMUM, MUL, PACK, RANGE, REDUCE_MAX, RESHAPE, REVERSE_SEQUENCE, SELECT, SHAPE, SPLIT, STRIDED_SLICE, TANH, TRANSPOSE. Here is a list of operators for which you will need custom implementations: LoopCond, RandomUniform, TensorArrayGatherV3, TensorArrayReadV3, TensorArrayScatterV3, TensorArraySizeV3, TensorArrayV3, TensorArrayWriteV3.
"
36963,image.resize tensor as size argumentnot working in tf.function,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): custom Layer, using tf.image.resize
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04):  Linux Mint 19.3 Cinnamon (Ubuntu based)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: No
- TensorFlow installed from (source or
binary): pip install
 - TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de 2.1.0
- Python version: 3.6.9

**Describe the current behavior**
image.resize is working in eager(standard) mode, with tensor as size argument
stops working if warped in tf.function

**Describe the expected behavior**
should work like in eager

possible reason:
live tf.function tensor is in the implementation of image.resize not evaluated.
so the cast to a appropriate value fails and None is returned

Error (full):
```
Traceback (most recent call last):
  File ""/home/bhb/.vscode/extensions/ms-python.python-2020.2.63990/pythonFiles/ptvsd_launcher.py"", line 48, in <module>
    main(ptvsdArgs)
  File ""/home/bhb/.vscode/extensions/ms-python.python-2020.2.63990/pythonFiles/lib/python/old_ptvsd/ptvsd/__main__.py"", line 432, in main
    run()
  File ""/home/bhb/.vscode/extensions/ms-python.python-2020.2.63990/pythonFiles/lib/python/old_ptvsd/ptvsd/__main__.py"", line 316, in run_file
    runpy.run_path(target, run_name='__main__')
  File ""/usr/lib/python3.6/runpy.py"", line 263, in run_path
    pkg_name=pkg_name, script_name=fname)
  File ""/usr/lib/python3.6/runpy.py"", line 96, in _run_module_code
    mod_name, mod_spec, pkg_name, script_name)
  File ""/usr/lib/python3.6/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/ShAReD_Net/model/modules/base.py"", line 204, in <module>
    main()
  File ""/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/ShAReD_Net/model/modules/base.py"", line 191, in main
    out = test_multiscale(inputs)
  File ""/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/ShAReD_Net/model/modules/base.py"", line 175, in run
    outputs = op(inputs, **kwargs)
  File ""/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 822, in __call__
    outputs = self.call(cast_inputs, *args, **kwargs)
  File ""/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/ShAReD_Net/model/modules/base.py"", line 126, in call
    outs.append(self.hour_glass(ins))
  File ""/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 822, in __call__
    outputs = self.call(cast_inputs, *args, **kwargs)
  File ""/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/ShAReD_Net/model/modules/base.py"", line 62, in call
    big_normal = self.big_normal(big_shared2_shc, scale_2)
  File ""/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 822, in __call__
    outputs = self.call(cast_inputs, *args, **kwargs)
  File ""/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 568, in __call__
    result = self._call(*args, **kwds)
  File ""/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 615, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File ""/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 497, in _initialize
    *args, **kwds))
  File ""/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2389, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2703, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2593, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py"", line 978, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 439, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 3211, in bound_method_wrapper
    return wrapped_fn(*args, **kwargs)
  File ""/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py"", line 968, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: in converted code:

    /mnt/7f43981f-bc0a-4b76-a721-46c0159f0cf5/cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/ShAReD_Net/model/layer/base.py:228 call  *
        scaled_conv = tf.image.resize(conv, destination_size, preserve_aspect_ratio=True, antialias=True)
    /home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/ops/image_ops_impl.py:1357 resize_images_v2
        skip_resize_if_same=False)
    /home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/ops/image_ops_impl.py:1100 _resize_images_common
        math_ops.cast(new_height_const, dtypes.float32) /
    /home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/util/dispatch.py:180 wrapper
        return target(*args, **kwargs)
    /home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/ops/math_ops.py:705 cast
        x = ops.convert_to_tensor(x, name=""x"")
    /home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1314 convert_to_tensor
        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
    /home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py:317 _constant_tensor_conversion_function
        return constant(v, dtype=dtype, name=name)
    /home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py:258 constant
        allow_broadcast=True)
    /home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py:296 _constant_impl
        allow_broadcast=allow_broadcast))
    /home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/tensor_util.py:439 make_tensor_proto
        raise ValueError(""None values not supported."")

    ValueError: None values not supported.
```

**Standalone code to reproduce the issue** 
Sorry not yet the time, but relevant code is:

custom Layer for scaling features to variable (depended on other feature size) size :+1: 
```
class Scale(keras.layers.Layer):
    def __init__(self, destination_channel = None, name = ""Scale"", **kwargs):
        super().__init__(name = name, **kwargs)
        self.destination_channel = destination_channel
        
    def build(self, input_shape):
        if self.destination_channel is None:
            self.destination_channel = input_shape[-1]
        self.compress_input = keras.layers.Convolution2D(int(input_shape[-1]/2), kernel_size=1, padding='SAME', activation=tf.nn.leaky_relu, kernel_initializer=tf.initializers.he_normal(), bias_initializer=tf.initializers.he_uniform())
        self.conv = keras.layers.Convolution2D(input_shape[-1], kernel_size=3, padding='SAME', activation=tf.nn.leaky_relu, kernel_initializer=tf.initializers.he_normal(), bias_initializer=tf.initializers.he_uniform())
        self.pool = keras.layers.MaxPool2D(pool_size=3,strides=1,padding=""SAME"")
        self.compress_output = keras.layers.Convolution2D(self.destination_channel, kernel_size=1, padding='SAME', activation=tf.nn.leaky_relu, kernel_initializer=tf.initializers.he_normal(), bias_initializer=tf.initializers.he_uniform())
        super().build(input_shape)

    def call(self, inputs, destination_size):
        
        compressed_input = self.compress_input(inputs)
        conv = self.conv(compressed_input)
        pool = self.pool(inputs)
        
        scaled_conv = tf.image.resize(conv, destination_size, preserve_aspect_ratio=True, antialias=True)
        scaled_pool = tf.image.resize(pool, destination_size, preserve_aspect_ratio=True, antialias=True)
        
        concat = keras.layers.concatenate([scaled_pool, scaled_conv])
        compressed_output = self.compress_output(concat)
        return compressed_output
```
works if like shown, stops working if @tf.function is added to 
`def call(self, inputs, destination_size):`

Calling code:
```
def call(self, inputs):
        input_res, input_shc = inputs
        
        scale = tf.cast(input_shc.shape[1:3], dtype=tf.int32)
        scale_2 = tf.cast(scale/2, dtype=tf.int32)
        scale_4 = tf.cast(scale/4, dtype=tf.int32)
        scale_8 = tf.cast(scale/8, dtype=tf.int32)
        
        big_normal = self.big_normal(big_shared2_shc, scale_2)
        return big_normal
```
`big_normal` is a instance of `class Scale`

thanks in advance"
36962,Cannot save model when not giving a name in Layer.add_weight call,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): Yes
- OS Platform and Distribution: Manjaro 19.0.0 Kyria
- TensorFlow installed from: binary
- TensorFlow version: 2.1.0 
- Python version: 3.7.4

**Describe the current behavior**
I made a custom `tf.keras.layers.Layer`, where I make my weights in the `build` function using `self.add_weight`. However, I do not pass a name to this function. When I try to save the model that uses the layer, I get an error because the name of the weight is `None` (see traceback below).

**Describe the expected behavior**
I expected that the weight would either get a default name (possibly only upon saving), that I would get an error when calling `add_weight` or that I would get a more informative error when saving the model.

**Standalone code to reproduce the issue** 
```
import tensorflow as tf
class CustomLayer(tf.keras.layers.Layer):
    def build(self, input_shape):
        self.w = self.add_weight(shape=(input_shape[-1], 1))
    def call(self, x):
        return tf.matmul(x, self.w)
inp = tf.keras.Input((5,))
m = tf.keras.Model(inputs=inp, outputs=CustomLayer()(inp))
m.save(""/tmp/savedmodel"")
```

**Other info / logs**
```
Traceback (most recent call last):
  File ""tfbug.py"", line 9, in <module>
    m.save(""/tmp/savedmodel"")
  File ""/home/arno/conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py"", line 1008, in save
    signatures, options)
  File ""/home/arno/conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py"", line 115, in save_model
    signatures, options)
  File ""/home/arno/conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/save.py"", line 78, in save 
    save_lib.save(model, filepath, signatures, options)
  File ""/home/arno/conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py"", line 899, in save
    _ = _SaveableView(checkpoint_graph_view)
  File ""/home/arno/conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py"", line 165, in __init__
    self.checkpoint_view.objects_ids_and_slot_variables())
  File ""/home/arno/conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/graph_view.py"", line 418, in objects_ids_and_slot_variables
    object_names[obj] = _object_prefix_from_path(path)
  File ""/home/arno/conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/graph_view.py"", line 64, in _object_prefix_from_path
    for trackable in path_to_root))
  File ""/home/arno/conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/graph_view.py"", line 64, in <genexpr>
    for trackable in path_to_root))
  File ""/home/arno/conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/graph_view.py"", line 57, in _escape_local_name
    return (name.replace(_ESCAPE_CHAR, _ESCAPE_CHAR + _ESCAPE_CHAR)
AttributeError: 'NoneType' object has no attribute 'replace'
```
"
36959,TF-TRT execution context management for multiple threads / streams,"This issue is created to discuss and possibly improve execution context management during TF-TRT inference. 

The TRT [best practices guide]() says: ""A common pattern is incoming requests dispatched to a pool of waiting for worker threads. In this case, the pool of worker threads will each have one execution context and CUDA stream. Each thread will request work in its own stream as the work becomes available. Each thread will synchronize with its stream to wait for results without blocking other worker threads.""

Note that we have a different pattern in TF-TRT. Let's consider the implicit batch case with  a single engine and a single execution context. For any given `TRTEngineOp` we keep a global execution context object in the resource manager. We guard the access to this `IExecutionContext` by a mutex until we prepare the buffers and equeue the inference job. But the mutex is released when we return from `ExecuteTRTEngine`, and the inference job might still be enqueued at that time when we release the mutex.

The TRT best practices guide says: to ""Create a CUDA stream using cudaStreamCreate for each independent batch and an `IExecutionContext` for each independent batch."" ~I would~ One should interpret this the following way: if we want to enque work on multiple GPU streams then each independent batch of work has to have a separate `IExecutionContext` object. Alternatively we can use a single stream with a single execution context.

So the current scheduling of TF-TRT inference would require that TRTEngineOp_0 puts all its work always on the same stream. This (while not efficient) would guarantee correctness. 

Is it guaranteed that the following call would always return the same stream for the given `TRTEngineOP` object?
https://github.com/tensorflow/tensorflow/blob/9b53275852f37fb1f48e22ed99237f1baef761c5/tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc#L416-L420

Tagging @bixia1"
36958,How to optimize a complex phase?,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): yes
- OS Platform and Distribution: MacOS 10.15.3
- TensorFlow installed from binary: 2.1.0

**Describe the current behavior**
A real loss function that uses complex numbers internally requires Variables to be complex.
But this leads to complex gradients, even though they should be real.

**Describe the expected behavior**
In TF1.x I used to circumvent this problem by defining my real variables as (e.g.):
```python
x = tf.complex(tf.Variable(1.0, dtype=tf.float32), tf.constant(0.0, dtype=tf.float32))
```
TF2.x cannot compute gradients if I use this trick.

**Standalone code to reproduce the issue** 
For example, I want to optimize the _real_ angle `x` in the complex phase `exp(1j*x)`:

```python
def loss(x):
    return tf.abs(tf.exp(1j*x)-1.0) # minimized by x = 0.0

x = tf.Variable(1.0, dtype=tf.complex64) # forced to have type tf.complex64
LR = 0.01

for n in range(10):
    with tf.GradientTape() as tape:
        L = loss(x)
        grad = tape.gradient(L, x)
        x.assign_sub(LR * grad)

print(x)
# <tf.Variable 'Variable:0' shape=() dtype=complex64, numpy=(0.9122518+0.043542963j)>
```
"
36957,ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.,"#Import the libraries
import tensorflow as tf

**System information**

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 64-bit
TensorFlow installed from (source or binary): pip package manager (20.0.2)
TensorFlow version (use command below): 2.1.0
Python version: Python 3.6.8 64-bit (python-3.6.8-amd64)
CUDA/cuDNN version: No GPU
GPU model and memory: No GPU
You can collect some of this information using our environment capture script
You can also obtain the TensorFlow version with
python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

**Describe the current behavior**
Just to test after installation, I tried importing Tensorflow in Python, but got an unexpected error (see Code section) .

**Describe the expected behavior**
Needs fixing the problem......

E:\Development\iShaft\iShaft-Trading-Bot\iShaft.Python>python prototype.py
C:\Program Files (x86)\Python36\lib\site-packages\pandas_datareader\compat\__init__.py:7: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.
  from pandas.util.testing import assert_frame_equal

E:\Development\iShaft\iShaft-Trading-Bot\iShaft.Python>python prototype.py
C:\Program Files (x86)\Python36\lib\site-packages\pandas_datareader\compat\__init__.py:7: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.
  from pandas.util.testing import assert_frame_equal
Traceback (most recent call last):
  File ""C:\Program Files (x86)\Python36\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Program Files (x86)\Python36\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Program Files (x86)\Python36\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Program Files (x86)\Python36\lib\imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Program Files (x86)\Python36\lib\imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""prototype.py"", line 12, in <module>
    from tensorflow import keras
  File ""C:\Program Files (x86)\Python36\lib\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""C:\Program Files (x86)\Python36\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Program Files (x86)\Python36\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Program Files (x86)\Python36\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Program Files (x86)\Python36\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Program Files (x86)\Python36\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Program Files (x86)\Python36\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Program Files (x86)\Python36\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Program Files (x86)\Python36\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Program Files (x86)\Python36\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Program Files (x86)\Python36\lib\imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Program Files (x86)\Python36\lib\imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help."
36956,Java.lang.ArrayIndexOutOfBoundsException: length=66049; index=66049,"I'm facing this error while integrating my custom Nails Segmentation Model with the app.

Other models are working find but whenever I use custom model app crashes and give above mentioned error.

Error in bellow while loop
`while (segmentedImage.hasRemaining()){
             outFrame[i++] = segmentedImage.int
        }`

**Android App Code to Reproduce this error:**
I have upload the stand alone code on [this ](https://drive.google.com/open?id=1WQ9LmAqJpxMwZIHtzMxRP2j6nq1Ga2lD)link which produce this error.

**System Information**
OS Platform and Distribution: Windows 10
Mobile device: Samsung Galaxy
TensorFlow version: Tensorflow Version installed on system is 1.15.0
Tensorflow Dependency using in android gradle file is: `implementation('org.tensorflow:tensorflow-lite:0.0.0-nightly') { changing = true }` 
TFlite Nails Detection Model file source: [Nail Detection Model](https://github.com/makeml-app/MakeML-Nails/tree/master/Segmentation%20Nails/Resources)



**Expected Behavior:**
Expected Behavior is showing in this [link](https://github.com/makeml-app/MakeML-Nails). 

**Current Behavior**
Currently when the camera view is open App crashes when the model start nails detection.
Exception throw in above while loop.
If I hide this above while loop then app is not crashing but not detecting nails and place colors on that.

What I need to change to get rid from this error ?

Thanks.
"
36954,"I got This error by upgrading to TensorFlow 2.1: ""AttributeError: 'Operation' object has no attribute '_graph'"" .","My code is written under TensorFlow 2.0 and I run it on Ubuntu 18.04.04. The code is perfectly run with TensorFlow 2.0. But I need to use TensorFlow 2.1 because of some functionality of TensorFlow_addones library.  I upgrade the Tensorflow within my virtual environment by the command "" conda install tensorflow-gpu"" and run the code. The code run for the first epoch and save the result but as soon as it starts next epoch, it stop and show this error.
If I downgrade the TensorFlow to 2.0, again the code run without any problem. Does anybody know what is the issue?
"
36953,MultiWorkerMirroredStrategy failed to run after a few batches occasionally,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): YES
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): TensorFlow 2.0 Ubuntu 18.04 official image
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38
- Python version: - Bazel
version (if compiling from source): 3.6.8
- GCC/Compiler version (if compiling from
source): 
- CUDA/cuDNN version: - GPU model and memory: CUDA 10.1 16GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
``` W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at collective_ops:234 : Aborted: The same RecvBuf (GrpcWorker) request was received twice.```
**Describe the expected behavior**
Should be able to train on each run.
**Standalone code to reproduce the issue** 
https://github.com/calmisential/TensorFlow2.0_ResNet
I modified some code to make it run with different distribute strategy.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
36950,How to use tensorflow2 keras model on java?,"i use keras to build my model on tf2
in tf1, keras.backend.get_session(), then create .pb file for java calling
please show me the solution of tf2"
36949,TF2.0 - why does this keras model learn data which is explicitly avoided in the loss?,"I do not understand, how does a trained model learn values not influencing the loss function as given below by a minimal example. I am avoiding the error computation of corrupted data but my model still learns that corrupted data. I want to understand what is happening.

Suppose you have the following data for a function f(x) with input x (4 data points, input is 3-dimensional, output is 2-dimensional)

```
#%% Import
import numpy as np
import tensorflow as tf

#%% Data
x = np.array([
     [1,1,1]
     ,[1,1,2]
     ,[1,2,1]
     ,[1,2,2]
     ])

x = (x-np.mean(x,axis=0))

f = np.array([
     [5,10]
     ,[6,50]
     ,[4,-30]
     ,[7,-30]
     ])

d_f = 2
```

Suppose you want to train a keras model on this data, and the data values for f are corrupt in the last two data points in the second dimension. That means, I do NOT trust the number -30 (corrupted data). I still want to train a keras model. For that, I simply build a custom loss function which takes the mean squared error in the first 2 data points ([5,10] and [6,50]) and then only the square error in the last 2 data points ONLY IN THE FIRST COLUMN (from [4,-30] only [4] and from [7,-30] only [7]).

```
#%% Model with custom loss

model = tf.keras.Sequential([
    tf.keras.layers.Dense(16,activation='softplus')
    ,tf.keras.layers.Dense(16,activation='softplus')
    ,tf.keras.layers.Dense(d_f)
    ])

def myloss(f,f_m):
    f = tf.keras.backend.cast(f,tf.float32)
    ds = (f-f_m)**2
    ok = tf.keras.backend.mean(ds[0:2],axis=-1)
    corrupted = ds[2:,0]
    return tf.keras.backend.concatenate([ok,corrupted])

model.compile(
    optimizer='adam'
    ,loss=myloss
    )

print('Keras - evaluated loss:\n\t%.8f' % model.evaluate(x,f,verbose=0))
f_m = model.predict(x)
ds = (f-f_m)**2
myloss_output = np.concatenate([np.mean(ds[:2],axis=-1),ds[2:,0]])
print('Check f, f_m and myloss_output')
print(f)
print(f_m)
print(myloss_output)
print('Manually computed mean:\n\t%.8f' % np.mean(myloss_output))
```

My custom function myloss does what it should (mse w.r.t the first two data points and squared error w.r.t. the last two). The evaluation returns the mean over the computations, see code above. Deviations w.r.t. to the number -30 DO NOT APPEAR IN THE OUTPUT OF MYLOSS. The thing I do NOT understand here is that when I train the model, the trained model also approximates -30, although this is not in the output of myloss (see final code below).

**1) Why is that?**

**2) How can I prevent it?**

**3) How can I train the model with the provided data such that after training I can see, what the model learned by itself for the positions of the corrupted data (-30)?**

```
#%% Train and check predictions

model.fit(x,f,epochs=1500,verbose=2,batch_size=len(x))

# I do not understand, why the components f[2:,1] are ALSO trained, although the custom loss does not contain them
print(f)
print(model.predict(x))


# Output in console
[[  5  10]
 [  6  50]
 [  4 -30]
 [  7 -30]]
[[  4.269913   16.358786 ]
 [  6.6172767  45.615295 ]
 [  4.704413  -35.412888 ]
 [  6.408976  -25.318275 ]]
```"
36948,Simpler way to avoid the UserWarning: Converting sparse IndexedSlices,"

I have a rnn network structure that looks like following

        cells = rnn.MultiRNNCell(
            [self._one_rnn_cell(l + 1) for l in range(self.layers)],
            state_is_tuple=True
        ) if self.layers > 1 else self._one_rnn_cell(1)


        out, _ = tf.nn.dynamic_rnn(cells, self.inputs,
                                   dtype=tf.float32, scope=""DyRNN"")
        out = tf.transpose(out, [1, 0, 2])
        num_time_steps = int(out.get_shape()[0])
        last_state = tf.gather(out, num_time_steps - 1, name=""last_lstm_state"")

Here while I am running the code, I am getting the following warning.

    UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory. ""Converting sparse IndexedSlices to a dense Tensor of unknown shape. ""

Now I understand why this error is coming. I tried out several ideas and the most common one is the following

How to deal with UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape

But the problem is this requires too many variable like

max_length time_steps seq_length n_dim partitions

this make the code very unreadable. I wanted to know if there is a simpler way I can avoid the problem.

Also if the sequence length remain same across all the batches, can I assume max_length == time_steps == seq_length ?

Please help, documentation is very less.

**Note:** I added this question in stackoverflow [here](https://stackoverflow.com/questions/60269407/simpler-way-to-avoid-the-userwarning-converting-sparse-indexedslices) but haven't received any replies yet. 
"
36945,ImportError after installing 2.1.0 on OSX Catalina 10.15.2 (From binary and source),"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OSX Catalina 10.15.2
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Binary AND source
- TensorFlow version: 2.1.0 (switched to branch r2.1.0)
- Python version: 3.7.6
- Installed using virtualenv? pip? conda?: pip (pip3 on my system)
- Bazel version (if compiling from source): 2.1.0
- GCC/Compiler version (if compiling from source): Apple clang version 11.0.0 (clang-1100.0.33.17)
- CUDA/cuDNN version:
- GPU model and memory: Intel UHD (using MacBookPro GPU not compatible)



**Describe the problem**
After successfully installing Tensorflow via pip or compiling Tensorflow from source, importing the Tensorflow2.1.0 package fails with the error below on OSX Catalina 10.15.2 (CPU = 2.6 GHz 6-Core Intel Core i7). Running `pip install tensorflow==2.0.0` works fine. I've tried installing `pywrap` with `pip3 install pywrap` but this does not fix the issue.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
PIP instructions:
1. `pip3 install tensorflow` (Tried `--user`, `--upgrade` and installing with `pip` as well)
2. `python3`
3. `>>> import tensorflow as tf`

Compilation instructions:
1. `git clone https://github.com/tensorflow/tensorflow.git & cd tensorflow`
2. `git checkout branch_name r2.1.0`
3. `./configure` setting python version as `/usr/local/bin/python3` and everything else as defaults
4.  `bazel build //tensorflow/tools/pip_package:build_pip_package`
5. `./bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg`
6. `pip install /tmp/tensorflow_pkg/tensorflow-2.1.0-cp37-cp37m-macosx_10_15_x86_64.whl`
7. `python3`
8. `>>> import tensorflow`

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

ERROR PRODUCED:
```
>>> import tensorflow as tf
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/__init__.py"", line 50, in <module>
    from tensorflow.python import _pywrap_utils
ImportError: dlopen(/usr/local/lib/python3.7/site-packages/tensorflow_core/python/_pywrap_utils.so, 2): Symbol not found: __ZN10tensorflow4swig10IsSequenceEP7_object
  Referenced from: /usr/local/lib/python3.7/site-packages/tensorflow_core/python/_pywrap_utils.so
  Expected in: flat namespace
 in /usr/local/lib/python3.7/site-packages/tensorflow_core/python/_pywrap_utils.so
```

"
36943,"assertion ""exponent <= 31"" failed while executing interpreter->Invoke()","@tensorflow/micro

**System information**
- Host OS Platform and Distribution: Windows 10
- TensorFlow installed from binary
- Tensorflow version: TF 2.0.0
- Target platform: M5Stack (ESP32)


**Description of the problem:**

I'm working on a CNN model that tries to detect a situation that occurs to patient with Parkinson disease. Based on accelerometers values, I try to detect the appearance of this situation with a CNN.
I trained a model with the Python version of TF, and I converted the model into a .tflite file that I'm using to put the model on a M5Stack microcontroller.

When I execute a basic program consisting in giving an input to my model on the microcontroller, this error is sent through the serial monitor:

> assertion ""exponent <= 31"" failed: file ""lib\tfmicro/fixedpoint/fixedpoint.h"", line 359, function: IntegerType gemmlowp::RoundingDivideByPOT(IntegerType, int) [with IntegerType = int]

It seems to happen when the ""interpreter->Invoke()"" part of the code is executed. 


**How I ran into the problem:**

The code in which I'm using the model on the microcontroller is based the the helloworld example. I'm simply just creating a sample user input, loading the model, and trying to invoke the interpreter on the sample data, but I get the ""assertion failed"" error.

I'm getting the error when the following part of the code is executed:
```cpp
if (interpreter->Invoke() != kTfLiteOk)
{
    M5.Lcd.println(""There was an error invoking the interpreter!"");
    return;
}
```
On this code, the message is not even printed, the ""assertion failed"" comes from the execution of *interpreter->Invoke()*.
This error makes my microcontroller reboot, again and again.

The repository https://github.com/GlennWasAlreadyTaken/CNN_M5Stack contains my whole project. 
In the cnn folder, you'll find the Python script I made for the training of the model and conversion to tflite file. You'll also find the weights (.h5), and the converted file (tflite) and the C array (.cc).
The M5StackCNN folder contains the code for the microcontroller, that should run the model. I use Platformio in order to deploy the program on the M5Stack.
You'll find the main code for the microcontroller in M5StackCNN/src/main.cpp.

Thank you in advance."
36940,typo or bug in documentation,"https://www.tensorflow.org/tutorials/quickstart/advanced

This page has an example class ""MyModel"".  When it is invoked further down the page, it is invoked with a ""training"" keyword argument that does not appear to be in the definition.

Slavishly copying the code produces this error:

```
TypeError: in converted code:

    tf/tutorial.py:61 train_step *
        predictions = model(images, training=True)
    /usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:634 __call__
        outputs = call_fn(inputs, *args, **kwargs)

    TypeError: tf__call() got an unexpected keyword argument 'training'
```

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): NO, this is as appears on doc page.
Using singularity, with docker://tensorflow/tensorflow.

When I remove the 'training' keyword, the operation executes, though I don't know if it's going to come out correctly or not. What is it supposed to do?

```
Singularity tf-py3.simg:~/projects> python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"" 
('v1.14.0-rc1-22-gaf24dc91b5', '1.14.0')
Singularity tf-py3.simg:~/projects> 
```


- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): 
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): 
- Python version: - Bazel
version (if compiling from source):
- GCC/Compiler version (if compiling from
source): 
- CUDA/cuDNN version: - GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
36937,Tensorflow 2.1.0 2.1.0-rc0 2.1.0-rc2 causes SIGSEGV when is used with textgenrnn,"Hi All,

I have a problem when I build TensorFlow 2.1.0 2.1.0-rc0 2.1.0-rc2 from sources on CentOS 7
build is successfully compiled without any problems but when trying to learn from a text file with textgenrnn package
it causes SIGSEGV error, you can see the log from gdb same on mentioned versions

```
Missing separate debuginfos, use: debuginfo-install python3-3.6.8-10.el7.x86_64
(gdb) run ./train-sources.py -k půjčky-limited
Starting program: /usr/bin/python3 ./train-sources.py -k půjčky-limited
[Thread debugging using libthread_db enabled]
Using host libthread_db library ""/lib64/libthread_db.so.1"".
[New Thread 0x7fffecf3f700 (LWP 27545)]
[New Thread 0x7fffec73e700 (LWP 27546)]
[New Thread 0x7fffe9f3d700 (LWP 27547)]
warning: File ""/usr/lib64/libstdc++.so.6.0.27-gdb.py"" auto-loading has been declined by your `auto-load safe-path' set to ""$debugdir:$datadir/auto-load:/usr/bin/mono-gdb.py"".
To enable execution of this file add
        add-auto-load-safe-path /usr/lib64/libstdc++.so.6.0.27-gdb.py
line to your configuration file ""/home/jpuchky/.gdbinit"".
To completely disable this security protection add
        set auto-load safe-path /
line to your configuration file ""/home/jpuchky/.gdbinit"".
For more information about this security protection see the
""Auto-loading safe path"" section in the GDB manual.  E.g., run from the shell:
        info ""(gdb)Auto-loading safe path""
[Thread 0x7fffec73e700 (LWP 27546) exited]
[Thread 0x7fffe9f3d700 (LWP 27547) exited]
[Thread 0x7fffecf3f700 (LWP 27545) exited]
Detaching after fork from child process 27777.
Detaching after fork from child process 27779.
[New Thread 0x7fffe9f3d700 (LWP 27893)]
[New Thread 0x7fffec73e700 (LWP 27894)]
[New Thread 0x7fffecf3f700 (LWP 27895)]
[New Thread 0x7fffb95aa700 (LWP 27896)]
[New Thread 0x7fffb8da9700 (LWP 27897)]
[New Thread 0x7fffa3fff700 (LWP 27898)]
[New Thread 0x7fffa37fe700 (LWP 27899)]
[New Thread 0x7fffa2ffd700 (LWP 27900)]
2020-02-20 19:06:27.583250: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2594220000 Hz
[Thread 0x7fffa37fe700 (LWP 27899) exited]
[New Thread 0x7fffa37fe700 (LWP 27901)]
[New Thread 0x7fffa27fc700 (LWP 27902)]
[New Thread 0x7fffa1ffb700 (LWP 27903)]
[New Thread 0x7fffa17fa700 (LWP 27904)]
2020-02-20 19:06:27.588578: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x34fe630 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-20 19:06:27.588620: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[New Thread 0x7fffa0ff9700 (LWP 27905)]
[New Thread 0x7fff83fff700 (LWP 27906)]
[New Thread 0x7fff837fe700 (LWP 27907)]
[New Thread 0x7fff82ffd700 (LWP 27908)]
[New Thread 0x7fff827fc700 (LWP 27909)]

Program received signal SIGSEGV, Segmentation fault.
---Type <return> to continue, or q <return> to quit---
[Switching to Thread 0x7fffb8da9700 (LWP 27897)]
0x00007fffd8967b20 in Eigen::internal::TensorBlockIOV2<unsigned int, long, 2, 1>::Copy(Eigen::internal::TensorBlockIOV2<unsigned int, long, 2, 1>::Dst const&, Eigen::internal::TensorBlockIOV2<unsigned int, long, 2, 1>::Src const&, Eigen::DSizes<int, 2> const&) ()
   from /usr/local/lib64/python3.6/site-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
(gdb) 
```"
