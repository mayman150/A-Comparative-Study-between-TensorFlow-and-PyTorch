Issue Number,Issue Title,Issue Body
781,rotate an image for data augmentation," I would like to rotate an image from a random angle, for data augmentation. But I don't find this transformation in the tf.image module.

see: http://stackoverflow.com/questions/34801342/tensorflow-how-to-rotate-an-image-for-data-augmentation
"
780,Potential to add tf.image.rotate?,"I experimented with the CIFAR10 example. I noticed that they have very good transformation functions. For example, flipping up down and left right. Would it be good if we add a rotate function? For example:

tf.image.rotate(image,angle)

where angle is the degrees to rotate by in the anti-clockwise direction. 
"
778,installation failed on redhat 5.7,"I installed tf from source code on redhat 5.7(I know it is a very old version), when I try to import tensorflow, it gives: anaconda/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so: ELF file OS ABI invalid
How can I solve that?
"
776,assertion failed: status == cudaSuccess in convolutional.py,"When trying to run convolutional.py on a Ubuntu 14.04 system with Titan, and CUDA Toolkit 7 and CUDNN 6.5, I get this error trying to run convolutional.py :  

 (tensorflow_env)sghosh@halaklin:~/anaconda/envs/tensorflow_env/lib/python2.7/site-packages/tensorflow$ python -m tensorflow.models.image.mnist.convolutional
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcublas.so.7.0 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcudnn.so.6.5 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcufft.so.7.0 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcurand.so.7.0 locally
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz
I tensorflow/core/common_runtime/local_device.cc:40] Local device intra op parallelism threads: 8
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:909] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:103] Found device 0 with properties: 
name: GeForce GTX TITAN
major: 3 minor: 5 memoryClockRate (GHz) 0.8755
pciBusID 0000:02:00.0
Total memory: 6.00GiB
Free memory: 5.15GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:127] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:137] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:702] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN, pci bus id: 0000:02:00.0)
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Allocating 4.86GiB bytes.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:52] GPU 0 memory begins at 0x600200000 extends to 0x737401000
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 16.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 32.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 64.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 128.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 256.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 512.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 16.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 32.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 64.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 128.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 256.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 512.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.00GiB
I tensorflow/core/common_runtime/direct_session.cc:58] Direct session inter op parallelism threads: 8
assertion failed: status == cudaSuccess in function void Eigen::initializeDeviceProp() at third_party/eigen3/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceType.h:464
Aborted (core dumped)
"
775,"TensorBoard ""Split on underscores"" does not split on underscores","No output to the terminal. No nothing. Running Chrome on Ubuntu 14.04 at 669790ac.
"
773,How to get the gradients of activations?,"In cifar10 example, the gradients of parameters can be got:
grads_and_vars = opt.compute_gradients(loss)
for grad, var in grads_and_vars:
    # ...

Is there any way to get the gradients of activations(not the parameters)， and watch them in Tensorboard?
"
772,Can't install current MASTER from source,"Hi!

I was trying to install a fresh install of the tensorflow master from source, but always run into an error:

```
$ bazel build -c opt --config=cuda  --verbose_failures --spawn_strategy=standalone //tensorflow/tools/pip_package:build_pip_package
```

Eventually fails with:

```
ERROR: /system/user/bioinf01/tom/sources/tensorflow/tensorflow/python/BUILD:71:1: C++ compilation of rule '//tensorflow/python:py_func_lib' failed: crosstool_wrapper_driver_is_not_
gcc failed: error executing command 
  (cd /system/user/unterthi/.cache/bazel/_bazel_unterthi/b4214462455bc5801962f5dfb9d41d3b/tensorflow && \
  exec env - \
    INTERCEPT_LOCALLY_EXECUTABLE=1 \
    PATH=/system/apps/biosoft/bazel-0.1.1/bazel-bin/src:/system/apps/biosoft/jdk1.8.0_40/bin:/usr/local/cuda/bin:/system/apps/biosoft/R-3.2.0/bin:/system/apps/biosoft/caffe_py351/d
istribute/bin:/system/apps/biosoft/lmdb-0.9.17/bin:/system/apps/biosoft/protobuf-3.0.0-alpha-3.1_py351/bin:/system/apps/biosoft/boost_1_59_0_py351/bin:/system/apps/biosoft/python-3
51/bin:/usr/local/cuda/bin:/system/apps/biosoft/R-3.2.0/bin:/system/apps/biosoft/caffe_py351/distribute/bin:/system/apps/biosoft/lmdb-0.9.17/bin:/system/apps/biosoft/protobuf-3.0.0
-alpha-3.1_py351/bin:/system/apps/biosoft/boost_1_59_0_py351/bin:/system/apps/biosoft/python-351/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/system
/user/unterthi/bin:/system/user/unterthi/bin \
  third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-fre
e-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++11' -iquote . -iquote bazel-out/local_linux-py3-opt/genfiles -isystem google/
protobuf/src -isystem bazel-out/local_linux-py3-opt/genfiles/google/protobuf/src -isystem tools/cpp/gcc3 -isystem external/jpeg_archive/jpeg-9a -isystem bazel-out/local_linux-py3-o
pt/genfiles/external/jpeg_archive/jpeg-9a -isystem external/png_archive/libpng-1.2.53 -isystem bazel-out/local_linux-py3-opt/genfiles/external/png_archive/libpng-1.2.53 -isystem ex
ternal/re2 -isystem bazel-out/local_linux-py3-opt/genfiles/external/re2 -isystem third_party/eigen3 -isystem bazel-out/local_linux-py3-opt/genfiles/third_party/eigen3 -isystem exte
rnal/eigen_archive/eigen-eigen-5651786d5e59 -isystem bazel-out/local_linux-py3-opt/genfiles/external/eigen_archive/eigen-eigen-5651786d5e59 -isystem third_party/py/numpy/numpy_incl
ude -isystem bazel-out/local_linux-py3-opt/genfiles/third_party/py/numpy/numpy_include -isystem util/python/python_include -isystem bazel-out/local_linux-py3-opt/genfiles/util/pyth
on/python_include -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' '-frandom-seed=bazel-out/local_li
nux-py3-opt/bin/tensorflow/python/_objs/py_func_lib/tensorflow/python/lib/core/py_func.pic.o' -MD -MF bazel-out/local_linux-py3-opt/bin/tensorflow/python/_objs/py_func_lib/tensorfl
ow/python/lib/core/py_func.pic.d -fPIC -c tensorflow/python/lib/core/py_func.cc -o bazel-out/local_linux-py3-opt/bin/tensorflow/python/_objs/py_func_lib/tensorflow/python/lib/core/
py_func.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1: crosstool_wrapper_driver_is_not_gcc failed: error executing command 
  (cd /system/user/unterthi/.cache/bazel/_bazel_unterthi/b4214462455bc5801962f5dfb9d41d3b/tensorflow && \
  exec env - \
    INTERCEPT_LOCALLY_EXECUTABLE=1 \
    PATH=/system/apps/biosoft/bazel-0.1.1/bazel-bin/src:/system/apps/biosoft/jdk1.8.0_40/bin:/usr/local/cuda/bin:/system/apps/biosoft/R-3.2.0/bin:/system/apps/biosoft/caffe_py351/d
istribute/bin:/system/apps/biosoft/lmdb-0.9.17/bin:/system/apps/biosoft/protobuf-3.0.0-alpha-3.1_py351/bin:/system/apps/biosoft/boost_1_59_0_py351/bin:/system/apps/biosoft/python-3
51/bin:/usr/local/cuda/bin:/system/apps/biosoft/R-3.2.0/bin:/system/apps/biosoft/caffe_py351/distribute/bin:/system/apps/biosoft/lmdb-0.9.17/bin:/system/apps/biosoft/protobuf-3.0.0
-alpha-3.1_py351/bin:/system/apps/biosoft/boost_1_59_0_py351/bin:/system/apps/biosoft/python-351/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/system
/user/unterthi/bin:/system/user/unterthi/bin \
  third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-fre
e-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++11' -iquote . -iquote bazel-out/local_linux-py3-opt/genfiles -isystem google/
protobuf/src -isystem bazel-out/local_linux-py3-opt/genfiles/google/protobuf/src -isystem tools/cpp/gcc3 -isystem external/jpeg_archive/jpeg-9a -isystem bazel-out/local_linux-py3-o
pt/genfiles/external/jpeg_archive/jpeg-9a -isystem external/png_archive/libpng-1.2.53 -isystem bazel-out/local_linux-py3-opt/genfiles/external/png_archive/libpng-1.2.53 -isystem ex
ternal/re2 -isystem bazel-out/local_linux-py3-opt/genfiles/external/re2 -isystem third_party/eigen3 -isystem bazel-out/local_linux-py3-opt/genfiles/third_party/eigen3 -isystem exte
rnal/eigen_archive/eigen-eigen-5651786d5e59 -isystem bazel-out/local_linux-py3-opt/genfiles/external/eigen_archive/eigen-eigen-5651786d5e59 -isystem third_party/py/numpy/numpy_incl
ude -isystem bazel-out/local_linux-py3-opt/genfiles/third_party/py/numpy/numpy_include -isystem util/python/python_include -isystem bazel-out/local_linux-py3-opt/genfiles/util/pyth
on/python_include -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' '-frandom-seed=bazel-out/local_li
nux-py3-opt/bin/tensorflow/python/_objs/py_func_lib/tensorflow/python/lib/core/py_func.pic.o' -MD -MF bazel-out/local_linux-py3-opt/bin/tensorflow/python/_objs/py_func_lib/tensorfl
ow/python/lib/core/py_func.pic.d -fPIC -c tensorflow/python/lib/core/py_func.cc -o bazel-out/local_linux-py3-opt/bin/tensorflow/python/_objs/py_func_lib/tensorflow/python/lib/core/
py_func.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 118.584s, Critical Path: 32.92s
```

Running that last command myself to see the GCC error message gives:

```
$ third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstac
k-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++11' -iquote . -iqu
ote bazel-out/local_linux-py3-opt/genfiles -isystem google/protobuf/src -isystem bazel-out/local_linux-py3-opt/genfiles/google/protobuf/src -isystem tools/cpp/gcc3 -isystem externa
l/jpeg_archive/jpeg-9a -isystem bazel-out/local_linux-py3-opt/genfiles/external/jpeg_archive/jpeg-9a -isystem external/png_archive/libpng-1.2.53 -isystem bazel-out/local_linux-py3-
opt/genfiles/external/png_archive/libpng-1.2.53 -isystem external/re2 -isystem bazel-out/local_linux-py3-opt/genfiles/external/re2 -isystem third_party/eigen3 -isystem bazel-out/lo
cal_linux-py3-opt/genfiles/third_party/eigen3 -isystem external/eigen_archive/eigen-eigen-5651786d5e59 -isystem bazel-out/local_linux-py3-opt/genfiles/external/eigen_archive/eigen-
eigen-5651786d5e59 -isystem third_party/py/numpy/numpy_include -isystem bazel-out/local_linux-py3-opt/genfiles/third_party/py/numpy/numpy_include -isystem util/python/python_includ
e -isystem bazel-out/local_linux-py3-opt/genfiles/util/python/python_include -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""
' '-D__TIME__=""redacted""' '-frandom-seed=bazel-out/local_linux-py3-opt/bin/tensorflow/python/_objs/py_func_lib/tensorflow/python/lib/core/py_func.pic.o' -MD -MF bazel-out/local_lin
ux-py3-opt/bin/tensorflow/python/_objs/py_func_lib/tensorflow/python/lib/core/py_func.pic.d -fPIC -c tensorflow/python/lib/core/py_func.cc -o bazel-out/local_linux-py3-opt/bin/tens
orflow/python/_objs/py_func_lib/tensorflow/python/lib/core/py_func.pic.o
In file included from ./tensorflow/core/public/tensor.h:19:0,
                 from ./tensorflow/python/lib/core/py_func.h:20,
                 from tensorflow/python/lib/core/py_func.cc:16:
./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1:90: fatal error: external/eigen_archive/eigen-eigen-5651786d5e59/unsupported/Eigen/CXX11/Tensor: No such file or directory
 #include ""external/eigen_archive/eigen-eigen-5651786d5e59/unsupported/Eigen/CXX11/Tensor""
                                                                                          ^
compilation terminated.
```
"
771,Had issues running ./configure and bazel build commands,"I did not get any error when I ran ./configure but when i ran 

bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer

I get following error 

Sending SIGTERM to previous Bazel server (pid=2919)... done.
........
INFO: Found 1 target...
INFO: From Compiling external/re2/re2/compile.cc:
src/main/tools/namespace-sandbox.c:633: execvp(argv[0], argv): No such file or directory
ERROR: /home/ushnish/.cache/bazel/_bazel_ushnish/f442d11296e91085e26406d3023541ae/external/re2/BUILD:9:1: C++ compilation of rule '@re2//:re2' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object ... (remaining 34 argument(s) skipped).
Target //tensorflow/cc:tutorials_example_trainer failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 9.317s, Critical Path: 1.97s

I was actually able to solve this problem and successfully run TF with GPUs by following exactly the instructions on this page, which did not mention ./configure or the bazel build command

https://groups.google.com/a/tensorflow.org/forum/#!topic/discuss/jRkkvsB1iWA

Please reflect these instructions or some modified version of the instructions on the Getting Started page of Tensorflow as this particular step caused a lot of grief :)
"
769,"""Deep MNIST for Experts"" too complex for second tutorial.","The end of the first tutorial, ""MNIST for ML Beginners"", has this paragraph:

> What matters is that we learned from this model. Still, if you're feeling a bit down about these results, check out [the next tutorial](https://www.tensorflow.org/versions/master/tutorials/mnist/pros/index.html#deep-mnist-for-experts) where we do a lot better, and learn how to build more sophisticated models using TensorFlow!

But the next tutorial is ""Deep MNIST for Experts"", and it does not explain things nearly as well as the first tutorial. For example, the second tutorial starts differing at the `Build a Multilayer Convolutional Network` section, but the very first paragraph under `Weight Initialization` does not explain the concepts it is using:

> To create this model, we're going to need to create a lot of weights and biases. One should generally initialize weights with a small amount of noise for symmetry breaking, and to prevent 0 gradients. Since we're using ReLU neurons, it is also good practice to initialize them with a slightly positive initial bias to avoid ""dead neurons."" Instead of doing this repeatedly while we build the model, let's create two handy functions to do it for us.

What are ""ReLU neurons""? Why are we using them? What _is_ a convolutional network even?

I would say, either
1. This tutorial should be expanded to clarify/explain things better for beginners, or
2. This tutorial should be moved to later in the list of tutorials, and
3. The first tutorial, ""MNIST for Beginners,"" should not say `the next tutorial` but instead say `a later tutorial on MNIST for Experts`.

Thanks!
"
766,Running TensorFlow on GTX 480 (Compute capability 2.0),"I'm trying to make tensorflow run on an older GPU (GTX 480). So I removed the compute checking condition in gpu_device.cc like this:

``` C
       // Only GPUs with no less than the minimum supported compute capability is
      // accepted.
      //if (device_capability < min_supported_capability) {
      //  LOG(INFO) << ""Ignoring gpu device ""
      //            << ""("" << GetShortDeviceDescription(i, desc) << "") ""
      //            << ""with Cuda compute capability "" << device_capability
      //            << "". The minimum required Cuda capability is ""
      //            << min_supported_capability << ""."";
      //  continue;
      //}
```

And run the cifar10_train.py
I got the errors as following: 

``` C
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 2.00GiB
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 2424 get requests, put_count=2259 evicted_count=1000 eviction_rate=0.442674 and unsatisfied allocation rate=0.521865
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:257] Raising pool_size_limit_ from 100 to 110
W tensorflow/core/common_runtime/executor.cc:1075] 0x206ad80 Compute status: Invalid argument: Indices are not valid: not lexicographically sorted or containing repeats.
     [[Node: SparseToDense = SparseToDense[T=DT_FLOAT, Tindices=DT_INT32, validate_indices=true, _device=""/job:localhost/replica:0/task:0/cpu:0""](concat/_195, SparseToDense/output_shape/_197, SparseToDense/sparse_values/_199, SparseToDense/default_value/_201)]]
W tensorflow/core/common_runtime/executor.cc:1075] 0x35962a0 Compute status: Invalid argument: Indices are not valid: not lexicographically sorted or containing repeats.
     [[Node: SparseToDense = SparseToDense[T=DT_FLOAT, Tindices=DT_INT32, validate_indices=true, _device=""/job:localhost/replica:0/task:0/cpu:0""](concat/_195, SparseToDense/output_shape/_197, SparseToDense/sparse_values/_199, SparseToDense/default_value/_201)]]
     [[Node: SparseToDense/_203 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_474_SparseToDense"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""]()]]

```

I'm guessing if tensorflow is trying to allocate more memory than supported?
"
762,tutorials_example_trainer working for cpu not gpu (built from source),"I am trying to install TF from source WITHOUT INTERNET so far I have been able to advance thanks to @damienmg by replacing git repos by local repos for re2,gemmlowp,libpng,jpegsvrc and eigen and modifying WORKSPACE accordingly.  
The `bazel build -c opt  //tensorflow/cc:tutorials_example_trainer` cmd for tutorials_example_trainer works fine (with a few warnings due to comparison between signed and unsigned entities and index subscript above array bounds).
And `bazel-bin/tensorflow/cc/tutorials_example_trainer` produces the expected result.
However when I clean up with `bazel clean --expunge` and rerun ./configure for GPU support and then run:  
`bazel build -c opt config=cuda //tensorflow/cc:tutorials_example_trainer`  
I get the error messages :  
`'@gemmlowp//:eight_bit_int_gemm' failed: crosstool_wrapper_driver-is_not_gcc failed: error executing command third_party/gpus/crosstool/cleang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D FORTIFY_SOURCE=1' fstack-protector -fpIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object`  
or the same with `'@re2//:re2'`
"
761,Optimizer got only float32?,"Got some big number so thought dtype float64 must be able to embrace a larger range. Everything looks fine until it comes to define the optimisation. I got this error:

```
site-packages/tensorflow/python/training/optimizer.py(343)_assert_valid_dtypes()
    342             ""Invalid type %r for %s, expected: %s."" % (
--> 343                 dtype, t.name, [v for v in valid_dtypes]))
    344 

ipdb> l
    338     for t in tensors:
    339       dtype = t.dtype.base_dtype
    340       if dtype not in valid_dtypes:
    341         raise ValueError(
    342             ""Invalid type %r for %s, expected: %s."" % (
--> 343                 dtype, t.name, [v for v in valid_dtypes]))
    344 
    345   # --------------
    346   # Methods to be implemented by subclasses if they want to use the
    347   # inherited implementation of apply_gradients() or compute_gradients().
    348   # --------------

ipdb> t
<tensorflow.python.framework.ops.Tensor object at 0x110b40630>
ipdb> t.dtype.base_dtype
tf.float64
ipdb> t.dtype
tf.float64
```

Looks like only tf.float32 accepted in this snippet? Can this be fixed?
"
760,"word2vec_basic.py line 54, yield instead of return","```
# Read the data into a string.
def read_data(filename):
  f = zipfile.ZipFile(filename)
  for name in f.namelist():
    return f.read(name).split() ### SHOULD BE: yeild  f.read(name).split()?
  f.close()
```

Oringial sample data got one big txt file in the zip file. 

```
def read_data(filename):
  with zipfile.ZipFile(filename) as f:
    for name in f.namelist():
      yield f.read(name).split() 
```
"
759,ImportError: No module named tensorflow after installing from sources,"I installed TF from sources because I do not have an internet access. I used @damienmg tricks to replace git repositories by internal sources for eigen, six, gemmlowp, re2, libpng and jpegsvrc.
Finally the line `bazel build -c opt //tensorflow/cc:tutorials_example_trainer` compiled successfully (however there were several warnings of index subscript above limits and comparison between signed and unsigned (I figure it is because it is a beta version of eigen)).  
And I ran the example `bazel-bin/tensorflow/cc/tutorials_example_trainer`  
It ran and the end line was :  
`000002/000005 lambda=2.000000 x =[0.894427 -0.447214] y =[1.788854 -0.894427]`  
However when I try to run python wherever `import tensorflow` fails with error no module named tensorflow (I am using anaconda if it is important and when I ran the configure the path for python was correct).  
Where do you think I got it wrong ?
"
758,[RBM implemention] Problem with GraphDef cannot be larger than 2GB ?,"Hi, everyone
I'm trying to implement RBM with tensorflow, here is the code:

rbm.py

"""""" An rbm implementation for TensorFlow, based closely on the one in Theano """"""

import tensorflow as tf
import math

def sample_prob(probs):
    """"""Takes a tensor of probabilities (as from a sigmoidal activation)
       and samples from all the distributions""""""
    return tf.nn.relu(
        tf.sign(
            probs - tf.random_uniform(probs.get_shape())))

class RBM(object):
    """""" represents a sigmoidal rbm """"""

```
def __init__(self, name, input_size, output_size):
    with tf.name_scope(""rbm_"" + name):
        self.weights = tf.Variable(
            tf.truncated_normal([input_size, output_size],
                stddev=1.0 / math.sqrt(float(input_size))), name=""weights"")
        self.v_bias = tf.Variable(tf.zeros([input_size]), name=""v_bias"")
        self.h_bias = tf.Variable(tf.zeros([output_size]), name=""h_bias"")

def propup(self, visible):
    """""" P(h|v) """"""
    return tf.nn.sigmoid(tf.matmul(visible, self.weights) + self.h_bias)

def propdown(self, hidden):
    """""" P(v|h) """"""
    return tf.nn.sigmoid(tf.matmul(hidden, tf.transpose(self.weights)) + self.v_bias)

def sample_h_given_v(self, v_sample):
    """""" Generate a sample from the hidden layer """"""
    return sample_prob(self.propup(v_sample))

def sample_v_given_h(self, h_sample):
    """""" Generate a sample from the visible layer """"""
    return sample_prob(self.propdown(h_sample))

def gibbs_hvh(self, h0_sample):
    """""" A gibbs step starting from the hidden layer """"""
    v_sample = self.sample_v_given_h(h0_sample)
    h_sample = self.sample_h_given_v(v_sample)
    return [v_sample, h_sample]

def gibbs_vhv(self, v0_sample):
    """""" A gibbs step starting from the visible layer """"""
    h_sample = self.sample_h_given_v(v0_sample)
    v_sample = self.sample_v_given_h(h_sample)
    return  [h_sample, v_sample]

def cd1(self, visibles, learning_rate=0.1):
    "" One step of contrastive divergence, with Rao-Blackwellization ""
    h_start = self.propup(visibles)
    v_end = self.propdown(h_start)
    h_end = self.propup(v_end)
    w_positive_grad = tf.matmul(tf.transpose(visibles), h_start)
    w_negative_grad = tf.matmul(tf.transpose(v_end), h_end)

    update_w = self.weights.assign_add(learning_rate * (w_positive_grad - w_negative_grad))

    update_vb = self.v_bias.assign_add(learning_rate * tf.reduce_mean(visibles - v_end, 0))

    update_hb = self.h_bias.assign_add(learning_rate * tf.reduce_mean(h_start - h_end, 0))

    return [update_w, update_vb, update_hb]

def reconstruction_error(self, dataset):
    """""" The reconstruction cost for the whole dataset """"""
    err = tf.stop_gradient(dataset - self.gibbs_vhv(dataset)[1])
    return tf.reduce_sum(err * err)
```
###### 

rbm_MNIST_test.py

import tensorflow as tf
import numpy as np
import rbm
import input_data

def build_model(X, w1, b1, wo, bo):
    h1 = tf.nn.sigmoid(tf.matmul(X, w1)+b1)
    model = tf.nn.sigmoid(tf.matmul(h1, wo)+bo)
    return model

def init_weight(shape):
    return tf.Variable(tf.random_normal(shape, mean=0.0, stddev=0.01))

def init_bias(dim):
    return tf.Variable(tf.zeros([dim]))

mnist = input_data.read_data_sets(""MNIST_data/"", one_hot=True)
trX, trY, teX, teY = mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labels

X = tf.placeholder(""float"", [None, 784])
Y = tf.placeholder(""float"", [None, 10])

rbm_layer = rbm.RBM(""mnist"", 784, 500)

for i in range(10):
    print ""RBM CD: "", i
    rbm_layer.cd1(trX)

rbm_w, rbm_vb, rbm_hb = rbm_layer.cd1(trX)

wo = init_weight([500,10])
bo = init_bias(10)
py_x = build_model(X, rbm_w, rbm_hb, wo, bo)

cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(py_x, Y))
train_op = tf.train.GradientDescentOptimizer(0.05).minimize(cost)
predict_op = tf.argmax(py_x, 1)

sess = tf.Session()
init = tf.initialize_all_variables()
sess.run(init)

for i in range(10):
    for start, end in zip(range(0, len(trX), 128), range(128, len(trX), 128)):
        sess.run(train_op, feed_dict={X: trX[start:end], Y: trY[start:end]})
    print i, np.mean(np.argmax(teY, axis=1) ==
                     sess.run(predict_op, feed_dict={X: teX, Y: teY}))
###### 

but here comes the error:

File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1626, in as_graph_def
    raise ValueError(""GraphDef cannot be larger than 2GB."")
ValueError: GraphDef cannot be larger than 2GB.

Can someone help me to solve?
"
757,Tensor indexing issue,"How to make confusion matrix with tensorflow?
is it possible or is there any work-around for the 
following code

```
nb_classes = 4
nb_samples = 10
a_ = np.random.randint(0, high=nb_classes, size=(nb_samples,))
b_ = np.random.randint(0, high=nb_classes, size=(nb_samples,))

conf_mat = tf.zeros([nb_classes, nb_classes], tf.int32)

for i in xrange(nb_samples):
    #conf_mat[a[i]][b[i]] += 1
    # above one gives error so I tried to use gather
    # from https://github.com/tensorflow/tensorflow/issues/418
    # but problem with it is that we can't set the values
    # with gather
    tf.gather(tf.gather(conf_mat, a[i]), b[i]) += 1

init = tf.initialize_all_variables()
with tf.Session as sess:
    sess.run(init)
    sess.run(conf_mat, feed_dict={a=a_, b=b_})
```

The error I am getting is 

```
tf.gather(tf.gather(conf_mat, a[i]), b[i]) += 1
SyntaxError: can't assign to function call
```
"
755,Saver is broken,"Upon calling `self.saver.save(self.sess, os.path.join(checkpoint_dir, model_name), global_step=step)`, I get the following stack trace. 

```
Traceback (most recent call last):
  File ""main.py"", line 83, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/default/_app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""main.py"", line 50, in main
    dcgan.train(FLAGS)
  File ""/home/panmari/DCGAN-tensorflow/model.py"", line 140, in train
    self.save(config.checkpoint_dir, counter)
  File ""/home/panmari/DCGAN-tensorflow/model.py"", line 245, in save
    global_step=step)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 886, in save
    self.last_checkpoints, latest_filename)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 485, in update_checkpoint_state
    elif all_model_checkpoint_paths[-1] != model_checkpoint_path:
IndexError: list index out of range
```

The problem lies in this line:
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/saver.py#L483

`all_model_checkpoint_paths` passed is not none, but an empty list, leading to the wrong branch of this if statement.
"
754,Allow sessions to be started in cpu-only mode.,"I would find it convenient to be able to start a session in cpu only mode (e. g. because you have another session running already that hogs all the VRAM). My workaround for now is to use

```
gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.01)
with tf.Session(config=tf.ConfigProto(log_device_placement=True, gpu_options=gpu_options)) as sess:
```

And then wrap `with tf.device('/cpu:0'):` around the model construction.
"
752,Using a model (post training),"I've trained a simple model of my own in python, categorizing images into two categories (Imagenet apples, vs imagenet oranges). I'm looking to now evaluate arbitrary images using this model to get a prediction (apples v oranges) and I'm having trouble finding out the right way to do that for some reason.

At the moment I'm just using a random training image for simplicity.

``` Python
# Use the existing graph and grab a sample image from the valid dataset.
tf_image = tf_valid_dataset[1001,:,:,:] 
result = tf.Session(graph=graph).run(tf_image)
```

I was trying to look at some of the API docs and the C++ imagenet example as inspiration, but I think I'm off track. `result` ends up being tf_image it seems.

I know that I want the result of a single forward pass, but having a hard time seeing the right way to get that.
"
751,Saver seems broken: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model.ckpt-0,"Updated to the last commit of 1/11. Saver seems broken. Here is the stack. 

File ""cnn_eval.py"", line 132, in evaluate
    eval_once(saver, summary_writer, logits, top_k_op,labels, names, prob, summary_op)
  File ""cnn_eval.py"", line 43, in eval_once
    saver.restore(sess, ckpt.model_checkpoint_path)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 904, in restore
    sess.run([self._restore_op_name], {self._filename_tensor_name: save_path})
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 388, in run
    results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 464, in _do_run
    e.code)
tensorflow.python.framework.errors.NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model.ckpt-0
         [[Node: save/restore_slice_2 = RestoreSlice[dt=DT_FLOAT, preferred_shard=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""](_recv_save/Const_0, save/restore_slice_2/tensor_name, save/restore_slice_2/shape_and_slice)]]
Caused by op u'save/restore_slice_2', defined at:
  File ""cnn_eval.py"", line 147, in <module>
    tf.app.run()
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/platform/default/_app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""cnn_eval.py"", line 143, in main
    evaluate()
  File ""cnn_eval.py"", line 121, in evaluate
    saver = tf.train.Saver(variables_to_restore)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 723, in __init__
    restore_sequentially=restore_sequentially)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 432, in build
    filename_tensor, vars_to_save, restore_sequentially, reshape)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 191, in _AddRestoreOps
    values = self.restore_op(filename_tensor, vs, preferred_shard)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 106, in restore_op
    preferred_shard=preferred_shard)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/io_ops.py"", line 192, in _restore_slice
    preferred_shard, name=name)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/gen_io_ops.py"", line 271, in _restore_slice
    preferred_shard=preferred_shard, name=name)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py"", line 659, in apply_op
    op_def=op_def)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1882, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1081, in __init__
    self._traceback = _extract_stack()
"
750,"Adding new Ops, how to install it?","Okay I have added a new op as suggested in tutorial, however I can't find instruction to compile it. Will I have to use bazel to add it to the current TensorFlow framework (which already installed in my machine)? Do I have to re-build the whole framework or just the part that I have modified?
"
747,imagnet example classify_image.py results in `AttrValue missing value with expected type 'bool'`,"Hi,

after having gotten the mnist example to run, I tried the imagenet/classify_image.py, but the script results an `AttrValue missing value with expected type 'bool'` error.

I use a ec2 g2.2xlarge with GRID K520 and ubuntu 14.04. For the installation I used [erikbern's install-tensorflow.sh](https://gist.github.com/erikbern/78ba519b97b440e10640), but used the cuda 7.0 deb installer and installed Tensorflow master (22b6b23d9778fe7ef53e1597248558f21d1dda48) instead of 0.5.0.

This is the complete error message

``` bash
python classify_image.py
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcublas.so.7.0 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcudnn.so.6.5 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcufft.so.7.0 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcurand.so.7.0 locally
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:909] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:103] Found device 0 with properties:
name: GRID K520
major: 3 minor: 0 memoryClockRate (GHz) 0.797
pciBusID 0000:00:03.0
Total memory: 4.00GiB
Free memory: 3.95GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:127] DMA: 0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:137] 0:   Y
I tensorflow/core/common_runtime/gpu/gpu_device.cc:707] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GRID K520, pci bus id: 0000:00:03.0)
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:43] Allocating 3.66GiB bytes.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:53] GPU 0 memory begins at 0x7022a0000 extends to 0x7ec588000
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 1.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 2.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 4.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 8.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 16.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 32.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 64.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 128.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 256.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 512.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 1.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 2.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 4.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 8.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 16.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 32.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 64.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 128.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 256.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 512.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 1.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 2.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 4.00GiB
E tensorflow/core/framework/op_segment.cc:53] Create kernel failed: Invalid argument: AttrValue missing value with expected type 'bool'
         for attr 'align_corners'
        ; NodeDef: ResizeBilinear = ResizeBilinear[T=DT_FLOAT, align_corners=<Unknown AttrValue type>, _device=""/job:localhost/replica:0/task:0/cpu:0""](ExpandDims/_3, ResizeBilinear/size/_5); Op<name=ResizeBilinear; signature=images:T, size:int32 -> resized_images:float; attr=T:type,allowed=[DT_UINT8, DT_INT8, DT_INT16, DT_INT32, DT_INT64, DT_FLOAT, DT_DOUBLE]; attr=align_corners:bool,default=false>
E tensorflow/core/common_runtime/executor.cc:265] Executor failed to create kernel. Invalid argument: AttrValue missing value with expected type 'bool'
         for attr 'align_corners'
        ; NodeDef: ResizeBilinear = ResizeBilinear[T=DT_FLOAT, align_corners=<Unknown AttrValue type>, _device=""/job:localhost/replica:0/task:0/cpu:0""](ExpandDims/_3, ResizeBilinear/size/_5); Op<name=ResizeBilinear; signature=images:T, size:int32 -> resized_images:float; attr=T:type,allowed=[DT_UINT8, DT_INT8, DT_INT16, DT_INT32, DT_INT64, DT_FLOAT, DT_DOUBLE]; attr=align_corners:bool,default=false>
         [[Node: ResizeBilinear = ResizeBilinear[T=DT_FLOAT, align_corners=<Unknown AttrValue type>, _device=""/job:localhost/replica:0/task:0/cpu:0""](ExpandDims/_3, ResizeBilinear/size/_5)]]
Traceback (most recent call last):
  File ""classify_image.py"", line 214, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/default/_app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""classify_image.py"", line 210, in main
    run_inference_on_image(image)
  File ""classify_image.py"", line 173, in run_inference_on_image
    {'DecodeJpeg/contents:0': image_data})
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 388, in run
    results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 464, in _do_run
    e.code)
tensorflow.python.framework.errors.InvalidArgumentError: AttrValue missing value with expected type 'bool'
         for attr 'align_corners'
        ; NodeDef: ResizeBilinear = ResizeBilinear[T=DT_FLOAT, align_corners=<Unknown AttrValue type>, _device=""/job:localhost/replica:0/task:0/cpu:0""](ExpandDims/_3, ResizeBilinear/size/_5); Op<name=ResizeBilinear; signature=images:T, size:int32 -> resized_images:float; attr=T:type,allowed=[DT_UINT8, DT_INT8, DT_INT16, DT_INT32, DT_INT64, DT_FLOAT, DT_DOUBLE]; attr=align_corners:bool,default=false>
         [[Node: ResizeBilinear = ResizeBilinear[T=DT_FLOAT, align_corners=<Unknown AttrValue type>, _device=""/job:localhost/replica:0/task:0/cpu:0""](ExpandDims/_3, ResizeBilinear/size/_5)]]
Caused by op u'ResizeBilinear', defined at:
  File ""classify_image.py"", line 214, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/default/_app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""classify_image.py"", line 210, in main
    run_inference_on_image(image)
  File ""classify_image.py"", line 160, in run_inference_on_image
    create_graph()
  File ""classify_image.py"", line 143, in create_graph
    _ = tf.import_graph_def(graph_def, name='')
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.py"", line 243, in import_graph_def
    compute_shapes=False)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1882, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1081, in __init__
    self._traceback = _extract_stack()
```
"
744,`tf.zeros_like()` and `tf.ones_like()` do not preserve partial shape information,"For example:

``` python
>>> p = tf.placeholder(tf.float32, [None, 4])
>>> z = tf.zeros_like(p)
>>> z.get_shape()
TensorShape([Dimension(None), Dimension(None)])
```

This happens because `ConstantValue(shape(p))` can't be evaluated completely. We should set the shape of the returned tensor.
"
743,Where is conv2d implemented?,"I have been looking for the code of tf.nn.conv2d(...), so I looked in the directory tensorflow/python/ops/nn.py and the only things I found is 
""depthwise_conv2d""
AND
""separable_conv2d""
Can someone point me to the location of conv2d?
"
740,PC cold boots during MNIST example on GPU (GF980Ti); PSU problem; reduce load?,"After getting Tensorflow to work at all, now I've got another issue: I can run through the 20.000 training steps (within about 1 second; holy sh... that thing's fast) of the Deep MNIST example (code below). But after the last step my PC does a cold reboot. It just turns off hard without shutdown and reboots after a few seconds.

It appears to be caused by an undersized PSU. Gaming on the GPU however works fine so far... 

So, is there any way that I can reduce the load on the GPU during usage of Tensorflow? I'd be fine if the MNIST example took 2 seconds instead of 1 if only my PC wouldn't reboot. 

At the moment unfortunately I cannot afford a new PSU, spent my whole available budget on the GF980Ti. 

Any ideas? 
"
739,Does TensorFlow support Fast R-CNN currenly?,"I've been working on transplanting Fast R-CNN to a TensorFlow version. And I came across 2 problems as below:
1. In [roi_pooling_layer.cpp](https://github.com/rbgirshick/caffe-fast-rcnn/blob/fast-rcnn/src/caffe/layers/roi_pooling_layer.cpp), the C++ implementation of RoI Pooling layer, a dynamic variable `num_rois` is used to control a loop to process each roi of each picture. Its value is stored in the original dataset and will only be valid during the graph is running. However, since the graph in TensorFlow has to be settled before it being run, I don't know what to put in the loop control as the iteration limit.
2. After the roi_pooling_layer, there follows a InnerProduct layer (in Caffe), the shape of whose input depends on the output shape of the roi_pooling_layer, which ultimately depends on `num_rois`. So the shape of the corresponding `weight_variable` and `bias_variable` for the following operation `matmul`, which is going to act as the InnerProduct layer, cannot be settled before the graph is running.

In addition, in the RoI Pooling layer, there are some other loop control variables based on the former calculation, like `hstart`, `hend`, `wstart` and `wend`. They are even harder to get valid values before the graph is built, because the `num_rois` is part of the input after all.

So may I ask if TensorFlow supports Fast R-CNN (currently)? Or are there any possible specific tips to solve these problems?

Thank you!
"
737,Following cuda install directions can lead to wrong version,"If you follow the link from the cuda install directions, and are trying to install under Ubuntu you will end up on this page:

https://developer.nvidia.com/cuda-toolkit-70

Unfortunately if you select the ""Network Install"" option and install the repository deb, you will end up installing cuda 7.5 not 7.0.

I suggest mentioning this before users click through to nvidia's site in the docs:

https://www.tensorflow.org/versions/master/get_started/os_setup.html#optional-install-cuda-gpus-on-linux
"
736,Build tools and versions listed in Jenkins build log.,"Since TensorFlow is built regularly and it success it reported on the GitHub page, it would be nice to see in the logs e.g. (http://ci.tensorflow.org/job/tensorflow-master/47/configure) the OS configuration, tools used and their version. This way if people want to know what tools and version of the tools currently work they would be available and automatically updated.

Example:
OS: Ubuntu 14.04 LTS
Memory: 2G
Swap space: 2G
Processor: i7
Free hard disk space: 2G
Javac: Oracle Javac 1.8.0_66
Python: 2.7
g++: 4.9
Bazel: 0.1.1
SWIG: 2.0.11
TensorFlow:  f9514a917265f0e98c8fb44abc51158685f72ca6
"
734,failed to enqueue convolution on stream: CUDNN_STATUS_BAD_PARAM,"Hi guys,

I'm just trying to run the Deep MNIST example on my GeForce GTX 980Ti (it worked on the CPU) but am getting the above mentioned error message during the training phase. Can anyone point me to the right direction what might be wrong?

Here's what `ipython notebook` outputs on my Ubuntu 14.04 system with CUDA 7.0, cuDNN 6.5 and NVIDIA drivers version 352.39 (linux-x86_64): http://pastebin.com/f4y3c9CH

Thanks
"
733,Build error under Python 3: error: void function 'InitIfNeeded' should not return a value,"Fresh clone with up to date bazel and swig from homebrew.

```
tensorflow/python/lib/core/py_func.cc:47:5: error: void function 'InitIfNeeded' should not return a value [-Wreturn-type]
    import_array();
    ^~~~~~~~~~~~~~
third_party/py/numpy/numpy_include/numpy/__multiarray_api.h:1532:144: note: expanded from macro 'import_array'
#define import_array() {if (_import_array() < 0) {PyErr_Print(); PyErr_SetString(PyExc_ImportError, ""numpy.core.multiarray failed to import""); return NUMPY_IMPORT_ARRAY_RETVAL; } }
```

The following seems to fix the build issue:

``` diff
diff --git a/tensorflow/python/lib/core/py_func.cc b/tensorflow/python/lib/core/py_func.cc
index 5da997e..8f9221b 100644
--- a/tensorflow/python/lib/core/py_func.cc
+++ b/tensorflow/python/lib/core/py_func.cc
@@ -39,7 +39,7 @@ PyObject* GetPyTrampoline() {
 }

 // Module initialization (mainly import numpy) if needed.
-void InitIfNeeded() {
+int InitIfNeeded() {
   mutex_lock l(mu);
   if (!initialized) {
     PyGILState_STATE py_threadstate;
```

but:
- I am not sure this is the correct fix: should we check for `NUMPY_IMPORT_ARRAY_RETVAL` instead?
- Why does this break now? Was it just a warning previously?
"
729,Parameter Server in python,"Hello, I'm trying to implement an asynchronous parameter server, DistBelief style using TensorFlow. I found that minimize() is split into two functions, compute_gradients and apply_gradients, so my plan is to insert a network boundary between them. I have a question about how to evaluate all the gradients simultaneously and pull them out all at once. I understand that eval only evaluates the subgraph necessary, but it also only returns one tensor, not the chain of tensors required to compute that tensor.

How can I do this more efficiently? I took the Deep MNIST example as a starting point:

```
import tensorflow as tf
import download_mnist

def weight_variable(shape, name):
   initial = tf.truncated_normal(shape, stddev=0.1)
   return tf.Variable(initial, name=name)

def bias_variable(shape, name):
   initial = tf.constant(0.1, shape=shape)
   return tf.Variable(initial, name=name)

def conv2d(x, W):
   return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')

def max_pool_2x2(x):
   return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],
                         strides=[1, 2, 2, 1], padding='SAME')

mnist = download_mnist.read_data_sets('MNIST_data', one_hot=True)
session = tf.InteractiveSession()
x = tf.placeholder(""float"", shape=[None, 784], name='x')
x_image = tf.reshape(x, [-1,28,28,1], name='reshape')
y_ = tf.placeholder(""float"", shape=[None, 10], name='y_')
W_conv1 = weight_variable([5, 5, 1, 32], 'W_conv1')
b_conv1 = bias_variable([32], 'b_conv1')
h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)
h_pool1 = max_pool_2x2(h_conv1)
W_conv2 = weight_variable([5, 5, 32, 64], 'W_conv2')
b_conv2 = bias_variable([64], 'b_conv2')
h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)
h_pool2 = max_pool_2x2(h_conv2)
W_fc1 = weight_variable([7 * 7 * 64, 1024], 'W_fc1')
b_fc1 = bias_variable([1024], 'b_fc1')
h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])
h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)
keep_prob = tf.placeholder(""float"", name='keep_prob')
h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)
W_fc2 = weight_variable([1024, 10], 'W_fc2')
b_fc2 = bias_variable([10], 'b_fc2')
y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)

variables = [W_conv1, b_conv1, W_conv2, b_conv2, W_fc1, b_fc1, W_fc2, b_fc2]
loss = -tf.reduce_sum(y_ * tf.log(y_conv))
optimizer = tf.train.AdamOptimizer(1e-4)
correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, ""float""))
compute_gradients = optimizer.compute_gradients(loss)
session.run(tf.initialize_all_variables())

batch = mnist.train.next_batch(50)
feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5}


gradients = []
for grad_var in compute_gradients:
    grad = grad_var[0].eval(feed_dict=feed_dict)
    var = grad_var[1]
    gradients.append((grad, var))
```

I think this last for loop is actually recalculating the last gradient several times, whereas the first gradient is computed only once? How can I grab all the gradients without recomputing them?
"
726,Segmentation fault for cifar10_train.py and minist/convolutional.py using 0.6.0 on ec2,"I installed tensorflow but running either the cifar10 or the mnist convolution result in a segmentation fault. It looks like a out of memory error, but the prints say they are `Allocating 3.66GiB bytes` and the GRID K520 has 3.95GiB free. Also both scripts have been run by other people successfully on ec2 instances.

For the installation I used erikbern's  [install-tensorflow.sh](https://gist.github.com/erikbern/78ba519b97b440e10640), but used the cuda 7.0 deb installer and installed Tensorflow 0.6.0 instead of 0.5.0

What additional data would be helpful or needed?

Tensorflow version: 0.6.0

``` bash
ludwig@rnd-development-02:/mnt/tmp$ python -c'import tensorflow; print tensorflow.__version__'
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcublas.so.7.0 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcudnn.so.6.5 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcufft.so.7.0 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcurand.so.7.0 locally
0.6.0
```

Running cifar10_train.py

``` bash
ludwig@rnd-development-02:/mnt/tmp/tensorflow/tensorflow/models/image/cifar10$ python cifar10_train.py
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcublas.so.7.0 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcudnn.so.6.5 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcufft.so.7.0 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcurand.so.7.0 locally
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:909] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:103] Found device 0 with properties:
name: GRID K520
major: 3 minor: 0 memoryClockRate (GHz) 0.797
pciBusID 0000:00:03.0
Total memory: 4.00GiB
Free memory: 3.95GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:127] DMA: 0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:137] 0:   Y
I tensorflow/core/common_runtime/gpu/gpu_device.cc:706] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GRID K520, pci bus id: 0000:00:03.0)
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:43] Allocating 3.66GiB bytes.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:53] GPU 0 memory begins at 0x7022a0000 extends to 0x7ec588000
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 1.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 2.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 4.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 8.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 16.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 32.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 64.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 128.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 256.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 512.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 1.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 2.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 4.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 8.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 16.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 32.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 64.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 128.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 256.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 512.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 1.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 2.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 4.00GiB
F tensorflow/stream_executor/cuda/cuda_driver.cc:299] failed to query current context: CUDA_ERROR_DEINITIALIZED
F tensorflow/stream_executor/cuda/cuda_driver.cc:408] Check failed: CUDA_SUCCESS == dynload::cuCtxSetCurrent(prior_context_) (0 vs. 4)
Aborted (core dumped)
```

Running convolutional.py

``` bash
ludwig@rnd-development-02:/mnt/tmp/tensorflow/tensorflow/models/image/cifar10$ python tensorflow/models/image/mnist/convolutional.py python: can't open file 'tensorflow/models/image/mnist/convolutional.py': [Errno 2] No such file or directory
ludwig@rnd-development-02:/mnt/tmp/tensorflow/tensorflow/models/image/cifar10$ cd ../../
ludwig@rnd-development-02:/mnt/tmp/tensorflow/tensorflow/models$ cd ../../
ludwig@rnd-development-02:/mnt/tmp/tensorflow$ python tensorflow/models/image/mnist/convolutional.py
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcublas.so.7.0 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcudnn.so.6.5 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcufft.so.7.0 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcurand.so.7.0 locally
Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.
Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.
Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.
Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:909] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:103] Found device 0 with properties:
name: GRID K520
major: 3 minor: 0 memoryClockRate (GHz) 0.797
pciBusID 0000:00:03.0
Total memory: 4.00GiB
Free memory: 3.95GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:127] DMA: 0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:137] 0:   Y
I tensorflow/core/common_runtime/gpu/gpu_device.cc:706] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GRID K520, pci bus id: 0000:00:03.0)
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:43] Allocating 3.66GiB bytes.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:53] GPU 0 memory begins at 0x7022a0000 extends to 0x7ec588000
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 1.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 2.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 4.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 8.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 16.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 32.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 64.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 128.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 256.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 512.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 1.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 2.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 4.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 8.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 16.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 32.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 64.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 128.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 256.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 512.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 1.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 2.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 4.00GiB
Segmentation fault (core dumped)
```
"
725,Packages in ~/tensorflow/tensorflow/models/image,"If we take a look at perhaps ~/tensorflow/tensorflow/models/image/cifar10/cifar10_train.py, there's a line

from tensorflow.models.image.cifar10 import cifar10

This works perfectly, and since there's a **init**.py in each directory, it can be seen as somewhat a package. When I try to create my own projects in this directory, it does not work. For example:

~/tensorflow/tensorflow/models/image/my_project/, such that

my_project/
    **init**.py
    code1.py
    code2.py

When I try to do the following in code1.py, it does not work:

from tensorflow.models.image.my_project import code2

*Another interesting to note, is that deleting all **init**.py in the various directories still allow tensorflow.models.image.cifar10 import cifar10 to work. There's something more to this that I'm not getting. Does anyone have this problem too?

**P.S. The init has two underscores in front and behind, the markdown removes it.
"
723,failed to query current context: CUDA_ERROR_DEINITIALIZED,"mlds-ws2@mldsws2-ThinkStation-P500:~/tensorflow/tensorflow/models/image/mnist$ python convolutional.py 
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcublas.so.7.0 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcudnn.so.6.5 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcufft.so.7.0 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcurand.so.7.0 locally
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz
I tensorflow/core/common_runtime/gpu/gpu_init.cc:103] Found device 0 with properties: 
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.076
pciBusID 0000:03:00.0
Total memory: 12.00GiB
Free memory: 11.67GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:127] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:137] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:705] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:03:00.0)
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Allocating 11.09GiB bytes.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:52] GPU 0 memory begins at 0xb06c80000 extends to 0xdcc64a99a
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 16.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 32.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 64.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 128.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 256.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 512.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 16.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 32.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 64.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 128.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 256.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 512.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 16.00GiB
F tensorflow/stream_executor/cuda/cuda_driver.cc:408] Check failed: CUDA_SUCCESS == dynload::cuCtxSetCurrent(prior_context_) (0 vs. 4)
F tensorflow/stream_executor/cuda/cuda_driver.cc:299] failed to query current context: CUDA_ERROR_DEINITIALIZED
Aborted (core dumped)

---

After installing tensorflow, I executed mnist example. 
What is this error?;;; this error is similar to #713.
How do I fix this problem? 
Please help me...
"
722,"Problems training the cnn model (Python 2.7.6rc1, Red Hat 4.4.7-16, 64bit) ","I'm getting the following error when trying to train a cnn model:

```
_pywrap_tensorflow.so: undefined symbol: cudnnCreate
```

Full traceback:

```
[root@localhost cnn_test]# python test_train.py
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcublas.so.7.0 locally
I tensorflow/stream_executor/dso_loader.cc:93] Couldn't open CUDA library libcudnn.so.6.5. LD_LIBRARY_PATH: /usr/local/cuda-7.0/lib64
I tensorflow/stream_executor/cuda/cuda_dnn.cc:1382] Unable to load cuDNN DSO
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcufft.so.7.0 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcurand.so.7.0 locally
I tensorflow/core/common_runtime/gpu/gpu_init.cc:127] DMA: 0 1 2 3 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:137] 0:   Y Y Y Y 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:137] 1:   Y Y Y Y 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:137] 2:   Y Y Y Y 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:137] 3:   Y Y Y Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:702] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K20c, pci bus id: 0000:02:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:702] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K20c, pci bus id: 0000:04:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:702] Creating TensorFlow device (/gpu:2) -> (device: 2, name: Tesla K20c, pci bus id: 0000:83:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:702] Creating TensorFlow device (/gpu:3) -> (device: 3, name: Tesla K20c, pci bus id: 0000:84:00.0)
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Allocating 4.31GiB bytes.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:52] GPU 0 memory begins at 0x130fb80000 extends to 0x1423e4d000
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 16.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 32.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 64.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 128.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 256.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 512.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 16.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 32.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 64.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 128.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 256.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 512.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Allocating 4.31GiB bytes.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:52] GPU 1 memory begins at 0x1423e60000 extends to 0x15380e5000
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 16.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 32.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 64.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 128.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 256.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 512.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 16.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 32.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 64.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 128.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 256.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 512.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Allocating 4.31GiB bytes.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:52] GPU 2 memory begins at 0x1538100000 extends to 0x164c33f000
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 16.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 32.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 64.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 128.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 256.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 512.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 16.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 32.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 64.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 128.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 256.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 512.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Allocating 4.31GiB bytes.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:52] GPU 3 memory begins at 0x164c340000 extends to 0x176053d000
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 16.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 32.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 64.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 128.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 256.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 512.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 16.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 32.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 64.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 128.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 256.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 512.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.00GiB
I tensorflow/core/common_runtime/direct_session.cc:58] Direct session inter op parallelism threads: 32
F tensorflow/stream_executor/cuda/cuda_dnn.cc:207] could not find cudnnCreate in cudnn DSO; dlerror: /usr/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so: undefined symbol: cudnnCreate
Aborted (core dumped)
```

@FreakTheMighty  ,  I saw that you met the same problem. Can you tell me how to solve this problem,  appreciate your help very much
"
721,Tensorflow API doc image is wrong for tf.scatter_*,"In `tf.scatter_{add,sub,update}`, the image has `indices = [0, 2, 5]`, but the arrow suggest it's actually `[2, 0, 5]`.  We can't help fix it though since the images in the dos are not part of git.

https://www.tensorflow.org/versions/master/api_docs/python/state_ops.html#scatter_update
"
720,Make tensorflow and tensorflow-devel deb packages,"Will you make it possible to install and update it by distributions package systems (deb & rpm)? You can make an official repository.
Will you make it possible to install a Tensorflow-devel package, which gives acces to C++ headers to make programs, which link to Tensorflow?
"
719,failed to enqueue async memcpy from device to host with latest code,"This problem shows up after I did a git pull today to the last commit of Jan 6th. <63bddb>
Roll back the the last commit of Jan 5th solves the issue

failed to enqueue async memcpy from device to host
check failed: CUDA_SUCCESS == dynlod::cuCtxSetCurrent(prior_context_) (0 vs. 4)
"
718,Tensorflow not showing summaries anymore,"On current master, the tensorboard will start as intended but only show the 'No scalar summaries found' error message. In the log, there are two errors:

```
WARNING:tensorflow:IOError [Errno 2] No such file or directory: '/usr/local/lib/python2.7/dist-packages/external/paper-tabs/paper-tabs.html' on path /usr/local/lib/python2.7/dist-packages/external/paper-t
abs/paper-tabs.html

... some GET

WARNING:tensorflow:IOError [Errno 2] No such file or directory: '/usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/runs' on path /usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/runs
```
"
717,Bazel stuck during build tensorflow.,"mlds-ws2@mldsws2-ThinkStation-P500:~/tensorflow$ bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer
.......
INFO: Loading package: 

---

And stop. After 1~2 hours, doesn't work anything.
I have 3 computer. 
1 is server. 2 CPU and TITAN X 3EA. -> This machine does work well.
But 2, 3 are desktop. 1 CPU and TITAN X or GTX 980 1EA -> Stuck while build tensorflow.
I did format and reinstall ubuntu and necessary program, 3 times. Results are same.
Please help me.
"
716,TensorBoard maybe timeout when show imagenet inception-3 event,"when i run imagenet example ; in tensorflow/models/image/imagenet/classify_image.py i add
-    w=tf.python.training.summary_io.SummaryWriter( sess.graph_def, FLAGS.model_dir, 'graph.pbtxt')  
-    tf.train.SummaryWriter.flush(w)
-    tf.train.SummaryWriter.close(w)

output a file: events.out.tfevents.1452154974.ip-172-30-.-.
when i open tensorboard , in tab  graph ,then i check top,tensorboard use cpu 100%; but wait a while ,tensorboard cpu use is down; tensorboard log a http 200:""GET /graph?run=%2Fopt%2Fpractice%2Ftf%2Fimagenet%2Flog%2F HTTP/1.1"" 200 ;

maybe event file so big cause http timeout?? 
92M Jan  7 09:01 log/events.out.tfevents.1452154974.ip-172-30

any one can help?
"
715,Android Demo build Error,"Get an error when building the Android demo on Ubuntu 14.04.

tp@tp-Inspiron-3421:~/tensorflow$ /home/tp/bin/bazel build tensorflow/examples/android:tensorflow_demo --verbose_failures
INFO: Found 1 target...
INFO: From Compiling google/protobuf/src/google/protobuf/util/internal/utility.cc:
google/protobuf/src/google/protobuf/util/internal/utility.cc:50:19: warning: 'const google::protobuf::StringPiece google::protobuf::util::converter::{anonymous}::SkipWhiteSpace(google::protobuf::StringPiece)' defined but not used [-Wunused-function]
 const StringPiece SkipWhiteSpace(StringPiece str) {
                   ^
INFO: From Compiling google/protobuf/src/google/protobuf/util/internal/field_mask_utility.cc:
google/protobuf/src/google/protobuf/util/internal/field_mask_utility.cc:47:14: warning: 'google::protobuf::util::Status google::protobuf::util::converter::{anonymous}::CreatePublicError(google::protobuf::util::error::Code, const string&)' defined but not used [-Wunused-function]
 util::Status CreatePublicError(util::error::Code code,
              ^
INFO: From Compiling external/re2/re2/stringpiece.cc:
external/re2/re2/stringpiece.cc:6:23: fatal error: util/util.h: No such file or directory
 #include ""util/util.h""
                       ^
compilation terminated.
ERROR: /home/tp/.cache/bazel/_bazel_tp/52515bfa99a2d82b1037ec6d5029c6c1/external/re2/BUILD:7:1: C++ compilation of rule '@re2//:stringpiece' failed: arm-linux-androideabi-gcc failed: error executing command 
  (cd /home/tp/.cache/bazel/_bazel_tp/52515bfa99a2d82b1037ec6d5029c6c1/tensorflow && \
  exec env - \
    PATH=/home/tp/bin:/home/tp/android-ndk-r10e:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/usr/java/jdk1.8.0_65/bin \
  external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/bin/arm-linux-androideabi-gcc -fstack-protector-strong -fpic -ffunction-sections -funwind-tables -no-canonical-prefixes '-march=armv7-a' '-mfpu=vfpv3-d16' '-mfloat-abi=softfp' -iquote external/re2 -iquote bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-fastbuild/genfiles/external/re2 -iquote external/bazel_tools -iquote bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-fastbuild/genfiles/external/bazel_tools -isystem external/re2 -isystem bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-fastbuild/genfiles/external/re2 -isystem external/bazel_tools/tools/cpp/gcc3 '--sysroot=external/androidndk/ndk/platforms/android-21/arch-arm' -isystem external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/lib/gcc/arm-linux-androideabi/4.9/include -isystem external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/lib/gcc/arm-linux-androideabi/4.9/include-fixed -isystem external/androidndk/ndk/sources/cxx-stl/gnu-libstdc++/4.9/include -isystem external/androidndk/ndk/sources/cxx-stl/gnu-libstdc++/4.9/libs/armeabi-v7a/include -isystem external/androidndk/ndk/sources/cxx-stl/gnu-libstdc++/4.9/include/backward '-frandom-seed=bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-fastbuild/bin/external/re2/_objs/stringpiece/external/re2/re2/stringpiece.o' -MD -MF bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-fastbuild/bin/external/re2/_objs/stringpiece/external/re2/re2/stringpiece.d -c external/re2/re2/stringpiece.cc -o bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-fastbuild/bin/external/re2/_objs/stringpiece/external/re2/re2/stringpiece.o): arm-linux-androideabi-gcc failed: error executing command 
  (cd /home/tp/.cache/bazel/_bazel_tp/52515bfa99a2d82b1037ec6d5029c6c1/tensorflow && \
  exec env - \
    PATH=/home/tp/bin:/home/tp/android-ndk-r10e:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/usr/java/jdk1.8.0_65/bin \
  external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/bin/arm-linux-androideabi-gcc -fstack-protector-strong -fpic -ffunction-sections -funwind-tables -no-canonical-prefixes '-march=armv7-a' '-mfpu=vfpv3-d16' '-mfloat-abi=softfp' -iquote external/re2 -iquote bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-fastbuild/genfiles/external/re2 -iquote external/bazel_tools -iquote bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-fastbuild/genfiles/external/bazel_tools -isystem external/re2 -isystem bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-fastbuild/genfiles/external/re2 -isystem external/bazel_tools/tools/cpp/gcc3 '--sysroot=external/androidndk/ndk/platforms/android-21/arch-arm' -isystem external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/lib/gcc/arm-linux-androideabi/4.9/include -isystem external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/lib/gcc/arm-linux-androideabi/4.9/include-fixed -isystem external/androidndk/ndk/sources/cxx-stl/gnu-libstdc++/4.9/include -isystem external/androidndk/ndk/sources/cxx-stl/gnu-libstdc++/4.9/libs/armeabi-v7a/include -isystem external/androidndk/ndk/sources/cxx-stl/gnu-libstdc++/4.9/include/backward '-frandom-seed=bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-fastbuild/bin/external/re2/_objs/stringpiece/external/re2/re2/stringpiece.o' -MD -MF bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-fastbuild/bin/external/re2/_objs/stringpiece/external/re2/re2/stringpiece.d -c external/re2/re2/stringpiece.cc -o bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-fastbuild/bin/external/re2/_objs/stringpiece/external/re2/re2/stringpiece.o).
Target //tensorflow/examples/android:tensorflow_demo failed to build
INFO: Elapsed time: 92.115s, Critical Path: 88.64s.
"
714,when do we support cudnn4?,"cudnn4 natively support batch normalization, when do we support cudnn4?
Actually, theano acts very fast, it support cudnn4 only several days after it comes out.
"
713,failed to query current context: CUDA_ERROR_DEINITIALIZED,"This is a regression problem, code was working fine 2 wks ago, did a git sync to the head and now I have this log message:

I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcublas.so.7.0 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcudnn.so.6.5 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcufft.so.7.0 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcurand.so.7.0 locally
I tensorflow/core/common_runtime/gpu/gpu_init.cc:103] Found device 0 with properties: 
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.076
pciBusID 0000:02:00.0
Total memory: 12.00GiB
Free memory: 11.87GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:127] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:137] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:705] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:02:00.0)
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Allocating 11.27GiB bytes.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:52] GPU 0 memory begins at 0x2306c80000 extends to 0x25d8436a67
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 16.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 32.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 64.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 128.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 256.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 512.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 16.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 32.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 64.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 128.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 256.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 512.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 16.00GiB
create_encoder graph time 0.569116
create_decoder graph time 2.629546
create_loss graph time 0.960969
create_optimizer graph time 34.311540
F tensorflow/stream_executor/cuda/cuda_driver.cc:299] failed to query current context: CUDA_ERROR_DEINITIALIZED
F tensorflow/stream_executor/cuda/cuda_driver.cc:299] failed to query current context: CUDA_ERROR_DEINITIALIZED
F tensorflow/stream_executor/cuda/cuda_driver.cc:299] failed to query current context: CUDA_ERROR_DEINITIALIZED
F tensorflow/stream_executor/cuda/cuda_driver.cc:408] Check failed: CUDA_SUCCESS == dynload::cuCtxSetCurrent(prior_context_) (0 vs. 4)
Aborted (core dumped)

Note: (the create_*) is my code creating the graph.
The python code it crashes on is:
sess.run(tf.initialize_all_variables())
"
709,Add round to nearest,"We have `tf.floor` and `tf.ceil`, but we don't have round to nearest.  I am conflicted on whether it should be called `rint` or `round`.  It would also be annoying if it depended on the processor flags.
"
707,Mistakes in docs of tf.range,"The `limit` argument doesn't have a default value of `None`, and the `start` argument does have a default value of `0`. As specified, the header part of the doc reads: `tf.range(start, limit=None, delta=1, name='range')`, which is misleading and incorrect for something like `tf.range(5)`.
"
706,swig command not found,"I try to build the GPU version on uBuntu 64 machine with command, 

```
bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
```

I installed swig and bazel successfully, but it still reports that swig not found.

```
src/main/tools/namespace-sandbox.c:476: arg: tensorflow/python/tensorflow.i
bazel-out/host/bin/tensorflow/swig: line 17: swig: command not found
ERROR: /userdata01/Users/wenhuchen/tensorflow/tensorflow/tensorflow.bzl:298:3: SWIGing tensorflow/python/tensorflow.i failed: Error during execution of spawn: Process exited with status 127: Error during execution of spawn: Process exited with status 127.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
```

Can anyone help me with that?
"
705,Fail to build from source,"Hi!

I am unable to build TensorFlow from source. I am using a custom installation of Python 3.5.1 on Centos7. Since the system  only has Cuda 7.5 / cudnn 7.0 installed, I changed all references in the source code to that (grepping for ""libcu"" in the source code).

```
$ bazel build --config=cuda --verbose_failures --spawn_strategy=standalone -c opt //tensorflow/tools/pip_package:build_pip_package
WARNING: Output base '/system/user/unterthi/.cache/bazel/_bazel_unterthi/85e103d92fd5b6e762399323367e173a' is on NFS. This may lead to surprising failures and undetermined behavior.
WARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.io/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.
____Loading...
____Loading complete.  Analyzing...
____Found 1 target...
____Building...
 ____From Compiling tensorflow/stream_executor/cuda/cuda_dnn.cc:
tensorflow/stream_executor/cuda/cuda_dnn.cc:147:39: error: '::cudnnAddTensor_v3' has not been declared
     typedef std::add_pointer<decltype(::__name)>::type FuncPointerT;       \
                                       ^
tensorflow/stream_executor/cuda/cuda_dnn.cc:215:3: note: in expansion of macro 'PERFTOOLS_GPUTOOLS_CUDNN_WRAP'
   __macro(cudnnAddTensor_v3)                                  \
   ^
tensorflow/stream_executor/cuda/cuda_dnn.cc:221:1: note: in expansion of macro 'CUDNN_DNN_ROUTINE_EACH_R3'
 CUDNN_DNN_ROUTINE_EACH_R3(PERFTOOLS_GPUTOOLS_CUDNN_WRAP)
 ^
tensorflow/stream_executor/cuda/cuda_dnn.cc:147:39: error: '::cudnnAddTensor_v3' has not been declared
     typedef std::add_pointer<decltype(::__name)>::type FuncPointerT;       \
                                       ^
tensorflow/stream_executor/cuda/cuda_dnn.cc:215:3: note: in expansion of macro 'PERFTOOLS_GPUTOOLS_CUDNN_WRAP'
   __macro(cudnnAddTensor_v3)                                  \
   ^
tensorflow/stream_executor/cuda/cuda_dnn.cc:221:1: note: in expansion of macro 'CUDNN_DNN_ROUTINE_EACH_R3'
 CUDNN_DNN_ROUTINE_EACH_R3(PERFTOOLS_GPUTOOLS_CUDNN_WRAP)
 ^
tensorflow/stream_executor/cuda/cuda_dnn.cc:147:48: error: template argument 1 is invalid
     typedef std::add_pointer<decltype(::__name)>::type FuncPointerT;       \
                                                ^
tensorflow/stream_executor/cuda/cuda_dnn.cc:215:3: note: in expansion of macro 'PERFTOOLS_GPUTOOLS_CUDNN_WRAP'
   __macro(cudnnAddTensor_v3)                                  \
   ^
tensorflow/stream_executor/cuda/cuda_dnn.cc:221:1: note: in expansion of macro 'CUDNN_DNN_ROUTINE_EACH_R3'
 CUDNN_DNN_ROUTINE_EACH_R3(PERFTOOLS_GPUTOOLS_CUDNN_WRAP)
 ^
tensorflow/stream_executor/cuda/cuda_dnn.cc:147:51: error: expected ';' at end of member declaration
     typedef std::add_pointer<decltype(::__name)>::type FuncPointerT;       \
                                                   ^
tensorflow/stream_executor/cuda/cuda_dnn.cc:215:3: note: in expansion of macro 'PERFTOOLS_GPUTOOLS_CUDNN_WRAP'
   __macro(cudnnAddTensor_v3)                                  \
   ^
tensorflow/stream_executor/cuda/cuda_dnn.cc:221:1: note: in expansion of macro 'CUDNN_DNN_ROUTINE_EACH_R3'
 CUDNN_DNN_ROUTINE_EACH_R3(PERFTOOLS_GPUTOOLS_CUDNN_WRAP)
 ^
tensorflow/stream_executor/cuda/cuda_dnn.cc:147:56: error: 'FuncPointerT' does not name a type
     typedef std::add_pointer<decltype(::__name)>::type FuncPointerT;       \
                                                        ^
tensorflow/stream_executor/cuda/cuda_dnn.cc:215:3: note: in expansion of macro 'PERFTOOLS_GPUTOOLS_CUDNN_WRAP'
   __macro(cudnnAddTensor_v3)                                  \
   ^
tensorflow/stream_executor/cuda/cuda_dnn.cc:221:1: note: in expansion of macro 'CUDNN_DNN_ROUTINE_EACH_R3'
 CUDNN_DNN_ROUTINE_EACH_R3(PERFTOOLS_GPUTOOLS_CUDNN_WRAP)
 ^
tensorflow/stream_executor/cuda/cuda_dnn.cc:148:12: error: 'FuncPointerT' does not name a type
     static FuncPointerT DynLoad() {                                        \
            ^
tensorflow/stream_executor/cuda/cuda_dnn.cc:215:3: note: in expansion of macro 'PERFTOOLS_GPUTOOLS_CUDNN_WRAP'
   __macro(cudnnAddTensor_v3)                                  \
   ^
tensorflow/stream_executor/cuda/cuda_dnn.cc:221:1: note: in expansion of macro 'CUDNN_DNN_ROUTINE_EACH_R3'
 CUDNN_DNN_ROUTINE_EACH_R3(PERFTOOLS_GPUTOOLS_CUDNN_WRAP)
 ^
tensorflow/stream_executor/cuda/cuda_dnn.cc: In member function 'void perftools::gputools::cuda::dynload::DynLoadShim__cudnnAddTensor_v3::CallWrapper(perftools::gputools::cuda::CUDAExecutor*, tensorflow::Notification*, cudnnStatus_t*, const Args& ...)':
tensorflow/stream_executor/cuda/cuda_dnn.cc:160:25: error: there are no arguments to 'DynLoad' that depend on a template parameter, so a declaration of 'DynLoad' must be available [-fpermissive]
       *retval = DynLoad()(args...);                                        \
                         ^
tensorflow/stream_executor/cuda/cuda_dnn.cc:215:3: note: in expansion of macro 'PERFTOOLS_GPUTOOLS_CUDNN_WRAP'
   __macro(cudnnAddTensor_v3)                                  \
   ^
tensorflow/stream_executor/cuda/cuda_dnn.cc:221:1: note: in expansion of macro 'CUDNN_DNN_ROUTINE_EACH_R3'
 CUDNN_DNN_ROUTINE_EACH_R3(PERFTOOLS_GPUTOOLS_CUDNN_WRAP)
 ^
tensorflow/stream_executor/cuda/cuda_dnn.cc:160:25: note: (if you use '-fpermissive', G++ will accept your code, but allowing the use of an undeclared name is deprecated)
       *retval = DynLoad()(args...);                                        \
                         ^
tensorflow/stream_executor/cuda/cuda_dnn.cc:215:3: note: in expansion of macro 'PERFTOOLS_GPUTOOLS_CUDNN_WRAP'
   __macro(cudnnAddTensor_v3)                                  \
   ^
tensorflow/stream_executor/cuda/cuda_dnn.cc:221:1: note: in expansion of macro 'CUDNN_DNN_ROUTINE_EACH_R3'
 CUDNN_DNN_ROUTINE_EACH_R3(PERFTOOLS_GPUTOOLS_CUDNN_WRAP)
 ^
tensorflow/stream_executor/cuda/cuda_dnn.cc: In instantiation of 'void perftools::gputools::cuda::dynload::DynLoadShim__cudnnAddTensor_v3::CallWrapper(perftools::gputools::cuda::CUDAExecutor*, tensorflow::Notification*, cudnnStatus_t*, const Args& ...) [with Args = {cudnnContext*, const float*, cudnnTensorStruct*, const void*, const float*, cudnnTensorStruct*, void*}]':
tensorflow/stream_executor/cuda/cuda_dnn.cc:221:1:   required from 'cudnnStatus_t perftools::gputools::cuda::dynload::DynLoadShim__cudnnAddTensor_v3::operator()(perftools::gputools::cuda::CUDAExecutor*, Args ...) [with Args = {cudnnContext*, const float*, cudnnTensorStruct*, const void*, const float*, cudnnTensorStruct*, void*}]'
tensorflow/stream_executor/cuda/cuda_dnn.cc:1081:30:   required from here
tensorflow/stream_executor/cuda/cuda_dnn.cc:160:25: error: 'DynLoad' was not declared in this scope
       *retval = DynLoad()(args...);                                        \
                         ^
tensorflow/stream_executor/cuda/cuda_dnn.cc:215:3: note: in expansion of macro 'PERFTOOLS_GPUTOOLS_CUDNN_WRAP'
   __macro(cudnnAddTensor_v3)                                  \
   ^
tensorflow/stream_executor/cuda/cuda_dnn.cc:221:1: note: in expansion of macro 'CUDNN_DNN_ROUTINE_EACH_R3'
 CUDNN_DNN_ROUTINE_EACH_R3(PERFTOOLS_GPUTOOLS_CUDNN_WRAP)
 ^
tensorflow/stream_executor/cuda/cuda_dnn.cc: In member function 'virtual bool perftools::gputools::cuda::CudnnSupport::DoNormalize(perftools::gputools::Stream*, const perftools::gputools::dnn::NormalizeDescriptor&, const perftools::gputools::DeviceMemory<float>&, perftools::gputools::DeviceMemory<float>*)':
tensorflow/stream_executor/cuda/cuda_dnn.cc:1226:1: warning: control reaches end of non-void function [-Wreturn-type]
 }
 ^
tensorflow/stream_executor/cuda/cuda_dnn.cc: In member function 'virtual bool perftools::gputools::cuda::CudnnSupport::DoElementwiseOperate(perftools::gputools::Stream*, perftools::gputools::dnn::ElementwiseOperation, tensorflow::gtl::ArraySlice<perftools::gputools::dnn::BatchDescriptor>, tensorflow::gtl::ArraySlice<const perftools::gputools::DeviceMemory<float>*>, const perftools::gputools::dnn::BatchDescriptor&, perftools::gputools::DeviceMemory<float>*)':
tensorflow/stream_executor/cuda/cuda_dnn.cc:1287:1: warning: control reaches end of non-void function [-Wreturn-type]
 }
 ^
tensorflow/stream_executor/cuda/cuda_dnn.cc: In member function 'virtual bool perftools::gputools::cuda::CudnnSupport::DoXYPad(perftools::gputools::Stream*, const perftools::gputools::dnn::BatchDescriptor&, const perftools::gputools::DeviceMemory<float>&, tensorflow::int64, tensorflow::int64, tensorflow::int64, tensorflow::int64, perftools::gputools::DeviceMemory<float>*)':
tensorflow/stream_executor/cuda/cuda_dnn.cc:1294:1: warning: control reaches end of non-void function [-Wreturn-type]
 }
 ^
tensorflow/stream_executor/cuda/cuda_dnn.cc: In member function 'virtual bool perftools::gputools::cuda::CudnnSupport::DoXYSlice(perftools::gputools::Stream*, const perftools::gputools::dnn::BatchDescriptor&, const perftools::gputools::DeviceMemory<float>&, tensorflow::int64, tensorflow::int64, tensorflow::int64, tensorflow::int64, perftools::gputools::DeviceMemory<float>*)':
tensorflow/stream_executor/cuda/cuda_dnn.cc:1301:1: warning: control reaches end of non-void function [-Wreturn-type]
 }
 ^
ERROR: /system/apps/biosoft/python-351/tmp/tensorflow/tensorflow/stream_executor/BUILD:5:1: C++ compilation of rule '//tensorflow/stream_executor:stream_executor' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command 
  (cd /system/user/unterthi/.cache/bazel/_bazel_unterthi/85e103d92fd5b6e762399323367e173a/tensorflow && \
  exec env - \
    INTERCEPT_LOCALLY_EXECUTABLE=1 \
    PATH=/system/apps/biosoft/jdk1.8.0_40/bin:/system/apps/biosoft/bazel-0.1.1/bazel-bin/src:/usr/local/cuda/bin:/system/apps/biosoft/R-3.2.0/bin:/system/apps/biosoft/caffe_py351/distribute/bin:/system/apps/biosoft/lmdb-0.9.17/bin:/system/apps/biosoft/protobuf-3.0.0-alpha-3.1_py351/bin:/system/apps/biosoft/boost_1_59_0_py351/bin:/system/apps/biosoft/python-351/bin:/usr/local/cuda/bin:/system/apps/biosoft/R-3.2.0/bin:/system/apps/biosoft/caffe_py351/distribute/bin:/system/apps/biosoft/lmdb-0.9.17/bin:/system/apps/biosoft/protobuf-3.0.0-alpha-3.1_py351/bin:/system/apps/biosoft/boost_1_59_0_py351/bin:/system/apps/biosoft/python-351/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/system/user/unterthi/bin:/system/user/unterthi/bin \
  third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++11' -iquote . -iquote bazel-out/local_linux-py3-opt/genfiles -isystem google/protobuf/src -isystem bazel-out/local_linux-py3-opt/genfiles/google/protobuf/src -isystem tools/cpp/gcc3 -isystem external/jpeg_archive/jpeg-9a -isystem bazel-out/local_linux-py3-opt/genfiles/external/jpeg_archive/jpeg-9a -isystem external/png_archive/libpng-1.2.53 -isystem bazel-out/local_linux-py3-opt/genfiles/external/png_archive/libpng-1.2.53 -isystem external/re2 -isystem bazel-out/local_linux-py3-opt/genfiles/external/re2 -isystem third_party/gpus/cuda -isystem bazel-out/local_linux-py3-opt/genfiles/third_party/gpus/cuda -isystem third_party/gpus/cuda/include -isystem bazel-out/local_linux-py3-opt/genfiles/third_party/gpus/cuda/include -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' '-frandom-seed=bazel-out/local_linux-py3-opt/bin/tensorflow/stream_executor/_objs/stream_executor/tensorflow/stream_executor/cuda/cuda_dnn.pic.o' -MD -MF bazel-out/local_linux-py3-opt/bin/tensorflow/stream_executor/_objs/stream_executor/tensorflow/stream_executor/cuda/cuda_dnn.pic.d -fPIC -c tensorflow/stream_executor/cuda/cuda_dnn.cc -o bazel-out/local_linux-py3-opt/bin/tensorflow/stream_executor/_objs/stream_executor/tensorflow/stream_executor/cuda/cuda_dnn.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1: crosstool_wrapper_driver_is_not_gcc failed: error executing command 
  (cd /system/user/unterthi/.cache/bazel/_bazel_unterthi/85e103d92fd5b6e762399323367e173a/tensorflow && \
  exec env - \
    INTERCEPT_LOCALLY_EXECUTABLE=1 \
    PATH=/system/apps/biosoft/jdk1.8.0_40/bin:/system/apps/biosoft/bazel-0.1.1/bazel-bin/src:/usr/local/cuda/bin:/system/apps/biosoft/R-3.2.0/bin:/system/apps/biosoft/caffe_py351/distribute/bin:/system/apps/biosoft/lmdb-0.9.17/bin:/system/apps/biosoft/protobuf-3.0.0-alpha-3.1_py351/bin:/system/apps/biosoft/boost_1_59_0_py351/bin:/system/apps/biosoft/python-351/bin:/usr/local/cuda/bin:/system/apps/biosoft/R-3.2.0/bin:/system/apps/biosoft/caffe_py351/distribute/bin:/system/apps/biosoft/lmdb-0.9.17/bin:/system/apps/biosoft/protobuf-3.0.0-alpha-3.1_py351/bin:/system/apps/biosoft/boost_1_59_0_py351/bin:/system/apps/biosoft/python-351/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/system/user/unterthi/bin:/system/user/unterthi/bin \
  third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++11' -iquote . -iquote bazel-out/local_linux-py3-opt/genfiles -isystem google/protobuf/src -isystem bazel-out/local_linux-py3-opt/genfiles/google/protobuf/src -isystem tools/cpp/gcc3 -isystem external/jpeg_archive/jpeg-9a -isystem bazel-out/local_linux-py3-opt/genfiles/external/jpeg_archive/jpeg-9a -isystem external/png_archive/libpng-1.2.53 -isystem bazel-out/local_linux-py3-opt/genfiles/external/png_archive/libpng-1.2.53 -isystem external/re2 -isystem bazel-out/local_linux-py3-opt/genfiles/external/re2 -isystem third_party/gpus/cuda -isystem bazel-out/local_linux-py3-opt/genfiles/third_party/gpus/cuda -isystem third_party/gpus/cuda/include -isystem bazel-out/local_linux-py3-opt/genfiles/third_party/gpus/cuda/include -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' '-frandom-seed=bazel-out/local_linux-py3-opt/bin/tensorflow/stream_executor/_objs/stream_executor/tensorflow/stream_executor/cuda/cuda_dnn.pic.o' -MD -MF bazel-out/local_linux-py3-opt/bin/tensorflow/stream_executor/_objs/stream_executor/tensorflow/stream_executor/cuda/cuda_dnn.pic.d -fPIC -c tensorflow/stream_executor/cuda/cuda_dnn.cc -o bazel-out/local_linux-py3-opt/bin/tensorflow/stream_executor/_objs/stream_executor/tensorflow/stream_executor/cuda/cuda_dnn.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
____Elapsed time: 11.581s, Critical Path: 9.50s
```

Any help would be appreciated
"
701,Provide a string_concat op,"Per http://stackoverflow.com/questions/34247374/merge-string-tensors-in-tensorflow

Provide an op that will concatenate two strings into a single string.
"
700,Potential Memory Leak with Session Closing,"Bug: When repeatedly creating and closing sessions on a GPU or CPU (on 0.6.0 release and Jan 5 dev version), memory appears to leak as the python process continually grows in memory usage. Additionally, the time to execute continues to grow. 

Expected behaviour: Once a session is closed, resources allocated should be freed or overwritten.

The following code illustrates the issue with a minimal graph created:

for i in range(0,10000000):
    t0 = time.clock()

```
sess = tf.Session()

a = tf.placeholder(""int16"",name = 'a')
y=tf.identity(a,name='y')

sess.run(y,feed_dict={a:3})
sess.close()

print time.clock() - t0
```

The same issue happens even if I use a constant or variable instead of placeholder.

Thanks!
"
699,Change name of sigmoid_cross_entropy_with_logits to log_loss,"Hi folks. This name sigmoid_cross_entropy_with_logits struck me as strange. In addition to being a mouthful, we're calling it cross_entropy when it really is just binary cross_entropy calculated separately on every node. 

The more intuitive name I would give to this function would be log_loss or mean_log_loss (if normalized). I think this would be both easier to write, and easier to understand. 
"
696,Serialize GraphKeys into GraphDef,"As I understand it, `GraphKeys.VARIABLES` and `GraphKeys.TRAINABLE_VARIABLES` (and other collections) are not serialized with the GraphDef. This means that in order to train a model that had previously been serialized we must recreate all of the variables (simply reifying a `GraphDef` doesn't perform the same init.)

There seem to be two solutions here:
1. To serialize these keys into their respective types on `GraphDef` so we can add the variables to their appropriate collections inside `import_graph_def`. (Seems easy enough?)
2. To recreate the variables the same way, they're created with `tf.Variable` when calling `import_graph_def`. (Seems harder, maybe cleaner?)

This is apparently on the roadmap per http://stackoverflow.com/a/33763208/307401 but I'd be happy to contribute a fix if someone can point me in the right direction.

(The goal is to be able to train something I've previously serialized.)

EDIT: This should also improve restoring `GraphDef` with `Saver` which is cumbersome.
"
694,Determining if A Value is in a Set,"Hey TF,

The `logical_or`, `logical_and`, and `select` functions are very useful.

However, suppose you have value x, and you wanted to see if it was in a set(a,b,c,d,e). In python you would simply write:

``` python

if x in set([a,b,c,d,e]):
   #do action
```

As far as I can tell, the only way to do this in tensorflow, is to have nested 'logical_or' along with 'tf.equal'. I provided just one iteration of this concept below:

``` python
tf.logical_or(
tf.logical_or(tf.equal(x, a), tf.equal(x,b)),
tf.logical_or(tf.equal(x, c), tf.equal(x,d)),
)

```

 I feel that there must be an easier way to do this in tensorflow. Is there?
"
692,How to read saved model,"I have trained a model, and I would like to write a code file implemented with C++. I know how to restore model with tf.train.Saver().restore() function, while how to get the values of parameters of trained model? Thanks in advance.
"
691,Wheels are far behind on tensorflow.org,"Hi there,

I'm new to GitHub contributions so let me know if I'm wrong in posting this here.

I have installed both TensorFlows (CPU and GPU) on Ubuntu 14.04 using pip. I faced many problems and then realized that the wheels on the <a href src=""https://www.tensorflow.org/versions/master/get_started/os_setup.html"">TensorFlow website</a> are quite outdated. The source on GitHub is moving really quickly. In particular, the GPU version does not have stuff like the configure file, among many others.

I then downloaded from source and built the wheels locally. Is there any intention to update the TensorFlow website soon? I can help to solve this issue too so let me know how I can help.
"
690,list of Ref(float) ,"How do you REGISTER_OP with a list of Ref(float) as input, for example use the OpKernelContext::mutable_input_list to modify a list of inputs:

.Attr(""y: int"")
.Input(""x: y \* Ref(float)"")

isn't working... how should I define it in the REGISTER_OP?

Thanks!
"
688,deadlock running MNIST example in debug mode on GPU,"tensorflow sources at commit d4f3c0a9a5d4bce0752b2883167092a8f5cfb494

when building TF for cuda debug:
bazel build  -config=cuda -c dbg --strip=never //tensorflow/tools/pip_package:build_pip_package

running the convolution model results in a hang
[~/tensorflow/tensorflow/models/image/mnist] python convolutional.py
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:909] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:103] Found device 0 with properties:
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.076
pciBusID 0000:05:00.0
Total memory: 12.00GiB
Free memory: 11.87GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:127] DMA: 0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:137] 0:   Y
I tensorflow/core/common_runtime/gpu/gpu_device.cc:702] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Allocating 11.27GiB bytes.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:52] GPU 0 memory begins at 0xb06c80000 extends to 0xdd853359a
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 16.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 32.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 64.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 128.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 256.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 512.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 16.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 32.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 64.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 128.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 256.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 512.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 16.00GiB
Initialized!
Epoch 0.00
Minibatch loss: 10.112, learning rate: 0.010000
Minibatch error: 82.8%
Validation error: 92.4%

attaching a debugger shows the following thread state:

(gdb) i th
  Id   Target Id         Frame
  22   Thread 0x7f775789e700 (LWP 18189) ""python"" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185
  21   Thread 0x7f775709d700 (LWP 18190) ""python"" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185
  20   Thread 0x7f775689c700 (LWP 18191) ""python"" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185
  19   Thread 0x7f774bca6700 (LWP 18192) ""python"" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185
  18   Thread 0x7f774b4a5700 (LWP 18193) ""python"" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185
  17   Thread 0x7f774aca4700 (LWP 18194) ""python"" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185
  16   Thread 0x7f771eda3700 (LWP 18195) ""python"" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185
  15   Thread 0x7f771e5a2700 (LWP 18196) ""python"" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185
  14   Thread 0x7f771dda1700 (LWP 18197) ""python"" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185
  13   Thread 0x7f771d5a0700 (LWP 18198) ""python"" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185
  12   Thread 0x7f771cd9f700 (LWP 18199) ""python"" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185
  11   Thread 0x7f771c59e700 (LWP 18200) ""python"" 0x00007f775a41212d in poll () at ../sysdeps/unix/syscall-template.S:81
  10   Thread 0x7f7709bff700 (LWP 18201) ""python"" pthread_cond_timedwait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_timedwait.S:238
  9    Thread 0x7f770931e700 (LWP 18202) ""python"" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185
  8    Thread 0x7f7708b1d700 (LWP 18203) ""python"" 0x00007f775a3e5f3d in nanosleep () at ../sysdeps/unix/syscall-template.S:81
  7    Thread 0x7f770831c700 (LWP 18204) ""python"" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185
  6    Thread 0x7f7707b1b700 (LWP 18205) ""python"" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185
  5    Thread 0x7f770731a700 (LWP 18206) ""python"" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185
  4    Thread 0x7f7706b19700 (LWP 18207) ""python"" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185
  3    Thread 0x7f76fa9b0700 (LWP 18208) ""python"" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185
  2    Thread 0x7f76fa1af700 (LWP 18209) ""python"" sem_wait () at ../nptl/sysdeps/unix/sysv/linux/x86_64/sem_wait.S:85
- 1    Thread 0x7f775ab0a740 (LWP 18188) ""python"" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185

this state never changes.
building TF w/o GPU support. or in release mode works fine
"
686,"tf.Fill has no gradient.  (Was: ""ValueError: No inputs provided"" when creating optimizer, seems like a bug)","I am in the process of implementing a version of BinaryConnect in tensorflow, and ran into this weird crash.  I pasted a simple example to demonstrate the crash.  Seems that line w = tf.select(draws,mx_fill,-mx_fill) is causing the problem when the optimization graph is being constructed.

```
# Simplified example to demonstrate the crash.  Seems that line w = tf.select(draws,mx_fill,-mx_fill) is causing the problem when the optimization graph is being constructed.

import tensorflow as tf

# Parameters
learning_rate = 0.001
batch_size = 100
SEED = None  # Set to None for random seed.

# Network Parameters
n_image_size = 28
n_channels = 1
n_classes = 10 # MNIST total classes (0-9 digits)

# tf Graph input
x = tf.placeholder(tf.types.float32, [batch_size, n_image_size, n_image_size, n_channels])
y = tf.placeholder(tf.types.float32, [batch_size, n_classes])

#BinaryConnect like projections
def project(W):
    weights = tf.clip_by_value(W,0.1,-0.1)
    shape = weights.get_shape()
    rnd = tf.random_uniform(shape, minval=0, maxval=1.0, dtype=tf.float32, seed=None)
    mx = tf.reduce_max(tf.abs(weights))
    mx_fill = tf.fill(shape,mx)        
    w_norm = tf.div(weights,mx_fill)
    #[-1,1] -> [0,1]
    w_prob = tf.div(tf.add(w_norm,tf.fill(shape,1.0)),tf.fill(shape,2.0))
    prob = tf.clip_by_value(w_prob, 0.0, 1.0) 
    draws = tf.greater(rnd,tf.fill(shape,1.0) - prob)
    w = tf.select(draws,mx_fill,-mx_fill) #This line seems to be the issue
    #Note that uncommenting below seems work, suggesting the graph is constructed correctly
    #w = tf.select(draws,mx_fill,weights)
    return w

def net_conv(_x, _weights): 
    wconv_proj = project(_weights['layer1'])
    out1 = tf.nn.relu(tf.nn.conv2d(x, wconv_proj, strides=[1, 1, 1, 1], padding='SAME'))
    out1p = tf.nn.max_pool(out1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')

    wfc_proj = project(_weights['layer2'])
    shape = out1p.get_shape().as_list()
    reshape = tf.reshape(out1p, [shape[0], shape[1] * shape[2] * shape[3]])
    out2 = tf.nn.relu(tf.matmul(reshape, wfc_proj))

    return out2

weights_conv = {
    'layer1': tf.Variable(tf.truncated_normal([5, 5, n_channels, 32], stddev=0.1, seed=SEED)),
    'layer2': tf.Variable(tf.truncated_normal([14 * 14 * 32, n_classes], stddev=0.1, seed=SEED))
}

pred1  = net_conv(x, weights_conv)
cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred1, y))
optimizer1 = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)
```
"
685,Could contens on tensorflow.org be mirrored on github or other places other than google server? ,"I am from China, and I cannot open the tensorflow.org web site. As known to all, google services are not available in China because the Firewall. It would be very helpful if the documents and turoirals can be obtained from other places other than google server. Sorry to bother. Thanks!
"
684,CUDA_ERROR_NO_DEVICE with Tesla K40c,"Hi,

I'm trying to use TF on a machine with 40 CPUs and 1 Tesla K40c. 

The machine is running openSUSE 13.2 and has CUDA 7 and cuDNN 6.5 installed.

**Problem**

When trying to run a simple test script

```
import tensorflow as tf
hello = tf.constant('Hello, TensorFlow!')
sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))
print sess.run(hello)
a = tf.constant(10)
b = tf.constant(32)
print sess.run(a+b)
```

I get this output + the error ""CUDA_ERROR_NO_DEVICE"":

```
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcublas.so.7.0 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcudnn.so.6.5 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcufft.so.7.0 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcurand.so.7.0 locally
I tensorflow/core/common_runtime/local_device.cc:40] Local device intra op parallelism threads: 40
E tensorflow/stream_executor/cuda/cuda_driver.cc:481] failed call to cuInit: CUDA_ERROR_NO_DEVICE
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:114] retrieving CUDA diagnostic information for host: ml-login2
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:121] hostname: ml-login2
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:146] libcuda reported version is: 346.46
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] driver version file contents: """"""NVRM version: NVIDIA UNIX x86_64 Kernel Module  346.46  Tue Feb 17 17:56:08 PST 2015
GCC version:  gcc version 4.8.3 20140627 [gcc-4_8-branch revision 212064] (SUSE Linux) 
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:150] kernel reported version is: 346.46
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:226] kernel version seems to match DSO: 346.46
I tensorflow/core/common_runtime/gpu/gpu_init.cc:127] DMA: 
I tensorflow/core/common_runtime/direct_session.cc:58] Direct session inter op parallelism threads: 40
Device mapping: no known devices.
I tensorflow/core/common_runtime/direct_session.cc:134] Device mapping:

Const: /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:304] Const: /job:localhost/replica:0/task:0/cpu:0
Hello, TensorFlow!
Const_2: /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:304] Const_2: /job:localhost/replica:0/task:0/cpu:0
Const_1: /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:304] Const_1: /job:localhost/replica:0/task:0/cpu:0
add: /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:304] add: /job:localhost/replica:0/task:0/cpu:0
```

**What I've tried**
I've tried reinstalling the CUDA toolkit, installing TF from source, but all resulted in the same error. 
nvidia-smi properly finds the GPU and I can successfully run GPU computations through C code that depends on CUDA. It seems that somehow TF can't detect the GPU.

Is this a known issue with k40c GPUs and is there a fix?

Thanks!
-Stephan
"
682,TensorFlow on iOS,"In his NIPS tutorial, Jeff Dean mentioned that Google has an internal version of TensorFlow which runs on iOS.  Will this be open sourced?  If so, is there an estimate of how long until it will be available? 
"
681,Building on OSX with custom swig location,"Tried to compile Tensorflow on OSX where I'd installed swig (through homebrew) to a location not usually in PATH (~/homebrew/bin) and found that it failed to run swig due to an issue with the swig.sh that's checked in. 

Changing the path in the swig.sh to the absolute path (rather than rely on it being globally accessible) fixed the issue, but I'm unsure how to fix properly through bazel.

Happy to submit a pull req. if someone could advise how best to fix the issue!
"
680,Document parse_single_sequence_example,"The docs are completely silent on `parse_single_sequence_example`, even though the (officially referenced) `tf.train.Example` protocol buffers documentation mentions `SequenceExample`, and the documentation for `parse_single_sequence_example` in the source code (parsing_ops.py) appears rather complete. I think just exposing the source code documentation would be very helpful to people. In general though `SequenceExample` could use better documentation as it's a very useful feature.
"
678,Tensorboard: missing variable name/label,"When I run the [MNIST example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/mnist/mnist_with_summaries.py) with tensorboard (v0.6.0) and look at the graph, the bias variable is unnamed (just `Variable`).  If I switch the order that the variables are defined, I can make it so that the weights variable is unnamed.  

It looks like perhaps the name of the last variable defined isn't captured in the graph_def?  Or perhaps tensorboard isn't picking up the name of the last variable defined?

![image](https://cloud.githubusercontent.com/assets/37310/12095395/28a32d5e-b2c3-11e5-9f26-0378f17f1cdb.png)
"
677,Tensorboard: missing image/broken link,"When running Tensorboard (v0.6.0) on the output from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/mnist/mnist_with_summaries.py I get a broken link symbol and the following in the logs:

```
192.168.99.1 - - [04/Jan/2016 16:58:45] code 404, message Not Found
192.168.99.1 - - [04/Jan/2016 16:58:45] ""GET /lib/svg/summary-icon.svg HTTP/1.1"" 404 -
WARNING:tensorflow:IOError [Errno 2] No such file or directory: '/usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/lib/svg/summary-icon.svg' on path /usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/lib/svg/summary-icon.svg
```
"
676," Run tutorials convolutional.py,  resource exhausted: OOM","My PC has Nvidia GTX960 2G memory, while run the convolutional.py of tutorials failed,
the tensorflow version is 0.6,  need some modify on  convolutional.py?

$ cd tensorflow/models/image/mnist
$ python convolutional.py
Minibatch loss: 0.739, learning rate: 0.006302
Minibatch error: 0.0%
Validation error: 2.0%
Epoch 9.84
......
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:403]      Summary of in-use Chunks by size: 
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 28 Chunks of size 256 totalling 7.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 1 Chunks of size 1280 totalling 1.2KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 4 Chunks of size 2048 totalling 8.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 3 Chunks of size 3328 totalling 9.8KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 3 Chunks of size 20480 totalling 60.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 1 Chunks of size 100352 totalling 98.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 3 Chunks of size 204800 totalling 600.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 1 Chunks of size 1605632 totalling 1.53MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 1 Chunks of size 4941824 totalling 4.71MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 3 Chunks of size 6422528 totalling 18.38MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 1 Chunks of size 13302272 totalling 12.69MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 1 Chunks of size 31360000 totalling 29.91MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 1 Chunks of size 1636141568 totalling 1.52GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:410] Sum Total of in-use chunks: 1.59GiB
W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:166] Ran out of memory trying to allocate 39.06MiB.  See logs for memory state
W tensorflow/core/kernels/conv_ops.cc:288] Resource exhausted: OOM when allocating tensor with shapedim { size: 10000 } dim { size: 32 } dim { size: 32 } dim { size: 1 }
W tensorflow/core/common_runtime/executor.cc:1076] 0x5a5c0d0 Compute status: Resource exhausted: OOM when allocating tensor with shapedim { size: 10000 } dim { size: 32 } dim { size: 32 } dim { size: 1 }
     [[Node: Conv2D_4 = Conv2D[T=DT_FLOAT, padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/gpu:0""](Const_1, Variable/read)]]
W tensorflow/core/common_runtime/executor.cc:1076] 0x62eaae0 Compute status: Resource exhausted: OOM when allocating tensor with shapedim { size: 10000 } dim { size: 32 } dim { size: 32 } dim { size: 1 }
     [[Node: Conv2D_4 = Conv2D[T=DT_FLOAT, padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/gpu:0""](Const_1, Variable/read)]]
     [[Node: Softmax_2/_53 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_753_Softmax_2"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
Traceback (most recent call last):
  File ""/usr/lib/python2.7/runpy.py"", line 162, in _run_module_as_main
    ""__main__"", fname, loader, pkg_name)
  File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code
    exec code in run_globals
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/models/image/mnist/convolutional.py"", line 292, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/default/_app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/models/image/mnist/convolutional.py"", line 283, in main
    test_error = error_rate(test_prediction.eval(), test_labels)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 460, in eval
    return _eval_using_default_session(self, feed_dict, self.graph, session)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2910, in _eval_using_default_session
    return session.run(tensors, feed_dict)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 368, in run
    results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 444, in _do_run
    e.code)
tensorflow.python.framework.errors.ResourceExhaustedError: OOM when allocating tensor with shapedim { size: 10000 } dim { size: 32 } dim { size: 32 } dim { size: 1 }
     [[Node: Conv2D_4 = Conv2D[T=DT_FLOAT, padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/gpu:0""](Const_1, Variable/read)]]
     [[Node: Softmax_2/_53 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_753_Softmax_2"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
Caused by op u'Conv2D_4', defined at:
  File ""/usr/lib/python2.7/runpy.py"", line 162, in _run_module_as_main
    ""__main__"", fname, loader, pkg_name)
  File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code
    exec code in run_globals
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/models/image/mnist/convolutional.py"", line 292, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/default/_app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/models/image/mnist/convolutional.py"", line 253, in main
    test_prediction = tf.nn.softmax(model(test_data_node))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/models/image/mnist/convolutional.py"", line 190, in model
    padding='SAME')
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py"", line 211, in conv2d
    use_cudnn_on_gpu=use_cudnn_on_gpu, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py"", line 664, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1834, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1043, in __init__
    self._traceback = _extract_stack()
"
675,Gradients of non-scalars (higher rank Jacobians),"Currently if you call gradients(ys, xs), it will return the sum of dy/dx over all ys for each x in xs. I believe this doesn't accord with an a priori mathematical notion of the derivative of a vector. I'd like the way to take the derivative of ys wrt xs where both are vectors and have a Jacobian matrix returned. By extension, I'd like to take the derivative of a vector wrt a matrix and get back a 3-tensor. There doesn't seem to be a convenient tensorflow function to compute the Jacobian or higher order derivatives. Am I missing something or is this functionality that we could add? 
"
674,Use of deprecated (Py2.6) / removed (Py3) BaseException.message,"The `message` attribute was [deprecated in Python 2.6 and removed in Python 3](https://www.python.org/dev/peps/pep-0352/). However, it's still used in TensorFlow.

For instance, [over here in session.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/client/session.py#L354). Under Python 3, this will raise another exception during exception handling.
"
672,Running different parts of a graph at a time without recomputation,"Motivated by [this StackOverflow question](http://stackoverflow.com/questions/34536340/how-to-use-tensorflow-optimizer-without-recomputing-activations-in-reinforcement)

According to George Dahl's answer, there is currently no way to run part of a graph, then later run the entire graph without recomputing that part of the graph.  Couldn't you always just run the whole thing in the first place, you ask?  Consider this scenario:
### Context/Example

You're using tensorflow to implement a reinforcement learning agent with value function approximation trained using stochastic gradient descent.  You're agent contains a method that is called once every iteration/timestep in the experiment.  The method takes an obervation and reward as input and outputs an action.  Consider this sequence of events (Say you're doing q-learning):
1.  At the end of an iteration, you compute your state-action values to choose an action and then return control to the calling program to simulate a step in the environment.
2.  At the beginning of the next iteration, it's time to update the parameters.  You want to use tensorflow's optimizer class to automatically calculate the gradients.  Here, you have three options:
-  Just recompute the state-action values, so you can use the optimizer.  This option leaves you inefficiently calculating part of the graph twice.  This also might not even be viable if you were using something like recurrent neural networks, where calculating the activations changes the state of the nodes.
-  Hardcode the gradients.  You could just write a function to calculate the gradients yourself and not even use optimizer.  However, if you were experimenting with different network architectures and activation functions in a big convolutional network, this could get pretty cumbersome.
-  Call everything else from within your agent.  This sacrifices a lot of modularity and neatness in any framework bigger than a small experiment.

So, in this case, the problem is that your graph (learning with SGD) depends on a value (observation/reward), calculated externally, that depends on the result of part of the graph (state-action values).  And we can't save the state-action values as variables to feed later as placeholders, because then they wouldn't be associated with the operations that produced them, which are required for automatic differentiation.
### Solution

I'm not yet very familiar with the inner workings of tensorflow, so I'm not sure what the best solution would be.  It would need to be able to give Optimizer the tensors already calculated and the graph with the operations that produced them.  Maybe some kind of Session.partial_run() that saves the computed tensors associated with their nodes until a normal run is done?  Maybe a new method under Optimizer that returns an operation to calculate gradients, depending on a placeholder?  What do you think?
"
668,Issue from executing zipalign_runner,
667,Question about the API document of convolution,"In [issue 196](https://github.com/tensorflow/tensorflow/issues/196), the problem of definition of different padding is mentioned. 
https://www.tensorflow.org/versions/master/api_docs/python/nn.html#convolution

I think the document of convolution is still quite confusing right now. 
What does the different dimension of `strides = [1, 1, 1, 1]` mean?
Why the definition of ""VALID"" and ""SAME"" padding is quite different from the [Stanford cs131n](http://cs231n.github.io/convolutional-networks/) tutorial. 

I think most of the people learn CNN according to the tutorials online. Is it possible to modify the document according to the tutorial?  Thank you very much. 
"
666,"""Error computing ByteSize (possible overflow?)"" when trying to save tensorflow model","[libprotobuf ERROR google/protobuf/src/google/protobuf/message_lite.cc:293] Error computing ByteSize (possible overflow?).

This happens for my mlp model, hidden size > 60, 
tf.train.Saver().save(self.session, model_path + '/model.ckpt', global_step = epoch)

How to avoid this?
"
665,CUDA_ERROR_ILLEGAL_INSTRUCTION occurs while running MNIST on Cuda 3.0 device,"Thanks for your working on Cuda compute capability 3.0 devices.
I've installed tensorflow from source on ubuntu14.04+Cuda Toolkit 7.0+CUDNN Toolkit 6.5 with NVIDIA driver 352.63.
The MNIST program on tutorial always goes well at first but crashes after a few seconds with CUDA_ERROR_ILLEGAL_ADDRESS or CUDA_ERROR_ILLEGAL_INSTRUCTION like below:
...
step 1300, training accuracy 0.94
step 1400, training accuracy 0.96
step 1500, training accuracy 0.98
step 1600, training accuracy 0.94
step 1700, training accuracy 0.96
step 1800, training accuracy 0.96
step 1900, training accuracy 1
E tensorflow/stream_executor/cuda/cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS
F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:123] Unexpected Event status: 1
Aborted (core dumped)

or
...
I tensorflow/core/common_runtime/gpu/gpu_device.cc:702] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GT 750M, pci bus id: 0000:01:00.0)
E tensorflow/stream_executor/cuda/cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_INSTRUCTION
F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:123] Unexpected Event status: 1
Aborted (core dumped)

Here's my dmesg information:
[  436.027718] nvidia_uvm: Loaded the UVM driver, major device number 248
[  569.125603] NVRM: GPU at PCI:0000:01:00: GPU-4e535941-7a6a-dcbe-2873-5faabb6099e7
[  569.125625] NVRM: Xid (PCI:0000:01:00): 13, Graphics SM Warp Exception on (GPC 0, TPC 0): Out Of Range Address
[  569.125640] NVRM: Xid (PCI:0000:01:00): 13, Graphics SM Global Exception on (GPC 0, TPC 0): Physical Multiple Warp Errors
[  569.125650] NVRM: Xid (PCI:0000:01:00): 13, Graphics Exception: ESR 0x504648=0x20000e 0x504650=0x24 0x504644=0x13eff2 0x50464c=0x7f
[  569.125750] NVRM: Xid (PCI:0000:01:00): 13, Graphics Exception: ChID 0020, Class 0000a0c0, Offset 00001b0c, Data 00000000

Did anyone meet the problem above?
"
663,Cross-compile Android demo for CUDA,"I was wondering how can I build the android demo with GPU support. I have a device with CUDA capability (Tegra K1 device). What I did was to pass a `--config=cuda` when building the demo. Is it supposed to be enough to enable gpu support by only passing  `--config=cuda`?

I ./configured the workspace given cuda and cudnn path and also specified proper `compute_capability=3.2`
Now that the app is running on my device, how can I make sure if it has gpu support? I did not see a noticeable speed up by doing this. So, What is the proper way to run and validate it?

P.S.
I am using CUDA 6.0. 
I modified few lines to ignore CUDA 7.5 and use 6.0 instead.
"
661,"The picture in tf.gather(params, indices, name=None) made mistake","The picture in tf.gather is wrong. It is P_5 in the `params` that should point to P_5 in `indices`. 
"
658,zombie process resulting from using many GPUs,"I run the example cifar10_multi_gpu_train.py on a PC equipped with 4 GPUs. Somehow the program occupies 4 GPUs, but only the first GPU is doing computation.

When I hit ctrl + c, the python scripts did not terminate, and I found zombie process using htop (the zombie process is associated with command python). After that I have to reboot using ""reboot -nf"" to gain access to GPUs. Tensorflow was installed from source (https://github.com/tensorflow/tensorflow.git).

```
  File ""cifar10_multi_gpu_train.py"", line 270, in <module>
    tf.app.run()
  File ""/home/pc/anaconda2/lib/python2.7/site-packages/tensorflow/python/platform/default/_app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""cifar10_multi_gpu_train.py"", line 266, in main
    train()
  File ""cifar10_multi_gpu_train.py"", line 236, in train
    _, loss_value = sess.run([train_op, loss])
  File ""/home/pc/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 373, in run
    results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)
  File ""/home/pc/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 433, in _do_run
    target_list)
KeyboardInterrupt
```

However, if I do export CUDA_VISIBLE_DEVICES=0 before running the example to limit it to one GPU, I am able to terminate the python scripts normally using ctrl + c.

nvidia-smi
![screenshot 2015-12-31 10 58 57](https://cloud.githubusercontent.com/assets/12500045/12065926/a9860536-afad-11e5-8b5d-12fdb343327d.png)

htop
![screenshot 2015-12-31 11 01 15](https://cloud.githubusercontent.com/assets/12500045/12065944/da739de8-afad-11e5-937b-dcfe1fc3591d.png)
"
657,MemoryError - Convolutional.py ,"I followed the pip install of TensorFlow and when trying the ""Test your installation"" I recevied the following output with a MemoryError.

```
Extracting data/train-images-idx3-ubyte.gz
Traceback (most recent call last):
  File ""convolutional.py"", line 290, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/default/_app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""convolutional.py"", line 127, in main
    train_data = extract_data(train_data_filename, 60000)
  File ""convolutional.py"", line 75, in extract_data
    data = (data - (PIXEL_DEPTH / 2.0)) / PIXEL_DEPTH
MemoryError
```

Any suggestions would be much appreciated. 
"
655,Add bitcast op,"`bitcast` would be the same as numpy's unwisely named `view`: it would turn a tensor of one POD dtype into any different POD type such that the last dimension's size is compatible, without touching the bits in any way.  Specifically,

```
tf.bitcast(x, dtype).shape = x.shape[:-1] + [x.shape[-1] * sizeof(x.dtype) / sizeof(dtype)]
```

with an error if the division isn't an exact integer.  The most useful case of bitcast is anything to `uint8` or back.
"
654,Beam Search 4 Translate.py,"Hi, 
I'm wondering which steps are necessary to move from the greedy decoder currently implemented to an actual beam search decoder. Is this enhancement already in someone's roadmap? If not, could anyone tell me which is the right point in the code where to add this functionality?  
Thanks a lot! 
Marcello 
"
653,translate.py - train path error,"```
python translate.py --decode --en_vocab_size=20000 --fr_vocab_size=20000 
--train_dir /Users/Translated/Downloads/train 
--data /Users/Translated/Downloads/data --size=256 
--num_layers=3 --steps_per_checkpoint=50
```

Will not load the correct model

translate.py

``` python
if ckpt and gfile.Exists(ckpt.model_checkpoint_path):
```

will fail on my Mac OSX El Capitain using VirtualEnv and cause to load an empty model.
I did not test on other systems.

Variable dump in pbb debugger:

```
(Pdb) pp FLAGS.train_dir
'/Users/Translated/Downloads/train' (Correct) 
(Pdb) pp ckpt.model_checkpoint_path
u'train/translate.ckpt-15350' (Wrong)
```

I was hoping it was related to #600 but it is not.  
"
652,--output_layer=pool_3 throws error,"Also posted this on [stackoverflow](http://stackoverflow.com/questions/34466356/error-running-label-image-with-output-layer-pool-3) but this could be a bug so I'm posting here:

The tensorflow exercise in the image recognition tutorial suggests running the c++ example with  `--output_layer=pool_3`. I have tried running this and am getting an error:

```
$ bazel-bin/tensorflow/examples/label_image/label_image --output_layer=pool_3

I tensorflow/core/common_runtime/local_device.cc:40] Local device intra op parallelism threads: 4
I tensorflow/core/common_runtime/direct_session.cc:58] Direct session inter op parallelism threads: 4
W tensorflow/core/common_runtime/executor.cc:1076] 0x558ae6a5d210 Compute status: Invalid argument: input must be 2-dimensional
     [[Node: top_k = TopK[T=DT_FLOAT, k=5, _device=""/job:localhost/replica:0/task:0/cpu:0""](Const/_0)]]
E tensorflow/examples/label_image/main.cc:311] Running print failed: Invalid argument: input must be 2-dimensional
     [[Node: top_k = TopK[T=DT_FLOAT, k=5, _device=""/job:localhost/replica:0/task:0/cpu:0""](Const/_0)]]
```
"
651,How ti make dataset?,"I have found to make my own dataset.
The example dataset is already bytestream.

Can you explain how can I add my image set?
"
650,TensorBoard's graph tab doesn't render in Firefox,"TensorBoard's graph tab works fine in Chrome and Safari, but does not render in Firefox.

[A few other people have reported this issue](https://groups.google.com/a/tensorflow.org/forum/?utm_medium=email&utm_source=footer#!topic/discuss/Lc7Y_6UEFOM).
"
649,translate.py - empty _buckets sets will crash,"If the dev_set does not contain all the string related to all the _buckets 
the script will crash.
Eg. If the dev set does not contain a string between 20 and 25 words, the script will crash.

translate.py, around line 178

``` python
encoder_inputs, decoder_inputs, target_weights = model.get_batch(
              dev_set, bucket_id)
...
```

I think that before that line you should had add an if to avoid that

``` python
     if len(dev_set[bucket_id])>0:
           encoder_inputs, decoder_inputs, target_weights = model.get_batch(
              dev_set, bucket_id)
           _, eval_loss, _ = model.step(sess, encoder_inputs, decoder_inputs,
                                       target_weights, bucket_id, True)
           eval_ppx = math.exp(eval_loss) if eval_loss < 300 else float('inf')
           print(""  eval: bucket %d perplexity %.2f"" % (bucket_id, eval_px))
```
"
647,Cannot import tensorflow under python,"Hi all, I first successfully installed the tensorflow following the instructions of ""Pip Installation"". However, I couldn't import tensorflow in Python. Thanks a lot!!

The error comes like this:

zhuotun@sunformoon:~$ python
Python 2.7.11 |Anaconda 2.4.1 (64-bit)| (default, Dec  6 2015, 18:08:32) 
[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
Anaconda is brought to you by Continuum Analytics.
Please check out: http://continuum.io/thanks and https://anaconda.org

> > > import tensorflow as tf
> > > Traceback (most recent call last):
> > >   File ""<stdin>"", line 1, in <module>
> > > ImportError: No module named tensorflow

I double check that I have installed successfully the tensorflow by re-installing the tensorflow as following:

zhuotun@sunformoon:~$ sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.6.0-cp27-none-linux_x86_64.whl
[sudo] password for zhuotun: 
Downloading/unpacking https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.6.0-cp27-none-linux_x86_64.whl
  Downloading tensorflow-0.6.0-cp27-none-linux_x86_64.whl (11.4MB): 11.4MB downloaded
Requirement already up-to-date: six>=1.10.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==0.6.0)
Requirement already up-to-date: protobuf==3.0.0a3 in /usr/local/lib/python2.7/dist-packages (from tensorflow==0.6.0)
Requirement already up-to-date: wheel in /usr/local/lib/python2.7/dist-packages (from tensorflow==0.6.0)
Requirement already up-to-date: numpy>=1.8.2 in /usr/local/lib/python2.7/dist-packages (from tensorflow==0.6.0)
Requirement already up-to-date: setuptools in /usr/local/lib/python2.7/dist-packages (from protobuf==3.0.0a3->tensorflow==0.6.0)
Installing collected packages: tensorflow
Successfully installed tensorflow
"
646,Can't call shuffle_batch with a boolean tensor,"`tf.bool` is not a valid dtype for tensors passed to `tf.train.shuffle_batch` (or most queues, I think)

I'm porting a data input pipeline to tensorflow, but doing it a little differently than the seq2seq tutorials. I have variable-length sequential data that I pad in pre-processing, while also generating a boolean mask for the valid entries. However, I can't store the mask in a `tf.bool` tensor because that breaks the queue system.
"
645,Casting int64 to int8 is not supported,"Nor `int32`->`int8` or `int16`->`int8`.

Granted, these aren't the safest of operations, but it's still a surprise that they throw an exception.
"
643,Eliminate TileGrad in favor of reshape followed by reduce_sum,"`TileGrad` is exactly equivalent to a reshape which splits each dimension into two pieces, an input dimension piece and a tile dimension piece, then does a reduce_sum over all the tile dimensions to get back the input shape.  There is no need for a separate op.

For example, if `x.shape = (2, 3)` and we do `tf.tile(x, [5, 7])`, the tiled tensor has shape `(2 * 5, 3 * 7)`.  Given a gradient `y` w.r.t. that output with shape `(2 * 5, 3 * 7)`, we can recover the input gradient as `tf.reduce_sum(tf.reshape(y, [5, 2, 7, 3]), reduction_indices=[0, 2])`.

Note that this works even in the case where `multiples` has zeros: in that case we'll do a `reduce_sum` where some of the dimensions we sum over will be zero.  This is well defined even if the result after summation is nonempty: in that case the result is zero.  If sum doesn't already work in that case, it should.
"
642,cifar10-train: tensorflow/core/common_runtime/executor.cc:1076] 0x3455350 Compute status: Failed precondition: Attempting to use uninitialized value conv1/weights,"Hi,

I'm trying to run this model on a system with GeForce GTX 960M:
python /usr/local/lib/python2.7/dist-packages/tensorflow/models/image/cifar10/cifar10_train.py
and get the following output:

I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcublas.so.7.0 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcudnn.so.6.5 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcufft.so.7.0 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcurand.so.7.0 locally
I tensorflow/core/common_runtime/local_device.cc:40] Local device intra op parallelism threads: 4
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:909] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:103] Found device 0 with properties: 
name: GeForce GTX 960M
major: 5 minor: 0 memoryClockRate (GHz) 1.176
pciBusID 0000:01:00.0
Total memory: 2.00GiB
Free memory: 1.69GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:127] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:137] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:702] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 960M, pci bus id: 0000:01:00.0)
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Allocating 1.50GiB bytes.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:52] GPU 0 memory begins at 0x501a40000 extends to 0x5616a0000
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 16.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 32.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 64.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 128.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 256.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 512.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 16.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 32.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 64.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 128.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 256.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 512.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.00GiB
I tensorflow/core/common_runtime/direct_session.cc:58] Direct session inter op parallelism threads: 4
W tensorflow/core/common_runtime/executor.cc:1076] 0x322d680 Compute status: Failed precondition: Attempting to use uninitialized value conv1/weights
     [[Node: conv1/weights/_72 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_341_conv1/weights"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/weights)]]
     [[Node: Identity/_79 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_344_Identity"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
W tensorflow/core/common_runtime/executor.cc:1076] 0x322d680 Compute status: Failed precondition: Attempting to use uninitialized value conv1/weights
     [[Node: conv1/weights/_72 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_341_conv1/weights"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/weights)]]
     [[Node: Variable/initial_value/_81 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_1185_Variable/initial_value"", tensor_type=DT_INT32, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
W tensorflow/core/common_runtime/executor.cc:1076] 0x322d680 Compute status: Failed precondition: Attempting to use uninitialized value conv1/weights
     [[Node: conv1/weights/_72 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_341_conv1/weights"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/weights)]]
     [[Node: conv1/biases/Assign/_67 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_304_conv1/biases/Assign"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/biases/Assign/_66)]]
W tensorflow/core/common_runtime/executor.cc:1076] 0x322d680 Compute status: Failed precondition: Attempting to use uninitialized value conv1/weights
     [[Node: conv1/weights/_72 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_341_conv1/weights"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/weights)]]
     [[Node: Identity_2/_63 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_293_Identity_2"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
W tensorflow/core/common_runtime/executor.cc:1076] 0x322d680 Compute status: Failed precondition: Attempting to use uninitialized value conv1/weights
     [[Node: conv1/weights/_72 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_341_conv1/weights"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/weights)]]
     [[Node: Identity_3/_55 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_275_Identity_3"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
W tensorflow/core/common_runtime/executor.cc:1076] 0x322d680 Compute status: Failed precondition: Attempting to use uninitialized value conv1/weights
     [[Node: conv1/weights/_72 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_341_conv1/weights"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/weights)]]
     [[Node: conv2/biases/Assign/_51 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_273_conv2/biases/Assign"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv2/biases/Assign/_50)]]
W tensorflow/core/common_runtime/executor.cc:1076] 0x322d680 Compute status: Failed precondition: Attempting to use uninitialized value conv1/weights
     [[Node: conv1/weights/_72 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_341_conv1/weights"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/weights)]]
     [[Node: Identity_4/_47 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_262_Identity_4"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
W tensorflow/core/common_runtime/executor.cc:1076] 0x322d680 Compute status: Failed precondition: Attempting to use uninitialized value conv1/weights
     [[Node: conv1/weights/_72 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_341_conv1/weights"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/weights)]]
     [[Node: Identity_5/_39 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_233_Identity_5"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
W tensorflow/core/common_runtime/executor.cc:1076] 0x322d680 Compute status: Failed precondition: Attempting to use uninitialized value conv1/weights
     [[Node: conv1/weights/_72 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_341_conv1/weights"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/weights)]]
     [[Node: Identity_6/_31 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_220_Identity_6"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
W tensorflow/core/common_runtime/executor.cc:1076] 0x322d680 Compute status: Failed precondition: Attempting to use uninitialized value conv1/weights
     [[Node: conv1/weights/_72 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_341_conv1/weights"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/weights)]]
     [[Node: local3/biases/Assign/_35 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_231_local3/biases/Assign"", _device=""/job:localhost/replica:0/task:0/cpu:0""](local3/biases/Assign/_34)]]
W tensorflow/core/common_runtime/executor.cc:1076] 0x322d680 Compute status: Failed precondition: Attempting to use uninitialized value conv1/weights
     [[Node: conv1/weights/_72 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_341_conv1/weights"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/weights)]]
     [[Node: Identity_7/_23 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_191_Identity_7"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
W tensorflow/core/common_runtime/executor.cc:1076] 0x322d680 Compute status: Failed precondition: Attempting to use uninitialized value conv1/weights
     [[Node: conv1/weights/_72 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_341_conv1/weights"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/weights)]]
     [[Node: local4/biases/Assign/_19 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_189_local4/biases/Assign"", _device=""/job:localhost/replica:0/task:0/cpu:0""](local4/biases/Assign/_18)]]
W tensorflow/core/common_runtime/executor.cc:1076] 0x322d680 Compute status: Failed precondition: Attempting to use uninitialized value conv1/weights
     [[Node: conv1/weights/_72 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_341_conv1/weights"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/weights)]]
     [[Node: Identity_8/_15 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_178_Identity_8"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
W tensorflow/core/common_runtime/executor.cc:1076] 0x322d680 Compute status: Failed precondition: Attempting to use uninitialized value conv1/weights
     [[Node: conv1/weights/_72 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_341_conv1/weights"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/weights)]]
     [[Node: Identity_9/_7 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_160_Identity_9"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
W tensorflow/core/common_runtime/executor.cc:1076] 0x322d680 Compute status: Failed precondition: Attempting to use uninitialized value conv1/weights
     [[Node: conv1/weights/_72 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_341_conv1/weights"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/weights)]]
     [[Node: softmax_linear/biases/Assign/_3 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_158_softmax_linear/biases/Assign"", _device=""/job:localhost/replica:0/task:0/cpu:0""](softmax_linear/biases/Assign/_2)]]
W tensorflow/core/common_runtime/executor.cc:1076] 0x322d680 Compute status: Failed precondition: Attempting to use uninitialized value conv1/weights
     [[Node: conv1/weights/_72 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_341_conv1/weights"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/weights)]]
     [[Node: Identity_1/_71 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_306_Identity_1"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
W tensorflow/core/common_runtime/executor.cc:1076] 0x322d680 Compute status: Failed precondition: Attempting to use uninitialized value conv1/weights
     [[Node: conv1/weights/_72 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_341_conv1/weights"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/weights)]]
     [[Node: conv1/weights/Assign/_75 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_342_conv1/weights/Assign"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/weights/Assign/_74)]]
W tensorflow/core/common_runtime/executor.cc:1076] 0x322d680 Compute status: Failed precondition: Attempting to use uninitialized value conv1/weights
     [[Node: conv1/weights/_72 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_341_conv1/weights"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/weights)]]
     [[Node: softmax_linear/weights/Assign/_11 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_176_softmax_linear/weights/Assign"", _device=""/job:localhost/replica:0/task:0/cpu:0""](softmax_linear/weights/Assign/_10)]]
W tensorflow/core/common_runtime/executor.cc:1076] 0x322d680 Compute status: Failed precondition: Attempting to use uninitialized value conv1/weights
     [[Node: conv1/weights/_72 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_341_conv1/weights"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/weights)]]
     [[Node: conv1/biases/_64 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_303_conv1/biases"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/biases)]]
W tensorflow/core/common_runtime/executor.cc:1076] 0x322d680 Compute status: Failed precondition: Attempting to use uninitialized value conv1/weights
     [[Node: conv1/weights/_72 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_341_conv1/weights"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/weights)]]
     [[Node: conv2/biases/_48 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_272_conv2/biases"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv2/biases)]]
W tensorflow/core/common_runtime/executor.cc:1076] 0x322d680 Compute status: Failed precondition: Attempting to use uninitialized value conv1/weights
     [[Node: conv1/weights/_72 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_341_conv1/weights"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/weights)]]
     [[Node: local3/biases/_32 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_230_local3/biases"", _device=""/job:localhost/replica:0/task:0/cpu:0""](local3/biases)]]
W tensorflow/core/common_runtime/executor.cc:1076] 0x322d680 Compute status: Failed precondition: Attempting to use uninitialized value conv1/weights
     [[Node: conv1/weights/_72 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_341_conv1/weights"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/weights)]]
     [[Node: local4/biases/_16 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_188_local4/biases"", _device=""/job:localhost/replica:0/task:0/cpu:0""](local4/biases)]]
W tensorflow/core/common_runtime/executor.cc:1076] 0x322d680 Compute status: Failed precondition: Attempting to use uninitialized value conv1/weights
     [[Node: conv1/weights/_72 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_341_conv1/weights"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/weights)]]
     [[Node: softmax_linear/biases/_0 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_157_softmax_linear/biases"", _device=""/job:localhost/replica:0/task:0/cpu:0""](softmax_linear/biases)]]
W tensorflow/core/common_runtime/executor.cc:1076] 0x32983e0 Compute status: Failed precondition: Attempting to use uninitialized value conv1/weights
     [[Node: conv1/weights/_72 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_341_conv1/weights"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/weights)]]
     [[Node: init/NoOp_1/_88 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_1192_init/NoOp_1"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""]()]]
W tensorflow/core/common_runtime/executor.cc:1076] 0x32983e0 Compute status: Failed precondition: Attempting to use uninitialized value conv1/weights
     [[Node: conv1/weights/_72 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_341_conv1/weights"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/weights)]]
     [[Node: Variable/Assign/_84 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_1186_Variable/Assign"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""]()]]
W tensorflow/core/common_runtime/executor.cc:1076] 0x32983e0 Compute status: Failed precondition: Attempting to use uninitialized value conv1/weights
     [[Node: conv1/weights/_72 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_341_conv1/weights"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/weights)]]
     [[Node: conv1/weights/Assign/_76 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_342_conv1/weights/Assign"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""]()]]
W tensorflow/core/common_runtime/executor.cc:1076] 0x32983e0 Compute status: Failed precondition: Attempting to use uninitialized value conv1/weights
     [[Node: conv1/weights/_72 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_341_conv1/weights"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/weights)]]
     [[Node: conv1/biases/Assign/_68 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_304_conv1/biases/Assign"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""]()]]
W tensorflow/core/common_runtime/executor.cc:1076] 0x32983e0 Compute status: Failed precondition: Attempting to use uninitialized value conv1/weights
     [[Node: conv1/weights/_72 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_341_conv1/weights"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/weights)]]
     [[Node: conv2/weights/Assign/_60 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_291_conv2/weights/Assign"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""]()]]
W tensorflow/core/common_runtime/executor.cc:1076] 0x32983e0 Compute status: Failed precondition: Attempting to use uninitialized value conv1/weights
     [[Node: conv1/weights/_72 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_341_conv1/weights"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/weights)]]
     [[Node: conv2/biases/Assign/_52 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_273_conv2/biases/Assign"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""]()]]
W tensorflow/core/common_runtime/executor.cc:1076] 0x32983e0 Compute status: Failed precondition: Attempting to use uninitialized value conv1/weights
     [[Node: conv1/weights/_72 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_341_conv1/weights"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/weights)]]
     [[Node: local3/weights/Assign/_44 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_260_local3/weights/Assign"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""]()]]
W tensorflow/core/common_runtime/executor.cc:1076] 0x32983e0 Compute status: Failed precondition: Attempting to use uninitialized value conv1/weights
     [[Node: conv1/weights/_72 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_341_conv1/weights"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/weights)]]
     [[Node: local3/biases/Assign/_36 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_231_local3/biases/Assign"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""]()]]
W tensorflow/core/common_runtime/executor.cc:1076] 0x32983e0 Compute status: Failed precondition: Attempting to use uninitialized value conv1/weights
     [[Node: conv1/weights/_72 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_341_conv1/weights"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/weights)]]
     [[Node: local4/weights/Assign/_28 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_218_local4/weights/Assign"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""]()]]
W tensorflow/core/common_runtime/executor.cc:1076] 0x32983e0 Compute status: Failed precondition: Attempting to use uninitialized value conv1/weights
     [[Node: conv1/weights/_72 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_341_conv1/weights"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/weights)]]
     [[Node: local4/biases/Assign/_20 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_189_local4/biases/Assign"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""]()]]
W tensorflow/core/common_runtime/executor.cc:1076] 0x32983e0 Compute status: Failed precondition: Attempting to use uninitialized value conv1/weights
     [[Node: conv1/weights/_72 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_341_conv1/weights"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/weights)]]
     [[Node: softmax_linear/weights/Assign/_12 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_176_softmax_linear/weights/Assign"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""]()]]
W tensorflow/core/common_runtime/executor.cc:1076] 0x32983e0 Compute status: Failed precondition: Attempting to use uninitialized value conv1/weights
     [[Node: conv1/weights/_72 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_341_conv1/weights"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/weights)]]
     [[Node: softmax_linear/biases/Assign/_4 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_158_softmax_linear/biases/Assign"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""]()]]
W tensorflow/core/common_runtime/executor.cc:1076] 0x322d680 Compute status: Failed precondition: Attempting to use uninitialized value conv1/weights
     [[Node: conv1/weights/_72 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_341_conv1/weights"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/weights)]]
     [[Node: conv2/weights/Assign/_59 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_291_conv2/weights/Assign"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv2/weights/Assign/_58)]]
W tensorflow/core/common_runtime/executor.cc:1076] 0x322d680 Compute status: Failed precondition: Attempting to use uninitialized value conv1/weights
     [[Node: conv1/weights/_72 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_341_conv1/weights"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/weights)]]
     [[Node: local4/weights/Assign/_27 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_218_local4/weights/Assign"", _device=""/job:localhost/replica:0/task:0/cpu:0""](local4/weights/Assign/_26)]]
W tensorflow/core/common_runtime/executor.cc:1076] 0x322d680 Compute status: Failed precondition: Attempting to use uninitialized value conv1/weights
     [[Node: conv1/weights/_72 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_341_conv1/weights"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/weights)]]
     [[Node: local3/weights/Assign/_43 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_260_local3/weights/Assign"", _device=""/job:localhost/replica:0/task:0/cpu:0""](local3/weights/Assign/_42)]]
W tensorflow/core/common_runtime/executor.cc:1076] 0x32983e0 Compute status: Failed precondition: Attempting to use uninitialized value conv1/weights
     [[Node: conv1/weights/_72 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_341_conv1/weights"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/weights)]]
     [[Node: Variable/initial_value/_80 = _HostSend[T=DT_INT32, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_1185_Variable/initial_value"", _device=""/job:localhost/replica:0/task:0/gpu:0""](Variable/initial_value)]]
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Traceback (most recent call last):
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/models/image/cifar10/cifar10_train.py"", line 138, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/default/_app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/models/image/cifar10/cifar10_train.py"", line 134, in main
    train()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/models/image/cifar10/cifar10_train.py"", line 94, in train
    sess.run(init)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 368, in run
    results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 444, in _do_run
    e.code)
tensorflow.python.framework.errors.FailedPreconditionError: Attempting to use uninitialized value conv1/weights
     [[Node: conv1/weights/_72 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_341_conv1/weights"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv1/weights)]]

Can somebody tell me what's wrong?

The mnist model: tensorflow/models/image/mnist/convolutional.py
seems to work well: 

I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcublas.so.7.0 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcudnn.so.6.5 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcufft.so.7.0 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcurand.so.7.0 locally
I tensorflow/core/common_runtime/local_device.cc:40] Local device intra op parallelism threads: 4
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:909] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:103] Found device 0 with properties: 
name: GeForce GTX 960M
major: 5 minor: 0 memoryClockRate (GHz) 1.176
pciBusID 0000:01:00.0
Total memory: 2.00GiB
Free memory: 1.71GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:127] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:137] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:702] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 960M, pci bus id: 0000:01:00.0)
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Allocating 1.51GiB bytes.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:52] GPU 0 memory begins at 0x501a40000 extends to 0x562600000
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 16.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 32.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 64.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 128.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 256.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 512.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 16.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 32.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 64.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 128.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 256.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 512.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.00GiB
I tensorflow/core/common_runtime/direct_session.cc:58] Direct session inter op parallelism threads: 4
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz
Initialized!
Epoch 0.00
Minibatch loss: 12.054, learning rate: 0.010000
Minibatch error: 90.6%
Validation error: 84.6%
Epoch 0.12
Minibatch loss: 3.297, learning rate: 0.010000
Minibatch error: 6.2%
Validation error: 7.5%
"
641,Mac install inside virtualenv cannot import examples,"I tried the tutorial on my mac, after using virtualenv to install (the normal pip installation failed for me).

I ran

``` bash
$ cd $PATH_TO_VIRTUALENV_OF_TENSORFLOW
$ source ./bin/activate
(tensorflow)$ python
>>> import tensorflow as tf  # This succeeds
>>> from tensorflow.examples.tutorials.mnist import input_data
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ImportError: No module named examples.tutorials.mnist
```

Inspecting the module tensorflow shows there is no submodule named ""examples"".

I think this is a Mac only issue, not sure if it's only virtualenv too.  When I tried the above on Linux it worked for me.
"
640,Attention modifications,"In the `attention_decoder` of `seq2seq.py`, attention is computed by the statements 

``` python
cell_output, new_state = cell(x, states[-1])
attns = attention(new_state)
with vs.variable_scope(""AttnOutputProjection""):
  output = rnn_cell.linear([cell_output] + attns, output_size, True)
```

However, in Grammar as a Foreign Language, attention is computed using the last hidden vector of the multi-layer LSTM (e.g. `cell_output`). Computing attention with `new_state` involves using every layer's state, including their cell state (which should probably be only used inside the LSTM layer). To match GaaFL, the attention call should be

``` python
attns = attention(cell_output)
```

Of course, if the `cell` is wrapped by an `OutputProjectionWrapper` as done in `embedding_attention_seq2seq`, then this call is computationally expensive. To prevent this, `embedding_attention_seq2seq` can be modified as such:

``` python
# Starting from line 606.
output_size = None
if output_projection is None:
  output_size = num_decoder_symbols # Projection wrapper removed.
```

Now, `cell_output` will be the last hidden vector of the multi-layered LSTM. The reason this works is because `output` is already being projected for the softmax, so `cell_output` does not need to be projected to a length of `num_decoder_symbols`. If as before`cell` is wrapped by `OutputProjectionWrapper`, the `cell_output` will have size `num_decoder_symbols`. Computing the `output` will then involve a `(num_decoder_symbols + num_heads * attn_size) x num_decoder_symbols` matrix, which can be huge. However, if we make the change, then the matrix is only of size `(cell.output_size + num_heads * attn_size) x num_decoder_symbols`.

Thoughts? Have I missed something important? If this sounds good, I can make a PR. Thanks!
"
638,could we have some branch to tag the release version. ,"Sometimes the code just have some small issue, if people fetch the master.
"
637,[Website] Download of Docker Images not possible,"This is not related to the source code but to the website.
I'm not able to download any of the four Docker Images. 

b.gcr.io/tensorflow/tensorflow: TensorFlow CPU binary image.
b.gcr.io/tensorflow/tensorflow:latest-devel: CPU Binary image plus source code.
b.gcr.io/tensorflow/tensorflow:latest-gpu: TensorFlow GPU binary image.
b.gcr.io/tensorflow/tensorflow:latest-devel-gpu: GPU Binary image plus source code.

Error Message:
""404. That’s an error.
The requested URL /tensorflow/tensorflow was not found on this server. That’s all we know.""
"
636,Implementation for GPU depthwise max pooling,"I have this code:

```
    sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,
                                        log_device_placement=True))
    with tf.device(""/gpu:0""):
        s, readout, h_fc1 = createNetwork()
    with sess:
            trainNetwork(s, readout, h_fc1, sess)
```

This fails with this error:

```
W tensorflow/core/common_runtime/executor.cc:1076] 0x28d7890 Compute status: Unimplemented: Depthwise max pooling is currently only implemented for CPU devices.
     [[Node: MaxPool = MaxPool[ksize=[1, 1, 1, 512], padding=""SAME"", strides=[1, 1, 1, 512], _device=""/job:localhost/replica:0/task:0/gpu:0""](Relu_2)]]
W tensorflow/core/common_runtime/executor.cc:1076] 0x2a693f0 Compute status: Unimplemented: Depthwise max pooling is currently only implemented for CPU devices.
     [[Node: MaxPool = MaxPool[ksize=[1, 1, 1, 512], padding=""SAME"", strides=[1, 1, 1, 512], _device=""/job:localhost/replica:0/task:0/gpu:0""](Relu_2)]]
     [[Node: add_4/_3 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_1039_add_4"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
Traceback (most recent call last):
  File ""/mnt/data1/PREZ/PROGRAMMING/2015/12/BOB_learning_0/gpu/lib/python3.4/site-packages/tensorflow/python/client/session.py"", line 428, in _do_run
    target_list)
tensorflow.python.pywrap_tensorflow.StatusNotOK: Unimplemented: Depthwise max pooling is currently only implemented for CPU devices.
     [[Node: MaxPool = MaxPool[ksize=[1, 1, 1, 512], padding=""SAME"", strides=[1, 1, 1, 512], _device=""/job:localhost/replica:0/task:0/gpu:0""](Relu_2)]]
     [[Node: add_4/_3 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_1039_add_4"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""bob_learning.py"", line 222, in <module>
    main()
  File ""bob_learning.py"", line 219, in main
    playGame()
  File ""bob_learning.py"", line 216, in playGame
    trainNetwork(s, readout, h_fc1, sess)
  File ""bob_learning.py"", line 141, in trainNetwork
    readout_t = readout.eval(feed_dict = {s : [s_t]})[0]
  File ""/mnt/data1/PREZ/PROGRAMMING/2015/12/BOB_learning_0/gpu/lib/python3.4/site-packages/tensorflow/python/framework/ops.py"", line 460, in eval
    return _eval_using_default_session(self, feed_dict, self.graph, session)
  File ""/mnt/data1/PREZ/PROGRAMMING/2015/12/BOB_learning_0/gpu/lib/python3.4/site-packages/tensorflow/python/framework/ops.py"", line 2910, in _eval_using_default_session
    return session.run(tensors, feed_dict)
  File ""/mnt/data1/PREZ/PROGRAMMING/2015/12/BOB_learning_0/gpu/lib/python3.4/site-packages/tensorflow/python/client/session.py"", line 368, in run
    results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)
  File ""/mnt/data1/PREZ/PROGRAMMING/2015/12/BOB_learning_0/gpu/lib/python3.4/site-packages/tensorflow/python/client/session.py"", line 444, in _do_run
    e.code)
tensorflow.python.framework.errors.UnimplementedError: Depthwise max pooling is currently only implemented for CPU devices.
     [[Node: MaxPool = MaxPool[ksize=[1, 1, 1, 512], padding=""SAME"", strides=[1, 1, 1, 512], _device=""/job:localhost/replica:0/task:0/gpu:0""](Relu_2)]]
     [[Node: add_4/_3 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_1039_add_4"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
Caused by op 'MaxPool', defined at:
  File ""bob_learning.py"", line 222, in <module>
    main()
  File ""bob_learning.py"", line 219, in main
    playGame()
  File ""bob_learning.py"", line 214, in playGame
    s, readout, h_fc1 = createNetwork()
  File ""bob_learning.py"", line 98, in createNetwork
    h_pool3_flat = tf.reshape(max_pool_featurewise(h_conv3, old_num_filters), [-1, IMSIZE * IMSIZE])
  File ""bob_learning.py"", line 52, in max_pool_featurewise
    return tf.nn.max_pool(x, ksize = [1, 1, 1, num_filters], strides = [1, 1, 1, num_filters], padding = ""SAME"")
  File ""/mnt/data1/PREZ/PROGRAMMING/2015/12/BOB_learning_0/gpu/lib/python3.4/site-packages/tensorflow/python/ops/nn_ops.py"", line 235, in max_pool
    name=name)
  File ""/mnt/data1/PREZ/PROGRAMMING/2015/12/BOB_learning_0/gpu/lib/python3.4/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 449, in _max_pool
    strides=strides, padding=padding, name=name)
  File ""/mnt/data1/PREZ/PROGRAMMING/2015/12/BOB_learning_0/gpu/lib/python3.4/site-packages/tensorflow/python/ops/op_def_library.py"", line 664, in apply_op
    op_def=op_def)
  File ""/mnt/data1/PREZ/PROGRAMMING/2015/12/BOB_learning_0/gpu/lib/python3.4/site-packages/tensorflow/python/framework/ops.py"", line 1834, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/mnt/data1/PREZ/PROGRAMMING/2015/12/BOB_learning_0/gpu/lib/python3.4/site-packages/tensorflow/python/framework/ops.py"", line 1043, in __init__
    self._traceback = _extract_stack()
```

As far as I understand, it should just place that single op on the CPU and everything else on the GPU.
"
634,AdamOptimizer + checkpoints,"When using the AdamOptimizer, does the checkpoint save the state of the AdamOptimizer? If yes, how do you clear the state (i.e., restart the AdamOptimizer but keep the model weights from the checkpoint); if no, how do you maintain the Adam state. Question can be applied to AdaGrad as well.
"
633,tf.decode_csv works with \n but not with \r\n for new lines,"I copied the example for reading CSV files from [here](https://www.tensorflow.org/versions/master/how_tos/reading_data/index.html#reading-from-files) and used it with csv files that I generated (5 columns, comma seperated) which used **\r\n** as line breaks which resulted in the following error:

> W tensorflow/core/common_runtime/executor.cc:1076] 0x1659ea0 Compute status: Invalid argument: Unquoted fields cannot have quotes/CRLFs inside

Using only **\n** worked as expected. According to the [standard](https://tools.ietf.org/html/rfc4180#section-2) using **\r\n** is also valid.

I'm using docker for windows and used the latest docker image, I haven't tried it on other machines.
"
631,Provide sugar for insuring gradient computation of an op is put on the desired device,"Currently, it is somewhat involved to insure that a set of ops are put on the desired device for both the forward and backward (gradient) computations. For example if I have a function that defines its own scope like:

```
def my_op(inputs, name=None):
    with tf.op_scope([inputs], name, 'my_op') as scope:
        ...
```

Simply using the following code would not place its gradient calculations on the specified device:

```
with tf.device('/gpu:0'):
    my_op(...)
```

Instead, the only way I got the above to really work is to define a device function that not only checks the name of the op but also all incoming nodes (because TF adds a lot of additional operations that are not explicitly named under the scope), like this:

```
def _device_function(op):
    if ('my_op' in op.name) or any('my_op' in node.name for node in op.inputs):
        return ""/gpu:0""
    else:
        return None
```

This is unnecessarily involved and may very well be error-prone. Something like a boolean `grad` option for `tf.device` so that the user can simply specify `tf.device(..., grad=True)` would be far cleaner.
"
629,How to print or see the value of Tensor? ,"Variable
Tensor
...
"
628,Bazel can't build anymore?,"Was a BUILD file or something recently changed?

This works perfectly fine:
bazel build -c opt --config=cuda //tensorflow/core:tensorflow --verbose_failures || exit 1

This fails (gets stuck):
bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --verbose_failures || exit 1

and gets stuck on:
bazel build --config=cuda //tensorflow/tools/pip_package:build_pip_package
INFO: Reading 'startup' options from /home/wchan/.bazelrc: --install_base /dev/shm/wchan/bazel/install_base --output_base /dev/shm/wchan/bazel/output_base
Extracting Bazel installation...
......
INFO: (12-26 18:02:26.076) Loading package: 

stuck on ""Loading package"", can't find anything in the logs. Tried the whole shebang of bazel clean and another server, doesn't work on different machines as well... any ideas?
"
627,Recommend to add search box in tensorflow API page,"I think the user experience would be better if we could have a search box in tensor API webpage. 
"
626,Cannot restore large model,"I'm using tf.train.save.Saver to save my model parameters which come out to be ~1.5GB on disk. When I try to reload the model I get a segmentation fault (this is on a machine with 60GB memory). This also happens when using the option restore_sequentially=True. I found an option to shard the save, but it saves one file per device -- surprisingly there are two files, one is virtually nothing and the other is ~1.5GB for a CPU-only machine, so this didn't help. How can I save my model in such a way that I can get it back into memory?

Update:
I tried saving/loading a smaller model. Surprising the save came out to be ~2GB, which is a larger than the save file of the original model; and this 2GB file loaded fine when restoring the model. So perhaps my original model is really larger than 1.5GB and failed to save properly.
"
624,Android Tensorflow demo crash,"I tried the tensorflow demo for android and it looks really promising, but there is a big problem, every time I completely cover the camera my cellphone will horribly crash and reboot, which has never happened to me, I have never encountered an error in an application that will reboot my phone completely, so in order to take this into production I have to find the reason for this, and try to fix it, I hope someone here can provide some guidance or feedback as to why this is happening, it might be that the app is working too hard, but still it would be weird for the whole phone to crash, the scenario is like this, the app is working fine and then when I cover the camera with my finger it will recognize a nematode and immediately crash, any comments would be appreciated, I wonder if anybody else has run into this issue, my cellphone is a samsung galaxy s6 by the way.
"
622,Cannot remove entries from nonexistent ,"Hello everyone

I am using Anaconda on Mac OS 10.11

I created a new environment with anaconda

``` bash
conda create -n tensorflow python
```

Then tried to install tensorflow

``` bash
pip install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.6.0-py2-none-any.whl
```

but I faced an error

``` bash
Installing collected packages: six, setuptools, protobuf, numpy, tensorflow
  Found existing installation: setuptools 19.1.1
**Cannot remove entries from nonexistent file /Users/qdang/anaconda/envs/tensorflow/lib/python2.7/site-packages/easy-install.pth**
```

How could I install tensorflow with anaconda python 2.7?

Btw, I have CUDA 3.0 (Nvidia 750M) with my Macbook? How could I utilize its power other than running only on CPU mode?

Thanks,
"
621,word2vec_optimized.py fails with large training files,"Here is the relevant part of the error for a 2400000000 byte file:

```
external/re2/re2/re2.cc:571: RE2: invalid startpos, endpos pair. [startpos: 0, endpos: -1894967296, text size: -1894967296]
W tensorflow/models/embedding/word2vec_kernels.cc:38] Invalid argument: The text file _train.txt contains too little data: 0 words
E tensorflow/core/framework/op_segment.cc:52] Create kernel failed: Invalid argument: The text file _train.txt contains too little data: 0 words
E tensorflow/core/common_runtime/executor.cc:262] Executor failed to create kernel. Invalid argument: The text file _train.txt contains too little data: 0 words
```

This doesn't happen for a 1000000000 byte file. I suppose there might be an overflow somewhere.

As an aside, how do I dump the embeddings from the final checkpoint?
"
620,"Question about MNIST For ML Beginners, the model definition?","https://www.tensorflow.org/versions/master/tutorials/mnist/beginners/index.html#mnist-for-ml-beginners
In the tutorial for beginner, the model definition flipped from original equation, as say it is a small trick to deal with x being a 2D tensor. 

> First, we multiply x by W with the expression tf.matmul(x, W). This is flipped from when we multiplied them in our equation, where we had Wx, as a small trick to deal with x being a 2D tensor with multiple inputs. We then add b, and finally apply tf.nn.softmax.

Why say it is a small trick ?  Both definition should be equivalent right?
As below
Model definition: 
(1) $y = Wx + b$  
Shape: (10, n) = (10, 784) x (784, n) + (10, n)  
(2) $y = xW + b$  
Shape: (n, 10) = (n, 784) x (784, 10) + (n, 10)

I change the downloaded code `mnist_softmax.py` code to model (1) version and run it, I found that the accuracy is lower than model (2)?
Anyone could tell me the reason? 
"
618,Strongly suggest to improve Tensorflow API document by adding examples,"Dear contributors, 
        I think the document of tensorflow is not good enough overall. 
        I really like Python and Numpy's official document, since they are give very **detailed explanation** and **importantly each concept has simple code example to illustrate the meaning, which helps a lot for easier understanding**. 
       However, tensorflow's document does not contains such example for illustration and the explanation is not in detail. 
       For example, the document for 
      `tf.nn.in_top_k(predictions, targets, k, name=None)` 
       spend me much time to guess what does it mean. The formula in it is not trivial to understand. 
       We could see in the **issue post** in this project that many of them are regarding the specific use of some method/function. 
       To once for all resolve this problem, please consider to improve the the overall document in the Python document fashion, it is very important for the popularity of tensorflow among all other similar tools. 
       Thank you all for your contribution for this project. 
"
617,Docs for tf.device should point to tf.Graph.device,"Currently the docs for `tf.device` located here:

https://www.tensorflow.org/versions/master/api_docs/python/framework.html#device

point to `tf.Graph.name_scope()` for more details, when it would be a lot more helpful if they pointed instead to `tf.Graph.device()`, i.e. here:

https://www.tensorflow.org/versions/master/api_docs/python/framework.html#Graph.device

This would be more consistent with the rest of the docs as well.
"
616,How  to use tf.train.write_graph() and tf.import_graph_def()? It seems that it does not work.,"How  to use tf.train.write_graph() and tf.import_graph_def()? It seems that it does not work.

Please refer the following codes and prints, the final result is None, but it is expected to be [101 102 103 104 105 106 107 108 109 110].

code：

import tensorflow as tf
import os
import numpy as np
from tensorflow.python.platform import gfile

input1= tf.placeholder(tf.int32, [10], name=""input"")
data = np.arange(10)
output1= tf.add(input1, tf.constant(1), name=""output"")

with tf.Session() as sess:
    os.system(""rm -rf /tmp/load"")
    tf.train.write_graph(sess.graph_def, ""/tmp/load"", ""test.pb"", False)
    print sess.run(output1,{input1:data})
print ""Done""
# load graph

with gfile.FastGFile(""/tmp/load/test.pb"",'rb') as f:
    graph_def = tf.GraphDef()
    graph_def.ParseFromString(f.read())
    tf.import_graph_def(graph_def, name='')
# run

with tf.Session() as sess:
    input_x = sess.graph.get_tensor_by_name(""input:0"")
    print input_x
    Const = sess.graph.get_tensor_by_name(""Const:0"")
    print Const  
    output = sess.graph.get_operation_by_name(""output"")
    print output

```
data1 = np.arange(10)+100
print ""data1:"", data1
result = sess.run(output, {input_x: data1})
print ""result:"",result
```

prints：
[ 1  2  3  4  5  6  7  8  9 10]
Done
Tensor(""input:0"", shape=TensorShape([Dimension(10)]), dtype=int32)
Tensor(""Const:0"", shape=TensorShape([]), dtype=int32)
name: ""output""
op: ""Add""
input: ""input""
input: ""Const""
attr {
  key: ""T""
  value {
    type: DT_INT32
  }
}

data1: [100 101 102 103 104 105 106 107 108 109]
result: None
"
615,please share a total example from training in python and prediction in C++.,"Hi, TFs

Current I'm trying prediction in C++ following the tutorial in tensorflow/tensorflow/g3doc/tutorials/image_recognition/index.md.

I want to train the mode in python, using interface tf.train.write_graph() to write the graph to a file, and then loading it in the C++ for predition, just like the above tutorial. Because there is no python codes in the tutorial and no guides to create the file of ""tensorflow_inception_graph.pb"".

I've tried several times, but failed. Could you share a total example in both sides in pyhton and c++?
"
611,A time saving mode to extract the MNIST data,"[tensorflow/tensorflow/examples/tutorials/mnist]
Since now it takes time to extract gz files even if they are already download on a local machine, why don't we consider an additional mode which saves extract data as binary data? 

I submitted the update code of input_data.py and the update first line in run_training(), which is
data_sets = input_data.read_data_sets(FLAGS.train_dir, FLAGS.fake_data, fastload = True)

Any opinion?

(James) Sung-Jin Kim
sungjinkim@fas.harvard.edu
"
610,Issues with running transpose on GPU,"I’m running into a couple of issues with `transpose` on GPUs. First, even the forward computation can’t be registered on a GPU unless I explicitly set the `perm` option. For example this fails (I’m setting `allow_soft_placement=False` in the session `Config`):

```
with tf.device('/gpu:0'):
    a = tf.constant(npr.rand(5, 3).astype('float32'))
    b = tf.transpose(a)
```

with the following error:

```
InvalidArgumentError: Cannot assign a device to node 'transpose/Reverse': Could not satisfy explicit device specification '/gpu:0'
[[Node: transpose/Reverse = Reverse[T=DT_INT32, _device=""/gpu:0""](transpose/Range, transpose/Reverse/dims)]]
```

If however I set `perm=(1, 0)` in the `transpose` operation above, it works. But that’s not the only problem, as the backward computation doesn’t work either way. For example this fails:

```
with tf.device('/gpu:0'):
    a = tf.Variable(tf.random_uniform([5, 3]))
    b = tf.transpose(a, perm=(1, 0))
    l = tf.reduce_sum(b)
    o = tf.train.AdamOptimizer().minimize(l)
    i = tf.initialize_all_variables()

sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=False))
sess.run(i)
sess.run(o)
```

with the following error:

```
InvalidArgumentError: Cannot assign a device to node 'gradients/transpose_grad/InvertPermutation': Could not satisfy explicit device specification '/gpu:0'
[[Node: gradients/transpose_grad/InvertPermutation = InvertPermutation[_device=""/gpu:0""](transpose/perm)]]
```
"
609,'convolutional.py' considered harmful?,"The [get started page](https://www.tensorflow.org/versions/master/get_started/os_setup.html#source) recommends to run [convolutional.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/mnist/convolutional.py) as the first tensorflow neural net model:

```
$ cd tensorflow/models/image/mnist
$ python convolutional.py
```

However, running it brought my machine down. After bringing it up again, the NVIDIA driver didn't work properly anymore (the boot messages showed nvidia-related errors and nvidia-smi became slow). I fixed it by booting into single-user mode and reinstalling the NVIDIA/CUDA drivers.

My desktop has two GPUs of type GeForce GTX 780 Ti with 3GB memory each.

I assume that `convolutional.py` uses too much GPU memory. Maybe a gentler script should be used in the getting-started manual.
"
608,Rescale weights (not gradients) column norms to 1,"How is this possible in TensorFlow, I feel like it should be trivial, but I can't find anything in the API to do this =\

This is to rescale the columns of the weight matrix (i.e., input connections).

Thanks!
"
605,batch_matmul doesn't work on GPUs,"It seems not possible to register the `batch_matmul` operation to a GPU device. For example this fails:

```
with tf.device('/gpu:0'):
    a = tf.constant(npr.rand(10, 5, 5).astype('float32'))
    b = tf.constant(npr.rand(10, 5, 5).astype('float32'))
    c = tf.batch_matmul(a, b)

sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=False))
sess.run(c)
```

This is a fundamental operation and so GPU support is rather important. I'm getting the error on Ubuntu 14.04 with CUDA 7.0.
"
603,Install Documentation still links to 0.5,"https://www.tensorflow.org/versions/master/get_started/os_setup.html#pip_install

The Virtualenv mentions the version 0.5 instead of 0.6 and this may cause some confusion since the rest of the documentation links 0.6.

see:

Ubuntu/Linux 64-bit, CPU only:
(tensorflow)$ pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.5.0-cp27-none-linux_x86_64.whl

Ubuntu/Linux 64-bit, GPU enabled:
(tensorflow)$ pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.5.0-cp27-none-linux_x86_64.whl

Mac OS X, CPU only:
(tensorflow)$ pip install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.5.0-py2-none-any.whl

I noticed that the 
"
602,Strange behavior and verbosity in Tensorboard for RNN,"I only have one encoder, but it lists 50+ encoder variables in the side bar (see attached). This also happens for my decoder. I presume that it is duplicating the variables for each time step? Notice that it says 500+ inputs!

Also, the graph becomes unwieldy and barely loaded in Safari (crashed in Chrome, wouldn't load in Firefox), and is displayed with a <i>very</i> long list of variable names (see attached).

![tf1](https://cloud.githubusercontent.com/assets/1364252/11982491/e9e57346-a968-11e5-9d05-1c6e6faded1e.jpg)
![tf2](https://cloud.githubusercontent.com/assets/1364252/11982496/eceb63ca-a968-11e5-9c59-3960f635f653.jpg)
"
601,failed call to cuInit: CUDA_ERROR_UNKNOWN after Docker build on Macbook Pro (Late 2013) with Linux,"This issue is similar to to #394. I believe i'm seeing it because tensorflow can't find `libcuda.so`.

I know that my `libcuda.so` can be found in `/usr/lib/x86_64-linux-gnu/`, but is this accessible to the compiler and to python without further configuration?  I tried adding it to my docker user's `$LD_LIBRARY_PATH`, but that did not fix the problem. 

I'm running on:
- Macbook Pro (Late 2013) Hardware
- Mint 17
- 3.0 Compute Capability
- CUDA 7.0 & cuDNN 2.0 
- running docker service under a docker user & group.  no sudo access for docker user.

on host os, values for `$CUDA_SO` and `$DEVICES` that are passed into `./docker_run_gpu.sh` are:

```
$ export CUDA_SO=$(\ls /usr/lib/x86_64-linux-gnu/libcuda* | xargs -I{} echo '-v {}:{}')
$ export DEVICES=$(\ls /dev/nvidia* | xargs -I{} echo '--device {}:{}')

$ echo $CUDA_SO
-v /usr/lib/x86_64-linux-gnu/libcuda.so:/usr/lib/x86_64-linux-gnu/libcuda.so -v /usr/lib/x86_64-linux-gnu/libcuda.so.1:/usr/lib/x86_64-linux-gnu/libcuda.so.1 -v /usr/lib/x86_64-linux-gnu/libcuda.so.352.68:/usr/lib/x86_64-linux-gnu/libcuda.so.352.68

$ echo $DEVICES
--device /dev/nvidia0:/dev/nvidia0 --device /dev/nvidiactl:/dev/nvidiactl
```

I customized `Dockerfile.devel-gpu` as below.  I prepended `TF_CUDA_COMPUTE_CAPABILITIES=3.0` and  `TF_UNOFFICIAL_SETTING=1` for the `./configure` step.  

Should I add the `libcuda.so` path to `ENV LD_LIBRARY_PATH`?

``` Dockerfile
# ........

RUN git clone --recursive https://github.com/tensorflow/tensorflow.git && \
    cd tensorflow && \
    git checkout 0.6.0
WORKDIR /tensorflow

# Configure the build for our CUDA configuration.
ENV CUDA_TOOLKIT_PATH /usr/local/cuda
ENV CUDNN_INSTALL_PATH /usr/local/cuda
ENV TF_NEED_CUDA 1

RUN TF_CUDA_COMPUTE_CAPABILITIES=3.0 TF_UNOFFICIAL_SETTING=1 ./configure && \
    bazel build -c opt --config=cuda tensorflow/tools/pip_package:build_pip_package && \
    bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/pip && \
    pip install --upgrade /tmp/pip/tensorflow-*.whl

WORKDIR /root

# Set up CUDA variables
ENV CUDA_PATH /usr/local/cuda
ENV LD_LIBRARY_PATH /usr/local/cuda/lib64

# TensorBoard
EXPOSE 6006
# IPython
EXPOSE 8888

RUN [""/bin/bash""]
```

Then I built the image and ran it with `./docker_run_gpu.sh tf/tf`

Started tensorflow with: `python -m tensorflow.models.image.mnist.convolutional`

And I'm getting `failed call to cuInit: CUDA_ERROR_UNKNOWN` when tensorflow starts up. But this is after reporting that it `successfully opened CUDA library libcuda.so locally`.

```
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcublas.so.7.0 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcudnn.so.6.5 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcufft.so.7.0 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcurand.so.7.0 locally

I tensorflow/core/common_runtime/local_device.cc:40] Local device intra op parallelism threads: 8
modprobe: ERROR: ../libkmod/libkmod.c:556 kmod_search_moddep() could not open moddep file '/lib/modules/3.19.0-32-generic/modules.dep.bin'
E tensorflow/stream_executor/cuda/cuda_driver.cc:481] failed call to cuInit: CUDA_ERROR_UNKNOWN
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:114] retrieving CUDA diagnostic information for host: 24b008aee65f
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:121] hostname: 24b008aee65f
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:146] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] driver version file contents: """"""NVRM version: NVIDIA UNIX x86_64 Kernel Module  352.68  Tue Dec  1 17:24:11 PST 2015
GCC version:  gcc version 4.8.4 (Ubuntu 4.8.4-2ubuntu1~14.04)
```
"
600,Translate (Seq2Seq) Tutorial Expectations,"The output I am getting from the translate.py tutorial looks corrupted.
hello -> G0

I followed the translate tutorial here:
https://www.tensorflow.org/versions/master/tutorials/seq2seq/index.html

I wanted to create a small test model, limiting to 1M records
python translate.py --data_dir data --train_dir train --en_vocab_size=40000 --fr_vocab_size=40000 --size=256 --num_layers=2 --steps_per_checkpoint=50 --max_train_data_size=1000000

No errors during the training.

After 15 hours, I stopped the training when the perplexity was below 10 points.
global step 19500 learning rate 0.2655 step-time 2.76 perplexity 8.63
  eval: bucket 0 perplexity 13.15
  eval: bucket 1 perplexity 10.71
  eval: bucket 2 perplexity 12.78
  eval: bucket 3 perplexity 14.38

After stopping the training I deleted the last corrupted training file.
rm train/translate.ckpt-19500

If I try to translate simple words I get junk.
python translate.py --decode --data_dir data --train_dir train
Created model with fresh parameters.
-> hello
G0 Processing Processing Processing Processing Processing Processing Processing Processing Processing
-> house
G0 G0 pâturage d’infrastructures d’infrastructures Twin Twin Twin Twin Twin
-> Who is the president of the United States?
expédiées expédiées expédiées m0 m0 m0 m0 m0 m0 m0 m0 m0 m0 m0 m0

Other translation technologies (es. Moses) will provide a decent translation with that training data.

If there a glitch somewhere or did I do something wrong?
"
598,SVG folder of tensorboard not found,"if you run the mnist_fully_connected tutorial and inspect it with tensorboard afterwards, you find the following: 

the graph-viz is calling this url for a image
http://localhost:6006/lib/svg/summary-icon.svg

<img width=""1277"" alt=""screen shot 2015-12-23 at 15 20 24"" src=""https://cloud.githubusercontent.com/assets/9993908/11978047/bc880e52-a988-11e5-8478-c08ba0a65d43.png"">

which is not there... 
"
597,Can you add the paper references for each of the implementations?,"Instead of labeling the constants and functions with description text, could you please add the paper references?

Thanks!
"
594,Will the tensorflow support nesterov momentum optimization?,"Does anybody have experience about ""momentum"" and ""nesterov momentum""?

does the ""nesterov momentum"" perform much better than than ""momentum""?
"
593,TensorArray failure with automatic gradient computation for nested scan/map_fn/fold,"I drew up this simple example to show that nested While gradient computation fails in the python interface (as the gradContext for the forwardContext of the second input of the Add op is None). Toggling the comment demonstrates the issue is not with all control flow graphs.

``` python
import tensorflow as tf
from tensorflow.python.ops import control_flow_ops

OUTER_LOOP_MAX = 5
INNER_LOOP_MAX = 3

inner = tf.placeholder(""float32"", [1, INNER_LOOP_MAX])
outer = tf.placeholder(""float32"", [1, OUTER_LOOP_MAX])

X = tf.Variable(tf.zeros([1], dtype=""float32""))

max = tf.constant(1)

def outer_cond_func(c1, outer_acc, outer_array):
    return tf.less(c1, OUTER_LOOP_MAX)


def outer_body_func(c1, outer_acc, outer_array):
    concat = tf.concat(0, [[0], tf.expand_dims(c1, 0)])
    slice = tf.slice(outer_array, concat, [1, 1])
    outer_num = tf.reduce_sum(slice)

    def inner_cond_func(c2, inner_acc, inner_array):
        return tf.less(c2, INNER_LOOP_MAX)

    def inner_body_func(c2, inner_acc, inner_array):
        concat2 = tf.concat(0, [[0], tf.expand_dims(c2, 0)])
        inner_num = tf.reduce_sum(tf.slice(inner_array, concat2, [1,1]))
        inner_acc += inner_num * outer_num * X

        c2 += 1
        return c2, inner_acc, inner_array

    _, inside_summed_products, _ = control_flow_ops.While(inner_cond_func, inner_body_func, [tf.constant(0), tf.constant(0.0), inner])

    def true_func():
        return 2*outer_num

    def false_func():
        return 3*outer_num

    cond_num = control_flow_ops.cond(tf.less(c1,max),true_func, false_func)
    outer_acc = tf.add(outer_acc, inside_summed_products)
    # outer_acc = tf.add(outer_acc, cond_num)
    c1 += 1
    return c1, outer_acc, outer_array

_, value, _ = control_flow_ops.While(outer_cond_func, outer_body_func, [tf.constant(0), tf.constant(0.0), outer])
control_flow_ops.switch()

loss = value * X
train_op = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(loss)

sess = tf.Session()
init = tf.initialize_all_variables()
sess.run(init)

for i in xrange(1, 10):
    feed_dict = {inner: [[1.0, 2.0, 3.0]], outer: [[4.0, 5.0, 6.0, 7.0, 8.0]]}
    print sess.run([train_op, loss], feed_dict=feed_dict)
```
"
592,How can I get Bazel to build iteratively?,"In 0.5.0, I could change files (e.g. tensorflow/models/rnn/seq2seq.py) and recompile iteratively with no problem. In 0.6.0, making changes in files like tensorflow/python/ops/rnn_cell.py, etc, gives me pretty long recompile times. I'm not sure that it's doing a full rebuild, but it's def not the snappy few second rebuilds I was experiencing before. I didn't see an issue about this and so I'm wondering if it's something with my setup. Is this a common problem?
"
591,tf.Print does not work on embedding gradients,"Is this expected? because an embedding gradient is an IndexedSlices rather than a Tensor.
"
590,pip install does not install the examples folder,"When doing on my Mac:
sudo pip install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.6.0-py2-none-any.whl
I got tensorflow to install, but without the `examples`directory. 
There is no mention of that in the setup here:
The page https://www.tensorflow.org/versions/master/get_started/os_setup.html

I needed the `examples` to do this tutorial:
https://www.tensorflow.org/versions/master/tutorials/mnist/beginners/index.html

(for the time being I just downloaded the whole zip of the repository and copy-pasted the folder, and so far appears to work)

Did I miss anything when installing? 
"
587,Android example finally works,"Finally was able to compile and install to Nexus 7 (2013) Marshmallow 6.0.1 with:
bazel mobile-install //tensorflow/examples/android:tensorflow_demo -c opt --start_app --copt=-mfpu=neon 

Crashes because no camera permission the first run so drop the --start_app  

Simple solution is to use ->settings -> apps -> Tensorflow Demo -> Permissions 
and enable both storage and camera.

So I'm wondering about the --copt=-mfpu=neon 

Tensorflow demo runs amazingly fast (a few seconds) on the Nexus 7 compared to waiting 10 minutes or so for the example label_image to produce results on an older Dell  - Intel(R) Core(TM)2 CPU         T7200  @ 2.00GHz
"
586,[feature request] numpy style `shape` sugar,"I'd like to suggest numpy-like `shape` read-only property for `tf.Tensor`, something like:

```
@property
def shape(self):
  return tuple(self.get_shape().as_list())
```
"
585,Failed installation on Mac OS X El Capitan,"When I run the suggested command: 

pip install https://storage.googleapis.com/tensorflow/mac/tensorflow-0.5.0-py2-none-any.whl

I get the following error:

tensorflow-0.5.0-py2-none-any.whl is not a supported wheel on this platform.

Please advise.
- Tom
"
583,Multiple CPU usage ineffective,"I'm running tensorflow on a machine with 64 CPUs and no GPUs. I noticed that although tf detects the number of CPU's correctly (
I tensorflow/core/common_runtime/local_device.cc:40] Local device intra op parallelism threads: 64
I tensorflow/core/common_runtime/direct_session.cc:58] Direct session inter op parallelism threads: 64
), the total CPU usage is less than 16 most of the time. It increases to 20-30 occasionally but for a very short period of time. And even that is much lower than 64. 
"
582,error parsing inception v3 file: 64MB python protobuf parsing limit,"I just upgraded TF to 469b3ddb4bb914a02f496748dd4ee5dbcbd7fce0 and I'm now getting an error importing the inception v3 model provided at https://storage.googleapis.com/download.tensorflow.org/models/inception_dec_2015.zip

I didn't have this problem before the upgrade. Here is the error

```
Traceback (most recent call last):
  File ""test.py"", line 7, in <module>
    graph_def.ParseFromString(fileContent)
google.protobuf.message.DecodeError: Error parsing message
```

And this is the code I'm using

``` python
import tensorflow as tf

with open(""tensorflow_inception_graph.pb"", mode='rb') as f:
  fileContent = f.read()
graph_def = tf.GraphDef()
graph_def.ParseFromString(fileContent)

input_layer = tf.placeholder(""float"", [1, 299, 299, 3])
tf.import_graph_def(graph_def, input_map={ ""Mul"": input_layer })
```
"
581,ConvNet tutorial,"https://tensorflow.googlesource.com/tensorflow/+/master/tensorflow/g3doc/tutorials/deep_cnn/index.md

Quote:

> EXERCISE: The model architecture in inference() differs slightly from the CIFAR-10 model specified in cuda-convnet. In particular, the top layers of Alex’s original model are locally connected and not fully connected. Try editing the architecture to exactly reproduce the locally connected architecture in the top layer.

When I look at the Figure2 of AlexNet paper, it seems that the only locally connected layers are conv1 and conv3 (which I would classify as ""bottom"" layers), both fully connected layers (which are ""top"" layers in my understanding) are connected across the two GPUs. Or am I not understanding the exercise correctly?
"
580,Failed compilation with avx or avx2 on Ubuntu 14.04,"I am unable to compile when passing avx or avx2 to bazel, even though I have an avx2-compatible CPU (Xeon E5-2643 v3). This is the command I'm using to compile:

```
bazel build -c opt --copt=-mavx2 //tensorflow/tools/pip_package:build_pip_package
```

Also I can compile just fine using the default CPU or GPU configurations, i.e. both of these commands work:

```
bazel build -c opt //tensorflow/tools/pip_package:build_pip_package
bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
```

Here is the error message when turning on `verbose_failures`:

 ERROR: /usr/local/tensorflow/tensorflow/core/BUILD:157:1: C++ compilation of rule '//tensorflow/core:framework' failed: gcc failed: error executing command 
  (cd /root/.cache/bazel/_bazel_root/e86f6fce5559de9e3e13fb6adb66b858/tensorflow && \
  exec env - \
    INTERCEPT_LOCALLY_EXECUTABLE=1 \
    PATH=/usr/local/cuda/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \
  /usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections -mavx2 '-std=c++0x' -iquote . -iquote bazel-out/local_linux-opt/genfiles -isystem google/protobuf/src -isystem bazel-out/local_linux-opt/genfiles/google/protobuf/src -isystem tools/cpp/gcc3 -isystem external/jpeg_archive/jpeg-9a -isystem bazel-out/local_linux-opt/genfiles/external/jpeg_archive/jpeg-9a -isystem external/png_archive/libpng-1.2.53 -isystem bazel-out/local_linux-opt/genfiles/external/png_archive/libpng-1.2.53 -isystem external/re2 -isystem bazel-out/local_linux-opt/genfiles/external/re2 -isystem third_party/eigen3 -isystem bazel-out/local_linux-opt/genfiles/third_party/eigen3 -isystem external/eigen_archive/eigen-eigen-ce5a455b34c0 -isystem bazel-out/local_linux-opt/genfiles/external/eigen_archive/eigen-eigen-ce5a455b34c0 -pthread -fno-exceptions -DEIGEN_AVOID_STL_ARRAY -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' '-frandom-seed=bazel-out/local_linux-opt/bin/tensorflow/core/_objs/framework/tensorflow/core/framework/kernel_def_builder.pic.o' -MD -MF bazel-out/local_linux-opt/bin/tensorflow/core/_objs/framework/tensorflow/core/framework/kernel_def_builder.pic.d -fPIC -c tensorflow/core/framework/kernel_def_builder.cc -o bazel-out/local_linux-opt/bin/tensorflow/core/_objs/framework/tensorflow/core/framework/kernel_def_builder.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1: gcc failed: error executing command 
  (cd /root/.cache/bazel/_bazel_root/e86f6fce5559de9e3e13fb6adb66b858/tensorflow && \
  exec env - \
    INTERCEPT_LOCALLY_EXECUTABLE=1 \
    PATH=/usr/local/cuda/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \
  /usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections -mavx2 '-std=c++0x' -iquote . -iquote bazel-out/local_linux-opt/genfiles -isystem google/protobuf/src -isystem bazel-out/local_linux-opt/genfiles/google/protobuf/src -isystem tools/cpp/gcc3 -isystem external/jpeg_archive/jpeg-9a -isystem bazel-out/local_linux-opt/genfiles/external/jpeg_archive/jpeg-9a -isystem external/png_archive/libpng-1.2.53 -isystem bazel-out/local_linux-opt/genfiles/external/png_archive/libpng-1.2.53 -isystem external/re2 -isystem bazel-out/local_linux-opt/genfiles/external/re2 -isystem third_party/eigen3 -isystem bazel-out/local_linux-opt/genfiles/third_party/eigen3 -isystem external/eigen_archive/eigen-eigen-ce5a455b34c0 -isystem bazel-out/local_linux-opt/genfiles/external/eigen_archive/eigen-eigen-ce5a455b34c0 -pthread -fno-exceptions -DEIGEN_AVOID_STL_ARRAY -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' '-frandom-seed=bazel-out/local_linux-opt/bin/tensorflow/core/_objs/framework/tensorflow/core/framework/kernel_def_builder.pic.o' -MD -MF bazel-out/local_linux-opt/bin/tensorflow/core/_objs/framework/tensorflow/core/framework/kernel_def_builder.pic.d -fPIC -c tensorflow/core/framework/kernel_def_builder.cc -o bazel-out/local_linux-opt/bin/tensorflow/core/_objs/framework/tensorflow/core/framework/kernel_def_builder.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
"
579,Requesting issue reopening,"#469

https://github.com/tensorflow/tensorflow/issues/469#issuecomment-166292118
"
577,Changing the number of (CPU) threads for cifar10,"Whenever I run the cifar10_eval.py, in creates 32 threads as following:

I tensorflow/core/common_runtime/local_device.cc:25] Local device intra op parallelism threads: 32

I think this number of threads is the number of threads running on CPUs, but when I check the usage, only 400-500% of CPUs are used. I wonder if there is anyway to change this number of threads?

Thanks
"
576,Resource Exhausted Error MNIST Example with CPU and Python3 (3.4.3),"I am having a Resource Exhausted Error in MNIST demo model with CPU and Python3 (3.4.3) [I am using Ubuntu 14.04LTS VMWare with 3 GB over a Windows 10 System; PIP Installation, No VirtualEnv, No Docker]:

$ python -m tensorflow.models.image.mnist.convolutional

david@ubuntu:~$ 
david@ubuntu:~$ python3 -m tensorflow.models.image.mnist.convolutional
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz
I tensorflow/core/common_runtime/local_device.cc:40] Local device intra op parallelism threads: 1
I tensorflow/core/common_runtime/direct_session.cc:58] Direct session inter op parallelism threads: 1
Initialized!
Epoch 0.00
Minibatch loss: 12.053, learning rate: 0.010000
Minibatch error: 90.6%
W tensorflow/core/kernels/conv_ops.cc:178] Resource exhausted: OOM when allocating tensor with shapedim { size: 5000 } dim { size: 28 } dim { size: 28 } dim { size: 32 }
W tensorflow/core/common_runtime/executor.cc:1076] 0x579eaa0 Compute status: Resource exhausted: OOM when allocating tensor with shapedim { size: 5000 } dim { size: 28 } dim { size: 28 } dim { size: 32 }
     [[Node: Conv2D_2 = Conv2D[T=DT_FLOAT, padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/cpu:0""](Const, Variable/read)]]
Traceback (most recent call last):
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py"", line 428, in _do_run
    target_list)
tensorflow.python.pywrap_tensorflow.StatusNotOK: Resource exhausted: OOM when allocating tensor with shapedim { size: 5000 } dim { size: 28 } dim { size: 28 } dim { size: 32 }
     [[Node: Conv2D_2 = Conv2D[T=DT_FLOAT, padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/cpu:0""](Const, Variable/read)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/usr/lib/python3.4/runpy.py"", line 170, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""/usr/lib/python3.4/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/models/image/mnist/convolutional.py"", line 290, in <module>
    tf.app.run()
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/platform/default/_app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/models/image/mnist/convolutional.py"", line 278, in main
    error_rate(validation_prediction.eval(), validation_labels))
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py"", line 460, in eval
    return _eval_using_default_session(self, feed_dict, self.graph, session)
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py"", line 2910, in _eval_using_default_session
    return session.run(tensors, feed_dict)
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py"", line 368, in run
    results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py"", line 444, in _do_run
    e.code)
tensorflow.python.framework.errors.ResourceExhaustedError: OOM when allocating tensor with shapedim { size: 5000 } dim { size: 28 } dim { size: 28 } dim { size: 32 }
     [[Node: Conv2D_2 = Conv2D[T=DT_FLOAT, padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/cpu:0""](Const, Variable/read)]]
Caused by op 'Conv2D_2', defined at:
  File ""/usr/lib/python3.4/runpy.py"", line 170, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""/usr/lib/python3.4/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/models/image/mnist/convolutional.py"", line 290, in <module>
    tf.app.run()
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/platform/default/_app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/models/image/mnist/convolutional.py"", line 250, in main
    validation_prediction = tf.nn.softmax(model(validation_data_node))
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/models/image/mnist/convolutional.py"", line 188, in model
    padding='SAME')
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/gen_nn_ops.py"", line 211, in conv2d
    use_cudnn_on_gpu=use_cudnn_on_gpu, name=name)
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/op_def_library.py"", line 664, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py"", line 1834, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py"", line 1043, in __init__
    self._traceback = _extract_stack()

david@ubuntu:~$ 
david@ubuntu:~$ 
"
571,Saver / tf.train.latest_checkpoint doesn't work very well with relative paths,"For example, if model is saved into a folder `test` by doing `saver.save(session, '/path/to/test')` - will result in the having `checkpoints` and `model-0` files. Where `checkpoints` file will have something like this:

```
model_checkpoint_path: ""test/model-0""
all_model_checkpoint_paths: ""test/model-0""
```

Which if you call now `tf.train.latest_checkpoint('test')` from the same directory, will result in the `None`.

This is due to `os.path.join(checkpoint_dir, ckpt.model_checkpoint_path)` which for relative path like above will result in the `test/test/model-0`.
"
566,"suppressing ""I"" log messages in tensorflow","I am using TF 0.6.0 with python 2.7.10 on both ubuntu linux and osx 10.9.5.  TF base functionality is working fine.  The issue is logging - I want to suppress the following messages that are emitted whenever I construct the first tensorflow Session:

I tensorflow/core/common_runtime/local_device.cc:40] Local device intra op parallelism threads: 2
I tensorflow/core/common_runtime/direct_session.cc:58] Direct session inter op parallelism threads: 2

They do not appear to be transmitted through the normal python logging mechanism.  Any ideas?  Did I just miss something?

I don't want to turn off all log messages, I just want TF to stop generating these two specific messages - and perhaps if you can tell me how to turn off all INFO messages from this particular (seemingly non-pythonic) source, that would be fine too.
"
565,Softmax Sampling Support,"I couldn't find all the pieces to do scheduled softmax sampling (Bengio et al, 2015), is that supported in TF atm? Is there an TensorOp that can sample from the previous layer?

Thanks!
"
564,Batchnorm gammas are all ones in the released Inception V3 model,"Every batchnorm gamma in the inception V3 model (http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz) is identically ones.  Is this a mistake?
"
563,Possible bug in seq2seq sequence_loss_by_example,"Looking at the tensorflow/python/ops/seq2seq.py file of the sequence_loss_by_example function:

```
  if softmax_loss_function is None:
    # TODO(lukaszkaiser): There is no SparseCrossEntropy in TensorFlow, so
    # we need to first cast targets into a dense representation, and as
    # SparseToDense does not accept batched inputs, we need to do this by
    # re-indexing and re-sizing. When TensorFlow adds SparseCrossEntropy,
    # rewrite this method.
    indices = targets[i] + num_decoder_symbols * math_ops.range(batch_size)
    with ops.device(""/cpu:0""):  # Sparse-to-dense must be on CPU for now.
      dense = sparse_ops.sparse_to_dense(
          indices, array_ops.expand_dims(length, 0), 1.0,
          0.0)
    target = array_ops.reshape(dense, [-1, num_decoder_symbols])
    crossent = nn_ops.softmax_cross_entropy_with_logits(
        logits[i], target, name=""SequenceLoss/CrossEntropy{0}"".format(i))
```

Isn't this a bug? the softmax_cross_entropy_with_logits doesn't take in the weights as a parameter, and hence if your sequence is heavily padded, it will bias the optimization. however, the inference perplexity is done correctly later on due to the element wise product with weights, however the gradient won't have that information, or am i wrong?

thanks!
"
562,Install problems,"I try to install tensorflow on Ubuntu 15
uname -a
Linux peter-linux 4.2.0-19-generic #23-Ubuntu SMP Wed Nov 11 11:39:30 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux
peter@peter-linux:~/tensorflow$ python
Python 2.7.10 (default, Oct 14 2015, 16:09:02) 
[GCC 5.2.1 20151010] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.

> > > exit()
> > > peter@peter-linux:~/tensorflow$ set|grep LD_LIBRARY
> > > LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/local/lib/python2.7/dist-packages/tensorflow/python/:
> > > peter@peter-linux:~/tensorflow$ set|grep CUDA
> > > CUDA_HOME=/usr/local/cuda-7.0
> > > ll /usr/local/cuda
> > > lrwxrwxrwx 1 root root 8 nov 14 11:39 /usr/local/cuda -> cuda-7.0/
> > > peter@peter-linux:~/tensorflow$ ls  /usr/local/cuda/lib64/libcudnn*
> > > /usr/local/cuda/lib64/libcudnn.so      /usr/local/cuda/lib64/libcudnn.so.6.5.48  /usr/local/cuda/lib64/libcudnn.so.7.0.64
> > > /usr/local/cuda/lib64/libcudnn.so.6.5  /usr/local/cuda/lib64/libcudnn.so.7.0     /usr/local/cuda/lib64/libcudnn_static.a
> > > peter@peter-linux:~/tensorflow$ pip -V
> > > pip 1.5.6 from /usr/lib/python2.7/dist-packages (python 2.7)
> > > pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.5.0-cp27-none-linux_x86_64.whl
> > > ......
> > >  warning: no previously-included files matching '_.pyo' found anywhere in distribution
> > >     warning: no previously-included files matching '_.pyd' found anywhere in distribution
> > >     changing mode of /home/peter/.local/bin/f2py to 775
> > > Successfully installed tensorflow six numpy
> > > Cleaning up...
> > >  python
> > > Python 2.7.10 (default, Oct 14 2015, 16:09:02) 
> > > [GCC 5.2.1 20151010] on linux2
> > > Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
> > > import tensorflow as tf
> > > Traceback (most recent call last):
> > >   File ""<stdin>"", line 1, in <module>
> > >   File ""tensorflow/**init**.py"", line 4, in <module>
> > >     from tensorflow.python import *
> > >   File ""tensorflow/tensorflow/**init**.py"", line 23, in <module>
> > >     from tensorflow.python import *
> > >   File ""tensorflow/python/**init**.py"", line 13, in <module>
> > >     from tensorflow.core.framework.graph_pb2 import *
> > >   File ""tensorflow/core/framework/graph_pb2.py"", line 6, in <module>
> > >     from google.protobuf import descriptor as _descriptor
> > > ImportError: No module named protobuf

or as it looks now
Downloading/unpacking https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.5.0-cp27-none-linux_x86_64.whl
  Downloading tensorflow-0.5.0-cp27-none-linux_x86_64.whl (50.5MB): 50.5MB downloaded
Requirement already up-to-date: six>=1.10.0 in /usr/local/lib/python2.7/dist-packages/six-1.10.0-py2.7.egg (from tensorflow==0.5.0)
Requirement already up-to-date: numpy>=1.9.2 in /home/peter/.local/lib/python2.7/site-packages (from tensorflow==0.5.0)
Installing collected packages: tensorflow
Successfully installed tensorflow
Cleaning up...
(tensorflow)peter@peter-linux:~/tensorflow$ python
Python 2.7.10 (default, Oct 14 2015, 16:09:02) 
[GCC 5.2.1 20151010] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.

> > > import tensorflow as tf
> > > Traceback (most recent call last):
> > >   File ""<stdin>"", line 1, in <module>
> > >   File ""tensorflow/**init**.py"", line 4, in <module>
> > >     from tensorflow.python import *
> > >   File ""tensorflow/tensorflow/python/**init**.py"", line 61, in <module>
> > >     from tensorflow.python.util import compat
> > > ImportError: cannot import name compat
"
561,from tensorflow.models.rnn import linear causes error in python3," from tensorflow.models.rnn import linear
  File ""/Users/Peace/Projects/venvs/allen/lib/python3.5/site-packages/tensorflow/models/rnn/linear.py"", line 25, in <module>
    linear = tf.nn.linear
AttributeError: module 'tensorflow.python.ops.nn' has no attribute 'linear'

This is using the 0.6 wheel in OS X
"
560,Syntax error when building with python3,"i followed the instructions to install Tensorflow from sources. However, before finishing the installation of the wheel with pip3 a SyntaxError: invalid syntax comes up. The error doesn't abort the installation, but when i'm trying to import Tensorflow it shows this error:

```
 >>> import tensorflow as tf
 I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library   libcublas.so.7.0 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcudnn.so.6.5 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcufft.so.7.0 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcurand.so.7.0 locally
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/__init__.py"", line 23, in <module>
    from tensorflow.python import *
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/__init__.py"", line 67, in <module>
    from tensorflow.python.training import training as train
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/training.py"", line 141, in      <module>
    from tensorflow.python.training.coordinator import Coordinator
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/coordinator.py"", line 201
    except Exception, ex:
                    ^
SyntaxError: invalid syntax
```

with python 2.7 it shows no such error and it works fine... it seems that the sources are not compatible with python3.4.

i'm running on Ubuntu 14.04 with python 3.4.3 and GCC 4.8.4.
"
559,ImportError: numpy.core.multiarray failed to import,
558,Web pages don't have titles,"None of the web pages at tensorflow.org have titles.
"
556,Tensorflow installation from local drive,"Hi,
I am trying to install Tensorflow in windows machine using docker. It's a corporate connection and I am not able to connect to daemon for installation. If there any way where I can download tensorflow in my local drive and execute it from docker?

$ docker run -it b.gcr.io/tensorflow.tensorflow
Unable to find image 'b.gcr.io/tensorflow.tensorflow:latest' locally
Error response from daemon: unable to ping registry endpoint https://b.gcr.io/v0/
v2 ping attempt failed with error: Get https://b.gcr.io/v2/: dial tcp 74.125.68.
82:443: connection refused

Please help.
"
554,Does the released Inception-v3 model only support forward pass with batch_size=1?,"Hi all,
I am new to TF. I am playing with Inception-v3 model and I found that I can only pass `batch_size=1` to the model. Here is my test code:

``` python
import tensorflow.python.platform
import tensorflow as tf
from tensorflow.python.platform import gfile
import numpy as np


with tf.device(""/cpu:0""):
    with gfile.FastGFile('/tmp/imagenet/classify_image_graph_def.pb', 'rb') as f:
        graph_def = tf.GraphDef()
        graph_def.ParseFromString(f.read())
        _ = tf.import_graph_def(graph_def, name='')

with tf.Session() as sess:

    array = np.random.rand(1, 299, 299, 3)
    image_data = tf.convert_to_tensor(array, dtype=tf.float32).eval()

    test_tensor = sess.graph.get_tensor_by_name('Mul:0')
    print(test_tensor.get_shape())
    softmax_tensor = sess.graph.get_tensor_by_name('softmax:0')
    predictions = sess.run(softmax_tensor,
                          {'Mul:0': image_data})
```

If I change `array = np.random.rand(1, 299, 299, 3)` with `batch_size=2`, then TF would complain about the size mismatch.

Am I doing something wrong? Any pointer would be of great help.
"
553,python: g != graph,"when you create a new op with say an input with name ""g"", the auto-generated python files will conflict with ""g"" because it thinks the ""g"" is the graph passed through rather than the input g due to the name overload.
"
552,TF 0.6.0 slower than 0.5.0 with the cifar10 example,"With the tensorflow/model/image/cifar10 example. While I run cifar10_train.py, 
It used to be able to achieve around 400+ examples/sec with my single K40 GPU. Today I pulled the code and installed the latest version (0.6.0x), but it can only achieve 300 examples/sec or less sometimes. 

I see Alexnet benchmark performance gets improved, but this actually use case gets worse performance. 
"
551,Lock contention in thread pool for CPU-based tensor operations,"Running the December 15 Inception model, with either serial or parallel inference steps, is showing serious lock contention on the thread pool lock, with about 50% of the CPU being spent in futex operations:

<img width=""1296"" alt=""jeremy_khan____projects_mldb"" src=""https://cloud.githubusercontent.com/assets/112556/11910933/8f720e80-a5d3-11e5-9a03-33ad7985fe3f.png"">

As an experiment, replacing the mutex with a basic spinlock reduces latency by around 35% (whilst obviously increasing CPU usage due to all of the CPUs constantly spinning even with nothing to do).  Obviously a pure spinlock is not a viable solution, but it shows that there is some scope for improvement.

This leads to three related questions:
1.  Would it be possible to allow the platform to provide its own thread pool implementation or factory?  The ThreadPool methods are virtual, so it would be possible to make it pluggable, except that the class is directly created wherever used.  In our case we have a separate thread pool that has a broadly compatible interface and we'd like to share with TensorFlow.
2.  Would it make sense to reduce the granularity of the Eigen tensor operation multithreading?
3.  If not, is there any interest in a lock free thread pool implementation?  Or is this something that somebody is already working on?
"
550,Translate.py - hard to detect convergence,"In the Sequence to Sequence machine translation example - the training pipeline only outputs perplexity numbers which are hard to interpret. If it could also output some sample translations it would be much easier for people to measure convergence

Anecdotally perplexities of around ~5 result in horrible translations - has anyone gotten it to work, and if so, what perplexities did you need to reach before you started getting reasonable translations?
"
549,Add a function unsorted_segment_max,"We have unsorted_segment_sum and segment_max , so it seems natural to also provide unsorted_segment_max, which I happen to need.
"
548,Latest dev release actually slower than 0.5,"After updating TensorFlow to the most recent source yesterday (I'm at b1cabed4e60015602dacd66ea39d419db50c3e1b), I've noticed that while GPU utilization frequently appears much higher in nividia-smi than in prior releases, my actual code is much slower. Some sequence to sequence models I was training began taking 3-4 times as long per step, despite GPU utilization hovering between 60 and 99%, which is much higher than I have observed in the past. As I have code for benchmarking fully connected feedforward networks on MNIST in various frameworks, I dusted that off and, again, slower. Previously, training a network with three hidden layers of 2,048 rectified linear units + dropout (input + hidden) took 1.78 seconds per epoch (averaged over 10 epochs)  when trained using vanilla SGD with momentum and a minibatch size of 256. That is now up to 65.2 seconds. This holds across different combinations of hidden layer sizes and minibatch sizes. On the other hand, convolutional net performance does not seem to be affected as when I run Soumith's convolutional net benchmarks, I get numbers close to what he originally reported using the same test setup.

So to summarize, I've been recompiling TensorFlow regularly (every few days since its release) and after the most recent compile noticed a quite substantial performance hit for vanilla fully connected feedforward and recurrent architectures, but not for convolutional networks. This is all with TensorFlow running on a Titan X with no other processes running and using the most recent versions of CUDA, cuDNN (well, I have v3 installed, not the release candidate for v4), cuBLAS, etc.
"
547,Tensorflow MaxPool doesn't accept float64,"I am using Tensorflow to train a CNN. I am currently basing my calculations on Float32 which is kind of default at the time of initialising variables.

I guessed that by using float64as my dtype I can get more accurate results so I changed the initilization of my varibales as follows:

`w1 = tf.Variable(tf.random_normal([5, 5, 3, 64], stddev=0.1, dtype=tf.float64))`
But I get following error in the maxpooloperation: I chacked the maxpooldocumentation and it accept value type as follow: `value: A 4-D Tensor with shape [batch, height, width, channels] and type float32, float64, qint8, quint8, qint32.`

But I get the following error. Is this a bug or I'm doing something wrong?

`Input 'input' of 'MaxPool' Op has type float64 that does not match expected type of float32.`

Full trace:

``` python
Traceback (most recent call last):
  File ""/Users/hamedketabdar/LearningTensorFlow/CIFAR-Khodam/convolutional_network_batch_2d2c_clean_64f.py"", line 213, in <module>
    pred = conv_net(x, weights, biases, keep_prob)
  File ""/Users/hamedketabdar/LearningTensorFlow/CIFAR-Khodam/convolutional_network_batch_2d2c_clean_64f.py"", line 153, in conv_net
    conv1 = max_pool(conv1, k=2) # Normally K=2
  File ""/Users/hamedketabdar/LearningTensorFlow/CIFAR-Khodam/convolutional_network_batch_2d2c_clean_64f.py"", line 135, in max_pool
    return tf.nn.max_pool(img, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.py"", line 235, in max_pool
    name=name)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 449, in _max_pool
    strides=strides, padding=padding, name=name)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py"", line 430, in apply_op
    (prefix, dtypes.as_dtype(input_arg.type).name))
TypeError: Input 'input' of 'MaxPool' Op has type float64 that does not match expected type of float32.
```

stackoverflow link: http://stackoverflow.com/questions/34354126/tensorflow-maxpool-doesnt-accept-float64
"
545,Tensorflow features,"If there any difference between Tensorflow installed on Linux machine and Windows machine in terms of features.
If yes, can anyone please list down the features available for both the machine versions.
"
543,Zero volatile GPU-Util but high GPU Memory Usage,"Hi I am running a model implemented by tensorflow with only one GPU, the GPU usage is 95% while the volatile GPU-Util is 0.

Specifically I have Tesla k40m with cuda 7.0 and cudnn 6.5v2 installed on Centos 7.0. There are three files: data_loader.py, model.py and train.py in my project. In the train.py I firstly declared 
"" with tf.device('/gpu:0'):"" and then sess.run([train_op]). When I run the code, errors raised:

""tensorflow/core/common_runtime/gpu/gpu_init.cc:45] cannot enable peer access from device ordinal 0 to device ordinal 2""

On the other hand, I installed tensorflow with Pip.

Any help are more than welcome.
"
542,"tf.transpose error when trying to transpose matrix of bools (workaround below), also recommend adding tf.repeat","I'm trying to implement some conditioning flows when training RNNs.  Basically, once an end-of-sequence event has been detected, I reset the RNN state to zeros, and have been able to build in this logic successfully I think with tf.greater() and tf.select()

I implemented a numpy.repeat(a, repeats) sort of equivalent in tensorflow.  I recommend in the future, this can be also added as a tf.repeat() function repeating a bunch of boolean values across a tensor for control flows.

Here's my implementation of a repeater (it only works for non-generalised case, for my problem, so I need to generalise it for higher dimensional tensors in the future):

```
def tfrepeat(a, repeats):
    num_row = a.get_shape()[0].value
    num_col = a.get_shape()[1].value
    assert(num_col == 1)
    result = [a for i in range(repeats)]
    result = tf.concat(0, result)
    result = tf.reshape(result, [repeats, num_row])
    result = tf.transpose(result)
    return result
```

The issue I have is I needed to transpose the result in the end to have the dimensions line up, and the results are all boolean values, and currently I noticed tf.transpose doesn't transpose a matrix of bool's

The workaround I have was to apply the functions to real numbers, and afterwards, make the end result into a large bool matrix, although this isn't ideal.

Workaround:

```
eoc_detection = inp[:,eoc_column]
eoc_detection = tf.reshape(eoc_detection, [num_batches, 1])
eoc_detection_state = tfrepeat(eoc_detection, num_state)
eoc_detection_state = tf.greater(eoc_detection_state, tf.zeros_like(eoc_detection_state,dtype=tf.float32))
new_state = tf.select(eoc_detection_state, initial_state, new_state)
```

`new_state` is the lstm state to be fed in next time. If the end of content state is detected in training, we reset it.  This way, I can allow batches of the same length to be trained.
"
540,Extract glimpse has no shape function,"I'm receiving this error when calling tf.image.extract_glimpse:

**No shape function registered for standard op: ExtractGlimpse**

Could someone confirm that this is a problem with the API itself? If so, how can I go about implementing a solution?
"
539,"Bug report, easy 1 line fix.","filename: tensorflow/python/framework/ops.py

def set_shapes_for_outputs(op):
  """"""Uses the registered shape functions to set the shapes for op's outputs.""""""
  try: 
    shape_func = _shape_registry.lookup(op.type)
  except LookupError:
    try: 
      shape_func = _default_shape_function_registry.lookup(op.type)
    except LookupError:
      raise RuntimeError(""No shape function registered for standard op: %s""
                         % op.type)
  shapes = shape_func(op)
  if len(op.outputs) != len(shapes):
    raise RuntimeError(
        ""Shape function for op %s returned %g shapes but expecting %g"" %
        (op, len(op.outputs), len(shapes)))
  for output, s in zip(op.outputs, shapes):
    output.set_shape(s)

The call of ""Shape function for op %s returned %g shapes but expecting %g"" %"" is reversed, should be (op, len(op.shapes), len(outputs)); (i swapped the shapes and outputs) ... took me awhile to debug an unrelated bug because i was getting the wrong debug message ;)
"
537,Is there a way to turn off variable reuse a number of scopes down?,"I'm having trouble with an under-sharing error for scope reuse. A specific example that I can point to using TF repo code is if we were to build an architecture with parallel attention modules.

Say we did something in the attention_decoder in rnn/seq2seq.py like this:

```
        # module can be any of ['a', 'b', 'c'...]
        with tf.variable_scope(module, reuse=None):
          k = tf.get_variable('AttnW', [1, 1, attn_size, attention_vec_size])
          hidden_features.append(tf.nn.conv2d(hidden, k, [1, 1, 1, 1], ""SAME""))
          v.append(tf.get_variable('AttnV', [attention_vec_size]))
```

I then build the model by running:

```
for module in modules:
  _outputs, _losses = seq2seq.model_with_buckets(..., 
                  lambda x, y: seq2seq.embedding_attention_seq2seq(x, y, module, False), 
                  ...)
  ...
```

This works just fine for one module, i.e. the first loop goes off without a hitch. When I get to the second module though, I get the following error:

ValueError: Under-sharing: Variable embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/b/AttnW_0 does not exist, disallowed. Did you mean to set reuse=None in VarScope?

I realize that I can build the variables up front and then push them through functions to where they're needed. However, that seems really bad because then there are floating variables built in the beginning that are way out of program scope. Is there a better way?
"
536,Add a way to see the shape of the Tensors (arrows) in Tensorboard.,"I think it would be useful to add functionality to check the calculated shape (if available) of the Tensors in the graph visualization. Maybe we could click the arrows to open a window that showed info about the tensor shape (and maybe other info too). What are your thoughts about that?
"
535,What need processing power?,"Hi,

I maybe be wrong but from what I read about machine learing the learning process is what take a lot of time and need a lot of processing power, is it true? If yes, can I teach the neural network and then use the results on a small pc like rpi?

thank you
"
534,Android Example SurfaceTextureRenderer,"i've build the app with **sdk** = 23 and **ndk** = 21 and installed the apk on a nexus 4.
_sometimes it works_ but often the camera preview is visible but without results on the top.

looking into Android Monitor, i get the following error message in case when the app doesn't work:

```
12-17 19:22:08.802 30054-30283/org.tensorflow.demo E/BufferQueueProducer: [unnamed-30054-2] dequeueBuffer: BufferQueue has been abandoned
12-17 19:22:08.802 30054-30283/org.tensorflow.demo E/Legacy-CameraDevice-JNI: LegacyCameraDevice_nativeProduceFrame: Error while producing frame No such device (-19).
12-17 19:22:08.803 30054-30283/org.tensorflow.demo W/SurfaceTextureRenderer: Surface abandoned, dropping frame. 
                                                                             android.hardware.camera2.legacy.LegacyExceptionUtils$BufferQueueAbandonedException
                                                                                 at android.hardware.camera2.legacy.LegacyExceptionUtils.throwOnError(LegacyExceptionUtils.java:64)
                                                                                 at android.hardware.camera2.legacy.LegacyCameraDevice.produceFrame(LegacyCameraDevice.java:583)
                                                                                 at android.hardware.camera2.legacy.SurfaceTextureRenderer.drawIntoSurfaces(SurfaceTextureRenderer.java:752)
                                                                                 at android.hardware.camera2.legacy.GLThreadManager$1.handleMessage(GLThreadManager.java:105)
                                                                                 at android.os.Handler.dispatchMessage(Handler.java:98)
                                                                                 at android.os.Looper.loop(Looper.java:135)
                                                                                 at android.os.HandlerThread.run(HandlerThread.java:61)
```
"
533,Provide GPU implementations for resize image methods,"As far as I can tell, these operations are only provided on CPU so far. It would be very convenient to also have GPU implementations. I'll have a go at it if there's nobody else working on it.

Edit: I mean methods such as resize_nearest_neighbor, not the reshape operator.
"
532,Disable logging,"Keep getting noise on the terminal:

```
 tensorflow/core/common_runtime/local_session.cc:45] Local session inter op parallelism threads: 8
```

Anyway to turn this off?
"
531,word2vec large corpus overflow,"I get the following error when I try to run the word2vec_optimized.py file with a corpus larger than 2^31 characters.

```
external/re2/re2/re2.cc:571: RE2: invalid startpos, endpos pair. [startpos: 0, endpos: -656988395, text size: -656988395]
W tensorflow/models/embedding/word2vec_kernels.cc:38] Invalid argument: The text file corpus_stripped.txt contains too little data: 0 words
E tensorflow/core/framework/op_segment.cc:52] Create kernel failed: Invalid argument: The text file corpus_stripped.txt contains too little data: 0 words
E tensorflow/core/common_runtime/executor.cc:262] Executor failed to create kernel. Invalid argument: The text file corpus_stripped.txt contains too little data: 0 words
     [[Node: Skipgram = Skipgram[batch_size=500, filename=""corpus_stripped.txt"", min_count=5, subsample=0.001, window_size=5, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
Traceback (most recent call last):
  File ""word2vec_optimized.py"", line 436, in <module>
    tf.app.run()
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/platform/default/_app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""word2vec_optimized.py"", line 418, in main
    model = Word2Vec(opts, session)
  File ""word2vec_optimized.py"", line 147, in __init__
    self.build_graph()
  File ""word2vec_optimized.py"", line 189, in build_graph
    opts.words_per_epoch) = self._session.run([words, counts, words_per_epoch])
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 368, in run
    results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 444, in _do_run
    e.code)
tensorflow.python.framework.errors.InvalidArgumentError: The text file corpus_stripped.txt contains too little data: 0 words
     [[Node: Skipgram = Skipgram[batch_size=500, filename=""corpus_stripped.txt"", min_count=5, subsample=0.001, window_size=5, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
Caused by op u'Skipgram', defined at:
  File ""word2vec_optimized.py"", line 436, in <module>
    tf.app.run()
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/platform/default/_app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""word2vec_optimized.py"", line 418, in main
    model = Word2Vec(opts, session)
  File ""word2vec_optimized.py"", line 147, in __init__
    self.build_graph()
  File ""word2vec_optimized.py"", line 187, in build_graph
    subsample=opts.subsample)
  File ""/usr/lib/python2.7/site-packages/tensorflow/models/embedding/gen_word2vec.py"", line 69, in skipgram
    name=name)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py"", line 664, in apply_op
    op_def=op_def)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1834, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1043, in __init__
    self._traceback = _extract_stack()
```
"
530,Tensorboard from pip installation broken ,"Tensorboard tries to load a file here https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tensorboard/tensorboard.py#L145

but `tensorboard/TAG` is missing from the pip installation, so it produces the following message:

```
WARNING:tensorflow:IOError [Errno 2] No such file or directory: '/usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/TAG' on path /usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/TAG
WARNING:tensorflow:Unable to read TensorBoard tag
Starting TensorBoard  on port 6006
(You can navigate to http://localhost:6006)
```

and does not render any logged events.
"
529,Spelling mistake in tensorflow.org,"https://www.tensorflow.org/versions/master/resources/index.html

In the white paper section:
""...can be found in **out** white paper""
"
528,tf.image.resize_images and resize_{method} should work with single image as well as batch,"Or at least not transparently do the wrong thing with the resulting shape.
At present, it's necessary to 
      image = tf.expand_dims(image, [0])
and then squeeze it before passing to resize.
"
527,"GLIBC error for RHEL, Centos clusters","After I tried all possible way to get Tensorflow work on my cluster, I re-open the issue according to this: https://github.com/tensorflow/tensorflow/issues/110

First, bazel require GLIBC 2.14, 3 issues came up, however, no solution or idea for the problem is proposed.
https://github.com/bazelbuild/bazel/issues/583
https://github.com/bazelbuild/bazel/issues/590
https://github.com/bazelbuild/bazel/issues/585

And some issues reported on Tensorflow:
https://github.com/tensorflow/tensorflow/issues/462
https://github.com/tensorflow/tensorflow/issues/53
https://github.com/tensorflow/tensorflow/issues/177

I want to emphasize that the issue is more hopeless for clusters' users, a large amount of services with old Centos remains, and it is impossible to update GLIBC on server.

I asked admin for others way around, and this is his response:

> I have made some progress in installing Tensorflow, but it turned out that the version of glibc installed on [Cluster](2.12) is not new enough.
> The version 0.1.1 of bazel checks the version of glibc during installation process and exits with an error that glibc 2.14 is not available.
> The version 0.1.0 of bazel builds successfully, but later it turns out that Tensorflow requires even newer version glibc: 2.16.
> Moreover, Glibc is very difficult, practically impossible, to install to a non-standard location, so I'm afraid that we cannot help with that either.

I can confirm that we should never try to build our own GLIBC, you cannot even type 'ls' or 'cd' on server. Hence, the only hope is from tensorflow team support.

Best Regards.
"
526,Context in use?,"Running the following with GPU support : 

`python convolutional.py`

throws the error:
`F tensorflow/stream_executor/cuda/cuda_driver.cc:383] Check failed: CUDA_SUCCESS == dynload::cuCtxSetCurrent(context) (0 vs. 216)`

`Aborted`

It seems like 216 when calling cuCtxSetCurrent (which I'm assuming assigns the context to the calling CPU thread) corresponds to CUDA_ERROR_CONTEXT_ALREADY_IN_USE. 

What may be causing this error? It seems like the script successfully transfers data to the GPU and fails when initialize_all_variables() is called. 
"
525,Consider adding tf.identity_like(),"Hey TF, 

This is not a big deal, but you may want to add an identity_like function that theano has here:
http://nullege.com/codes/search/theano.tensor.identity_like

It would be useful for orthogonality with RNN's. 

It would basically be something like:

``` python
def identity_like(input_tensor, scope = None):
  with tf.variable_scope(scope or ""identity_like""): #in this linear scope, the library that you're retriving is Linear
    shape_0 = tf.shape(input_tensor)[0]
  return tf.diag(tf.ones(shape_0))
```
"
524,More descriptive error message when op is not defined for GPU or CPU,"When trying to use MaxPoolWithArgmax I got the following error:

InvalidArgumentError: No OpKernel was registered to support Op 'MaxPoolWithArgmax' with these attrs
     [[Node: MaxPoolWithArgmax_5 = MaxPoolWithArgmax[Targmax=DT_INT64, ksize=[1, 3, 3, 1], padding=""SAME"", strides=[1, 2, 2, 1]](random_normal_4)]]

Which doesn't tell me that the op is available in GPU but not in CPU.
"
523,Import Error: Ubuntu 14.04 Python 2.7,"I followed the Pip Installation instructions and successfully downloaded tensorflow (as shown as ""Successfully installed tensorflow wheel six setuptools"").
However, when I entered ""import tensorflow as tf"" in python, it gives: 

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ImportError: No module named tensorflow

I don't know what is the problem. Help please? Thank you so much in advance! :D 
"
522,mmist failure when running with gpu on EC2,"I compiled tensorflow to run with CUDA 3.0 as described here
https://gist.github.com/erikbern/78ba519b97b440e10640

When running mint example I am getting the error below. Is there a quick explanation for this?

W tensorflow/core/common_runtime/executor.cc:1076] 0x6d39c90 Compute status: Invalid argument: Expected multiples[0] > 0, bu
t got 0
         [[Node: gradients/Mean_grad/Tile = Tile[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""](gradients/Mean
_grad/Reshape, gradients/Mean_grad/floordiv/_41)]]
W tensorflow/core/common_runtime/executor.cc:1076] 0x6d39190 Compute status: Invalid argument: Expected multiples[0] > 0, bu
t got 0
         [[Node: gradients/Mean_grad/Tile = Tile[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""](gradients/Mean
_grad/Reshape, gradients/Mean_grad/floordiv/_41)]]
         [[Node: Momentum/value/_43 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", se
nd_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_653_Momentum/value"", tensor_
type=DT_INT32, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
Traceback (most recent call last):
  File ""/usr/lib/python2.7/runpy.py"", line 162, in _run_module_as_main
    ""__main__"", fname, loader, pkg_name)
  File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code
    exec code in run_globals
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/models/image/mnist/convolutional.py"", line 290, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/default/_app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/models/image/mnist/convolutional.py"", line 272, in main
    feed_dict=feed_dict)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 368, in run
    results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 444, in _do_run
    e.code)
"
521,resize_image_with_crop_or_pad doesn't work with input pipelines,"Because `tf.image.resize_image_with_crop_or_pad()` requires its input to have a fully defined shape, it's not useful as part of an input pipeline since the size of images loaded will not be known in advance.

``` python
  queue = tf.train.string_input_producer(filenames)
  reader = tf.WholeFileReader()
  _, contents = reader.read(queue)
  image = tf.image.decode_jpeg(contents, channels=3)
  cropped = tf.image.resize_image_with_crop_or_pad(image, 224, 224)
```

Ideally the above would work...
"
520,Changing 1 kernel op requires recompile of the entire kernel package... slow : (,"For example, I make some working changes into any one tensorflow/core/my_kernel.{cc,h} file will require the recompile of the entire:

240 tf_cuda_library(
241     name = ""kernels"",

library, which may be OK for Google assuming you guys have many cores and very fast machines, but for the average developer on say mac laptop, its insanely slow ... total compile time can range several minutes : (

I am not sure what the correct solution is, either fix this in Bazel or seperate out each kernel to have its own build rule?
"
519,Can I use the GPU when installing via pip? If so where is the 'configure' script? If not where should I clone the repo?,"Hi all, 

I am installing tensorflow and am really stuck with the GPU setup ( pip install worked fine for CPU ).

I was forced to install via source because I could not find the 'configure' script anywhere at all when installing by pip. In fact the source directory was not created at all, only the 'tensorflow' folder in the level below.

To install by source I followed the tutorial here: https://www.tensorflow.org/versions/master/get_started/os_setup.html#installation-for-linux and successfully ran bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu

However, importing tensorflow into a python file gives the familiar 'No module' import error. I cloned the repo while in my home directory, but I am not sure if this is correct.

Is the pip installation supposed to allow GPU use? If so where can I locate the 'configure' script? If not where should I clone the repo, and is this the cause of the import error? 

Any help is greatly appreciated because I am very much lost! 
"
518,Unable to fetch IndexedSlices,"It appears that IndexedSlices cannot be fetched, as demonstrated by the following program, which is trying to inspect the gradients of an embedding matrix:

```
import tensorflow as tf

x = tf.placeholder(tf.int32)
y = tf.placeholder(tf.float32)
embeddings = tf.get_variable(""embeddings"", [1, 1])
loss = tf.reduce_mean(tf.square(y - tf.nn.embedding_lookup(embeddings, x)))
grads = tf.gradients(loss, embeddings)

with tf.Session() as session:
    tf.initialize_all_variables().run()
    print(""Gradient value: {}"".format(session.run(grads, { x : 0, y : 0.0 })))
```

Running the code above gives this error:

```
TypeError: Fetch argument <tensorflow.python.framework.ops.IndexedSlices object at 0x1053d69d0> of <tensorflow.python.framework.ops.IndexedSlices object at 0x1053d69d0> has invalid type <class 'tensorflow.python.framework.ops.IndexedSlices'>, must be a string or Tensor. (Can not convert a IndexedSlices into a Tensor or Operation.)
```

Is this result intended? If so, would there be a better way to inspect the gradients?

Thanks!
"
516,Feature Request: AdaDelta optimizer,"AdaDelta (http://arxiv.org/abs/1212.5701) is a popular training algorithm for Neural Network. It is available in most other libraries I have used, like Torch or chainer. 

In my small personal experience (and at least for the Neural Networks I have used), AdaDelta is often the optimizer that works best out of the box (RMSProp working quite well as well, while Adam, Adagrad and SGD typically being not as good)

Therefore, it would be nice if AdaDelta could be added to the set of available optimizers.
"
514,"MNIST works, but word2vec_basic does not","Ubuntu 15.10, tensorflow 0.6.0, Nvida Titan X

All of my MNIST example runs work fine. Other examples work great too.

Can confirm they use the GPU fine with log output.

Here's the output of word2vec_basic.py

```
~/tensorflow/tensorflow/examples/tutorials/word2vec$ python word2vec_basic.py
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcublas.so.7.0 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcudnn.so.6.5 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcufft.so.7.0 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcurand.so.7.0 locally
Found and verified text8.zip
Data size 17005207
Most common words (+UNK) [['UNK', 418391], ('the', 1061396), ('of', 593677), ('and', 416629), ('one', 411764)]
Sample data [5239, 3084, 12, 6, 195, 2, 3137, 46, 59, 156]
3084 -> 5239
originated -> anarchism
3084 -> 12
originated -> as
12 -> 6
as -> a
12 -> 3084
as -> originated
6 -> 195
a -> term
6 -> 12
a -> as
195 -> 2
term -> of
195 -> 6
term -> a
I tensorflow/core/common_runtime/local_device.cc:40] Local device intra op parallelism threads: 8
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:909] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:103] Found device 0 with properties:
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.2405
pciBusID 0000:03:00.0
Total memory: 12.00GiB
Free memory: 11.21GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:127] DMA: 0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:137] 0:   Y
I tensorflow/core/common_runtime/gpu/gpu_device.cc:702] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:03:00.0)
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Allocating 10.65GiB bytes.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:52] GPU 0 memory begins at 0xb06c80000 extends to 0xdb07d7e67
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 16.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 32.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 64.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 128.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 256.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 512.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 16.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 32.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 64.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 128.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 256.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 512.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 16.00GiB
I tensorflow/core/common_runtime/direct_session.cc:58] Direct session inter op parallelism threads: 8
Initialized
Traceback (most recent call last):
  File ""word2vec_basic.py"", line 189, in <module>
    _, loss_val = session.run([optimizer, loss], feed_dict=feed_dict)
  File ""/home/paul/.virtualenvs/mypy/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 368, in run
    results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)
  File ""/home/paul/.virtualenvs/mypy/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 444, in _do_run
    e.code)
tensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'GradientDescent/update_Variable_2/ScatterSub': Could not satisfy explicit device specification '' because the node was colocated with a group of nodes that required incompatible device '/job:localhost/replica:0/task:0/GPU:0'
     [[Node: GradientDescent/update_Variable_2/ScatterSub = ScatterSub[T=DT_FLOAT, Tindices=DT_INT64, use_locking=false](Variable_2, gradients/concat_1, GradientDescent/update_Variable_2/mul)]]
Caused by op u'GradientDescent/update_Variable_2/ScatterSub', defined at:
  File ""word2vec_basic.py"", line 163, in <module>
    optimizer = tf.train.GradientDescentOptimizer(1.0).minimize(loss)
  File ""/home/paul/.virtualenvs/mypy/local/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py"", line 188, in minimize
    name=name)
  File ""/home/paul/.virtualenvs/mypy/local/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py"", line 289, in apply_gradients
    update_ops.append(self._apply_sparse(grad, var))
  File ""/home/paul/.virtualenvs/mypy/local/lib/python2.7/site-packages/tensorflow/python/training/gradient_descent.py"", line 59, in _apply_sparse
    return var.scatter_sub(delta, use_locking=self._use_locking)
  File ""/home/paul/.virtualenvs/mypy/local/lib/python2.7/site-packages/tensorflow/python/ops/variables.py"", line 392, in scatter_sub
    use_locking=use_locking)
  File ""/home/paul/.virtualenvs/mypy/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_state_ops.py"", line 227, in scatter_sub
    name=name)
  File ""/home/paul/.virtualenvs/mypy/local/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py"", line 664, in apply_op
    op_def=op_def)
  File ""/home/paul/.virtualenvs/mypy/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1834, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/home/paul/.virtualenvs/mypy/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1043, in __init__
    self._traceback = _extract_stack()
```
"
513,Support for MLP batch normalization,"any plans to support batch normalization for MLP soon?
"
512,Possible bug in attention seq2seq,"source file is seq2seq.py

```
def attention(query):
  """"""Put attention masks on hidden using hidden_features and query.""""""
  ds = []  # Results of attention reads will be stored here.
  for a in xrange(num_heads):
    with vs.variable_scope(""Attention_%d"" % a): 
      y = rnn_cell.linear(query, attention_vec_size, True)
      y = array_ops.reshape(y, [-1, 1, 1, attention_vec_size])
      # Attention mask is a softmax of v^T * tanh(...).
      s = math_ops.reduce_sum(
          v[a] * math_ops.tanh(hidden_features[a] + y), [2, 3]) 
      a = nn_ops.softmax(s)
      # Now calculate the attention-weighted vector d.
      d = math_ops.reduce_sum(
          array_ops.reshape(a, [-1, attn_length, 1, 1]) * hidden,
          [1, 2]) 
      ds.append(array_ops.reshape(d, [-1, attn_size]))
  return ds
```

at line 440, you compute the energies, ok… then at line 441 you normalize the energies… you need to do a -FLT_MAX mask on only the part of the encoder sequence (i.e., you don’t want to pay attention to “empty” part of the sequence)... I don't see the masking op? Or am i missing something?

I can wrap an op patch for this if nobody is working on this (let me know).

Thanks all!
"
511,"Large RNN graphs, incredibly slow graph creation and step time...","When I build a large seq2seq RNN graph (i.e., 3000 timesteps encoder, and 100 time steps decoder), both the graph construction and step time is insanely slow.

For example, using approx 3000 timesteps of stacked 4 layers of GRUs (in a seq2seq model w/ attention), we get something like this:

**\* graph creation time ***
create_encoder graph time 77.442740
create_decoder graph time 7.298214
create_loss graph time 0.934293
create_optimizer graph time 349.426908
create_model graph time 489.119399

create_optimizer is the part where i call something like this (pulled from the tutorial):
  def create_optimizer(self):
    start_time = time.time()

```
params = tf.trainable_variables()

self.gradient_norms = []
self.updates = []
opt = tf.train.GradientDescentOptimizer(0.001)

gradients = tf.gradients(self.losses, params)
clipped_gradients, norm = tf.clip_by_global_norm(gradients, self.max_gradient_norm)

self.gradient_norms.append(norm)
self.updates.append(opt.apply_gradients(
    zip(clipped_gradients, params), global_step=self.global_step))

print('create_optimizer graph time %f' % (time.time() - start_time))
```

**\* step time ***
step_time: 142.356251001

When I run nvidia-smi while the graph is computing , the utilization is something like 12% ... definitely something wrong...

In my personal framework (not TF), creating a graph of equal size takes approx 2 secs (as opposed to TF almost 8 mins) and the step time is less 4 seconds (as opposed to TF 2 mins).... something really weird is going on.

I wasn't able to profile / debug it too much (are there public tools for that? i cant find anything on tensorboard). also, is there a command i can run to confirm how many weights i have (and the dimensions and the device location of the variables).

I've confirmed with the tensorboard and log_device_placement=True, and seems like most of the graph is in the GPU (except for embedding layers).

If you want a link to my graph, send me an email.

Thanks All!
"
510,Sequence labelling tutorial,"Thank you for the great job and the tensorflow. But I don't think the tutorial on LSTM is clearly enough. In addition, I suggest adding sequence labelling tutorial on LSTM tutorial for better explanation.
"
509,error with tf.app.flags in fully_connected_feed.py,"I am getting the following error when I try to use flags. Can you please advise?
Thanks

flags = tf.app.flags
FLAGS = flags.FLAGS
flags.DEFINE_float('learning_rate', 0.01, 'Initial learning rate.')
flags.DEFINE_integer('max_steps', 2000, 'Number of steps to run trainer.')
flags.DEFINE_integer('hidden1', 128, 'Number of units in hidden layer 1.')
flags.DEFINE_integer('hidden2', 32, 'Number of units in hidden layer 2.')
flags.DEFINE_integer('batch_size', 100, 'Batch size.  '
                     'Must divide evenly into the dataset sizes.')
flags.DEFINE_string('train_dir', 'data', 'Directory to put the training data.')
flags.DEFINE_boolean('fake_data', False, 'If true, uses fake data '
                     'for unit testing.')

The error is:

usage: **main**.py [-h] [--learning_rate LEARNING_RATE]
                   [--max_steps MAX_STEPS] [--hidden1 HIDDEN1]
                   [--hidden2 HIDDEN2] [--batch_size BATCH_SIZE]
                   [--train_dir TRAIN_DIR] [--fake_data FAKE_DATA]
                   [--nofake_data]
**main**.py: error: unrecognized arguments: -f /Users/sergulaydore/.ipython/profile_default/security/kernel-3561b41d-e378-459a-9e96-5333ea079712.json --profile-dir /Users/sergulaydore/.ipython/profile_default
"
508,Document the broadcasting behavior for `tf.mul` etc.,"The fact that many of the elementwise operators in TensorFlow support numpy-style broadcasting is not well documented or discoverable. (e.g. [This SO question.](http://stackoverflow.com/questions/34220374/apply-1-channel-mask-to-3-channel-tensor-in-tensorflow/34220963)) We should improve the documentation on this.
"
507,"New type of decays, esp. for learning rate ","After playing around TF for multiple CNN models with different optimizers (SGD and Adam) I found it difficult to find the best time to decay from only steps number. 
- It would be nice if you add decay based on changes in a loss, as it was common, if loss doesn't change for a threshold of a step and amount, then decay it. 
- The other feature may be useful is to increase the decay steps as it goes further, for example decay it each 200 steps for the first 2,000 steps and then decay it for each 1,000 steps to the rest or another decay level which can be decay it only each 5,000 after step 100,000.
"
506,ptb_word_lm.py error: unsupported operand type(s) for /: 'Tensor' and 'int',"Hi,

I ran the `ptb_word_lm` example from `models/rnn/ptb`. however I got the `unsupported operand type(s) for /: 'Tensor' and 'int'` for line 139 in `ptb_word_lm.py`.

I also managed to fix it, by changing 
139 `self._cost = cost = tf.reduce_sum(loss) / batch_size`
to
139 `self._cost = cost = tf.div(tf.reduce_sum(loss), tf.constant(batch_size, dtype=tf.types.float32))`

And it works fine so far.
"
505,Momentum and Adagrad don't work with reshape and embeddings,"Momentum and Adagrad optimizers do not work when I use `tf.reshape` like this:

``` python
embeddings = tf.Variable(                                                                                                  
    tf.random_uniform([50000, 50], -1.0, 1.0))

embed = tf.reshape(                                                                                                        
        tf.nn.embedding_lookup(embeddings, input_op),                                                                          
        [-1, em_layer_size])

# a few dense layers and a softmax would follow here
```

The code above works with SGD and AdamOptimizer. With Momentum or Adagrad it produces this error:

```
    optimizer = tf.train.MomentumOptimizer(0.01, 0.9).minimize(loss)
  File ""/home/tom/tf-env/local/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py"", line 188, in minimize
    name=name)
  File ""/home/tom/tf-env/local/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py"", line 289, in apply_gradients
    update_ops.append(self._apply_sparse(grad, var))
  File ""/home/tom/tf-env/local/lib/python2.7/site-packages/tensorflow/python/training/momentum.py"", line 70, in _apply_sparse
    self._momentum_tensor, use_locking=self._use_locking).op
  File ""/home/tom/tf-env/local/lib/python2.7/site-packages/tensorflow/python/training/gen_training_ops.py"", line 237, in sparse_apply_momentum
    name=name)
  File ""/home/tom/tf-env/local/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py"", line 664, in apply_op
    op_def=op_def)
  File ""/home/tom/tf-env/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1836, in create_op
    set_shapes_for_outputs(ret)
  File ""/home/tom/tf-env/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1476, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/home/tom/tf-env/local/lib/python2.7/site-packages/tensorflow/python/training/training_ops.py"", line 130, in _SparseApplyMomentumShape
    tensor_shape.TensorShape([None]).concatenate(accum_shape[1:]))
  File ""/home/tom/tf-env/local/lib/python2.7/site-packages/tensorflow/python/framework/tensor_shape.py"", line 527, in merge_with
    self.assert_same_rank(other)
  File ""/home/tom/tf-env/local/lib/python2.7/site-packages/tensorflow/python/framework/tensor_shape.py"", line 570, in assert_same_rank
    ""Shapes %s and %s must have the same rank"" % (self, other))
ValueError: Shapes TensorShape([Dimension(None), Dimension(None), Dimension(None)]) and TensorShape([Dimension(None), Dimension(50)]) must have the same rank
```

This might be connected to #464, the error is similar and also appears with Momentum and Adagrad. 

When I replace the `tf.reshape` with following code, the error disappears:

``` python
_emb = []                                                                                                                 
for x in tf.split(1, 4, input_op):                                                                          
    _emb.append(tf.nn.embedding_lookup(embeddings, tf.squeeze(x)))                                                        
embed = tf.concat(1, _emb) 
```
"
504,Transfer learning tutorial,"The [image recognitions tutorial](https://www.tensorflow.org/versions/master/tutorials/image_recognition/index.html#usage-with-python-api) suggests exploring transfer learning as an exercise. I would like to see a tutorial dedicated to the topic and would be especially interested in transfer learning using the Inception-V3 model.
"
503,Request to add API documentation for using tf.flags,"I saw some tensorflow project contains hyperparameter configuration like:
`tf.flags.DEFINE_integer(""embedding_dim"", 128, ""Dimensionality of character embedding (default: 128)"")`

I think it is better to add corresponding document for using this feature. 
"
502,Native arm 32 bit compilation,"Having issues compiling natively TensorFlow. The process fails over and over at this point:

```
erle@erle-brain-2 ~/tensorflow $ ../bazel-0.1.2/output/bazel build -c opt //tensorflow/tools/pip_package:build_pip_package --local_resources 1024,.5,1.0 -s --spawn_strategy=standalone --genrule_strategy=standalone --verbose_failures
.............................................................................................................................................................................................
INFO: Waiting for response from Bazel server (pid 15928)...
WARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.io/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.
ERROR: /home/erle/tensorflow/tensorflow/tensorboard/bower/BUILD:3:1: no such package '@accessibility-developer-tools//': SSL peer shut down incorrectly and referenced by '//tensorflow/tensorboard/bower:bower'.
ERROR: Loading failed; build aborted.
INFO: Elapsed time: 990.385s.
```

Also tried with bazel `0.1.1`. Same result.
Thanks,
"
501,assertion when running on GPU with debug enabled,"when I compile TensorFlow with --config=cuda  -c dbg --strip=never, I get an assertion when running the mnist example (same goes for cifar10. Also tried CUDA 7.5, with same outcome. Reproduces with both TF 0.5.0 and TF 0.6.0.)

The GPU being used is a Titan X.

[~/tensorflow/tensorflow/models/image/mnist] python convolutional.py
 ......
python: third_party/eigen3/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceType.h:734: void Eigen::assertCudaOk(): Assertion `err == cudaSuccess' failed.
Aborted (core dumped)

dmesg shows that an illegal memory access was performed:
[780540.251853] NVRM: Xid (PCI:0000:03:00): 31, Ch 0000000f, engmask 00000101, intr 10000000

any when running with cuda-memcheck, I get:
========= CUDA-MEMCHECK
========= Invalid **global** read of size 4
=========     at 0x000002f0 in /opt/bas/bazel/_bazel_bas/194e5d2548bb77b7040a7c94ff604a15/tensorflow/third_party/eigen3/unsupported/Eigen/CXX11/src/Tensor/TensorEvaluator.h:346:_ZNK5Eigen15TensorEvaluatorIKNS_18TensorCwiseUnaryOpINS_8internal13scalar_log_opIfEEKNS_9TensorMapINS_6TensorIfLm2ELi1ElEELi1EEEEENS_9GpuDeviceEE6packetILi1EEE6float4l
=========     by thread (15,0,0) in block (0,0,0)
=========     Address 0x00000000 is out of bounds
=========     Device Frame:/opt/bas/bazel/_bazel_bas/194e5d2548bb77b7040a7c94ff604a15/tensorflow/third_party/eigen3/unsupported/Eigen/CXX11/src/Tensor/TensorEvalTo.h:122:Eigen::TensorEvaluatorEigen::TensorEvalToOp<Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_log_op<float, Eigen::TensorMap<Eigen::Tensor<float, unsigned long=2, int=1, long>, int=1> const > const > const , Eigen::GpuDevice(long)>::evalPacket (Eigen::TensorEvaluatorEigen::TensorEvalToOp<Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_log_op<float, Eigen::TensorMap<Eigen::Tensor<float, unsigned long=2, int=1, long>, int=1> const > const > const , Eigen::GpuDevice(long)>::evalPacket : 0x350)
=========     Device Frame:/opt/bas/bazel/_bazel_bas/194e5d2548bb77b7040a7c94ff604a15/tensorflow/third_party/eigen3/unsupported/Eigen/CXX11/src/Tensor/TensorExecutor.h:407:void Eigen::internal::EigenMetaKernel_VectorizableEigen::TensorEvaluator<Eigen::TensorEvalToOp<Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_log_op<float, Eigen::TensorMap<Eigen::Tensor<float, unsigned long=2, int=1, long>, int=1> const > const > const , Eigen::GpuDevice>, long>(float, Eigen::internal::scalar_log_op<float>) (void Eigen::internal::EigenMetaKernel_VectorizableEigen::TensorEvaluator<Eigen::TensorEvalToOp<Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_log_op<float, Eigen::TensorMap<Eigen::Tensor<float, unsigned long=2, int=1, long>, int=1> const > const > const , Eigen::GpuDevice>, long>(float, Eigen::internal::scalar_log_op<float>) : 0x1460)
=========     Saved host backtrace up to driver entry point at kernel launch time
=========     Host Frame:/usr/lib/x86_64-linux-gnu/libcuda.so (cuLaunchKernel + 0x2cd) [0x15865d]
=========     Host Frame:/usr/local/cuda/lib64/libcudart.so.7.0 [0x131b0]
=========     Host Frame:/usr/local/cuda/lib64/libcudart.so.7.0 (cudaLaunch + 0x143) [0x2d653]
=========     Host Frame:/home/users/bas/.python_packages/package1/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so [0xb4bc036]
=========     Host Frame:/home/users/bas/.python_packages/package1/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so [0xb4bb2f8]
.....

The assertion changes from run to run (non determinism due to multi threading), but the cause is always the NULL pointer dereference in float4 Eigen::TensorEvaluatorEigen::TensorCwiseUnaryOp<Eigen::internal::scalar_log_op<float, Eigen::TensorMap<Eigen::Tensor<float, 2ul, 1, long>, 1> const> const, Eigen::GpuDevice>::packet<1>(long) const

Could be an nvcc compiler bug  in debug mode only (kernel runs fine when optimized)
"
500,MacOS X El Capitan Tensorflow 0.6 upgrade error,"Had a good-running 0.5 tensor flow, now upgrade to 0.6 with command line from Google instruction:
""sudo pip install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.6.0-py2-none-any.whl"", run into following exception:
""Installing collected packages: setuptools, protobuf, wheel, tensorflow
  Found existing installation: setuptools 1.1.6
    Uninstalling setuptools-1.1.6:
Exception:
Traceback (most recent call last):
  File ""/Library/Python/2.7/site-packages/pip-7.1.2-py2.7.egg/pip/basecommand.py"", line 211, in main
    status = self.run(options, args)
  File ""/Library/Python/2.7/site-packages/pip-7.1.2-py2.7.egg/pip/commands/install.py"", line 311, in run
    root=options.root_path,
  File ""/Library/Python/2.7/site-packages/pip-7.1.2-py2.7.egg/pip/req/req_set.py"", line 640, in install
    requirement.uninstall(auto_confirm=True)
  File ""/Library/Python/2.7/site-packages/pip-7.1.2-py2.7.egg/pip/req/req_install.py"", line 716, in uninstall
    paths_to_remove.remove(auto_confirm)
  File ""/Library/Python/2.7/site-packages/pip-7.1.2-py2.7.egg/pip/req/req_uninstall.py"", line 125, in remove
    renames(path, new_path)
  File ""/Library/Python/2.7/site-packages/pip-7.1.2-py2.7.egg/pip/utils/**init**.py"", line 315, in renames
    shutil.move(old, new)
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py"", line 299, in move
    copytree(src, real_dst, symlinks=True)
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py"", line 208, in copytree
    raise Error, errors
Error: [('/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/__init__.py', '/tmp/pip-XBiBee-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/__init__.py', ""[Errno 1] Operation not permitted: '/tmp/pip-XBiBee-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/__init__.py'""), ('/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/__init__.pyc', '/tmp/pip-XBiBee-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/__init__.pyc', ""[Errno 1] Operation not permitted: '/tmp/pip-XBiBee-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/__init__.pyc'""), ('/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/markers.py', '/tmp/pip-XBiBee-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/markers.py', ""[Errno 1] Operation not permitted: '/tmp/pip-XBiBee-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/markers.py'""), ('/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/markers.pyc', '/tmp/pip-XBiBee-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/markers.pyc', ""[Errno 1] Operation not permitted: '/tmp/pip-XBiBee-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/markers.pyc'""), ('/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib', '/tmp/pip-XBiBee-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib', ""[Errno 1] Operation not permitted: '/tmp/pip-XBiBee-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib'"")]

It's stock Mac python 2.7.10 (without ipython).
"
499,using #pragma once,"Shouldn't we use both `pragma` once and `ifndef` gaurds ?
"
498,Installation exception in EI Capitan,"I just installed homebrew, and also set brew python as default.
when I import tensorflow:

`````` javascript
Python 2.7.11 (default, Dec 13 2015, 19:34:28)
[GCC 4.2.1 Compatible Apple LLVM 7.0.0 (clang-700.1.76)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 23, in <module>
    from tensorflow.python import *
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 43, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 37, in <module>
    from tensorflow.core.framework.graph_pb2 import *
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/core/framework/graph_pb2.py"", line 6, in <module>
    from google.protobuf import descriptor as _descriptor
ImportError: No module named protobuf


Error importing tensorflow.  Unless you are using bazel,
you should not try to import tensorflow from its source directory;
please exit the tensorflow source tree, and relaunch your python interpreter
from there.```

what is the problem?
I can't find the solution anywhere
``````
"
497,Add reference to CONTRIBUTING.md,"Can we add in some way a reference to https://github.com/tensorflow/tensorflow/issues/26
"
496,tensorflow/core/user_kernels needed,"correct me if I am wrong, but I believe a subdir of tensorflow/core/user_kernels is needed to support user written GPU kernels (CPU is fine), this is due to the build rules in tensorflow/core/BUILD when building the user_ops_op_lib is a cc_library rather than say tf_cuda_library.
"
495,"cannot use tf.nn.elu(features, name=None)","Error Message:
AttributeError: 'module' object has no attribute 'elu'

When I try to use tf.nn.elu. 

Is it not written in the package yet?  Why it is included in the API document?
"
494,"What is quantized data type? For instance qint8, quint8, qint32","In tensorflow document of class tf.DType: https://www.tensorflow.org/versions/master/api_docs/python/framework.html#DType

There are three types:
tf.qint8: Quantized 8-bit signed integer.
tf.quint8: Quantized 8-bit unsigned integer.
tf.qint32: Quantized 32-bit signed integer.

And also related method about quantized data type. I searched online, but did not find useful resource about it. 
Could you add some explanation in the document?
"
493,dual gpu memory allocation problem in 0.6,"For the tensorflow 0.6, when I specifically assign the model on one gpu on a dual-gpu machine, it takes up the memory of both gpus.

This problem does not happen for tensorflow 0.5
"
492,memory issues,"Hi,

It seems the memory allocation of tensorflow is rather inefficient. I have been running a single layer rnn with 256 batch size, 124 length and dim of 512, it constantly gets memory not enough error for my 4GB 980. In theory, the model size is much less than 1GB

no matter how large the batch size I set, it always use up all the 4GB memory, which is unreasonable. I have been compiling tensorflow from the source and BFC memory allocator is set as default.

I think the memory problem was also mentioned here 
https://github.com/soumith/convnet-benchmarks/issues/66
and mentioned by many other users. In compare with Theano and Torch, tensorflow can only experiment with smaller models.

Are there any solutions to this? This is a major problem that stops me from experimenting with tensorflow.

Many thanks!!
"
491,Mac OS X GPU Support Request,"Hi Team

Currently I've been doing some work with TensorFlow (some of my work on http://blog.otoro.net/) and have been developing everything a Macbook Pro running the IPython stack.  My Mac is fairly fast for regular sized tasks, and even has an NVIDA chip (NVIDIA GeForce GT 750M 2048 MB).  Although the current build doesn't support GPU's for Macs, it seems to me from reading earlier threads that it is not possible to custom build for GPU support on the Mac, despite having CUDA libraries installed.

This would really help out my work flow, especially I can get other frameworks to utilize my GPU / CUDA on the Mac.  The Macbook Pro is a great machine to develop use and develop stuff on, and lots of people I know also use MBP's to develop ML algorithms, and then send jobs off to AWS for the heavy-lifting after it works locally.

I think having GPU support for Mac would really help in not just the performance front, but allows us to debug and check any GPU specific issues when running some script locally, and be able to fix them quickly, before sending them to a EC2 or some remote GPU server.  It would make the workflow a lot smoother for developers who use Macbook Pro's with the NVIDIA chip.

Thanks in advance!
"
490,Error in TF.pad API docs,"Please note the following error in tf.pad in ""array_ops.md"":

Example 1 currently reads as follows:

```
# 't' is [[1, 1], [2, 2]]
# 'paddings' is [[1, 1]], [2, 2]] ##This is not a valid tensor
# rank of 't' is 2
pad(t, paddings) ==> 
     [[0, 0, 0, 0, 0] ##This is not the correct output
      [0, 0, 0, 0, 0]
      [0, 1, 1, 0, 0]
     [[0, 2, 2, 0, 0]
      [0, 0, 0, 0, 0]]
```

It can be fixed as follows:

```
# 't' is [[1, 1], [2, 2]]
# 'paddings' is [[1, 1], [2, 2]]
# rank of 't' is 2
pad(t, paddings) ==> 
    [[0, 0, 0, 0, 0, 0]
     [0, 0, 1, 1, 0, 0]
     [0, 0, 2, 2, 0, 0]
     [0, 0, 0, 0, 0, 0]]
```
"
489,tensorflow hello world catch error,"this is my installation info

```
sudo -H pip install https://storage.googleapis.com/tensorflow/mac/tensorflow-0.5.0-py2-none-any.whl
Requirement already satisfied (use --upgrade to upgrade): tensorflow==0.5.0 from https://storage.googleapis.com/tensorflow/mac/tensorflow-0.5.0-py2-none-any.whl in /Library/Python/2.7/site-packages
Requirement already satisfied (use --upgrade to upgrade): six>=1.10.0 in /Library/Python/2.7/site-packages (from tensorflow==0.5.0)
Requirement already satisfied (use --upgrade to upgrade): numpy>=1.9.2 in /Library/Python/2.7/site-packages (from tensorflow==0.5.0)
```

but when I run the code in readme I got this error

```
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/Library/Python/2.7/site-packages/tensorflow/__init__.py"", line 4, in <module>
    from tensorflow.python import *
  File ""/Library/Python/2.7/site-packages/tensorflow/python/__init__.py"", line 13, in <module>
    from tensorflow.core.framework.graph_pb2 import *
  File ""/Library/Python/2.7/site-packages/tensorflow/core/framework/graph_pb2.py"", line 8, in <module>
    from google.protobuf import reflection as _reflection
  File ""/Library/Python/2.7/site-packages/google/protobuf/reflection.py"", line 58, in <module>
    from google.protobuf.internal import python_message as message_impl
  File ""/Library/Python/2.7/site-packages/google/protobuf/internal/python_message.py"", line 59, in <module>
    import six.moves.copyreg as copyreg
ImportError: No module named copyreg
```

six i has installed.
I'm a python fresher.
"
488,when i install i got this error,
487,TypeError: metaclass conflict in Python 2 and 3,"TF 0.6.0 installed using PIP gives the following error on import in both Python 2 and 3:

```
>>> import tensorflow
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/user/.local/lib/python3.4/site-packages/tensorflow/__init__.py"", line 23, in <module>
    from tensorflow.python import *
  File ""/home/user/.local/lib/python3.4/site-packages/tensorflow/python/__init__.py"", line 37, in <module>
    from tensorflow.core.framework.graph_pb2 import *
  File ""/home/user/.local/lib/python3.4/site-packages/tensorflow/core/framework/graph_pb2.py"", line 10, in <module>
    from google.protobuf import descriptor_pb2
  File ""/home/user/.local/lib/python3.4/site-packages/google/protobuf/descriptor_pb2.py"", line 1533, in <module>
    __module__ = 'google.protobuf.descriptor_pb2'
  File ""/home/user/.local/lib/python3.4/site-packages/google/protobuf/reflection.py"", line 123, in __new__
    new_class = superclass.__new__(cls, name, bases, dictionary)
TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases
```
"
486,string_input_producer has no analogue for other dtypes,"It would be nice to a corresponding int_input_producer for producing a queue cycles through labels, for instance. This is a super easy fix by just adding another wrapper around _input_producer.
"
485,Backport for moved models.rnn.linear doesn't work,"In v0.6 linear got moved into `ops.rnn_cell.linear`, but backport here `https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/linear.py` points to `tf.nn.linear`.

This break code with v0.5.
"
484,Move public protobufs into a special directory,"Currently all the `.proto` definitions are in `core/framework`, but not all of them are public.  For now I'm going to list the public ones in the version document, but this is obviously silly.
"
483,Request for angle,"Getting the angle of a complex number is another mathematical operation that would be useful / basic to have, along the lines of [np.angle](http://docs.scipy.org/doc/numpy/reference/generated/numpy.angle.html).
"
482,error in running sequence to sequence model demo using bazel,"![1](https://cloud.githubusercontent.com/assets/10511526/11749467/edc39e5c-a053-11e5-90f7-739ef703e47c.png)
![2](https://cloud.githubusercontent.com/assets/10511526/11749468/edc7d7ba-a053-11e5-8d04-0532412c76d2.png)

  I am using bazel for compiling and run in tensor flow. when i try to run the sequence to sequence example i got the following error. If anyone knows help us. I also tried to execute
 using python translate.py --data_dir <path for data>. it is also showing an error. The image 1 shows the error when i try with bazel and image 2 shows the error when i try with python translate.py method.

for bazel

bazel run -c opt <...>/models/rnn/translate/translate.py
  --data_dir [your_data_directory]

showing error

ERROR: Cannot run target //tensorflow/models/rnn/translate:translate.py: Not executable.
INFO: Elapsed time: 0.089s
ERROR: Build failed. Not running target.

python translate.py showing error

Traceback (most recent call last):
  File ""translate.py"", line 46, in <module>
    from tensorflow.models.rnn.translate import data_utils
ImportError: No module named translate
"
481,Error Running cifar10_train.py in Ver 0.6.0 ,"The cifar-10 demo ran fine under 0.5.0 but gives errors under 0.6.0 (I rolled back to 0.5.0 and confirmed this). Also cifar10_multi_gpu_train.py works under 0.6.0 as well as 0.5.0.  The output I'm getting when running cifar10_train.py in 0.6.0 is attached. I'm running under Ubuntu 14.04.
[error.txt](https://github.com/tensorflow/tensorflow/files/59525/error.txt)
"
480,2 bugs in training/input.py,"In the `_dtype()` method in the training/input.py file, the following code for TypeError:

```
  raise TypeError(""Expected types to be consistent: %s vs. %s."" %
                  "", "".join(x.name for x in types),
                  "", "".join(x.name for x in other_types))
```

should be:

```
  raise TypeError(""Expected types to be consistent: %s vs. %s."" %
                  ("", "".join(x.name for x in types),
                  "", "".join(x.name for x in other_types)))
```

Also, when using the `tf.train.shuffle_batch_join()` method, you are suppose to pass a list of tuples of tensors, but if you pass a list of tuple and each tuple _only contains one item_, python will ignore the tuples and simply make it into a list. Thus, when the _flatten method in training/inputs.py is called, a `TypeError: 'Tensor' object is not iterable` is thrown. I suppose it's not necessarily a bug as one should know if you want to pass a tuple containing just one item, you must put a comma at the end of the tuple, but it may still may cause confusion.

Instead, _flatten could be:

```
def _flatten(tensor_list_list):
        for elm in tensor_list_list:
            if not isinstance(elm, tuple):
                raise TypeError(""tensor_list_list must contain tuples."")
        return [tensor for tensor_list in tensor_list_list for tensor in tensor_list]
```
"
479,undefined symbol: PyUnicode_AsUTF8String,"Hi, when I try to do `import tensorflow` I receive the following error:

```
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 23, in <module>
    from tensorflow.python import *
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 50, in <module>
    from tensorflow.python.framework.framework_lib import *
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/framework_lib.py"", line 62, in <module>
    from tensorflow.python.framework.ops import Graph
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 40, in <module>
    from tensorflow.python.framework import versions
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/versions.py"", line 24, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 28, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)
ImportError: /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so: undefined symbol: PyUnicode_AsUTF8String
```

OS is Ubuntu 14.04, and I get the same error with both python2.7 and python3.4.

The binaries works fine, but I'm trying to install from source cause I need support for CUDA 3.0.

Thanks
"
478,Extend tf.unsorted_segment_sum to allow 'rejecting' entries,"As already discussed in #466, it would be useful to be able to mark entries which are not to be summed anywhere by assigning negative indexes (or just -1) there. @girving suggested, that this behavior should only be enabled when setting a flag (e. g. `drop_negatives`) to preserve the existing error detection behavior, which I support. 
"
477,An error occurred while installing,"OS：ubuntu 15
python：2.7.9

error Log：
/usr/bin/pip run on Fri Dec 11 12:02:09 2015
tensorflow-0.5.0-cp27-none-linux_x86_64.whl is not a supported wheel on this platform.
Exception information:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/dist-packages/pip/basecommand.py"", line 122, in main
    status = self.run(options, args)
  File ""/usr/lib/python2.7/dist-packages/pip/commands/install.py"", line 283, in run
    InstallRequirement.from_line(name, None))
  File ""/usr/lib/python2.7/dist-packages/pip/req.py"", line 168, in from_line
    raise UnsupportedWheel(""%s is not a supported wheel on this platform."" % wheel.filename)
UnsupportedWheel: tensorflow-0.5.0-cp27-none-linux_x86_64.whl is not a supported wheel on this platform.
"
476,Make Sure Full Functionality is Available in C/C++,"Please make sure all the functionality is defined in the C++ core.
"
474,How to change the type of placeholder,"I declared a placeholder with labels=tf.placeholder(tf.float32,shape=(5)), 
while when I checked the shape of 'labels' with tf.shape(labels), it returned 
Tensor(""Shape_2:0"", shape=TensorShape([Dimension(1)]), dtype=int32, device=/gpu:1) TensorShape([Dimension(5)]). 

Obviously I set labels as tf.float32, it is actually int32. How can I resolve it. Thanks in advance. 
"
473,Occupies GPU even if it is not compatible,"As the title states, even if a GPU is not CUDA compatible, Tensorflow will occupy the GPU and then proceed to ignore it.

Here's a use case : 

CUDA_VISIBLE_DEVICES=3 python convolutional.py
....
I tensorflow/core/common_runtime/gpu/gpu_device.cc:669] Ignoring gpu device (device: 0, name: Tesla K10.G2.8GB, pci bus id: 0000:45:00.0) with Cuda compute capability 3.0. The minimum required Cuda capability is 3.5. 
....
From nvidia-dmi
|   3  Tesla K10.G2.8GB    Off  | 0000:45:00.0     Off |                    0 |
| N/A   34C    P0    43W / 117W |     50MiB /  3583MiB |      **0%**    E. Thread |
.....
|    3     26078    C   python                                          37MiB |
+-----------------------------------------------------------------------------+
"
472,bazel test numpy issue: RuntimeError: module compiled against API version a but this version of numpy is 7,"Hello everyone,

  I just wrote my own op, and finally got it to compile, but I'm having trouble running bazel test. Specifically, I get the following error:

> RuntimeError: module compiled against API version a but this version of numpy is 7

I am surprised as I was able to compile tensorflow with bazel, and import it without any problems. Any ideas as to what might be causing this? My test is the following:

``` python
import tensorflow as tf

class ChainCRFTest(tf.test.TestCase):
    def testChainCRF(self):
        with self.test_session():
            pre_pots = [[[1, 3, 1], [4, 1, 2], [2, 1, 1]],
                        [[2, 2, 1], [3, 1, 1], [1, 2, 3]],
                        [[3, 1, 1], [2, 1, 2], [1, 3, 2]],
                        [[1, 2, 1], [4, 1, 3], [1, 1, 1]]]
            potentials = tf.convert_to_tensor(pre_pots, tf.float32)
            result = tf.user_ops.chain_crf(potentials)
            print(result.eval()) # TODO

# bazel test tensorflow/python:chain_crf_op_test --verbose_failures
```

And the full error:

```
$ cat /home/jernite/.cache/bazel/_bazel_jernite/f9fe393f3882802b0a658bd50e054d61/tensorflow/bazel-out/local_linux-fastbuild/testlogs/tensorflow/python/chain_crf_op_test/test.log
exec ${PAGER:-/usr/bin/less} ""$0"" || exit 1
-----------------------------------------------------------------------------
RuntimeError: module compiled against API version a but this version of numpy is 7
Traceback (most recent call last):
  File ""/home/jernite/.cache/bazel/_bazel_jernite/f9fe393f3882802b0a658bd50e054d61/tensorflow/bazel-out/local_linux-fastbuild/bin/tensorflow/python/chain_crf_op_test.runfiles/tensorflow/python/kernel_tests/chain_crf_op_test.py"", line 1, in <module>
    import tensorflow as tf
  File ""/home/jernite/.cache/bazel/_bazel_jernite/f9fe393f3882802b0a658bd50e054d61/tensorflow/bazel-out/local_linux-fastbuild/bin/tensorflow/python/chain_crf_op_test.runfiles/tensorflow/__init__.py"", line 23, in <module>
    from tensorflow.python import *
  File ""/home/jernite/.cache/bazel/_bazel_jernite/f9fe393f3882802b0a658bd50e054d61/tensorflow/bazel-out/local_linux-fastbuild/bin/tensorflow/python/chain_crf_op_test.runfiles/tensorflow/python/__init__.py"", line 50, in <module>
    from tensorflow.python.framework.framework_lib import *
  File ""/home/jernite/.cache/bazel/_bazel_jernite/f9fe393f3882802b0a658bd50e054d61/tensorflow/bazel-out/local_linux-fastbuild/bin/tensorflow/python/chain_crf_op_test.runfiles/tensorflow/python/framework/framework_lib.py"", line 62, in <module>
    from tensorflow.python.framework.ops import Graph
  File ""/home/jernite/.cache/bazel/_bazel_jernite/f9fe393f3882802b0a658bd50e054d61/tensorflow/bazel-out/local_linux-fastbuild/bin/tensorflow/python/chain_crf_op_test.runfiles/tensorflow/python/framework/ops.py"", line 40, in <module>
    from tensorflow.python.framework import versions
  File ""/home/jernite/.cache/bazel/_bazel_jernite/f9fe393f3882802b0a658bd50e054d61/tensorflow/bazel-out/local_linux-fastbuild/bin/tensorflow/python/chain_crf_op_test.runfiles/tensorflow/python/framework/versions.py"", line 24, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/home/jernite/.cache/bazel/_bazel_jernite/f9fe393f3882802b0a658bd50e054d61/tensorflow/bazel-out/local_linux-fastbuild/bin/tensorflow/python/chain_crf_op_test.runfiles/tensorflow/python/pywrap_tensorflow.py"", line 26, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""/home/jernite/.cache/bazel/_bazel_jernite/f9fe393f3882802b0a658bd50e054d61/tensorflow/bazel-out/local_linux-fastbuild/bin/tensorflow/python/chain_crf_op_test.runfiles/tensorflow/python/pywrap_tensorflow.py"", line 22, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)
ImportError: numpy.core.multiarray failed to import
```

Thanks in advance,
Yacine
"
471,"Build issue with bazel ""python_bin_path.sh: No such file or directory""","I've updated my code, and following what is currently listed under https://www.tensorflow.org/versions/master/get_started/os_setup.html#source arrived at this output:

``` bash
alex@ml1:~/tensorflow$ bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
INFO: Found 1 target...
Target //tensorflow/tools/pip_package:build_pip_package up-to-date:
  bazel-bin/tensorflow/tools/pip_package/build_pip_package
INFO: Elapsed time: 0.793s, Critical Path: 0.00s
alex@ml1:~/tensorflow$ bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg
Thu Dec 10 12:13:53 PST 2015 : === Using tmpdir: /tmp/tmp.NqHERREKmr
/tmp/tmp.NqHERREKmr ~/tensorflow
Thu Dec 10 12:13:53 PST 2015 : === Building wheel
bazel-bin/tensorflow/tools/pip_package/build_pip_package: line 45: tensorflow/tools/python_bin_path.sh: No such file or directory
```

Any idea why the python_bin_path.sh file hasn't been generated?
"
470,Tensorboard does not support Python 3,"[tensorboard.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tensorboard/tensorboard.py) and [tensorboard_handler.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tensorboard/tensorboard_handler.py) are still using `BaseHTTPServer` which was move to `http.server` in Python 3. There are some other changes with `StringIO` and `urlparse` that were quickly resolved with `2to3`.

Strings also need to be encoded for the `wfile.write`s in [tensorboard_handler.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tensorboard/tensorboard_handler.py).

Everything seemed to work after I made these changes.
"
469,bazel 0.1.2  undeclared inclusions fixes needed in BUILD files,"Started out with this error

```
(env)gbowyer@compute-10-3-61-179 ~/tensorflow $ bazel build --verbose_failures -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer
INFO: Found 1 target...
INFO: From Compiling external/gemmlowp/eight_bit_int_gemm/eight_bit_int_gemm.cc:
src/main/tools/namespace-sandbox.c:633: execvp(argv[0], argv): No such file or directory
ERROR: /tmp/gbowyer/.cache/bazel/_bazel_gbowyer/d132132edbbae685571ab9488dabc906/external/gemmlowp/BUILD:77:1: C++ compilation of rule '@gemmlowp//:eight_bit_int_gemm' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command
  (cd /tmp/gbowyer/.cache/bazel/_bazel_gbowyer/d132132edbbae685571ab9488dabc906/tensorflow && \
  exec env - \
    PATH=/opt/java/jdk1.8.0_31/bin:/tmp/gbowyer/dbpedia-thing/env/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/usr/local/cuda-7.0/bin:/usr/local/cuda-7.0/bin:/sbin:/usr/sbin:/tmp/gbowyer/.scripts:/sbin:/usr/sbin:/tmp/gbowyer/pkg/bin:/tmp/gbowyer/.scripts:/tmp/gbowyer/pkgs/bin \
  third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++11' -iquote external/gemmlowp -iquote bazel-out/local_linux-opt/genfiles/external/gemmlowp -iquote external/bazel_tools -iquote bazel-out/local_linux-opt/genfiles/external/bazel_tools -isystem external/bazel_tools/tools/cpp/gcc3 -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' '-frandom-seed=bazel-out/local_linux-opt/bin/external/gemmlowp/_objs/eight_bit_int_gemm/external/gemmlowp/eight_bit_int_gemm/eight_bit_int_gemm.o' -MD -MF bazel-out/local_linux-opt/bin/external/gemmlowp/_objs/eight_bit_int_gemm/external/gemmlowp/eight_bit_int_gemm/eight_bit_int_gemm.d -c external/gemmlowp/eight_bit_int_gemm/eight_bit_int_gemm.cc -o bazel-out/local_linux-opt/bin/external/gemmlowp/_objs/eight_bit_int_gemm/external/gemmlowp/eight_bit_int_gemm/eight_bit_int_gemm.o): crosstool_wrapper_driver_is_not_gcc failed: error executing command
  (cd /tmp/gbowyer/.cache/bazel/_bazel_gbowyer/d132132edbbae685571ab9488dabc906/tensorflow && \
  exec env - \
    PATH=/opt/java/jdk1.8.0_31/bin:/tmp/gbowyer/dbpedia-thing/env/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/usr/local/cuda-7.0/bin:/usr/local/cuda-7.0/bin:/sbin:/usr/sbin:/tmp/gbowyer/.scripts:/sbin:/usr/sbin:/tmp/gbowyer/pkg/bin:/tmp/gbowyer/.scripts:/tmp/gbowyer/pkgs/bin \
  third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++11' -iquote external/gemmlowp -iquote bazel-out/local_linux-opt/genfiles/external/gemmlowp -iquote external/bazel_tools -iquote bazel-out/local_linux-opt/genfiles/external/bazel_tools -isystem external/bazel_tools/tools/cpp/gcc3 -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' '-frandom-seed=bazel-out/local_linux-opt/bin/external/gemmlowp/_objs/eight_bit_int_gemm/external/gemmlowp/eight_bit_int_gemm/eight_bit_int_gemm.o' -MD -MF bazel-out/local_linux-opt/bin/external/gemmlowp/_objs/eight_bit_int_gemm/external/gemmlowp/eight_bit_int_gemm/eight_bit_int_gemm.d -c external/gemmlowp/eight_bit_int_gemm/eight_bit_int_gemm.cc -o bazel-out/local_linux-opt/bin/external/gemmlowp/_objs/eight_bit_int_gemm/external/gemmlowp/eight_bit_int_gemm/eight_bit_int_gemm.o).
Target //tensorflow/cc:tutorials_example_trainer failed to build
INFO: Elapsed time: 1.907s, Critical Path: 1.27s
(env)gbowyer@compute-10-3-61-179 ~/tensorflow $ third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc
gcc: fatal error: no input files
compilation terminated.
(env)gbowyer@compute-10-3-61-179 ~/tensorflow $ nvcc --version
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2015 NVIDIA Corporation
Built on Mon_Feb_16_22:59:02_CST_2015
Cuda compilation tools, release 7.0, V7.0.27
(env)gbowyer@compute-10-3-61-179 ~/tensorflow $
```

---

Suggestion from Vijay Vasudevan is to use different bazel build params

> Can you try building with --spawn_strategy=standalone ?  After talking with the bazel folks it looks like the sandbox for some reason doesn't have the crosstool wrapper in the right location, so running in standalone mode might work better.

---

That yields this error

```
(env)gbowyer@compute-10-3-61-179 ~/tensorflow $ bazel build --verbose_failures -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer --spawn_strategy=standalone
INFO: Found 1 target...
ERROR: /tmp/gbowyer/tensorflow/tensorflow/stream_executor/BUILD:5:1: undeclared inclusion(s) in rule '//tensorflow/stream_executor:stream_executor':
this rule is missing dependency declarations for the following files included by 'tensorflow/stream_executor/cuda/cuda_platform_id.cc':
  '/tmp/gbowyer/tensorflow/tensorflow/stream_executor/cuda/cuda_platform_id.h'.
Target //tensorflow/cc:tutorials_example_trainer failed to build
INFO: Elapsed time: 2.893s, Critical Path: 2.64s
(env)gbowyer@compute-10-3-61-179 ~/tensorflow $ bazel build --verbose_failures -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --spawn_strategy=standalone
INFO: Found 1 target...
ERROR: /tmp/gbowyer/tensorflow/tensorflow/core/BUILD:272:1: undeclared inclusion(s) in rule '//tensorflow/core:gpu_kernels':
this rule is missing dependency declarations for the following files included by 'tensorflow/core/kernels/aggregate_ops_gpu.cu.cc':
  '/tmp/gbowyer/tensorflow/tensorflow/core/framework/tensor_types.h'.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 38.609s, Critical Path: 37.67s
(env)gbowyer@compute-10-3-61-179 ~/tensorflow $
```

---

Evgeny Shaliov notes that

> nvcc --version should return 6.5.\* but CUDA toolkit should be installed 7.0. 
> 
> I posted https://groups.google.com/a/tensorflow.org/forum/#!topic/discuss/jRkkvsB1iWA.
> Also pay attention what gcc version you use.
> 
> Best regards,
> Evgeny.

---

Vijay Vasudevan also remarks

> Yikes! :(
> 
> What version of bazel do you happen to be using? 

And asks to move this to github issues, so here we are :P
"
468,"Generated wheel files are named incorrectly (python wheel experts, please help!)","**Note:** If you know lots about python wheels, and can answer some of the questions here, please jump in!

Python wheel files encode metadata about supported architectures into their names, cf [the wheel PEP](https://www.python.org/dev/peps/pep-0427/) and [the suffix PEP](https://www.python.org/dev/peps/pep-0425/).

Currently, when we generate wheel files, we end up with either too-broad names (eg all Mac wheels are `py2-none-any`, which is wrong) or too-specific (some linux wheels are tagged `cp34-cp34m-linux-x86_64`, but we think the abi component should be `none`). This leads to issues like #467.

A part of the issue here is that we're not sure what some of these tags mean -- for instance, the only explanation I've found of the `m` suffix is in [an issue on the wheel bug tracker](https://bitbucket.org/pypa/wheel/issues/61/abi-version-is-not-found) and even that doesn't clear things up.

There are really three parts to fixing this:
- we should know what the ""right"" filename is for these wheel files.
- we should fix our build process to generate the right output on all architectures.
- we should consider serving our wheel files via a custom PyPA.

More details on the last one: we're making our lives harder by asking people to point to the ""right"" wheel file. `pip` knows how to take a package name (eg `tensorflow`) and a list of wheel files, and then install the right one. We can and should serve our own PyPA, so that installation instructions on **all** platforms we support would be something like

```
pip install --extra_index_url=https://tensorflow.org/pypa tensorflow
```

/cc @vrv @martinwicke @keveman on the TF side.
"
467,0.6.0 whl package named incorrectly as of 12/10 9am PST,"From #1:

> Closing since it seems to work. Python 3 support will ship with version 0.6.0, which is coming very soon. Future Python 3 bugs should be filed as separate issues!

In a python 2 virtualenv:

``` sh
$ python --version
Python 2.7.10
$ pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.6.0-cp27-none-linux_x86_64.whl
...
Successfully installed protobuf-3.0.0a3 setuptools-18.7.1 tensorflow-0.6.0 wheel-0.26.0
```

In a python 3 virtualenv:

``` sh
$ python --version
Python 3.4.3
$ pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.6.0-cp34-cp34m-linux_x86_64.whl
tensorflow-0.6.0-cp34-cp34m-linux_x86_64.whl is not a supported wheel on this platform.
```
"
466,tf.unsorted_segment_sum exits without error message if segment_ids contains negative number.,"When running

   tf.unsorted_segment_sum(data, segment_ids, num_segments, name=None)

and passing a tensor containing -1 as `segment_ids`, tensorflow just exits without error message. I'm on the current master. 

Desired behavior in my case would be to these values are 'rejected', i. e. are not summed anywhere at all. Would it make sense to extend this method this way? And if not, can you give me an idea how to implement this behavior?
"
465,Allow mixing values with tensors in lists that specify the shape of a Tensor.,"There are many methods that expect a list or a tensor specifying a shape as argument. It is often the case that I want to pass an argument such as shape=[t1, v2] where t1 is a tensor with shape = TensorShape([]) and v2 is a value. This is currently not possible in many (maybe all) methods.

My current work around is the following.
1- convert v2 to a tensor t2 with tf.convert_to_tensor
2- use t1 = tf.expand_dims(0, t1) and t2 = tf.expand_dims(0, t2) to add a dimension of size 1 to the tensors
3- pass the argument as shape=tf.concat(0, [t1, t2])

Am I missing a simpler way to accomplish that? Is it a good idea to add a feature that allows passing mixture of tensors and values inside a list as argument?

Edit: I just found out that the method tf.pack allows lists with tensors and values as argument. But the method tf.truncated_normal for instance, doesn't allow.
I also realized that I can use tf.pack to replace the steps (1,2,3) above. But it still would be nice if all methods had the same behaviour.
"
464,RMSProp optimization support for sparse tensors,"It seems that tf.nce_loss is not compatible with the optimizers RMSProp, ADAGRAD and Momentum. (while SGD, ADAM and FTRL works fine).

When using rmsprop, I get this error:

```
    optimizer = tf.train.RMSPropOptimizer(learning_rate = learning_rate, decay = rms_prop_decay).minimize(nce_loss)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py"", line 167, in minimize
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py"", line 256, in apply_gradients
    update_ops.append(self._apply_sparse(grad, var))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/rmsprop.py"", line 81, in _apply_sparse
    raise NotImplementedError()
NotImplementedError
```

When using adagrad or momentum, I get this error:

```
    optimizer = tf.train.MomentumOptimizer(learning_rate, learning_momentum).minimize(nce_loss)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py"", line 167, in minimize
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py"", line 256, in apply_gradients
    update_ops.append(self._apply_sparse(grad, var))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/momentum.py"", line 51, in _apply_sparse
    self._momentum_tensor, use_locking=self._use_locking).op
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/gen_training_ops.py"", line 237, in sparse_apply_momentum
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py"", line 633, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1712, in create_op
    set_shapes_for_outputs(ret)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1417, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/training_ops.py"", line 111, in _SparseApplyMomentumShape
    tensor_shape.TensorShape([None]).concatenate(accum_shape[1:]))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.py"", line 481, in merge_with
    self.assert_same_rank(other)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.py"", line 524, in assert_same_rank
    ""Shapes %s and %s must have the same rank"" % (self, other))
ValueError: Shapes TensorShape([Dimension(128), Dimension(11), Dimension(192)]) and TensorShape([Dimension(None), Dimension(192)]) must have the same rank
```

Is that expected?
The exact same code works perfectly fine with adam or sgd optimizers, so I do not think I made a mistake when constructing the graph.
"
463,No imagenet folder in the 0.6.0 wheel linked on tensorflow.org,"Trying to follow the Inception-v3 tutorial, but there is  no imagenet folder in my installation.

```
(d)[nani@nande cat]$ pip show tensorflow

---
Metadata-Version: 2.0
Name: tensorflow
Version: 0.6.0
Summary: TensorFlow helps the tensors flow
Home-page: http://tensorflow.com/
Author: Google Inc.
Author-email: opensource@google.com
License: Apache 2.0
Location: /home/nani/Desktop/cat/d/lib/python2.7/site-packages
Requires: six, protobuf, wheel, numpy


(d)[nani@nande cat]$ ls d/lib/python2.7/site-packages/tensorflow/models/image/
cifar10  __init__.py  __init__.pyc  mnist
```
"
462,Building static-linked tensorflow,"Have you considered distributing a static-built version of tensorflow so poor uses of old CentOS clusters  with an old glibc could use it? I understand static builds are dirty but it seems that there are many users that would benefit from this solution...
I tried to build tensorflow using an old glibc myself but did not succeed. I guess it could be done but some knowledge of bazel and the internal structure of tensorflow required (and a lot of time!)...
"
461,broken links in word2vec tutorial docs,"Some of the links to word2vec_basic.py currently give a 404 -- they point to https://tensorflow.googlesource.com/tensorflow/+/master/tensorflow/g3doc/tutorials/word2vec/word2vec_basic.py . They should probably point to the version at  https://www.tensorflow.org/versions/master/tutorials/word2vec/word2vec_basic.py , right?
"
460,"Make a helpful python Tensor __repr__ that describes type, shape, etc.","Currently `repr(tf.placeholder(tf.float32, shape=(3,1)))` gives:

```
'<tensorflow.python.framework.ops.Tensor object at 0x7fa0e9f99b10>'
```

This is not very informative and it's what you see as the output for interactive shell (IPython). In contrast to that, `repr(np.array([[1,2]]))` will give us nice:

```
'array([[1, 2]])'
```
"
459,Single scalar summary point not visible in the plot,"When only one event is available for a scalar summary, the plot remains empty, as shown below (here the value is 2.0):
![snapshot2](https://cloud.githubusercontent.com/assets/331795/11701319/b1919762-9e83-11e5-8f85-fa1740c52c57.png)
It would be great to see one point corresponding to the value instead. The value does appear in the JSON/CSV file.
"
458,Visualizing scalar summaries on the graph,"Would it be possible to visualize the values of scalar summaries (e.g. from a chosen or simply last event) directly on the graph? If not, what is the best way to easily inspect the values of the tensors after the most recent run?
"
457,Wheel out of date,"The wheel used for installing via pip for Tensorflow is out of date and is missing parts needed for the tutorials.

I've built from source successfully, but is very difficult to do on a machine that I don't have root access to. An updated wheel would make it much easier to do a user install of Tensorflow.
"
456,Batch Multinomial Function for TensorFlow,"Hey TF,

Is there some sort of multinomial function that can handle batches? When generating content, it is incredibly useful to introduce variance by 'rolling a dice'. I searched extensively in the docs and could not find one.

[Numpy has one](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.random.multinomial.html), but it can not do batches. Tensorflow could capitalize on the fact that it uses a GPU. Thanks alot! 
"
455,Problem with L2_Loss on GPU,"The following code works correctly when running on CPU but produces an error when run on GPU. This has been experienced with both a workstation with an Nvidia GTX 980 and a Nvidia Titan X. The error message indicates theres a problem on the CUDA Backend.

---

import tensorflow as tf

sess = tf.InteractiveSession()

input = tf.placeholder(""float32"", shape=[None, 2])
target = tf.placeholder(""float32"", shape=[None, 2])

w=tf.Variable(tf.zeros([2, 2]))
b=tf.Variable(tf.zeros([1]))
l=tf.nn.relu(tf.matmul(input, w) + b)

cost = tf.reduce_sum(tf.nn.l2_loss(l - target)) # this breaks
# cost = tf.reduce_sum( tf.pow(l - target, 2)/2 )

train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cost)

sess.run(tf.initialize_all_variables())
dict={input: [[1,1],[1,1]], target: [[1,1],[1,1]]}
train_step.run(feed_dict=dict) # <---- this throws ""F tensorflow/core/kernels/tile_ops.cc:116] TileOp: Invalid combination of Device, DT and NDIM: N5Eigen9GpuDeviceE, float, 0""
"
454,Help Needed To Understand Tensor Flow Weights and Gradient Histogram,"Hi,

I am experimenting with conv nets for sentiment analysis.
I used a basic convent architecture, my network looks like:
![screen shot 2015-12-09 at 10 58 08 am](https://cloud.githubusercontent.com/assets/15708499/11695403/cb3e4644-9e63-11e5-8bc2-c3d71baf1b2f.png)
I am trying to analyze the learning, I have a bad feeling about weights, Although I am early in the learning process, but the weights for 5x5 filter essentially suggest no updates/ update on only very few component , because histogram essentially remains the same.

Any hints on what I could be missing?

[TensorBoard_basic_convnet.pdf](https://github.com/tensorflow/tensorflow/files/57216/TensorBoard_basic_convnet.pdf)

Everyone has said that, none the less, I would say it too, Thanks for the amazing library.

Regards,
Vaibhav Singh
"
452,bazel build error for PolymerElements,"I am trying to build tensorflow from source, and bazel is giving some unrelated error 

```
eddie7@albus:~/lab/tensorflow$ git pull
Already up-to-date.
eddie7@albus:~/lab/tensorflow$ ~/lab/bazel/bazel-bin/src/bazel build -c opt //tensorflow/tools/pip_package:build_pip_package
.......
ERROR: /home/eddie7/lab/tensorflow/tensorflow/tensorboard/bower/BUILD:3:1: no such package '@iron-validatable-behavior//': https://github.com/PolymerElements/iron-validatable-behavior.git: cannot open git-upload-pack and referenced by '//tensorflow/tensorboard/bower:bower'.
ERROR: Loading failed; build aborted.
INFO: Elapsed time: 129.792s

```

_FYI: I have also build bazel from source_
"
451,MNIST tutorial data cant be downloaded (404),"Hey, tried to work my way through tf but the download link seems down

https://tensorflow.googlesource.com/tensorflow/+/master/tensorflow/g3doc/tutorials/mnist/input_data.py

404s
"
450,tf.placeholder API docs should mention possibility of None,"For `tf.placeholder`, it's possible to have `None` as one or more of the dimensions passed to the `shape` option. This is described in the MNIST tutorial, but is nowhere to be found in the API docs. The latter only mentions that the `shape` option itself may be `None`, but that is an entirely different thing.
"
449,TF code crashes python kernel,"The following piece of code:

```
import tensorflow as tf
a = tf.placeholder(tf.float32, shape=(-1, 10))
sess = tf.Session()
sess.run(tf.array_ops.shape(a))
```

crashes the Python kernel. I realize it's not right (for one thing I'm not feeding it a `feed_dict`), but it should give an error and not crash the kernel.
"
448,Image bug fix for tf.gather documentation,"<img width=""791"" alt=""screen shot 2015-12-08 at 2 21 45 pm"" src=""https://cloud.githubusercontent.com/assets/2761597/11665778/1fc3de48-9db7-11e5-9fb3-c086aa9aaa3c.png"">
"
447,"Python get_attr on DT_FLOAT returns proto type, not python DType","If my graph has a Sub operation, and I get the ""T"" key for the op, it always returns an integer type incorrectly.

```
op: ""Sub""
input: ""ResizeBilinear""
input: ""Sub/y""
attr {
  key: ""T""
  value {
    type: DT_FLOAT
  }
}
```

```
print(ops[8].get_attr(""T""))
1

print(type(ops[8].get_attr(""T"")))
int
```
"
446,tf.train.L_BFGS_Optimizer,"This would be a great addition to tensorflow, and is conspicuously missing. Is there some specific reason it's missing, or is it in the works? 
"
445,tensorflow in armv7l,"Hi,

I've cross-compiled tensorflow for `armv7l` and generated a wheel successfully however when deploying it into an embedded board with the same architecture (e.g.: Raspberry Pi 2), i get the following when executing https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/1%20-%20Introduction/helloworld.py:

```
erle@erle-brain-2 ~/TensorFlow-Examples/examples/1 - Introduction $ python helloworld.py 
I tensorflow/core/common_runtime/local_device.cc:40] Local device intra op parallelism threads: 4
pure virtual method called
terminate called without an active exception
I tensorflow/core/common_runtime/direct_session.cc:60] Direct session inter op parallelism threads: 4
Aborted
```

Digging a bit more:

```
erle@erle-brain-2 ~/TensorFlow-Examples/examples/1 - Introduction $ gdb -ex r --args python helloworld.py
GNU gdb (Raspbian 7.7.1+dfsg-5) 7.7.1
Copyright (C) 2014 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.  Type ""show copying""
and ""show warranty"" for details.
This GDB was configured as ""arm-linux-gnueabihf"".
Type ""show configuration"" for configuration details.
For bug reporting instructions, please see:
<http://www.gnu.org/software/gdb/bugs/>.
Find the GDB manual and other documentation resources online at:
<http://www.gnu.org/software/gdb/documentation/>.
For help, type ""help"".
Type ""apropos word"" to search for commands related to ""word""...
Reading symbols from python...(no debugging symbols found)...done.
Starting program: /usr/bin/python helloworld.py
[Thread debugging using libthread_db enabled]
Using host libthread_db library ""/lib/arm-linux-gnueabihf/libthread_db.so.1"".

Program received signal SIGILL, Illegal instruction.
0x73f1cd08 in ?? () from /usr/lib/arm-linux-gnueabihf/libcrypto.so.1.0.0
(gdb) bt
#0  0x73f1cd08 in ?? () from /usr/lib/arm-linux-gnueabihf/libcrypto.so.1.0.0
#1  0x73f193f4 in OPENSSL_cpuid_setup () from /usr/lib/arm-linux-gnueabihf/libcrypto.so.1.0.0
#2  0x76fdf058 in call_init (l=<optimized out>, argc=2, argv=0x7efff184, env=0x7efff190) at dl-init.c:78
#3  0x76fdf134 in _dl_init (main_map=main_map@entry=0x8e9268, argc=2, argv=0x7efff184, env=0x7efff190) at dl-init.c:126
#4  0x76fe36b4 in dl_open_worker (a=<optimized out>) at dl-open.c:577
#5  0x76fdeef0 in _dl_catch_error (objname=0x76fdeef0 <_dl_catch_error+112>, objname@entry=0x7effcc04, errstring=0x76ff6510, errstring@entry=0x7effcc08, 
    mallocedp=0x7effcc04, mallocedp@entry=0x7effcc03, operate=0x7effcc03, args=args@entry=0x7effcc0c) at dl-error.c:187
#6  0x76fe2da4 in _dl_open (file=0x9094e0 ""/usr/lib/python2.7/lib-dynload/_hashlib.arm-linux-gnueabihf.so"", mode=-2147483646, 
    caller_dlopen=0x10aa94 <_PyImport_GetDynLoadFunc+272>, nsid=-2, argc=2, argv=0x7efff184, env=0x7efff190) at dl-open.c:661
#7  0x76f66ba8 in dlopen_doit (a=0x7effce58) at dlopen.c:66
#8  0x76fdeef0 in _dl_catch_error (objname=0x76fdeef0 <_dl_catch_error+112>, errstring=0x76ff6510, mallocedp=0x4e93a4, operate=0x4e93a0, args=0x7effce58)
    at dl-error.c:187
#9  0x76f672a8 in _dlerror_run (operate=0x76f66b28 <dlopen_doit>, args=args@entry=0x7effce58) at dlerror.c:163
#10 0x76f66c74 in __dlopen (file=<optimized out>, mode=<optimized out>) at dlopen.c:87
#11 0x0010aa94 in _PyImport_GetDynLoadFunc ()
#12 0x0010a338 in _PyImport_LoadDynamicModule ()
#13 0x00067844 in ?? ()
Backtrace stopped: previous frame identical to this frame (corrupt stack?)
(gdb) Quit
(gdb) quit
A debugging session is active.
```

`cryt*` libraries in the machine used to cross compile tensorflow:

```
root@debian-arm:~/TensorFlow-Examples/examples/1 - Introduction# dpkg -l|grep crypt
ii  libcryptsetup4:armhf          2:1.6.6-5                 armhf        disk encryption support - shared library
ii  libgcrypt20:armhf             1.6.3-2                   armhf        LGPL Crypto library - runtime library
ii  libhogweed2:armhf             2.7.1-5                   armhf        low level cryptographic library (public-key cryptos)
ii  libk5crypto3:armhf            1.12.1+dfsg-19            armhf        MIT Kerberos runtime libraries - Crypto Library
ii  libnettle4:armhf              2.7.1-5                   armhf        low level cryptographic library (symmetric and one-way cryptos)
ii  openssl                       1.0.1k-3+deb8u1           armhf        Secure Sockets Layer toolkit - cryptographic utility
ii  python-cryptography           0.6.1-1                   armhf        Python library exposing cryptographic recipes and primitives (Python 2)

```

`cryt*` libraries in the target machine (Raspberry Pi 2):

```
erle@erle-brain-2 ~/TensorFlow-Examples/examples/1 - Introduction $ dpkg -l|grep crypt
ii  cryptsetup-bin                         2:1.6.6-5                                 armhf        disk encryption support - command line tools
ii  libcryptsetup4:armhf                   2:1.6.6-5                                 armhf        disk encryption support - shared library
ii  libgcrypt20:armhf                      1.6.3-2                                   armhf        LGPL Crypto library - runtime library
ii  libhcrypto4-heimdal:armhf              1.6~rc2+dfsg-9+rpi1                       armhf        Heimdal Kerberos - crypto library
ii  libhogweed2:armhf                      2.7.1-5                                   armhf        low level cryptographic library (public-key cryptos)
ii  libk5crypto3:armhf                     1.12.1+dfsg-19                            armhf        MIT Kerberos runtime libraries - Crypto Library
ii  libmhash2:armhf                        0.9.9.9-7                                 armhf        Library for cryptographic hashing and message authentication
ii  libnettle4:armhf                       2.7.1-5                                   armhf        low level cryptographic library (symmetric and one-way crypos)
ii  libpococrypto9                         1.3.6p1-5                                 armhf        C++ Portable Components (POCO) Crypto library
ii  openssl                                1.0.1k-3+deb8u1                           armhf        Secure Sockets Layer toolkit - cryptographic utility
```
"
444,"Python3 bug, filter has no len","I have build the latest source (a5d8217c4ed) and I tried running the mnist tutorial. This fails with:

  File ""/l/psmit/tensorflow/env_py3/lib/python3.4/site-packages/tensorflow/python/ops/gradients.py"", line 447, in gradients
    if gate_gradients and len(filter(None, in_grads)) > 1:
TypeError: object of type 'filter' has no len()

A filter in py3 is not a list, so it has not length. This could be solved by changing 

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/gradients.py#L447

to e.g. sum(1 for _ in filter())
"
443,Feature Request: LogSoftmax layer,"Torch has a LogSoftmax layer, that does what the name imply: it is the equivalent of a softmax followed by a log. However, I could not find a similar layer in tensorflow.

LogSoftmax is quite convenient because I am often more interested in log-probabilities (eg for computing a log-likelihood) than in the probabilities themselves. 

Further, I suspect a LogSoftmax can be implemented more efficiently than a Softmax (it should at least saves a log call, if one is interested in the log-probabilities; plus it is less sensitive to underflow/overflows). Indeed Torch documentation indicates it is faster when one need the log-probabilities.

Would you consider adding such a layer at some point?
"
442,cannot find numpy/arrayobject.h,"INFO: From Compiling tensorflow/python/client/tf_session_helper.cc:
In file included from tensorflow/python/client/tf_session_helper.cc:20:0:
./tensorflow/python/client/tf_session_helper.h:34:31: fatal error: numpy/                                                            arrayobject.h: No such file or directory
 #include ""numpy/arrayobject.h""
                               ^
compilation terminated.
ERROR: /root/download/tensorflowgit/tensorflow/tensorflow/python/BUILD:70                                                            4:1: C++ compilation of rule '//tensorflow/python:tf_session_helper' fail                                                            ed: gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE '-                                                            D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parame                                                            ter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ff                                                            unction-sections ... (remaining 51 argument(s) skipped): com.google.devto                                                            ols.build.lib.shell.BadExitStatusException: Process exited with status 1.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
"
441,max_images defaults to 3 images instead of batch_size in tf.image_summary,"Even though the default value for the max_images parameter in tf.image_summary is None, a maximum of 3 images are displayed by default.

It looks like this is [by design](https://github.com/tensorflow/tensorflow/blob/a5d8217c4ed90041bea2616c14a8ddcf11ec8c03/tensorflow/core/ops/ops.pbtxt#L2993), but I can't find it mentioned in the documentation.  Should a note be added to the docs, or possibly the default value changed to 3 instead of None?

``` python
import tensorflow as tf

images = tf.Variable(tf.truncated_normal([10, 48, 48, 1]))

tf.image_summary(""max_images_bug_no_param"", images) # 3 images displayed

tf.image_summary(""max_images_bug_none_param"", images, max_images=None) # 3 images displayed

tf.image_summary(""max_images_bug_100_param"", images, max_images=100) # 10 images displayed

with tf.Session() as sess:
    sess.run(tf.initialize_all_variables())
    summary_op = tf.merge_all_summaries()
    writer = tf.train.SummaryWriter('max_images_bug')
    summary_str = sess.run(summary_op)
    writer.add_summary(summary_str, 0)
```
"
440,Will TensorFlow run on an AMD FX processor?,"I'm looking at buying a new PC to run TensorFlow on.  The system I'm looking at has an AMD FX processor and a GTX 960 with 2GB of memory.  Will TensorFlow run fine on that processor and be able to take advantage of the GTX 960 for CUDA processing?  The O/S I'm planning on is Ubuntu Linux.
"
439,"Say that we need gcc >= 4.8 (was ""Need help on compilation error on Mac"")","Having met the following compilation errors:

tensorflow/core/kernels/fifo_queue.cc:247:46: error: expected body of lambda expression
          [callback, this](Attempt* attempt) EXCLUSIVE_LOCKS_REQUIRED(mu_) {
                                                               ^

Please let me know if you have any ideas. Thanks!
"
438,build error - target names may not contain ' '.,"bazel build -c opt //tensorflow/tools/pip_package:build_pip_package
ERROR: /tensorflow/BUILD:27:1: //tensorflow:all_files: invalid label 'TensorFlow-Examples/examples/1 - Introduction/basic_operations.py' in element 4 of attribute 'srcs' in 'filegroup' rule: invalid target name 'TensorFlow-Examples/examples/1 - Introduction/basic_operations.py': target names may not contain ' '.
"
436,Need better error message for error in checkpoint loading,"Hi, I'm loading a previously-built model using the tf.train.Saver and running into an error: `tensorflow.python.pywrap_tensorflow.StatusNotOK: Internal: Unable to get element from the feed.`.

I'm not quite sure what this is referring to as I can load other models just fine. This one also builds and runs as expected. It's only after, when retrieving it again, do I get this error. The ckpt file also points to the correct locations and is reading from the right place.

```
Traceback (most recent call last):
  File ""bridge.py"", line 518, in <module>
    tf.app.run()
  ...
  File ""bridge.py"", line 375, in train
    saver.restore(sess, checkpoint)
  File "".../site-packages/tensorflow/python/training/saver.py"", line 887, in restore
    sess.run([self._restore_op_name], {self._filename_tensor_name: save_path})
  File "".../site-packages/tensorflow/python/client/session.py"", line 368, in run
    results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)
  File "".../site-packages/tensorflow/python/client/session.py"", line 446, in _do_run
    six.reraise(e_type, e_value, e_traceback)
  File "".../site-packages/tensorflow/python/client/session.py"", line 428, in _do_run
    target_list)
tensorflow.python.pywrap_tensorflow.StatusNotOK: Internal: Unable to get element from the feed.
```

Thoughts?
"
435,Cross products?,"Can we get support for cross products? This is a fundamental / elementary mathematical operation and I suspect it can be more efficiently implemented in C++, for example as in [this example](http://fastcpp.blogspot.com/2011/04/vector-cross-product-using-sse-code.html). A function that would take two tensors of 3D vectors and return the cross products of the 3D vectors would be nice. This would be done element wise, so for two tensors x and y, the returned tensor would be [x1 x y1, x2 x y2, ...].
"
434,Identity matrix initialization (was Custom Initialization of Weights),"Hey TF,

In your seq2seq library you define your weights W, by setting your initializer to none:

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn_cell.py#L675

I'm trying to build Identity RNN's and Unitary RNN's in tensorflow. For identity rnn's they need to be initialized by a identity matrix. [Numpy easily makes this](http://docs.scipy.org/doc/numpy/reference/generated/numpy.identity.html)

How can this be done using `get_variable`? Is there way you can custom build your own matrix and then use `get_variable` and its initializer?

Also, when you set `initializer = None` in `get_variable` what is created? A matrix full of zeros? Thanks alot!  
"
433,display bug in mnist_softmax.py?,"Hi,

I ran the mnist_softmax.py example and get an test accuracy of 0.91 or so.

But when I tried to looked at the values of W and b:
`>>>  W.eval()`

```
array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],
       [ 0.,  0.,  0., ...,  0.,  0.,  0.],
       [ 0.,  0.,  0., ...,  0.,  0.,  0.],
       ..., 
       [ 0.,  0.,  0., ...,  0.,  0.,  0.],
       [ 0.,  0.,  0., ...,  0.,  0.,  0.],
       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)
```

`>>> b.eval()`

```
Out[6]: 
array([-0.53140152,  0.38159987,  0.19011307, -0.29761535, -0.02665209,
        1.94714248, -0.21013401,  0.93898344, -1.9967736 , -0.39526111], dtype=float32)
```

The value of W is still zero, not chagned? If this is the case, then why the prediction accuracy is 0.91.
"
431,No module named ptb,"When running the ptb example/model/tutorial:
https://www.tensorflow.org/versions/master/tutorials/recurrent/index.html
`~/ai/tensorflow/tensorflow/models/rnn/ptb$ python ptb_word_lm.py`
Traceback (most recent call last):
  File ""./ptb_word_lm.py"", line 72, in <module>
    from tensorflow.models.rnn.ptb import reader
ImportError: No module named ptb

Trying to fix it via
 export PYTHONPATH=$PYTHONPATH:/Users/me/ai/tensorflow
yields the other common error:
ImportError: No module named core.framework.graph_pb2
"
430,scalar_summary does not support int32 datatypes,"```
import tensorflow as tf
x=tf.constant(2)
tf.scalar_summary(""x"",x)
TypeError: DataType int32 for attr 'T' not in list of allowed values: float32, float64
```
"
429,Bazel error on six_archive when compiling from source,"Hello,

I am having issues building tensorflow from source. I have a local checkout and the required packages installed, following the manual from the tensorflow.org getting-started pages. However, when trying to use bazel to compile the pip-package I get the following error. Can anyone help me to solve this problem? Thanks in advance!

**Command:** bazel build -c opt //tensorflow/tools/pip_package:build_pip_package -s --verbose_failures

**ERROR:**  ~/development/alexander/.cache/bazel/_bazel_alexande/44250d582377ce08fbe503824f986778/external/six_archive/BUILD:1:1: Executing genrule @six_archive//:copy_six failed: bash failed: error executing command 
  (cd ~/development/alexander/.cache/bazel/_bazel_alexande/44250d582377ce08fbe503824f986778/tensorflow && \
  exec env - \
    PATH=/usr/local/bin:/usr/bin:/bin:/usr/X11R6/bin::/usr/lib64/java/bin:/usr/lib64/java/jre/bin:/usr/lib64/java/bin:/usr/lib64/kde4/libexec:/usr/lib64/qt/bin:.:/usr/local/tmake/bin:/home/alexander/bin:/home/alexander/development/alexander/bazel/ \
    TMPDIR=/home/alexander/development/alexander/.tmp \
  /bin/bash -c 'source tools/genrule/genrule-setup.sh; cp external/six_archive/six-1.10.0/six.py bazel-out/local_linux-opt/genfiles/external/six_archive/six.py'): bash failed: error executing command 
"
428,Support more image formats,"Hello

Forgive me if Ive missed something obvious - new to Tensorflow / machine learning.

I notice there are image creation functions which deal with JPG and PNG image creation via parsing those formats.

Is it planned to support uncompressed images? Client applications may want to decompress video frames and use them for analysis.

Perhaps I am missing a way to construct a tensor from an uncompressed byte array? How would one handle some video optimization for byte alignment / stride etc? 

If there is a more appropriate place to ask beginner questions I am happy to take the conversation there. Thank you!
"
427,Cannot find 'util/python/python_include',"```
root@debian-arm:~/tensorflow# ../bazel-0.1.1/output/bazel build -c opt //tensorflow/tools/pip_package:build_pip_package --local_resources 2048,.5,1.0 
INFO: Waiting for response from Bazel server (pid 3825)...
INFO: Found 1 target...
INFO: From Executing genrule //util/python:python_check:


ERROR: Cannot find 'util/python/python_include'.  Did you run configure?


ERROR: /root/tensorflow/util/python/BUILD:14:1: Executing genrule //util/python:python_check failed: bash failed: error executing command /bin/bash -c 'source tools/genrule/genrule-setup.sh; OUTPUTDIR=""bazel-out/local_linux-opt/genfiles/util/python/""; ./util/python/python_config.sh --check && touch $OUTPUTDIR/python_checked': com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 46.917s, Critical Path: 1.53s

```

Checked around and i don't seem to be missing any fundamental package. Is this a configuration issue and if so, how can I bypass it?

Thanks,
"
426,problem about session.run,"Hi guys, I am very new to tensorflow. Now I am implementing a pairwise cnn model. While I got the error:

File ""Train.py"", line 72, in <module>
    train()
  File ""Train.py"", line 48, in train
    feature1,feature2,train_loss,_=sess.run([model.feature1,model.feature2,model.cost,model.train_op],feed)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 345, in run
    results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 404, in _do_run
    target_list)
tensorflow.python.pywrap_tensorflow.StatusNotOK: Not found: FeedInputs: unable to find feed output Placeholder:0

Here in the sess.run function, feed is a dictionary containing input data and corresponding labels. feature1 and feature2 are the output of the same neural networks and finally I would like to compare feature1 and feature2.

Any help are more than welcome. Thanks!
"
425,Cannot install tensorflow via pip,"## 1) If I install directly

(I already have pip in my machine):

``` sh
sudo pip install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.5.0-py2-none-any.whl
sudo easy_install --upgrade six
```

I receive the following errors: 

```
Downloading/unpacking https://storage.googleapis.com/tensorflow/mac/tensorflow-0.5.0-py2-none-any.whl
  Downloading tensorflow-0.5.0-py2-none-any.whl (9.8MB): 9.8MB downloaded
  Running setup.py egg_info for package from https://storage.googleapis.com/tensorflow/mac/tensorflow-0.5.0-py2-none-any.whl
    Traceback (most recent call last):
      File ""<string>"", line 16, in <module>
    IOError: [Errno 2] No such file or directory: '/tmp/pip-Kf4UD9-build/setup.py'
    Complete output from command python setup.py egg_info:
    Traceback (most recent call last):

  File ""<string>"", line 16, in <module>

IOError: [Errno 2] No such file or directory: '/tmp/pip-Kf4UD9-build/setup.py'

----------------------------------------
Command python setup.py egg_info failed with error code 1 in /tmp/pip-Kf4UD9-build
Storing complete log in /Users/kanitw/.pip/pip.log
```
## 2) If I install via virtualenv

``` sh
virtualenv --system-site-packages ~/tensorflow
source ~/tensorflow/bin/activate
pip install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.5.0-py2-none-any.whl
```

I receive the following errors: 

```
Downloading/unpacking https://storage.googleapis.com/tensorflow/mac/tensorflow-0.5.0-py2-none-any.whl
  Downloading tensorflow-0.5.0-py2-none-any.whl (9.8MB): 9.8MB downloaded
  Running setup.py egg_info for package from https://storage.googleapis.com/tensorflow/mac/tensorflow-0.5.0-py2-none-any.whl
    Traceback (most recent call last):
      File ""<string>"", line 16, in <module>
    IOError: [Errno 2] No such file or directory: '/var/folders/h3/9m4gf8ln7yngtp_36k84d9hm0000gn/T/pip-Wy0s9g-build/setup.py'
    Complete output from command python setup.py egg_info:
    Traceback (most recent call last):

  File ""<string>"", line 16, in <module>

IOError: [Errno 2] No such file or directory: '/var/folders/h3/9m4gf8ln7yngtp_36k84d9hm0000gn/T/pip-Wy0s9g-build/setup.py'

----------------------------------------
Command python setup.py egg_info failed with error code 1 in /var/folders/h3/9m4gf8ln7yngtp_36k84d9hm0000gn/T/pip-Wy0s9g-build
Storing complete log in /Users/kanitw/.pip/pip.log
```
"
424,Using Linear Algebraic Functions In TensorFlow Python,"Hey TF, 

Matrix norm in python, it doesn't appear the documentation. However, in your Eigen section, there is a matrix norm function. 

Is it possible to use these eigen functions via python and ensure that it is performed on the gpu? These linear algebraic functions are very easy to do in theano, but I'm having difficulty figuring out how to do this in python. 

My ultimate goal is to perform a [euclidean norm](http://mathworld.wolfram.com/FrobeniusNorm.html).  I just don't know what is the best way to do this in python would be. Thanks!
"
422,Sigaction invalid argument error while running the translate example.,"I am running the translate example (installed from the source using the CPU only mode on Ubuntu running in VMware) using this command from the tutorial:

```
bazel run -c opt tensorflow/models/rnn/translate:translate -- 
--data_dir [your_data_directory] --train_dir [checkpoints_directory] --en_vocab_size=40000 --fr_vocab_size=40000
```

The data downloads fine and runs for a few hours. It creates the vocabulary and tokenizes giga-fren.release2.fr and giga-fren.release2.en. However it throws an error in the ""Reading development and training data (limit: 0)."" step. Here are the last couple of log lines:

```
  reading data line 13300000
  reading data line 13400000
  reading data line 13500000
  reading data line 13600000
  reading data line 13700000
src/main/tools/process-tools.c:88: sigaction(sig, &sa, NULL): Invalid argument
ERROR: Non-zero return code '1' from command: Process exited with status 1.
```

Any idea why I get this error?
"
421,Use __all__ to restrict exported Python symbols to the public API,"As part of semantic versioning, our public Python API is (about to be) defined as the symbols documented at https://www.tensorflow.org/api_docs/python.  This is a good definition, but it makes it easy for users to accidentally depend on the non-public API.  To fix this, we should add `__all__` to our Python modules and make sure `__all__` matches the documented public API exactly.

Since we already declare the public symbols via '@@' references in the module docstring, we may be able to do this programmatically.  Indeed,

```
__all__ = [m.group(1) for m in re.finditer(r'^@@(\w+)$', sys.modules[__name__].__doc__)]
```

For Google folk, see b/25561952.
"
420,SparseCrossEntropy in TensorFlow,"Hey TF, 

In your Translate, seq2seq example, there is a part where you require conversion from a sparse to dense matrix to do a softmax. 

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/seq2seq.py#L670

The comment there states that tensorflow needs a sparsecrossentropy function in order for this computation to be done on the gpu (and more efficiently overall). I was wondering: was this implementation planned to happen soon? Thanks!
"
419,Failed to run Android demo targeting API < 20,"I tried to build the demo application for Android for KitKat device (API 20). I was able to modify the app not to use new `hardware.camera2` and it worked on Android Lollipops successfully. However there is an issue targeting older Android device. 
It turned out that the app crashes right after trying to load the native shared library, `tensorflow_demo` in my case.
And that's due to dependency of `libpthread.so` to `libmediandk.so` that is not supported for API older than 21. See the following logcat message:

Error: `..dlopen failed: could not load library ""libmediandk.so"" needed by ""libtensorflow_demo.so""; caused by library ""libmediandk.so"" not found`

I also desperately tried to replace the cloned `libpthread.so` with the same file from my  `/usr/arm-linux-gnueabi/lib/` directory with no success.
I am using:
    1- android-ndk-r10c
    2- api_level=20
    3- build_tools_version = ""20.0.0""

Did I missed anything in that process? 
"
418,"Tensor slice or indexing with tensor i, j ","What I want to do is retrieving(or slicing 1-element) from tensor with tensor indices.

for example, 

```
data = tf.constant( [ [1,2,3], [4,5,6] ] )
i = tf.constant(2)
j = tf.constant(1)

k = data[i,j]    # error
l = tf.gather( tf.gather(data, i) , j) # ok. but generate errors when gradient optimization process..
```

<code>sess.run(k, ...)</code> generates bad slice errors. 

```
 data[i,j]
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py"", line 129, in _SliceHelper
    raise TypeError(""Bad slice index %s of type %s"" % (s, type(s)))
```

<code>tf.gather</code> is ok to slice element, but it yields errors when training time (<code>tf.train.GradientDescentOptimizer.minimize</code>)

Any tips to work-around this problem?
"
417,Explanation of the constants in the tutorials for TensorFlow,"Hi,

Would you be able to provide more explanation in the comments for the code (or at least the papers that are relevant to the underlying theory) for the TensorFlow tutorials?

Thanks!

Shyamal
"
416,small typo for BiRNN comment,"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn.py#L193

do you mean with shape [batch_size x input_size] ?
"
415,'import cifar10' bug,"I have inserted simple print('xxx') in cifar10.py and run cifar10_train.py but no 'xxx' is printed.
Examining cifar10_train.py find out 'import cifar10' from different source:
    from tensorflow.models.image.cifar10 import cifar10
I changed it to:
   import cifar10
and run again, get 'xxx' but crashed the program at the function loss() in cifar10.py saying:

Traceback (most recent call last):
  File ""cifar10_train.py"", line 139, in <module>
    tf.app.run()
  File ""/home/ooky/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/platform/default/_app.py"", line 11, in run
    sys.exit(main(sys.argv))
  File ""cifar10_train.py"", line 135, in main
    train()
  File ""cifar10_train.py"", line 77, in train
    loss = cifar10.loss(logits, labels)
  File ""/home/ooky/work/cifar10/cifar10.py"", line 401, in loss
    indices = tf.reshape(tf.range(FLAGS.batch_size), [FLAGS.batch_size, 1])
TypeError: range() takes at least 2 arguments (1 given)

What's wrong?
"
414,crosstool_wrapper_driver_is_not_gcc cannot find libpython2.7.so.1.0,"I encountered error
python2: error while loading shared libraries: libpython2.7.so.1.0: cannot open shared object file: No such file or directory
while trying to install tensorflow from source with GPU-enabled.

I can see the error command is
 (cd /home/xxx/.cache/bazel/_bazel_xxx/d568262eb4464bf011ab3d998aff21ac/tensorflow && \
  exec env - \
    INTERCEPT_LOCALLY_EXECUTABLE=1 \
    PATH=/share/software/python/2.7.10/Python-2.7.10/release/bin:/share/software/java/jdk1.8.0_66/bin:/share/software/NLP/bazel/output:/usr/local/cuda/bin:/opt/attila/:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/opt/ibutils/bin:/usr/local/MATLAB/R2014a/bin \
  third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++11' -iquote . -iquote bazel-out/local_linux-opt/genfiles -isystem tools/cpp/gcc3 -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' '-frandom-seed=bazel-out/local_linux-opt/bin/external/gemmlowp/_objs/eight_bit_int_gemm/external/gemmlowp/eight_bit_int_gemm/eight_bit_int_gemm.o' -MD -MF bazel-out/local_linux-opt/bin/external/gemmlowp/_objs/eight_bit_int_gemm/external/gemmlowp/eight_bit_int_gemm/eight_bit_int_gemm.d -c external/gemmlowp/eight_bit_int_gemm/eight_bit_int_gemm.cc -o bazel-out/local_linux-opt/bin/external/gemmlowp/_objs/eight_bit_int_gemm/external/gemmlowp/eight_bit_int_gemm/eight_bit_int_gemm.o)

I guess the problem is I'm using a local python version, which is installed under
/share/software/python/2.7.10/Python-2.7.10/release/bin
and path to libpython2.7.so.1.0 is not accessible. 
If I add LD_LIBRARY_PATH=/share/software/python/2.7.10/Python-2.7.10/release/lib to the error command, I would be able to get rid of the error.

It seems to me bazel does not allow user to add ld_library_path(?), so what should I do in this case..?

This error has bothered me for days and I still cannot get over it.... Thank you in advance for your help and suggestions!
"
413,How to use tensorflow python API from the source tree?,"I am trying to setup an efficient development environment for new code inside tensorflow source tree and an external library. Therefore, I am trying to avoid the pip installation process (after every code change) and use the output of bazel build directly in the source tree. In particular, I need access to the Python API from the external library. Can that be accomplished? 
"
412,Adding operations after gradient are applied screws with the optimizer,"I'm currently trying to add an operation after I apply the gradients. Essentially I have a row of some variables that I don't to change via gradients so I would ideally reset it after gradients are applied (I could also set that part of the gradient to 0 but w/e). I currently have this done after my forward inference pass as putting it after apply_gradients doesn't seem to work.

Even adding an op like tf.Print seems to completely screw with the optimizer. What I gather from my debugging is no variables are updated.

```
train_op = self._opt.apply_gradients(...)
train_op = tf.Print(train_op, ....)
```

If I understand Print correctly it just prints stuff and then returns have the op that was passed in, so the returned op should work the same. tf.Print works as expected it prints out what I wanted it to print.
"
411,image_ops.per_image_whitening returns NaN,"It computes a negative variance for certain uniform values.

```
import tensorflow as tf
import numpy as np

im = tf.Variable(np.ones([19,19,3]).astype(np.float32)) * 249
w = tf.image.per_image_whitening(im)
s = tf.Session()
with s.as_default():
  s.run(tf.initialize_all_variables())
  assert not s.run(w).any(), 'NaN'
```
"
410,Batching from two string_input_producers does that don't preserve order.,"I'm trying to read in multiple files (one file consists of the input, the other is the label). I assembled a pipeline using `tf.train.string_input_producer`, some custom decoder and `tf.train.batch` to put them together to batches. Unfortunately, the order does somehow get mixed up in this process. I extracted a minimal example that uses randomly generated strings instead of filenames (and also skips the decoding step), [see my gist here](https://gist.github.com/panmari/6bf13e06c21493d08c75)

In this example, all shuffling was disabled. But the error also occurs if I enabled shuffle and set the same seed for both string input producers. 

Am I using these classes not as intended? Or is there an actual bug?
"
408,Can't find pngwutil.c building tensorflow,"I am getting this error when compiling tensorflow on RHEL 6.6. 

```
[<user>@blah tensorflow]$ ../bazel/output/bazel --output_base=/lvol/<user> build --genrule_strategy=standalone --spawn_strategy=standalone --verbose_failures -j 1 -c opt //tensorflow/cc:tutorials_example_trainer 2>&1|tee compile0.log
......
WARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.io/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.
____Loading package: tensorflow/cc
____Loading...
____Loading package: @bazel_tools//tools/cpp
____Loading package: @local-jdk//
____Loading package: tensorflow/core/platform/default/build_config
____Loading package: @png_archive//
____Loading package: @jpeg_archive//
____Loading complete.  Analyzing...
____Found 1 target...
____Building...
____[0 / 1] BazelWorkspaceStatusAction stable-status.txt
____[3 / 28] Compiling google/protobuf/src/google/protobuf/arena.cc
____[27 / 82] Compiling google/protobuf/src/google/protobuf/any.cc
____[108 / 169] Compiling google/protobuf/src/google/protobuf/any.cc [for host]
____[161 / 260] Compiling google/protobuf/src/google/protobuf/compiler/code_generator.cc [for host]
____[252 / 330] Compiling external/re2/re2/bitstate.cc
ERROR: missing input file '@png_archive//:libpng-1.2.53/pngwutil.c'.
ERROR: /lvol/<user>/external/png_archive/BUILD:33:1: @png_archive//:png: missing input file '@png_archive//:libpng-1.2.53/pngwutil.c'.
____Building complete.
Target //tensorflow/cc:tutorials_example_trainer failed to build
ERROR: /lvol/<user>/external/png_archive/BUILD:33:1 1 input file(s) do not exist.
____Elapsed time: 277.881s, Critical Path: 6.96s
```

Here is what the tree looks like. All the soft-links point to valid files.

```
[<user>@atl4-05 tensorflow]$ ls /lvol/<user>/external/png_archive/
aclocal.m4      config.guess  example.c          LICENSE        pngbar.jpg  png.h       pngrutil.c   pngwrite.c   test-pngtest.sh
ANNOUNCE        config.h.in   INSTALL            ltmain.sh      pngbar.png  pngmem.c    pngset.c     pngwtran.c   TODO
autogen.sh      config.sub    install-sh         Makefile.am    png.c       pngnow.png  pngtest.c    pngwutil.c   WORKSPACE
BUILD           configure     KNOWNBUG           Makefile.in    pngconf.h   pngpread.c  pngtest.png  projects     Y2KINFO
CHANGES         configure.ac  libpng-1.2.53.txt  missing        pngerror.c  pngread.c   pngtrans.c   README
CMakeLists.txt  contrib       libpng.3           mkinstalldirs  pnggccrd.c  pngrio.c    pngvcrd.c    scripts
compile         depcomp       libpngpf.3         png.5          pngget.c    pngrtran.c  pngwio.c     test-driver
```

Here is what the /lvol/<user>/external/png_archive/BUILD file looks like.

```
package(default_visibility = [""//visibility:public""])

prefix_dir = ""libpng-1.2.53""

PNG_SOURCES = [
    ""png.c"",
    ""pngerror.c"",
    ""pngget.c"",
    ""pngmem.c"",
    ""pngpread.c"",
    ""pngread.c"",
    ""pngrio.c"",
    ""pngrtran.c"",
    ""pngrutil.c"",
    ""pngset.c"",
    ""pngtrans.c"",
    ""pngwio.c"",
    ""pngwrite.c"",
    ""pngwtran.c"",
    ""pngwutil.c"",
]

genrule(
    name = ""configure"",
    srcs = glob(
        [""**/*""],
        exclude = [prefix_dir + ""/config.h"", ""configure""],
    ),
    outs = [prefix_dir + ""/config.h""],
    cmd = ""pushd external/png_archive/%s; workdir=$$(mktemp -d -t tmp.XXXXXXXXXX); cp -a * $$workdir; pushd $$workdir; ./configure --enable-shared=no --with-pic=no; popd; popd; cp $$workdir/config.h $(@D); rm -rf $$workdir;"" % prefix_dir,
)

cc_library(
    name = ""png"",
    srcs = [prefix_dir + ""/"" + source for source in PNG_SOURCES],
    hdrs = glob([""**/*.h""]) + ["":configure""],
    includes = [prefix_dir],
    linkopts = [""-lz""],
    visibility = [""//visibility:public""],
)
```
"
407,"Adding new op, no c++ wrapper gen and user_ops.h not found","I followed wiki of adding new op
https://github.com/jikexueyuanwiki/tensorflow-zh/blob/master/SOURCE/how_tos/adding_an_op/index.md

But after rebuild successfully using 
bazel build -c opt //tensorflow/tools/pip_package:build_pip_package
pip install /tmp/tensorflow_pkg/tensorflow-0.5.0-py2-none-any.whl

No user_op.zero_out found.

It seems python wrapper automatically generated ok,
 ./bazel-genfiles/tensorflow/python/ops/gen_user_ops.py 

But c++ wrapper not generated,
I can not find ./bazel-genfiles/tensorflow/cc/ops/user_ops.{h,cc}., though tensorflow/core/user_ops/zero_out.cc exists.

""The C++ Op wrapper

C++ op wrappers are created automatically for all ops placed in the tensorflow/core/user_ops directory, when you build Tensorflow. For example, ops in tensorflow/core/user_ops/zero_out.cc will generate wrappers in bazel-genfiles/tensorflow/cc/ops/user_ops.{h,cc}.""
"
406,How to do a Bilinear Tensor Product? Or generally multiply 3D tensor by a vector?,"Seems like there are only two multiplication operations available, tf.mul which is element-wise and tf.matmul which performs regular 2d matrix multiplication. Am I missing something? 
"
405,gcc-4.8.1 wouldn't compile matrix_inverse_op.cc,"gcc-4.8.1 didn't like the way 'using' was used. This patch fixed the issue for me.

[using_typename.txt](https://github.com/tensorflow/tensorflow/files/51293/using_typename.txt)
"
404,gcc-4.8.1 is unhappy with usage of auto* in conv_grad_ops.cc,"Seems like gcc-4.8.1 can't resolve the type of some of the instances of auto. This diff fixed it for me:

[remove_auto.txt](https://github.com/tensorflow/tensorflow/files/51290/remove_auto.txt)
"
403,Bidirectional RNNs,"I'd like to request support for bidirectional RNNs, as these are rather canonical architectures. I realize it's possible to do using the existing rnn API, but given all the intricacies of padding and such (especially in the reverse direction), it would be nice if this had builtin support.
"
402,More details of Inception model?,"Please include the following details for the inception model included in the android and label-image example:
1. training dataset
2. testing dataset and what's the top-1 and top-5 performance
3. training parameters, number of iterations, learning rate, optimization algorithm
"
401,"Tutorial TensorBoard: Visualizing Learning, path error","In the following tutorial about visualizing TensorBoard is an error: http://www.tensorflow.org/how_tos/summaries_and_tensorboard/index.html

The tutorial says the code to run the visualization of the mnist data is:

```
tensorboard --logdir=/tmp/mnist_data
```

However in the code you provide, you put:

```
writer = tf.train.SummaryWriter(""/tmp/mnist_logs"", sess.graph_def)
```

mnist_data =/= mnist_logs. The right code is:

```
tensorboard --logdir=/tmp/mnist_logs
```

---

Additionally would it be possible to explain how TensorBoard takes it current path?
For example, if I change `--logdir=/tmp/mnist_logs` to `--logdir=mnist_logs` (to put it in the current directory I'm working in), it correctly makes a new folder `mnist_logs`. However if I run the following code in the current directory:

```
 tensorboard --logdir=mnist_logs
```

TensorBoard cannot find the log file. How would I run `tensorboard` from the current directory?

---

On the subject of path clarity, could you add an output which states where TensorBoard looks for the log file? Currently:

```
Starting TensorBoard on port 6006
(You can navigate to http://localhost:6006)
```

Could you add:

```
TensorBoard looks for the log files in: /path/to/folder/
and found a file / didn't find a file
```
"
400,Tutorial: Visual Object Recognition,"When will the 'Visual Object Recognition' part of the tutorial be released?
"
399,connection refused,"Hello all,
I have a problem when running: python tensorflow/models/image/mnist/convolutional.py
An error evoked :  IOError: [Errno socket error] [Errno 111] Connection refused

Can it be related to proxy settings problem? 
"
398,GPU ran-out-of-memory problem,"I've got a GPU ran-out-of-memory problem.

My single GPU Card has about 11GB memory. As the nvidia-smi shows below:
## N/A   48C    P0   129W / 235W |  10985MiB / 11519MiB |     99%      Default

I define a big CNN models, it is like this:
## My CNN Models Start...

Layer 1.
input: one batch 35 pics, with 1024x1024x3:
(35,1024,1024,3)

Layer 2.
2D conv-layer and 2D max-pool layer:
conv-kernel (3,3,3), 16 feature maps, stride=1, and using ""SAME"" padding,
max-pool-kernel (2,2), stride=2, so the output should be
(35,512,512,16)
and the parameters of the layer should be:
W: 3x3x3x16+b: 16=448

Layer3, 4, 5, 6:
The same as Layer2, 2D Conv and 2D Max Pool,
conv-kernel (3,3,16), 16 feature maps, stride=1, and using ""SAME"" padding,
max-pool-kernel (2,2), strides=2, 
the output of the layers is:
(35,256,256,16)
(35,128,128,16)
(35,64,64,16)
(35,32,32,16)
The total parameters is:
4x(3x3x16x16)+4x16=9280

Layer7:
dense layer with 2048 hidden nodes,
the parameters:
32x32x16x2048+2048=33556480

Layer8:
dense layer with 600 hidden nodes,
the parameters:
600x2048+600=1229400
## END.

So all together, the model has 448+9280+33556480+1229400=34795608 float32 parameters, it is  34795608x4/1024/1024=132MB parameters.

Maybe I should also add the memory cost by the outputs, so it is
(35x1024x1024x3)+(35x512x512x16)+(35x256x256x16)+(35x128x128x16)+(35x64x64x16)+(35x32x32x16)=305643520 float32
=305643520x4/1024/1024=1164MB
## All together, no more than 2GB. Far from 11GB.

But I got the following:
## Ran out of memory trying to allocate 512.00MiB.  See logs for memory state

However,  once I changed the number of output feature-maps for each layer from 16 to 8 (or less), the model just trained well.

I use the latest tensor-flow codes (20151202), the following session configs:
## Code start

```
### start session
config=tf.ConfigProto()
# config.gpu_options.per_process_gpu_memory_fraction=0.98
config.gpu_options.allocator_type=""BFC""
config.log_device_placement=True
sess=tf.Session(config=config)
```
## Code end

But it doesn't solve my problems.
## So, help....
"
397,Add auc calculation operator ?,"Any plans for adding this ?  Like in sklearn   roc_auc_score(teY, predicts)
"
396,Cifar10 example bug (batch #5 not loading),"In _tensorflow/models/image/cifar10/cifar10.py_ it says:

```
filenames = [os.path.join(FLAGS.data_dir, 'cifar-10-batches-bin',
                        'data_batch_%d.bin' % i)
           for i in xrange(1, 5)]
```

which will only load batches 1 to 4, while batch number 5 is ignored entirely. This would be correct imo:

```
for i in xrange(1, 6)]
```
"
395,The `external` directory missing when building from source,"Trying to run Tensorboard, and the complains with about several things missing in the tensorflow/external directory. This entire directory is not the at all, and it's not a part of any submodule (the only submodule included is protobuf).
"
394,failed call to cuInit: CUDA_ERROR_UNKNOWN in python programs using Ubuntu bumblebee,"I have a Quadro K1100M integrated gpu with compute capability 3.0. I had to install bumblebee to make CUDA work. I am now able to run the tutorials_example_trainer with the command `sudo optirun bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu`. I have been able to do that with `TF_UNOFFICIAL_SETTING=1 ./configure`. However, I am not able to run examples in python directly.

For example, if I run the convolutional.py in tensorflow/models/image/mnist with the command `optirun python convolutional.py`, I get the following error : 

```
tensorflow/tensorflow/models/image/mnist$ optirun python convolutional.py 
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz
I tensorflow/core/common_runtime/local_device.cc:25] Local device intra op parallelism threads: 8
E tensorflow/stream_executor/cuda/cuda_driver.cc:466] failed call to cuInit: CUDA_ERROR_UNKNOWN
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:98] retrieving CUDA diagnostic information for host: jp-pc
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] hostname: jp-pc
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:131] libcuda reported version is: 352.63
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:242] driver version file contents: """"""NVRM version: NVIDIA UNIX x86_64 Kernel Module  352.63  Sat Nov  7 21:25:42 PST 2015
GCC version:  gcc version 4.8.4 (Ubuntu 4.8.4-2ubuntu1~14.04) 
""""""
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:135] kernel reported version is: 352.63
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:211] kernel version seems to match DSO: 352.63
I tensorflow/core/common_runtime/gpu/gpu_init.cc:112] DMA: 
I tensorflow/core/common_runtime/local_session.cc:45] Local session inter op parallelism threads: 8
```

It is like my gpu is not recognized in python programs because of the 3.0 compute capability.  Is there a way to avoid this problem?
"
393,"TensorBoard,No scalar summary tags were found","sess = tf.Session() 
init = tf.initialize_all_variables()
sess.run(init)

summary_writer = tf.train.SummaryWriter('./tmp/tensorflow_log', graph_def=sess.graph_def)
# However after launching TensorBoard I can not see any grah def info..

I also tried tf.training.summary_io.SummaryWriter, but it will not generate any log..
""""
No scalar summary tags were found.

Maybe data hasn't loaded yet, or maybe you need to add some tf.scalar_summary ops to your graph, and serialize them using the tf.training.summary_io.SummaryWriter.
""""""

Seems there are people facing the same issue, on stackoverflow but not solved.
http://stackoverflow.com/questions/33634764/tensorboard-doesnt-find-scalar-statistics/33652076#33652076
"
392,Mac virtualenv: TensorFlow Mechanics 101 failure,"When I try to run the Mechanics 101 tutorial on a Mac using virtualenv, it fails with:

$ python fully_connected_feed.py
Traceback (most recent call last):
  File ""fully_connected_feed.py"", line 31, in <module>
    from tensorflow.g3doc.tutorials.mnist import input_data
ImportError: No module named g3doc.tutorials.mnist

To reproduce:
$ virtualenv --system-site-packages ~/tensorflow
$ source ~/tensorflow/bin/activate
$ pip install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.5.0-py2-none-any.whl
$ python, running ""hello world"" test: works fine
$ python -m tensorflow.models.image.mnist.convolutional: works fine

First problem:
$ python -c 'import site; print ""\n"".join(site.getsitepackages())'
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
AttributeError: 'module' object has no attribute 'getsitepackages'

Expected behavior: should print path, according to instructions at http://www.tensorflow.org/get_started/os_setup.html#run-a-tensorflow-demo-model
This seems to be a problem with virtualenv: See https://github.com/pypa/virtualenv/issues/228

Second problem:
Download fully_connected_feed.py 
$ python fully_connected_feed.py
Traceback (most recent call last):
  File ""fully_connected_feed.py"", line 31, in <module>
    from tensorflow.g3doc.tutorials.mnist import input_data
ImportError: No module named g3doc.tutorials.mnist

Expected behavior: should run MNIST according to instructions at http://www.tensorflow.org/tutorials/mnist/tf/index.html#tutorial-files

I suspect some sort of path problem, but due to the first problem I can't figure out the right path.

System:
MacBook Pro (Retina, 15-inch, Early 2013)
OS X El Capitan, version 10.11.1 (15B42)
Python 2.7.10 (default, Aug 22 2015, 20:33:39)
[GCC 4.2.1 Compatible Apple LLVM 7.0.0 (clang-700.0.59.1)] on darwin
"
391,Fatal error in TileOps: invalid combination,"I have an RNN I adapted from the PTB example that works fine on CPU.  But when I try to run it on a GPU, it dies with:

F tensorflow/core/kernels/tile_ops.cc:131] TileOp: Invalid combination of Device, DT and NDIM: N5Eigen9GpuDeviceE, float, 0

I'm guessing this is complaining about a 0-dimensional tensor?  What's going on?
"
390,parse_example can be _much_ faster than parse_single_example,"FYI I am working with Example protos for model input, and I am learning that use `tf.parse_example` to parse a (shuffled) batch of serialized examples is _much_ faster than using `tf.parse_single_example` prior to batching. For my particular dataset, using parse_single_example allows me to create `feed_dict`s with batch size 128 at about 100/min; batching the serialized Example protos and then using parse_example is running at around 3000/min.

You may want to update the [documentation](http://www.tensorflow.org/how_tos/reading_data/index.html#file-formats) to suggest using `tf.parse_example` everywhere, as is suggested when using [sparse input data](http://www.tensorflow.org/how_tos/reading_data/index.html#sparse-input-data).
"
389,Cifar-10 eval script verbose output,"I've ran cifa10_train.py successfully. Now, I'm trying to run cifar10_eval.py, but the code's following verbose repeatedly without stopping. Any idea what this means?

I tensorflow/core/common_runtime/local_device.cc:25] Local device intra op parallelism threads: 4
I tensorflow/core/common_runtime/local_session.cc:45] Local session inter op parallelism threads: 4
2015-12-01 08:17:18.602794: precision @ 1 = 0.855
W tensorflow/core/common_runtime/executor.cc:1027] 0x7fa024001740 Compute status: Cancelled: Enqueue operation was cancelled
     [[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""](shuffle_batch/random_shuffle_queue, Div, Cast)]]
W tensorflow/core/common_runtime/executor.cc:1027] 0x7fa03c001630 Compute status: Cancelled: Enqueue operation was cancelled
     [[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""](shuffle_batch/random_shuffle_queue, Div, Cast)]]
W tensorflow/core/common_runtime/executor.cc:1027] 0x7fa02c001630 Compute status: Cancelled: Enqueue operation was cancelled
     [[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""](shuffle_batch/random_shuffle_queue, Div, Cast)]]
W tensorflow/core/common_runtime/executor.cc:1027] 0x7fa0500018c0 Compute status: Cancelled: Enqueue operation was cancelled
     [[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""](shuffle_batch/random_shuffle_queue, Div, Cast)]]
W tensorflow/core/common_runtime/executor.cc:1027] 0x7fa028001630 Compute status: Cancelled: Enqueue operation was cancelled
     [[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""](shuffle_batch/random_shuffle_queue, Div, Cast)]]
W tensorflow/core/common_runtime/executor.cc:1027] 0x7fa0480098d0 Compute status: Cancelled: Enqueue operation was cancelled
     [[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""](shuffle_batch/random_shuffle_queue, Div, Cast)]]
W tensorflow/core/common_runtime/executor.cc:1027] 0x7fa020001630 Compute status: Cancelled: Enqueue operation was cancelled
     [[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""](shuffle_batch/random_shuffle_queue, Div, Cast)]]
W tensorflow/core/common_runtime/executor.cc:1027] 0x7fa030001630 Compute status: Cancelled: Enqueue operation was cancelled
     [[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""](shuffle_batch/random_shuffle_queue, Div, Cast)]]
W tensorflow/core/common_runtime/executor.cc:1027] 0x7fa038001730 Compute status: Cancelled: Enqueue operation was cancelled
     [[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""](shuffle_batch/random_shuffle_queue, Div, Cast)]]
W tensorflow/core/common_runtime/executor.cc:1027] 0x7fa0540098d0 Compute status: Cancelled: Enqueue operation was cancelled
     [[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""](shuffle_batch/random_shuffle_queue, Div, Cast)]]
W tensorflow/core/common_runtime/executor.cc:1027] 0x7fa018001630 Compute status: Cancelled: Enqueue operation was cancelled
     [[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""](shuffle_batch/random_shuffle_queue, Div, Cast)]]
W tensorflow/core/common_runtime/executor.cc:1027] 0x7fa0400018e0 Compute status: Cancelled: Enqueue operation was cancelled
     [[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""](shuffle_batch/random_shuffle_queue, Div, Cast)]]
W tensorflow/core/common_runtime/executor.cc:1027] 0x7fa0440098d0 Compute status: Cancelled: Enqueue operation was cancelled
     [[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""](shuffle_batch/random_shuffle_queue, Div, Cast)]]
W tensorflow/core/common_runtime/executor.cc:1027] 0x7fa05c055a30 Compute status: Cancelled: Enqueue operation was cancelled
     [[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""](shuffle_batch/random_shuffle_queue, Div, Cast)]]
W tensorflow/core/common_runtime/executor.cc:1027] 0x7fa04c0098d0 Compute status: Cancelled: Enqueue operation was cancelled
     [[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""](shuffle_batch/random_shuffle_queue, Div, Cast)]]
W tensorflow/core/common_runtime/executor.cc:1027] 0x7fa060052d90 Compute status: Cancelled: Enqueue operation was cancelled
     [[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""](shuffle_batch/random_shuffle_queue, Div, Cast)]]
I tensorflow/core/kernels/random_shuffle_queue_op.cc:282] Skipping cancelled enqueue attempt
I tensorflow/core/kernels/random_shuffle_queue_op.cc:282] Skipping cancelled enqueue attempt
I tensorflow/core/kernels/random_shuffle_queue_op.cc:282] Skipping cancelled enqueue attempt
I tensorflow/core/kernels/random_shuffle_queue_op.cc:282] Skipping cancelled enqueue attempt
I tensorflow/core/kernels/random_shuffle_queue_op.cc:282] Skipping cancelled enqueue attempt
I tensorflow/core/kernels/random_shuffle_queue_op.cc:282] Skipping cancelled enqueue attempt
I tensorflow/core/kernels/random_shuffle_queue_op.cc:282] Skipping cancelled enqueue attempt
I tensorflow/core/kernels/random_shuffle_queue_op.cc:282] Skipping cancelled enqueue attempt
I tensorflow/core/kernels/random_shuffle_queue_op.cc:282] Skipping cancelled enqueue attempt
I tensorflow/core/kernels/random_shuffle_queue_op.cc:282] Skipping cancelled enqueue attempt
I tensorflow/core/kernels/random_shuffle_queue_op.cc:282] Skipping cancelled enqueue attempt
I tensorflow/core/kernels/random_shuffle_queue_op.cc:282] Skipping cancelled enqueue attempt
I tensorflow/core/kernels/random_shuffle_queue_op.cc:282] Skipping cancelled enqueue attempt
I tensorflow/core/kernels/random_shuffle_queue_op.cc:282] Skipping cancelled enqueue attempt
I tensorflow/core/kernels/random_shuffle_queue_op.cc:282] Skipping cancelled enqueue attempt
I tensorflow/core/kernels/random_shuffle_queue_op.cc:282] Skipping cancelled enqueue attempt
W tensorflow/core/common_runtime/executor.cc:1027] 0x7fa064001480 Compute status: Cancelled: Enqueue operation was cancelled
     [[Node: input_producer/input_producer_EnqueueMany = QueueEnqueueMany[Tcomponents=[DT_STRING], timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""](input_producer, input_producer/RandomShuffle)]]
"
388,Rust API,"TensorFlow should have a Rust interface.

Original e-mail:
I'd like to write Rust bindings for TensorFlow, and I had a few questions.  First of all, is anyone already working on this, and if so, can I lend a hand?  If not, is this something the TensorFlow team would be interested in?  I assume that the TensorFlow team would not be willing to commit right now to supporting Rust, so I thought a separate open source project (with the option to fold into the main project later) would be the way to go.
"
387,Any intentions of R interface?,"Hi!

Im working with the python wrapper for tensorflow. Is there any intentions of implement similar wrappers for the R languages?
"
386,Implement Fast Fourier Transform ops,"Hey TF,

Trying to integrate the new Unitary RNN's into tensorflow. Unfortunately, they require Fast Fourier Transform and Inverse Fast Fourier Transforms. 

For efficiency this needs to be done on the GPU. On the author's code (theano), they do this by making a Theano Op, and inserting scikit's Fast Fourier and Inverse Fast Fourier Here:

https://github.com/amarshah/complex_RNN/blob/master/fftconv.py

How can this be done in TF? Upon completing the Unitary RNN, I plan to share it to everyone! I asked on the google groups, but didn't get a reply. 
"
385,when the tensorflow support for cluster installation,"when the tensorflow support for cluster installation
"
384,32-bit architecture support?,"There's some discussion [pointer](http://stackoverflow.com/questions/33752772/tensorflow-on-raspberry-pi) pointing out that TensorFlow only supports 64 bit architectures. Is this correct?

Can someone confirm, that given the right dependencies are met, TensorFlow could also run in 32-bit machines?

Thanks,
"
383,tf.train.saver.restore failed error,"Cause training a model is time consuming, So Save a Checkpoint on training, but error occurred when to restore.
The `saver.restore` says as follow:

```
Signature: saver.restore(sess, save_path)
Docstring:
Restores previously saved variables.

This method runs the ops added by the constructor for restoring variables.
It requires a session in which the graph was launched.  The variables to
restore do not have to have been initialized, as restoring is itself a way
to initialize variables.

The `save_path` argument is typically a value previously returned from a
`save()` call, or a call to `latest_checkpoint()`.

Args:
  sess: A Session to use to restore the parameters.
  save_path: Path where parameters were previously saved.
```

So I used it as following:

```
with tf.Graph().as_default():
    saver = tf.train.Saver()
    sess = tf.Session()
    Saver.restore(sess, ""./MNIST_data/-1"")
```

But got the following err:

```
ValueError                                Traceback (most recent call last)
<ipython-input-10-4c62153b8108> in <module>()
     31 
     32 with tf.Graph().as_default():
---> 33     saver = tf.train.Saver()
     34     sess = tf.Session()
     35     Saver.restore(sess, ""./MNIST_data/-1"")

/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in __init__(self, var_list, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, saver_def, builder)
    678         var_list = variables.all_variables()
    679       if not var_list:
--> 680         raise ValueError(""No variables to save"")
    681       saver_def = builder.build(
    682           var_list,

ValueError: No variables to save
```
"
382,Failed to bazel build when executing label_image example ,"When I run the root@795c87fec335:/tensorflow# bazel build tensorflow/examples/label_image/...
It shows the ERRORs

ERROR: /tensorflow/tensorflow/core/BUILD:210:1: C++ compilation of rule '//tensorflow/core:kernels' failed: gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer '-std=c++0x' -iquote . -iquote ... (remaining 47 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
INFO: Elapsed time: 91.739s, Critical Path: 73.71s
"
381,Failed to bazel build when executing label_image example ,"When I build bazel it shows this ERROR

root@ee32ec72b8cb:/tensorflow/tensorflow/examples/label_image# bazel build tensorflow/tensorflow/examples/label_image/...
INFO: Reading 'startup' options from /root/.bazelrc: --batch
ERROR: no targets found beneath 'tensorflow/examples/label_image/tensorflow/tensorflow/examples/label_image'.
INFO: Elapsed time: 0.771s

I try to run bazel fetch//
It shows BUILD file have ERRORs

ERROR: /tensorflow/tensorflow/examples/label_image/BUILD:1:3: invalid character: '!'.
ERROR: /tensorflow/tensorflow/examples/label_image/BUILD:8:118: invalid character: '!'.
ERROR: /tensorflow/tensorflow/examples/label_image/BUILD:8:243: invalid character: '!'.
ERROR: /tensorflow/tensorflow/examples/label_image/BUILD:8:256: invalid character: '!'.
.....
"
380,wishlist: provide alternative build system,"The memory consumption for bootstraping bazel is very huge, according to my observation.
And I really have trouble building bazel on my machine because lacking of enough memory.

So could you please provide an alternative (traditional) build system (e.g. make, cmake) or setup.py, 
for users who insist on building software from source by themselves.

Thanks.
"
379,incorrect app.flags.DEFINE_boolean behavior ,"### demo python script

 test.py 

```
#!/usr/bin/python
import tensorflow as tf
tf.app.flags.DEFINE_boolean('tea',False,'Soggy Leaves')
cfg = tf.app.flags.FLAGS

if cfg.tea:
    print( ""have some tea"" )
else:
    print( ""no tea"" )
```
### Expected behavior

When the above test.py is run with any of {(no arguments), --notea, or --tea=True}, the script behaves as expected...

```
[markb@schur tmp]$ ./test.py
no tea
[markb@schur tmp]$ ./test.py --notea
no tea
[markb@schur tmp]$ ./test.py --tea=True
have some tea
```
### Weird stuff

Strangely `--tea=False` is _incorrectly_ interpreted as True.  Having both tea and no tea is only possible in certain Infocom games.

```
[markb@schur tmp]$ ./test.py --tea=False
have some tea
```

Apparently, only those who _truly_ want tea will get it.  

```
[markb@schur tmp]$ ./test.py --tea
usage: test.py [-h] [--tea TEA] [--notea]
test.py: error: argument --tea: expected one argument
```

C'mon. It's a boolean flag ! 
""Say something once.  Why say it again?""  -- _Talking Heads_
"
378,matmul gradients incorrect with complex64 tensors,"The conjugation step was skipped.
See  https://tensorflow-review.googlesource.com/#/c/1154/ for unit tests and a fix
"
377,How to install/run/use TensorFlow on windows machines?,
376,undefined symbol: clock_gettime with tensorflow on ubuntu14.04,"I have posted my problem on stackoverflow.
http://stackoverflow.com/questions/33980109/undefined-symbol-clock-gettime-with-tensorflow-on-ubuntu14-04
"
375,CUDA headers not found when implementing GPU kernel for user-op,"I am following the tutorial to implement a user-op. I have three files `dna_encode_op.cc`, `dna_encode_op_gpu.cu.cc`, and `dna_encode_op.h`.

I have configured TensorFlow with GPU support using `./configure`. However, during compilation of `dna_encode_op_gpu.cu.cc`, Bazel doesn't find the CUDA headers:

```
INFO: From Compiling tensorflow/core/user_ops/dna_encode_op_gpu.cu.cc [for host]:
In file included from ./tensorflow/core/framework/tensor_types.h:4:0,
                 from tensorflow/core/user_ops/dna_encode_op_gpu.cu.cc:8:
./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:55:18: fatal error: cuda.h: No such file or directory
 #include <cuda.h>
                  ^
compilation terminated.
ERROR: /home/hannes/git/DNAflow_internal/tensorflow/core/BUILD:339:1: C++ compilation of rule '//tensorflow/core:user_ops_op_lib' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object ... (remaining 50 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
```

Building the included ops works well, so I'm wondering whether I have to modify `BUILD` - however, there is no mention of this in the tutorials.
"
374,No module named tensorflow.python.platform,"Hi, I am running tensorflow/g3doc/tutorials/mnist/fully_connected_feed.py. I get:

hiro106@hiro106-virtual-machine:~$ python tensorflow/tensorflow/g3doc/tutorials/mnist/fully_connected_feed.py
Traceback (most recent call last):
  File ""tensorflow/tensorflow/g3doc/tutorials/mnist/fully_connected_feed.py"", line 33, in <module>
    import tensorflow.python.platform
ImportError: No module named tensorflow.python.platform

If you have any idea, please help me.
Thanks,
"
373,Random numbers with None value in shape,"There are several use cases where the shape of random numbers is to be determined at runtime. E.g. for variational auto encoder or injection of noise into an MLPs units. As of now, this seems not possible in an elegant way with tensorflow:

```
import tensorflow as tf
x = tf.placeholder('float32', [None, 784])
noised = x + tf.random_normal(x.get_shape())
```

The above throws [this traceback](https://gist.github.com/bayerj/12e6a80c36593173a489). I have to replace `None` above with a number known before runtime. But then I have to fix my batch size beforehand (to which the None corresponds) and need different expressions for each batch size.
"
371,Sparse tensor construction given repeated indices,"TensorFlow behaves differently (and surprisingly) to SciPy when converting sparse matrices to dense matrices.

``` python
import tensorflow as tf
import scipy as sp
import scipy.sparse

i = [0, 0]
j = [0, 0]
values = [1, 2]

sp_answer = sp.sparse.coo_matrix((values, (i, j))).todense()
print(""SciPy's answer is "" + str(sp_answer)) # prints [[3]]

tf_answer = tf.sparse_to_dense([i, j], [1, 1], values, 0)
print(""TF's answer is "" + str(tf.Session().run(tf_answer))) # prints [[2]]
```

Specifically, if an index pair is repeated, then SciPy will sum the corresponding values, while TF just keeps the last value.

Is this behaviour intentional or accidental? If it's intentional, I'll make a pull request to add a mention of it to the docs. If it's accidental, I'll make a pull request to fix it.
"
370,convert_to_records.py don't write all values into .tfrecords file,"Hi,
at first i suppose there is a typing mistake in line 56 (dat.shape[0], num_examples) i think it should be (images.shape[0],num_examples). the second thing was that this code did'nt wrote me the depth values into .tfrecords file. I need to pass them as _bytes_feature(str(depth)) after that the value was written into .tfrecords file.
"
369,reduce_mean gradient wrong,"The `reduce_mean` code was incorrectly scaling the gradient from `reduce_sum` to adjust for the number of element in the **input** tensor as well as the **output** tensor.  
The only adjustment should be based on the number of output elements N, since mean=sum/N.

Fixed in patch at https://tensorflow-review.googlesource.com/#/c/1153/
"
368,Sampled decoding instead of argmax decoding in seq2seq (feature request for tf.choice),"Currently, the seq2seq decoders only support argmax decoding. To enable sampled decoding, we would need a `tf.choice` function to replace `tf.argmax` in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/seq2seq.py#L326

Any plans on implementing this? Can the desired functionality be achieved using other ways?

Theano's `choice` function: http://deeplearning.net/software/theano/library/tensor/raw_random.html
However, it would be preferable for `choice` to have the same interface as `argmax`.
"
367,Gradient for tf.cholesky,"It would be really nice to have a gradient operation for `tf.cholesky` similar to Theano's [CholeskyGrad](http://deeplearning.net/software/theano/library/tensor/slinalg.html#theano.tensor.slinalg.CholeskyGrad). 

I'll be seeing if I can implement the gradient using `tf.control_flow_ops.While` following the suggestion provided [here](http://stackoverflow.com/questions/33962959/cholesky-factor-differentiation-in-tensorflow), but if someone with C++ experience can implement the gradient directly in C++, that'd be great.

Thanks!
"
366,Missing graph_vis_animation.gif image in http://www.tensorflow.org/how_tos/graph_viz/index.html,"http://www.tensorflow.org/how_tos/graph_viz/index.html has a bad embedded image link:

```
<p>
  <img src=""./graph_vis_animation.gif"" 
   alt=""Visualization of a TensorFlow graph"" 
  title=""Visualization of a TensorFlow graph"" />
<em>Visualization of a TensorFlow graph.</em></p>
```

Nearby: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/g3doc/how_tos/graph_viz (and https://tensorflow.googlesource.com/tensorflow/+/master/tensorflow/g3doc/how_tos/graph_viz/ ) are missing the file. 
"
365,Hamburger menu no longer appears on mobile,"I noticed that the hamburger menu no longer appears on mobile:

<img width=""400"" alt=""screen shot 2015-11-26 at 9 20 26 pm"" src=""https://cloud.githubusercontent.com/assets/5283042/11434590/a97d28de-9483-11e5-9587-70a6a1b45e79.png"">
"
364,Integer random_uniform,"Feature request:

Support for dtype=tf.int32/int64 in tf.random_uniform.
"
363,"No Rollback after ""cifar10_train.py"" canceled","Hi,

I noticed than on both Ubuntu and Mac OSX there is no handling of cancelling (rollback?) the cifar10-set download process of the cifar10_train.py via ctrl+c.

If the process was once canceled you will be incapable of running the script again. The following error will be issued:

```
Traceback (most recent call last):
  File ""cifar10_train.py"", line 138, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/default/_app.py"", line 11, in run
    sys.exit(main(sys.argv))
  File ""cifar10_train.py"", line 134, in main
    train()
  File ""cifar10_train.py"", line 69, in train
    images, labels = cifar10.distorted_inputs()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/models/image/cifar10/cifar10.py"", line 166, in distorted_inputs
    raise ValueError('Failed to find file: ' + f)
ValueError: Failed to find file: /tmp/cifar10_data/cifar-10-batches-bin/data_batch_1.bin
```
"
362,Some wrong code in get_started document,"On your get started website http://www.tensorflow.org/get_started/basic_usage.html#basic-usage
I found a small piece of wrong code:
In the sample code of Feeds section:

```
input1 = tf.placeholder(tf.types.float32)
input2 = tf.placeholder(tf.types.float32)
```

I tried them and python gave the AttributeError: 'module' object has no attribute 'types'
After reading the document http://www.tensorflow.org/resources/dims_types.html
I think it should be `tf.float32` instead of `tf.types.float32`.  Probably it's a version issue?
"
361,wget ...mnist/input_data.py from tensorflow.googlesource.com results in jargon,"`wget https://tensorflow.googlesource.com/tensorflow/+/master/tensorflow/g3doc/tutorials/mnist/input_data.py` 
result is html formatted, unusable. 

`wget https://tensorflow.googlesource.com/tensorflow/+/master/tensorflow/g3doc/tutorials/mnist/input_data.py?format=TEXT` 
results in jargon, unusable. 

`wget https://github.com/tensorflow/tensorflow/raw/master/tensorflow/g3doc/tutorials/mnist/input_data.py`
works
"
360,Warn when calling session.run() on a very large scatter,"Scatter ops output a ref to the whole tensor for easier chaining. The problem is if one executes the op directly in Session.run() the whole tensor is copied back as a numpy array. This can create very annoying and hard to find performance problems. I think you should consider adding a warning.

For example:
large_table = tf.Variable(... [1000000, 3])
set3_op = tf.scatter_update(large_table, 3, [1,2,3])

session.run([set3_op])

Here run() modifies just 3 elements of the table but returns the whole table as a numpy array that is then 
ignored.
"
359,ADAM optimizer creates trainable variable,"ADAM optimizer crates two variables that are marked as trainable for no good reason (at least not apparent to me). 

I sent the following path but no one seems to have looked at it:
https://tensorflow-review.googlesource.com/#/c/1141/
"
358,SWIG signature mismatch at RecordWriter,"I tried to run the example ""tensorflow/g3doc/how_tos/reading_data/convert_to_records.py"", but there is an error saying function signature mismatch on the `bool WriteRecord(::tensorflow::StringPiece record);` call.

My swig version is `SWIG Version 1.3.40`

A simple fix is to change `bool WriteRecord(::tensorflow::StringPiece record);` to `bool WriteRecord(const string &record);` for these two files,

```
tensorflow/tensorflow/python/lib/io/py_record_writer.h
tensorflow/tensorflow/python/lib/io/py_record_writer.cc
```
"
357,reduce_sum (complex) on GPU segfaults,"When the `reduce_sum` operation is run on a complex tensor on my GPU, it segfaults. See the attached python bug demo script.
- OS: Linux CentOS 7
- GPU: GeForce GTX 750 ti

[bug.txt](https://github.com/tensorflow/tensorflow/files/44567/bug.txt)
"
356,translate: unrecognized option --data_dir,"I tried the 'translate' command described in the tutorial (http://www.tensorflow.org/tutorials/seq2seq/index.html#run_it). But it threw an error:

```
$ bazel run -c opt tensorflow/models/rnn/translate:translate --data_dir /tmp/data --train_dir /tmp/train  
Unrecognized option: --data_dir 
```

For the records, this worked instead:

```
$ bazel build -c opt --config=cuda tensorflow/models/rnn/translate:translate            
$ bazel-bin/tensorflow/models/rnn/translate/translate --data_dir /tmp/data --train_dir /tmp/train
```
"
355,The first name of Françoise Beaufays is misspelled in whitepaper2015.pdf,"In the TensorFlow white paper (http://download.tensorflow.org/paper/whitepaper2015.pdf), on page 17, reference [6], the first name of Françoise Beaufays is misspelled as Franoise, missing a ""ç"".
"
354,Tutorials are difficult to read,"Greyish text on white background causes eye fatigue. Especially with longer text, and sanserif fonts.
"
353,cifar10 speed numbers,"In the comments of [cifar10_train.py](https://tensorflow.googlesource.com/tensorflow/+/master/tensorflow/models/image/cifar10/cifar10_train.py), it says: 

```
Accuracy:
cifar10_train.py achieves ~86% accuracy after 100K steps (256 epochs of
data) as judged by cifar10_eval.py.

Speed: With batch_size 128.

System        | Step Time (sec/batch)  |     Accuracy
------------------------------------------------------------------
1 Tesla K20m  | 0.35-0.60              | ~86% at 60K steps  (5 hours)
1 Tesla K40m  | 0.25-0.35              | ~86% at 100K steps (4 hours)
```

The math doesn't look right to me: 
5 x 60 x 60 / 60K=**0.3** sec/batch
4 x 60 x 60 / 100K=**0.144** sec/batch

Also, on my machine (K40c, 28 CPU cores, SSD) I can only reach about half the speed (~0.6 sec/batch). Any idea what might be the factor that slows it down? Thanks! 
"
352,Out of GPU Memory -- Only 1 LSTM layer on 980 TI,"Hey TF,

I have been using your translate model from your seq2seq tutorial and everything seems to work great. 

However, I have encountered a substantial problem. On my 980 TI with 6gb of memory:
- 5 GRU layers, 512 cells, batch size 32 -- _works_
- 1 GRU layer, 1024 cells, batch size 2 -- _barely works_ (tried batch size of 2, 4, 8, 16)

In Keras, I could run 2 GRU layers each with 2048 cells on my the 6gb memory. So the question I have is: how is this possible? What is taking up so much memory when you increase the cell size? 

I have a second 980 TI as well. I was really hoping I could put one layer 2048 cells on each card. Thanks again! 
"
351,Failed to load compute graph when executing label_image example,"after cloning tensorflow on my OSX 10.10.4, I tried to run label_image example in tensorflow/examples/, and followed the instructions.
currently seems fine after built even some warnings were occured but no error.
but when I typed 'bazel-bin/tensorflow/examples/label_image/label_image'
it showed:
E tensorflow/examples/label_image/main.cc:260] Not found: Failed to load compute graph at 'tensorflow/examples/label_image/data/googlenet_graph.pb'

I saw a file named tensorflow_inception_graph.pb in that folder, and I tried to rename it to googlenet_graph.pb and executed again, and it showed:
I tensorflow/core/common_runtime/local_device.cc:40] Local device intra op parallelism threads: 4
I tensorflow/core/common_runtime/direct_session.cc:60] Direct session inter op parallelism threads: 4
Segmentation fault: 11

then I don't know what I am supposed to try, please show me a way to solve it, thanks.
"
350,"CPU Version install successfull,but import tensorflow error","Python 2.7.3 (default, Jul 29 2015, 13:52:45) 
[GCC 3.4.5 20051201 (Red Hat 3.4.5-2)] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.

> > > import tensorflow as tf
> > > Traceback (most recent call last):
> > >   File ""<stdin>"", line 1, in <module>
> > >   File ""/home/users/caohao/.jumbo/lib/python2.7/site-packages/tensorflow/**init**.py"", line 4, in <module>
> > >     from tensorflow.python import *
> > >   File ""/home/users/caohao/.jumbo/lib/python2.7/site-packages/tensorflow/python/**init**.py"", line 22, in <module>
> > >     from tensorflow.python.client.client_lib import *
> > >   File ""/home/users/caohao/.jumbo/lib/python2.7/site-packages/tensorflow/python/client/client_lib.py"", line 35, in <module>
> > >     from tensorflow.python.client.session import InteractiveSession
> > >   File ""/home/users/caohao/.jumbo/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 11, in <module>
> > >     from tensorflow.python import pywrap_tensorflow as tf_session
> > >   File ""/home/users/caohao/.jumbo/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 28, in <module>
> > >     _pywrap_tensorflow = swig_import_helper()
> > >   File ""/home/users/caohao/.jumbo/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 24, in swig_import_helper
> > >     _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)
> > > ImportError: /home/users/caohao/.jumbo/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so: ELF file OS ABI invalid
"
349,"Building from source, gcc issues","Hi everyone,

I'm trying to build tensorflow from source but got stucked at the following:

```
root@ubuntu:/tensorflow# ../bazel/output/bazel build -c opt //tensorflow/tools/pip_package:build_pip_package
WARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.io/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.
INFO: Found 1 target...
INFO: From Compiling tensorflow/core/kernels/cwise_op_add.cc:
gcc: internal compiler error: Killed (program cc1plus)
Please submit a full bug report,
with preprocessed source if appropriate.
See <file:///usr/share/doc/gcc-4.8/README.Bugs> for instructions.
ERROR: /tensorflow/tensorflow/core/BUILD:210:1: C++ compilation of rule '//tensorflow/core:kernels' failed: gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections ... (remaining 72 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 4.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 126.561s, Critical Path: 123.83s
```

`gcc` should be fine:

```
root@ubuntu:/tensorflow# gcc -v
Using built-in specs.
COLLECT_GCC=gcc
COLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-linux-gnu/4.8/lto-wrapper
Target: x86_64-linux-gnu
Configured with: ../src/configure -v --with-pkgversion='Ubuntu 4.8.4-2ubuntu1~14.04' --with-bugurl=file:///usr/share/doc/gcc-4.8/README.Bugs --enable-languages=c,c++,java,go,d,fortran,objc,obj-c++ --prefix=/usr --program-suffix=-4.8 --enable-shared --enable-linker-build-id --libexecdir=/usr/lib --without-included-gettext --enable-threads=posix --with-gxx-include-dir=/usr/include/c++/4.8 --libdir=/usr/lib --enable-nls --with-sysroot=/ --enable-clocale=gnu --enable-libstdcxx-debug --enable-libstdcxx-time=yes --enable-gnu-unique-object --disable-libmudflap --enable-plugin --with-system-zlib --disable-browser-plugin --enable-java-awt=gtk --enable-gtk-cairo --with-java-home=/usr/lib/jvm/java-1.5.0-gcj-4.8-amd64/jre --enable-java-home --with-jvm-root-dir=/usr/lib/jvm/java-1.5.0-gcj-4.8-amd64 --with-jvm-jar-dir=/usr/lib/jvm-exports/java-1.5.0-gcj-4.8-amd64 --with-arch-directory=amd64 --with-ecj-jar=/usr/share/java/eclipse-ecj.jar --enable-objc-gc --enable-multiarch --disable-werror --with-arch-32=i686 --with-abi=m64 --with-multilib-list=m32,m64,mx32 --with-tune=generic --enable-checking=release --build=x86_64-linux-gnu --host=x86_64-linux-gnu --target=x86_64-linux-gnu
Thread model: posix
gcc version 4.8.4 (Ubuntu 4.8.4-2ubuntu1~14.04) 
```

Every time i execute `../bazel/output/bazel build -c opt //tensorflow/tools/pip_package:build_pip_package` i get the same:

```
WARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.io/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.
INFO: Found 1 target...
[810 / 839] Still waiting for 27 jobs to complete:
      Running (spawn):
        Compiling tensorflow/core/kernels/transpose_op.cc, 10 s
        Compiling tensorflow/core/kernels/cwise_op_add.cc, 10 s
        Compiling tensorflow/core/kernels/slice_op.cc, 10 s
        Compiling tensorflow/core/kernels/cwise_op_equal_to.cc, 10 s
      Scheduling:
        Compiling tensorflow/core/kernels/argmax_op.cc, 10 s
        Compiling tensorflow/core/kernels/cwise_op_sub.cc, 10 s
        Compiling tensorflow/core/kernels/reduction_ops_mean.cc, 10 s
        Compiling tensorflow/core/kernels/reduction_ops_prod.cc, 10 s
        Compiling tensorflow/core/kernels/matmul_op.cc, 10 s
        Compiling tensorflow/core/kernels/reverse_sequence_op.cc, 10 s
        Compiling tensorflow/core/kernels/segment_reduction_ops.cc, 10 s
        Compiling tensorflow/core/kernels/aggregate_ops.cc, 10 s
        Compiling tensorflow/core/kernels/cwise_op_mul.cc, 10 s
        ... 14 more jobs

```

Those 27 missing packages never seem to finish. Any advice here?
"
348,error: invalid command 'bdist_wheel',"ub1404@ub1404-A:~/github/tensorflow$ bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg
Wed Nov 25 02:32:35 EST 2015 : === Using tmpdir: /tmp/tmp.lVOy4pRiQ5
/tmp/tmp.lVOy4pRiQ5 ~/github/tensorflow
Wed Nov 25 02:32:35 EST 2015 : === Building wheel
usage: setup.py [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]
   or: setup.py --help [cmd1 cmd2 ...]
   or: setup.py --help-commands
   or: setup.py cmd --help

error: invalid command 'bdist_wheel'
"
347,"""constrastive"" in the document","In tensorflow/g3doc/tutorials/word2vec/index.md:

> practice we approximate the expectation by drawing \(k\) constrastive words
> from the noise distribution (i.e. we compute a

I think ""constrastive"" would be typo, ""contrastive"" is correct?
"
345,conv_grad_ops.cc:623:46: error: invalid use of 'auto',"I'm getting a compile error when trying to compile the `example_trainer` using gcc 4.8.1:

```
$ bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer  --verbose_failures 
____From Compiling tensorflow/core/kernels/conv_grad_ops.cc:
tensorflow/core/kernels/conv_grad_ops.cc: In instantiation of 'tensorflow::Conv2DCustomBackpropFilterOp<Device, T>::Compute(tensorflow::OpKernelContext*) [with Device = Eigen::ThreadPoolDevice; T = float]
::__lambda3':
tensorflow/core/kernels/conv_grad_ops.cc:621:22:   required from 'struct tensorflow::Conv2DCustomBackpropFilterOp<Device, T>::Compute(tensorflow::OpKernelContext*) [with Device = Eigen::ThreadPoolDevice; 
T = float]::__lambda3'
tensorflow/core/kernels/conv_grad_ops.cc:632:7:   required from 'void tensorflow::Conv2DCustomBackpropFilterOp<Device, T>::Compute(tensorflow::OpKernelContext*) [with Device = Eigen::ThreadPoolDevice; T =
 float]'
tensorflow/core/kernels/conv_grad_ops.cc:1265:1:   required from here
tensorflow/core/kernels/conv_grad_ops.cc:621:56: error: use of 'tensorflow::Conv2DCustomBackpropFilterOp<Device, T>::Compute(tensorflow::OpKernelContext*) [with Device = Eigen::ThreadPoolDevice; T = float]::__lambda3::__col_buffer_data' before deduction of 'auto'
                     &size_A](int64 start, int64 limit) {
                                                        ^
tensorflow/core/kernels/conv_grad_ops.cc:621:56: error: use of 'tensorflow::Conv2DCustomBackpropFilterOp<Device, T>::Compute(tensorflow::OpKernelContext*) [with Device = Eigen::ThreadPoolDevice; T = float]::__lambda3::__col_buffer_data' before deduction of 'auto'
tensorflow/core/kernels/conv_grad_ops.cc:621:56: error: use of 'tensorflow::Conv2DCustomBackpropFilterOp<Device, T>::Compute(tensorflow::OpKernelContext*) [with Device = Eigen::ThreadPoolDevice; T = float]::__lambda3::__input_data' before deduction of 'auto'
tensorflow/core/kernels/conv_grad_ops.cc:621:56: error: use of 'tensorflow::Conv2DCustomBackpropFilterOp<Device, T>::Compute(tensorflow::OpKernelContext*) [with Device = Eigen::ThreadPoolDevice; T = float]::__lambda3::__input_data' before deduction of 'auto'
tensorflow/core/kernels/conv_grad_ops.cc:623:46: error: use of 'input_data' before deduction of 'auto'
           auto input_data_shard = input_data + shard_id * input_offset;
                                              ^
tensorflow/core/kernels/conv_grad_ops.cc:623:46: error: invalid use of 'auto'
```
"
344,Dropout Appears to Lose Tensor Shape,"While training a model, I encountered a strange issue around dropout.  I can't yet rule out user error and haven't yet produced the minimum viable product, but I wanted to get this on the board before I forgot.

```
# With dropout...
        wc1 = tf.Variable(tf.random_normal([1, sample_vec_len, 1, 64]))
        bc1 = tf.Variable(tf.random_normal([64,]))
        conv1 = tf.nn.conv2d(inputs, wc1, strides=[1, 1, 1, 1], padding='SAME') + bc1
        act1 = tf.nn.relu(conv1)
        drop1 = tf.nn.dropout(act1, keep_prob=dropout_toggle)
        # TensorShape([Dimension(None), Dimension(1), Dimension(4620), Dimension(64)])

        wc2 = tf.Variable(tf.random_normal([1, char_sample_size, 64, 32]))
        bc2 = tf.Variable(tf.random_normal([32,]))
        conv2 = tf.nn.conv2d(drop1, wc2, strides=[1, 1, 1, 1], padding='SAME') + bc2
        act2 = tf.nn.relu(conv2)
        norm2 = tf.nn.lrn(act2, bitreader.get_sentence_vector_length(1), bias=1.0, alpha=0.001, beta=0.75)
        # TensorShape([Dimension(None), Dimension(1), Dimension(4620), Dimension(32)])

        # Conv -> FC
        dims = act2.get_shape()
        shape = [dims[0].value, dims[1].value, dims[2].value, dims[3].value] # dims[0].value -> None
        c_fc = tf.reshape(act2, [-1, shape[1]*shape[2]*shape[3]])
```

(venv)jcatrambone-osx:nlp jcatrambone$ python ./nlp_tensorflow.py ../wikipedia_utf8_filtered_20pageviews.csv.gz 1
Building model.
Traceback (most recent call last):
  File ""./nlp_tensorflow.py"", line 92, in <module>
    encoder, decoder, weights, biases = build_model(""ConvNLP"", x, keep_prob)
  File ""./nlp_tensorflow.py"", line 56, in build_model
    c_fc = tf.reshape(act2, [-1, shape[1]_shape[2]_shape[3]])
TypeError: unsupported operand type(s) for *: 'NoneType' and 'NoneType'

```
# Remove dropout...
        wc1 = tf.Variable(tf.random_normal([1, sample_vec_len, 1, 64]))
        bc1 = tf.Variable(tf.random_normal([64,]))
        conv1 = tf.nn.conv2d(inputs, wc1, strides=[1, 1, 1, 1], padding='SAME') + bc1
        act1 = tf.nn.relu(conv1)
        # TensorShape([Dimension(None), Dimension(1), Dimension(4620), Dimension(64)])

        wc2 = tf.Variable(tf.random_normal([1, char_sample_size, 64, 32]))
        bc2 = tf.Variable(tf.random_normal([32,]))
        conv2 = tf.nn.conv2d(act1, wc2, strides=[1, 1, 1, 1], padding='SAME') + bc2
        act2 = tf.nn.relu(conv2)
        norm2 = tf.nn.lrn(act2, bitreader.get_sentence_vector_length(1), bias=1.0, alpha=0.001, beta=0.75)
        # TensorShape([Dimension(None), Dimension(1), Dimension(4620), Dimension(32)])

        # Conv -> FC
        dims = act2.get_shape()
        shape = [dims[0].value, dims[1].value, dims[2].value, dims[3].value] # dims[0].value -> None
        c_fc = tf.reshape(act2, [-1, shape[1]*shape[2]*shape[3]])
```

(venv)jcatrambone-osx:nlp jcatrambone$ python ./nlp_tensorflow.py ../wikipedia_utf8_filtered_20pageviews.csv.gz 1
Building model.
Defining loss functions and optimizer.
Gathering variables.
Beginning training session.
can't determine number of CPU cores: assuming 4
I tensorflow/core/common_runtime/local_device.cc:25] Local device intra op parallelism threads: 4
can't determine number of CPU cores: assuming 4
I tensorflow/core/common_runtime/local_session.cc:45] Local session inter op parallelism threads: 4
Initializing variables.
Session, variables, and generator initialized.  Training.

Runs fine...
"
343,failed installing using virtualenv,"(tensorflow)itay@ubuntu:~/tensorflow$ pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.5.0-cp27-none-linux_x86_64.whl
Downloading/unpacking https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.5.0-cp27-none-linux_x86_64.whl
  Downloading tensorflow-0.5.0-cp27-none-linux_x86_64.whl (10.9Mb): 10.9Mb downloaded
  Running setup.py egg_info for package from https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.5.0-cp27-none-linux_x86_64.whl
    Traceback (most recent call last):
      File ""<string>"", line 14, in <module>
    IOError: [Errno 2] No such file or directory: '/tmp/pip-2LuRsH-build/setup.py'
    Complete output from command python setup.py egg_info:
    Traceback (most recent call last):

  File ""<string>"", line 14, in <module>

IOError: [Errno 2] No such file or directory: '/tmp/pip-2LuRsH-build/setup.py'

---

Command python setup.py egg_info failed with error code 1 in /tmp/pip-2LuRsH-build

any help?
"
342,Feed sparse array for placeholder ?,"X = tf.placeholder(""float"", [None, num_features]) # create symbolic variables
Y = tf.placeholder(""float"", [None, 1])

predicts = sess.run(predict_op, feed_dict={X: teX, Y: teY})

What if I'am facing text classification problem, where every instance is extremely sparse, 
like using scipy.sparse.csr_matrix or somethint else, what's the best to do this ?
"
341,Forking TensorFlow after You Already Pip Installed,"Hey TF, love your code.

I recently forked and cloned TF because I wanted to add some new features to it. 

However, previously I pip installed it, so my question is:

How do I change it so that when I call in `import TensorFlow`, it comes from my specified directory (cloned dir) and not the one in `dist-packages`? 

Do I need to re-install TensorFlow? Or can I just simply use the scripts found in my TensorFlow clone?

Thanks!
"
339,segmentation fault during data loading of machine translation example on amazon ec2,"Hello,

I am running tensorflow on amazon ec2 with AMI id ami-cf5028a5 constructed as follows:
https://gist.github.com/erikbern/78ba519b97b440e10640. The instance is a g2.2xlarge.

The only modification to the AMI was to move /models/rnn/translate from the ~/tensorflow dir, to the installation directory (/usr/local/lib/python2.7/dist-packages/tensorflow), so that the libs in translate.py are properly imported.

The command I run is:

```
python tensorflow/tensorflow/models/rnn/translate/translate.py --data_dir /mnt/translate/data --train_dir /mnt/translate/train --size=256 --num_layers=2 --steps_per_checkpoint=50
```

Output looks like this:

```
I tensorflow/core/common_runtime/gpu/gpu_init.cc:88] Found device 0 with properties:
name: GRID K520
major: 3 minor: 0 memoryClockRate (GHz) 0.797
pciBusID 0000:00:03.0
Total memory: 4.00GiB
Free memory: 3.95GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:112] DMA: 0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:122] 0:   Y
I tensorflow/core/common_runtime/gpu/gpu_device.cc:644] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GRID K520, pci bus id: 0000:00:03.0)
I tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:47] Setting region size to 3927400448
I tensorflow/core/common_runtime/direct_session.cc:45] Direct session inter op parallelism threads: 8
Creating 2 layers of 256 units.
Created model with fresh parameters.
Reading development and training data (limit: 0).
  reading data line 100000
  reading data line 200000
  reading data line 300000
[...]
  reading data line 15000000
Segmentation fault (core dumped)
```

When I set --max_train_data_size 100000 everything is okay.
"
338,Compressed input?,"Is there any support for reading/writing compressed input files, e.g. with gzip? I would like to use the ""standard"" file format, but the uncompressed TFRecords files I am generating are huge for my datasets.
"
336,Cannot make tensorflow to  use a local gcc installation?,"Hi,
I am bound to an old installation on a machine. I had to install a local gcc 4.8.1 and make my way through a bazel compilation (thanks to the community for their help :) ). However, now I am unable to compile tensorflow. This is the error I get:

```
gcc: unrecognized option '-no-canonical-prefixes'
cc1plus: error: unrecognized command line option ""-std=c++11""
cc1plus: warning: unrecognized command line option ""-Wno-free-nonheap-object""
ERROR: $HOME/tensorflow/google/protobuf/BUILD:29:1: C++ compilation of rule '//google/protobuf:protobuf_lite' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object ... : com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
```

I guess it is not getting the correct gcc, since if I run : 

```
/path/to/local/gcc.4.8.1/bin/gcc -std=c++11  example.cc 
```

All is ok, but if I run 

```
/usr/bin/gcc  -std=c++11 example.cc
```

I get the same error""

```
cc1plus: error: unrecognized command line option ""-std=c++11""
```

If I add the `--verbose_failures` option, I get this additional information:

```
(cd $HOME/.cache/bazel/_bazel_$USER/2d4cdeea5be55811d371414ca0f7bd15/tensorflow && \
  exec env - \
    PATH=$HOME/jdk1.8.0_65/bin/:$HOME/local.gcc-4.8.1/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:$HOME/bin \
  third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++11' -iquote . -iquote bazel-out/local_linux-opt/genfiles -iquote external/bazel_tools -iquote bazel-out/local_linux-opt/genfiles/external/bazel_tools -isystem google/protobuf/src -isystem bazel-out/local_linux-opt/genfiles/google/protobuf/src -isystem external/bazel_tools/tools/cpp/gcc3 -DHAVE_PTHREAD -Wall -Wwrite-strings -Woverloaded-virtual -Wno-sign-compare '-Wno-error=unused-function' -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' '-frandom-seed=bazel-out/local_linux-opt/bin/google/protobuf/_objs/protobuf_lite/google/protobuf/src/google/protobuf/wire_format_lite.o' -MD -MF bazel-out/local_linux-opt/bin/google/protobuf/_objs/protobuf_lite/google/protobuf/src/google/protobuf/wire_format_lite.d -c google/protobuf/src/google/protobuf/wire_format_lite.cc -o bazel-out/local_linux-opt/bin/google/protobuf/_objs/protobuf_lite/google/protobuf/src/google/protobuf/wire_format_lite.o)
```

 How can I make it use the correct gcc ?

Thanks,
"
335,Extend image summary so it allows displaying a label next to an image,"It would be really neat if the tensorboard could additionally show the predicted and/or given label for an image in the 'images' tab. 
"
334,Error: Executing cifar10_train.py on Ubuntu with Cuda,"I just went through the [cifar10 tensorflow tutorial](http://www.tensorflow.org/tutorials/deep_cnn/index.md) on my mac. This tutorial aroused my enthusiasm for NN so I set a Ubuntu Server up in order to train in large scale.

However I cant run the cifar10_train.py on my server. I always run into this error:

Path of the tensorflow source code:

```
~/python/tensorflow/tensorflow/tensorflow/
```

Path of the tensorflow virtualenv installation:

```
~/tensorflow/
```

**Cmd:**

```
source ~/tensorflow/bin/activate #activate virtualenv
python/tensorflow/tensorflow/tensorflow/models/image/cifar10/cifar10_train.py #the raw source code of tensorflow is in ~/python/tensorflow/tensorflow/tensorflow
```

**Error:**

```
Traceback (most recent call last):
  File ""python/tensorflow/tensorflow/tensorflow/models/image/cifar10/cifar10_train.py"", line 28, in <module>
    import tensorflow.python.platform
  File ""/home/it13095/tensorflow/local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 4, in <module>
    from tensorflow.python import *
  File ""/home/it13095/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 22, in <module>
    from tensorflow.python.client.client_lib import *
  File ""/home/it13095/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/client_lib.py"", line 35, in <module>
    from tensorflow.python.client.session import InteractiveSession
  File ""/home/it13095/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 11, in <module>
    from tensorflow.python import pywrap_tensorflow as tf_session
  File ""/home/it13095/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 28, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""/home/it13095/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)
```

I installed tensorflow just like on my mac in a virtualenv and activated it correctly before executing the script. 
As by many in other threads suggested I upgraded already six, however I still got the same error.

**Update 1**
After going the issue threads on github/tensorflow through I noticed this is a bug involving cuda. I added these to my path environment:

```
export LD_LIBRARY_PATH=""$LD_LIBRARY_PATH:/usr/local/cuda/lib64""
export CUDA_HOME=/usr/local/cuda
```

I still run into a error, however it has shortened down to the following:

```
Traceback (most recent call last):
File ""cifar10_train.py"", line 28, in <module>
import tensorflow.python.platform
ImportError: No module named tensorflow.python.platform
```

**Update 2** As someone suggested, I install protobuf via pip. The Error has once again change for some weird reason:

```
Traceback (most recent call last):
  File ""cifar10_train.py"", line 28, in <module>
    import tensorflow.python.platform
  File ""/home/it13095/tensorflow/local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 4, in <module>
    from tensorflow.python import *
  File ""/home/it13095/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 13, in <module>
    from tensorflow.core.framework.graph_pb2 import *
  File ""/home/it13095/tensorflow/local/lib/python2.7/site-packages/tensorflow/core/framework/graph_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2
  File ""/home/it13095/tensorflow/local/lib/python2.7/site-packages/tensorflow/core/framework/attr_value_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2
  File ""/home/it13095/tensorflow/local/lib/python2.7/site-packages/tensorflow/core/framework/tensor_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import tensor_shape_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2
  File ""/home/it13095/tensorflow/local/lib/python2.7/site-packages/tensorflow/core/framework/tensor_shape_pb2.py"", line 22, in <module>
    serialized_pb=_b('\n,tensorflow/core/framework/tensor_shape.proto\x12\ntensorflow\""d\n\x10TensorShapeProto\x12-\n\x03\x64im\x18\x02 \x03(\x0b\x32 .tensorflow.TensorShapeProto.Dim\x1a!\n\x03\x44im\x12\x0c\n\x04size\x18\x01 \x01(\x03\x12\x0c\n\x04name\x18\x02 \x01(\tb\x06proto3')
TypeError: __init__() got an unexpected keyword argument 'syntax'
```
"
333,Issue with _create_slots: var_list[0].device empty,"I have problem running 

```
loss = crossentropy(activation, y)
train_loss = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss)
```

with crossentropy defined in another file as a simple function that return 

```
def crossentropy(activation, y)
    return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(activation, y))
```

I got this error:

```
Traceback (most recent call last):
  File ""test/test.py"", line 66, in <module>
    train_loss = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss) # Adam Optimizer
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py"", line 167, in minimize
    name=name)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py"", line 245, in apply_gradients
    self._create_slots([v for g, v in grads_and_vars if g is not None])
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/training/adam.py"", line 87, in _create_slots
    with ops.device(var_list[0].device):
IndexError: list index out of range
```

But this is working: (only call function from another file is not)

```
loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(activation, y))
train_loss  = self.optimizer(learning_rate=0.01).minimize(loss)
```

It seemed I can't define that expression outside the main thread, I also tried using same graph as default graph, but it doesn't seem to work either. I think this is an issue with graph building.
If you ever ran into this problem, thanks for helping!
"
332,Link error using c api: undefined reference to symbol 'powf@@GLIBC_2.2.5',"http://theyoungcoder.com/loading-a-tensorflow-graph-with-the-c-api/
I followed this acticle. 

1   cc_binary(
2   name = ""loader"",
3   srcs = [""loader.cc""],
4   deps = [
5   ""//tensorflow/core:tensorflow"",
6   ]
7   )
Here’s the final directory structure:
• tensorflow/tensorflow/loader/
• tensorflow/tensorflow/loader/loader.cc
• tensorflow/tensorflow/loader/BUILD
Compile & Run
• From inside the project folder call bazel build :loader.
• From the repository root, go into bazel-bin/tensorflow/loader.
• Copy the graph protobuf to models/train.pb.

Then run ./loader and check the output!

But when building I got link error
Slow read: a 551318010-byte read from /home/users/chenghuige/.cache/bazel/_bazel_chenghuige/56e262ed5e70da1d7ac42e55562c6970/tensorflow/bazel-out/local_linux-fastbuild/bin/tensorflow/core/libkernels.lo took 6143ms.
INFO: From Linking tensorflow/loader/loader:
/usr/bin/ld: bazel-out/local_linux-fastbuild/bin/tensorflow/core/libkernels.lo(cwise_op_pow.pic.o): undefined reference to symbol 'powf@@GLIBC_2.2.5'
/usr/bin/ld: note: 'powf@@GLIBC_2.2.5' is defined in DSO /top/lib/libm.so.6 so try adding it to the linker command line
/top/lib/libm.so.6: could not read symbols: Invalid operation
collect2: error: ld returned 1 exit status
ERROR: /home/users/chenghuige/other/tensorflow/tensorflow/loader/BUILD:1:1: Linking of rule '//tensorflow/loader:loader' failed: gcc failed: error executing command /usr/bin/gcc -o bazel-out/local_linux-fastbuild/bin/tensorflow/loader/loader bazel-out/local_linux-fastbuild/bin/tensorflow/loader/_objs/loader/tensorflow/loader/loader.pic.o -Wl,-whole-archive ... (remaining 45 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
Target //tensorflow/loader:loader failed to build
Use --verbose_failures to see the command lines of failed build steps.
"
331,1:1 between internal and external commits,"Currently, it seems that the internal commits to TensorFlow are generally exported to the GitHub repository in batches.

We have some infrastructure set up for bazelbuild/bazel for both importing external patches into the internal repository and pushing internal commits to the GitHub repository, scrubbing any sensitive information from commit messages. Perhaps we can sync offline to see if we can use the tools for TensorFlow and then rewrite the Git history, especially given #294.

Related: #26
"
330,Link to next tutorial at the bottom of the first tutorial leads to the home page,"On: http://www.tensorflow.org/tutorials/mnist/beginners/index.md
The last paragraph:
What matters is that we learned from this model. Still, if you're feeling a bit down about these results, check out the next tutorial where we do a lot better, and learn how to build more sophisticated models using TensorFlow!

'The next tutorial' links to http://www.tensorflow.org/tutorials/index.md which ends up showing me the home page.
"
329,Is it possible to plot two scalar summary in one plot?,"Hi, 

I have spent some time writing scripts to do stat in Caffe and this let me know Tensorboard is so amazing! It is actually one of the major reasons that makes me switch to tensorflow quickly. 

I just wonder could an option be added to plot more than two scalars in the same plot? More specifically. it could allow:
1. training loss and test loss being plotted together
2. regularization loss and top level loss to be plotted together.
3. maybe adding accuracy on the right vertical axis

Just name a few. This would help a lot.
"
328,initializing seq2seq embedding with pretrained w2v,"Hi, is there a straightforward way to initialize seq2seq embedding with pretrained w2v?

the embedding variable is in the embedding_tied_seq2seq (the model I am using). is there anyway to access this variable from translate.py and call .assign() to assign it after random initialisation with all other variables?? is there a global variable name I could call for this embedding?
"
327,How to find <Python.h> ? compile with bazel will fail not find Python.h,"INFO: Found 1 target...
INFO: From Compiling tensorflow/python/client/tf_session_helper.cc:
In file included from tensorflow/python/client/tf_session_helper.cc:16:0:
./tensorflow/python/client/tf_session_helper.h:19:20: fatal error: Python.h: No such file or directory
 #include <Python.h>

Acutally I have Python.h in   /SomePath/python2.7/
But how to tell bazel ? I tried
export CPLUS_INCLUDE_PATH= /SomePath/python2.7/
Still not work, any suggestions ?
"
325,Installation exception in EI Capitan,"Hi,
I am getting this errors after runing 
""pip install https://storage.googleapis.com/tensorflow/mac/tensorflow-0.5.0-py2-none-any.whl""
I am using OSX:10.11.1. Is it a permission problem? should I run sudo?
Thanks in advance!

Exception:
Traceback (most recent call last):
  File ""/Library/Python/2.7/site-packages/pip-1.5.4-py2.7.egg/pip/basecommand.py"", line 122, in main
    status = self.run(options, args)
  File ""/Library/Python/2.7/site-packages/pip-1.5.4-py2.7.egg/pip/commands/install.py"", line 283, in run
    requirement_set.install(install_options, global_options, root=options.root_path)
  File ""/Library/Python/2.7/site-packages/pip-1.5.4-py2.7.egg/pip/req.py"", line 1435, in install
    requirement.install(install_options, global_options, _args, *_kwargs)
  File ""/Library/Python/2.7/site-packages/pip-1.5.4-py2.7.egg/pip/req.py"", line 671, in install
    self.move_wheel_files(self.source_dir, root=root)
  File ""/Library/Python/2.7/site-packages/pip-1.5.4-py2.7.egg/pip/req.py"", line 901, in move_wheel_files
    pycompile=self.pycompile,
  File ""/Library/Python/2.7/site-packages/pip-1.5.4-py2.7.egg/pip/wheel.py"", line 207, in move_wheel_files
    clobber(source, lib_dir, True)
  File ""/Library/Python/2.7/site-packages/pip-1.5.4-py2.7.egg/pip/wheel.py"", line 194, in clobber
    os.makedirs(destsubdir)
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/os.py"", line 157, in makedirs
    mkdir(name, mode)
OSError: [Errno 13] Permission denied: '/Library/Python/2.7/site-packages/external'

Storing debug log for failure in /var/folders/ky/4cxqzftd7q1844xgkvvb_4dc0000gn/T/tmpcQCpeO
"
324,TensorBoard Documentation - Confusing and Incorrect in places. (Need End to End Example),"It would be nice to have a complete, end-to-end working example using TensorBoard.  In addition, some of the documentation appears to be incorrect.

Possible Incorrect Documentation:
http://tensorflow.org/how_tos/summaries_and_tensorboard/index.md

<img width=""731"" alt=""screenshot 2015-11-22 10 42 18"" src=""https://cloud.githubusercontent.com/assets/755710/11324647/bc5560d8-9105-11e5-8293-ddd36cf7c946.png"">

A concise, completely coded example may help. Note, more detail is shown here, but it's still have hard to grasp the full picture.  A complete coded example may help.

``` python

...
sess.run(init)

# Build the summary operation based on the TF collection of Summaries.
tf.train.write_graph(sess.graph_def, './tenIrisSave/logsd','graph.pbtxt')

tf.scalar_summary(""Accuracy:"", tf_accuracy)
tf.histogram_summary('weights', tf_weight)
tf.histogram_summary('bias', tf_bias)
tf.histogram_summary('softmax', tf_softmax)
tf.histogram_summary('accuracy', tf_accuracy)


summary_op = tf.merge_all_summaries()
summary_writer = tf.train.SummaryWriter('./tenIrisSave/logs',sess.graph_def)

# This will not work. You need the full path.
# tensorboard --logdir=./tenIrisSave/   # BAD!
# tensorboard --logdir=$(pwd)/tenIrisSave/  # Good!
...
for i in range(100):
   ...
    summary_str = sess.run(summary_op,feed_dict={tf_in: x_test, tf_softmax_correct: y_test_onehot})
    summary_writer.add_summary(summary_str, i)


```

The complete example can be seen here:
https://gist.github.com/mchirico/bcc376fb336b73f24b29

Agreed. The example needs to be cleaned up. The point is to give the user a complete working example that can be run and verified.
"
323,Tensorflow crashed when using AdamOptimizer,"I tried the cnn in the tutorial for MNIST data, but initialize the parameters with stddev=1 (instead of stddev=0.1).

Error message:
I tensorflow/core/common_runtime/local_device.cc:25] Local device intra op parallelism threads: 4
I tensorflow/core/common_runtime/local_session.cc:45] Local session inter op parallelism threads: 4
0 0.098
W tensorflow/core/common_runtime/executor.cc:1027] 0x4472710 Compute status: Invalid argument: ReluGrad input is not finite. : Tensor had NaN values
     [[Node: gradients/Relu_grad/Relu/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""ReluGrad input is not finite."", _device=""/job:localhost/replica:0/task:0/cpu:0""](add)]]
W tensorflow/core/common_runtime/executor.cc:1027] 0x4472710 Compute status: Invalid argument: ReluGrad input is not finite. : Tensor had NaN values
     [[Node: gradients/Relu_1_grad/Relu_1/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""ReluGrad input is not finite."", _device=""/job:localhost/replica:0/task:0/cpu:0""](add_1)]]
W tensorflow/core/common_runtime/executor.cc:1027] 0x4472710 Compute status: Invalid argument: ReluGrad input is not finite. : Tensor had NaN values
     [[Node: gradients/Relu_2_grad/Relu_2/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""ReluGrad input is not finite."", _device=""/job:localhost/replica:0/task:0/cpu:0""](add_2)]]
Traceback (most recent call last):
  File ""2_cnn.py"", line 67, in <module>
    session.run(train_step, feed_dict={X: x, Y: y, keep_prob: 0.5})
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 345, in run
    results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 419, in _do_run
    e.code)
tensorflow.python.framework.errors.InvalidArgumentError: ReluGrad input is not finite. : Tensor had NaN values
     [[Node: gradients/Relu_grad/Relu/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""ReluGrad input is not finite."", _device=""/job:localhost/replica:0/task:0/cpu:0""](add)]]
Caused by op u'gradients/Relu_grad/Relu/CheckNumerics', defined at:
  File ""2_cnn.py"", line 55, in <module>
    train_step = tf.train.AdamOptimizer().minimize(loss)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py"", line 165, in minimize
    gate_gradients=gate_gradients)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py"", line 205, in compute_gradients
    loss, var_list, gate_gradients=(gate_gradients == Optimizer.GATE_OP))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients.py"", line 414, in gradients
    in_grads = _AsList(grad_fn(op_wrapper, *out_grads))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_grad.py"", line 107, in _ReluGrad
    t = _VerifyTensor(op.inputs[0], op.name, ""ReluGrad input is not finite."")
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_grad.py"", line 100, in _VerifyTensor
    verify_input = array_ops.check_numerics(t, message=msg)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py"", line 48, in check_numerics
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py"", line 633, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1710, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 988, in __init__
    self._traceback = _extract_stack()

...which was originally created as op u'Relu', defined at:
  File ""2_cnn.py"", line 32, in <module>
    h_conv1 = tf.nn.relu(conv2d(X1, w_conv1) + b_conv1)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py"", line 506, in relu
    return _op_def_lib.apply_op(""Relu"", features=features, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py"", line 633, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1710, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 988, in __init__
    self._traceback = _extract_stack()
"
322,Allow adding and deleting graph nodes and edges in Tensorboard,"Generating the graph from Python is not an expensive process.  It would greatly lower the barrier to entry if new users & data scientists who are more comfortable with GUIs could modify graph parameters directly from Tensorboard.

If I understand correctly (per a short tutorial from @rsepassi) you currently cant delete nodes from the graph without regenerating it, however regenerating the graph takes seconds, so it would be nice to allow creation of nodes and edges via the GUI (like Cafe).

I know this is a really high-level feature request, and probably requires a fair amount of work.  Feel free to close it if this would be better discussed on a mailing list instead of Github Issues.
"
321,Don't require absolute path when specifying tensorboard logs dir,"When running tensorboard on Mac OS X currently, you have to specify the absolute directory to the logs path in order to get it to run.

``` bash
tensorboard --logdir /Users/myusername/Code/tensor-play/tf-play/linear_regression/logs/events
```

It should accept relative paths (like most unix commands) for convenience.

``` bash
tensorboard --logdir logs/events
```
"
320,__ldg intrinsic unavailable on compute capability <3.2,"I'm not sure if supporting compute 3.0 capability will ever be a priority for the project, it's mainly useful for people who want to train small convnets on AWS g2.2x and g2.8x boxes as they're learning the framework.

A very recent commit 9c3043ff added the read-only data cache load function intrinsic __ldg to two operation defs: conv_ops_gpu_3.cu.cc and bias_op_gpu.cu.cc

All that's needed to maintain 3.0 support is to pass through __ldg(x) as a pointer -->  *x (I've confirmed this compiles and runs fine on the AWS GPU instances)  One could do this properly in theory with e.g. a generic wrapper:  (this is way too simplistic I'm sure...)

```
template<typename T>
__device__ __forceinline__ T ldg(const T* ptr) {
#if __CUDA_ARCH__ >= 320
    return __ldg(ptr);
#else
    return *ptr;
#endif
}
```

Again, it's mainly an issue if you want to keep the unsupported TF_UNOFFICIAL_SETTING=1 option working for people who happen to be working with slightly older GPUs.  (BTW thanks for all the amazing work!)
"
319,"Argmax, fetching top 5 probabilities","I'm having an issue with computing the accuracy of my model. I want to see if the top 5 predictions contains the actual label when comparing against the test set.

```
correct_prediction = tf.equal(tf.argmax(activation, 1), tf.argmax(y, 1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, ""float""))
print (""ACCURACY IS:"")
print sess.run(accuracy, feed_dict={x: data.test_set.inputs(), y: data.test_set.targets()})
```

From what I've read in the documentation TensorFlow doesn't seem to have something like fetching the top 5 from `activation` and seeing if one of the items is contained in `argmax(y,1)`

Something like this would be nice:

```
correct_prediction = tf.contains(tf.argmax(activation, dim, N_VALUES_TO_FETCH), tf.argmax(y, dim)
```

Can anyone help me with the problem I am facing? Thank you.
"
318,TensorFlow with Cuda 7.5 on Ubuntu 15.4?,"Hi,

I have not been able to install GPU TensorFlow on my Ubuntu 15.04 workstation because it seems to require Cuda 7.0, while I am running Cuda 7.5. As far as I can tell there are no Cuda 7.0 installs available for Ubuntu 15.04. Are there any patches/upgrades that will make it possible for me to use TensorFlow on my system? Or do I right now have to downgrade my Ubuntu in order to be able to work with it?

Thanks,

Bojan
"
316,Recursively copying elements from one graph to another,"One nifty feature to have in the codebase would be allowing recursive copying of Operation/Tensor/Variable instances from one graph to another. By recursive, I mean that copying the 'top' node (say the trainer for a basic NN) would automatically copy all the required Ops and tensors in the dataflow graph.
This could allow users to easily port common components of different frameworks from an 'origin' graph to a 'target' graph. To avoid naming conflicts, we could add the copied elements under a common namespace in the target graph.

I tried writing up some code for it, and since the project doesn't accept pull request as of now, wrote up a blog post about it. I would like the community's feed back on possible issues or applications. Thanks!

Heres a link to the post: https://codesachin.wordpress.com/2015/11/20/recursively-copying-elements-from-one-graph-to-another-in-tensorflow/
"
315,Use CFFI for interfacing C functions.,"[CFFI](https://cffi.readthedocs.org/en/latest/)  is a big step towards standard practices for making and distributing Python packages with C extension modules.

With CFFI the maintenance is much easier, and the code is still fast.
There are lot of benefits:
- Abstract the Python version (CPython2, CPython3, PyPy).
- Better control over when and why the C compilation occurs, and more standard ways to write distutils- or setuptools-based setup.py files.
- Keep all the Python-related logic in Python so that you don’t need to write much C code.

I'm really looking forward to use [PyPy](http://pypy.org/) with tensorflow.
"
313,Allow learning rates of specific variables to be scaled,"When repurposing a network, it can be useful to set layer-wise learning rates so that the final layer (which has random weights) does most of the learning initially. A useful pattern for applying learning rate scaling would be tf.stop_gradient(input, name=None), which can be seen as effectively scaling the learning rate by a factor of zero (obviously it also stops computation).
"
312,Relax the requirements for saver checkpoints,"I'm working on testing a few modifications to an existing network including attempting to use it as a teacher in a student/teacher network and swapping its optimizer but I get the following error:

```
Traceback (most recent call last):
  File ""knit_net_train_tf.py"", line 40, in <module>
    saver.restore(sesh, CHECKPOINT_FILE)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 869, in restore
    sess.run([self._restore_op_name], {self._filename_tensor_name: save_path})
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 401, in run
    results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 477, in _do_run
    e.code)
tensorflow.python.framework.errors.NotFoundError: Tensor name ""conv1/biases/Adagrad"" not found in checkpoint files knitnet.0.ckpt
         [[Node: save/restore_slice_2 = RestoreSlice[dt=DT_FLOAT, preferred_shard=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""](_recv_save/Const_0, save/restore_slice_2/tensor_name, save/restore_slice_2/shape_and_slice)]]
```

It appears that the saver requires that every variable that exists in the current graph also be present in the checkpoint and that every variable that that exists in the checkpoint also be in the current graph. I can work around this by making major modifications to the way that my network is constructed but I would be nice to have a feature that says ""don't error out if you don't find this variable, its ok"". Alternatively it appears that I can specify which variables I want to restore, which could also solve the problem, but I have a lot of variable that I haven't explicitly tracked, many of which are created by the optimizer. It would make this feature a lot more useful if there were a function that did ""return all variables that this op depends on"", which I could call on the training variable or the prediction variable and only save those tensors.
"
311,Tensorflow not assigning any tasks to GPU in cifar10 example,"I'm running the `cifar10_multi_gpu_train.py` script with the device placement logging turned on, and I see that all of the operations are being placed on the CPU. When I run it, it outputs:

```
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
I tensorflow/core/common_runtime/local_device.cc:25] Local device intra op parallelism threads: 8
I tensorflow/core/common_runtime/direct_session.cc:45] Direct session inter op parallelism threads: 8
Device mapping: no known devices.
I tensorflow/core/common_runtime/direct_session.cc:111] Device mapping:

softmax_linear/biases/ExponentialMovingAverage: /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:289] softmax_linear/biases/ExponentialMovingAverage: /job:localhost/replica:0/task:0/cpu:0
.....
.....
```

I would imagine that the line `Device mapping: no known devices.` is supposed to list the devices associated with the current Session, but why does it not have any devices? The script calls 
`tf.device('/gpu:0')`.

My GPU is Nvidia GeForce GTX 970.
"
310,Fast python protocol buffers?,"This might be a better question for the protobuf team, but is there any way to get [fast python protocol buffers](https://developers.google.com/protocol-buffers/docs/reference/python-generated#cpp_impl) with TensorFlow? I have tried `bazel build --copt=-DPYTHON_PROTO2_CPP_IMPL_V2` but running with `PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION='cpp'` gives the following error:

``` python
Traceback (most recent call last):
  File ""/home/kearnes/git/tensorflow/bazel-bin/deaps/test.runfiles/deaps/test.py"", line 21, in <module>
    import tensorflow as tf
  File ""/home/kearnes/git/tensorflow/bazel-bin/deaps/test.runfiles/tensorflow/__init__.py"", line 8, in <module>
    from tensorflow.python import *
  File ""/home/kearnes/git/tensorflow/bazel-bin/deaps/test.runfiles/tensorflow/python/__init__.py"", line 24, in <module>
    raise ImportError(msg)
ImportError: Error importing tensorflow: you should not try to import
  tensorflow from its source directory; please exit the tensorflow source tree,
  and relaunch your python interpreter from there.
  Original ImportError: cannot import name _message
```
"
309,time series example,"is there a multivariate numerical time series example in tensorflow.

Many thanks,
Andrew
"
308,IOError: [Errno socket error] [Errno 60] Operation timed out,"I used tensorflow with Mac. But when running the code convolutional.py, there is some unexpected error.

(cinos)➜  ~  python anaconda/envs/cinos/lib/python2.7/site-packages/tensorflow/models/image/mnist/convolutional.py

Traceback (most recent call last):
  File ""anaconda/envs/cinos/lib/python2.7/site-packages/tensorflow/models/image/mnist/convolutional.py"", line 270, in <module>
    tf.app.run()
  File ""/Users/kk/anaconda/envs/cinos/lib/python2.7/site-packages/tensorflow/python/platform/default/_app.py"", line 11, in run
    sys.exit(main(sys.argv))
  File ""anaconda/envs/cinos/lib/python2.7/site-packages/tensorflow/models/image/mnist/convolutional.py"", line 103, in main
    test_data_filename = maybe_download('t10k-images-idx3-ubyte.gz')
  File ""anaconda/envs/cinos/lib/python2.7/site-packages/tensorflow/models/image/mnist/convolutional.py"", line 39, in maybe_download
    filepath, _ = urllib.urlretrieve(SOURCE_URL + filename, filepath)
  File ""/Users/kk/anaconda/envs/cinos/lib/python2.7/urllib.py"", line 98, in urlretrieve
    return opener.retrieve(url, filename, reporthook, data)
  File ""/Users/kk/anaconda/envs/cinos/lib/python2.7/urllib.py"", line 245, in retrieve
    fp = self.open(url, data)
  File ""/Users/kk/anaconda/envs/cinos/lib/python2.7/urllib.py"", line 213, in open
    return getattr(self, name)(url)
  File ""/Users/kk/anaconda/envs/cinos/lib/python2.7/urllib.py"", line 351, in open_http
    errcode, errmsg, headers = h.getreply()
  File ""/Users/kk/anaconda/envs/cinos/lib/python2.7/httplib.py"", line 1207, in getreply
    response = self._conn.getresponse()
  File ""/Users/kk/anaconda/envs/cinos/lib/python2.7/httplib.py"", line 1132, in getresponse
    response.begin()
  File ""/Users/kk/anaconda/envs/cinos/lib/python2.7/httplib.py"", line 453, in begin
    version, status, reason = self._read_status()
  File ""/Users/kk/anaconda/envs/cinos/lib/python2.7/httplib.py"", line 409, in _read_status
    line = self.fp.readline(_MAXLINE + 1)
  File ""/Users/kk/anaconda/envs/cinos/lib/python2.7/socket.py"", line 480, in readline
    data = self._sock.recv(self._rbufsize)
IOError: [Errno socket error] [Errno 60] Operation timed out
"
307,Setting large batch_size in logistic regression method will result output nan,"import tensorflow as tf
import numpy as np
import melt_dataset
import sys
from sklearn.metrics import roc_auc_score

def init_weights(shape):
    return tf.Variable(tf.random_normal(shape, stddev=0.01))

def model(X, w):
    return 1.0/(1.0 + tf.exp(-(tf.matmul(X, w))))
# ./logistic_regression.py corpus/feature.normed.rand.12000.0_2.txt corpus/feature.normed.rand.12000.1_2.txt
# notice if setting batch_size too big here 500 will result in learning turn output nan...  why? @TODO

batch_size = 100
learning_rate = 0.01
num_iters = 100

argv = sys.argv 
trainset = argv[1]
testset = argv[2]

trX, trY = melt_dataset.load_dense_data(trainset)
print ""finish loading train set "",trainset
teX, teY = melt_dataset.load_dense_data(testset)
print ""finish loading test set "", testset

num_features = trX[0].shape[0]
print 'num_features: ',num_features 
print 'trainSet size: ', len(trX)
print 'testSet size: ', len(teX)
print 'batch_size:', batch_size, ' learning_rate:', learning_rate, ' num_iters:', num_iters

X = tf.placeholder(""float"", [None, num_features]) # create symbolic variables
Y = tf.placeholder(""float"", [None, 1])

w = init_weights([num_features, 1]) # like in linear regression, we need a shared variable weight matrix for logistic regression

py_x = model(X, w)

cost = -tf.reduce_sum(Y*tf.log(py_x) + (1 - Y) \* tf.log(1 - py_x))
train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost) # construct optimizer

predict_op = py_x

sess = tf.Session()
init = tf.initialize_all_variables()
sess.run(init)

for i in range(num_iters):
    predicts, cost_ = sess.run([predict_op, cost], feed_dict={X: teX, Y: teY})
    print i, 'auc:', roc_auc_score(teY, predicts), 'cost:', cost_
    for start, end in zip(range(0, len(trX), batch_size), range(batch_size, len(trX), batch_size)):
            sess.run(train_op, feed_dict={X: trX[start:end], Y: trY[start:end]})

predicts, cost_ = sess.run([predict_op, cost], feed_dict={X: teX, Y: teY})
print 'final ', 'auc:', roc_auc_score(teY, predicts),'cost:', cost_

if  setting batch_size to 100
0 auc: 0.595120586861 cost: 1422.4
1 auc: 0.911648704913 cost: 477.082
2 auc: 0.916009327839 cost: 459.99
3 auc: 0.918605639188 cost: 460.72
4 auc: 0.919915596278 cost: 474.58
5 auc: 0.920871510912 cost: 487.933
6 auc: 0.921381332049 cost: 500.054
7 auc: 0.921853388658 cost: 510.762

if setting batch_size to 500
0 auc: 0.615236099113 cost: 1354.38
1 auc: 0.560017277272 cost: nan
2 auc: 0.560017277272 cost: nan
3 auc: 0.560017277272 cost: nan
4 auc: 0.560017277272 cost: nan
5 auc: 0.560017277272 cost: nan
6 auc: 0.560017277272 cost: nan
7 auc: 0.560017277272 cost: nan
8 auc: 0.560017277272 cost: nan

I am a bit curious as I will not face nan for the same train,test data using thenao implemented logistic regression.
"
306,Strange input image in android demo,"I'm running android camera-based demo application. When I change SAVE_PREVIEW_BITMAP in TensorflowImageListener.java into true, I can save croppedBitmap. However, this saved image is all green with little detail of image.

![preview](https://cloud.githubusercontent.com/assets/13412657/11295381/69658806-8fae-11e5-8db7-9943d1f5a195.png)

When the camera is connected, YUV_420_888 format is used, Then plane #0 is always Y, plane #1 is always U (Cb), and plane #2 is always V (Cr).

```
imageReader =
            ImageReader.newInstance(
                largest.getWidth(), largest.getHeight(), ImageFormat.YUV_420_888, /*maxImages*/ 2);
```

However in TensorflowImageListener.java only 0, 2 planes are used.

```
final int[] planeOrder = {0, 2};
for (int i = 0; i < planeOrder.length; ++i) {
  final Plane plane = planes[planeOrder[i]];
  final ByteBuffer buffer = plane.getBuffer();
  buffer.rewind();
  final int readAmount = buffer.remaining();
  buffer.get(yuvBytes, position, readAmount);
  position += readAmount;
}
```

By the way I'm using LG G2 and Android version is 5.0.1
"
305,ScatterSub on GPU,"I tried running a CNN with embedding layer on a GPU (AWS), but ran into the same problem as described here: http://stackoverflow.com/questions/33624048/fail-to-run-word-embedding-example-in-tensorflow-tutorial-with-gpus

`ScatterSub` doesn't seem to be supported on GPUs and the device placement fails. It would be great if was :) 

It would be great if the examples worked on GPUs.
"
304,Reduction / Term Rewriting / Optimisation / etc.,"Can you add an optimisation layer which will do a global optimisation based on a pre defined set of rules  to ensure that the resulting DAG is the absolute minimised form (based on the set of rewiring rules) to transform the inputs to the the outputs or effects. Based on the domain or know ledge of the input data you can register new rules and also when adding new operation you should be able to add new rules.

Perhaps this can be part of the DSL (https://github.com/tensorflow/tensorflow/issues/70)
"
303,Typo in variable name in Variables Getting Started Doc,"Example code begins by defining the counter variable as ""var"" but later on adds to an undefined variable called ""state""
"
302,"Generating Data Flow Graph for existing code or IR, ByteCode, IL, Object Code, AST, etc.","There are a lot of existing libraries and code.  It will be good if there is a mechanism to generated the Dataflow representation of these programs in TensorFlow. Say I have a library you can analyse the Intermediate Code (ByteCode, IL, IR, Web Asm, Object Code, directly from particular languages code, etc.) and from this generate the DataFlow graph with a view to target GPU, FPGA, Other Accelerate or conventional scenarios.

There were some commercial products doing just the above but I have forgotten some of these vendors. https://www.maxeler.com/ also do this but just one of the vendors I remember.
"
301,I think there is a small mistake in the tensorflow's documents,"I don't know whether it's right to report documents mistakes in this place,i don't find other place to report mistakes...
On tensorflow's website, the introduce of [tf.transpose(a, perm=None, name='transpose')](http://tensorflow.org/api_docs/python/array_ops.md#transpose) in the doc says:

For example:

```
# 'x' is [[1 2 3]
#         [4 5 6]]
tf.transpose(x) ==> [[1 4]
                     [2 5]
                     [3 6]]

# Equivalently
tf.transpose(x perm=[0, 1]) ==> [[1 4]
                                 [2 5]
                                 [3 6]]
```

I think the perm should be [1, 0] , not [0, 1].
"
300,visualizing feature maps using tensorboard?,"After following the tensorboard intro guides and looking at the tensorboard data produced from the cifar example, I'm also wondering if tensorboard allows you to display feature maps like this:

http://neuralnetworksanddeeplearning.com/images/net_full_layer_0.png
"
299,www.tensorflow.org returns a 404 :),"Which is funny, because it's indexed in Google Web Search as www.tensorflow.org :)

tensorflow.org works though...
"
297,Navigation of docs has just become very difficult,"The new docs pages have been changed so that the left navigation pane no longer has collapsable entries. This seems like a step back in many ways, as the API pages are virtually impossible to navigate now.
"
296,Better support for composite dataflow variables and time series,"Perhaps you can have better support for composite data flow variables. E.g. modelling a moving window multivariate time-series, where you have a series of vectors and as new vectors are added calculations are triggered only for values which need re calculation. Also if a calculation is dependent on a slice updates are propagated in the most optimal way that only the needed data is recalculated.

The composite values can be:
- Same type:
  - Vectors
  - Matrices
  - Arrays
  - Series
  - Data frames
  - Slices
- Different types:
  - Tuples (also series with different types)
  - Tables (also Data Frames with different types)
  - Views (slices with different types)
"
295,Better docs for node methods,"I see that nodes / tensors have a number of available methods, like `eval` and `get_shape`, which are very useful for interrogating the graph in interactive sessions for debugging and such. But as far as I can tell they're not really documented anyway. Seems like very useful features that are worth drawing attention to.
"
294,Rewrite git history to purge large model files,"As the following commit comment https://github.com/tensorflow/tensorflow/commit/7e1e25b16ba8d01edf6d53d442cac4f93deda2c1  mentioned, I think this would be a good idea. There is no reason to keep this burden in the history.
"
293,tensorflow/tensorflow/models/rnn/ptb/ptb_word_lm.py TypeError,"when running ptb_word_lm.py:

File ""ptb_word_lm.py"", line 259, in main
    config = get_config()
  File ""ptb_word_lm.py"", line 122, in **init**
    self._cost = cost = tf.reduce_sum(loss) / batch_size
TypeError: unsupported operand type(s) for /: 'Tensor' and 'int'

I replaced
 self._cost = cost = tf.reduce_sum(loss) / batch_size
to
self._cost = cost = tf.div(tf.reduce_sum(loss), batch_size)
and it seems to work fine.
"
292,Rank of Tensors,"I think that there is an error in the description of the rank of the tensors.
In the example the tensor has  rank 3 i think but you wrote that it has rank 2. 

http://tensorflow.org/resources/dims_types.html

""
Rank

In the TensorFlow system, tensors are described by a unit of dimensionality known as rank. Tensor rank is not the same as matrix rank. Tensor rank (sometimes referred to as order or degree or n-dimension) is the number of dimensions of the tensor. For example, the following tensor (defined as a Python list) has a rank of -------2-------------:

t = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]

A rank two tensor is what we typically think of as a matrix, a rank one tensor is a vector. For a rank two tensor you can acccess any element with the syntax t[i, j]. For a rank three tensor you would need to address an element with 't[i, j, k]'.
""
let me know .
Thanks
gg
"
291,Support for special functions,"If the intent is for TensorFlow to be a general purpose computational tool for machine learning there should be more support for special functions (i.e. the functions in scipy.special). In particular, functions occurring in probability distributions such as the gamma(ln) are quite central to probabilistic machine learning.
"
290,Check code description in seq2seq.py - embedding_rnn_seq2seq,"I'm checking the codes line by line to understand how TF works. 

Please check following comments are correct or not. 

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/seq2seq.py#L198-L199

It seems that the encoder_inputs for <code>embedding_rnn_seq2seq</code> should have indexs of vocabularies.

<code> encoder_inputs: [batch_size] </code> 
<code> decoder_inputs: [batch_size] </code>

If not, give some tips to understand it. 
"
289,Website Issue; Some lines in tutorials should pass session data,"I get this error when following the [tutorial](http://tensorflow.org/tutorials/mnist/pros/index.html#deep-mnist-for-experts), using the `eval` function:

```
in _eval_using_default_session
raise ValueError(""Cannot evaluate tensor using eval(): No default ""
ValueError: Cannot evaluate tensor using eval(): No default session is registered. Use 'with DefaultSession(sess)' or pass an explicit session to eval(session=sess)`
```

It also happens with `run`, for instance in the line `train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})`.
"
288,Sorting tensors,"how to sort a tensor (argsort)?
"
287,sequence_length causes error when using GRU,"Calling this works just fine:
outputs, states = rnn.rnn(gru_cell, input, initial_state=initial_state)

But this causes an error:
outputs, states = rnn.rnn(gru_cell, input, initial_state=initial_state, sequence_length=seq_length)

Where I have tried the following for seq_length:
seq_length = tf.placeholder(tf.int64)
seq_length = tf.placeholder(tf.int32)
seq_length = tf.placeholder(tf.int64, shape=[1,1])

This is the error:

File ""/site-packages/tensorflow/models/rnn/rnn.py"", line 85, in rnn
    output_state = cell(input_, state)
  File ""/site-packages/tensorflow/models/rnn/rnn_cell.py"", line 120, in **call**
    2 \* self._num_units, True, 1.0))
  File ""/site-packages/tensorflow/models/rnn/linear.py"", line 29, in linear
    shapes = [a.get_shape().as_list() for a in args]
  File ""/site-packages/tensorflow/python/framework/tensor_shape.py"", line 676, in as_list
    return [dim.value for dim in self._dims]
TypeError: 'NoneType' object is not iterable
"
286,Spread Sheet Abstraction in TensorBoard,"Spreadsheet abstraction is more convenient and familiar. Is it possible to add flow based Spreadsheet like modelling capabilities:
- http://www.ankhor.com/
- https://www.dadisp.com/
- http://matrex.sourceforge.net/
- https://www.quantrix.com/en/

Here the inputs and outputs on each node in the Dataflow Graph are abstracted as cells to which you can link and perform computations which forms a sub graph but which is rendered as a spreadsheet.
"
285,SKFlow - in CPP,"Can you consider developing https://github.com/google/skflow in CPP with binding to other languages including Python than pure Python?
"
284,"Small typo in ""Basic usage"" docs","Looks like there is a comma missing in:

""A tensor has a static type a rank, and a shape""

http://tensorflow.org/get_started/basic_usage.html#tensors
"
282,install on mac gives ImportError: cannot import name symbol_database,"protobuf is not happy. What can I do?

```
import tensorflow
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/Users/philipteare/anaconda/lib/python2.7/site-packages/tensorflow/__init__.py"", line 4, in <module>
    from tensorflow.python import *
  File ""/Users/philipteare/anaconda/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 13, in <module>
    from tensorflow.core.framework.graph_pb2 import *
  File ""/Users/philipteare/anaconda/lib/python2.7/site-packages/tensorflow/core/framework/graph_pb2.py"", line 9, in <module>
    from google.protobuf import symbol_database as _symbol_database
ImportError: cannot import name symbol_database
```
"
281,Reshape docs should mention that -1 can go anywhere,"I.e., -1 is not just for flattening, which is what the current docs say.
"
280,Android App Crash On Start,"After building and installing an apk with bazel mobile-install, the Android application crashes on start.  Occurs on both a Nexus 10 and a Nexus 9 on 5.1.1.

LOGCAT:

11-18 12:53:53.614 427-28083/? I/ActivityManager: START u0 {act=android.intent.action.MAIN cat=[android.intent.category.LAUNCHER] flg=0x10200000 cmp=org.tensorflow.demo/.CameraActivity (has extras)} from uid 10012 on display 0
11-18 12:53:53.671 427-1019/? I/ActivityManager: Start proc 1947:org.tensorflow.demo/u0a113 for activity org.tensorflow.demo/.CameraActivity
11-18 12:53:53.935 1963-1963/? I/dex2oat: /system/bin/dex2oat --runtime-arg -classpath --runtime-arg  --instruction-set=arm --instruction-set-features=div --runtime-arg -Xrelocate --boot-image=/system/framework/boot.art --dex-file=/data/local/tmp/incrementaldeployment/org.tensorflow.demo/dex/incremental_classes1.dex --oat-fd=23 --oat-location=/data/data/org.tensorflow.demo/cache/incremental_classes1.dex --runtime-arg -Xms64m --runtime-arg -Xmx512m
11-18 12:53:54.114 1947-1947/org.tensorflow.demo W/linker: libtensorflow_demo.so: unused DT entry: type 0x1d arg 0x1159c7e
11-18 12:53:54.170 1947-1969/org.tensorflow.demo D/OpenGLRenderer: Use EGL_SWAP_BEHAVIOR_PRESERVED: true
11-18 12:53:54.177 1947-1947/org.tensorflow.demo D/Atlas: Validating map...
11-18 12:53:54.218 1947-1969/org.tensorflow.demo I/OpenGLRenderer: Initialized EGL, version 1.4
11-18 12:53:54.231 1947-1969/org.tensorflow.demo D/OpenGLRenderer: Enabling debug mode 0
11-18 12:53:54.234 1947-1969/org.tensorflow.demo D/mali_winsys: new_window_surface returns 0x3000
11-18 12:53:54.263 1947-1947/org.tensorflow.demo I/CameraManagerGlobal: getCameraService: Reconnecting to camera service
11-18 12:53:54.298 1947-1947/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Adding size: 1440x1080
11-18 12:53:54.298 1947-1947/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Adding size: 1440x960
11-18 12:53:54.298 1947-1947/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Adding size: 1280x1024
11-18 12:53:54.298 1947-1947/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Adding size: 1280x720
11-18 12:53:54.298 1947-1947/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Adding size: 960x720
11-18 12:53:54.298 1947-1947/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Adding size: 768x576
11-18 12:53:54.298 1947-1947/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Adding size: 720x576
11-18 12:53:54.298 1947-1947/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Adding size: 800x480
11-18 12:53:54.298 1947-1947/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Adding size: 720x480
11-18 12:53:54.298 1947-1947/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Adding size: 640x480
11-18 12:53:54.298 1947-1947/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Not adding size: 352x288
11-18 12:53:54.298 1947-1947/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Not adding size: 320x240
11-18 12:53:54.298 1947-1947/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Not adding size: 240x160
11-18 12:53:54.298 1947-1947/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Not adding size: 176x144
11-18 12:53:54.298 1947-1947/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Not adding size: 128x96
11-18 12:53:54.298 1947-1947/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Chosen size: 640x480
11-18 12:53:54.305 1947-1947/org.tensorflow.demo I/CameraManager: Using legacy camera HAL.
11-18 12:53:54.350 130-887/? I/Camera2ClientBase: Camera 0: Opened. Client: org.tensorflow.demo (PID 1947, UID 10113)
11-18 12:53:54.550 1947-1968/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Opening camera preview: 640x480
11-18 12:53:54.555 1947-1968/org.tensorflow.demo I/CameraDeviceState: Legacy camera service transitioning to state CONFIGURING
11-18 12:53:54.556 1947-1996/org.tensorflow.demo I/RequestThread-0: Configure outputs: 3 surfaces configured.
11-18 12:53:54.556 1947-1996/org.tensorflow.demo D/Camera: app passed NULL surface
11-18 12:53:54.568 1947-1998/org.tensorflow.demo D/mali_winsys: new_window_surface returns 0x3000
11-18 12:53:54.624 427-459/? I/ActivityManager: Displayed org.tensorflow.demo/.CameraActivity: +981ms
11-18 12:53:54.673 1947-1968/org.tensorflow.demo I/CameraDeviceState: Legacy camera service transitioning to state IDLE
11-18 12:53:54.676 1947-1968/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Getting assets.
11-18 12:53:54.677 1947-1968/org.tensorflow.demo I/native: tensorflow/examples/android/jni/tensorflow_jni.cc:51 Loading Tensorflow.
11-18 12:53:54.677 1947-1968/org.tensorflow.demo I/native: tensorflow/examples/android/jni/tensorflow_jni.cc:53 Making new SessionOptions.
11-18 12:53:54.677 1947-1968/org.tensorflow.demo I/native: tensorflow/examples/android/jni/tensorflow_jni.cc:56 Got config, 0 devices
11-18 12:53:54.678 427-459/? I/WindowManager: Screen frozen for +948ms due to Window{259ea1a0 u0 Starting org.tensorflow.demo}
11-18 12:53:54.679 1947-1968/org.tensorflow.demo I/native: tensorflow/core/common_runtime/local_device.cc:25 Local device intra op parallelism threads: 4
11-18 12:53:54.684 1947-1968/org.tensorflow.demo I/native: tensorflow/core/common_runtime/direct_session.cc:45 Direct session inter op parallelism threads: 4
11-18 12:53:54.691 1947-1968/org.tensorflow.demo I/native: tensorflow/examples/android/jni/tensorflow_jni.cc:59 Session created.
11-18 12:53:54.691 1947-1968/org.tensorflow.demo I/native: tensorflow/examples/android/jni/tensorflow_jni.cc:62 Graph created.
11-18 12:53:54.692 1947-1968/org.tensorflow.demo I/native: tensorflow/examples/android/jni/tensorflow_jni.cc:66 Acquired AssetManager.
11-18 12:53:54.692 1947-1968/org.tensorflow.demo I/native: tensorflow/examples/android/jni/tensorflow_jni.cc:68 Reading file to proto: file:///android_asset/tensorflow_inception_graph.pb
11-18 12:53:54.693 1947-1968/org.tensorflow.demo I/native: tensorflow/examples/android/jni/jni_utils.cc:85 Opening asset tensorflow_inception_graph.pb from disk with zero-copy.
11-18 12:53:54.709 1947-1968/org.tensorflow.demo A/native: tensorflow/examples/android/jni/jni_utils.cc:90 Check failed: message->ParseFromZeroCopyStream(&lis) 
11-18 12:53:54.710 1947-1968/org.tensorflow.demo A/libc: Fatal signal 6 (SIGABRT), code -6 in tid 1968 (CameraBackgroun)
11-18 12:53:54.820 128-128/? I/DEBUG: pid: 1947, tid: 1968, name: CameraBackgroun  >>> org.tensorflow.demo <<<
11-18 12:53:54.867 128-128/? W/debuggerd: type=1400 audit(0.0:100): avc: denied { search } for name=""org.tensorflow.demo"" dev=""mmcblk0p9"" ino=97888 scontext=u:r:debuggerd:s0 tcontext=u:object_r:app_data_file:s0 tclass=dir permissive=0
11-18 12:53:54.867 128-128/? W/debuggerd: type=1400 audit(0.0:101): avc: denied { search } for name=""org.tensorflow.demo"" dev=""mmcblk0p9"" ino=97888 scontext=u:r:debuggerd:s0 tcontext=u:object_r:app_data_file:s0 tclass=dir permissive=0
11-18 12:53:54.872 128-128/? W/debuggerd: type=1400 audit(0.0:102): avc: denied { search } for name=""org.tensorflow.demo"" dev=""mmcblk0p9"" ino=97888 scontext=u:r:debuggerd:s0 tcontext=u:object_r:app_data_file:s0 tclass=dir permissive=0
11-18 12:53:54.883 128-128/? I/DEBUG: Abort message: 'tensorflow/examples/android/jni/jni_utils.cc:90 Check failed: message->ParseFromZeroCopyStream(&lis) '
11-18 12:53:54.889 128-128/? I/DEBUG:     #05 pc 01c026a8  /data/app/org.tensorflow.demo-1/lib/arm/libtensorflow_demo.so (tensorflow::internal::LogMessage::GenerateLogMessage()+432)
11-18 12:53:54.889 128-128/? I/DEBUG:     #06 pc 01c02b78  /data/app/org.tensorflow.demo-1/lib/arm/libtensorflow_demo.so (tensorflow::internal::LogMessageFatal::~LogMessageFatal()+80)
11-18 12:53:54.889 128-128/? I/DEBUG:     #07 pc 0139e8d4  /data/app/org.tensorflow.demo-1/lib/arm/libtensorflow_demo.so (ReadFileToProto(AAssetManager_, char const_, google::protobuf::MessageLite*)+752)
11-18 12:53:54.889 128-128/? I/DEBUG:     #08 pc 013a1ffc  /data/app/org.tensorflow.demo-1/lib/arm/libtensorflow_demo.so (Java_org_tensorflow_demo_TensorflowClassifier_initializeTensorflow+1016)
11-18 12:53:54.889 128-128/? I/DEBUG:     #09 pc 0000419d  /data/data/org.tensorflow.demo/cache/incremental_classes1.dex
11-18 12:53:56.039 427-2007/? W/ActivityManager:   Force finishing activity 1 org.tensorflow.demo/.CameraActivity
"
279,ResourceExhaustedError when testing Deep MNIST for experts,"tensorflow.python.framework.errors.ResourceExhaustedError: OOM when allocating tensor with shapedim { size: 10000 } dim { size: 14 } dim { size: 14 } dim { size: 64 }
     [[Node: Conv2D_1 = Conv2D[T=DT_FLOAT, padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/gpu:0""](MaxPool, Variable_4)]]
     [[Node: range_3/_21 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_207_range_3"", tensor_type=DT_INT32, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
Caused by op u'Conv2D_1', defined at:

A bit more info here 

I tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 256 (256B) Pool: chunks: 64 free: 24 cumulative malloc: 73160 cumulative freed: 73120
Number of chunks: 64, in_use chunks: 40
I tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 512 (512B) Pool: chunks: 8 free: 8 cumulative malloc: 3040 cumulative freed: 3040
Number of chunks: 8, in_use chunks: 0
I tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 2048 (2.0KiB) Pool: chunks: 16 free: 16 cumulative malloc: 28080 cumulative freed: 28080
Number of chunks: 16, in_use chunks: 0
I tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 4096 (4.0KiB) Pool: chunks: 16 free: 5 cumulative malloc: 24035 cumulative freed: 24024
Number of chunks: 16, in_use chunks: 11
I tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 16384 (16.0KiB) Pool: chunks: 1 free: 1 cumulative malloc: 1 cumulative freed: 1
Number of chunks: 1, in_use chunks: 0
I tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 32768 (32.0KiB) Pool: chunks: 4 free: 2 cumulative malloc: 1002 cumulative freed: 1000
Number of chunks: 4, in_use chunks: 2
I tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 65536 (64.0KiB) Pool: chunks: 8 free: 3 cumulative malloc: 2011 cumulative freed: 2006
Number of chunks: 8, in_use chunks: 5
I tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 81920 (80.0KiB) Pool: chunks: 2 free: 1 cumulative malloc: 3 cumulative freed: 2
Number of chunks: 2, in_use chunks: 1
I tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 163840 (160.0KiB) Pool: chunks: 8 free: 8 cumulative malloc: 8020 cumulative freed: 8020
Number of chunks: 8, in_use chunks: 0
I tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 212992 (208.0KiB) Pool: chunks: 20 free: 15 cumulative malloc: 42248 cumulative freed: 42243
Number of chunks: 20, in_use chunks: 5
I tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 327680 (320.0KiB) Pool: chunks: 4 free: 4 cumulative malloc: 2000 cumulative freed: 2000
Number of chunks: 4, in_use chunks: 0
I tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 425984 (416.0KiB) Pool: chunks: 4 free: 4 cumulative malloc: 5 cumulative freed: 5
Number of chunks: 4, in_use chunks: 0
I tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 655360 (640.0KiB) Pool: chunks: 4 free: 4 cumulative malloc: 8020 cumulative freed: 8020
Number of chunks: 4, in_use chunks: 0
I tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 1310720 (1.25MiB) Pool: chunks: 6 free: 6 cumulative malloc: 12020 cumulative freed: 12020
Number of chunks: 6, in_use chunks: 0
I tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 2097152 (2.00MiB) Pool: chunks: 1 free: 1 cumulative malloc: 2020 cumulative freed: 2020
Number of chunks: 1, in_use chunks: 0
I tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 2621440 (2.50MiB) Pool: chunks: 8 free: 8 cumulative malloc: 16040 cumulative freed: 16040
Number of chunks: 8, in_use chunks: 0
I tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 5242880 (5.00MiB) Pool: chunks: 8 free: 8 cumulative malloc: 18060 cumulative freed: 18060
Number of chunks: 8, in_use chunks: 0
I tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 13631488 (13.00MiB) Pool: chunks: 8 free: 3 cumulative malloc: 2008 cumulative freed: 2003
Number of chunks: 8, in_use chunks: 5
I tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 31457280 (30.00MiB) Pool: chunks: 1 free: 1 cumulative malloc: 2 cumulative freed: 2
Number of chunks: 1, in_use chunks: 0
I tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 41943040 (40.00MiB) Pool: chunks: 1 free: 1 cumulative malloc: 1 cumulative freed: 1
Number of chunks: 1, in_use chunks: 0
I tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 251658240 (240.00MiB) Pool: chunks: 1 free: 0 cumulative malloc: 1 cumulative freed: 0
Number of chunks: 1, in_use chunks: 1
I tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 503316480 (480.00MiB) Pool: chunks: 0 free: 0 cumulative malloc: 0 cumulative freed: 0
Number of chunks: 0, in_use chunks: 0
I tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 1006632960 (960.00MiB) Pool: chunks: 3 free: 3 cumulative malloc: 3 cumulative freed: 3
Number of chunks: 3, in_use chunks: 0
I tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:345] Aggregate Region Memory: 3576057856 (3.33GiB)
I tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:347] Aggregate Chunk Memory: 3539046400 (3.30GiB)
W tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:89] Out of GPU memory, see memory state dump above
W tensorflow/core/kernels/conv_ops.cc:162] Resource exhausted: OOM when allocating tensor with shapedim { size: 10000 } dim { size: 14 } dim { size: 14 } dim { size: 64 }
W tensorflow/core/common_runtime/executor.cc:1027] 0x3c81ab0 Compute status: Resource exhausted: OOM when allocating tensor with shapedim { size: 10000 } dim { size: 14 } dim { size: 14 } dim { size: 64 }
     [[Node: Conv2D_1 = Conv2D[T=DT_FLOAT, padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/gpu:0""](MaxPool, Variable_4)]]
W tensorflow/core/common_runtime/executor.cc:1027] 0x49fab20 Compute status: Resource exhausted: OOM when allocating tensor with shapedim { size: 10000 } dim { size: 14 } dim { size: 14 } dim { size: 64 }
     [[Node: Conv2D_1 = Conv2D[T=DT_FLOAT, padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/gpu:0""](MaxPool, Variable_4)]]
     [[Node: range_3/_21 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_207_range_3"", tensor_type=DT_INT32, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
W tensorflow/core/common_runtime/executor.cc:1027] 0x49fab20 Compute status: Resource exhausted: OOM when allocating tensor with shapedim { size: 10000 } dim { size: 14 } dim { size: 14 } dim { size: 64 }
     [[Node: Conv2D_1 = Conv2D[T=DT_FLOAT, padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/gpu:0""](MaxPool, Variable_4)]]
     [[Node: Cast_1/_19 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_206_Cast_1"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
Traceback (most recent call last):
  File ""/home/andorremus/PycharmProjects/facial-keypoints/mnist.py"", line 93, in <module>
    print ""test accuracy %g"" % accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob:1.0}, session=sess)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 405, in eval
    return _eval_using_default_session(self, feed_dict, self.graph, session)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2728, in _eval_using_default_session
    return session.run(tensors, feed_dict)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 345, in run
    results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 419, in _do_run
    e.code)
tensorflow.python.framework.errors.ResourceExhaustedError: OOM when allocating tensor with shapedim { size: 10000 } dim { size: 14 } dim { size: 14 } dim { size: 64 }
     [[Node: Conv2D_1 = Conv2D[T=DT_FLOAT, padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/gpu:0""](MaxPool, Variable_4)]]
     [[Node: range_3/_21 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_207_range_3"", tensor_type=DT_INT32, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
Caused by op u'Conv2D_1', defined at:
  File ""/home/andorremus/PycharmProjects/facial-keypoints/mnist.py"", line 63, in <module>
    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2))
  File ""/home/andorremus/PycharmProjects/facial-keypoints/mnist.py"", line 42, in conv2d
    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 207, in conv2d
    use_cudnn_on_gpu=use_cudnn_on_gpu, name=name)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py"", line 633, in apply_op
    op_def=op_def)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1710, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 988, in __init__
    self._traceback = _extract_stack()
"
278,Provide a working example involving reading csv data,"I have successfully read in csv data.  I have successfully trained/classified using the mnist data utility.  But I have not successfully been able to train from csv data.

It would also be helpful to clarify pack vs concat which is done on at StackOverflow for a given question but is left unexplained on the tensorflow site.
"
272,softmax_cross_entropy_with_logits to take integer labels / avoid giant dense one-hot matrix,"Currently to compute this loss for a classifier you need to generate a big dense matrix of one-hot vectors to pass to softmax_cross_entropy_with_logits, as in the example at http://tensorflow.org/tutorials/mnist/tf/index.html#loss

This is kinda fiddly to do, but also rather wasteful of memory especially in the case of a larger multiclass softmax. Could we have a version of this function which accepts a list of indices, e.g. like Theano's: http://deeplearning.net/software/theano/library/tensor/nnet/nnet.html#tensor.nnet.categorical_crossentropy ?
"
271,Predicting words instead of probabilities?,"The tensorflow tutorial on language model allows to compute the probability of sentences :

probabilities = tf.nn.softmax(logits)

in the comments below it also specifies a way of predicting the next word instead of probabilities but does not specify how this can be done. So how to output a word instead of probability using this example?

```
lstm = rnn_cell.BasicLSTMCell(lstm_size)
# Initial state of the LSTM memory.
state = tf.zeros([batch_size, lstm.state_size])

loss = 0.0
for current_batch_of_words in words_in_dataset:
    # The value of state is updated after processing each batch of words.
    output, state = lstm(current_batch_of_words, state)

    # The LSTM output can be used to make next word predictions
    logits = tf.matmul(output, softmax_w) + softmax_b
    probabilities = tf.nn.softmax(logits)
    loss += loss_function(probabilities, target_words)

```
"
270,Error: tensorflow/core/common_runtime/executor.cc:1052] 0x400d2bbe0 Compute status: Not found: ./checkpoints_directory/translate.ckpt-200.tempstate9246663217899500702,"I have described the  error  in detail with all the output:
http://stackoverflow.com/questions/33772819/tensorflow-error-on-running-the-seq2seq-model

The other language model example is working and the library has also been built. As per comments I created the checkpoint directory , still throwing the same error: tensorflow/core/common_runtime/executor.cc:1052] 0x400d2bbe0 Compute status: Not found: ./checkpoints_directory/translate.ckpt-200.tempstate9246663217899500702
"
269,LLVM JIT / Runtime Code Re Optimisation,"Some optimisations may not be apparent when statical set up. Perhaps TensorFlow can do some staging and optimisation of the execution while running based on usage patterns.

Perhaps you can borrow some ideas from projects related to: https://scala-lms.github.io/
"
268,Can't install on ubuntu,"New to ubuntu

Trying to install tensorflow using

$ sudo pip ...

I get:

......

  ""Cannot compile 'Python.h'. Perhaps you need to ""

SystemError: Cannot compile 'Python.h'. Perhaps you need to install python-dev|python-devel.

---

Cleaning up...
Command /usr/bin/python -c ""import setuptools, tokenize;**file**='/tmp/pip_build_root/numpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(**file**).read().replace('\r\n', '\n'), **file**, 'exec'))"" install --record /tmp/pip-yiRxwW-record/install-record.txt --single-version-externally-managed --compile failed with error code 1 in /tmp/pip_build_root/numpy
Traceback (most recent call last):
  File ""/usr/local/bin/pip"", line 9, in <module>
    load_entry_point('pip==1.5.4', 'console_scripts', 'pip')()
  File ""/usr/lib/python2.7/dist-packages/pip/**init**.py"", line 235, in main
    return command.main(cmd_args)
  File ""/usr/lib/python2.7/dist-packages/pip/basecommand.py"", line 161, in main
    text = '\n'.join(complete_log)
UnicodeDecodeError: 'ascii' codec can't decode byte 0xe2 in position 72: ordinal not in range(128)

$

Any help is greatly appreciated
"
267,Links broken,"http://tensorflow.org/tutorials/mnist/pros/index.md#build_a_multilayer_convolutional_network

""See the Computation Graph section of Basic Usage for more detail.""

Basic Usage
old: http://tensorflow.org/get_started/basic_usage.md
new: http://tensorflow.org/get_started/index.html#basic-usage

Computation Graph
old: http://tensorflow.org/get_started/basic_usage.md#the-computation-graph
new: http://tensorflow.org/get_started/index.html#the-computation-graph
"
266,Include reset_default_graph in the public API,"`ops.reset_default_graph` is a very useful function that resets the current graph. It's particularly important in interactive sessions where loading data and setting up the kernel may take a long time, and having to restart the kernel every time one wants to start over is a hassle.
"
265,Trouble running a tutorial file,"Hi,

I'm trying to run all tutorials, and I'm stuck with fully_connected_feed.py as it produced following error:
Traceback (most recent call last):

  File ""fully_connected_feed.py"", line 15, in <module>
    import tensorflow.python.platform
  File ""/home/pilotwarela0/Development/tensorflow/tensorflow/**init**.py"", line 4, in <module>
    from tensorflow.python import *
  File ""/home/pilotwarela0/Development/tensorflow/tensorflow/python/**init**.py"", line 15, in <module>
    from tensorflow.core.framework.graph_pb2 import *
ImportError: No module named core.framework.graph_pb2

I managed to track down the location of module:

/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/

So, added this path to PYTHONPATH with this:

PYTHONPATH=""${PYTHONPATH}:/usr/local/lib/python2.7/dist-packages/tensorflow/""
export PYTHONPATH

It didn't work. So, I tried this solution by adding the lines:

import sys
sys.path.append(""/usr/local/lib/python2.7/dist-packages/tensorflow/"")

in ~/tensorflow/tensorflow/python/platform/**init**.py

None of these solution worked out for me. What am I doing wrong here? Could you please suggest a correct way to solve this problem?
"
264,Unable to Build Android Example,"Getting an error when building the Android example.  Have run into protobuf build issues on Mac OS X before, is this related?

Mac OS X - 10.11.1

Output:
$ bazel build //tensorflow/examples/android:tensorflow_demo -c opt --copt=-mfpu=neon --verbose_failures
INFO: Found 1 target...
INFO: From Compiling google/protobuf/src/google/protobuf/arena.cc:
src/main/tools/process-wrapper.c:119: execvp(argv[0], argv): No such file or directory
ERROR: /Users/astellato/Desktop/tensorflow/google/protobuf/BUILD:29:1: C++ compilation of rule '//google/protobuf:protobuf_lite' failed: false failed: error executing command 
  (cd /private/var/tmp/_bazel_astellato/e1414493f08fd994c717215d0d5d2bb5/tensorflow && \
  exec env - \
    INTERCEPT_LOCALLY_EXECUTABLE=1 \
    PATH=/Users/astellato/anaconda/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/opt/X11/bin:/usr/local/MacGPG2/bin:/usr/local/share/npm/bin:/Users/astellato/Development/Android/sdk/platform-tools:/Users/astellato/Development/Android/sdk/tools:/Users/astellato/Development/Android/ndk/android-ndk-r10d:/Users/astellato/bin \
    TMPDIR=/var/folders/3z/18r1p7zn1x74lqpkv377thpc0000gn/T/ \
  /bin/false '-mfpu=neon' -iquote . -iquote bazel-out/android-stub_armeabi-v7a-opt/genfiles -isystem google/protobuf/src -isystem bazel-out/android-stub_armeabi-v7a-opt/genfiles/google/protobuf/src -isystem tools/cpp/gcc3 -DHAVE_PTHREAD -Wall -Wwrite-strings -Woverloaded-virtual -Wno-sign-compare '-Wno-error=unused-function' '-frandom-seed=bazel-out/android-stub_armeabi-v7a-opt/bin/google/protobuf/_objs/protobuf_lite/google/protobuf/src/google/protobuf/arena.pic.o' -MD -MF bazel-out/android-stub_armeabi-v7a-opt/bin/google/protobuf/_objs/protobuf_lite/google/protobuf/src/google/protobuf/arena.pic.d -fPIC -c google/protobuf/src/google/protobuf/arena.cc -o bazel-out/android-stub_armeabi-v7a-opt/bin/google/protobuf/_objs/protobuf_lite/google/protobuf/src/google/protobuf/arena.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1: false failed: error executing command 
  (cd /private/var/tmp/_bazel_astellato/e1414493f08fd994c717215d0d5d2bb5/tensorflow && \
  exec env - \
    INTERCEPT_LOCALLY_EXECUTABLE=1 \
    PATH=/Users/astellato/anaconda/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/opt/X11/bin:/usr/local/MacGPG2/bin:/usr/local/share/npm/bin:/Users/astellato/Development/Android/sdk/platform-tools:/Users/astellato/Development/Android/sdk/tools:/Users/astellato/Development/Android/ndk/android-ndk-r10d:/Users/astellato/bin \
    TMPDIR=/var/folders/3z/18r1p7zn1x74lqpkv377thpc0000gn/T/ \
  /bin/false '-mfpu=neon' -iquote . -iquote bazel-out/android-stub_armeabi-v7a-opt/genfiles -isystem google/protobuf/src -isystem bazel-out/android-stub_armeabi-v7a-opt/genfiles/google/protobuf/src -isystem tools/cpp/gcc3 -DHAVE_PTHREAD -Wall -Wwrite-strings -Woverloaded-virtual -Wno-sign-compare '-Wno-error=unused-function' '-frandom-seed=bazel-out/android-stub_armeabi-v7a-opt/bin/google/protobuf/_objs/protobuf_lite/google/protobuf/src/google/protobuf/arena.pic.o' -MD -MF bazel-out/android-stub_armeabi-v7a-opt/bin/google/protobuf/_objs/protobuf_lite/google/protobuf/src/google/protobuf/arena.pic.d -fPIC -c google/protobuf/src/google/protobuf/arena.cc -o bazel-out/android-stub_armeabi-v7a-opt/bin/google/protobuf/_objs/protobuf_lite/google/protobuf/src/google/protobuf/arena.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
Target //tensorflow/examples/android:tensorflow_demo failed to build
INFO: Elapsed time: 4.001s, Critical Path: 0.18s
"
263,Archlinux Installation using pip!,"Probably this should be mentioned in the documentation that for distros like archlinux that use python 3 by default users can do this use virtualenv like this:

virtualenv --python=python2.7 --system-site-packages
"
262,models/image/mnist/convolutional.py failed on GTX 980!,"NVidia Driver Ver: 355.11

I tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:345] Aggregate Region Memory: 2990620672 (2.79GiB)
I tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:347] Aggregate Chunk Memory: 2903089152 (2.70GiB)

Probably because GPU has only 4GB of memory.
"
261,Building a REPL for tensorflow,"Would an interactive CLI in the spirit of pgcli that would be build on top of python-prompt-toolkit is a good step forward? 
"
260,Error when building seqtoseq model,"Hi all,

I'm trying to understand the seq2seq models defined in seq2seq.py in tensorflow. I use bits of code I copy from the translate.py example that comes with tensorflow. I keep getting the same error and really do not understand where it comes from.

A minimal code example to reproduce the error:

``` python
 import tensorflow as tf
from tensorflow.models.rnn import rnn_cell
from tensorflow.models.rnn import seq2seq

encoder_inputs = []
decoder_inputs = []
for i in xrange(350):  
    encoder_inputs.append(tf.placeholder(tf.int32, shape=[None],
                                              name=""encoder{0}"".format(i)))

for i in xrange(45):
    decoder_inputs.append(tf.placeholder(tf.int32, shape=[None],
                                         name=""decoder{0}"".format(i)))

model = seq2seq.basic_rnn_seq2seq(encoder_inputs,
                                  decoder_inputs,rnn_cell.BasicLSTMCell(512))
```

The error I get when evaluating the last line (I evaluated it interactively in the python interpreter):

```
>>>  Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/tmp/py1053173el"", line 12, in <module>
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/models/rnn/seq2seq.py"", line 82, in basic_rnn_seq2seq
    _, enc_states = rnn.rnn(cell, encoder_inputs, dtype=dtype)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/models/rnn/rnn.py"", line 85, in rnn
    output_state = cell(input_, state)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/models/rnn/rnn_cell.py"", line 161, in __call__
    concat = linear.linear([inputs, h], 4 * self._num_units, True)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/models/rnn/linear.py"", line 32, in linear
    raise ValueError(""Linear is expecting 2D arguments: %s"" % str(shapes))
ValueError: Linear is expecting 2D arguments: [[None], [None, 512]]
```

I suspect the error comes from my side :)
On a sidenote. The documentation and the tutorials are really great but the example code for the sequence to sequence model (the english to french translation example) is quite dense. You also have to jump a lot between files to understand what's going on. Me atleast got lost several times in the code.

A minimal example (perhaps on some toy data) of constructing and training a basic seq2seq model would really be helpful here. :)

Have a nice evening
"
259,TensorBoard: Add select all or none in side panel,"It would be helpful if TensorBoard supported selecting all or none of the models listed in the side panel. I often work in a directory with many models but only want to look at a few of them and end up unchecking a lot of boxes.
"
258,Import error on MAC OSX Yosemite 10.10.5,"I installed TensorFlow through 
pip install https://storage.googleapis.com/tensorflow/mac/tensorflow-0.5.0-py2-none-any.whl

When I tried to import tensorflow, I got following error

> > > import tensorflow
> > > Traceback (most recent call last):
> > >   File ""<stdin>"", line 1, in <module>
> > >   File ""/usr/local/lib/python2.7/site-packages/tensorflow/**init**.py"", line 4, in <module>
> > >     from tensorflow.python import *
> > >   File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/**init**.py"", line 13, in <module>
> > >     from tensorflow.core.framework.graph_pb2 import *
> > >   File ""/usr/local/lib/python2.7/site-packages/tensorflow/core/framework/graph_pb2.py"", line 16, in <module>
> > >     from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2
> > >   File ""/usr/local/lib/python2.7/site-packages/tensorflow/core/framework/attr_value_pb2.py"", line 16, in <module>
> > >     from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2
> > > File ""/usr/local/lib/python2.7/site-packages/tensorflow/core/framework/tensor_pb2.py"", line 16, in <module>
> > >     from tensorflow.core.framework import tensor_shape_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2
> > >   File ""/usr/local/lib/python2.7/site-packages/tensorflow/core/framework/tensor_shape_pb2.py"", line 22, in <module>
> > >     serialized_pb=_b('\n,tensorflow/core/framework/tensor_shape.proto\x12\ntensorflow\""d\n\x10TensorShapeProto\x12-\n\x03\x64im\x18\x02 \x03(\x0b\x32 .tensorflow.TensorShapeProto.Dim\x1a!\n\x03\x44im\x12\x0c\n\x04size\x18\x01 \x01(\x03\x12\x0c\n\x04name\x18\x02 \x01(\tb\x06proto3')
> > > TypeError: __init__() got an unexpected keyword argument 'syntax'

Any thoughts??
"
257,error in computation graph tutorials,"http://www.tensorflow.org/get_started/basic_usage.md#the-computation-graph

new_value = tf.add(state, one)
 update = tf.assign(state, new_value)

should be:

new_value = tf.add(var, one)
 update = tf.assign(var, new_value)

right?
"
256,Transpose convolution layer for tensorflow (was deconvolution),"Has anyone already started implementing a deconvolutional layer for tensorflow as it's used e. g. here https://github.com/stokasto/caffe ? Is anyone else interested in such a functionality or is there any trivial way to implement this using the existing tensors?
"
255,CUDA_ERROR_NO_DEVICE,"I just installed TensorFlow for Ubuntu using the instructions on the [website](http://www.tensorflow.org/get_started/os_setup.md).

If I open a session in python:

``` python
import tensorflow as tf
hello = tf.constant('Hello, TensorFlow!')
sess = tf.Session()
```

I get these warnings:

``` sh
I tensorflow/core/common_runtime/local_device.cc:25] Local device intra op parallelism threads: 8
E tensorflow/stream_executor/cuda/cuda_driver.cc:466] failed call to cuInit: CUDA_ERROR_NO_DEVICE
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:86] kernel driver does not appear to be running on this host (joao): /proc/driver/nvidia/version does not exist
I tensorflow/core/common_runtime/gpu/gpu_init.cc:112] DMA: 
I tensorflow/core/common_runtime/local_session.cc:45] Local session inter op parallelism threads: 8
```

What have I done wrong?
"
254,Tensorflow on Raspberry Pi,"Hi,
Is it possible to install Tensorflow on a Raspberry Pi? OS Ubuntu Mate, Python2.7
"
253,"Need help, how to choose one column of a tensor","predict_op = tf.argmax(py_x, 1) # at predict time, evaluate the argmax of the logistic regression

here what to do if I want to choose one column of py_x, like py_x[1] ?

Also it would be of great help if we have example of showing how to do text classification using tensorflow( sparse feature). 

Example of showing how to evaluate using auc instead of  precision is greatly appreciated.
"
252,Make TensorFlow compatible with PyPy,"I know it's not a priority and will be a long way to get there; but making TF compatible with PyPy woud be super cool.

Thoughts?
"
251,Install tensorflow from source ,"OS: xUbuntu
python-2.7
gcc 4.8
I have installed python-dev

when I build from source using 

```
bazel build --jobs 2 -c opt //tensorflow/tools/pip_package:build_pip_package --verbose_failures
```

I got the following errors:

```
aurora@aurora-Z170X-UD5:~/workspace/tensorflow/tensorflow$ bazel build --jobs 2 -c opt //tensorflow/tools/pip_package:build_pip_package --verbose_failures
....
INFO: Found 1 target...
INFO: From Compiling tensorflow/python/client/tf_session_helper.cc:
In file included from tensorflow/python/client/tf_session_helper.cc:1:0:
./tensorflow/python/client/tf_session_helper.h:6:31: fatal error: numpy/arrayobject.h: No such file or directory
 #include ""numpy/arrayobject.h""
                               ^
compilation terminated.
ERROR: /home/aurora/workspace/tensorflow/tensorflow/tensorflow/python/BUILD:698:1: C++ compilation of rule '//tensorflow/python:tf_session_helper' failed: gcc failed: error executing command 
  (cd /home/aurora/.cache/bazel/_bazel_aurora/67e9d46b2d6eaad7004805288b920919/tensorflow && \
  exec env - \
    INTERCEPT_LOCALLY_EXECUTABLE=1 \
    PATH=/home/aurora/software/anaconda2/bin:/usr/local/cuda/bin:/home/aurora/software/jdk1.8.0_25/bin:/usr/local/cuda/bin:/home/aurora/software/jdk1.8.0_25/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games \
  /usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -iquote . -iquote bazel-out/local_linux-opt/genfiles -isystem google/protobuf/src -isystem bazel-out/local_linux-opt/genfiles/google/protobuf/src -isystem tools/cpp/gcc3 -isystem external/jpeg_archive/jpeg-9a -isystem bazel-out/local_linux-opt/genfiles/external/jpeg_archive/jpeg-9a -isystem external/png_archive/libpng-1.2.53 -isystem bazel-out/local_linux-opt/genfiles/external/png_archive/libpng-1.2.53 -isystem external/re2 -isystem bazel-out/local_linux-opt/genfiles/external/re2 -isystem third_party/gpus/cuda -isystem bazel-out/local_linux-opt/genfiles/third_party/gpus/cuda -isystem third_party/gpus/cuda/include -isystem bazel-out/local_linux-opt/genfiles/third_party/gpus/cuda/include -isystem third_party/eigen3 -isystem bazel-out/local_linux-opt/genfiles/third_party/eigen3 -I/usr/include/python2.7 -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' '-frandom-seed=bazel-out/local_linux-opt/bin/tensorflow/python/_objs/tf_session_helper/tensorflow/python/client/tf_session_helper.pic.o' -MD -MF bazel-out/local_linux-opt/bin/tensorflow/python/_objs/tf_session_helper/tensorflow/python/client/tf_session_helper.pic.d -fPIC -c tensorflow/python/client/tf_session_helper.cc -o bazel-out/local_linux-opt/bin/tensorflow/python/_objs/tf_session_helper/tensorflow/python/client/tf_session_helper.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1: gcc failed: error executing command 
  (cd /home/aurora/.cache/bazel/_bazel_aurora/67e9d46b2d6eaad7004805288b920919/tensorflow && \
  exec env - \
    INTERCEPT_LOCALLY_EXECUTABLE=1 \
    PATH=/home/aurora/software/anaconda2/bin:/usr/local/cuda/bin:/home/aurora/software/jdk1.8.0_25/bin:/usr/local/cuda/bin:/home/aurora/software/jdk1.8.0_25/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games \
  /usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -iquote . -iquote bazel-out/local_linux-opt/genfiles -isystem google/protobuf/src -isystem bazel-out/local_linux-opt/genfiles/google/protobuf/src -isystem tools/cpp/gcc3 -isystem external/jpeg_archive/jpeg-9a -isystem bazel-out/local_linux-opt/genfiles/external/jpeg_archive/jpeg-9a -isystem external/png_archive/libpng-1.2.53 -isystem bazel-out/local_linux-opt/genfiles/external/png_archive/libpng-1.2.53 -isystem external/re2 -isystem bazel-out/local_linux-opt/genfiles/external/re2 -isystem third_party/gpus/cuda -isystem bazel-out/local_linux-opt/genfiles/third_party/gpus/cuda -isystem third_party/gpus/cuda/include -isystem bazel-out/local_linux-opt/genfiles/third_party/gpus/cuda/include -isystem third_party/eigen3 -isystem bazel-out/local_linux-opt/genfiles/third_party/eigen3 -I/usr/include/python2.7 -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' '-frandom-seed=bazel-out/local_linux-opt/bin/tensorflow/python/_objs/tf_session_helper/tensorflow/python/client/tf_session_helper.pic.o' -MD -MF bazel-out/local_linux-opt/bin/tensorflow/python/_objs/tf_session_helper/tensorflow/python/client/tf_session_helper.pic.d -fPIC -c tensorflow/python/client/tf_session_helper.cc -o bazel-out/local_linux-opt/bin/tensorflow/python/_objs/tf_session_helper/tensorflow/python/client/tf_session_helper.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 600.219s, Critical Path: 0.40s
```

I have installed ananconda and the path of  numpy/arrayobject.h is 

```
/software/anaconda2/lib/python2.7/site-packages/numpy/core/include/numpy
```
"
250,Out-of-source builds,"The build instructions have us run bazel such that all the build artifacts are dumped right in the source directory. So are we stuck creating a bunch of .gitignore rules? Seems barbaric when the usual approach is to avoid polluting source directory with build artifacts in the first place.

On behalf of all of us who don't know anything about bazel, I'll ask: does it not support out-of-source builds? I spent some time looking, and trying to do a bazel build from somewhere other than the source directory, and haven't had any luck. 
"
249,Documentation: 'typo' in softmax explanation image,"In the top part of the attached image - is it just me or is the **X** matrix written the wrong way around? In keeping with dot product notation, shouldn't this be:

`y1 = W11 * x1 + W12 * x2 + W13 * x3 + b1`

and so on for y2 and y3?

![wrong](http://api.tensorflow.org/system/image/body/1707/softmax-regression-scalarequation.png)
"
248,typo in placeholder docs,"The example code provided in the docs for the placeholder op doesn't work: 

``` python
  x = tf.placeholder(float, shape=(1024, 1024))
  y = tf.matmul(x, x)

  with tf.Session() as sess:
    print sess.run(y)  # ERROR: will fail because x was not fed.

    rand_array = np.random.rand(1024, 1024)
    print sess.run(y, feed_dict={x: rand_array})  # Will succeed.
```

Should it be `x = tf.placeholder(""float"", shape=(1024, 1024))`?
"
247,translate module not present in binary pip installation,"The translate module (among others) is a part of source, but not the pip install. Is there a plan for adding it in the binary installation?
"
246,Examples for loop control flow ops (Enter/Leave/NextIteration),"These are mentioned tantalisingly in the whitepaper, and code for them seems to be present (although omitted from the docs).

It's not clear at all (to me at least) how to use Enter/Leave/NextIteration to actually construct a loop -- an example would be really nice here :-)

In particular I'm interested in whether recurrent networks could be implemented using these constructs, and if there's a reason you chose not to use them in the examples. Is it a case of the looping stuff not being quite ready enough yet in the open source version? Is it that loop control flow doesn't perform as well?
"
245,word2vec tutorial plot labels are incorrect,"The plot produced by the word2vec tutorial looks like random words.

In tensorflow/tensorflow/g3doc/tutorials/word2vec/word2vec_basic.py line 223 (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/tutorials/word2vec/word2vec_basic.py#L223), the code gets labels for the first 500 words/embeddings by extracting 500 keys from the word dictionary without respect to their indices, using:

```
labels = list(dictionary.keys())[:plot_only]
```

Line 223 should probably be something like the following, since the each key's value is the word index:

```
labels = list(sorted(dictionary, key=dictionary.get))[:plot_only]
```
"
244,Example word2vec.py,"Error while executing python word2vec.py:

from tensorflow.models.embedding import gen_word2vec as word2vec
ImportError: No module named embedding
"
243,Wheel for binary installation is outdated; consider automating release process,"[Installation instructions](http://tensorflow.org/get_started/os_setup.md) suggest

```
pip install https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.5.0-cp27-none-linux_x86_64.whl
```

As far as I can tell, content of this wheel is pre- 6b12d081d54b89869e26d9d99828f13de381761e.

In particular, this means that advanced mnist tutorial from trunk fails when run with this binary installation (even after applying workaround from #226):

```
$ python .../tensorflow/g3doc/tutorials/mnist/fully_connected_feed.py
...
Traceback (most recent call last):
  ...
  File "".../tensorflow/g3doc/tutorials/mnist/mnist.py"", line 94, in loss
    indices = tf.expand_dims(tf.range(batch_size), 1)
TypeError: range() takes at least 2 arguments (1 given)
```
"
240,Mistake in matrix multiplication(http://tensorflow.org/tutorials/mnist/beginners/index.md),"When single layer network math is described you have following:
""""""If we write that out as equations, we get:""""""
after that comes picture with weight multiplications, but there should be
W_1,1_x_1 + W_1,2_x_2 + W_1,3_x_3 + b_1
etc..
Instead there written:
W_1,1_x_1 + W_1,2_x_1 + W_1,3_x_1 + b_1
etc..
Please correct me if I am mistaken.
"
239,Basic Usage - Variables: incorrect variable name,"The state variable is named 'var', but it is referred as 'state' afterwards.
Changing this:
new_value = tf.add(**state**, one)
update = tf.assign(**state**, new_value)
To this:
new_value = tf.add(**var**, one)
update = tf.assign(**var**, new_value)
Solves the problem.
"
238,Empty input to conv2d causes floating point exception,"When empty data is passed into conv2d, the following is displayed, and the program quits:

```
Floating point exception (core dumped)
```

This problem occurs on both Mac (10.9) and Linux (Ubuntu 12.04) in CPU mode (I haven't tried GPU). Here is code that reproduces the problem. 

``` python
import numpy as np
import tensorflow as tf

x = tf.placeholder(tf.float32, shape=[None, 28, 28, 1])
conv1_weights = tf.Variable(tf.truncated_normal([5, 5, 1, 32], stddev=0.1))
conv = tf.nn.conv2d(x, conv1_weights, strides=[1, 1, 1, 1], padding='SAME')

with tf.Session() as sess:
    tf.initialize_all_variables().run()
    sess.run([conv], {x: np.empty((0, 28, 28, 1))})
```
"
237,Error when running code from seq2seq translate model,"Hi all,

I have trained my model on an english to french database, as specified in the tutorial. And yet, when I run this command 

```
./bazel-bin/tensorflow/models/rnn/translate/translate  --decode DECODE --train_dir /Users/User/train/
```

I get a pageful of errors like this:

```
tensorflow.python.framework.errors.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [1024] rhs shape= [256]
     [[Node: save/Assign_3 = Assign[T=DT_FLOAT, use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/cpu:0""](embedding_attention_seq2seq/RNN/MultiRNNCell/Cell0/GRUCell/Candidate/Linear/Bias, save/restore_slice_3)]]
```

What do I do?
"
236,Getting Started variable name mismatch,"In http://tensorflow.org/get_started/basic_usage.md#variables

the variable in the example is initialized as `var`, then subsequently referred to as `state`
leading to an obvious NameError:

```
Traceback (most recent call last):
  File ""./variables.py"", line 8, in <module>
    new_value = tf.add(state, one)
NameError: name 'state' is not defined
```
"
235,the tutorial Sequence to Sequence Models has errors,"first: the bazel downloading statement is missing a -- after the -c opt:
second : the directory translate does not exist in the directory rnn, neither the file translate.py
"
234,translate example is missing '--' in its 'run' command,"There should be a '--' after 'opt'.
bazel run -c opt -- tensorflow/models/rnn/translate:translate --data_dir <DIR>
"
233,Need a way to ask users what version of tensorflow they are running,"And ideally where they got it from.  Something like `tf.version`?
"
232,NameError: name 'init' is not defined,"I am getting the following error while trying MNIST tutorial

sessi.run(init,init)
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
NameError: name 'init' is not defined
"
231,cannot enable peer access from device ordinal 0 to device ordinal 1,"I tensorflow/core/common_runtime/gpu/gpu_init.cc:88] Found device 0 with properties: 
name: GeForce GTX 680
major: 3 minor: 0 memoryClockRate (GHz) 1.0585
pciBusID 0000:02:00.0
Total memory: 2.00GiB
Free memory: 1.95GiB
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:888] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:88] Found device 1 with properties: 
name: GeForce GTX 480
major: 2 minor: 0 memoryClockRate (GHz) 1.401
pciBusID 0000:01:00.0
Total memory: 1.50GiB
Free memory: 929.24MiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:45] cannot enable peer access from device ordinal 0 to device ordinal 1
I tensorflow/core/common_runtime/gpu/gpu_init.cc:45] cannot enable peer access from device ordinal 1 to device ordinal 0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:112] DMA: 0 1 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:122] 0:   Y N 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:122] 1:   N Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:611] Ignoring gpu device (device: 0, name: GeForce GTX 680, pci bus id: 0000:02:00.0) with Cuda compute capability 3.0. The minimum required Cuda capability is 3.5.
I tensorflow/core/common_runtime/gpu/gpu_device.cc:611] Ignoring gpu device (device: 1, name: GeForce GTX 480, pci bus id: 0000:01:00.0) with Cuda compute capability 2.0. The minimum required Cuda capability is 3.5.
I tensorflow/core/common_runtime/local_session.cc:45] Local session inter op parallelism threads: 4
Initialized!
Epoch 0.00
Minibatch loss: 12.054, learning rate: 0.010000
Minibatch error: 90.6%
Validation error: 84.6%
Epoch 0.12
Minibatch loss: 3.285, learning rate: 0.010000
Minibatch error: 6.2%
Validation error: 7.0%
## Epoch 0.23

I have gtx680 and gtx480(I know the two GPUs do not have peer accesses),when I run the example mnist,I got these problems and it  runs very slowly.
Am I running without GPUs or GPU??
Can I run with only one GPU,  e.g. GTX680?
How? Thanks~
"
230,document error,"I was following the getting started tutorial and found one issue in this http://tensorflow.org/get_started/basic_usage.md#overview. 

there is undefined name ""state"" in the example of Variables section. I think it should be ""var"" but I am new to tensorflow. Please confirm and update the doc so that others don't get confused.  
"
229,"from __future__ import division gives error in word2vec_basic when dividing tensors.Just comment out ""from __future__....""",
228,AttributeError in Tensor,"While running workd2vec_basic.py as is, an AttributeError rises when dividing tesors. 

AttributeError: type object 'Tensor' has no attribute '**truediv**'

Dividing arbitrary tensors inside the console in a python session would not give such error. Maybe multiple class definitions for Tensor?
"
227,Compute capability < 3.5,"I have a little bit old GPU card with compute capability 2.0 (GeForce GTX 560).
Is there a way to get TensorFlow work with this card?
"
226,`from tensorflow.g3doc...` is Broken,"There are a dozen places in `g3doc/how_tos` and `g3doc/tutorials` where things are imported from the `g3doc` directory. 

The `g3doc` directory isn't included in the installation, and `tensorflow`, intentionally, can't be imported from the source directory, so those are likely all broken.
"
225,Cannot get TensorBoard example working,"Here's my code:

```
merged_summary_op = tf.merge_all_summaries()
summary_writer = tf.train.SummaryWriter('/tmp/mnist_logs', sess.graph_def)
for i in range(200):
    batch = mnist.train.next_batch(50)
    sess.run(train_step, feed_dict={x: batch[0], y_: batch[1])
    if i % 100 == 0:
        train_accuracy = sess.run(train_step, feed_dict={x: batch[0], y_: batch[1]})
        summary_str = sess.run(merged_summary_op, feed_dict={x: batch[0], y_: batch[1]})
        summary_writer.add_summary(summary_str, i)
```

but got this error at line `sess.run(merged_summary_op, ...)`

```
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-39-f56ad86fef0b> in <module>()
----> sess.run(merged_summary_op, feed_dict={x: batch[0], y_: batch[1]})

/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict)
    343 
    344     # Run request and get response.
--> 345     results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)
    346 
    347     # User may have fetched the same tensor multiple times, but we

/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in _do_run(self, target_list, fetch_list, feed_dict)
    417         # pylint: disable=protected-access
    418         raise errors._make_specific_exception(node_def, op, e.error_message,
--> 419                                               e.code)
    420         # pylint: enable=protected-access
    421       raise e_type, e_value, e_traceback

InvalidArgumentError: You must feed a value for placeholder tensor 'Placeholder' with dtype float
```

The error message `you must feed a value for placeholder tensor` doesn't make much sense. The line above that with similar structure ran just fine.
"
224,TensorFlow for Jetson TK1 (ARM + Cuda),"I have a gpu-enabled build for Jetson TK1 using CUDA 6.5 runtime and CUDNN 6.5.
This is a link to download the binary for the pip install if someone wants to try it:
https://drive.google.com/file/d/0B1uGKNpQ7xNqeTB4RFE2MXdNWUU/view?usp=sharing

Jetson  TK1 has a limited amount of memory ( CPU+GPU <2GB) so most of the examples will not run without modifications but aside from  Out Of Memory errors, TensorFlow runs just fine.
"
223,extra cpus not recognized when using docker on windows 10,"Not sure if this is a windows 10 specific issue, a virtual box issue, a docker issue or a tensorflow/docker integration issue, but I'm getting 

""tensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'random_normal/stddev': Could not satisfy explicit device specification '/cpu:1'""

For the following code:

with tf.device(""/cpu:1""):
    sess = tf.Session()
    op = tf.matrix_inverse(tf.random_normal([100,100]))
    sess.run(op)

Note that /proc/cpuinfo is reporting that I have cpu cores       : 8

Also, when I do run  tf.matrix_inverse(tf.random_normal([3000,3000])) my CPUs are barely used. 

Another thing I tried was  

""cat cifar10_multi_gpu_train.py | sed -e 's:gpu:cpu:g' > cifar10_multi_cpu_train.py""
python cifar10_multi_cpu_train.py --num_cpus=7

That didn't seem to work at all.
"
222,Error in api_docs/images/Gather.png ,"The last arrow should originate from p_5. I'd photoshop it, but I imagine there's an source illustrator file somewhere which would be better to change.

http://www.tensorflow.org/api_docs/python/array_ops.md#gather
https://github.com/tensorflow/tensorflow/blob/a9ca5173b2252b0de5dd754147b275e85298e522/tensorflow/g3doc/api_docs/images/Gather.png
"
221,tf.matrix_inverse() is slow compared to numpy.linalg.inv,"Running this snippet

```
import numpy as np
import scipy as sp
from datetime import datetime
import tensorflow as tf

s = tf.Session()
dim = 3000
mat = tf.random_uniform((dim,dim))
s.run(tf.initialize_all_variables())
matinv = tf.matrix_inverse(mat)
st = datetime.now()
s.run(matinv)
print ""time elapsed tensorflow:"", datetime.now() - st

st = datetime.now()
x = np.random.rand(dim,dim)
sp.linalg.inv(x)
print ""time elapsed scipy:     "", datetime.now() - st
```

yields this output

```
I tensorflow/core/common_runtime/gpu/gpu_device.cc:643] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 750 Ti, pci bus id: 0000:01:00.0)
time elapsed tensorflow: 0:00:18.078232
time elapsed scipy:      0:00:01.613825
```

**1.6 sec (Scipy)  vs. ~18 sec (tensorflow), that's a huge difference.**
- Is this expected behavior?
- Why is TensorFlow so slow when inverting a matrix? I was hoping it leverages the GPU.
- Is there a way to improve the TensorFlow runtime duration?
"
220,how can I export android-tensorflow into my android stuido,"Is it possible for me to import the android example into android studio? I am confused because I haven't found the libtensorflowdemo.so lib (in the code ,this lib is loaded) about tensorflow in the folders
"
219,ImportError:No module named setuptools after exectued the step for bazel-bin,"I setup tensorflow according to http://tensorflow.org/tutorials/seq2seq/index.md. When I do the step as below:
bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg,but the below error was throw:
Sat XXXXXXXXXXXXX CST 2015: ===Building wheel
Traceback(most recent call last):
  File “setup.py”,line 3,in <module>
    from setuptools import find_packages,setup,Extension
ImportError:No module named setuptools
BTW, I had no do the step for (Optional) Enable GPU Support
"
218,bazel run error,"I am trying to run the code from this tutorial: http://tensorflow.org/tutorials/seq2seq/index.md

When I try to run this command:

`bazel run -c opt tensorflow/models/rnn/translate/translate.py -- -- data_dir ../data/translate/`
I get the following error:

```
...................
ERROR: Cannot run target //tensorflow/models/rnn/translate:translate.py: Not   executable.
INFO: Elapsed time: 1.537s
ERROR: Build failed. Not running target.
```

Any ideas how to resolve?
"
217,Is pep8 compatibility necessary right now for tensorflow?,"On running the pep8 test, I found out around 18k warnings. I think we should strict to some guideline, so that as the project grows, a proper standard is maintained. We can use flake8 for this.

I can work on this and submit a PR, if pep8 compatibility is required.
"
216,MatMul Broadcasting / tensordot,"It would really help if `matmul()` and element-wise `mul()` were broadcastable, like in Numpy.  Otherwise you're writing a bunch of boilerplate reshaping code.

For example, suppose I have a `T x n x k` and want to multiply it by a `k x k2`, and then to a max pool over `T` and then a mean pool over `n`.  To do this now, I think you need to reshape, do the `matmul()` and then undo the reshape and then do the pooling.
"
215,Question:  Example on how can TensorFlow be used for Text classification?,
214,Beam Search,"Is there anything in place supporting this yet? Wanted to ask before I implement my own.
"
213,tensorflow howto for sharing variable is confusing,"at here:
http://tensorflow.org/how_tos/variable_scope/index.md

The tutorial talk about using ""two sets of variables"" and talk about their duplication, however the network itself uses 2 layers of convolution. So there's 2 different things that can be the quantity of 2. 
1) The number of layers is 2, being conv1 and conv2, these 2 should be distinct
2) The number of image filters, applied once to each image, these 2 should be identical

I was having a hard time understanding at first and thought we're attempting to use the same weights for both of the conv layers. It didn't help that the definition for ""variables_dict"" only explicitly states the existence for the weights for the first conv layer, leading me to believe that the weights of the 2 layers are actually shared as well.

I think a simple fix is to make the network have say 5 conv layers instead of 2, this way you get to demonstrate variable_scope as well in the later section

Just my 2 cents, I starred at this for much longer than I should have because of this confusion.
"
212,Multiple models in one session,"Is this possible? I'm doing something where I need the outputs of multiple distinct models to be compared. To do that, I'm batching up inputs and running them over each model. It's unclear to me how I can do this in one session.
"
211,Add gpu support for LRN,"When I launch a network that uses local response normalization, it works perfectly on a CPU, but it appears to not have a gpu implementation and results in the following error when I switch to a gpu device:

`tensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'LRN': Could not satisfy explicit device specification '/gpu:0'
     [[Node: LRN = LRN[alpha=0.0005, beta=0.75, bias=2, depth_radius=5, _device=""/gpu:0""](conv1/conv1)]]`

I could probably explicitly deploy this operation on the cpu, but it since this is a sliding window algorithm I'm surprised it doesn't have a gpu implementation.
"
210,feature request: softmax target axes / multi-dimensional softmax,"The current softmax implementation operates only on 2d tensors, and computes the normalization over the second dimension.

It would be useful to have a softmax operation that can sum over arbitrary dimensions in the same way that the `reduce_*` operations do.

As a concrete example application, one might have a convolutional network that outputs a (soft) 1-of-k prediction for each position.
"
209,Yann LeCun's web page is not available - cannot download data from there is there a mirror?,"Yan Lecun''s web page is not available - cannot download data from there is there a mirror?

python tensorflow/models/image/mnist/convolutional.py attempts to download from http://yann.lecun.com/exdb/mnist/

For the past hour or so yann.lecun.com is not responding...
"
208,"Symbolic loops (like ""scan"" in Theano)","I've been wondering if there are plans to add symbolic loops to TensorFlow because I feel like this is a major feature when it comes to variable length sequences. Finite unfolding (with bucketing) seems like a dirty hack to me and since (as far as I understand) TensorFlow is meant for deployment, too, how do you envision using it for seq2seq translation given that you don't know ahead of time how long the generated sequence will be?

Thanks,
Sigurd
"
207,confused by device placement on Amazon AWS,"First - loving tensorflow.  The tutorials were really great fun to read.   Tensorflow API architecture is clear and amazing.   Hope to do pull requests once I get up to speed.

However, I'm trying to do device placement to do some basic benchmarks to see if it's worth using Amazon at all versus my own computers.  So far, not so promising, but maybe I'm doing something wrong.

From the example here:  http://tensorflow.org/how_tos/using_gpu/index.md

I get the following results.

<pre>

>>> with tf.device('/cpu:0'):
...   a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')
...   b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')
...   sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))
...   print sess.run(c)
...
I tensorflow/core/common_runtime/gpu/gpu_device.cc:644] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GRID K520, pci bus\
 id: 0000:00:03.0)
Device mapping:
/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GRID K520, pci bus id: 0000:00:03.0
I tensorflow/core/common_runtime/direct_session.cc:111] Device mapping:
/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GRID K520, pci bus id: 0000:00:03.0

b: /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:289] b: /job:localhost/replica:0/task:0/cpu:0
a: /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:289] a: /job:localhost/replica:0/task:0/cpu:0
MatMul_1: /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:289] MatMul_1: /job:localhost/replica:0/task:0/gpu:0
[[ 22.  28.]
 [ 49.  64.]]
</pre>

Looking at that, it looks like it's placing the matmul on the gpu.   I want it on the cpu.  Is that possible?  

Also, is matrix_inverse or matmul of say a 5000x5000 matrix a good (but very rough!) benchmark to help evaluate the value of Amazon GPU/CPU large instances?

Thanks again
"
206,Generalize slicing and slice assignment ops (including gather and scatter),"We should make our slicing and assignment ops more general to capture more of the functionality of numpy slicing, and add `__getitem__` sugar for all of it.  Specifically,
1. We should have a 2.5 dimensional set of ops, with dimensions (1) get vs. set, (2) slice type, and for the assignment ops (3) the update op.  Currently we have `slice`, `assign_update`, `assign_add`, `assign_sub`, `gather`, `scatter_update`, `scatter_add`, `scatter_sub`.  We should also have `assign_slice_update`, `assign_slice_add`, `assign_slice_sub`.
2. Both slicing and slice assignment should support strides, with no performance cost if strides aren't used.
3. Ideally, the slice ops should support negative indexing a la Python.  Since the slice parameters are already CPU, this is implementable with near zero cost.   The unfortunate bit is that since we picked the wrong format for specifying ranges (start + length instead of start : end), negative indexing might be awkward.  Thus, it might be best left to a separate bug.
4. Support numpy-like boolean indexing.
5. Generalize `gather` and `scatter_*` to take an array of input index tensors, efficiently broadcast them, and do multidimensional indexing similar to numpy.
6. Make `__getitem__` provide sugar for all of the above.  Ideally we'd have something idiomatically similar at least to `__setitem__`, but this is problematic since the returned assignment op is important to have, `__setitem__` does not return a value, and the nice range sugar is available only inside indexing / assignment calls.

@ebrevdo: I'm assigning this to you for now since you might get to it first, but feel free to grab only the piece of it that you need for now.
"
205,Remove unnecessary null pointer checks,"[An extra null pointer check is not needed in functions](https://isocpp.org/wiki/faq/freestore-mgmt#delete-handles-null) like the following.
- [TensorSliceReaderCacheWrapper](https://github.com/tensorflow/tensorflow/blob/d6357a5849db980df51d00d8a9ff874cda2faeb3/tensorflow/core/util/tensor_slice_reader_cache.cc#L11)
- [Uncompress](https://github.com/tensorflow/tensorflow/blob/d6357a5849db980df51d00d8a9ff874cda2faeb3/tensorflow/core/lib/jpeg/jpeg_mem.cc#L323)
"
204,Using 3d Input for seq2seq Models -- Word Vector Input,"Hey TF, great code.

I was wondering for your seq2seq models, if it is possible to insert 3d input. The reason being is that you usually want to embed your words to lets say 128 vectors. Google's Word2vec tool does this very well.

However, it looks that for all the seq2seq models, the input to the encoder and decoder are only 2d. This means that each word has to be converted to an integer correct? It would be nice if we could insert a 128 vector instead. Or perhaps I'm missing something? Thanks! 
"
203,Promote usage of docker above all other installation methods,"Shouldn't we just focus on docker? At least on the main page, and then link to other methods elsewhere.

Would just need a good docker development workflow (I personally got none yet).
"
202,Better error message for tf.assign,"When I try to use tf.assign I'm always running into the error message

TypeError: Input 'ref' of 'Assign' Op requires l-value input

I have no idea what this means. It's a pretty unhelpful error message.

Some context ...

```
a = tf.random_normal([4,4]) # I tried this with tf.constant and tf.Variable and got the same result

tf.assign(tf.slice(a, [1, 0], [-1, -1]), tf.slice(a, [0, 0], [3, -1]))

tf.assign(a, 5)

tf.assign(a, a)
```

All three give the same error message.
"
201,How To doc for tensor indexing and assigning ops,"If you're coming from numpy you're used to be able to index and assign into arrays in the usual way.
"
200,Broken link on beginner's tutorial page,"At the bottom of http://www.tensorflow.org/tutorials/mnist/beginners/index.md is a link to ""the next tutorial"": http://www.tensorflow.org/tutorials/index.md

For some reason, that link redirects to the home page. Removing index.md from the end of the URL works.
"
199,a Makefile would be supremely helpful,"It'd be really useful to have a Makefile to build the tree.  Bazel (or it is blaze?) isn't working for us out of the gate, and it's rather non-obvious what it will try to do given its config files.

If someone could provide a transcript of a full build (preferably with GPU), showing external commands run and simulated (e.g., if bazel does 'cp' itself, for example), I'll try to work on this.

For the record, here's the initial fail I see when trying to build, without GPU to keep things simple.  No doubt I'm making some novice error.  Nonetheless, this diagnostic is rather opaque compared to what one might expect from 'make'.  (Maybe something is missing?  The tree was grabbed with 'git clone --recurse-submodules' though.) 

$ bazel build --logging=6 -c opt //tensorflow/cc:tutorials_example_trainer  
WARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.io/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.
ERROR: Loading of target '//tools/cpp:toolchain' failed; build aborted: no such package 'tools/cpp': BUILD file not found on package path.
ERROR: Loading failed; build aborted.
INFO: Elapsed time: 0.877s
"
198,cumulative longer epochs,"A simple logistic regression (or any other function for that matter), incurs a hefty penalty over time. Code [gist here](https://gist.github.com/graphific/7f0a214350fd763275b8). 
Each training epoch takes increasingly longer, from 1.7s for th first epoch and already at 2.7 at 20 epochs:

```
Epoch: 0001 cost= 29.860479714
time this epoch= 1.749361
Epoch: 0002 cost= 22.108508758
time this epoch= 1.873362
Epoch: 0003 cost= 21.061937475
time this epoch= 2.053877
Epoch: 0004 cost= 20.553687506
time this epoch= 2.401098
Epoch: 0005 cost= 20.262585952
time this epoch= 2.563413
Epoch: 0006 cost= 19.878952036
time this epoch= 2.675142
Epoch: 0007 cost= 19.573502880
time this epoch= 2.638027
Epoch: 0008 cost= 19.433302383
time this epoch= 2.632813
Epoch: 0009 cost= 19.428594169
time this epoch= 2.616152
Epoch: 0010 cost= 19.276754012
time this epoch= 2.553015
Epoch: 0011 cost= 19.082279745
time this epoch= 2.571626
Epoch: 0012 cost= 19.017995413
time this epoch= 2.657914
Epoch: 0013 cost= 18.981637795
time this epoch= 2.684047
Epoch: 0014 cost= 18.957392608
time this epoch= 2.626817
Epoch: 0015 cost= 18.679365802
time this epoch= 2.629546
Epoch: 0016 cost= 18.732087401
time this epoch= 2.633352
Epoch: 0017 cost= 18.655737654
time this epoch= 2.662984
Epoch: 0018 cost= 18.450943058
time this epoch= 2.765998
Epoch: 0019 cost= 18.539302767
time this epoch= 2.774611
Epoch: 0020 cost= 18.555477153
time this epoch= 2.79623
Epoch: 0021 cost= 18.401914994
time this epoch= 2.81699
Epoch: 0022 cost= 18.408855550
time this epoch= 2.864744
Epoch: 0023 cost= 18.456620145
time this epoch= 2.852341
Epoch: 0024 cost= 18.365951549
time this epoch= 2.787942
Epoch: 0025 cost= 18.230793715
time this epoch= 2.748816
```

it might be something wrong in the code, or things to be fixed with tensorflow, any ideas?
"
197,Small typo in Beginners MNIST Tutorial,"There is an extra 'as' in the following sentence, in the ""The MNIST Data"" section:

> For the purposes of this tutorial, we're going to want our labels as as ""one-hot vectors"".

http://tensorflow.org/tutorials/mnist/beginners/index.md
"
196,Padding type definition is swapped in the documentation.,"In http://tensorflow.org/api_docs/python/nn.md#pooling and http://tensorflow.org/api_docs/python/nn.md#convolution

The definition of the padding types should be swapped.

Now it is like this:

> padding = 'SAME': Round down (only full size windows are considered).
> padding = 'VALID': Round up (partial windows are included).

But it should be like this:

> padding = 'SAME': Round up (partial windows are included).
> padding = 'VALID': Round down (only full size windows are considered).

I also think it should be made clear that the padding is already included in the shape(value) of the formula ""shape(output) = (shape(value) - ksize + 1) / strides"".

Or maybe the formula should be changed to the following simpler one (taken from http://cs231n.github.io/convolutional-networks/#conv):

> shape(output) = ((shape(value)+2*pad - ksize) / strides) + 1

where pad = 0 if padding='VALID' or pad = floor(ksize/2) if padding='SAME'.
"
195,Maybe the website in other languages?,"We'll be able to translate the site for other idioms? 
"
194,g3doc tutorial mnist.py tf.range missing argument,"`indices = tf.expand_dims(tf.range(batch_size), 1)`
in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/tutorials/mnist/mnist.py#L94

which should be `indices = tf.expand_dims(tf.range(0, batch_size, 1), 1)`

The [tutorial doc](http://www.tensorflow.org/tutorials/mnist/tf/index.md) shows the correct code.
"
193,Building from source for BSD,"Arch linux uses this line:

```
bazel build --jobs 2 -c opt //tensorflow/tools/pip_package:build_pip_package
```

I am on BSD, and I would rather build just executables, and not a pip package. How do I do this? Could you add build instructions?
"
192,ImportError: No module named copyreg,"when I use OS X system to write first tensorflow program,I get some error message, who can tell me how to fix it??
## here is error message

bogon:~ ra$ python
Python 2.7.10 (default, Jul 14 2015, 19:46:27) 
[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.39)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.

> > > import tensorflow as tf
> > > Traceback (most recent call last):
> > >   File ""<stdin>"", line 1, in <module>
> > >   File ""/Library/Python/2.7/site-packages/tensorflow/**init**.py"", line 4, in <module>
> > >     from tensorflow.python import *
> > >   File ""/Library/Python/2.7/site-packages/tensorflow/python/**init**.py"", line 13, in <module>
> > >     from tensorflow.core.framework.graph_pb2 import *
> > >   File ""/Library/Python/2.7/site-packages/tensorflow/core/framework/graph_pb2.py"", line 8, in <module>
> > >     from google.protobuf import reflection as _reflection
> > >   File ""/Library/Python/2.7/site-packages/google/protobuf/reflection.py"", line 58, in <module>
> > >     from google.protobuf.internal import python_message as message_impl
> > >   File ""/Library/Python/2.7/site-packages/google/protobuf/internal/python_message.py"", line 59, in <module>
> > >     import six.moves.copyreg as copyreg
> > > ImportError: No module named copyreg
"
191,Unrecognized option: --data_dir,"When I try to run the command 

```
bazel run -c opt <...>/models/rnn/translate/translate.py
  --data_dir [your_data_directory]
```

I get the error: 
`Unrecognized option: --data_dir`

Is my syntax wrong?
"
190,"when install from sources, I encounter ERROR: C++ compilation of rule '//google/protobuf:protobuf_lite' failed: crosstool_wrapper_driver_is_not_gcc failed","Do anyone compile the source of Tensor Flow?
When I install Tensor Flow from sources, After I excute under command in terminal. 

``` bash
bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer
```

I encounter the follow error.

```
ERROR: ~/tensorflow/google/protobuf/BUILD:29:1: C++ compilation of rule 
'//google/protobuf:protobuf_lite' failed: crosstool_wrapper_driver_is_not_gcc failed: error 
executing command third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -
U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-
parameter -Wno-free-nonheap-object ... (remaining 40 argument(s) skipped).
Target //tensorflow/cc:tutorials_example_trainer failed to build
```

My OS is Ubuntu 14.04，GCC/G++ is 4.7, GPU is K40c, Python is 2.7,  cuda is 7.0, cudnn is 6.5v2, bazel is installed by compile source code.
"
189,No model directory,"I just installed tensorflow in a Virtualenv on Mac OS. There is no models directory. How do I get the models installed?
"
188,Extra exp in softmax formula?,"The Vector Representations of Words tutorial says:
P(wt|h)=softmax(exp{score(wt,h)}) =exp{score(wt,h)} / ∑exp{score(w′,h)}.

Shouldn't that be ... softmax(score(wt,h)) ... since softmax applies an exp to its arguments?

Page is http://www.tensorflow.org/tutorials/word2vec/index.md
"
187,Make Python/Numpy include paths configurable,"The Mac OS X Numpy and Python include paths are hard-coded to `/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/numpy/core/include` and `/usr/include/python2.7`. I am on OS X 10.11 and I use the Anaconda Python distribution (installed to `/Users/<user>/anaconda`).

Currently, Bazel doesn't find my headers:

```
./tensorflow/python/client/tf_session_helper.h:4:10: fatal error: 'Python.h' file not found
#include <Python.h>
         ^
1 error generated.
```

It would be great if Python include paths could be configured in `configure` along with the cuDNN and CUDA paths.
"
186,No documentation for Saver class,"There are multiple references to **Saver** class in _api_docs/python/train.md_ and _tutorials/mnist/tf/index.md_, yet the documentation for the Saver class does not exist. 

Is there any way I can help with the documentation?
"
185,Incorrect matrix in beginner tutorial on www.tensorflow.org,"The following image on the [Beginner's tutorial page](http://www.tensorflow.org/tutorials/mnist/beginners/index.md) is wrong:
![softmax-regression-scalarequation](https://cloud.githubusercontent.com/assets/10536745/11130763/d030c652-89ac-11e5-8d19-186bf9af9b28.png)

Here is a corrected version:
![softmax-regression-scalarequationcorrected](https://cloud.githubusercontent.com/assets/10536745/11130892/910fafaa-89ad-11e5-88d0-083f3da5a3fe.png)
"
184,Dropout Loses Shape Inference Information,"I was working on a simple conv net architecture (stack of convs followed by fully connected) and I came across the following issue. If you apply dropout to the output of a convolution and use a placeholder for p_keep on the dropout, you lose all of the shape information except for the last axis'. Below is a code snippet demonstrating this behavior

```
def conv(input_, h, w, nfilt_in, nfilt_out, layer_number):
    with tf.name_scope('conv_%d' % layer_number) as scope:
        kernel = tf.Variable(tf.truncated_normal([h, w, nfilt_in, nfilt_out],
                                                 dtype=tf.float32,
                                                 stddev=1e-1), name='conv_kernel')
        conv = tf.nn.conv2d(input_, kernel, [1, 1, 1, 1], padding='SAME')
    return conv


def model(X, p_keep):

    c = conv(X, 5, 5, 1, 8, 0)
    print ""c_shape before dropout:"", c.get_shape()  # prints TensorShape([Dimension(None), Dimension(28), Dimension(28), Dimension(8)]) as expected
    c = tf.nn.dropout(c, p_keep)
    print ""c_shape after dropout:"", c.get_shape()  # prints TensorShape(None) which is strange
    c2 = conv(c, 5, 5, 8, 16, 1)
    print ""c2_shape:"", c2.get_shape()  # prints TensorShape([Dimension(None), Dimension(None), Dimension(None), Dimension(16)]) which is strange
    return c2

X = tf.placeholder(""float"", [None, 28, 28, 1])
p_keep = tf.placeholder(""float"")
y_model = model(X, p_keep)
sess = tf.Session()
init = tf.initialize_all_variables()
sess.run(init)

```

As an aside, if you explicitly pass in a value instead of using a placeholder (e.g. replace p_keep=tf.placeholder('float') with p_keep=0.5) this issue does not occur.
"
183,does tensorboard allow for building/editing models?,"I was under the impression that tensorboard was an interactive UI that allows you to build/edit models.  Is this not the case?
"
182,The icon is assymetric,"The icon for Tensor Flow should be fixed. The horizontal bar of T is longer on one side of the structure but the shadow shows a perfect T. The part of the bar on the right side of the structure should be one more unit long.
"
181,Typo in tf.Graph.name_scope(name) docs,"`c_1 = tf.constant(6.0, name=""c"")` should be `c_1 = tf.constant(6.0, name=""c_1"")`
"
180,'state' is not defined ,"When I was trying to run the samples I got an error while running -> new_value = tf.add(state,one)

Error : Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
NameError: name 'state' is not defined

> > > import tensorflow as tf
> > > var = tf.Variable(0, name= ""counter"")
> > > one = tf.constant(1)
> > > new_value = tf.add(state,one)
> > > Traceback (most recent call last):
> > >   File ""<stdin>"", line 1, in <module>
> > > NameError: name 'state' is not defined
"
179,Typo in TensorBoard: Visualizing Learning docs,"I believe there is a typo. In the code snippet in that section, currently it states:

`summary_writer = tf.train.SummaryWriter('/tmp/mnist_logs', sess.graph)`

But `sess.graph` is a `Graph` object and `SummaryWriter` expects a `GraphDef` object instead, so something like:

`summary_writer = tf.train.SummaryWriter('/tmp/mnist_logs', tf.Graph.as_graph_def(sess.graph))`
"
178,Installation error,"While running the `sudo bazel build -c opt //tensorflow/tools/pip_package:build_pip_package`, I get the following error:

```
./tensorflow/python/client/tf_session_helper.h:6:10: fatal error: 'numpy/arrayobject.h' file not found
#include ""numpy/arrayobject.h""
         ^
1 error generated.

```

However, I installed numpy from the source listed and it worked perfectly. Any suggestions?
"
177,ImportError: /lib64/libc.so.6: version `GLIBC_2.17',"After the installation of tensorflow(cpu version) via pip command, I just used **import tensorflow as tf** which leads to the following error message

> > > import tensorflow as tf
> > > Traceback (most recent call last):
> > >   File ""<stdin>"", line 1, in <module>
> > >   File ""/home/hpc/pr63so/ga93yih2/anaconda/lib/python2.7/site-packages/tensorflow/**init**.py"", line 4, in <module>
> > >     from tensorflow.python import *
> > >   File ""/home/hpc/pr63so/ga93yih2/anaconda/lib/python2.7/site-packages/tensorflow/python/**init**.py"", line 22, in <module>
> > >     from tensorflow.python.client.client_lib import *
> > >   File ""/home/hpc/pr63so/ga93yih2/anaconda/lib/python2.7/site-packages/tensorflow/python/client/client_lib.py"", line 35, in <module>
> > >     from tensorflow.python.client.session import InteractiveSession
> > >   File ""/home/hpc/pr63so/ga93yih2/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 11, in <module>
> > >     from tensorflow.python import pywrap_tensorflow as tf_session
> > >   File ""/home/hpc/pr63so/ga93yih2/anaconda/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 28, in <module>
> > >     _pywrap_tensorflow = swig_import_helper()
> > >   File ""/home/hpc/pr63so/ga93yih2/anaconda/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 24, in swig_import_helper
> > >     _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)
> > > ImportError: /lib64/libc.so.6: version `GLIBC_2.17' not found (required by /home/hpc/pr63so/ga93yih2/anaconda/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so)
"
176,Split a tensor with Tensor 0-D int32 as num_split argument,"Hi,

According to the doc, th.split takes a 0-D int32 Tensor as num_split argument but executing :

x = tf.placeholder(tf.float32, [5, None])
numsplit = tf.shape(x)[1]
splits = tf.split(1, numsplit, x)

returns :

""Expected int for argument 'num_split' not  < tensorflow.python.framework.ops.Tensor object at 0x7fcad834f810>""

If the dimension is defined split also returns the same error :

x = tf.placeholder(tf.float32, [5, 30])
numsplit = tf.shape(x)[1]
splits = tf.split(1, numsplit, x)

Same thing with a constant as argument:

x = tf.placeholder(tf.float32, [5, 30])
numsplit = tf.constant(30)
splits = tf.split(1, numsplit, x)

Any ideas ?
"
175,einsum-like function?,"Numpy has einsum which is very useful for formulating and computing tensor operations efficiently. Any plans to include an equivalent in tensorflow?
"
174,run from script only instead of compiling with bazel?,"I posted in the google discussion group but I think the turn-over rate is faster here. Hopefully I get a faster response.

In the RNN example tutorial, we're compiling the python script with bazel before executing it, instead of executing the script directory as in the simple MNIST example. Is it possible to do the RNN example purely in python script instead of using bazel? I used a binary installation instead of cloning the repo, so many of the file structures are different. I tried to hack it so I can run it from script instead of compiling with bazel, but I'm getting this error:

```
$ python ptb_word_lm.py --data_path=simple-examples/data --model small
   File ""ptb_word_lm.py"", line 128, in __init__
   self._cost = cost = tf.reduce_sum(loss) / batch_size
   TypeError: unsupported operand type(s) for /: 'Tensor' and 'int'
```

Or is learning bazel the only way (which I don't mind but would like to avoid)? 
"
173,"Unable to restore trained models on the en-fr translate model:  tensorflow.python.framework.errors.NotFoundError: Tensor name ""embedding_attention_seq2seq/RNN/MultiRNNCell/Cell2/GRUCell/Gates/Linear/Matrix"" not found","Hi, when I try the command:

Since ultimately I want to use a model similar to translate for POS tagging, I just copies translate.py to pos.py and trained a model.

`/home/vvkulkarni/bazel/output/bazel run -- //tensorflow/models/rnn/translate:pos --data_dir /data/vivek/pos_tags/ --train_dir /data/vivek/pos_tags/models/ --decode 1`

I get the error:

`File ""/home/vvkulkarni/.cache/bazel/_bazel_vvkulkarni/4fc9a6787896f8b64890985f604431f2/tensorflow/bazel-out/local_linux-fastbuild/bin/tensorfl
ow/models/rnn/translate/pos.runfiles/tensorflow/python/platform/default/_app.py"", line 15, in run
    sys.exit(main(sys.argv))
  File ""/home/vvkulkarni/.cache/bazel/_bazel_vvkulkarni/4fc9a6787896f8b64890985f604431f2/tensorflow/bazel-out/local_linux-fastbuild/bin/tensorfl
ow/models/rnn/translate/pos.runfiles/tensorflow/models/rnn/translate/pos.py"", line 262, in main
    decode()
  File ""/home/vvkulkarni/.cache/bazel/_bazel_vvkulkarni/4fc9a6787896f8b64890985f604431f2/tensorflow/bazel-out/local_linux-fastbuild/bin/tensorfl
ow/models/rnn/translate/pos.runfiles/tensorflow/models/rnn/translate/pos.py"", line 196, in decode
    model = create_model(sess, True)
  File ""/home/vvkulkarni/.cache/bazel/_bazel_vvkulkarni/4fc9a6787896f8b64890985f604431f2/tensorflow/bazel-out/local_linux-fastbuild/bin/tensorfl
ow/models/rnn/translate/pos.runfiles/tensorflow/models/rnn/translate/pos.py"", line 112, in create_model
    model.saver.restore(session, ""/data/vivek/pos_tags/models/translate.ckpt-13450"")
  File ""/home/vvkulkarni/.cache/bazel/_bazel_vvkulkarni/4fc9a6787896f8b64890985f604431f2/tensorflow/bazel-out/local_linux-fastbuild/bin/tensorfl
ow/models/rnn/translate/pos.runfiles/tensorflow/python/training/saver.py"", line 867, in restore
    sess.run([self._restore_op_name], {self._filename_tensor_name: save_path})
  File ""/home/vvkulkarni/.cache/bazel/_bazel_vvkulkarni/4fc9a6787896f8b64890985f604431f2/tensorflow/bazel-out/local_linux-fastbuild/bin/tensorfl
ow/models/rnn/translate/pos.runfiles/tensorflow/python/client/session.py"", line 349, in run
    results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)
  File ""/home/vvkulkarni/.cache/bazel/_bazel_vvkulkarni/4fc9a6787896f8b64890985f604431f2/tensorflow/bazel-out/local_linux-fastbuild/bin/tensorfl
ow/models/rnn/translate/pos.runfiles/tensorflow/python/client/session.py"", line 423, in _do_run
    e.code)
tensorflow.python.framework.errors.NotFoundError: Tensor name ""embedding_attention_seq2seq/RNN/MultiRNNCell/Cell2/GRUCell/Gates/Linear/Matrix"" n
ot found in checkpoint files /data/vivek/pos_tags/models/translate.ckpt-13450
         [[Node: save/restore_slice_14 = RestoreSlice[dt=DT_FLOAT, preferred_shard=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""](_recv_sa
ve/Const_0, save/restore_slice_14/tensor_name, save/restore_slice_14/shape_and_slice)]]
Caused by op u'save/restore_slice_14', defined at`
"
