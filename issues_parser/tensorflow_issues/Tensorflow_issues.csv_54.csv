Issue Number,Issue Title,Issue Body
18514,Build error from source,"I encountered an error while building from source.some system infomation as follows:
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution**: Ubuntu 16.04(x64)
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.7.0
- **Python version**: 3.5
- **Bazel version (if compiling from source)**: 0.10
- **GCC/Compiler version (if compiling from source)**: 4.8
- **CUDA/cuDNN version**: 9.0/7.1
- **GPU model and memory**: Tesla K80
- **Exact command to reproduce**: bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package

### Source code / logs
WARNING: /home/zhangzw/.cache/bazel/_bazel_root/0b0b28318d2a7ef283e46c49f1b108b6/external/protobuf_archive/WORKSPACE:1: Workspace name in /home/zhangzw/.cache/bazel/_bazel_root/0b0b28318d2a7ef283e46c49f1b108b6/external/protobuf_archive/WORKSPACE (@com_google_protobuf) does not match the name given in the repository's definition (@protobuf_archive); this will cause a build error in future versions
WARNING: /home/zhangzw/.cache/bazel/_bazel_root/0b0b28318d2a7ef283e46c49f1b108b6/external/grpc/WORKSPACE:1: Workspace name in /home/zhangzw/.cache/bazel/_bazel_root/0b0b28318d2a7ef283e46c49f1b108b6/external/grpc/WORKSPACE (@com_github_grpc_grpc) does not match the name given in the repository's definition (@grpc); this will cause a build error in future versions
WARNING: /home/zhangzw/.cache/bazel/_bazel_root/0b0b28318d2a7ef283e46c49f1b108b6/external/grpc/BUILD:1943:1: in srcs attribute of cc_library rule @grpc//:grpc_nanopb: please do not import '@grpc//third_party/nanopb:pb_common.c' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'grpc_generate_one_off_targets', the error might have been caused by the macro implementation in /home/zhangzw/.cache/bazel/_bazel_root/0b0b28318d2a7ef283e46c49f1b108b6/external/grpc/bazel/grpc_build_system.bzl:172:12
WARNING: /home/zhangzw/.cache/bazel/_bazel_root/0b0b28318d2a7ef283e46c49f1b108b6/external/grpc/BUILD:1943:1: in srcs attribute of cc_library rule @grpc//:grpc_nanopb: please do not import '@grpc//third_party/nanopb:pb_decode.c' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'grpc_generate_one_off_targets', the error might have been caused by the macro implementation in /home/zhangzw/.cache/bazel/_bazel_root/0b0b28318d2a7ef283e46c49f1b108b6/external/grpc/bazel/grpc_build_system.bzl:172:12
WARNING: /home/zhangzw/.cache/bazel/_bazel_root/0b0b28318d2a7ef283e46c49f1b108b6/external/grpc/BUILD:1943:1: in srcs attribute of cc_library rule @grpc//:grpc_nanopb: please do not import '@grpc//third_party/nanopb:pb_encode.c' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'grpc_generate_one_off_targets', the error might have been caused by the macro implementation in /home/zhangzw/.cache/bazel/_bazel_root/0b0b28318d2a7ef283e46c49f1b108b6/external/grpc/bazel/grpc_build_system.bzl:172:12
WARNING: /home/zhangzw/tensorflow-1.8.0-rc0/tensorflow/contrib/learn/BUILD:17:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': No longer supported. Switch to SavedModel immediately.
WARNING: /home/zhangzw/tensorflow-1.8.0-rc0/tensorflow/contrib/learn/BUILD:17:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': No longer supported. Switch to SavedModel immediately.
...
collect2: error: ld returned 1 exit status
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 288.567s, Critical Path: 58.33s
FAILED: Build did NOT complete successfully"
18512,NoOp replacement in DependencyOptimizer misses some control dependency conversions,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Debian testing (buster)
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
('v1.7.0-3-g024aecf414', '1.7.0')
- **Python version**: 
2.7.14
- **Bazel version (if compiling from source)**:
N/A
- **GCC/Compiler version (if compiling from source)**:
N/A
- **CUDA/cuDNN version**:
N/A
- **GPU model and memory**:
N/A
- **Exact command to reproduce**:
Run Python code below with environment variable `TF_CPP_MIN_VLOG_LEVEL=1`

### Describe the problem
When `DependencyOptimizer::OptimizeNode()` converts a node to a NoOp, it only converts the first input from each input node to a control dependencies. Multiple inputs from the same node can cause a NoOp to be created with non-control inputs. In the VLOG output below, the IdentityN node has inputs ""^Placeholder"" and ""Placeholder"". I haven't tried it but perhaps when [this condition](https://github.com/tensorflow/tensorflow/blob/92e6c3e4f5c1cabfda1e61547a6a1b268ef95fa5/tensorflow/core/grappler/optimizers/dependency_optimizer.cc#L214) is false, the input should be deleted (like in the [control input case](https://github.com/tensorflow/tensorflow/blob/92e6c3e4f5c1cabfda1e61547a6a1b268ef95fa5/tensorflow/core/grappler/optimizers/dependency_optimizer.cc#L204)). Note that the bad NoOp gets deleted in the small example here (because that was the easiest way to display the problem) but the real code I was running, the NoOp remains in the graph to cause trouble later.

This bug is pretty sneaky: a NoOp with non-control inputs can cause `GraphConstructor` methods to fail, which in turn (silently!) prevents graph optimization ([see here](https://github.com/tensorflow/tensorflow/blob/92e6c3e4f5c1cabfda1e61547a6a1b268ef95fa5/tensorflow/core/common_runtime/graph_execution_state.cc#L396)). The fallback original graph runs fine. I only went investigating because I saw output like this:

```
2018-04-12 13:09:26.465603: E tensorflow/core/framework/types.cc:102] Unrecognized DataType enum value 425390044
```

The cause was an error message from `GraphConstructor::MakeEdge()`, called [here](https://github.com/tensorflow/tensorflow/blob/92e6c3e4f5c1cabfda1e61547a6a1b268ef95fa5/tensorflow/core/graph/graph_constructor.cc#L1008). It appears `node` and `node_def` did not agree on how many inputs there were to the node! `node` thought zero, which is where that strange DataType enum value came from: reading uninitialized memory [here](https://github.com/tensorflow/tensorflow/blob/92e6c3e4f5c1cabfda1e61547a6a1b268ef95fa5/tensorflow/core/graph/graph_constructor.cc#L1156). I wasn't able to reproduce that exact failure in a tiny example; I believe the example here causes optimization to fail [here](https://github.com/tensorflow/tensorflow/blob/92e6c3e4f5c1cabfda1e61547a6a1b268ef95fa5/tensorflow/core/graph/graph_constructor.cc#L442).

It would also be nice to see a warning when graph optimization fails.

### Source code / logs

#### Code to reproduce the problem
```python
import tensorflow as tf

with tf.device('/cpu:0'):
    x = tf.placeholder(dtype=tf.int32, shape=[])
    id2 = tf.identity_n([x, x])
    with tf.control_dependencies(id2):
        y = x + 1

with tf.Session() as sess:
    print sess.run(y, feed_dict={x: 5})
```

#### Relevant log output
```
2018-04-13 15:58:27.870639: I tensorflow/core/grappler/optimizers/dependency_optimizer.cc:194] ***** Replacing  IdentityN (IdentityN) with NoOp.
2018-04-13 15:58:27.870678: I tensorflow/core/grappler/optimizers/dependency_optimizer.cc:332] ***** Rerouting input around
name: ""IdentityN""
op: ""NoOp""
input: ""^Placeholder""
input: ""Placeholder""
device: ""/job:localhost/replica:0/task:0/device:CPU:0""
```"
18506,Error when building Tensorflow-GPU from source on windows,"
------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
 No.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 8.1
- **TensorFlow installed from (source or binary)**:
Source
- **TensorFlow version (use command below)**:
r1.7
- **Python version**: 
3.5
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
9.0
- **GPU model and memory**:
NVIDIA Geforce GT 740M
- **Exact command to reproduce**:
First cmake works fine with:

> 
> cmake .. -A x64  -DCMAKE_BUILD_TYPE=Release ^
> -DSWIG_EXECUTABLE=C:/swigwin-3.0.12/swig.exe  ^
> -DPYTHON_EXECUTABLE=C:/Users/M/Anaconda3/python.exe  ^
> -DPYTHON_LIBRARIES=C:/Users/M/Anaconda3/libs/python35.lib  ^
> -Dtensorflow_ENABLE_GPU=ON  ^
> -DCUDNN_HOME=""C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0""  ^
> -DCUDA_HOST_COMPILER=""C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\bin\cl.exe"" 

But when I try to build it using

> ""C:/Program Files (x86)/Microsoft Visual Studio/2017/Community/MSBuild/15.0/Bin/MSBuild.exe"" 
> /p:Configuration=Release tf_tutorials_example_trainer.vcxproj

the errors appear (I'm not really familiar with C++, MSBuild , so pardon my naivity)


### Describe the problem
When building tensorflow using above command I get a lot of syntax errors and the process fails.

### Source code / logs
(Logs are in german, but they are basically warning about missing semicolons,brackets etc.)
An excerpt:

>  ""C:\tesnorflow_build\tensorflow\tensorflow\contrib\cmake\build\ALL_BUILD
>  .vcxproj"" (Standardziel) (1) ->
>  ""C:\tesnorflow_build\tensorflow\tensorflow\contrib\cmake\build\_beam_sea
>  rch_ops.vcxproj"" (Standardziel) (2) ->
>  ""C:\tesnorflow_build\tensorflow\tensorflow\contrib\cmake\build\pywrap_te
>  nsorflow_internal.vcxproj"" (Standardziel) (3) ->
>  ""C:\tesnorflow_build\tensorflow\tensorflow\contrib\cmake\build\pywrap_te
>  nsorflow_internal_static.vcxproj"" (Standardziel) (4) ->
>  ""C:\tesnorflow_build\tensorflow\tensorflow\contrib\cmake\build\tf_c.vcxp
>  roj"" (Standardziel) (6) ->
>  ""C:\tesnorflow_build\tensorflow\tensorflow\contrib\cmake\build\tf_cc_fra
>  mework.vcxproj"" (Standardziel) (7) ->
>  ""C:\tesnorflow_build\tensorflow\tensorflow\contrib\cmake\build\tf_core_f
>  ramework.vcxproj"" (Standardziel) (9) ->
>  ""C:\tesnorflow_build\tensorflow\tensorflow\contrib\cmake\build\proto_tex
>  t.vcxproj"" (Standardziel) (10) ->
>  ""C:\tesnorflow_build\tensorflow\tensorflow\contrib\cmake\build\grpc.vcxp
>  roj"" (Standardziel) (11) ->
>  (CustomBuild Ziel) ->
>    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\iphlpap
>  i.h(508): error C2146: Syntaxfehler: Fehlendes "")"" vor Bezeichner ""Stati
>  stics"" [C:\tesnorflow_build\tensorflow\tensorflow\contrib\cmake\build\gr
>  pc\src\grpc\third_party\cares\cares\c-ares.vcxproj] [C:\tesnorflow_build
>  \tensorflow\tensorflow\contrib\cmake\build\grpc.vcxproj]
>    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\iphlpap
>  i.h(508): error C2061: Syntaxfehler: Bezeichner ""Statistics"" [C:\tesnorf
>  low_build\tensorflow\tensorflow\contrib\cmake\build\grpc\src\grpc\third_
>  party\cares\cares\c-ares.vcxproj] [C:\tesnorflow_build\tensorflow\tensor
>  flow\contrib\cmake\build\grpc.vcxproj]
>    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\iphlpap
>  i.h(508): error C2059: Syntaxfehler: "";"" [C:\tesnorflow_build\tensorflow
>  \tensorflow\contrib\cmake\build\grpc\src\grpc\third_party\cares\cares\c-
>  ares.vcxproj] [C:\tesnorflow_build\tensorflow\tensorflow\contrib\cmake\b
>  uild\grpc.vcxproj]
>    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\iphlpap
>  i.h(508): error C2059: Syntaxfehler: "","" [C:\tesnorflow_build\tensorflow
>  \tensorflow\contrib\cmake\build\grpc\src\grpc\third_party\cares\cares\c-
>  ares.vcxproj] [C:\tesnorflow_build\tensorflow\tensorflow\contrib\cmake\b
>  uild\grpc.vcxproj]
>    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\iphlpap
>  i.h(510): error C2059: Syntaxfehler: "")"" [C:\tesnorflow_build\tensorflow
>  \tensorflow\contrib\cmake\build\grpc\src\grpc\third_party\cares\cares\c-
>  ares.vcxproj] [C:\tesnorflow_build\tensorflow\tensorflow\contrib\cmake\b
>  uild\grpc.vcxproj]
>    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\iphlpap
>  i.h(515): error C2146: Syntaxfehler: Fehlendes "")"" vor Bezeichner ""Stati
>  stics"" [C:\tesnorflow_build\tensorflow\tensorflow\contrib\cmake\build\gr
>  pc\src\grpc\third_party\cares\cares\c-ares.vcxproj] [C:\tesnorflow_build
>  \tensorflow\tensorflow\contrib\cmake\build\grpc.vcxproj]
>    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\iphlpap
>  i.h(515): error C2061: Syntaxfehler: Bezeichner ""Statistics"" [C:\tesnorf
>  low_build\tensorflow\tensorflow\contrib\cmake\build\grpc\src\grpc\third_
>  party\cares\cares\c-ares.vcxproj] [C:\tesnorflow_build\tensorflow\tensor
>  flow\contrib\cmake\build\grpc.vcxproj]
>    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\iphlpap
>  i.h(515): error C2059: Syntaxfehler: "";"" [C:\tesnorflow_build\tensorflow
>  \tensorflow\contrib\cmake\build\grpc\src\grpc\third_party\cares\cares\c-
>  ares.vcxproj] [C:\tesnorflow_build\tensorflow\tensorflow\contrib\cmake\b
>  uild\grpc.vcxproj]
>    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\iphlpap
>  i.h(515): error C2059: Syntaxfehler: "","" [C:\tesnorflow_build\tensorflow
>  \tensorflow\contrib\cmake\build\grpc\src\grpc\third_party\cares\cares\c-
>  ares.vcxproj] [C:\tesnorflow_build\tensorflow\tensorflow\contrib\cmake\b
>  uild\grpc.vcxproj]
>    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\iphlpap
>  i.h(517): error C2059: Syntaxfehler: "")"" [C:\tesnorflow_build\tensorflow
>  \tensorflow\contrib\cmake\build\grpc\src\grpc\third_party\cares\cares\c-
>  ares.vcxproj] [C:\tesnorflow_build\tensorflow\tensorflow\contrib\cmake\b
>  uild\grpc.vcxproj]
>    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\iphlpap
>  i.h(508): error C2146: Syntaxfehler: Fehlendes "")"" vor Bezeichner ""Stati
>  stics"" [C:\tesnorflow_build\tensorflow\tensorflow\contrib\cmake\build\gr
>  pc\src\grpc\third_party\cares\cares\c-ares.vcxproj] [C:\tesnorflow_build
>  \tensorflow\tensorflow\contrib\cmake\build\grpc.vcxproj]
>    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\iphlpap
>  i.h(508): error C2061: Syntaxfehler: Bezeichner ""Statistics"" [C:\tesnorf
>  low_build\tensorflow\tensorflow\contrib\cmake\build\grpc\src\grpc\third_
>  party\cares\cares\c-ares.vcxproj] [C:\tesnorflow_build\tensorflow\tensor
>  flow\contrib\cmake\build\grpc.vcxproj]
>    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\iphlpap
>  i.h(508): error C2059: Syntaxfehler: "";"" [C:\tesnorflow_build\tensorflow
>  \tensorflow\contrib\cmake\build\grpc\src\grpc\third_party\cares\cares\c-
>  ares.vcxproj] [C:\tesnorflow_build\tensorflow\tensorflow\contrib\cmake\b
>  uild\grpc.vcxproj]
>    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\iphlpap
>  i.h(508): error C2059: Syntaxfehler: "","" [C:\tesnorflow_build\tensorflow
>  \tensorflow\contrib\cmake\build\grpc\src\grpc\third_party\cares\cares\c-
>  ares.vcxproj] [C:\tesnorflow_build\tensorflow\tensorflow\contrib\cmake\b
>  uild\grpc.vcxproj]
>    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\iphlpap
>  i.h(510): error C2059: Syntaxfehler: "")"" [C:\tesnorflow_build\tensorflow
>  \tensorflow\contrib\cmake\build\grpc\src\grpc\third_party\cares\cares\c-
>  ares.vcxproj] [C:\tesnorflow_build\tensorflow\tensorflow\contrib\cmake\b
>  uild\grpc.vcxproj]
>    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\iphlpap
>  i.h(515): error C2146: Syntaxfehler: Fehlendes "")"" vor Bezeichner ""Stati
>  stics"" [C:\tesnorflow_build\tensorflow\tensorflow\contrib\cmake\build\gr
>  pc\src\grpc\third_party\cares\cares\c-ares.vcxproj] [C:\tesnorflow_build
>  \tensorflow\tensorflow\contrib\cmake\build\grpc.vcxproj]
>    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\iphlpap
>  i.h(515): error C2061: Syntaxfehler: Bezeichner ""Statistics"" [C:\tesnorf
>  low_build\tensorflow\tensorflow\contrib\cmake\build\grpc\src\grpc\third_
>  party\cares\cares\c-ares.vcxproj] [C:\tesnorflow_build\tensorflow\tensor
>  flow\contrib\cmake\build\grpc.vcxproj]
>    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\iphlpap
>  i.h(515): error C2059: Syntaxfehler: "";"" [C:\tesnorflow_build\tensorflow
>  \tensorflow\contrib\cmake\build\grpc\src\grpc\third_party\cares\cares\c-
>  ares.vcxproj] [C:\tesnorflow_build\tensorflow\tensorflow\contrib\cmake\b
>  uild\grpc.vcxproj]
>    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\iphlpap
>  i.h(515): error C2059: Syntaxfehler: "","" [C:\tesnorflow_build\tensorflow
>  \tensorflow\contrib\cmake\build\grpc\src\grpc\third_party\cares\cares\c-
>  ares.vcxproj] [C:\tesnorflow_build\tensorflow\tensorflow\contrib\cmake\b
>  uild\grpc.vcxproj]
>    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\iphlpap
>  i.h(517): error C2059: Syntaxfehler: "")"" [C:\tesnorflow_build\tensorflow
>  \tensorflow\contrib\cmake\build\grpc\src\grpc\third_party\cares\cares\c-
>  ares.vcxproj] [C:\tesnorflow_build\tensorflow\tensorflow\contrib\cmake\b
>  uild\grpc.vcxproj]
>    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\iphlpap
>  i.h(508): error C2146: Syntaxfehler: Fehlendes "")"" vor Bezeichner ""Stati
>  stics"" [C:\tesnorflow_build\tensorflow\tensorflow\contrib\cmake\build\gr
>  pc\src\grpc\third_party\cares\cares\c-ares.vcxproj] [C:\tesnorflow_build
>  \tensorflow\tensorflow\contrib\cmake\build\grpc.vcxproj]
>    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\iphlpap
>  i.h(508): error C2061: Syntaxfehler: Bezeichner ""Statistics"" [C:\tesnorf
>  low_build\tensorflow\tensorflow\contrib\cmake\build\grpc\src\grpc\third_
>  party\cares\cares\c-ares.vcxproj] [C:\tesnorflow_build\tensorflow\tensor
>  flow\contrib\cmake\build\grpc.vcxproj]
>    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\iphlpap
>  i.h(508): error C2059: Syntaxfehler: "";"" [C:\tesnorflow_build\tensorflow
>  \tensorflow\contrib\cmake\build\grpc\src\grpc\third_party\cares\cares\c-
>  ares.vcxproj] [C:\tesnorflow_build\tensorflow\tensorflow\contrib\cmake\b
>  uild\grpc.vcxproj]
>    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\iphlpap
>  i.h(508): error C2059: Syntaxfehler: "","" [C:\tesnorflow_build\tensorflow
>  \tensorflow\contrib\cmake\build\grpc\src\grpc\third_party\cares\cares\c-
>  ares.vcxproj] [C:\tesnorflow_build\tensorflow\tensorflow\contrib\cmake\b
>  uild\grpc.vcxproj]
>    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\iphlpap
>  i.h(510): error C2059: Syntaxfehler: "")"" [C:\tesnorflow_build\tensorflow
>  \tensorflow\contrib\cmake\build\grpc\src\grpc\third_party\cares\cares\c-
>  ares.vcxproj] [C:\tesnorflow_build\tensorflow\tensorflow\contrib\cmake\b
>  uild\grpc.vcxproj]
>    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\iphlpap
>  i.h(515): error C2146: Syntaxfehler: Fehlendes "")"" vor Bezeichner ""Stati
>  stics"" [C:\tesnorflow_build\tensorflow\tensorflow\contrib\cmake\build\gr
>  pc\src\grpc\third_party\cares\cares\c-ares.vcxproj] [C:\tesnorflow_build
>  \tensorflow\tensorflow\contrib\cmake\build\grpc.vcxproj]
>    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\iphlpap
>  i.h(515): error C2061: Syntaxfehler: Bezeichner ""Statistics"" [C:\tesnorf
>  low_build\tensorflow\tensorflow\contrib\cmake\build\grpc\src\grpc\third_
>  party\cares\cares\c-ares.vcxproj] [C:\tesnorflow_build\tensorflow\tensor
>  flow\contrib\cmake\build\grpc.vcxproj]
>    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\iphlpap
>  i.h(515): error C2059: Syntaxfehler: "";"" [C:\tesnorflow_build\tensorflow
>  \tensorflow\contrib\cmake\build\grpc\src\grpc\third_party\cares\cares\c-
>  ares.vcxproj] [C:\tesnorflow_build\tensorflow\tensorflow\contrib\cmake\b
>  uild\grpc.vcxproj]
>    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\iphlpap
>  i.h(515): error C2059: Syntaxfehler: "","" [C:\tesnorflow_build\tensorflow
>  \tensorflow\contrib\cmake\build\grpc\src\grpc\third_party\cares\cares\c-
>  ares.vcxproj] [C:\tesnorflow_build\tensorflow\tensorflow\contrib\cmake\b
>  uild\grpc.vcxproj]
>    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\iphlpap
>  i.h(517): error C2059: Syntaxfehler: "")"" [C:\tesnorflow_build\tensorflow
>  \tensorflow\contrib\cmake\build\grpc\src\grpc\third_party\cares\cares\c-
>  ares.vcxproj] [C:\tesnorflow_build\tensorflow\tensorflow\contrib\cmake\b
>  uild\grpc.vcxproj]
>    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\iphlpap
>  i.h(508): error C2146: Syntaxfehler: Fehlendes "")"" vor Bezeichner ""Stati
>  stics"" [C:\tesnorflow_build\tensorflow\tensorflow\contrib\cmake\build\gr
>  pc\src\grpc\third_party\cares\cares\c-ares.vcxproj] [C:\tesnorflow_build
>  \tensorflow\tensorflow\contrib\cmake\build\grpc.vcxproj]
>    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\iphlpap
>  i.h(508): error C2061: Syntaxfehler: Bezeichner ""Statistics"" [C:\tesnorf
>  low_build\tensorflow\tensorflow\contrib\cmake\build\grpc\src\grpc\third_
>  party\cares\cares\c-ares.vcxproj] [C:\tesnorflow_build\tensorflow\tensor
>  flow\contrib\cmake\build\grpc.vcxproj]
>    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\iphlpap
>  i.h(508): error C2059: Syntaxfehler: "";"" [C:\tesnorflow_build\tensorflow
>  \tensorflow\contrib\cmake\build\grpc\src\grpc\third_party\cares\cares\c-
>  ares.vcxproj] [C:\tesnorflow_build\tensorflow\tensorflow\contrib\cmake\b
>  uild\grpc.vcxproj]
>    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\iphlpap
>  i.h(508): error C2059: Syntaxfehler: "","" [C:\tesnorflow_build\tensorflow
>  \tensorflow\contrib\cmake\build\grpc\src\grpc\third_party\cares\cares\c-
>  ares.vcxproj] [C:\tesnorflow_build\tensorflow\tensorflow\contrib\cmake\b
>  uild\grpc.vcxproj]
>    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\iphlpap
>  i.h(510): error C2059: Syntaxfehler: "")"" [C:\tesnorflow_build\tensorflow
>  \tensorflow\contrib\cmake\build\grpc\src\grpc\third_party\cares\cares\c-
>  ares.vcxproj] [C:\tesnorflow_build\tensorflow\tensorflow\contrib\cmake\b
>  uild\grpc.vcxproj]
>    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\iphlpap
>  i.h(515): error C2146: Syntaxfehler: Fehlendes "")"" vor Bezeichner ""Stati
>  stics"" [C:\tesnorflow_build\tensorflow\tensorflow\contrib\cmake\build\gr
>  pc\src\grpc\third_party\cares\cares\c-ares.vcxproj] [C:\tesnorflow_build
>  \tensorflow\tensorflow\contrib\cmake\build\grpc.vcxproj]
>    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\iphlpap
>  i.h(515): error C2061: Syntaxfehler: Bezeichner ""Statistics"" [C:\tesnorf
>  low_build\tensorflow\tensorflow\contrib\cmake\build\grpc\src\grpc\third_
>  party\cares\cares\c-ares.vcxproj] [C:\tesnorflow_build\tensorflow\tensor
>  flow\contrib\cmake\build\grpc.vcxproj]
>    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\iphlpap
>  i.h(515): error C2059: Syntaxfehler: "";"" [C:\tesnorflow_build\tensorflow
>  \tensorflow\contrib\cmake\build\grpc\src\grpc\third_party\cares\cares\c-
>  ares.vcxproj] [C:\tesnorflow_build\tensorflow\tensorflow\contrib\cmake\b
>  uild\grpc.vcxproj]
>    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\iphlpap
>  i.h(515): error C2059: Syntaxfehler: "","" [C:\tesnorflow_build\tensorflow
>  \tensorflow\contrib\cmake\build\grpc\src\grpc\third_party\cares\cares\c-
>  ares.vcxproj] [C:\tesnorflow_build\tensorflow\tensorflow\contrib\cmake\b
>  uild\grpc.vcxproj]
>    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\iphlpap
>  i.h(517): error C2059: Syntaxfehler: "")"" [C:\tesnorflow_build\tensorflow
>  \tensorflow\contrib\cmake\build\grpc\src\grpc\third_party\cares\cares\c-
>  ares.vcxproj] [C:\tesnorflow_build\tensorflow\tensorflow\contrib\cmake\b
>  uild\grpc.vcxproj]
"
18503,[Install] Failed to load the native TensorFlow runtime.,"### System information
- **Have I written custom code**: Yes
- **OS Platform and Distribution**: windows 8.1 x64
- **TensorFlow installed from**: have no idea, I suppose binary
- **TensorFlow version**: 1.7
- **Python version**: 3.6.5
- **Bazel version**: ???
- **GCC/Compiler version**: ?
- **CUDA/cuDNN version**: cuDNN 7.0 for CUDA 9.0
- **GPU model and memory**: tensorflow-gpu, NVIDIA 4GHZ dualcore, 8GB RAM
- **Exact command to reproduce**: `python test.py`

### Describe the problem

I downloaded tensorflow and installed everything properly and getting error (click on it to expand):

<details>
<summary>
Error
</summary>

```console
Traceback (most recent call last):
  File ""C:\Users\abcdef\AppData\Local\Programs\Python\Python36\lib\site-packages
\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\abcdef\AppData\Local\Programs\Python\Python36\lib\site-packages
\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\abcdef\AppData\Local\Programs\Python\Python36\lib\site-packages
\tensorflow\python\pywrap_tensorflow_internal.py"", line 17, in swig_import_helpe
r
    return importlib.import_module(mname)
  File ""C:\Users\abcdef\AppData\Local\Programs\Python\Python36\lib\importlib\__i
nit__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: DLL load failed: A dynamic link library (DLL) initialization routin
e failed.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""main.py"", line 1, in <module>
    import tensorflow as tf
  File ""C:\Users\abcdef\AppData\Local\Programs\Python\Python36\lib\site-packages
\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import *  # pylint: disable=redefined-builtin
  File ""C:\Users\abcdef\AppData\Local\Programs\Python\Python36\lib\site-packages
\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\abcdef\AppData\Local\Programs\Python\Python36\lib\site-packages
\tensorflow\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\abcdef\AppData\Local\Programs\Python\Python36\lib\site-packages
\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\abcdef\AppData\Local\Programs\Python\Python36\lib\site-packages
\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\abcdef\AppData\Local\Programs\Python\Python36\lib\site-packages
\tensorflow\python\pywrap_tensorflow_internal.py"", line 17, in swig_import_helpe
r
    return importlib.import_module(mname)
  File ""C:\Users\abcdef\AppData\Local\Programs\Python\Python36\lib\importlib\__i
nit__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: DLL load failed: A dynamic link library (DLL) initialization routin
e failed.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_probl
ems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
```

</details><br/>

Asked on stack overflow and they suggested me to report an issue here because they dont know the answer. I also was thinking that I did something wrong, but maybe there is a bug somewhere. I installed everything needed, including cuda, cudnn, python latest, pip and I used pip to install tensorflow gpu

### Source code

```python
import tensorflow as tf
hello = tf.constant('Hello, TensorFlow!')
sess = tf.Session()
print(sess.run(hello))
```

### Edit

Here is my `%PATH%` environment variable:

<details>
<summary>
Path
</summary>

```console
C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\bin;C:\Program Files\NVI
DIA GPU Computing Toolkit\CUDA\v9.0\libnvvp;C:\Program Files (x86)\Common Files\
Intel\Shared Files\cpp\bin\Intel64;C:\Windows;C:\Windows\System32\Wbem;C:\Window
s\System32\WindowsPowerShell\v1.0;C:\Program Files (x86)\ATI Technologies\ATI.AC
E\Core-Static;C:\Program Files (x86)\Windows Kits\10\Windows Performance Toolkit
;C:\MinGW\bin;C:\Program Files (x86)\Windows Kits\8.0\Windows Performance Toolki
t;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Makefi
le;C:\windows\system32;C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC;C:
\Users\abcdef\AppData\Local\Programs\Python\Python36\Scripts;C:\Users\abcdef\App
Data\Local\Programs\Python\Python36;C:\Program Files (x86)\Microsoft Visual Stud
io\2017\Enterprise\VC\Tools\MSVC\14.10.25017\bin\HostX64\x64
```
</details>"
18496,Issue with Colab Pytnotebook and Tensorflow hub,"I was trying the Colab example with Tensorflow hub [here](https://www.tensorflow.org/tutorials/text_classification_with_tf_hub)

```
# Install the latest Tensorflow version.
!pip install --quiet --upgrade --pre tensorflow
# Install TF-Hub.
!pip install tensorflow-hub
!pip install tf-nightly
```

to have the nightly build, but when I try to install

```python
import tensorflow as tf
import tensorflow_hub as hub
import matplotlib.pyplot as plt
import numpy as np
import os
import pandas as pd
import re
import seaborn as sns
```

I get this version error

```
RuntimeErrorTraceback (most recent call last)
<ipython-input-6-48e1bdaa8642> in <module>()
      1 import tensorflow as tf
----> 2 import tensorflow_hub as hub
      3 import matplotlib.pyplot as plt
      4 import numpy as np
      5 import os

/usr/local/lib/python2.7/dist-packages/tensorflow_hub/__init__.py in <module>()
     63 
     64 # Comment/uncomment to skip checking the TensorFlow version.
---> 65 _check_tensorflow_version(tf.VERSION)
     66 
     67 # Used by doc generation script.

/usr/local/lib/python2.7/dist-packages/tensorflow_hub/__init__.py in _check_tensorflow_version(version)
     60       ""TensorFlow Hub depends on 'tf-nightly' build after %s or ""
     61       ""'tensorflow~=%s'. Found tf.VERSION = %s"" % (
---> 62           _NIGHTLY_VERSION, _MAIN_VERSION, version))
     63 
     64 # Comment/uncomment to skip checking the TensorFlow version.

RuntimeError: TensorFlow Hub depends on 'tf-nightly' build after 20180308 or 'tensorflow~=1.7'. Found tf.VERSION = 1.6.0
```

But I have already installed

```
Collecting tf-nightly
  Downloading tf_nightly-1.8.0.dev20180331-cp36-cp36m-manylinux1_x86_64.whl (48.6MB)
    100% |████████████████████████████████| 48.6MB 28kB/s 
Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly)
Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly)
Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tf-nightly)
Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly)
Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly)
Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly)
Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly)
Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tf-nightly)
Collecting tb-nightly<1.9.0a0,>=1.8.0a0 (from tf-nightly)
  Downloading tb_nightly-1.8.0a20180409-py3-none-any.whl (3.1MB)
    100% |████████████████████████████████| 3.1MB 382kB/s 
Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly)
Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tf-nightly)
Requirement already satisfied: html5lib==0.9999999 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.9.0a0,>=1.8.0a0->tf-nightly)
Requirement already satisfied: bleach==1.5.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.9.0a0,>=1.8.0a0->tf-nightly)
Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.9.0a0,>=1.8.0a0->tf-nightly)
Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.9.0a0,>=1.8.0a0->tf-nightly)
Installing collected packages: tb-nightly, tf-nightly
Successfully installed tb-nightly-1.8.0a20180409 tf-nightly-1.8.0.dev20180331
```


"
18493,Tensorflow js returns NAN on large data set ,"
<html>
--
  | <head>
  | <!-- Load TensorFlow.js -->
  | <script src=""https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@0.9.0""> </script>
  |  
  | <!-- Place your code in the script tag below. You can also use an external .js file -->
  | <script>
  | <!--var x=[];-->
  | <!--var y=[];-->
  | <!--for(var i=1;i<=100;i++){-->
  | <!--x.push(i);-->
  | <!--x.push(i+2);-->
  | <!--}-->
  | const model = tf.sequential();
  | model.add(tf.layers.dense({units: 1, inputShape: [1]}));
  | model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});
  | const xs = tf.tensor2d([1, 2, 3, 4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24], [24, 1]);
  | const ys = tf.tensor2d([3, 4, 5, 6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26], [24, 1]);
  | model.fit(xs, ys).then(() => {
  | model.predict(tf.tensor2d([11], [1, 1])).print();
  | });
  | </script>
  | </head>
  |  
  | <body>
  | </body>
  | </html>

"
18492,"Worker is failing with InvalidArgumentError>, ""A session is not created yet""","System information
------------------

 - Have I written custom code - Yes
 - OS Platform CentOS - 7.2.1511
 - TensorFlow installed from - Binary
 - TensorFlow version - 1.3.0
 - Python version - 2.7
 - Bazel version - N/A
 - CUDA/cuDNN version - N/A
 - GPU model and memory - N/A

Source Code
-----------
Sharing my code snippet below,

    cluster = tf.train.ClusterSpec({""ps"": parameter_servers, ""worker"": workers})
    
    server = tf.train.Server(
        cluster,
        job_name=FLAGS.job_name,
        task_index=FLAGS.task_index)
       
    if FLAGS.pipeline_id is None:
        raise ValueError('pipeline_id [%s] was not recognized', FLAGS.pipeline_id)
    
    #print('job name '+FLAGS.job_name)
    #print('task index name ' + FLAGS.task_index)
    if FLAGS.job_name == ""ps"":
        server.join()
    elif FLAGS.job_name == ""worker"":
        print('only for worker')
        # if not os.path.exists(FLAGS.train_dir):
        #    os.mkdir(FLAGS.train_dir)
        train_logs_path = FLAGS.logs_dir + '/' + FLAGS.pipeline_id + '/training'
        eval_logs_path = FLAGS.logs_dir + '/' + FLAGS.pipeline_id + '/eval'
        print 'Train logs path -- ', train_logs_path
        print 'Eval logs path -- ', eval_logs_path
    
        tf.logging.set_verbosity(tf.logging.INFO)  # Set the verbosity to INFO level
    
        # First create the dataset and load one batch
    
        ##
        ## replace flowers with FLAGS.pipeline_id in get_split()
        ##
        ##
        labels_file = FLAGS.tf_records_dir + '/labels.txt'
    
        dataset = get_split(FLAGS.dataset_split_name, FLAGS.tf_records_dir, 'flowers', FLAGS.num_classes, labels_file)
        print 'num of classes ------------------->', dataset.num_classes
        images, _, labels = load_batch(FLAGS, dataset, batch_size=FLAGS.training_batch_size, height=FLAGS.image_resize,
                                       width=FLAGS.image_resize, is_training=True)
    
        # Get number of steps to decay
        num_batches_per_epoch = int(dataset.num_samples / FLAGS.training_batch_size)
        num_steps_per_epoch = num_batches_per_epoch  # Because one step is one batch processed
        decay_steps = int(FLAGS.num_epochs_before_decay * num_steps_per_epoch)
    
        with tf.device(tf.train.replica_device_setter(
                worker_device=""/job:worker/task:%d"" % FLAGS.task_index,
                cluster=cluster)):
       
    
    
    
    
    
    
            #======================= INITIATE TRAINING  =========================
    
    
    
    
    
            #Create the model inference
            with slim.arg_scope(inception_v3_arg_scope()):
                logits, end_points = inception_v3(images, num_classes = dataset.num_classes, is_training = True)
    
    
    
            exclude = ['InceptionV3/Logits', 'InceptionV3/AuxLogits']
            #exclude = get_variables_to_exclude()
            for i in exclude:
               print ""var to exclude -> "",i
            variables_to_restore = slim.get_variables_to_restore(exclude = exclude)
    
            #Perform one-hot-encoding of the labels
            one_hot_labels = slim.one_hot_encoding(labels, dataset.num_classes)
    
            #Calculate loss
            loss = tf.losses.softmax_cross_entropy(onehot_labels = one_hot_labels, logits = logits)
            total_loss = tf.losses.get_total_loss()
    
            #Create the global step
            global_step = get_or_create_global_step()
    
    
            #Define your exponentially decaying learning rate
            lr = tf.train.exponential_decay(
                learning_rate = FLAGS.initial_learning_rate,
                global_step = global_step,
                decay_steps = decay_steps,
                decay_rate = FLAGS.learning_rate_decay_factor,
                staircase = True)
    
            #Get optimizer as configured by user
            optimizer = tf.train.AdamOptimizer(learning_rate = lr)
            #optimizer = getOptimizer(learning_rate = lr)
    
            #Create the train_op.
            variables_to_train = get_variables_to_train()
            #for j in variables_to_train:
              #print ""var to train "",j
            #vn = tf.trainable_variables()
            train_op = slim.learning.create_train_op(total_loss, optimizer,variables_to_train=variables_to_train)
    
    
            predictions = tf.argmax(end_points['Predictions'], 1)
            probabilities = end_points['Predictions']
            accuracy, accuracy_update = tf.contrib.metrics.streaming_accuracy(predictions, labels)
            metrics_op = tf.group(accuracy_update, probabilities)
    
    
            #create all the summaries you need to monitor
            tf.summary.scalar('losses/Total_Loss', total_loss)
            tf.summary.scalar('accuracy', accuracy)
            tf.summary.scalar('learning_rate', lr)
            my_summary_op = tf.summary.merge_all()
    
            #Define train step to run training operation
            def train_step(sess, train_op, global_step):
    
                start_time = time.time()
                total_loss, global_step_count, _ = sess.run([train_op, global_step, metrics_op])
                time_elapsed = time.time() - start_time
    
    
                logging.info('global step %s: loss: %.4f (%.2f sec/step)', global_step_count, total_loss, time_elapsed)
    
                return total_loss, global_step_count
    
        #Restore variables from checkpoint
        saver = tf.train.Saver(variables_to_restore)
        def restore_fn(sess):
            return saver.restore(sess, FLAGS.checkpoint_path)
    
        #Create supervisor
        writer = tf.summary.FileWriter(train_logs_path, graph=tf.get_default_graph())
        sv = tf.train.Supervisor(is_chief=(FLAGS.task_index == 0),global_step=global_step,logdir = train_logs_path,
                                 summary_writer=writer,
                                 summary_op = my_summary_op, init_fn = restore_fn)
    
    
        #Run the managed session
        with sv.prepare_or_wait_for_session(server.target) as sess:
            #writer = tf.summary.FileWriter(train_logs_path, graph=tf.get_default_graph())
            for step in xrange(num_steps_per_epoch * FLAGS.training_num_epochs):
                #Log info at each epoch:
                if step % num_batches_per_epoch == 0:
                    logging.info('Epoch %s/%s', step/num_batches_per_epoch + 1, FLAGS.training_num_epochs)
                    learning_rate_value, accuracy_value = sess.run([lr, accuracy])
                    logging.info('Current Learning Rate: %s', learning_rate_value)
                    logging.info('Current Streaming Training Accuracy: %s', accuracy_value)
    
    
                    logits_value, probabilities_value, predictions_value, labels_value = sess.run([logits, probabilities, predictions, labels])
                    print 'logits: \n', logits_value
                    print 'Probabilities: \n', probabilities_value
                    print 'predictions: \n', predictions_value
                    print 'Labels:\n:', labels_value
    
                #Log the summaries every 10 step.
                if step % FLAGS.steps_update_frequency == 0 and step != 0:
                    loss, gs = train_step(sess, train_op, sv.global_step)
                    summaries = sess.run(my_summary_op)
                    if FLAGS.task_index == 0:
                        print('Compute Summaries--------------')
                        sv.summary_computed(sess, summaries)
                        #writer.add_summary(summaries, gs)
                        print ""**** SAVE THE MODEL ****""
                        print 'Train logs path -- ', train_logs_path
                        sv.saver.save(sess,sv.save_path,global_step=sv.global_step)
                        #saver.save(sess, train_logs_path+'/model', global_step=gs)
                        ##
    
                    checkpoint_path = tf.train.latest_checkpoint(train_logs_path)
                    training_json = '{""model_path"":""'+ checkpoint_path +'"",""no_of_steps"":' +str(gs)+',""loss"":'+str(loss)+'}'
                    current_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    print 'training_json -- ', training_json
                    print 'sv.save_path', sv.save_path
                    #dbClient.store_metrices([(FLAGS.pipeline_id,FLAGS.operation_type,training_json,current_time)])
    
                    ##
                    print('*************** Running eval at step = {0} *********************'.format(step))
                    #cmd = 'python ./eval_image_classifier.py --pipeline_id='+FLAGS.pipeline_id+'  --eval_recording_step='+str(gs) + '  --tf_records_dir='+FLAGS.tf_records_dir + '  --checkpoint_dir='+train_logs_path + '  --eval_log_dir='+eval_logs_path + '  --dataset_name='+FLAGS.pipeline_id + '  --num_classes='+str(FLAGS.num_classes)  + '  --eval_num_epochs='+str(FLAGS.eval_num_epochs) + '  --eval_batch_size='+str(FLAGS.eval_batch_size) + '  --image_resize_method='+FLAGS.image_resize_method + '  --color_ordering='+str(FLAGS.color_ordering) + '  --saturation_contrast_lower_bound='+str(FLAGS.saturation_contrast_lower_bound) + '  --saturation_contrast_upper_bound='+str(FLAGS.saturation_contrast_upper_bound) + '  --brightness_max_delta='+str(FLAGS.brightness_max_delta) + '  --hue_max_delta='+str(FLAGS.hue_max_delta)
                    #p = subprocess.Popen(cmd, stdout=subprocess.PIPE, shell=True)
                    #out, err = p.communicate()
                    print('***************Eval finished for step = {0}*********************'.format(step))
    
    
                else:
                    loss, _ = train_step(sess, train_op, sv.global_step)
    
            #We log the final training loss and accuracy
            logging.info('Final Loss: %s', loss)
            logging.info('Final Training Accuracy: %s', sess.run(accuracy))
    
            #Save the model on completing the training
            logging.info('Finished training! Saving model to disk now.')
            if FLAGS.task_index == 0:
              sv.saver.save(sess, sv.save_path, global_step = sv.global_step)

Problem Description
-------------------

I am having three nodes Tensorflow cluster with one parameter server, two workers.
On machine A, I am running a parameter server and chief worker.
On machine B, I am running 2nd worker.
My tensorflow script expects one of the input parameter as the path to the directory containing tfrecord file.

Issue 1
-------

Parameter server and chief worker are running fine but 2nd worker fails with below error.
I am running 2nd worker on machine B and input path to the tfrecords directory exists there.But I don't have any clue why it is looking for data under ps device=""/job:ps/replica:0/task:0/cpu:0"" which is actually running on machine A where this path doesn't exist.

    
    INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.NotFoundError'>, /home/mapr/mano/slim_data/flowers/slim_data_dir/flowers_train_00002-of-00005.tfrecord
             [[Node: parallel_read/ReaderReadV2 = ReaderReadV2[_device=""/job:ps/replica:0/task:0/cpu:0""](parallel_read/TFRecordReaderV2, parallel_read/filenames)]]
    

Issue 2
-------

Just for my curiosity, I copied input tfrecord directory to machine A with the same path as on machine B.
Then the previous error gone but now I am facing different error.
I also checked no code has run within **sv.prepare_or_wait_for_session(server.target)**  block.
It seems to me 2nd worker waits for chief to initialize the session but somehow chief doesn't return session and thus worker fails.

    INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, A session is not created yet....

Plz help me here."
18491,crf_log_likelihood become 2x slower after upgrade TensorFlow from 1.4 to 1.7,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: CentOS Linux release 7.4.1708
- **TensorFlow installed from (source or binary)**: pip install tensorflow-gpu==1.4.0, pip install tensorflow-gpu==1.7.0
- **TensorFlow version (use command below)**: 1.4 and 1.7
- **Python version**:  2.7.5
- **Bazel version (if compiling from source)**: N/A (not compiled from source)
- **GCC/Compiler version (if compiling from source)**: N/A (not compiled from source)
- **CUDA/cuDNN version**: CUDA8.0 + cuDNN6.0 for Tensorflow 1.4, CUDA9 + cuDNN7.0 for Tensorflow 1.7
- **GPU model and memory**: GeForce GTX 1080 Ti, 11178MiB
- **Exact command to reproduce**: python profile_crf.py

### Describe the problem
After upgrade TensorFlow from 1.4 to 1.7,  crf become 2x slower.

When run in TF1.4, it cost about 19 seconds every 100 steps, but about 43 seconds every 100 steps in TF1.7, the source code are the same, see below.
### Source code / logs
the source code are modified from 
https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/crf
```
import numpy as np
import tensorflow as tf
import time

# Data settings.
num_examples = 1000
num_words = 100
num_features = 1000
num_tags = 50

# Random features.
x = np.random.rand(num_examples, num_words, num_features).astype(np.float32)

# Random tag indices representing the gold sequence.
y = np.random.randint(num_tags, size=[num_examples, num_words]).astype(np.int32)

# All sequences in this example have the same length, but they can be variable in a real model.
# sequence_lengths = np.full(num_examples, num_words - 1, dtype=np.int32)
sequence_lengths = np.full(num_examples, num_words, dtype=np.int32)

# Train and evaluate the model.
with tf.Graph().as_default():
  with tf.Session() as session:
    # Add the data to the TensorFlow graph.
    x_t = tf.constant(x)
    y_t = tf.constant(y)
    sequence_lengths_t = tf.constant(sequence_lengths)

    # Compute unary scores from a linear layer.
    weights = tf.get_variable(""weights"", [num_features, num_tags])
    matricized_x_t = tf.reshape(x_t, [-1, num_features])
    matricized_unary_scores = tf.matmul(matricized_x_t, weights)
    unary_scores = tf.reshape(matricized_unary_scores,
                              [num_examples, num_words, num_tags])

    # Compute the log-likelihood of the gold sequences and keep the transition
    # params for inference at test time.
    log_likelihood, transition_params = tf.contrib.crf.crf_log_likelihood(
        unary_scores, y_t, sequence_lengths_t)

    # Compute the viterbi sequence and score.
    viterbi_sequence, viterbi_score = tf.contrib.crf.crf_decode(
        unary_scores, transition_params, sequence_lengths_t)

    # Add a training op to tune the parameters.
    loss = tf.reduce_mean(-log_likelihood)
    train_op = tf.train.GradientDescentOptimizer(0.01).minimize(loss)

    session.run(tf.global_variables_initializer())

    mask = (np.expand_dims(np.arange(num_words), axis=0) <
            np.expand_dims(sequence_lengths, axis=1))
    total_labels = np.sum(sequence_lengths)

    # Train for a fixed number of iterations.
    seconds = 0
    for i in range(500):
      start_time = time.time()
      tf_viterbi_sequence, _ = session.run([viterbi_sequence, train_op])
      seconds += time.time() - start_time
      if i>0 and i % 100 == 0:
        print('time elapsed: {}'.format(seconds))
        seconds = 0
        correct_labels = np.sum((y == tf_viterbi_sequence) * mask)
        accuracy = 100.0 * correct_labels / float(total_labels)
        print(""Accuracy: %.2f%%"" % accuracy)
```"
18490,macOS: Debug fails when running though PyCharm,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS High Sierra 10.13.4
- **TensorFlow installed from (source or binary)**: binary, pip
- **TensorFlow version (use command below)**: 1.7
- **Python version**: 3.6.4 Anaconda, Inc.
- **Bazel version (if compiling from source)**: n/a
- **GCC/Compiler version (if compiling from source)**: n/a
- **CUDA/cuDNN version**: n/a
- **GPU model and memory**: Intel Iris Pro 1536 MB
- **Exact command to reproduce**: n/a

### Describe the problem
Trying to debug a tf.Estimator script, using PyCharm as IDE. For this I use the tfdbg.LocalCLIDebugHook. When running the script through terminal debugging works fine, but through PyCharm i get a curses error:

`_curses.error: setupterm: could not find terminal`

I know this is more a PyCharm issue than a tf issue, but if there is anything simple you could do to mitigate this, it would be nice.

### Source code / logs
File ""/Users/harald/anaconda3/envs/thesis/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 355, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/Users/harald/anaconda3/envs/thesis/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 903, in _train_model
    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])
  File ""/Users/harald/anaconda3/envs/thesis/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 546, in run
    run_metadata=run_metadata)
  File ""/Users/harald/anaconda3/envs/thesis/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 1022, in run
    run_metadata=run_metadata)
  File ""/Users/harald/anaconda3/envs/thesis/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 1113, in run
    raise six.reraise(*original_exc_info)
  File ""/Users/harald/anaconda3/envs/thesis/lib/python3.6/site-packages/six.py"", line 693, in reraise
    raise value
  File ""/Users/harald/anaconda3/envs/thesis/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 1098, in run
    return self._sess.run(*args, **kwargs)
  File ""/Users/harald/anaconda3/envs/thesis/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 1162, in run
    feed_dict, options)
  File ""/Users/harald/anaconda3/envs/thesis/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 1188, in _call_hook_before_run
    request = hook.before_run(run_context)
  File ""/Users/harald/anaconda3/envs/thesis/lib/python3.6/site-packages/tensorflow/python/debug/wrappers/hooks.py"", line 106, in before_run
    on_run_start_request)
  File ""/Users/harald/anaconda3/envs/thesis/lib/python3.6/site-packages/tensorflow/python/debug/wrappers/local_cli_wrapper.py"", line 255, in on_run_start
    self._prep_cli_for_run_start()
  File ""/Users/harald/anaconda3/envs/thesis/lib/python3.6/site-packages/tensorflow/python/debug/wrappers/local_cli_wrapper.py"", line 277, in _prep_cli_for_run_start
    self._run_cli = ui_factory.get_ui(self._ui_type)
  File ""/Users/harald/anaconda3/envs/thesis/lib/python3.6/site-packages/tensorflow/python/debug/cli/ui_factory.py"", line 61, in get_ui
    return curses_ui.CursesUI(on_ui_exit=on_ui_exit, config=config)
  File ""/Users/harald/anaconda3/envs/thesis/lib/python3.6/site-packages/tensorflow/python/debug/cli/curses_ui.py"", line 287, in __init__
    self._screen_init()
  File ""/Users/harald/anaconda3/envs/thesis/lib/python3.6/site-packages/tensorflow/python/debug/cli/curses_ui.py"", line 400, in _screen_init
    self._stdscr = curses.initscr()
  File ""/Users/harald/anaconda3/envs/thesis/lib/python3.6/curses/__init__.py"", line 30, in initscr
    fd=_sys.__stdout__.fileno())
_curses.error: setupterm: could not find terminal
"
18489,Can device run tensorflow lite be used as a work task when performing distribute training?,"Tensorflow lite is designed for mobile device, so can the lite version be used to do some training work. Like using the standard version tensorflow as parameter server, and the edge mobile device do some edge computing and work with the ps?"
18488,Compile error on couldn't find gunit.h,"What's a `gunit.h` which is included in `tensorflow/stream_executor/cuda/cudnn_version_test.cc`? Since I can't find a `gunit.h` in tensorflow folder nor in the system

System OS: Windows 10.0.16299.334"
18485,Can not download tensorflow C libray of macOS GPU version.,"### Describe the problem
Can not download tensorflow c libray of macOS GPU version.

### Source code / logs
I can't download that form the link :
https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-gpu-darwin-x86_64-1.7.0.tar.gz

According to https://www.tensorflow.org/install/install_c
`TF_TYPE=""cpu"" # Change to ""gpu"" for GPU support`
 `OS=""linux"" # Change to ""darwin"" for macOS`
` curl -L ""https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-${TF_TYPE}-${OS}-x86_64-1.7.0.tar.gz"" |`
"
18484,cannot add op with name conv2d/convolution as that name is already used,"Here is my code : 
```python
class final_model:
    # CNN encoder
    encoder, preprocess_for_model = get_cnn_encoder()
    #saver.restore(s, os.path.abspath(""weights""))  # keras applications corrupt our graph, so we restore trained weights
    
    # containers for current lstm state
    lstm_c = tf.Variable(tf.zeros([1, LSTM_UNITS]), name=""cell"")
    lstm_h = tf.Variable(tf.zeros([1, LSTM_UNITS]), name=""hidden"")

    # input images
    input_images = tf.placeholder('float32', [1, IMG_SIZE, IMG_SIZE, 3], name='images')

    # get image embeddings
    img_embeds = encoder(input_images)

    # initialize lstm state conditioned on image
    init_c = init_h = decoder.img_embed_bottleneck_to_h0(decoder.img_embed_to_bottleneck(img_embeds))
    init_lstm = tf.assign(lstm_c, init_c), tf.assign(lstm_h, init_h)
    
    # current word index
    current_word = tf.placeholder('int32', [1], name='current_input')

    # embedding for current word
    word_embed = decoder.word_embed(current_word)

    # apply lstm cell, get new lstm states
    new_c, new_h = decoder.lstm(word_embed, tf.nn.rnn_cell.LSTMStateTuple(lstm_c, lstm_h))[1]

    # compute logits for next token
    new_logits = decoder.token_logits(decoder.token_logits_bottleneck(new_h))
    # compute probabilities for next token
    new_probs = tf.nn.softmax(new_logits)

    # `one_step` outputs probabilities of next token and updates lstm hidden state
    one_step = new_probs, tf.assign(lstm_c, new_c), tf.assign(lstm_h, new_h)
```

And I am getting following error : 

```python
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-42-73f88badc13d> in <module>()
----> 1 class final_model:
      2     # CNN encoder
      3     encoder, preprocess_for_model = get_cnn_encoder()
      4     #saver.restore(s, os.path.abspath(""weights""))  # keras applications corrupt our graph, so we restore trained weights
      5 

<ipython-input-42-73f88badc13d> in final_model()
     12 
     13     # get image embeddings
---> 14     img_embeds = encoder(input_images)
     15 
     16     # initialize lstm state conditioned on image

C:\Program Files\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\keras\_impl\keras\engine\topology.py in __call__(self, inputs, **kwargs)
    250     """"""
    251     # Actually call the layer (optionally building it).
--> 252     output = super(Layer, self).__call__(inputs, **kwargs)
    253 
    254     # Update learning phase info.

C:\Program Files\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\layers\base.py in __call__(self, inputs, *args, **kwargs)
    573         if in_graph_mode:
    574           self._assert_input_compatibility(inputs)
--> 575         outputs = self.call(inputs, *args, **kwargs)
    576 
    577         if outputs is None:

C:\Program Files\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\layers\base.py in call(self, inputs, mask)
   1918     else:
   1919       # Cache miss: actually apply the network graph to the new inputs.
-> 1920       output_tensors, _, _ = self._run_internal_graph(inputs, masks)
   1921       return output_tensors
   1922 

C:\Program Files\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\layers\base.py in _run_internal_graph(self, inputs, masks)
   2082                 if 'mask' not in kwargs:
   2083                   kwargs['mask'] = computed_mask
-> 2084               output_tensors = _to_list(layer.call(computed_tensor, **kwargs))
   2085               if hasattr(layer, 'compute_mask'):
   2086                 output_masks = _to_list(

C:\Program Files\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\layers\convolutional.py in call(self, inputs)
    169     # TODO(agarwal): do we need this name_scope ?
    170     with ops.name_scope(None, 'convolution', [inputs, self.kernel]):
--> 171       outputs = self._convolution_op(inputs, self.kernel)
    172 
    173     if self.use_bias:

C:\Program Files\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\ops\nn_ops.py in __call__(self, inp, filter)
    833 
    834   def __call__(self, inp, filter):  # pylint: disable=redefined-builtin
--> 835     return self.conv_op(inp, filter)
    836 
    837 

C:\Program Files\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\ops\nn_ops.py in __call__(self, inp, filter)
    497 
    498   def __call__(self, inp, filter):  # pylint: disable=redefined-builtin
--> 499     return self.call(inp, filter)
    500 
    501 

C:\Program Files\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\ops\nn_ops.py in __call__(self, inp, filter)
    185         padding=self.padding,
    186         data_format=self.data_format,
--> 187         name=self.name)
    188 
    189 

C:\Program Files\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\ops\gen_nn_ops.py in conv2d(input, filter, strides, padding, use_cudnn_on_gpu, data_format, name)
    628         ""Conv2D"", input=input, filter=filter, strides=strides,
    629         padding=padding, use_cudnn_on_gpu=use_cudnn_on_gpu,
--> 630         data_format=data_format, name=name)
    631     _result = _op.outputs[:]
    632     _inputs_flat = _op.inputs

C:\Program Files\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\framework\op_def_library.py in _apply_op_helper(self, op_type_name, name, **keywords)
    785         op = g.create_op(op_type_name, inputs, output_types, name=scope,
    786                          input_types=input_types, attrs=attr_protos,
--> 787                          op_def=op_def)
    788       return output_structure, op_def.is_stateful, op
    789 

C:\Program Files\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\framework\ops.py in create_op(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)
   2957     if compute_shapes:
   2958       set_shapes_for_outputs(ret)
-> 2959     self._add_op(ret)
   2960     self._record_op_seen_by_control_dependencies(ret)
   2961 

C:\Program Files\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\framework\ops.py in _add_op(self, op)
   2597       if op.name in self._nodes_by_name:
   2598         raise ValueError(""cannot add op with name %s as that name ""
-> 2599                          ""is already used"" % op.name)
   2600       self._nodes_by_id[op._id] = op
   2601       self._nodes_by_name[op.name] = op

ValueError: cannot add op with name conv2d/convolution as that name is already used
```

How can solve this issue ? Please help . THANKS."
18482,Not able to import tensorflow,"Ubuntu: 16.04.4
Tensorflow installed from Anaconda
Tensorflow version: 1.4.1
Python: Python3
CUDA: 8
Cudnn: 7.0.5
GPU: GTX 1080 8GB
Command: import tensorflow on ipython notebook
Error:
```
ImportError                               Traceback (most recent call last)
~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py in <module>()
     57 
---> 58   from tensorflow.python.pywrap_tensorflow_internal import *
     59   from tensorflow.python.pywrap_tensorflow_internal import __version__

~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py in <module>()
     27             return _mod
---> 28     _pywrap_tensorflow_internal = swig_import_helper()
     29     del swig_import_helper

~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py in swig_import_helper()
     23             try:
---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
     25             finally:

~/anaconda3/envs/tf/lib/python3.6/imp.py in load_module(name, file, filename, details)
    242         else:
--> 243             return load_dynamic(name, filename, file)
    244     elif type_ == PKG_DIRECTORY:

~/anaconda3/envs/tf/lib/python3.6/imp.py in load_dynamic(name, path, file)
    342             name=name, loader=loader, origin=path)
--> 343         return _load(spec)
    344 

ImportError: libcuda.so.1: cannot open shared object file: No such file or directory

During handling of the above exception, another exception occurred:

ImportError                               Traceback (most recent call last)
<ipython-input-1-64156d691fe5> in <module>()
----> 1 import tensorflow as tf

~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/__init__.py in <module>()
     22 
     23 # pylint: disable=wildcard-import
---> 24 from tensorflow.python import *
     25 # pylint: enable=wildcard-import
     26 

~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/__init__.py in <module>()
     47 import numpy as np
     48 
---> 49 from tensorflow.python import pywrap_tensorflow
     50 
     51 # Protocol buffers

~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py in <module>()
     70 for some common reasons and solutions.  Include the entire stack trace
     71 above this error message when asking for help."""""" % traceback.format_exc()
---> 72   raise ImportError(msg)
     73 
     74 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long

ImportError: Traceback (most recent call last):
  File ""/home/sarvagya/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/home/sarvagya/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/home/sarvagya/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/home/sarvagya/anaconda3/envs/tf/lib/python3.6/imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""/home/sarvagya/anaconda3/envs/tf/lib/python3.6/imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: libcuda.so.1: cannot open shared object file: No such file or directory


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

```
**UPDATE:**
I installed normal tensorflow and I was able to import tensorflow. However, now, I am not able use the GPU, even though tensoeflorw-gpu is installed in the environment. "
18480,Remove Python dep on 'enum',"Python enum is only used by a couple files, and has caused a lot of pain. Maybe we shouldn't use it?

Python enum is used by a couple files in TensorFlow. It's not portable. It was only quite recently backported to Python 2.7. For example, TensorFlow won't compile on Debian 8 without `sudo apt-get install python-enum34` however `sudo apt-get install python-enum` will break the build.

- https://github.com/tensorflow/tensorflow/issues/12491
- https://github.com/tensorflow/tensorflow/issues/15136"
18478,Tensorflow server doesn't pick version updates if pointed to shared model_config.conf file,"I'm currently deploying tensorflow models on multiple servers in production but seem to have a issue while there is a model config file update.

**Issue is -** 
On updating the model config file located at a common shared location that all then tensorflow servers point to, not all the servers pick up the version updates!
 
On the contrary, the issue seems to be not occuring when each of the tensorflow server has its own model_config file, then it simultaneously updates with new versions.

This is a unwanted behavior, wanted to know if there is a work around or is it a bug which is existent in tensorflow serving.

model_config looks something similar to this -

```
model_config_list: {
  config: {
    name: ""modelName1"",
    base_path: ""/path to model1 files/"",
    model_platform: ""tensorflow""
  },
    config: {
    name: ""modelName2"",
    base_path: ""/path to model2 files/"",
    model_platform: ""tensorflow""
  }
}
```"
18477,tf.gather's gradient fails on GPU in eager mode,"Tested with TensorFlow v1.7.0 on Ubuntu 16.06.

Consider the following contrived example:
```python
import tensorflow as tf
import tensorflow.contrib.eager as tfe

tfe.enable_eager_execution()

with tf.device('/gpu:0'):
    with tfe.GradientTape() as tape:
        params = tfe.Variable(tf.zeros((1024,)))
        indices = tf.constant(range(5))
        output = tf.reduce_sum(tf.gather(params, indices))
    print(tape.gradient(output, [params]))
```

When executed, it fails with:

```
Tensorflow.python.framework.errors_impl.InvalidArgumentError: Tensors on conflicting devices: cannot compute Cast as input #0 was expected to be on /job:localhost/replica:0/task:0/device:GPU:0 but is actually on /job:localhost/replica:0/task:0/device:CPU:0 (operation running on /job:localhost/replica:0/task:0/device:GPU:0) Tensors can be copied explicitly using .gpu() or .cpu(), or transparently copied by using tfe.enable_eager_execution(tfe.DEVICE_PLACEMENT_SILENT). Copying tensors between devices may slow down your model [Op:Cast] name: ToInt32
```

This does not occur on the CPU.

The issue can be fixed by removing the `to_int32` call and just changing the `out_types` to `int32` here in [array_grad.py](https://github.com/tensorflow/tensorflow/blob/v1.7.0/tensorflow/python/ops/array_grad.py#L398-L399) as follows:
```python
params_shape = array_ops.shape(params, out_type=ops.dtypes.int32) # int64 -> int32
# params_shape = math_ops.to_int32(params_shape) [remove this line]
```"
18474,Segfault on bad input to tf.constant.,"One can get a segfault providing some wrong data into a `tf.constant`:

```python
>> tf.constant(tf.string, ""[,]"")
Segmentation fault (core dumped)
```

While `tf.constant(tf.string, ""[]"")` and `tf.constant(tf.string, "","")` both give the proper error (`dtype not understood`).

"
18473,Error when trying to use tf.contrib.distribute.MirroredStrategy in tf.estimator,"**System information**
- **OS Platform and Distribution**:  Linux Ubuntu 16.04.2
- **TensorFlow installed from**: source
- **TensorFlow version**: 1.7
- **Python version**: 3.5
- **Bazel version**: 0.11.1
- **GCC/Compiler version**: 5.4.0
- **CUDA/cuDNN version**: 9/7
- **GPU model and memory**: TITAN X (Pascal) 11170 MB memory

I'm trying to add multi-gpu support to my tensorflow training code using tf.contrib.distribute.MirroredStrategy as a parameter to tf.estimator.RunConfig. 
I get the following error message: 

<!-- language: python -->

    Traceback (most recent call last):
      File ""python3.5/site-packages/tensorflow/python/training/coordinator.py"", line 297, in stop_on_exception
        yield
      File ""python3.5/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py"", line 248, in _call_for_each_tower
        self, *merge_args, **merge_kwargs)
      File ""python3.5/site-packages/tensorflow/python/training/optimizer.py"", line 667, in _distributed_apply
        reduced_grads = distribution.batch_reduce(""sum"", grads_and_vars)
      File ""python3.5/site-packages/tensorflow/python/training/distribute.py"", line 801, in batch_reduce
        return self._batch_reduce(method_string, value_destination_pairs)
      File ""python3.5/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py"", line 295, in _batch_reduce
        value_destination_pairs)
      File ""python3.5/site-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py"", line 169, in batch_reduce
        raise ValueError(""`value_destination_pairs` must be a list or a tuple of ""
    ValueError: `value_destination_pairs` must be a list or a tuple of tuples of PerDevice objects and destinations 

The following code produces the error (I omitted the code for parsing the tfrecord to image tensor as I don't believe this code effects the error, but I can add it if necessary):

<!-- language: python -->
    
    import glob, os
    import tensorflow as tf
    slim = tf.contrib.slim
    
    # Initialization of args - arguments parser.
    def init():
        pass
 

    def input_fn():
    
        dataset = tf.data.TFRecordDataset(glob.glob(os.path.join(args.train_data_dir, 'train*')))
        dataset = dataset.map(
                    lambda x: parse_and_preprocess_image(x, args.image_size),
                    num_parallel_calls=2,
        )
        dataset = dataset.repeat()
        dataset = dataset.batch(batch_size=4)
        dataset = dataset.prefetch(1)
    
        return dataset
    
    
    def model_fn(features, labels=None, mode=tf.estimator.ModeKeys.TRAIN, params=None):
    
        train_images_batch = features
        res = slim.conv2d(inputs=train_images_batch, kernel_size=9, stride=1, num_outputs=3, scope='conv1')
        loss = tf.reduce_mean((train_images_batch - res) ** 2)
        optimizer = tf.train.AdamOptimizer(0.001)
        train_op = slim.learning.create_train_op(loss, optimizer)
        return tf.estimator.EstimatorSpec(
            mode=tf.estimator.ModeKeys.TRAIN,
            loss=loss, train_op=train_op)
    
    
    def train():
    
        init()
    
        distribution = tf.contrib.distribute.MirroredStrategy(num_gpus=args.num_gpus)
    
        config = tf.estimator.RunConfig(
            model_dir=args.log_dir,
            train_distribute=distribution,
        )
    
        estimator = tf.estimator.Estimator(model_fn=model_fn, config=config)
        estimator.train(
                input_fn=input_fn,
                max_steps=args.train_steps,
            )
    
    
    def main():
        train()
    
    
    if __name__ == '__main__':
        main()


Thank you!
Adva


"
18469,Feature request: Use feature columns for labels,"As you describe in the documentation
> Think of feature columns as the intermediaries between raw data and Estimators. Feature columns are very rich, enabling you to transform a diverse range of raw data into formats that Estimators can use, allowing easy experimentation. [https://www.tensorflow.org/get_started/feature_columns](https://www.tensorflow.org/get_started/feature_columns)

feature columns are pretty handy to transform input data. I would like to see the same functionality for labels. Why can't I transform labels with the same ""data columns"" as features?

Have I written custom code N/A
OS Platform and Distribution N/A
TensorFlow installed from N/A
TensorFlow version N/A
Bazel version N/A
CUDA/cuDNN version N/A
GPU model and memory N/A
Exact command to reproduce N/A"
18463,Op type not registered 'GatherV2' error when using libtensorflow maven artifacts,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: maven
- **TensorFlow version (use command below)**: 1.7.0-rc1
- **Java version**: 1.8.0_162
- **GPU model and memory**: Tesla K80

### Describe the problem
When attempting to use the **libtensorflow** maven artifacts mentioned in the [GPU Support for Java](https://www.tensorflow.org/versions/master/install/install_java#gpu_support) page to load an exported graph, I received the error:

```
Exception in thread ""main"" org.tensorflow.TensorFlowException: Op type not registered 'GatherV2'
	at org.tensorflow.SavedModelBundle.load(Native Method)
	at org.tensorflow.SavedModelBundle.load(SavedModelBundle.java:39)
	at net.imagej.ops.experiments.filter.deconvolve.FlowdecGraph.load(FlowdecGraph.java:38)
```

Please let me know if any other information would help, but the error seems pretty informative so I just wanted to check and see if support for newer operations like ""GatherV2"" were likely to make it into the java artifacts in the near future.

It may also help to note that the same code I was running works just fine when using either python or the non-gpu-enabled java artifact like this:

```
<dependency>
         <groupId>org.tensorflow</groupId>
         <artifactId>tensorflow</artifactId>
         <version>1.7.0-rc1</version>
</dependency>
```

But switching that to these dependencies results in the error (with no other changes):

```
<dependency>
	<groupId>org.tensorflow</groupId>
	<artifactId>libtensorflow</artifactId>
	<version>1.7.0-rc1</version>
</dependency>
<dependency>
	<groupId>org.tensorflow</groupId>
	<artifactId>libtensorflow_jni_gpu</artifactId>
	<version>1.7.0-rc1</version>
</dependency>
```

Thanks for the help!

"
18460,tf.nn.conv3d_transpose operation with data_format='NCDHW',"### System information
Irrelevant.

### Describe the problem
In implementation of ""tf.nn.conv3d_transpose"" operation with ""data_format='NCDHW'"",
the shape compatibility of ""output shape"" and ""kernel size"" check is not carried out correctly. (However, the check is fine in tf.nn.conv2d_transpose)


### Source code / logs
`    if isinstance(output_shape, (list, np.ndarray)):
      # output_shape's shape should be == [5] if reached this point.
      if not filter.get_shape()[3].is_compatible_with(output_shape[4]):
        raise ValueError(
            ""output_shape does not match filter's output channels, ""
            ""{} != {}"".format(output_shape[4],
                              filter.get_shape()[3]))`

should be changed to 

`    if isinstance(output_shape, (list, np.ndarray)):
      # output_shape's shape should be == [5] if reached this point.
      if not filter.get_shape()[3].is_compatible_with(output_shape[axis]):
        raise ValueError(
            ""output_shape does not match filter's output channels, ""
            ""{} != {}"".format(output_shape[axis],
                              filter.get_shape()[3]))`

more specifically, output_shape[4] to output_shape[axis]."
18459,crop_and_resize on gpu in eager mode fails,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
 Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
using pip
- **TensorFlow version (use command below)**:
('v1.7.0-3-g024aecf414', '1.7.0')
- **Python version**: 
2.7
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
Cuda 9, Cudnn 7
- **GPU model and memory**:
GeForce GTX 745, 4GB
- **Exact command to reproduce**:
import tensorflow as tf, numpy as np
tf.enable_eager_execution()
images = np.random.uniform(size=[1, 28, 28, 1]).astype('float32')
with tf.device('gpu:0'):
  tf.image.crop_and_resize(images, boxes=[(0, 0, 0.9, 0.5)], box_ind=[0], crop_size=[20, 20])

### Describe the problem
When using `tf.image.crop_and_resize` in eager mode with the gpu, getting the error that says `box_index` has wrong values, where values are actually fine. 

See the reproduction code above. Works without the gpu, or without eager mode. 
Looks similar to [https://github.com/tensorflow/tensorflow/issues/10618](url)

Error message:
2018-04-12 14:44:57.137104: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-04-12 14:44:57.542554: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-12 14:44:57.542970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 745 major: 5 minor: 0 memoryClockRate(GHz): 1.0325
pciBusID: 0000:01:00.0
totalMemory: 3.95GiB freeMemory: 3.92GiB
2018-04-12 14:44:57.542987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-12 14:44:57.688951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-12 14:44:57.688973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-12 14:44:57.688982: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-12 14:44:57.689139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3713 MB memory) -> physical GPU (device: 0, name: GeForce GTX 745, pci bus id: 0000:01:00.0, compute capability: 5.0)
Traceback (most recent call last):
  File ""<stdin>"", line 2, in <module>
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_image_ops.py"", line 368, in crop_and_resize
    extrapolation_value=extrapolation_value, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_image_ops.py"", line 396, in crop_and_resize_eager_fallback
    attrs=_attrs, ctx=_ctx, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/eager/execute.py"", line 66, in quick_execute
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""/usr/local/lib/python2.7/dist-packages/six.py"", line 737, in raise_from
    raise value
tensorflow.python.framework.errors_impl.OutOfRangeError: box_index has values outside [0, batch_size) [Op:CropAndResize]
"
18457,Could change Eigen to other blas for matrix  operation,"As for CPU Tensorflow, matrix operation use `eigen`. Could replace it with other blases, such as openBlas, atlas,  gotoBlas et al."
18456,Tensorflow failed when build with MSVC," System information
•	Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
N/A
•	OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Windows server 2016
•	TensorFlow installed from (source or binary):
Source
•	TensorFlow version (use command below):
Master branch latest revison
•	Python version:
Anaconda 4.1.1 (Python 3.5 64-bit)
•	Bazel version (if compiling from source):
N/A
•	GCC/Compiler version (if compiling from source):
VS2017 15.5.7
•	CUDA/cuDNN version:
NVidia CUDA Toolkit 8.0
NVidia CUDNN 5.1
•	GPU model and memory:
N/A
•	Exact command to reproduce:
N/A

**Describe the problem:**
Tensorflow failed to build due to the error: No module named 'google'. This issue can be reproduced from master revision [90a3db9.](https://github.com/tensorflow/tensorflow/commit/90a3db9ff995634314227f0aacf4984d1eee752a) This should be tensorflow source issue, could you please help take a look at this? Thanks!

**The failures like:**
The whole log file please see attachment.
[log_x64_build.log](https://github.com/tensorflow/tensorflow/files/1902589/log_x64_build.log)

 520>CustomBuild:
         Traceback (most recent call last):
           File ""D:/TensorFlow/build_x64/tf_python/tensorflow/tools/api/generator/create_python_api.py"", line 26, in <module>
             from tensorflow.python.util import tf_decorator
           File ""D:\TensorFlow\build_x64\tf_python\tensorflow\python\__init__.py"", line 52, in <module>
             from tensorflow.core.framework.graph_pb2 import *
           File ""D:\TensorFlow\build_x64\tf_python\tensorflow\core\framework\graph_pb2.py"", line 6, in <module>
             from google.protobuf import descriptor as _descriptor
         ModuleNotFoundError: No module named 'google'
   520>C:\Program Files (x86)\Microsoft Visual Studio\2017\Enterprise\Common7\IDE\VC\VCTargets\Microsoft.CppCommon.targets(171,5): error MSB6006: ""cmd.exe"" exited with code 1. [D:\TensorFlow\build_x64\tf_python_api.vcxproj]

**Repro steps:**

1. git clone https://github.com/tensorflow/tensorflow D:\Tensorflow\src
2. pushd D:\Tensorflow
3. set PreferredToolArchitecture=x64
4. set rel=Release
5. set CUDNN_HOME=""C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\cuda""
6. set PY=C:\ProgramData\Anaconda3
7. set CL=/FS /permissive-
8. cmake D:\Tensorflow\src\tensorflow\contrib\cmake -A x64 -DCMAKE_BUILD_TYPE=Release -DPYTHON_EXECUTABLE=C:\ProgramData\Anaconda3\python.exe -DPYTHON_LIBRARIES=C:\ProgramData\Anaconda3\libs\python36.lib -DSWIG_EXECUTABLE=D:\Tensorflow\swigwin-3.0.12\swig.exe -Dtensorflow_BUILD_PYTHON_TESTS=ON -Dtensorflow_BUILD_SHARED_LIB=ON
9. MSBuild /m /p:Configuration=Release;Platform=x64 /p:WindowsTargetPlatformVersion=10.0.16299.0 tensorflow.sln /t:Rebuild
"
18455,eager mode fails with custom operator,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:

Yes, I have written a custom tensorflow operator

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:

Linux Ubuntu 16.04

- **TensorFlow installed from (source or binary)**:

binary wheel

- **TensorFlow version (use command below)**:

('v1.7.0-3-g024aecf414', '1.7.0')

- **Python version**: 

python 2.7.12

- **Bazel version (if compiling from source)**:

N/A

- **GCC/Compiler version (if compiling from source)**:

N/A

- **CUDA/cuDNN version**:

N/A

- **GPU model and memory**:

N/A

- **Exact command to reproduce**:

Custom operator is defined [here](https://github.com/ska-sa/montblanc/blob/f168870a9756f31c8639ff0c0219ce16af68e612/montblanc/impl/rime/tensorflow/rime_ops/phase_op_cpu.h#L44-L122) but I doubt you'll want to look through that.

```python
import tensorflow as tf
tf.enable_eager_execution()

from montblanc.impl.rime.tensorflow.tensorflow_ops import phase

lm = np.random.random((10,2)).astype(np.float32)
uvw = np.random.random((10,3,2)).astype(np.float32)
freq = np.linspace(.856e9, .856e8*2, 4).astype(np.float32)

# Convert into tfe Variable
lm, uvw, freq = (tfe.Variable(a) for a in (lm, uvw, freq))
value = phase(lm, uvw, freq, CT=tf.complex64)
```

This produces the following stack trace

```
Traceback (most recent call last):
  File ""test_tf_eager_grad.py"", line 65, in <module>
    value = phase(lm, uvw, freq, CT=tf.complex64)
  File ""<string>"", line 419, in phase
  File ""/home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 328, in apply_op
    op_type_name, name, **keywords)
  File ""/home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 3277, in create_op
    input_ops = set([t.op for t in inputs])
  File ""/home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 842, in op
    raise AttributeError(""op not supported for Eager Tensors."")
AttributeError: op not supported for Eager Tensors.
```

### Describe the problem

Eager mode does not work with a custom operator.

### Source code / logs

See above"
18454,Wrong behavior of tf.nn.conv2d when dilated rate>1 on CPU version of tensorflow.,"# Required Info
- **OS Platform and Distribution**:Linux Ubuntu 16.04
- **TensorFlow installed from**:binary
- **Tensorflow Version**:1.6.0
- **Python Version**:3.6.3
- **Have I written custom code**:Yes
- **Bazel version**:N/A
- **CUDA/cuDNN version** : N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: See Below

# Problem description:
When constucting the graph, i use tf.nn.conv2d with diated_rate > 1 and padding='VALID', the wrapper returns a correct shape. However when i feed an input in, and use sess.run to get the output, it turns out that tf.nn.ops is not using diliated conv at all. Then i run the exact commands on a machine with tensorflow_gpu, the gpu_versions output is correct. So i believe that i should be a bug.

# Exact Commands:
```
import tensorflow as tf
import numpy as np
inputs = tf.get_variable(shape=[1, 7, 7, 1], dtype=tf.float32, name='inputs')
filters = tf.get_variable(shape=[3, 3, 1, 1], dtype=tf.float32, name='filters', initializer=tf.constant_initializer(
    [
        [1, 1, 1],
        [1, 1, 1],
        [1, 1, 1]
    ]
))
conv = tf.nn.conv2d(input=inputs,
                    filter=filters,
                    strides=[1] + [1, 1] + [1],
                    padding='VALID',
                    use_cudnn_on_gpu=False,
                    data_format=""NHWC"",
                    dilations=[1] + [2, 2] + [1],
                    name='conv')
print(conv)

inputs_v = np.zeros([1,7,7,1])
inputs_v[:,0,:,:] = np.reshape([1,2,3,4,5,6,7], newshape=[1,7,1])
sess = tf.Session()
sess.run(tf.global_variables_initializer())

conv_v = sess.run(conv, feed_dict={inputs:inputs_v})
print(conv_v) 
```
"
18453,Slim Train API doesn't provide control to user to extract loss and accuracy metrics,"I am referring to [train_image_classifier.py][1] script provided by Tensorflow for image classification.

Script uses slim.learning.train API to kick off the training and then it takes care for everything internally.
Though it logs the metrics i.e. loss/accuracy but that's all internal to slim. I doesn't provide handle to get periodic updates of loss/accuracy in my script while training is going on.
My requirement is to extract loss and accuracy metrics after every n number of epochs, i.e. 5 and dump that into database for later analysis.

But because of high level abstraction of slim train API, It seems there is now way to get periodic updates loss/accuracy info during the training.


Is it possible to tap the training process and get the loss/accuracy values after every given number of steps/epochs ?
If it's possible, please share the pseudo code for that.

It will be really helpful for me. 

Thanks.


  [1]: https://github.com/tensorflow/models/blob/master/research/slim/train_image_classifier.py"
18452,Different pixel values for the same image when read using DecodeJpeg on x86_64 and arm64,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 10 
- **TensorFlow installed from (source or binary)**:
Source
- **TensorFlow version (use command below)**:
1.5.0
- **Python version**: 
3.4
- **Bazel version (if compiling from source)**:
0.11.0
- **CUDA/cuDNN version**:
9.0/7.0.5
- **GPU model and memory**:
N/A
- **Exact command to reproduce**:
given below in the problem description

I used `DecodeJpeg` method to read in images during training, I used it with `dct_method=""""`.
In order to use the same operation on Android, I compiled TensorFlow with DecodeJpeg using bazel.
I compiled it for `arm64`.

The problem I'm facing is that, the pixel values from both the platforms are significantly different

In Python, I use the snippet below to read image,
```
with tf.gfile.FastGFile(r'path\to\image.jpg', 'rb') as image_file:
    image_bytes = image_file.read()
decode_jpeg_data = tf.placeholder(dtype=tf.string)
decode_jpeg = tf.image.decode_jpeg(decode_jpeg_data_f, channels=3)
image = sess.run(decode_jpeg , feed_dict={decode_jpeg_data: image_bytes })
```
I use [this ](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/java/src/main/java/org/tensorflow/examples/LabelImage.java)script to execute the model on Android. 
I executed `DecodeJpeg` with `dct_method` set to `' '`, `INTEGER_FAST`, `INTEGER_ACCURATE`, on both desktop as well as Android.
All of them gave pixel values which were significantly different from what I got on a desktop, for the same `dct_method`

For instance, for the same image, at (100,100,0) the value on `x86_64` is `213`, while it is `204` on `arm64`.
The problem is that, the prediction label sometimes flips across the two platforms, for the same image.

How can I get the same behavior on both platforms?
I had asked this on [StackOverflow](https://stackoverflow.com/questions/49748902/tensorflow-decodejpeg-method-gives-different-pixel-values-on-desktop-and-mobile)
"
18450,Tensorflow failed to compile,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Arch Linux 
- **TensorFlow installed from (source or binary)**: Source from branch r1.7, did not compile
- **TensorFlow version (use command below)**: 1.7.0
- **Python version**: 3.6.4
- **Bazel version (if compiling from source)**: 0.12.0
- **GCC/Compiler version (if compiling from source)**: 7.3.1
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**:  ./configure && bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package

### Describe the problem
While compiling tensorflow build failed. I just pulled the latest commit(92e6c3e4f5c1cabfda1e61547a6a1b268ef95fa5) from the r1.7 branch. I also updated bazel (from 0.11.1 to 0.12.0) and some other programs(should be irrelevant to tensorflow) beforehand.

### Source code / logs
`ERROR: /home/UserHome/.cache/bazel/_bazel_UserHome/ab33c8274551e1ea3125872a4c4e7db9/external/jpeg/BUILD:126:12: Illegal ambiguous match on configurable attribute ""deps"" in @jpeg//:jpeg:
@jpeg//:k8
@jpeg//:armeabi-v7a
Multiple matches are not allowed unless one is unambiguously more specialized.
ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted:

/home/UserHome/.cache/bazel/_bazel_UserHome/ab33c8274551e1ea3125872a4c4e7db9/external/jpeg/BUILD:126:12: Illegal ambiguous match on configurable attribute ""deps"" in @jpeg//:jpeg:
@jpeg//:k8
@jpeg//:armeabi-v7a
Multiple matches are not allowed unless one is unambiguously more specialized.
INFO: Elapsed time: 1.086s
FAILED: Build did NOT complete successfully (3 packages loaded)`

**UPDATE:** The r1.8 branch compiles successfully. The 1.8 branch might have a fix? Or perhaps a dependency was updated and that fixed it?"
18449,tf.contrib.summary to export the graph to tensorboard,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Very simple change from provided script
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04 LTS
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: v1.7.0-13-g99322a9 1.7.0
- **Python version**: 3.5.2
- **Bazel version (if compiling from source)**: 0.11.1
- **GCC/Compiler version (if compiling from source)**: gcc (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609
- **CUDA/cuDNN version**: 9.1 / 7.1
- **GPU model and memory**: TitanXp 12Gb
- **Exact command to reproduce**:
```
import tensorflow as tf

if tf.gfile.IsDirectory(""testos""):
    tf.gfile.DeleteRecursively(""testos"")
tf.gfile.MakeDirs(""testos"")

global_step = tf.train.get_or_create_global_step()
summary_writer = tf.contrib.summary.create_file_writer(
    ""./testos/test"", flush_millis=10000)

with summary_writer.as_default(), tf.contrib.summary.always_record_summaries():
    x = tf.placeholder(tf.float32, [])
    test = x > 5

    res = tf.cond(test, true_fn=lambda: tf.constant(0), false_fn=lambda: tf.constant(2))

    tf.contrib.summary.scalar(""x"", x)
    tf.contrib.summary.scalar(""res"", res)

    inc_op = global_step.assign(global_step + 1)

    tf.contrib.summary.scalar(""global_step"", global_step)

    with tf.Session() as sess:
        tf.global_variables_initializer().run()

        tf.contrib.summary.initialize(graph=tf.get_default_graph())
        summ = tf.contrib.summary.all_summary_ops()

        for i in range(10):
            plop, _sum, _g = sess.run([res, summ, inc_op], {x: i})
```

### Describe the problem
I wanted to use summary with tf.cond. I then decided to use the tf.contrib.summary that makes it possible.
Then based on the example given here https://github.com/tensorflow/tensorflow/blob/r1.7/tensorflow/contrib/summary/summary.py
I wrote the above code. (By the way the example does not show clearly that we need to stay in the `with summary_writer.as_default(), tf.contrib.summary.always_record_summaries():` scope when we write in the summary.)

For the scalar there is no problem, it appear correctly in tensorboard. But the graph does not appear. 
I get the following message:
> Namespace hiearchy: Failed Adding Nodes

Here is a screen shot:
![screenshot from 2018-04-12 15-01-33](https://user-images.githubusercontent.com/10159876/38659030-807f6204-3e62-11e8-91df-ab29d7c24431.png)
"
18447,Numerically safe cross_entropy for tfd.Bernoulli?,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: 1.7
- **Python version**: 3.5
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**:
```[python]
import tensorflow as tf
from tensorflow import distributions as tfd

tf.enable_eager_execution()

def test_bernoulli_cross_entropy():
    logits = tf.random_normal(shape=[3, 4])
    labels = tf.cast(tf.random_normal(shape=[3, 4]) > 0.0, tf.float32)
    p = tfd.Bernoulli(logits=logits)
    q = tfd.Bernoulli(probs=labels)

    ce1 = tf.nn.sigmoid_cross_entropy_with_logits(logits=p.logits, labels=q.probs)
    ce2 = q.cross_entropy(p)
    print(ce1)
    print(ce2)
```

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

v1.7.0-3-g024aecf414 1.7.0

### Describe the problem
The Bernoulli in Tensorflow distributions does not seem to have a numerically safe cross entropy operation. See code above -- it should produce the same results as tf.nn.sigmoid_cross_entropy_with_logits, but produces NaN. If I set probs to be not exactly zero or one, then ce1 = ce2. So it seems to be a numerical stability issue.

Example output:
```
tf.Tensor(
[[0.88931024 1.4332782  0.47688866 0.48566538]
 [0.93064773 0.39325503 1.1308188  1.5703993 ]
 [0.09037975 0.1828385  0.39422417 0.839576  ]], shape=(3, 4), dtype=float32)
tf.Tensor(
[[nan nan nan nan]
 [nan nan nan nan]
 [nan nan nan nan]], shape=(3, 4), dtype=float32)
```

### Source code / logs
```[python]
import tensorflow as tf
from tensorflow import distributions as tfd

tf.enable_eager_execution()

def test_bernoulli_cross_entropy():
    logits = tf.random_normal(shape=[3, 4])
    labels = tf.cast(tf.random_normal(shape=[3, 4]) > 0.0, tf.float32)
    p = tfd.Bernoulli(logits=logits)
    q = tfd.Bernoulli(probs=labels)

    ce1 = tf.nn.sigmoid_cross_entropy_with_logits(logits=p.logits, labels=q.probs)
    ce2 = q.cross_entropy(p)
    print(ce1)
    print(ce2)
```
"
18443,"In Matmul, is FP16 x FP16 accumulated to FP16 or FP32?","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
1.7
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
9.0
- **GPU model and memory**:
V100 16GB
- **Exact command to reproduce**:

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

It is not clear in documents that, in Matmul, FP16xFP16 is accumulated to FP16 or FP32. 
This choice affects not only training accuracy, but also TensorCore computing performance on Volta GPU.

"
18441,Something seems like a bug in r1.8 when building from source code?,"I try to build tensorflow with gpu support from source.

# **Basic information:**

- OS Platform and Distribution : ubuntu 14.04
- TensorFlow installed from : source code, branch r1.7
- TensorFlow version : r1.7
- Bazel version : 0.11.1
- CUDA/cuDNN version: 8.0/6.0
- GPU model and memory : Titan X
- Exact command to reproduce:
    `bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package `

# **My configuration:**
```
Do you wish to build TensorFlow with jemalloc as malloc support? [Y/n]:
jemalloc as malloc support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Google Cloud Platform support? [Y/n]: n
No Google Cloud Platform support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Hadoop File System support? [Y/n]: n
No Hadoop File System support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Amazon S3 File System support? [Y/n]: n
No Amazon S3 File System support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Apache Kafka Platform support? [Y/n]: n
No Apache Kafka Platform support will be enabled for TensorFlow.

Do you wish to build TensorFlow with XLA JIT support? [y/N]:
No XLA JIT support will be enabled for TensorFlow.

Do you wish to build TensorFlow with GDR support? [y/N]:
No GDR support will be enabled for TensorFlow.

Do you wish to build TensorFlow with VERBS support? [y/N]:
No VERBS support will be enabled for TensorFlow.

Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]:
No OpenCL SYCL support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: y
CUDA support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: y
CUDA support will be enabled for TensorFlow.

Please specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 9.0]: 8.0

Please specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default
 is /usr/local/cuda]:

Please specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7.0]: 6.0

Please specify the location where cuDNN 6 library is installed. Refer to README.md for more details. [Default
is /usr/local/cuda]:/home/chongyang/RemoteSensingImage/cuda

Do you wish to build TensorFlow with TensorRT support? [y/N]:
No TensorRT support will be enabled for TensorFlow.

Please specify the NCCL version you want to use. [Leave empty to default to NCCL 1.3]:

Please specify a list of comma-separated Cuda compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size. [Default is: 6.1,6.1,6.1,6.1]

Do you want to use clang as CUDA compiler? [y/N]:
nvcc will be used as CUDA compiler.

Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]:

Do you wish to build TensorFlow with MPI support? [y/N]:
No MPI support will be enabled for TensorFlow.

Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native]:

Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]:
Not configuring the WORKSPACE for Android builds.

Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See tools/bazel.rc for more details.
        --config=mkl            # Build with MKL support.
        --config=monolithic     # Config for mostly static monolithic build.
Configuration finished
```
# **The error I encountered:**
```
ERROR: /home/chongyang/RemoteSensingImage/tensorflow/tensorflow/stream_executor/BUILD:52:1: C++ compilation of
 rule '//tensorflow/stream_executor:cuda_platform' failed (Exit 1)
In file included from ./tensorflow/stream_executor/platform/port.h:21:0,
                 from ./tensorflow/stream_executor/device_memory.h:30,
                 from ./tensorflow/stream_executor/dnn.h:30,
                 from ./tensorflow/stream_executor/cuda/cuda_dnn.h:22,
                 from tensorflow/stream_executor/cuda/cuda_dnn.cc:16:
tensorflow/stream_executor/cuda/cuda_dnn.cc: In constructor 'perftools::gputools::cuda::CudnnRnnDescriptor::Cu
dnnRnnDescriptor(perftools::gputools::cuda::CUDAExecutor*, cudnnHandle_t, int, int, int, cudnnRNNInputMode_t,
cudnnDirectionMode_t, cudnnRNNMode_t, cudnnDataType_t, cudnnDataType_t, const perftools::gputools::dnn::Algori
thmConfig&, float, tensorflow::uint64, perftools::gputools::ScratchAllocator*)':
tensorflow/stream_executor/cuda/cuda_dnn.cc:1188:29: error: 'class perftools::gputools::dnn::AlgorithmConfig' has no member named 'is_default'
     CHECK(algorithm_config_.is_default())
```

# **Something seems like a bug in r1.7?**
As the error message show, 'class perftools::gputools::dnn::AlgorithmConfig' has no member named 'is_default'. Then I check the code in ` tensorflow/stream_executor/cuda/cuda_dnn.cc` and `tensorflow/stream_executor/dnn.h`

```
//tensorflow/stream_executor/dnn.h
class AlgorithmConfig {
 public:
  AlgorithmConfig() {}
  explicit AlgorithmConfig(AlgorithmDesc algorithm) : algorithm_(algorithm) {}
  AlgorithmConfig(AlgorithmDesc algorithm, AlgorithmDesc algorithm_no_scratch)
      : algorithm_(algorithm), algorithm_no_scratch_(algorithm_no_scratch) {}
  AlgorithmDesc algorithm() const { return algorithm_; }
  void set_algorithm(AlgorithmDesc val) { algorithm_ = val; }
  AlgorithmDesc algorithm_no_scratch() const { return algorithm_no_scratch_; }
  void set_algorithm_no_scratch(AlgorithmDesc val) {
    algorithm_no_scratch_ = val;
  }
  bool operator==(const AlgorithmConfig& other) const {
    return this->algorithm_ == other.algorithm_ &&
           this->algorithm_no_scratch_ == other.algorithm_no_scratch_;
  }
  bool operator!=(const AlgorithmConfig& other) const {
    return !(*this == other);
  }
  string ToString() const;

 private:
  AlgorithmDesc algorithm_;
  AlgorithmDesc algorithm_no_scratch_;
};
```
```
//tensorflow/stream_executor/cuda/cuda_dnn.cc
CudnnRnnDescriptor(CUDAExecutor* parent, cudnnHandle_t cudnn_handle,
                     int num_layers, int hidden_size, int input_size,
                     cudnnRNNInputMode_t input_mode,
                     cudnnDirectionMode_t direction_mode,
                     cudnnRNNMode_t rnn_mode, cudnnDataType_t data_type,
                     cudnnDataType_t compute_type,
                     const dnn::AlgorithmConfig& algorithm_config,
                     float dropout, uint64 seed,
                     ScratchAllocator* state_allocator)
      : parent_(parent),
        rnn_desc_(nullptr),
        num_layers_(num_layers),
        hidden_size_(hidden_size),
        input_size_(input_size),
        input_mode_(input_mode),
        direction_mode_(direction_mode),
        rnn_mode_(rnn_mode),
        data_type_(data_type),
        compute_type_(compute_type),
       ///////////////////////////////////////////////////
       ///// //algorithm_config_ is defined here!/////
       ///////////////////////////////////////////////////
        algorithm_config_(algorithm_config) {
....
       /////////////////////////////////////////////////////////////////////////////
       //algorithm_config_ call function is_default(), which occurs the bug//
        ////////////////////////////////////////////////////////////////////////////
       CHECK(algorithm_config_.is_default())
            << ""Non-default algorithm not supported for CUDA version < 6.0"";
```

**Actually, algorithm_config_ has no member named `is_default()`. Only `class AlgorithmDesc` has this function.**

Thanks for helping me to solve this problem and correct me!"
18440,TenflowLite Crash,"
device : Galaxy Tab advanced 4
version : 6.0 

04-12 11:37:19.164 1221-1221/? A/DEBUG: Build fingerprint: 'samsung/matisse10wifikx/matisse10wifikx:6.0.1/MMB29K/T536KXU1AQF1:user/release-keys'
04-12 11:37:19.164 1221-1221/? A/DEBUG: Revision: '4'
04-12 11:37:19.164 1221-1221/? A/DEBUG: ABI: 'arm'
04-12 11:37:19.164 1221-1221/? A/DEBUG: pid: 27456, tid: 28023, name: Thread-24515  >>> me.visual.camp.mobileeye <<<
04-12 11:37:19.164 1221-1221/? A/DEBUG: signal 11 (SIGSEGV), code 1 (SEGV_MAPERR), fault addr 0x6a9e1398
04-12 11:37:19.174 1221-1221/? A/DEBUG:     r0 00000004  r1 00000020  r2 dec48050  r3 00000002
04-12 11:37:19.174 1221-1221/? A/DEBUG:     r4 dec40010  r5 b8d7a6d0  r6 6a9e1398  r7 00000002
04-12 11:37:19.174 1221-1221/? A/DEBUG:     r8 ebc9fe14  r9 ebc9fe04  sl dec40000  fp 00000004
04-12 11:37:19.174 1221-1221/? A/DEBUG:     ip 00000000  sp d197f2f0  lr dec40008  pc f388cfee  cpsr a00f0030
04-12 11:37:19.184 1221-1221/? A/DEBUG: backtrace:
04-12 11:37:19.184 1221-1221/? A/DEBUG:     #00 pc 0005efee  /data/app/me.visual.camp.mobileeye-1/lib/arm/libtensorflowlite_jni.so
04-12 11:37:19.184 1221-1221/? A/DEBUG:     #01 pc 0007922d  /data/app/me.visual.camp.mobileeye-1/lib/arm/libtensorflowlite_jni.so
04-12 11:37:19.184 1221-1221/? A/DEBUG:     #02 pc 00007895  /data/app/me.visual.camp.mobileeye-1/lib/arm/libtensorflowlite_jni.so (Java_org_tensorflow_lite_NativeInterpreterWrapper_run+980)
04-12 11:37:19.184 1221-1221/? A/DEBUG:     #03 pc 005b1539  /data/app/me.visual.camp.mobileeye-1/oat/arm/base.odex (offset 0x431000)

"
18437,"Converting TensorFlow frozen and inference model to lite fails with ""Check failed: array->has_shape""","- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow):**
Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Mac OS X High Sierra
- **TensorFlow installed from (source or binary)**:
Source
- **TensorFlow version (use command below)**:
'v1.7.0-rc1-1018-g7a0def60d4' 1.7.0-rc1
- **Python version**: 
3.5.5
- **Bazel version (if compiling from source)**:
0.10.1
- **GCC/Compiler version (if compiling from source)**:
Apple LLVM version 9.1.0 (clang-902.0.39.1)
- **CUDA/cuDNN version**:
NA
- **GPU model and memory**:
NA
- **Exact command to reproduce**:
bazel-bin/tensorflow/contrib/lite/toco/toco \
--input_file=frozen.pb \
--input_format=TENSORFLOW_GRAPHDEF \
--output_format=TFLITE \
--output_file=frozen.lite \
--input_array=Inputs/Input \
--output_array=Outputs/Prediction \
--input_shape=1,28,28,1 \
--inference_type=FLOAT
-**Error Message**
 F tensorflow/contrib/lite/toco/tooling_util.cc:831] Check failed: array->has_shape()

I have created a TensorFlow model which classifies MNIST image data. The model is then frozen and optimized for inference. These models I can benchmark as well. But when converting to TensorFlow lite, the toco command fails with the above mentioned error message.

I have summarized the graph as well for both frozen and inference model.
The frozen model has the same size of (1,28,28,1) but the inference has a size of (None). I am using a placeholder when creating the model for the Input.
"
18429,Get error when compiling with gcc 6.4.0: error: mismatched argument pack lengths while expanding...,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Debian Testing buster/sid
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: 1cd76c209ce6f74298843568a7fc397c2e6f958f
- **Python version**: 2.7.13
- **Bazel version (if compiling from source)**: 0.11.0
- **GCC/Compiler version (if compiling from source)**: 6.4.0
- **CUDA/cuDNN version**: CUDA 9.0, cuDNN 7.0.5
- **GPU model and memory**: Titan V
- **Exact command to reproduce**:

```
bazel build  --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
```

### Describe the problem
When compiling TensorFlow, I get the compilation error shown at the bottom of this post. This is the same error as #16246, but I am opening a new issue since the issue has been fixed, then broken again by 1cd76c209ce6f74298843568a7fc397c2e6f958f. The commit before 1cd76c209ce6f74298843568a7fc397c2e6f958f, e7ea87f97e03360719d132a71acc1eb2f93c249f, compiles fine.

According to [this link](https://devtalk.nvidia.com/default/topic/1028112/cuda-setup-and-installation/nvcc-bug-related-to-gcc-6-lt-tuple-gt-header-/), CUDA 9 does not support gcc 6.4.0, so it may not be possible to fix this. If so, this issue should be closed. But gcc 6.4.0 is currently the earliest version of gcc in Debian Testing (at least on our internal workstations), so I cannot compile TensorFlow otherwise.

/CC @gunan @jlebar
### Source code / logs
```
INFO: From Compiling tensorflow/core/kernels/dynamic_stitch_op_gpu.cu.cc:
/usr/include/c++/6/tuple: In instantiation of 'static constexpr bool std::_TC<<anonymous>, _Elements>::_MoveConstructibleTuple() [with _UElements = {const std::tuple<int, int, int>&}; bool <anonymous> = true; _Elements = {int, int, int}]':
/usr/include/c++/6/tuple:626:248:   required by substitution of 'template<class ... _UElements, typename std::enable_if<(((std::_TC<(sizeof... (_UElements) == 1), int, int, int>::_NotSameTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_MoveConstructibleTuple<_UElements ...>()) && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyMoveConvertibleTuple<_UElements ...>()) && (3ul >= 1)), bool>::type <anonymous> > constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {const std::tuple<int, int, int>&}; typename std::enable_if<(((std::_TC<(sizeof... (_UElements) == 1), int, int, int>::_NotSameTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_MoveConstructibleTuple<_UElements ...>()) && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyMoveConvertibleTuple<_UElements ...>()) && (3ul >= 1)), bool>::type <anonymous> = <missing>]'
./tensorflow/stream_executor/dnn.h:891:91:   required from here
/usr/include/c++/6/tuple:483:67: error: mismatched argument pack lengths while expanding 'std::is_constructible<_Elements, _UElements&&>'
       return __and_<is_constructible<_Elements, _UElements&&>...>::value;
                                                                   ^~~~~
/usr/include/c++/6/tuple:484:1: error: body of constexpr function 'static constexpr bool std::_TC<<anonymous>, _Elements>::_MoveConstructibleTuple() [with _UElements = {const std::tuple<int, int, int>&}; bool <anonymous> = true; _Elements = {int, int, int}]' not a return-statement
     }
 ^
/usr/include/c++/6/tuple: In instantiation of 'static constexpr bool std::_TC<<anonymous>, _Elements>::_ImplicitlyMoveConvertibleTuple() [with _UElements = {const std::tuple<int, int, int>&}; bool <anonymous> = true; _Elements = {int, int, int}]':
/usr/include/c++/6/tuple:626:362:   required by substitution of 'template<class ... _UElements, typename std::enable_if<(((std::_TC<(sizeof... (_UElements) == 1), int, int, int>::_NotSameTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_MoveConstructibleTuple<_UElements ...>()) && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyMoveConvertibleTuple<_UElements ...>()) && (3ul >= 1)), bool>::type <anonymous> > constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {const std::tuple<int, int, int>&}; typename std::enable_if<(((std::_TC<(sizeof... (_UElements) == 1), int, int, int>::_NotSameTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_MoveConstructibleTuple<_UElements ...>()) && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyMoveConvertibleTuple<_UElements ...>()) && (3ul >= 1)), bool>::type <anonymous> = <missing>]'
./tensorflow/stream_executor/dnn.h:891:91:   required from here
/usr/include/c++/6/tuple:489:65: error: mismatched argument pack lengths while expanding 'std::is_convertible<_UElements&&, _Elements>'
       return __and_<is_convertible<_UElements&&, _Elements>...>::value;
                                                                 ^~~~~
/usr/include/c++/6/tuple:490:1: error: body of constexpr function 'static constexpr bool std::_TC<<anonymous>, _Elements>::_ImplicitlyMoveConvertibleTuple() [with _UElements = {const std::tuple<int, int, int>&}; bool <anonymous> = true; _Elements = {int, int, int}]' not a return-statement
     }
 ^
/usr/include/c++/6/tuple: In instantiation of 'static constexpr bool std::_TC<<anonymous>, _Elements>::_NonNestedTuple() [with _SrcTuple = const std::tuple<int, int, int>&; bool <anonymous> = true; _Elements = {int, int, int}]':
/usr/include/c++/6/tuple:662:419:   required by substitution of 'template<class ... _UElements, class _Dummy, typename std::enable_if<((std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ConstructibleTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyConvertibleTuple<_UElements ...>()) && std::_TC<(std::is_same<_Dummy, void>::value && (1ul == 1)), int, int, int>::_NonNestedTuple<const tuple<_Elements ...>&>()), bool>::type <anonymous> > constexpr std::tuple< <template-parameter-1-1> >::tuple(const std::tuple<_Args1 ...>&) [with _UElements = {int, int, int}; _Dummy = void; typename std::enable_if<((std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ConstructibleTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyConvertibleTuple<_UElements ...>()) && std::_TC<(std::is_same<_Dummy, void>::value && (1ul == 1)), int, int, int>::_NonNestedTuple<const tuple<_Elements ...>&>()), bool>::type <anonymous> = <missing>]'
./tensorflow/stream_executor/dnn.h:891:91:   required from here
/usr/include/c++/6/tuple:495:244: error: wrong number of template arguments (4, should be 2)
       return  __and_<__not_<is_same<tuple<_Elements...>,
                                                                                                                                                                                                                                                    ^    
/usr/include/c++/6/type_traits:1558:8: note: provided for 'template<class _From, class _To> struct std::is_convertible'
     struct is_convertible
        ^~~~~~~~~~~~~~
/usr/include/c++/6/tuple:502:1: error: body of constexpr function 'static constexpr bool std::_TC<<anonymous>, _Elements>::_NonNestedTuple() [with _SrcTuple = const std::tuple<int, int, int>&; bool <anonymous> = true; _Elements = {int, int, int}]' not a return-statement
     }
 ^
/usr/include/c++/6/tuple: In instantiation of 'static constexpr bool std::_TC<<anonymous>, _Elements>::_MoveConstructibleTuple() [with _UElements = {std::tuple<int, int, int>}; bool <anonymous> = true; _Elements = {int, int, int}]':
/usr/include/c++/6/tuple:626:248:   required by substitution of 'template<class ... _UElements, typename std::enable_if<(((std::_TC<(sizeof... (_UElements) == 1), int, int, int>::_NotSameTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_MoveConstructibleTuple<_UElements ...>()) && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyMoveConvertibleTuple<_UElements ...>()) && (3ul >= 1)), bool>::type <anonymous> > constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {std::tuple<int, int, int>}; typename std::enable_if<(((std::_TC<(sizeof... (_UElements) == 1), int, int, int>::_NotSameTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_MoveConstructibleTuple<_UElements ...>()) && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyMoveConvertibleTuple<_UElements ...>()) && (3ul >= 1)), bool>::type <anonymous> = <missing>]'
./tensorflow/stream_executor/dnn.h:891:91:   required from here
/usr/include/c++/6/tuple:483:67: error: mismatched argument pack lengths while expanding 'std::is_constructible<_Elements, _UElements&&>'
       return __and_<is_constructible<_Elements, _UElements&&>...>::value;
                                                                   ^~~~~
/usr/include/c++/6/tuple:484:1: error: body of constexpr function 'static constexpr bool std::_TC<<anonymous>, _Elements>::_MoveConstructibleTuple() [with _UElements = {std::tuple<int, int, int>}; bool <anonymous> = true; _Elements = {int, int, int}]' not a return-statement
     }
 ^
/usr/include/c++/6/tuple: In instantiation of 'static constexpr bool std::_TC<<anonymous>, _Elements>::_ImplicitlyMoveConvertibleTuple() [with _UElements = {std::tuple<int, int, int>}; bool <anonymous> = true; _Elements = {int, int, int}]':
/usr/include/c++/6/tuple:626:362:   required by substitution of 'template<class ... _UElements, typename std::enable_if<(((std::_TC<(sizeof... (_UElements) == 1), int, int, int>::_NotSameTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_MoveConstructibleTuple<_UElements ...>()) && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyMoveConvertibleTuple<_UElements ...>()) && (3ul >= 1)), bool>::type <anonymous> > constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {std::tuple<int, int, int>}; typename std::enable_if<(((std::_TC<(sizeof... (_UElements) == 1), int, int, int>::_NotSameTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_MoveConstructibleTuple<_UElements ...>()) && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyMoveConvertibleTuple<_UElements ...>()) && (3ul >= 1)), bool>::type <anonymous> = <missing>]'
./tensorflow/stream_executor/dnn.h:891:91:   required from here
/usr/include/c++/6/tuple:489:65: error: mismatched argument pack lengths while expanding 'std::is_convertible<_UElements&&, _Elements>'
       return __and_<is_convertible<_UElements&&, _Elements>...>::value;
                                                                 ^~~~~
/usr/include/c++/6/tuple:490:1: error: body of constexpr function 'static constexpr bool std::_TC<<anonymous>, _Elements>::_ImplicitlyMoveConvertibleTuple() [with _UElements = {std::tuple<int, int, int>}; bool <anonymous> = true; _Elements = {int, int, int}]' not a return-statement
     }
 ^
/usr/include/c++/6/tuple: In instantiation of 'static constexpr bool std::_TC<<anonymous>, _Elements>::_NonNestedTuple() [with _SrcTuple = std::tuple<int, int, int>&&; bool <anonymous> = true; _Elements = {int, int, int}]':
/usr/include/c++/6/tuple:686:422:   required by substitution of 'template<class ... _UElements, class _Dummy, typename std::enable_if<((std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_MoveConstructibleTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyMoveConvertibleTuple<_UElements ...>()) && std::_TC<(std::is_same<_Dummy, void>::value && (1ul == 1)), int, int, int>::_NonNestedTuple<tuple<_Elements ...>&&>()), bool>::type <anonymous> > constexpr std::tuple< <template-parameter-1-1> >::tuple(std::tuple<_Args1 ...>&&) [with _UElements = {int, int, int}; _Dummy = void; typename std::enable_if<((std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_MoveConstructibleTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyMoveConvertibleTuple<_UElements ...>()) && std::_TC<(std::is_same<_Dummy, void>::value && (1ul == 1)), int, int, int>::_NonNestedTuple<tuple<_Elements ...>&&>()), bool>::type <anonymous> = <missing>]'
./tensorflow/stream_executor/dnn.h:891:91:   required from here
/usr/include/c++/6/tuple:495:244: error: wrong number of template arguments (4, should be 2)
       return  __and_<__not_<is_same<tuple<_Elements...>,
                                                                                                                                                                                                                                                    ^    
/usr/include/c++/6/type_traits:1558:8: note: provided for 'template<class _From, class _To> struct std::is_convertible'
     struct is_convertible
        ^~~~~~~~~~~~~~
/usr/include/c++/6/tuple:502:1: error: body of constexpr function 'static constexpr bool std::_TC<<anonymous>, _Elements>::_NonNestedTuple() [with _SrcTuple = std::tuple<int, int, int>&&; bool <anonymous> = true; _Elements = {int, int, int}]' not a return-statement
     }
 ^
```
"
18428,TensorFlow Hub models crashing on TF Lite,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: 1.6
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: 0.10.0
- **GCC/Compiler version (if compiling from source)**: 5.4
- **CUDA/cuDNN version**: 9.0
- **GPU model and memory**: Nvidia GTX 1050Ti 4GB
- **Exact command to reproduce**: Running TF Lite label_image example with a retrained TF Hub model

### Describe the problem
[Bug] I used TensorFlow image model retraining scripts to train a custom model using TensorFlow Hub feature extractors (MobileNetV1 and MobileNetV2). When I try to run the retrained TensorFlow Hub image models in Tensorflow Lite, I get errors about dimension mismatches and allocations (see error below). I have successfully run retrained MobileNetV1 classifiers (that were not downloaded from TF Hub) using TensorFlow Lite without issue, so I am assuming that the problem stems from an issue with TF Lite/TOCO and TF Hub models.

I am running TF Lite 1.6 right now because the build process for 1.7 is broken (lite/kernels/internal/spectogram.cc depends on the FFT2D library which is built with the full TF Makefile/dependency download script but not in the TF Lite Makefile/dependency download script).

### Source code / logs
The error output:
```
tensorflow/contrib/lite/kernels/sub.cc:48 NumDimensions(input1) != NumDimensions(input2) (4 != 0)
FATAL: Failed to allocate tensors!
```

The verbose graph definition:
```
INFO: Resolved reporter
INFO: Tensors size: 95
INFO: Nodes size: 33
INFO: Inputs: 1
INFO: Input(0) name: Placeholder
INFO: 0: Placeholder, 602112, 1, 0, 0
INFO: 1: final_result, 20, 1, 0, 0
INFO: 2: final_retrain_ops/Wx_plus_b/MatMul_bias, 20, 1, 0, 0
INFO: 3: final_retrain_ops/Wx_plus_b/add, 20, 1, 0, 0
INFO: 4: final_retrain_ops/weights/final_weights/transpose, 20480, 1, 0, 0
INFO: 5: module/MobilenetV1/Conv2d_0/weights, 3456, 1, 0, 0
......... (standard MobileNetV1 definition, I can post the full definition if it would help)
INFO: 86: module_apply_default/MobilenetV1/MobilenetV1/Conv2d_9_pointwise/Conv2D_bias, 2048, 1, 0, 0
INFO: 87: module_apply_default/MobilenetV1/MobilenetV1/Conv2d_9_pointwise/Relu6, 401408, 1, 0, 0
INFO: 88: module_apply_default/hub_input/Mul, 602112, 1, 0, 0
INFO: 89: module_apply_default/hub_input/Mul/y, 4, 1, 0, 0
INFO: 90: module_apply_default/hub_input/Sub, 602112, 1, 0, 0
INFO: 91: module_apply_default/hub_input/Sub/y, 4, 1, 0, 0
INFO: 92: module_apply_default/hub_output/feature_vector/SpatialSqueeze, 4096, 1, 0, 0
```"
18427,Failed to load the native TensorFlow runtime on Win 10 64,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No, I'm just importing tensorflow
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 (x64) Home
- **TensorFlow installed from**: N/A
- **TensorFlow version (use command below)**: r1.7
- **Python version**: 3.6.4
- **CUDA/cuDNN version**: CUDA 9.0, cuDNN v7.0.5
- **GPU model and memory**: NVidia Gforce GTX 660ti
- **Exact command to reproduce**: import tensorflow as tf
- **Bazel version**: N/A

I'm trying to install TensorFlow as described [here ](https://www.tensorflow.org/install/install_windows)on my Windows 10 (x64) machine.

First I installed CUDA. My GPU (GTX 660ti, Compute Capability 3.0) is supported. Versions: Toolkit 9.0 (accidently installed 9.1 aswell beforehand), cuDNN v7.0.5 for CUDA 9.0

Then I installed Tensorflow using native pip3. Python-Version: 3.6.4

When I'm just importing the tensorflow package I'm getting the following error:


```
>>> import tensorflow as tf
Traceback (most recent call last):
  File ""C:\Users\Max\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Max\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Max\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 17, in swig_import_helper
    return importlib.import_module(mname)
  File ""C:\Users\Max\AppData\Local\Programs\Python\Python36\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: DLL load failed: A dynamic link library (dll) initialization routine failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Users\Max\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import *  # pylint: disable=redefined-builtin
  File ""C:\Users\Max\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\Max\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
      File ""C:\Users\Max\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Max\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Max\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 17, in swig_import_helper
    return importlib.import_module(mname)
  File ""C:\Users\Max\AppData\Local\Programs\Python\Python36\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: DLL load failed: A dynamic link library (dll) initialization routine failed


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.`

```

I have the following System environment variables set:
```
CUDA_PATH - C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0
CUDA_PATH_V9_0 - C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0
CUDA_PATH_V9_1 - C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.1
Path - C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\libnvvp;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.1\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.1\libnvvp;

```
I have Microsoft Visual C++ 2015 Redistributable (x64) - 14.0.24215 installed. MSVCP140.dll is in my System32 folder.

What I also tried:

- Using Python version 3.6.2 (What i currently have)
- Installing via anaconda
- Using pip instead of pip3
- Upgrading pip3, pip
- Reinstalling (python, pip, cuda toolkit, tensorflow)
- Using tensorflow version from uci repository"
18425,Non chief worker is throwing exception while saving the model,"System information
------------------

 - Have I written custom code - Yes
 - OS Platform CentOS - 7.2.1511
 - TensorFlow installed from - Binary
 - TensorFlow version - 1.3.0
 - Python version - 2.7
 - Bazel version - N/A
 - CUDA/cuDNN version - N/A
 - GPU model and memory - N/A

I am having three nodes Tensorflow cluster with one parameter server, two workers, first one is chief worker.
All three servers are running on the single machine but on different ports.

Source Code
-----------
Sharing my code snippet below,

    sv = tf.train.Supervisor(is_chief=(FLAGS.task_index == 0),global_step=global_step,logdir = train_logs_path,
                                     summary_op = my_summary_op, init_fn = restore_fn)
     with sv.prepare_or_wait_for_session(server.target) as sess:
                for step in xrange(num_steps_per_epoch * FLAGS.training_num_epochs):
                    #Log info at each epoch:
                    if step % num_batches_per_epoch == 0:
                        logging.info('Epoch %s/%s', step/num_batches_per_epoch + 1, FLAGS.training_num_epochs)
                        learning_rate_value, accuracy_value = sess.run([lr, accuracy])
                        logging.info('Current Learning Rate: %s', learning_rate_value)
                        logging.info('Current Streaming Training Accuracy: %s', accuracy_value)
    					
                    #Log the summaries every 10 step.
                    if step % FLAGS.steps_update_frequency == 0 and step != 0:
                        loss, gs = train_step(sess, train_op, sv.global_step)
                        summaries = sess.run(my_summary_op)
                        
                        sv.summary_computed(sess, summaries)
                        print ""**** SAVE THE MODEL ****""
                        sv.saver.save(sess,sv.save_path,global_step=sv.global_step)
    
                    else:
                        loss, _ = train_step(sess, train_op, sv.global_step)
    
                #We log the final training loss and accuracy
                logging.info('Final Loss: %s', loss)
                logging.info('Final Training Accuracy: %s', sess.run(accuracy))
    
                #Save the model on completing the training
                logging.info('Finished training! Saving model to disk now.')
                sv.saver.save(sess, sv.save_path, global_step = sv.global_step)


Describe the problem
--------------------

Parameter server and workers have been started fine and training is running on the both the workers.
Plz note that I am using tensorflow Supervisor API to run my training.

Problem starts at non-chief worker when I try to save summaries and checkpoint after certain number of training steps.
I am using the single script for running parameter server and workers.
I don't understand why is chief worker not reporting any issue while saving summaries and checkpoint and only non-chief worker is complaining about it.
Am I doing anything wrong in my code ?

As per my understanding, every worker will run training on it's own data and store the checkpoints periodically.
However, I have read somewhere that it's the responsibility of only chief worker to save summaries and checkpoints.
Is that true and that's the reason saving model is failing for me at non-worker node?

If yes, then my question is what is the use of other worker here if it doesn't store the model, don't we loose pottentially a better model at other non-chief worker ?

Error Logs
----------
Posting error logs received at non-chief worker while saving summaries.Similarly some other exception was thrown while saving the model.

    Traceback (most recent call last):
      File ""./DTF_train_image_classifier.py"", line 469, in <module>
        tf.app.run()
      File ""/usr/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 48, in run
        _sys.exit(main(_sys.argv[:1] + flags_passthrough))
      File ""./DTF_train_image_classifier.py"", line 433, in main
        sv.summary_computed(sess, summaries)
      File ""/usr/lib/python2.7/site-packages/tensorflow/python/training/supervisor.py"", line 852, in summary_computed
        raise RuntimeError(""Writing a summary requires a summary writer."")
    RuntimeError: Writing a summary requires a summary writer.

Plz note that error is thrown at below two lines,

    sv.summary_computed(sess, summaries)
    sv.saver.save(sess,sv.save_path,global_step=sv.global_step)"
18424,sneaky re-release of TF 1.7.0?,"Someone informed us that the checksum of the source tarball from https://github.com/tensorflow/tensorflow/archive/v1.7.0.tar.gz changed according to what we had in place (was `2df5e308357356c9ffb7e9a7816dfa9947bd8928f9d406cf7e851b82853931ea`, now is `c676a96fc8700722816b2b98c85578b2f99fac7a7b2484c9c7f0641484f8d50d`).

After some investigation, it seems there was indeed a ""re-release"" without changing the version number, see https://github.com/easybuilders/easybuild-easyconfigs/issues/6146 for more details.

Can someone confirm this, and share some more information on why this was done?
This sort of practice should really be avoided at all costs...

I guess @annarev could probably shed some light on this, since the most recent `1.7.0` tag done by @annarev."
18421,Cannot apply convolution twice,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Fedora 27
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: b'v1.3.0-rc1-3011-gd86448938' 1.3.0

- **Python version**: 3.6.4
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**:
```
import tensorflow as tf

sess = tf.Session()
inp1 = tf.ones((1, 2, 2, 5))
inp2 = tf.zeros((1, 2, 2, 5))

conv_layer = tf.layers.Conv2D(
    filters=2,
    kernel_size=2,
    padding='SAME',
    kernel_initializer=tf.glorot_uniform_initializer(),
    name=""vconv"")
dense_layer = tf.layers.Dense(units=1, use_bias=False, activation=None)

tdout1 = dense_layer.apply(inp1)
tdout2 = dense_layer.apply(inp2)
sess.run(tf.global_variables_initializer())
# This works:
print(sess.run((tdout1, tdout2)))

tcout1 = conv_layer.apply(inp1)
tcout2 = conv_layer.apply(inp2)
sess.run(tf.global_variables_initializer())
# This does not work:
print(sess.run((tcout1, tcout2)))
# ValueError: cannot add op with name vconv/convolution as that name is already used
```
Throws:
```
Traceback (most recent call last):
  File ""div/tf_2conv.py"", line 16, in <module>
    tcout2 = conv_layer.apply(inp2)
  File ""/home/torstein/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py"", line 659, in apply
    return self.__call__(inputs, *args, **kwargs)
  File ""/home/torstein/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py"", line 563, in __call__
    outputs = self.call(inputs, *args, **kwargs)
  File ""/home/torstein/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/convolutional.py"", line 171, in call
    outputs = self._convolution_op(inputs, self.kernel)
  File ""/home/torstein/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py"", line 835, in __call__
    return self.conv_op(inp, filter)
  File ""/home/torstein/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py"", line 499, in __call__
    return self.call(inp, filter)
  File ""/home/torstein/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py"", line 187, in __call__
    name=self.name)
  File ""/home/torstein/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 631, in conv2d
    data_format=data_format, name=name)
  File ""/home/torstein/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/home/torstein/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 2941, in create_op
    self._add_op(ret)
  File ""/home/torstein/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 2595, in _add_op
    ""is already used"" % op.name)
ValueError: cannot add op with name vconv/convolution as that name is already used
```
"
18417,freeze_graph,"

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: None
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  macOS High Sierra 10.13.3
- **TensorFlow installed from (source or binary)**:  binary, Installing with Virtualenv and pip install 
- **TensorFlow version (use command below)**:1.7.0
- **Python version**:  2.7
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: 
- **GPU model and memory**: 
- **Exact command to reproduce**:   freeze_graph \
--input_graph=/Users/cc/TF/MNIST/mnist_convnet_model/graph.pbtxt \
--input_checkpoint=/Users/cc/TF/MNIST/mnist_convnet_model/model.ckpt-31817 \
--output_graph=/tmp/frozen_graph_mnist.pb \
--output_node_names='save/restore_all' \
--input_binary=false


### Describe the problem

I'm trying to freeze my mnist graph which name is graph.pbtxt with these command:

```
      freeze_graph \
--input_graph=/Users/cc/TF/MNIST/mnist_convnet_model/graph.pbtxt \
--input_checkpoint=/Users/cc/TF/MNIST/mnist_convnet_model/model.ckpt-31817 \
--output_graph=/tmp/frozen_graph_mnist.pb \
--output_node_names='save/restore_all' \
--input_binary=false
```
but the following error always acours:

```
    Instructions for updating:
Use the retry module or similar alternatives.
Traceback (most recent call last):
  File ""/usr/local/bin/freeze_graph"", line 11, in <module>
    sys.exit(main())
TypeError: main() takes exactly 1 argument (0 given)

```


### Source code / logs
WARNING:tensorflow:From /usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Use the retry module or similar alternatives.
Traceback (most recent call last):
  File ""/usr/local/bin/freeze_graph"", line 11, in <module>
    sys.exit(main())
TypeError: main() takes exactly 1 argument (0 given)


"
18415,A bug related to conv2d_transpose and tf.cond,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.7.0
- **Python version**: 2.7
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: 7.0
- **GPU model and memory**: GTX 980M / 4G
- **Exact command to reproduce**: python the_following_code.py

### Describe the problem
I am trying to implement a model named progressive GAN. I met some very weird problems. My problems could be reproduced by the following code. I believe it is a bug of tensorflow because removing any trivial tf.cond or removing conv2d_transpose will make the code work.


```
  File ""/home/yfeng23/test/tf/cond_test1.py"", line 38, in <module>
    net = upscale2d(net_out[0])                                                   # net.shape = [16, 16, 16, 512]
  File ""/home/yfeng23/test/tf/cond_test1.py"", line 12, in upscale2d

InvalidArgumentError (see above for traceback): Input to reshape is a tensor with 2097152 values, but the requested shape has 524288
	 [[Node: Upscale2D_1/Reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](Upscale2D_1/Tile, Upscale2D_1/Reshape/shape)]]
```

### Source code / logs
```
import tensorflow as tf
import tensorflow.contrib.slim as slim


def upscale2d(x, factor=2):
  """"""increase the resolution""""""
  with tf.variable_scope('Upscale2D'):
    channels = x.shape[-1]
    s = tf.shape(x)
    x = tf.expand_dims(tf.expand_dims(x, axis=3), axis=2)
    x = tf.tile(x, [1, 1, factor, 1, factor, 1])
    x = tf.reshape(x, [s[0], s[1] * factor, s[2] * factor, channels])
    return x


def to_rgb(x, lod, num_outputs):
  """"""generate image output""""""
  with tf.variable_scope('ToRGB_lod%d' % lod):
    return slim.conv2d(x, num_outputs, 1, activation_fn=None)


batch_size = 16
num_outputs = 3
noise = tf.random_normal([batch_size, 128])
with slim.arg_scope([slim.conv2d, slim.conv2d_transpose],
                    activation_fn=tf.nn.leaky_relu):
  net = tf.expand_dims(tf.expand_dims(noise, 1), 1)
  net = slim.conv2d_transpose(net, 512, kernel_size=4, padding='VALID')         # net.shape = [16, 4, 4, 512]
  net0 = net
  net_out = (net, tf.zeros([batch_size, 2, 2, 3]))                              # ([16, 4, 4, 512], [16, 2, 2, 3])

  out = to_rgb(net_out[0], 1, num_outputs)                                      # out.shape = [16, 4, 4, 3]
  net = upscale2d(net_out[0])                                                   # net.shape = [16, 8, 8, 512]
  net_out = tf.cond(tf.less(0, 1), lambda: (net, out), lambda: net_out)         # ([16, 8, 8, 512], [16, 4, 4, 3])

  with tf.control_dependencies([tf.assert_equal(tf.shape(net_out[0])[1], 8)]):
    out = to_rgb(net_out[0], 2, num_outputs)                                    # out.shape = [16, 8, 8, 3]
  net = upscale2d(net_out[0])                                                   # net.shape = [16, 16, 16, 512]
  net = slim.conv2d(net, 512, 3, scope='conv1')
  #net_out = tf.cond(tf.less(3, 4), lambda: net_out, lambda: (net, out))
  net_out = tf.cond(tf.less(3, 1), lambda: (net, out), lambda: net_out)         # ([16, 8, 8, 512], [16, 4, 4, 3])

  out = to_rgb(net_out[0], 3, num_outputs)                                      # out.shape = [16, 8, 8, 3]
  up_out = upscale2d(net_out[1])                                                # out_up.shape = [16, 8, 8, 3]
  net = tf.cond(tf.equal(0.0, 0.0), lambda: out, lambda: up_out + out)

loss = tf.reduce_mean(net)
grad0 = tf.gradients(loss, net0)[0]
grad1 = tf.gradients(loss, noise)[0]
with tf.Session() as sess:
  sess.run(tf.global_variables_initializer())
  print(sess.run(net).shape)
  print(sess.run(grad0).shape)
  print(sess.run(grad1).shape)
```
"
18408,Unable to write an event file for TF-TRT model,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.7.0
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: 0.11.1
- **GCC/Compiler version (if compiling from source)**: 5.4.0
- **CUDA/cuDNN version**: 9.0/7.0.5
- **GPU model and memory**: 1080 Ti 8GB
- **Exact command to reproduce**:
```
import tensorflow as tf
from tensorflow.python.platform import gfile
with tf.Session() as sess:
    model_filename ='test_TFTRT.pb'
    with gfile.FastGFile(model_filename, 'rb') as f:
        graph_def = tf.GraphDef()
        graph_def.ParseFromString(f.read())
        g_in = tf.import_graph_def(graph_def)
LOGDIR=""/check_graph""
train_writer = tf.summary.FileWriter(LOGDIR)
train_writer.add_graph(sess.graph)
```
### Describe the problem
I was trying to write an event file for a TF-TRT model so I can visualize it after the graph was optimized by TensorRT. When running the snippet above, I got error message:

### Source code / logs
g_in = tf.import_graph_def(graph_def)
  File ""/home/user/.virtualenvs/BuildTF_1.7/local/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py"", line 432, in new_func
    return func(*args, **kwargs)
  File ""/home/user/.virtualenvs/BuildTF_1.7/local/lib/python2.7/site-packages/tensorflow/python/framework/importer.py"", line 570, in import_graph_def
    raise ValueError('No op named %s in defined operations.' % node.op)
ValueError: No op named TRTEngineOp in defined operations.
"
18405,Reopening #9294 error in RNN tutorial,"Thanks to @kevinashaw for pointing out [various](https://github.com/tensorflow/tensorflow/issues/9294) problems with the RNN tensorflow tutorial

Although the issue was closed, as far as I can see @MarkDaoust @drpngx @ebrevdo @martinwicke 
the tutorial code posted here and at TF site still has the same errors after nearly 12 months

I did try making some of the modifications suggested in the thread, they don't appear to solve the issue

Have I written custom code: NO

OS Platform and Distribution: Windows 10; 
Python v. 3.5 
TensorFlow installed from: Anaconda
TensorFlow version 1.2.0
GPU model and memory: CPU 16GB of RAM
Exact command to reproduce (see below)
```
Xin =tf.random_normal((100,100))

batch_size_var  = tf.shape(Xin)[0]
lstm = tf.nn.rnn_cell.LSTMCell(lstm_size)
hidden_state = lstm_cells.zero_state(batch_size_var, tf.float32) 
current_state = lstm_cells.zero_state(batch_size_var, tf.float32)
```

There was a suggestion to use  dynamic rnn . It wasnt fully explained but using  dynamic rnn renders the reference to .LSTMCell  invalid

Is there another RNN tutorial or a revised version anyone can recommend?



"
18402,DnnSupport::GetVersion() is failing with 'too perfect fowarding' issue with gcc-6,"A similar issue was #16309
newly added DnnSupport::GetVersion() call is causing gcc-6 compilation to fail. Using a structure instead of a tuple could workaround the issue.


> INFO: From Compiling tensorflow/contrib/seq2seq/kernels/beam_search_ops_gpu.cu.cc [for host]:
> /usr/include/c++/6/tuple: In instantiation of 'static constexpr bool std::_TC<<anonymous>, _Elements>::_MoveConstructibleTuple() [with _UElements = {const std::tuple<int, int, int>&}; bool <anonymous> = true; _Elements = {int, int, int}]':
> /usr/include/c++/6/tuple:626:248:   required by substitution of 'template<class ... _UElements, typename std::enable_if<(((std::_TC<(sizeof... (_UElements) == 1), int, int, int>::_NotSameTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_MoveConstructibleTuple<_UElements ...>()) && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyMoveConvertibleTuple<_UElements ...>()) && (3ul >= 1)), bool>::type <anonymous> > constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {const std::tuple<int, int, int>&}; typename std::enable_if<(((std::_TC<(sizeof... (_UElements) == 1), int, int, int>::_NotSameTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_MoveConstructibleTuple<_UElements ...>()) && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyMoveConvertibleTuple<_UElements ...>()) && (3ul >= 1)), bool>::type <anonymous> = <missing>]'
> ./tensorflow/stream_executor/dnn.h:891:91:   required from here
> /usr/include/c++/6/tuple:483:67: error: mismatched argument pack lengths while expanding 'std::is_constructible<_Elements, _UElements&&>'
>        return __and_<is_constructible<_Elements, _UElements&&>...>::value;
>                                                                    ^~~~~
> /usr/include/c++/6/tuple:484:1: error: body of constexpr function 'static constexpr bool std::_TC<<anonymous>, _Elements>::_MoveConstructibleTuple() [with _UElements = {const std::tuple<int, int, int>&}; bool <anonymous> = true; _Elements = {int, int, int}]' not a return-statement
>      }
>  ^
> /usr/include/c++/6/tuple: In instantiation of 'static constexpr bool std::_TC<<anonymous>, _Elements>::_ImplicitlyMoveConvertibleTuple() [with _UElements = {const std::tuple<int, int, int>&}; bool <anonymous> = true; _Elements = {int, int, int}]':
> /usr/include/c++/6/tuple:626:362:   required by substitution of 'template<class ... _UElements, typename std::enable_if<(((std::_TC<(sizeof... (_UElements) == 1), int, int, int>::_NotSameTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_MoveConstructibleTuple<_UElements ...>()) && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyMoveConvertibleTuple<_UElements ...>()) && (3ul >= 1)), bool>::type <anonymous> > constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {const std::tuple<int, int, int>&}; typename std::enable_if<(((std::_TC<(sizeof... (_UElements) == 1), int, int, int>::_NotSameTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_MoveConstructibleTuple<_UElements ...>()) && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyMoveConvertibleTuple<_UElements ...>()) && (3ul >= 1)), bool>::type <anonymous> = <missing>]'
> ./tensorflow/stream_executor/dnn.h:891:91:   required from here
> /usr/include/c++/6/tuple:489:65: error: mismatched argument pack lengths while expanding 'std::is_convertible<_UElements&&, _Elements>'
>        return __and_<is_convertible<_UElements&&, _Elements>...>::value;
>                                                                  ^~~~~
> /usr/include/c++/6/tuple:490:1: error: body of constexpr function 'static constexpr bool std::_TC<<anonymous>, _Elements>::_ImplicitlyMoveConvertibleTuple() [with _UElements = {const std::tuple<int, int, int>&}; bool <anonymous> = true; _Elements = {int, int, int}]' not a return-statement
>      }
>  ^
> /usr/include/c++/6/tuple: In instantiation of 'static constexpr bool std::_TC<<anonymous>, _Elements>::_NonNestedTuple() [with _SrcTuple = const std::tuple<int, int, int>&; bool <anonymous> = true; _Elements = {int, int, int}]':
> /usr/include/c++/6/tuple:662:419:   required by substitution of 'template<class ... _UElements, class _Dummy, typename std::enable_if<((std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ConstructibleTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyConvertibleTuple<_UElements ...>()) && std::_TC<(std::is_same<_Dummy, void>::value && (1ul == 1)), int, int, int>::_NonNestedTuple<const tuple<_Elements ...>&>()), bool>::type <anonymous> > constexpr std::tuple< <template-parameter-1-1> >::tuple(const std::tuple<_Args1 ...>&) [with _UElements = {int, int, int}; _Dummy = void; typename std::enable_if<((std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ConstructibleTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyConvertibleTuple<_UElements ...>()) && std::_TC<(std::is_same<_Dummy, void>::value && (1ul == 1)), int, int, int>::_NonNestedTuple<const tuple<_Elements ...>&>()), bool>::type <anonymous> = <missing>]'
> ./tensorflow/stream_executor/dnn.h:891:91:   required from here
> /usr/include/c++/6/tuple:495:244: error: wrong number of template arguments (4, should be 2)
>        return  __and_<__not_<is_same<tuple<_Elements...>,
>                                                                                                                                                                                                                                                     ^    
> /usr/include/c++/6/type_traits:1558:8: note: provided for 'template<class _From, class _To> struct std::is_convertible'
>      struct is_convertible
>         ^~~~~~~~~~~~~~
> /usr/include/c++/6/tuple:502:1: error: body of constexpr function 'static constexpr bool std::_TC<<anonymous>, _Elements>::_NonNestedTuple() [with _SrcTuple = const std::tuple<int, int, int>&; bool <anonymous> = true; _Elements = {int, int, int}]' not a return-statement
>      }
>  ^
> /usr/include/c++/6/tuple: In instantiation of 'static constexpr bool std::_TC<<anonymous>, _Elements>::_MoveConstructibleTuple() [with _UElements = {std::tuple<int, int, int>}; bool <anonymous> = true; _Elements = {int, int, int}]':
> /usr/include/c++/6/tuple:626:248:   required by substitution of 'template<class ... _UElements, typename std::enable_if<(((std::_TC<(sizeof... (_UElements) == 1), int, int, int>::_NotSameTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_MoveConstructibleTuple<_UElements ...>()) && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyMoveConvertibleTuple<_UElements ...>()) && (3ul >= 1)), bool>::type <anonymous> > constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {std::tuple<int, int, int>}; typename std::enable_if<(((std::_TC<(sizeof... (_UElements) == 1), int, int, int>::_NotSameTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_MoveConstructibleTuple<_UElements ...>()) && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyMoveConvertibleTuple<_UElements ...>()) && (3ul >= 1)), bool>::type <anonymous> = <missing>]'
> ./tensorflow/stream_executor/dnn.h:891:91:   required from here
> /usr/include/c++/6/tuple:483:67: error: mismatched argument pack lengths while expanding 'std::is_constructible<_Elements, _UElements&&>'
>        return __and_<is_constructible<_Elements, _UElements&&>...>::value;
>                                                                    ^~~~~
> /usr/include/c++/6/tuple:484:1: error: body of constexpr function 'static constexpr bool std::_TC<<anonymous>, _Elements>::_MoveConstructibleTuple() [with _UElements = {std::tuple<int, int, int>}; bool <anonymous> = true; _Elements = {int, int, int}]' not a return-statement
>      }
>  ^
> /usr/include/c++/6/tuple: In instantiation of 'static constexpr bool std::_TC<<anonymous>, _Elements>::_ImplicitlyMoveConvertibleTuple() [with _UElements = {std::tuple<int, int, int>}; bool <anonymous> = true; _Elements = {int, int, int}]':
> /usr/include/c++/6/tuple:626:362:   required by substitution of 'template<class ... _UElements, typename std::enable_if<(((std::_TC<(sizeof... (_UElements) == 1), int, int, int>::_NotSameTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_MoveConstructibleTuple<_UElements ...>()) && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyMoveConvertibleTuple<_UElements ...>()) && (3ul >= 1)), bool>::type <anonymous> > constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {std::tuple<int, int, int>}; typename std::enable_if<(((std::_TC<(sizeof... (_UElements) == 1), int, int, int>::_NotSameTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_MoveConstructibleTuple<_UElements ...>()) && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyMoveConvertibleTuple<_UElements ...>()) && (3ul >= 1)), bool>::type <anonymous> = <missing>]'
> ./tensorflow/stream_executor/dnn.h:891:91:   required from here
> /usr/include/c++/6/tuple:489:65: error: mismatched argument pack lengths while expanding 'std::is_convertible<_UElements&&, _Elements>'
>        return __and_<is_convertible<_UElements&&, _Elements>...>::value;
>                                                                  ^~~~~
> /usr/include/c++/6/tuple:490:1: error: body of constexpr function 'static constexpr bool std::_TC<<anonymous>, _Elements>::_ImplicitlyMoveConvertibleTuple() [with _UElements = {std::tuple<int, int, int>}; bool <anonymous> = true; _Elements = {int, int, int}]' not a return-statement
>      }
>  ^
> /usr/include/c++/6/tuple: In instantiation of 'static constexpr bool std::_TC<<anonymous>, _Elements>::_NonNestedTuple() [with _SrcTuple = std::tuple<int, int, int>&&; bool <anonymous> = true; _Elements = {int, int, int}]':
> /usr/include/c++/6/tuple:686:422:   required by substitution of 'template<class ... _UElements, class _Dummy, typename std::enable_if<((std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_MoveConstructibleTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyMoveConvertibleTuple<_UElements ...>()) && std::_TC<(std::is_same<_Dummy, void>::value && (1ul == 1)), int, int, int>::_NonNestedTuple<tuple<_Elements ...>&&>()), bool>::type <anonymous> > constexpr std::tuple< <template-parameter-1-1> >::tuple(std::tuple<_Args1 ...>&&) [with _UElements = {int, int, int}; _Dummy = void; typename std::enable_if<((std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_MoveConstructibleTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyMoveConvertibleTuple<_UElements ...>()) && std::_TC<(std::is_same<_Dummy, void>::value && (1ul == 1)), int, int, int>::_NonNestedTuple<tuple<_Elements ...>&&>()), bool>::type <anonymous> = <missing>]'
> ./tensorflow/stream_executor/dnn.h:891:91:   required from here
> /usr/include/c++/6/tuple:495:244: error: wrong number of template arguments (4, should be 2)
>        return  __and_<__not_<is_same<tuple<_Elements...>,
>                                                                                                                                                                                                                                                     ^    
> /usr/include/c++/6/type_traits:1558:8: note: provided for 'template<class _From, class _To> struct std::is_convertible'
>      struct is_convertible
>         ^~~~~~~~~~~~~~
> /usr/include/c++/6/tuple:502:1: error: body of constexpr function 'static constexpr bool std::_TC<<anonymous>, _Elements>::_NonNestedTuple() [with _SrcTuple = std::tuple<int, int, int>&&; bool <anonymous> = true; _Elements = {int, int, int}]' not a return-statement
>      }
> "
18400,Using boosted trees without an estimator,"Have I written custom code : NO
OS Platform and Distribution : CentOS
TensorFlow installed from : Sources
TensorFlow version : r1.8
Bazel version : 0.11
CUDA/cuDNN version : 9.1/7.0
GPU model and memory : GTX 1080 Ti
Exact command to reproduce : N/A

At the moment is it  possible to use the TensorFlow implementation of boosted trees without invoking the concept of an Estimator ?
[Examples](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/boosted_trees) , demonstrate its usage using estimator. 

Can it be used as just another node in a TensorFlow graph ? "
18397,Java wrapper floods temp dir with copies of extracted native library,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 7 x64
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: 1.5.0
- **Python version**: N/A
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: None

### Describe the problem

I've been working on a Java application that uses TensorFlow. I launched it thousand times - unit tests, debugging sessions, etc. And at some point I discovered I had 8 GB of tensorflow_jni.dll copies in my Temp directory.

Apparently `deleteOnExit()` is not enough to cleanup the extracted native library ([NativeLibrary.java:150](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/java/src/main/java/org/tensorflow/NativeLibrary.java#L150)). Not on Windows at least. It appears DLL is still loaded when the deletion is attempted. So the deletion fails and the DLL is left behind.

A better approach would be to use semi-static path for library extraction rather than fully random.
In such case the library could be deleted or re-used upon the next application run.

I would suggest to use a target folder name like this:
```
File tmp = new File(System.getProperty(""java.io.tmpdir""));
File dir = new File(tmp, ""tensorflow-"" + TF_VERSION + '-' + System.getProperty(""user.name"").hashCode());
```

And then check if the folder and files exist already upon startup. And either delete them and extract again (better security) or just call `System.loadLibrary()` directly.

You could still keep using `deleteOnExit()`. When it works properly the only copy of the library will not be left laying on the disk after JVM shutdown.

A similar approach is used by other native libraries handling frameworks. For example, in JNA project.
See https://github.com/java-native-access/jna/blob/master/src/com/sun/jna/Native.java"
18394,Feature Request: Early Stopping with the tf.estimator,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Pip
- **TensorFlow version (use command below)**: 1.7
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: 9
- **GPU model and memory**: NVIDIA K80
- **Exact command to reproduce**: N/A

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I would love for there to be a SessionRunHook implementation in tensorflow that implements early stopping. Now that `tf.contrib.learn` is being officially deprecated, the existing way that I did early stopping (using a ValidationMonitor) is no longer an option. This seems like a super important feature to have.

The docs indicate in several places that you can simply extend a SessionRunHook to do this, and that seems reasonable. I think that having a standard way to do this would be super useful to lots of users, perhaps even directly built into TrainSpec.


### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

N/A"
18393,label_image.py  Example:  Show ONLY results Higher than 75 % ?,"Hello,

can Sombody please explain how to change `label_image.py` from the [Example Codes](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/label_image/label_image.py)  
so its only Shows the Result (Name,Score) if the Score is Higher than 75 % , else  print "".... "" 

Would be very Helpfull."
18384,tf.decode_csv New Feature Request option to remove leading/trailing whitespace on text fields,"tf.decode_csv currently allows leading and trailing spaces with int or float fields and quietly strips the whitespace off, see: https://www.tensorflow.org/api_docs/python/tf/decode_csv
 
It would be really nice if the text fields could also have the leading/trailing whitespace stripped off. The embedded whitespace in a text field or sentence does need to be left intact, although it might be useful to compress it down to a single space between words. 
 
Pandas.read_csv has an option skipinitialspace to strip leading/trailing whitespace, which defaults to False. I would suggest a similar option for tf.decode_csv for text fields. If you wanted to aggressively deploy the option, you could default it to True.

Currently I remove whitespaces via a call to tf.py_func and a small rexexp function. There is also tf_regex_replace which works.
 
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Win 7
- **TensorFlow installed from (source or binary)**: pip install tensorflow-gpu
- **TensorFlow version (use command below)**: 1.7.0
- **Python version**: 3.6.4
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: 9.0 / cudnn64_7
- **GPU model and memory**: Nvidia GeForce GTX660, 2GB RAM
- **Exact command to reproduce**: N/A
"
18383,Feature Request: Slice replacement operation,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: b'unknown' 1.4.0
- **Python version**: 3.6.3 Anaconda
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

### Describe the problem

In the last couple of weeks I have answered up to three questions in Stack Overflow ([this](https://stackoverflow.com/questions/49493444/tensorflow-set-block-within-2d-tensor-to-constant-value/49493702), [this](https://stackoverflow.com/questions/49487647/how-to-assign-a-value-to-a-tf-variable-in-tensorflow-without-using-tf-assign/49534185) and [this](https://stackoverflow.com/questions/49755316/best-way-to-mimic-pytorch-sliced-assignment-with-keras-tensorflow/49756271)) solving essentially the same problem, namely how to replace a slice in one tensor with the contents of (a slice of) another tensor. On the one hand, newer users try to solve it with a slice assignment to a variable, which is easy and intuitive but wrong. On the other hand, even for experience users it can be quite a hassle (my approaches are either to concatenate thing after thing or make comprehensive masks and use `tf.where`, both of them, I suspect, take more resources than the operation should require).

I think everyone would benefit from a slice replacement operation that returns a tensor with a slice replaced with some values. I do not know about the technical challenges of this (e.g. to keep gradient propagation and so on), but syntactically there is the problem that one cannot use slicing syntax with functions. Like in `tf.slice`, a couple of `begin` and `size` tensors could be passed:

    tf.replace_slice(my_tensor, [1, 2], [3, 4], new_values)

But, similarly to how `tf.Tensor` implements `__getitem__` for easy slicing, it would be neat to have a simplified syntax for this. Maybe (not necessarily) something like:

    my_tensor = my_tensor.replace[1:4, 2:6].with_values(new_values) 

(I was going to say ` .with(new_values)`, but that's a keyword)

It could also be just:

    my_tensor = my_tensor[1:4, 2:6].replace_with(new_values) 

Which is more similar to how slice assignment works for variables, but that seems harder to implement consistently (the slicing should return not just a regular tensor, and the slicing operation would be created anyway even if it's not necessary).

### Source code / logs

N/A"
18382,where can I find people to help with tensorflow for windows? ,"I'm on server 2016, Windows 10 LTSB

I cannot get tensorflow to work with a tf/python open source project I have interested in.

Is there somewhere I can find help like someone good at tensorflow on Windows to remote in or use teamviewer to walk me through step by step to show me how to do a net2net and start a training (supervised training, not reinforced training) just in order to show me how to get the process started? 

I would like to convert using Net2Net an existing 15 block 192 filter to 40 block 256 filters and then start trainging it for many steps using raw training data that is also open source/public domain for it to get strong.

I'm willing to compensate them for said time and effort 
"
18380,TF does not seem to map all available VRAM in multi-gpu config,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.7.0-3-g024aecf414 1.7.0
- **Python version**: 3.5.2
- **Bazel version (if compiling from source)**: /
- **GCC/Compiler version (if compiling from source)**: /
- **CUDA/cuDNN version**: 9.0/7.0.4
- **GPU model and memory**: Tesla K80 x2
- **Exact command to reproduce**: See script in my comment below to reproduce

### Describe the problem
I am facing an OOM error (Out of memory) error while running a large TF app on a multi-gpu config (2 Tesla K80).

The memory Limit displayed by the error log accounts for the VRAM of a single GPU (12GB), while I was expecting to account both (24GB): 

```
Limit:                 11272152679
InUse:                  7797125376
MaxInUse:              10294759168
NumAllocs:                   41821
MaxAllocSize:           4742250496
```

I am 100% certain both GPUs are used, since they both show up in the log:

```
2018-04-10 12:08:37.937431: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use:
 AVX2 FMA
2018-04-10 12:08:38.052749: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero
2018-04-10 12:08:38.053215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:00:04.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2018-04-10 12:08:38.129345: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero
2018-04-10 12:08:38.129745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 1 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:00:05.0
totalMemory: 11.17GiB freeMemory: 11.10GiB
2018-04-10 12:08:38.130022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0, 1
2018-04-10 12:08:38.658026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-10 12:08:38.658156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 1 
2018-04-10 12:08:38.658180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N Y 
2018-04-10 12:08:38.658201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 1:   Y N 
2018-04-10 12:08:38.658793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10
749 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)
2018-04-10 12:08:38.853578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10
765 MB memory) -> physical GPU (device: 1, name: Tesla K80, pci bus id: 0000:00:05.0, compute capability: 3.7)
```

This behavior is inconsistent with TF documentation: https://www.tensorflow.org/programmers_guide/using_gpu#allowing_gpu_memory_growth

> By default, TensorFlow maps nearly all of the GPU memory of all GPUs

## logs
```
2018-04-10 12:09:40.993943: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.42GiB.  Current allocation summary follows.
2018-04-10 12:09:40.994041: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (256):   Total Chunks: 76, Chunks in use: 76. 19.0KiB allocated for chunks. 19.0KiB in use in bin. 1.8KiB client-requested in use in bin.
2018-04-10 12:09:40.994060: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (512):   Total Chunks: 6, Chunks in use: 6. 3.0KiB allocated for chunks. 3.0KiB in use in bin. 3.0KiB client-requested in use in bin.
2018-04-10 12:09:40.994075: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (1024):  Total Chunks: 10, Chunks in use: 10. 11.0KiB allocated for chunks. 11.0KiB in use in bin. 10.0KiB client-requested in use in bin.
2018-04-10 12:09:40.994086: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (2048):  Total Chunks: 14, Chunks in use: 14. 28.0KiB allocated for chunks. 28.0KiB in use in bin. 28.0KiB client-requested in use in bin.
2018-04-10 12:09:40.994097: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (4096):  Total Chunks: 3, Chunks in use: 2. 20.0KiB allocated for chunks. 13.5KiB in use in bin. 13.5KiB client-requested in use in bin.
2018-04-10 12:09:40.994107: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (8192):  Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-04-10 12:09:40.994118: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (16384):         Total Chunks: 5, Chunks in use: 5. 80.0KiB allocated for chunks. 80.0KiB in use in bin. 80.0KiB client-requested in use in bin.
2018-04-10 12:09:40.994126: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (32768):         Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-04-10 12:09:40.994137: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (65536):         Total Chunks: 9, Chunks in use: 9. 704.2KiB allocated for chunks. 704.2KiB in use in bin. 600.6KiB client-requested in use in bin.
2018-04-10 12:09:40.994148: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (131072):        Total Chunks: 6, Chunks in use: 5. 1.03MiB allocated for chunks. 919.5KiB in use in bin. 919.3KiB client-requested in use in bin.
2018-04-10 12:09:40.994158: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (262144):        Total Chunks: 6, Chunks in use: 6. 1.67MiB allocated for chunks. 1.67MiB in use in bin. 1.66MiB client-requested in use in bin.
2018-04-10 12:09:40.994169: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (524288):        Total Chunks: 8, Chunks in use: 7. 6.09MiB allocated for chunks. 5.27MiB in use in bin. 5.26MiB client-requested in use in bin.
2018-04-10 12:09:40.994179: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (1048576):       Total Chunks: 4, Chunks in use: 4. 4.50MiB allocated for chunks. 4.50MiB in use in bin. 4.18MiB client-requested in use in bin.
2018-04-10 12:09:40.994190: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (2097152):       Total Chunks: 4, Chunks in use: 4. 9.00MiB allocated for chunks. 9.00MiB in use in bin. 9.00MiB client-requested in use in bin.
2018-04-10 12:09:40.994200: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (4194304):       Total Chunks: 2, Chunks in use: 2. 9.00MiB allocated for chunks. 9.00MiB in use in bin. 9.00MiB client-requested in use in bin.
2018-04-10 12:09:40.994213: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (8388608):       Total Chunks: 42, Chunks in use: 39. 467.91MiB allocated for chunks. 433.54MiB in use in bin. 426.99MiB client-requested in use in bin.
2018-04-10 12:09:40.994224: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (16777216):      Total Chunks: 10, Chunks in use: 10. 170.47MiB allocated for chunks. 170.47MiB in use in bin. 157.25MiB client-requested in use in bin.
2018-04-10 12:09:40.994233: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (33554432):      Total Chunks: 11, Chunks in use: 10. 404.75MiB allocated for chunks. 369.16MiB in use in bin. 350.70MiB client-requested in use in bin.
2018-04-10 12:09:40.994269: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (67108864):      Total Chunks: 13, Chunks in use: 13. 919.70MiB allocated for chunks. 919.70MiB in use in bin. 918.65MiB client-requested in use in bin.
2018-04-10 12:09:40.994281: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (134217728):     Total Chunks: 3, Chunks in use: 3. 423.99MiB allocated for chunks. 423.99MiB in use in bin. 353.33MiB client-requested in use in bin.
2018-04-10 12:09:40.994291: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (268435456):     Total Chunks: 4, Chunks in use: 3. 8.13GiB allocated for chunks. 4.97GiB in use in bin. 4.97GiB client-requested in use in bin.
2018-04-10 12:09:40.994300: I tensorflow/core/common_runtime/bfc_allocator.cc:646] Bin for 4.42GiB was 256.00MiB, Chunk State: 
2018-04-10 12:09:40.994314: I tensorflow/core/common_runtime/bfc_allocator.cc:652]   Size: 3.17GiB | Requested Size: 2.13MiB | in_use: 0, prev:   Size: 70.67MiB | Requested Size: 70.67MiB | in_use: 1
2018-04-10 12:09:40.994325: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a280000 of size 1280
2018-04-10 12:09:40.994331: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a280500 of size 1280
2018-04-10 12:09:40.994339: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a280a00 of size 256
2018-04-10 12:09:40.994363: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a280b00 of size 256
2018-04-10 12:09:40.994371: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a280c00 of size 256
2018-04-10 12:09:40.994379: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a280d00 of size 256
2018-04-10 12:09:40.994383: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a280e00 of size 256
2018-04-10 12:09:40.994390: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a280f00 of size 256
2018-04-10 12:09:40.994398: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a281000 of size 256
2018-04-10 12:09:40.994406: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a281100 of size 512
2018-04-10 12:09:40.994414: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a281300 of size 256
2018-04-10 12:09:40.994422: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a281400 of size 256
2018-04-10 12:09:40.994429: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a281500 of size 256
2018-04-10 12:09:40.994437: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a281600 of size 256
2018-04-10 12:09:40.994444: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a281700 of size 1024
2018-04-10 12:09:40.994452: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a281b00 of size 256
2018-04-10 12:09:40.994460: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a281c00 of size 256
2018-04-10 12:09:40.994478: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a281d00 of size 256
2018-04-10 12:09:40.994485: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a281e00 of size 256
2018-04-10 12:09:40.994494: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a281f00 of size 2048
2018-04-10 12:09:40.994518: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a282700 of size 256
2018-04-10 12:09:40.994523: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a282800 of size 256
2018-04-10 12:09:40.994528: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a282900 of size 256
2018-04-10 12:09:40.994532: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a282a00 of size 256
2018-04-10 12:09:40.994537: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a282b00 of size 256
2018-04-10 12:09:40.994545: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a282c00 of size 256
2018-04-10 12:09:40.994554: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a282d00 of size 256
2018-04-10 12:09:40.994559: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a282e00 of size 256
2018-04-10 12:09:40.994567: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a282f00 of size 256
2018-04-10 12:09:40.994574: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a283000 of size 256
2018-04-10 12:09:40.994580: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a283100 of size 256
2018-04-10 12:09:40.994588: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a283200 of size 256
2018-04-10 12:09:40.994593: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a283300 of size 256
2018-04-10 12:09:40.994600: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a283400 of size 256
2018-04-10 12:09:40.994605: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a283500 of size 256
2018-04-10 12:09:40.994609: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a283600 of size 256
2018-04-10 12:09:40.994615: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a283700 of size 256
2018-04-10 12:09:40.994628: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a283800 of size 512
2018-04-10 12:09:40.994635: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a283a00 of size 256
2018-04-10 12:09:40.994642: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a283b00 of size 256
2018-04-10 12:09:40.994648: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a283c00 of size 256
2018-04-10 12:09:40.994655: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a283d00 of size 256
2018-04-10 12:09:40.994661: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a283e00 of size 1536
2018-04-10 12:09:40.994667: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a284400 of size 256
2018-04-10 12:09:40.994672: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a284500 of size 256
2018-04-10 12:09:40.994680: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a284600 of size 256
2018-04-10 12:09:40.994685: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a284700 of size 256
2018-04-10 12:09:40.994693: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a284800 of size 256
2018-04-10 12:09:40.994699: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a284900 of size 2048
2018-04-10 12:09:40.994706: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a285100 of size 256
2018-04-10 12:09:40.994712: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a285200 of size 256
2018-04-10 12:09:40.994719: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a285300 of size 256
2018-04-10 12:09:40.994725: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a285400 of size 256
2018-04-10 12:09:40.994733: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a285500 of size 256
2018-04-10 12:09:40.994738: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a285600 of size 256
2018-04-10 12:09:40.994746: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a285700 of size 256
2018-04-10 12:09:40.994751: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a285800 of size 256
2018-04-10 12:09:40.994758: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a285900 of size 256
2018-04-10 12:09:40.994764: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a285a00 of size 256
2018-04-10 12:09:40.994772: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a285b00 of size 256
2018-04-10 12:09:40.994778: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a285c00 of size 256
2018-04-10 12:09:40.994785: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a285d00 of size 256
2018-04-10 12:09:40.994791: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a285e00 of size 256
2018-04-10 12:09:40.994798: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a285f00 of size 256
2018-04-10 12:09:40.994803: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a286000 of size 256
2018-04-10 12:09:40.994810: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a286100 of size 256
2018-04-10 12:09:40.994817: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a286200 of size 256
2018-04-10 12:09:40.994824: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a286300 of size 256
2018-04-10 12:09:40.994829: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a286400 of size 256
2018-04-10 12:09:40.994837: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a286500 of size 256
2018-04-10 12:09:40.994843: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a286600 of size 256
2018-04-10 12:09:40.994850: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a286700 of size 256
2018-04-10 12:09:40.994856: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a286800 of size 256
2018-04-10 12:09:40.994864: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a286900 of size 256
2018-04-10 12:09:40.994869: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a286a00 of size 256
2018-04-10 12:09:40.994876: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a286b00 of size 256
2018-04-10 12:09:40.994882: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a286c00 of size 256
2018-04-10 12:09:40.994890: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a286d00 of size 256
2018-04-10 12:09:40.994896: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a286e00 of size 256
2018-04-10 12:09:40.994903: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a286f00 of size 256
2018-04-10 12:09:40.994908: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a287000 of size 512
2018-04-10 12:09:40.994917: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a287200 of size 512
2018-04-10 12:09:40.994922: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a287400 of size 1024
2018-04-10 12:09:40.994929: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a287800 of size 1024
2018-04-10 12:09:40.994935: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a287c00 of size 1024
2018-04-10 12:09:40.994942: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a288000 of size 2048
2018-04-10 12:09:40.994950: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a288800 of size 2048
2018-04-10 12:09:40.994959: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a289000 of size 2048
2018-04-10 12:09:40.994964: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a289800 of size 2048
2018-04-10 12:09:40.994968: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a28a000 of size 2048
2018-04-10 12:09:40.994973: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a28a800 of size 2048
2018-04-10 12:09:40.994978: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a28b000 of size 6912
2018-04-10 12:09:40.994990: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a28cb00 of size 113152
2018-04-10 12:09:40.994998: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a2a8500 of size 256
2018-04-10 12:09:40.995008: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a2a8600 of size 65536
2018-04-10 12:09:40.995018: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a2b8600 of size 81920
2018-04-10 12:09:40.995025: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a2cc600 of size 147456
2018-04-10 12:09:40.995040: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a2f0600 of size 512
2018-04-10 12:09:40.995052: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a2f0800 of size 294912
2018-04-10 12:09:40.995062: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a338800 of size 294912
2018-04-10 12:09:40.995074: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a380800 of size 512
2018-04-10 12:09:40.995080: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a380a00 of size 289536
2018-04-10 12:09:40.995086: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a3c7500 of size 71936
2018-04-10 12:09:40.995092: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a3d8e00 of size 16384
2018-04-10 12:09:40.995098: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a3dce00 of size 16384
2018-04-10 12:09:40.995106: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a3e0e00 of size 16384
2018-04-10 12:09:40.995111: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a3e4e00 of size 71936
2018-04-10 12:09:40.995118: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a3f6700 of size 107264
2018-04-10 12:09:40.995127: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a410a00 of size 589824
2018-04-10 12:09:40.995134: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a4a0a00 of size 1024
2018-04-10 12:09:40.995154: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a4a0e00 of size 2359296
2018-04-10 12:09:40.995159: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a6e0e00 of size 16384
2018-04-10 12:09:40.995164: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a6e4e00 of size 65536
2018-04-10 12:09:40.995171: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a6f4e00 of size 16384
2018-04-10 12:09:40.995179: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a6f8e00 of size 289536
2018-04-10 12:09:40.995184: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a73f900 of size 287488
2018-04-10 12:09:40.995191: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a785c00 of size 71936
2018-04-10 12:09:40.995199: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a797500 of size 215552
2018-04-10 12:09:40.995207: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a7cbf00 of size 256
2018-04-10 12:09:40.995212: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a7cc000 of size 256
2018-04-10 12:09:40.995219: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a7cc100 of size 256
2018-04-10 12:09:40.995227: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0x50a7cc200 of size 6656
2018-04-10 12:09:40.995235: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a7cdc00 of size 71936
2018-04-10 12:09:40.995240: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0x50a7df500 of size 137472
2018-04-10 12:09:40.995247: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a800e00 of size 1179648
2018-04-10 12:09:40.995253: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a920e00 of size 1024
2018-04-10 12:09:40.995260: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a921200 of size 1024
2018-04-10 12:09:40.995266: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50a921600 of size 2359296
2018-04-10 12:09:40.995273: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50ab61600 of size 1157888
2018-04-10 12:09:40.995281: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50ac7c100 of size 1201408
2018-04-10 12:09:40.995289: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50ada1600 of size 2048
2018-04-10 12:09:40.995294: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50ada1e00 of size 9437184
2018-04-10 12:09:40.995301: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50b6a1e00 of size 9437184
2018-04-10 12:09:40.995306: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50bfa1e00 of size 9437184
2018-04-10 12:09:40.995314: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50c8a1e00 of size 9437184
2018-04-10 12:09:40.995319: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50d1a1e00 of size 9437184
2018-04-10 12:09:40.995326: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50daa1e00 of size 2048
2018-04-10 12:09:40.995334: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50daa2600 of size 2048
2018-04-10 12:09:40.995342: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50daa2e00 of size 2048
2018-04-10 12:09:40.995347: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50daa3600 of size 2048
2018-04-10 12:09:40.995354: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50daa3e00 of size 2048
2018-04-10 12:09:40.995360: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50daa4600 of size 6912
2018-04-10 12:09:40.995367: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50daa6100 of size 147456
2018-04-10 12:09:40.995372: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50daca100 of size 294912
2018-04-10 12:09:40.995380: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50db12100 of size 589824
2018-04-10 12:09:40.995387: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50dba2100 of size 1179648
2018-04-10 12:09:40.995396: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50dcc2100 of size 2359296
2018-04-10 12:09:40.995400: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50df02100 of size 4718592
2018-04-10 12:09:40.995407: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50e382100 of size 9437184
2018-04-10 12:09:40.995413: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50ec82100 of size 16777216
2018-04-10 12:09:40.995421: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x50fc82100 of size 16777216
2018-04-10 12:09:40.995426: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x510c82100 of size 8388608
2018-04-10 12:09:40.995433: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x511482100 of size 16777216
2018-04-10 12:09:40.995439: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x512482100 of size 16777216
2018-04-10 12:09:40.995446: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x513482100 of size 8388608
2018-04-10 12:09:40.995454: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x513c82100 of size 8388608
2018-04-10 12:09:40.995462: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x514482100 of size 14155776
2018-04-10 12:09:40.995468: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x515202100 of size 9437184
2018-04-10 12:09:40.995475: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x515b02100 of size 9437184
2018-04-10 12:09:40.995485: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x516402100 of size 9437184
2018-04-10 12:09:40.995492: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x516d02100 of size 9437184
2018-04-10 12:09:40.995500: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x517602100 of size 2359296
2018-04-10 12:09:40.995505: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x517842100 of size 4718592
2018-04-10 12:09:40.995512: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x517cc2100 of size 9437184
2018-04-10 12:09:40.995518: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x5185c2100 of size 74097664
2018-04-10 12:09:40.995525: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x51cc6c500 of size 74097664
2018-04-10 12:09:40.995530: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x521316900 of size 36773888
2018-04-10 12:09:40.995538: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x523628900 of size 36773888
2018-04-10 12:09:40.995545: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x52593a900 of size 16777216
2018-04-10 12:09:40.995553: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x52693a900 of size 74097664
2018-04-10 12:09:40.995560: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x52afe4d00 of size 16777216
2018-04-10 12:09:40.995567: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x52bfe4d00 of size 16777216
2018-04-10 12:09:40.995573: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x52cfe4d00 of size 74097664
2018-04-10 12:09:40.995594: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x53168f100 of size 74097664
2018-04-10 12:09:40.995603: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x535d39500 of size 13893376
2018-04-10 12:09:40.995611: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x536a79400 of size 36773888
2018-04-10 12:09:40.995618: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x538d8b400 of size 74097664
2018-04-10 12:09:40.995626: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x53d435800 of size 13893376
2018-04-10 12:09:40.995634: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x53e175700 of size 13893376
2018-04-10 12:09:40.995642: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x53eeb5600 of size 8388608
2018-04-10 12:09:40.995649: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x53f6b5600 of size 8388608
2018-04-10 12:09:40.995657: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x53feb5600 of size 36773888
2018-04-10 12:09:40.995665: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x5421c7600 of size 36773888
2018-04-10 12:09:40.995672: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x5444d9600 of size 13893376
2018-04-10 12:09:40.995680: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x545219500 of size 16777216
2018-04-10 12:09:40.995688: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x546219500 of size 13893376
2018-04-10 12:09:40.995695: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x546f59400 of size 8388608
2018-04-10 12:09:40.995703: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x547759400 of size 13893376
2018-04-10 12:09:40.995711: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x548499300 of size 36773888
2018-04-10 12:09:40.995718: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x54a7ab300 of size 13893376
2018-04-10 12:09:40.995723: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x54b4eb200 of size 13893376
2018-04-10 12:09:40.995746: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x54c22b100 of size 16777216
2018-04-10 12:09:40.995754: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x54d22b100 of size 13893376
2018-04-10 12:09:40.995763: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x54df6b000 of size 13893376
2018-04-10 12:09:40.995770: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x54ecaaf00 of size 13893376
2018-04-10 12:09:40.995778: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x54f9eae00 of size 8388608
2018-04-10 12:09:40.995785: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x5501eae00 of size 13893376
2018-04-10 12:09:40.995793: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x550f2ad00 of size 13893376
2018-04-10 12:09:40.995800: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x551c6ac00 of size 13893376
2018-04-10 12:09:40.995808: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x5529aab00 of size 868352
2018-04-10 12:09:40.995813: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x552a7eb00 of size 868352
2018-04-10 12:09:40.995820: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x552b52b00 of size 868352
2018-04-10 12:09:40.995828: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0x552c26b00 of size 11288320
2018-04-10 12:09:40.995836: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x5536eaa00 of size 868352
2018-04-10 12:09:40.995843: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x5537bea00 of size 215552
2018-04-10 12:09:40.995851: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x5537f3400 of size 215552
2018-04-10 12:09:40.995856: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0x553827e00 of size 868352
2018-04-10 12:09:40.995863: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x5538fbe00 of size 868352
2018-04-10 12:09:40.995871: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0x5539cfe00 of size 10857216
2018-04-10 12:09:40.995879: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x55442a900 of size 55573504
2018-04-10 12:09:40.995886: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x55792a500 of size 13893376
2018-04-10 12:09:40.995893: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x55866a400 of size 13893376
2018-04-10 12:09:40.995901: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x5593aa300 of size 13893376
2018-04-10 12:09:40.995909: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x55a0ea200 of size 13893376
2018-04-10 12:09:40.995916: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x55ae2a100 of size 13945088
2018-04-10 12:09:40.995924: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x55bb76a00 of size 13893376
2018-04-10 12:09:40.995946: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x55c8b6900 of size 74097664
2018-04-10 12:09:40.995954: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x560f60d00 of size 75203584
2018-04-10 12:09:40.995961: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x565719100 of size 147089408
2018-04-10 12:09:40.995965: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0x56e35f900 of size 13893376
2018-04-10 12:09:40.995969: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x56f09f800 of size 296390656
2018-04-10 12:09:40.995974: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x580b48800 of size 27760896
2018-04-10 12:09:40.995978: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x5825c2100 of size 74097664
2018-04-10 12:09:40.996009: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x586c6c500 of size 36773888
2018-04-10 12:09:40.996017: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0x588f7e500 of size 37323776
2018-04-10 12:09:40.996047: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x58b316900 of size 149298176
2018-04-10 12:09:40.996055: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x594178500 of size 296390656
2018-04-10 12:09:40.996063: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x5a5c21500 of size 74097664
2018-04-10 12:09:40.996075: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x5aa2cb900 of size 36773888
2018-04-10 12:09:40.996080: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x5ac5dd900 of size 37323776
2018-04-10 12:09:40.996086: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x5ae975d00 of size 148195328
2018-04-10 12:09:40.996091: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x5b76ca500 of size 74097664
2018-04-10 12:09:40.996098: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x5bbd74900 of size 74097664
2018-04-10 12:09:40.996106: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x5c041ed00 of size 4742250496
2018-04-10 12:09:40.996115: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x6daeaed00 of size 74097664
2018-04-10 12:09:40.996123: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0x6df559100 of size 3400652032
2018-04-10 12:09:40.996130: I tensorflow/core/common_runtime/bfc_allocator.cc:671]      Summary of in-use Chunks by size: 
2018-04-10 12:09:40.996141: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 76 Chunks of size 256 totalling 19.0KiB
2018-04-10 12:09:40.996150: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 6 Chunks of size 512 totalling 3.0KiB
2018-04-10 12:09:40.996156: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 7 Chunks of size 1024 totalling 7.0KiB
2018-04-10 12:09:40.996164: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 2 Chunks of size 1280 totalling 2.5KiB
2018-04-10 12:09:40.996172: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 1536 totalling 1.5KiB
2018-04-10 12:09:40.996184: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 14 Chunks of size 2048 totalling 28.0KiB
2018-04-10 12:09:40.996193: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 2 Chunks of size 6912 totalling 13.5KiB
2018-04-10 12:09:40.996201: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 5 Chunks of size 16384 totalling 80.0KiB
2018-04-10 12:09:40.996210: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 2 Chunks of size 65536 totalling 128.0KiB
2018-04-10 12:09:40.996218: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 4 Chunks of size 71936 totalling 281.0KiB
2018-04-10 12:09:40.996226: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 81920 totalling 80.0KiB
2018-04-10 12:09:40.996234: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 107264 totalling 104.8KiB
2018-04-10 12:09:40.996243: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 113152 totalling 110.5KiB
2018-04-10 12:09:40.996251: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 2 Chunks of size 147456 totalling 288.0KiB
2018-04-10 12:09:40.996259: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 3 Chunks of size 215552 totalling 631.5KiB
2018-04-10 12:09:40.996267: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 287488 totalling 280.8KiB
2018-04-10 12:09:40.996276: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 2 Chunks of size 289536 totalling 565.5KiB
2018-04-10 12:09:40.996284: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 3 Chunks of size 294912 totalling 864.0KiB
2018-04-10 12:09:40.996295: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 2 Chunks of size 589824 totalling 1.12MiB
2018-04-10 12:09:40.996304: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 5 Chunks of size 868352 totalling 4.14MiB
2018-04-10 12:09:40.996312: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 1157888 totalling 1.10MiB
2018-04-10 12:09:40.996324: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 2 Chunks of size 1179648 totalling 2.25MiB
2018-04-10 12:09:40.996330: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 1201408 totalling 1.15MiB
2018-04-10 12:09:40.996338: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 4 Chunks of size 2359296 totalling 9.00MiB
2018-04-10 12:09:40.996350: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 2 Chunks of size 4718592 totalling 9.00MiB
2018-04-10 12:09:40.996359: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 7 Chunks of size 8388608 totalling 56.00MiB
2018-04-10 12:09:40.996371: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 11 Chunks of size 9437184 totalling 99.00MiB
2018-04-10 12:09:40.996378: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 19 Chunks of size 13893376 totalling 251.75MiB
2018-04-10 12:09:40.996386: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 13945088 totalling 13.30MiB
2018-04-10 12:09:40.996395: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 14155776 totalling 13.50MiB
2018-04-10 12:09:40.996403: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 9 Chunks of size 16777216 totalling 144.00MiB
2018-04-10 12:09:40.996411: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 27760896 totalling 26.47MiB
2018-04-10 12:09:40.996420: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 8 Chunks of size 36773888 totalling 280.56MiB
2018-04-10 12:09:40.996428: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 37323776 totalling 35.59MiB
2018-04-10 12:09:40.996436: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 55573504 totalling 53.00MiB
2018-04-10 12:09:40.996445: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 12 Chunks of size 74097664 totalling 847.98MiB
2018-04-10 12:09:40.996453: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 75203584 totalling 71.72MiB
2018-04-10 12:09:40.996461: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 147089408 totalling 140.28MiB
2018-04-10 12:09:40.996470: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 148195328 totalling 141.33MiB
2018-04-10 12:09:40.996478: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 149298176 totalling 142.38MiB
2018-04-10 12:09:40.996486: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 2 Chunks of size 296390656 totalling 565.32MiB
2018-04-10 12:09:40.996494: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 4742250496 totalling 4.42GiB
2018-04-10 12:09:40.996503: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Sum Total of in-use chunks: 7.26GiB
2018-04-10 12:09:40.996512: I tensorflow/core/common_runtime/bfc_allocator.cc:680] Stats: 
Limit:                 11272152679
InUse:                  7797125376
MaxInUse:              10294759168
NumAllocs:                   41821
MaxAllocSize:           4742250496
```"
18379,issues in the tflite_camera_example on IOS,"------------------------

### System information
- **Xcode 9.3 and Mac OS is 10.13.4  **:
- **TensorFlow r1.2**:
- **iPhone 7 plus**:


### Describe the problem
NSString* graph_path = FilePathForResourceName(model_file_name, @""tflite"");
  model = **tflite::FlatBufferModel::BuildFromFile**([graph_path UTF8String]);
  if (!model) {
    LOG(FATAL) << ""Failed to mmap model "" << graph_path;
  }
  LOG(INFO) << ""Loaded model "" << graph_path;
  model->error_reporter();
  LOG(INFO) << ""resolved reporter"";

### Source code / logs
After ""tflite::FlatBufferModel::BuildFromFile"" is excuted, and it returns
nnapi error: unable to open library libneuralnetworks.so
Loaded model 1resolved reporter(lldb) 

Does anyone know how to solve this issue? Thanks in advance."
18377,tf.layers.conv3d_transpose with channels_first flips the last two dimensions of the gradient,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: pip3 install --upgrade tf-nightly-gpu
- **TensorFlow version (use command below)**: 1.8.0-dev20180329
- **Python version**: 3.6.4
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**:N/A
- **CUDA/cuDNN version**: 9.0/7.1.2
- **GPU model and memory**: NVIDIA Geforce 940M/2GB
- **Exact command to reproduce**:
```
import tensorflow as tf
a = tf.placeholder(tf.float32, [None, 16, 4, 8, 16])
b = tf.layers.conv3d_transpose(a, 16, [1, 1, 1], (1, 2, 1), 'same', 'channels_first')
c = tf.placeholder(tf.float32, [None, 16, 4, 16, 16])
loss = tf.reduce_mean(tf.squared_difference(b, c))
train = tf.train.AdamOptimizer().minimize(loss)
```

### Describe the problem

When using ```tf.layers.conv3d_transpose``` with ```'channels_first'```, gradients are calculated with the last two dimensions flipped. The only workaround I currently know is to split the 3d convolution into 2d convolutions with the parameters shared.

### Source code / logs

Error message below.

```
Traceback (most recent call last):
  File ""C:\Users\julia\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\tensor_shape.py"", line 667, in merge_with
    new_dims.append(dim.merge_with(other[i]))
  File ""C:\Users\julia\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\tensor_shape.py"", line 140, in merge_with
    self.assert_is_compatible_with(other)
  File ""C:\Users\julia\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\tensor_shape.py"", line 113, in assert_is_compatible_with
    other))
ValueError: Dimensions 16 and 8 are not compatible

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\julia\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\ops\gradients_impl.py"", line 648, in _GradientsHelper
    in_grad.set_shape(t_in.get_shape())
  File ""C:\Users\julia\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\ops.py"", line 471, in set_shape
    self._shape_val = self._shape_val.merge_with(shape)
  File ""C:\Users\julia\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\tensor_shape.py"", line 670, in merge_with
    raise ValueError(""Shapes %s and %s are not compatible"" % (self, other))
ValueError: Shapes (?, 16, 4, 16, 8) and (?, 16, 4, 8, 16) are not compatible

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<pyshell#5>"", line 1, in <module>
    train = tf.train.AdamOptimizer().minimize(loss)
  File ""C:\Users\julia\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\training\optimizer.py"", line 390, in minimize
    grad_loss=grad_loss)
  File ""C:\Users\julia\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\training\optimizer.py"", line 483, in compute_gradients
    colocate_gradients_with_ops=colocate_gradients_with_ops)
  File ""C:\Users\julia\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\ops\gradients_impl.py"", line 488, in gradients
    gate_gradients, aggregation_method, stop_gradients)
  File ""C:\Users\julia\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\ops\gradients_impl.py"", line 655, in _GradientsHelper
    (op.name, i, t_in.shape, in_grad.shape))
ValueError: Incompatible shapes between op input and calculated input gradient.  Forward operation: conv3d_transpose/conv3d_transpose.  Input index: 2. Original input shape: (?, 16, 4, 8, 16).  Calculated input gradient shape: (?, 16, 4, 16, 8)
```"
18376,Tensorflow MNIST Estimator: does the training batch size affect the graph expected input?,"Hello Tensorflow team, 

First of all let me thank you for your amazing job. Tensorflow is one of the greatest Deep Learning frameworks out there.

I am opening this issue because I am experiencing  something weird after following the MNIST tutorial with the new Estimator high level interface. 
The training and evaluation worked fine, but visualizing the model graph on Tensorboard there is something weird: the input shape that the model requires is 100 x 784.
I thought I would see ?x784 there, because even if I did use 100 as a batch size in training, in the model function it is explicitly specified that the amount of samples in the input is variable:
 ```python
input_layer = tf.reshape(features[""x""], [-1, 28, 28, 1], name=""input_layer"")
```

Here is a screenshot from Tensorboard: as you can see in the right box, expected input size is 100x784.

![image](https://user-images.githubusercontent.com/6909990/38542816-285b9dc4-3ca3-11e8-99ac-dafb8b3822f3.png)

At first I thought this was a Tensorboard issue, but after some testing I don't think so anymore.

First of all I tried to test my model changing the amount of input samples using the Estimator interface:
- I tried to use the estimator.train and estimator.evaluate methods on the same model with different batch sizes (e.g. 50).
- I tried to use the estimator.predict method passing a single sample at a time.  

In these cases, everything worked fine.

After that, I have frozen my model using the ""freeze_graph"" script in the TensorFlow tools, and I have tried to load the frozen model into a GraphDef and to run it in a session.
This is the code I have used:
```python
import tensorflow as tf
import cv2
import numpy as np

with tf.gfile.GFile(""/path/to/my/frozen/model.pb"", ""rb"") as f:
    graph_def = tf.GraphDef()
    graph_def.ParseFromString(f.read())

with tf.Graph().as_default() as graph:
    tf.import_graph_def(graph_def, name=""prefix"")

    for op in graph.get_operations():
        print(op.name)

    # so far it worked: i was able to print the operation of the MNIST model

    x = graph.get_tensor_by_name('prefix/input_layer:0')
    y = graph.get_tensor_by_name('prefix/softmax_tensor:0')

    with tf.Session(graph=graph) as sess:
        img = cv2.imread(""/path/to/a/mnist/like/image.png"", cv2.IMREAD_GRAYSCALE)
        img = np.asarray(1-img/255, dtype=np.float32)
        img = np.reshape(img, (28, 28, 1))

        y_out = sess.run(y, feed_dict={x: [img]})
        print(y_out)
```

I got this error: **ValueError: Cannot feed value of shape (1, 28, 28, 1) for Tensor 'prefix/input_layer:0', which has shape '(100, 28, 28, 1)'**

So, I feel that I get problems if I try to use this model without passing through the Estimator interface.   
This worries me a lot, because in production I do need to freeze, optimize and convert my models to run them on TensorFlow Lite. So I won't be using the Estimator interface to perform prediction (but I still would like to employ it during training and evaluation).

### Environment
**Have I written custom code**: Yes, but only for testing purposes. My model was trained with this [MNIST tutorial code](https://github.com/tensorflow/tensorflow/blob/r1.7/tensorflow/examples/tutorials/layers/cnn_mnist.py) 
**OS Platform and Distribution**: MacOS High Sierra 10.13.3
**TensorFlow installed from**: pip
**TensorFlow version**: 1.7
**Bazel version**: N/A
**CUDA/cuDNN version**: N/A
**GPU model and memory**: N/A
**Exact command to reproduce**: N/A







"
18375,Using tensorflow lite invoke inference with multiple input tensors and specifying input node?,"**System information**
Have I written custom code: Yes
OS Platform and Distribution: Ubuntu  16.04
TensorFlow installed from: source:Yes
TensorFlow version: 1.7.0
Python version: 3.6
Bazel version: 0.11.1
GCC/Compiler version: N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A


**Describe the problem**

I converted my tflite model foo.tflite with multiple input arrays flag , I got two inputs (decoded_sample_data: FLOAT32[],decoded_sample_data:1 FLOAT32[])

When invoke inference , I refer to 
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/apis.md
float* input = interpreter->typed_input_tensor<float>(0)

**My question:**
Can  I assign the data to specific input node  like tensorflow mobile method
ex: 

private static final String INPUT_DATA_NAME = ""decoded_sample_data:0"";
private static final String SAMPLE_RATE_NAME = ""decoded_sample_data:1""; inferenceInterface.feed(SAMPLE_RATE_NAME, sampleRateList);
inferenceInterface.feed(INPUT_DATA_NAME, floatInputBuffer, RECORDING_LENGTH, 1)
inferenceInterface.run(outputScoresNames);

Thank you!


 


"
18374,Feed_dict slow in Google compute engine," _preds = sess.run(preds, feed_dict={img_placeholder: X})


while running in computer it took around 1-2 seconds while running in compute engine cost more than 50 s 
"
18373,CI nightly libtensorflow stuck,"@asimshankar @alextp the nightly libtensorflow build on the CI server seems to have been stuck for a few days now due to the Mac build. Is there a way to resolve this in order to have the binaries built for the recent changes to the eager C API? I'm currently cross-compiling on my machine but that is very expensive and so this would really help! Thanks a lot! :)

[http://ci.tensorflow.org/job/nightly-libtensorflow/](http://ci.tensorflow.org/job/nightly-libtensorflow/)"
18372,"Is Docker image tag ""latest-devel-py3"" Python2?","I'd like to use Tensorflow with Python3 on Docker.
I set my Dockerfile below then build and run.

`FROM tensorflow/tensorflow:latest-devel-py3`

I entered in a shell on Docker and typed next command.

```
# python --version
Python 2.7.12
```


Is the image tag of ""latest-devel-py3"" Python2?

However, I tried to build and run using ""latest-py3"".
This response was,
```
# python --version
Python 3.5.2
```

Anyway, could anyone describe me about the difference between ""latest-devel-py3"" and ""latest-py3""?"
18371,compile tf-lite error,"I want to **cross compile** some components of **tf-lite**.So I do these:
```
bazel build tensorflow/contrib/lite/arm_build:test_only \
      --crosstool_top=@local_config_arm_compiler//:toolchain \
      --cpu=armeabi\
      --host_crosstool_top=@bazel_tools//tools/cpp:toolchain \
      --verbose_failures
```
in my **arm_build** folder the **BUILD** file is:
```
package(default_visibility = [""//visibility:public""])
load(""//tensorflow/contrib/lite:build_def.bzl"", ""tflite_copts"")
licenses([""notice""])  # Apache 2.0
cc_binary(
    name = ""test_only"",
    srcs = [
        ""test.cc"",
    ],
    copts = [ ""-O3"",],
    linkopts = [
    ],
    deps = [
        ""//tensorflow/contrib/lite:context"",
        ""//tensorflow/contrib/lite:framework"",
        ""//tensorflow/contrib/lite:schema_fbs_version"",
    ],
    linkstatic=1,
)
```
the **test.cc** is:
```
#include <stdio.h>
int main(){
  printf(""---"");
  return 0;
}
```
Actually I just want to compile the ""context,framework and schema_fbs_version"" components.
I got like this ""**error: '_Float128' does not name a type**""
![a](https://user-images.githubusercontent.com/14851411/38535744-98ca9ada-3c74-11e8-8ad3-e4e3ef9d7c40.png)
If compiled with native gcc ,it is okay.
**gcc version 7.3.1 20180312 (GCC)**
cross-toolchain **4.9.3 raspberry pi** which was downloaded by the **Bazel(version 0.11.1**)automatically.
OS:  4.15.15-1-ARCH
Can anyone help?"
18363,"Won't build on Ubuntu 16, CUDA 9.0","I've tried to build TF from source, a number of times over the span of a week, each day pulling the latest TF.  I've tried gcc and I've tried clang.  With gcc it fails near the end.  If needed I'll open a separate issue for clang (the error is very different)

First I'll give configuration, then the FAIL output.

Configuration
--------------
 - bazel 0.11.1
 - python3.5 (/home/ubuntu/envs/med/lib/python3.5/site-packages)
 - jemalloc
 - No Google Cloud Platform support
 - No Hadoop File System support
 - Amazon S3 File System support enabled
 - No Apache Kafka Platform support
 - No XLA JIT support
 - No GDR support
 - No VERBS support
 - No OpenCL SYCL support
 - CUDA support
 - CUDA SDK 9.0
 - cuDNN version 7.0
 - TensorRT support will be enabled
 - NCCL 1.3
 - Nvidia compute capability 7.0
 - nvcc will be used as CUDA compiler
 - MPI support will be enabled for TensorFlow.
 - optimization flags during compilation when bazel option ""--config=opt"": -march=native
 - Not configuring the WORKSPACE for Android builds.


Latest fail output:
-----------------
... (many warnings before this)

./tensorflow/core/kernels/cwise_ops.h(199): warning: __device__ annotation on a defaulted function(""scalar_right"") is ignored

./tensorflow/core/kernels/cwise_ops.h(169): warning: __host__ annotation on a defaulted function(""scalar_left"") is ignored

./tensorflow/core/kernels/cwise_ops.h(169): warning: __device__ annotation on a defaulted function(""scalar_left"") is ignored

./tensorflow/core/kernels/cwise_ops.h(199): warning: __host__ annotation on a defaulted function(""scalar_right"") is ignored

./tensorflow/core/kernels/cwise_ops.h(199): warning: __device__ annotation on a defaulted function(""scalar_right"") is ignored

INFO: From Compiling tensorflow/core/kernels/data/repeat_dataset_op.cc:
tensorflow/core/kernels/data/repeat_dataset_op.cc: In member function 'virtual void tensorflow::{anonymous}::RepeatDatasetOp::MakeDataset(tensorflow::OpKernelContext*, tensorflow::DatasetBase*, tensorflow::DatasetBase**)':
tensorflow/core/kernels/data/repeat_dataset_op.cc:45:61: warning: 'count' may be used uninitialized in this function [-Wmaybe-uninitialized]
         : GraphDatasetBase(ctx), count_(count), input_(input) {
                                                             ^
tensorflow/core/kernels/data/repeat_dataset_op.cc:36:11: note: 'count' was declared here
     int64 count;
           ^
INFO: From Compiling tensorflow/core/kernels/cwise_op_gpu_bitwise_and.cu.cc:
./tensorflow/core/kernels/cwise_ops.h(169): warning: __host__ annotation on a defaulted function(""scalar_left"") is ignored

./tensorflow/core/kernels/cwise_ops.h(169): warning: __device__ annotation on a defaulted function(""scalar_left"") is ignored

./tensorflow/core/kernels/cwise_ops.h(199): warning: __host__ annotation on a defaulted function(""scalar_right"") is ignored

./tensorflow/core/kernels/cwise_ops.h(199): warning: __device__ annotation on a defaulted function(""scalar_right"") is ignored

./tensorflow/core/kernels/cwise_ops.h(169): warning: __host__ annotation on a defaulted function(""scalar_left"") is ignored

./tensorflow/core/kernels/cwise_ops.h(169): warning: __device__ annotation on a defaulted function(""scalar_left"") is ignored

./tensorflow/core/kernels/cwise_ops.h(199): warning: __host__ annotation on a defaulted function(""scalar_right"") is ignored

./tensorflow/core/kernels/cwise_ops.h(199): warning: __device__ annotation on a defaulted function(""scalar_right"") is ignored

INFO: From ProtoCompile tensorflow/core/debug/debugger_event_metadata.pb.cc:
bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/contrib/mpi/mpi_msg.pb.cc:
bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.
bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.
bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/python/framework/cpp_shape_inference.pb.cc:
bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.
bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/debug/debug_service.pb.cc:
bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.
bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.
bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.
bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.
bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.
INFO: From Compiling tensorflow/core/grappler/optimizers/graph_optimizer_stage.cc:
tensorflow/core/grappler/optimizers/graph_optimizer_stage.cc: In function 'tensorflow::Status tensorflow::grappler::GetTensorProperties(const tensorflow::grappler::GraphOptimizerContext&, const string&, tensorflow::OpInfo::TensorProperties*)':
tensorflow/core/grappler/optimizers/graph_optimizer_stage.cc:60:32: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
   if (num_outputs == 0 || port > num_outputs - 1) {
                                ^
ERROR: /home/ubuntu/downloads/tensorflow/tensorflow/contrib/mpi/BUILD:60:1: C++ compilation of rule '//tensorflow/contrib/mpi:mpi_rendezvous_mgr' failed (Exit 1)
In file included from ./tensorflow/contrib/mpi/mpi_rendezvous_mgr.h:34:0,
                 from tensorflow/contrib/mpi/mpi_rendezvous_mgr.cc:18:
./tensorflow/contrib/mpi/mpi_utils.h: In member function 'const int tensorflow::MPIUtils::GetSourceID(const string&) const':
./tensorflow/contrib/mpi/mpi_utils.h:49:11: error: 'FATAL' was not declared in this scope
       LOG(FATAL) << ""Failed to convert worker name to MPI index: "" << task_id;
           ^
./tensorflow/contrib/mpi/mpi_utils.h:49:16: error: 'LOG' was not declared in this scope
       LOG(FATAL) << ""Failed to convert worker name to MPI index: "" << task_id;
                ^
In file included from ./tensorflow/core/lib/strings/strcat.h:27:0,
                 from ./tensorflow/core/lib/strings/str_util.h:23,
                 from ./tensorflow/contrib/mpi/mpi_utils.h:25,
                 from ./tensorflow/contrib/mpi/mpi_rendezvous_mgr.h:34,
                 from tensorflow/contrib/mpi/mpi_rendezvous_mgr.cc:18:
./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetTensorDim(tensorflow::gtl::ArraySlice<T>, tensorflow::TensorFormat, char) [with T = long long int]':
./tensorflow/core/util/tensor_format.h:372:47:   required from here
./tensorflow/core/util/tensor_format.h:340:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
   CHECK(index >= 0 && index < dimension_attributes.size())
                             ^
./tensorflow/core/platform/macros.h:82:47: note: in definition of macro 'TF_PREDICT_FALSE'
 #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))
                                               ^
./tensorflow/core/util/tensor_format.h:340:3: note: in expansion of macro 'CHECK'
   CHECK(index >= 0 && index < dimension_attributes.size())
   ^
./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetFilterDim(tensorflow::gtl::ArraySlice<T>, tensorflow::FilterTensorFormat, char) [with T = long long int]':
./tensorflow/core/util/tensor_format.h:381:54:   required from here
./tensorflow/core/util/tensor_format.h:355:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
   CHECK(index >= 0 && index < dimension_attribute.size())
                             ^
./tensorflow/core/platform/macros.h:82:47: note: in definition of macro 'TF_PREDICT_FALSE'
 #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))
                                               ^
./tensorflow/core/util/tensor_format.h:355:3: note: in expansion of macro 'CHECK'
   CHECK(index >= 0 && index < dimension_attribute.size())
   ^
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 2688.392s, Critical Path: 200.30s
FAILED: Build did NOT complete successfully
"
18361,Android: Not a valid TensorFlow Graph serialization: Invalid GraphDef,"I have an issue with loading custom model into Android app. 
I'm using `LinearClassifier` and the function `export_savedmodel()` for saving the model.
It looks like this
```
model_path = model.export_savedmodel(export_dir_base=""model"", serving_input_receiver_fn=serving_input_fn)
```

Then from the path, I'm getting the file `saved_model.pb` and put it into the `assets` folder of the Android app. Then I try to load the model
```
val inferenceInterface = TensorFlowInferenceInterface(assets, ""saved_model.pb"")
```
However, at runtime IOException is thrown:
```
Failed to load model from 'saved_model.pb'
...
Android: Not a valid TensorFlow Graph serialization: Invalid GraphDef
```

Does anybody know what can be the issue? Seems like either the model is exported wrong or the issue with the implementation of `TensorFlowInferenceInterface`. Did somebody have experience loading models in Android app?

Model export is located [here](https://github.com/dkhmelenko/fitness-ml/blob/master/simple/Fitness%20Classification.ipynb)"
18360,Include C and C++ APIs with binary distributions,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Any
- **TensorFlow installed from (source or binary)**: see below
- **TensorFlow version (use command below)**: Any
- **Python version**:  Any
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

When you install a precompiled Tensorflow binary with pip or conda, it doesn't include the C and C++ interfaces.  To use it from those languages, you need to compile Tensorflow for source and build a special version of it that includes the needed API (see #2412).  I suggest including them in the standard binaries.  This would have multiple benefits.

First, it would make development in other languages much easier.  You could just `pip install tensorflow` and link against the library it installed.  Having to build a special version of Tensorflow from source adds an unnecessary barrier to getting started.

Second, it would eliminate a problem that so far I've been unable to resolve.  I want to create a C++ library that uses Tensorflow.  That library will be usable directly from C++, but I'll also use SWIG to create a Python wrapper for it.  For example, a user should be able to write Python code to build a Graph, then pass it directly to my library.

That won't work right now, because there are two separate versions of Tensorflow involved, one that Python is linked against and a different one that my library is linked against.  When the user is building a Graph in Python, they're working with one Tensorflow library.  But when they try to pass it to my library, they're suddenly switching to a completely different copy of Tensorflow, so it doesn't have access to memory allocated by the first copy.  I haven't found any solution to this problem."
18359,Tensorflow import error for tf.contrib.data.python.ops.threadpool(used for benchmark script),"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No, I am trying to run tf_cnn_benchmarks provided by tensorflow
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Redhat linux 7.4
- **TensorFlow version (use command below)**: v1.5.0-0-g37aa430d84 1.5.0
- **GCC/Compiler version (if compiling from source)**:c++ (GCC) 5.3.0
- **CUDA/cuDNN version**:cuda-toolkit/9.0.176 nccl/2.1.2-1 anaconda cuDNN/9.0v7
- **GPU model and memory**: Tesla k40, memory 55gb
- **Exact command to reproduce**:  python tf_cnn_benchmarks.py 

### Describe the problem
I am trying to run the benchmark provided in this link([https://github.com/tensorflow/benchmarks/blob/master/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py])
It says it can not import threadpool. Threadpool is inside tf.contrib.data API which may be deprecated. 



### Source code / logs
I am including the trace below:

```
>>> import tensorflow
>>> from tensorflow.contrib.data.python.ops import threadpool
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ImportError: cannot import name threadpool
```

"
18358,"Not a valid TensorFlow Graph serialization: NodeDef expected inputs '' do not match 1 inputs specified; Op<name=Const; signature= -> output:dtype; attr=value:tensor; attr=dtype:type>; NodeDef: dropout_1/cond/dropout/random_uniform/max = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [] values: 1>](dropout_1/cond/Switch:1)","I used Transfer Learning to learn a set of features. So used these 3 final layers on my transfer learning task.

_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 256)               6422784   
_________________________________________________________________
dropout_1 (Dropout)          (None, 256)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 514       
=================================================================
Total params: 6,423,298
Trainable params: 6,423,298
Non-trainable params: 0
_________________________________________________________________

 All workout on ipythonNotebook but after making it into a .pb file and loading into Android Studio. This error occurs

> **Not a valid TensorFlow Graph serialization: NodeDef expected inputs '' do not match 1 inputs specified; Op<name=Const; signature= -> output:dtype; attr=value:tensor; attr=dtype:type>; NodeDef: dropout_1/cond/dropout/random_uniform/max = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [] values: 1>](dropout_1/cond/Switch:1)**

**The same code works on those models which have input on their first layer**
_Example: conv2d_input_1_ which was my previous task which didn't relate to transfer learning but as soon as the model changed the code didn't work. I think tensorflowAndroid wants the input layer to feed the images but our transfer learning model doesn't have the input layer to feed and is showing problem everytime
I checked the version of tensorflow and tensorflow on android and matched the version but still no luck. Could you please help me!!

"
18357,Bug: GPU resources not released appropriately when graph is reset & session is closed,"Have I written custom code: Forked network arch for FasterRCNN from `https://github.com/endernewton/tf-faster-rcnn`
OS Platform and Distribution: Ubuntu 16.04.4, x86_64 GNU/Linux
TensorFlow installed from: 
Bazel version: 0.5.2
CUDA/cuDNN version: CUDA V8.0.61, release 8.0
GPU model and memory: `Nvidia Tesla K80`, 12 GB memory
Exact procedure to reproduce: Load `graph` and `net` in GPU memory, use `tf.reset_default_graph()` followed by `sess.close()`, GPU memory not freed as seen through `nvidia-smi`
______________________________________________________________________________________________
Possible duplicate but re-opening here since it doesn't appear to have been resolved & there's no way to re-open the previously filed ones:

Versions Used/Tried:
 - System: aws EC2 (ubuntu) (with p2.xlarge elastic GPU instance)
 - GPU: `NVIDIA Tesla K80`
 - Tensorflow versions: 1.3.0, 1.5.5 (tried on both)
 - CUDA Version: 8.0, 9.0 (tried on both)

Calling `tf.reset_graph()` and `sess.close()` doesn't free GPU as seen using `nvidia-smi`. 
It might be possible that nvidia-smi doesn't update but in that case, there wouldn't be resource errors on subsequent code trying to run on the GPU as seen here:
![image](https://user-images.githubusercontent.com/15898956/38519614-6ad30aec-3c0e-11e8-895e-b9b2d20dab17.png)

What i tried after this was to use a subprocess within my script to kill the previous processes occupying resources on the GPU as seen here:
![image](https://user-images.githubusercontent.com/15898956/38519591-55817534-3c0e-11e8-8bae-51d91e20b98e.png)
Although this works, it seems like incredibly bad practice & I shouldn't be doing this.

What I tried then was to use the `numba` host API for interacting with the GPU to shut down processes i.e. clear `current_context` and then clear deallocations from the GPU like this:
`from numba import cuda
current_context = get_context(devnum=0)
current_context.reset()
cuda.current_context().deallocations.clear()`

When this didn't work out, as a last resort, i tried to use this:
`from numba import cuda
cuda.gpus[0].numba.cuda.cudadrv.devices.reset()` 
which works but results in a substantial memory leak everytime it runs which implies that after running my code a few times, the leak accumulated to a large enough value to again give me  resource errors.

___________________________________________________________________________________________________

Context: I am trying to deploy a deep learning model using a flask API. Since this is a pipeline with multiple computation graphs, I cannot afford to keep all of those in memory so i need to do something like this:
1) Upload data & store it
2) Build Graph
2) Run Inference on stored data
3) Remove graph from memory
4) Build new graph
5) Run Inference on stored data again
.
.
....and so on
--------------------------------------------------------------------------------------------
What I suspect might be going on under the hood:
          It's possible that `tf.reset_graph()` frees memory but doesn't remove the actual process holding onto that chunk of memory in the GPU in which case it makes sense for `nvidia-smi` to still show me the PID occupying memory in the GPU. But shouldn't `tf.reset_graph()` followed by `sess.close()` be freeing the GPU entirely?

----------

Any help on the issue will be appreciated."
18356,Failed to build for iOS using Xcode 9.3: thread-local storage is not supported for the current target,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS High Sierra 10.13.3
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.6.0
- **Python version**: 2.7.14
- **Bazel version (if compiling from source)**: 0.9.0
- **GCC/Compiler version (if compiling from source)**: Xcode 9.3: `Apple LLVM version 9.1.0 (clang-902.0.39.1)`
- **CUDA/cuDNN version**: n/a
- **GPU model and memory**: n/a
- **Exact command to reproduce**: `tensorflow/contrib/makefile/build_all_ios.sh -g /path/to/model.pb`

### Describe the problem
As of Xcode 9.3 (was working fine on 9.2), compiling TF for iOS using `build_all_ios.sh` fails, complaining that ""thread-local storage is not supported for the current target"". This is related to #12573, which introduced the `thread_local` attribute for iOS builds.

### Source code / logs
```
$ tensorflow/contrib/makefile/build_all_ios.sh -g /path/to/model.pb
[...]
gcc --std=c++11 -DIS_SLIM_BUILD -fno-exceptions -DNDEBUG -O3 -DANDROID_TYPES=__ANDROID_TYPES_FULL__ -DSELECTIVE_REGISTRATION -DSUPPORT_SELECTIVE_REGISTRATION -mios-simulator-version-min=9.0 -arch i386 -mno-sse -fembed-bitcode -D__thread=thread_local -DUSE_GEMM_FOR_CONV -Wno-c++11-narrowing -DTF_LEAN_BINARY -D__ANDROID_TYPES_FULL__ -fno-exceptions -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator11.3.sdk -MT /Users/json/everalbum/ios-sdk/submodules/tensorflow/tensorflow/contrib/makefile/gen/obj/ios_I386/tensorflow/core/common_runtime/local_device.o -MMD -MP -MF /Users/json/everalbum/ios-sdk/submodules/tensorflow/tensorflow/contrib/makefile/gen/dep/ios_I386//tensorflow/core/common_runtime/local_device.Td -I. -I/Users/json/everalbum/ios-sdk/submodules/tensorflow/tensorflow/contrib/makefile/downloads/ -I/Users/json/everalbum/ios-sdk/submodules/tensorflow/tensorflow/contrib/makefile/downloads/eigen -I/Users/json/everalbum/ios-sdk/submodules/tensorflow/tensorflow/contrib/makefile/downloads/gemmlowp -I/Users/json/everalbum/ios-sdk/submodules/tensorflow/tensorflow/contrib/makefile/downloads/nsync/public -I/Users/json/everalbum/ios-sdk/submodules/tensorflow/tensorflow/contrib/makefile/downloads/fft2d -I/Users/json/everalbum/ios-sdk/submodules/tensorflow/tensorflow/contrib/makefile/gen/proto/ -I/Users/json/everalbum/ios-sdk/submodules/tensorflow/tensorflow/contrib/makefile/gen/proto_text/ -I/Users/json/everalbum/ios-sdk/submodules/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host/include -I/usr/local/include -c tensorflow/core/common_runtime/local_device.cc -o /Users/json/everalbum/ios-sdk/submodules/tensorflow/tensorflow/contrib/makefile/gen/obj/ios_I386/tensorflow/core/common_runtime/local_device.o
In file included from tensorflow/core/common_runtime/local_device.cc:18:
In file included from ./tensorflow/core/common_runtime/local_device.h:19:
In file included from ./tensorflow/core/common_runtime/device.h:35:
In file included from ./tensorflow/core/framework/allocator.h:23:
In file included from ./tensorflow/core/framework/numeric_types.h:21:
In file included from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1:
In file included from /Users/json/everalbum/ios-sdk/submodules/tensorflow/tensorflow/contrib/makefile/downloads/eigen/unsupported/Eigen/CXX11/Tensor:79:
In file included from /Users/json/everalbum/ios-sdk/submodules/tensorflow/tensorflow/contrib/makefile/downloads/eigen/unsupported/Eigen/CXX11/ThreadPool:58:
/Users/json/everalbum/ios-sdk/submodules/tensorflow/tensorflow/contrib/makefile/downloads/eigen/unsupported/Eigen/CXX11/src/ThreadPool/SimpleThreadPool.h:153:5: error:
      thread-local storage is not supported for the current target
    EIGEN_THREAD_LOCAL PerThread per_thread;
    ^
/Users/json/everalbum/ios-sdk/submodules/tensorflow/tensorflow/contrib/makefile/downloads/eigen/unsupported/Eigen/CXX11/src/ThreadPool/ThreadLocal.h:15:35: note:
      expanded from macro 'EIGEN_THREAD_LOCAL'
#define EIGEN_THREAD_LOCAL static __thread
                                  ^
<command line>:6:18: note: expanded from here
#define __thread thread_local
```"
18355,Cannot return string from tf.data map function,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.6.0
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: see below

### Describe the problem
The map method of tf.data does not allow returning a string because no implicit conversion to a tensor is made. Instead, an error `AttributeError: 'str' object has no attribute 'get_shape'` is raised.

According to @mrry this is a bug introduced in TF 1.5. For a reference, see the comments at: https://stackoverflow.com/questions/49668252/returning-strings-in-tf-data-dataset-map-method this is also the Q&A that originally noted this problem.

### Source code / logs
To reproduce:
```
import tensorflow as tf

def map_fn(x):
    return x*2, 'foo'

dataset = tf.data.Dataset.range(5)
dataset = dataset.map(map_fn)
```

Error trace:
```
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/username/tensorflow-remote/local/lib/python2.7/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 790, in map
    return MapDataset(self, map_func)
  File ""/home/username/tensorflow-remote/local/lib/python2.7/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 1597, in __init__
    self._map_func.add_to_graph(ops.get_default_graph())
  File ""/home/username/tensorflow-remote/local/lib/python2.7/site-packages/tensorflow/python/framework/function.py"", line 486, in add_to_graph
    self._create_definition_if_needed()
  File ""/home/username/tensorflow-remote/local/lib/python2.7/site-packages/tensorflow/python/framework/function.py"", line 321, in _create_definition_if_needed
    self._create_definition_if_needed_impl()
  File ""/home/username/tensorflow-remote/local/lib/python2.7/site-packages/tensorflow/python/framework/function.py"", line 338, in _create_definition_if_needed_impl
    outputs = self._func(*inputs)
  File ""/home/username/tensorflow-remote/local/lib/python2.7/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 1585, in tf_map_func
    ret, [t.get_shape() for t in nest.flatten(ret)])
AttributeError: 'str' object has no attribute 'get_shape'
```
"
18354,LookupError: No gradient defined for operation DepthwiseConv2dNativeBackpropFilter,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Fedora 27
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: b'v1.3.0-rc1-3011-gd86448938' 1.3.0
- **Python version**: Python 3.6.4 
-Bazel version: N/A
-CUDA/cuDNN version: N/A
-GPU model and memory: N/A
- **Exact command to reproduce**:

```
import tensorflow as tf

inp = tf.ones((1, 2, 2, 5))
shape = (3, 3, 5, 1)
filters = tf.Variable(tf.zeros_initializer()(shape))
conv = tf.nn.depthwise_conv2d(inp, filters, strides=[1, 1, 1, 1], padding=""SAME"")
value_layer = tf.layers.Dense(
    units=1, kernel_initializer=tf.zeros_initializer(), use_bias=False, activation=None)
val = value_layer.apply(conv)

trainer = tf.train.GradientDescentOptimizer(1e-4)
v_grads, _ = zip(*trainer.compute_gradients(val))
v_gradsf = tf.concat([tf.reshape(e, [-1, 1]) for e in v_grads], axis=0)
vweights = tf.random_uniform((50, 1))
dot = tf.matmul(tf.transpose(v_gradsf), vweights)
v_hess, _ = zip(*trainer.compute_gradients(dot))

sess = tf.Session()
sess.run(tf.global_variables_initializer())
print(sess.run((v_grads, dot, v_hess)))
```
```
LookupError: No gradient defined for operation 'gradients/depthwise_grad/DepthwiseConv2dNativeBackpropFilter' (op type: DepthwiseConv2dNativeBackpropFilter)
```
I'm not sure if this is a bug or feature request. "
18353,InvalidArgumentError in tensorflow reduce_sum gradient when compiling from sources (still a problem in TF 1.7),"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: source, without AVX support
- **TensorFlow version (use command below)**: 1.7.0
- **Python version**: 3.5.4
- **Bazel version (if compiling from source)**: CMake 3.10.3
- **GCC/Compiler version (if compiling from source)**: MSVC 2017
- **CUDA/cuDNN version**: CPU only
- **GPU model and memory**: CPU only
- **Exact command to reproduce**:
Using the same example provided in [#12177](https://github.com/tensorflow/tensorflow/issues/12177) and following the suggestions in the comment:
```
import tensorflow as tf
import numpy as np

x = tf.placeholder(tf.float32, [2,3])
y = tf.placeholder(tf.float32, [2,3])
W = tf.Variable(tf.random_normal([3,3], stddev=0.01))

z = tf.matmul(x, W)
# works when removing the reduce_sum op
z = tf.reduce_sum(tf.multiply(z, y), axis=1, keep_dims=True)

optimizer = tf.train.AdamOptimizer()
train_op = optimizer.minimize(z)

Xdata = np.array([[1,2,3],[4,5,6]])
Ydata = np.array([[2,3,4],[3,4,5]])

op = tf.get_default_graph().get_operation_by_name(""gradients/Sum_grad/Reshape"")
with tf.Session() as sess:
    for input_ in op.inputs:
        print(input_, sess.run(input_, feed_dict={x: Xdata, y: Ydata}))
    sess.run(tf.global_variables_initializer())
    sess.run(train_op, feed_dict={ x: Xdata, y: Ydata })
    print('done')
```
Results:
- Build from source
```
Tensor(""gradients/Fill:0"", shape=(2, 1), dtype=float32) [[1.]
 [1.]]
Tensor(""gradients/Sum_grad/DynamicStitch:0"", shape=(?,), dtype=int32) [2 1 0 ... 0 0 0]
2018-04-09 14:59:09.801431: F C:\Users\hcheng\tensorflow\tensorflow\core\framework\tensor_shape.cc:243] Check failed: ndims_byte() < MaxDimensions() (unsigned char value 254 vs. 254)Too many dimensions in tensor
```
- Precompiled binary
```
Tensor(""gradients/Fill:0"", shape=(2, 1), dtype=float32) [[1.]
 [1.]]
Tensor(""gradients/Sum_grad/DynamicStitch:0"", shape=(?,), dtype=int32) [2 1]
done
```

"
18352,Placeholder not replaced by import_graph_def input_map argument,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: I have written custom code
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04 
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.6
- **Python version**: 3.5
- **Bazel version (if compiling from source)**: n/a
- **GCC/Compiler version (if compiling from source)**: n/a
- **CUDA/cuDNN version**: n/a
- **GPU model and memory**: n/a
- **Exact command to reproduce**: 

### Problem Description
I'm having trouble connecting a placeholder in a GraphDef loaded from a file to a dataset provider using the`input_map` argument to `tf.import_graph_def`, and I don't think it's behaving as expected.

I first set up a data source, referenced in a tensor called `images`. Then I load a GraphDef from a file that contains a Placeholder called `batch`. Then I call

      tf.import_graph_def(quantized_graph_def, input_map={'batch': images}, name='')

to connect them together. When I run this I get the error:

    InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 
    'batch_1' with dtype float and shape [100,224,224,3]
                 [[Node: batch_1 = Placeholder[dtype=DT_FLOAT, shape=[100,224,224,3], 
    _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]

According to the documentation for `tf.import_graph_def`:

> `input_map`: A dictionary mapping input names (as strings) in graph_def to Tensor objects. The values of the named input tensors in the imported graph will be re-mapped to the respective Tensor values.

As I understand it, the `input_map` argument should connect the two graphs, but that doesn't seem to be working. See related article [""Connecting Two Graphs Together using `import_graph_def`""](https://blog.konpat.me/tf-connecting-two-graphs-together/). I believe that I am doing the same thing as in the article.

### Source Code/Logs

This script borrows heavily from [`models/research/slim/eval_image_classifier.py`](https://github.com/tensorflow/models/blob/master/research/slim/eval_image_classifier.py).

First I open a graph

    with tf.Graph().as_default():

Then I set up a dataset provider and preprocessing function using the `slim` API

      # Select the dataset
      # Create a dataset provider that loads data from the dataset
      # Select the preprocessing function
      ...
      image = image_preprocessing_fn(image, eval_image_size, eval_image_size)

      images, labels = tf.train.batch(
          [image, label],
          batch_size=batch_size,
          num_threads=num_preprocessing_threads,
          capacity=5 * batch_size)

Then I import a graph from a GraphDef from a file and load it into the current graph using `import_graph_def`

      quantized_graph_def = graph_pb2.GraphDef()
      with tf.gfile.FastGFile(path.join(cwd(), quantized_graph_filename), 'rb') as f:
        quantized_graph_def.ParseFromString(f.read())
      tf.import_graph_def(quantized_graph_def, input_map={'batch': images}, name='')

Then I set up the metrics and call `slim.evaluation.evaluate_once` to process the batches

      # Define the metrics:
      names_to_values, names_to_updates = slim.metrics.aggregate_metric_map({
          'Accuracy': slim.metrics.streaming_accuracy(predictions, labels),
          'Recall_5': slim.metrics.streaming_recall_at_k(
              logits, labels, 5),
      })

      ...

      slim.evaluation.evaluate_once(
          master=master,
          checkpoint_path=checkpoint_path,
          logdir=log_dir,
          num_evals=num_batches,
          eval_op=list(names_to_updates.values()))

When I run this I get the following error:

    Caused by op 'batch_1', defined at:
      File ""vanilla_vgg.py"", line 319, in <module>
        import_quantized_graph_with_imagenet()
      File ""vanilla_vgg.py"", line 251, in import_quantized_graph_with_imagenet
        tf.import_graph_def(quantized_graph_def, input_map={'batch': images}, name='')
      File ""/localtmp/mp3t/venv/doggett/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py"", line 432, in new_func
        return func(*args, **kwargs)
      File ""/localtmp/mp3t/venv/doggett/lib/python3.5/site-packages/tensorflow/python/framework/importer.py"", line 553, in import_graph_def
        op_def=op_def)
      File ""/localtmp/mp3t/venv/doggett/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 3271, in create_op
        op_def=op_def)
      File ""/localtmp/mp3t/venv/doggett/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1650, in __init__
        self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

    InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'batch_1' with dtype float and shape [100,224,224,3]
             [[Node: batch_1 = Placeholder[dtype=DT_FLOAT, shape=[100,224,224,3], _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]

The GraphDef that I am loading has a Placeholder op with the name `batch`, with the same shape and dtype as the tensor `images`. For reference, running `print(images)` returns:

    Tensor(""batch:0"", shape=(100, 224, 224, 3), dtype=float32)

I have also tried using `batch:0` and `batch_1` as the key to the `input_map` but neither works.

The `evaluate_once` function runs a batch of images in a single function call, so I cannot simply call `images.eval()` and pass the result to `evaluate_once` because it would only run the first batch. So the two graphs must be connected and able to be run with a single invocation.
"
18351,TF Lite Documentation and Raspberry Pi Demo Request,"Hi All,

I want to request further documentation for running TF Lite on a Raspberry Pi.
I was really impressed by the SSD demo shown by Andrew Selle during the TensorFlow Dev Summit and would love to see documentation to reimplement something like that.

At some point the tensorflow/contrib/lite/README.md stated something about a Raspberry Pi demo app coming soon, but it is no longer there. Is this something that you still plan to support?

Thanks!"
18345,Using Tensorflow with RNNs & batch normalisation,"### System information
- **Have I written custom code**: Yes
- **OS Platform and Distribution**: Archlinux/Linux 4.14
- **TensorFlow installed from**: source (will segfault before [7535f6b](https://github.com/tensorflow/tensorflow/commit/7535f6beb7ba95bf54e1513b0c2c51b844a7a49f))
- **TensorFlow version**: b'unknown' 1.7.0 / latest master
- **Python version**: 3.6
- **Bazel version**: 0.11.1
- **GCC/Compiler version**: 7.3.0
- **CUDA/cuDNN version**: 9.1/7.1.2
- **GPU model and memory**: Titan XP/12GB
- **Exact command to reproduce**: See below

### Describe the problem

When trying to run the source code below I get an error saying there's a cycle in my graph. This only seems to happen with XLA enabled and does not happen if I don't include the [additional required control dependency for batch normalisation](https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization). Indeed this seems to occur whenever I use a dynamic RNN in combination with batch normalisation and XLA JIT support.

#### Sample code to reproduce

```Python
import tensorflow as tf                                                                                                                                                                                                                       

with tf.device('/cpu:0'):
    xin = tf.placeholder(tf.float32, [None, 1, 1], name='input')
    rnn_cell = tf.contrib.rnn.LSTMCell(1)
    out, _ = tf.nn.dynamic_rnn(rnn_cell, xin, dtype=tf.float32)
    out = tf.layers.batch_normalization(out, training=True)
    out = tf.identity(out, name='output')

    optimiser = tf.train.AdamOptimizer(.0001)
    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)
    with tf.control_dependencies(update_ops):
        out = optimiser.minimize(out, global_step=tf.Variable(0, dtype=tf.float32), name='train_op')

config = tf.ConfigProto(allow_soft_placement = False)
sess = tf.Session(config=config)
sess.run(tf.global_variables_initializer())

sample_in = [[[0]]]
sess.run(out, feed_dict={xin: sample_in})
```
#### Output log
```
2018-04-03 13:09:24.326950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 0 with properties:                                                                                                                          
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:65:00.0
totalMemory: 11.90GiB freeMemory: 11.74GiB
2018-04-03 13:09:24.326982: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1312] Adding visible gpu devices: 0
2018-04-03 13:09:24.512956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11366 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:65:00.0, compute capability: 6.1)
Traceback (most recent call last):
  File ""/home/thom/.python/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1361, in _do_call
    return fn(*args)
  File ""/home/thom/.python/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1340, in _run_fn
    target_list, status, run_metadata)
  File ""/home/thom/.python/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py"", line 516, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.InternalError: Cycle detected when adding enter->frame edge: Edge from gradients/f_count to (null) would create a cycle.
+-> (null)
|   rnn/TensorArrayStack/TensorArrayGatherV3
|   rnn/transpose_1
|   batch_normalization/moments/mean
|   batch_normalization/moments/Squeeze
|   batch_normalization/AssignMovingAvg/sub
|   batch_normalization/AssignMovingAvg/mul
|   batch_normalization/AssignMovingAvg
+-- gradients/f_count
```

### Workaround

I seem to be able to workaround the issue by relying on [`tf.contrib.layers.batch_norm`](https://www.tensorflow.org/api_docs/python/tf/contrib/layers/batch_norm) instead of [`tf.layers.batch_normalization`](https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization) by setting the `updates_collections` parameter to `None` in order to force inlining of the update operation.

#### Sample code with workaround

```Python
import tensorflow as tf                                                                                                                                                                                                                       

with tf.device('/cpu:0'):
    xin = tf.placeholder(tf.float32, [None, 1, 1], name='input')
    rnn_cell = tf.contrib.rnn.LSTMCell(1)
    out, _ = tf.nn.dynamic_rnn(rnn_cell, xin, dtype=tf.float32)
    out = tf.contrib.layers.batch_norm(out, is_training=True, updates_collections=None)
    out = tf.identity(out, name='output')

    optimiser = tf.train.AdamOptimizer(.0001)
    out = optimiser.minimize(out, global_step=tf.Variable(0, dtype=tf.float32), name='train_op')

config = tf.ConfigProto(allow_soft_placement = False)
sess = tf.Session(config=config)
sess.run(tf.global_variables_initializer())

sample_in = [[[0]]]
sess.run(out, feed_dict={xin: sample_in})
```

### Additional information

1. I have already submitted a question on [Stack Overflow](https://stackoverflow.com/questions/49630269/using-tensorflow-with-rnns-batch-normalisation) a week ago and have had no answers so far.
2. Make sure you try and reproduce the issue on the tip of master or the sample will cause a segmentation fault.
"
18343,iOS Demo can't run,"iOS Demo run crash in interpreter.h line 221 if (tensor_ptr->type == typeToTfLiteType<T>()) ,How can I solve this problem?

Have I written custom code : NO
OS Platform and Distribution: High Sierra 10.13.4,  iOS 11.3 on iPhoneX,iOS11.0.3 on iPhone6
TensorFlow installed from : https://github.com/tensorflow/tensorflow
TensorFlow version : 1.7.0
Exact command to reproduce  : Followed instructions at https://www.tensorflow.org/mobile/tflite/demo_ios"
18342,operation concat causes error when using toco converter,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:Y
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:16.04
- **TensorFlow installed from (source or binary)**:source
- **TensorFlow version (use command below)**:('v1.7.0-1116-g5d33c1e', '1.7.0')
- **Python version**: 2.7
- **Bazel version (if compiling from source)**:0.11.1
- **GCC/Compiler version (if compiling from source)**:4.8.5
- **CUDA/cuDNN version**:9.1/7.1
- **GPU model and memory**: TITAN X (Pascal) 



### Describe the problem
 HI,I am trying to quantize ssd_mobilenet_v1 using tensorflow object detection api.First,I replace all the graph_hook_fn with tf.contrib.quantize.create_training_graph and enable fused batch norm in https://github.com/tensorflow/models/blob/b6bcc450b981eba721ee2760c92d87da86900988/research/object_detection/models/ssd_mobilenet_v1_feature_extractor.py#L114. After training, I manage to get the mobilenet_ssd.tflite with the commands below.Then,I deploy the tflite model file in  a SAMSUNG GALAXY Note 8 but failed with the following exception,which happens in:
https://github.com/tensorflow/tensorflow/blob/3e0fd55ccec1f8ac5ca7d11f9999a16871a9198c/tensorflow/contrib/lite/java/src/main/native/nativeinterpreterwrapper_jni.cc#L410-L419

>     java.lang.RuntimeException: java.lang.NullPointerException: Can not allocate memory for the interpreter at org.tensorflow.demo.TFLiteObjectDetectionAPIModel.create(TFLiteObjectDetectionAPIModel.java:181)
        at org.tensorflow.demo.DetectorActivity.onPreviewSizeChosen(DetectorActivity.java:109)
        at org.tensorflow.demo.CameraActivity.onPreviewFrame(CameraActivity.java:119)
        at android.hardware.Camera$EventHandler.handleMessage(Camera.java:1162)
        at android.os.Handler.dispatchMessage(Handler.java:102)
        at android.os.Looper.loop(Looper.java:135)
        at android.app.ActivityThread.main(ActivityThread.java:5232)
        at java.lang.reflect.Method.invoke(Native Method)
        at java.lang.reflect.Method.invoke(Method.java:372)
        at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:904)
        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:699)
     Caused by: java.lang.NullPointerException: Can not allocate memory for the interpreter
        at org.tensorflow.lite.NativeInterpreterWrapper.createInterpreter(Native Method)
        at org.tensorflow.lite.NativeInterpreterWrapper.<init>(NativeInterpreterWrapper.java:50)
        at org.tensorflow.lite.Interpreter.<init>(Interpreter.java:77)
        at org.tensorflow.demo.TFLiteObjectDetectionAPIModel.create(TFLiteObjectDetectionAPIModel.java:179)
        at org.tensorflow.demo.DetectorActivity.onPreviewSizeChosen(DetectorActivity.java:109) 
        at org.tensorflow.demo.CameraActivity.onPreviewFrame(CameraActivity.java:119) 
        at android.hardware.Camera$EventHandler.handleMessage(Camera.java:1162) 
        at android.os.Handler.dispatchMessage(Handler.java:102) 
        at android.os.Looper.loop(Looper.java:135) 
        at android.app.ActivityThread.main(ActivityThread.java:5232) 
        at java.lang.reflect.Method.invoke(Native Method) 
        at java.lang.reflect.Method.invoke(Method.java:372) 
        at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:904) 
        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:699) 

When I convert .tflite back to .pb format and check the inference graph in tensorboard,I find some relu6_unfused nodes are not quantized properly.What is the problem?
**Before toco convert** 
![before](https://user-images.githubusercontent.com/37242917/38499663-e9870b50-3c3a-11e8-9993-431b392f3104.png)

**After toco convert** 
![relu](https://user-images.githubusercontent.com/37242917/38499487-4c8a5212-3c3a-11e8-99d9-a7ad4910257d.png)
![screenshot from 2018-04-10 10-51-35](https://user-images.githubusercontent.com/37242917/38533796-71355b52-3cad-11e8-91fa-66e0845de5bc.png)

By the way,if I use ""dummy-quantization"" to try out quantized inference on a float graph,the tflite model works fine in android,and the structure of Graph in GraphViz Dot format  just looks the same as  my quantized version.
 
### Source code / logs

>  #Strip out problematic nodes before even letting TOCO see the graphdef
bazel run -c opt tensorflow/python/tools/optimize_for_inference -- \
--input=$DETECT_PB  --output=$STRIPPED_PB --frozen_graph=True \
--input_names=Preprocessor/sub --output_names=concat,concat_1 \
--alsologtostderr

 

> #Run TOCO conversion.
IMAGE_SIZE=300
bazel run tensorflow/contrib/lite/toco:toco -- \
  --input_file=$STRIPPED_PB \
  --output_file=$DETECT_FB \
  --input_format=TENSORFLOW_GRAPHDEF \
  --output_format=TFLITE \
  --input_shapes=1,${IMAGE_SIZE},${IMAGE_SIZE},3 \
  --input_arrays=Preprocessor/sub \
  --output_arrays=concat,concat_1 \
  --inference_type=QUANTIZED_UINT8 \
  --mean_values=128 \
  --std_values=127 \
  --dump_graphviz=/tmp


"
18341,Distributed Tensorflow stucks in multiple loss functions,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes, I have implemented the code based on the official Distributed Tensorflow example and my non-distributed implementation
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 10
- **TensorFlow installed from (source or binary)**:
binary, using ""pip install tensorflow-gpu""
- **TensorFlow version (use command below)**:
Tensorflow-GPU 1.7
- **Python version**: 
3.6
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
CUDA_9.0.176 / cudnn-9.0
- **GPU model and memory**:
2X NVIDIA GeForce GTX 980 Ti / 6GB
- **Exact command to reproduce**:
see the description of the problem

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
I am implementing our distributed-application based on the official example. We were using between-graph replication and synchronous training (tf.train.SyncReplicasOptimizer
). The model we trained is a variational autoencoder plus GAN. In each iteration, it updates the coefficients with two loss functions -- one for the generator and one for the discriminator. The first loss function for the generator runs well, but the second one for the discriminator doesn't return. I tried swapping the loss functions, but the second one still stucks. 
I tried using the asynchronous training, this works. But I prefer the synchronous training which seems perform better in terms of throughput.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
18339,GPU support for macOS,"Hi there, with the launch of version 10.13.4, now the macOS officially support eGPU(extend GPU). Though there does not have a official Nvidia GPU driver, users still can drive their Nvidia eGPU with the Nvidia Web Driver. So the use of CUDA and cuDNN on macOS become possible. 

For now, without the official GPU-support binary package, eGPU users like me have to compile from source code, which is a really nasty work. I am appreciated if there could have an official GPU-support binary package for macOS users again.

Considering the reality, the feature I mentioned above may hard to implement.  But I think a more friendly compile process would be helpful. I tried six times to compile the r1.7 branch last night and all failed. 

Anyway, thanks for your effort and contribution :)"
18338,SeparableConv2D from tf.keras.layers and tf.layers gives different results,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.7.0
- **Python version**: 3.6.5
- **Bazel version (if compiling from source)**: NA
- **GCC/Compiler version (if compiling from source)**: NA
- **CUDA/cuDNN version**: NA
- **GPU model and memory**: NA
- **Exact command to reproduce**: See source code

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

The shape of the weight matrices of a SeparableConv2D using tf.keras.layers and tf.layers is different even when using the same arguments. It looks like the SeparableConv2D class from tf.keras.layers is ignoring the `depth_multiplier` argument.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

```
import tensorflow as tf

sess = tf.InteractiveSession()

sep_conv1 = tf.keras.layers.SeparableConv2D(filters=2, kernel_size=2, strides=1, padding='same', depth_multiplier=5)
sep_conv2 = tf.layers.SeparableConv2D(filters=2, kernel_size=2, strides=1, padding='same', depth_multiplier=5)

x = tf.random_uniform((1, 4, 4, 3), minval=1, maxval=10, dtype=tf.int32)
x = tf.cast(x, tf.float32)

y1 = sep_conv1(x)
y2 = sep_conv2(x)

init = tf.global_variables_initializer()
sess.run(init)
sess.run([y1, y2])

# the shape of the depthwise_kernel is (2, 2, 3, 1) and the shape of the pointwise_kernel is (1, 1, 3, 2)
for w in sep_conv1.variables:
    print(w)

# the shape of the depthwise_kernel is (2, 2, 3, 5) and the shape of the pointwise_kernel is (1, 1, 15, 2)
for w in sep_conv2.variables:
    print(w)
```
"
18337,   c_api.TF_GetCode(self.status.status)) tensorflow.python.framework.errors_impl.NotFoundError: ; No such file or directory 	 [[Node: save_1/SaveV2 = SaveV2[,"Please suggest what is wrong and how to fix it:
-----------------------------------------
Right on the 60k iteration, I got this error, please suggest what might have been wrong. Can you also share your models for MPII human pose dataset? I basically followed all the instructions for training and had no error until 60k-th iteration!! The error is cause when using this repo https://github.com/eldar/pose-tensorflow/issues/71

```
iteration: 59940 loss: 0.0395 lr: 0.02
iteration: 59960 loss: 0.0473 lr: 0.02
iteration: 59980 loss: 0.0389 lr: 0.02
iteration: 60000 loss: 0.0414 lr: 0.02
2018-04-08 21:22:32.268116: W tensorflow/core/framework/op_kernel.cc:1192] Not found: ; No such file or directory
Traceback (most recent call last):
  File ""/scratch/sjn/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1323, in _do_call
    return fn(*args)
  File ""/scratch/sjn/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1302, in _run_fn
    status, run_metadata)
  File ""/scratch/sjn/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py"", line 473, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.NotFoundError: ; No such file or directory
	 [[Node: save_1/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save_1/Const_0_0, save_1/SaveV2/tensor_names, save_1/SaveV2/shape_and_slices, pose/intermediate_supervision/block4/biases/_1167, pose/intermediate_supervision/block4/weights/_1169, pose/locref_pred/block4/biases/_1171, pose/locref_pred/block4/weights/_1173, pose/part_pred/block4/biases/_1175, pose/part_pred/block4/weights/_1177, resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/BatchNorm/beta/_1179, resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/BatchNorm/gamma/_1181, resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/BatchNorm/moving_mean/_1183, resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/BatchNorm/moving_variance/_1185, resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/weights/_1187, resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/BatchNorm/beta/_1189, resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/BatchNorm/gamma/_1191, resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/BatchNorm/moving_mean/_1193, resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/BatchNorm/moving_variance/_1195, resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/weights/_1197, resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/BatchNorm/beta/_1199, resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/BatchNorm/gamma/_1201, resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/BatchNorm/moving_mean/_1203, resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/BatchNorm/moving_variance/_1205, resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/weights/_1207, resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/BatchNorm/beta/_1209, resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma/_1211, resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_mean/_1213, resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_variance/_1215, resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/weights/_1217, resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm/beta/_1219, resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm/gamma/_1221, resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm/moving_mean/_1223, resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm/moving_variance/_1225, resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/weights/_1227, resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/BatchNorm/beta/_1229, resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/BatchNorm/gamma/_1231, resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/BatchNorm/moving_mean/_1233, resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/BatchNorm/moving_variance/_1235, resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/weights/_1237, resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/BatchNorm/beta/_1239, resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/BatchNorm/gamma/_1241, resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/BatchNorm/moving_mean/_1243, resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/BatchNorm/moving_variance/_1245, resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/weights/_1247, resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/BatchNorm/beta/_1249, resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/BatchNorm/gamma/_1251, resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/BatchNorm/moving_mean/_1253, resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/BatchNorm/moving_variance/_1255, resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/weights/_1257, resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/BatchNorm/beta/_1259, resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/BatchNorm/gamma/_1261, resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/BatchNorm/moving_mean/_1263, resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/BatchNorm/moving_variance/_1265, resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/weights/_1267, resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/BatchNorm/beta/_1269, resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/BatchNorm/gamma/_1271, resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/BatchNorm/moving_mean/_1273, resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/BatchNorm/moving_variance/_1275, resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/weights/_1277, resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/BatchNorm/beta/_1279, resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/BatchNorm/gamma/_1281, resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/BatchNorm/moving_mean/_1283, resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/BatchNorm/moving_variance/_1285, resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/weights/_1287, resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/BatchNorm/beta/_1289, resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/BatchNorm/gamma/_1291, resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/BatchNorm/moving_mean/_1293, resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/BatchNorm/moving_variance/_1295, resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/weights/_1297, resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/BatchNorm/beta/_1299, resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/BatchNorm/gamma/_1301, resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/BatchNorm/moving_mean/_1303, resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/BatchNorm/moving_variance/_1305, resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/weights/_1307, resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/BatchNorm/beta/_1309, resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma/_1311, resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_mean/_1313, resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_variance/_1315, resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/weights/_1317, resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/BatchNorm/beta/_1319, resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/BatchNorm/gamma/_1321, resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/BatchNorm/moving_mean/_1323, resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/BatchNorm/moving_variance/_1325, resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/weights/_1327, resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/BatchNorm/beta/_1329, resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/BatchNorm/gamma/_1331, resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/BatchNorm/moving_mean/_1333, resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/BatchNorm/moving_variance/_1335, resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/weights/_1337, resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/BatchNorm/beta/_1339, resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/BatchNorm/gamma/_1341, resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/BatchNorm/moving_mean/_1343, resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/BatchNorm/moving_variance/_1345, resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/weights/_1347, resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/BatchNorm/beta/_1349, resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/BatchNorm/gamma/_1351, resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/BatchNorm/moving_mean/_1353, resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/BatchNorm/moving_variance/_1355, resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/weights/_1357, resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/BatchNorm/beta/_1359, resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/BatchNorm/gamma/_1361, resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/BatchNorm/moving_mean/_1363, resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/BatchNorm/moving_variance/_1365, resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/weights/_1367, resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/BatchNorm/beta/_1369, resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/BatchNorm/gamma/_1371, resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/BatchNorm/moving_mean/_1373, resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/BatchNorm/moving_variance/_1375, resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/weights/_1377, resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/BatchNorm/beta/_1379, resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/BatchNorm/gamma/_1381, resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/BatchNorm/moving_mean/_1383, resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/BatchNorm/moving_variance/_1385, resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/weights/_1387, resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/BatchNorm/beta/_1389, resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/BatchNorm/gamma/_1391, resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/BatchNorm/moving_mean/_1393, resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/BatchNorm/moving_variance/_1395, resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/weights/_1397, resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/BatchNorm/beta/_1399, resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/BatchNorm/gamma/_1401, resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/BatchNorm/moving_mean/_1403, resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/BatchNorm/moving_variance/_1405, resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/weights/_1407, resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/BatchNorm/beta/_1409, resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/BatchNorm/gamma/_1411, resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/BatchNorm/moving_mean/_1413, resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/BatchNorm/moving_variance/_1415, resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/weights/_1417, resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/BatchNorm/beta/_1419, resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/BatchNorm/gamma/_1421, resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/BatchNorm/moving_mean/_1423, resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/BatchNorm/moving_variance/_1425, resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/weights/_1427, resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/BatchNorm/beta/_1429, resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/BatchNorm/gamma/_1431, resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/BatchNorm/moving_mean/_1433, resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/BatchNorm/moving_variance/_1435, resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/weights/_1437, resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/BatchNorm/beta/_1439, resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma/_1441, resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_mean/_1443, resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_variance/_1445, resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/weights/_1447, resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/BatchNorm/beta/_1449, resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/BatchNorm/gamma/_1451, resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/BatchNorm/moving_mean/_1453, resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/BatchNorm/moving_variance/_1455, resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/weights/_1457, resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/BatchNorm/beta/_1459, resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/BatchNorm/gamma/_1461, resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/BatchNorm/moving_mean/_1463, resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/BatchNorm/moving_variance/_1465, resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/weights/_1467, resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/BatchNorm/beta/_1469, resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/BatchNorm/gamma/_1471, resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/BatchNorm/moving_mean/_1473, resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/BatchNorm/moving_variance/_1475, resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/weights/_1477, resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/BatchNorm/beta/_1479, resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/BatchNorm/gamma/_1481, resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/BatchNorm/moving_mean/_1483, resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/BatchNorm/moving_variance/_1485, resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/weights/_1487, resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/BatchNorm/beta/_1489, resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/BatchNorm/gamma/_1491, resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/BatchNorm/moving_mean/_1493, resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/BatchNorm/moving_variance/_1495, resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/weights/_1497, resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/BatchNorm/beta/_1499, resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/BatchNorm/gamma/_1501, resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/BatchNorm/moving_mean/_1503, resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/BatchNorm/moving_variance/_1505, resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/weights/_1507, resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/BatchNorm/beta/_1509, resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/BatchNorm/gamma/_1511, resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/BatchNorm/moving_mean/_1513, resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/BatchNorm/moving_variance/_1515, resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/weights/_1517, resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/BatchNorm/beta/_1519, resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/BatchNorm/gamma/_1521, resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/BatchNorm/moving_mean/_1523, resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/BatchNorm/moving_variance/_1525, resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/weights/_1527, resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/BatchNorm/beta/_1529, resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/BatchNorm/gamma/_1531, resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/BatchNorm/moving_mean/_1533, resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/BatchNorm/moving_variance/_1535, resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/weights/_1537, resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/BatchNorm/beta/_1539, resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/BatchNorm/gamma/_1541, resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/BatchNorm/moving_mean/_1543, resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/BatchNorm/moving_variance/_1545, resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/weights/_1547, resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/BatchNorm/beta/_1549, resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/BatchNorm/gamma/_1551, resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/BatchNorm/moving_mean/_1553, resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/BatchNorm/moving_variance/_1555, resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/weights/_1557, resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/BatchNorm/beta/_1559, resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/BatchNorm/gamma/_1561, resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/BatchNorm/moving_mean/_1563, resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/BatchNorm/moving_variance/_1565, resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/weights/_1567, resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/BatchNorm/beta/_1569, resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/BatchNorm/gamma/_1571, resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/BatchNorm/moving_mean/_1573, resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/BatchNorm/moving_variance/_1575, resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/weights/_1577, resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/BatchNorm/beta/_1579, resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/BatchNorm/gamma/_1581, resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/BatchNorm/moving_mean/_1583, resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/BatchNorm/moving_variance/_1585, resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/weights/_1587, resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/BatchNorm/beta/_1589, resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/BatchNorm/gamma/_1591, resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/BatchNorm/moving_mean/_1593, resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/BatchNorm/moving_variance/_1595, resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/weights/_1597, resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/BatchNorm/beta/_1599, resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/BatchNorm/gamma/_1601, resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/BatchNorm/moving_mean/_1603, resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/BatchNorm/moving_variance/_1605, resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/weights/_1607, resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/BatchNorm/beta/_1609, resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/BatchNorm/gamma/_1611, resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/BatchNorm/moving_mean/_1613, resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/BatchNorm/moving_variance/_1615, resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/weights/_1617, resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/BatchNorm/beta/_1619, resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/BatchNorm/gamma/_1621, resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/BatchNorm/moving_mean/_1623, resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/BatchNorm/moving_variance/_1625, resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/weights/_1627, resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/BatchNorm/beta/_1629, resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/BatchNorm/gamma/_1631, resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/BatchNorm/moving_mean/_1633, resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/BatchNorm/moving_variance/_1635, resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/weights/_1637, resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/BatchNorm/beta/_1639, resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/BatchNorm/gamma/_1641, resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/BatchNorm/moving_mean/_1643, resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/BatchNorm/moving_variance/_1645, resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/weights/_1647, resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/BatchNorm/beta/_1649, resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/BatchNorm/gamma/_1651, resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/BatchNorm/moving_mean/_1653, resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/BatchNorm/moving_variance/_1655, resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/weights/_1657, resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/BatchNorm/beta/_1659, resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/BatchNorm/gamma/_1661, resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/BatchNorm/moving_mean/_1663, resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/BatchNorm/moving_variance/_1665, resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/weights/_1667, resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/BatchNorm/beta/_1669, resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/BatchNorm/gamma/_1671, resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/BatchNorm/moving_mean/_1673, resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/BatchNorm/moving_variance/_1675, resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/weights/_1677, resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/BatchNorm/beta/_1679, resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/BatchNorm/gamma/_1681, resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/BatchNorm/moving_mean/_1683, resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/BatchNorm/moving_variance/_1685, resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/weights/_1687, resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/BatchNorm/beta/_1689, resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/BatchNorm/gamma/_1691, resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/BatchNorm/moving_mean/_1693, resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/BatchNorm/moving_variance/_1695, resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/weights/_1697, resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/BatchNorm/beta/_1699, resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/BatchNorm/gamma/_1701, resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/BatchNorm/moving_mean/_1703, resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/BatchNorm/moving_variance/_1705, resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/weights/_1707, resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/BatchNorm/beta/_1709, resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/BatchNorm/gamma/_1711, resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/BatchNorm/moving_mean/_1713, resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/BatchNorm/moving_variance/_1715, resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/weights/_1717, resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/BatchNorm/beta/_1719, resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/BatchNorm/gamma/_1721, resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/BatchNorm/moving_mean/_1723, resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/BatchNorm/moving_variance/_1725, resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/weights/_1727, resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/BatchNorm/beta/_1729, resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/BatchNorm/gamma/_1731, resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/BatchNorm/moving_mean/_1733, resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/BatchNorm/moving_variance/_1735, resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/weights/_1737, resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/BatchNorm/beta/_1739, resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/BatchNorm/gamma/_1741, resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/BatchNorm/moving_mean/_1743, resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/BatchNorm/moving_variance/_1745, resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/weights/_1747, resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/BatchNorm/beta/_1749, resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/BatchNorm/gamma/_1751, resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/BatchNorm/moving_mean/_1753, resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/BatchNorm/moving_variance/_1755, resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/weights/_1757, resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/BatchNorm/beta/_1759, resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/BatchNorm/gamma/_1761, resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/BatchNorm/moving_mean/_1763, resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/BatchNorm/moving_variance/_1765, resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/weights/_1767, resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/BatchNorm/beta/_1769, resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/BatchNorm/gamma/_1771, resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/BatchNorm/moving_mean/_1773, resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/BatchNorm/moving_variance/_1775, resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/weights/_1777, resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/BatchNorm/beta/_1779, resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/BatchNorm/gamma/_1781, resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/BatchNorm/moving_mean/_1783, resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/BatchNorm/moving_variance/_1785, resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/weights/_1787, resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/BatchNorm/beta/_1789, resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/BatchNorm/gamma/_1791, resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/BatchNorm/moving_mean/_1793, resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/BatchNorm/moving_variance/_1795, resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/weights/_1797, resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/BatchNorm/beta/_1799, resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/BatchNorm/gamma/_1801, resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/BatchNorm/moving_mean/_1803, resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/BatchNorm/moving_variance/_1805, resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/weights/_1807, resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/BatchNorm/beta/_1809, resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/BatchNorm/gamma/_1811, resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/BatchNorm/moving_mean/_1813, resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/BatchNorm/moving_variance/_1815, resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/weights/_1817, resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/BatchNorm/beta/_1819, resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/BatchNorm/gamma/_1821, resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/BatchNorm/moving_mean/_1823, resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/BatchNorm/moving_variance/_1825, resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/weights/_1827, resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/BatchNorm/beta/_1829, resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/BatchNorm/gamma/_1831, resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/BatchNorm/moving_mean/_1833, resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/BatchNorm/moving_variance/_1835, resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/weights/_1837, resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/BatchNorm/beta/_1839, resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/BatchNorm/gamma/_1841, resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/BatchNorm/moving_mean/_1843, resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/BatchNorm/moving_variance/_1845, resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/weights/_1847, resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/BatchNorm/beta/_1849, resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/BatchNorm/gamma/_1851, resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/BatchNorm/moving_mean/_1853, resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/BatchNorm/moving_variance/_1855, resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/weights/_1857, resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/BatchNorm/beta/_1859, resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/BatchNorm/gamma/_1861, resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/BatchNorm/moving_mean/_1863, resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/BatchNorm/moving_variance/_1865, resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/weights/_1867, resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/BatchNorm/beta/_1869, resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/BatchNorm/gamma/_1871, resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/BatchNorm/moving_mean/_1873, resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/BatchNorm/moving_variance/_1875, resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/weights/_1877, resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/BatchNorm/beta/_1879, resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/BatchNorm/gamma/_1881, resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/BatchNorm/moving_mean/_1883, resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/BatchNorm/moving_variance/_1885, resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/weights/_1887, resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/BatchNorm/beta/_1889, resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/BatchNorm/gamma/_1891, resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/BatchNorm/moving_mean/_1893, resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/BatchNorm/moving_variance/_1895, resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/weights/_1897, resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/BatchNorm/beta/_1899, resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/BatchNorm/gamma/_1901, resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/BatchNorm/moving_mean/_1903, resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/BatchNorm/moving_variance/_1905, resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/weights/_1907, resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/BatchNorm/beta/_1909, resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/BatchNorm/gamma/_1911, resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/BatchNorm/moving_mean/_1913, resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/BatchNorm/moving_variance/_1915, resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/weights/_1917, resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/BatchNorm/beta/_1919, resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/BatchNorm/gamma/_1921, resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/BatchNorm/moving_mean/_1923, resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/BatchNorm/moving_variance/_1925, resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/weights/_1927, resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/BatchNorm/beta/_1929, resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/BatchNorm/gamma/_1931, resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/BatchNorm/moving_mean/_1933, resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/BatchNorm/moving_variance/_1935, resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/weights/_1937, resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/BatchNorm/beta/_1939, resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/BatchNorm/gamma/_1941, resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/BatchNorm/moving_mean/_1943, resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/BatchNorm/moving_variance/_1945, resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/weights/_1947, resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/BatchNorm/beta/_1949, resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/BatchNorm/gamma/_1951, resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/BatchNorm/moving_mean/_1953, resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/BatchNorm/moving_variance/_1955, resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/weights/_1957, resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/BatchNorm/beta/_1959, resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/BatchNorm/gamma/_1961, resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/BatchNorm/moving_mean/_1963, resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/BatchNorm/moving_variance/_1965, resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/weights/_1967, resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/BatchNorm/beta/_1969, resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/BatchNorm/gamma/_1971, resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/BatchNorm/moving_mean/_1973, resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/BatchNorm/moving_variance/_1975, resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/weights/_1977, resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/BatchNorm/beta/_1979, resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/BatchNorm/gamma/_1981, resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/BatchNorm/moving_mean/_1983, resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/BatchNorm/moving_variance/_1985, resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/weights/_1987, resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/BatchNorm/beta/_1989, resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/BatchNorm/gamma/_1991, resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/BatchNorm/moving_mean/_1993, resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/BatchNorm/moving_variance/_1995, resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/weights/_1997, resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/BatchNorm/beta/_1999, resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/BatchNorm/gamma/_2001, resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/BatchNorm/moving_mean/_2003, resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/BatchNorm/moving_variance/_2005, resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/weights/_2007, resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/BatchNorm/beta/_2009, resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/BatchNorm/gamma/_2011, resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/BatchNorm/moving_mean/_2013, resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/BatchNorm/moving_variance/_2015, resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/weights/_2017, resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/BatchNorm/beta/_2019, resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/BatchNorm/gamma/_2021, resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/BatchNorm/moving_mean/_2023, resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/BatchNorm/moving_variance/_2025, resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/weights/_2027, resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/BatchNorm/beta/_2029, resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/BatchNorm/gamma/_2031, resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/BatchNorm/moving_mean/_2033, resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/BatchNorm/moving_variance/_2035, resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/weights/_2037, resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/BatchNorm/beta/_2039, resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/BatchNorm/gamma/_2041, resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/BatchNorm/moving_mean/_2043, resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/BatchNorm/moving_variance/_2045, resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/weights/_2047, resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/BatchNorm/beta/_2049, resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/BatchNorm/gamma/_2051, resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/BatchNorm/moving_mean/_2053, resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/BatchNorm/moving_variance/_2055, resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/weights/_2057, resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/BatchNorm/beta/_2059, resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/BatchNorm/gamma/_2061, resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/BatchNorm/moving_mean/_2063, resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/BatchNorm/moving_variance/_2065, resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/weights/_2067, resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/BatchNorm/beta/_2069, resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/BatchNorm/gamma/_2071, resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/BatchNorm/moving_mean/_2073, resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/BatchNorm/moving_variance/_2075, resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/weights/_2077, resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/BatchNorm/beta/_2079, resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/BatchNorm/gamma/_2081, resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/BatchNorm/moving_mean/_2083, resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/BatchNorm/moving_variance/_2085, resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/weights/_2087, resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/BatchNorm/beta/_2089, resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/BatchNorm/gamma/_2091, resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/BatchNorm/moving_mean/_2093, resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/BatchNorm/moving_variance/_2095, resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/weights/_2097, resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/BatchNorm/beta/_2099, resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/BatchNorm/gamma/_2101, resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/BatchNorm/moving_mean/_2103, resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/BatchNorm/moving_variance/_2105, resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/weights/_2107, resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/BatchNorm/beta/_2109, resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/BatchNorm/gamma/_2111, resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/BatchNorm/moving_mean/_2113, resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/BatchNorm/moving_variance/_2115, resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/weights/_2117, resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/BatchNorm/beta/_2119, resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/BatchNorm/gamma/_2121, resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/BatchNorm/moving_mean/_2123, resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/BatchNorm/moving_variance/_2125, resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/weights/_2127, resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/BatchNorm/beta/_2129, resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/BatchNorm/gamma/_2131, resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/BatchNorm/moving_mean/_2133, resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/BatchNorm/moving_variance/_2135, resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/weights/_2137, resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/beta/_2139, resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma/_2141, resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_mean/_2143, resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_variance/_2145, resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/weights/_2147, resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/BatchNorm/beta/_2149, resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/BatchNorm/gamma/_2151, resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/BatchNorm/moving_mean/_2153, resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/BatchNorm/moving_variance/_2155, resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/weights/_2157, resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/BatchNorm/beta/_2159, resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/BatchNorm/gamma/_2161, resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/BatchNorm/moving_mean/_2163, resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/BatchNorm/moving_variance/_2165, resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/weights/_2167, resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/BatchNorm/beta/_2169, resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/BatchNorm/gamma/_2171, resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/BatchNorm/moving_mean/_2173, resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/BatchNorm/moving_variance/_2175, resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/weights/_2177, resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/BatchNorm/beta/_2179, resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/BatchNorm/gamma/_2181, resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/BatchNorm/moving_mean/_2183, resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/BatchNorm/moving_variance/_2185, resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/weights/_2187, resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/BatchNorm/beta/_2189, resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/BatchNorm/gamma/_2191, resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/BatchNorm/moving_mean/_2193, resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/BatchNorm/moving_variance/_2195, resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/weights/_2197, resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/BatchNorm/beta/_2199, resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/BatchNorm/gamma/_2201, resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/BatchNorm/moving_mean/_2203, resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/BatchNorm/moving_variance/_2205, resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/weights/_2207, resnet_v1_101/conv1/BatchNorm/beta/_2209, resnet_v1_101/conv1/BatchNorm/gamma/_2211, resnet_v1_101/conv1/BatchNorm/moving_mean/_2213, resnet_v1_101/conv1/BatchNorm/moving_variance/_2215, resnet_v1_101/conv1/weights/_2217)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/scratch/sjn/anaconda/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 1573, in save
    {self.saver_def.filename_tensor_name: checkpoint_file})
  File ""/scratch/sjn/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 889, in run
    run_metadata_ptr)
  File ""/scratch/sjn/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1120, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/scratch/sjn/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1317, in _do_run
    options, run_metadata)
  File ""/scratch/sjn/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1336, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.NotFoundError: ; No such file or directory
	 [[Node: save_1/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save_1/Const_0_0, save_1/SaveV2/tensor_names, save_1/SaveV2/shape_and_slices, pose/intermediate_supervision/block4/biases/_1167, pose/intermediate_supervision/block4/weights/_1169, pose/locref_pred/block4/biases/_1171, pose/locref_pred/block4/weights/_1173, pose/part_pred/block4/biases/_1175, pose/part_pred/block4/weights/_1177, resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/BatchNorm/beta/_1179, resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/BatchNorm/gamma/_1181, resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/BatchNorm/moving_mean/_1183, resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/BatchNorm/moving_variance/_1185, resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/weights/_1187, resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/BatchNorm/beta/_1189, resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/BatchNorm/gamma/_1191, resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/BatchNorm/moving_mean/_1193, resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/BatchNorm/moving_variance/_1195, resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/weights/_1197, resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/BatchNorm/beta/_1199, resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/BatchNorm/gamma/_1201, resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/BatchNorm/moving_mean/_1203, resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/BatchNorm/moving_variance/_1205, resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/weights/_1207, resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/BatchNorm/beta/_1209, resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma/_1211, resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_mean/_1213, resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_variance/_1215, resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/weights/_1217, resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm/beta/_1219, resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm/gamma/_1221, resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm/moving_mean/_1223, resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm/moving_variance/_1225, resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/weights/_1227, resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/BatchNorm/beta/_1229, resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/BatchNorm/gamma/_1231, resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/BatchNorm/moving_mean/_1233, resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/BatchNorm/moving_variance/_1235, resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/weights/_1237, resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/BatchNorm/beta/_1239, resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/BatchNorm/gamma/_1241, resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/BatchNorm/moving_mean/_1243, resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/BatchNorm/moving_variance/_1245, resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/weights/_1247, resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/BatchNorm/beta/_1249, resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/BatchNorm/gamma/_1251, resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/BatchNorm/moving_mean/_1253, resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/BatchNorm/moving_variance/_1255, resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/weights/_1257, resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/BatchNorm/beta/_1259, resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/BatchNorm/gamma/_1261, resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/BatchNorm/moving_mean/_1263, resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/BatchNorm/moving_variance/_1265, resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/weights/_1267, resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/BatchNorm/beta/_1269, resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/BatchNorm/gamma/_1271, resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/BatchNorm/moving_mean/_1273, resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/BatchNorm/moving_variance/_1275, resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/weights/_1277, resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/BatchNorm/beta/_1279, resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/BatchNorm/gamma/_1281, resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/BatchNorm/moving_mean/_1283, resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/BatchNorm/moving_variance/_1285, resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/weights/_1287, resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/BatchNorm/beta/_1289, resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/BatchNorm/gamma/_1291, resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/BatchNorm/moving_mean/_1293, resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/BatchNorm/moving_variance/_1295, resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/weights/_1297, resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/BatchNorm/beta/_1299, resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/BatchNorm/gamma/_1301, resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/BatchNorm/moving_mean/_1303, resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/BatchNorm/moving_variance/_1305, resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/weights/_1307, resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/BatchNorm/beta/_1309, resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma/_1311, resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_mean/_1313, resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_variance/_1315, resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/weights/_1317, resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/BatchNorm/beta/_1319, resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/BatchNorm/gamma/_1321, resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/BatchNorm/moving_mean/_1323, resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/BatchNorm/moving_variance/_1325, resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/weights/_1327, resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/BatchNorm/beta/_1329, resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/BatchNorm/gamma/_1331, resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/BatchNorm/moving_mean/_1333, resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/BatchNorm/moving_variance/_1335, resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/weights/_1337, resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/BatchNorm/beta/_1339, resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/BatchNorm/gamma/_1341, resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/BatchNorm/moving_mean/_1343, resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/BatchNorm/moving_variance/_1345, resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/weights/_1347, resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/BatchNorm/beta/_1349, resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/BatchNorm/gamma/_1351, resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/BatchNorm/moving_mean/_1353, resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/BatchNorm/moving_variance/_1355, resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/weights/_1357, resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/BatchNorm/beta/_1359, resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/BatchNorm/gamma/_1361, resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/BatchNorm/moving_mean/_1363, resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/BatchNorm/moving_variance/_1365, resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/weights/_1367, resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/BatchNorm/beta/_1369, resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/BatchNorm/gamma/_1371, resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/BatchNorm/moving_mean/_1373, resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/BatchNorm/moving_variance/_1375, resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/weights/_1377, resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/BatchNorm/beta/_1379, resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/BatchNorm/gamma/_1381, resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/BatchNorm/moving_mean/_1383, resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/BatchNorm/moving_variance/_1385, resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/weights/_1387, resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/BatchNorm/beta/_1389, resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/BatchNorm/gamma/_1391, resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/BatchNorm/moving_mean/_1393, resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/BatchNorm/moving_variance/_1395, resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/weights/_1397, resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/BatchNorm/beta/_1399, resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/BatchNorm/gamma/_1401, resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/BatchNorm/moving_mean/_1403, resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/BatchNorm/moving_variance/_1405, resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/weights/_1407, resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/BatchNorm/beta/_1409, resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/BatchNorm/gamma/_1411, resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/BatchNorm/moving_mean/_1413, resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/BatchNorm/moving_variance/_1415, resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/weights/_1417, resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/BatchNorm/beta/_1419, resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/BatchNorm/gamma/_1421, resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/BatchNorm/moving_mean/_1423, resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/BatchNorm/moving_variance/_1425, resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/weights/_1427, resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/BatchNorm/beta/_1429, resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/BatchNorm/gamma/_1431, resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/BatchNorm/moving_mean/_1433, resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/BatchNorm/moving_variance/_1435, resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/weights/_1437, resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/BatchNorm/beta/_1439, resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma/_1441, resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_mean/_1443, resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_variance/_1445, resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/weights/_1447, resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/BatchNorm/beta/_1449, resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/BatchNorm/gamma/_1451, resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/BatchNorm/moving_mean/_1453, resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/BatchNorm/moving_variance/_1455, resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/weights/_1457, resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/BatchNorm/beta/_1459, resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/BatchNorm/gamma/_1461, resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/BatchNorm/moving_mean/_1463, resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/BatchNorm/moving_variance/_1465, resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/weights/_1467, resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/BatchNorm/beta/_1469, resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/BatchNorm/gamma/_1471, resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/BatchNorm/moving_mean/_1473, resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/BatchNorm/moving_variance/_1475, resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/weights/_1477, resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/BatchNorm/beta/_1479, resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/BatchNorm/gamma/_1481, resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/BatchNorm/moving_mean/_1483, resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/BatchNorm/moving_variance/_1485, resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/weights/_1487, resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/BatchNorm/beta/_1489, resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/BatchNorm/gamma/_1491, resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/BatchNorm/moving_mean/_1493, resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/BatchNorm/moving_variance/_1495, resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/weights/_1497, resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/BatchNorm/beta/_1499, resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/BatchNorm/gamma/_1501, resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/BatchNorm/moving_mean/_1503, resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/BatchNorm/moving_variance/_1505, resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/weights/_1507, resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/BatchNorm/beta/_1509, resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/BatchNorm/gamma/_1511, resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/BatchNorm/moving_mean/_1513, resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/BatchNorm/moving_variance/_1515, resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/weights/_1517, resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/BatchNorm/beta/_1519, resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/BatchNorm/gamma/_1521, resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/BatchNorm/moving_mean/_1523, resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/BatchNorm/moving_variance/_1525, resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/weights/_1527, resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/BatchNorm/beta/_1529, resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/BatchNorm/gamma/_1531, resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/BatchNorm/moving_mean/_1533, resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/BatchNorm/moving_variance/_1535, resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/weights/_1537, resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/BatchNorm/beta/_1539, resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/BatchNorm/gamma/_1541, resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/BatchNorm/moving_mean/_1543, resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/BatchNorm/moving_variance/_1545, resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/weights/_1547, resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/BatchNorm/beta/_1549, resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/BatchNorm/gamma/_1551, resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/BatchNorm/moving_mean/_1553, resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/BatchNorm/moving_variance/_1555, resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/weights/_1557, resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/BatchNorm/beta/_1559, resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/BatchNorm/gamma/_1561, resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/BatchNorm/moving_mean/_1563, resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/BatchNorm/moving_variance/_1565, resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/weights/_1567, resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/BatchNorm/beta/_1569, resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/BatchNorm/gamma/_1571, resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/BatchNorm/moving_mean/_1573, resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/BatchNorm/moving_variance/_1575, resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/weights/_1577, resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/BatchNorm/beta/_1579, resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/BatchNorm/gamma/_1581, resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/BatchNorm/moving_mean/_1583, resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/BatchNorm/moving_variance/_1585, resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/weights/_1587, resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/BatchNorm/beta/_1589, resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/BatchNorm/gamma/_1591, resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/BatchNorm/moving_mean/_1593, resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/BatchNorm/moving_variance/_1595, resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/weights/_1597, resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/BatchNorm/beta/_1599, resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/BatchNorm/gamma/_1601, resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/BatchNorm/moving_mean/_1603, resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/BatchNorm/moving_variance/_1605, resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/weights/_1607, resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/BatchNorm/beta/_1609, resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/BatchNorm/gamma/_1611, resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/BatchNorm/moving_mean/_1613, resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/BatchNorm/moving_variance/_1615, resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/weights/_1617, resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/BatchNorm/beta/_1619, resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/BatchNorm/gamma/_1621, resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/BatchNorm/moving_mean/_1623, resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/BatchNorm/moving_variance/_1625, resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/weights/_1627, resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/BatchNorm/beta/_1629, resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/BatchNorm/gamma/_1631, resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/BatchNorm/moving_mean/_1633, resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/BatchNorm/moving_variance/_1635, resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/weights/_1637, resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/BatchNorm/beta/_1639, resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/BatchNorm/gamma/_1641, resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/BatchNorm/moving_mean/_1643, resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/BatchNorm/moving_variance/_1645, resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/weights/_1647, resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/BatchNorm/beta/_1649, resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/BatchNorm/gamma/_1651, resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/BatchNorm/moving_mean/_1653, resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/BatchNorm/moving_variance/_1655, resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/weights/_1657, resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/BatchNorm/beta/_1659, resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/BatchNorm/gamma/_1661, resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/BatchNorm/moving_mean/_1663, resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/BatchNorm/moving_variance/_1665, resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/weights/_1667, resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/BatchNorm/beta/_1669, resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/BatchNorm/gamma/_1671, resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/BatchNorm/moving_mean/_1673, resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/BatchNorm/moving_variance/_1675, resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/weights/_1677, resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/BatchNorm/beta/_1679, resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/BatchNorm/gamma/_1681, resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/BatchNorm/moving_mean/_1683, resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/BatchNorm/moving_variance/_1685, resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/weights/_1687, resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/BatchNorm/beta/_1689, resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/BatchNorm/gamma/_1691, resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/BatchNorm/moving_mean/_1693, resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/BatchNorm/moving_variance/_1695, resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/weights/_1697, resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/BatchNorm/beta/_1699, resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/BatchNorm/gamma/_1701, resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/BatchNorm/moving_mean/_1703, resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/BatchNorm/moving_variance/_1705, resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/weights/_1707, resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/BatchNorm/beta/_1709, resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/BatchNorm/gamma/_1711, resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/BatchNorm/moving_mean/_1713, resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/BatchNorm/moving_variance/_1715, resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/weights/_1717, resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/BatchNorm/beta/_1719, resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/BatchNorm/gamma/_1721, resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/BatchNorm/moving_mean/_1723, resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/BatchNorm/moving_variance/_1725, resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/weights/_1727, resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/BatchNorm/beta/_1729, resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/BatchNorm/gamma/_1731, resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/BatchNorm/moving_mean/_1733, resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/BatchNorm/moving_variance/_1735, resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/weights/_1737, resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/BatchNorm/beta/_1739, resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/BatchNorm/gamma/_1741, resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/BatchNorm/moving_mean/_1743, resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/BatchNorm/moving_variance/_1745, resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/weights/_1747, resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/BatchNorm/beta/_1749, resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/BatchNorm/gamma/_1751, resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/BatchNorm/moving_mean/_1753, resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/BatchNorm/moving_variance/_1755, resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/weights/_1757, resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/BatchNorm/beta/_1759, resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/BatchNorm/gamma/_1761, resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/BatchNorm/moving_mean/_1763, resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/BatchNorm/moving_variance/_1765, resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/weights/_1767, resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/BatchNorm/beta/_1769, resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/BatchNorm/gamma/_1771, resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/BatchNorm/moving_mean/_1773, resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/BatchNorm/moving_variance/_1775, resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/weights/_1777, resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/BatchNorm/beta/_1779, resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/BatchNorm/gamma/_1781, resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/BatchNorm/moving_mean/_1783, resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/BatchNorm/moving_variance/_1785, resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/weights/_1787, resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/BatchNorm/beta/_1789, resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/BatchNorm/gamma/_1791, resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/BatchNorm/moving_mean/_1793, resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/BatchNorm/moving_variance/_1795, resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/weights/_1797, resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/BatchNorm/beta/_1799, resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/BatchNorm/gamma/_1801, resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/BatchNorm/moving_mean/_1803, resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/BatchNorm/moving_variance/_1805, resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/weights/_1807, resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/BatchNorm/beta/_1809, resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/BatchNorm/gamma/_1811, resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/BatchNorm/moving_mean/_1813, resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/BatchNorm/moving_variance/_1815, resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/weights/_1817, resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/BatchNorm/beta/_1819, resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/BatchNorm/gamma/_1821, resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/BatchNorm/moving_mean/_1823, resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/BatchNorm/moving_variance/_1825, resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/weights/_1827, resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/BatchNorm/beta/_1829, resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/BatchNorm/gamma/_1831, resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/BatchNorm/moving_mean/_1833, resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/BatchNorm/moving_variance/_1835, resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/weights/_1837, resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/BatchNorm/beta/_1839, resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/BatchNorm/gamma/_1841, resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/BatchNorm/moving_mean/_1843, resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/BatchNorm/moving_variance/_1845, resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/weights/_1847, resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/BatchNorm/beta/_1849, resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/BatchNorm/gamma/_1851, resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/BatchNorm/moving_mean/_1853, resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/BatchNorm/moving_variance/_1855, resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/weights/_1857, resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/BatchNorm/beta/_1859, resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/BatchNorm/gamma/_1861, resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/BatchNorm/moving_mean/_1863, resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/BatchNorm/moving_variance/_1865, resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/weights/_1867, resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/BatchNorm/beta/_1869, resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/BatchNorm/gamma/_1871, resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/BatchNorm/moving_mean/_1873, resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/BatchNorm/moving_variance/_1875, resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/weights/_1877, resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/BatchNorm/beta/_1879, resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/BatchNorm/gamma/_1881, resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/BatchNorm/moving_mean/_1883, resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/BatchNorm/moving_variance/_1885, resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/weights/_1887, resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/BatchNorm/beta/_1889, resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/BatchNorm/gamma/_1891, resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/BatchNorm/moving_mean/_1893, resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/BatchNorm/moving_variance/_1895, resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/weights/_1897, resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/BatchNorm/beta/_1899, resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/BatchNorm/gamma/_1901, resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/BatchNorm/moving_mean/_1903, resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/BatchNorm/moving_variance/_1905, resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/weights/_1907, resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/BatchNorm/beta/_1909, resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/BatchNorm/gamma/_1911, resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/BatchNorm/moving_mean/_1913, resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/BatchNorm/moving_variance/_1915, resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/weights/_1917, resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/BatchNorm/beta/_1919, resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/BatchNorm/gamma/_1921, resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/BatchNorm/moving_mean/_1923, resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/BatchNorm/moving_variance/_1925, resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/weights/_1927, resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/BatchNorm/beta/_1929, resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/BatchNorm/gamma/_1931, resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/BatchNorm/moving_mean/_1933, resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/BatchNorm/moving_variance/_1935, resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/weights/_1937, resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/BatchNorm/beta/_1939, resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/BatchNorm/gamma/_1941, resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/BatchNorm/moving_mean/_1943, resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/BatchNorm/moving_variance/_1945, resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/weights/_1947, resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/BatchNorm/beta/_1949, resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/BatchNorm/gamma/_1951, resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/BatchNorm/moving_mean/_1953, resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/BatchNorm/moving_variance/_1955, resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/weights/_1957, resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/BatchNorm/beta/_1959, resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/BatchNorm/gamma/_1961, resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/BatchNorm/moving_mean/_1963, resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/BatchNorm/moving_variance/_1965, resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/weights/_1967, resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/BatchNorm/beta/_1969, resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/BatchNorm/gamma/_1971, resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/BatchNorm/moving_mean/_1973, resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/BatchNorm/moving_variance/_1975, resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/weights/_1977, resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/BatchNorm/beta/_1979, resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/BatchNorm/gamma/_1981, resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/BatchNorm/moving_mean/_1983, resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/BatchNorm/moving_variance/_1985, resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/weights/_1987, resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/BatchNorm/beta/_1989, resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/BatchNorm/gamma/_1991, resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/BatchNorm/moving_mean/_1993, resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/BatchNorm/moving_variance/_1995, resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/weights/_1997, resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/BatchNorm/beta/_1999, resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/BatchNorm/gamma/_2001, resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/BatchNorm/moving_mean/_2003, resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/BatchNorm/moving_variance/_2005, resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/weights/_2007, resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/BatchNorm/beta/_2009, resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/BatchNorm/gamma/_2011, resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/BatchNorm/moving_mean/_2013, resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/BatchNorm/moving_variance/_2015, resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/weights/_2017, resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/BatchNorm/beta/_2019, resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/BatchNorm/gamma/_2021, resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/BatchNorm/moving_mean/_2023, resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/BatchNorm/moving_variance/_2025, resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/weights/_2027, resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/BatchNorm/beta/_2029, resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/BatchNorm/gamma/_2031, resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/BatchNorm/moving_mean/_2033, resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/BatchNorm/moving_variance/_2035, resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/weights/_2037, resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/BatchNorm/beta/_2039, resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/BatchNorm/gamma/_2041, resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/BatchNorm/moving_mean/_2043, resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/BatchNorm/moving_variance/_2045, resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/weights/_2047, resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/BatchNorm/beta/_2049, resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/BatchNorm/gamma/_2051, resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/BatchNorm/moving_mean/_2053, resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/BatchNorm/moving_variance/_2055, resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/weights/_2057, resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/BatchNorm/beta/_2059, resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/BatchNorm/gamma/_2061, resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/BatchNorm/moving_mean/_2063, resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/BatchNorm/moving_variance/_2065, resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/weights/_2067, resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/BatchNorm/beta/_2069, resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/BatchNorm/gamma/_2071, resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/BatchNorm/moving_mean/_2073, resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/BatchNorm/moving_variance/_2075, resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/weights/_2077, resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/BatchNorm/beta/_2079, resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/BatchNorm/gamma/_2081, resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/BatchNorm/moving_mean/_2083, resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/BatchNorm/moving_variance/_2085, resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/weights/_2087, resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/BatchNorm/beta/_2089, resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/BatchNorm/gamma/_2091, resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/BatchNorm/moving_mean/_2093, resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/BatchNorm/moving_variance/_2095, resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/weights/_2097, resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/BatchNorm/beta/_2099, resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/BatchNorm/gamma/_2101, resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/BatchNorm/moving_mean/_2103, resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/BatchNorm/moving_variance/_2105, resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/weights/_2107, resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/BatchNorm/beta/_2109, resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/BatchNorm/gamma/_2111, resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/BatchNorm/moving_mean/_2113, resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/BatchNorm/moving_variance/_2115, resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/weights/_2117, resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/BatchNorm/beta/_2119, resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/BatchNorm/gamma/_2121, resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/BatchNorm/moving_mean/_2123, resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/BatchNorm/moving_variance/_2125, resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/weights/_2127, resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/BatchNorm/beta/_2129, resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/BatchNorm/gamma/_2131, resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/BatchNorm/moving_mean/_2133, resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/BatchNorm/moving_variance/_2135, resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/weights/_2137, resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/beta/_2139, resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma/_2141, resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_mean/_2143, resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_variance/_2145, resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/weights/_2147, resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/BatchNorm/beta/_2149, resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/BatchNorm/gamma/_2151, resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/BatchNorm/moving_mean/_2153, resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/BatchNorm/moving_variance/_2155, resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/weights/_2157, resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/BatchNorm/beta/_2159, resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/BatchNorm/gamma/_2161, resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/BatchNorm/moving_mean/_2163, resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/BatchNorm/moving_variance/_2165, resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/weights/_2167, resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/BatchNorm/beta/_2169, resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/BatchNorm/gamma/_2171, resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/BatchNorm/moving_mean/_2173, resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/BatchNorm/moving_variance/_2175, resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/weights/_2177, resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/BatchNorm/beta/_2179, resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/BatchNorm/gamma/_2181, resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/BatchNorm/moving_mean/_2183, resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/BatchNorm/moving_variance/_2185, resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/weights/_2187, resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/BatchNorm/beta/_2189, resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/BatchNorm/gamma/_2191, resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/BatchNorm/moving_mean/_2193, resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/BatchNorm/moving_variance/_2195, resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/weights/_2197, resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/BatchNorm/beta/_2199, resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/BatchNorm/gamma/_2201, resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/BatchNorm/moving_mean/_2203, resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/BatchNorm/moving_variance/_2205, resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/weights/_2207, resnet_v1_101/conv1/BatchNorm/beta/_2209, resnet_v1_101/conv1/BatchNorm/gamma/_2211, resnet_v1_101/conv1/BatchNorm/moving_mean/_2213, resnet_v1_101/conv1/BatchNorm/moving_variance/_2215, resnet_v1_101/conv1/weights/_2217)]]

Caused by op 'save_1/SaveV2', defined at:
  File ""../../../train.py"", line 140, in <module>
    train()
  File ""../../../train.py"", line 94, in train
    saver = tf.train.Saver(max_to_keep=5)
  File ""/scratch/sjn/anaconda/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 1218, in __init__
    self.build()
  File ""/scratch/sjn/anaconda/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 1227, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File ""/scratch/sjn/anaconda/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 1263, in _build
    build_save=build_save, build_restore=build_restore)
  File ""/scratch/sjn/anaconda/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 748, in _build_internal
    save_tensor = self._AddSaveOps(filename_tensor, saveables)
  File ""/scratch/sjn/anaconda/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 296, in _AddSaveOps
    save = self.save_op(filename_tensor, saveables)
  File ""/scratch/sjn/anaconda/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 239, in save_op
    tensors)
  File ""/scratch/sjn/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py"", line 1163, in save_v2
    shape_and_slices=shape_and_slices, tensors=tensors, name=name)
  File ""/scratch/sjn/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/scratch/sjn/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 2956, in create_op
    op_def=op_def)
  File ""/scratch/sjn/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1470, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

NotFoundError (see above for traceback): ; No such file or directory
	 [[Node: save_1/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save_1/Const_0_0, save_1/SaveV2/tensor_names, save_1/SaveV2/shape_and_slices, pose/intermediate_supervision/block4/biases/_1167, pose/intermediate_supervision/block4/weights/_1169, pose/locref_pred/block4/biases/_1171, pose/locref_pred/block4/weights/_1173, pose/part_pred/block4/biases/_1175, pose/part_pred/block4/weights/_1177, resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/BatchNorm/beta/_1179, resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/BatchNorm/gamma/_1181, resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/BatchNorm/moving_mean/_1183, resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/BatchNorm/moving_variance/_1185, resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/weights/_1187, resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/BatchNorm/beta/_1189, resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/BatchNorm/gamma/_1191, resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/BatchNorm/moving_mean/_1193, resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/BatchNorm/moving_variance/_1195, resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/weights/_1197, resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/BatchNorm/beta/_1199, resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/BatchNorm/gamma/_1201, resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/BatchNorm/moving_mean/_1203, resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/BatchNorm/moving_variance/_1205, resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/weights/_1207, resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/BatchNorm/beta/_1209, resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma/_1211, resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_mean/_1213, resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_variance/_1215, resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/weights/_1217, resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm/beta/_1219, resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm/gamma/_1221, resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm/moving_mean/_1223, resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm/moving_variance/_1225, resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/weights/_1227, resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/BatchNorm/beta/_1229, resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/BatchNorm/gamma/_1231, resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/BatchNorm/moving_mean/_1233, resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/BatchNorm/moving_variance/_1235, resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/weights/_1237, resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/BatchNorm/beta/_1239, resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/BatchNorm/gamma/_1241, resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/BatchNorm/moving_mean/_1243, resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/BatchNorm/moving_variance/_1245, resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/weights/_1247, resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/BatchNorm/beta/_1249, resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/BatchNorm/gamma/_1251, resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/BatchNorm/moving_mean/_1253, resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/BatchNorm/moving_variance/_1255, resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/weights/_1257, resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/BatchNorm/beta/_1259, resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/BatchNorm/gamma/_1261, resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/BatchNorm/moving_mean/_1263, resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/BatchNorm/moving_variance/_1265, resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/weights/_1267, resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/BatchNorm/beta/_1269, resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/BatchNorm/gamma/_1271, resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/BatchNorm/moving_mean/_1273, resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/BatchNorm/moving_variance/_1275, resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/weights/_1277, resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/BatchNorm/beta/_1279, resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/BatchNorm/gamma/_1281, resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/BatchNorm/moving_mean/_1283, resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/BatchNorm/moving_variance/_1285, resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/weights/_1287, resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/BatchNorm/beta/_1289, resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/BatchNorm/gamma/_1291, resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/BatchNorm/moving_mean/_1293, resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/BatchNorm/moving_variance/_1295, resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/weights/_1297, resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/BatchNorm/beta/_1299, resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/BatchNorm/gamma/_1301, resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/BatchNorm/moving_mean/_1303, resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/BatchNorm/moving_variance/_1305, resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/weights/_1307, resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/BatchNorm/beta/_1309, resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma/_1311, resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_mean/_1313, resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_variance/_1315, resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/weights/_1317, resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/BatchNorm/beta/_1319, resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/BatchNorm/gamma/_1321, resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/BatchNorm/moving_mean/_1323, resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/BatchNorm/moving_variance/_1325, resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/weights/_1327, resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/BatchNorm/beta/_1329, resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/BatchNorm/gamma/_1331, resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/BatchNorm/moving_mean/_1333, resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/BatchNorm/moving_variance/_1335, resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/weights/_1337, resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/BatchNorm/beta/_1339, resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/BatchNorm/gamma/_1341, resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/BatchNorm/moving_mean/_1343, resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/BatchNorm/moving_variance/_1345, resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/weights/_1347, resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/BatchNorm/beta/_1349, resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/BatchNorm/gamma/_1351, resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/BatchNorm/moving_mean/_1353, resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/BatchNorm/moving_variance/_1355, resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/weights/_1357, resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/BatchNorm/beta/_1359, resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/BatchNorm/gamma/_1361, resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/BatchNorm/moving_mean/_1363, resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/BatchNorm/moving_variance/_1365, resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/weights/_1367, resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/BatchNorm/beta/_1369, resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/BatchNorm/gamma/_1371, resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/BatchNorm/moving_mean/_1373, resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/BatchNorm/moving_variance/_1375, resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/weights/_1377, resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/BatchNorm/beta/_1379, resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/BatchNorm/gamma/_1381, resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/BatchNorm/moving_mean/_1383, resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/BatchNorm/moving_variance/_1385, resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/weights/_1387, resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/BatchNorm/beta/_1389, resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/BatchNorm/gamma/_1391, resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/BatchNorm/moving_mean/_1393, resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/BatchNorm/moving_variance/_1395, resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/weights/_1397, resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/BatchNorm/beta/_1399, resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/BatchNorm/gamma/_1401, resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/BatchNorm/moving_mean/_1403, resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/BatchNorm/moving_variance/_1405, resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/weights/_1407, resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/BatchNorm/beta/_1409, resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/BatchNorm/gamma/_1411, resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/BatchNorm/moving_mean/_1413, resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/BatchNorm/moving_variance/_1415, resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/weights/_1417, resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/BatchNorm/beta/_1419, resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/BatchNorm/gamma/_1421, resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/BatchNorm/moving_mean/_1423, resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/BatchNorm/moving_variance/_1425, resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/weights/_1427, resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/BatchNorm/beta/_1429, resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/BatchNorm/gamma/_1431, resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/BatchNorm/moving_mean/_1433, resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/BatchNorm/moving_variance/_1435, resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/weights/_1437, resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/BatchNorm/beta/_1439, resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma/_1441, resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_mean/_1443, resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_variance/_1445, resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/weights/_1447, resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/BatchNorm/beta/_1449, resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/BatchNorm/gamma/_1451, resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/BatchNorm/moving_mean/_1453, resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/BatchNorm/moving_variance/_1455, resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/weights/_1457, resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/BatchNorm/beta/_1459, resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/BatchNorm/gamma/_1461, resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/BatchNorm/moving_mean/_1463, resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/BatchNorm/moving_variance/_1465, resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/weights/_1467, resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/BatchNorm/beta/_1469, resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/BatchNorm/gamma/_1471, resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/BatchNorm/moving_mean/_1473, resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/BatchNorm/moving_variance/_1475, resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/weights/_1477, resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/BatchNorm/beta/_1479, resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/BatchNorm/gamma/_1481, resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/BatchNorm/moving_mean/_1483, resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/BatchNorm/moving_variance/_1485, resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/weights/_1487, resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/BatchNorm/beta/_1489, resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/BatchNorm/gamma/_1491, resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/BatchNorm/moving_mean/_1493, resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/BatchNorm/moving_variance/_1495, resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/weights/_1497, resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/BatchNorm/beta/_1499, resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/BatchNorm/gamma/_1501, resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/BatchNorm/moving_mean/_1503, resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/BatchNorm/moving_variance/_1505, resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/weights/_1507, resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/BatchNorm/beta/_1509, resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/BatchNorm/gamma/_1511, resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/BatchNorm/moving_mean/_1513, resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/BatchNorm/moving_variance/_1515, resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/weights/_1517, resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/BatchNorm/beta/_1519, resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/BatchNorm/gamma/_1521, resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/BatchNorm/moving_mean/_1523, resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/BatchNorm/moving_variance/_1525, resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/weights/_1527, resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/BatchNorm/beta/_1529, resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/BatchNorm/gamma/_1531, resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/BatchNorm/moving_mean/_1533, resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/BatchNorm/moving_variance/_1535, resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/weights/_1537, resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/BatchNorm/beta/_1539, resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/BatchNorm/gamma/_1541, resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/BatchNorm/moving_mean/_1543, resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/BatchNorm/moving_variance/_1545, resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/weights/_1547, resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/BatchNorm/beta/_1549, resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/BatchNorm/gamma/_1551, resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/BatchNorm/moving_mean/_1553, resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/BatchNorm/moving_variance/_1555, resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/weights/_1557, resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/BatchNorm/beta/_1559, resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/BatchNorm/gamma/_1561, resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/BatchNorm/moving_mean/_1563, resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/BatchNorm/moving_variance/_1565, resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/weights/_1567, resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/BatchNorm/beta/_1569, resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/BatchNorm/gamma/_1571, resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/BatchNorm/moving_mean/_1573, resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/BatchNorm/moving_variance/_1575, resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/weights/_1577, resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/BatchNorm/beta/_1579, resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/BatchNorm/gamma/_1581, resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/BatchNorm/moving_mean/_1583, resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/BatchNorm/moving_variance/_1585, resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/weights/_1587, resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/BatchNorm/beta/_1589, resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/BatchNorm/gamma/_1591, resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/BatchNorm/moving_mean/_1593, resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/BatchNorm/moving_variance/_1595, resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/weights/_1597, resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/BatchNorm/beta/_1599, resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/BatchNorm/gamma/_1601, resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/BatchNorm/moving_mean/_1603, resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/BatchNorm/moving_variance/_1605, resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/weights/_1607, resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/BatchNorm/beta/_1609, resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/BatchNorm/gamma/_1611, resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/BatchNorm/moving_mean/_1613, resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/BatchNorm/moving_variance/_1615, resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/weights/_1617, resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/BatchNorm/beta/_1619, resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/BatchNorm/gamma/_1621, resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/BatchNorm/moving_mean/_1623, resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/BatchNorm/moving_variance/_1625, resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/weights/_1627, resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/BatchNorm/beta/_1629, resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/BatchNorm/gamma/_1631, resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/BatchNorm/moving_mean/_1633, resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/BatchNorm/moving_variance/_1635, resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/weights/_1637, resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/BatchNorm/beta/_1639, resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/BatchNorm/gamma/_1641, resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/BatchNorm/moving_mean/_1643, resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/BatchNorm/moving_variance/_1645, resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/weights/_1647, resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/BatchNorm/beta/_1649, resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/BatchNorm/gamma/_1651, resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/BatchNorm/moving_mean/_1653, resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/BatchNorm/moving_variance/_1655, resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/weights/_1657, resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/BatchNorm/beta/_1659, resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/BatchNorm/gamma/_1661, resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/BatchNorm/moving_mean/_1663, resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/BatchNorm/moving_variance/_1665, resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/weights/_1667, resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/BatchNorm/beta/_1669, resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/BatchNorm/gamma/_1671, resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/BatchNorm/moving_mean/_1673, resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/BatchNorm/moving_variance/_1675, resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/weights/_1677, resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/BatchNorm/beta/_1679, resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/BatchNorm/gamma/_1681, resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/BatchNorm/moving_mean/_1683, resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/BatchNorm/moving_variance/_1685, resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/weights/_1687, resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/BatchNorm/beta/_1689, resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/BatchNorm/gamma/_1691, resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/BatchNorm/moving_mean/_1693, resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/BatchNorm/moving_variance/_1695, resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/weights/_1697, resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/BatchNorm/beta/_1699, resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/BatchNorm/gamma/_1701, resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/BatchNorm/moving_mean/_1703, resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/BatchNorm/moving_variance/_1705, resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/weights/_1707, resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/BatchNorm/beta/_1709, resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/BatchNorm/gamma/_1711, resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/BatchNorm/moving_mean/_1713, resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/BatchNorm/moving_variance/_1715, resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/weights/_1717, resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/BatchNorm/beta/_1719, resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/BatchNorm/gamma/_1721, resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/BatchNorm/moving_mean/_1723, resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/BatchNorm/moving_variance/_1725, resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/weights/_1727, resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/BatchNorm/beta/_1729, resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/BatchNorm/gamma/_1731, resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/BatchNorm/moving_mean/_1733, resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/BatchNorm/moving_variance/_1735, resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/weights/_1737, resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/BatchNorm/beta/_1739, resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/BatchNorm/gamma/_1741, resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/BatchNorm/moving_mean/_1743, resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/BatchNorm/moving_variance/_1745, resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/weights/_1747, resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/BatchNorm/beta/_1749, resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/BatchNorm/gamma/_1751, resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/BatchNorm/moving_mean/_1753, resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/BatchNorm/moving_variance/_1755, resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/weights/_1757, resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/BatchNorm/beta/_1759, resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/BatchNorm/gamma/_1761, resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/BatchNorm/moving_mean/_1763, resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/BatchNorm/moving_variance/_1765, resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/weights/_1767, resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/BatchNorm/beta/_1769, resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/BatchNorm/gamma/_1771, resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/BatchNorm/moving_mean/_1773, resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/BatchNorm/moving_variance/_1775, resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/weights/_1777, resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/BatchNorm/beta/_1779, resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/BatchNorm/gamma/_1781, resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/BatchNorm/moving_mean/_1783, resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/BatchNorm/moving_variance/_1785, resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/weights/_1787, resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/BatchNorm/beta/_1789, resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/BatchNorm/gamma/_1791, resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/BatchNorm/moving_mean/_1793, resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/BatchNorm/moving_variance/_1795, resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/weights/_1797, resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/BatchNorm/beta/_1799, resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/BatchNorm/gamma/_1801, resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/BatchNorm/moving_mean/_1803, resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/BatchNorm/moving_variance/_1805, resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/weights/_1807, resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/BatchNorm/beta/_1809, resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/BatchNorm/gamma/_1811, resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/BatchNorm/moving_mean/_1813, resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/BatchNorm/moving_variance/_1815, resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/weights/_1817, resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/BatchNorm/beta/_1819, resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/BatchNorm/gamma/_1821, resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/BatchNorm/moving_mean/_1823, resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/BatchNorm/moving_variance/_1825, resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/weights/_1827, resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/BatchNorm/beta/_1829, resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/BatchNorm/gamma/_1831, resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/BatchNorm/moving_mean/_1833, resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/BatchNorm/moving_variance/_1835, resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/weights/_1837, resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/BatchNorm/beta/_1839, resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/BatchNorm/gamma/_1841, resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/BatchNorm/moving_mean/_1843, resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/BatchNorm/moving_variance/_1845, resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/weights/_1847, resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/BatchNorm/beta/_1849, resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/BatchNorm/gamma/_1851, resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/BatchNorm/moving_mean/_1853, resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/BatchNorm/moving_variance/_1855, resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/weights/_1857, resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/BatchNorm/beta/_1859, resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/BatchNorm/gamma/_1861, resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/BatchNorm/moving_mean/_1863, resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/BatchNorm/moving_variance/_1865, resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/weights/_1867, resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/BatchNorm/beta/_1869, resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/BatchNorm/gamma/_1871, resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/BatchNorm/moving_mean/_1873, resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/BatchNorm/moving_variance/_1875, resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/weights/_1877, resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/BatchNorm/beta/_1879, resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/BatchNorm/gamma/_1881, resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/BatchNorm/moving_mean/_1883, resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/BatchNorm/moving_variance/_1885, resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/weights/_1887, resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/BatchNorm/beta/_1889, resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/BatchNorm/gamma/_1891, resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/BatchNorm/moving_mean/_1893, resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/BatchNorm/moving_variance/_1895, resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/weights/_1897, resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/BatchNorm/beta/_1899, resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/BatchNorm/gamma/_1901, resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/BatchNorm/moving_mean/_1903, resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/BatchNorm/moving_variance/_1905, resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/weights/_1907, resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/BatchNorm/beta/_1909, resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/BatchNorm/gamma/_1911, resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/BatchNorm/moving_mean/_1913, resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/BatchNorm/moving_variance/_1915, resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/weights/_1917, resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/BatchNorm/beta/_1919, resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/BatchNorm/gamma/_1921, resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/BatchNorm/moving_mean/_1923, resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/BatchNorm/moving_variance/_1925, resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/weights/_1927, resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/BatchNorm/beta/_1929, resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/BatchNorm/gamma/_1931, resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/BatchNorm/moving_mean/_1933, resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/BatchNorm/moving_variance/_1935, resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/weights/_1937, resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/BatchNorm/beta/_1939, resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/BatchNorm/gamma/_1941, resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/BatchNorm/moving_mean/_1943, resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/BatchNorm/moving_variance/_1945, resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/weights/_1947, resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/BatchNorm/beta/_1949, resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/BatchNorm/gamma/_1951, resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/BatchNorm/moving_mean/_1953, resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/BatchNorm/moving_variance/_1955, resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/weights/_1957, resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/BatchNorm/beta/_1959, resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/BatchNorm/gamma/_1961, resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/BatchNorm/moving_mean/_1963, resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/BatchNorm/moving_variance/_1965, resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/weights/_1967, resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/BatchNorm/beta/_1969, resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/BatchNorm/gamma/_1971, resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/BatchNorm/moving_mean/_1973, resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/BatchNorm/moving_variance/_1975, resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/weights/_1977, resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/BatchNorm/beta/_1979, resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/BatchNorm/gamma/_1981, resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/BatchNorm/moving_mean/_1983, resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/BatchNorm/moving_variance/_1985, resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/weights/_1987, resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/BatchNorm/beta/_1989, resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/BatchNorm/gamma/_1991, resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/BatchNorm/moving_mean/_1993, resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/BatchNorm/moving_variance/_1995, resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/weights/_1997, resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/BatchNorm/beta/_1999, resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/BatchNorm/gamma/_2001, resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/BatchNorm/moving_mean/_2003, resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/BatchNorm/moving_variance/_2005, resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/weights/_2007, resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/BatchNorm/beta/_2009, resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/BatchNorm/gamma/_2011, resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/BatchNorm/moving_mean/_2013, resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/BatchNorm/moving_variance/_2015, resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/weights/_2017, resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/BatchNorm/beta/_2019, resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/BatchNorm/gamma/_2021, resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/BatchNorm/moving_mean/_2023, resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/BatchNorm/moving_variance/_2025, resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/weights/_2027, resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/BatchNorm/beta/_2029, resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/BatchNorm/gamma/_2031, resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/BatchNorm/moving_mean/_2033, resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/BatchNorm/moving_variance/_2035, resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/weights/_2037, resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/BatchNorm/beta/_2039, resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/BatchNorm/gamma/_2041, resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/BatchNorm/moving_mean/_2043, resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/BatchNorm/moving_variance/_2045, resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/weights/_2047, resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/BatchNorm/beta/_2049, resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/BatchNorm/gamma/_2051, resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/BatchNorm/moving_mean/_2053, resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/BatchNorm/moving_variance/_2055, resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/weights/_2057, resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/BatchNorm/beta/_2059, resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/BatchNorm/gamma/_2061, resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/BatchNorm/moving_mean/_2063, resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/BatchNorm/moving_variance/_2065, resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/weights/_2067, resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/BatchNorm/beta/_2069, resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/BatchNorm/gamma/_2071, resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/BatchNorm/moving_mean/_2073, resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/BatchNorm/moving_variance/_2075, resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/weights/_2077, resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/BatchNorm/beta/_2079, resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/BatchNorm/gamma/_2081, resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/BatchNorm/moving_mean/_2083, resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/BatchNorm/moving_variance/_2085, resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/weights/_2087, resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/BatchNorm/beta/_2089, resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/BatchNorm/gamma/_2091, resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/BatchNorm/moving_mean/_2093, resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/BatchNorm/moving_variance/_2095, resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/weights/_2097, resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/BatchNorm/beta/_2099, resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/BatchNorm/gamma/_2101, resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/BatchNorm/moving_mean/_2103, resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/BatchNorm/moving_variance/_2105, resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/weights/_2107, resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/BatchNorm/beta/_2109, resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/BatchNorm/gamma/_2111, resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/BatchNorm/moving_mean/_2113, resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/BatchNorm/moving_variance/_2115, resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/weights/_2117, resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/BatchNorm/beta/_2119, resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/BatchNorm/gamma/_2121, resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/BatchNorm/moving_mean/_2123, resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/BatchNorm/moving_variance/_2125, resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/weights/_2127, resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/BatchNorm/beta/_2129, resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/BatchNorm/gamma/_2131, resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/BatchNorm/moving_mean/_2133, resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/BatchNorm/moving_variance/_2135, resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/weights/_2137, resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/beta/_2139, resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma/_2141, resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_mean/_2143, resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_variance/_2145, resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/weights/_2147, resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/BatchNorm/beta/_2149, resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/BatchNorm/gamma/_2151, resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/BatchNorm/moving_mean/_2153, resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/BatchNorm/moving_variance/_2155, resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/weights/_2157, resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/BatchNorm/beta/_2159, resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/BatchNorm/gamma/_2161, resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/BatchNorm/moving_mean/_2163, resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/BatchNorm/moving_variance/_2165, resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/weights/_2167, resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/BatchNorm/beta/_2169, resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/BatchNorm/gamma/_2171, resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/BatchNorm/moving_mean/_2173, resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/BatchNorm/moving_variance/_2175, resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/weights/_2177, resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/BatchNorm/beta/_2179, resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/BatchNorm/gamma/_2181, resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/BatchNorm/moving_mean/_2183, resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/BatchNorm/moving_variance/_2185, resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/weights/_2187, resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/BatchNorm/beta/_2189, resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/BatchNorm/gamma/_2191, resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/BatchNorm/moving_mean/_2193, resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/BatchNorm/moving_variance/_2195, resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/weights/_2197, resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/BatchNorm/beta/_2199, resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/BatchNorm/gamma/_2201, resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/BatchNorm/moving_mean/_2203, resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/BatchNorm/moving_variance/_2205, resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/weights/_2207, resnet_v1_101/conv1/BatchNorm/beta/_2209, resnet_v1_101/conv1/BatchNorm/gamma/_2211, resnet_v1_101/conv1/BatchNorm/moving_mean/_2213, resnet_v1_101/conv1/BatchNorm/moving_variance/_2215, resnet_v1_101/conv1/weights/_2217)]]


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""../../../train.py"", line 140, in <module>
    train()
  File ""../../../train.py"", line 132, in train
    saver.save(sess, model_name, global_step=it)
  File ""/scratch/sjn/anaconda/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 1594, in save
    raise exc
ValueError: Parent directory of snapshot doesn't exist, can't save.
^CException ignored in: <module 'threading' from '/scratch/sjn/anaconda/lib/python3.6/threading.py'>
Traceback (most recent call last):
  File ""/scratch/sjn/anaconda/lib/python3.6/threading.py"", line 1294, in _shutdown
    t.join()
```

complete error can be found at:
https://hastebin.com/pivuzisece.lua

This is my pose_cfg.yaml file:

```
dataset: /scratch2/body_pose/pose-tensorflow/dataset/cropped/dataset.mat
dataset_type: ""mpii""

pos_dist_thresh: 17
global_scale: 0.8452830189
scale_jitter_lo: 0.85
scale_jitter_up: 1.15

net_type: resnet_101
init_weights: ../../pretrained/resnet_v1_101.ckpt

location_refinement: true
locref_huber_loss: true
locref_loss_weight: 0.05
locref_stdev: 7.2801

intermediate_supervision: true
intermediate_supervision_layer: 12

max_input_size: 850
multi_step:
- [0.005, 10000]
- [0.02, 430000]
- [0.002, 730000]
- [0.001, 1030000]
display_iters: 20
save_iters: 60000

mirror: true

```
```
[jalal@goku pose-tensorflow]$ conda list tensorflow
# packages in environment at /scratch/sjn/anaconda:
#
tensorflow-gpu            1.4.0                     <pip>
tensorflow-gpu-base       1.3.0           py36cuda8.0cudnn6.0_1  
tensorflow-tensorboard    0.4.0                     <pip>
tensorflow-tensorboard    0.1.5                    py36_0  
```
```
$ lsb_release -a
LSB Version:	:core-4.1-amd64:core-4.1-noarch
Distributor ID:	CentOS
Description:	CentOS Linux release 7.4.1708 (Core) 
Release:	7.4.1708
Codename:	Core
```


```
$ nvidia-smi
Sun Apr  8 22:03:20 2018       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 390.30                 Driver Version: 390.30                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 108...  Off  | 00000000:05:00.0  On |                  N/A |
|  0%   28C    P8    22W / 250W |    900MiB / 11178MiB |      3%      Default |
+-------------------------------+----------------------+----------------------+
|   1  GeForce GTX 108...  Off  | 00000000:06:00.0 Off |                  N/A |
|  0%   37C    P8    19W / 250W |      2MiB / 11178MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0      2572      G   /usr/bin/X                                   291MiB |
|    0      3196      G   /usr/bin/gnome-shell                         286MiB |
|    0     11624      G   ...-token=9F12957866330844F4A125587F711884   319MiB |
+-----------------------------------------------------------------------------+
[jalal@goku pose-tensorflow]$ 


```

```
$ cat /usr/local/cuda/version.txt
CUDA Version 8.0.61
```
"
18334,always get negative moving_variance in batchnormalization,"
------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
   Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
MacOS 10.12.6
- **TensorFlow installed from (source or binary)**:
pycharm
- **TensorFlow version (use command below)**:
1.5.0
- **Python version**: 
2.7
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
no CUDA
- **GPU model and memory**:
0
- **Exact command to reproduce**:

### Describe the problem
I trained a simple NN on my local mac without GPU. training data is random generated and validation data is exactly same as training data. During validation,  i always got negative moving_variance in some dimension in batchnormalization, which as a result, causes the network to output NaN issue.
By the way, frontend is Keras 2.1.5.
Here's the code

def create_pointwise_model():
        inputs = Input(shape=(13,), name='input_layer')
        normalized_inputs = BatchNormalization(momentum=0.01)(inputs) # i incline to take the value of current batch
        sum_inputs = Dense(1, name=""final_dense"", use_bias=False, kernel_initializer='glorot_normal')(normalized_inputs)
        sum_inputs = Activation('selu')(sum_inputs)
        
        model = Model(inputs=inputs, outputs=sum_inputs, name='pointwise_model')
        model.compile(optimizer='Adam', loss='binary_crossentropy')
        return model

#here's the test I wrote:
sample  = np.random.rand(4,13)

def get_data():
    while 1:
          yield (sample, np.array([[1],[1],[0],[0]]))

model = create_pointwise_model()
model.fit_generator(get_data(), steps_per_epoch=1, epochs=1000, validation_data= get_data().next())

During the training, I got NaN error and pinpointed that it's caused by negative moving_variance in batchnormalization. The way I fix this is that inside 
def batch_normalization(x,
                        mean,
                        variance,
                        offset,
                        scale,
                        variance_epsilon,
                        name=None):

I added this line:
    variance = tf.multiply(variance, tf.cast(tf.greater_equal(variance, 0),tf.float32))

But that's not the right way...

"
18333,Tree-LSTM couldn't be trained on the GPU,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 16.04;macOS10.12.6
- **TensorFlow installed from (source or binary)**:pip
- **TensorFlow version (use command below)**:1.6.0
- **Python version**: 3.6.4
- **Bazel version (if compiling from source)**:N/A
- **GCC/Compiler version (if compiling from source)**:N/A
- **CUDA/cuDNN version**: V9.0.176
- **GPU model and memory**: Titan XP, 12G
- **Exact command to reproduce**: GPU: python main.py;
                                                              CPU: running main.py on the Pycharm

### Describe the problem
Optimization function could not be used. Because once using the optimization, the process will be stuck. When I don't use the optimization, the process can be continued. 
based on strace -p, process stucks on futex_wait_private

### Source code / logs
https://github.com/JerryZeyu/SQuAd-tree-LSTM"
18332,tf_debug incompatibility with importlib (Python 3.6),"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: 1.7.0
- **Python version**: Python 3.6
- **Exact command to reproduce**:
- Bazel version: N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

### Describe the problem
When using tf_debug with a class that is dynamically imported using `importlib`, Tensorflow throws an exception since it is unable to determine if the dynamically imported library is either a compiled/uncompiled python file. This is due to how importlib handles imports, as a class imported using that library does not have a proper `file_path`, as seen in [this function](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/debug/lib/source_utils.py#L42) (Line 42 of `source_utils.py`). I believe it does this because it is trying to find the lines of the file which the traceback mentions, but is unable to find them.

### Source code / logs
```
229 ops no flops stats due to incomplete shapes.
Traceback (most recent call last):
  File ""C:\Users\Matt\PycharmProjects\Saltie\bot_code\models\base_model.py"", line 308, in _initialize_variables
    self.sess.run(init, run_metadata=run_metadata)
  File ""C:\Users\Matt\PycharmProjects\venvs\Saltie-3.6\lib\site-packages\tensorflow\python\debug\wrappers\grpc_wrapper.py"", line 225, in run
    self._sent_graph_version)
  File ""C:\Users\Matt\PycharmProjects\venvs\Saltie-3.6\lib\site-packages\tensorflow\python\debug\wrappers\grpc_wrapper.py"", line 61, in publish_traceback
    send_source=True)
  File ""C:\Users\Matt\PycharmProjects\venvs\Saltie-3.6\lib\site-packages\tensorflow\python\debug\lib\source_remote.py"", line 192, in send_graph_tracebacks
    graph=graph, send_source=send_source)
  File ""C:\Users\Matt\PycharmProjects\venvs\Saltie-3.6\lib\site-packages\tensorflow\python\debug\lib\source_remote.py"", line 154, in _send_call_tracebacks
    call_traceback.graph_traceback.id_to_string))
  File ""C:\Users\Matt\PycharmProjects\venvs\Saltie-3.6\lib\site-packages\tensorflow\python\debug\lib\source_remote.py"", line 94, in <genexpr>
    if not source_utils.guess_is_tensorflow_py_library(f) and gfile.Exists(f))
  File ""C:\Users\Matt\PycharmProjects\venvs\Saltie-3.6\lib\site-packages\tensorflow\python\debug\lib\source_utils.py"", line 76, in guess_is_tensorflow_py_library
    ""Input file path (%s) is not a Python source file."" % py_file_path)
ValueError: Input file path (<frozen importlib._bootstrap>) is not a Python source file.
```"
18329,Failed to load the native TensorFlow runtime.,"
------------------------

### System information

- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 Pro
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: tensorflow-gpu (1.7.0). 
- **Python version**:  3.5.5 
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: Cudnn 5,  Cudnn 6 with Cuda 8  and Cudnn 7 with Cuda 9 
- **GPU model and memory**: 3*GeForce GTX 1060 6G  MSI
- **Exact command to reproduce**: import tensorflow


### Describe the problem
My issue is I cannot even import tensorflow. I takes 2 minutes to load and output this error: 

### Source code / logs

```

(tensorflow) C:\Users\Technotronics Ltd\Documents\AI\nlp>python
Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 17:44:09) [MSC
v.1900 64 bit (AMD64)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow
Traceback (most recent call last):
Traceback (most recent call last):


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Users\Technotronics
Ltd\AppData\Local\conda\conda\envs\tensorflow\lib\site-packages\tensorflow\__init__.py"",
line 24, in <module>
    from tensorflow.python import *  # pylint: disable=redefined-builtin
  File ""C:\Users\Technotronics
Ltd\AppData\Local\conda\conda\envs\tensorflow\lib\site-packages\tensorflow\python\__init__.py"",
line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\Technotronics
Ltd\AppData\Local\conda\conda\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"",
line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\Technotronics
Ltd\AppData\Local\conda\conda\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"",
line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Technotronics
Ltd\AppData\Local\conda\conda\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"",
line 18, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Technotronics
Ltd\AppData\Local\conda\conda\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"",
line 17, in swig_import_helper
    return importlib.import_module(mname)
  File ""C:\Users\Technotronics
Ltd\AppData\Local\conda\conda\envs\tensorflow\lib\importlib\__init__.py"",
line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: DLL load failed: A dynamic link library (DLL)
initialization routine failed.


Failed to load the native TensorFlow runtime.

```

I stumbled upon this [script](https://gist.github.com/mrry/ee5dbcfdd045fa48a27d56664411d41c) that checks the tensorflow package but it tells me that all the required DLLs appear to be present but Failed to import the TensorFlow module. 

```

ERROR: Failed to import the TensorFlow module.

WARNING! This script is no longer maintained!
=============================================
Since TensorFlow 1.4, the self-check has been integrated with TensorFlow itself,
and any missing DLLs will be reported when you execute the `import tensorflow`
statement. The error messages printed below refer to TensorFlow 1.3 and earlier,
and are inaccurate for later versions of TensorFlow.

- Python version is 3.5.

- TensorFlow is installed at: C:\Users\Technotronics
Ltd\AppData\Local\conda\conda\envs\tensorflow\lib\site-packages\tensorflow

- All required DLLs appear to be present. Please open an issue on the
  TensorFlow GitHub page: https://github.com/tensorflow/tensorflow/issues
```
I am totally out of clue now. Please help

"
18328,saving model under different directory if specified one is already taken,"[https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/saved_model/builder_impl.py](url)
Line 87

If the specified directory name is already taken, is there a reason why the model saving has to fail instead of saving to some alternate directory? I was wondering if we could add a while loop that says that while the directory name is taken, we'll try again and save it in `export_dir + ""_"" + incr`?"
18326,"Input shape Error, bidirectional rnn","System Info:
    - OS: Windows 7
    - Cude: 9, 9.1
    - Tensorflow: 1.7.0
    - GPU Mode


I have some problems with bidirectional rnn inputs. After my anderstanging, a bidirectional  rnn needs a input from the shape ""[batch_size, input_size]"".  
May input ""hidden"" has first the shape (?, 512), I then reshape is to (1, 512) and expande the dims to
(1, 1, 512). I treid to pass all three versions to the bidirectional  rnn (and many more).  I have already used the last shap successful, with a normal rnn.




Error:
```
Traceback (most recent call last):
  File ""X:/PyProjects/Domm_Lerner/A3C_Arthur_Julianis_Doom.py"", line 572, in <module>
    master_network = AC_Network(s_size, a_size, cnn_size, 'global', None)  # Generate global network
  File ""X:/PyProjects/Domm_Lerner/A3C_Arthur_Julianis_Doom.py"", line 159, in __init__
    lstm_1_outputs, lstm_1_state_fw, lstm_1_state_bw = tf.nn.static_bidirectional_rnn(lstm_cell, lstm_cell, rnn_in,         initial_state_fw=state_1_in_fw, initial_state_bw=state_1_in_bw, sequence_length=step_size)
  File ""X:\PyProjects\Domm_Lerner\venv\lib\site-packages\tensorflow\python\ops\rnn.py"", line 1478, in static_bidirectional_rnn
    raise TypeError(""inputs must be a sequence"")
TypeError: inputs must be a sequence
```
 
 

Code:
```
            hidden = tf.reshape(hidden, shape=[1, cnn_size])
            rnn_in = tf.expand_dims(hidden, [0])

            step_size = tf.shape(self.imageIn)[:1]

            lstm_1_outputs, lstm_1_state_fw, lstm_1_state_bw = tf.nn.static_bidirectional_rnn(lstm_cell, lstm_cell, rnn_in,         initial_state_fw=state_1_in_fw, initial_state_bw=state_1_in_bw, sequence_length=step_size)
            lstm_2_outputs, lstm_2_state_fw, lstm_2_state_bw = tf.nn.static_bidirectional_rnn(lstm_cell, lstm_cell, lstm_1_outputs, initial_state_fw=state_2_in_fw, initial_state_bw=state_2_in_bw, sequence_length=step_size)
            lstm_3_outputs, lstm_3_state_fw, lstm_3_state_bw = tf.nn.static_bidirectional_rnn(lstm_cell, lstm_cell, lstm_2_outputs, initial_state_fw=state_3_in_fw, initial_state_bw=state_3_in_bw, sequence_length=step_size)
            lstm_4_outputs, lstm_4_state_fw, lstm_4_state_bw = tf.nn.static_bidirectional_rnn(lstm_cell, lstm_cell, lstm_3_outputs, initial_state_fw=state_4_in_fw, initial_state_bw=state_4_in_bw, sequence_length=step_size)
            lstm_5_outputs, lstm_5_state_fw, lstm_5_state_bw = tf.nn.static_bidirectional_rnn(lstm_cell, lstm_cell, lstm_4_outputs, initial_state_fw=state_5_in_fw, initial_state_bw=state_5_in_bw, sequence_length=step_size)
            lstm_6_outputs, lstm_6_state_fw, lstm_6_state_bw = tf.nn.static_bidirectional_rnn(lstm_cell, lstm_cell, lstm_5_outputs, initial_state_fw=state_6_in_fw, initial_state_bw=state_6_in_bw, sequence_length=step_size)
```
"
18325,"Caught OutOfRangeError. Stopping Training. FIFOQueue '_3_prefetch_queue' is closed and has insufficient elements (requested 1, current size 0)","- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 16.04 (PaperSpace Quadro P4000
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: 1.70
- **Python version**:  3.6.3
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: Cuda-repo-Ubuntu1604-9-1-local..9.1.85-1..amd64 , cudnn-9.1-linux-x64-v7.1
- **GPU model and memory**: Quadro P4000 - 8GB
- **Exact command to reproduce**:python3 train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/pipeline.config

While running the above command for ""faster_rcnn_resnet101_kitti"" model in the PaperSpace cloud in the machine Quadro P4000 it throws the error as follows:
    
    INFO:tensorflow:Caught OutOfRangeError. Stopping Training. FIFOQueue '_3_prefetch_queue' is 
    closed and has insufficient elements (requested 1, current size 0)
	 [[Node: prefetch_queue_Dequeue = QueueDequeueV2[component_types=[DT_STRING, DT_INT32, 
    DT_FLOAT, DT_INT32, DT_FLOAT, ..., DT_INT32, DT_INT32, DT_INT32, DT_STRING, DT_INT32], 
    timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](prefetch_queue)]]
	 [[Node: BatchMultiClassNonMaxSuppression/map/TensorArray_9/_2883 = 
    _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", 
    send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, 
    tensor_name=""edge_3507_BatchMultiClassNonMaxSuppression/map/TensorArray_9"", 
    tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]

    Caused by op 'prefetch_queue_Dequeue', defined at:
      File ""train.py"", line 167, in <module>
       tf.app.run()
      File ""/home/paperspace/anaconda3/lib/python3.6/site- 
    packages/tensorflow/python/platform/app.py"", line 126, in run
    _sys.exit(main(argv))
      File ""train.py"", line 163, in main
     worker_job_name, is_chief, FLAGS.train_dir)
     File ""/home/paperspace/Desktop/models-master/research/object_detection/trainer.py"", line 246, in 
    train
    clones = model_deploy.create_clones(deploy_config, model_fn, [input_queue])
    File ""/home/paperspace/Desktop/models-master/research/slim/deployment/model_deploy.py"", line 
    193, in create_clones
     outputs = model_fn(*args, **kwargs)
    File ""/home/paperspace/Desktop/models-master/research/object_detection/trainer.py"", line 158, in 
    _create_losses
     train_config.merge_multiple_label_boxes)
     File ""/home/paperspace/Desktop/models-master/research/object_detection/trainer.py"", line 114, in 
     get_inputs
     read_data_list = input_queue.dequeue()
     File ""/home/paperspace/Desktop/models-master/research/object_detection/core/batcher.py"", line 
     111, in dequeue
     batched_tensors = self._queue.dequeue()
     File ""/home/paperspace/anaconda3/lib/python3.6/site- 
     packages/tensorflow/python/ops/data_flow_ops.py"", line 440, in dequeue
     self._queue_ref, self._dtypes, name=name)
     File ""/home/paperspace/anaconda3/lib/python3.6/site- 
     packages/tensorflow/python/ops/gen_data_flow_ops.py"", line 3730, in queue_dequeue_v2
     timeout_ms=timeout_ms, name=name)
     File ""/home/paperspace/anaconda3/lib/python3.6/site- 
     packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
     op_def=op_def)
     File ""/home/paperspace/anaconda3/lib/python3.6/site- 
     packages/tensorflow/python/framework/ops.py"", line 3290, in create_op
     op_def=op_def)
     File ""/home/paperspace/anaconda3/lib/python3.6/site- 
     packages/tensorflow/python/framework/ops.py"", line 1654, in __init__
     self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

     OutOfRangeError (see above for traceback): FIFOQueue '_3_prefetch_queue' is closed and has 
     insufficient elements (requested 1, current size 0)
	 [[Node: prefetch_queue_Dequeue = QueueDequeueV2[component_types=[DT_STRING, DT_INT32, 
     DT_FLOAT, DT_INT32, DT_FLOAT, ..., DT_INT32, DT_INT32, DT_INT32, DT_STRING, DT_INT32], t 
     imeout_ms=-1, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](prefetch_queue)]]
	 [[Node: BatchMultiClassNonMaxSuppression/map/TensorArray_9/_2883 = 
     _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", 
     send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, 
     tensor_name=""edge_3507_BatchMultiClassNonMaxSuppression/map/TensorArray_9"", 
     tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]

     INFO:tensorflow:Finished training! Saving model to disk.
"
18324,can tensorflow lite be accelerated on android devices below 8.0? can renderscript or any gpu acceleration do the tricks?,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
18323,"The LSTM does not generate reproducible results, but GRU does","I can not get reproducible results by just using the LSTM, but GRU is Okay.

Let me explain what happens.

if I train an identical LSTM, 10 times in a loop, for the first 6 run it handles MSE equal to value `a` and for the rest 4 run it handles MSE value `b`. weird isn't? 
Just value `a` OR `b`. it means an identical LSTM can handle two MSEs by random and just two MSE values.

and if I just replace the LSTM with GRU, all 10 runs handle identical MSEs.

I use Tensorflow 1.7 and Keras 2.1.5, I run on the CPU."
18322,Tensorflow 1.7.0 - Illegal instruction,"Hy everyone!

I have Illegal instruction with tensorflow (v. 1.7) when I just type the import command:

Python 2.7.14 |Anaconda, Inc.| (default, Mar 27 2018, 17:29:31) 
[GCC 7.2.0] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
Illegal instruction ( core dumped creato )

Surface the internet for the solution, I found that I can downgrade at 1.5 but I cannot downgrade at 1.5 because I need new attribute that are located in 1.6 and 1.7. (the attribute is tf.contrib.data.shuffle_and_repeat).

How can I fix the problem?

This is my CPU: AMD A4-3300M APU with Radeon(tm) HD Graphics
It's to old to run tensorflow? Is tensorflow works with new CPU and GPU? My PC is 6-7 years old.
"
18320,How to solve the problem that the unsupported operations,"### Describe the problem
I want to convert my project to xxx.tflite,but i meet the problem blew ""Didn't find custom op for name 'FLOOR'"". So how to solve this problem?

### Source code / logs
![image](https://user-images.githubusercontent.com/15247604/38462856-e05f469e-3b1f-11e8-8e0e-07c61f28cedf.png)
"
18318,Is input of tf.contrib.cudnn_rnn.CudnnLSTM time-major?,"

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 17.10
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.6
- **Python version**: 3.6
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:9/7.0
- **GPU model and memory**:
- **Exact command to reproduce**:

### Describe the problem

I save this in tensorflow/models: [quick_draw exmple](https://github.com/tensorflow/models/blob/master/tutorials/rnn/quickdraw/train_model.py)

you can see that in the comment of this function.  it says that CudnnLSTM is time-major, so it need a transpose. But I don't find this information in documentation [here](https://tensorflow.google.cn/versions/r1.6/api_docs/python/tf/contrib/cudnn_rnn/CudnnLSTM#__call__):

Where can I get confirmation of this ?
```
  def _add_cudnn_rnn_layers(convolved):
    """"""Adds CUDNN LSTM layers.""""""
    # Convolutions output [B, L, Ch], while CudnnLSTM is time-major.
    convolved = tf.transpose(convolved, [1, 0, 2])
    lstm = tf.contrib.cudnn_rnn.CudnnLSTM(
        num_layers=params.num_layers,
        num_units=params.num_nodes,
        dropout=params.dropout if mode == tf.estimator.ModeKeys.TRAIN else 0.0,
        direction=""bidirectional"")
    outputs, _ = lstm(convolved)
    # Convert back from time-major outputs to batch-major outputs.
    outputs = tf.transpose(outputs, [1, 0, 2])
    return outputs

```
"
18317,[bug] FtrlOptimizer with l2_shrinkage_regularization_strength is incorrect,"The result of `accum` in FtrlOptimizer with l2_shrinkage_regularization_strength seems incorrect.

Test code:
```
import tensorflow as tf

from tensorflow.python.framework import constant_op
from tensorflow.python.ops import variables
from tensorflow.python.training import ftrl

dtype = ""float32""

with tf.Session() as sess:
  var0 = variables.Variable([1.0], dtype=dtype)
  grads0 = constant_op.constant([0.1], dtype=dtype)
  opt = ftrl.FtrlOptimizer(
      3.0,
      initial_accumulator_value=0.0,
      l1_regularization_strength=0.0,
      l2_regularization_strength=0.0,
      l2_shrinkage_regularization_strength=0.5)
  update = opt.apply_gradients(zip([grads0], [var0]))
  variables.global_variables_initializer().run()

  v0_val = sess.run(var0)

  update.run()

  v0_val = sess.run(var0)
  print (sess.run(opt._slots))
  print (v0_val)
```

My result is 
```
{'accum': {(<tensorflow.python.framework.ops.Graph object at 0x7f1d1221a990>, u'Variable'): array([3.61], dtype=float32)}, 'linear': {(<tensorflow.python.framework.ops.Graph object at 0x7f1d1221a990>, u'Variable'): array([0.73333335], dtype=float32)}}
[-2.]
```
OS Platform and Distribution
OS: Ubuntu 16.04
Tensorflow version: 1.7.0
CPU: i7 4790

TensorFlow installed from
pypi

According to comments of apply_ftrl_v2 in gen_training_ops.py
```
grad_with_shrinkage = grad + 2 * l2_shrinkage * var
accum_new = accum + grad_with_shrinkage * grad_with_shrinkage
linear += grad_with_shrinkage +
      (accum_new^(-lr_power) - accum^(-lr_power)) / lr * var
quadratic = 1.0 / (accum_new^(lr_power) * lr) + 2 * l2
var = (sign(linear) * l1 - linear) / quadratic if |linear| > l1 else 0.0
accum = accum_new
```
grad_with_shrinkage should be [0.1] + 2 * 0.5 * [1.0] = 1.1
accum_new should be [0.0] + [1.1] * [1.1] = [1.21]
so accum should be [1.21], but the result of accum from the test code is [3.61] ???

"
18316,TensorFlow-GPU random GPU crashes while training,"### System information
- Custom code - Simple q learning model using Keras with TF and Open AI Gym
- Windows 10
- Tensorflow installed with pip
- TensorFlow-gpu 1.7.0
- Python 3.6.4
- CUDA 9.0, cuDNN 7
- Nvidia GeForce GTX 1050 Ti GDDR5 4GB

### Describtion
When I'm running a script randomly two types of errors happen:

-  Blue Screen with Driver Power State Failure
- TensorFlow cannot locate gpu "" failed call to cuInit: CUDA_ERROR_NO_DEVICE""

This happens approximately once per 10 runs. GeForce is my secondary gpu card, so I assume, that it is not related to watchdog timer.

Result od deviceQuery:
> Device 0: ""GeForce GTX 1050 Ti""
>   CUDA Driver Version / Runtime Version          9.0 / 9.0
>   CUDA Capability Major/Minor version number:    6.1
>   Total amount of global memory:                 4096 MBytes (4294967296 bytes)
>   ( 6) Multiprocessors, (128) CUDA Cores/MP:     768 CUDA Cores
>   GPU Max Clock rate:                            1620 MHz (1.62 GHz)
>   Memory Clock rate:                             3504 Mhz
>   Memory Bus Width:                              128-bit
>   L2 Cache Size:                                 1048576 bytes
>   Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)
>   Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers
>   Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers
>   Total amount of constant memory:               65536 bytes
>   Total amount of shared memory per block:       49152 bytes
>   Total number of registers available per block: 65536
>   Warp size:                                     32
>   Maximum number of threads per multiprocessor:  2048
>   Maximum number of threads per block:           1024
>   Max dimension size of a thread block (x,y,z): (1024, 1024, 64)
>   Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)
>   Maximum memory pitch:                          2147483647 bytes
>   Texture alignment:                             512 bytes
>   Concurrent copy and kernel execution:          Yes with 2 copy engine(s)
>   Run time limit on kernels:                     Yes
>   Integrated GPU sharing Host Memory:            No
>   Support host page-locked memory mapping:       Yes
>   Alignment requirement for Surfaces:            Yes
>   Device has ECC support:                        Disabled
>   CUDA Device Driver Mode (TCC or WDDM):         WDDM (Windows Display Driver Model)
>   Device supports Unified Addressing (UVA):      Yes
>   Supports Cooperative Kernel Launch:            No
>   Supports MultiDevice Co-op Kernel Launch:      No
>   Device PCI Domain ID / Bus ID / location ID:   0 / 1 / 0
>   Compute Mode:
>      < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >
> 
> deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 9.0, CUDA Runtime Version = 9.0, NumDevs = 1
> Result = PASS
"
18314,Feature Request: Allow extending Estimator,"Our model is time based and we are doing continuous training and eval on the same machine. The model is very large and takes 1+ minutes to load, so we don't want the overhead of reloading the graph and weights every time we switch from training to eval https://github.com/tensorflow/tensorflow/issues/13895#issuecomment-375990484.

I tried to subclass Estimator to override the `_train_model fn` but it is not allowed due to this [white-list](https://github.com/tensorflow/tensorflow/blob/e7f158858479400f17a1b6351e9827e3aa83e7ff/tensorflow/python/estimator/estimator.py#L524-L528). Can you remove this restriction and let people override methods at their own peril?

`Subclasses of Estimator cannot override members of Estimator. <class ... does override ['_train_model']` (relates to https://github.com/tensorflow/tensorflow/issues/12908)."
18311,[Feature request] unsquashing unsorted_segment_x,"Have I written custom code? No
OS Platform and Distribution? Win10
TensorFlow installed from? pip
TensorFlow version? 1.7
Bazel version? N/A
CUDA/cuDNN version? N/A
GPU model and memory? N/A
Exact command to reproduce: unsorted_segment_sum

### Describe the problem
Let's say you have 3 sequences of 12 values (shape (3,12)) with 5 segments and you have an input of shape (None,12,3) transposed to (3,12,None)
using any function with unsorted_segement_x the output will be (5,None).

Would it be possible to have a function that does the same but still keep the first dimention.
Something equivalent to:
```python
input.shape==(None,12,3)
segment.shape==(3,12)

outputs=[]
for ix, val in enumerate(tf.unstack(input)):
    ouputs.append(tf.unsorted_segment_sum(val,sequence[ix],5)
output=tf.stack(outputs)
output.shape==(3,5,None)
```
The use of such a thing would be to iterate over a weighted input and without having to loop over the data or using reshape. I think this should be somewhat straightforward to implement; not concatenate together all the sequences for the superior dimensions and use ""keep_dims"" similar to reduce_sum to trigger that behaviour.



"
18310,Feature Request: Locally Connected Conv2d,"### Describe the problem
Need new features, the local conv is avaiable in Keras.
https://www.tensorflow.org/api_docs/python/tf/keras/layers/LocallyConnected2D
But tensorflow does not have this feature. I have writen this layer with tensorlayer, it can work, but the initializing is too slow. So I want offical to release a better implementation. Thanks
### Source code / logs
```
class LocalConnectedConv(Layer):
    def __init__(
        self,
        layer = None,
        filters=0,
        size=3,
        multiplexH=1,
        multiplexW=1,
        stride=1,
        overlap=True,
        act = tf.identity,
        name ='lcconv2d',
    ):
        Layer.__init__(self, name=name)
        self.inputs = layer.outputs
        channels = int(self.inputs.get_shape()[-1])
        inputH=int(self.inputs.get_shape()[1])
        inputW = int(self.inputs.get_shape()[2])
        if inputH%multiplexH==0 and inputW%multiplexW==0:
            print('ok')
        else:
            return 0
        CellH= int(np.floor(inputH/multiplexH))
        CellW=int(np.floor(inputW/multiplexW))
        CellHm= int(np.floor(inputH/multiplexH))
        CellWm=int(np.floor(inputW/multiplexW))
        if overlap:
            CellH = np.floor(inputH / multiplexH*2)
            CellW = np.floor(inputW / multiplexW*2)
            CellH=int(CellH)
            CellW=int(CellW)
        Wd=False
        Hd=False
        if CellH%2==0:
            Hd=True
        if CellW%2==0:
            Wd=True
        with tf.variable_scope(name) as vs:
            Welist=[]
            Bilist=[]
            for i in range(multiplexH):
                for j in range(multiplexW):

                    We = tf.get_variable(name='weights%d-%d'%(i,j), shape=[size, size, channels, filters],
                                               initializer=tf.truncated_normal_initializer(stddev=0.03),
                                               dtype=tf.float32, trainable=True)
                    bi = tf.get_variable(name='biases%d-%d'%(i,j), shape=[filters, ],
                                              initializer=tf.constant_initializer(value=0.1),
                                              dtype=tf.float32, trainable=True)
                    Welist.append(We)
                    Bilist.append(bi)
        Convij=[]
        for i in range(multiplexH):
            for j in range(multiplexW):
                ci=np.floor((i+0.5)*CellHm-0.01)+1
                cj=np.floor((j+0.5)*CellWm-0.01)+1
                if not overlap:
                    if i==0:
                        hcs=0
                        hce=hcs+CellH+size-1
                    elif i==multiplexH-1:
                        hce=inputH
                        hcs = hce-CellH-size+1
                    elif Hd:
                        hcs=ci-(CellH+size-1)/2
                        hce=ci+(CellH+size-1)/2
                    else:
                        hcs=ci-np.floor((CellH+size-1)*0.5-0.01)-1
                        hce=ci+np.floor((CellH+size-1)*0.5-0.01)
                    if j==0:
                        wcs=0
                        wce=wcs+CellW+size-1
                    elif j==multiplexW-1:
                        wce=inputW
                        wcs = wce-CellW-size+1
                    elif Wd:
                        wcs=cj-(CellW+size-1)/2
                        wce=cj+(CellW+size-1)/2
                    else:
                        wcs=cj-np.floor((CellW+size-1)*0.5-0.01)-1
                        wce=cj+np.floor((CellW+size-1)*0.5-0.01)
                else:
                    if i == 0:
                        hcs = 0
                        hce = hcs + CellH
                    elif i == multiplexH - 1:
                        hce = inputH
                        hcs = hce - CellH
                    elif Hd:
                        hcs = ci - (CellH) / 2
                        hce = ci + (CellH) / 2
                    else:
                        hcs = ci - np.floor((CellH ) * 0.5 - 0.01)-1
                        hce = ci + np.floor((CellH ) * 0.5 - 0.01)
                    if j == 0:
                        wcs = 0
                        wce = wcs + CellW
                    elif j == multiplexW - 1:
                        wce = inputW
                        wcs = wce - CellW
                    elif Wd:
                        wcs = cj - (CellW ) / 2
                        wce = cj + (CellW ) / 2
                    else:
                        wcs = cj - np.floor((CellW ) * 0.5 - 0.01)-1
                        wce = cj + np.floor((CellW) * 0.5 - 0.01)
                hcs=int(hcs)
                wcs=int(wcs)
                hce=int(hce)
                wce=int(wce)
                it=self.inputs[:,hcs:hce,wcs:wce,:]
                convtemp=tf.nn.conv2d(it,Welist[multiplexW*i+j], strides=[1, stride, stride, 1], padding='VALID')
                convtemp=tf.add(convtemp, Bilist[multiplexW*i+j])
                Convij.append(convtemp)
        convli=[]
        for i in range(multiplexH):
            convlii=[]
            for j in range(multiplexW):
                convlii.append(Convij[multiplexW * i + j])
            convli.append(convlii)
        convt=[]
        for i in range(multiplexH):
            convt.append(tf.concat(convli[i],axis=2))
        convfin=tf.concat(convt,axis=1)
        self.outputs =act(convfin)
        self.all_layers = list(layer.all_layers)
        self.all_params = list(layer.all_params)
        self.all_drop = dict(layer.all_drop)
        self.all_layers.extend([self.outputs])
        self.all_params.extend(Welist)
        self.all_params.extend(Bilist)
```
"
18309,Cannot build toco or use it to convert pretrained model,"Hi, i encountered a lot of problems using tflite. I can build the demo and run it on my android phone. I am trying to convert my trained model to tflite format and cannot even build toco. I have already editted the workspace with the directory of sdk and ndk. The first problem shows up saying max/min is no -std member. I add the `#include<algorithm>` to that file and the next strange problem shows up. Is this tool(tensorflow lite) is going to be obsoleted? 

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: win 10
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.6.0
- **Python version**: 3.6.4
- **Bazel version (if compiling from source)**: 0.11.1
- **GCC/Compiler version (if compiling from source)**:7.3.0
- **CUDA/cuDNN version**: 9.0/7
- **GPU model and memory**: 1060/6G
- **Exact command to reproduce**: bazel run --config=opt //tensorflow/contrib/lite/toco:toco -- --input_file=/tmp/mobilenet_v1_0.50_128/frozen_graph.pb --output_file=/tmp/foo.tflite  --inference_type=FLOAT --input_shape=1,128,128,3 --input_array=input --output_array=MobilenetV1/Predictions/Reshape_1 --verbose_failures

### Describe the problem
The command above is verifying my setup through official site examples, and it even cannot work. The error msg is below.
`ERROR: C:/users/herrick/appdata/local/temp/_bazel_herrick/emsryngl/external/com_google_absl/absl/strings/BUILD.bazel:35:1: C++ compilation of rule '@com_google_absl//absl/strings:strings' failed (Exit 2)`

### Source code / logs
The logs is too long. The latest error is above."
18307,WinML or DirectML support planned?,"Windows only, but this should support AMD and Intel GPUs using D3D12 backend or even DirectML which with custom metacommands seems even able to use tensor cores on Volta GPUs..
Hope to hear news at least by Build conference in May
"
18306,"[Go] SIGABRT (Unexpected type: 23) when running go test, using tensorflow > 1.4","The same error reported in #14546 is still present in every tensorflow release > 1.4 (and master branch).

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Archlinux
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: Build label: 0.7.0- (@non-git)
- **GCC/Compiler version (if compiling from source)**: gcc-6
- **CUDA/cuDNN version**: CUDA 9 / cuDNN 7
- **GPU model and memory**: Dual Nvidia 1080 Ti
- **Exact command to reproduce**:

```
go test github.com/tensorflow/tensorflow/tensorflow/go
```

### Describe the problem

I have build tensorflow with CUDA support. Since Go requires the C library, I built `libtensorflow.so` and `libtensorflow_framework.so`, with:

```
bazel build //tensorflow:libtensorflow_framework.so
bazel build //tensorflow:libtensorflow.so
```

I updated `LD_LIBRARY_PATH` accordingly:

```bash
TENSORFLOW_LIBLIB=""${HOME}/sources/tensorflow/bazel-bin/tensorflow/""
export LD_LIBRARY_PATH=""$LD_LIBRARY_PATH:/opt/cuda/lib64:/opt/cuda/extras/CUPTI/lib64:${TENSORFLOW_LIBLIB}""
export LIBRARY_PATH=""${TENSORFLOW_LIBLIB}:${LIBRARY_PATH}""
```

I can now go get tensorflow without problems, I can hence compile it and use the `-ltensorflow` linker flag.

When I run `go test` on the tensorflow package, the following error (`tensorflow/core/framework/tensor.cc:822] Unexpected type: 23 `) is thrown and causes SIGABRT.

### Source code / logs

**1.5**
```
(cv) [pgaleone@persefone go]$ git checkout r1.5
Switched to branch 'r1.5'
Your branch is up to date with 'origin/r1.5'.
(cv) [pgaleone@persefone go]$ go test
2018-04-07 08:37:06.625482: F tensorflow/core/framework/tensor.cc:822] Unexpected type: 23
SIGABRT: abort
PC=0x7f82afedd860 m=8 sigcode=18446744073709551610

goroutine 0 [idle]:
runtime: unknown pc 0x7f82afedd860
stack: frame={sp:0x7f82937f5880, fp:0x0} stack=[0x7f8292ff61d0,0x7f82937f5dd0)
00007f82937f5780:  0000000000000000  0000006e0000005b 
00007f82937f5790:  0000000000000000  000000770000007c 
00007f82937f57a0:  000000000000001b  00007f827c000020 
00007f82937f57b0:  0000000000000014  fffffffffffffef8 
00007f82937f57c0:  00007f827c00822d  0000000000000003 
00007f82937f57d0:  00007f827c006940  00007f82aff2b47a 
00007f82937f57e0:  00007f827c0052b0  00007f827c0052c1 
00007f82937f57f0:  000000000000000d  00007f82aff5cdc2 
00007f82937f5800:  00007f82b025b350  0000000000000001 
00007f82937f5810:  0000000000000000  00000000000000ac 
00007f82937f5820:  00007f82b025b350  00007f82aff5de29 
00007f82937f5830:  0000000000000001  ffffffff00000008 
00007f82937f5840:  01000000004d1d96  0000000000000011 
00007f82937f5850:  0000000000000008  0000000000000008 
00007f82937f5860:  00000000000006b8  00000000000006b8 
00007f82937f5870:  00007f82937f5900  0000000000000000 
00007f82937f5880: <0000000000000000  0000000000000000 
00007f82937f5890:  0800000000000000  0000000008000000 
00007f82937f58a0:  08000000ae000000  0000000011000000 
00007f82937f58b0:  0000000000000802  000000000076074b 
00007f82937f58c0:  0000000000000003  a56bbb4077756a00 
00007f82937f58d0:  0000000000000000  00007f82937f5ae0 
00007f82937f58e0:  00007f82937f5a50  00007f82937f5a70 
00007f82937f58f0:  0000000000098b4a  00007f82937f5a20 
00007f82937f5900:  fffffffe7fffffff  ffffffffffffffff 
00007f82937f5910:  ffffffffffffffff  ffffffffffffffff 
00007f82937f5920:  ffffffffffffffff  ffffffffffffffff 
00007f82937f5930:  ffffffffffffffff  ffffffffffffffff 
00007f82937f5940:  ffffffffffffffff  ffffffffffffffff 
00007f82937f5950:  ffffffffffffffff  ffffffffffffffff 
00007f82937f5960:  ffffffffffffffff  ffffffffffffffff 
00007f82937f5970:  ffffffffffffffff  ffffffffffffffff 
runtime: unknown pc 0x7f82afedd860
stack: frame={sp:0x7f82937f5880, fp:0x0} stack=[0x7f8292ff61d0,0x7f82937f5dd0)
00007f82937f5780:  0000000000000000  0000006e0000005b 
00007f82937f5790:  0000000000000000  000000770000007c 
00007f82937f57a0:  000000000000001b  00007f827c000020 
00007f82937f57b0:  0000000000000014  fffffffffffffef8 
00007f82937f57c0:  00007f827c00822d  0000000000000003 
00007f82937f57d0:  00007f827c006940  00007f82aff2b47a 
00007f82937f57e0:  00007f827c0052b0  00007f827c0052c1 
00007f82937f57f0:  000000000000000d  00007f82aff5cdc2 
00007f82937f5800:  00007f82b025b350  0000000000000001 
00007f82937f5810:  0000000000000000  00000000000000ac 
00007f82937f5820:  00007f82b025b350  00007f82aff5de29 
00007f82937f5830:  0000000000000001  ffffffff00000008 
00007f82937f5840:  01000000004d1d96  0000000000000011 
00007f82937f5850:  0000000000000008  0000000000000008 
00007f82937f5860:  00000000000006b8  00000000000006b8 
00007f82937f5870:  00007f82937f5900  0000000000000000 
00007f82937f5880: <0000000000000000  0000000000000000 
00007f82937f5890:  0800000000000000  0000000008000000 
00007f82937f58a0:  08000000ae000000  0000000011000000 
00007f82937f58b0:  0000000000000802  000000000076074b 
00007f82937f58c0:  0000000000000003  a56bbb4077756a00 
00007f82937f58d0:  0000000000000000  00007f82937f5ae0 
00007f82937f58e0:  00007f82937f5a50  00007f82937f5a70 
00007f82937f58f0:  0000000000098b4a  00007f82937f5a20 
00007f82937f5900:  fffffffe7fffffff  ffffffffffffffff 
00007f82937f5910:  ffffffffffffffff  ffffffffffffffff 
00007f82937f5920:  ffffffffffffffff  ffffffffffffffff 
00007f82937f5930:  ffffffffffffffff  ffffffffffffffff 
00007f82937f5940:  ffffffffffffffff  ffffffffffffffff 
00007f82937f5950:  ffffffffffffffff  ffffffffffffffff 
00007f82937f5960:  ffffffffffffffff  ffffffffffffffff 
00007f82937f5970:  ffffffffffffffff  ffffffffffffffff 

goroutine 30 [syscall]:
runtime.cgocall(0x6524d0, 0xc42005b8d0, 0xc42005b8d8)
	/usr/lib/go/src/runtime/cgocall.go:128 +0x64 fp=0xc42005b8a0 sp=0xc42005b868 pc=0x405454
github.com/tensorflow/tensorflow/tensorflow/go._Cfunc_TF_SetAttrTensor(0x7f827c0043b0, 0x7f827c005190, 0x7f827c005280, 0x7f827c006650)
	_cgo_gotypes.go:921 +0x45 fp=0xc42005b8d0 sp=0xc42005b8a0 pc=0x522ac5
github.com/tensorflow/tensorflow/tensorflow/go.setAttr.func18(0x7f827c0043b0, 0x7f827c005190, 0x7f827c005280, 0x7f827c006650)
	/home/pgaleone/projects/go/src/github.com/tensorflow/tensorflow/tensorflow/go/graph.go:306 +0xce fp=0xc42005b908 sp=0xc42005b8d0 pc=0x52e4ae
github.com/tensorflow/tensorflow/tensorflow/go.setAttr(0x7f827c0043b0, 0xc42000e0c0, 0x6ed34c, 0x5, 0x6b21a0, 0xc420112500, 0x0, 0x0)
	/home/pgaleone/projects/go/src/github.com/tensorflow/tensorflow/tensorflow/go/graph.go:306 +0x1006 fp=0xc42005bad8 sp=0xc42005b908 pc=0x5255f6
github.com/tensorflow/tensorflow/tensorflow/go.(*Graph).AddOperation(0xc42000e080, 0x6ed1a3, 0x5, 0xc42001a7e8, 0x6, 0x0, 0x0, 0x0, 0xc42005bcb0, 0xc420047cf0, ...)
	/home/pgaleone/projects/go/src/github.com/tensorflow/tensorflow/tensorflow/go/graph.go:209 +0x49d fp=0xc42005bc30 sp=0xc42005bad8 pc=0x52443d
github.com/tensorflow/tensorflow/tensorflow/go.Const(0xc42000e080, 0xc42001a7e8, 0x6, 0x67d160, 0xc420112340, 0xc42001a7e8, 0x6, 0x7ad090, 0x7ad0d0)
	/home/pgaleone/projects/go/src/github.com/tensorflow/tensorflow/tensorflow/go/util_test.go:38 +0x247 fp=0xc42005be40 sp=0xc42005bc30 pc=0x51fb77
github.com/tensorflow/tensorflow/tensorflow/go.TestOutputDataTypeAndShape.func1(0xc420128780)
	/home/pgaleone/projects/go/src/github.com/tensorflow/tensorflow/tensorflow/go/operation_test.go:137 +0x111 fp=0xc42005bfa8 sp=0xc42005be40 pc=0x52bbc1
testing.tRunner(0xc420128780, 0xc4201124c0)
	/usr/lib/go/src/testing/testing.go:777 +0xd0 fp=0xc42005bfd0 sp=0xc42005bfa8 pc=0x4ce240
runtime.goexit()
	/usr/lib/go/src/runtime/asm_amd64.s:2361 +0x1 fp=0xc42005bfd8 sp=0xc42005bfd0 pc=0x45cf41
created by testing.(*T).Run
	/usr/lib/go/src/testing/testing.go:824 +0x2e0

goroutine 1 [chan receive]:
testing.(*T).Run(0xc4201283c0, 0x6f3637, 0x1a, 0x7013f0, 0x477b01)
	/usr/lib/go/src/testing/testing.go:825 +0x301
testing.runTests.func1(0xc420128000)
	/usr/lib/go/src/testing/testing.go:1063 +0x64
testing.tRunner(0xc420128000, 0xc42006bdf8)
	/usr/lib/go/src/testing/testing.go:777 +0xd0
testing.runTests(0xc420112260, 0xa49460, 0x11, 0x11, 0x413b29)
	/usr/lib/go/src/testing/testing.go:1061 +0x2c4
testing.(*M).Run(0xc420126000, 0x0)
	/usr/lib/go/src/testing/testing.go:978 +0x171
main.main()
	_testmain.go:82 +0x151

goroutine 26 [chan receive]:
testing.(*T).Run(0xc420128780, 0xc420018420, 0x13, 0xc4201124c0, 0x2)
	/usr/lib/go/src/testing/testing.go:825 +0x301
github.com/tensorflow/tensorflow/tensorflow/go.TestOutputDataTypeAndShape(0xc4201283c0)
	/home/pgaleone/projects/go/src/github.com/tensorflow/tensorflow/tensorflow/go/operation_test.go:136 +0x552
testing.tRunner(0xc4201283c0, 0x7013f0)
	/usr/lib/go/src/testing/testing.go:777 +0xd0
created by testing.(*T).Run
	/usr/lib/go/src/testing/testing.go:824 +0x2e0

rax    0x0
rbx    0x6
rcx    0x7f82afedd860
rdx    0x0
rdi    0x2
rsi    0x7f82937f5880
rbp    0x7f82937f5ad0
rsp    0x7f82937f5880
r8     0x0
r9     0x7f82937f5880
r10    0x8
r11    0x246
r12    0x7f82937f5d10
r13    0x5
r14    0x7f827c005190
r15    0x7f82937f5d10
rip    0x7f82afedd860
rflags 0x246
cs     0x33
fs     0x0
gs     0x0
exit status 2
FAIL	github.com/tensorflow/tensorflow/tensorflow/go	0.081s
```

**1.6**
```
(cv) [pgaleone@persefone go]$ git checkout r1.6
Switched to branch 'r1.6'
Your branch is up to date with 'origin/r1.6'.
(cv) [pgaleone@persefone go]$ go test
2018-04-07 08:37:33.608147: F tensorflow/core/framework/tensor.cc:822] Unexpected type: 23
SIGABRT: abort
PC=0x7f884c725860 m=7 sigcode=18446744073709551610

goroutine 0 [idle]:
runtime: unknown pc 0x7f884c725860
stack: frame={sp:0x7f88307f7880, fp:0x0} stack=[0x7f882fff81d0,0x7f88307f7dd0)
00007f88307f7780:  0000000000000000  0000006e0000005b 
00007f88307f7790:  0000000000000000  000000770000007c 
00007f88307f77a0:  000000000000001b  00007f8828000020 
00007f88307f77b0:  0000000000000014  fffffffffffffef8 
00007f88307f77c0:  00007f882800a19d  0000000000000003 
00007f88307f77d0:  00007f88280088b0  00007f884c77347a 
00007f88307f77e0:  00007f8828007220  00007f8828007231 
00007f88307f77f0:  000000000000000d  00007f884c7a4dc2 
00007f88307f7800:  00007f884caa3350  0000000000000001 
00007f88307f7810:  0000000000000000  00000000000000ac 
00007f88307f7820:  00007f884caa3350  00007f884c7a5e29 
00007f88307f7830:  0000000000000001  ffffffff00000008 
00007f88307f7840:  01000000004d2166  0000000000000011 
00007f88307f7850:  0000000000000008  0000000000000008 
00007f88307f7860:  00000000000006b8  00000000000006b8 
00007f88307f7870:  00007f88307f7900  0000000000000000 
00007f88307f7880: <0000000000000000  0000000000000000 
00007f88307f7890:  0800000000000000  0000000008000000 
00007f88307f78a0:  08000000ae000000  0000000011000000 
00007f88307f78b0:  0000000000000802  000000000076074b 
00007f88307f78c0:  0000000000000003  61e47ad4235a2e00 
00007f88307f78d0:  0000000000000000  00007f88307f7ae0 
00007f88307f78e0:  00007f88307f7a50  00007f88307f7a70 
00007f88307f78f0:  0000000000094793  00007f88307f7a20 
00007f88307f7900:  fffffffe7fffffff  ffffffffffffffff 
00007f88307f7910:  ffffffffffffffff  ffffffffffffffff 
00007f88307f7920:  ffffffffffffffff  ffffffffffffffff 
00007f88307f7930:  ffffffffffffffff  ffffffffffffffff 
00007f88307f7940:  ffffffffffffffff  ffffffffffffffff 
00007f88307f7950:  ffffffffffffffff  ffffffffffffffff 
00007f88307f7960:  ffffffffffffffff  ffffffffffffffff 
00007f88307f7970:  ffffffffffffffff  ffffffffffffffff 
runtime: unknown pc 0x7f884c725860
stack: frame={sp:0x7f88307f7880, fp:0x0} stack=[0x7f882fff81d0,0x7f88307f7dd0)
00007f88307f7780:  0000000000000000  0000006e0000005b 
00007f88307f7790:  0000000000000000  000000770000007c 
00007f88307f77a0:  000000000000001b  00007f8828000020 
00007f88307f77b0:  0000000000000014  fffffffffffffef8 
00007f88307f77c0:  00007f882800a19d  0000000000000003 
00007f88307f77d0:  00007f88280088b0  00007f884c77347a 
00007f88307f77e0:  00007f8828007220  00007f8828007231 
00007f88307f77f0:  000000000000000d  00007f884c7a4dc2 
00007f88307f7800:  00007f884caa3350  0000000000000001 
00007f88307f7810:  0000000000000000  00000000000000ac 
00007f88307f7820:  00007f884caa3350  00007f884c7a5e29 
00007f88307f7830:  0000000000000001  ffffffff00000008 
00007f88307f7840:  01000000004d2166  0000000000000011 
00007f88307f7850:  0000000000000008  0000000000000008 
00007f88307f7860:  00000000000006b8  00000000000006b8 
00007f88307f7870:  00007f88307f7900  0000000000000000 
00007f88307f7880: <0000000000000000  0000000000000000 
00007f88307f7890:  0800000000000000  0000000008000000 
00007f88307f78a0:  08000000ae000000  0000000011000000 
00007f88307f78b0:  0000000000000802  000000000076074b 
00007f88307f78c0:  0000000000000003  61e47ad4235a2e00 
00007f88307f78d0:  0000000000000000  00007f88307f7ae0 
00007f88307f78e0:  00007f88307f7a50  00007f88307f7a70 
00007f88307f78f0:  0000000000094793  00007f88307f7a20 
00007f88307f7900:  fffffffe7fffffff  ffffffffffffffff 
00007f88307f7910:  ffffffffffffffff  ffffffffffffffff 
00007f88307f7920:  ffffffffffffffff  ffffffffffffffff 
00007f88307f7930:  ffffffffffffffff  ffffffffffffffff 
00007f88307f7940:  ffffffffffffffff  ffffffffffffffff 
00007f88307f7950:  ffffffffffffffff  ffffffffffffffff 
00007f88307f7960:  ffffffffffffffff  ffffffffffffffff 
00007f88307f7970:  ffffffffffffffff  ffffffffffffffff 

goroutine 30 [syscall]:
runtime.cgocall(0x653f10, 0xc420057898, 0xc4200578a0)
	/usr/lib/go/src/runtime/cgocall.go:128 +0x64 fp=0xc420057868 sp=0xc420057830 pc=0x405824
github.com/tensorflow/tensorflow/tensorflow/go._Cfunc_TF_SetAttrTensor(0x7f8828006320, 0x7f8828007100, 0x7f88280071f0, 0x7f88280085c0)
	_cgo_gotypes.go:1024 +0x45 fp=0xc420057898 sp=0xc420057868 pc=0x523695
github.com/tensorflow/tensorflow/tensorflow/go.setAttr.func18(0x7f8828006320, 0x7f8828007100, 0x7f88280071f0, 0x7f88280085c0)
	/home/pgaleone/projects/go/src/github.com/tensorflow/tensorflow/tensorflow/go/graph.go:313 +0xce fp=0xc4200578d0 sp=0xc420057898 pc=0x52f98e
github.com/tensorflow/tensorflow/tensorflow/go.setAttr(0x7f8828006320, 0xc4200a60b8, 0x6ef1cc, 0x5, 0x6b3f40, 0xc4201284e0, 0x0, 0x0)
	/home/pgaleone/projects/go/src/github.com/tensorflow/tensorflow/tensorflow/go/graph.go:313 +0x1006 fp=0xc420057aa0 sp=0xc4200578d0 pc=0x526226
github.com/tensorflow/tensorflow/tensorflow/go.(*Graph).AddOperation(0xc4200a6080, 0x6ef023, 0x5, 0xc42001a408, 0x6, 0x0, 0x0, 0x0, 0xc420057c98, 0x0, ...)
	/home/pgaleone/projects/go/src/github.com/tensorflow/tensorflow/tensorflow/go/graph.go:216 +0x4fb fp=0xc420057c00 sp=0xc420057aa0 pc=0x52506b
github.com/tensorflow/tensorflow/tensorflow/go.Const(0xc4200a6080, 0xc42001a408, 0x6, 0x67ee40, 0xc420128320, 0xc42001a408, 0x6, 0x7af1f0, 0x7af230)
	/home/pgaleone/projects/go/src/github.com/tensorflow/tensorflow/tensorflow/go/util_test.go:38 +0x271 fp=0xc420057e40 sp=0xc420057c00 pc=0x5201e1
github.com/tensorflow/tensorflow/tensorflow/go.TestOutputDataTypeAndShape.func1(0xc420140780)
	/home/pgaleone/projects/go/src/github.com/tensorflow/tensorflow/tensorflow/go/operation_test.go:137 +0x111 fp=0xc420057fa8 sp=0xc420057e40 pc=0x52cff1
testing.tRunner(0xc420140780, 0xc4201284a0)
	/usr/lib/go/src/testing/testing.go:777 +0xd0 fp=0xc420057fd0 sp=0xc420057fa8 pc=0x4ce610
runtime.goexit()
	/usr/lib/go/src/runtime/asm_amd64.s:2361 +0x1 fp=0xc420057fd8 sp=0xc420057fd0 pc=0x45d311
created by testing.(*T).Run
	/usr/lib/go/src/testing/testing.go:824 +0x2e0

goroutine 1 [chan receive]:
testing.(*T).Run(0xc4201403c0, 0x6f54ea, 0x1a, 0x703348, 0x477f01)
	/usr/lib/go/src/testing/testing.go:825 +0x301
testing.runTests.func1(0xc420140000)
	/usr/lib/go/src/testing/testing.go:1063 +0x64
testing.tRunner(0xc420140000, 0xc42006bdf8)
	/usr/lib/go/src/testing/testing.go:777 +0xd0
testing.runTests(0xc420128220, 0xa4c4c0, 0x12, 0x12, 0x413ef9)
	/usr/lib/go/src/testing/testing.go:1061 +0x2c4
testing.(*M).Run(0xc42013e000, 0x0)
	/usr/lib/go/src/testing/testing.go:978 +0x171
main.main()
	_testmain.go:84 +0x151

goroutine 26 [chan receive]:
testing.(*T).Run(0xc420140780, 0xc4200d22c0, 0x13, 0xc4201284a0, 0x2)
	/usr/lib/go/src/testing/testing.go:825 +0x301
github.com/tensorflow/tensorflow/tensorflow/go.TestOutputDataTypeAndShape(0xc4201403c0)
	/home/pgaleone/projects/go/src/github.com/tensorflow/tensorflow/tensorflow/go/operation_test.go:136 +0x552
testing.tRunner(0xc4201403c0, 0x703348)
	/usr/lib/go/src/testing/testing.go:777 +0xd0
created by testing.(*T).Run
	/usr/lib/go/src/testing/testing.go:824 +0x2e0

rax    0x0
rbx    0x6
rcx    0x7f884c725860
rdx    0x0
rdi    0x2
rsi    0x7f88307f7880
rbp    0x7f88307f7ad0
rsp    0x7f88307f7880
r8     0x0
r9     0x7f88307f7880
r10    0x8
r11    0x246
r12    0x7f88307f7d10
r13    0x5
r14    0x7f8828007100
r15    0x7f88307f7d10
rip    0x7f884c725860
rflags 0x246
cs     0x33
fs     0x0
gs     0x0
exit status 2
FAIL	github.com/tensorflow/tensorflow/tensorflow/go	0.082s
```

**1.7**
```
(cv) [pgaleone@persefone go]$ git checkout r1.7
Switched to branch 'r1.7'
Your branch is up to date with 'origin/r1.7'.
(cv) [pgaleone@persefone go]$ go test
2018-04-07 08:38:02.846973: F tensorflow/core/framework/tensor.cc:822] Unexpected type: 23
SIGABRT: abort
PC=0x7f88599b1860 m=7 sigcode=18446744073709551610

goroutine 0 [idle]:
runtime: unknown pc 0x7f88599b1860
stack: frame={sp:0x7f88417f9880, fp:0x0} stack=[0x7f8840ffa1d0,0x7f88417f9dd0)
00007f88417f9780:  0000000000000000  0000006e0000005b 
00007f88417f9790:  0000000000000000  000000770000007c 
00007f88417f97a0:  000000000000001b  00007f8838000020 
00007f88417f97b0:  0000000000000014  fffffffffffffef8 
00007f88417f97c0:  00007f8838009d4d  0000000000000003 
00007f88417f97d0:  00007f8838008460  00007f88599ff47a 
00007f88417f97e0:  00007f8838006dd0  00007f8838006de1 
00007f88417f97f0:  000000000000000d  00007f8859a30dc2 
00007f88417f9800:  00007f8859d2f350  0000000000000001 
00007f88417f9810:  0000000000000000  00000000000000ac 
00007f88417f9820:  00007f8859d2f350  00007f8859a31e29 
00007f88417f9830:  0000000000000001  ffffffff00000008 
00007f88417f9840:  01000000004d2166  0000000000000011 
00007f88417f9850:  0000000000000008  0000000000000008 
00007f88417f9860:  00000000000006b8  00000000000006b8 
00007f88417f9870:  00007f88417f9900  0000000000000000 
00007f88417f9880: <0000000000000000  0000000000000000 
00007f88417f9890:  0800000000000000  0000000008000000 
00007f88417f98a0:  08000000ae000000  0000000011000000 
00007f88417f98b0:  0000000000000802  000000000076074b 
00007f88417f98c0:  0000000000000003  6b320cc32e502500 
00007f88417f98d0:  0000000000000000  00007f88417f9ae0 
00007f88417f98e0:  00007f88417f9a50  00007f88417f9a70 
00007f88417f98f0:  00000000000cec7d  00007f88417f9a20 
00007f88417f9900:  fffffffe7fffffff  ffffffffffffffff 
00007f88417f9910:  ffffffffffffffff  ffffffffffffffff 
00007f88417f9920:  ffffffffffffffff  ffffffffffffffff 
00007f88417f9930:  ffffffffffffffff  ffffffffffffffff 
00007f88417f9940:  ffffffffffffffff  ffffffffffffffff 
00007f88417f9950:  ffffffffffffffff  ffffffffffffffff 
00007f88417f9960:  ffffffffffffffff  ffffffffffffffff 
00007f88417f9970:  ffffffffffffffff  ffffffffffffffff 
runtime: unknown pc 0x7f88599b1860
stack: frame={sp:0x7f88417f9880, fp:0x0} stack=[0x7f8840ffa1d0,0x7f88417f9dd0)
00007f88417f9780:  0000000000000000  0000006e0000005b 
00007f88417f9790:  0000000000000000  000000770000007c 
00007f88417f97a0:  000000000000001b  00007f8838000020 
00007f88417f97b0:  0000000000000014  fffffffffffffef8 
00007f88417f97c0:  00007f8838009d4d  0000000000000003 
00007f88417f97d0:  00007f8838008460  00007f88599ff47a 
00007f88417f97e0:  00007f8838006dd0  00007f8838006de1 
00007f88417f97f0:  000000000000000d  00007f8859a30dc2 
00007f88417f9800:  00007f8859d2f350  0000000000000001 
00007f88417f9810:  0000000000000000  00000000000000ac 
00007f88417f9820:  00007f8859d2f350  00007f8859a31e29 
00007f88417f9830:  0000000000000001  ffffffff00000008 
00007f88417f9840:  01000000004d2166  0000000000000011 
00007f88417f9850:  0000000000000008  0000000000000008 
00007f88417f9860:  00000000000006b8  00000000000006b8 
00007f88417f9870:  00007f88417f9900  0000000000000000 
00007f88417f9880: <0000000000000000  0000000000000000 
00007f88417f9890:  0800000000000000  0000000008000000 
00007f88417f98a0:  08000000ae000000  0000000011000000 
00007f88417f98b0:  0000000000000802  000000000076074b 
00007f88417f98c0:  0000000000000003  6b320cc32e502500 
00007f88417f98d0:  0000000000000000  00007f88417f9ae0 
00007f88417f98e0:  00007f88417f9a50  00007f88417f9a70 
00007f88417f98f0:  00000000000cec7d  00007f88417f9a20 
00007f88417f9900:  fffffffe7fffffff  ffffffffffffffff 
00007f88417f9910:  ffffffffffffffff  ffffffffffffffff 
00007f88417f9920:  ffffffffffffffff  ffffffffffffffff 
00007f88417f9930:  ffffffffffffffff  ffffffffffffffff 
00007f88417f9940:  ffffffffffffffff  ffffffffffffffff 
00007f88417f9950:  ffffffffffffffff  ffffffffffffffff 
00007f88417f9960:  ffffffffffffffff  ffffffffffffffff 
00007f88417f9970:  ffffffffffffffff  ffffffffffffffff 

goroutine 24 [syscall]:
runtime.cgocall(0x653f10, 0xc42005b898, 0xc42005b8a0)
	/usr/lib/go/src/runtime/cgocall.go:128 +0x64 fp=0xc42005b868 sp=0xc42005b830 pc=0x405824
github.com/tensorflow/tensorflow/tensorflow/go._Cfunc_TF_SetAttrTensor(0x7f8838005ed0, 0x7f8838006cb0, 0x7f8838006da0, 0x7f8838008170)
	_cgo_gotypes.go:1024 +0x45 fp=0xc42005b898 sp=0xc42005b868 pc=0x523695
github.com/tensorflow/tensorflow/tensorflow/go.setAttr.func18(0x7f8838005ed0, 0x7f8838006cb0, 0x7f8838006da0, 0x7f8838008170)
	/home/pgaleone/projects/go/src/github.com/tensorflow/tensorflow/tensorflow/go/graph.go:313 +0xce fp=0xc42005b8d0 sp=0xc42005b898 pc=0x52f98e
github.com/tensorflow/tensorflow/tensorflow/go.setAttr(0x7f8838005ed0, 0xc42000e0c0, 0x6ef1cc, 0x5, 0x6b3f40, 0xc420104500, 0x0, 0x0)
	/home/pgaleone/projects/go/src/github.com/tensorflow/tensorflow/tensorflow/go/graph.go:313 +0x1006 fp=0xc42005baa0 sp=0xc42005b8d0 pc=0x526226
github.com/tensorflow/tensorflow/tensorflow/go.(*Graph).AddOperation(0xc42000e080, 0x6ef023, 0x5, 0xc42001a808, 0x6, 0x0, 0x0, 0x0, 0xc42005bc98, 0x0, ...)
	/home/pgaleone/projects/go/src/github.com/tensorflow/tensorflow/tensorflow/go/graph.go:216 +0x4fb fp=0xc42005bc00 sp=0xc42005baa0 pc=0x52506b
github.com/tensorflow/tensorflow/tensorflow/go.Const(0xc42000e080, 0xc42001a808, 0x6, 0x67ee40, 0xc420104340, 0xc42001a808, 0x6, 0x7af1f0, 0x7af230)
	/home/pgaleone/projects/go/src/github.com/tensorflow/tensorflow/tensorflow/go/util_test.go:38 +0x271 fp=0xc42005be40 sp=0xc42005bc00 pc=0x5201e1
github.com/tensorflow/tensorflow/tensorflow/go.TestOutputDataTypeAndShape.func1(0xc42011a780)
	/home/pgaleone/projects/go/src/github.com/tensorflow/tensorflow/tensorflow/go/operation_test.go:137 +0x111 fp=0xc42005bfa8 sp=0xc42005be40 pc=0x52cff1
testing.tRunner(0xc42011a780, 0xc4201044c0)
	/usr/lib/go/src/testing/testing.go:777 +0xd0 fp=0xc42005bfd0 sp=0xc42005bfa8 pc=0x4ce610
runtime.goexit()
	/usr/lib/go/src/runtime/asm_amd64.s:2361 +0x1 fp=0xc42005bfd8 sp=0xc42005bfd0 pc=0x45d311
created by testing.(*T).Run
	/usr/lib/go/src/testing/testing.go:824 +0x2e0

goroutine 1 [chan receive]:
testing.(*T).Run(0xc42011a3c0, 0x6f54ea, 0x1a, 0x703348, 0x477f01)
	/usr/lib/go/src/testing/testing.go:825 +0x301
testing.runTests.func1(0xc42011a000)
	/usr/lib/go/src/testing/testing.go:1063 +0x64
testing.tRunner(0xc42011a000, 0xc42006bdf8)
	/usr/lib/go/src/testing/testing.go:777 +0xd0
testing.runTests(0xc420104260, 0xa4c4c0, 0x12, 0x12, 0x413ef9)
	/usr/lib/go/src/testing/testing.go:1061 +0x2c4
testing.(*M).Run(0xc420118000, 0x0)
	/usr/lib/go/src/testing/testing.go:978 +0x171
main.main()
	_testmain.go:84 +0x151

goroutine 20 [chan receive]:
testing.(*T).Run(0xc42011a780, 0xc420018420, 0x13, 0xc4201044c0, 0x2)
	/usr/lib/go/src/testing/testing.go:825 +0x301
github.com/tensorflow/tensorflow/tensorflow/go.TestOutputDataTypeAndShape(0xc42011a3c0)
	/home/pgaleone/projects/go/src/github.com/tensorflow/tensorflow/tensorflow/go/operation_test.go:136 +0x552
testing.tRunner(0xc42011a3c0, 0x703348)
	/usr/lib/go/src/testing/testing.go:777 +0xd0
created by testing.(*T).Run
	/usr/lib/go/src/testing/testing.go:824 +0x2e0

rax    0x0
rbx    0x6
rcx    0x7f88599b1860
rdx    0x0
rdi    0x2
rsi    0x7f88417f9880
rbp    0x7f88417f9ad0
rsp    0x7f88417f9880
r8     0x0
r9     0x7f88417f9880
r10    0x8
r11    0x246
r12    0x7f88417f9d10
r13    0x5
r14    0x7f8838006cb0
r15    0x7f88417f9d10
rip    0x7f88599b1860
rflags 0x246
cs     0x33
fs     0x0
gs     0x0
exit status 2
FAIL	github.com/tensorflow/tensorflow/tensorflow/go	0.073s
```"
18304,tf.enable_eager_execution must be called at program startup.,"```
from __future__ import absolute_import, division, print_function
import os
import matplotlib.pyplot as plt

import tensorflow as tf
print(tf.VERSION)   #  => 1.7.0
import tensorflow.contrib.eager as tfe

tf.enable_eager_execution()
```

```
ValueError                                Traceback (most recent call last)
<ipython-input-59-0c62cac7517d> in <module>()
      7 import tensorflow.contrib.eager as tfe
      8 
----> 9 tf.enable_eager_execution()

D:\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\framework\ops.py in enable_eager_execution(config, device_policy)
   5242     if graph_mode_has_been_used:
   5243       raise ValueError(
-> 5244           ""tf.enable_eager_execution must be called at program startup."")
   5245   context._default_mode = context.EAGER_MODE
   5246   if context._context is None:

ValueError: tf.enable_eager_execution must be called at program startup.
```"
18302,Add sparse tensor support to Dataset.padded_batch(),"@jsimsa Please help :) Thx

Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.7.0
- **Python version**:  3.5.2
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: 9.0/7.0.3.11
- **GPU model and memory**: TitanX 12Gb
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
```
Traceback (most recent call last):
  File ""trainer.py"", line 70, in <module>
    main(ARGS)
  File ""trainer.py"", line 20, in main
    train(source, meta, args.destination)
  File ""trainer.py"", line 49, in train
    dataset = dataset.padded_batch(batch_size, padded_shapes=(0, None, 0, None))
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/dataset_ops.py"", line 821, in padded_batch
    return PaddedBatchDataset(self, batch_size, padded_shapes, padding_values)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/dataset_ops.py"", line 1713, in __init__
    ""Batching of padded sparse tensors is not currently supported"")
TypeError: Batching of padded sparse tensors is not currently supported
```
### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
```python
from argparse import ArgumentParser
import pickle

import tensorflow as tf

def main(args):

    # Generate the complete source and meta paths.
    source = args.source
    if not source.endswith('.tfrecords'):
        source = '{}.tfrecords'.format(source)

    meta = args.source
    if not source.endswith('.tfrecords'):
        meta = '{}.meta.pkl'.format(meta)
    else:
        meta = '{}.meta.pkl'.format(meta.rsplit('.', 1)[0])
    
    # Train the model.
    train(source, meta, args.destination)

def parse(example_proto):

    features = {
        'bucket': tf.FixedLenFeature([], tf.int64),
        'coefficients': tf.FixedLenFeature([], tf.string),
        'coefficients_length': tf.FixedLenFeature([], tf.int64),
        'label': tf.VarLenFeature(tf.int64)
    }
    parsed_features = tf.parse_single_example(example_proto, features)

    bucket = tf.cast(parsed_features['bucket'], tf.int32)
    coefficients = tf.decode_raw(parsed_features['coefficients'], tf.float32)
    coefficients_length = tf.cast(parsed_features['coefficients_length'], tf.int32)
    label = tf.cast(parsed_features['label'], tf.int32)

    return bucket, coefficients, coefficients_length, label

def train(source, meta, destination, batch_size=64, epochs=1):

    # Load the training meta data.
    file = open(meta, 'rb')
    meta = pickle.load(file)
    file.close()

    # Create a tf.data input pipe line.
    dataset = tf.data.TFRecordDataset([source])
    dataset = dataset.map(parse)
    dataset = dataset.padded_batch(batch_size, padded_shapes=([], [None], [], [None]))
    dataset = dataset.repeat(epochs) 
    iterator = dataset.make_initializable_iterator()

    bucket, coefficients, coefficients_length, label = iterator.get_next()

    with tf.Session() as session:
        
        session.run(iterator.initializer)
        
        print(session.run([bucket, coefficients, coefficients_length, label]))

if __name__ == '__main__':
    
    PARSER = ArgumentParser(description='Trains a model.')
    PARSER.add_argument('--destination', required=True, type=str,
    					help='The path where the trained model should be stored.')
    PARSER.add_argument('--source', required=True, type=str,
    					help='The path to the training data.')
    ARGS = PARSER.parse_args()

    main(ARGS)

```"
18301,tf.data.TFRecordDataset does not properly infer shape,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.7.0
- **Python version**: 3.5.2
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: 9.0/7.0.3.11
- **GPU model and memory**: TitanX 12Gb
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
```
Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/dataset_ops.py"", line 1659, in _partial_shape_to_tensor
    [dim if dim is not None else -1 for dim in shape_like.as_list()],
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_shape.py"", line 820, in as_list
    raise ValueError(""as_list() is not defined on an unknown TensorShape."")
ValueError: as_list() is not defined on an unknown TensorShape.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""trainer.py"", line 70, in <module>
    main(ARGS)
  File ""trainer.py"", line 20, in main
    train(source, meta, args.destination)
  File ""trainer.py"", line 49, in train
    dataset = dataset.padded_batch(batch_size, padded_shapes=(0, None, 0, None))
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/dataset_ops.py"", line 821, in padded_batch
    return PaddedBatchDataset(self, batch_size, padded_shapes, padding_values)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/dataset_ops.py"", line 1721, in __init__
    input_dataset.output_shapes, _partial_shape_to_tensor, padded_shapes)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/data/util/nest.py"", line 538, in map_structure_up_to
    results = [func(*tensors) for tensors in zip(*all_flattened_up_to)]
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/data/util/nest.py"", line 538, in <listcomp>
    results = [func(*tensors) for tensors in zip(*all_flattened_up_to)]
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/dataset_ops.py"", line 1665, in _partial_shape_to_tensor
    return ops.convert_to_tensor(shape_like, dtype=dtypes.int64)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py"", line 950, in convert_to_tensor
    as_ref=False)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py"", line 1040, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/constant_op.py"", line 256, in _tensor_shape_tensor_conversion_function
    ""Cannot convert a partially known TensorShape to a Tensor: %s"" % s)
ValueError: Cannot convert a partially known TensorShape to a Tensor: <unknown>
```
### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

```python
from argparse import ArgumentParser
import pickle

import tensorflow as tf

def main(args):

    # Generate the complete source and meta paths.
    source = args.source
    if not source.endswith('.tfrecords'):
        source = '{}.tfrecords'.format(source)

    meta = args.source
    if not source.endswith('.tfrecords'):
        meta = '{}.meta.pkl'.format(meta)
    else:
        meta = '{}.meta.pkl'.format(meta.rsplit('.', 1)[0])
    
    # Train the model.
    train(source, meta, args.destination)

def parse(example_proto):

    features = {
        'bucket': tf.FixedLenFeature([], tf.int64),
        'coefficients': tf.FixedLenFeature([], tf.string),
        'coefficients_length': tf.FixedLenFeature([], tf.int64),
        'label': tf.FixedLenFeature([], tf.int64)
    }
    parsed_features = tf.parse_single_example(example_proto, features)

    bucket = tf.cast(parsed_features['bucket'], tf.int32)
    coefficients = tf.decode_raw(parsed_features['coefficients'], tf.float32)
    coefficients_length = tf.cast(parsed_features['coefficients_length'], tf.int32)
    label = tf.cast(parsed_features['label'], tf.int32)

    return bucket, coefficients, coefficients_length, label

def train(source, meta, destination, batch_size=64, epochs=1):

    # Load the training meta data.
    file = open(meta, 'rb')
    meta = pickle.load(file)
    file.close()

    # Create a tf.data input pipe line.
    dataset = tf.data.TFRecordDataset([source])
    dataset = dataset.map(parse)
    dataset = dataset.padded_batch(batch_size, padded_shapes=(0, None, 0, None))
    dataset = dataset.repeat(epochs) 
    iterator = dataset.make_initializable_iterator()

    bucket, coefficients, coefficients_length, label = iterator.get_next()

    with tf.Session() as session:
        
        session.run(iterator.initializer)
        
        print(session.run([bucket, coefficients, coefficients_length, label]))

if __name__ == '__main__':
    
    PARSER = ArgumentParser(description='Trains a model.')
    PARSER.add_argument('--destination', required=True, type=str,
    					help='The path where the trained model should be stored.')
    PARSER.add_argument('--source', required=True, type=str,
    					help='The path to the training data.')
    ARGS = PARSER.parse_args()

    main(ARGS)
```
"
18300,Thread limits are not respected in latest tf-nightly build.,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes. My minimal example is as follows:
```
import tensorflow as tf

config = tf.ConfigProto(
    inter_op_parallelism_threads=1,
    intra_op_parallelism_threads=1,
)

with tf.Session(config=config) as sess:
  a = tf.random_uniform((25000, 25000))

  a_sq = tf.matmul(a, a)
  a_sq.eval()
```
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Goobuntu desktop.
- **TensorFlow installed from (source or binary)**:
tf-nightly (see below)
- **Python version**: 
3.5.3

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

When I run the minimal example provided above with tf-nightly==1.8.0.dev20180404, everything works correctly. It saturates one CPU core and leaves the rest unused. However, when run with tf-nightly==1.8.0.dev20180405 TensorFlow consumes all 8 cores.
"
18297,Tensorflow-gpu performance drop,"### System information
- **Have I written custom code**: No
- **OS Platform and Distribution**: Windows 10 64-bit 
- **TensorFlow installed from**: binary
- **TensorFlow version**: 1.6.0
- **Python version**: 3.6.3
- **CUDA/cuDNN version**: 9.0
- **GPU model and memory**: GeForce GTX 780, 3Gb

Using Keras in Python with tensorflow-gpu backend. Worked fine for weeks until a few days ago, when I have suffered a huge performance drop.

When Tensorflow is initialising, it all appears to work correctly and finds my GPU as normal. Output:

    2018-04-05 02:08:32.791893: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1212] Found device 0 with properties: 
    name: GeForce GTX 780 major: 3 minor: 5 memoryClockRate(GHz): 1.0195
    pciBusID: 0000:01:00.0
    totalMemory: 3.00GiB freeMemory: 2.46GiB
    2018-04-05 02:08:32.792360: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
    2018-04-05 02:08:33.132555: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2187 MB memory) -> physical GPU (device: 0, name: GeForce GTX 780, pci bus id: 0000:01:00.0, compute capability: 3.5)

But whereas before with exactly the same model on the same data, each epoch took about 2-3 seconds, they now take ~17 seconds.

I had a look in Task Manager, and my IDE shows to be using GPU Engine - ""GPU 0 - Copy"". Also at the beginning of each epoch, the GPU will go under ~70% load for about a second, but then the load switches over to my CPU and Memory for the remaining 15 seconds or so and the GPU goes back down to its idle load around 2%."
18296,Building Tensorflow on Windows,"At https://www.tensorflow.org/install/install_sources, you say:

""We do not support building TensorFlow on Windows.""

Why not? Are there any plans to support this in future? I know it is technically possible to build with CMake, but official support would be nice. At the moment, I am trying to use a trained model for inference as part of a C++ application. I am constrained to Windows, and getting a trained model into the app is much more difficult than it needs to be. Surely there are many people out there also using Windows?

Thanks!"
18294,Issue using/importing unsorted_segment_mean,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Win 10
- **TensorFlow installed from (source or binary)**: pip install ( and reinstalled after the first errors)
- **TensorFlow version (use command below)**: 1.7
- **Python version**: 3.5.4
- **Bazel version (if compiling from source)**:N/A
- **GCC/Compiler version (if compiling from source)**:N/A
- **CUDA/cuDNN version**:N/A
- **GPU model and memory**:N/A
- **Exact command to reproduce**: test = tensorflow.unsorted_segment_mean

### Describe the problem

I cannot import the or use the function unsorted_segment_mean despite it being present in python/ops/math_ops and exported with tf_export, but I am able to use unsorted_segment_sum.
My IDE shows me the function but when trying to call it I get AttributeError.
I have tried to import it directly using
import tensorflow.unsorted_segment_mean
And this failed too.
I have tried to import permutations of the path (ops, math_ops, ops.math_ops, etc) to try to access is directly and I got error that tensorflow did not have those modules (despite my IDE stating the opposite). And I could not access it that way either.

### Source code / logs
Code
```python
import tensorflow as tf
try:
    test=tf.unsorted_segment_mean
except:
    from tensorflow import unsorted_segment_mean
    test=unsorted_segment_mean()
```
Error:
`
Traceback (most recent call last):
  File ""[redacted]"", line 25, in <module>
    test=tf.unsorted_segment_mean
AttributeError: module 'tensorflow' has no attribute 'unsorted_segment_mean'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""[redacted]"", line 27, in <module>
    from tensorflow import unsorted_segment_mean
ImportError: cannot import name 'unsorted_segment_mean'
`"
18292,Memory leak with py_func,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes (see below)
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.7.0
- **Python version**: 3.6.4 64bit
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: 9.0
- **GPU model and memory**: GeForce 1080 Ti
- **Exact command to reproduce**: (see below)

### Issue
`py_func` which has a python function referencing the graph (might be an unobvious reference, see below) results in the graph never being garbage collected. If you know about this issue usually it can be worked around, but in general it's a pitfall which should be fixed in the code (see below for suggestion).

### Source Code Example

The following source code produces the leak. If you comment out `py_func.graph = graph` you will see that ""Deleted MyPyFunc"" will be printed.
```py
import gc
import tensorflow as tf


class MyPyFunc:
    def __init__(self):
        self.graph = None

    def __call__(self, inputs):
        return inputs

    def __del__(self):
        print(""Deleted MyPyFunc"")


def run_graph():
    graph = tf.Graph()
    with graph.as_default():
        inputs = tf.constant(0)
        py_func = MyPyFunc()
        op = tf.py_func(py_func, [inputs], [inputs.dtype])
        # Comment this out to fix the leak
        py_func.graph = graph

    with tf.Session(graph=graph) as sess:
        print(""Result:"", sess.run(op))


run_graph()
gc.collect()
run_graph()
gc.collect()
```

### Analysis
The issue originates from [script_ops.py:181](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/script_ops.py#L181). Here, all `py_func`s get registered globally, i.e. these will only be deleted when [`CleanupFunc`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/script_ops.py#L186) is garbage collected. It is instantiated at [script_ops.py:222](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/script_ops.py#L222) and stored in the graph when `py_func` is called. The idea is, that the `CleanupFunc.__del__` method is called when the graph is garbage collected, which in turn will delete the reference to the python function, so it can get garbage collected as well.

In the example, `MyPyFunc` contains a reference to the graph. By calling `py_func` the reference to `MyPyFunc` is stored globally in `_py_funcs = FuncRegistry()`. That means the graph is referenced globally, so it will never get garbage collected, which in turn means that the `CleanupFunc.__del__` will never be called, so `MyPyFunc` will never be deleted from `_py_funcs`.

### Importance
Consider the following:
```py
class MyOp:
    def __init__(self, inputs):
        self.op = tf.py_func(self._py_func, [inputs], [inputs.dtype])

    def _py_func(self, inputs):
        return inputs
```
This looks like valid code, but having `MyOp.op` in your graph will make the graph leak. The problem lies in the fact that `_py_func` has is bound to the `MyOp` instance which contains a reference to a TensorFlow op which in turn has a reference to the graph (for the remaining inference see above). This is a big issue, because `tf.estimator.train_and_evaluate` creates a lot of graphs during training (i.e. when it switches between training and evaluation a new graph is created).

### Suggestion
Instead of globally storing references to the functions and keys to them, they might be better stored in the graph directly. This also prevents them from being deleted while the graph exists. Thus they are only cyclic references in the graph and can be garbage collected with the graph. Instead of storing
[`graph._cleanup_py_funcs_used_in_graph.append(cleanup)`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/script_ops.py#L232), the function should be stored directly like `graph._py_funcs_used_in_graph.append(func)`."
18291,data_generator,"  import data_generators
ModuleNotFoundError: No module named 'data_generators'"
18290,Tensorflow reimplementation performs significantly worse than original POC,"### Intro
I have asked this question several times on stackoverflow using different wording and level of details yet didn't get a single answer. Given the nature of the problem it is understandable, you cannot debug the network without training data and code. Still, maybe there is something obvious that I am missing here. We are trying to rewrite successful Torch POC binary classifier using Tensorflow to put it into production.

### Torch POC
Torch model is a sequential binary classifier that works on word sequences and attempts to predict if the current word belongs to class 1 or 0. The model is quite simple, we have embedding layer and a special feature layer which we sum together before feeding the result vector into LSTM / GRU cell. At the output we do linear transform with sigmoid, compute binary cross entropy loss and update our parameters. Depending on the vocabulary size the model consists of 700k - 1000k params. 

### Tensorflow reimplementation
We have been using standard Tensorflow language model trainable on Penn Treebank dataset as our code base. We have adapted it to the point where it looks identical to our Torch POC (same hyperparams and equal number of parameters) and started training. 

### Problem
It quickly became clear that Tensorflow reimplemetation does not learn anything even though the loss drops and test dataset shows error decrease: `Test loss reduced: 97690.06433105469 --> 9929.968887329102`. Loading the trained model and quering it with words showed that the model predictions are garbage. Besides the loss values are different for Torch and Tensorflow. 

### Tensorflow implementation (main part):
```python
#################### PLACEHOLDERS ####################
# We use placeholders for the word, feature inputs and corresponding targets
self.words_input = tf.placeholder(tf.int32, [config.batch_size, config.seq_length])
self.feats_input = tf.placeholder(tf.float32, [config.batch_size, config.seq_length, config.nfeats])
self.targets_input = tf.placeholder(tf.float32, [config.batch_size, config.seq_length])

#################### VARIABLES ####################
# We use variables for trainable network params like word embeddings, weights and biases
# select params initialization
if self.init_method == ""xavier"":
    self.initer = tf.contrib.layers.xavier_initializer(uniform=False)

elif self.init_method == ""uniform"":
    self.initer = tf.random_uniform_initializer(-config.init_scale, config.init_scale)

elif self.init_method == ""normal"":
    self.initer = tf.random_normal_initializer()

else:
    self.initer = tf.zeros_initializer()

# word embeddings
with tf.variable_scope(""input_layer""):
    self.embedding = tf.get_variable(""embedding"", [self.vocab_size, self.input_size],
                                     initializer=self.initer, trainable=True)
    # feature weights for linear transform
    self.feature_weight = tf.get_variable(""feature_weigths"", [config.nfeats, config.input_size],
                                          initializer=self.initer, trainable=True)
    # feature biases for linear transform
    self.feature_bias = tf.get_variable(""feature_bias"", [config.input_size],
                                        initializer=self.initer, trainable=True)

# weights and biases of output layer (follows hidden layer(s))
with tf.variable_scope(""output_layer""):
    # this is where we define out linear + sigmoid sizes [hidden_size x 1 or several classes]
    self.output_w = tf.get_variable(""output_w"", [self.last_layer_size, self.pay_type],
                                    initializer=self.initer, trainable=True)

    self.output_b = tf.get_variable(""output_b"", [self.pay_type], initializer=self.initer,
                                    trainable=True)


#################### GRAPH ####################
# create embedding lookup table with embedding variable and word inputs placeholder
word_embeddings = tf.nn.embedding_lookup(self.embedding, self.words_input)  # [32 x 25 x 100]

# create feature linear transform layer with feature inputs placeholder
# first we need to swap tensor dims from [0, 1, 2] --> [1, 0, 2] to make seq_length first
_feats_trans = tf.transpose(self.feats_input, [1, 0, 2])  # [25 x 32 x 4]

# apply linear transform without activation in order
# to expand feature vectors [batch_size x nfeats] -> [batch_size x input_size]
# this is needed to sum them with word embeddings before recurrent layer
#_feats_exp = tf.map_fn(self._linear, _feats_trans, dtype=tf.float32, back_prop=True)  # [25 x 32 x 100]
_feats_exp = [tf.nn.xw_plus_b(s, self.feature_weight, self.feature_bias)
              for s in tf.unstack(_feats_trans, axis=0)]

# now stack the list of tensors and transpose back to [batch_size x seq_length x input_size]
feats_exp = tf.transpose(tf.stack(_feats_exp, axis=0), [1, 0, 2])  # [32 x 25 x 100]

# sum the outputs of the embedding and linear ops
inputs_sum = tf.add(word_embeddings, feats_exp)  # [32 x 25 x 100]

# apply dropout here if needed
#if self.training and self.input_keep_prob < 1:
#    inputs_sum = tf.nn.dropout(inputs_sum, self.input_keep_prob)

# split the input matrices vertically into separate tensors
_inputs_spl = tf.split(inputs_sum, config.seq_length, axis=1)
# remove single tensor dimensions
inputs = [tf.squeeze(split, [1]) for split in _inputs_spl]  # [25 * [32 x 100]]

# build recurrent cells
self.cell = self._create_recurrent_cell(config)

# initialize the hidden (recurrent) state to zero
self.initial_state = self.cell.zero_state(config.batch_size, tf.float32)

# create recurrent network using rnn cell and return outputs and final state
_outputs, self.final_state = self._apply_rec_cell(inputs, self.initial_state, self.cell, config)  # [800 x 200]

# apply dropout here if needed
if self.training and self.input_keep_prob < 1:
    cell_output = tf.nn.dropout(_outputs, self.input_keep_prob)

# the hidden layer output is fed into matmul(x, weights) + biases function
logits = tf.nn.xw_plus_b(cell_output, self.output_w, self.output_b)  # [800 x 1]

# transform logits into [seq_length x batch_size x 1]
_logits = tf.reshape(logits, [config.seq_length, config.batch_size, config.pay_type])  # [25 x 32 x 1]

self.logits = _logits

# add single dim to target tensor [32 x 25] --> [32 x 25 x 1]
_targets = tf.expand_dims(self.targets_input, axis=2)
# transform targets tensor [32 x 25 x 1] --> [25 x 32 x 1] for loss computation
_targets = tf.transpose(_targets, [1, 0, 2])

#################### LOSS CALCULATION ####################
# unstack logits and targets along seq_length dimension
_logits_uns = tf.unstack(_logits, axis=0)
_targets_uns = tf.unstack(_targets, axis=0)

# apply loss function to each sequence and compute individual losses
loss_fn = tf.losses.sigmoid_cross_entropy
#loss_fn = tf.nn.sigmoid_cross_entropy_with_logits
individual_losses = []

for t, o in zip(_targets_uns, _logits_uns):  # [32 x 1], [32 x 1]
    _loss = loss_fn(t, o, weights=1.0, label_smoothing=0, scope=""sigmoid_cross_entropy"",
                    loss_collection=tf.GraphKeys.LOSSES, reduction=tf.losses.Reduction.NONE)
    #_loss = loss_fn(labels=t, logits=o, name=""sigmoid_cross_entropy"")
    individual_losses.append(_loss)

# calculate the loss sum of individual losses
with tf.name_scope('loss'):
    self.loss = tf.reduce_sum(individual_losses)

#################### TRAINING ####################
if self.training:
    self.lr = tf.Variable(0.0, trainable=False)
    tvars = tf.trainable_variables()

    # print model shapes and total params
    print(""MODEL params:"")
    for t in tvars:
        print(t.shape)
    print(""TOTAL params:"", np.sum([np.prod(t.shape) for t in tvars]))

    # clip the gradient by norm
    if config.grad_clip > 0:
        grads, _ = tf.clip_by_global_norm(tf.gradients(self.loss, tvars), config.grad_clip)
    else:
        grads = tf.gradients(self.loss, tvars)

    # update variables (weights, biases, embeddings...)
    with tf.name_scope(""optimizer""):
        optimizer = tf.train.AdamOptimizer(self.lr)
        #optimizer = tf.train.GradientDescentOptimizer(self.lr)
        # compute grads/vars for tensorboard
        self.grads_and_vars = optimizer.compute_gradients(self.loss)

        self.train_op = optimizer.apply_gradients(zip(grads, tvars),          global_step=tf.train.get_or_create_global_step())
```
### Recurrent cell creation
```python
    def _create_recurrent_cell(self, config):
        """"""
        Define and return recurrent cell.
        """"""
            cell = rnn.GRUCell(self.hidden_size,
                                           kernel_initializer=self.initer,
                                           bias_initializer=self.initer,
                                           activation=tf.nn.tanh)

            # apply dropout if required
            if self.training and self.output_keep_prob < 1.0:
                cell = rnn.DropoutWrapper(cell, output_keep_prob=self.output_keep_prob)

        # we might use several rnn cells in future
        return rnn.MultiRNNCell(cell, state_is_tuple=True)
```

### Recurrent cell application
```python
    def _apply_rec_cell(self, inputs, initial_state, cell, config):
        """"""
        Apply recurrence cell to each input sequence.
        """"""

        with variable_scope.variable_scope(""recurrent_cell""):
            state = initial_state
            _outputs = []
            for i, inp in enumerate(inputs):  # 25 * [32 x 100]
                if i > 0:
                    variable_scope.get_variable_scope().reuse_variables()
                output, state = cell(inp, state)  # [32 x 200]
                _outputs.append(output)

        # concat the outputs and reshape them into 2D tensor (for xw_plus_b)
        outputs = tf.reshape(tf.concat(_outputs, 1), [-1, self.recurrent_state_size]) 
        return outputs, state
```

### Torch POC training analysis
We first take a look at our Torch model and see how it trains during first 10 epochs. We use batch_size=32, seq_length=25, word embedding and feature vectors of size 100 and GRU cell size = 200.

```
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> output]
  (1): nn.ParallelTable {
    input
      |`-> (1): nn.Sequential {
      |      [input -> (1) -> (2) -> output]
      |      (1): nn.LookupTable
      |      (2): nn.SplitTable
      |    }
       `-> (2): nn.Sequential {
             [input -> (1) -> (2) -> output]
             (1): nn.SplitTable
             (2): nn.MapTable {
               nn.Linear(4 -> 100)
             }
           }
       ... -> output
  }
  (2): nn.ZipTable
  (3): nn.MapTable {
    nn.CAddTable
  }
  (4): nn.Sequencer @ nn.Recursor @ nn.Sequential {
    [input -> (1) -> (2) -> (3) -> (4) -> output]
    (1): nn.RecGRU(100 -> 200)
    (2): nn.Dropout(0.5, busy)
    (3): nn.Linear(200 -> 1)
    (4): nn.Sigmoid
  }
}

Epoch #1	
training...	
8.5397211080362e-08	embeddings grads	
0.020771607756615	feature weights grads	
0.00044380914187059	feature bias grads	
8.6396757978946e-06	gru grads	
5.7720841141418e-05	gru bias grads	
0.022520124912262	output_w grads	
0.32349386811256	output_b grads	
learning rate:	0.0497500005	
Elapsed time: 3.190759	
Speed: 0.000019 sec/batch	
Training ERR: 959.54436812177	
validating...	
Validation ERR: 121.4889880009	
check early-stopping...	
Found new minima. Saving 
Last best epoch: 1, ERR: 121.488988	
	
Epoch #2	
training...	
5.9534809082606e-08	embeddings grads	
0.010755381546915	feature weights grads	
0.00030940235592425	feature bias grads	
2.632729774632e-05	gru grads	
8.1771839177236e-05	gru bias grads	
0.044476393610239	output_w grads	
0.37297031283379	output_b grads	
learning rate:	0.049500001	
Elapsed time: 2.988541	
Speed: 0.000018 sec/batch	
Training ERR: 862.21877676807	
validating...	
Validation ERR: 115.8837774843	
check early-stopping...	
Found new minima. Saving
Last best epoch: 2, ERR: 115.883777	
	
Epoch #3	
training...	
1.9829073494293e-08	embeddings grads	
0.0085931243374944	feature weights grads	
0.00010305171599612	feature bias grads	
-2.4194558136514e-05	gru grads	
-4.8788820095069e-06	gru bias grads	
0.0073388875462115	output_w grads	
0.40312686562538	output_b grads	
learning rate:	0.0492500015	
Elapsed time: 2.969960	
Speed: 0.000018 sec/batch	
Training ERR: 820.93807517737	
validating...	
Validation ERR: 110.50921051018	
check early-stopping...	
Found new minima. Saving 
Last best epoch: 3, ERR: 110.509211	
	
Epoch #4	
training...	
-7.4974275676709e-09	embeddings grads	
0.0028696460649371	feature weights grads	
-3.8964077248238e-05	feature bias grads	
-3.4580276405904e-05	gru grads	
-3.2265303161694e-05	gru bias grads	
0.049573861062527	output_w grads	
0.4097863137722	output_b grads	
learning rate:	0.049000002	
Elapsed time: 3.005452	
Speed: 0.000018 sec/batch	
Training ERR: 783.27910768799	
validating...	
Validation ERR: 107.62939401716	
check early-stopping...	
Found new minima. Saving
Last best epoch: 4, ERR: 107.629394	
	
Epoch #5	
training...	
-3.623286559673e-08	embeddings grads	
-0.01051034592092	feature weights grads	
-0.00018830213230103	feature bias grads	
4.4970302042202e-06	gru grads	
3.8041966035962e-05	gru bias grads	
0.0042808093130589	output_w grads	
0.13134820759296	output_b grads	
learning rate:	0.0487500025	
Elapsed time: 2.966464	
Speed: 0.000018 sec/batch	
Training ERR: 753.93339692801	
validating...	
Validation ERR: 108.99283232633	
check early-stopping...	
Last best epoch: 4, ERR: 107.629394	
	
Epoch #6	
training...	
-1.7328080303969e-08	embeddings grads	
-0.0070463065057993	feature weights grads	
-9.0054127213079e-05	feature bias grads	
2.1397584077931e-06	gru grads	
6.5339445427526e-05	gru bias grads	
0.0060789352282882	output_w grads	
0.13912197947502	output_b grads	
learning rate:	0.048500003	
Elapsed time: 2.984332	
Speed: 0.000018 sec/batch	
Training ERR: 727.82390461024	
validating...	
Validation ERR: 101.84884516429	
check early-stopping...	
Found new minima. Saving 
Last best epoch: 6, ERR: 101.848845	
	
Epoch #7	
training...	
-2.1446611597753e-08	embeddings grads	
-0.0099087124690413	feature weights grads	
-0.000111457935418	feature bias grads	
4.289226126275e-06	gru grads	
9.2848667918588e-06	gru bias grads	
0.033868614584208	output_w grads	
0.36384600400925	output_b grads	
learning rate:	0.0482500035	
Elapsed time: 2.971069	
Speed: 0.000018 sec/batch	
Training ERR: 693.15547975153	
validating...	
Validation ERR: 89.342911911197	
check early-stopping...	
Found new minima. Saving
Last best epoch: 7, ERR: 89.342912	
	
Epoch #8	
training...	
-2.4536879195125e-08	embeddings grads	
-0.019674839451909	feature weights grads	
-0.00012751790927723	feature bias grads	
2.5825884222286e-06	gru grads	
2.7131845854456e-06	gru bias grads	
0.021293396130204	output_w grads	
0.52193140983582	output_b grads	
learning rate:	0.048000004	
Elapsed time: 2.977743	
Speed: 0.000018 sec/batch	
Training ERR: 662.76471467828	
validating...	
Validation ERR: 85.326015817933	
check early-stopping...	
Found new minima. Saving 
Last best epoch: 8, ERR: 85.326016	
	
Epoch #9	
training...	
-4.5795339076449e-08	embeddings grads	
-0.019793825224042	feature weights grads	
-0.00023799829068594	feature bias grads	
-6.2910985434428e-06	gru grads	
-2.7645726731862e-05	gru bias grads	
-0.0087647764012218	output_w grads	
0.11675848066807	output_b grads	
learning rate:	0.0477500045	
Elapsed time: 3.058577	
Speed: 0.000018 sec/batch	
Training ERR: 630.08797416603	
validating...	
Validation ERR: 81.433456174098	
check early-stopping...	
Found new minima. Saving 
Last best epoch: 9, ERR: 81.433456	
	
Epoch #10	
training...	
-1.2227498302764e-07	embeddings grads	
-0.079100400209427	feature weights grads	
-0.00063546327874064	feature bias grads	
2.7701785256795e-06	gru grads	
-3.344654396642e-05	gru bias grads	
-0.0030312589369714	output_w grads	
0.41179794073105	output_b grads	
learning rate:	0.047500005	
Elapsed time: 3.000976	
Speed: 0.000018 sec/batch	
Training ERR: 603.50259356992	
validating...	
Validation ERR: 79.982634914108	
check early-stopping...	
Found new minima. Saving 
Last best epoch: 10, ERR: 79.982635	
```

You can well see that during first 10 epochs Torch POC loss dropped significantly. Now let's take a look at idential Tensorflow implementation that uses the same dataset, same hyperparameters and has the same number of parameters as well as optimizer.

### Tensorflow version training analysis
```
MODEL params:
(5197, 100)
(4, 100)
(100,)
(200, 1)
(1,)
(300, 400)
(400,)
(300, 200)
(200,)
TOTAL params: 701001
2018-04-06 11:26:30.534418: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-04-06 11:26:30.592130: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:895] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-06 11:26:30.592438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.695
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.61GiB
2018-04-06 11:26:30.592470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)

ERROR: unable to remove saved_model dir!
saved_model does not exist or locked, remove manually

>>> Start test loss: 143462.57397460938

Epoch: 1
> lr update: 0.0497500005
#################### DEBUGGING ####################
-8.42829e-09 	 Model/input_layer/embedding:0_grads
-1.0331846e-05 	 Model/input_layer/feature_weigths:0_grads
-6.7426217e-06 	 Model/input_layer/feature_bias:0_grads
0.32880843 	 Model/output_layer/output_w:0_grads
-18.802212 	 Model/output_layer/output_b:0_grads
-2.583741e-07 	 Model/recurrent_cell/multi_rnn_cell/cell_0/gru_cell/gates/kernel:0_grads
2.0594268e-06 	 Model/recurrent_cell/multi_rnn_cell/cell_0/gru_cell/gates/bias:0_grads
1.7847007e-06 	 Model/recurrent_cell/multi_rnn_cell/cell_0/gru_cell/candidate/kernel:0_grads
-1.2758308e-05 	 Model/recurrent_cell/multi_rnn_cell/cell_0/gru_cell/candidate/bias:0_grads

==================== debug_var ====================
> Train loss: 41251.31823730469
> Valid loss: 4779.414421081543
> Best valid loss so far: 143462.57397460938
Stopping in (35) epochs if no new minima!
!!! NEW local minima found, saving the model...

Epoch: 2
> lr update: 0.049500001
#################### DEBUGGING ####################
4.380058e-12 	 Model/input_layer/embedding:0_grads
-1.5687052e-09 	 Model/input_layer/feature_weigths:0_grads
3.5040453e-09 	 Model/input_layer/feature_bias:0_grads
1.0858363 	 Model/output_layer/output_w:0_grads
-24.059809 	 Model/output_layer/output_b:0_grads
9.927889e-11 	 Model/recurrent_cell/multi_rnn_cell/cell_0/gru_cell/gates/kernel:0_grads
-1.6885447e-09 	 Model/recurrent_cell/multi_rnn_cell/cell_0/gru_cell/gates/bias:0_grads
7.744753e-11 	 Model/recurrent_cell/multi_rnn_cell/cell_0/gru_cell/candidate/kernel:0_grads
-1.343922e-09 	 Model/recurrent_cell/multi_rnn_cell/cell_0/gru_cell/candidate/bias:0_grads

==================== debug_var ====================
> Train loss: 36458.438621520996
> Valid loss: 4771.496253967285
> Best valid loss so far: 4779.414421081543
Stopping in (35) epochs if no new minima!
!!! NEW local minima found, saving the model...

Epoch: 3
> lr update: 0.0492500015
#################### DEBUGGING ####################
-9.34557e-13 	 Model/input_layer/embedding:0_grads
-2.8814911e-18 	 Model/input_layer/feature_weigths:0_grads
-7.4764217e-10 	 Model/input_layer/feature_bias:0_grads
1.0264161 	 Model/output_layer/output_w:0_grads
-28.068089 	 Model/output_layer/output_b:0_grads
-3.470961e-10 	 Model/recurrent_cell/multi_rnn_cell/cell_0/gru_cell/gates/kernel:0_grads
3.2109366e-09 	 Model/recurrent_cell/multi_rnn_cell/cell_0/gru_cell/gates/bias:0_grads
-3.8721065e-10 	 Model/recurrent_cell/multi_rnn_cell/cell_0/gru_cell/candidate/kernel:0_grads
3.5263255e-09 	 Model/recurrent_cell/multi_rnn_cell/cell_0/gru_cell/candidate/bias:0_grads

==================== debug_var ====================
> Train loss: 36571.039489746094
> Valid loss: 5612.627830505371
> Best valid loss so far: 4771.496253967285
Stopping in (35) epochs if no new minima!

Epoch: 4
> lr update: 0.049000002
#################### DEBUGGING ####################
-1.5510707e-08 	 Model/input_layer/embedding:0_grads
-1.9394596e-05 	 Model/input_layer/feature_weigths:0_grads
-1.2408569e-05 	 Model/input_layer/feature_bias:0_grads
0.4255897 	 Model/output_layer/output_w:0_grads
-15.242744 	 Model/output_layer/output_b:0_grads
-2.0200261e-09 	 Model/recurrent_cell/multi_rnn_cell/cell_0/gru_cell/gates/kernel:0_grads
1.8209105e-08 	 Model/recurrent_cell/multi_rnn_cell/cell_0/gru_cell/gates/bias:0_grads
2.867294e-07 	 Model/recurrent_cell/multi_rnn_cell/cell_0/gru_cell/candidate/kernel:0_grads
-2.1903145e-06 	 Model/recurrent_cell/multi_rnn_cell/cell_0/gru_cell/candidate/bias:0_grads

==================== debug_var ====================
> Train loss: 37006.26306152344
> Valid loss: 4739.623916625977
> Best valid loss so far: 4771.496253967285
Stopping in (34) epochs if no new minima!
!!! NEW local minima found, saving the model...

Epoch: 5
> lr update: 0.0487500025
#################### DEBUGGING ####################
1.2948664e-11 	 Model/input_layer/embedding:0_grads
4.020792e-08 	 Model/input_layer/feature_weigths:0_grads
1.035893e-08 	 Model/input_layer/feature_bias:0_grads
-0.23937465 	 Model/output_layer/output_w:0_grads
-4.5712795 	 Model/output_layer/output_b:0_grads
-1.2125412e-10 	 Model/recurrent_cell/multi_rnn_cell/cell_0/gru_cell/gates/kernel:0_grads
1.2779661e-09 	 Model/recurrent_cell/multi_rnn_cell/cell_0/gru_cell/gates/bias:0_grads
-5.819682e-10 	 Model/recurrent_cell/multi_rnn_cell/cell_0/gru_cell/candidate/kernel:0_grads
3.9421697e-09 	 Model/recurrent_cell/multi_rnn_cell/cell_0/gru_cell/candidate/bias:0_grads

==================== debug_var ====================
> Train loss: 35687.37390899658
> Valid loss: 4758.33650970459
> Best valid loss so far: 4739.623916625977
Stopping in (35) epochs if no new minima!

Epoch: 6
> lr update: 0.048500003
#################### DEBUGGING ####################
8.107671e-14 	 Model/input_layer/embedding:0_grads
0.0 	 Model/input_layer/feature_weigths:0_grads
6.486137e-11 	 Model/input_layer/feature_bias:0_grads
0.86348265 	 Model/output_layer/output_w:0_grads
-19.398884 	 Model/output_layer/output_b:0_grads
2.4077628e-12 	 Model/recurrent_cell/multi_rnn_cell/cell_0/gru_cell/gates/kernel:0_grads
-2.4667464e-11 	 Model/recurrent_cell/multi_rnn_cell/cell_0/gru_cell/gates/bias:0_grads
-1.07752e-15 	 Model/recurrent_cell/multi_rnn_cell/cell_0/gru_cell/candidate/kernel:0_grads
9.429133e-15 	 Model/recurrent_cell/multi_rnn_cell/cell_0/gru_cell/candidate/bias:0_grads

==================== debug_var ====================
> Train loss: 34959.51641845703
> Valid loss: 4720.412452697754
> Best valid loss so far: 4739.623916625977
Stopping in (34) epochs if no new minima!
!!! NEW local minima found, saving the model...

Epoch: 7
> lr update: 0.0482500035
#################### DEBUGGING ####################
1.1791363e-14 	 Model/input_layer/embedding:0_grads
0.0 	 Model/input_layer/feature_weigths:0_grads
9.433085e-12 	 Model/input_layer/feature_bias:0_grads
0.46038043 	 Model/output_layer/output_w:0_grads
-18.42015 	 Model/output_layer/output_b:0_grads
-5.90758e-14 	 Model/recurrent_cell/multi_rnn_cell/cell_0/gru_cell/gates/kernel:0_grads
6.253203e-13 	 Model/recurrent_cell/multi_rnn_cell/cell_0/gru_cell/gates/bias:0_grads
-1.6275301e-15 	 Model/recurrent_cell/multi_rnn_cell/cell_0/gru_cell/candidate/kernel:0_grads
1.5087512e-14 	 Model/recurrent_cell/multi_rnn_cell/cell_0/gru_cell/candidate/bias:0_grads

==================== debug_var ====================
> Train loss: 35122.075828552246
> Valid loss: 4872.291694641113
> Best valid loss so far: 4720.412452697754
Stopping in (35) epochs if no new minima!

Epoch: 8
> lr update: 0.048000004
#################### DEBUGGING ####################
1.5793947e-14 	 Model/input_layer/embedding:0_grads
0.0 	 Model/input_layer/feature_weigths:0_grads
1.26351585e-11 	 Model/input_layer/feature_bias:0_grads
-0.23440647 	 Model/output_layer/output_w:0_grads
-17.745054 	 Model/output_layer/output_b:0_grads
6.400091e-13 	 Model/recurrent_cell/multi_rnn_cell/cell_0/gru_cell/gates/kernel:0_grads
-6.770721e-12 	 Model/recurrent_cell/multi_rnn_cell/cell_0/gru_cell/gates/bias:0_grads
-7.499852e-14 	 Model/recurrent_cell/multi_rnn_cell/cell_0/gru_cell/candidate/kernel:0_grads
6.953364e-13 	 Model/recurrent_cell/multi_rnn_cell/cell_0/gru_cell/candidate/bias:0_grads

==================== debug_var ====================
> Train loss: 35376.37155151367
> Valid loss: 4934.555885314941
> Best valid loss so far: 4720.412452697754
Stopping in (34) epochs if no new minima!

Epoch: 9
> lr update: 0.0477500045
#################### DEBUGGING ####################
-1.2424676e-13 	 Model/input_layer/embedding:0_grads
0.0 	 Model/input_layer/feature_weigths:0_grads
-9.939738e-11 	 Model/input_layer/feature_bias:0_grads
0.5383458 	 Model/output_layer/output_w:0_grads
-21.300901 	 Model/output_layer/output_b:0_grads
-7.6299974e-13 	 Model/recurrent_cell/multi_rnn_cell/cell_0/gru_cell/gates/kernel:0_grads
8.020704e-12 	 Model/recurrent_cell/multi_rnn_cell/cell_0/gru_cell/gates/bias:0_grads
-7.250712e-16 	 Model/recurrent_cell/multi_rnn_cell/cell_0/gru_cell/candidate/kernel:0_grads
6.68652e-15 	 Model/recurrent_cell/multi_rnn_cell/cell_0/gru_cell/candidate/bias:0_grads

==================== debug_var ====================
> Train loss: 35422.02657318115
> Valid loss: 4915.4898681640625
> Best valid loss so far: 4720.412452697754
Stopping in (33) epochs if no new minima!

Epoch: 10
> lr update: 0.047500005
#################### DEBUGGING ####################
4.3053272e-14 	 Model/input_layer/embedding:0_grads
0.0 	 Model/input_layer/feature_weigths:0_grads
3.4442636e-11 	 Model/input_layer/feature_bias:0_grads
-0.4148861 	 Model/output_layer/output_w:0_grads
-16.681393 	 Model/output_layer/output_b:0_grads
-3.3981418e-12 	 Model/recurrent_cell/multi_rnn_cell/cell_0/gru_cell/gates/kernel:0_grads
3.5677305e-11 	 Model/recurrent_cell/multi_rnn_cell/cell_0/gru_cell/gates/bias:0_grads
-1.0744528e-14 	 Model/recurrent_cell/multi_rnn_cell/cell_0/gru_cell/candidate/kernel:0_grads
9.898426e-14 	 Model/recurrent_cell/multi_rnn_cell/cell_0/gru_cell/candidate/bias:0_grads

==================== debug_var ====================
> Train loss: 35475.495765686035
> Valid loss: 4763.377861022949
> Best valid loss so far: 4720.412452697754
Stopping in (32) epochs if no new minima!
```

You can well see the gradients are very low in comparison to Torch POC up to the point that  some of them become zero or very close. Additionally, binary cross entropy loss is much higher and basically does not drop. Using standard `tf.train.GradientDescentOptimizer(self.lr)` does not make the gradients that small and is more stable in general but produces the same garbage predictions after training. We have been trying to figure out the reason for several weeks now and are simply out of clue what could cause such a drastic difference.  We checked our data preprocessing up to the point where we printed out the input matrix values and compared them side by side with Torch. They are identical so it is highly unlikely to be the data feeding mechanism. There is something not right with backpropagation it seems but our lack of experience with Tensorflow does not allow us to proceed further. Maybe somebody here could give us an advice on what could be the reason?

Addtionally attaching Tensorboard output as well. 

![2018-04-06-114156_793x370_scrot](https://user-images.githubusercontent.com/7676160/38414743-a9d43972-398f-11e8-87d1-3a934fc9af3e.png)

![2018-04-06-114228_1534x946_scrot](https://user-images.githubusercontent.com/7676160/38414748-acc7cd60-398f-11e8-8947-645e4bc63b43.png)

![2018-04-06-114236_1544x719_scrot](https://user-images.githubusercontent.com/7676160/38414750-af4aab34-398f-11e8-8d9b-d20c5bdc1f7c.png)
"
18289,I can't transfer .pb file to .tflite file,"
Hi,
I trained a model with keras framework. And i saved model as .pb file. This model takes input as ""String Array"" and gives out as ""String Array"" .I want use this model on Android device. Therefore, i use TOCO but i can't give true  --input_shaped and --inference_type parameters.  I use this toco command

bazel-bin/tensorflow/contrib/lite/toco/toco --input_file=modelimtest.pb --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --output_file=modelim.lite --inference_type=QUANTIZED_UINT8 --input_arrays=input_1 --output_arrays=activation_1/truediv input_shaped=

How can i change this command line for my problem?


------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:Source
- **TensorFlow version (use command below)**:1.7
- **Python version**: 3.4
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: Cuda 9.0
- **GPU model and memory**: GTX 1050
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
18288,ctc_loss complains  that Labels length is zero,"OS Platform and Distribution ubuntu 16.04
TensorFlow installed from pip 
TensorFlow version 1.7
Bazel version N/A
CUDA/cuDNN version 9.0 7.0
GPU model and memory N/A
Exact command to reproduce N/A

I want to use ctc_loss to do gesture recognition. But I keep getting error message that Labels length is zero at batch 0. I can't figure out the problem. So come here for help.
The data I feed into ctc_loss are listed in the following table

```
tensname                    type                      dimension
labels                  sparsetensor         batch_size(5) x label_length(1)
sequence_predicts         tensor                  time_steps(10) x batch_size(5) x num_classes(26)
sequence_lengths          tensor                  batch_size(5)
```

I create ctc_loss with the following code

```python
loss = tf.nn.ctc_loss(labels,sequence_predicts,sequence_lengths,time_major = True);
```

I print all input tensors with the following code
```python
denselabels = tf.sparse_to_dense(labels.indices,labels.dense_shape,labels.values);
denselabels = tf.Print(denselabels,[denselabels],message = ""labels = "", summarize = 20, name = ""denselabels"");
sequence_predicts = tf.Print(sequence_predicts,[sequence_predicts],message = ""sequence_predicts = "", summarize = 20, name = ""sequence_predicts"");
sequence_lengths = tf.Print(sequence_lengths,[sequence_lengths],message = ""sequence_lengths = "", summarize = 200, name = ""sequence_lengths"");
```

The output on the console is 
```bash
sequence_lengths = [10 10 10 10 10]
labels = [[1][2][1][0][0]]
sequence_predicts = [[[0.0183351934 -0.0540067367 0.0173245296 0.10416019 -0.06072326 -0.0563994423 0.00676568877 -0.046640303 -0.0107666068 0.0554158054 0.0658506081 0.0124566173 0.0133351646 0.0134876268 -0.0453479 -0.058809232 0.0160786062 -0.0285613891 -0.105710872 0.0354634598]]...]
```"
18287,Eager execution breaks fit_generator in tf.keras,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS 10.12.6
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version**: 1.7.0
- **Python version**: 3.6.3
- **Numpy version**: 1.14.2
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: not installed
- **GPU model and memory**: CPU only
- **Exact command to reproduce**: Run code below

### Describe the problem
`tf.enable_eager_execution()` leads to a `RuntimeError: You must compile your model before using it.` when calling Keras's `model.fit_generator`, even if the model has already been compiled. Calling `model.fit` works on the other hand. 

### Source code / logs
Minimum reproducible test case:
```python
import numpy as np
import tensorflow as tf

tf.enable_eager_execution()  # It works without this line

x, y = np.random.randn(100, 10), np.random.randn(100, 4)
model = tf.keras.models.Sequential([tf.keras.layers.Dense(4, input_dim=10)])
model.compile(tf.train.RMSPropOptimizer(0.001), 'mse')

model.fit(x, y)  # Fitting without a generator works in eager mode

class Iterator:
    def __next__(self):
        return x, y

model.fit_generator(Iterator(), steps_per_epoch=10)
```

Log:

    Epoch 1/1
    100/100 [==============================] - 0s 445us/step - loss: 2.1153
    Traceback (most recent call last):
      File ""tmp.py"", line 16, in <module>
        model.fit_generator(Iterator(), steps_per_epoch=10)
      File ""/Users/kilian/.pyenv/versions/3.6.3/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/sequential.py"", line 860, in fit_generator
        initial_epoch=initial_epoch)
      File ""/Users/kilian/.pyenv/versions/3.6.3/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/training.py"", line 1603, in fit_generator
        initial_epoch=initial_epoch)
      File ""/Users/kilian/.pyenv/versions/3.6.3/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/training_generator.py"", line 52, in fit_generator
        model._make_train_function()
      File ""/Users/kilian/.pyenv/versions/3.6.3/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/training.py"", line 578, in _make_train_function
        raise RuntimeError('You must compile your model before using it.')
    RuntimeError: You must compile your model before using it."
18285,why is the tensor value of the dimension resolved when reading tfrecord files is twice as much as is required to rescontruct the dimension？,"

-----------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 16.04)
- **TensorFlow installed from (source or binary)**: pip install tensorflow
- **TensorFlow version (use command below)**: tensorflow1.4
- **Python version**: Python 3.6.3
- **Bazel version (if compiling from source)**: --
- **GCC/Compiler version (if compiling from source)**: --
- **CUDA/cuDNN version**: --
- **GPU model and memory**:Tesla K80 
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
![image](https://user-images.githubusercontent.com/35683771/38402256-8349acbc-398d-11e8-8f27-a6393ddf9b7e.png)
image Segmentation:why is the tensor value of the dimension resolved when reading tfrecord files is twice as much as is required to rescontruct the dimension？



### Source code / logs

2018-04-06 10:39:40.367069: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-04-06 10:39:40.845083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:05:00.0
totalMemory: 11.17GiB freeMemory: 6.90GiB
2018-04-06 10:39:40.845182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:05:00.0, compute capability: 3.7)
No checkpoint file found
ERROR:tensorflow:Exception in QueueRunner: Input to reshape is a tensor with 26136 values, but the requested shape has 13068
	 [[Node: Reshape = Reshape[T=DT_UINT8, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](DecodeRaw/_87, Reshape/shape)]]
	 [[Node: random_crop_1/_101 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_80_random_crop_1"", tensor_type=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]2018-04-06 10:39:51.060248: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: Input to reshape is a tensor with 8712 values, but the requested shape has 4356
	 [[Node: Reshape_1 = Reshape[T=DT_UINT8, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](DecodeRaw_1/_71, Reshape_1/shape)]]
2018-04-06 10:39:51.060359: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: Input to reshape is a tensor with 8712 values, but the requested shape has 4356
	 [[Node: Reshape_1 = Reshape[T=DT_UINT8, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](DecodeRaw_1/_71, Reshape_1/shape)]]
2018-04-06 10:39:51.060728: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: Input to reshape is a tensor with 8712 values, but the requested shape has 4356
	 [[Node: Reshape_1 = Reshape[T=DT_UINT8, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](DecodeRaw_1/_71, Reshape_1/shape)]]
2018-04-06 10:39:51.060779: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: Input to reshape is a tensor with 8712 values, but the requested shape has 4356
	 [[Node: Reshape_1 = Reshape[T=DT_UINT8, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](DecodeRaw_1/_71, Reshape_1/shape)]]
2018-04-06 10:39:51.060868: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: Input to reshape is a tensor with 8712 values, but the requested shape has 4356
	 [[Node: Reshape_1 = Reshape[T=DT_UINT8, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](DecodeRaw_1/_71, Reshape_1/shape)]]
2018-04-06 10:39:51.060926: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: Input to reshape is a tensor with 8712 values, but the requested shape has 4356
	 [[Node: Reshape_1 = Reshape[T=DT_UINT8, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](DecodeRaw_1/_71, Reshape_1/shape)]]

ERROR:tensorflow:Exception in QueueRunner: Input to reshape is a tensor with 26136 values, but the requested shape has 13068
	 [[Node: Reshape = Reshape[T=DT_UINT8, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](DecodeRaw/_87, Reshape/shape)]]
	 [[Node: random_crop_1/_101 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_80_random_crop_1"", tensor_type=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]2018-04-06 10:39:51.066487: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: Input to reshape is a tensor with 26136 values, but the requested shape has 13068
	 [[Node: Reshape = Reshape[T=DT_UINT8, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](DecodeRaw/_87, Reshape/shape)]]
2018-04-06 10:39:51.066576: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: Input to reshape is a tensor with 26136 values, but the requested shape has 13068
	 [[Node: Reshape = Reshape[T=DT_UINT8, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](DecodeRaw/_87, Reshape/shape)]]

2018-04-06 10:39:51.074663: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: Input to reshape is a tensor with 8712 values, but the requested shape has 4356
	 [[Node: Reshape_1 = Reshape[T=DT_UINT8, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](DecodeRaw_1/_71, Reshape_1/shape)]]
2018-04-06 10:39:51.074663: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: Input to reshape is a tensor with 8712 values, but the requested shape has 4356
	 [[Node: Reshape_1 = Reshape[T=DT_UINT8, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](DecodeRaw_1/_71, Reshape_1/shape)]]
ERROR:tensorflow:Exception in QueueRunner: Input to reshape is a tensor with 8712 values, but the requested shape has 4356
	 [[Node: Reshape_1 = Reshape[T=DT_UINT8, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](DecodeRaw_1/_71, Reshape_1/shape)]]
	 [[Node: random_crop/All/_73 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_33_random_crop/All"", tensor_type=DT_BOOL, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]
ERROR:tensorflow:Exception in QueueRunner: Input to reshape is a tensor with 8712 values, but the requested shape has 4356
	 [[Node: Reshape_1 = Reshape[T=DT_UINT8, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](DecodeRaw_1/_71, Reshape_1/shape)]]
	 [[Node: random_crop_1/_101 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_80_random_crop_1"", tensor_type=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]
ERROR:tensorflow:Exception in QueueRunner: Input to reshape is a tensor with 8712 values, but the requested shape has 4356
	 [[Node: Reshape_1 = Reshape[T=DT_UINT8, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](DecodeRaw_1/_71, Reshape_1/shape)]]
ERROR:tensorflow:Exception in QueueRunner: Input to reshape is a tensor with 26136 values, but the requested shape has 13068
	 [[Node: Reshape = Reshape[T=DT_UINT8, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](DecodeRaw/_87, Reshape/shape)]]
Exception in thread QueueRunnerThread-shuffle_batch/random_shuffle_queue-shuffle_batch/random_shuffle_queue_enqueue:

**I am attaching below my code snippet **
"
18283,Document for `tf.TextLine.Dataset.shuffle` is confusing.,"In the [doc](https://www.tensorflow.org/api_docs/python/tf/data/TextLineDataset#shuffle) for V1.7.

The signature is:
```
shuffle(
    buffer_size,
    seed=None,
    reshuffle_each_iteration=None
)
```

and in below description:
`reshuffle_each_iteration: (Optional.) A boolean, which if true indicates that the dataset should be pseudorandomly reshuffled each time it is iterated over. (Defaults to True.)`

I can't tell what is default value for `reshuffle_each_iteration` and so I can't tell the default behaviour."
18280,[feature] js_func (for javascript) equivalent of py_func,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
n/a
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
iOS, Android
- **TensorFlow installed from (source or binary)**:
n/a
- **TensorFlow version (use command below)**:
n/a
- **Python version**: 
n/a
- **Bazel version (if compiling from source)**:
n/a
- **GCC/Compiler version (if compiling from source)**:
n/a
- **CUDA/cuDNN version**:
n/a
- **GPU model and memory**:
n/a
- **Exact command to reproduce**:
n/a

### Describe the problem
I suggest adding a `js_func` that allows defining nodes in javascript. This would be similar to the existing `py_func`. There are many systems (ie iOS and Android) that have JS runtimes but do not have python runtimes."
18279,h5py Dockerfile,"h5py is a quite hard dependency but it is not in all the flavors of TF Dockerfile.
I.e. https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/_impl/keras/applications/vgg16.py#L50-L51

See https://github.com/keras-team/keras/pull/9830
/cc @fchollet "
18276,tf.train.latest_checkpoint always return the same checkpoint for GCS paths (pywrap_tensorflow cache bug?),"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS High Sierra 10.13.3 (confirmed on Ubuntu 16.04.4 LTS as well)
- **TensorFlow installed from (source or binary)**: binary (confirmed from 1.6 source as well)
- **TensorFlow version (use command below)**: ('v1.6.0-0-gd2e24b6039', '1.6.0')
- **Python version**: 2.7.13
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A (confirmed with CUDA 9.1 cuDNN 7.1)
- **GPU model and memory**: N/A (confirmed with P100 16GB)
- **Exact command to reproduce**:

Open 2 terminals, 1 and 2

**From terminal 1**
```
cat <<EOT > checkpoint
model_checkpoint_path: ""model.ckpt-4""
all_model_checkpoint_paths: ""model.ckpt-0""
all_model_checkpoint_paths: ""model.ckpt-1""
all_model_checkpoint_paths: ""model.ckpt-2""
all_model_checkpoint_paths: ""model.ckpt-3""
all_model_checkpoint_paths: ""model.ckpt-4""
EOT
gsutil cp checkpoint gs://path_to_checkpoint_dir/
```

**From terminal 2**
```
python
import tensorflow as tf
print tf.train.get_checkpoint_state('gs://path_to_checkpoint_dir')
```

**From terminal 1**
```
cat <<EOT > checkpoint
model_checkpoint_path: ""model.ckpt-7""
all_model_checkpoint_paths: ""model.ckpt-3""
all_model_checkpoint_paths: ""model.ckpt-4""
all_model_checkpoint_paths: ""model.ckpt-5""
all_model_checkpoint_paths: ""model.ckpt-6""
all_model_checkpoint_paths: ""model.ckpt-7""
EOT
gsutil cp checkpoint gs://path_to_checkpoint_dir/
```

**From terminal 2** (python shell still opened, **do not reimport tensorflow**)
```
print tf.train.get_checkpoint_state('gs://path_to_checkpoint_dir')
```

tensorflow always returns the same cached copy of the checkpoint file.


### Describe the problem
tf.train.latest_checkpoint and tf.train.get_checkpoint_state always returns a cached version of the latest checkpoint file on GCS, ignoring new checkpoints written to the checkpoint file. This is extremely problematic when training a model.

I traced the problem to pywrap_tensorflow so my guess is it's coming from the underlying native code. I would be happy with a way to reset the cache or an input bool to just not use it at all.

### Source code / logs

```
>>> import tensorflow as tf
>>> print tf.train.get_checkpoint_state('gs://path_to_checkpoint_dir')
model_checkpoint_path: ""gs://path_to_checkpoint_dir/model.ckpt-4""
all_model_checkpoint_paths: ""gs://path_to_checkpoint_dir/model.ckpt-0""
all_model_checkpoint_paths: ""gs://path_to_checkpoint_dir/model.ckpt-1""
all_model_checkpoint_paths: ""gs://path_to_checkpoint_dir/model.ckpt-2""
all_model_checkpoint_paths: ""gs://path_to_checkpoint_dir/model.ckpt-3""
all_model_checkpoint_paths: ""gs://path_to_checkpoint_dir/model.ckpt-4""

>>> print tf.train.get_checkpoint_state('gs://path_to_checkpoint_dir')
model_checkpoint_path: ""gs://path_to_checkpoint_dir/model.ckpt-4""
all_model_checkpoint_paths: ""gs://path_to_checkpoint_dir/model.ckpt-0""
all_model_checkpoint_paths: ""gs://path_to_checkpoint_dir/model.ckpt-1""
all_model_checkpoint_paths: ""gs://path_to_checkpoint_dir/model.ckpt-2""
all_model_checkpoint_paths: ""gs://path_to_checkpoint_dir/model.ckpt-3""
all_model_checkpoint_paths: ""gs://path_to_checkpoint_dir/model.ckpt-4""
```
"
18275,"SIGILL, Illegal instruction, when importing tensorflow","I'm getting a `terminated by signal SIGILL (Illegal instruction)` when importing tensorflow.

`less /proc/cpuinfo` yields

```
processor       : 0
vendor_id       : GenuineIntel
cpu family      : 6
model           : 26
model name      : Intel(R) Core(TM) i7 CPU         920  @ 2.67GHz
stepping        : 5
microcode       : 0x11
cpu MHz         : 1598.913
cache size      : 8192 KB
physical id     : 0
siblings        : 8
core id         : 0
cpu cores       : 4
apicid          : 0
initial apicid  : 0
fpu             : yes
fpu_exception   : yes
cpuid level     : 11
wp              : yes
flags           : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti retpoline tpr_shadow vnmi flexpriority ept vpid dtherm ida
bugs            : cpu_meltdown spectre_v1 spectre_v2
bogomips        : 5331.70
clflush size    : 64
cache_alignment : 64
address sizes   : 36 bits physical, 48 bits virtual
power management:
```

Is my CPU too old to use tensorflow?"
18272,"hi, oops","Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
18271,[Feature Request] Python - like behavior of tf.string_split. Consider whole multi-byte delimiter.,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS, Ubuntu
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**:1.7
- **Python version**: 3.6,3.5
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:No
- **GPU model and memory**:
- **Exact command to reproduce**:

### Describe the problem

`tf.string_split` is documented as `If delimiter contains multiple bytes, it is treated as a set of delimiters with each considered a potential split point.` Hence, each character in a multi-byte string delimiter will become a separate delimiter, which is very non-intuitive and difficult to implement.

so for example, I want to split by to the token `<eos>`
```
tf.string_split([""hello world <eos> tensorflow""], delimiter=""<eos>"").values
# equal:     ['h', 'll', ' w', 'rld ', ' t', 'n', 'rfl', 'w']  
# should be ['hello world ', ' tensorflow]  
```

Can tf.string_split be reimplemented so that it consider the whole delimiter string, whether single or multiple character, to be its true delimiter instead making every single character in it delimiter?

Thank you

"
18270,why the kfac in tensorflow is not working suddenly?,"Hi,

I wrote a simple code using tf.contrib.kfac for regression. It worked fine in the last two weeks. However, when I tried to run the code again the day before yesterday, there was an error: 

**AttributeError: module 'tensorflow.contrib' has no attribute 'kfac'**

![image](https://user-images.githubusercontent.com/38111150/38382416-c53529aa-38be-11e8-9220-d6f9102f61e8.png)

I just don't know why suddenly this goes wrong. Can anyone help me?

Thanks so much.
"
18268,Distributed Tensorflow :: Worker is getting terminated after running few training steps,"Hi,

I am having 2 nodes cluster and running parameter server and first worker on one machine, and second worker on another machine.
Environment and version details are below,
Have I written custom code - Yes
OS Platform and Distribution - CentOS 7.2.1511
TensorFlow installed from - Binary
TensorFlow version - 1.3.0
Bazel version - N/A
CUDA/cuDNN version - N/A
GPU model and memory - N/A
Exact command to reproduce - N/A

Parameter server and first worker that is also the chief(master) worker, starts correctly.
When I start send worker that also starts and training runs for few steps and then the worker is terminated with below exception.
Plz noote all are CPU machines (no GPUs)

INFO:tensorflow:global step 482: loss: 0.8154 (15.70 sec/step)
INFO:tensorflow:global step 483: loss: 1.1079 (15.20 sec/step)
INFO:tensorflow:global step 485: loss: 0.8833 (15.21 sec/step)
INFO:tensorflow:global step 487: loss: 1.0541 (15.78 sec/step)
INFO:tensorflow:global step 489: loss: 0.8346 (14.84 sec/step)
Now run summeries
INFO:tensorflow:global step 491: loss: 1.0193 (14.91 sec/step)
loss is done
**INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framewo                                                                                           rk.errors_impl.CancelledError'>, Step was cancelled by an explicit call to `Session::Close()`.**
Traceback (most recent call last):
  File ""./DTF_train_image_classifier.py"", line 464, in <module>
    tf.app.run()
	
On parameter server, I see below error logs,

**2018-04-05 14:47:12.860894: W tensorflow/core/kernels/queue_base.cc:295] _0_parallel_read/filenames: Skipping cancelled enqueue attempt with queue not closed
2018-04-05 14:47:12.861414: W tensorflow/core/kernels/queue_base.cc:295] _2_parallel_read/common_queue: Skipping cancelled enqueue attempt with queue not closed
2018-04-05 14:47:12.861552: W tensorflow/core/kernels/queue_base.cc:295] _4_batch/fifo_queue: Skipping cancelled enqueue attempt with queue not closed
2018-04-05 14:47:12.864402: W tensorflow/core/kernels/queue_base.cc:295] _4_batch/fifo_queue: Skipping cancelled enqueue attempt with queue not closed
2018-04-05 14:47:12.864472: W tensorflow/core/kernels/queue_base.cc:295] _4_batch/fifo_queue: Skipping cancelled enqueue attempt with queue not closed
2018-04-05 14:47:12.864504: W tensorflow/core/kernels/queue_base.cc:295] _4_batch/fifo_queue: Skipping cancelled enqueue attempt with queue not closed**

I am attaching below my code snippet ,

server = tf.train.Server(
        cluster,
        job_name=FLAGS.job_name,
        task_index=FLAGS.task_index)
   
    if FLAGS.pipeline_id is None:
        raise ValueError('pipeline_id [%s] was not recognized', FLAGS.pipeline_id)

    #print('job name '+FLAGS.job_name)
    #print('task index name ' + FLAGS.task_index)
    if FLAGS.job_name == ""ps"":
        server.join()
    elif FLAGS.job_name == ""worker"":
	dataset = get_split(FLAGS.dataset_split_name, FLAGS.tf_records_dir, 'flowers', FLAGS.num_classes, labels_file)
    print 'num of classes ------------------->', dataset.num_classes
    images, _, labels = load_batch(FLAGS, dataset, batch_size=FLAGS.training_batch_size, height=FLAGS.image_resize,
                                       width=FLAGS.image_resize, is_training=True)

    # Get number of steps to decay
    num_batches_per_epoch = int(dataset.num_samples / FLAGS.training_batch_size)
    num_steps_per_epoch = num_batches_per_epoch  # Because one step is one batch processed
    decay_steps = int(FLAGS.num_epochs_before_decay * num_steps_per_epoch)

	with tf.device(tf.train.replica_device_setter(
			worker_device=""/job:worker/task:%d"" % FLAGS.task_index,
			cluster=cluster)):
						with slim.arg_scope(inception_v3_arg_scope()):
			logits, end_points = inception_v3(images, num_classes = dataset.num_classes, is_training = True)



		exclude = ['InceptionV3/Logits', 'InceptionV3/AuxLogits']
		#exclude = get_variables_to_exclude()
		for i in exclude:
		   print ""var to exclude -> "",i
		variables_to_restore = slim.get_variables_to_restore(exclude = exclude)

		#Perform one-hot-encoding of the labels
		one_hot_labels = slim.one_hot_encoding(labels, dataset.num_classes)

		#Calculate loss
		loss = tf.losses.softmax_cross_entropy(onehot_labels = one_hot_labels, logits = logits)
		total_loss = tf.losses.get_total_loss()

		#Create the global step
		global_step = get_or_create_global_step()


		#Define your exponentially decaying learning rate
		lr = tf.train.exponential_decay(
			learning_rate = FLAGS.initial_learning_rate,
			global_step = global_step,
			decay_steps = decay_steps,
			decay_rate = FLAGS.learning_rate_decay_factor,
			staircase = True)

		#Get optimizer as configured by user
		optimizer = tf.train.AdamOptimizer(learning_rate = lr)
		#optimizer = getOptimizer(learning_rate = lr)

		#Create the train_op.
		variables_to_train = get_variables_to_train()
		#for j in variables_to_train:
		  #print ""var to train "",j
		#vn = tf.trainable_variables()
		train_op = slim.learning.create_train_op(total_loss, optimizer,variables_to_train=variables_to_train)


		predictions = tf.argmax(end_points['Predictions'], 1)
		probabilities = end_points['Predictions']
		accuracy, accuracy_update = tf.contrib.metrics.streaming_accuracy(predictions, labels)
		metrics_op = tf.group(accuracy_update, probabilities)


		#create all the summaries you need to monitor
		tf.summary.scalar('losses/Total_Loss', total_loss)
		tf.summary.scalar('accuracy', accuracy)
		tf.summary.scalar('learning_rate', lr)
		my_summary_op = tf.summary.merge_all()

		#Define train step to run training operation
		def train_step(sess, train_op, global_step):

			start_time = time.time()
			total_loss, global_step_count, _ = sess.run([train_op, global_step, metrics_op])
			time_elapsed = time.time() - start_time


			logging.info('global step %s: loss: %.4f (%.2f sec/step)', global_step_count, total_loss, time_elapsed)

			return total_loss, global_step_count
			
	saver = tf.train.Saver(variables_to_restore)
        def restore_fn(sess):
            return saver.restore(sess, FLAGS.checkpoint_path)

	#Create supervisor
	sv = tf.train.Supervisor(is_chief=(FLAGS.task_index == 0),global_step=global_step,logdir = train_logs_path, summary_op = None, init_fn = restore_fn)


	#Run the managed session
	with sv.prepare_or_wait_for_session(server.target) as sess:
		for step in xrange(num_steps_per_epoch * FLAGS.training_num_epochs):
			#Log info at each epoch:
			if step % num_batches_per_epoch == 0:
				logging.info('Epoch %s/%s', step/num_batches_per_epoch + 1, FLAGS.training_num_epochs)
				learning_rate_value, accuracy_value = sess.run([lr, accuracy])
				logging.info('Current Learning Rate: %s', learning_rate_value)
				logging.info('Current Streaming Training Accuracy: %s', accuracy_value)


				logits_value, probabilities_value, predictions_value, labels_value = sess.run([logits, probabilities, predictions, labels])
				print 'logits: \n', logits_value
				print 'Probabilities: \n', probabilities_value
				print 'predictions: \n', predictions_value
				print 'Labels:\n:', labels_value

			#Log the summaries every 10 step.
			if step % FLAGS.steps_update_frequency == 0 and step != 0:
				loss, gs = train_step(sess, train_op, sv.global_step)
				summaries = sess.run(my_summary_op)
				sv.summary_computed(sess, summaries)
				print ""**** SAVE THE MODEL ****""
				sv.saver.save(sess,sv.save_path,global_step=sv.global_step)
				##

				checkpoint_path = tf.train.latest_checkpoint(train_logs_path)
				training_json = '{""model_path"":""'+ checkpoint_path +'"",""no_of_steps"":' +str(gs)+',""loss"":'+str(loss)+'}'
				current_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
				#dbClient.store_metrices([(FLAGS.pipeline_id,FLAGS.operation_type,training_json,current_time)])

				


			else:
				loss, _ = train_step(sess, train_op, sv.global_step)

"
18266,Cache lockfile already exists,"Using the train_and_evaluate method from estimator API and cache policy on filesystem, I get an error because the evaluation starts before that all cache is written on the filesystem. So when the train runs the second time, after the evaluation, I get the error because it finds the lock file. 
If the cache is written before the first evaluation I don't get the error.

Here a snippet runnable on colab 
```
import tensorflow as tf
import numpy as np
from tensorflow import keras as ks
import itertools


def batch_reshape(a, b):
    a.set_shape([None, None, 3])
    b.set_shape([None, None, 1])
    return (a, b)


def gen(n):
    a = np.array(np.random.rand(5, 5, 3).astype(np.float32))
    b = np.array(np.random.rand(5, 5, 1).astype(np.float32))
    return (a, b)


def my_input_fn_train():
    ds = tf.data.Dataset.range(100000)
    ds = ds.map(
        lambda x: tf.py_func(func=gen, inp=[x], Tout=[tf.float32, tf.float32]))
    ds = ds.map(batch_reshape)
    ds = ds.cache(""/tmp/mycache_train"")

    ds = ds.repeat(3)

    value = ds.make_one_shot_iterator().get_next()

    return {""input_rgb"": value[0]}, {""softmax"": value[1]}


def my_input_fn_eval():
    ds = tf.data.Dataset.range(100000)
    ds = ds.map(
        lambda x: tf.py_func(func=gen, inp=[x], Tout=[tf.float32, tf.float32]))
    ds = ds.map(batch_reshape)
    ds = ds.cache(""/tmp/mycache_eval"")

    ds = ds.repeat(3)

    value = ds.make_one_shot_iterator().get_next()

    return {""input_rgb"": value[0]}, {""softmax"": value[1]}


def main():
    tf.logging.set_verbosity(tf.logging.INFO)
    input_rgb = ks.layers.Input(shape=(1, 5, 5, 3), name=""input_rgb"")
    x = ks.layers.Dense(1, activation='relu', name=""Dense_1"")(input_rgb)
    x = ks.layers.Dense(1, activation='softmax', name=""softmax"")(x)
    model = ks.models.Model(inputs=[input_rgb], outputs=[x])
    model.compile(
        loss={'softmax': 'binary_crossentropy'},
        optimizer=tf.keras.optimizers.Adam())

    estimator = ks.estimator.model_to_estimator(keras_model=model)

    train_spec = tf.estimator.TrainSpec(input_fn=my_input_fn_train)

    eval_spec = tf.estimator.EvalSpec(
        input_fn=my_input_fn_eval, steps=5, throttle_secs=2)

    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)


if __name__ == ""__main__"":
    main()

```

and here the output

```
INFO:tensorflow:Using the Keras model from memory.
INFO:tensorflow:Using default config.
WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpd1r865ry
INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpd1r865ry', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fcb48f9ecf8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:Running training and evaluation locally (non-distributed).
INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 2 secs (eval_spec.throttle_secs) or training is finished.
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /tmp/tmpd1r865ry/keras_model.ckpt
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpd1r865ry/model.ckpt.
INFO:tensorflow:loss = 9.25762, step = 1
INFO:tensorflow:global_step/sec: 612.893
INFO:tensorflow:loss = 9.348354, step = 101 (0.166 sec)
INFO:tensorflow:global_step/sec: 952.69
INFO:tensorflow:loss = 8.319871, step = 201 (0.108 sec)
INFO:tensorflow:global_step/sec: 838.883
INFO:tensorflow:loss = 7.7207212, step = 301 (0.119 sec)
INFO:tensorflow:global_step/sec: 917.55
INFO:tensorflow:loss = 8.657611, step = 401 (0.110 sec)
INFO:tensorflow:global_step/sec: 866.062
INFO:tensorflow:loss = 8.567427, step = 501 (0.118 sec)
INFO:tensorflow:global_step/sec: 862.789
INFO:tensorflow:loss = 7.4227247, step = 601 (0.110 sec)
INFO:tensorflow:global_step/sec: 847.577
INFO:tensorflow:loss = 6.676866, step = 701 (0.118 sec)
INFO:tensorflow:global_step/sec: 911.827
INFO:tensorflow:loss = 7.4915752, step = 801 (0.112 sec)
INFO:tensorflow:global_step/sec: 837.15
INFO:tensorflow:loss = 7.7332606, step = 901 (0.120 sec)
INFO:tensorflow:global_step/sec: 857.915
INFO:tensorflow:loss = 7.283838, step = 1001 (0.116 sec)
INFO:tensorflow:global_step/sec: 786.144
INFO:tensorflow:loss = 8.61713, step = 1101 (0.127 sec)
INFO:tensorflow:Saving checkpoints for 1150 into /tmp/tmpd1r865ry/model.ckpt.
INFO:tensorflow:Loss for final step: 8.417924.
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Starting evaluation at 2018-04-05-15:36:08
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /tmp/tmpd1r865ry/model.ckpt-1150
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Evaluation [1/5]
INFO:tensorflow:Evaluation [2/5]
INFO:tensorflow:Evaluation [3/5]
INFO:tensorflow:Evaluation [4/5]
INFO:tensorflow:Evaluation [5/5]
INFO:tensorflow:Finished evaluation at 2018-04-05-15:36:08

INFO:tensorflow:Saving dict for global step 1150: global_step = 1150, loss = 8.261229
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /tmp/tmpd1r865ry/model.ckpt-1150
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.

---------------------------------------------------------------------------
AlreadyExistsError                        Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
   1360     try:
-> 1361       return fn(*args)
   1362     except errors.OpError as e:

/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata)
   1339           return tf_session.TF_Run(session, options, feed_dict, fetch_list,
-> 1340                                    target_list, status, run_metadata)
   1341 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/errors_impl.py in __exit__(self, type_arg, value_arg, traceback_arg)
    515             compat.as_text(c_api.TF_Message(self.status.status)),
--> 516             c_api.TF_GetCode(self.status.status))
    517     # Delete the underlying status object from memory otherwise it stays alive

AlreadyExistsError: There appears to be a concurrent caching iterator running - cache lockfile already exists ('/tmp/mycache_train.lockfile'). If you are sure no other running TF computations are using this cache prefix, delete the lockfile and re-initialize the iterator. Lockfile contents: Created at: 1522942566
	 [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,?,3], [?,?,1]], output_types=[DT_FLOAT, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](OneShotIterator)]]

During handling of the above exception, another exception occurred:

AlreadyExistsError                        Traceback (most recent call last)
<ipython-input-5-9d8332f50ddd> in <module>()
     66 
     67 if __name__ == ""__main__"":
---> 68     main()

<ipython-input-5-9d8332f50ddd> in main()
     62         input_fn=my_input_fn_eval, steps=5, throttle_secs=2)
     63 
---> 64     tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)
     65 
     66 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/training.py in train_and_evaluate(estimator, train_spec, eval_spec)
    419         '(with task id 0).  Given task id {}'.format(config.task_id))
    420 
--> 421   executor.run()
    422 
    423 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/training.py in run(self)
    492         config.task_type != run_config_lib.TaskType.EVALUATOR):
    493       logging.info('Running training and evaluation locally (non-distributed).')
--> 494       self.run_local()
    495       return
    496 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/training.py in run_local(self)
    624           input_fn=self._train_spec.input_fn,
    625           max_steps=self._train_spec.max_steps,
--> 626           hooks=train_hooks)
    627 
    628       # Final export signal: For any eval result with global_step >= train

/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in train(self, input_fn, hooks, steps, max_steps, saving_listeners)
    350 
    351     saving_listeners = _check_listeners_type(saving_listeners)
--> 352     loss = self._train_model(input_fn, hooks, saving_listeners)
    353     logging.info('Loss for final step: %s.', loss)
    354     return self

/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _train_model(self, input_fn, hooks, saving_listeners)
    889         loss = None
    890         while not mon_sess.should_stop():
--> 891           _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])
    892       return loss
    893 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py in run(self, fetches, feed_dict, options, run_metadata)
    544                           feed_dict=feed_dict,
    545                           options=options,
--> 546                           run_metadata=run_metadata)
    547 
    548   def run_step_fn(self, step_fn):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py in run(self, fetches, feed_dict, options, run_metadata)
   1020                               feed_dict=feed_dict,
   1021                               options=options,
-> 1022                               run_metadata=run_metadata)
   1023       except _PREEMPTION_ERRORS as e:
   1024         logging.info('An error was raised. This may be due to a preemption in '

/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py in run(self, *args, **kwargs)
   1111         raise six.reraise(*original_exc_info)
   1112       else:
-> 1113         raise six.reraise(*original_exc_info)
   1114 
   1115 

/usr/local/lib/python3.6/dist-packages/six.py in reraise(tp, value, tb)
    691             if value.__traceback__ is not tb:
    692                 raise value.with_traceback(tb)
--> 693             raise value
    694         finally:
    695             value = None

/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py in run(self, *args, **kwargs)
   1096   def run(self, *args, **kwargs):
   1097     try:
-> 1098       return self._sess.run(*args, **kwargs)
   1099     except _PREEMPTION_ERRORS:
   1100       raise

/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py in run(self, fetches, feed_dict, options, run_metadata)
   1168                                   feed_dict=feed_dict,
   1169                                   options=options,
-> 1170                                   run_metadata=run_metadata)
   1171 
   1172     for hook in self._hooks:

/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py in run(self, *args, **kwargs)
    948 
    949   def run(self, *args, **kwargs):
--> 950     return self._sess.run(*args, **kwargs)
    951 
    952   def run_step_fn(self, step_fn, raw_session, run_with_hooks):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)
    903     try:
    904       result = self._run(None, fetches, feed_dict, options_ptr,
--> 905                          run_metadata_ptr)
    906       if run_metadata:
    907         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
   1135     if final_fetches or final_targets or (handle and feed_dict_tensor):
   1136       results = self._do_run(handle, final_targets, final_fetches,
-> 1137                              feed_dict_tensor, options, run_metadata)
   1138     else:
   1139       results = []

/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
   1353     if handle is None:
   1354       return self._do_call(_run_fn, self._session, feeds, fetches, targets,
-> 1355                            options, run_metadata)
   1356     else:
   1357       return self._do_call(_prun_fn, self._session, handle, feeds, fetches)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
   1372         except KeyError:
   1373           pass
-> 1374       raise type(e)(node_def, op, message)
   1375 
   1376   def _extend_graph(self):

AlreadyExistsError: There appears to be a concurrent caching iterator running - cache lockfile already exists ('/tmp/mycache_train.lockfile'). If you are sure no other running TF computations are using this cache prefix, delete the lockfile and re-initialize the iterator. Lockfile contents: Created at: 1522942566
	 [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,?,3], [?,?,1]], output_types=[DT_FLOAT, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](OneShotIterator)]]

Caused by op 'IteratorGetNext', defined at:
  File ""/usr/lib/python3.6/runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""/usr/lib/python3.6/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py"", line 16, in <module>
    app.launch_new_instance()
  File ""/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py"", line 658, in launch_instance
    app.start()
  File ""/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py"", line 477, in start
    ioloop.IOLoop.instance().start()
  File ""/usr/local/lib/python3.6/dist-packages/zmq/eventloop/ioloop.py"", line 177, in start
    super(ZMQIOLoop, self).start()
  File ""/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py"", line 888, in start
    handler_func(fd_obj, events)
  File ""/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py"", line 277, in null_wrapper
    return fn(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py"", line 440, in _handle_events
    self._handle_recv()
  File ""/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py"", line 472, in _handle_recv
    self._run_callback(callback, msg)
  File ""/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py"", line 414, in _run_callback
    callback(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py"", line 277, in null_wrapper
    return fn(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py"", line 283, in dispatcher
    return self.dispatch_shell(stream, msg)
  File ""/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py"", line 235, in dispatch_shell
    handler(stream, idents, msg)
  File ""/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py"", line 399, in execute_request
    user_expressions, allow_stdin)
  File ""/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py"", line 196, in do_execute
    res = shell.run_cell(code, store_history=store_history, silent=silent)
  File ""/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py"", line 533, in run_cell
    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py"", line 2718, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py"", line 2822, in run_ast_nodes
    if self.run_code(code, result):
  File ""/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py"", line 2882, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-5-9d8332f50ddd>"", line 68, in <module>
    main()
  File ""<ipython-input-5-9d8332f50ddd>"", line 64, in main
    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/training.py"", line 421, in train_and_evaluate
    executor.run()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/training.py"", line 494, in run
    self.run_local()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/training.py"", line 626, in run_local
    hooks=train_hooks)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py"", line 352, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py"", line 809, in _train_model
    input_fn, model_fn_lib.ModeKeys.TRAIN))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py"", line 668, in _get_features_and_labels_from_input_fn
    result = self._call_input_fn(input_fn, mode)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py"", line 760, in _call_input_fn
    return input_fn(**kwargs)
  File ""<ipython-input-5-9d8332f50ddd>"", line 28, in my_input_fn_train
    value = ds.make_one_shot_iterator().get_next()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 330, in get_next
    name=name)), self._output_types,
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 866, in iterator_get_next
    output_shapes=output_shapes, name=name)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 3271, in create_op
    op_def=op_def)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 1650, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

AlreadyExistsError (see above for traceback): There appears to be a concurrent caching iterator running - cache lockfile already exists ('/tmp/mycache_train.lockfile'). If you are sure no other running TF computations are using this cache prefix, delete the lockfile and re-initialize the iterator. Lockfile contents: Created at: 1522942566
	 [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,?,3], [?,?,1]], output_types=[DT_FLOAT, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](OneShotIterator)]]

```
"
18265,tf.Print does not print anything in Spyder IPython console,"### System information
- Both Windows and Debian
- Anaconda3
- Python3.6

### Describe the problem
I tried this simple code, but nothing was printed! I use Anaconda3, python 3.6. Anyone can give a hint? Thanks.

### Source code / logs
import tensorflow as tf
sess = tf.InteractiveSession()
a = tf.constant([1.0, 3.0])
a = tf.Print(a, [a], message=""This is a: "")
b = tf.add(a, a).eval()

###I posted the problem here on stackoverflow:
https://stackoverflow.com/questions/49676232/tf-print-does-not-print-anything-in-spyder-ipython-console"
18264,tensorflow new feature request: tf.regex_match,"The new tf.regex_replace feature in tensorflow 1.7.0 works fine for modifying data and returning tf.string. However to filter a dataset, a separate method is needed in order to return tf.bool for use in tf.dataset.filter

I would like to be able to filter blank lines, or lines with only whitespace from a dataset, like:
dataset = dataset.filter(lambda line: tf.regex_match(line, ""^\s*$""))

Currently, I can do this using tf.py_func, see details: https://stackoverflow.com/questions/49654187/tensorflow-removing-blank-lines-in-dataset
"
18262,image Segmentation:why is the tensor value of the dimension resolved when reading tfrecord files is twice as much as is required to rescontruct the dimension？,"ERROR:tensorflow:Exception in QueueRunner: Input to reshape is a tensor with 26136 values, but the requested shape has 13068
	 [[Node: Reshape = Reshape[T=DT_UINT8, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](DecodeRaw, Reshape/shape)]]
ERROR:tensorflow:Exception in QueueRunner: Input to reshape is a tensor with 8712 values, but the requested shape has 4356
	 [[Node: Reshape_1 = Reshape[T=DT_UINT8, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](DecodeRaw_1, Reshape_1/shape)]]
ERROR:tensorflow:Exception in QueueRunner: Input to reshape is a tensor with 8712 values, but the requested shape has 4356
	 [[Node: Reshape_1 = Reshape[T=DT_UINT8, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](DecodeRaw_1, Reshape_1/shape)]]
ERROR:tensorflow:Exception in QueueRunner: Input to reshape is a tensor with 8712 values, but the requested shape has 4356
	 [[Node: Reshape_1 = Reshape[T=DT_UINT8, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](DecodeRaw_1, Reshape_1/shape)]]
ERROR:tensorflow:Exception in QueueRunner: Input to reshape is a tensor with 8712 values, but the requested shape has 4356
	 [[Node: Reshape_1 = Reshape[T=DT_UINT8, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](DecodeRaw_1, Reshape_1/shape)]]
ERROR:tensorflow:Exception in QueueRunner: Input to reshape is a tensor with 8712 values, but the requested shape has 4356
	 [[Node: Reshape_1 = Reshape[T=DT_UINT8, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](DecodeRaw_1, Reshape_1/shape)]]
ERROR:tensorflow:Exception in QueueRunner: Input to reshape is a tensor with 8712 values, but the requested shape has 4356
"
18261,How to set the truncation time series length parameter for RNN training in this example: tensorflow/tensorflow/contrib/timeseries/examples/lstm.py,"In the function of tf.contrib.timeseries.ARRegressor, we can set the input_window_size and output_window_size for building a time series forecasting model.
But in this example, we can only set the parameter of num_units of cell and num_features of input data for _LSTMModel，but we can not set the parameter of the truncation time series length in this model of TFTS.
"
18260,[BUG] [1.8] prefetch_to_device() doesn't work with eager Iterators,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: YES, Minimal (non-) working example can be seen below.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: pip install tf-nightly-gpu (05.04.2018)
- **TensorFlow version (use command below)**: 1.8.0.dev20180329
- **Python version**: Python 3.6.3
- **Bazel version (if compiling from source)**: --
- **GCC/Compiler version (if compiling from source)**: --
- **CUDA/cuDNN version**: CUDA 9, CuDNN 7.1
- **GPU model and memory**: 2x GTX 1080 8GB
- **Exact command to reproduce**: 
```python
import tensorflow as tf
contrib_data=tf.contrib.data
data=tf.data
import tensorflow.contrib.eager as tfe
tf.enable_eager_execution()
ds=data.Dataset.range(50)
ds=ds.apply(contrib_data.prefetch_to_device(""/gpu:1""))
it=tfe.Iterator(ds)
```
### Describe the problem
Even when applying prefetch_to_device as the last operation, it throws the following error:

### logs
```
WARNING:tensorflow:From C:\Users\PHANTOM\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\contrib\learn\python\learn\datasets\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Use the retry module or similar alternatives.
2018-04-05 14:40:24.616506: I C:\tf_jenkins\workspace\tf-nightly-windows\M\windows-gpu\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2018-04-05 14:40:24.831563: I C:\tf_jenkins\workspace\tf-nightly-windows\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1355] Found device 0 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.835
pciBusID: 0000:01:00.0
totalMemory: 8.00GiB freeMemory: 6.52GiB
2018-04-05 14:40:24.883091: I C:\tf_jenkins\workspace\tf-nightly-windows\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1355] Found device 1 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.835
pciBusID: 0000:02:00.0
totalMemory: 8.00GiB freeMemory: 6.52GiB
2018-04-05 14:40:24.883562: I C:\tf_jenkins\workspace\tf-nightly-windows\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1434] Adding visible gpu devices: 0, 1
2018-04-05 14:40:25.804203: I C:\tf_jenkins\workspace\tf-nightly-windows\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:922] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-05 14:40:25.804487: I C:\tf_jenkins\workspace\tf-nightly-windows\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:928]      0 1 
2018-04-05 14:40:25.804689: I C:\tf_jenkins\workspace\tf-nightly-windows\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:941] 0:   N N 
2018-04-05 14:40:25.804889: I C:\tf_jenkins\workspace\tf-nightly-windows\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:941] 1:   N N 
2018-04-05 14:40:25.805180: I C:\tf_jenkins\workspace\tf-nightly-windows\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1052] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6303 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)
2018-04-05 14:40:26.469466: I C:\tf_jenkins\workspace\tf-nightly-windows\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1052] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 6303 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080, pci bus id: 0000:02:00.0, compute capability: 6.1)
Traceback (most recent call last):
  File ""MWE.py"", line 17, in <module>
    it=tfe.Iterator(ds)
  File ""C:\Users\PHANTOM\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\contrib\eager\python\datasets.py"", line 76, in __init__
    super(Iterator, self).__init__(dataset)
  File ""C:\Users\PHANTOM\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\data\ops\iterator_ops.py"", line 463, in __init__
    ds_variant = dataset._as_variant_tensor()  # pylint: disable=protected-access
  File ""C:\Users\PHANTOM\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\contrib\data\python\ops\prefetching_ops.py"", line 154, in _as_variant_tensor
    raise NotImplementedError(""`prefetch_to_device()` must be the last ""
NotImplementedError: `prefetch_to_device()` must be the last transformation in a dataset pipeline.
```"
18258,Feature Request: Porting tensorflow to onion omega 2+,"I have been working with onion omega 2+ an iot computer with following specifications :
Operating system-OpenWrt
System-on-chip used MediaTek MT7688
CPU-580 MHz 32-bit computing Single-core MIPS 24KEc
Memory-128 MB for Omega2 Plus
Storage-32 MB and a MicroSDHC slot
Graphics-No graphic
Power-0.6 Watts

I would like to run inception V3 model but I am unable to install tensorflow on omega 2+. Is it possible to run tensorflow or tensorflow lite on omega 2+????"
18257,tf.while example is not working in eager mode,"
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes, see below
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: pip
- **TensorFlow version (use command below)**: 1.7, release
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: NA
- **GCC/Compiler version (if compiling from source)**: NA
- **CUDA/cuDNN version**: 9.0 / 7.0
- **GPU model and memory**:  GTX TITAN, 6GB
- **Exact command to reproduce**: see below

### Describe the problem

`tf.while` example is not working in eager mode

### Source code / logs

Here is the code 
```python
import tensorflow as tf
tf.enable_eager_execution() # the only line added to the example

i = tf.constant(0)
c = lambda i: tf.less(i, 10)
b = lambda i: tf.add(i, 1)
r = tf.while_loop(c, b, [i])
```

result:
TypeError: Cannot iterate over a scalar tensor.

### Reason

```python
b = lambda i: tf.add(i, 1)       # original
b = lambda i: (tf.add(i, 1), )   # fixed, working 
```

- Body code (`b`) returns a single scalar, which code later tries to unpack.
- Eager code doesn't support auto-wrapping single item to tuple

Possible solutions:
- require body function to always return tuple
- always check if body output is a single variable"
18256,use lib static tensorflow-core.a error when build,"undefined reference to 'google::protobuf::internal::fixed_address_empty_string' ....
i think my program can't find lib protobuf to used. Even I have already lib protbuf.a and protobuf.so. Before i use lib tensorflow-core.a I have used lib dynamic: tensorflow_cc.so and lib tensorflow_framework.so i build with bazel, and lib protbuf.so include. I don't know ho to fix this error. Can anyone help me?
#issue using static lib tensorflow"
18255,"InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'x_1' with dtype float and shape [?,300,300,3] 	 [[Node: x_1 = Placeholder[dtype=DT_FLOAT, shape=[?,300,300,3], _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]","Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
18254,can tensorflow/compiler/aot/libruntime.so be renamed?,"### Describe the problem
linking -lruntime is a bit too generic (and prone to conflicts) for a large project

for instance -lxla_compiled_cpu_function
for
/tensorflow/compiler/tf2xla/libxla_compiled_cpu_function.so
is already more acceptable

In general would be useful for any library required to be linked in user applications to have a more descriptive name that associate it to tensorflow"
18253,undefined symbol: _ZN6google8protobuf8internal26fixed_address_empty_stringB5cxx11E error for building r1.7 from source Ubuntu 16.10,"bazel-out/host/bin/tensorflow/cc/ops/remote_fused_graph_ops_gen_cc: symbol lookup error: bazel-out/host/bin/tensorflow/cc/ops/remote_fused_graph_ops_gen_cc: undefined symbol: _ZN6google8protobuf8internal26fixed_address_empty_stringB5cxx11E


mgyong@mgyong-Precision-5510:/tmp/tensorflow$ bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package
..........
WARNING: /home/mgyong/.cache/bazel/_bazel_mgyong/e5cce820cc082410b4fcc604db349066/external/protobuf_archive/WORKSPACE:1: Workspace name in /home/mgyong/.cache/bazel/_bazel_mgyong/e5cce820cc082410b4fcc604db349066/external/protobuf_archive/WORKSPACE (@com_google_protobuf) does not match the name given in the repository's definition (@protobuf_archive); this will cause a build error in future versions
WARNING: /home/mgyong/.cache/bazel/_bazel_mgyong/e5cce820cc082410b4fcc604db349066/external/grpc/WORKSPACE:1: Workspace name in /home/mgyong/.cache/bazel/_bazel_mgyong/e5cce820cc082410b4fcc604db349066/external/grpc/WORKSPACE (@com_github_grpc_grpc) does not match the name given in the repository's definition (@grpc); this will cause a build error in future versions
WARNING: /tmp/tensorflow/tensorflow/core/BUILD:1955:1: in includes attribute of cc_library rule //tensorflow/core:framework_headers_lib: '../../external/nsync/public' resolves to 'external/nsync/public' not below the relative path of its package 'tensorflow/core'. This will be an error in the future. Since this rule was created by the macro 'cc_header_only_library', the error might have been caused by the macro implementation in /tmp/tensorflow/tensorflow/tensorflow.bzl:1179:30
WARNING: /tmp/tensorflow/tensorflow/core/BUILD:1955:1: in includes attribute of cc_library rule //tensorflow/core:framework_headers_lib: '../../external/nsync/public' resolves to 'external/nsync/public' not below the relative path of its package 'tensorflow/core'. This will be an error in the future. Since this rule was created by the macro 'cc_header_only_library', the error might have been caused by the macro implementation in /tmp/tensorflow/tensorflow/tensorflow.bzl:1179:30
WARNING: /tmp/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': No longer supported. Switch to SavedModel immediately.
WARNING: /tmp/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': No longer supported. Switch to SavedModel immediately.
INFO: Analysed target //tensorflow/tools/pip_package:build_pip_package (260 packages loaded).
INFO: Found 1 target...
INFO: From Compiling external/snappy/snappy-sinksource.cc [for host]:
cc1plus: warning: command line option '-Wno-implicit-function-declaration' is valid for C/ObjC but not for C++
INFO: From Compiling external/snappy/snappy-c.cc [for host]:
cc1plus: warning: command line option '-Wno-implicit-function-declaration' is valid for C/ObjC but not for C++
INFO: From Compiling external/snappy/snappy-stubs-internal.cc [for host]:
cc1plus: warning: command line option '-Wno-implicit-function-declaration' is valid for C/ObjC but not for C++
INFO: From Compiling external/snappy/snappy.cc [for host]:
cc1plus: warning: command line option '-Wno-implicit-function-declaration' is valid for C/ObjC but not for C++
external/snappy/snappy.cc: In member function 'void snappy::SnappySinkAllocator::Flush(size_t)':
external/snappy/snappy.cc:1403:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
     for (int i = 0; i < blocks_.size(); ++i) {
                     ~~^~~~~~~~~~~~~~~~
In file included from external/snappy/snappy-internal.h:34:0,
                 from external/snappy/snappy.cc:30:
external/snappy/snappy.cc: In instantiation of 'bool snappy::SnappyScatteredWriter<Allocator>::AppendFromSelf(size_t, size_t) [with Allocator = snappy::SnappySinkAllocator; size_t = long unsigned int]':
external/snappy/snappy.cc:715:13:   required from 'void snappy::SnappyDecompressor::DecompressAllTags(Writer*) [with Writer = snappy::SnappyScatteredWriter<snappy::SnappySinkAllocator>]'
external/snappy/snappy.cc:799:3:   required from 'bool snappy::InternalUncompressAllTags(snappy::SnappyDecompressor*, Writer*, snappy::uint32) [with Writer = snappy::SnappyScatteredWriter<snappy::SnappySinkAllocator>; snappy::uint32 = unsigned int]'
external/snappy/snappy.cc:1460:78:   required from here
external/snappy/snappy.cc:1316:34: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
     if (PREDICT_TRUE(offset - 1u < op_ptr_ - op_base_ && op_end <= op_limit_)) {
                      ~~~~~~~~~~~~^~~~~~~~~~~~~
external/snappy/snappy-stubs-internal.h:80:25: note: in definition of macro 'PREDICT_TRUE'
 #define PREDICT_TRUE(x) x
                         ^
INFO: From ProtoCompile tensorflow/core/grappler/costs/op_performance_data.pb.cc:
bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.
bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/debug/debugger_event_metadata.pb.cc:
bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/python/framework/cpp_shape_inference.pb.cc:
bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.
bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/protobuf/worker.pb.cc:
bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.
bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/protobuf/master.pb.cc:
bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.
bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/contrib/lite/toco/types.pb.cc:
bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/contrib/lite/toco/toco_flags.pb.cc:
bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.
bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/contrib/lite/toco/model_flags.pb.cc:
bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.
bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/profiler/profile.pb.cc:
bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.
bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/contrib/cloud/kernels/bigquery_table_partition.pb.cc:
bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/debug/debug_service.pb.cc:
bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.
bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.
bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.
bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.
bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.
INFO: From Compiling tensorflow/core/platform/stacktrace_handler.cc [for host]:
tensorflow/core/platform/stacktrace_handler.cc: In function 'void tensorflow::testing::InstallStacktraceHandler()':
tensorflow/core/platform/stacktrace_handler.cc:118:51: warning: ignoring return value of 'ssize_t write(int, const void*, size_t)', declared with attribute warn_unused_result [-Wunused-result]
       (void)write(STDERR_FILENO, buf, strlen(buf));
                                                   ^
tensorflow/core/platform/stacktrace_handler.cc:125:51: warning: ignoring return value of 'ssize_t write(int, const void*, size_t)', declared with attribute warn_unused_result [-Wunused-result]
       (void)write(STDERR_FILENO, buf, strlen(buf));
                                                   ^
tensorflow/core/platform/stacktrace_handler.cc: In function 'void tensorflow::testing::StacktraceHandler(int, siginfo_t*, void*)':
tensorflow/core/platform/stacktrace_handler.cc:80:47: warning: ignoring return value of 'ssize_t write(int, const void*, size_t)', declared with attribute warn_unused_result [-Wunused-result]
   (void)write(STDERR_FILENO, buf, strlen(buf));
                                               ^
tensorflow/core/platform/stacktrace_handler.cc:90:70: warning: ignoring return value of 'ssize_t write(int, const void*, size_t)', declared with attribute warn_unused_result [-Wunused-result]
   (void)write(STDERR_FILENO, stacktrace.c_str(), stacktrace.length());
                                                                      ^
tensorflow/core/platform/stacktrace_handler.cc: In function 'void tensorflow::testing::SafePrintStackTrace()':
tensorflow/core/platform/stacktrace_handler.cc:47:59: warning: ignoring return value of 'ssize_t write(int, const void*, size_t)', declared with attribute warn_unused_result [-Wunused-result]
   (void)write(STDERR_FILENO, begin_msg, strlen(begin_msg));
                                                           ^
tensorflow/core/platform/stacktrace_handler.cc:58:55: warning: ignoring return value of 'ssize_t write(int, const void*, size_t)', declared with attribute warn_unused_result [-Wunused-result]
   (void)write(STDERR_FILENO, end_msg, strlen(end_msg));
                                                       ^
INFO: From Compiling tensorflow/stream_executor/stream_executor_pimpl.cc [for host]:
In file included from ./tensorflow/core/platform/default/logging.h:24:0,
                 from ./tensorflow/core/platform/logging.h:25,
                 from ./tensorflow/core/lib/core/status.h:25,
                 from ./tensorflow/stream_executor/lib/status.h:21,
                 from ./tensorflow/stream_executor/stream_executor_pimpl.h:25,
                 from tensorflow/stream_executor/stream_executor_pimpl.cc:20:
./tensorflow/core/platform/default/logging.h: In instantiation of 'std::__cxx11::string* tensorflow::internal::Check_EQImpl(const T1&, const T2&, const char*) [with T1 = int; T2 = long long unsigned int; std::__cxx11::string = std::__cxx11::basic_string<char>]':
tensorflow/stream_executor/stream_executor_pimpl.cc:634:3:   required from here
./tensorflow/core/platform/default/logging.h:230:25: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
                         ==)  // Compilation error with CHECK_EQ(NULL, x)?
                          
./tensorflow/core/platform/macros.h:79:29: note: in definition of macro 'TF_PREDICT_TRUE'
 #define TF_PREDICT_TRUE(x) (x)
                             ^
./tensorflow/core/platform/default/logging.h:229:1: note: in expansion of macro 'TF_DEFINE_CHECK_OP_IMPL'
 TF_DEFINE_CHECK_OP_IMPL(Check_EQ,
 ^~~~~~~~~~~~~~~~~~~~~~~
INFO: From Compiling tensorflow/core/kernels/initializable_lookup_table.cc [for host]:
In file included from ./tensorflow/core/platform/default/logging.h:24:0,
                 from ./tensorflow/core/platform/logging.h:25,
                 from ./tensorflow/core/lib/core/status.h:25,
                 from ./tensorflow/core/lib/core/errors.h:19,
                 from ./tensorflow/core/framework/tensor_shape.h:23,
                 from ./tensorflow/core/framework/partial_tensor_shape.h:20,
                 from ./tensorflow/core/framework/attr_value_util.h:23,
                 from ./tensorflow/core/framework/node_def_util.h:23,
                 from ./tensorflow/core/framework/shape_inference.h:20,
                 from ./tensorflow/core/framework/common_shape_fns.h:20,
                 from ./tensorflow/core/framework/resource_mgr.h:24,
                 from ./tensorflow/core/framework/lookup_interface.h:19,
                 from ./tensorflow/core/kernels/initializable_lookup_table.h:19,
                 from tensorflow/core/kernels/initializable_lookup_table.cc:16:
./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetTensorDim(tensorflow::gtl::ArraySlice<T>, tensorflow::TensorFormat, char) [with T = long long int]':
./tensorflow/core/util/tensor_format.h:372:47:   required from here
./tensorflow/core/util/tensor_format.h:340:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
   CHECK(index >= 0 && index < dimension_attributes.size())
                              
./tensorflow/core/platform/macros.h:78:30: note: in definition of macro 'TF_PREDICT_FALSE'
 #define TF_PREDICT_FALSE(x) (x)
                              ^
./tensorflow/core/util/tensor_format.h:340:3: note: in expansion of macro 'CHECK'
   CHECK(index >= 0 && index < dimension_attributes.size())
   ^
./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetFilterDim(tensorflow::gtl::ArraySlice<T>, tensorflow::FilterTensorFormat, char) [with T = long long int]':
./tensorflow/core/util/tensor_format.h:381:54:   required from here
./tensorflow/core/util/tensor_format.h:355:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
   CHECK(index >= 0 && index < dimension_attribute.size())
                              
./tensorflow/core/platform/macros.h:78:30: note: in definition of macro 'TF_PREDICT_FALSE'
 #define TF_PREDICT_FALSE(x) (x)
                              ^
./tensorflow/core/util/tensor_format.h:355:3: note: in expansion of macro 'CHECK'
   CHECK(index >= 0 && index < dimension_attribute.size())
   ^
INFO: From Compiling tensorflow/core/kernels/lookup_util.cc [for host]:
tensorflow/core/kernels/lookup_util.cc: In member function 'virtual void tensorflow::lookup::{anonymous}::TextFileLineIterator::Next()':
tensorflow/core/kernels/lookup_util.cc:134:46: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
       if (std::max(key_index_, value_index_) >= tokens.size()) {
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~
In file included from ./tensorflow/core/platform/default/logging.h:24:0,
                 from ./tensorflow/core/platform/logging.h:25,
                 from ./tensorflow/core/lib/core/status.h:25,
                 from ./tensorflow/core/lib/core/errors.h:19,
                 from ./tensorflow/core/framework/tensor_shape.h:23,
                 from ./tensorflow/core/framework/partial_tensor_shape.h:20,
                 from ./tensorflow/core/framework/attr_value_util.h:23,
                 from ./tensorflow/core/framework/node_def_util.h:23,
                 from ./tensorflow/core/framework/shape_inference.h:20,
                 from ./tensorflow/core/framework/common_shape_fns.h:20,
                 from ./tensorflow/core/framework/resource_mgr.h:24,
                 from ./tensorflow/core/framework/lookup_interface.h:19,
                 from ./tensorflow/core/kernels/lookup_util.h:19,
                 from tensorflow/core/kernels/lookup_util.cc:16:
./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetTensorDim(tensorflow::gtl::ArraySlice<T>, tensorflow::TensorFormat, char) [with T = long long int]':
./tensorflow/core/util/tensor_format.h:372:47:   required from here
./tensorflow/core/util/tensor_format.h:340:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
   CHECK(index >= 0 && index < dimension_attributes.size())
                              
./tensorflow/core/platform/macros.h:78:30: note: in definition of macro 'TF_PREDICT_FALSE'
 #define TF_PREDICT_FALSE(x) (x)
                              ^
./tensorflow/core/util/tensor_format.h:340:3: note: in expansion of macro 'CHECK'
   CHECK(index >= 0 && index < dimension_attributes.size())
   ^
./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetFilterDim(tensorflow::gtl::ArraySlice<T>, tensorflow::FilterTensorFormat, char) [with T = long long int]':
./tensorflow/core/util/tensor_format.h:381:54:   required from here
./tensorflow/core/util/tensor_format.h:355:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
   CHECK(index >= 0 && index < dimension_attribute.size())
                              
./tensorflow/core/platform/macros.h:78:30: note: in definition of macro 'TF_PREDICT_FALSE'
 #define TF_PREDICT_FALSE(x) (x)
                              ^
./tensorflow/core/util/tensor_format.h:355:3: note: in expansion of macro 'CHECK'
   CHECK(index >= 0 && index < dimension_attribute.size())
   ^
INFO: From Compiling tensorflow/core/grappler/utils.cc [for host]:
tensorflow/core/grappler/utils.cc: In function 'void tensorflow::grappler::PermuteNodesInPlace(tensorflow::GraphDef*, std::vector<int>*, bool)':
tensorflow/core/grappler/utils.cc:319:14: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
     while (n != (*permutation)[n]) {
               
tensorflow/core/grappler/utils.cc: In member function 'std::__cxx11::string tensorflow::grappler::SimpleGraphView::PrintToString() const':
tensorflow/core/grappler/utils.cc:422:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
     for (int j = 0; j < outputs(i).size(); ++j) {
                     ~~^~~~~~~~~~~~~~~~~~~
INFO: From Compiling tensorflow/stream_executor/stream.cc [for host]:
tensorflow/stream_executor/stream.cc: In function 'std::__cxx11::string perftools::gputools::{anonymous}::ToVlogString(perftools::gputools::dnn::DataType)':
tensorflow/stream_executor/stream.cc:184:1: warning: control reaches end of non-void function [-Wreturn-type]
 }
 ^
INFO: From Compiling tensorflow/core/protobuf/config.pb_text.cc [for host]:
bazel-out/host/genfiles/tensorflow/core/protobuf/config.pb_text.cc: In function 'bool tensorflow::internal::ProtoParseFromScanner(tensorflow::strings::Scanner*, bool, bool, tensorflow::ConfigProto*)':
bazel-out/host/genfiles/tensorflow/core/protobuf/config.pb_text.cc:826:23: warning: 'map_value' may be used uninitialized in this function [-Wmaybe-uninitialized]
       (*map)[map_key] = map_value;
                        
bazel-out/host/genfiles/tensorflow/core/protobuf/config.pb_text.cc:817:9: note: 'map_value' was declared here
   int32 map_value;
         ^~~~~~~~~
INFO: From Compiling tensorflow/core/common_runtime/gpu/process_state.cc [for host]:
tensorflow/core/common_runtime/gpu/process_state.cc:62:6: warning: 'bool tensorflow::{anonymous}::useCudaMemoryGuardAllocator()' defined but not used [-Wunused-function]
 bool useCudaMemoryGuardAllocator() {
      ^~~~~~~~~~~~~~~~~~~~~~~~~~~
tensorflow/core/common_runtime/gpu/process_state.cc:56:6: warning: 'bool tensorflow::{anonymous}::useCudaMallocAllocator()' defined but not used [-Wunused-function]
 bool useCudaMallocAllocator() {
      ^~~~~~~~~~~~~~~~~~~~~~
INFO: From ProtoCompile tensorflow/core/example/example.pb.cc:
bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.
INFO: From Compiling tensorflow/python/eager/python_eager_op_gen.cc [for host]:
tensorflow/python/eager/python_eager_op_gen.cc: In function 'std::__cxx11::string tensorflow::{anonymous}::VectorToTuple(const std::vector<std::__cxx11::basic_string<char> >&)':
tensorflow/python/eager/python_eager_op_gen.cc:65:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
   for (int i = 0; i < l.size(); ++i) {
                   ~~^~~~~~~~~~
tensorflow/python/eager/python_eager_op_gen.cc: In function 'void tensorflow::{anonymous}::Unflatten(const string&, const std::vector<std::__cxx11::basic_string<char> >&, const string&, std::__cxx11::string*)':
tensorflow/python/eager/python_eager_op_gen.cc:77:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
   for (int i = 0; i < output_sizes.size(); ++i) {
                   ~~^~~~~~~~~~~~~~~~~~~~~
tensorflow/python/eager/python_eager_op_gen.cc:81:17: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
       if (i + 1 < output_sizes.size()) {
           ~~~~~~^~~~~~~~~~~~~~~~~~~~~
tensorflow/python/eager/python_eager_op_gen.cc: In member function 'virtual std::__cxx11::string tensorflow::{anonymous}::GenEagerPythonOp::Code()':
tensorflow/python/eager/python_eager_op_gen.cc:302:44: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
   for (int i = op_def_.input_arg_size(); i < params_no_default_.size(); ++i) {
                                          ~~^~~~~~~~~~~~~~~~~~~~~~~~~~~
tensorflow/python/eager/python_eager_op_gen.cc:330:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
   for (int i = 0; i < attrs_.size(); ++i) {
                   ~~^~~~~~~~~~~~~~~
tensorflow/python/eager/python_eager_op_gen.cc: In member function 'bool tensorflow::{anonymous}::GenEagerPythonOp::GetEagerFunctionSetup(const string&, std::__cxx11::string*)':
tensorflow/python/eager/python_eager_op_gen.cc:480:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
   for (int i = 0; i < attrs_.size(); ++i) {
                   ~~^~~~~~~~~~~~~~~
INFO: From Compiling tensorflow/python/framework/python_op_gen.cc [for host]:
tensorflow/python/framework/python_op_gen.cc: In member function 'virtual std::__cxx11::string tensorflow::python_op_gen_internal::GenPythonOp::Code()':
tensorflow/python/framework/python_op_gen.cc:548:44: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
   for (int i = op_def_.input_arg_size(); i < params_no_default.size(); ++i) {
                                          ~~^~~~~~~~~~~~~~~~~~~~~~~~~~
tensorflow/python/framework/python_op_gen.cc:551:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
   for (int i = 0; i < params_with_default.size(); ++i) {
                   ~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~
ERROR: /tmp/tensorflow/tensorflow/cc/BUILD:510:1: Executing genrule //tensorflow/cc:remote_fused_graph_ops_genrule failed (Exit 127)
bazel-out/host/bin/tensorflow/cc/ops/remote_fused_graph_ops_gen_cc: symbol lookup error: bazel-out/host/bin/tensorflow/cc/ops/remote_fused_graph_ops_gen_cc: undefined symbol: _ZN6google8protobuf8internal26fixed_address_empty_stringB5cxx11E
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 391.219s, Critical Path: 57.13s
FAILED: Build did NOT complete successfully
"
18252,Empty tensorflow r1.7 api after virtualenv install of tensorflow r1.7 ,"Ubuntu 16.10 using below commands for tensorflow r1.7
########
virtualenv --system-site-packages -p python3 tensorflow
pip3 install tensorflow
########
pip3 install --upgrade tensorflow
Collecting tensorflow
  Using cached tensorflow-1.7.0-cp36-cp36m-manylinux1_x86_64.whl
Collecting tensorboard<1.8.0,>=1.7.0 (from tensorflow)
  Using cached tensorboard-1.7.0-py3-none-any.whl
Requirement not upgraded as not directly required: six>=1.10.0 in /usr/local/lib/python3.6/site-packages (from tensorflow) (1.11.0)
Requirement not upgraded as not directly required: wheel>=0.26 in ./tensorflow/lib/python3.6/site-packages (from tensorflow) (0.31.0)
Collecting gast>=0.2.0 (from tensorflow)
Collecting grpcio>=1.8.6 (from tensorflow)
  Using cached grpcio-1.10.0-cp36-cp36m-manylinux1_x86_64.whl
Collecting astor>=0.6.0 (from tensorflow)
  Using cached astor-0.6.2-py2.py3-none-any.whl
Requirement not upgraded as not directly required: absl-py>=0.1.6 in /usr/local/lib/python3.6/site-packages (from tensorflow) (0.1.10)
Requirement not upgraded as not directly required: numpy>=1.13.3 in /usr/local/lib/python3.6/site-packages (from tensorflow) (1.14.0)
Requirement not upgraded as not directly required: protobuf>=3.4.0 in /usr/local/lib/python3.6/site-packages (from tensorflow) (3.5.1)
Collecting termcolor>=1.1.0 (from tensorflow)
Requirement not upgraded as not directly required: html5lib==0.9999999 in /usr/local/lib/python3.6/site-packages (from tensorboard<1.8.0,>=1.7.0->tensorflow) (0.9999999)
Requirement not upgraded as not directly required: werkzeug>=0.11.10 in /usr/local/lib/python3.6/site-packages (from tensorboard<1.8.0,>=1.7.0->tensorflow) (0.14.1)
Requirement not upgraded as not directly required: bleach==1.5.0 in /usr/local/lib/python3.6/site-packages (from tensorboard<1.8.0,>=1.7.0->tensorflow) (1.5.0)
Requirement not upgraded as not directly required: markdown>=2.6.8 in /usr/local/lib/python3.6/site-packages (from tensorboard<1.8.0,>=1.7.0->tensorflow) (2.6.11)
Requirement not upgraded as not directly required: setuptools in ./tensorflow/lib/python3.6/site-packages (from protobuf>=3.4.0->tensorflow) (39.0.1)
tensorboard 1.7.0 requires bleach==1.5.0, which is not installed.
tensorboard 1.7.0 requires html5lib==0.9999999, which is not installed.
tensorboard 1.7.0 requires markdown>=2.6.8, which is not installed.
tensorboard 1.7.0 requires numpy>=1.12.0, which is not installed.
tensorboard 1.7.0 requires protobuf>=3.4.0, which is not installed.
tensorboard 1.7.0 requires six>=1.10.0, which is not installed.
tensorboard 1.7.0 requires werkzeug>=0.11.10, which is not installed.
grpcio 1.10.0 requires protobuf>=3.5.0.post1, which is not installed.
grpcio 1.10.0 requires six>=1.5.2, which is not installed.
tensorflow 1.7.0 requires absl-py>=0.1.6, which is not installed.
tensorflow 1.7.0 requires numpy>=1.13.3, which is not installed.
tensorflow 1.7.0 requires protobuf>=3.4.0, which is not installed.
tensorflow 1.7.0 requires six>=1.10.0, which is not installed.
Installing collected packages: tensorboard, gast, grpcio, astor, termcolor, tensorflow
Successfully installed astor-0.6.2 gast-0.2.0 grpcio-1.10.0 tensorboard-1.7.0 tensorflow-1.7.0 termcolor-1.1.0

##########
When i tried to verify tensorflow r1.7 installed properly, i got an empty api
Python 3.6.4 (default, Jan 28 2018, 16:44:18) 
[GCC 6.2.0 20161005] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
>>> hello = tf.constant('Hello, TensorFlow!')
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
AttributeError: module 'tensorflow' has no attribute 'constant'
"
18250,WebP support,"### Describe the problem
It would be nice if tensorflow supports webp image files.
https://developers.google.com/speed/webp/
Our image dataset gets 2-3 times smaller when using webp compared to png.
"
18248,"ValueError: Initializer for variable cudnn_gru/opaque_kernel/ is from inside a control-flow construct, such as a loop or conditional. When creating a variable inside a loop or conditional, use a lambda as the initializer.","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution**: Ubuntu 16.04
- **TensorFlow installed from**: Binary
- **TensorFlow version**: 1.5.0
- **Python version**: 3.5.2
- **Bazel version**: Not compiled from source
- **GCC/Compiler version**: Not compiled from source
- **CUDA/cuDNN version**: 9.0/7
- **GPU model and memory**: NVIDIA GTX 1080 8GB x 4 
- **Exact command to reproduce**: Code as below

I have been trying to use a for-loop with `tf.cond` applied on `cudnn_gru` to run multiple times on inputs, and the minimum error reproducible code is as below:
```
import tensorflow as tf
max_para = tf.placeholder(tf.int32)
num_units = 150
inputs = tf.placeholder(tf.float32,shape=[15,8,num_units])
class cudnn_gru:
	def __init__(self):
		self.gru_fw = tf.contrib.cudnn_rnn.CudnnGRU(1, num_units, 
						kernel_initializer=tf.random_normal_initializer(stddev=0.1))
	def __call__(self,inputs):
		out_fw, _ = self.gru_fw(inputs)

class cudnn_gru2:
	def __init__(self):
		self.gru_fw = tf.contrib.cudnn_rnn.CudnnGRU(1, num_units-1, 
						kernel_initializer=tf.random_normal_initializer(stddev=0.1))
	def __call__(self,inputs):
		out_fw, _ = self.gru_fw(inputs)

def get_output():
	gru = cudnn_gru()
	out = gru(inputs)
	return tf.constant(1)

def get_output2():
	gru = cudnn_gru2()
	out = gru(inputs)
	return tf.constant(2)

for i in range(3):
	i_ = tf.constant(i)
	out = tf.cond(i_<max_para,get_output,get_output2)
```

The error stacktrace is as follows:

```
Traceback (most recent call last):
  File ""temp.py"", line 31, in <module>
    out = tf.cond(i_<max_para,get_output,get_output2)
  File ""/home/search/snetP/virtual_bhavya/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py"", line 316, in new_func
    return func(*args, **kwargs)
  File ""/home/search/snetP/virtual_bhavya/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 1894, in cond
    orig_res_t, res_t = context_t.BuildCondBranch(true_fn)
  File ""/home/search/snetP/virtual_bhavya/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 1752, in BuildCondBranch
    original_result = fn()
  File ""temp.py"", line 21, in get_output
    out = gru(inputs)
  File ""temp.py"", line 10, in __call__
    out_fw, _ = self.gru_fw(inputs)
  File ""/home/search/snetP/virtual_bhavya/lib/python3.5/site-packages/tensorflow/python/layers/base.py"", line 636, in __call__
    self.build(input_shapes)
  File ""/home/search/snetP/virtual_bhavya/lib/python3.5/site-packages/tensorflow/contrib/cudnn_rnn/python/layers/cudnn_rnn.py"", line 357, in build
    ""opaque_kernel"", initializer=opaque_params_t, validate_shape=False)
  File ""/home/search/snetP/virtual_bhavya/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py"", line 1262, in get_variable
    constraint=constraint)
  File ""/home/search/snetP/virtual_bhavya/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py"", line 1097, in get_variable
    constraint=constraint)
  File ""/home/search/snetP/virtual_bhavya/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py"", line 427, in get_variable
    return custom_getter(**custom_getter_kwargs)
  File ""/home/search/snetP/virtual_bhavya/lib/python3.5/site-packages/tensorflow/contrib/cudnn_rnn/python/layers/cudnn_rnn.py"", line 290, in _update_trainable_weights
    variable = getter(*args, **kwargs)
  File ""/home/search/snetP/virtual_bhavya/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py"", line 404, in _true_getter
    use_resource=use_resource, constraint=constraint)
  File ""/home/search/snetP/virtual_bhavya/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py"", line 806, in _get_single_variable
    constraint=constraint)
  File ""/home/search/snetP/virtual_bhavya/lib/python3.5/site-packages/tensorflow/python/ops/variables.py"", line 229, in __init__
    constraint=constraint)
  File ""/home/search/snetP/virtual_bhavya/lib/python3.5/site-packages/tensorflow/python/ops/variables.py"", line 342, in _init_from_args
    ""initializer."" % name)
ValueError: Initializer for variable cudnn_gru/opaque_kernel/ is from inside a control-flow construct, such as a loop or conditional. When creating a variable inside a loop or conditional, use a lambda as the initializer.
```

How can I achieve this without causing compilation error during model building?"
18247,Feature request: ability to pass training_hooks and others through keras.estimator.model_to_estimator,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: I'm trying to
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: n/a
- **TensorFlow installed from (source or binary)**: pip
- **TensorFlow version (use command below)**: n/a
- **Python version**: n/a
- **Bazel version (if compiling from source)**: n/a
- **GCC/Compiler version (if compiling from source)**: n/a
- **CUDA/cuDNN version**: n/a
- **GPU model and memory**: n/a 
- **Exact command to reproduce**: n/a

### Describe the problem

When I go to create an Estimator from a Keras model, I'm unable to pass training hooks, evaluation hooks, and other fun things (like scaffolds) since the `_create_keras_model_fn` call doesn't take any of that stuff in. 

Could it simply just take these as arbitrary `**kwargs` and pass them through to the `EstimatorSpec` initializer?

### Source code / logs

Here's the relevant code: https://github.com/tensorflow/tensorflow/blob/r1.7/tensorflow/python/keras/_impl/keras/estimator.py#L364

Thanks!"
18246,RecurssionError in params parameter to Estimator,
18245,spatial sparse conv  layer,"### System information
**- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):**
Yes
**- OS Platform and Distribution (e.g., Linux Ubuntu 16.04)*:**
Ubuntu 14.04
**- TensorFlow installed from (source or binary)*:**
binary
**- TensorFlow version (use command below)*:**
1.4.1
**- Python version:** 
2.7
**- Bazel version (if compiling from source):**  N/A
**- GCC/Compiler version (if compiling from source):**  N/A
**- CUDA/cuDNN version:**
8.0
**- GPU model and memory:**
K40, 12 GB
**- Exact command to reproduce:** N/A
 
### Describe the problem

I found out that Tensorflow does not support a convolution layer with sparse kernels, is there any plan to support it?

Thanks.
"
18243,TensorFlow verbose logging is too verbose even at level 1,"Hello,

This is more of a feature request than an issue. Currently there is no convention on verbose logging of TensorFlow with VLOG() levels. This is making it pretty useless for development purposes. For example at  TF_CPP_MIN_VLOG_LEVEL=1, tensorflow/core/framework/log_memory.cc is printing all allocations and de-allocations which are spamming the log with hundreds of messages if not thousands per second. on the other hand tensorflow/core/common_runtime/graph_execution_state.cc is dumping nodedefs to the log file which sometimes contain the input data, creating hundreds of megabytes of strings as outputs . Similarly extremely verbose output is printed even at the verbosity level 1 making levels useless and logs unusable other than a few tiny example cases probably. 

It would be nice to establish some conventions for logging levels on number of messages per second or amount of data printed to the log. Something in the lines of
0 < level 1 <= 0.1 msg/s
0.1 msg/s <= level 2 <= ~1-2 msg/s
1-2msg/s <= level 3 <= ~5-10 msg/s
.... and similarly for amount of information printed in the logs.

But the best solution would be to have a more advanced logging structure that would allow users to selectively enable or disable different logging levels for each module but I don't know how hard would it be to implement. 

I am creating this issue to bring this feature/improvement request into attention.

Thanks,
Sami
"
18242,Make tf.train.Scaffold._default_local_init_op() a public static method?,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yep
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Debian Rolling
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**:  N/A
- **Python version**: 2.7.13
- **Bazel version (if compiling from source)**:  N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

### Describe the problem

This is a continuation in spirit of Issue #11665, but could we expose tf.train.Scaffold._default_local_init_op() as a **public** static method? This would make it easier in init_fn/init_op/local_init_op to add specific local op initializers to the existing defaults instead of reproducing the logic.

For example:
```
    local_init_op = tf.group(
        tf.train.Scaffold.default_local_init_op(),
        tf.variables_initializer([some_local_var]))
    scaffold = tf.train.Scaffold(
        local_init_op=local_init_op,
        ready_for_local_init_op=tf.report_uninitialized_variables(
            vars_to_load),
        saver=tf.train.Saver(vars_to_load))
```"
18241,Tensorflow assume the pointer size is 64bit cause problem on 32bit platform,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 1709 x64
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.7.0
- **Python version**: 3.6.4
- **Bazel version (if compiling from source)**: cmake 3.9.6
- **GCC/Compiler version (if compiling from source)**: msvc 1911 (vs 2017 15.4)
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**:

VS2017 x64_x86 Cross Tools Command Prompt

    cmake .. -G ""Visual Studio 15 2017"" -T host=x64 ^
    -DCMAKE_BUILD_TYPE=Release ^
    -Dtensorflow_BUILD_PYTHON_BINDINGS=OFF ^
    -Dtensorflow_BUILD_SHARED_LIB=ON ^
    
    cmake --build . --target tensorflow --config Release -- /fileLogger

### Describe the problem

Tensorflow should use proper pointer type instead of hardcode int64.

### Source code / logs
    ""C:\Users\User\Source\Repos\tensorflow\tensorflow\contrib\cmake\build\tensorflow.vcxproj"" (預設目標) (1) ->
    ""C:\Users\User\Source\Repos\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj"" (預設目標) (13) ->
    (ClCompile 目標) -> 
      C:\Users\User\Source\Repos\tensorflow\tensorflow\core\kernels\batch_kernels.cc(160): error C2398: 項目 '1': 從 'tensorflow::int64' 到 'Eigen::DenseIndex' 的轉換必須是縮小轉換 [C:\Users\User\Source\Repos\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj]
      C:\Users\User\Source\Repos\tensorflow\tensorflow\core\kernels\batch_kernels.cc(161): error C2398: 項目 '1': 從 'const tensorflow::int64' 到 'Eigen::DenseIndex' 的轉換必須是縮小轉換 [C:\Users\User\Source\Repos\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj]
      C:\Users\User\Source\Repos\tensorflow\tensorflow\core\kernels\batch_kernels.cc(161): error C2398: 項目 '2': 從 'tensorflow::int64' 到 'Eigen::DenseIndex' 的轉換必須是縮小轉換 [C:\Users\User\Source\Repos\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj]
      C:\Users\User\Source\Repos\tensorflow\tensorflow\core\kernels\conv_grad_ops_3d.cc(296): error C2398: 項目 '2': 從 'initializer list' 到 'Eigen::IndexPair<int>' 的轉換必須是縮小轉換 [C:\Users\User\Source\Repos\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj]
      C:\Users\User\Source\Repos\tensorflow\tensorflow\core\kernels\conv_grad_ops_3d.cc(296): error C2398: 項目 '3': 從 'initializer list' 到 'Eigen::IndexPair<int>' 的轉換必須是縮小轉換 [C:\Users\User\Source\Repos\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj]
      C:\Users\User\Source\Repos\tensorflow\tensorflow\core\kernels\conv_grad_ops_3d.cc(296): error C2398: 項目 '4': 從 'initializer list' 到 'Eigen::IndexPair<int>' 的轉換必須是縮小轉換 [C:\Users\User\Source\Repos\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj]
      C:\Users\User\Source\Repos\tensorflow\tensorflow\core\kernels\conv_grad_ops_3d.cc(296): error C2398: 項目 '1': 從 'const tensorflow::int64' 到 'int' 的轉換必須是縮小轉換 [C:\Users\User\Source\Repos\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj]
      C:\Users\User\Source\Repos\tensorflow\tensorflow\core\kernels\conv_grad_ops_3d.cc(296): error C2398: 項目 '2': 從 'const tensorflow::int64' 到 'int' 的轉換必須是縮小轉換 [C:\Users\User\Source\Repos\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj]
      C:\Users\User\Source\Repos\tensorflow\tensorflow\core\kernels\conv_grad_ops_3d.cc(320): error C2398: 項目 '2': 從 'const tensorflow::int64' 到 'Eigen::DenseIndex' 的轉換必須是縮小轉換 [C:\Users\User\Source\Repos\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj]
      c:\users\user\source\repos\tensorflow\tensorflow\contrib\cmake\build\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorMap.h(242): error C2398: 項目 '3': 從 'tensorflow::int64' 到 'ptrdiff_t' 的轉換必須是縮小轉換 (正在編譯原始程式檔 C:\Users\User\Source\Repos\tensorflow\tensorflow\core\kernels\draw_bounding_box_op.cc) [C:\Users\User\Source\Repos\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj]
      c:\users\user\source\repos\tensorflow\tensorflow\contrib\cmake\build\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorMap.h(242): error C2398: 項目 '4': 從 'tensorflow::int64' 到 'ptrdiff_t' 的轉換必須是縮小轉換 (正在編譯原始程式檔 C:\Users\User\Source\Repos\tensorflow\tensorflow\core\kernels\draw_bounding_box_op.cc) [C:\Users\User\Source\Repos\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj]
      c:\users\user\source\repos\tensorflow\tensorflow\contrib\cmake\build\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorMap.h(245): error C2398: 項目 '3': 從 'tensorflow::int64' 到 'ptrdiff_t' 的轉換必須是縮小轉換 (正在編譯原始程式檔 C:\Users\User\Source\Repos\tensorflow\tensorflow\core\kernels\draw_bounding_box_op.cc) [C:\Users\User\Source\Repos\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj]
      c:\users\user\source\repos\tensorflow\tensorflow\contrib\cmake\build\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorMap.h(245): error C2398: 項目 '4': 從 'tensorflow::int64' 到 'ptrdiff_t' 的轉換必須是縮小轉換 (正在編譯原始程式檔 C:\Users\User\Source\Repos\tensorflow\tensorflow\core\kernels\draw_bounding_box_op.cc) [C:\Users\User\Source\Repos\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj]
      c:\users\user\source\repos\tensorflow\tensorflow\contrib\cmake\build\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorMap.h(242): error C2398: 項目 '3': 從 'tensorflow::int64' 到 'ptrdiff_t' 的轉換必須是縮小轉換 (正在編譯原始程式檔 C:\Users\User\Source\Repos\tensorflow\tensorflow\core\kernels\matrix_band_part_op.cc) [C:\Users\User\Source\Repos\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj]
      c:\users\user\source\repos\tensorflow\tensorflow\contrib\cmake\build\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorMap.h(245): error C2398: 項目 '3': 從 'tensorflow::int64' 到 'ptrdiff_t' 的轉換必須是縮小轉換 (正在編譯原始程式檔 C:\Users\User\Source\Repos\tensorflow\tensorflow\core\kernels\matrix_band_part_op.cc) [C:\Users\User\Source\Repos\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj]
      c:\users\user\source\repos\tensorflow\tensorflow\contrib\cmake\build\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorDimensions.h(289): error C2398: 項目 '3': 從 'tensorflow::int64' 到 'ptrdiff_t' 的轉換必須是縮小轉換 (正在編譯原始程式檔 C:\Users\User\Source\Repos\tensorflow\tensorflow\core\kernels\matrix_band_part_op.cc) [C:\Users\User\Source\Repos\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj]
      c:\users\user\source\repos\tensorflow\tensorflow\contrib\cmake\build\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorMap.h(242): error C2398: 項目 '3': 從 'tensorflow::int64' 到 'ptrdiff_t' 的轉換必須是縮小轉換 (正在編譯原始程式檔 C:\Users\User\Source\Repos\tensorflow\tensorflow\core\kernels\matrix_set_diag_op.cc) [C:\Users\User\Source\Repos\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj]
      c:\users\user\source\repos\tensorflow\tensorflow\contrib\cmake\build\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorMap.h(245): error C2398: 項目 '3': 從 'tensorflow::int64' 到 'ptrdiff_t' 的轉換必須是縮小轉換 (正在編譯原始程式檔 C:\Users\User\Source\Repos\tensorflow\tensorflow\core\kernels\matrix_set_diag_op.cc) [C:\Users\User\Source\Repos\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj]
      c:\users\user\source\repos\tensorflow\tensorflow\contrib\cmake\build\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorMap.h(242): error C2398: 項目 '3': 從 'tensorflow::int64' 到 'ptrdiff_t' 的轉換必須是縮小轉換 (正在編譯原始程式檔 C:\Users\User\Source\Repos\tensorflow\tensorflow\core\kernels\matrix_diag_op.cc) [C:\Users\User\Source\Repos\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj]
      c:\users\user\source\repos\tensorflow\tensorflow\contrib\cmake\build\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorMap.h(245): error C2398: 項目 '3': 從 'tensorflow::int64' 到 'ptrdiff_t' 的轉換必須是縮小轉換 (正在編譯原始程式檔 C:\Users\User\Source\Repos\tensorflow\tensorflow\core\kernels\matrix_diag_op.cc) [C:\Users\User\Source\Repos\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj]
      c:\users\user\source\repos\tensorflow\tensorflow\contrib\cmake\build\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorMap.h(242): error C2398: 項目 '3': 從 'tensorflow::int64' 到 'ptrdiff_t' 的轉換必須是縮小轉換 (正在編譯原始程式檔 C:\Users\User\Source\Repos\tensorflow\tensorflow\core\kernels\resize_bilinear_op.cc) [C:\Users\User\Source\Repos\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj]
      c:\users\user\source\repos\tensorflow\tensorflow\contrib\cmake\build\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorMap.h(242): error C2398: 項目 '4': 從 'tensorflow::int64' 到 'ptrdiff_t' 的轉換必須是縮小轉換 (正在編譯原始程式檔 C:\Users\User\Source\Repos\tensorflow\tensorflow\core\kernels\resize_bilinear_op.cc) [C:\Users\User\Source\Repos\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj]
      c:\users\user\source\repos\tensorflow\tensorflow\contrib\cmake\build\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorMap.h(245): error C2398: 項目 '3': 從 'tensorflow::int64' 到 'ptrdiff_t' 的轉換必須是縮小轉換 (正在編譯原始程式檔 C:\Users\User\Source\Repos\tensorflow\tensorflow\core\kernels\resize_bilinear_op.cc) [C:\Users\User\Source\Repos\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj]
      c:\users\user\source\repos\tensorflow\tensorflow\contrib\cmake\build\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorMap.h(245): error C2398: 項目 '4': 從 'tensorflow::int64' 到 'ptrdiff_t' 的轉換必須是縮小轉換 (正在編譯原始程式檔 C:\Users\User\Source\Repos\tensorflow\tensorflow\core\kernels\resize_bilinear_op.cc) [C:\Users\User\Source\Repos\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj]
      c:\users\user\source\repos\tensorflow\tensorflow\contrib\cmake\build\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorMap.h(242): error C2398: 項目 '3': 從 'tensorflow::int64' 到 'ptrdiff_t' 的轉換必須是縮小轉換 (正在編譯原始程式檔 C:\Users\User\Source\Repos\tensorflow\tensorflow\core\kernels\resize_bicubic_op.cc) [C:\Users\User\Source\Repos\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj]
      c:\users\user\source\repos\tensorflow\tensorflow\contrib\cmake\build\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorMap.h(242): error C2398: 項目 '4': 從 'tensorflow::int64' 到 'ptrdiff_t' 的轉換必須是縮小轉換 (正在編譯原始程式檔 C:\Users\User\Source\Repos\tensorflow\tensorflow\core\kernels\resize_bicubic_op.cc) [C:\Users\User\Source\Repos\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj]
      c:\users\user\source\repos\tensorflow\tensorflow\contrib\cmake\build\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorMap.h(245): error C2398: 項目 '3': 從 'tensorflow::int64' 到 'ptrdiff_t' 的轉換必須是縮小轉換 (正在編譯原始程式檔 C:\Users\User\Source\Repos\tensorflow\tensorflow\core\kernels\resize_bicubic_op.cc) [C:\Users\User\Source\Repos\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj]
      c:\users\user\source\repos\tensorflow\tensorflow\contrib\cmake\build\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorMap.h(245): error C2398: 項目 '4': 從 'tensorflow::int64' 到 'ptrdiff_t' 的轉換必須是縮小轉換 (正在編譯原始程式檔 C:\Users\User\Source\Repos\tensorflow\tensorflow\core\kernels\resize_bicubic_op.cc) [C:\Users\User\Source\Repos\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj]
      c:\users\user\source\repos\tensorflow\tensorflow\contrib\cmake\build\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorMap.h(242): error C2398: 項目 '3': 從 'tensorflow::int64' 到 'ptrdiff_t' 的轉換必須是縮小轉換 (正在編譯原始程式檔 C:\Users\User\Source\Repos\tensorflow\tensorflow\core\kernels\resize_nearest_neighbor_op.cc) [C:\Users\User\Source\Repos\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj]
      c:\users\user\source\repos\tensorflow\tensorflow\contrib\cmake\build\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorMap.h(245): error C2398: 項目 '3': 從 'tensorflow::int64' 到 'ptrdiff_t' 的轉換必須是縮小轉換 (正在編譯原始程式檔 C:\Users\User\Source\Repos\tensorflow\tensorflow\core\kernels\resize_nearest_neighbor_op.cc) [C:\Users\User\Source\Repos\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj]
      C:\Users\User\Source\Repos\tensorflow\tensorflow\core\kernels\tensor_array_ops.cc(1286): error C2398: 項目 '2': 從 'tensorflow::int64' 到 'int' 的轉換必須是縮小轉換 [C:\Users\User\Source\Repos\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj]
      C:\Users\User\Source\Repos\tensorflow\tensorflow\core\kernels\tensor_array_ops.cc(1288): error C2398: 項目 '2': 從 'const __int64' 到 'int' 的轉換必須是縮小轉換 [C:\Users\User\Source\Repos\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj]
      c:\users\user\source\repos\tensorflow\tensorflow\contrib\cmake\build\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorMap.h(242): error C2398: 項目 '3': 從 'tensorflow::int64' 到 'ptrdiff_t' 的轉換必須是縮小轉換 (正在編譯原始程式檔 C:\Users\User\Source\Repos\tensorflow\tensorflow\core\kernels\unique_op.cc) [C:\Users\User\Source\Repos\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj]
      c:\users\user\source\repos\tensorflow\tensorflow\contrib\cmake\build\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorMap.h(245): error C2398: 項目 '3': 從 'tensorflow::int64' 到 'ptrdiff_t' 的轉換必須是縮小轉換 (正在編譯原始程式檔 C:\Users\User\Source\Repos\tensorflow\tensorflow\core\kernels\unique_op.cc) [C:\Users\User\Source\Repos\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj]
"
18239,tensorflow object detection training on own data,"I want to use the tensorflow object detection api for my own objects, so I am using the ssd_mobilenet_v1_coco and I have made the necessary changes in the config files and all and now after I run my train.py file through the following command:

python3 train.py --logtostderr --train_dir=data/ --pipeline_config_path=data/ssd_mobilenet_v1_pets.config

I get this error:

2018-04-04 21:42:05.832786: I tensorflow/core/common_runtime/bfc_allocator.cc:67                               9] 2 Chunks of size 4194304 totalling 8.00MiB
2018-04-04 21:42:05.832801: I tensorflow/core/common_runtime/bfc_allocator.cc:67                               9] 2 Chunks of size 4718592 totalling 9.00MiB
2018-04-04 21:42:05.832817: I tensorflow/core/common_runtime/bfc_allocator.cc:68                               3] Sum Total of in-use chunks: 50.14MiB
2018-04-04 21:42:05.832837: I tensorflow/core/common_runtime/bfc_allocator.cc:68                               5] Stats:
Limit:                   701038592
InUse:                    52573952
MaxInUse:                 75702272
NumAllocs:                    6172
MaxAllocSize:              4718592

2018-04-04 21:42:05.832996: W tensorflow/core/common_runtime/bfc_allocator.cc:27                               7] *__********__________________________________________________________________                               _______________________
Traceback (most recent call last):
  File ""/home/16mcmt36/anaconda3/envs/object_detection/lib/python3.5/site-packag                               es/tensorflow/python/client/session.py"", line 1323, in _do_call
    return fn(*args)
  File ""/home/16mcmt36/anaconda3/envs/object_detection/lib/python3.5/site-packag                               es/tensorflow/python/client/session.py"", line 1302, in _run_fn
    status, run_metadata)
  File ""/home/16mcmt36/anaconda3/envs/object_detection/lib/python3.5/site-packag                               es/tensorflow/python/framework/errors_impl.py"", line 473, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.InternalError: Dst tensor is not initial                               ized.
         [[Node: prefetch_queue_Dequeue/_3249 = _Recv[client_terminated=false, r                               ecv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:loc                               alhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""e                               dge_912_prefetch_queue_Dequeue"", tensor_type=DT_FLOAT, _device=""/job:localhost/r                               eplica:0/task:0/device:GPU:0""]()]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/16mcmt36/anaconda3/envs/object_detection/lib/python3.5/site-packag                               es/tensorflow/python/training/supervisor.py"", line 954, in managed_session
    yield sess
  File ""/home/16mcmt36/anaconda3/envs/object_detection/lib/python3.5/site-packag                               es/tensorflow/contrib/slim/python/slim/learning.py"", line 763, in train
    sess, train_op, global_step, train_step_kwargs)
  File ""/home/16mcmt36/anaconda3/envs/object_detection/lib/python3.5/site-packag                               es/tensorflow/contrib/slim/python/slim/learning.py"", line 487, in train_step
    run_metadata=run_metadata)
  File ""/home/16mcmt36/anaconda3/envs/object_detection/lib/python3.5/site-packag                               es/tensorflow/python/client/session.py"", line 889, in run
    run_metadata_ptr)
  File ""/home/16mcmt36/anaconda3/envs/object_detection/lib/python3.5/site-packag                               es/tensorflow/python/client/session.py"", line 1120, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/16mcmt36/anaconda3/envs/object_detection/lib/python3.5/site-packag                               es/tensorflow/python/client/session.py"", line 1317, in _do_run
    options, run_metadata)
  File ""/home/16mcmt36/anaconda3/envs/object_detection/lib/python3.5/site-packag                               es/tensorflow/python/client/session.py"", line 1336, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InternalError: Dst tensor is not initial                               ized.
         [[Node: prefetch_queue_Dequeue/_3249 = _Recv[client_terminated=false, r                               ecv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:loc                               alhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""e                               dge_912_prefetch_queue_Dequeue"", tensor_type=DT_FLOAT, _device=""/job:localhost/r                               eplica:0/task:0/device:GPU:0""]()]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""train.py"", line 163, in <module>
    tf.app.run()
  File ""/home/16mcmt36/anaconda3/envs/object_detection/lib/python3.5/site-packag                               es/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""train.py"", line 159, in main
    worker_job_name, is_chief, FLAGS.train_dir)
  File ""/home/16mcmt36/models/object_detection/trainer.py"", line 332, in train
    saver=saver)
  File ""/home/16mcmt36/anaconda3/envs/object_detection/lib/python3.5/site-packag                               es/tensorflow/contrib/slim/python/slim/learning.py"", line 775, in train
    sv.stop(threads, close_summary_writer=True)
  File ""/home/16mcmt36/anaconda3/envs/object_detection/lib/python3.5/contextlib.                               py"", line 77, in __exit__
    self.gen.throw(type, value, traceback)
  File ""/home/16mcmt36/anaconda3/envs/object_detection/lib/python3.5/site-packag                               es/tensorflow/python/training/supervisor.py"", line 964, in managed_session
    self.stop(close_summary_writer=close_summary_writer)
  File ""/home/16mcmt36/anaconda3/envs/object_detection/lib/python3.5/site-packag                               es/tensorflow/python/training/supervisor.py"", line 792, in stop
    stop_grace_period_secs=self._stop_grace_secs)
  File ""/home/16mcmt36/anaconda3/envs/object_detection/lib/python3.5/site-packag                               es/tensorflow/python/training/coordinator.py"", line 389, in join
    six.reraise(*self._exc_info_to_raise)
  File ""/home/16mcmt36/anaconda3/envs/object_detection/lib/python3.5/site-packag                               es/six.py"", line 693, in reraise
    raise value
  File ""/home/16mcmt36/anaconda3/envs/object_detection/lib/python3.5/site-packag                               es/tensorflow/python/training/coordinator.py"", line 296, in stop_on_exception
    yield
  File ""/home/16mcmt36/anaconda3/envs/object_detection/lib/python3.5/site-packag                               es/tensorflow/python/training/coordinator.py"", line 494, in run
    self.run_loop()
  File ""/home/16mcmt36/anaconda3/envs/object_detection/lib/python3.5/site-packag                               es/tensorflow/python/training/supervisor.py"", line 994, in run_loop
    self._sv.global_step])
  File ""/home/16mcmt36/anaconda3/envs/object_detection/lib/python3.5/site-packag                               es/tensorflow/python/client/session.py"", line 889, in run
    run_metadata_ptr)
  File ""/home/16mcmt36/anaconda3/envs/object_detection/lib/python3.5/site-packag                               es/tensorflow/python/client/session.py"", line 1120, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/16mcmt36/anaconda3/envs/object_detection/lib/python3.5/site-packag                               es/tensorflow/python/client/session.py"", line 1317, in _do_run
    options, run_metadata)
  File ""/home/16mcmt36/anaconda3/envs/object_detection/lib/python3.5/site-packag                               es/tensorflow/python/client/session.py"", line 1336, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InternalError: Dst tensor is not initialized.
         [[Node: prefetch_queue_Dequeue/_21 = _Recv[client_terminated=false, rec                               v_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:local                               host/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edg                               e_379_prefetch_queue_Dequeue"", tensor_type=DT_FLOAT, _device=""/job:localhost/rep                               lica:0/task:0/device:GPU:0""]()]]
sorflow

Please help..."
18238,Feature Request: keepdims option for tf.boolean_mask(),"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: N/A
- **TensorFlow installed from (source or binary)**: N/A
- **TensorFlow version (use command below)**: ('v1.6.0-0-gd2e24b6039', '1.6.0')
- **Python version**: Python 2.7.14
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

### Describe the problem
`tf.boolean_mask()` currently grabs individual elements from the input tensor according to the shape and content of the boolean mask argument (see https://www.tensorflow.org/api_docs/python/tf/boolean_mask). The returning tensor's dimensionality is always lower than or equal to the input tensor. It would be very useful if `tf.boolean_mask()` included an additional, optional boolean argument `keepdims`. If `keepdims=False`, the behavior of the method is unchanged. If `keepdims=True`, the output tensor would have the same dimensionality as the input tensor. This would allow 'filtering out' of certain values from the input, while keeping its overall shape as much as possible (see example below).

### Source code / logs
```
tensor = [[1, 2], [3, 4], [5, 6]]
mask = np.array([[True, False],[False, True],[False, True]])
boolean_mask(tensor, mask, keepdims=False)  # [1, 4, 6]
boolean_mask(tensor, mask, keepdims=True) # [[1],[4],[6]]

mask = np.array([[True, False],[False, True],[False, False]])
boolean_mask(tensor, mask, keepdims=False)  # [1, 4]
boolean_mask(tensor, mask, keepdims=True) # [[1],[4]]
```
"
18237,ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory,"I had installed CUDA toolkit version 9.1.85, cuDNN v7.1.2  for CUDA 9.1 and tensorflow 1.6 from [this link](https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.6.0-cp36-cp36m-linux_x86_64.whl
)

When i try import tensorflow i get the following error.

(tensorflow) akshith@Akshith:~$ python
Python 3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 18:10:19) 
[GCC 7.2.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow
Traceback (most recent call last):
  File ""/home/akshith/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/home/akshith/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/home/akshith/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/home/akshith/anaconda3/lib/python3.6/imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""/home/akshith/anaconda3/lib/python3.6/imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/akshith/anaconda3/lib/python3.6/site-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/home/akshith/anaconda3/lib/python3.6/site-packages/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/home/akshith/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/home/akshith/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/home/akshith/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/home/akshith/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/home/akshith/anaconda3/lib/python3.6/imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""/home/akshith/anaconda3/lib/python3.6/imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
>>> 

how to solve this?
TIA"
18236,cannot be overwritten again on class - tensorflow,"
Tensorflow: 1.6.0
OS: Red Hat Enterprise Linux 7

I created weights & json model using keras but when I try to load it from my code I am getting the error from tensorflow.

ValueError(operator getitem cannot be overwritten again on class <class 'tensorflow.python.framework.ops.Tensor'>.)

Initially I was loading the model from other lib & then referring it, to test I clubbed all in one place, still gets the same exception. Any idea when & why this exception occurs? Please let me know if you need any more "
18234,android build bazel fails when using constraint-layout,"- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes, I have included a [Constraint-Layout](https://github.engineering.zhaw.ch/Einardan/tensorflow-ba/blob/master/tensorflow/examples/android/res/layout/fragment_camera2_video.xml). 
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 17.10
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
1.6
- **Python version**: 
3.6.5
- **Bazel version (if compiling from source)**:
0.11.1
- **GCC/Compiler version (if compiling from source)**:
6
- **CUDA/cuDNN version**:
9.0/7.0.5
- **GPU model and memory**:
Nvidia GTX 1060 Mobile
- **Exact command to reproduce**:
´bazel build -c opt //tensorflow/examples/android:tensorflow_demooid:tensorflow_demo´

Expected Output: Build Complete

Actual Output: Build Failed.

Fixes Attempted:
 * [Including the Constraint-Layout in a fast file](https://github.com/NovaTecConsulting/fastlane-plugin-android_sdk_update/issues/2#issuecomment-378245524) has been unsuccessful because ```sudo fastlane update``` required (Linux)Brew, which in turn wanted a separate android-sdk installation, which is only possible with ```brew cask```, which is only available on OSX
 * [Including the *.aar file in the BUILD file] (https://github.com/bazelbuild/bazel/issues/2830) as recommended here. Unfortunately this failed as well because (I suspect) it was not recognized
 * Moving the constraint-layout from the ```extras/m2repository/com/android/support/constraint/constraint-layout``` to ```extras/android/m2repository/com/android/support/``` folder but, unfortunately, it was not picked up either.



Bazel Build Output

```
(ba)  λ bazel build -c opt //tensorflow/examples/android:tensorflow_demooid:tensorflow_demo
WARNING: The major revision of the Android NDK referenced by android_ndk_repository rule 'androidndk' is 15. The major revisions supported by Bazel are [10, 11, 12, 13, 14]. Defaulting to revision 14.
WARNING: /home/polaroidkidd/.cache/bazel/_bazel_polaroidkidd/a57cb0f131ca59db599675965fb76260/external/protobuf_archive/WORKSPACE:1: Workspace name in /home/polaroidkidd/.cache/bazel/_bazel_polaroidkidd/a57cb0f131ca59db599675965fb76260/external/protobuf_archive/WORKSPACE (@com_google_protobuf) does not match the name given in the repository's definition (@protobuf_archive); this will cause a build error in future versions
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/core/BUILD:1130:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:avgpooling_op.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/core/BUILD:1130:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:batch_util.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/core/BUILD:1130:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:bounds_check.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/core/BUILD:1130:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:cwise_ops.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/core/BUILD:1130:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:cwise_ops_common.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/core/BUILD:1130:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:cwise_ops_gradients.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/core/BUILD:1130:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_activations.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/core/BUILD:1130:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_attention.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/core/BUILD:1130:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_backward_cuboid_convolutions.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/core/BUILD:1130:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_backward_spatial_convolutions.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/core/BUILD:1130:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_cuboid_convolution.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/core/BUILD:1130:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_pooling.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/core/BUILD:1130:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_softmax.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/core/BUILD:1130:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_spatial_convolutions.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/core/BUILD:1130:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_volume_patch.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/core/BUILD:1130:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:fifo_queue.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/core/BUILD:1130:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:maxpooling_op.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/core/BUILD:1130:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:ops_util.cc' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/core/BUILD:1130:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:ops_util.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/core/BUILD:1130:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:padding_fifo_queue.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/core/BUILD:1130:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:pooling_ops_common.cc' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/core/BUILD:1130:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:pooling_ops_common.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/core/BUILD:1130:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:queue_base.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/core/BUILD:1130:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:queue_op.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/core/BUILD:1130:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:typed_queue.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/core/BUILD:1130:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_entry.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/core/BUILD:1130:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_scorer.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/core/BUILD:1130:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_search.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/core/BUILD:1130:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_decoder.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/core/BUILD:1130:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_loss_util.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/core/BUILD:1130:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:naming.cc' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/core/BUILD:1130:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:naming.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/core/BUILD:1130:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:tensor_bundle.cc' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/core/BUILD:1130:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:tensor_bundle.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/contrib/android/BUILD:58:12: in srcs attribute of android_library rule //tensorflow/contrib/android:android_tensorflow_inference_java: please do not import '//tensorflow/java:src/main/java/org/tensorflow/DataType.java' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/contrib/android/BUILD:58:12: in srcs attribute of android_library rule //tensorflow/contrib/android:android_tensorflow_inference_java: please do not import '//tensorflow/java:src/main/java/org/tensorflow/Graph.java' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/contrib/android/BUILD:58:12: in srcs attribute of android_library rule //tensorflow/contrib/android:android_tensorflow_inference_java: please do not import '//tensorflow/java:src/main/java/org/tensorflow/NativeLibrary.java' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/contrib/android/BUILD:58:12: in srcs attribute of android_library rule //tensorflow/contrib/android:android_tensorflow_inference_java: please do not import '//tensorflow/java:src/main/java/org/tensorflow/Operand.java' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/contrib/android/BUILD:58:12: in srcs attribute of android_library rule //tensorflow/contrib/android:android_tensorflow_inference_java: please do not import '//tensorflow/java:src/main/java/org/tensorflow/Operation.java' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/contrib/android/BUILD:58:12: in srcs attribute of android_library rule //tensorflow/contrib/android:android_tensorflow_inference_java: please do not import '//tensorflow/java:src/main/java/org/tensorflow/OperationBuilder.java' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/contrib/android/BUILD:58:12: in srcs attribute of android_library rule //tensorflow/contrib/android:android_tensorflow_inference_java: please do not import '//tensorflow/java:src/main/java/org/tensorflow/Output.java' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/contrib/android/BUILD:58:12: in srcs attribute of android_library rule //tensorflow/contrib/android:android_tensorflow_inference_java: please do not import '//tensorflow/java:src/main/java/org/tensorflow/SavedModelBundle.java' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/contrib/android/BUILD:58:12: in srcs attribute of android_library rule //tensorflow/contrib/android:android_tensorflow_inference_java: please do not import '//tensorflow/java:src/main/java/org/tensorflow/Session.java' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/contrib/android/BUILD:58:12: in srcs attribute of android_library rule //tensorflow/contrib/android:android_tensorflow_inference_java: please do not import '//tensorflow/java:src/main/java/org/tensorflow/Shape.java' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/contrib/android/BUILD:58:12: in srcs attribute of android_library rule //tensorflow/contrib/android:android_tensorflow_inference_java: please do not import '//tensorflow/java:src/main/java/org/tensorflow/Tensor.java' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/contrib/android/BUILD:58:12: in srcs attribute of android_library rule //tensorflow/contrib/android:android_tensorflow_inference_java: please do not import '//tensorflow/java:src/main/java/org/tensorflow/TensorFlow.java' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/contrib/android/BUILD:58:12: in srcs attribute of android_library rule //tensorflow/contrib/android:android_tensorflow_inference_java: please do not import '//tensorflow/java:src/main/java/org/tensorflow/TensorFlowException.java' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/contrib/android/BUILD:58:12: in srcs attribute of android_library rule //tensorflow/contrib/android:android_tensorflow_inference_java: please do not import '//tensorflow/java:src/main/java/org/tensorflow/Tensors.java' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/contrib/android/BUILD:58:12: in srcs attribute of android_library rule //tensorflow/contrib/android:android_tensorflow_inference_java: please do not import '//tensorflow/java:src/main/java/org/tensorflow/package-info.java' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/contrib/android/BUILD:58:12: in srcs attribute of android_library rule //tensorflow/contrib/android:android_tensorflow_inference_java: please do not import '//tensorflow/java:src/main/java/org/tensorflow/types/UInt8.java' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/contrib/android/BUILD:58:12: in srcs attribute of android_library rule //tensorflow/contrib/android:android_tensorflow_inference_java: please do not import '//tensorflow/java:src/main/java/org/tensorflow/types/package-info.java' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/examples/android/BUILD:64:1: in android_binary rule //tensorflow/examples/android:tensorflow_demo: manifest_merger 'legacy' is deprecated. Please update to 'android'.
See https://developer.android.com/studio/build/manifest-merge.html for more information about the manifest merger.
INFO: Analysed target //tensorflow/examples/android:tensorflow_demo (53 packages loaded).
INFO: Found 1 target...
INFO: From Compiling external/protobuf_archive/src/google/protobuf/struct.pb.cc:
external/protobuf_archive/src/google/protobuf/struct.pb.cc:115:3: warning: offset of on non-POD type '::google::protobuf::ValueDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::google::protobuf::ValueDefaultTypeInternal, null_value_),
  ^                                                      ~~~~~~~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
external/protobuf_archive/src/google/protobuf/struct.pb.cc:116:3: warning: offset of on non-POD type '::google::protobuf::ValueDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::google::protobuf::ValueDefaultTypeInternal, number_value_),
  ^                                                      ~~~~~~~~~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
external/protobuf_archive/src/google/protobuf/struct.pb.cc:117:3: warning: offset of on non-POD type '::google::protobuf::ValueDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::google::protobuf::ValueDefaultTypeInternal, string_value_),
  ^                                                      ~~~~~~~~~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
external/protobuf_archive/src/google/protobuf/struct.pb.cc:118:3: warning: offset of on non-POD type '::google::protobuf::ValueDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::google::protobuf::ValueDefaultTypeInternal, bool_value_),
  ^                                                      ~~~~~~~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
external/protobuf_archive/src/google/protobuf/struct.pb.cc:119:3: warning: offset of on non-POD type '::google::protobuf::ValueDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::google::protobuf::ValueDefaultTypeInternal, struct_value_),
  ^                                                      ~~~~~~~~~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
external/protobuf_archive/src/google/protobuf/struct.pb.cc:120:3: warning: offset of on non-POD type '::google::protobuf::ValueDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::google::protobuf::ValueDefaultTypeInternal, list_value_),
  ^                                                      ~~~~~~~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
6 warnings generated.
INFO: From ProtoCompile tensorflow/core/example/example.pb.cc:
bazel-out/android-armeabi-v7a-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.
INFO: From Compiling tensorflow/core/framework/attr_value.pb.cc:
bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/core/framework/attr_value.pb.cc:116:3: warning: offset of on non-POD type '::tensorflow::AttrValueDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::tensorflow::AttrValueDefaultTypeInternal, s_),
  ^                                                    ~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/core/framework/attr_value.pb.cc:117:3: warning: offset of on non-POD type '::tensorflow::AttrValueDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::tensorflow::AttrValueDefaultTypeInternal, i_),
  ^                                                    ~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/core/framework/attr_value.pb.cc:118:3: warning: offset of on non-POD type '::tensorflow::AttrValueDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::tensorflow::AttrValueDefaultTypeInternal, f_),
  ^                                                    ~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/core/framework/attr_value.pb.cc:119:3: warning: offset of on non-POD type '::tensorflow::AttrValueDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::tensorflow::AttrValueDefaultTypeInternal, b_),
  ^                                                    ~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/core/framework/attr_value.pb.cc:120:3: warning: offset of on non-POD type '::tensorflow::AttrValueDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::tensorflow::AttrValueDefaultTypeInternal, type_),
  ^                                                    ~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/core/framework/attr_value.pb.cc:121:3: warning: offset of on non-POD type '::tensorflow::AttrValueDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::tensorflow::AttrValueDefaultTypeInternal, shape_),
  ^                                                    ~~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/core/framework/attr_value.pb.cc:122:3: warning: offset of on non-POD type '::tensorflow::AttrValueDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::tensorflow::AttrValueDefaultTypeInternal, tensor_),
  ^                                                    ~~~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/core/framework/attr_value.pb.cc:123:3: warning: offset of on non-POD type '::tensorflow::AttrValueDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::tensorflow::AttrValueDefaultTypeInternal, list_),
  ^                                                    ~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/core/framework/attr_value.pb.cc:124:3: warning: offset of on non-POD type '::tensorflow::AttrValueDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::tensorflow::AttrValueDefaultTypeInternal, func_),
  ^                                                    ~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/core/framework/attr_value.pb.cc:125:3: warning: offset of on non-POD type '::tensorflow::AttrValueDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::tensorflow::AttrValueDefaultTypeInternal, placeholder_),
  ^                                                    ~~~~~~~~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
10 warnings generated.
INFO: From Compiling tensorflow/core/framework/summary.pb.cc:
bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/core/framework/summary.pb.cc:309:3: warning: offset of on non-POD type '::tensorflow::Summary_ValueDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::tensorflow::Summary_ValueDefaultTypeInternal, simple_value_),
  ^                                                        ~~~~~~~~~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/core/framework/summary.pb.cc:310:3: warning: offset of on non-POD type '::tensorflow::Summary_ValueDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::tensorflow::Summary_ValueDefaultTypeInternal, obsolete_old_style_histogram_),
  ^                                                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/core/framework/summary.pb.cc:311:3: warning: offset of on non-POD type '::tensorflow::Summary_ValueDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::tensorflow::Summary_ValueDefaultTypeInternal, image_),
  ^                                                        ~~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/core/framework/summary.pb.cc:312:3: warning: offset of on non-POD type '::tensorflow::Summary_ValueDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::tensorflow::Summary_ValueDefaultTypeInternal, histo_),
  ^                                                        ~~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/core/framework/summary.pb.cc:313:3: warning: offset of on non-POD type '::tensorflow::Summary_ValueDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::tensorflow::Summary_ValueDefaultTypeInternal, audio_),
  ^                                                        ~~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/core/framework/summary.pb.cc:314:3: warning: offset of on non-POD type '::tensorflow::Summary_ValueDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::tensorflow::Summary_ValueDefaultTypeInternal, tensor_),
  ^                                                        ~~~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
6 warnings generated.
INFO: From Compiling tensorflow/core/framework/tensor_slice.pb.cc:
bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/core/framework/tensor_slice.pb.cc:88:3: warning: offset of on non-POD type '::tensorflow::TensorSliceProto_ExtentDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::tensorflow::TensorSliceProto_ExtentDefaultTypeInternal, length_),
  ^                                                                  ~~~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
1 warning generated.
INFO: From Compiling tensorflow/core/util/event.pb.cc:
bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/core/util/event.pb.cc:178:3: warning: offset of on non-POD type '::tensorflow::EventDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::tensorflow::EventDefaultTypeInternal, file_version_),
  ^                                                ~~~~~~~~~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/core/util/event.pb.cc:179:3: warning: offset of on non-POD type '::tensorflow::EventDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::tensorflow::EventDefaultTypeInternal, graph_def_),
  ^                                                ~~~~~~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/core/util/event.pb.cc:180:3: warning: offset of on non-POD type '::tensorflow::EventDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::tensorflow::EventDefaultTypeInternal, summary_),
  ^                                                ~~~~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/core/util/event.pb.cc:181:3: warning: offset of on non-POD type '::tensorflow::EventDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::tensorflow::EventDefaultTypeInternal, log_message_),
  ^                                                ~~~~~~~~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/core/util/event.pb.cc:182:3: warning: offset of on non-POD type '::tensorflow::EventDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::tensorflow::EventDefaultTypeInternal, session_log_),
  ^                                                ~~~~~~~~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/core/util/event.pb.cc:183:3: warning: offset of on non-POD type '::tensorflow::EventDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::tensorflow::EventDefaultTypeInternal, tagged_run_metadata_),
  ^                                                ~~~~~~~~~~~~~~~~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/core/util/event.pb.cc:184:3: warning: offset of on non-POD type '::tensorflow::EventDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::tensorflow::EventDefaultTypeInternal, meta_graph_def_),
  ^                                                ~~~~~~~~~~~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
7 warnings generated.
INFO: From Compiling tensorflow/core/protobuf/meta_graph.pb.cc:
bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/core/protobuf/meta_graph.pb.cc:546:3: warning: offset of on non-POD type '::tensorflow::CollectionDefDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::tensorflow::CollectionDefDefaultTypeInternal, node_list_),
  ^                                                        ~~~~~~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/core/protobuf/meta_graph.pb.cc:547:3: warning: offset of on non-POD type '::tensorflow::CollectionDefDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::tensorflow::CollectionDefDefaultTypeInternal, bytes_list_),
  ^                                                        ~~~~~~~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/core/protobuf/meta_graph.pb.cc:548:3: warning: offset of on non-POD type '::tensorflow::CollectionDefDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::tensorflow::CollectionDefDefaultTypeInternal, int64_list_),
  ^                                                        ~~~~~~~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/core/protobuf/meta_graph.pb.cc:549:3: warning: offset of on non-POD type '::tensorflow::CollectionDefDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::tensorflow::CollectionDefDefaultTypeInternal, float_list_),
  ^                                                        ~~~~~~~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/core/protobuf/meta_graph.pb.cc:550:3: warning: offset of on non-POD type '::tensorflow::CollectionDefDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::tensorflow::CollectionDefDefaultTypeInternal, any_list_),
  ^                                                        ~~~~~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/core/protobuf/meta_graph.pb.cc:565:3: warning: offset of on non-POD type '::tensorflow::TensorInfoDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::tensorflow::TensorInfoDefaultTypeInternal, name_),
  ^                                                     ~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/core/protobuf/meta_graph.pb.cc:566:3: warning: offset of on non-POD type '::tensorflow::TensorInfoDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::tensorflow::TensorInfoDefaultTypeInternal, coo_sparse_),
  ^                                                     ~~~~~~~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
7 warnings generated.
INFO: From Compiling tensorflow/core/example/feature.pb.cc:
bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/core/example/feature.pb.cc:294:3: warning: offset of on non-POD type '::tensorflow::FeatureDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::tensorflow::FeatureDefaultTypeInternal, bytes_list_),
  ^                                                  ~~~~~~~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/core/example/feature.pb.cc:295:3: warning: offset of on non-POD type '::tensorflow::FeatureDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::tensorflow::FeatureDefaultTypeInternal, float_list_),
  ^                                                  ~~~~~~~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/core/example/feature.pb.cc:296:3: warning: offset of on non-POD type '::tensorflow::FeatureDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::tensorflow::FeatureDefaultTypeInternal, int64_list_),
  ^                                                  ~~~~~~~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
3 warnings generated.
INFO: From Compiling tensorflow/core/util/test_log.pb.cc:
bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/core/util/test_log.pb.cc:440:3: warning: offset of on non-POD type '::tensorflow::EntryValueDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::tensorflow::EntryValueDefaultTypeInternal, double_value_),
  ^                                                     ~~~~~~~~~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/core/util/test_log.pb.cc:441:3: warning: offset of on non-POD type '::tensorflow::EntryValueDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::tensorflow::EntryValueDefaultTypeInternal, string_value_),
  ^                                                     ~~~~~~~~~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/core/util/test_log.pb.cc:482:3: warning: offset of on non-POD type '::tensorflow::CommitIdDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::tensorflow::CommitIdDefaultTypeInternal, changelist_),
  ^                                                   ~~~~~~~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/core/util/test_log.pb.cc:483:3: warning: offset of on non-POD type '::tensorflow::CommitIdDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::tensorflow::CommitIdDefaultTypeInternal, hash_),
  ^                                                   ~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
4 warnings generated.
INFO: From Compiling tensorflow/core/protobuf/control_flow.pb.cc:
bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/core/protobuf/control_flow.pb.cc:152:3: warning: offset of on non-POD type '::tensorflow::ControlFlowContextDefDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::tensorflow::ControlFlowContextDefDefaultTypeInternal, cond_ctxt_),
  ^                                                                ~~~~~~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/core/protobuf/control_flow.pb.cc:153:3: warning: offset of on non-POD type '::tensorflow::ControlFlowContextDefDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::tensorflow::ControlFlowContextDefDefaultTypeInternal, while_ctxt_),
  ^                                                                ~~~~~~~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
2 warnings generated.
INFO: From Compiling tensorflow/core/example/example_parser_configuration.pb.cc:
bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/core/example/example_parser_configuration.pb.cc:188:3: warning: offset of on non-POD type '::tensorflow::FeatureConfigurationDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::tensorflow::FeatureConfigurationDefaultTypeInternal, fixed_len_feature_),
  ^                                                               ~~~~~~~~~~~~~~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/core/example/example_parser_configuration.pb.cc:189:3: warning: offset of on non-POD type '::tensorflow::FeatureConfigurationDefaultTypeInternal' [-Winvalid-offsetof]
  offsetof(::tensorflow::FeatureConfigurationDefaultTypeInternal, var_len_feature_),
  ^                                                               ~~~~~~~~~~~~~~~~
external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/lib64/clang/5.0.300080/include/stddef.h:120:24: note: expanded from macro 'offsetof'
#define offsetof(t, d) __builtin_offsetof(t, d)
                       ^                     ~
2 warnings generated.
ERROR: /home/polaroidkidd/DevWork/ZHAW/OnDeviceTrainingBA/development/tensorflow-ba/tensorflow/examples/android/BUILD:64:1: Processing Android resources for //tensorflow/examples/android:tensorflow_demo failed (Exit 1)
Apr 04, 2018 12:15:23 PM com.google.devtools.build.android.AndroidDataMerger doMerge
WARNING: 
CONFLICT: asset:WORKSPACE is provided with ambiguous priority from:
	external/speech_commands/WORKSPACE
	external/mobile_ssd/WORKSPACE
CONFLICT: asset:conv_actions_frozen.pb is provided with ambiguous priority from:
	tensorflow/examples/android/assets/conv_actions_frozen.pb
	external/speech_commands/conv_actions_frozen.pb
CONFLICT: asset:WORKSPACE is provided with ambiguous priority from:
	external/stylize/WORKSPACE
	external/speech_commands/WORKSPACE
CONFLICT: asset:WORKSPACE is provided with ambiguous priority from:
	external/mobile_ssd/WORKSPACE
	external/inception_v1/WORKSPACE
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:10: error: No resource identifier found for attribute 'layout_constraintBottom_toTopOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:10: error: No resource identifier found for attribute 'layout_constraintEnd_toEndOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:10: error: No resource identifier found for attribute 'layout_constraintHorizontal_bias' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:10: error: No resource identifier found for attribute 'layout_constraintStart_toEndOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:20: error: No resource identifier found for attribute 'layout_constraintBottom_toBottomOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:20: error: No resource identifier found for attribute 'layout_constraintEnd_toEndOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:20: error: No resource identifier found for attribute 'layout_constraintHorizontal_bias' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:20: error: No resource identifier found for attribute 'layout_constraintStart_toEndOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:30: error: No resource identifier found for attribute 'layout_constraintBottom_toTopOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:30: error: No resource identifier found for attribute 'layout_constraintEnd_toStartOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:30: error: No resource identifier found for attribute 'layout_constraintHorizontal_bias' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:30: error: No resource identifier found for attribute 'layout_constraintStart_toStartOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:40: error: No resource identifier found for attribute 'layout_constraintBottom_toBottomOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:40: error: No resource identifier found for attribute 'layout_constraintEnd_toStartOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:40: error: No resource identifier found for attribute 'layout_constraintHorizontal_bias' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:40: error: No resource identifier found for attribute 'layout_constraintStart_toStartOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:24: error: No resource identifier found for attribute 'layout_constraintBottom_toTopOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:24: error: No resource identifier found for attribute 'layout_constraintEnd_toEndOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:24: error: No resource identifier found for attribute 'layout_constraintStart_toStartOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:24: error: No resource identifier found for attribute 'layout_constraintTop_toTopOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:33: error: No resource identifier found for attribute 'layout_constraintBottom_toBottomOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:33: error: No resource identifier found for attribute 'layout_constraintTop_toBottomOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:41: error: No resource identifier found for attribute 'layout_constraintBottom_toBottomOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:41: error: No resource identifier found for attribute 'layout_constraintEnd_toEndOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:41: error: No resource identifier found for attribute 'layout_constraintHorizontal_bias' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:41: error: No resource identifier found for attribute 'layout_constraintStart_toEndOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:41: error: No resource identifier found for attribute 'layout_constraintTop_toTopOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:56: error: No resource identifier found for attribute 'layout_constraintBottom_toBottomOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:56: error: No resource identifier found for attribute 'layout_constraintEnd_toEndOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:56: error: No resource identifier found for attribute 'layout_constraintHorizontal_bias' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:56: error: No resource identifier found for attribute 'layout_constraintStart_toEndOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:56: error: No resource identifier found for attribute 'layout_constraintTop_toTopOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:70: error: No resource identifier found for attribute 'layout_constraintBottom_toBottomOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:70: error: No resource identifier found for attribute 'layout_constraintEnd_toStartOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:70: error: No resource identifier found for attribute 'layout_constraintHorizontal_bias' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:70: error: No resource identifier found for attribute 'layout_constraintStart_toStartOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:70: error: No resource identifier found for attribute 'layout_constraintTop_toTopOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:11: error: No resource identifier found for attribute 'layout_constraintEnd_toEndOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:11: error: No resource identifier found for attribute 'layout_constraintHorizontal_bias' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:11: error: No resource identifier found for attribute 'layout_constraintStart_toStartOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:11: error: No resource identifier found for attribute 'layout_constraintTop_toTopOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:26: error: No resource identifier found for attribute 'layout_constraintEnd_toEndOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:26: error: No resource identifier found for attribute 'layout_constraintHorizontal_bias' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:26: error: No resource identifier found for attribute 'layout_constraintStart_toStartOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:26: error: No resource identifier found for attribute 'layout_constraintTop_toBottomOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:37: error: No resource identifier found for attribute 'layout_constraintBottom_toBottomOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:37: error: No resource identifier found for attribute 'layout_constraintEnd_toEndOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:37: error: No resource identifier found for attribute 'layout_constraintHorizontal_bias' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:37: error: No resource identifier found for attribute 'layout_constraintStart_toStartOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:48: error: No resource identifier found for attribute 'layout_constraintBottom_toTopOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:48: error: No resource identifier found for attribute 'layout_constraintStart_toStartOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:57: error: No resource identifier found for attribute 'layout_constraintEnd_toStartOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:57: error: No resource identifier found for attribute 'layout_constraintStart_toStartOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:57: error: No resource identifier found for attribute 'layout_constraintTop_toBottomOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:69: error: No resource identifier found for attribute 'layout_constraintEnd_toEndOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:69: error: No resource identifier found for attribute 'layout_constraintStart_toEndOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:69: error: No resource identifier found for attribute 'layout_constraintTop_toTopOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_label.xml:13: error: No resource identifier found for attribute 'layout_constraintEnd_toEndOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_label.xml:13: error: No resource identifier found for attribute 'layout_constraintHorizontal_bias' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_label.xml:13: error: No resource identifier found for attribute 'layout_constraintStart_toStartOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_label.xml:13: error: No resource identifier found for attribute 'layout_constraintTop_toBottomOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_label.xml:30: error: No resource identifier found for attribute 'layout_constraintEnd_toEndOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_label.xml:30: error: No resource identifier found for attribute 'layout_constraintHorizontal_bias' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_label.xml:30: error: No resource identifier found for attribute 'layout_constraintStart_toStartOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_label.xml:30: error: No resource identifier found for attribute 'layout_constraintTop_toTopOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_label.xml:42: error: No resource identifier found for attribute 'layout_constraintEnd_toEndOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_label.xml:42: error: No resource identifier found for attribute 'layout_constraintHorizontal_bias' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_label.xml:42: error: No resource identifier found for attribute 'layout_constraintStart_toStartOf' in package 'org.tensorflow.demo'
Error: 
Error: /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_label.xml:42: error: No resource identifier found for attribute 'layout_constraintTop_toBottomOf' in package 'org.tensorflow.demo'
Error: 
Apr 04, 2018 12:15:23 PM com.google.devtools.build.android.AndroidResourceProcessingAction main
SEVERE: Error during processing resources
com.android.ide.common.internal.LoggedErrorException: Failed to run command:
	bazel-out/host/bin/external/androidsdk/aapt_binary package -f --no-crunch --no-version-vectors -I external/androidsdk/platforms/android-26/android.jar -M /tmp/android_resources_tmp2553409785033894779/AndroidManifest.xml -S /tmp/android_resources_tmp2553409785033894779/merged_resources -A /tmp/android_resources_tmp2553409785033894779/merged_assets -m -J /tmp/android_resources_tmp2553409785033894779/generated_resources --output-text-symbols /tmp/android_resources_tmp2553409785033894779/generated_resources -F bazel-out/k8-opt/bin/tensorflow/examples/android/tensorflow_demo.ap_ -G bazel-out/k8-opt/bin/tensorflow/examples/android/proguard/tensorflow_demo/_tensorflow_demo_proguard.cfg -D bazel-out/k8-opt/bin/tensorflow/examples/android/proguard/tensorflow_demo/main_dex_tensorflow_demo_proguard.cfg -P /tmp/android_resources_tmp2553409785033894779/merged_resources/values/public.xml --custom-package org.tensorflow.demo -0 apk
Error Code:
	1
Output:
	
Error at 10 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:10: error: No resource identifier found for attribute 'layout_constraintBottom_toTopOf' in package 'org.tensorflow.demo'
5	:    android:layout_width=""match_parent""
6	:    android:layout_height=""match_parent""
7	:    tools:context="".MainActivity"">
8	:  
9	:    <Button
10	:      android:id=""@+id/button_Classify""
11	:      android:layout_width=""180dp""
12	:      android:layout_height=""wrap_content""
13	:      android:layout_marginBottom=""8dp""
14	:      android:text=""Classify""
	
	
Error at 10 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:10: error: No resource identifier found for attribute 'layout_constraintEnd_toEndOf' in package 'org.tensorflow.demo'
5	:    android:layout_width=""match_parent""
6	:    android:layout_height=""match_parent""
7	:    tools:context="".MainActivity"">
8	:  
9	:    <Button
10	:      android:id=""@+id/button_Classify""
11	:      android:layout_width=""180dp""
12	:      android:layout_height=""wrap_content""
13	:      android:layout_marginBottom=""8dp""
14	:      android:text=""Classify""
	
	
Error at 10 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:10: error: No resource identifier found for attribute 'layout_constraintHorizontal_bias' in package 'org.tensorflow.demo'
5	:    android:layout_width=""match_parent""
6	:    android:layout_height=""match_parent""
7	:    tools:context="".MainActivity"">
8	:  
9	:    <Button
10	:      android:id=""@+id/button_Classify""
11	:      android:layout_width=""180dp""
12	:      android:layout_height=""wrap_content""
13	:      android:layout_marginBottom=""8dp""
14	:      android:text=""Classify""
	
	
Error at 10 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:10: error: No resource identifier found for attribute 'layout_constraintStart_toEndOf' in package 'org.tensorflow.demo'
5	:    android:layout_width=""match_parent""
6	:    android:layout_height=""match_parent""
7	:    tools:context="".MainActivity"">
8	:  
9	:    <Button
10	:      android:id=""@+id/button_Classify""
11	:      android:layout_width=""180dp""
12	:      android:layout_height=""wrap_content""
13	:      android:layout_marginBottom=""8dp""
14	:      android:text=""Classify""
	
	
Error at 20 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:20: error: No resource identifier found for attribute 'layout_constraintBottom_toBottomOf' in package 'org.tensorflow.demo'
15	:      app:layout_constraintBottom_toTopOf=""@+id/button_ObjectDetection""
16	:      app:layout_constraintEnd_toEndOf=""parent""
17	:      app:layout_constraintHorizontal_bias=""0.5""
18	:      app:layout_constraintStart_toEndOf=""@+id/button_Vid2Img""/>
19	:    <Button
20	:      android:id=""@+id/button_ObjectDetection""
21	:      android:layout_width=""180dp""
22	:      android:layout_height=""wrap_content""
23	:      android:layout_marginBottom=""8dp""
24	:      android:text=""Object Detection""
	
	
Error at 20 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:20: error: No resource identifier found for attribute 'layout_constraintEnd_toEndOf' in package 'org.tensorflow.demo'
15	:      app:layout_constraintBottom_toTopOf=""@+id/button_ObjectDetection""
16	:      app:layout_constraintEnd_toEndOf=""parent""
17	:      app:layout_constraintHorizontal_bias=""0.5""
18	:      app:layout_constraintStart_toEndOf=""@+id/button_Vid2Img""/>
19	:    <Button
20	:      android:id=""@+id/button_ObjectDetection""
21	:      android:layout_width=""180dp""
22	:      android:layout_height=""wrap_content""
23	:      android:layout_marginBottom=""8dp""
24	:      android:text=""Object Detection""
	
	
Error at 20 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:20: error: No resource identifier found for attribute 'layout_constraintHorizontal_bias' in package 'org.tensorflow.demo'
15	:      app:layout_constraintBottom_toTopOf=""@+id/button_ObjectDetection""
16	:      app:layout_constraintEnd_toEndOf=""parent""
17	:      app:layout_constraintHorizontal_bias=""0.5""
18	:      app:layout_constraintStart_toEndOf=""@+id/button_Vid2Img""/>
19	:    <Button
20	:      android:id=""@+id/button_ObjectDetection""
21	:      android:layout_width=""180dp""
22	:      android:layout_height=""wrap_content""
23	:      android:layout_marginBottom=""8dp""
24	:      android:text=""Object Detection""
	
	
Error at 20 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:20: error: No resource identifier found for attribute 'layout_constraintStart_toEndOf' in package 'org.tensorflow.demo'
15	:      app:layout_constraintBottom_toTopOf=""@+id/button_ObjectDetection""
16	:      app:layout_constraintEnd_toEndOf=""parent""
17	:      app:layout_constraintHorizontal_bias=""0.5""
18	:      app:layout_constraintStart_toEndOf=""@+id/button_Vid2Img""/>
19	:    <Button
20	:      android:id=""@+id/button_ObjectDetection""
21	:      android:layout_width=""180dp""
22	:      android:layout_height=""wrap_content""
23	:      android:layout_marginBottom=""8dp""
24	:      android:text=""Object Detection""
	
	
Error at 30 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:30: error: No resource identifier found for attribute 'layout_constraintBottom_toTopOf' in package 'org.tensorflow.demo'
25	:      app:layout_constraintBottom_toBottomOf=""parent""
26	:      app:layout_constraintEnd_toEndOf=""parent""
27	:      app:layout_constraintHorizontal_bias=""0.5""
28	:      app:layout_constraintStart_toEndOf=""@+id/button_Record""/>
29	:    <Button
30	:      android:id=""@+id/button_Vid2Img""
31	:      android:layout_width=""180dp""
32	:      android:layout_height=""wrap_content""
33	:      android:layout_marginBottom=""8dp""
34	:      android:text=""Vid2Img""
	
	
Error at 30 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:30: error: No resource identifier found for attribute 'layout_constraintEnd_toStartOf' in package 'org.tensorflow.demo'
25	:      app:layout_constraintBottom_toBottomOf=""parent""
26	:      app:layout_constraintEnd_toEndOf=""parent""
27	:      app:layout_constraintHorizontal_bias=""0.5""
28	:      app:layout_constraintStart_toEndOf=""@+id/button_Record""/>
29	:    <Button
30	:      android:id=""@+id/button_Vid2Img""
31	:      android:layout_width=""180dp""
32	:      android:layout_height=""wrap_content""
33	:      android:layout_marginBottom=""8dp""
34	:      android:text=""Vid2Img""
	
	
Error at 30 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:30: error: No resource identifier found for attribute 'layout_constraintHorizontal_bias' in package 'org.tensorflow.demo'
25	:      app:layout_constraintBottom_toBottomOf=""parent""
26	:      app:layout_constraintEnd_toEndOf=""parent""
27	:      app:layout_constraintHorizontal_bias=""0.5""
28	:      app:layout_constraintStart_toEndOf=""@+id/button_Record""/>
29	:    <Button
30	:      android:id=""@+id/button_Vid2Img""
31	:      android:layout_width=""180dp""
32	:      android:layout_height=""wrap_content""
33	:      android:layout_marginBottom=""8dp""
34	:      android:text=""Vid2Img""
	
	
Error at 30 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:30: error: No resource identifier found for attribute 'layout_constraintStart_toStartOf' in package 'org.tensorflow.demo'
25	:      app:layout_constraintBottom_toBottomOf=""parent""
26	:      app:layout_constraintEnd_toEndOf=""parent""
27	:      app:layout_constraintHorizontal_bias=""0.5""
28	:      app:layout_constraintStart_toEndOf=""@+id/button_Record""/>
29	:    <Button
30	:      android:id=""@+id/button_Vid2Img""
31	:      android:layout_width=""180dp""
32	:      android:layout_height=""wrap_content""
33	:      android:layout_marginBottom=""8dp""
34	:      android:text=""Vid2Img""
	
	
Error at 40 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:40: error: No resource identifier found for attribute 'layout_constraintBottom_toBottomOf' in package 'org.tensorflow.demo'
35	:      app:layout_constraintBottom_toTopOf=""@+id/button_Record""
36	:      app:layout_constraintEnd_toStartOf=""@+id/button_Classify""
37	:      app:layout_constraintHorizontal_bias=""0.5""
38	:      app:layout_constraintStart_toStartOf=""parent""/>
39	:    <Button
40	:      android:id=""@+id/button_Record""
41	:      android:layout_width=""180dp""
42	:      android:layout_height=""wrap_content""
43	:      android:layout_marginBottom=""8dp""
44	:      android:text=""Record""
	
	
Error at 40 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:40: error: No resource identifier found for attribute 'layout_constraintEnd_toStartOf' in package 'org.tensorflow.demo'
35	:      app:layout_constraintBottom_toTopOf=""@+id/button_Record""
36	:      app:layout_constraintEnd_toStartOf=""@+id/button_Classify""
37	:      app:layout_constraintHorizontal_bias=""0.5""
38	:      app:layout_constraintStart_toStartOf=""parent""/>
39	:    <Button
40	:      android:id=""@+id/button_Record""
41	:      android:layout_width=""180dp""
42	:      android:layout_height=""wrap_content""
43	:      android:layout_marginBottom=""8dp""
44	:      android:text=""Record""
	
	
Error at 40 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:40: error: No resource identifier found for attribute 'layout_constraintHorizontal_bias' in package 'org.tensorflow.demo'
35	:      app:layout_constraintBottom_toTopOf=""@+id/button_Record""
36	:      app:layout_constraintEnd_toStartOf=""@+id/button_Classify""
37	:      app:layout_constraintHorizontal_bias=""0.5""
38	:      app:layout_constraintStart_toStartOf=""parent""/>
39	:    <Button
40	:      android:id=""@+id/button_Record""
41	:      android:layout_width=""180dp""
42	:      android:layout_height=""wrap_content""
43	:      android:layout_marginBottom=""8dp""
44	:      android:text=""Record""
	
	
Error at 40 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:40: error: No resource identifier found for attribute 'layout_constraintStart_toStartOf' in package 'org.tensorflow.demo'
35	:      app:layout_constraintBottom_toTopOf=""@+id/button_Record""
36	:      app:layout_constraintEnd_toStartOf=""@+id/button_Classify""
37	:      app:layout_constraintHorizontal_bias=""0.5""
38	:      app:layout_constraintStart_toStartOf=""parent""/>
39	:    <Button
40	:      android:id=""@+id/button_Record""
41	:      android:layout_width=""180dp""
42	:      android:layout_height=""wrap_content""
43	:      android:layout_marginBottom=""8dp""
44	:      android:text=""Record""
	
	
Error at 24 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:24: error: No resource identifier found for attribute 'layout_constraintBottom_toTopOf' in package 'org.tensorflow.demo'
19	:      android:layout_width=""match_parent""
20	:      android:layout_height=""match_parent""
21	:      tools:layout_editor_absoluteY=""89dp"">
22	:  
23	:      <org.tensorflow.demo.einardan.AutoFitTextureView
24	:          android:id=""@+id/texture""
25	:          android:layout_width=""0dp""
26	:          android:layout_height=""0dp""
27	:          app:layout_constraintBottom_toTopOf=""@+id/constraintLayout""
28	:          app:layout_constraintEnd_toEndOf=""parent""
	
	
Error at 24 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:24: error: No resource identifier found for attribute 'layout_constraintEnd_toEndOf' in package 'org.tensorflow.demo'
19	:      android:layout_width=""match_parent""
20	:      android:layout_height=""match_parent""
21	:      tools:layout_editor_absoluteY=""89dp"">
22	:  
23	:      <org.tensorflow.demo.einardan.AutoFitTextureView
24	:          android:id=""@+id/texture""
25	:          android:layout_width=""0dp""
26	:          android:layout_height=""0dp""
27	:          app:layout_constraintBottom_toTopOf=""@+id/constraintLayout""
28	:          app:layout_constraintEnd_toEndOf=""parent""
	
	
Error at 24 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:24: error: No resource identifier found for attribute 'layout_constraintStart_toStartOf' in package 'org.tensorflow.demo'
19	:      android:layout_width=""match_parent""
20	:      android:layout_height=""match_parent""
21	:      tools:layout_editor_absoluteY=""89dp"">
22	:  
23	:      <org.tensorflow.demo.einardan.AutoFitTextureView
24	:          android:id=""@+id/texture""
25	:          android:layout_width=""0dp""
26	:          android:layout_height=""0dp""
27	:          app:layout_constraintBottom_toTopOf=""@+id/constraintLayout""
28	:          app:layout_constraintEnd_toEndOf=""parent""
	
	
Error at 24 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:24: error: No resource identifier found for attribute 'layout_constraintTop_toTopOf' in package 'org.tensorflow.demo'
19	:      android:layout_width=""match_parent""
20	:      android:layout_height=""match_parent""
21	:      tools:layout_editor_absoluteY=""89dp"">
22	:  
23	:      <org.tensorflow.demo.einardan.AutoFitTextureView
24	:          android:id=""@+id/texture""
25	:          android:layout_width=""0dp""
26	:          android:layout_height=""0dp""
27	:          app:layout_constraintBottom_toTopOf=""@+id/constraintLayout""
28	:          app:layout_constraintEnd_toEndOf=""parent""
	
	
Error at 33 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:33: error: No resource identifier found for attribute 'layout_constraintBottom_toBottomOf' in package 'org.tensorflow.demo'
28	:          app:layout_constraintEnd_toEndOf=""parent""
29	:          app:layout_constraintStart_toStartOf=""parent""
30	:          app:layout_constraintTop_toTopOf=""parent"" />
31	:  
32	:      <android.support.constraint.ConstraintLayout
33	:          android:id=""@+id/constraintLayout""
34	:          android:layout_width=""match_parent""
35	:          android:layout_height=""50dp""
36	:          android:background=""#4285f4""
37	:          app:layout_constraintBottom_toBottomOf=""parent""
	
	
Error at 33 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:33: error: No resource identifier found for attribute 'layout_constraintTop_toBottomOf' in package 'org.tensorflow.demo'
28	:          app:layout_constraintEnd_toEndOf=""parent""
29	:          app:layout_constraintStart_toStartOf=""parent""
30	:          app:layout_constraintTop_toTopOf=""parent"" />
31	:  
32	:      <android.support.constraint.ConstraintLayout
33	:          android:id=""@+id/constraintLayout""
34	:          android:layout_width=""match_parent""
35	:          android:layout_height=""50dp""
36	:          android:background=""#4285f4""
37	:          app:layout_constraintBottom_toBottomOf=""parent""
	
	
Error at 41 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:41: error: No resource identifier found for attribute 'layout_constraintBottom_toBottomOf' in package 'org.tensorflow.demo'
36	:          android:background=""#4285f4""
37	:          app:layout_constraintBottom_toBottomOf=""parent""
38	:          app:layout_constraintTop_toBottomOf=""@+id/texture"">
39	:  
40	:          <Button
41	:              android:id=""@+id/button_start_recording_video""
42	:              android:layout_width=""0dp""
43	:              android:layout_height=""0dp""
44	:              android:layout_marginEnd=""8dp""
45	:              android:layout_marginStart=""8dp""
	
	
Error at 41 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:41: error: No resource identifier found for attribute 'layout_constraintEnd_toEndOf' in package 'org.tensorflow.demo'
36	:          android:background=""#4285f4""
37	:          app:layout_constraintBottom_toBottomOf=""parent""
38	:          app:layout_constraintTop_toBottomOf=""@+id/texture"">
39	:  
40	:          <Button
41	:              android:id=""@+id/button_start_recording_video""
42	:              android:layout_width=""0dp""
43	:              android:layout_height=""0dp""
44	:              android:layout_marginEnd=""8dp""
45	:              android:layout_marginStart=""8dp""
	
	
Error at 41 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:41: error: No resource identifier found for attribute 'layout_constraintHorizontal_bias' in package 'org.tensorflow.demo'
36	:          android:background=""#4285f4""
37	:          app:layout_constraintBottom_toBottomOf=""parent""
38	:          app:layout_constraintTop_toBottomOf=""@+id/texture"">
39	:  
40	:          <Button
41	:              android:id=""@+id/button_start_recording_video""
42	:              android:layout_width=""0dp""
43	:              android:layout_height=""0dp""
44	:              android:layout_marginEnd=""8dp""
45	:              android:layout_marginStart=""8dp""
	
	
Error at 41 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:41: error: No resource identifier found for attribute 'layout_constraintStart_toEndOf' in package 'org.tensorflow.demo'
36	:          android:background=""#4285f4""
37	:          app:layout_constraintBottom_toBottomOf=""parent""
38	:          app:layout_constraintTop_toBottomOf=""@+id/texture"">
39	:  
40	:          <Button
41	:              android:id=""@+id/button_start_recording_video""
42	:              android:layout_width=""0dp""
43	:              android:layout_height=""0dp""
44	:              android:layout_marginEnd=""8dp""
45	:              android:layout_marginStart=""8dp""
	
	
Error at 41 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:41: error: No resource identifier found for attribute 'layout_constraintTop_toTopOf' in package 'org.tensorflow.demo'
36	:          android:background=""#4285f4""
37	:          app:layout_constraintBottom_toBottomOf=""parent""
38	:          app:layout_constraintTop_toBottomOf=""@+id/texture"">
39	:  
40	:          <Button
41	:              android:id=""@+id/button_start_recording_video""
42	:              android:layout_width=""0dp""
43	:              android:layout_height=""0dp""
44	:              android:layout_marginEnd=""8dp""
45	:              android:layout_marginStart=""8dp""
	
	
Error at 56 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:56: error: No resource identifier found for attribute 'layout_constraintBottom_toBottomOf' in package 'org.tensorflow.demo'
51	:              app:layout_constraintStart_toEndOf=""@+id/button_convert_videos_to_images""
52	:              app:layout_constraintTop_toTopOf=""parent"" />
53	:  
54	:  
55	:          <Button
56	:              android:id=""@+id/button_stop_recording_video""
57	:              android:layout_width=""0dp""
58	:              android:layout_height=""0dp""
59	:              android:layout_marginEnd=""8dp""
60	:              android:layout_marginStart=""8dp""
	
	
Error at 56 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:56: error: No resource identifier found for attribute 'layout_constraintEnd_toEndOf' in package 'org.tensorflow.demo'
51	:              app:layout_constraintStart_toEndOf=""@+id/button_convert_videos_to_images""
52	:              app:layout_constraintTop_toTopOf=""parent"" />
53	:  
54	:  
55	:          <Button
56	:              android:id=""@+id/button_stop_recording_video""
57	:              android:layout_width=""0dp""
58	:              android:layout_height=""0dp""
59	:              android:layout_marginEnd=""8dp""
60	:              android:layout_marginStart=""8dp""
	
	
Error at 56 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:56: error: No resource identifier found for attribute 'layout_constraintHorizontal_bias' in package 'org.tensorflow.demo'
51	:              app:layout_constraintStart_toEndOf=""@+id/button_convert_videos_to_images""
52	:              app:layout_constraintTop_toTopOf=""parent"" />
53	:  
54	:  
55	:          <Button
56	:              android:id=""@+id/button_stop_recording_video""
57	:              android:layout_width=""0dp""
58	:              android:layout_height=""0dp""
59	:              android:layout_marginEnd=""8dp""
60	:              android:layout_marginStart=""8dp""
	
	
Error at 56 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:56: error: No resource identifier found for attribute 'layout_constraintStart_toEndOf' in package 'org.tensorflow.demo'
51	:              app:layout_constraintStart_toEndOf=""@+id/button_convert_videos_to_images""
52	:              app:layout_constraintTop_toTopOf=""parent"" />
53	:  
54	:  
55	:          <Button
56	:              android:id=""@+id/button_stop_recording_video""
57	:              android:layout_width=""0dp""
58	:              android:layout_height=""0dp""
59	:              android:layout_marginEnd=""8dp""
60	:              android:layout_marginStart=""8dp""
	
	
Error at 56 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:56: error: No resource identifier found for attribute 'layout_constraintTop_toTopOf' in package 'org.tensorflow.demo'
51	:              app:layout_constraintStart_toEndOf=""@+id/button_convert_videos_to_images""
52	:              app:layout_constraintTop_toTopOf=""parent"" />
53	:  
54	:  
55	:          <Button
56	:              android:id=""@+id/button_stop_recording_video""
57	:              android:layout_width=""0dp""
58	:              android:layout_height=""0dp""
59	:              android:layout_marginEnd=""8dp""
60	:              android:layout_marginStart=""8dp""
	
	
Error at 70 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:70: error: No resource identifier found for attribute 'layout_constraintBottom_toBottomOf' in package 'org.tensorflow.demo'
65	:              app:layout_constraintHorizontal_bias=""0.5""
66	:              app:layout_constraintStart_toEndOf=""@+id/button_convert_videos_to_images""
67	:              app:layout_constraintTop_toTopOf=""parent"" />
68	:  
69	:          <Button
70	:              android:id=""@+id/button_convert_videos_to_images""
71	:              android:layout_width=""0dp""
72	:              android:layout_height=""0dp""
73	:              android:layout_marginEnd=""8dp""
74	:              android:layout_marginStart=""8dp""
	
	
Error at 70 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:70: error: No resource identifier found for attribute 'layout_constraintEnd_toStartOf' in package 'org.tensorflow.demo'
65	:              app:layout_constraintHorizontal_bias=""0.5""
66	:              app:layout_constraintStart_toEndOf=""@+id/button_convert_videos_to_images""
67	:              app:layout_constraintTop_toTopOf=""parent"" />
68	:  
69	:          <Button
70	:              android:id=""@+id/button_convert_videos_to_images""
71	:              android:layout_width=""0dp""
72	:              android:layout_height=""0dp""
73	:              android:layout_marginEnd=""8dp""
74	:              android:layout_marginStart=""8dp""
	
	
Error at 70 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:70: error: No resource identifier found for attribute 'layout_constraintHorizontal_bias' in package 'org.tensorflow.demo'
65	:              app:layout_constraintHorizontal_bias=""0.5""
66	:              app:layout_constraintStart_toEndOf=""@+id/button_convert_videos_to_images""
67	:              app:layout_constraintTop_toTopOf=""parent"" />
68	:  
69	:          <Button
70	:              android:id=""@+id/button_convert_videos_to_images""
71	:              android:layout_width=""0dp""
72	:              android:layout_height=""0dp""
73	:              android:layout_marginEnd=""8dp""
74	:              android:layout_marginStart=""8dp""
	
	
Error at 70 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:70: error: No resource identifier found for attribute 'layout_constraintStart_toStartOf' in package 'org.tensorflow.demo'
65	:              app:layout_constraintHorizontal_bias=""0.5""
66	:              app:layout_constraintStart_toEndOf=""@+id/button_convert_videos_to_images""
67	:              app:layout_constraintTop_toTopOf=""parent"" />
68	:  
69	:          <Button
70	:              android:id=""@+id/button_convert_videos_to_images""
71	:              android:layout_width=""0dp""
72	:              android:layout_height=""0dp""
73	:              android:layout_marginEnd=""8dp""
74	:              android:layout_marginStart=""8dp""
	
	
Error at 70 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:70: error: No resource identifier found for attribute 'layout_constraintTop_toTopOf' in package 'org.tensorflow.demo'
65	:              app:layout_constraintHorizontal_bias=""0.5""
66	:              app:layout_constraintStart_toEndOf=""@+id/button_convert_videos_to_images""
67	:              app:layout_constraintTop_toTopOf=""parent"" />
68	:  
69	:          <Button
70	:              android:id=""@+id/button_convert_videos_to_images""
71	:              android:layout_width=""0dp""
72	:              android:layout_height=""0dp""
73	:              android:layout_marginEnd=""8dp""
74	:              android:layout_marginStart=""8dp""
	
	
Error at 11 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:11: error: No resource identifier found for attribute 'layout_constraintEnd_toEndOf' in package 'org.tensorflow.demo'
6	:    tools:context=""org.tensorflow.demo.einardan.Video2ImageConversionFragment"">
7	:  
8	:    <!-- TODO: Update blank fragment layout -->
9	:  
10	:    <TextView
11	:      android:id=""@+id/textView_conversion_info""
12	:      android:layout_width=""wrap_content""
13	:      android:layout_height=""wrap_content""
14	:      android:layout_marginTop=""16dp""
15	:      android:layout_marginStart=""16dp""
	
	
Error at 11 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:11: error: No resource identifier found for attribute 'layout_constraintHorizontal_bias' in package 'org.tensorflow.demo'
6	:    tools:context=""org.tensorflow.demo.einardan.Video2ImageConversionFragment"">
7	:  
8	:    <!-- TODO: Update blank fragment layout -->
9	:  
10	:    <TextView
11	:      android:id=""@+id/textView_conversion_info""
12	:      android:layout_width=""wrap_content""
13	:      android:layout_height=""wrap_content""
14	:      android:layout_marginTop=""16dp""
15	:      android:layout_marginStart=""16dp""
	
	
Error at 11 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:11: error: No resource identifier found for attribute 'layout_constraintStart_toStartOf' in package 'org.tensorflow.demo'
6	:    tools:context=""org.tensorflow.demo.einardan.Video2ImageConversionFragment"">
7	:  
8	:    <!-- TODO: Update blank fragment layout -->
9	:  
10	:    <TextView
11	:      android:id=""@+id/textView_conversion_info""
12	:      android:layout_width=""wrap_content""
13	:      android:layout_height=""wrap_content""
14	:      android:layout_marginTop=""16dp""
15	:      android:layout_marginStart=""16dp""
	
	
Error at 11 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:11: error: No resource identifier found for attribute 'layout_constraintTop_toTopOf' in package 'org.tensorflow.demo'
6	:    tools:context=""org.tensorflow.demo.einardan.Video2ImageConversionFragment"">
7	:  
8	:    <!-- TODO: Update blank fragment layout -->
9	:  
10	:    <TextView
11	:      android:id=""@+id/textView_conversion_info""
12	:      android:layout_width=""wrap_content""
13	:      android:layout_height=""wrap_content""
14	:      android:layout_marginTop=""16dp""
15	:      android:layout_marginStart=""16dp""
	
	
Error at 26 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:26: error: No resource identifier found for attribute 'layout_constraintEnd_toEndOf' in package 'org.tensorflow.demo'
21	:      app:layout_constraintHorizontal_bias=""0.5""
22	:      app:layout_constraintStart_toStartOf=""parent""
23	:      app:layout_constraintTop_toTopOf=""parent""/>
24	:  
25	:    <Button
26	:      android:id=""@+id/button_begin_conversion""
27	:      android:layout_width=""wrap_content""
28	:      android:layout_height=""wrap_content""
29	:      android:layout_marginTop=""18dp""
30	:      android:text=""@string/button_BeginConversion""
	
	
Error at 26 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:26: error: No resource identifier found for attribute 'layout_constraintHorizontal_bias' in package 'org.tensorflow.demo'
21	:      app:layout_constraintHorizontal_bias=""0.5""
22	:      app:layout_constraintStart_toStartOf=""parent""
23	:      app:layout_constraintTop_toTopOf=""parent""/>
24	:  
25	:    <Button
26	:      android:id=""@+id/button_begin_conversion""
27	:      android:layout_width=""wrap_content""
28	:      android:layout_height=""wrap_content""
29	:      android:layout_marginTop=""18dp""
30	:      android:text=""@string/button_BeginConversion""
	
	
Error at 26 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:26: error: No resource identifier found for attribute 'layout_constraintStart_toStartOf' in package 'org.tensorflow.demo'
21	:      app:layout_constraintHorizontal_bias=""0.5""
22	:      app:layout_constraintStart_toStartOf=""parent""
23	:      app:layout_constraintTop_toTopOf=""parent""/>
24	:  
25	:    <Button
26	:      android:id=""@+id/button_begin_conversion""
27	:      android:layout_width=""wrap_content""
28	:      android:layout_height=""wrap_content""
29	:      android:layout_marginTop=""18dp""
30	:      android:text=""@string/button_BeginConversion""
	
	
Error at 26 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:26: error: No resource identifier found for attribute 'layout_constraintTop_toBottomOf' in package 'org.tensorflow.demo'
21	:      app:layout_constraintHorizontal_bias=""0.5""
22	:      app:layout_constraintStart_toStartOf=""parent""
23	:      app:layout_constraintTop_toTopOf=""parent""/>
24	:  
25	:    <Button
26	:      android:id=""@+id/button_begin_conversion""
27	:      android:layout_width=""wrap_content""
28	:      android:layout_height=""wrap_content""
29	:      android:layout_marginTop=""18dp""
30	:      android:text=""@string/button_BeginConversion""
	
	
Error at 37 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:37: error: No resource identifier found for attribute 'layout_constraintBottom_toBottomOf' in package 'org.tensorflow.demo'
32	:      app:layout_constraintHorizontal_bias=""0.5""
33	:      app:layout_constraintStart_toStartOf=""parent""
34	:      app:layout_constraintTop_toBottomOf=""@+id/textView_conversion_info""/>
35	:  
36	:    <Button
37	:      android:id=""@+id/button_back_to_video_recording""
38	:      android:layout_width=""wrap_content""
39	:      android:layout_height=""wrap_content""
40	:      android:layout_marginBottom=""66dp""
41	:      android:text=""Back to Video Recording""
	
	
Error at 37 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:37: error: No resource identifier found for attribute 'layout_constraintEnd_toEndOf' in package 'org.tensorflow.demo'
32	:      app:layout_constraintHorizontal_bias=""0.5""
33	:      app:layout_constraintStart_toStartOf=""parent""
34	:      app:layout_constraintTop_toBottomOf=""@+id/textView_conversion_info""/>
35	:  
36	:    <Button
37	:      android:id=""@+id/button_back_to_video_recording""
38	:      android:layout_width=""wrap_content""
39	:      android:layout_height=""wrap_content""
40	:      android:layout_marginBottom=""66dp""
41	:      android:text=""Back to Video Recording""
	
	
Error at 37 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:37: error: No resource identifier found for attribute 'layout_constraintHorizontal_bias' in package 'org.tensorflow.demo'
32	:      app:layout_constraintHorizontal_bias=""0.5""
33	:      app:layout_constraintStart_toStartOf=""parent""
34	:      app:layout_constraintTop_toBottomOf=""@+id/textView_conversion_info""/>
35	:  
36	:    <Button
37	:      android:id=""@+id/button_back_to_video_recording""
38	:      android:layout_width=""wrap_content""
39	:      android:layout_height=""wrap_content""
40	:      android:layout_marginBottom=""66dp""
41	:      android:text=""Back to Video Recording""
	
	
Error at 37 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:37: error: No resource identifier found for attribute 'layout_constraintStart_toStartOf' in package 'org.tensorflow.demo'
32	:      app:layout_constraintHorizontal_bias=""0.5""
33	:      app:layout_constraintStart_toStartOf=""parent""
34	:      app:layout_constraintTop_toBottomOf=""@+id/textView_conversion_info""/>
35	:  
36	:    <Button
37	:      android:id=""@+id/button_back_to_video_recording""
38	:      android:layout_width=""wrap_content""
39	:      android:layout_height=""wrap_content""
40	:      android:layout_marginBottom=""66dp""
41	:      android:text=""Back to Video Recording""
	
	
Error at 48 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:48: error: No resource identifier found for attribute 'layout_constraintBottom_toTopOf' in package 'org.tensorflow.demo'
43	:      app:layout_constraintEnd_toEndOf=""parent""
44	:      app:layout_constraintHorizontal_bias=""0.5""
45	:      app:layout_constraintStart_toStartOf=""parent""/>
46	:  
47	:    <Button
48	:      android:id=""@+id/button_delete_recorded_videos""
49	:      android:layout_width=""wrap_content""
50	:      android:layout_height=""wrap_content""
51	:      android:layout_marginBottom=""71dp""
52	:      android:layout_marginStart=""3dp""
	
	
Error at 48 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:48: error: No resource identifier found for attribute 'layout_constraintStart_toStartOf' in package 'org.tensorflow.demo'
43	:      app:layout_constraintEnd_toEndOf=""parent""
44	:      app:layout_constraintHorizontal_bias=""0.5""
45	:      app:layout_constraintStart_toStartOf=""parent""/>
46	:  
47	:    <Button
48	:      android:id=""@+id/button_delete_recorded_videos""
49	:      android:layout_width=""wrap_content""
50	:      android:layout_height=""wrap_content""
51	:      android:layout_marginBottom=""71dp""
52	:      android:layout_marginStart=""3dp""
	
	
Error at 57 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:57: error: No resource identifier found for attribute 'layout_constraintEnd_toStartOf' in package 'org.tensorflow.demo'
52	:      android:layout_marginStart=""3dp""
53	:      android:text=""Delete Recorded Videos""
54	:      app:layout_constraintBottom_toTopOf=""@+id/button_back_to_video_recording""
55	:      app:layout_constraintStart_toStartOf=""@+id/button_back_to_video_recording""/>
56	:    <Button
57	:      android:id=""@+id/button_launch_object_detection""
58	:      android:layout_width=""0dp""
59	:      android:layout_height=""wrap_content""
60	:      android:layout_marginTop=""33dp""
61	:      android:layout_marginStart=""8dp""
	
	
Error at 57 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:57: error: No resource identifier found for attribute 'layout_constraintStart_toStartOf' in package 'org.tensorflow.demo'
52	:      android:layout_marginStart=""3dp""
53	:      android:text=""Delete Recorded Videos""
54	:      app:layout_constraintBottom_toTopOf=""@+id/button_back_to_video_recording""
55	:      app:layout_constraintStart_toStartOf=""@+id/button_back_to_video_recording""/>
56	:    <Button
57	:      android:id=""@+id/button_launch_object_detection""
58	:      android:layout_width=""0dp""
59	:      android:layout_height=""wrap_content""
60	:      android:layout_marginTop=""33dp""
61	:      android:layout_marginStart=""8dp""
	
	
Error at 57 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:57: error: No resource identifier found for attribute 'layout_constraintTop_toBottomOf' in package 'org.tensorflow.demo'
52	:      android:layout_marginStart=""3dp""
53	:      android:text=""Delete Recorded Videos""
54	:      app:layout_constraintBottom_toTopOf=""@+id/button_back_to_video_recording""
55	:      app:layout_constraintStart_toStartOf=""@+id/button_back_to_video_recording""/>
56	:    <Button
57	:      android:id=""@+id/button_launch_object_detection""
58	:      android:layout_width=""0dp""
59	:      android:layout_height=""wrap_content""
60	:      android:layout_marginTop=""33dp""
61	:      android:layout_marginStart=""8dp""
	
	
Error at 69 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:69: error: No resource identifier found for attribute 'layout_constraintEnd_toEndOf' in package 'org.tensorflow.demo'
64	:      app:layout_constraintEnd_toStartOf=""@+id/button_launch_image_classification""
65	:      app:layout_constraintStart_toStartOf=""parent""
66	:      app:layout_constraintTop_toBottomOf=""@+id/button_begin_conversion""
67	:      />
68	:    <Button
69	:      android:id=""@+id/button_launch_image_classification""
70	:      android:layout_width=""0dp""
71	:      android:layout_height=""wrap_content""
72	:      android:layout_marginEnd=""8dp""
73	:      android:text=""Image Classification""
	
	
Error at 69 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:69: error: No resource identifier found for attribute 'layout_constraintStart_toEndOf' in package 'org.tensorflow.demo'
64	:      app:layout_constraintEnd_toStartOf=""@+id/button_launch_image_classification""
65	:      app:layout_constraintStart_toStartOf=""parent""
66	:      app:layout_constraintTop_toBottomOf=""@+id/button_begin_conversion""
67	:      />
68	:    <Button
69	:      android:id=""@+id/button_launch_image_classification""
70	:      android:layout_width=""0dp""
71	:      android:layout_height=""wrap_content""
72	:      android:layout_marginEnd=""8dp""
73	:      android:text=""Image Classification""
	
	
Error at 69 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:69: error: No resource identifier found for attribute 'layout_constraintTop_toTopOf' in package 'org.tensorflow.demo'
64	:      app:layout_constraintEnd_toStartOf=""@+id/button_launch_image_classification""
65	:      app:layout_constraintStart_toStartOf=""parent""
66	:      app:layout_constraintTop_toBottomOf=""@+id/button_begin_conversion""
67	:      />
68	:    <Button
69	:      android:id=""@+id/button_launch_image_classification""
70	:      android:layout_width=""0dp""
71	:      android:layout_height=""wrap_content""
72	:      android:layout_marginEnd=""8dp""
73	:      android:text=""Image Classification""
	
	
Error at 13 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_label.xml:13: error: No resource identifier found for attribute 'layout_constraintEnd_toEndOf' in package 'org.tensorflow.demo'
8	:    tools:context=""org.tensorflow.demo.einardan.VideoLabelFragment""
9	:    tools:layout_editor_absoluteY=""81dp"">
10	:  
11	:  
12	:    <EditText
13	:      android:id=""@+id/editText_user_input_label""
14	:      android:layout_width=""match_parent""
15	:      android:layout_height=""wrap_content""
16	:      android:layout_marginTop=""21dp""
17	:      android:layout_marginStart=""24dp""
	
	
Error at 13 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_label.xml:13: error: No resource identifier found for attribute 'layout_constraintHorizontal_bias' in package 'org.tensorflow.demo'
8	:    tools:context=""org.tensorflow.demo.einardan.VideoLabelFragment""
9	:    tools:layout_editor_absoluteY=""81dp"">
10	:  
11	:  
12	:    <EditText
13	:      android:id=""@+id/editText_user_input_label""
14	:      android:layout_width=""match_parent""
15	:      android:layout_height=""wrap_content""
16	:      android:layout_marginTop=""21dp""
17	:      android:layout_marginStart=""24dp""
	
	
Error at 13 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_label.xml:13: error: No resource identifier found for attribute 'layout_constraintStart_toStartOf' in package 'org.tensorflow.demo'
8	:    tools:context=""org.tensorflow.demo.einardan.VideoLabelFragment""
9	:    tools:layout_editor_absoluteY=""81dp"">
10	:  
11	:  
12	:    <EditText
13	:      android:id=""@+id/editText_user_input_label""
14	:      android:layout_width=""match_parent""
15	:      android:layout_height=""wrap_content""
16	:      android:layout_marginTop=""21dp""
17	:      android:layout_marginStart=""24dp""
	
	
Error at 13 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_label.xml:13: error: No resource identifier found for attribute 'layout_constraintTop_toBottomOf' in package 'org.tensorflow.demo'
8	:    tools:context=""org.tensorflow.demo.einardan.VideoLabelFragment""
9	:    tools:layout_editor_absoluteY=""81dp"">
10	:  
11	:  
12	:    <EditText
13	:      android:id=""@+id/editText_user_input_label""
14	:      android:layout_width=""match_parent""
15	:      android:layout_height=""wrap_content""
16	:      android:layout_marginTop=""21dp""
17	:      android:layout_marginStart=""24dp""
	
	
Error at 30 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_label.xml:30: error: No resource identifier found for attribute 'layout_constraintEnd_toEndOf' in package 'org.tensorflow.demo'
25	:      app:layout_constraintStart_toStartOf=""parent""
26	:      app:layout_constraintTop_toBottomOf=""@+id/textView_user_prompt""/>
27	:  
28	:  
29	:    <TextView
30	:      android:id=""@+id/textView_user_prompt""
31	:      android:layout_width=""wrap_content""
32	:      android:layout_height=""wrap_content""
33	:      android:layout_marginTop=""34dp""
34	:      android:text=""@string/enter_video_label""
	
	
Error at 30 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_label.xml:30: error: No resource identifier found for attribute 'layout_constraintHorizontal_bias' in package 'org.tensorflow.demo'
25	:      app:layout_constraintStart_toStartOf=""parent""
26	:      app:layout_constraintTop_toBottomOf=""@+id/textView_user_prompt""/>
27	:  
28	:  
29	:    <TextView
30	:      android:id=""@+id/textView_user_prompt""
31	:      android:layout_width=""wrap_content""
32	:      android:layout_height=""wrap_content""
33	:      android:layout_marginTop=""34dp""
34	:      android:text=""@string/enter_video_label""
	
	
Error at 30 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_label.xml:30: error: No resource identifier found for attribute 'layout_constraintStart_toStartOf' in package 'org.tensorflow.demo'
25	:      app:layout_constraintStart_toStartOf=""parent""
26	:      app:layout_constraintTop_toBottomOf=""@+id/textView_user_prompt""/>
27	:  
28	:  
29	:    <TextView
30	:      android:id=""@+id/textView_user_prompt""
31	:      android:layout_width=""wrap_content""
32	:      android:layout_height=""wrap_content""
33	:      android:layout_marginTop=""34dp""
34	:      android:text=""@string/enter_video_label""
	
	
Error at 30 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_label.xml:30: error: No resource identifier found for attribute 'layout_constraintTop_toTopOf' in package 'org.tensorflow.demo'
25	:      app:layout_constraintStart_toStartOf=""parent""
26	:      app:layout_constraintTop_toBottomOf=""@+id/textView_user_prompt""/>
27	:  
28	:  
29	:    <TextView
30	:      android:id=""@+id/textView_user_prompt""
31	:      android:layout_width=""wrap_content""
32	:      android:layout_height=""wrap_content""
33	:      android:layout_marginTop=""34dp""
34	:      android:text=""@string/enter_video_label""
	
	
Error at 42 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_label.xml:42: error: No resource identifier found for attribute 'layout_constraintEnd_toEndOf' in package 'org.tensorflow.demo'
37	:      app:layout_constraintHorizontal_bias=""0.5""
38	:      app:layout_constraintStart_toStartOf=""parent""
39	:      app:layout_constraintTop_toTopOf=""parent""/>
40	:  
41	:    <Button
42	:      android:id=""@+id/button_OK""
43	:      android:layout_width=""wrap_content""
44	:      android:layout_height=""wrap_content""
45	:      android:layout_marginTop=""8dp""
46	:      android:text=""OK""
	
	
Error at 42 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_label.xml:42: error: No resource identifier found for attribute 'layout_constraintHorizontal_bias' in package 'org.tensorflow.demo'
37	:      app:layout_constraintHorizontal_bias=""0.5""
38	:      app:layout_constraintStart_toStartOf=""parent""
39	:      app:layout_constraintTop_toTopOf=""parent""/>
40	:  
41	:    <Button
42	:      android:id=""@+id/button_OK""
43	:      android:layout_width=""wrap_content""
44	:      android:layout_height=""wrap_content""
45	:      android:layout_marginTop=""8dp""
46	:      android:text=""OK""
	
	
Error at 42 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_label.xml:42: error: No resource identifier found for attribute 'layout_constraintStart_toStartOf' in package 'org.tensorflow.demo'
37	:      app:layout_constraintHorizontal_bias=""0.5""
38	:      app:layout_constraintStart_toStartOf=""parent""
39	:      app:layout_constraintTop_toTopOf=""parent""/>
40	:  
41	:    <Button
42	:      android:id=""@+id/button_OK""
43	:      android:layout_width=""wrap_content""
44	:      android:layout_height=""wrap_content""
45	:      android:layout_marginTop=""8dp""
46	:      android:text=""OK""
	
	
Error at 42 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_label.xml:42: error: No resource identifier found for attribute 'layout_constraintTop_toBottomOf' in package 'org.tensorflow.demo'
37	:      app:layout_constraintHorizontal_bias=""0.5""
38	:      app:layout_constraintStart_toStartOf=""parent""
39	:      app:layout_constraintTop_toTopOf=""parent""/>
40	:  
41	:    <Button
42	:      android:id=""@+id/button_OK""
43	:      android:layout_width=""wrap_content""
44	:      android:layout_height=""wrap_content""
45	:      android:layout_marginTop=""8dp""
46	:      android:text=""OK""
	

	at com.google.devtools.build.android.AndroidResourceProcessor.runAapt(AndroidResourceProcessor.java:448)
	at com.google.devtools.build.android.AndroidResourceProcessor.processResources(AndroidResourceProcessor.java:315)
	at com.google.devtools.build.android.AndroidResourceProcessingAction.main(AndroidResourceProcessingAction.java:465)
	at com.google.devtools.build.android.ResourceProcessorBusyBox$Tool$1.call(ResourceProcessorBusyBox.java:61)
	at com.google.devtools.build.android.ResourceProcessorBusyBox.main(ResourceProcessorBusyBox.java:188)

Exception in thread ""main"" com.android.ide.common.internal.LoggedErrorException: Failed to run command:
	bazel-out/host/bin/external/androidsdk/aapt_binary package -f --no-crunch --no-version-vectors -I external/androidsdk/platforms/android-26/android.jar -M /tmp/android_resources_tmp2553409785033894779/AndroidManifest.xml -S /tmp/android_resources_tmp2553409785033894779/merged_resources -A /tmp/android_resources_tmp2553409785033894779/merged_assets -m -J /tmp/android_resources_tmp2553409785033894779/generated_resources --output-text-symbols /tmp/android_resources_tmp2553409785033894779/generated_resources -F bazel-out/k8-opt/bin/tensorflow/examples/android/tensorflow_demo.ap_ -G bazel-out/k8-opt/bin/tensorflow/examples/android/proguard/tensorflow_demo/_tensorflow_demo_proguard.cfg -D bazel-out/k8-opt/bin/tensorflow/examples/android/proguard/tensorflow_demo/main_dex_tensorflow_demo_proguard.cfg -P /tmp/android_resources_tmp2553409785033894779/merged_resources/values/public.xml --custom-package org.tensorflow.demo -0 apk
Error Code:
	1
Output:
	
Error at 10 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:10: error: No resource identifier found for attribute 'layout_constraintBottom_toTopOf' in package 'org.tensorflow.demo'
5	:    android:layout_width=""match_parent""
6	:    android:layout_height=""match_parent""
7	:    tools:context="".MainActivity"">
8	:  
9	:    <Button
10	:      android:id=""@+id/button_Classify""
11	:      android:layout_width=""180dp""
12	:      android:layout_height=""wrap_content""
13	:      android:layout_marginBottom=""8dp""
14	:      android:text=""Classify""
	
	
Error at 10 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:10: error: No resource identifier found for attribute 'layout_constraintEnd_toEndOf' in package 'org.tensorflow.demo'
5	:    android:layout_width=""match_parent""
6	:    android:layout_height=""match_parent""
7	:    tools:context="".MainActivity"">
8	:  
9	:    <Button
10	:      android:id=""@+id/button_Classify""
11	:      android:layout_width=""180dp""
12	:      android:layout_height=""wrap_content""
13	:      android:layout_marginBottom=""8dp""
14	:      android:text=""Classify""
	
	
Error at 10 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:10: error: No resource identifier found for attribute 'layout_constraintHorizontal_bias' in package 'org.tensorflow.demo'
5	:    android:layout_width=""match_parent""
6	:    android:layout_height=""match_parent""
7	:    tools:context="".MainActivity"">
8	:  
9	:    <Button
10	:      android:id=""@+id/button_Classify""
11	:      android:layout_width=""180dp""
12	:      android:layout_height=""wrap_content""
13	:      android:layout_marginBottom=""8dp""
14	:      android:text=""Classify""
	
	
Error at 10 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:10: error: No resource identifier found for attribute 'layout_constraintStart_toEndOf' in package 'org.tensorflow.demo'
5	:    android:layout_width=""match_parent""
6	:    android:layout_height=""match_parent""
7	:    tools:context="".MainActivity"">
8	:  
9	:    <Button
10	:      android:id=""@+id/button_Classify""
11	:      android:layout_width=""180dp""
12	:      android:layout_height=""wrap_content""
13	:      android:layout_marginBottom=""8dp""
14	:      android:text=""Classify""
	
	
Error at 20 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:20: error: No resource identifier found for attribute 'layout_constraintBottom_toBottomOf' in package 'org.tensorflow.demo'
15	:      app:layout_constraintBottom_toTopOf=""@+id/button_ObjectDetection""
16	:      app:layout_constraintEnd_toEndOf=""parent""
17	:      app:layout_constraintHorizontal_bias=""0.5""
18	:      app:layout_constraintStart_toEndOf=""@+id/button_Vid2Img""/>
19	:    <Button
20	:      android:id=""@+id/button_ObjectDetection""
21	:      android:layout_width=""180dp""
22	:      android:layout_height=""wrap_content""
23	:      android:layout_marginBottom=""8dp""
24	:      android:text=""Object Detection""
	
	
Error at 20 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:20: error: No resource identifier found for attribute 'layout_constraintEnd_toEndOf' in package 'org.tensorflow.demo'
15	:      app:layout_constraintBottom_toTopOf=""@+id/button_ObjectDetection""
16	:      app:layout_constraintEnd_toEndOf=""parent""
17	:      app:layout_constraintHorizontal_bias=""0.5""
18	:      app:layout_constraintStart_toEndOf=""@+id/button_Vid2Img""/>
19	:    <Button
20	:      android:id=""@+id/button_ObjectDetection""
21	:      android:layout_width=""180dp""
22	:      android:layout_height=""wrap_content""
23	:      android:layout_marginBottom=""8dp""
24	:      android:text=""Object Detection""
	
	
Error at 20 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:20: error: No resource identifier found for attribute 'layout_constraintHorizontal_bias' in package 'org.tensorflow.demo'
15	:      app:layout_constraintBottom_toTopOf=""@+id/button_ObjectDetection""
16	:      app:layout_constraintEnd_toEndOf=""parent""
17	:      app:layout_constraintHorizontal_bias=""0.5""
18	:      app:layout_constraintStart_toEndOf=""@+id/button_Vid2Img""/>
19	:    <Button
20	:      android:id=""@+id/button_ObjectDetection""
21	:      android:layout_width=""180dp""
22	:      android:layout_height=""wrap_content""
23	:      android:layout_marginBottom=""8dp""
24	:      android:text=""Object Detection""
	
	
Error at 20 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:20: error: No resource identifier found for attribute 'layout_constraintStart_toEndOf' in package 'org.tensorflow.demo'
15	:      app:layout_constraintBottom_toTopOf=""@+id/button_ObjectDetection""
16	:      app:layout_constraintEnd_toEndOf=""parent""
17	:      app:layout_constraintHorizontal_bias=""0.5""
18	:      app:layout_constraintStart_toEndOf=""@+id/button_Vid2Img""/>
19	:    <Button
20	:      android:id=""@+id/button_ObjectDetection""
21	:      android:layout_width=""180dp""
22	:      android:layout_height=""wrap_content""
23	:      android:layout_marginBottom=""8dp""
24	:      android:text=""Object Detection""
	
	
Error at 30 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:30: error: No resource identifier found for attribute 'layout_constraintBottom_toTopOf' in package 'org.tensorflow.demo'
25	:      app:layout_constraintBottom_toBottomOf=""parent""
26	:      app:layout_constraintEnd_toEndOf=""parent""
27	:      app:layout_constraintHorizontal_bias=""0.5""
28	:      app:layout_constraintStart_toEndOf=""@+id/button_Record""/>
29	:    <Button
30	:      android:id=""@+id/button_Vid2Img""
31	:      android:layout_width=""180dp""
32	:      android:layout_height=""wrap_content""
33	:      android:layout_marginBottom=""8dp""
34	:      android:text=""Vid2Img""
	
	
Error at 30 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:30: error: No resource identifier found for attribute 'layout_constraintEnd_toStartOf' in package 'org.tensorflow.demo'
25	:      app:layout_constraintBottom_toBottomOf=""parent""
26	:      app:layout_constraintEnd_toEndOf=""parent""
27	:      app:layout_constraintHorizontal_bias=""0.5""
28	:      app:layout_constraintStart_toEndOf=""@+id/button_Record""/>
29	:    <Button
30	:      android:id=""@+id/button_Vid2Img""
31	:      android:layout_width=""180dp""
32	:      android:layout_height=""wrap_content""
33	:      android:layout_marginBottom=""8dp""
34	:      android:text=""Vid2Img""
	
	
Error at 30 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:30: error: No resource identifier found for attribute 'layout_constraintHorizontal_bias' in package 'org.tensorflow.demo'
25	:      app:layout_constraintBottom_toBottomOf=""parent""
26	:      app:layout_constraintEnd_toEndOf=""parent""
27	:      app:layout_constraintHorizontal_bias=""0.5""
28	:      app:layout_constraintStart_toEndOf=""@+id/button_Record""/>
29	:    <Button
30	:      android:id=""@+id/button_Vid2Img""
31	:      android:layout_width=""180dp""
32	:      android:layout_height=""wrap_content""
33	:      android:layout_marginBottom=""8dp""
34	:      android:text=""Vid2Img""
	
	
Error at 30 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:30: error: No resource identifier found for attribute 'layout_constraintStart_toStartOf' in package 'org.tensorflow.demo'
25	:      app:layout_constraintBottom_toBottomOf=""parent""
26	:      app:layout_constraintEnd_toEndOf=""parent""
27	:      app:layout_constraintHorizontal_bias=""0.5""
28	:      app:layout_constraintStart_toEndOf=""@+id/button_Record""/>
29	:    <Button
30	:      android:id=""@+id/button_Vid2Img""
31	:      android:layout_width=""180dp""
32	:      android:layout_height=""wrap_content""
33	:      android:layout_marginBottom=""8dp""
34	:      android:text=""Vid2Img""
	
	
Error at 40 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:40: error: No resource identifier found for attribute 'layout_constraintBottom_toBottomOf' in package 'org.tensorflow.demo'
35	:      app:layout_constraintBottom_toTopOf=""@+id/button_Record""
36	:      app:layout_constraintEnd_toStartOf=""@+id/button_Classify""
37	:      app:layout_constraintHorizontal_bias=""0.5""
38	:      app:layout_constraintStart_toStartOf=""parent""/>
39	:    <Button
40	:      android:id=""@+id/button_Record""
41	:      android:layout_width=""180dp""
42	:      android:layout_height=""wrap_content""
43	:      android:layout_marginBottom=""8dp""
44	:      android:text=""Record""
	
	
Error at 40 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:40: error: No resource identifier found for attribute 'layout_constraintEnd_toStartOf' in package 'org.tensorflow.demo'
35	:      app:layout_constraintBottom_toTopOf=""@+id/button_Record""
36	:      app:layout_constraintEnd_toStartOf=""@+id/button_Classify""
37	:      app:layout_constraintHorizontal_bias=""0.5""
38	:      app:layout_constraintStart_toStartOf=""parent""/>
39	:    <Button
40	:      android:id=""@+id/button_Record""
41	:      android:layout_width=""180dp""
42	:      android:layout_height=""wrap_content""
43	:      android:layout_marginBottom=""8dp""
44	:      android:text=""Record""
	
	
Error at 40 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:40: error: No resource identifier found for attribute 'layout_constraintHorizontal_bias' in package 'org.tensorflow.demo'
35	:      app:layout_constraintBottom_toTopOf=""@+id/button_Record""
36	:      app:layout_constraintEnd_toStartOf=""@+id/button_Classify""
37	:      app:layout_constraintHorizontal_bias=""0.5""
38	:      app:layout_constraintStart_toStartOf=""parent""/>
39	:    <Button
40	:      android:id=""@+id/button_Record""
41	:      android:layout_width=""180dp""
42	:      android:layout_height=""wrap_content""
43	:      android:layout_marginBottom=""8dp""
44	:      android:text=""Record""
	
	
Error at 40 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/activity_main.xml:40: error: No resource identifier found for attribute 'layout_constraintStart_toStartOf' in package 'org.tensorflow.demo'
35	:      app:layout_constraintBottom_toTopOf=""@+id/button_Record""
36	:      app:layout_constraintEnd_toStartOf=""@+id/button_Classify""
37	:      app:layout_constraintHorizontal_bias=""0.5""
38	:      app:layout_constraintStart_toStartOf=""parent""/>
39	:    <Button
40	:      android:id=""@+id/button_Record""
41	:      android:layout_width=""180dp""
42	:      android:layout_height=""wrap_content""
43	:      android:layout_marginBottom=""8dp""
44	:      android:text=""Record""
	
	
Error at 24 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:24: error: No resource identifier found for attribute 'layout_constraintBottom_toTopOf' in package 'org.tensorflow.demo'
19	:      android:layout_width=""match_parent""
20	:      android:layout_height=""match_parent""
21	:      tools:layout_editor_absoluteY=""89dp"">
22	:  
23	:      <org.tensorflow.demo.einardan.AutoFitTextureView
24	:          android:id=""@+id/texture""
25	:          android:layout_width=""0dp""
26	:          android:layout_height=""0dp""
27	:          app:layout_constraintBottom_toTopOf=""@+id/constraintLayout""
28	:          app:layout_constraintEnd_toEndOf=""parent""
	
	
Error at 24 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:24: error: No resource identifier found for attribute 'layout_constraintEnd_toEndOf' in package 'org.tensorflow.demo'
19	:      android:layout_width=""match_parent""
20	:      android:layout_height=""match_parent""
21	:      tools:layout_editor_absoluteY=""89dp"">
22	:  
23	:      <org.tensorflow.demo.einardan.AutoFitTextureView
24	:          android:id=""@+id/texture""
25	:          android:layout_width=""0dp""
26	:          android:layout_height=""0dp""
27	:          app:layout_constraintBottom_toTopOf=""@+id/constraintLayout""
28	:          app:layout_constraintEnd_toEndOf=""parent""
	
	
Error at 24 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:24: error: No resource identifier found for attribute 'layout_constraintStart_toStartOf' in package 'org.tensorflow.demo'
19	:      android:layout_width=""match_parent""
20	:      android:layout_height=""match_parent""
21	:      tools:layout_editor_absoluteY=""89dp"">
22	:  
23	:      <org.tensorflow.demo.einardan.AutoFitTextureView
24	:          android:id=""@+id/texture""
25	:          android:layout_width=""0dp""
26	:          android:layout_height=""0dp""
27	:          app:layout_constraintBottom_toTopOf=""@+id/constraintLayout""
28	:          app:layout_constraintEnd_toEndOf=""parent""
	
	
Error at 24 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:24: error: No resource identifier found for attribute 'layout_constraintTop_toTopOf' in package 'org.tensorflow.demo'
19	:      android:layout_width=""match_parent""
20	:      android:layout_height=""match_parent""
21	:      tools:layout_editor_absoluteY=""89dp"">
22	:  
23	:      <org.tensorflow.demo.einardan.AutoFitTextureView
24	:          android:id=""@+id/texture""
25	:          android:layout_width=""0dp""
26	:          android:layout_height=""0dp""
27	:          app:layout_constraintBottom_toTopOf=""@+id/constraintLayout""
28	:          app:layout_constraintEnd_toEndOf=""parent""
	
	
Error at 33 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:33: error: No resource identifier found for attribute 'layout_constraintBottom_toBottomOf' in package 'org.tensorflow.demo'
28	:          app:layout_constraintEnd_toEndOf=""parent""
29	:          app:layout_constraintStart_toStartOf=""parent""
30	:          app:layout_constraintTop_toTopOf=""parent"" />
31	:  
32	:      <android.support.constraint.ConstraintLayout
33	:          android:id=""@+id/constraintLayout""
34	:          android:layout_width=""match_parent""
35	:          android:layout_height=""50dp""
36	:          android:background=""#4285f4""
37	:          app:layout_constraintBottom_toBottomOf=""parent""
	
	
Error at 33 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:33: error: No resource identifier found for attribute 'layout_constraintTop_toBottomOf' in package 'org.tensorflow.demo'
28	:          app:layout_constraintEnd_toEndOf=""parent""
29	:          app:layout_constraintStart_toStartOf=""parent""
30	:          app:layout_constraintTop_toTopOf=""parent"" />
31	:  
32	:      <android.support.constraint.ConstraintLayout
33	:          android:id=""@+id/constraintLayout""
34	:          android:layout_width=""match_parent""
35	:          android:layout_height=""50dp""
36	:          android:background=""#4285f4""
37	:          app:layout_constraintBottom_toBottomOf=""parent""
	
	
Error at 41 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:41: error: No resource identifier found for attribute 'layout_constraintBottom_toBottomOf' in package 'org.tensorflow.demo'
36	:          android:background=""#4285f4""
37	:          app:layout_constraintBottom_toBottomOf=""parent""
38	:          app:layout_constraintTop_toBottomOf=""@+id/texture"">
39	:  
40	:          <Button
41	:              android:id=""@+id/button_start_recording_video""
42	:              android:layout_width=""0dp""
43	:              android:layout_height=""0dp""
44	:              android:layout_marginEnd=""8dp""
45	:              android:layout_marginStart=""8dp""
	
	
Error at 41 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:41: error: No resource identifier found for attribute 'layout_constraintEnd_toEndOf' in package 'org.tensorflow.demo'
36	:          android:background=""#4285f4""
37	:          app:layout_constraintBottom_toBottomOf=""parent""
38	:          app:layout_constraintTop_toBottomOf=""@+id/texture"">
39	:  
40	:          <Button
41	:              android:id=""@+id/button_start_recording_video""
42	:              android:layout_width=""0dp""
43	:              android:layout_height=""0dp""
44	:              android:layout_marginEnd=""8dp""
45	:              android:layout_marginStart=""8dp""
	
	
Error at 41 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:41: error: No resource identifier found for attribute 'layout_constraintHorizontal_bias' in package 'org.tensorflow.demo'
36	:          android:background=""#4285f4""
37	:          app:layout_constraintBottom_toBottomOf=""parent""
38	:          app:layout_constraintTop_toBottomOf=""@+id/texture"">
39	:  
40	:          <Button
41	:              android:id=""@+id/button_start_recording_video""
42	:              android:layout_width=""0dp""
43	:              android:layout_height=""0dp""
44	:              android:layout_marginEnd=""8dp""
45	:              android:layout_marginStart=""8dp""
	
	
Error at 41 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:41: error: No resource identifier found for attribute 'layout_constraintStart_toEndOf' in package 'org.tensorflow.demo'
36	:          android:background=""#4285f4""
37	:          app:layout_constraintBottom_toBottomOf=""parent""
38	:          app:layout_constraintTop_toBottomOf=""@+id/texture"">
39	:  
40	:          <Button
41	:              android:id=""@+id/button_start_recording_video""
42	:              android:layout_width=""0dp""
43	:              android:layout_height=""0dp""
44	:              android:layout_marginEnd=""8dp""
45	:              android:layout_marginStart=""8dp""
	
	
Error at 41 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:41: error: No resource identifier found for attribute 'layout_constraintTop_toTopOf' in package 'org.tensorflow.demo'
36	:          android:background=""#4285f4""
37	:          app:layout_constraintBottom_toBottomOf=""parent""
38	:          app:layout_constraintTop_toBottomOf=""@+id/texture"">
39	:  
40	:          <Button
41	:              android:id=""@+id/button_start_recording_video""
42	:              android:layout_width=""0dp""
43	:              android:layout_height=""0dp""
44	:              android:layout_marginEnd=""8dp""
45	:              android:layout_marginStart=""8dp""
	
	
Error at 56 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:56: error: No resource identifier found for attribute 'layout_constraintBottom_toBottomOf' in package 'org.tensorflow.demo'
51	:              app:layout_constraintStart_toEndOf=""@+id/button_convert_videos_to_images""
52	:              app:layout_constraintTop_toTopOf=""parent"" />
53	:  
54	:  
55	:          <Button
56	:              android:id=""@+id/button_stop_recording_video""
57	:              android:layout_width=""0dp""
58	:              android:layout_height=""0dp""
59	:              android:layout_marginEnd=""8dp""
60	:              android:layout_marginStart=""8dp""
	
	
Error at 56 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:56: error: No resource identifier found for attribute 'layout_constraintEnd_toEndOf' in package 'org.tensorflow.demo'
51	:              app:layout_constraintStart_toEndOf=""@+id/button_convert_videos_to_images""
52	:              app:layout_constraintTop_toTopOf=""parent"" />
53	:  
54	:  
55	:          <Button
56	:              android:id=""@+id/button_stop_recording_video""
57	:              android:layout_width=""0dp""
58	:              android:layout_height=""0dp""
59	:              android:layout_marginEnd=""8dp""
60	:              android:layout_marginStart=""8dp""
	
	
Error at 56 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:56: error: No resource identifier found for attribute 'layout_constraintHorizontal_bias' in package 'org.tensorflow.demo'
51	:              app:layout_constraintStart_toEndOf=""@+id/button_convert_videos_to_images""
52	:              app:layout_constraintTop_toTopOf=""parent"" />
53	:  
54	:  
55	:          <Button
56	:              android:id=""@+id/button_stop_recording_video""
57	:              android:layout_width=""0dp""
58	:              android:layout_height=""0dp""
59	:              android:layout_marginEnd=""8dp""
60	:              android:layout_marginStart=""8dp""
	
	
Error at 56 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:56: error: No resource identifier found for attribute 'layout_constraintStart_toEndOf' in package 'org.tensorflow.demo'
51	:              app:layout_constraintStart_toEndOf=""@+id/button_convert_videos_to_images""
52	:              app:layout_constraintTop_toTopOf=""parent"" />
53	:  
54	:  
55	:          <Button
56	:              android:id=""@+id/button_stop_recording_video""
57	:              android:layout_width=""0dp""
58	:              android:layout_height=""0dp""
59	:              android:layout_marginEnd=""8dp""
60	:              android:layout_marginStart=""8dp""
	
	
Error at 56 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:56: error: No resource identifier found for attribute 'layout_constraintTop_toTopOf' in package 'org.tensorflow.demo'
51	:              app:layout_constraintStart_toEndOf=""@+id/button_convert_videos_to_images""
52	:              app:layout_constraintTop_toTopOf=""parent"" />
53	:  
54	:  
55	:          <Button
56	:              android:id=""@+id/button_stop_recording_video""
57	:              android:layout_width=""0dp""
58	:              android:layout_height=""0dp""
59	:              android:layout_marginEnd=""8dp""
60	:              android:layout_marginStart=""8dp""
	
	
Error at 70 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:70: error: No resource identifier found for attribute 'layout_constraintBottom_toBottomOf' in package 'org.tensorflow.demo'
65	:              app:layout_constraintHorizontal_bias=""0.5""
66	:              app:layout_constraintStart_toEndOf=""@+id/button_convert_videos_to_images""
67	:              app:layout_constraintTop_toTopOf=""parent"" />
68	:  
69	:          <Button
70	:              android:id=""@+id/button_convert_videos_to_images""
71	:              android:layout_width=""0dp""
72	:              android:layout_height=""0dp""
73	:              android:layout_marginEnd=""8dp""
74	:              android:layout_marginStart=""8dp""
	
	
Error at 70 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:70: error: No resource identifier found for attribute 'layout_constraintEnd_toStartOf' in package 'org.tensorflow.demo'
65	:              app:layout_constraintHorizontal_bias=""0.5""
66	:              app:layout_constraintStart_toEndOf=""@+id/button_convert_videos_to_images""
67	:              app:layout_constraintTop_toTopOf=""parent"" />
68	:  
69	:          <Button
70	:              android:id=""@+id/button_convert_videos_to_images""
71	:              android:layout_width=""0dp""
72	:              android:layout_height=""0dp""
73	:              android:layout_marginEnd=""8dp""
74	:              android:layout_marginStart=""8dp""
	
	
Error at 70 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:70: error: No resource identifier found for attribute 'layout_constraintHorizontal_bias' in package 'org.tensorflow.demo'
65	:              app:layout_constraintHorizontal_bias=""0.5""
66	:              app:layout_constraintStart_toEndOf=""@+id/button_convert_videos_to_images""
67	:              app:layout_constraintTop_toTopOf=""parent"" />
68	:  
69	:          <Button
70	:              android:id=""@+id/button_convert_videos_to_images""
71	:              android:layout_width=""0dp""
72	:              android:layout_height=""0dp""
73	:              android:layout_marginEnd=""8dp""
74	:              android:layout_marginStart=""8dp""
	
	
Error at 70 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:70: error: No resource identifier found for attribute 'layout_constraintStart_toStartOf' in package 'org.tensorflow.demo'
65	:              app:layout_constraintHorizontal_bias=""0.5""
66	:              app:layout_constraintStart_toEndOf=""@+id/button_convert_videos_to_images""
67	:              app:layout_constraintTop_toTopOf=""parent"" />
68	:  
69	:          <Button
70	:              android:id=""@+id/button_convert_videos_to_images""
71	:              android:layout_width=""0dp""
72	:              android:layout_height=""0dp""
73	:              android:layout_marginEnd=""8dp""
74	:              android:layout_marginStart=""8dp""
	
	
Error at 70 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_camera2_video.xml:70: error: No resource identifier found for attribute 'layout_constraintTop_toTopOf' in package 'org.tensorflow.demo'
65	:              app:layout_constraintHorizontal_bias=""0.5""
66	:              app:layout_constraintStart_toEndOf=""@+id/button_convert_videos_to_images""
67	:              app:layout_constraintTop_toTopOf=""parent"" />
68	:  
69	:          <Button
70	:              android:id=""@+id/button_convert_videos_to_images""
71	:              android:layout_width=""0dp""
72	:              android:layout_height=""0dp""
73	:              android:layout_marginEnd=""8dp""
74	:              android:layout_marginStart=""8dp""
	
	
Error at 11 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:11: error: No resource identifier found for attribute 'layout_constraintEnd_toEndOf' in package 'org.tensorflow.demo'
6	:    tools:context=""org.tensorflow.demo.einardan.Video2ImageConversionFragment"">
7	:  
8	:    <!-- TODO: Update blank fragment layout -->
9	:  
10	:    <TextView
11	:      android:id=""@+id/textView_conversion_info""
12	:      android:layout_width=""wrap_content""
13	:      android:layout_height=""wrap_content""
14	:      android:layout_marginTop=""16dp""
15	:      android:layout_marginStart=""16dp""
	
	
Error at 11 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:11: error: No resource identifier found for attribute 'layout_constraintHorizontal_bias' in package 'org.tensorflow.demo'
6	:    tools:context=""org.tensorflow.demo.einardan.Video2ImageConversionFragment"">
7	:  
8	:    <!-- TODO: Update blank fragment layout -->
9	:  
10	:    <TextView
11	:      android:id=""@+id/textView_conversion_info""
12	:      android:layout_width=""wrap_content""
13	:      android:layout_height=""wrap_content""
14	:      android:layout_marginTop=""16dp""
15	:      android:layout_marginStart=""16dp""
	
	
Error at 11 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:11: error: No resource identifier found for attribute 'layout_constraintStart_toStartOf' in package 'org.tensorflow.demo'
6	:    tools:context=""org.tensorflow.demo.einardan.Video2ImageConversionFragment"">
7	:  
8	:    <!-- TODO: Update blank fragment layout -->
9	:  
10	:    <TextView
11	:      android:id=""@+id/textView_conversion_info""
12	:      android:layout_width=""wrap_content""
13	:      android:layout_height=""wrap_content""
14	:      android:layout_marginTop=""16dp""
15	:      android:layout_marginStart=""16dp""
	
	
Error at 11 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:11: error: No resource identifier found for attribute 'layout_constraintTop_toTopOf' in package 'org.tensorflow.demo'
6	:    tools:context=""org.tensorflow.demo.einardan.Video2ImageConversionFragment"">
7	:  
8	:    <!-- TODO: Update blank fragment layout -->
9	:  
10	:    <TextView
11	:      android:id=""@+id/textView_conversion_info""
12	:      android:layout_width=""wrap_content""
13	:      android:layout_height=""wrap_content""
14	:      android:layout_marginTop=""16dp""
15	:      android:layout_marginStart=""16dp""
	
	
Error at 26 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:26: error: No resource identifier found for attribute 'layout_constraintEnd_toEndOf' in package 'org.tensorflow.demo'
21	:      app:layout_constraintHorizontal_bias=""0.5""
22	:      app:layout_constraintStart_toStartOf=""parent""
23	:      app:layout_constraintTop_toTopOf=""parent""/>
24	:  
25	:    <Button
26	:      android:id=""@+id/button_begin_conversion""
27	:      android:layout_width=""wrap_content""
28	:      android:layout_height=""wrap_content""
29	:      android:layout_marginTop=""18dp""
30	:      android:text=""@string/button_BeginConversion""
	
	
Error at 26 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:26: error: No resource identifier found for attribute 'layout_constraintHorizontal_bias' in package 'org.tensorflow.demo'
21	:      app:layout_constraintHorizontal_bias=""0.5""
22	:      app:layout_constraintStart_toStartOf=""parent""
23	:      app:layout_constraintTop_toTopOf=""parent""/>
24	:  
25	:    <Button
26	:      android:id=""@+id/button_begin_conversion""
27	:      android:layout_width=""wrap_content""
28	:      android:layout_height=""wrap_content""
29	:      android:layout_marginTop=""18dp""
30	:      android:text=""@string/button_BeginConversion""
	
	
Error at 26 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:26: error: No resource identifier found for attribute 'layout_constraintStart_toStartOf' in package 'org.tensorflow.demo'
21	:      app:layout_constraintHorizontal_bias=""0.5""
22	:      app:layout_constraintStart_toStartOf=""parent""
23	:      app:layout_constraintTop_toTopOf=""parent""/>
24	:  
25	:    <Button
26	:      android:id=""@+id/button_begin_conversion""
27	:      android:layout_width=""wrap_content""
28	:      android:layout_height=""wrap_content""
29	:      android:layout_marginTop=""18dp""
30	:      android:text=""@string/button_BeginConversion""
	
	
Error at 26 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:26: error: No resource identifier found for attribute 'layout_constraintTop_toBottomOf' in package 'org.tensorflow.demo'
21	:      app:layout_constraintHorizontal_bias=""0.5""
22	:      app:layout_constraintStart_toStartOf=""parent""
23	:      app:layout_constraintTop_toTopOf=""parent""/>
24	:  
25	:    <Button
26	:      android:id=""@+id/button_begin_conversion""
27	:      android:layout_width=""wrap_content""
28	:      android:layout_height=""wrap_content""
29	:      android:layout_marginTop=""18dp""
30	:      android:text=""@string/button_BeginConversion""
	
	
Error at 37 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:37: error: No resource identifier found for attribute 'layout_constraintBottom_toBottomOf' in package 'org.tensorflow.demo'
32	:      app:layout_constraintHorizontal_bias=""0.5""
33	:      app:layout_constraintStart_toStartOf=""parent""
34	:      app:layout_constraintTop_toBottomOf=""@+id/textView_conversion_info""/>
35	:  
36	:    <Button
37	:      android:id=""@+id/button_back_to_video_recording""
38	:      android:layout_width=""wrap_content""
39	:      android:layout_height=""wrap_content""
40	:      android:layout_marginBottom=""66dp""
41	:      android:text=""Back to Video Recording""
	
	
Error at 37 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:37: error: No resource identifier found for attribute 'layout_constraintEnd_toEndOf' in package 'org.tensorflow.demo'
32	:      app:layout_constraintHorizontal_bias=""0.5""
33	:      app:layout_constraintStart_toStartOf=""parent""
34	:      app:layout_constraintTop_toBottomOf=""@+id/textView_conversion_info""/>
35	:  
36	:    <Button
37	:      android:id=""@+id/button_back_to_video_recording""
38	:      android:layout_width=""wrap_content""
39	:      android:layout_height=""wrap_content""
40	:      android:layout_marginBottom=""66dp""
41	:      android:text=""Back to Video Recording""
	
	
Error at 37 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:37: error: No resource identifier found for attribute 'layout_constraintHorizontal_bias' in package 'org.tensorflow.demo'
32	:      app:layout_constraintHorizontal_bias=""0.5""
33	:      app:layout_constraintStart_toStartOf=""parent""
34	:      app:layout_constraintTop_toBottomOf=""@+id/textView_conversion_info""/>
35	:  
36	:    <Button
37	:      android:id=""@+id/button_back_to_video_recording""
38	:      android:layout_width=""wrap_content""
39	:      android:layout_height=""wrap_content""
40	:      android:layout_marginBottom=""66dp""
41	:      android:text=""Back to Video Recording""
	
	
Error at 37 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:37: error: No resource identifier found for attribute 'layout_constraintStart_toStartOf' in package 'org.tensorflow.demo'
32	:      app:layout_constraintHorizontal_bias=""0.5""
33	:      app:layout_constraintStart_toStartOf=""parent""
34	:      app:layout_constraintTop_toBottomOf=""@+id/textView_conversion_info""/>
35	:  
36	:    <Button
37	:      android:id=""@+id/button_back_to_video_recording""
38	:      android:layout_width=""wrap_content""
39	:      android:layout_height=""wrap_content""
40	:      android:layout_marginBottom=""66dp""
41	:      android:text=""Back to Video Recording""
	
	
Error at 48 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:48: error: No resource identifier found for attribute 'layout_constraintBottom_toTopOf' in package 'org.tensorflow.demo'
43	:      app:layout_constraintEnd_toEndOf=""parent""
44	:      app:layout_constraintHorizontal_bias=""0.5""
45	:      app:layout_constraintStart_toStartOf=""parent""/>
46	:  
47	:    <Button
48	:      android:id=""@+id/button_delete_recorded_videos""
49	:      android:layout_width=""wrap_content""
50	:      android:layout_height=""wrap_content""
51	:      android:layout_marginBottom=""71dp""
52	:      android:layout_marginStart=""3dp""
	
	
Error at 48 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:48: error: No resource identifier found for attribute 'layout_constraintStart_toStartOf' in package 'org.tensorflow.demo'
43	:      app:layout_constraintEnd_toEndOf=""parent""
44	:      app:layout_constraintHorizontal_bias=""0.5""
45	:      app:layout_constraintStart_toStartOf=""parent""/>
46	:  
47	:    <Button
48	:      android:id=""@+id/button_delete_recorded_videos""
49	:      android:layout_width=""wrap_content""
50	:      android:layout_height=""wrap_content""
51	:      android:layout_marginBottom=""71dp""
52	:      android:layout_marginStart=""3dp""
	
	
Error at 57 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:57: error: No resource identifier found for attribute 'layout_constraintEnd_toStartOf' in package 'org.tensorflow.demo'
52	:      android:layout_marginStart=""3dp""
53	:      android:text=""Delete Recorded Videos""
54	:      app:layout_constraintBottom_toTopOf=""@+id/button_back_to_video_recording""
55	:      app:layout_constraintStart_toStartOf=""@+id/button_back_to_video_recording""/>
56	:    <Button
57	:      android:id=""@+id/button_launch_object_detection""
58	:      android:layout_width=""0dp""
59	:      android:layout_height=""wrap_content""
60	:      android:layout_marginTop=""33dp""
61	:      android:layout_marginStart=""8dp""
	
	
Error at 57 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:57: error: No resource identifier found for attribute 'layout_constraintStart_toStartOf' in package 'org.tensorflow.demo'
52	:      android:layout_marginStart=""3dp""
53	:      android:text=""Delete Recorded Videos""
54	:      app:layout_constraintBottom_toTopOf=""@+id/button_back_to_video_recording""
55	:      app:layout_constraintStart_toStartOf=""@+id/button_back_to_video_recording""/>
56	:    <Button
57	:      android:id=""@+id/button_launch_object_detection""
58	:      android:layout_width=""0dp""
59	:      android:layout_height=""wrap_content""
60	:      android:layout_marginTop=""33dp""
61	:      android:layout_marginStart=""8dp""
	
	
Error at 57 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:57: error: No resource identifier found for attribute 'layout_constraintTop_toBottomOf' in package 'org.tensorflow.demo'
52	:      android:layout_marginStart=""3dp""
53	:      android:text=""Delete Recorded Videos""
54	:      app:layout_constraintBottom_toTopOf=""@+id/button_back_to_video_recording""
55	:      app:layout_constraintStart_toStartOf=""@+id/button_back_to_video_recording""/>
56	:    <Button
57	:      android:id=""@+id/button_launch_object_detection""
58	:      android:layout_width=""0dp""
59	:      android:layout_height=""wrap_content""
60	:      android:layout_marginTop=""33dp""
61	:      android:layout_marginStart=""8dp""
	
	
Error at 69 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:69: error: No resource identifier found for attribute 'layout_constraintEnd_toEndOf' in package 'org.tensorflow.demo'
64	:      app:layout_constraintEnd_toStartOf=""@+id/button_launch_image_classification""
65	:      app:layout_constraintStart_toStartOf=""parent""
66	:      app:layout_constraintTop_toBottomOf=""@+id/button_begin_conversion""
67	:      />
68	:    <Button
69	:      android:id=""@+id/button_launch_image_classification""
70	:      android:layout_width=""0dp""
71	:      android:layout_height=""wrap_content""
72	:      android:layout_marginEnd=""8dp""
73	:      android:text=""Image Classification""
	
	
Error at 69 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:69: error: No resource identifier found for attribute 'layout_constraintStart_toEndOf' in package 'org.tensorflow.demo'
64	:      app:layout_constraintEnd_toStartOf=""@+id/button_launch_image_classification""
65	:      app:layout_constraintStart_toStartOf=""parent""
66	:      app:layout_constraintTop_toBottomOf=""@+id/button_begin_conversion""
67	:      />
68	:    <Button
69	:      android:id=""@+id/button_launch_image_classification""
70	:      android:layout_width=""0dp""
71	:      android:layout_height=""wrap_content""
72	:      android:layout_marginEnd=""8dp""
73	:      android:text=""Image Classification""
	
	
Error at 69 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_2_image_conversion.xml:69: error: No resource identifier found for attribute 'layout_constraintTop_toTopOf' in package 'org.tensorflow.demo'
64	:      app:layout_constraintEnd_toStartOf=""@+id/button_launch_image_classification""
65	:      app:layout_constraintStart_toStartOf=""parent""
66	:      app:layout_constraintTop_toBottomOf=""@+id/button_begin_conversion""
67	:      />
68	:    <Button
69	:      android:id=""@+id/button_launch_image_classification""
70	:      android:layout_width=""0dp""
71	:      android:layout_height=""wrap_content""
72	:      android:layout_marginEnd=""8dp""
73	:      android:text=""Image Classification""
	
	
Error at 13 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_label.xml:13: error: No resource identifier found for attribute 'layout_constraintEnd_toEndOf' in package 'org.tensorflow.demo'
8	:    tools:context=""org.tensorflow.demo.einardan.VideoLabelFragment""
9	:    tools:layout_editor_absoluteY=""81dp"">
10	:  
11	:  
12	:    <EditText
13	:      android:id=""@+id/editText_user_input_label""
14	:      android:layout_width=""match_parent""
15	:      android:layout_height=""wrap_content""
16	:      android:layout_marginTop=""21dp""
17	:      android:layout_marginStart=""24dp""
	
	
Error at 13 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_label.xml:13: error: No resource identifier found for attribute 'layout_constraintHorizontal_bias' in package 'org.tensorflow.demo'
8	:    tools:context=""org.tensorflow.demo.einardan.VideoLabelFragment""
9	:    tools:layout_editor_absoluteY=""81dp"">
10	:  
11	:  
12	:    <EditText
13	:      android:id=""@+id/editText_user_input_label""
14	:      android:layout_width=""match_parent""
15	:      android:layout_height=""wrap_content""
16	:      android:layout_marginTop=""21dp""
17	:      android:layout_marginStart=""24dp""
	
	
Error at 13 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_label.xml:13: error: No resource identifier found for attribute 'layout_constraintStart_toStartOf' in package 'org.tensorflow.demo'
8	:    tools:context=""org.tensorflow.demo.einardan.VideoLabelFragment""
9	:    tools:layout_editor_absoluteY=""81dp"">
10	:  
11	:  
12	:    <EditText
13	:      android:id=""@+id/editText_user_input_label""
14	:      android:layout_width=""match_parent""
15	:      android:layout_height=""wrap_content""
16	:      android:layout_marginTop=""21dp""
17	:      android:layout_marginStart=""24dp""
	
	
Error at 13 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_label.xml:13: error: No resource identifier found for attribute 'layout_constraintTop_toBottomOf' in package 'org.tensorflow.demo'
8	:    tools:context=""org.tensorflow.demo.einardan.VideoLabelFragment""
9	:    tools:layout_editor_absoluteY=""81dp"">
10	:  
11	:  
12	:    <EditText
13	:      android:id=""@+id/editText_user_input_label""
14	:      android:layout_width=""match_parent""
15	:      android:layout_height=""wrap_content""
16	:      android:layout_marginTop=""21dp""
17	:      android:layout_marginStart=""24dp""
	
	
Error at 30 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_label.xml:30: error: No resource identifier found for attribute 'layout_constraintEnd_toEndOf' in package 'org.tensorflow.demo'
25	:      app:layout_constraintStart_toStartOf=""parent""
26	:      app:layout_constraintTop_toBottomOf=""@+id/textView_user_prompt""/>
27	:  
28	:  
29	:    <TextView
30	:      android:id=""@+id/textView_user_prompt""
31	:      android:layout_width=""wrap_content""
32	:      android:layout_height=""wrap_content""
33	:      android:layout_marginTop=""34dp""
34	:      android:text=""@string/enter_video_label""
	
	
Error at 30 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_label.xml:30: error: No resource identifier found for attribute 'layout_constraintHorizontal_bias' in package 'org.tensorflow.demo'
25	:      app:layout_constraintStart_toStartOf=""parent""
26	:      app:layout_constraintTop_toBottomOf=""@+id/textView_user_prompt""/>
27	:  
28	:  
29	:    <TextView
30	:      android:id=""@+id/textView_user_prompt""
31	:      android:layout_width=""wrap_content""
32	:      android:layout_height=""wrap_content""
33	:      android:layout_marginTop=""34dp""
34	:      android:text=""@string/enter_video_label""
	
	
Error at 30 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_label.xml:30: error: No resource identifier found for attribute 'layout_constraintStart_toStartOf' in package 'org.tensorflow.demo'
25	:      app:layout_constraintStart_toStartOf=""parent""
26	:      app:layout_constraintTop_toBottomOf=""@+id/textView_user_prompt""/>
27	:  
28	:  
29	:    <TextView
30	:      android:id=""@+id/textView_user_prompt""
31	:      android:layout_width=""wrap_content""
32	:      android:layout_height=""wrap_content""
33	:      android:layout_marginTop=""34dp""
34	:      android:text=""@string/enter_video_label""
	
	
Error at 30 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_label.xml:30: error: No resource identifier found for attribute 'layout_constraintTop_toTopOf' in package 'org.tensorflow.demo'
25	:      app:layout_constraintStart_toStartOf=""parent""
26	:      app:layout_constraintTop_toBottomOf=""@+id/textView_user_prompt""/>
27	:  
28	:  
29	:    <TextView
30	:      android:id=""@+id/textView_user_prompt""
31	:      android:layout_width=""wrap_content""
32	:      android:layout_height=""wrap_content""
33	:      android:layout_marginTop=""34dp""
34	:      android:text=""@string/enter_video_label""
	
	
Error at 42 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_label.xml:42: error: No resource identifier found for attribute 'layout_constraintEnd_toEndOf' in package 'org.tensorflow.demo'
37	:      app:layout_constraintHorizontal_bias=""0.5""
38	:      app:layout_constraintStart_toStartOf=""parent""
39	:      app:layout_constraintTop_toTopOf=""parent""/>
40	:  
41	:    <Button
42	:      android:id=""@+id/button_OK""
43	:      android:layout_width=""wrap_content""
44	:      android:layout_height=""wrap_content""
45	:      android:layout_marginTop=""8dp""
46	:      android:text=""OK""
	
	
Error at 42 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_label.xml:42: error: No resource identifier found for attribute 'layout_constraintHorizontal_bias' in package 'org.tensorflow.demo'
37	:      app:layout_constraintHorizontal_bias=""0.5""
38	:      app:layout_constraintStart_toStartOf=""parent""
39	:      app:layout_constraintTop_toTopOf=""parent""/>
40	:  
41	:    <Button
42	:      android:id=""@+id/button_OK""
43	:      android:layout_width=""wrap_content""
44	:      android:layout_height=""wrap_content""
45	:      android:layout_marginTop=""8dp""
46	:      android:text=""OK""
	
	
Error at 42 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_label.xml:42: error: No resource identifier found for attribute 'layout_constraintStart_toStartOf' in package 'org.tensorflow.demo'
37	:      app:layout_constraintHorizontal_bias=""0.5""
38	:      app:layout_constraintStart_toStartOf=""parent""
39	:      app:layout_constraintTop_toTopOf=""parent""/>
40	:  
41	:    <Button
42	:      android:id=""@+id/button_OK""
43	:      android:layout_width=""wrap_content""
44	:      android:layout_height=""wrap_content""
45	:      android:layout_marginTop=""8dp""
46	:      android:text=""OK""
	
	
Error at 42 : /tmp/android_resources_tmp2553409785033894779/merged_resources/layout/fragment_video_label.xml:42: error: No resource identifier found for attribute 'layout_constraintTop_toBottomOf' in package 'org.tensorflow.demo'
37	:      app:layout_constraintHorizontal_bias=""0.5""
38	:      app:layout_constraintStart_toStartOf=""parent""
39	:      app:layout_constraintTop_toTopOf=""parent""/>
40	:  
41	:    <Button
42	:      android:id=""@+id/button_OK""
43	:      android:layout_width=""wrap_content""
44	:      android:layout_height=""wrap_content""
45	:      android:layout_marginTop=""8dp""
46	:      android:text=""OK""
	

	at com.google.devtools.build.android.AndroidResourceProcessor.runAapt(AndroidResourceProcessor.java:448)
	at com.google.devtools.build.android.AndroidResourceProcessor.processResources(AndroidResourceProcessor.java:315)
	at com.google.devtools.build.android.AndroidResourceProcessingAction.main(AndroidResourceProcessingAction.java:465)
	at com.google.devtools.build.android.ResourceProcessorBusyBox$Tool$1.call(ResourceProcessorBusyBox.java:61)
	at com.google.devtools.build.android.ResourceProcessorBusyBox.main(ResourceProcessorBusyBox.java:188)
Target //tensorflow/examples/android:tensorflow_demo failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 353.436s, Critical Path: 66.21s
FAILED: Build did NOT complete successfully
```



"
18232,[RFC] Native GPU-Direct RDMA implementation of collective ops,"In a [recent CL](https://github.com/tensorflow/tensorflow/commit/a0e0685ca974e484de9200caf8c414dcb55277bb), the remote memory access based collective ops (`CollectiveRemoteAccess`) and a local implementation (`CollectiveRemoteAccessLocal`) has been added (looks like @poxvoculi's glorious work).

I am wondering if there would be enough space for a verbs implementation of the remote access collective ops, or its design has been carried out and TF team will release its implementation soon? If there is no such plan in a short term, I would love to extend the GDR runtime to the collective ops. In particular, I would like to request for comments to the future of the GDR runtime, as it seems the contrib modules may eventually be moved out to other places (https://github.com/tensorflow/tensorflow/pull/16984#issuecomment-365918193).

Any suggestion from the TF team?"
18230,TypeError: unsupported format string passed to Tensor.__format__,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS X  version: 10.12.1
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**:v1.7.0-3-g024aecf414 1.7.0
- **Python version**: 3.6.4
- **Bazel version (if compiling from source)**:-
- **GCC/Compiler version (if compiling from source)**:-
- **CUDA/cuDNN version**: -
- **GPU model and memory**:  Intel Iris Graphics 6100 1536 MB
- **Exact command to reproduce**: python toy-dataset.py

### Describe the problem
I run the toy dataset code in the [Eager Execution Guide Document](https://www.tensorflow.org/programmers_guide/eager), but I got an error.  
 
### Source code / logs
```
WARNING:tensorflow:From /XXXXXXX/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Use the retry module or similar alternatives.
Traceback (most recent call last):
  File ""toy-dataset.py"", line 31, in <module>
    print(""Initial loss: {:.3f}"".format(loss(W, B)))
TypeError: unsupported format string passed to Tensor.__format__
```
```python
from __future__ import absolute_import, division, print_function
import tensorflow as tf
import tensorflow.contrib.eager as tfe

# A toy dataset of points around 3 * x + 2
NUM_EXAMPLES = 1000
training_inputs = tf.random_normal([NUM_EXAMPLES])
noise = tf.random_normal([NUM_EXAMPLES])
training_outputs = training_inputs * 3 + 2 + noise
def prediction(input, weight, bias):
  return input * weight + bias

# A loss function using mean-squared error
def loss(weights, biases):
  error = prediction(training_inputs, weights, biases) - training_outputs
  return tf.reduce_mean(tf.square(error))

# Return the derivative of loss with respect to weight and bias
def grad(weights, biases):
  with tfe.GradientTape() as tape:
    loss_value = loss(weights, biases)
  return tape.gradient(loss_value, [weights, biases])

train_steps = 200
learning_rate = 0.01
# Start with arbitrary values for W and B on the same batch of data
W = tfe.Variable(5.)
B = tfe.Variable(10.)

tf.Print(loss(W, B), [loss(W, B)], message=""This is a: "")
print(""Initial loss: {:.3f}"".format(loss(W, B)))

for i in range(train_steps):
  dW, dB = grad(W, B)
  W.assign_sub(dW * learning_rate)
  B.assign_sub(dB * learning_rate)
  if i % 20 == 0:
    # print(i, loss(W, B))
    print(""Loss at step {:03d}: {:.3f}"".format(i, loss(W, B)))

print(""Final loss: {:.3f}"".format(loss(W, B)))
print(""W = {}, B = {}"".format(W.numpy(), B.numpy()))
```"
18229,Bug - in Freeze Graph tool when trying to convert Graph.pb for Mobile Deployment,"System information
Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 7
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): release 1.6
Python version: 3.5
Bazel version (if compiling from source): -
GCC/Compiler version (if compiling from source): - N/A
CUDA/cuDNN version: using dell laptop
GPU model and memory: N/A 
Exact command to reproduce:  python freeze_graph.py  --input_binary=true --input_graph=c:/tmp/output_graph.pb  --input_checkpoint=c:/tmp/_retrain_checkpoint --output_graph=c:/tmp/frozen_graph.pb --output_node_names=output_node

I have trained Tesnsorflow to identify 2 classes(my own classes) of images which has resulted in output_graph.pb, _retrain_checkpoint.data-00000-of-00001, _retrain_checkpoint.index, _retrain_checkpoint.meta, checkpoint files being generated.

I want to convert this graph file to mobile version so I used below command as mentioned in tutorials..
python freeze_graph.py  --input_binary=true --input_graph=c:/tmp/output_graph.pb  --input_checkpoint=c:/tmp/_retrain_checkpoint --output_graph=c:/tmp/frozen_graph.pb --output_node_names=output_node

**I get this error:**
_saveables = self._ValidateAndSliceInputs(names_to_saveables) 
File ""C:\Users\svm\AppData\Local\Continuum\anaconda3\envs\tensorflow\lib\
site-packages\tensorflow\python\training\saver.py"", line 677, in _ValidateAndSli
ceInputs variable)
TypeError: names_to_saveables must be a dict mapping string names to Tensors/Var
iables. Not a variable: Tensor(""final_retrain_ops/biases/final_biases:0"", shape=
(2,), dtype=float32)_"
18228,why the convolution network output changes when i have already fixed the parameters of the convolution and only feed the net with same input?,"Sorry to bother, but i have trouble with the convolution in tensorflow.

I am working with the network as below, input shape is [1,256,256,33], go through some convs, and after them i add a fully connected layer( not show in this picture). i fix the parameters of the convs, and try to train the fc layer.

However, i found something weird... the network won't converge at all, so i only feed the network with one same input to test whether the network has any problem and print the output of each layer every iteration.

and i found that the output of 'conv6' changes, though my net has been fixed.

but the output of 'conv5_1' doesn't change at all!....

so i changed the stride of conv6... and when i change the stride of conv6 from 2 to 1, the output of conv6 doesn't change either.... So the net is very weird to me.... the stride of conv6 decides whether it changes?

Could anyone help me? thanks!!!

[my network ('is training' is false]
```python
    conv1 = conv(data, 3, 3, 64, 1, 1, name='conv1', is_training=is_training)
    conv1_1 = conv(conv1, 3, 3, 64, 1, 1, name='conv1_1', is_training=is_training)
    conv2 = conv(conv1_1, 3, 3, 128, 2, 2, name='conv2', is_training=is_training)
    conv2_1 = conv(conv2, 3, 3, 128, 1, 1, name='conv2_1', is_training=is_training)    
    conv3 = conv(conv2_1, 3, 3, 256, 2, 2, name='conv3', is_training=is_training)
    conv3_1 = conv(conv3, 3, 3, 256, 1, 1, name='conv3_1', is_training=is_training)
    conv4 = conv(conv3_1, 3, 3, 512, 2, 2, name='conv4', is_training=is_training)
    conv4_1 = conv(conv4, 3, 3, 512, 1, 1, name='conv4_1', is_training=is_training)
    conv5 = conv(conv4_1, 3, 3, 512, 2, 2, name='conv5', is_training=is_training)
    conv5_1 = conv(conv5, 3, 3, 512, 1, 1, name='conv5_1', is_training=is_training)
    conv6 = conv(conv5_1, 3, 3, 1024, 2, 2, name='conv6', is_training=is_training)
```

[the conv definition]
```python
def conv(inputs,k_h,k_w,c_o,s_h,s_w,name,relu=True,padding='SAME',group=1,biased=True,is_training=False):

    c_i = inputs.get_shape()[-1]
    convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding)
    with tf.variable_scope(name) as scope:
        
      if is_training:
        initializer = slim.xavier_initializer()
        weights_regularizer = slim.l2_regularizer(5e-4)
      else:
        initializer = None
        weights_regularizer = None

      kernel = make_var('weights', shape=[k_h, k_w, c_i / group, c_o],is_training=is_training,initializer=initializer ,regularizer=weights_regularizer)

      output = convolve(inputs, kernel)
      if biased:
        biases = make_var('biases', [c_o],is_training=is_training)
        output = tf.nn.bias_add(output, biases)
      if relu:
        output= tf.nn.relu(output, name=scope.name)
      return output
```

[make_var definition]
```python
    def make_var( name, shape,is_training, initializer=None,regularizer=None):

      return tf.get_variable(name, shape,initializer= initializer,regularizer=regularizer,trainable=is_training)
```"
18227,(feature request) batch results from tf.estimator.Estimator.predict,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: tensorflow-gpu 1.6.0
- **Python version**: 3.6.3 64-bit
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: CUDA 9.0 / cuDNN 6
- **GPU model and memory**: Nvidia Geforce GTX 1060 6GB
- **Exact command to reproduce**:

        import tensorflow as tf
        import numpy as np
        import itertools
        
        net_inputs = np.array(...)
        estimator = tf.estimator.Estimator(...) # custom model_fn, not all that relevant
        
        # feed a large numpy array in as a single batch
        my_input_fn = tf.estimator.inputs.numpy_input_fn(
            x={""inputs"": net_inputs},
            y=None, shuffle=False, batch_size=net_inputs.shape[0])

        # this generator only gives one result at a time
        predictions_generator = estimator.predict(input_fn=my_input_fn, predict_keys=['raw_predictions'])
        
        # aggregate the whole batch back together again (slow!)
        predictions = np.reshape(
            np.fromiter(itertools.chain.from_iterable(x['raw_predictions'] for x in predictions_generator), input_vects.dtype),
            [-1, net_inputs.shape[1]])

### Describe the problem

The way the generator in `tf.estimator.Estimator.predict()` is currently implemented to yield individual predictions from batched predictions adds quite a bit of overhead. Specifically the loop here 
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/estimator/estimator.py#L516

I hacked together my own copy of `predict()` that directly yields `preds_evaluated` and the total time taken on my test-set of a few million examples with a batch size of 128k was 64% of the time taken when I used the method above to re-aggregate back to a numpy array. Is there any chance of adding an optional parameter to `predict()` to change the behaviour to this? I realise that estimators are more intended for ease-of-use but this would only be a few lines to change and by keeping it as an optional parameter backwards-compatibility would be maintained. Happy to prepare a PR if there's a chance it would be accepted."
18226,"After applying dataset.batch(batchsize), could the batchsize show in items' dimension?","### System information
- **Have I written custom code (https://github.com/umich-vl/px2graph/blob/master/util/loader.py)**:
- **OS Platform and Distribution (CentOS Linux release 7.4.1708 (Core))**:
- **TensorFlow installed from (binary)**:
- **TensorFlow version (1.4)**:
- **Python version (3.6)**: 
- **Bazel version (N/A)**:
- **CUDA/cuDNN version (Cuda 8, Cudnn v6)**:
- **GPU model and memory (Titan X, 12 G)**:
- **Exact command to reproduce: The original code is from https://github.com/umich-vl/px2graph, the author use a queue-based input data method, and I want to change it to use tf.data API. Basically only the util/loader.py need to be changed, and the main parts have been shown as follows.**:

### Describe the problem
I would like to change the original queue based data load mechanism to tf.data API.

The original code is:
```
        # Index queue
        self.input_idxs = tf.placeholder(tf.int64, shape=[None, 2])
        idx_queue = tf.FIFOQueue(1e8, tf.int64)
        self.enq_idxs = idx_queue.enqueue_many(self.input_idxs)
        get_idx = idx_queue.dequeue()

        # Image loading queue
        img_queue = tf.FIFOQueue(opt.max_queue_size, task.proc_arg_dtype)
        load_data = tf.py_func(task.load_sample_data, [get_idx], task.proc_arg_dtype)
        enq_img = img_queue.enqueue(load_data)
        init_sample = img_queue.dequeue()

        # Preprocessing queue
        # (for any preprocessing that can be done with TF operations)
        data_queue = tf.FIFOQueue(opt.max_queue_size, task.data_arg_dtype,
                                  shapes=task.data_shape)
        enq_data = data_queue.enqueue(task.preprocess(init_sample, train_flag))
        self.get_sample = data_queue.dequeue_many(opt.batchsize)
```

After the change, it is:
```
        # Dataset
        self.input_idxs = tf.placeholder(tf.int64, shape=[None, 2])
        dataset = tf.data.Dataset.from_tensor_slices(self.input_idxs)

        def load_sample(idx):
            sample = task.load_sample_data(idx)
            sample = task.preprocess(sample, train_flag)
            return sample

        dataset = dataset.map(lambda idx: tf.py_func(load_sample, [idx], task.proc_arg_dtype), num_parallel_calls=self.num_threads)

        def gen(dataset):
            yield dataset.make_one_shot_iterator().get_next()

        dataset = tf.data.Dataset.from_generator(gen, tuple(task.proc_arg_dtype), tuple(task.data_shape)) # set task.data_shape
        dataset = dataset.batch(opt.batchsize)
        self.iterator = dataset.make_initializable_iterator()
        self.get_sample = self.iterator.get_next()
```

where `task.proc_arg_dtype` and `task.data_shape` are:
```
    proc_arg_dtype = [tf.float32, tf.float32, tf.int32, tf.int32, tf.int32, tf.float32, tf.int32, tf.int32, tf.int32]
    data_shape = [
        [opt.input_res, opt.input_res, 3],
        [opt.output_res, opt.output_res, opt.det_inputs],
        [2, opt.max_nodes, 2],
        [4],
        [opt.max_nodes, opt.obj_slots + opt.rel_slots],
        [opt.max_nodes, opt.obj_slots, 5],
        [opt.max_nodes, opt.rel_slots, 2],
        [opt.max_nodes, 7],
        [1]
    ]
```
Since I find `tf.py_func` doesn't have `data_shape` argument so that I add additional `gen` function and use the `tf.data.Dataset.from_generator` to specify the `data_shape` of items in a dataset. 

My problem is the shape of item in `dataset.batch(opt.batchsize)` is 
```
[<tf.Tensor 'IteratorGetNext:0' shape=(?, 512, 512, 3) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(?, 64, 64, 300) dtype=float32>, <tf.Tensor 'IteratorGetNext:2' shape=(?, 2, 200, 2) dtype=int32>, <tf.Tensor 'IteratorGetNext:3' shape=(?, 4) dtype=int32>, <tf.Tensor 'IteratorGetNext:4' shape=(?, 200, 9) dtype=int32>, <tf.Tensor 'IteratorGetNext:5' shape=(?, 200, 3, 5) dtype=float32>, <tf.Tensor 'IteratorGetNext:6' shape=(?, 200, 6, 2) dtype=int32>, <tf.Tensor 'IteratorGetNext:7' shape=(?, 200, 7) dtype=int32>, <tf.Tensor 'IteratorGetNext:8' shape=(?, 1) dtype=int32>]
```
But I need 
```
[<tf.Tensor 'IteratorGetNext:0' shape=(8, 512, 512, 3) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(8, 64, 64, 300) dtype=float32>, <tf.Tensor 'IteratorGetNext:2' shape=(8, 2, 200, 2) dtype=int32>, <tf.Tensor 'IteratorGetNext:3' shape=(8, 4) dtype=int32>, <tf.Tensor 'IteratorGetNext:4' shape=(8, 200, 9) dtype=int32>, <tf.Tensor 'IteratorGetNext:5' shape=(8, 200, 3, 5) dtype=float32>, <tf.Tensor 'IteratorGetNext:6' shape=(8, 200, 6, 2) dtype=int32>, <tf.Tensor 'IteratorGetNext:7' shape=(8, 200, 7) dtype=int32>, <tf.Tensor 'IteratorGetNext:8' shape=(8, 1) dtype=int32>]
```
where `8` is the batchsize.

I tried the following code to solve it:
```
        def add_batch_shape(data):
            for d in data:
                shapes = [int(s) for s in d.shape[1:]]
                shapes.insert(0, opt.batchsize)
                d.set_shape(shapes)

        def wrapped_add(data):
            return tf.py_func(add_batch_shape, [data], task.proc_arg_dtype)

        dataset = dataset.map(wrapped_add, num_parallel_calls=self.num_threads) # (?, 512, 512, 3) to (batchsize, 512, 512, 3)
```
But it will give out an error:

`TypeError: wrapped_add() takes 1 positional argument but 9 were given`

The `[data]` has a `data_shape` as above.

I am wondering after applying `dataset.batch(batchsize)`, could the first dimension of items be the batchsize but not `None`. (and whether `tf.py_func` could add a new argument which specify the data's shape)
"
18225,Distributed TensorFlow: All works use the same GPU device on host with 4 GPUs,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO
- **OS Platform and Distribution **: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: pip2.7 install
- **TensorFlow version (use command below)**: 
tf.VERSION = 1.4.0
tf.GIT_VERSION = v1.4.0-rc1-11-g130a514
tf.COMPILER_VERSION = v1.4.0-rc1-11-g130a514
- **Python version**: python2.7
- **Bazel version (if compiling from source)**: None
- **GCC/Compiler version (if compiling from source)**: None
- **CUDA/cuDNN version**:  cuda_8.0.61_375.26_linux.run/cudnn-8.0-linux-x64-v6.0.tgz
- **GPU model and memory**: TITAN Xp, 12189MiB
- **Exact command to reproduce**:
- **Cuda libs**:
/usr/local/cuda-8.0/lib64/libcudart_static.a
/usr/local/cuda-8.0/lib64/libcudart.so.8.0.61
/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7
/usr/local/cuda-8.0/doc/man/man7/libcudart.7

### Describe the problem
All the 4 works use the same GPU device(GPU:0) when running a distributed training on a host with 4 GPUs.

### Source code / logs
**The distributed runner:**
```
START_PORT = 2222

def evaluate_on_data(estimator, test_input_fn, steps=1):
    """"""Evaluates and prints results, set data to test_data or train_data.""""""
    evaluation = estimator.evaluate(
        input_fn=test_input_fn,
        steps=steps)
    print(""Evaluation on test data:"")
    for key in evaluation:
        print(""| {}: {:.4f} |"".format(key, evaluation[key]))


def ps_start(num_gpus):
    with tf.device('/job:worker/task:0/device:CPU:0'):
        worker_hosts = [""localhost:"" + str(START_PORT + i + 1) for i in range(num_gpus)]
        cluster = tf.train.ClusterSpec({""ps"": [""localhost:"" + str(START_PORT)], ""worker"": worker_hosts})

        # Create and start a server for the local task.
        ps_server = tf.train.Server(cluster, job_name=""ps"", task_index=0)
        ps_server.join()


def distributed_train(num_gpus,
                      task_index,
                      train_input_fn,
                      test_input_fn,
                      model_fn,
                      **model_params):
    worker_hosts = [""localhost:"" + str(START_PORT + i + 1) for i in range(num_gpus)]
    cluster = tf.train.ClusterSpec({""ps"": [""localhost:"" + str(START_PORT)], ""worker"": worker_hosts})
    server = tf.train.Server(cluster, job_name=""worker"", task_index=task_index)

    if task_index == 0:
        tf.logging.info('hyper-params:')
        for k, v in model_params.items():
            tf.logging.info(""  - "" + k + "":\t"" + str(v))

    num_steps_per_epoch = model_params[""num_steps_per_epoch""]
    total_steps = num_steps_per_epoch * model_params[""num_epochs""]
    evaluate_when_train = model_params.get(""evaluate_when_train"", 0)
    eval_steps = model_params[""eval_steps""]
    model_dir = model_params[""model_dir""]

    # Assigns ops to the local worker by default.
    with tf.device(tf.train.replica_device_setter(
            worker_device=""/job:worker/task:%d/device:GPU:%d"" % (task_index, task_index),
            cluster=cluster)):

        os.environ['TF_CONFIG'] = json.dumps(
            {'is_chief': task_index == 0})

        sess_config = tf.ConfigProto(
            allow_soft_placement=True,
            intra_op_parallelism_threads=0)
        model_config = tf.contrib.learn.RunConfig(
            master=server.target,
            log_device_placement=False,
            save_checkpoints_steps=2000,
            session_config=sess_config
        )

        model_params.update({""device_info"": ""gpu-"" + str(task_index)})
        model = tf.estimator.Estimator(
            model_fn=model_fn,
            model_dir=model_dir,
            config=model_config,
            params=model_params
        )

        if evaluate_when_train > 0:
            steps_trained = 0
            while steps_trained < total_steps:
                train_steps = min(num_steps_per_epoch, total_steps - steps_trained)
                model.train(input_fn=train_input_fn, steps=train_steps)
                steps_trained += train_steps
                tf.logging.info(""Trained for {} steps, total {} so far."".format(train_steps, steps_trained))
                # evaluation on the last device
                if task_index == num_gpus - 1:
                    evaluate_on_data(model, test_input_fn, steps=eval_steps)
        else:
            model.train(input_fn=train_input_fn, steps=total_steps)
            # evaluation on the last device
            if task_index == num_gpus - 1:
                evaluate_on_data(model, test_input_fn, steps=eval_steps)
```

**Main python script to use the runner:**
```
def main(_):
    if FLAGS.job_name == ""ps"":
        ps_start(FLAGS.num_gpus)
    else:
        """"""Train and test input_fn.""""""
        train_input_fn = functools.partial(
            generate_sparse_batch_from_proto,
            data_source=FLAGS.train_data,
            batch_size=FLAGS.batch_size,
            max_field_index=FLAGS.max_field_index,
            mode='train'
        )

        test_input_fn = functools.partial(
            generate_sparse_batch_from_proto,
            data_source=FLAGS.test_data,
            batch_size=FLAGS.eval_batch_size,
            max_field_index=FLAGS.max_field_index,
            mode='eval'
            )

        num_steps_per_epoch = FLAGS.num_train // FLAGS.batch_size
        field_size = FLAGS.max_field_index + 1
        model_params = {
            ""dropout_keep"": 0.6,
            ""learning_rate"": FLAGS.learning_rate,
            ""lr_decay_rate"": FLAGS.lr_decay_rate,
            ""l2_reg"": FLAGS.l2_reg,
            ""field_size"": field_size,
            ""num_steps_per_epoch"": num_steps_per_epoch,
            ""num_epochs"": FLAGS.train_epochs,
            ""model_dir"": FLAGS.model_dir,
            ""eval_steps"": FLAGS.eval_steps,
            ""evaluate_when_train"": FLAGS.evaluate_when_train
        }

        distributed_train(
            task_index=FLAGS.task_index,
            num_gpus=FLAGS.num_gpus,
            train_input_fn=train_input_fn,
            test_input_fn=test_input_fn,
            model_fn=model_fn,
            **model_params)
```

**Shell script to trigger the main script:**
```bash
#!/usr/bin/env bash

gpu_index=(0 1 2 3)

num_gpus=${#gpu_index[@]}
date=`date  +""%Y%m%d""`
# start ps
export CUDA_VISIBLE_DEVICES=-1
nohup python -m examples/*_async --job_name=ps --num_gpus=${num_gpus} 1>>ps.${date}.log 2>>ps.${date}.log &
sleep 5

# start worker
for index in ${gpu_index[@]}
do
    export CUDA_VISIBLE_DEVICES=${index}
    nohup python -m examples/*_async --task_index=${index} --num_gpus=${num_gpus} 1>>train.${date}.log 2>>train.${date}.log &
done
```"
18222,Synchronized BatchNorm statistics across GPUs,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: n/a
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: n/a
- **TensorFlow installed from (source or binary)**: n/a
- **TensorFlow version (use command below)**: n/a
- **Python version**:  n/a
- **Bazel version (if compiling from source)**: n/a
- **GCC/Compiler version (if compiling from source)**: n/a
- **CUDA/cuDNN version**: n/a
- **GPU model and memory**: n/a
- **Exact command to reproduce**: n/a

Following the discussion with @isaprykin last Friday, there should be an option for batchnorm to compute the mean & variance over the entire batch across GPUs, when running with distribution strategy.
For typical image classification models it's not needed, however this is essential to other applications where batch-per-GPU is highly limited, such as object detection.

Some related papers:
https://arxiv.org/pdf/1711.07240.pdf 
https://arxiv.org/abs/1803.08494

NOTE: added my own implementation for  TF1 at https://tensorpack.readthedocs.io/modules/models.html#tensorpack.models.BatchNorm"
18221,Running tensorflow on GPU encountered ERROR: libcublas.so.9.0: cannot open shared object file: No such file or directory,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: I'm using the tensorflow object detection API
- **OS Platform and Distribution : Linux Ubuntu 16.04
- **TensorFlow installed from : pip install
- **TensorFlow version (use command below)**: 1.6
- **Python version**: python3
- **CUDA/cuDNN version**: Cuda 9.0
- **GPU model and memory**: GTX 1060
- **Exact command to reproduce**: import tensorflow

ERROR:
import tensorflow
Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/usr/lib/python3.5/imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""/usr/lib/python3.5/imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/usr/lib/python3.5/imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""/usr/lib/python3.5/imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help"
18219,Feature Request:  OutputProjectionWrapper compatible with tf.nn.bidirectional_dynamic_rnn,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:  Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Tensorflow 1.4 Docker under CentOS 7.3
- **TensorFlow installed from (source or binary)**:  Tensorflow 1.4 Docker
- **TensorFlow version (use command below)**:  1.4
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: 8.0
- **GPU model and memory**: Quadro M4000
- **Exact command to reproduce**: N/A (feature request, not bug report)

### Describe the problem
Feature request:  OutputProjectionWrappers for use with tf.nn.bidirectional_dynamic_rnn.  I don't think this is a bug report, per se, because I don't think the wrapper was designed for Bidirectional RNNs. 

tf.nn.bidirectional_dynamic_rnn wants a forward and backward RNN cell, and provides a tuple of tuples:  forward and backward outputs, forward and backward output_states.  

The outputProjectionWrapper just wants a cell as input, and returns another cell as an output.

So while we can wrap both the forward and backward layers in their own outputProjectionWrappers and send those on to tf.nn.bidirectional_dynamic_rnn -- syntactically, it works -- it's not at all what we want conceptually.  All we've done is project the forward and backward layers independently.

"
18218,Feature Request: Named global_step,"I have been developing GAN models for some time now and I find it useful to track the individual stages (pretraining of generator/discriminator, adversarial training) in different global_steps so I can save and restore my actual progress without doing a lot of calculations based on configured training steps and so on.

Therefore, I have basically rebuild the functionality that [tf.train.get_or_create_global_step](https://www.tensorflow.org/versions/master/api_docs/python/tf/train/get_or_create_global_step) provides but with support for named global_steps.

Looks something like `tf.train.get_or_create_global_step(graph, name)`.

Am I the only one finding this particularly helpful?"
18217,TensorRT create exception when engine is created from sub-process,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
TensorRT works well when called in a single process however it breaks when trt.utils.uff_to_trt_engine () is called from sub-process. 


### Source code / logs
Here is the summary of error and how to reproduce it.

Working TensorRT example Python code with a single process :

import pycuda.driver as cuda
import pycuda.autoinit
import argparse
import numpy as np
import time
import tensorrt as trt
from tensorrt.parsers import uffparser

uff_model = open('resnet_v2_50_dc.uff', 'rb').read()

parser = uffparser.create_uff_parser()
parser.register_input(""input"", (3, 224, 224), 0)
parser.register_output(""resnet_v2_50/predictions/Reshape_1"")


trt_logger = trt.infer.ConsoleLogger(trt.infer.LogSeverity.INFO)

engine = trt.utils.uff_to_trt_engine(logger=trt_logger,
                                     stream=uff_model,
                                     parser=parser,
                                     max_batch_size=4,
                                     max_workspace_size= 1 << 30,
                                     datatype=trt.infer.DataType.FLOAT)


Non-working TensorRT  example Python code  where  trt.utils.uff_to_trt_engine () is called from sub-process :

import pycuda.driver as cuda
import pycuda.autoinit
import argparse
import numpy as np
import time
import tensorrt as trt
from tensorrt.parsers import uffparser
import multiprocessing
from multiprocessing import sharedctypes, Queue

def inference_process():
    uff_model = open('resnet_v2_50_dc.uff', 'rb').read()

    parser = uffparser.create_uff_parser()
    parser.register_input(""input"", (3, 224, 224), 0)
    parser.register_output(""resnet_v2_50/predictions/Reshape_1"")

    trt_logger = trt.infer.ConsoleLogger(trt.infer.LogSeverity.INFO)
    engine = trt.utils.uff_to_trt_engine(logger=trt_logger,
                                         stream=uff_model,
                                         parser=parser,
                                         max_batch_size=4,
                                         max_workspace_size= 1 << 30,
                                         datatype=trt.infer.DataType.FLOAT)

inference_p = multiprocessing.Process(target=inference_process, args=( ))
inference_p.start()


Console Error Message :
[TensorRT] ERROR: cudnnLayerUtils.cpp (288) - Cuda Error in smVersion: 3
terminate called after throwing an instance of 'nvinfer1::CudaError'
  what():  std::exception

"
18216, tf.space_to_depth alters input type if its quantized.  But why?,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:  stock from the tf.space_to_depth() example as given on tensorflow.org, with output directed to tf.quantize()

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**:
>>> tf.GIT_VERSION
""b'unknown'""
>>> tf.VERSION
'1.6.0'
- **Python version**: , Python 3.5.4 Tk 8.6.4 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**: dst = tf.dequantize(qstd,qmin,qmax)  see the script below please.

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
tf.depth_to_space() doesnt return the input dtype when it is dtype=tf.qint8.  The type is changed to tf.int8.

### Source code / logs
>>> 
Source:

#
import tensorflow as tf
sess = tf.Session()

dt=tf.float32
box=2
slist = [(1,2,2,1),(1,2,2,3),(1,4,4,1),(2,2,4,1,)]
dlist = [(1,1,1,4),(1,1,1,12),(1,2,2,4)]
sshape=2

space_t=tf.random_uniform(slist[sshape],minval=-10, maxval=10,dtype=tf.float32)

print(sess.run(space_t))

ftin = tf.reshape(space_t,[-1])
max=ftin[tf.argmax(ftin)]
min=ftin[tf.argmin(ftin)]

aq_op = tf.quantize(space_t,min,max,tf.qint8,name=""TFQuantize"")
aq_space_t = sess.run(aq_op)

# The following qstd op should yield a type the same as aq_space_t.output, but does not, according to documentation.
qstd = tf.space_to_depth(aq_space_t.output, box,name = 'TestOut')
out1 = sess.run(qstd)
qftin = tf.reshape(out1,[-1])
qmax=ftin[tf.argmax(qftin)]
qmin=ftin[tf.argmin(qftin)]

dst = tf.dequantize(qstd,qmin,qmax)   ### This is the failing command
out2 = sess.run(dqstd)

# The NON quantized original space_to_depth 
std = tf.space_to_depth(space_t, box,name = 'TestOut')

>>> LOG:
== RESTART: C:/Users/c_jrost/projects/tensorTest/py_tests/autoQuantize3.py ==
[[[[-6.970806 ]
   [-8.151844 ]
   [ 1.0674906]
   [-2.021196 ]]

  [[-6.90624  ]
   [ 7.7964478]
   [ 8.286434 ]
   [ 5.0095863]]

  [[-0.5847721]
   [ 7.9649334]
   [-1.1554356]
   [ 8.961611 ]]

  [[ 1.2922192]
   [-5.9919786]
   [-5.741205 ]
   [ 5.86102  ]]]]
Traceback (most recent call last):
  File ""C:/Users/c_jrost/projects/tensorTest/py_tests/autoQuantize3.py"", line 33, in <module>
    dst = tf.dequantize(qstd,qmin,qmax)
  File ""c:\Users\c_jrost\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\ops\gen_array_ops.py"", line 1319, in dequantize
    mode=mode, name=name)
  File ""c:\Users\c_jrost\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 609, in _apply_op_helper
    param_name=input_name)
  File ""c:\Users\c_jrost\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 60, in _SatisfiesTypeConstraint
    "", "".join(dtypes.as_dtype(x).name for x in allowed_list)))
TypeError: Value passed to parameter 'input' has DataType int8 not in list of allowed values: qint8, quint8, qint32, qint16, quint16

"
18214,Documentation missing for tensorrt in Python API,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: N/A
- **TensorFlow installed from (source or binary)**: N/A
- **TensorFlow version (use command below)**: 1.7
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

### Describe the problem
 Native TensorRT support in TensorFlow was announced by both [Google ](https://developers.googleblog.com/2018/03/tensorrt-integration-with-tensorflow.html) and Nvidia blog posts last week. But `tf.contrib.tensorrt` is missing from the Python API list. Currently, the only documentation is on readme file in the  [tensorflow/contrib/tensorrt](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/tensorrt) repository. But it doesn't given details about using the API.  Please include documentation for this important feature."
18213,Request a new padding mode,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: n/a
- **TensorFlow installed from (source or binary)**: n/a
- **TensorFlow version (use command below)**: n/a
- **Python version**: n/a
- **Bazel version (if compiling from source)**: n/a
- **GCC/Compiler version (if compiling from source)**: n/a
- **CUDA/cuDNN version**: n/a
- **GPU model and memory**: n/a
- **Exact command to reproduce**: n/a

According to https://www.tensorflow.org/api_guides/python/nn#Convolution, the current padding mode ""SAME"" will depend on the input size to determine how many pixels to pad, for example:

input=225, kernel=7, stride=2  ---> padding = [3, 3]
input=224, kernel=7, stride=2  ---> padding = [2, 3]

However, in most other CNN implementations, (and also, historically), padding does not depend on the input size. For kernel=7 and stride=2, padding usually will be [3, 3] (which is actually equivalent to [3, 2] when input=224).

Potential issues:
1. Inconsistent with models trained in other frameworks. It's not the first time I have to manually fix the padding when loading a model released by others, e.g. [here](https://github.com/ppwwyyxx/tensorpack/blob/1139854d7e286b56f87a92f96fe8f1b70789d794/examples/ResNet/load-resnet.py#L40-L42). This also causes pain for multi-backend framework such as Keras, because ""SAME"" does not mean the same thing for each backend. One example Keras issue [here](https://github.com/keras-team/keras/pull/9473). Also Keras has to explicit pad the image in its ResNet50 model: [here](https://github.com/keras-team/keras/blob/ef13db05731bfd53fa0a877637c99c1734be933b/keras/applications/resnet50.py#L213).

2. Due to how padding is computed (by `left=total_padding//2, right=total_padding-left`), the number of pixels padded on __left or top__ of the image may change with different input size, as shown by the example above. This is not a good default and in particular harmful for pixel-level tasks, such as detection&segmentation, where all the annotations have an offset starting from the top-left corner of the image.

In fact, many of Google's own code has to fix this manually by `tf.pad`, for example:
1. tensorflow/benchmarks has a new mode called ""SAME_RESNET"": https://github.com/tensorflow/benchmarks/blob/bab8a61aaca3d2b94072ae2b87f0aafe1797b165/scripts/tf_cnn_benchmarks/convnet_builder.py#L183-L199
2. The recent tpu training code has a function called ""conv2d_fixed_padding"": https://github.com/tensorflow/tpu/blob/b189540102d6b5b40b1730d7e5ad5c884bae323c/models/experimental/resnet_bfloat16/resnet_model.py#L102-L107
3. slim has a function called `conv2d_same`: https://github.com/tensorflow/models/blob/696b69a498b43f8e6a1ecb24bb82f7b9db87c570/research/slim/nets/resnet_utils.py#L77-L122
4. google-research/big_transfer: https://github.com/google-research/big_transfer/blob/49afe42338b62af9fbe18f0258197a33ee578a6b/bit_tf2/models.py#L36-L38
5. google-research/simclr: https://github.com/google-research/simclr/blob/6bf69ce127ae33e181e1a6c5777c84570cb5d147/tf2/resnet.py#L160-L183
6. TPU object detection codebase: https://github.com/tensorflow/tpu/blob/6f9c87c1215a67fd97da7272eff247e53f266e80/models/official/detection/modeling/architecture/nn_ops.py#L309-L327
Given all these I think it's reasonable to add a new mode to make things easier."
18211,freeze_graph.py generates error messages when run on sample model (census / wide_deep),"1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: ('v1.6.0-0-gd2e24b6039', '1.6.0')
- **Python version**: Python 2.7.12 (default, Dec  4 2017, 14:50:18) [GCC 5.4.0 20160609] on linux2
- **CUDA/cuDNN version**: Not using GPU
- **GPU model and memory**: Not using GPU
- **Exact command to reproduce**:
Follow the ""wide_deep"" tutorial
Try to freeze the generated model by running: 
python freeze_graph.py 
  --input_graph=/tmp/census_model/graph.pbtxt 
  --input_checkpoint=/tmp/census_model/model.ckpt-190 
  --output_graph=/tmp/census_model/frozen_graph.pb
  --output_node_names=softmax

An error is generated:
TypeError: names_to_saveables must be a dict mapping string names to Tensors/Variables. Not a variable: Tensor(""dnn/hiddenlayer_0/bias:0"", shape=(100,), dtype=float32)

### Describe the problem
I would think that the freeze_graph script should finish successfully, hence I believe the problem is that an error message is generated.

### Source code / logs
Traceback (most recent call last):
  File ""freeze_graph.py"", line 380, in <module>
    app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/media/LinuxApps/home/karsten/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 126, in run
    _sys.exit(main(argv))
  File ""freeze_graph.py"", line 274, in main
    FLAGS.saved_model_tags, checkpoint_version)
  File ""freeze_graph.py"", line 256, in freeze_graph
    checkpoint_version=checkpoint_version)
  File ""freeze_graph.py"", line 130, in freeze_graph_with_def_protos
    var_list=var_list, write_version=checkpoint_version)
  File ""/media/LinuxApps/home/karsten/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1293, in __init__
    self.build()
  File ""/media/LinuxApps/home/karsten/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1302, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File ""/media/LinuxApps/home/karsten/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1339, in _build
    build_save=build_save, build_restore=build_restore)
  File ""/media/LinuxApps/home/karsten/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 774, in _build_internal
    saveables = self._ValidateAndSliceInputs(names_to_saveables)
  File ""/media/LinuxApps/home/karsten/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 677, in _ValidateAndSliceInputs
    variable)
TypeError: names_to_saveables must be a dict mapping string names to Tensors/Variables. Not a variable: Tensor(""dnn/hiddenlayer_0/bias:0"", shape=(100,), dtype=float32)
"
18207,Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2,"#When i try run code python train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/ssd_mobilenet_v1_pets.config

It tells me: 
WARNING:tensorflow:From C:\Users\kuba7\AppData\Local\Programs\Python\Python35\lib\site-packages\object_detection-0.1-py3.5.egg\object_detection\trainer.py:228: create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.create_global_step
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:Summary name /clone_loss is illegal; using clone_loss instead.
WARNING:tensorflow:From C:\Users\kuba7\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\contrib\slim\python\slim\learning.py:736: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
2018-04-03 17:15:26.363868: I C:\tf_jenkins\workspace\rel-win\M\windows\PY\35\tensorflow\core\platform\cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
INFO:tensorflow:Restoring parameters from training/model.ckpt-0
INFO:tensorflow:Starting Session.
INFO:tensorflow:Saving checkpoint to path training/model.ckpt
INFO:tensorflow:Starting Queues.
INFO:tensorflow:global_step/sec: 0

What should i do?"
18206,Do you have plan to optimize memory for Tensorflow Lite?,"Do you have plan to optimize memory for Tensorflow Lite? For a image or video related task, the memory occupation is too large."
18205,Distribution Strategy not working with tf-nightly-gpu for Python3.5,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No, I am using the script https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/distribute/python/examples/simple_estimator_example.py provided as an example for DistributionStrategy API
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux  4.13.0-37-generic #42~16.04.1-Ubuntu SMP Wed Mar 7 16:03:28 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux ""16.04.4 LTS (Xenial Xerus)""
- **TensorFlow installed from (source or binary)**: binary through pip3 install tf-nightly-gpu
tf.VERSION = 1.8.0-dev20180402
tf.GIT_VERSION = v1.7.0-rc1-1091-gc7a04561fb
tf.COMPILER_VERSION = v1.7.0-rc1-1091-gc7a04561fb
Sanity check: array([1], dtype=int32)
- **TensorFlow version (use command below)**: v1.7.0-rc1-1091-gc7a04561fb 1.8.0-dev20180402
- **Python version**: 3.5
- **CUDA/cuDNN version**: 
CUDA version: 9.0, V9.0.176
#define CUDNN_MAJOR 7
#define CUDNN_MINOR 0
#define CUDNN_PATCHLEVEL 5
- **GPU model and memory**: Quadro M6000 24GB
- **Exact command to reproduce**: python3 

### Describe the problem
I am trying to test the DistributionStrategy API. In order to do that I downloaded the tensorflow nightly build by executing  
pip3 install tf-nightly-gpu
Then I tried to execute the example provided here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/distribute/python/examples/simple_estimator_example.py
But it is not working, there is an exception shortly after the script starts to run ( I am copying the stack trace in the next section).
I have tried to do the same using the  tensorflow nightly build for python 2.7 downloaded by executing  
pip install tf-nightly-gpu and it works without any problem.
The issue here, is that I would like to integrate this API with my multi-gpu training and inference processes, which are complete written for python3. 
I would like to know, if DistributionStrategy API is already supported in for python 3.5 and the problem is that I am using a wrong example. Or, in case it is not supported yet, if there are plans to do it.

Thanks in advance.


### Source code / logs
(vtf_nightly_gpu) /ccrespo/mirrored_strategy/src$ python3 mirrored_strategy_test.py 
WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpmou3ft0t
2018-04-03 16:17:32.334622: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-04-03 16:17:32.686755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: Quadro M6000 24GB major: 5 minor: 2 memoryClockRate(GHz): 1.114
pciBusID: 0000:03:00.0
totalMemory: 23.90GiB freeMemory: 23.35GiB
2018-04-03 16:17:32.956384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 1 with properties: 
name: Quadro M6000 24GB major: 5 minor: 2 memoryClockRate(GHz): 1.114
pciBusID: 0000:04:00.0
totalMemory: 23.90GiB freeMemory: 23.78GiB
2018-04-03 16:17:33.215141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 2 with properties: 
name: Quadro M6000 24GB major: 5 minor: 2 memoryClockRate(GHz): 1.114
pciBusID: 0000:a1:00.0
totalMemory: 23.90GiB freeMemory: 23.78GiB
2018-04-03 16:17:33.215663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1, 2
2018-04-03 16:17:34.314104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-03 16:17:34.314172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 2 
2018-04-03 16:17:34.314181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N Y N 
2018-04-03 16:17:34.314185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   Y N N 
2018-04-03 16:17:34.314190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 2:   N N N 
2018-04-03 16:17:34.315429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/device:GPU:0 with 22663 MB memory) -> physical GPU (device: 0, name: Quadro M6000 24GB, pci bus id: 0000:03:00.0, compute capability: 5.2)
2018-04-03 16:17:34.802106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/device:GPU:1 with 23083 MB memory) -> physical GPU (device: 1, name: Quadro M6000 24GB, pci bus id: 0000:04:00.0, compute capability: 5.2)
2018-04-03 16:17:35.250349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/device:GPU:2 with 23083 MB memory) -> physical GPU (device: 2, name: Quadro M6000 24GB, pci bus id: 0000:a1:00.0, compute capability: 5.2)
2018-04-03 16:17:35.726606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1, 2
2018-04-03 16:17:35.726819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-03 16:17:35.726838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 2 
2018-04-03 16:17:35.726849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N Y N 
2018-04-03 16:17:35.726858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   Y N N 
2018-04-03 16:17:35.726867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 2:   N N N 
2018-04-03 16:17:35.727458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22663 MB memory) -> physical GPU (device: 0, name: Quadro M6000 24GB, pci bus id: 0000:03:00.0, compute capability: 5.2)
2018-04-03 16:17:35.727626: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 23083 MB memory) -> physical GPU (device: 1, name: Quadro M6000 24GB, pci bus id: 0000:04:00.0, compute capability: 5.2)
2018-04-03 16:17:35.727819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 23083 MB memory) -> physical GPU (device: 2, name: Quadro M6000 24GB, pci bus id: 0000:a1:00.0, compute capability: 5.2)
Traceback (most recent call last):
  File ""mirrored_strategy_test.py"", line 86, in <module>
    tf.app.run()
  File ""/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/platform/app.py"", line 126, in run
    _sys.exit(main(argv))
  File ""mirrored_strategy_test.py"", line 70, in main
    estimator.train(input_fn=input_fn, steps=10)
  File ""/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py"", line 363, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py"", line 841, in _train_model
    return self._train_model_distributed(input_fn, hooks, saving_listeners)
  File ""/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py"", line 884, in _train_model_distributed
    self.config)
  File ""/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/training/distribute.py"", line 751, in call_for_each_tower
    return self._call_for_each_tower(fn, *args, **kwargs)
  File ""/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py"", line 254, in _call_for_each_tower
    coord.join(threads)
  File ""/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/training/coordinator.py"", line 389, in join
    six.reraise(*self._exc_info_to_raise)
  File ""/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/six.py"", line 693, in reraise
    raise value
  File ""/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/training/coordinator.py"", line 297, in stop_on_exception
    yield
  File ""/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py"", line 248, in _call_for_each_tower
    self, *merge_args, **merge_kwargs)
  File ""/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py"", line 667, in _distributed_apply
    reduced_grads = distribution.batch_reduce(""sum"", grads_and_vars)
  File ""/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/training/distribute.py"", line 796, in batch_reduce
    return self._batch_reduce(method_string, value_destination_pairs)
  File ""/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py"", line 295, in _batch_reduce
    value_destination_pairs)
  File ""/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py"", line 175, in batch_reduce
    return self._batch_reduce(method_string, value_destination_pairs)
  File ""/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py"", line 462, in _batch_reduce
    [v[0] for v in value_destination_pairs])
  File ""/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py"", line 517, in _batch_all_reduce
    method_string)
  File ""/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py"", line 276, in _ungroup_and_make_mirrored
    index[i][destinations[d]] = v
TypeError: 'dict_keys' object does not support indexing
"
18204,Unable to compile from source using Bazel,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: CentOS 7
- **TensorFlow installed from (source or binary)**: Attempting source. (Binary installation works)
- **TensorFlow version (use command below)**: 1.7 (tried 1.5+)
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: 0.11
- **GCC/Compiler version (if compiling from source)**: 4.8
- **CUDA/cuDNN version**: 9.0/7
- **GPU model and memory**: K10, 12GB
- **Exact command to reproduce**: bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package


I receive the following error:

`INFO: Analysed target //tensorflow/tools/pip_package:build_pip_package (258 packages loaded).
INFO: Found 1 target...
Unhandled exception thrown during build; message: /home/dmallon@isd.csc.mrc.ac.uk/cardiac/dl_stuff/tensorflow/bazel-out (Operation not supported)
INFO: Elapsed time: 6.481s
FAILED: Build did NOT complete successfully
java.lang.UnsupportedOperationException: /home/dmallon@isd.csc.mrc.ac.uk/cardiac/dl_stuff/tensorflow/bazel-out (Operation not supported)
        at com.google.devtools.build.lib.unix.NativePosixFiles.symlink(Native Method)
        at com.google.devtools.build.lib.unix.UnixFileSystem.createSymbolicLink(UnixFileSystem.java:329)
        at com.google.devtools.build.lib.vfs.Path.createSymbolicLink(Path.java:883)
        at com.google.devtools.build.lib.vfs.FileSystemUtils.ensureSymbolicLink(FileSystemUtils.java:369)
        at com.google.devtools.build.lib.vfs.FileSystemUtils.ensureSymbolicLink(FileSystemUtils.java:320)
        at com.google.devtools.build.lib.buildtool.OutputDirectoryLinksUtils.createLink(OutputDirectoryLinksUtils.java:251)
        at com.google.devtools.build.lib.buildtool.OutputDirectoryLinksUtils.createOutputDirectoryLinks(OutputDirectoryLinksUtils.java:89)
        at com.google.devtools.build.lib.buildtool.ExecutionTool.executeBuild(ExecutionTool.java:380)
        at com.google.devtools.build.lib.buildtool.BuildTool.buildTargets(BuildTool.java:279)
        at com.google.devtools.build.lib.buildtool.BuildTool.processRequest(BuildTool.java:383)
        at com.google.devtools.build.lib.buildtool.BuildTool.processRequest(BuildTool.java:350)
        at com.google.devtools.build.lib.runtime.commands.BuildCommand.exec(BuildCommand.java:74)
        at com.google.devtools.build.lib.runtime.BlazeCommandDispatcher.execExclusively(BlazeCommandDispatcher.java:489)
        at com.google.devtools.build.lib.runtime.BlazeCommandDispatcher.exec(BlazeCommandDispatcher.java:218)
        at com.google.devtools.build.lib.runtime.CommandExecutor.exec(CommandExecutor.java:58)
        at com.google.devtools.build.lib.server.GrpcServerImpl.executeCommand(GrpcServerImpl.java:851)
        at com.google.devtools.build.lib.server.GrpcServerImpl.access$2100(GrpcServerImpl.java:109)
        at com.google.devtools.build.lib.server.GrpcServerImpl$2.lambda$run$0(GrpcServerImpl.java:916)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
java.lang.UnsupportedOperationException: /home/dmallon@isd.csc.mrc.ac.uk/cardiac/dl_stuff/tensorflow/bazel-out (Operation not supported)
        at com.google.devtools.build.lib.unix.NativePosixFiles.symlink(Native Method)
        at com.google.devtools.build.lib.unix.UnixFileSystem.createSymbolicLink(UnixFileSystem.java:329)
        at com.google.devtools.build.lib.vfs.Path.createSymbolicLink(Path.java:883)
        at com.google.devtools.build.lib.vfs.FileSystemUtils.ensureSymbolicLink(FileSystemUtils.java:369)
        at com.google.devtools.build.lib.vfs.FileSystemUtils.ensureSymbolicLink(FileSystemUtils.java:320)
        at com.google.devtools.build.lib.buildtool.OutputDirectoryLinksUtils.createLink(OutputDirectoryLinksUtils.java:251)
        at com.google.devtools.build.lib.buildtool.OutputDirectoryLinksUtils.createOutputDirectoryLinks(OutputDirectoryLinksUtils.java:89)
        at com.google.devtools.build.lib.buildtool.ExecutionTool.executeBuild(ExecutionTool.java:380)
        at com.google.devtools.build.lib.buildtool.BuildTool.buildTargets(BuildTool.java:279)
        at com.google.devtools.build.lib.buildtool.BuildTool.processRequest(BuildTool.java:383)
        at com.google.devtools.build.lib.buildtool.BuildTool.processRequest(BuildTool.java:350)
        at com.google.devtools.build.lib.runtime.commands.BuildCommand.exec(BuildCommand.java:74)
        at com.google.devtools.build.lib.runtime.BlazeCommandDispatcher.execExclusively(BlazeCommandDispatcher.java:489)
        at com.google.devtools.build.lib.runtime.BlazeCommandDispatcher.exec(BlazeCommandDispatcher.java:218)
        at com.google.devtools.build.lib.runtime.CommandExecutor.exec(CommandExecutor.java:58)
        at com.google.devtools.build.lib.server.GrpcServerImpl.executeCommand(GrpcServerImpl.java:851)
        at com.google.devtools.build.lib.server.GrpcServerImpl.access$2100(GrpcServerImpl.java:109)
        at com.google.devtools.build.lib.server.GrpcServerImpl$2.lambda$run$0(GrpcServerImpl.java:916)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
`

Does anyone have any ideas? I've tried multiple versions of Java (8-151, 8-161, 7-161). 
"
18203,As per documentation Tensorflow 1.5 with Cuda -8 ,"Hi,

As per documentation in the below link:

[https://www.tensorflow.org/versions/r1.5/install/install_linux#InstallingVirtualenv](url)

Requirement for tensorflow 1.5 is Cuda 8. I installed tensorflow using the following tf binary url https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.5.0rc1-cp27-none-linux_x86_64.whl

However, still it is asking for cuda 9. Is there any .whl, which supports cuda 8 ( tensorflow 1.5)."
18202,Submit Raspberry Pi releases to piwheels.org,"I maintain the [piwheels](https://www.piwheels.org/) project where we build Arm platform Python wheels on Raspberry Pi, and provide them to Raspbian users (pre-configured in pip.conf) for speedy installs. As well as automating building most packages, we're able to manually import wheels built elsewhere.

It's great that you're now providing Raspberry Pi builds on Jenkins, but the current (undocumented) installation process is to `pip install` from the URL of the file on Jenkins. If you were able to upload these wheels to piwheels, users would just be able to `pip install tensorflow` and get it.

However, you seem to provide wheels for Python 2.7 and 3.4 (but not 3.5, which is the version which ships with Raspbian Stretch). Would you be able to build for Python 3.5 as well?

Also you give your wheels a platform tag of `any` which is naughty. The platform reported on Pi 1/Zero is `linux_armv6l` and on Pi 2/3 is `linux_armv7l`.

If you can provide the following wheels for v1.7 (and future releases submitted to pypi - no need for nightlies):

- Python 2.7 Armv6
- Python 3.4 Armv6
- Python 3.5 Armv6
- Python 2.7 Armv7
- Python 3.4 Armv7
- Python 3.5 Armv7

then I can upload them to piwheels and Raspberry Pi users will have them available no hassle.

Thanks!

P.S. If you want to get in touch I'm ben [at] raspberrypi [dot] org"
18201,Cleanup the file structures in tensorflow/core/kernels,"This is a feature request about the file structure in ```tensorflow/core/kernels``` .

### The problem

There is a CPU/GPU mingled source codes in the OpKernel directory.
This file structure seems that it is complicated to search the CPU/GPU independent code.
How about to cleanup the file structures?
I think the file structures (```tensorflow/compiler/xla/service```) on XLA is great approach because it is more pluggable and less dependency with another device.

And I would like to contribute if you accept this idea.

Thanks"
18199,[Question]TFLite gpu acceleration.,"Current, my model's inference speed (mate 10) 300ms
We have applied all the structural transformations that can be done in the model, algorithm
So, I am looking for a way to improve the performance of the Android platform.
Example of Render Script, OpenCL...
But, don't know if these ways really improve inference performance dramatically.
I wonder if these methods are applied to Tensorflow Mobile(including TFLite) at present.
I also wonder which method is the most appropriate.

Have a nice day :)"
18198,Different scatter_nd behaviours with int and float,"I am using tensorflow 1.4.1.
scatter_nd seems not check the index validation with float, because following codes generate no error. 

```
a = tf.scatter_nd( [[0,99,0,0]], [[1.0 for i in range(16)]], [100, 8, 100, 100, 16])
with tf.Session() as sess:
    print(sess.run(a))
```
If the 1.0 is changed to 1, the codes generate errors:

```
a = tf.scatter_nd( [[0,99,0,0]], [[1 for i in range(16)]], [100, 8, 100, 100, 16])
with tf.Session() as sess:
    print(sess.run(a))
```
Is this designed for some purpose or a bug?
"
18195,Saving frozen model to tflite error,"------------------------
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, I write own model define, loss and training codes.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 14.04
- **TensorFlow installed from (source or binary)**: binary, pip install
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**:  2.7
- **Bazel version (if compiling from source)**: 0.10.0
- **GCC/Compiler version (if compiling from source)**: 4.9.4
- **CUDA/cuDNN version**: 8.0
- **GPU model and memory**: GeForce GTX 1060
- **Exact command to reproduce**:

### Describe the problem
I have train some customized model with tensorflow and trying to make it a tensorflow lite model for mobile apps. I success in freezing the model and viewing it in tensorboard. I get error when I trying to save it to a tensorflow lite file.

my model defins like: 

```
`def P_Net(inputs,label=None,bbox_target=None,landmark_target=None,training=True):
    #define common param
    with slim.arg_scope([slim.conv2d],
                        activation_fn=prelu,
                        weights_initializer=slim.xavier_initializer(),
                        biases_initializer=tf.zeros_initializer(),
                        weights_regularizer=slim.l2_regularizer(0.0005), 
                        padding='valid'):
        print inputs.get_shape()
        net = slim.conv2d(inputs, 28, 3, stride=1,scope='conv1')
......
        conv4_1 = slim.conv2d(net,num_outputs=2,kernel_size=[1,1],stride=1,scope='conv4_1',activation_fn=tf.nn.softmax)
        #conv4_1 = slim.conv2d(net,num_outputs=1,kernel_size=[1,1],stride=1,scope='conv4_1',activation_fn=tf.nn.sigmoid)

        print conv4_1.get_shape()
        #batch*H*W*4
        bbox_pred = slim.conv2d(net,num_outputs=4,kernel_size=[1,1],stride=1,scope='conv4_2',activation_fn=None)
        print bbox_pred.get_shape()`
```

where conv4_1 and conv4_2 is the output layer.

I freeze the model with:

`freeze_graph.freeze_graph('out_put_model/model.pb', '', False, model_path, 'Squeeze,Squeeze_1', '', '', 'out_put_model/frozen_model.pb', '', '')`

I use tensorboard to view the graph and even try to read them back and forward. it produces same result as reading from checkpoint.

![screenshot from 2018-04-03 11 34 54](https://user-images.githubusercontent.com/4598153/38235205-d847d230-3752-11e8-98b4-8b9b235c517a.png)

![screenshot from 2018-04-03 11 23 06](https://user-images.githubusercontent.com/4598153/38235214-dc606a26-3752-11e8-926e-7193e1174e47.png)

Squeeze and Squeeze_1 is the output nodes. image_height, image_width, input_image is input nodes. all of the input nodes is not fixed shape, and resized in the graph.

code of input placeholder like:

```
with graph.as_default():
            #define tensor and op in graph(-1,1)
            self.image_op = tf.placeholder(tf.float32, name='input_image')
            self.width_op = tf.placeholder(tf.int32, name='image_width')
            self.height_op = tf.placeholder(tf.int32, name='image_height')
            image_reshape = tf.reshape(self.image_op, [1, self.height_op, self.width_op, 3])
            #self.cls_prob batch*2
            #self.bbox_pred batch*4
            #construct model here
            #self.cls_prob, self.bbox_pred = net_factory(image_reshape, training=False)
            #contains landmark
            self.cls_prob, self.bbox_pred, _ = net_factory(image_reshape, training=False)
```


I find the tensorflow 1.4.0 don't have tf lite module and checkout tensorflow master branch from github. and run bazel toco for a tflite model.

` bazel run --config=opt   //tensorflow/contrib/lite/toco:toco --   --input_file='/home/sen/mtcnn_cat/MTCNN-Tensorflow/test/out_put_model/frozen_model.pb'    --output_file='/home/sen/mtcnn_cat/MTCNN-Tensorflow/test/out_put_model/pnet.tflite'    --inference_type=FLOAT   --input_shape=None,None,None   --input_array=image_height,image_width,input_image   --output_array=Squeeze,Squeeze_1  --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --dump_graphviz=/tmp`


but I got this error:
```
INFO: Analysed target //tensorflow/contrib/lite/toco:toco (0 packages loaded).
INFO: Found 1 target...
Target //tensorflow/contrib/lite/toco:toco up-to-date:
  bazel-bin/tensorflow/contrib/lite/toco/toco
INFO: Elapsed time: 0.288s, Critical Path: 0.00s
INFO: Build completed successfully, 1 total action

INFO: Running command line: bazel-bin/tensorflow/contrib/lite/toco/toco '--input_file=/home/sensetime/mtcnn_cat/MTCNN-Tensorflow/test/out_put_model/frozen_model.pb' '--output_file=/home/sensetime/mtcnn_cat/MTCNN-Tensorflow/test/out_put_model/pnet.tflite' '--inference_type=FLOAT' '--input_shape=None,None,None' '--input_array=image_height,image_width,input_image' '--output_array=Squeeze,Squeeze_1' '--input_format=TENSORFLOW_GRAPHDEF' '--output_format=TFLITE' '--dump_graphviz=/tmp'
ERROR: Non-zero return code '1' from command: Process exited with status 1
```

what's the problem? is the input_array, input_shape, output_array parameter right?
Thanks and any suggestion is welcome.




"
18194,warnings building Tensorflow 1.7 from source,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
no, just tensorflow 1.7.0
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
installed from source
- **TensorFlow version (use command below)**:
1.7.0
- **Python version**:
3.6.5 (Anaconda)
- **Bazel version (if compiling from source)**:
0.11.1
- **GCC/Compiler version (if compiling from source)**:
gcc (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609
- **CUDA/cuDNN version**:
9.1 / 7.1.2
- **GPU model and memory**:
GeForce GTX 980, 4GB
- **Exact command to reproduce**:
```
source activate python36
./configure

Please specify the location of python. [Default is /home/hunterwolf/anaconda3/envs/python36/bin/python]: 

Found possible Python library paths:
  /home/hunterwolf/anaconda3/envs/python36/lib/python3.6/site-packages
Please input the desired Python library path to use.  Default is [/home/hunterwolf/anaconda3/envs/python36/lib/python3.6/site-packages]

Do you wish to build TensorFlow with CUDA support? [y/N]: y
CUDA support will be enabled for TensorFlow.

Please specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 9.0]: 9.1

Please specify the location where CUDA 9.1 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: /usr/local/cuda-9.1

Please specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7.0]: 7.1.2

Please specify the location where cuDNN 7 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda-9.1]:

Please specify a list of comma-separated Cuda compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size. [Default is: 5.2]5.2

Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: 

Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native]:

bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
```

### Describe the problem
following https://www.tensorflow.org/install/install_sources gide, I get a lot of warnings while building Tensorflow 1.7 from source. the process is completed anyway and the whl file created.


### Source code / logs
```
WARNING:
/home/hunterwolf/.cache/bazel/_bazel_hunterwolf/52c81ed9b047b1a3afd28a55294d981e/external/protobuf_archive/WORKSPACE:1: Workspace name in /home/hunterwolf/.cache/bazel/_bazel_hunterwolf/52c81ed9b047b1a3afd28a55294d981e/external/protobuf_archive/WORKSPACE (@com_google_protobuf) does not match the name given in the repository's definition (@protobuf_archive); this will cause a build error in future versions
WARNING: /home/hunterwolf/.cache/bazel/_bazel_hunterwolf/52c81ed9b047b1a3afd28a55294d981e/external/grpc/WORKSPACE:1: Workspace name in /home/hunterwolf/.cache/bazel/_bazel_hunterwolf/52c81ed9b047b1a3afd28a55294d981e/external/grpc/WORKSPACE (@com_github_grpc_grpc) does not match the name given in the repository's definition (@grpc); this will cause a build error in future versions
WARNING: /home/hunterwolf/.cache/bazel/_bazel_hunterwolf/52c81ed9b047b1a3afd28a55294d981e/external/grpc/BUILD:1943:1: in srcs attribute of cc_library rule @grpc//:grpc_nanopb: please do not import '@grpc//third_party/nanopb:pb_common.c' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'grpc_generate_one_off_targets', the error might have been caused by the macro implementation in /home/hunterwolf/.cache/bazel/_bazel_hunterwolf/52c81ed9b047b1a3afd28a55294d981e/external/grpc/bazel/grpc_build_system.bzl:172:12
WARNING: /home/hunterwolf/.cache/bazel/_bazel_hunterwolf/52c81ed9b047b1a3afd28a55294d981e/external/grpc/BUILD:1943:1: in srcs attribute of cc_library rule @grpc//:grpc_nanopb: please do not import '@grpc//third_party/nanopb:pb_decode.c' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'grpc_generate_one_off_targets', the error might have been caused by the macro implementation in /home/hunterwolf/.cache/bazel/_bazel_hunterwolf/52c81ed9b047b1a3afd28a55294d981e/external/grpc/bazel/grpc_build_system.bzl:172:12
WARNING: /home/hunterwolf/.cache/bazel/_bazel_hunterwolf/52c81ed9b047b1a3afd28a55294d981e/external/grpc/BUILD:1943:1: in srcs attribute of cc_library rule @grpc//:grpc_nanopb: please do not import '@grpc//third_party/nanopb:pb_encode.c' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'grpc_generate_one_off_targets', the error might have been caused by the macro implementation in /home/hunterwolf/.cache/bazel/_bazel_hunterwolf/52c81ed9b047b1a3afd28a55294d981e/external/grpc/bazel/grpc_build_system.bzl:172:12
WARNING: /home/hunterwolf/tensorflow/tensorflow/contrib/learn/BUILD:17:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': No longer supported. Switch to SavedModel immediately.
WARNING: /home/hunterwolf/tensorflow/tensorflow/contrib/learn/BUILD:17:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': No longer supported. Switch to SavedModel immediately.
```
What (eventually) I'm doing wrong?
First time building Tensorflow from code and first time using Bazel, sorry for the noob question :)"
18193,tf.keras.estimator.model_to_estimator fails with pre-trained models,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 7 x64
- **TensorFlow installed from (source or binary)**: binary (pip)
- **TensorFlow version (use command below)**: 1.7.0 (cpu)
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: n.a.
- **GCC/Compiler version (if compiling from source)**: n.a.
- **CUDA/cuDNN version**: n.a.
- **GPU model and memory**: n.a.
- **Exact command to reproduce**:

### Describe the problem
Following the example code for [Creating Estimators from Keras models](https://www.tensorflow.org/programmers_guide/estimators), I encountered a problem: the example code runs fine when `weights=None` is used in the initialization of the `InceptionV3` object. But when I change it to `weights=imagenet` the call to `model_to_estimator(...)` fails:

> FailedPreconditionError: Attempting to use uninitialized value batch_normalization_100/beta
> 	 [[Node: _retval_batch_normalization_100/beta_0_0 = _Retval[T=DT_FLOAT, index=0, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](batch_normalization_100/beta)]]

 This looks like the weights of the model are not correctly initialized. But strangely I can use the keras model to obtain predictions, which should mean that the model is correctly initialized.

As far as I know there are no information in the documentation that pre-trained models (i.e. models with `weights` set to anything different than `None`) are not supported by this function, or that one has to change the workflow somehow. Therefore, this is either a bug in tensorflow or a case of a misleading documentation.

### Source code / logs
```python
# Instantiate a Keras inception v3 model.
keras_inception_v3 = tf.keras.applications.inception_v3.InceptionV3(weights=""imagenet"")
# Compile model with the optimizer, loss, and metrics you'd like to train with.
keras_inception_v3.compile(optimizer=tf.keras.optimizers.SGD(lr=0.0001, momentum=0.9),
                          loss='categorical_crossentropy',
                          metric='accuracy')
# Create an Estimator from the compiled Keras model. Note the initial model
# state of the keras model is preserved in the created Estimator.
est_inception_v3 = tf.keras.estimator.model_to_estimator(keras_model=keras_inception_v3)

# Treat the derived Estimator as you would with any other Estimator.
# First, recover the input name(s) of Keras model, so we can use them as the
# feature column name(s) of the Estimator input function:
keras_inception_v3.input_names  # print out: ['input_1']
# Once we have the input name(s), we can create the input function, for example,
# for input(s) in the format of numpy ndarray:
train_input_fn = tf.estimator.inputs.numpy_input_fn(
    x={""input_1"": train_data},
    y=train_labels,
    num_epochs=1,
    shuffle=False)
# To train, we call Estimator's train function:
est_inception_v3.train(input_fn=train_input_fn, steps=2000)
```"
18191,How to add unsupported operation in TF-Lite?(ResizeNearestNeighbor),"Converting Hourglass model, I encountered an unsupported error.
This [document] is very simple. so I have to need more information(example code)(https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/custom_operators.md)

[Custom operation](https://github.com/tensorflow/tensorflow/pull/17074) Is there only this way? It is a difficulty for me.

**Error**
```
2018-04-03 12:16:05.786878: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1173] Converting unsupported operation: ResizeNearestNeighbor
2018-04-03 12:16:05.787136: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1173] Converting unsupported operation: ResizeNearestNeighbor
2018-04-03 12:16:05.787422: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1173] Converting unsupported operation: ResizeNearestNeighbor
2018-04-03 12:16:05.787639: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1173] Converting unsupported operation: ResizeNearestNeighbor
2018-04-03 12:16:05.792603: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 558 operators, 854 arrays (0 quantized)
2018-04-03 12:16:05.798150: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 558 operators, 854 arrays (0 quantized)
2018-04-03 12:16:05.807106: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 193 operators, 382 arrays (0 quantized)
2018-04-03 12:16:05.809755: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 193 operators, 382 arrays (0 quantized)
2018-04-03 12:16:05.811826: F tensorflow/contrib/lite/toco/toco_tooling.cc:46] Check failed: unsupported_ops.empty() These unsupported ops were not removed by graph transformations: ResizeNearestNeighbor
```

### System information
-**OS Platform and Distribution : Ubuntu 16.04 LTS
-**TensorFlow installed from : official
-**TensorFlow version : 1.5 version
-**Bazel version : 0.9.0
-**CUDA/cuDNN version : V 8.0.61 (8.0)
-**GPU model and memory : GeForce GTX 1060 / 3G
Exact command to reproduce :
```
bazel run -c opt --copt=-msse4.1 --copt=-msse4.2 --config=opt //tensorflow/contrib/lite/toco:toco --
 --input_file=/home/danshin/tensorflow_lite/final_sa_ri_mobile_192_1stack.pb 
--output_file=/home/danshin/tensorflow_lite/final_sa_ri_mobile_192_1stack.tflite 
--input_format=TENSORFLOW_GRAPHDEF 
--output_format=TENSORFLOW_GRAPHDEF
--input_shape=1,192,144,3 --input_array=inference_images/Placeholder 
--output_array=Generator_1/stage1/confidence_map/Conv/convolution
```

Have a nice day.
"
18190,How to implement fine-tune training in blstm?,"I just want a cnn network,blstm network,word embedding and implement them separately
Save their params and use into a new network.
I have tried tf.saver\restore and tf.collection,it dosen't work.
How and I do that?
thank u very much"
18188,contrib.distribute is not Python3 compatible,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes. Porting internal ResNet distributed back into models/official
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 16.04 on GCP
- **TensorFlow installed from (source or binary)**:
pip
- **TensorFlow version (use command below)**:
tf-nightly-gpu==1.8.0.dev20180330
- **Python version**: 
3.5.2
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
CUDA 9.0, CUDNN 7.0
- **GPU model and memory**:
4xP100
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.


```
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:batch_all_reduce invoked for batches size = 153 with algorithm = nccl and num_packs = 1
INFO:tensorflow:Error reported to Coordinator: 'dict_keys' object does not support indexing
Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/coordinator.py"", line 297, in stop_on_exception
    yield
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py"", line 248, in _call_for_each_tower
    self, *merge_args, **merge_kwargs)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/optimizer.py"", line 667, in _distributed_apply
    reduced_grads = distribution.batch_reduce(""sum"", grads_and_vars)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/distribute.py"", line 796, in batch_reduce
    return self._batch_reduce(method_string, value_destination_pairs)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py"", line 295, in _batch_reduce
    value_destination_pairs)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py"", line 175, in batch_reduce
    return self._batch_reduce(method_string, value_destination_pairs)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py"", line 462, in _batch_reduce
    [v[0] for v in value_destination_pairs])
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py"", line 517, in _batch_all_reduce
    method_string)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py"", line 276, in _ungroup_and_make_mirrored
    index[i][destinations[d]] = v
TypeError: 'dict_keys' object does not support indexing
Traceback (most recent call last):
  File ""imagenet_main.py"", line 318, in <module>
    main(argv=sys.argv)
  File ""imagenet_main.py"", line 313, in main
    shape=[_DEFAULT_IMAGE_SIZE, _DEFAULT_IMAGE_SIZE, _NUM_CHANNELS])
  File ""/home/taylorrobie/TensorFlow/models/official/resnet/resnet_run_loop.py"", line 444, in resnet_main
    max_steps=flags.max_train_steps)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py"", line 363, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py"", line 841, in _train_model
    return self._train_model_distributed(input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py"", line 884, in _train_model_distributed
    self.config)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/distribute.py"", line 751, in call_for_each_tower
    return self._call_for_each_tower(fn, *args, **kwargs)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py"", line 254, in _call_for_each_tower
    coord.join(threads)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/coordinator.py"", line 389, in join
    six.reraise(*self._exc_info_to_raise)
  File ""/usr/local/lib/python3.5/dist-packages/six.py"", line 693, in reraise
    raise value
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/coordinator.py"", line 297, in stop_on_exception
    yield
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py"", line 248, in _call_for_each_tower
    self, *merge_args, **merge_kwargs)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/optimizer.py"", line 667, in _distributed_apply
    reduced_grads = distribution.batch_reduce(""sum"", grads_and_vars)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/distribute.py"", line 796, in batch_reduce
    return self._batch_reduce(method_string, value_destination_pairs)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py"", line 295, in _batch_reduce
    value_destination_pairs)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py"", line 175, in batch_reduce
    return self._batch_reduce(method_string, value_destination_pairs)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py"", line 462, in _batch_reduce
    [v[0] for v in value_destination_pairs])
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py"", line 517, in _batch_all_reduce
    method_string)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py"", line 276, in _ungroup_and_make_mirrored
    index[i][destinations[d]] = v
TypeError: 'dict_keys' object does not support indexing
```
"
18187,Adam optimizer with decaying learning rate,"I tried to implement the Adam optimizer with different beta1 and beta2 to observe the decaying learning rate changes using:
```
optimizer_obj = tf.train.optimizer(learning_rate=0.001, beta1=0.3, beta2=0.7)
```

To track the changes in learning rate, I printed the ```_lr_t``` variable of the object in the session:
```
print(sess.run(optimizer_obj._lr_t))
```

But for all iterations, I get the same value (the initialized 0.001 value).

I couldn't find how the parameters are updated in this class.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 7
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.5
- **Python version**: 3.5
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: 
```
optimizer_obj = tf.train.optimizer(learning_rate=0.001, beta1=0.3, beta2=0.7)
with tf.Session() as sess:
    print(sess.run(optimizer_obj._lr_t))
```"
18186,Estimators can't restore from their saved configuration,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A: no verbatim example from TensorFlow on restoring from and `export_savedmodel()`.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Window 10x64; Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: 1.7
- **Python version**: 3.6.4
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

```python
# Create and train some classifier ....
c = tf.estimator.DNNClassifier(hidden_units = [10,10], feature_columns=my_feature_columns)
# ... do some training
# We'll assume here that I'm using Pandas, and just have floats
specDict = {}
for col in list(train_x.columns):
    specDict[col] = tf.FixedLenFeature([], tf.float32)
psirf = tf.estimator.export.build_parsing_serving_input_receiver_fn(specDict, 100)
pathOut = c.export_savedmodel(""./trainedModels/"", psirf)
# I'll write pathOut to a file ...
```

In a new instance:

```python
# We recreate my cols, and pull pathOut from the file it was written to
c = tf.estimator.DNNClassifier(hidden_units = [10,10], feature_columns=my_feature_columns, model_dir = pathOut)
# Using the canned `eval_input_fn` from the iris_data.py example
# dataDict is the source data
predictions = c.predict(input_fn=eval_input_fn(dataDict, None))
for predDict in predictions:
    # raises ""ValueError: Could not find trained model in model_dir: pathOut""
    print(predDict)

```

### Describe the problem

The estimator [only looks for the latest checkpoint](https://github.com/tensorflow/tensorflow/blob/r1.7/tensorflow/python/estimator/estimator.py#L476-L480), and ignores any exports that might have been created from its own `export_savedmodel` function

Because of https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/estimator/estimator.py#L644-L652 , seems like [tf.saved_model.loader.load](https://www.tensorflow.org/api_docs/python/tf/saved_model/loader/load) should also be checked"
18185,Building Graphs documentation,"System information
Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux ubuntu 16.04
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 1.4.1 gpu
Python version: 3.5.4
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: Cuda 8.0/Cudnn 6.0
GPU model and memory: Titan xp
Exact command to reproduce: no method for outer product

Describe the problem
Many links in the documentation say 'see the guide' and point to `Building Graphs > ...` 
https://www.tensorflow.org/api_guides/python/framework#Core_graph_data_structures
but no prose guide is present. It would be useful to have some examples of using such methods as `tf.reset_default_graph` , etc.
 

For example, the `tf.Graph` page links to 'Building Graphs': https://www.tensorflow.org/api_docs/python/tf/Graph"
18184,Variable Scope with Eager Execution,
18182,Tensorflow llite more support ,"Hello,
I am using tflite for my development and I used label_image example for inference. Can you please provide more documentation either on tflite and how to use it or provide support for reading PNG and JPEG files for the inference?

Is there any python example available for tflite inference pipeline?

Additionally, tensorflow lite is slow on RaspberryPi. Slower than normal tensorflow graph. I can run MobileNet in 600ms and for same model converted in tflite takes 1300ms for an inference. Is there any solution for this?

Have I written custom code - N/A
OS Platform and Distribution - Any
TensorFlow installed from - Source
TensorFlow version - 1.6
Bazel version - 0.9
CUDA/cuDNN version - 9/7
GPU model and memory - 1080Ti 12GB
Exact command to reproduce - N/A

Thank you,"
18180,Eager: tf.size() does not respect `out_type`,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux, Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.7.0
- **Python version**:  2.7.12
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**:

```python
import tensorflow as tf

tf.enable_eager_execution()

print(tf.size([1, 2, 3]).dtype)
```

### Describe the problem
As per the documentation of [`tf.size`](https://www.tensorflow.org/api_docs/python/tf/size), the `dtype` of the returned tensor should default to `tf.int32` and it can be optionally overridden by providing an `out_type` argument.

However, in the snippet above, `tf.size()` returns a `tf.int64` tensor, and in a related StackOverflow question: https://stackoverflow.com/questions/49604969/gradient-error-occurred-when-calculate-two-embeddings-on-eager-mode the `tf.size()` used by `_GatherGrad` is resulting in a `float64` tensor.

Long story short, this is a buggy discrepancy between eager execution and graph construction.
(Likely introduced in commit https://github.com/tensorflow/tensorflow/commit/47ea851d3faf029d5b23ee70cb3b96bad0128324)

CC @alextp "
18179,tf.layers.Input missing on 1.7,Recently updated to 1.7 and a script is now crashing because tf.layers.Input is missing. I just check the docs and it appears until 1.6 but it wasn't deprecated. 
18177,"pip install tensorflow in anaconda,can't use it in pycharm","
i use anaconda environment with ""pip install tensorflow-gpu==1.0"" to install tensorflow.i can use it in console,while i wanted to create a project,i chose the interpreter ""home/anaconda2/envs/tensorflow/bin/python"",and it occur a error""encodings.CodecRegistryError: incompatible codecs in module ""encodings.utf_8"" (/home/red/anaconda2/envs/tensorflow/lib/python2.7/encodings/utf_8.pyc)""
------------------------

### System information
yes,a very easy hello code- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Linux 16.04- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
source- **TensorFlow installed from (source or binary)**:
1.0- **TensorFlow version (use command below)**:
2.7.14- **Python version**: 
- **Bazel version (if compiling from source)**:
gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.9) - **GCC/Compiler version (if compiling from source)**:
8.0/5.1- **CUDA/cuDNN version**:
gtx1060/3gb- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
encodings.utf_8"" (/home/red/anaconda2/envs/tensorflow/lib/python2.7/encodings/utf_8.pyc)

### Source code / logs
hello = tf.constant(""hello,world"")
print(sess.run(hello))
"
18176,_pywrap_tensorflow_internal.so gdb load very slow!,"I build a _pywrap_tensorflow_internal.so have 2.7G big.  so that gdb load very slow ，mybe takes one hour. please help me !

I try many way , such as strip symbols from .so and so on.

I want to ask is there way to use -g in the single tensorflow module by bazel  build ?"
18175,import data_provider from google3.third_party.tensorflow_models.gan.pix2pix import networks  .............. error importing these modules... ,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
18174,'unsupported/Eigen/CXX11/Tensor' file not found on iOS/Xcode,"when I ran this project( https://github.com/yjmade/ios_camera_object_detection )on ios. I met this warning.

Stack Overflow didn't give any help, case #4680 is for Raspberry Pi. It didn't help me.


Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
#18174
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
macOS10.13.4 Xcode9.2 iOS11.2
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
v1.7
- **Python version**: 
python3.6
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh
“

== cat /etc/issue ===============================================
Darwin Davids-New-MacBook-Pro.local 17.5.0 Darwin Kernel Version 17.5.0: Mon Mar  5 22:24:32 PST 2018; root:xnu-4570.51.1~1/RELEASE_X86_64 x86_64
Mac OS X 10.13.4

== are we in docker =============================================
No

== compiler =====================================================
Apple LLVM version 9.1.0 (clang-902.0.39.1)
Target: x86_64-apple-darwin17.5.0
Thread model: posix
InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin

== uname -a =====================================================
Darwin Davids-New-MacBook-Pro.local 17.5.0 Darwin Kernel Version 17.5.0: Mon Mar  5 22:24:32 PST 2018; root:xnu-4570.51.1~1/RELEASE_X86_64 x86_64

== check pips ===================================================
numpy (1.13.1)
numpydoc (0.7.0)
protobuf (3.5.0)
tensorflow (1.4.0)
tensorflow-tensorboard (0.4.0rc3)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.4.0
tf.GIT_VERSION = v1.4.0-rc1-11-g130a514
tf.COMPILER_VERSION = v1.4.0-rc1-11-g130a514
Sanity check: array([1], dtype=int32)
/Users/David/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6
  return f(*args, **kwds)

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
/Users/David/tensorflow-1.7.0/tools/tf_env_collect.sh: line 105: nvidia-smi: command not found

== cuda libs  ===================================================

== cat /etc/issue ===============================================
Darwin Davids-New-MacBook-Pro.local 17.5.0 Darwin Kernel Version 17.5.0: Mon Mar  5 22:24:32 PST 2018; root:xnu-4570.51.1~1/RELEASE_X86_64 x86_64
Mac OS X 10.13.4

== are we in docker =============================================
No

== compiler =====================================================
Apple LLVM version 9.1.0 (clang-902.0.39.1)
Target: x86_64-apple-darwin17.5.0
Thread model: posix
InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin

== uname -a =====================================================
Darwin Davids-New-MacBook-Pro.local 17.5.0 Darwin Kernel Version 17.5.0: Mon Mar  5 22:24:32 PST 2018; root:xnu-4570.51.1~1/RELEASE_X86_64 x86_64

== check pips ===================================================
numpy (1.13.1)
numpydoc (0.7.0)
protobuf (3.5.0)
tensorflow (1.4.0)
tensorflow-tensorboard (0.4.0rc3)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.4.0
tf.GIT_VERSION = v1.4.0-rc1-11-g130a514
tf.COMPILER_VERSION = v1.4.0-rc1-11-g130a514
Sanity check: array([1], dtype=int32)
/Users/David/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6
  return f(*args, **kwds)

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
/Users/David/tensorflow-1.7.0/tools/tf_env_collect.sh: line 105: nvidia-smi: command not found

== cuda libs  ===================================================

”
You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem."
18173,how to debug lite jni so in android ,"
after building the so of lite, some how i need to debug in the android mobile; how can i debug the native c++ code using android studio?  appriciated"
18172,Do tensorflow have plan to support deep complex netowrk?,"Do tensorflow have plan to support deep complex netowrk?
such as ""Deep Complex Networks"" in https://arxiv.org/abs/1705.09792"
18170,How about supporting delegation of OEM operations in TFL ?,"Currently, the interpreter delegates only built-in ops to NN API. I'm writing here to see if any plan to support to delegate OEM operations(ANEURALNETWORKS_OEM_OPERATION) defined in
https://android.googlesource.com/platform/frameworks/ml/+/master/nn/runtime/include/NeuralNetworksOEM.h

My understanding is it's just a minor change on TOCO and interpreter, right ?"
18169,Why tensorflow.org is not reachable from Iran? ,"When I try to access [tensorflow.org](tensorflow.org) from my computer in Iran I get the error ""403: Your client does not have permission to get URL / from this server. That’s all we know.""

I didn't know any other (reachable) location to post it. Would appreciate it if someone would respond/act on this. "
18167,tensorboard take an TypeError after change tensorflow-cpu to tensorflow-gpu installed by pip ,"error messages are as follows：
Traceback (most recent call last):
File ""e:\anaconda\lib\runpy.py"", line 184, in _run_module_as_main
""main"", mod_spec)
File ""e:\anaconda\lib\runpy.py"", line 85, in run_code
exec(code, run_globals)
File ""E:\Anaconda\Scripts\tensorboard.exe_main.py"", line 5, in 
File ""e:\anaconda\lib\site-packages\tensorboard\main.py"", line 30, in 
from tensorboard import default
File ""e:\anaconda\lib\site-packages\tensorboard\default.py"", line 35, in 
from tensorboard.plugins.audio import audio_plugin
File ""e:\anaconda\lib\site-packages\tensorboard\plugins\audio\audio_plugin.py"", line 30, in 
from tensorboard.plugins.audio import metadata
File ""e:\anaconda\lib\site-packages\tensorboard\plugins\audio\metadata.py"", line 22, in 
from tensorboard.plugins.audio import plugin_data_pb2
File ""e:\anaconda\lib\site-packages\tensorboard\plugins\audio\plugin_data_pb2.py"", line 63, in 
options=None, file=DESCRIPTOR),
TypeError: init() got an unexpected keyword argument 'file'

before i changed the version，tensorboard worked，i don't know whether the tensorboard arguments are different between cpu version and gpu version
I will appreciate for your help

OS Platform and Distribution ： windows 10
TensorFlow installed from： pip
TensorFlow version： tensorflow-gpu 1.7
CUDA/cuDNN version： cuda 9.0 cudnn9.0"
18166,Tensorboard has takew,
18165,eager execution not working with placeholders,"------------
### System information
- **Have I written custom code: Yes**:
- **OS Platform and Distribution (Linux Ubuntu 16.04)**:
- **TensorFlow installed from (binary)**:
- **TensorFlow version (1.7)**:
- **Python version (3.6)**: 
- **CUDA/cuDNN version (9.0/7.0.)**:
- **GPU model and memory (1080 Ti)**:

### Describe the problem
I get the following error when I use eager execution on a simple graph with a couple of convolutional layers.
```
tf.placeholder() is not compatible with eager execution
```

Does that mean that eager execution is not working with placeholders. That would be useful to have since if have older code constructed using graphs and sessions we won't be able to utilize eager execution for debugging purposes.
"
18163,cannot import name bayesflow Error,"Hi, 
I get the error I mentioned in the title. I did a search on Google and I usually found a solution to update dask. I updated Dask to version 0.17.2 but I still get the same error. I can not import BayesFlow. The Tensorflow version is 0.12.1. Thanks for the answers ...

Code :  
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets(""/tmp/data/"")

OS : Ubuntu 16.04 LTS
Tensorflow version is 0.12.1
Cuda : 8.0
CuDNN : 5.1
GPU : 4  GB GTX 1050Ti
Dask : 0.17.2
"
18158,"Centos: C++, No OpKernel was registered to support Op 'RandomUniform' with these attrs.","OS Platform : Cestos7
python:2.7
gcc:4.8
TensorFlow installed from source
tf version : ('v1.4.0-19-ga52c8d9', '1.4.1')
Bazel version:N/A
CUDA Version 8.0.61
CUDNN_MAJOR : 6
GPU model and memory: 22912MiB*4


Invalid argument: No OpKernel was registered to support Op 'RandomUniform' with these attrs.  Registered devices: [CPU], Registered kernels:
  <no registered kernels>
[[Node: loss/transitions/Initializer/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, _class=[""loc:@loss/transitions""], _output_shapes=[[71,71]], dtype=DT_FLOAT, seed=0, seed2=0](loss/transitions/Initializer/random_uniform/shape)]]

the C++ code is :

```
int main(int argc, char* argv[]) {

	std::cout << ""test start----.\n"";
	Session* session;
	Status status = NewSession(SessionOptions(), &session);
	if (!status.ok()) {
		std::cout << status.ToString() << ""\n"";
		return 1;
	}
	std::cout << ""Session successfully created..\n"";


	//GraphDef graph_def;
	//status = ReadBinaryProto(Env::Default(), ""../demo/deep_model/freeze_graph.pb"", &graph_def);
	//
	MetaGraphDef graph_def;
	status = ReadBinaryProto(Env::Default(), ""../src/checkpoints/model-1.meta"", &graph_def);
	if (!status.ok()) {
		std::cout << ""readerror="" << status.ToString() << std::endl;
		return 0;
	} 
	else {
		std::cout << ""Load graph protobuf successfully"" << std::endl;
	}


	//status = session->Create(graph_def);
	status = session->Create(graph_def.graph_def());
	if (!status.ok()) {
  		std::cout << std::endl << std::endl << ""error:""<< status.ToString() << std::endl;
	} 
	else {
  		std::cout << ""Add graph to session successfully"" << std::endl;
	}

	tensorflow::Tensor checkpointTensor(DT_STRING, tensorflow::TensorShape());
	checkpointTensor.scalar<string>()() = ""../src/checkpoints/model-1"";
   
	status = session->Run(
		{{ graph_def.saver_def().filename_tensor_name(), checkpointTensor }},
        	{},
        	{graph_def.saver_def().restore_op_name()},
       		nullptr);
	if (!status.ok()) {
		std::cout << ""run1:"" << status.ToString() << std::endl;
		return 0;
	}
	std::cout << ""ok"" << std::endl;

	session->Close();
	
}
```"
18157,Failed to convert object of type <class 'werkzeug.datastructures.File.Storage> to tensor.,"This is my client python file that uses flask framework to create REST api.  I am running this inside a docker machine. So this take an input .txt file and read the contents of it.

```
from flask import Flask, render_template, request, url_for, jsonify
import json
import tensorflow as tf 
import numpy as np 
import os 
import argparse
import sys
from google.protobuf import json_format
from datetime import datetime 
from werkzeug import secure_filename

from grpc.beta import implementations
from tensorflow_serving.apis import predict_pb2
from tensorflow_serving.apis import prediction_service_pb2

tf.app.flags.DEFINE_string('server', 'localhost:9000', 'PredictionService host:port')
FLAGS = tf.app.flags.FLAGS

app = Flask(__name__)

class mainSessRunning():
    
    def __init__(self):
        host, port = FLAGS.server.split(':')
        channel = implementations.insecure_channel(host, int(port))
        self.stub = prediction_service_pb2.beta_create_PredictionService_stub(channel)

        self.request = predict_pb2.PredictRequest()
        self.request.model_spec.name = 'example_model'
        self.request.model_spec.signature_name = 'prediction'

    def inference(self, val_x):
        #temp_data = numpy.random.randn(100, 3).astype(numpy.float32)
        #temp_data = val_x.astype(np.float32).reshape(-1, 3)
        data = val_x
        self.request.inputs['input'].CopyFrom(tf.contrib.util.make_tensor_proto(data))
        result = self.stub.Predict(self.request, 5.0)
        return result

run = mainSessRunning()

print(""Initialization done. "")

# Define a route for the default URL, which loads the form
@app.route('/inference', methods=['POST'])
def inference():
    request_data = request.files['file']
    result = run.inference(request_data)
    r = json_format.MessageToJson(result)
    return jsonify({'result':r})

@app.route('/test', methods=['GET'])
def test_serv():
    return (""Hello"")
        
if __name__ == ""__main__"":
    app.run(host= '0.0.0.0')
    
    


```


When i try too run it produces error, 
![capture](https://user-images.githubusercontent.com/26268279/38171661-117fa570-35bc-11e8-9f12-dd6242552794.JPG)

Is this a bug?

"
18156,Broken links of assignment 1:https://commondatastorage.googleapis.com/books1000/,"The download link for ""notMNIST_large.tar.gz"" and ""notMNIST_small.tar.gz"" is broken. Can u provide other download link and edit [the file of assignment 1](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/udacity/1_notmnist.ipynb).







-----------------

Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
18152,Missing @grpc//third_party/address_sorting,"I think a [regression was introduced recently](https://github.com/tensorflow/tensorflow/commit/f80486324807181614ac71367dbb9cf588aa2804#diff-bb845bf0c867fef59b6527c0946799f9R116) when doing a new cpu build:

`failed; build aborted: no such package '@grpc//third_party/address_sorting': java.io.IOException: Error downloading [https://mirror.bazel.build/github.com/grpc/grpc/archive/bd6bdf93279a39a8cd92978fd7c9d14eccd98fc2.tar.gz, https://github.com/grpc/grpc/archive/bd6bdf93279a39a8cd92978fd7c9d14eccd98fc2.tar.gz] `

Reverting this commit allowed the build to continue.

Update:  building origin/master"
18151,tf.contrib.layers.l2_regularizer() cause warning,"TF version: 1.7
```
import tensorflow as tf
r = tf.contrib.layers.l2_regularizer(0.001)
```
Then a warning message will occur:

> WARNING:tensorflow:From /.../tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
> Instructions for updating:
> Use the retry module or similar alternatives."
18149,C++ Const and Assign to initialize variable causes a segfault depending on the Const constructor used,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes see a very short example below.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
macOS 10.13.3 clang 900.0.39.2 and CentOS Linux 7 gcc-4.8.5
- **TensorFlow installed from (source or binary)**:
Source from the 1.7.0 release tag
- **TensorFlow version (use command below)**:
I have not actually installed the python pip package, but the source tree came from:
https://github.com/tensorflow/tensorflow/archive/v1.7.0.tar.gz

- **Python version**: 
N/A using the C++ API
- **Bazel version (if compiling from source)**:
macOS Build label: 0.11.1-homebrew and Centos Linux 7 Build label: 0.11.1- (@non-git)
- **GCC/Compiler version (if compiling from source)**:
macOS clang 900.0.39.2 and CentOS Linux 7 gcc-4.8.5
- **CUDA/cuDNN version**:
N/A
- **GPU model and memory**:
N/A
- **Exact command to reproduce**:
extract the sources/configure
`tar -xzvf v1.7.0.tar.gz`
`cd tensorflow-1.7.0`
`./configure`

Then add the following directory to hold the work:
`mkdir tensorflow/basic-example`

Put into basic-example the following BUILD file:
```
load(""//tensorflow:tensorflow.bzl"", ""tf_cc_binary"")

tf_cc_binary(
    name = ""basic-example"",
    srcs = [
        ""basic-example.cc"",
    ],
    deps = [
        ""//tensorflow/cc:cc_ops"",
        ""//tensorflow/cc:client_session"",
        ""//tensorflow/core:tensorflow""
    ]
)
```
Put into basic-example the following C++ source file:
```c++
#include ""tensorflow/cc/client/client_session.h""
#include ""tensorflow/cc/ops/standard_ops.h""
#include ""tensorflow/core/framework/tensor.h""

using namespace tensorflow;
using namespace tensorflow::ops;
using namespace std;

int main() {

  Scope scope = Scope::NewRootScope();
 
  auto c = Const(scope.WithOpName(""const_c""), {1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}, {3,3});

  auto v = Variable(scope.WithOpName(""var1""), {3, 3}, DT_FLOAT);
  auto init_v = Assign(scope.WithOpName(""init_v""), v, c);

  std::vector<Tensor> outputs;
  ClientSession session(scope);

  TF_CHECK_OK(session.Run({init_v}, &outputs));
}
```
Now compile and run the resulting program:
`bazel build -c dbg //tensorflow/basic-example`
`./bazel-bin/tensorflow/basic-example/basic-example`

Observe the following behavior:
```
./bazel-bin/tensorflow/basic-example/basic-example
2018-03-31 11:47:57.135532: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.2 AVX
Segmentation fault: 11
```
### Describe the problem
The code given above causes a segfault when the session runner tries to get the name of a node because the node is nullptr. I have included a stacktrace using lldb below (a trace showing the same information can be created using gdb on Linux).

However the following slightly modified C++ program works fine:
```c++
#include ""tensorflow/cc/client/client_session.h""
#include ""tensorflow/cc/ops/standard_ops.h""
#include ""tensorflow/core/framework/tensor.h""

using namespace tensorflow;
using namespace tensorflow::ops;
using namespace std;

int main() {

  std::vector<float> initConstData = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0};

  Scope scope = Scope::NewRootScope();

  Tensor initConstT(DT_FLOAT, TensorShape({3,3}));
  std::copy_n(initConstData.begin(), initConstData.size(), initConstT.flat<float>().data());

  auto c = Const(scope.WithOpName(""const_c""), initConstT);

  auto v = Variable(scope.WithOpName(""var1""), {3, 3}, DT_FLOAT);
  auto init_v = Assign(scope.WithOpName(""init_v""), v, c);

  std::vector<Tensor> outputs;
  ClientSession session(scope);

  TF_CHECK_OK(session.Run({init_v}, &outputs));
}
```
The difference between the code that works and the code that doesn't:
a) the explicit creation of a tensor initConstT
b) calling Const with a Tensor rather than an Input::Initializer

The behavior is identical if I omit the use of scope.WithOpName and just pass scope.
I have been able to test this back as far as Tensorflow 1.4 I can not build Tensorflow 1.3.1 with my installed version of bazel.

If I have done something wrong, please point it out. Otherwise I feel that because there is no semantic difference between the two programs and the API allows the former program to compile then they should both work.

### Source code / logs
Stacktrace of the problem:
```
(lldb) bt
* thread #1, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x60)
  * frame #0: 0x0000000126e677bc libtensorflow_framework.so`tensorflow::Node::name() const [inlined] std::__1::shared_ptr<tensorflow::NodeProperties>::operator->(this=0x0000000000000060) const at memory:4071
    frame #1: 0x0000000126e677bc libtensorflow_framework.so`tensorflow::Node::name(this=0x0000000000000000) const at graph.cc:140
    frame #2: 0x000000010018592f basic-example`tensorflow::Output::name(this=0x000000012bc020f0) const at ops.h:76
    frame #3: 0x0000000100184e7a basic-example`tensorflow::ClientSession::Run(this=0x00007ffeefbff4a8, run_options=0x00007ffeefbfefd0, inputs=size=0, fetch_outputs=size=1, run_outputs=size=1, outputs=0x00007ffeefbff4b0 size=1, run_metadata=0x0000000000000000) const at client_session.cc:118
    frame #4: 0x0000000100184145 basic-example`tensorflow::ClientSession::Run(this=0x00007ffeefbff4a8, inputs=size=0, fetch_outputs=size=1, run_outputs=size=1, outputs=0x00007ffeefbff4b0 size=1) const at client_session.cc:89
    frame #5: 0x000000010018408a basic-example`tensorflow::ClientSession::Run(this=0x00007ffeefbff4a8, fetch_outputs=size=1, outputs=0x00007ffeefbff4b0 size=1) const at client_session.cc:76
    frame #6: 0x0000000100002bfc basic-example`main at basic-example.cc:22
    frame #7: 0x00007fff76249115 libdyld.dylib`start + 1
    frame #8: 0x00007fff76249115 libdyld.dylib`start + 1
(lldb)
```
"
18147,Exit code 132 on TensorFlow import,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Arch Linux 4.15.8
- **TensorFlow installed from (source or binary)**: Binary  wheel (`pip install tensorflow`)
- **TensorFlow version (use command below)**: 1.7.0
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: Intel graphics, 4GB RAM
- **Exact command to reproduce**: `import tensorflow`

### Describe the problem
I've installed tensorflow v1.7.0 via PIP and I am having issues working with it. Upon entering a REPL and attempting to `import tensorflow` the REPL silently exits with an exit code of 132. I've run PDB and tried importing it and it appears it is exiting around the `from tensorflow.python import *` section of the tensorflow code. Looking at the PDB output it appears that code is exiting with error code 132 after running `importlib._bootstrap._find_and_load` which is a python internal.

### Source code / logs
PDB output from trying to import tensorflow (around the section that it exits):
```
> <frozen importlib._bootstrap>(191)_get_module_lock()->_ModuleLock('...40427194539368
(Pdb) n
> <frozen importlib._bootstrap>(149)__enter__()
(Pdb) n
--Return--
> <frozen importlib._bootstrap>(149)__enter__()->None
(Pdb) n
> <frozen importlib._bootstrap>(969)_find_and_load()
(Pdb) n
> <frozen importlib._bootstrap>(970)_find_and_load()
(Pdb) n
> <frozen importlib._bootstrap>(971)_find_and_load()
(Pdb) n

```
What I'm trying to run:
```py
$ python3.6
Python 3.6.4 (default, Jan  5 2018, 02:35:40) 
[GCC 7.2.1 20171224] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
$ echo $?
132
```
"
18146,"Continous Messages of  ""I tensorflow/core/common_runtime/placer.cc:874]"" in every training iteration","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu16.04
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: 1.4
- **Python version**: 2.7
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:8.0
- **GPU model and memory**: NVIDIA 1080 (8GB)
- **Exact command to reproduce**:

### Describe the problem
So I have written a DQN code for my research which has two networks(Target Network and Eval Networks). Eval Network is for training and target network is or generating samples. But during training in every iteration I get a long message like below.My code is running well and fine in CPU but I get these messages while training them in GPU and what does '(Const)' means.

### Source code / logs
018-03-31 21:43:19.799483: I tensorflow/core/common_runtime/placer.cc:874] Target_Network/RNN_Layer/rnn/while/rnn/basic_lstm_cell/BiasAdd: (BiasAdd)/job:localhost/replica:0/task:0/device:GPU:1
Target_Network/RNN_Layer/rnn/while/rnn/basic_lstm_cell/split: (Split): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.799498: I tensorflow/core/common_runtime/placer.cc:874] Target_Network/RNN_Layer/rnn/while/rnn/basic_lstm_cell/split: (Split)/job:localhost/replica:0/task:0/device:GPU:1
Target_Network/RNN_Layer/rnn/while/rnn/basic_lstm_cell/Sigmoid_2: (Sigmoid): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.799513: I tensorflow/core/common_runtime/placer.cc:874] Target_Network/RNN_Layer/rnn/while/rnn/basic_lstm_cell/Sigmoid_2: (Sigmoid)/job:localhost/replica:0/task:0/device:GPU:1
Target_Network/RNN_Layer/rnn/while/rnn/basic_lstm_cell/Tanh: (Tanh): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.799529: I tensorflow/core/common_runtime/placer.cc:874] Target_Network/RNN_Layer/rnn/while/rnn/basic_lstm_cell/Tanh: (Tanh)/job:localhost/replica:0/task:0/device:GPU:1
Target_Network/RNN_Layer/rnn/while/rnn/basic_lstm_cell/Sigmoid_1: (Sigmoid): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.799544: I tensorflow/core/common_runtime/placer.cc:874] Target_Network/RNN_Layer/rnn/while/rnn/basic_lstm_cell/Sigmoid_1: (Sigmoid)/job:localhost/replica:0/task:0/device:GPU:1
Target_Network/RNN_Layer/rnn/while/rnn/basic_lstm_cell/mul_1: (Mul): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.799559: I tensorflow/core/common_runtime/placer.cc:874] Target_Network/RNN_Layer/rnn/while/rnn/basic_lstm_cell/mul_1: (Mul)/job:localhost/replica:0/task:0/device:GPU:1
Target_Network/RNN_Layer/rnn/while/rnn/basic_lstm_cell/add: (Add): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.799574: I tensorflow/core/common_runtime/placer.cc:874] Target_Network/RNN_Layer/rnn/while/rnn/basic_lstm_cell/add: (Add)/job:localhost/replica:0/task:0/device:GPU:1
Target_Network/RNN_Layer/rnn/while/rnn/basic_lstm_cell/Sigmoid: (Sigmoid): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.799588: I tensorflow/core/common_runtime/placer.cc:874] Target_Network/RNN_Layer/rnn/while/rnn/basic_lstm_cell/Sigmoid: (Sigmoid)/job:localhost/replica:0/task:0/device:GPU:1
Target_Network/RNN_Layer/rnn/while/rnn/basic_lstm_cell/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.799602: I tensorflow/core/common_runtime/placer.cc:874] Target_Network/RNN_Layer/rnn/while/rnn/basic_lstm_cell/mul: (Mul)/job:localhost/replica:0/task:0/device:GPU:1
Target_Network/RNN_Layer/rnn/while/rnn/basic_lstm_cell/add_1: (Add): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.799617: I tensorflow/core/common_runtime/placer.cc:874] Target_Network/RNN_Layer/rnn/while/rnn/basic_lstm_cell/add_1: (Add)/job:localhost/replica:0/task:0/device:GPU:1
Target_Network/RNN_Layer/rnn/while/NextIteration_2: (NextIteration): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.799633: I tensorflow/core/common_runtime/placer.cc:874] Target_Network/RNN_Layer/rnn/while/NextIteration_2: (NextIteration)/job:localhost/replica:0/task:0/device:GPU:1
Target_Network/RNN_Layer/rnn/while/rnn/basic_lstm_cell/Tanh_1: (Tanh): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.799648: I tensorflow/core/common_runtime/placer.cc:874] Target_Network/RNN_Layer/rnn/while/rnn/basic_lstm_cell/Tanh_1: (Tanh)/job:localhost/replica:0/task:0/device:GPU:1
Target_Network/RNN_Layer/rnn/while/rnn/basic_lstm_cell/mul_2: (Mul): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.799662: I tensorflow/core/common_runtime/placer.cc:874] Target_Network/RNN_Layer/rnn/while/rnn/basic_lstm_cell/mul_2: (Mul)/job:localhost/replica:0/task:0/device:GPU:1
Target_Network/RNN_Layer/rnn/while/NextIteration_3: (NextIteration): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.799677: I tensorflow/core/common_runtime/placer.cc:874] Target_Network/RNN_Layer/rnn/while/NextIteration_3: (NextIteration)/job:localhost/replica:0/task:0/device:GPU:1
Target_Network/RNN_Layer/rnn/while/TensorArrayWrite/TensorArrayWriteV3: (TensorArrayWriteV3): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.799690: I tensorflow/core/common_runtime/placer.cc:874] Target_Network/RNN_Layer/rnn/while/TensorArrayWrite/TensorArrayWriteV3: (TensorArrayWriteV3)/job:localhost/replica:0/task:0/device:GPU:1
Target_Network/RNN_Layer/rnn/while/NextIteration_1: (NextIteration): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.799705: I tensorflow/core/common_runtime/placer.cc:874] Target_Network/RNN_Layer/rnn/while/NextIteration_1: (NextIteration)/job:localhost/replica:0/task:0/device:GPU:1
Adam/epsilon: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.799725: I tensorflow/core/common_runtime/placer.cc:874] Adam/epsilon: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Adam/beta2: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.799743: I tensorflow/core/common_runtime/placer.cc:874] Adam/beta2: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Adam/beta1: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.799760: I tensorflow/core/common_runtime/placer.cc:874] Adam/beta1: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Adam/learning_rate: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.799777: I tensorflow/core/common_runtime/placer.cc:874] Adam/learning_rate: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/Final_Dense_Connected_Layer/Action_Output_Layer/bias/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.799791: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/Final_Dense_Connected_Layer/Action_Output_Layer/bias/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/Final_Dense_Connected_Layer/Action_Output_Layer/bias/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.799806: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/Final_Dense_Connected_Layer/Action_Output_Layer/bias/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/Final_Dense_Connected_Layer/Action_Output_Layer/kernel/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.799821: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/Final_Dense_Connected_Layer/Action_Output_Layer/kernel/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/Final_Dense_Connected_Layer/Action_Output_Layer/kernel/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.799836: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/Final_Dense_Connected_Layer/Action_Output_Layer/kernel/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/RNN_Layer/rnn/basic_lstm_cell/bias/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.799851: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/RNN_Layer/rnn/basic_lstm_cell/bias/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/RNN_Layer/rnn/basic_lstm_cell/bias/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.799866: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/RNN_Layer/rnn/basic_lstm_cell/bias/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/RNN_Layer/rnn/basic_lstm_cell/kernel/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.799881: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/RNN_Layer/rnn/basic_lstm_cell/kernel/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/RNN_Layer/rnn/basic_lstm_cell/kernel/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.799895: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/RNN_Layer/rnn/basic_lstm_cell/kernel/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/First_Fully_Connected/Dense_Layer_1_input_2/bias/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.799910: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/First_Fully_Connected/Dense_Layer_1_input_2/bias/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/First_Fully_Connected/Dense_Layer_1_input_2/bias/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.799925: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/First_Fully_Connected/Dense_Layer_1_input_2/bias/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/First_Fully_Connected/Dense_Layer_1_input_2/kernel/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.799940: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/First_Fully_Connected/Dense_Layer_1_input_2/kernel/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/First_Fully_Connected/Dense_Layer_1_input_2/kernel/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.799954: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/First_Fully_Connected/Dense_Layer_1_input_2/kernel/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/First_Fully_Connected/Dense_Layer_1_input_1/bias/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.799969: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/First_Fully_Connected/Dense_Layer_1_input_1/bias/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/First_Fully_Connected/Dense_Layer_1_input_1/bias/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.799984: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/First_Fully_Connected/Dense_Layer_1_input_1/bias/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/First_Fully_Connected/Dense_Layer_1_input_1/kernel/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.799999: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/First_Fully_Connected/Dense_Layer_1_input_1/kernel/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/First_Fully_Connected/Dense_Layer_1_input_1/kernel/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800014: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/First_Fully_Connected/Dense_Layer_1_input_1/kernel/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/conv5/Convolution_Layer_5_input_2_Biases/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800029: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/conv5/Convolution_Layer_5_input_2_Biases/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/conv5/Convolution_Layer_5_input_2_Biases/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800044: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/conv5/Convolution_Layer_5_input_2_Biases/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/conv5/Convolution_Layer_5_input_2/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800059: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/conv5/Convolution_Layer_5_input_2/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/conv5/Convolution_Layer_5_input_2/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800073: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/conv5/Convolution_Layer_5_input_2/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/conv5/Convolution_Layer_5_input_1_Biases/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800088: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/conv5/Convolution_Layer_5_input_1_Biases/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/conv5/Convolution_Layer_5_input_1_Biases/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800102: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/conv5/Convolution_Layer_5_input_1_Biases/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/conv5/Convolution_Layer_5_input_1/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800117: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/conv5/Convolution_Layer_5_input_1/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/conv5/Convolution_Layer_5_input_1/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800132: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/conv5/Convolution_Layer_5_input_1/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/conv4/Convolution_Layer_4_input_1_Biases/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800147: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/conv4/Convolution_Layer_4_input_1_Biases/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/conv4/Convolution_Layer_4_input_1_Biases/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800161: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/conv4/Convolution_Layer_4_input_1_Biases/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/conv4/Convolution_Layer_4_input_1/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800175: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/conv4/Convolution_Layer_4_input_1/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/conv4/Convolution_Layer_4_input_1/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800190: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/conv4/Convolution_Layer_4_input_1/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/conv3/Convolution_Layer_3_input_2_Biases/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800205: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/conv3/Convolution_Layer_3_input_2_Biases/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/conv3/Convolution_Layer_3_input_2_Biases/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800220: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/conv3/Convolution_Layer_3_input_2_Biases/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/conv3/Convolution_Layer_3_input_2/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800234: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/conv3/Convolution_Layer_3_input_2/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/conv3/Convolution_Layer_3_input_2/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800249: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/conv3/Convolution_Layer_3_input_2/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/conv3/Convolution_Layer_3_input_1_Biases/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800263: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/conv3/Convolution_Layer_3_input_1_Biases/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/conv3/Convolution_Layer_3_input_1_Biases/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800278: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/conv3/Convolution_Layer_3_input_1_Biases/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/conv3/Convolution_Layer_3_input_1/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800293: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/conv3/Convolution_Layer_3_input_1/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/conv3/Convolution_Layer_3_input_1/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800307: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/conv3/Convolution_Layer_3_input_1/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/conv2/Convolution_Layer_2_input_2_Biases/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800321: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/conv2/Convolution_Layer_2_input_2_Biases/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/conv2/Convolution_Layer_2_input_2_Biases/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800337: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/conv2/Convolution_Layer_2_input_2_Biases/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/conv2/Convolution_Layer_2_input_2/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800351: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/conv2/Convolution_Layer_2_input_2/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/conv2/Convolution_Layer_2_input_2/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800365: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/conv2/Convolution_Layer_2_input_2/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/conv2/Convolution_Layer_2_input_1_Biases/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800380: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/conv2/Convolution_Layer_2_input_1_Biases/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/conv2/Convolution_Layer_2_input_1_Biases/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800395: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/conv2/Convolution_Layer_2_input_1_Biases/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/conv2/Convolution_Layer_2_input_1/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800411: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/conv2/Convolution_Layer_2_input_1/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/conv2/Convolution_Layer_2_input_1/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800425: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/conv2/Convolution_Layer_2_input_1/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/conv1/Convolution_Layer_1_input_2_Biases/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800439: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/conv1/Convolution_Layer_1_input_2_Biases/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/conv1/Convolution_Layer_1_input_2_Biases/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800454: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/conv1/Convolution_Layer_1_input_2_Biases/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/conv1/Convolution_Layer_1_input_2/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800468: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/conv1/Convolution_Layer_1_input_2/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/conv1/Convolution_Layer_1_input_2/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800483: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/conv1/Convolution_Layer_1_input_2/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/conv1/Convolution_Layer_1_input_1_Biases/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800497: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/conv1/Convolution_Layer_1_input_1_Biases/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/conv1/Convolution_Layer_1_input_1_Biases/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800512: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/conv1/Convolution_Layer_1_input_1_Biases/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/conv1/Convolution_Layer_1_input_1/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800526: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/conv1/Convolution_Layer_1_input_1/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
Eval_Network/conv1/Convolution_Layer_1_input_1/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800540: I tensorflow/core/common_runtime/placer.cc:874] Eval_Network/conv1/Convolution_Layer_1_input_1/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:GPU:1
beta2_power/initial_value: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800554: I tensorflow/core/common_runtime/placer.cc:874] beta2_power/initial_value: (Const)/job:localhost/replica:0/task:0/device:GPU:1
beta1_power/initial_value: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800570: I tensorflow/core/common_runtime/placer.cc:874] beta1_power/initial_value: (Const)/job:localhost/replica:0/task:0/device:GPU:1
gradients/Eval_Network/conv2_1/concat_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800584: I tensorflow/core/common_runtime/placer.cc:874] gradients/Eval_Network/conv2_1/concat_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/device:GPU:1
gradients/Eval_Network/conv2_1/concat_grad/Shape: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800599: I tensorflow/core/common_runtime/placer.cc:874] gradients/Eval_Network/conv2_1/concat_grad/Shape: (Const)/job:localhost/replica:0/task:0/device:GPU:1
gradients/Eval_Network/conv2_1/concat_grad/Rank: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800614: I tensorflow/core/common_runtime/placer.cc:874] gradients/Eval_Network/conv2_1/concat_grad/Rank: (Const)/job:localhost/replica:0/task:0/device:GPU:1
gradients/Eval_Network/conv2/concat_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800628: I tensorflow/core/common_runtime/placer.cc:874] gradients/Eval_Network/conv2/concat_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/device:GPU:1
gradients/Eval_Network/conv2/concat_grad/Shape: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800643: I tensorflow/core/common_runtime/placer.cc:874] gradients/Eval_Network/conv2/concat_grad/Shape: (Const)/job:localhost/replica:0/task:0/device:GPU:1
gradients/Eval_Network/conv2/concat_grad/Rank: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800658: I tensorflow/core/common_runtime/placer.cc:874] gradients/Eval_Network/conv2/concat_grad/Rank: (Const)/job:localhost/replica:0/task:0/device:GPU:1
gradients/Eval_Network/conv4_1/concat_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800672: I tensorflow/core/common_runtime/placer.cc:874] gradients/Eval_Network/conv4_1/concat_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/device:GPU:1
gradients/Eval_Network/conv4_1/concat_grad/Shape: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800686: I tensorflow/core/common_runtime/placer.cc:874] gradients/Eval_Network/conv4_1/concat_grad/Shape: (Const)/job:localhost/replica:0/task:0/device:GPU:1
gradients/Eval_Network/conv4_1/concat_grad/Rank: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800735: I tensorflow/core/common_runtime/placer.cc:874] gradients/Eval_Network/conv4_1/concat_grad/Rank: (Const)/job:localhost/replica:0/task:0/device:GPU:1
gradients/Eval_Network/conv4/concat_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800753: I tensorflow/core/common_runtime/placer.cc:874] gradients/Eval_Network/conv4/concat_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/device:GPU:1
gradients/Eval_Network/conv4/concat_grad/Shape: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800803: I tensorflow/core/common_runtime/placer.cc:874] gradients/Eval_Network/conv4/concat_grad/Shape: (Const)/job:localhost/replica:0/task:0/device:GPU:1
gradients/Eval_Network/conv4/concat_grad/Rank: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800818: I tensorflow/core/common_runtime/placer.cc:874] gradients/Eval_Network/conv4/concat_grad/Rank: (Const)/job:localhost/replica:0/task:0/device:GPU:1
gradients/Eval_Network/conv5_1/concat_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800832: I tensorflow/core/common_runtime/placer.cc:874] gradients/Eval_Network/conv5_1/concat_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/device:GPU:1
gradients/Eval_Network/conv5_1/concat_grad/Shape: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800848: I tensorflow/core/common_runtime/placer.cc:874] gradients/Eval_Network/conv5_1/concat_grad/Shape: (Const)/job:localhost/replica:0/task:0/device:GPU:1
gradients/Eval_Network/conv5_1/concat_grad/Rank: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800863: I tensorflow/core/common_runtime/placer.cc:874] gradients/Eval_Network/conv5_1/concat_grad/Rank: (Const)/job:localhost/replica:0/task:0/device:GPU:1
gradients/Eval_Network/conv5/concat_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800897: I tensorflow/core/common_runtime/placer.cc:874] gradients/Eval_Network/conv5/concat_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/device:GPU:1
gradients/Eval_Network/conv5/concat_grad/Shape: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800913: I tensorflow/core/common_runtime/placer.cc:874] gradients/Eval_Network/conv5/concat_grad/Shape: (Const)/job:localhost/replica:0/task:0/device:GPU:1
gradients/Eval_Network/conv5/concat_grad/Rank: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800928: I tensorflow/core/common_runtime/placer.cc:874] gradients/Eval_Network/conv5/concat_grad/Rank: (Const)/job:localhost/replica:0/task:0/device:GPU:1
gradients/Eval_Network/Flatten_input_2/Reshape_grad/Shape: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800943: I tensorflow/core/common_runtime/placer.cc:874] gradients/Eval_Network/Flatten_input_2/Reshape_grad/Shape: (Const)/job:localhost/replica:0/task:0/device:GPU:1
gradients/Eval_Network/Flatten_input_1/Reshape_grad/Shape: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800958: I tensorflow/core/common_runtime/placer.cc:874] gradients/Eval_Network/Flatten_input_1/Reshape_grad/Shape: (Const)/job:localhost/replica:0/task:0/device:GPU:1
gradients/Eval_Network/Reshape_1_grad/Shape: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800973: I tensorflow/core/common_runtime/placer.cc:874] gradients/Eval_Network/Reshape_1_grad/Shape: (Const)/job:localhost/replica:0/task:0/device:GPU:1
gradients/Eval_Network/Reshape_grad/Shape: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.800987: I tensorflow/core/common_runtime/placer.cc:874] gradients/Eval_Network/Reshape_grad/Shape: (Const)/job:localhost/replica:0/task:0/device:GPU:1
gradients/Eval_Network/concat_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.801002: I tensorflow/core/common_runtime/placer.cc:874] gradients/Eval_Network/concat_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/device:GPU:1
gradients/Eval_Network/concat_grad/Shape: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2018-03-31 21:43:19.801017: I tensorflow/core/common_runtime/placer.cc:874] gradients/Eval_Network/concat_grad/Shape: (Const)/job:localhost/replica:0/task:0/device:GPU:1
gradients/Eval_Network/concat_grad/Rank: (Const): /job:localhost/replica:0/task:0/device:GPU:1
"
18144,tf.data.apply does not return output shape,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS High Sierra
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: 1.8.0-dev20180328
- **Python version**:  3.6
- **Bazel version (if compiling from source)**: NA
- **GCC/Compiler version (if compiling from source)**: NA
- **CUDA/cuDNN version**: NA
- **GPU model and memory**: NA
- **Exact command to reproduce**:


### Describe the problem
I am using tf.data API to transform my dataset. Following is the code Transform:

### Transformation Function
```python

win_len = 32
look_back = 11
pad = int(look_back/2)
slen = 1344
sh = int(slen + 2*pad)
batch_size = 840

def _parse_function(example_proto):
    keys_to_features = {'mix':tf.FixedLenFeature((slen), tf.float32),
                        'pure':tf.FixedLenFeature((slen), tf.float32)}
    parsed_features = tf.parse_single_example(example_proto, keys_to_features)
    return {""pure"":parsed_features['pure'], ""mix"":parsed_features['mix']}
def _dict_pad(sig):
    return {'pure':tf.pad(sig['pure'],[[pad,pad]]),'mix':tf.pad(sig['mix'],[[pad,pad]])}
def _dict_slide_reduce(sig,sh):
    return sig.apply(sliding_window_batch(window_size=look_back,stride=1))
def _pure_reduce(sig):
    return {'pure': sig['pure'][:,pad],'mix':sig['mix'] }
```

### Data Reading:

```python
train_data = tf.data.TFRecordDataset(train_files)\
            .map(_parse_function)\
            .map(_dict_pad)\
            .apply(unbatch())\
            .apply((group_by_window(key_func= lambda sig : 1,reduce_func = lambda key,sig : _dict_slide_reduce(sig,sh),window_size=sh)))\
            .batch(win_len)\
            .map(_pure_reduce)\
            .batch(batch_size) 
train_data = train_data.prefetch(100)
print(train_data.output_shapes)
iterator_train = train_data.make_one_shot_iterator()
tr_sig = iterator_train.get_next()
```

output of `print(train_data.output_shapes) ` is following:

`{'pure': TensorShape([Dimension(None), Dimension(None)]), 'mix': TensorShape([Dimension(None), Dimension(None), Dimension(None)])}
`

output shape after each transformation:
```python
train_data = tf.data.TFRecordDataset(train_files)
train_data = train_data.map(_parse_function)
print(train_data.output_shapes)
# {'pure': TensorShape([Dimension(1344)]), 'mix': TensorShape([Dimension(1344)])}
train_data = train_data.map(_dict_pad)
print(train_data.output_shapes)
# {'pure': TensorShape([Dimension(1354)]), 'mix': TensorShape([Dimension(1354)])}
train_data = train_data.apply(tf.contrib.data.unbatch())
print(train_data.output_shapes)
# {'pure': TensorShape([]), 'mix': TensorShape([])}
train_data = train_data.apply((group_by_window(key_func= lambda sig : 1,reduce_func = lambda key,sig : _dict_slide_reduce(sig,sh),window_size=32)))
print(train_data.output_shapes)
# {'pure': TensorShape([Dimension(None)]), 'mix': TensorShape([Dimension(None)])}
train_data = train_data.batch(win_len)
print(train_data.output_shapes)
# {'pure': TensorShape([Dimension(None), Dimension(None)]), 'mix': TensorShape([Dimension(None), Dimension(None)])}
train_data = train_data.map(_pure_reduce)
print(train_data.output_shapes)
# {'pure': TensorShape([Dimension(None)]), 'mix': TensorShape([Dimension(None), Dimension(None)])}
train_data = train_data.batch(batch_size)
print(train_data.output_shapes)
# {'pure': TensorShape([Dimension(None), Dimension(None)]), 'mix': TensorShape([Dimension(None), Dimension(None), Dimension(None)])}
```

The expected output is `{'mix': TensorShape([Dimension(None), Dimension(32), Dimension(11)]), 'pure': TensorShape([Dimension(None), Dimension(32)])}
`
```python
iterator_train = train_data.make_one_shot_iterator()
tr_sig = iterator_train.get_next()
with tf.Session() as sess:
    data = sess.run(tr_sig)
    print(data['mix'].shape,data['pure'].shape)
# (840, 32, 11) (840, 32)
```
Because of this issue I am getting following error in  dynamic_rnn:

`
ValueError: Input size (depth of inputs) must be accessible via shape inference, but saw value None.
`"
18143,contribute: Add the API to set the session configuration when load the model in the JAVA,"System information
Have I written custom code (as opposed to using a stock example script provided in TensorFlow): NO
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): Master
Python version: 3.6
Bazel version (if compiling from source): N/A
GCC/Compiler version (if compiling from source): N/A
CUDA/cuDNN version: None
GPU model and memory: None
Exact command to reproduce: Run the snippet below.

In the Java, only can set the run options and can't modify the session configuration when load the model. Sometimes I want to set the session strategies, ex. Set the session threads, op threads number, and so on.

I write the code to add new interface in the JAVA, and also add the JNI corresponding method.
I have been submit the code in the github:
URL:
https://github.com/raintung/TensorflowPatch

I will use it in my company project, I think it should not conflict the Tensorflow license, I still contribute it.
 




"
18142,+1,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
18141,Tensorflow model save using c++,I can't find any c++ api to save a tensorflow model. Is there any way to implement this?
18139,Error in restoring the tensorflow model and metagraph while using seq2seq and attention model.,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: pip3 install tensorflow-gpu==1.0.0
- **TensorFlow version (use command below)**: 1.0.0
- **Python version**: 3.5.2
- **Bazel version (if compiling from source)**:No
- **GCC/Compiler version (if compiling from source)**: 5.4.0
- **CUDA/cuDNN version**: 8/7
- **GPU model and memory**:GTX 1060X and 6GB
- **Exact command to reproduce**:

I am using seq2seq model with attention mechanism for a chatbot as given in the [link](https://github.com/Currie32/Chatbot-from-Movie-Dialogue/blob/master/Chatbot_Attention.ipynb), I am able to train the model and save it but when I am trying to restore the model I am getting an error:

Code for loading the model:
```
with tf.Session() as sess:
        #try:
        saver = tf.train.import_meta_graph('/media/saurabh/New Volume/nlp_ucf/project/model/model_0.ckpt.meta')
        saver.restore(sess, '/media/saurabh/New Volume/nlp_ucf/project/model/model_0.ckpt.data-00000-of-00001')
```
The error I am getting is

```
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0)
Traceback (most recent call last):
  File ""start_something.py"", line 254, in <module>
    saver = tf.train.import_meta_graph('/media/saurabh/New Volume/nlp_ucf/project/model/model_0.ckpt.meta')
  File ""/home/saurabh/tfenv3/lib/python3.5/site-packages/tensorflow/python/training/saver.py"", line 1577, in import_meta_graph
    **kwargs)
  File ""/home/saurabh/tfenv3/lib/python3.5/site-packages/tensorflow/python/framework/meta_graph.py"", line 498, in import_scoped_meta_graph
    producer_op_list=producer_op_list)
  File ""/home/saurabh/tfenv3/lib/python3.5/site-packages/tensorflow/python/framework/importer.py"", line 259, in import_graph_def
    raise ValueError('No op named %s in defined operations.' % node.op)
ValueError: No op named attn_add_fun_f32f32f32 in defined operations.
```
I am even unable to understand the error. Does anyone have any clue about it? I was able to find one more person with a similar issue on StackOverflow but couldn't understand what exactly is the solution?"
18136,Tenorflow gpu problems,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:source
- **TensorFlow version (use command below)**:sudo pip3 install --upgrade tensorflow-gpu==1.4
- **Python version**: python3
- **Bazel version (if compiling from source)**:no
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
Traceback (most recent call last):
  File ""utils.py"", line 15, in <module>
    import tensorflow as tf
  File ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

"
18133,Segmentation fault with TF 1.7 built from source with MKL support,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Amazon Linux (Linux version 4.9.85-38.58.amzn1.x86_64)
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.7.0
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: 0.11.1
- **GCC/Compiler version (if compiling from source)**: 5.3.0
- **CUDA/cuDNN version**: None
- **GPU model and memory**: None
- **Exact command to reproduce**:
```
git clone -b r1.7 https://github.com/tensorflow/tensorflow.git
cd tensorflow
./configure
bazel build --jobs $(nproc) --config=opt --config=mkl --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --copt=""-DEIGEN_USE_VML"" //tensorflow/tools/pip_package:build_pip_package

git clone https://github.com/tensorflow/models.git
cd models/tutorials/image/cifar10/
python cifar10_train.py
```
**Result:**
```
[ec2-user@ip-xxx-xx-xx-xxx cifar10]$ python cifar10_train.py
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Segmentation fault
```

### Describe the problem
I tried to compile TF 1.7 from source with MKL and AVX512 support on my AWS EC2 C5.18xlarge instance. 
This Segmentation fault appeared when running cifar10_train.py. This error appeared with TF1.5 as well and TF 1.6 fixed it, but now it appears again with 1.7. 
I have tried to compile TF without AVX512 with following commands and this error didn't appear again:
```
bazel build --jobs $(nproc) --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --config=mkl --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx2 --copt=-mavx --copt=-mfma --copt=""-DEIGEN_USE_VML"" //tensorflow/tools/pip_package:build_pip_package
```
So I'm guessing this issue is related with AVX512.
"
18132,Build error using bazel for r1.7 -> gen_gen_stats_ops_py_py_wrappers_cc: undefined symbol: _ZN6google8protobuf8internal26fixed_address_empty_stringB5cxx11E,"Tried to build r1.7 from source for CPU only
Build logs below
###############
INFO: From Compiling external/kafka/src/rdkafka_op.c:
external/kafka/src/rdkafka_op.c: In function 'rd_kafka_op_destroy':
external/kafka/src/rdkafka_op.c:299:35: warning: variable 'res' set but not used [-Wunused-but-set-variable]
                 rd_kafka_op_res_t res;
                                   ^~~
ERROR: /tmp/tensorflow/tensorflow/contrib/tensor_forest/BUILD:324:1: Executing genrule //tensorflow/contrib/tensor_forest:gen_stats_ops_py_pygenrule failed (Exit 127)
bazel-out/host/bin/tensorflow/contrib/tensor_forest/gen_gen_stats_ops_py_py_wrappers_cc: symbol lookup error: bazel-out/host/bin/tensorflow/contrib/tensor_forest/gen_gen_stats_ops_py_py_wrappers_cc: undefined symbol: _ZN6google8protobuf8internal26fixed_address_empty_stringB5cxx11E
Target //tensorflow/tools/pip_package:build_pip_package failed to build

####################
Ubuntu 16.10
Bazel
Build label: 0.11.1
Build target: bazel-out/k8-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
"
18131,What's the min version of glibc required for building TF from source?,"I want to compile TF from source, what's the min version of glibc I can use for building?"
18129,AttributeError: module 'tensorflow.contrib.slim.python.slim.nets.inception' has no attribute 'inception_v4_arg_scope',"when i use this code in my code , i get that error but for v1-3 don't problem.
```
with slim.arg_scope(inception.inception_v4_arg_scope()):
    	_, end_points = inception.inception_v4(x_input, num_classes=num_classes, is_training=False)
```
"
18127,Was the ExpandDims op merged into TFLite?,"[Here](https://github.com/tensorflow/tensorflow/pull/14849) I see somebody proposing a pull request for ExpandDims. However, when I run TOCO on my model, I get a message saying 

`Here is a list of operators for which you will need custom implementations: ExpandDims, ...`

What is the status of this pull request? If it has been merged, why does TOCO still complain?"
18124,Model behavior changes after saving and restoring!,"Hi there,
My tf version is 1.2.1.
It's Okay if I feed the test data after model training, to get an accuracy of 98%.
But after I save and restore the model. The accuracy will only be around 10%. What happened...

Besides, I think the accuracy from the test data should be a constant given that weights and biases won't be updated after training, but each time the accuracy is slightly different. Say, 0.1012, 0.9982, things like that...

Any help?"
18123,No float16 batch matrix multiplication support for GPU,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: b'v1.6.0-rc1-1857-g67e2efa' 1.6.0
- **Python version**: 3.5.2
- **Bazel version (if compiling from source)**: 0.10.0
- **GCC/Compiler version (if compiling from source)**: 5.4.0
- **CUDA/cuDNN version**: 9.0/7.0
- **GPU model and memory**: not relevant
- **Exact command to reproduce**:

```
import tensorflow as tf
import numpy.random as npr

with tf.device('/gpu:0'):
    a = tf.constant(npr.rand(10, 5, 5).astype('float16'))
    b = tf.constant(npr.rand(10, 5, 5).astype('float16'))
    c = tf.matmul(a, b)

sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=False))
sess.run(c)
```

### Describe the problem
The problem is the same as in issue #605, but for float16: there is no GPU support for batch matrix multiplication. There is a quick workaround of reshaping the tensors to 2D, multiplying and reshaping back, but that is not possible to do when this function is called inside some TensorFlow classes, like in attention_wrapper.py line 336. And this significantly slows down computation of RNNs with attention on float16.

### Source code / logs
Traceback:

```
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
   1329     try:
-> 1330       return fn(*args)
   1331     except errors.OpError as e:

~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)
   1312       # Ensure any changes to the graph are reflected in the runtime.
-> 1313       self._extend_graph()
   1314       return self._call_tf_sessionrun(

~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py in _extend_graph(self)
   1360             tf_session.TF_ExtendGraph(self._session,
-> 1361                                       graph_def.SerializeToString(), status)
   1362           self._opened = True

~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py in __exit__(self, type_arg, value_arg, traceback_arg)
    515             compat.as_text(c_api.TF_Message(self.status.status)),
--> 516             c_api.TF_GetCode(self.status.status))
    517     # Delete the underlying status object from memory otherwise it stays alive

InvalidArgumentError: Cannot assign a device for operation 'MatMul': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
Registered kernels:
  device='XLA_GPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]
  device='XLA_CPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]
  device='GPU'; T in [DT_DOUBLE]
  device='GPU'; T in [DT_FLOAT]
  device='GPU'; T in [DT_COMPLEX128]
  device='GPU'; T in [DT_COMPLEX64]
  device='CPU'; T in [DT_INT32]
  device='CPU'; T in [DT_HALF]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_COMPLEX128]
  device='CPU'; T in [DT_COMPLEX64]
  device='XLA_GPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]
  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]

	 [[Node: MatMul = BatchMatMul[T=DT_HALF, adj_x=false, adj_y=false, _device=""/device:GPU:0""](Const, Const_1)]]

During handling of the above exception, another exception occurred:

InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-1-8739d1f2e967> in <module>()
      8 
      9 sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=False))
---> 10 sess.run(c)

~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)
    906     try:
    907       result = self._run(None, fetches, feed_dict, options_ptr,
--> 908                          run_metadata_ptr)
    909       if run_metadata:
    910         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
   1141     if final_fetches or final_targets or (handle and feed_dict_tensor):
   1142       results = self._do_run(handle, final_targets, final_fetches,
-> 1143                              feed_dict_tensor, options, run_metadata)
   1144     else:
   1145       results = []

~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
   1322     if handle is None:
   1323       return self._do_call(_run_fn, feeds, fetches, targets, options,
-> 1324                            run_metadata)
   1325     else:
   1326       return self._do_call(_prun_fn, handle, feeds, fetches)

~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
   1341         except KeyError:
   1342           pass
-> 1343       raise type(e)(node_def, op, message)
   1344 
   1345   def _extend_graph(self):

InvalidArgumentError: Cannot assign a device for operation 'MatMul': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
Registered kernels:
  device='XLA_GPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]
  device='XLA_CPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]
  device='GPU'; T in [DT_DOUBLE]
  device='GPU'; T in [DT_FLOAT]
  device='GPU'; T in [DT_COMPLEX128]
  device='GPU'; T in [DT_COMPLEX64]
  device='CPU'; T in [DT_INT32]
  device='CPU'; T in [DT_HALF]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_COMPLEX128]
  device='CPU'; T in [DT_COMPLEX64]
  device='XLA_GPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]
  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]

	 [[Node: MatMul = BatchMatMul[T=DT_HALF, adj_x=false, adj_y=false, _device=""/device:GPU:0""](Const, Const_1)]]

Caused by op 'MatMul', defined at:
  File ""/usr/lib/python3.5/runpy.py"", line 184, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""/usr/lib/python3.5/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/home/igitman/Documents/venv/lib/python3.5/site-packages/ipykernel_launcher.py"", line 16, in <module>
    app.launch_new_instance()
  File ""/home/igitman/Documents/venv/lib/python3.5/site-packages/traitlets/config/application.py"", line 658, in launch_instance
    app.start()
  File ""/home/igitman/Documents/venv/lib/python3.5/site-packages/ipykernel/kernelapp.py"", line 486, in start
    self.io_loop.start()
  File ""/home/igitman/Documents/venv/lib/python3.5/site-packages/tornado/ioloop.py"", line 888, in start
    handler_func(fd_obj, events)
  File ""/home/igitman/Documents/venv/lib/python3.5/site-packages/tornado/stack_context.py"", line 277, in null_wrapper
    return fn(*args, **kwargs)
  File ""/home/igitman/Documents/venv/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py"", line 450, in _handle_events
    self._handle_recv()
  File ""/home/igitman/Documents/venv/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py"", line 480, in _handle_recv
    self._run_callback(callback, msg)
  File ""/home/igitman/Documents/venv/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py"", line 432, in _run_callback
    callback(*args, **kwargs)
  File ""/home/igitman/Documents/venv/lib/python3.5/site-packages/tornado/stack_context.py"", line 277, in null_wrapper
    return fn(*args, **kwargs)
  File ""/home/igitman/Documents/venv/lib/python3.5/site-packages/ipykernel/kernelbase.py"", line 283, in dispatcher
    return self.dispatch_shell(stream, msg)
  File ""/home/igitman/Documents/venv/lib/python3.5/site-packages/ipykernel/kernelbase.py"", line 233, in dispatch_shell
    handler(stream, idents, msg)
  File ""/home/igitman/Documents/venv/lib/python3.5/site-packages/ipykernel/kernelbase.py"", line 399, in execute_request
    user_expressions, allow_stdin)
  File ""/home/igitman/Documents/venv/lib/python3.5/site-packages/ipykernel/ipkernel.py"", line 208, in do_execute
    res = shell.run_cell(code, store_history=store_history, silent=silent)
  File ""/home/igitman/Documents/venv/lib/python3.5/site-packages/ipykernel/zmqshell.py"", line 537, in run_cell
    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
  File ""/home/igitman/Documents/venv/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2728, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""/home/igitman/Documents/venv/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2850, in run_ast_nodes
    if self.run_code(code, result):
  File ""/home/igitman/Documents/venv/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-1-8739d1f2e967>"", line 7, in <module>
    c = tf.matmul(a, b)
  File ""/home/igitman/Documents/venv/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py"", line 2082, in matmul
    a, b, adj_x=adjoint_a, adj_y=adjoint_b, name=name)
  File ""/home/igitman/Documents/venv/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py"", line 1236, in batch_mat_mul
    ""BatchMatMul"", x=x, y=y, adj_x=adj_x, adj_y=adj_y, name=name)
  File ""/home/igitman/Documents/venv/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/home/igitman/Documents/venv/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 3306, in create_op
    op_def=op_def)
  File ""/home/igitman/Documents/venv/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1669, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): Cannot assign a device for operation 'MatMul': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
Registered kernels:
  device='XLA_GPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]
  device='XLA_CPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]
  device='GPU'; T in [DT_DOUBLE]
  device='GPU'; T in [DT_FLOAT]
  device='GPU'; T in [DT_COMPLEX128]
  device='GPU'; T in [DT_COMPLEX64]
  device='CPU'; T in [DT_INT32]
  device='CPU'; T in [DT_HALF]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_COMPLEX128]
  device='CPU'; T in [DT_COMPLEX64]
  device='XLA_GPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]
  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]

	 [[Node: MatMul = BatchMatMul[T=DT_HALF, adj_x=false, adj_y=false, _device=""/device:GPU:0""](Const, Const_1)]]
```
"
18119,can I use tracker(used android example) from opencv tracking lib?,"The performance of tracker used android example is very nice.
I really want to use it via opencv tracking library.
is it possible in the future? anyone send pull request to opencv library?"
18118,tfdbg error on windows 10,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 10 x64 pro
- **TensorFlow installed from (source or binary)**:
binary 1.7.0 gpu win64
- **TensorFlow version (use command below)**:
1.7.0
- **Python version**: 
3.6.5
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
9.0/7.0
- **GPU model and memory**:
GTX1080 GDDR5X 8GB
- **Exact command to reproduce**:
python -m tensorflow.python.debug.examples.debug_mnist --debug

### Describe the problem

### Source code / logs

WARNING:tensorflow:From C:\Anaconda3\lib\site-packages\tensorflow\contrib\learn\python\learn\datasets\mnist.py:290: Data
Set.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future v
ersion.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2018-03-30 20:50:57.501717: I T:\src\github\tensorflow\tensorflow\core\platform\cpu_feature_guard.cc:140] Your CPU suppo
rts instructions that this TensorFlow binary was not compiled to use: AVX2
2018-03-30 20:50:57.892716: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1344] Found devi
ce 0 with properties:
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.835
pciBusID: 0000:01:00.0
totalMemory: 8.00GiB freeMemory: 6.60GiB
2018-03-30 20:50:57.904881: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1423] Adding vis
ible gpu devices: 0
2018-03-30 20:50:58.560856: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:911] Device inte
rconnect StreamExecutor with strength 1 edge matrix:
2018-03-30 20:50:58.568769: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:917]      0
2018-03-30 20:50:58.574326: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:930] 0:   N
2018-03-30 20:50:58.578842: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1041] Created Te
nsorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6379 MB memory) -> physical GPU (device: 0, name: GeF
orce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)
Traceback (most recent call last):
  File ""C:\Anaconda3\lib\site-packages\tensorflow\python\debug\cli\ui_factory.py"", line 60, in get_ui
    from tensorflow.python.debug.cli import curses_ui
  File ""C:\Anaconda3\lib\site-packages\tensorflow\python\debug\cli\curses_ui.py"", line 21, in <module>
    import curses
  File ""C:\Anaconda3\lib\curses\__init__.py"", line 13, in <module>
    from _curses import *
ModuleNotFoundError: No module named '_curses'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Anaconda3\lib\site-packages\tensorflow\python\debug\cli\ui_factory.py"", line 63, in get_ui
    from tensorflow.python.debug.cli import readline_ui
  File ""C:\Anaconda3\lib\site-packages\tensorflow\python\debug\cli\readline_ui.py"", line 20, in <module>
    import readline
ModuleNotFoundError: No module named 'readline'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Anaconda3\lib\runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""C:\Anaconda3\lib\runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""C:\Anaconda3\lib\site-packages\tensorflow\python\debug\examples\debug_mnist.py"", line 193, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""C:\Anaconda3\lib\site-packages\tensorflow\python\platform\app.py"", line 126, in run
    _sys.exit(main(argv))
  File ""C:\Anaconda3\lib\site-packages\tensorflow\python\debug\examples\debug_mnist.py"", line 136, in main
    acc = sess.run(accuracy, feed_dict=feed_dict(False))
  File ""C:\Anaconda3\lib\site-packages\tensorflow\python\debug\wrappers\framework.py"", line 462, in run
    is_callable_runner=bool(callable_runner)))
  File ""C:\Anaconda3\lib\site-packages\tensorflow\python\debug\wrappers\local_cli_wrapper.py"", line 255, in on_run_start

    self._prep_cli_for_run_start()
  File ""C:\Anaconda3\lib\site-packages\tensorflow\python\debug\wrappers\local_cli_wrapper.py"", line 277, in _prep_cli_fo
r_run_start
    self._run_cli = ui_factory.get_ui(self._ui_type)
  File ""C:\Anaconda3\lib\site-packages\tensorflow\python\debug\cli\ui_factory.py"", line 71, in get_ui
    available_ui_types=available_ui_types)
  File ""C:\Anaconda3\lib\site-packages\tensorflow\python\debug\cli\ui_factory.py"", line 69, in get_ui
    raise ValueError(""Exhausted all fallback ui_types."")
ValueError: Exhausted all fallback ui_types."
18117,"unexpected 10 sec hang, related to tf.TensorArray","
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, code is below
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Debian 9.4, Linux wc4 4.9.0-6-amd64  SMP Debian 4.9.82-1+deb9u3 (2018-03-02) x86_64 GNU/Linux
- **TensorFlow installed from (source or binary)**: binary pip
- **TensorFlow version (use command below)**: v1.5.0-0-g37aa430d84 1.5.0
- **Python version**: 3.5.3
- **Bazel version (if compiling from source)**: -
- **GCC/Compiler version (if compiling from source)**: -
- **CUDA/cuDNN version**: 9.0
- **GPU model and memory**: GeForce GTX 1080, 11GB
- **Exact command to reproduce**: see code below

### Describe the problem
The test case below causes an unexpected hang for about 10 seconds.
I think it is related to `tf.TensorArray` but also the other operations in the graph are important.
I have already tried to reduce it as much as possible. If I remove something now,
the hang will disappear.

### Source code / logs

```
import tensorflow as tf
import contextlib
import numpy

@contextlib.contextmanager
def make_scope():
  """"""
  :rtype: tf.Session
  """"""
  with tf.Graph().as_default() as graph:
    with tf.Session(graph=graph) as session:
      yield session


def test_slow_TensorArray():
  import time
  random = numpy.random.RandomState(seed=1)
  num_inputs = 4
  num_outputs = 3
  seq_len = 10
  limit = 1.0

  def linear(x, output_dim):
    input_dim = x.get_shape().dims[-1].value
    assert input_dim is not None
    with tf.variable_scope(""linear"", reuse=tf.AUTO_REUSE):
      weights = tf.get_variable(""W"", shape=(input_dim, output_dim))
      bias = tf.get_variable(""b"", shape=(output_dim,))
    assert x.get_shape().ndims == 2  # (batch,input_dim)
    return tf.matmul(x, weights) + bias

  with make_scope() as session:
    print(""create graph"")
    src_placeholder = tf.placeholder(tf.float32, (None, seq_len, num_inputs), name=""src_placeholder"")
    tgt_placeholder = tf.placeholder(tf.float32, (None, seq_len, num_outputs), name=""tgt_placeholder"")
    batch_size = tf.shape(src_placeholder)[0]

    def make_feed_dict():
      return {
        src_placeholder: random.uniform(-limit, limit, (1, seq_len, num_inputs)),
        tgt_placeholder: random.uniform(-limit, limit, (1, seq_len, num_outputs)),
      }

    state = tf.zeros((batch_size, num_outputs))
    loss_ta = tf.TensorArray(tf.float32, size=seq_len, element_shape=(None,))
    # Unroll the loop here.
    for f in range(seq_len):
      inputs = src_placeholder[:, f]
      x = tf.concat([inputs, state], axis=-1)
      with tf.variable_scope('h'):
        h = tf.tanh(linear(x, num_outputs))
      with tf.variable_scope('t'):
        t = tf.sigmoid(linear(x, num_outputs))
      state += t * (h - state)
      frame_loss = tf.reduce_mean(tf.squared_difference(tgt_placeholder[:, f], state), axis=1)
      assert frame_loss.get_shape().ndims == 1  # (batch,)
      loss_ta = loss_ta.write(f, frame_loss)
    loss = tf.reduce_sum(loss_ta.stack())
    optimizer = tf.train.AdamOptimizer(learning_rate=0.1, epsilon=1e-16, use_locking=False)
    minimize_op = optimizer.minimize(loss)

    print('variables:')
    train_vars = (
      tf.trainable_variables() +
      tf.get_collection(tf.GraphKeys.TRAINABLE_RESOURCE_VARIABLES))
    print(train_vars)
    print('init vars')
    session.run(tf.global_variables_initializer())
    print('graph size:', session.graph_def.ByteSize())
    print('train')
    for s in range(10):
      start_time = time.time()
      loss_val, _ = session.run([loss, minimize_op], feed_dict=make_feed_dict())
      print(""step %i, loss: %f, time: %f"" % (s, loss_val, time.time() - start_time))

test_slow_TensorArray()
```

My output:

```
create graph
variables:
[<tf.Variable 'h/linear/W:0' shape=(7, 3) dtype=float32_ref>, <tf.Variable 'h/linear/b:0' shape=(3,) dtype=float32_ref>, <tf.Variable 't/linear/W:0' shape=(7, 3) dtype=float32_ref>, <tf.Variable 't/linear/b:0' shape=(3,) dtype=float32_ref>]
init vars
graph size: 222234
train
step 0, loss: 5.506713, time: 10.675434
step 1, loss: 7.865020, time: 0.003913
step 2, loss: 5.450877, time: 0.003354
step 3, loss: 3.361173, time: 0.003227
step 4, loss: 4.493120, time: 0.003563
step 5, loss: 5.137649, time: 0.003203
step 6, loss: 3.610677, time: 0.003376
step 7, loss: 3.657249, time: 0.003544
step 8, loss: 4.405594, time: 0.003454
step 9, loss: 4.380188, time: 0.003491
```
"
18116,ImportError : Could not find 'msvcp140.dll',"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Window 7
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.5, 1.6, 1.7
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: NA
- **GCC/Compiler version (if compiling from source)**: NA
- **CUDA/cuDNN version**: NA
- **GPU model and memory**: NA
- **Exact command to reproduce**: import tensorflow as tf

### Problem
I am using python 3.6 and have successfully installed tensorflow 1.7 via pip3 command. While importing tensorflow in python interpreter an OSError occurs and while handling the exception ImportError also occurs which gives the message that 'Couldnot find msvcp140.dll'. I checked that the dll files are present in the directory that is in the PATH variable and also installed the Visual C++ Redistributable as mentioned.

### Logs
>>> import tensorflow as tf
<module 'tensorflow.python.platform.build_info' from 'C:\\Python36\\lib\\site-packages\\tensorflow\\python\\platform\\build_info.py'>
Traceback (most recent call last):
  File ""C:\Python36\lib\site-packages\tensorflow\python\platform\self_check.py"",
 line 48, in preload_check
    ctypes.WinDLL(build_info.msvcp_dll_name)
  File ""C:\Python36\lib\ctypes\__init__.py"", line 348, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: [WinError 193] %1 is not a valid Win32 application
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Python36\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""C:\Python36\lib\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 30, in <module>
    self_check.preload_check()
  File ""C:\Python36\lib\site-packages\tensorflow\python\platform\self_check.py"",
 line 56, in preload_check
    % build_info.msvcp_dll_name)
ImportError: Could not find 'msvcp140.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. You may install this DLL by downloading Visual C++ 2015 Redistributable Update 3 from this URL:https://www.microsoft.com/en-us/download/details.aspx?id=53587
"
18115,image restauration,
18112,Why is tf.images.resize_bicubic different from misc.imresize with bicubic method,"Have I written custom code (as opposed to using a stock example script provided in TensorFlow): N
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win 10
TensorFlow installed from (source or binary): binary 
TensorFlow version (use command below): 1.6
Python version: 3.6
Bazel version (if compiling from source): 
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: 9.0  cudnn 7.0
GPU model and memory: GTX 1080ti
Exact command to reproduce: N

I consider the implement of tf.images.resize_bicubic is similar to opencv resize method, but it has problem.
The opencv resize has more noise and less soomth. If we use opencv to resize image and process image super-resolution, it will degrade the performance.
There are some visual results generated by tensorflow and scipy.misc:
tersorflow:
![res2](https://user-images.githubusercontent.com/8861423/38127143-649f5e44-3427-11e8-8bcc-3c0c4f46b617.png)
misc:
![res1](https://user-images.githubusercontent.com/8861423/38127136-592109fa-3427-11e8-800e-1e0ad4fe61a7.png)

I wish the tensorflow can offer the implement of misc (or PIL, MATLAB)  resize method. Thanks!

"
18111,importing tensorflow.contrib produces a warning,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows and Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.7
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: 9.0/7
- **GPU model and memory**:
- **Exact command to reproduce**:
python
import tensorflow.contrib

### Describe the problem
Using tensorflow.contrib produces a warning in 1.7. The warning is

WARNING:tensorflow:From ...\envs\tf-1.7\lib\site-packages\tensorflow\contrib\learn\python\learn\datasets\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Use the retry module or similar alternatives."
18108,building from source with branch r1.7 gives tf1.5.1 after building wheel,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:ubuntu 16.04.9
- **TensorFlow installed from (source or binary)**:source
- **TensorFlow version (use command below)**:1.5.1 after successful building, but i want 1.7
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: build label 0.11.1
- **GCC/Compiler version (if compiling from source)**:5.4.0 when i type gcc --version, 7.2.0 shown in python terminal
- **CUDA/cuDNN version**:cuda 9, cudnn 7
- **GPU model and memory**: gtx1080 ti 11 gb
- **Exact command to reproduce**: following this https://gist.github.com/kmhofmann/e368a2ebba05f807fa1a90b3bf9a1e03

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
I've make sure i'd pull everything from tensorflow. i remove all other branch and check out r1.7, building was successful. No errors and stuff. The wheel i got says tensorflow-1.5.1-cp36 ... etc. , i go on to install it, tf.__version__ = 1.5.1 . I am confused how to build tf 1.7 from source.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
18107,Mask_Rcnn real time?,"Though Mask_Rcnn is amazing, if it can't be applied to mobile devices, it will be useless. Can theoretically run on mobile devices in real time?

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:1.7
- **TensorFlow version (use command below)**:1.7
- **Python version**: 3.5
- **Bazel version (if compiling from source)**:none
- **GCC/Compiler version (if compiling from source)**:none
- **CUDA/cuDNN version**:9.0
- **GPU model and memory**:7.1
- **Exact command to reproduce**:none
"
18103,Keras TimeDistributed wrapper around GlobalMaxPooling2D error with TPU,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux 4.9.0-6-amd64 #1 SMP Debian 4.9.82-1+deb9u3 (2018-03-02) x86_64 GNU/Linux
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.7.0-rc1
- **Python version**: 2.7.13
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: Google Cloud TPU v2-8 running TF 1.7
- **Exact command to reproduce**: See below


### Describe the problem
Using a Keras TimeDistributed wrapper to wrap a Keras GlobalMaxPooling2D layer, and processing on a Google Cloud TPU results in a ```ValueError```. The layer behaves as expected if the TPUEstimator is configured to use CPU. Error raised by the TPU failure case:
```ValueError: Cannot create a gradient accumulator for tensor 'TPUReplicate/loop/time_distributed/while/Identity:0' inside XLA while_loop because maximum_iterations was not passed to the tf.while_loop call ('TPUReplicate/loop/time_distributed/while/while_context').```

### Source code / logs
Test code minimal example keras_td_test.py:
```python
"""""" Test for Keras model TimeDistributed wrapper on TPU.
    Based on https://github.com/tensorflow/tpu/blob/master/models/official/resnet/
""""""

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from absl import flags
import absl.logging as _logging  # pylint: disable=unused-import
import tensorflow as tf
import numpy as np

from tensorflow.contrib.tpu.python.tpu import tpu_config
from tensorflow.contrib.tpu.python.tpu import tpu_estimator
from tensorflow.contrib.tpu.python.tpu import tpu_optimizer

# Define flags for the system
FLAGS = flags.FLAGS
flags.DEFINE_bool(
    'use_tpu', True,
    help=('Use TPU to execute the model for training and evaluation. If'
          ' --use_tpu=false, will use whatever devices are available to'
          ' TensorFlow by default (e.g. CPU and GPU)'))
flags.DEFINE_string(
    'tpu_name', default=None,
    help='Name of the Cloud TPU for Cluster Resolvers.')
flags.DEFINE_string(
    'model_dir', default=None,
    help=('The directory where the model and training/evaluation summaries are'
          ' stored.'))

def main(unused_argv):
    # Get the TPU GRPC URL if it is needed
    if FLAGS.use_tpu:
        tpu_cluster_resolver = (
            tf.contrib.cluster_resolver.TPUClusterResolver(
                FLAGS.tpu_name))
        tpu_grpc_url = tpu_cluster_resolver.get_master()
    else:
        tpu_grpc_url = None

    # Set the configuration for the TPU
    config = tpu_config.RunConfig(
        master=tpu_grpc_url,
        model_dir=FLAGS.model_dir)

    # Create the TPUEstimator
    test_estimator = tpu_estimator.TPUEstimator(
            use_tpu=FLAGS.use_tpu,
            model_fn=test_model_fn,
            config=config,
            train_batch_size=1024)

    # Train the estimator for 10 steps
    test_estimator.train(input_fn, max_steps=10)

def input_fn(params):
    # Generate a random dataset of the correct shape
    data = np.random.rand(1024, 10, 10, 10).astype(np.float32)
    label = np.random.rand(1024,10).astype(np.float32)

    # Repeat and batch
    rand_dataset = tf.data.Dataset.from_tensor_slices((data, label)).repeat()
    rand_dataset = rand_dataset.apply(tf.contrib.data.batch_and_drop_remainder(params['batch_size']))

    # Make input_fn for the TPUEstimator train step
    rand_dataset_fn = rand_dataset.make_one_shot_iterator().get_next()
    return rand_dataset_fn

def test_model_fn(features, labels, mode, params):
    # Dense layer to give the system something to train
    dense_out = tf.keras.layers.Dense(10)(features)

    ##########################################
    # The Keras wrapper that causes an error #
    ##########################################
    predictions = tf.keras.layers.TimeDistributed(
        tf.keras.layers.GlobalMaxPooling2D()
    )(dense_out)

    # Create ops for the TPUEstimatorSpec
    loss = tf.losses.mean_squared_error(labels=labels, predictions=predictions)
    optimizer = tf.train.GradientDescentOptimizer(0.001)
    if FLAGS.use_tpu:
        optimizer = tpu_optimizer.CrossShardOptimizer(optimizer)
    global_step = tf.train.get_global_step()
    train_op = optimizer.minimize(loss, global_step)

    # Return the TPUEstimatorSpec
    return tpu_estimator.TPUEstimatorSpec(
        mode=mode,
        loss=loss,
        train_op=train_op)

if __name__ == '__main__':
    # Do the thing
    print('main wrapper')
    tf.logging.set_verbosity(tf.logging.INFO)
    tf.app.run()
```

Error on TPU, and sanitized log file:
```
$ python keras_td_test.py --model_dir=gs://my_bucket/keras_td_test --tpu_name=tpu-name
WARNING: Logging before flag parsing goes to stderr.
W0329 19:53:32.386956 139824142264064 tf_logging.py:126] From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Use the retry module or similar alternatives.
main wrapper
W0329 19:53:32.582829 139824142264064 __init__.py:44] file_cache is unavailable when using oauth2client >= 4.0.0
Traceback (most recent call last):
  File ""/usr/local/lib/python2.7/dist-packages/googleapiclient/discovery_cache/__init__.py"", line 41, in autodetect
    from . import file_cache
  File ""/usr/local/lib/python2.7/dist-packages/googleapiclient/discovery_cache/file_cache.py"", line 41, in <module>
    'file_cache is unavailable when using oauth2client >= 4.0.0')
ImportError: file_cache is unavailable when using oauth2client >= 4.0.0
2018-03-29 19:53:32.619736: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-03-29 19:53:32.622444: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job local -> {0 -> localhost:44849}
2018-03-29 19:53:32.623808: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:333] Started server with target: grpc://localhost:44849
W0329 19:53:32.704463 139824142264064 tf_logging.py:126] Estimator's model_fn (<function test_model_fn at 0x7f2b1fc4d7d0>) includes params argument, but params are not passed to Estimator.
I0329 19:53:32.705055 139824142264064 tf_logging.py:116] Using config: {'_tpu_config': TPUConfig(iterations_per_loop=2, num_shards=None, computation_shape=None, per_host_input_for_training=True, tpu_job_name=None, initial_infeed_sleep_secs=None), '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2b1fc4bc90>, '_cluster': None, '_model_dir': 'gs://my_bucket/keras_td_test', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_master': u'grpc://10.240.1.2:8470', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': u'grpc://10.240.1.2:8470', '_service': None, '_save_summary_steps': 100, '_num_ps_replicas': 0}
I0329 19:53:32.772562 139824142264064 tf_logging.py:116] Querying Tensorflow master (grpc://10.240.1.2:8470) for TPU system metadata.
2018-03-29 19:53:32.773276: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:351] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
I0329 19:53:32.776926 139824142264064 tf_logging.py:116] Found TPU system:
I0329 19:53:32.777101 139824142264064 tf_logging.py:116] *** Num TPU Cores: 8
I0329 19:53:32.777353 139824142264064 tf_logging.py:116] *** Num TPU Workers: 1
I0329 19:53:32.777436 139824142264064 tf_logging.py:116] *** Num TPU Cores Per Worker: 8
I0329 19:53:32.777509 139824142264064 tf_logging.py:116] *** Available Devices: [_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184)]
I0329 19:53:32.789855 139824142264064 tf_logging.py:116] Calling model_fn.
Traceback (most recent call last):
  File ""keras_td_test.py"", line 101, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 126, in run
    _sys.exit(main(argv))
  File ""keras_td_test.py"", line 57, in main
    test_estimator.train(input_fn, max_steps=10)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 355, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 824, in _train_model
    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 805, in _call_model_fn
    model_fn_results = self._model_fn(features=features, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py"", line 1827, in _model_fn
    _train_on_tpu_system(ctx, model_fn_wrapper, dequeue_fn))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py"", line 2016, in _train_on_tpu_system
    device_assignment=ctx.device_assignment)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu.py"", line 491, in shard
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu.py"", line 323, in replicate
    outputs = computation(*computation_inputs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py"", line 2009, in multi_tpu_train_steps_on_single_shard
    name=b'loop')
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/training_loop.py"", line 207, in repeat
    cond, body_wrapper, inputs=inputs, infeed_queue=infeed_queue, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/training_loop.py"", line 169, in while_loop
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 3202, in while_loop
    result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 2940, in BuildLoop
    pred, body, original_loop_vars, loop_vars, shape_invariants)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 2877, in _BuildLoop
    body_result = body(*packed_vars_for_body)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/training_loop.py"", line 120, in body_wrapper
    outputs = body(*(inputs + dequeue_ops))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/training_loop.py"", line 203, in body_wrapper
    return [i + 1] + _convert_to_list(body(*args))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py"", line 1076, in train_step
    self._call_model_fn(features, labels))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py"", line 1230, in _call_model_fn
    estimator_spec = self._model_fn(features=features, **kwargs)
  File ""keras_td_test.py"", line 89, in test_model_fn
    train_op = optimizer.minimize(loss, global_step)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py"", line 399, in minimize
    grad_loss=grad_loss)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_optimizer.py"", line 85, in compute_gradients
    return self._opt.compute_gradients(loss, var_list=var_list, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py"", line 492, in compute_gradients
    colocate_gradients_with_ops=colocate_gradients_with_ops)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py"", line 488, in gradients
    gate_gradients, aggregation_method, stop_gradients)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py"", line 625, in _GradientsHelper
    lambda: grad_fn(op, *out_grads))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py"", line 379, in _MaybeCompile
    return grad_fn()  # Exit early
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py"", line 625, in <lambda>
    lambda: grad_fn(op, *out_grads))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/tensor_array_grad.py"", line 131, in _TensorArrayWriteGrad
    grad = g.read(index)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/tensor_array_ops.py"", line 861, in read
    return self._implementation.read(index, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/tensor_array_ops.py"", line 260, in read
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_data_flow_ops.py"", line 6419, in tensor_array_read_v3
    dtype=dtype, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 3290, in create_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1696, in __init__
    self._control_flow_post_processing()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1707, in _control_flow_post_processing
    self._control_flow_context.AddOp(self)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 2429, in AddOp
    self._AddOpInternal(op)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 2450, in _AddOpInternal
    real_x = self.AddValue(x)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 2382, in AddValue
    real_val = grad_ctxt.grad_state.GetRealValue(val)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 1152, in GetRealValue
    history_value = cur_grad_state.AddForwardAccumulator(cur_value)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 1017, in AddForwardAccumulator
    value, self.forward_context)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 752, in GetMaxSizeFromNestedMaximumIterations
    ""the tf.while_loop call ('%s')."" % (value_name, while_ctxt.name))
ValueError: Cannot create a gradient accumulator for tensor 'TPUReplicate/loop/time_distributed/while/Identity:0' inside XLA while_loop because maximum_iterations was not passed to the tf.while_loop call ('TPUReplicate/loop/time_distributed/while/while_context').
```

Working as expected on CPU:
```
$ python keras_td_test.py --model_dir=gs://my_bucket/keras_td_test --use_tpu=False
WARNING: Logging before flag parsing goes to stderr.
W0329 19:52:51.631102 140253725816576 tf_logging.py:126] From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Use the retry module or similar alternatives.
main wrapper
W0329 19:52:51.829307 140253725816576 tf_logging.py:126] Estimator's model_fn (<function test_model_fn at 0x7f8f24f2c7d0>) includes params argument, but params are not passed to Estimator.
I0329 19:52:51.829844 140253725816576 tf_logging.py:116] Using config: {'_tpu_config': TPUConfig(iterations_per_loop=2, num_shards=None, computation_shape=None, per_host_input_for_training=True, tpu_job_name=None, initial_infeed_sleep_secs=None), '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8f24f2a550>, '_cluster': None, '_model_dir': 'gs://my_bucket/keras_td_test', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': '', '_service': None, '_save_summary_steps': 100, '_num_ps_replicas': 0}
I0329 19:52:51.967509 140253725816576 tf_logging.py:116] Calling model_fn.
I0329 19:52:51.967808 140253725816576 tf_logging.py:116] Running train on CPU
I0329 19:52:52.141927 140253725816576 tf_logging.py:116] Done calling model_fn.
I0329 19:52:52.143158 140253725816576 tf_logging.py:116] Create CheckpointSaverHook.
I0329 19:52:53.315506 140253725816576 tf_logging.py:116] Graph was finalized.
2018-03-29 19:52:53.315908: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
I0329 19:52:53.452600 140253725816576 tf_logging.py:116] Running local_init_op.
I0329 19:52:53.456309 140253725816576 tf_logging.py:116] Done running local_init_op.
I0329 19:52:55.594362 140253725816576 tf_logging.py:116] Saving checkpoints for 1 into gs://my_bucket/keras_td_test/model.ckpt.
I0329 19:52:58.770798 140253725816576 tf_logging.py:116] loss = 0.62052673, step = 0
I0329 19:52:59.185467 140253725816576 tf_logging.py:116] Saving checkpoints for 10 into gs://my_bucket/keras_td_test/model.ckpt.
I0329 19:53:03.196044 140253725816576 tf_logging.py:116] Loss for final step: 0.5509924.
```"
18102,Keras LSTM layer error with TPU unless it is unrolled,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux 4.9.0-6-amd64 #1 SMP Debian 4.9.82-1+deb9u3 (2018-03-02) x86_64 GNU/Linux
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.7.0-rc1
- **Python version**: 2.7.13
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: Google Cloud TPU v2-8 running TF 1.7
- **Exact command to reproduce**: See below


### Describe the problem
Using a Keras LSTM layer, and processing on a Google Cloud TPU results in a ```ValueError``` if the lstm is not unrolled. The layer behaves as expected if the TPUEstimator is configured to use CPU, or if the lstm loop is unrolled on either the TPU or CPU. Error raised by the TPU failure case:
```ValueError: Cannot create a gradient accumulator for tensor 'TPUReplicate/loop/lstm/while/Identity:0' inside XLA while_loop because maximum_iterations was not passed to the tf.while_loop call ('TPUReplicate/loop/lstm/while/while_context').```

### Source code / logs
Test code minimal example keras_lstm_test.py:
```python
"""""" Test for Keras model LSTM on TPU.
    Based on https://github.com/tensorflow/tpu/blob/master/models/official/resnet/
""""""

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from absl import flags
import absl.logging as _logging  # pylint: disable=unused-import
import tensorflow as tf
import numpy as np

from tensorflow.contrib.tpu.python.tpu import tpu_config
from tensorflow.contrib.tpu.python.tpu import tpu_estimator
from tensorflow.contrib.tpu.python.tpu import tpu_optimizer

# Define flags for the system
FLAGS = flags.FLAGS
flags.DEFINE_bool(
    'use_tpu', True,
    help=('Use TPU to execute the model for training and evaluation. If'
          ' --use_tpu=false, will use whatever devices are available to'
          ' TensorFlow by default (e.g. CPU and GPU)'))
flags.DEFINE_string(
    'tpu_name', default=None,
    help='Name of the Cloud TPU for Cluster Resolvers.')
flags.DEFINE_string(
    'model_dir', default=None,
    help=('The directory where the model and training/evaluation summaries are'
          ' stored.'))
flags.DEFINE_bool(
    'unroll_lstm', default=False,
    help=('Unrolls the Keras LSTM if this is True.'))

def main(unused_argv):
    # Get the TPU GRPC URL if it is needed
    if FLAGS.use_tpu:
        tpu_cluster_resolver = (
            tf.contrib.cluster_resolver.TPUClusterResolver(
                FLAGS.tpu_name))
        tpu_grpc_url = tpu_cluster_resolver.get_master()
    else:
        tpu_grpc_url = None

    # Set the configuration for the TPU
    config = tpu_config.RunConfig(
        master=tpu_grpc_url,
        model_dir=FLAGS.model_dir)

    # Create the TPUEstimator
    test_estimator = tpu_estimator.TPUEstimator(
            use_tpu=FLAGS.use_tpu,
            model_fn=test_model_fn,
            config=config,
            train_batch_size=1024)

    # Train the estimator for 10 steps
    test_estimator.train(input_fn, max_steps=10)

def input_fn(params):
    # Generate a random dataset of the correct shape
    data = np.random.rand(1024, 10, 10).astype(np.float32)
    label = np.random.rand(1024,10).astype(np.float32)

    # Repeat and batch
    rand_dataset = tf.data.Dataset.from_tensor_slices((data, label)).repeat()
    rand_dataset = rand_dataset.apply(tf.contrib.data.batch_and_drop_remainder(params['batch_size']))

    # Make input_fn for the TPUEstimator train step
    rand_dataset_fn = rand_dataset.make_one_shot_iterator().get_next()
    return rand_dataset_fn

def test_model_fn(features, labels, mode, params):
    ###################################################################
    # The Keras LSTM layer that causes an error unless it is unrolled #
    ###################################################################
    predictions = tf.keras.layers.LSTM(10, unroll=FLAGS.unroll_lstm)(features)

    # Create ops for the TPUEstimatorSpec
    loss = tf.losses.mean_squared_error(labels=labels, predictions=predictions)
    optimizer = tf.train.GradientDescentOptimizer(0.001)
    if FLAGS.use_tpu:
        optimizer = tpu_optimizer.CrossShardOptimizer(optimizer)
    global_step = tf.train.get_global_step()
    train_op = optimizer.minimize(loss, global_step)

    # Return the TPUEstimatorSpec
    return tpu_estimator.TPUEstimatorSpec(
        mode=mode,
        loss=loss,
        train_op=train_op)

if __name__ == '__main__':
    # Do the thing
    print('main wrapper')
    tf.logging.set_verbosity(tf.logging.INFO)
    tf.app.run()
```


Error on TPU with unroll_loop set to False, and sanitized log file:
```
$ python keras_lstm_test.py --model_dir=gs://my_bucket/keras_lstm_test --tpu_name=tpu-name --unroll_lstm=False
WARNING: Logging before flag parsing goes to stderr.
W0329 19:54:49.412791 140278551017216 tf_logging.py:126] From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Use the retry module or similar alternatives.
main wrapper
W0329 19:54:49.621851 140278551017216 __init__.py:44] file_cache is unavailable when using oauth2client >= 4.0.0
Traceback (most recent call last):
  File ""/usr/local/lib/python2.7/dist-packages/googleapiclient/discovery_cache/__init__.py"", line 41, in autodetect
    from . import file_cache
  File ""/usr/local/lib/python2.7/dist-packages/googleapiclient/discovery_cache/file_cache.py"", line 41, in <module>
    'file_cache is unavailable when using oauth2client >= 4.0.0')
ImportError: file_cache is unavailable when using oauth2client >= 4.0.0
2018-03-29 19:54:49.659244: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-03-29 19:54:49.662161: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job local -> {0 -> localhost:45589}
2018-03-29 19:54:49.663623: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:333] Started server with target: grpc://localhost:45589
W0329 19:54:49.753117 140278551017216 tf_logging.py:126] Estimator's model_fn (<function test_model_fn at 0x7f94eca3f7d0>) includes params argument, but params are not passed to Estimator.
I0329 19:54:49.753689 140278551017216 tf_logging.py:116] Using config: {'_tpu_config': TPUConfig(iterations_per_loop=2, num_shards=None, computation_shape=None, per_host_input_for_training=True, tpu_job_name=None, initial_infeed_sleep_secs=None), '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f94eca3d710>, '_cluster': None, '_model_dir': 'gs://my_bucket/keras_lstm_test', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_master': u'grpc://10.240.1.2:8470', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': u'grpc://10.240.1.2:8470', '_service': None, '_save_summary_steps': 100, '_num_ps_replicas': 0}
I0329 19:54:49.827284 140278551017216 tf_logging.py:116] Querying Tensorflow master (grpc://10.240.1.2:8470) for TPU system metadata.
2018-03-29 19:54:49.828047: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:351] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
I0329 19:54:49.831892 140278551017216 tf_logging.py:116] Found TPU system:
I0329 19:54:49.832133 140278551017216 tf_logging.py:116] *** Num TPU Cores: 8
I0329 19:54:49.832345 140278551017216 tf_logging.py:116] *** Num TPU Workers: 1
I0329 19:54:49.832411 140278551017216 tf_logging.py:116] *** Num TPU Cores Per Worker: 8
I0329 19:54:49.832514 140278551017216 tf_logging.py:116] *** Available Devices: [_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184)]
I0329 19:54:49.845520 140278551017216 tf_logging.py:116] Calling model_fn.
Traceback (most recent call last):
  File ""keras_lstm_test.py"", line 99, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 126, in run
    _sys.exit(main(argv))
  File ""keras_lstm_test.py"", line 60, in main
    test_estimator.train(input_fn, max_steps=10)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 355, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 824, in _train_model
    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 805, in _call_model_fn
    model_fn_results = self._model_fn(features=features, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py"", line 1827, in _model_fn
    _train_on_tpu_system(ctx, model_fn_wrapper, dequeue_fn))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py"", line 2016, in _train_on_tpu_system
    device_assignment=ctx.device_assignment)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu.py"", line 491, in shard
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu.py"", line 323, in replicate
    outputs = computation(*computation_inputs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py"", line 2009, in multi_tpu_train_steps_on_single_shard
    name=b'loop')
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/training_loop.py"", line 207, in repeat
    cond, body_wrapper, inputs=inputs, infeed_queue=infeed_queue, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/training_loop.py"", line 169, in while_loop
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 3202, in while_loop
    result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 2940, in BuildLoop
    pred, body, original_loop_vars, loop_vars, shape_invariants)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 2877, in _BuildLoop
    body_result = body(*packed_vars_for_body)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/training_loop.py"", line 120, in body_wrapper
    outputs = body(*(inputs + dequeue_ops))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/training_loop.py"", line 203, in body_wrapper
    return [i + 1] + _convert_to_list(body(*args))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py"", line 1076, in train_step
    self._call_model_fn(features, labels))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py"", line 1230, in _call_model_fn
    estimator_spec = self._model_fn(features=features, **kwargs)
  File ""keras_lstm_test.py"", line 87, in test_model_fn
    train_op = optimizer.minimize(loss, global_step)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py"", line 399, in minimize
    grad_loss=grad_loss)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_optimizer.py"", line 85, in compute_gradients
    return self._opt.compute_gradients(loss, var_list=var_list, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py"", line 492, in compute_gradients
    colocate_gradients_with_ops=colocate_gradients_with_ops)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py"", line 488, in gradients
    gate_gradients, aggregation_method, stop_gradients)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py"", line 625, in _GradientsHelper
    lambda: grad_fn(op, *out_grads))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py"", line 379, in _MaybeCompile
    return grad_fn()  # Exit early
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py"", line 625, in <lambda>
    lambda: grad_fn(op, *out_grads))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/tensor_array_grad.py"", line 131, in _TensorArrayWriteGrad
    grad = g.read(index)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/tensor_array_ops.py"", line 861, in read
    return self._implementation.read(index, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/tensor_array_ops.py"", line 260, in read
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_data_flow_ops.py"", line 6419, in tensor_array_read_v3
    dtype=dtype, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 3290, in create_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1696, in __init__
    self._control_flow_post_processing()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1707, in _control_flow_post_processing
    self._control_flow_context.AddOp(self)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 2429, in AddOp
    self._AddOpInternal(op)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 2450, in _AddOpInternal
    real_x = self.AddValue(x)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 2382, in AddValue
    real_val = grad_ctxt.grad_state.GetRealValue(val)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 1152, in GetRealValue
    history_value = cur_grad_state.AddForwardAccumulator(cur_value)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 1017, in AddForwardAccumulator
    value, self.forward_context)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 752, in GetMaxSizeFromNestedMaximumIterations
    ""the tf.while_loop call ('%s')."" % (value_name, while_ctxt.name))
ValueError: Cannot create a gradient accumulator for tensor 'TPUReplicate/loop/lstm/while/Identity:0' inside XLA while_loop because maximum_iterations was not passed to the tf.while_loop call ('TPUReplicate/loop/lstm/while/while_context').
```


Working as expected on TPU with unroll_lstm set to True:
```
$ python keras_lstm_test.py --model_dir=gs://my_bucket/keras_lstm_test --tpu_name=tpu-name --unroll_lstm=True
WARNING: Logging before flag parsing goes to stderr.
W0329 19:54:56.462137 140718335936256 tf_logging.py:126] From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Use the retry module or similar alternatives.
main wrapper
W0329 19:54:56.665755 140718335936256 __init__.py:44] file_cache is unavailable when using oauth2client >= 4.0.0
Traceback (most recent call last):
  File ""/usr/local/lib/python2.7/dist-packages/googleapiclient/discovery_cache/__init__.py"", line 41, in autodetect
    from . import file_cache
  File ""/usr/local/lib/python2.7/dist-packages/googleapiclient/discovery_cache/file_cache.py"", line 41, in <module>
    'file_cache is unavailable when using oauth2client >= 4.0.0')
ImportError: file_cache is unavailable when using oauth2client >= 4.0.0
2018-03-29 19:54:56.704991: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-03-29 19:54:56.707871: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job local -> {0 -> localhost:42697}
2018-03-29 19:54:56.709444: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:333] Started server with target: grpc://localhost:42697
W0329 19:54:56.802102 140718335936256 tf_logging.py:126] Estimator's model_fn (<function test_model_fn at 0x7ffb51dff7d0>) includes params argument, but params are not passed to Estimator.
I0329 19:54:56.802637 140718335936256 tf_logging.py:116] Using config: {'_tpu_config': TPUConfig(iterations_per_loop=2, num_shards=None, computation_shape=None, per_host_input_for_training=True, tpu_job_name=None, initial_infeed_sleep_secs=None), '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ffb51dfdcd0>, '_cluster': None, '_model_dir': 'gs://my_bucket/keras_lstm_test', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_master': u'grpc://10.240.1.2:8470', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': u'grpc://10.240.1.2:8470', '_service': None, '_save_summary_steps': 100, '_num_ps_replicas': 0}
I0329 19:54:56.876996 140718335936256 tf_logging.py:116] Querying Tensorflow master (grpc://10.240.1.2:8470) for TPU system metadata.
2018-03-29 19:54:56.877690: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:351] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
I0329 19:54:56.881433 140718335936256 tf_logging.py:116] Found TPU system:
I0329 19:54:56.881619 140718335936256 tf_logging.py:116] *** Num TPU Cores: 8
I0329 19:54:56.881828 140718335936256 tf_logging.py:116] *** Num TPU Workers: 1
I0329 19:54:56.881892 140718335936256 tf_logging.py:116] *** Num TPU Cores Per Worker: 8
I0329 19:54:56.881998 140718335936256 tf_logging.py:116] *** Available Devices: [_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184)]
I0329 19:54:56.894473 140718335936256 tf_logging.py:116] Calling model_fn.
I0329 19:55:00.045663 140718335936256 tf_logging.py:116] Done calling model_fn.
I0329 19:55:00.046016 140718335936256 tf_logging.py:116] Create CheckpointSaverHook.
I0329 19:55:01.532725 140718335936256 tf_logging.py:116] TPU job name tpu_worker
I0329 19:55:01.588900 140718335936256 tf_logging.py:116] Graph was finalized.
I0329 19:55:02.225465 140718335936256 tf_logging.py:116] Running local_init_op.
I0329 19:55:02.271645 140718335936256 tf_logging.py:116] Done running local_init_op.
I0329 19:55:02.415777 140718335936256 tf_logging.py:116] Init TPU system
I0329 19:55:07.818669 140718335936256 tf_logging.py:116] Start infeed thread controller
I0329 19:55:07.819324 140713782138624 tf_logging.py:116] Starting infeed thread controller.
I0329 19:55:07.819504 140718335936256 tf_logging.py:116] Start outfeed thread controller
I0329 19:55:07.820395 140713773745920 tf_logging.py:116] Starting outfeed thread controller.
I0329 19:55:10.587852 140718335936256 tf_logging.py:116] Enqueue next (2) batch(es) of data to infeed.
I0329 19:55:10.588713 140718335936256 tf_logging.py:116] Dequeue next (2) batch(es) of data from outfeed.
I0329 19:55:12.060930 140718335936256 tf_logging.py:116] Saving checkpoints for 2 into gs://my_bucket/keras_lstm_test/model.ckpt.
I0329 19:55:15.523288 140718335936256 tf_logging.py:116] loss = 0.4525105, step = 0
I0329 19:55:15.525207 140718335936256 tf_logging.py:116] loss = 0.4525105, step = 0
I0329 19:55:15.527029 140718335936256 tf_logging.py:116] Enqueue next (2) batch(es) of data to infeed.
I0329 19:55:15.527189 140718335936256 tf_logging.py:116] Dequeue next (2) batch(es) of data from outfeed.
I0329 19:55:15.618277 140718335936256 tf_logging.py:116] Enqueue next (2) batch(es) of data to infeed.
I0329 19:55:15.618545 140718335936256 tf_logging.py:116] Dequeue next (2) batch(es) of data from outfeed.
I0329 19:55:15.628783 140718335936256 tf_logging.py:116] Enqueue next (2) batch(es) of data to infeed.
I0329 19:55:15.629064 140718335936256 tf_logging.py:116] Dequeue next (2) batch(es) of data from outfeed.
I0329 19:55:15.640600 140718335936256 tf_logging.py:116] Enqueue next (2) batch(es) of data to infeed.
I0329 19:55:15.640825 140718335936256 tf_logging.py:116] Dequeue next (2) batch(es) of data from outfeed.
I0329 19:55:15.649879 140718335936256 tf_logging.py:116] Saving checkpoints for 10 into gs://my_bucket/keras_lstm_test/model.ckpt.
I0329 19:55:19.049213 140718335936256 tf_logging.py:116] Stop infeed thread controller
I0329 19:55:19.049483 140718335936256 tf_logging.py:116] Shutting down InfeedController thread.
I0329 19:55:19.049849 140713782138624 tf_logging.py:116] InfeedController received shutdown signal, stopping.
I0329 19:55:19.050069 140713782138624 tf_logging.py:116] Infeed thread finished, shutting down.
I0329 19:55:19.050215 140718335936256 tf_logging.py:116] Stop output thread controller
I0329 19:55:19.050323 140718335936256 tf_logging.py:116] Shutting down OutfeedController thread.
I0329 19:55:19.050463 140713773745920 tf_logging.py:116] OutfeedController received shutdown signal, stopping.
I0329 19:55:19.050602 140713773745920 tf_logging.py:116] Outfeed thread finished, shutting down.
I0329 19:55:19.050734 140718335936256 tf_logging.py:116] Shutdown TPU system.
I0329 19:55:19.303575 140718335936256 tf_logging.py:116] Loss for final step: 0.45125633.
```


Working as expected with unroll_loop set to either True or False on CPU:
```
$ python keras_lstm_test.py --model_dir=gs://my_bucket/keras_lstm_test --use_tpu=False --unroll_lstm=False
WARNING: Logging before flag parsing goes to stderr.
W0329 19:55:58.036350 139650416416512 tf_logging.py:126] From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Use the retry module or similar alternatives.
main wrapper
W0329 19:55:58.224196 139650416416512 tf_logging.py:126] Estimator's model_fn (<function test_model_fn at 0x7f02ace3f7d0>) includes params argument, but params are not passed to Estimator.
I0329 19:55:58.224781 139650416416512 tf_logging.py:116] Using config: {'_tpu_config': TPUConfig(iterations_per_loop=2, num_shards=None, computation_shape=None, per_host_input_for_training=True, tpu_job_name=None, initial_infeed_sleep_secs=None), '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f02ace3d590>, '_cluster': None, '_model_dir': 'gs://my_bucket/keras_lstm_test', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': '', '_service': None, '_save_summary_steps': 100, '_num_ps_replicas': 0}
I0329 19:55:58.333888 139650416416512 tf_logging.py:116] Calling model_fn.
I0329 19:55:58.334151 139650416416512 tf_logging.py:116] Running train on CPU
I0329 19:55:58.917757 139650416416512 tf_logging.py:116] Done calling model_fn.
I0329 19:55:58.919229 139650416416512 tf_logging.py:116] Create CheckpointSaverHook.
I0329 19:56:00.058123 139650416416512 tf_logging.py:116] Graph was finalized.
2018-03-29 19:56:00.058509: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
I0329 19:56:00.216192 139650416416512 tf_logging.py:116] Running local_init_op.
I0329 19:56:00.223177 139650416416512 tf_logging.py:116] Done running local_init_op.
I0329 19:56:01.895720 139650416416512 tf_logging.py:116] Saving checkpoints for 1 into gs://my_bucket/keras_lstm_test/model.ckpt.
I0329 19:56:04.683254 139650416416512 tf_logging.py:116] loss = 0.4141244, step = 0
I0329 19:56:05.080931 139650416416512 tf_logging.py:116] Saving checkpoints for 10 into gs://my_bucket/keras_lstm_test/model.ckpt.
I0329 19:56:08.176239 139650416416512 tf_logging.py:116] Loss for final step: 0.41163954.
```
```
$ python keras_lstm_test.py --model_dir=gs://my_bucket/keras_lstm_test --use_tpu=False --unroll_lstm=True
WARNING: Logging before flag parsing goes to stderr.
W0329 19:56:34.716190 140417782937344 tf_logging.py:126] From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Use the retry module or similar alternatives.
main wrapper
W0329 19:56:34.914796 140417782937344 tf_logging.py:126] Estimator's model_fn (<function test_model_fn at 0x7fb55784e7d0>) includes params argument, but params are not passed to Estimator.
I0329 19:56:34.915416 140417782937344 tf_logging.py:116] Using config: {'_tpu_config': TPUConfig(iterations_per_loop=2, num_shards=None, computation_shape=None, per_host_input_for_training=True, tpu_job_name=None, initial_infeed_sleep_secs=None), '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb55784c590>, '_cluster': None, '_model_dir': 'gs://my_bucket/keras_lstm_test', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': '', '_service': None, '_save_summary_steps': 100, '_num_ps_replicas': 0}
I0329 19:56:35.047240 140417782937344 tf_logging.py:116] Calling model_fn.
I0329 19:56:35.047514 140417782937344 tf_logging.py:116] Running train on CPU
I0329 19:56:37.489144 140417782937344 tf_logging.py:116] Done calling model_fn.
I0329 19:56:37.490300 140417782937344 tf_logging.py:116] Create CheckpointSaverHook.
I0329 19:56:39.153974 140417782937344 tf_logging.py:116] Graph was finalized.
2018-03-29 19:56:39.154479: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
I0329 19:56:39.485604 140417782937344 tf_logging.py:116] Running local_init_op.
I0329 19:56:39.513873 140417782937344 tf_logging.py:116] Done running local_init_op.
I0329 19:56:43.631685 140417782937344 tf_logging.py:116] Saving checkpoints for 1 into gs://my_bucket/keras_lstm_test/model.ckpt.
I0329 19:56:47.166574 140417782937344 tf_logging.py:116] loss = 0.41451082, step = 0
I0329 19:56:48.535309 140417782937344 tf_logging.py:116] Saving checkpoints for 10 into gs://my_bucket/keras_lstm_test/model.ckpt.
I0329 19:56:52.381931 140417782937344 tf_logging.py:116] Loss for final step: 0.41207257.
```
"
18101,Issue in understanding tf.record and tf-slim. (I couldn't find Documentation),"I am trying to fine-tune inceptionv3 model using slim tensorflow library. 
I tried to read source code (no proper documentation) and figured out few things and I am able to fine-tune it and save the checkpoint. However, I am unable to understand certain things while writing the code for it.   Here are the steps I followed 

 1. I created a tf.record for my training data which is fine, now I am reading the data using the below code. 
[
  ```
  import tensorflow as tf
    import tensorflow.contrib.slim.nets as nets
    import tensorflow.contrib.slim as slim
    import matplotlib.pyplot as plt
    import numpy as np
    
    # get the data and labels here
    
    data_path = '/home/sfarkya/nvidia_challenge/datasets/detrac/train1.tfrecords'
    
    # Training setting
    num_epochs = 100
    initial_learning_rate = 0.0002
    learning_rate_decay_factor = 0.7
    num_epochs_before_decay = 5
    num_classes = 5980
    
    # load the checkpoint
    model_path = '/home/sfarkya/nvidia_challenge/datasets/detrac/inception_v3.ckpt'
    
    # log directory
    log_dir = '/home/sfarkya/nvidia_challenge/datasets/detrac/fine_tuned_model'
    
    with tf.Session() as sess:
        feature = {'train/image': tf.FixedLenFeature([], tf.string),
                   'train/label': tf.FixedLenFeature([], tf.int64)}
    
        # Create a list of filenames and pass it to a queue
        filename_queue = tf.train.string_input_producer([data_path], num_epochs=1)
    
        # Define a reader and read the next record
        reader = tf.TFRecordReader()
        _, serialized_example = reader.read(filename_queue)
    
        # Decode the record read by the reader
        features = tf.parse_single_example(serialized_example, features=feature)
    
        # Convert the image data from string back to the numbers
        image = tf.decode_raw(features['train/image'], tf.float32)
    
        # Cast label data into int32
        label = tf.cast(features['train/label'], tf.int32)
    
        # Reshape image data into the original shape
        image = tf.reshape(image, [128, 128, 3])
    
        # Creates batches by randomly shuffling tensors
        images, labels = tf.train.shuffle_batch([image, label], batch_size=64, capacity=128, num_threads=2,
                                                min_after_dequeue=64)](url)
```

Now I am finetuning the model using slim and this is the code. 

      init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())
        sess.run(init_op)
    
        # Create a coordinator and run all QueueRunner objects
        coord = tf.train.Coordinator()
        threads = tf.train.start_queue_runners(coord=coord)
    
        # load model
    
        # load the inception model from the slim library - we are using inception v3
        #inputL = tf.placeholder(tf.float32, (64, 128, 128, 3))
    
        img, lbl = sess.run([images, labels])
        one_hot_labels = slim.one_hot_encoding(lbl, num_classes)
    
        with slim.arg_scope(slim.nets.inception.inception_v3_arg_scope()):
            logits, inceptionv3 = nets.inception.inception_v3(inputs=img, num_classes=5980, is_training=True,
                                                              dropout_keep_prob=.6)
    
        # Restore convolutional layers:
    
        variables_to_restore = slim.get_variables_to_restore(exclude=['InceptionV3/Logits', 'InceptionV3/AuxLogits'])
        init_fn = slim.assign_from_checkpoint_fn(model_path, variables_to_restore)
    
        # loss function
        loss = tf.losses.softmax_cross_entropy(onehot_labels=one_hot_labels, logits = logits)
        total_loss = tf.losses.get_total_loss()
    
        # train operation
        train_op = slim.learning.create_train_op(total_loss + loss, optimizer= tf.train.AdamOptimizer(learning_rate=1e-4))
    
        print('Im here')
        # Start training.
        slim.learning.train(train_op, log_dir, init_fn=init_fn, save_interval_secs=20, number_of_steps= 10)

Now I have few questions about the code, which I am quite unable to figure out. Once, the code reaches **slim.learning.train** I don't see anything printing however, it's training, I can see in the log. Now, 
1. How do I give the number of epochs to the code? Right now it's running step by step with each step has batch_size = 64.  
2. How do I make sure that in the code **tf.train.shuffle_batch** I am not repeating my images and I am training over the whole dataset? 
3. How can I print the loss values while it's training?
4. If I create a validation set then how can I switch betweem training the model and validation? 

Thanks for the help!  "
18099,Luong attention fails when used with scale=True and dtype=tf.float16,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: b'v1.6.0-rc1-1857-g67e2efa' 1.6.0
- **Python version**: 3.5.2
- **Bazel version (if compiling from source)**: 0.10.0
- **GCC/Compiler version (if compiling from source)**: 5.4.0
- **CUDA/cuDNN version**: 9.0/7.0
- **GPU model and memory**: not relevant
- **Exact command to reproduce**:

```
import tensorflow as tf
dtype = tf.float16

with tf.variable_scope(""name"", dtype=dtype):
    cell = tf.nn.rnn_cell.LSTMCell(128)

    encoder_outputs = tf.placeholder(dtype, shape=[64, None, 256])
    input_lengths = tf.placeholder(tf.int32, shape=[64])
    tgt_lengths = tf.placeholder(tf.int32, shape=[64])
    input_vectors = tf.placeholder(dtype, shape=[64, None, 128])

    attention_mechanism = tf.contrib.seq2seq.LuongAttention(
        num_units=128,
        memory=encoder_outputs,
        scale=True,
        memory_sequence_length=input_lengths,
        probability_fn=tf.nn.softmax,
        dtype=dtype,
    )
    attn_cell = tf.contrib.seq2seq.AttentionWrapper(cell, attention_mechanism)

    helper = tf.contrib.seq2seq.TrainingHelper(
        inputs=input_vectors,
        sequence_length=tgt_lengths,
    )

    decoder = tf.contrib.seq2seq.BasicDecoder(
        cell=attn_cell,
        helper=helper,
        initial_state=attn_cell.zero_state(64, dtype),
    )

    tf.contrib.seq2seq.dynamic_decode(decoder=decoder)
```

### Describe the problem
Luong attention fails when using with scale=True and dtype=tf.float16. Changing lines 341-342 of attention_wrapper.py to:
```
g = variable_scope.get_variable(
    ""attention_g"", dtype=dtype, shape=(),
    initializer=init_ops.ones_initializer(),
)
```
seems to solve the problem.

### Source code / logs
Traceback:

```
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-1-4dec9cd8e3b2> in <module>()
     31     )
     32 
---> 33     tf.contrib.seq2seq.dynamic_decode(decoder=decoder)

~/Documents/venv/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py in dynamic_decode(decoder, output_time_major, impute_finished, maximum_iterations, parallel_iterations, swap_memory, scope)
    307         ],
    308         parallel_iterations=parallel_iterations,
--> 309         swap_memory=swap_memory)
    310 
    311     final_outputs_ta = res[1]

~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py in while_loop(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations)
   3203     if loop_context.outer_context is None:
   3204       ops.add_to_collection(ops.GraphKeys.WHILE_CONTEXT, loop_context)
-> 3205     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)
   3206     if maximum_iterations is not None:
   3207       return result[1]

~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py in BuildLoop(self, pred, body, loop_vars, shape_invariants)
   2941       with ops.get_default_graph()._lock:  # pylint: disable=protected-access
   2942         original_body_result, exit_vars = self._BuildLoop(
-> 2943             pred, body, original_loop_vars, loop_vars, shape_invariants)
   2944     finally:
   2945       self.Exit()

~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py in _BuildLoop(self, pred, body, original_loop_vars, loop_vars, shape_invariants)
   2878         flat_sequence=vars_for_body_with_tensor_arrays)
   2879     pre_summaries = ops.get_collection(ops.GraphKeys._SUMMARY_COLLECTION)  # pylint: disable=protected-access
-> 2880     body_result = body(*packed_vars_for_body)
   2881     post_summaries = ops.get_collection(ops.GraphKeys._SUMMARY_COLLECTION)  # pylint: disable=protected-access
   2882     if not nest.is_sequence(body_result):

~/Documents/venv/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py in body(time, outputs_ta, state, inputs, finished, sequence_lengths)
    252       """"""
    253       (next_outputs, decoder_state, next_inputs,
--> 254        decoder_finished) = decoder.step(time, inputs, state)
    255       if decoder.tracks_own_finished:
    256         next_finished = decoder_finished

~/Documents/venv/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/basic_decoder.py in step(self, time, inputs, state, name)
    135     """"""
    136     with ops.name_scope(name, ""BasicDecoderStep"", (time, inputs, state)):
--> 137       cell_outputs, cell_state = self._cell(inputs, state)
    138       if self._output_layer is not None:
    139         cell_outputs = self._output_layer(cell_outputs)

~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/ops/rnn_cell_impl.py in __call__(self, inputs, state, scope)
    230         setattr(self, scope_attrname, scope)
    231       with scope:
--> 232         return super(RNNCell, self).__call__(inputs, state)
    233 
    234   def _rnn_get_variable(self, getter, *args, **kwargs):

~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/layers/base.py in __call__(self, inputs, *args, **kwargs)
    712 
    713         if not in_deferred_mode:
--> 714           outputs = self.call(inputs, *args, **kwargs)
    715           if outputs is None:
    716             raise ValueError('A layer\'s `call` method should return a Tensor '

~/Documents/venv/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py in call(self, inputs, state)
   1409       attention, alignments, next_attention_state = _compute_attention(
   1410           attention_mechanism, cell_output, previous_attention_state[i],
-> 1411           self._attention_layers[i] if self._attention_layers else None)
   1412       alignment_history = previous_alignment_history[i].write(
   1413           state.time, alignments) if self._alignment_history else ()

~/Documents/venv/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py in _compute_attention(attention_mechanism, cell_output, attention_state, attention_layer)
   1046   """"""Computes the attention and alignments for a given attention_mechanism.""""""
   1047   alignments, next_attention_state = attention_mechanism(
-> 1048       cell_output, state=attention_state)
   1049 
   1050   # Reshape from [batch_size, memory_time] to [batch_size, 1, memory_time]

~/Documents/venv/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py in __call__(self, query, state)
    427     """"""
    428     with variable_scope.variable_scope(None, ""luong_attention"", [query]):
--> 429       score = _luong_score(query, self._keys, self._scale)
    430     alignments = self._probability_fn(score, state)
    431     next_state = alignments

~/Documents/venv/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py in _luong_score(query, keys, scale)
    340     # Scalar used in weight scaling
    341     g = variable_scope.get_variable(
--> 342         ""attention_g"", dtype=dtype, initializer=1.)
    343     score = g * score
    344   return score

~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py in get_variable(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)
   1315       partitioner=partitioner, validate_shape=validate_shape,
   1316       use_resource=use_resource, custom_getter=custom_getter,
-> 1317       constraint=constraint)
   1318 get_variable_or_local_docstring = (
   1319     """"""%s

~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py in get_variable(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)
   1064         if init_dtype != dtype:
   1065           raise ValueError(""Initializer type '%s' and explicit dtype '%s' ""
-> 1066                            ""don't match."" % (init_dtype, dtype))
   1067       if initializer is None:
   1068         initializer = self._initializer

ValueError: Initializer type '<dtype: 'float32'>' and explicit dtype '<dtype: 'float16'>' don't match.
```"
18096,Feature Request: Support for configuring deterministic options of cudNN Conv routines,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.6
- **Python version**: 3.6
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: 7.1
- **GPU model and memory**: GPU
- **Exact command to reproduce**: N/A

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem

http://docs.nvidia.com/deeplearning/sdk/cudnn-developer-guide/index.html#reproducibility
cudNN documentation indicates that there are several routine options for `cudnnConvolutionBackwardFilter`, `cudnnConvolutionBackwardData`, and `cudnnPoolingBackward` operations. They default to non-deterministic atomic operations, but have the option to run in a deterministic mode. To achieve determinism on TensorFlow GPU, I would like to be able to make this performance trade-off, but currently cannot find a way to enable these options in TensorFlow.

Can a user-facing option be added, perhaps in `tf.ConfigProto`, to configurate these cudNN routines? This could be configured in a similar way as `inter_op_parallelism_threads` and `intra_op_parallelism_threads` are set to 1 to achieve determinism on CPU (https://stackoverflow.com/questions/41233635/meaning-of-inter-op-parallelism-threads-and-intra-op-parallelism-threads)

### Source code / logs

N/A"
18094,"`tf.keras.estimator._create_ordered_io` casts everything to floatx, which breaks non-floatx inputs","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Debian 3.16.36
- **TensorFlow installed from (source or binary)**: Installed via pip
- **TensorFlow version (use command below)**: `('v1.6.0-0-gd2e24b6039', '1.6.0')`
- **Python version**: 2.7.9
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: n/a
- **GPU model and memory**: n/a
- **Exact command to reproduce**: Requires significant code, let me know if necessary

### Describe the problem

This is kind of a simple issue with using `Keras` models as Tensorflow Estimators. I unfortunately need to do this awkward conversion in order to use SageMaker, which is even more awkwardly behind by two versions of Tensorflow. Which is fun.

Basically, I have a `Keras` model that expects a `tf.string` input `dtype`, which is then passed through to a Lookup layer for some text embeddings. This works fine as a Keras model and works fine if I extract the input layers myself and connect them into an Estimator. However, if I go to create an estimator from the model using `model_to_estimator` I run into this code path: https://github.com/tensorflow/tensorflow/blob/r1.6/tensorflow/python/keras/_impl/keras/estimator.py#L80

This conversion then causes the model to break further down the line. I'm not sure why this float cast occurs, but this commit https://github.com/tensorflow/tensorflow/commit/4c86ece040cb96ea689f5c0d084b6959274eab91#diff-69effda952f96b36c8015cc1a3462d65 seems to imply that Keras models are meant to only take floatx input, which doesn't really seem right.

Would not doing this cast break anything? If so, is there a way to use a non-float32 input with Keras models that need to be converted to Estimators?

Thanks!

### Source code / logs

Here's the exact traceback for the issue:

```
/home/u1/zach/proj/dataplayground2/local/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument 
of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.          
  from ._conv import register_converters as _register_converters                                                                           
WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp6Wogzk                                                               
2018-03-29 14:12:41.586292: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow       
binary was not compiled to use: AVX2 FMA                                                                                                   
WARNING:tensorflow:Output ""final_representation"" missing from loss dictionary. We assume this was done on purpose, and we will not be      
expecting any data to be passed to ""final_representation"" during training.                                                                 
WARNING:tensorflow:Output ""oov_code"" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any    
data to be passed to ""oov_code"" during training.                                                                                           
Testing common_estimator_fns.py locally                                                                                                    
Making estimator                                                                                                                           
Model dir: /tmp/tmp6Wogzk                                                                                                                  
Training estimator                                                                                                                         
float64                                                                                                                                    
Tensor(""random_shuffle_queue_DequeueMany:1"", shape=(32, 1), dtype=string, device=/device:CPU:0)                                            
Traceback (most recent call last):                                                                                                         
  File ""common_estimator_fns.py"", line 423, in <module>                                                                                    
    hooks=[tf_debug.LocalCLIDebugHook()])                                                                                                  
  File ""/home/u1/zach/proj/dataplayground2/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py"", line 352, in train 
    loss = self._train_model(input_fn, hooks, saving_listeners)                                                                            
  File ""/home/u1/zach/proj/dataplayground2/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py"", line 812, in       
_train_model                                                                                                                               
    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)                                                                            
  File ""/home/u1/zach/proj/dataplayground2/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py"", line 793, in       
_call_model_fn                                                                                                                             
    model_fn_results = self._model_fn(features=features, **kwargs)                                                                         
  File ""common_estimator_fns.py"", line 381, in model_fn                                                                                    
    return keras_model_fn(features, labels, mode)                                                                                          
  File ""/home/u1/zach/proj/dataplayground2/local/lib/python2.7/site-packages/tensorflow/python/keras/_impl/keras/estimator.py"", line 160,  
in model_fn                                                                                                                                
    labels)                                                                                                                                
  File ""/home/u1/zach/proj/dataplayground2/local/lib/python2.7/site-packages/tensorflow/python/keras/_impl/keras/estimator.py"", line 109,  
in _clone_and_build_model                                                                                                                  
    model = models.clone_model(keras_model, input_tensors=input_tensors)                                                                   
  File ""/home/u1/zach/proj/dataplayground2/local/lib/python2.7/site-packages/tensorflow/python/keras/_impl/keras/models.py"", line 1557, in 
clone_model                                                                                                                                
    return _clone_functional_model(model, input_tensors=input_tensors)                                                                     
  File ""/home/u1/zach/proj/dataplayground2/local/lib/python2.7/site-packages/tensorflow/python/keras/_impl/keras/models.py"", line 1451, in 
_clone_functional_model                                                                                                                    
    output_tensors = topology._to_list(layer(computed_tensor, **kwargs))                                                                   
  File ""/home/u1/zach/proj/dataplayground2/local/lib/python2.7/site-packages/tensorflow/python/keras/_impl/keras/engine/topology.py"", line 
258, in __call__                                                                                                                           
    output = super(Layer, self).__call__(inputs, **kwargs)                                                                                 
  File ""/home/u1/zach/proj/dataplayground2/local/lib/python2.7/site-packages/tensorflow/python/layers/base.py"", line 673, in __call__      
    self._assert_input_compatibility(inputs)                                                                                               
  File ""/home/u1/zach/proj/dataplayground2/local/lib/python2.7/site-packages/tensorflow/python/layers/base.py"", line 1204, in              
_assert_input_compatibility                                                                                                                
    ', found dtype=' + str(x.dtype))                                                                                                       
ValueError: Input 0 of layer lookedup is incompatible with the layer: expected dtype=<dtype: 'string'>, found dtype=<dtype: 'float32'>     
```

I can provide code if absolutely necessary, but it'd take some work to get to a minimal reproduction."
18092,Distributed TensorFlow got error message with the MPI collective Ops units test,"Have I written custom code:  None
OS Platform and Distribution: Linux Ubuntu 16.04
Open MPI version: 3.0.0
TensorFlow installed from: b'v1.7.0-rc1-816-g1712002ad0' 1.7.0-rc1
Bazel version: 0.11.1 
Python version: 3.5.2
GCC version: 6.3.0
CUDA/cuDNN version: N/A
GPU model and memory: N/A
Exact command to reproduce: `mpirun -np 1 python mpi_allreduce_test.py` under directory `tensorflow/tensorflow/contrib/mpi_collectives`

I ran the unit test under directory `tensorflow/tensorflow/contrib/mpi_collectives` and the run command is `mpirun -np 1 python mpi_allreduce_test.py` . I got the following error message:
Could someone please help me take a look at this? Thanks!

```
WARNING:tensorflow:From /ec/fm/disks/nrv_algo_home01/langjian/.tf_17/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Use the retry module or similar alternatives.
Traceback (most recent call last):
  File ""mpi_allreduce_test.py"", line 23, in <module>
    import tensorflow.contrib.mpi_collectives as mpi
  File ""$HOME/.tf_17/lib/python3.5/site-packages/tensorflow/contrib/mpi_collectives/__init__.py"", line 128, in <module>
    from tensorflow.contrib.mpi_collectives.python.ops.mpi_ops import init
  File ""$HOME/.tf_17/lib/python3.5/site-packages/tensorflow/contrib/mpi_collectives/python/ops/mpi_ops.py"", line 29, in <module>
    resource_loader.get_path_to_datafile('_mpi_ops.so'))
  File ""$HOME/.tf_17/lib/python3.5/site-packages/tensorflow/contrib/util/loader.py"", line 55, in load_op_library
    ret = load_library.load_op_library(path)
  File ""$HOME/.tf_17/lib/python3.5/site-packages/tensorflow/python/framework/load_library.py"", line 58, in load_op_library
    lib_handle = py_tf.TF_LoadLibrary(library_filename, status)
  File ""$HOME/.tf_17/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py"", line 516, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.NotFoundError: $HOME/.tf_17/lib/python3.5/site-packages/tensorflow/contrib/mpi_collectives/python/ops/_mpi_ops.so: undefined symbol: _ZN10tensorflow7contrib15mpi_collectives7MPITypeIiEEP15ompi_datatype_tv
-------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
-------------------------------------------------------
--------------------------------------------------------------------------
mpirun detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[18657,1],0]
  Exit code:    1
--------------------------------------------------------------------------
```
"
18087,is the sytem wrong leading tensorboard No dashboards are active for the current data set.,"

### Describe the problem

 i fisrt input tensorboard --logdir='logs',then i enter ctrl+c, it shows:
![image](https://user-images.githubusercontent.com/3324257/38097184-45b93700-33a7-11e8-884d-72aaab629ce9.png)
is my system wrong?


"
18086,distributed Tensorflow using grpc is slow,"### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 14.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.6
- **Python version**:  python 3.4
- **CUDA/cuDNN version**: 8.0/6.1


### Describe the problem
Distributed Tensorflow using grpc is very slow , here is my timeline of a step 
![image](https://user-images.githubusercontent.com/33949779/38095081-2628836e-33a2-11e8-9f4c-883562bbf42f.png)
I want to know why there is a huge gap. GPU is idle for a long time, waiting for ps.

"
18085,Jsonify serialisation error for tensorflow output ,"
I created a flask client in python that returns output of tensorflow model like this: 

Result is:
```

outputs {
 key: ""output""
 value {
 dtype: DT_FLOAT
 tensor_shape {
 }
 float_val: -3.33661770821
 }
}
```
And when i tried to jsonify this output . 

> def inference():
>     ........
>     return jsonify({'result':result})

It sends error:

```
File ""/usr/lib/python2.7/json/encoder.py"", line 184, in default
       raise TypeError(repo(o) + ""is not JSON serializable"")
TypeError:outputs {
     key: ""output""
     value {
     dtype: DT_FLOAT
     tensor_shape {
     }
     float_val: -3.33661770821
     }
    }
```
How do i jsonify the above output? Any idea? This is not in dictionary too. "
18084,"ERROR: /tensorflow/third_party/mkl/BUILD:45:12: Configurable attribute ""deps"" doesn't match this configuration","### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
     Ubuntu 16.04 (ppc64le)
- **TensorFlow installed from (source or binary)**:
      Installed from source (master)
- **TensorFlow version (use command below)**:
      (master)
- **Python version**: 
     Python 2.7.5
- **Bazel version (if compiling from source)**:
       0.11.1
- **CUDA/cuDNN version**:
     NA
- **GPU model and memory**:
      NA
- **Exact command to reproduce**:
      bazel test -c opt //tensorflow/...

### Describe the problem
I have started working on TensorFlow master. The build passed successfully , however the test command is failing with below error  - 
```
ERROR: /tensorflow/third_party/mkl/BUILD:45:12: Configurable attribute ""deps"" doesn't match this configuration (would a default condition help?).
Conditions checked:
@org_tensorflow//tensorflow:darwin
@org_tensorflow//tensorflow:linux_x86_64
@org_tensorflow//tensorflow:windows
ERROR: Analysis of target '//tensorflow/core/kernels:mkl_softmax_op' failed; build aborted:

/tensorflow/third_party/mkl/BUILD:45:12: Configurable attribute ""deps"" doesn't match this configuration (would a default condition help?).
Conditions checked:
@org_tensorflow//tensorflow:darwin
@org_tensorflow//tensorflow:linux_x86_64
@org_tensorflow//tensorflow:windows
INFO: Elapsed time: 4.290s
FAILED: Build did NOT complete successfully (8 packages loaded)
ERROR: Couldn't start the build. Unable to run tests
```

Looks like need some code changes to fix this on ppc64le, I have started my analysis. Please provide if any suggestions.Thanks!"
18083,No equivalent to theano.tensor.slinalg.Eigvalsh,"Good morning,

I have been trying to reproduce DeepLDA loss function implementation in Tensorflow 
(https://github.com/VahidooX/DeepLDA/blob/master/code/objectives.py theano version).
In order to solve a gep, in theano we use T.slinalg.eigvalsh to compute eigenvalues
evals_t = T.slinalg.eigvalsh(Sb_t, St_t)

Tensorflow doesn't provide something similar and approximation are very unstable.
I tried both to solve the gep Aei = Bviei
cho = tf.cholesky(B_t + tf.eye(dim) * r ) 
inv_cho = tf.matrix_inverse(cho)
evals_t = tf.linalg.eigvalsh(inv_cho * A * tf.transpose(inv_cho)) 

evals_t =tf.linalg.eigvalsh(tf.matrix_inverse(B) * A )
If you have a solution, please tell me :)


"
18082,Android speech recognition sample averaging wrong values,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: none
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  not related to this question
- **TensorFlow installed from (source or binary)**: not related to this question
- **TensorFlow version (use command below)**: not related to this question
- **Python version**: not related to this question
- **Bazel version (if compiling from source)**: not related to this question
- **GCC/Compiler version (if compiling from source)**: not related to this question
- **CUDA/cuDNN version**: not related to this question
- **GPU model and memory**: not related to this question
- **Exact command to reproduce**: not related to this question

### Describe the problem &  Source code / logs
Please refer to this question and comments on stackoverflow: https://stackoverflow.com/questions/49269555/logging-and-deque-operation-problems-in-tensorflow-android-speech-recognition-sa

In brief, previousResults.addLast should be revised. Otherwise, it will take wrong values to average. 
"
18081,running distributed tensorflow failed after update tf from 1.0 to 1.5,"Hi TF Experts,

after I upgrade the tf from 1.0 to 1.5(cuda from 8.0 to 9.0), run the example distributed tensorflow codes failed. below are the codes, it is very simple. The log always output ""CreateSession still waiting for response from worker: /job:ps/replica:0/task:0"". the code works fine for any of my machines whose tf version is under 1.5
```
import tensorflow as tf

cluster = tf.train.ClusterSpec({""ps"": [""localhost:33562""], ""worker"": [""localhost:12563""]})

ps = tf.train.Server(cluster, job_name=""ps"", task_index=0)
worker = tf.train.Server(cluster, job_name=""worker"", task_index=0)

print(""PS: {0}"".format(ps.target))
print(""Worker: {0}"".format(worker.target))

with tf.Session(worker.target) as sess:

    W = tf.Variable(tf.zeros([784, 10]))
    b = tf.Variable(tf.zeros([10]))

    init = tf.global_variables_initializer()

    print(""RUNNING SESSION"")
    sess.run(init)
    print(""SESSION FINISHED"")
```
below are the full log:

2018-03-29 15:17:37.084856: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-03-29 15:17:38.367466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 0 with properties: 
name: Tesla M40 24GB major: 5 minor: 2 memoryClockRate(GHz): 1.112
pciBusID: 0000:04:00.0
totalMemory: 23.90GiB freeMemory: 23.78GiB
2018-03-29 15:17:38.865113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 1 with properties: 
name: Tesla M40 24GB major: 5 minor: 2 memoryClockRate(GHz): 1.112
pciBusID: 0000:05:00.0
totalMemory: 23.90GiB freeMemory: 23.78GiB
2018-03-29 15:17:39.369172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 2 with properties: 
name: Tesla M40 24GB major: 5 minor: 2 memoryClockRate(GHz): 1.112
pciBusID: 0000:08:00.0
totalMemory: 23.90GiB freeMemory: 23.78GiB
2018-03-29 15:17:39.884151: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 3 with properties: 
name: Tesla M40 24GB major: 5 minor: 2 memoryClockRate(GHz): 1.112
pciBusID: 0000:09:00.0
totalMemory: 23.90GiB freeMemory: 23.78GiB
2018-03-29 15:17:40.416114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 4 with properties: 
name: Tesla M40 24GB major: 5 minor: 2 memoryClockRate(GHz): 1.112
pciBusID: 0000:85:00.0
totalMemory: 23.90GiB freeMemory: 23.78GiB
2018-03-29 15:17:40.903122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 5 with properties: 
name: Tesla M40 24GB major: 5 minor: 2 memoryClockRate(GHz): 1.112
pciBusID: 0000:86:00.0
totalMemory: 23.90GiB freeMemory: 23.78GiB
2018-03-29 15:17:41.388600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 6 with properties: 
name: Tesla M40 24GB major: 5 minor: 2 memoryClockRate(GHz): 1.112
pciBusID: 0000:89:00.0
totalMemory: 23.90GiB freeMemory: 23.78GiB
2018-03-29 15:17:41.869760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 7 with properties: 
name: Tesla M40 24GB major: 5 minor: 2 memoryClockRate(GHz): 1.112
pciBusID: 0000:8a:00.0
totalMemory: 23.90GiB freeMemory: 23.78GiB
2018-03-29 15:17:41.875020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1227] Device peer to peer matrix
2018-03-29 15:17:41.875488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1233] DMA: 0 1 2 3 4 5 6 7 
2018-03-29 15:17:41.875509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1243] 0:   Y Y Y Y N N N N 
2018-03-29 15:17:41.875523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1243] 1:   Y Y Y Y N N N N 
2018-03-29 15:17:41.875533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1243] 2:   Y Y Y Y N N N N 
2018-03-29 15:17:41.875543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1243] 3:   Y Y Y Y N N N N 
2018-03-29 15:17:41.875553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1243] 4:   N N N N Y Y Y Y 
2018-03-29 15:17:41.875563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1243] 5:   N N N N Y Y Y Y 
2018-03-29 15:17:41.875572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1243] 6:   N N N N Y Y Y Y 
2018-03-29 15:17:41.875585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1243] 7:   N N N N Y Y Y Y 
2018-03-29 15:17:41.875614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1312] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
2018-03-29 15:17:46.028033: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:ps/replica:0/task:0/device:GPU:0 with 23084 MB memory) -> physical GPU (device: 0, name: Tesla M40 24GB, pci bus id: 0000:04:00.0, compute capability: 5.2)
2018-03-29 15:17:46.610150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:ps/replica:0/task:0/device:GPU:1 with 23082 MB memory) -> physical GPU (device: 1, name: Tesla M40 24GB, pci bus id: 0000:05:00.0, compute capability: 5.2)
2018-03-29 15:17:47.276168: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:ps/replica:0/task:0/device:GPU:2 with 23080 MB memory) -> physical GPU (device: 2, name: Tesla M40 24GB, pci bus id: 0000:08:00.0, compute capability: 5.2)
2018-03-29 15:17:48.026291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:ps/replica:0/task:0/device:GPU:3 with 23080 MB memory) -> physical GPU (device: 3, name: Tesla M40 24GB, pci bus id: 0000:09:00.0, compute capability: 5.2)
2018-03-29 15:17:49.020908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:ps/replica:0/task:0/device:GPU:4 with 23084 MB memory) -> physical GPU (device: 4, name: Tesla M40 24GB, pci bus id: 0000:85:00.0, compute capability: 5.2)
2018-03-29 15:17:49.806995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:ps/replica:0/task:0/device:GPU:5 with 23082 MB memory) -> physical GPU (device: 5, name: Tesla M40 24GB, pci bus id: 0000:86:00.0, compute capability: 5.2)
2018-03-29 15:17:50.654150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:ps/replica:0/task:0/device:GPU:6 with 23080 MB memory) -> physical GPU (device: 6, name: Tesla M40 24GB, pci bus id: 0000:89:00.0, compute capability: 5.2)
2018-03-29 15:17:51.499643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:ps/replica:0/task:0/device:GPU:7 with 23080 MB memory) -> physical GPU (device: 7, name: Tesla M40 24GB, pci bus id: 0000:8a:00.0, compute capability: 5.2)
2018-03-29 15:17:52.345019: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:33562}
2018-03-29 15:17:52.345127: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12563}
2018-03-29 15:17:52.362801: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:324] Started server with target: grpc://localhost:33562
2018-03-29 15:17:52.363232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1312] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
2018-03-29 15:17:52.363789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:worker/replica:0/task:0/device:GPU:0 with 983 MB memory) -> physical GPU (device: 0, name: Tesla M40 24GB, pci bus id: 0000:04:00.0, compute capability: 5.2)
2018-03-29 15:17:52.364275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:worker/replica:0/task:0/device:GPU:1 with 985 MB memory) -> physical GPU (device: 1, name: Tesla M40 24GB, pci bus id: 0000:05:00.0, compute capability: 5.2)
2018-03-29 15:17:52.364715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:worker/replica:0/task:0/device:GPU:2 with 987 MB memory) -> physical GPU (device: 2, name: Tesla M40 24GB, pci bus id: 0000:08:00.0, compute capability: 5.2)
2018-03-29 15:17:52.365138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:worker/replica:0/task:0/device:GPU:3 with 987 MB memory) -> physical GPU (device: 3, name: Tesla M40 24GB, pci bus id: 0000:09:00.0, compute capability: 5.2)
2018-03-29 15:17:52.366627: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:worker/replica:0/task:0/device:GPU:4 with 983 MB memory) -> physical GPU (device: 4, name: Tesla M40 24GB, pci bus id: 0000:85:00.0, compute capability: 5.2)
2018-03-29 15:17:52.367325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:worker/replica:0/task:0/device:GPU:5 with 985 MB memory) -> physical GPU (device: 5, name: Tesla M40 24GB, pci bus id: 0000:86:00.0, compute capability: 5.2)
2018-03-29 15:17:52.367962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:worker/replica:0/task:0/device:GPU:6 with 987 MB memory) -> physical GPU (device: 6, name: Tesla M40 24GB, pci bus id: 0000:89:00.0, compute capability: 5.2)
2018-03-29 15:17:52.368731: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:worker/replica:0/task:0/device:GPU:7 with 987 MB memory) -> physical GPU (device: 7, name: Tesla M40 24GB, pci bus id: 0000:8a:00.0, compute capability: 5.2)
2018-03-29 15:17:52.376139: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:33562}
2018-03-29 15:17:52.376230: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12563}
2018-03-29 15:17:52.382382: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:324] Started server with target: grpc://localhost:12563
PS: grpc://localhost:33562
Worker: grpc://localhost:12563
RUNNING SESSION
2018-03-29 15:18:02.506942: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0
2018-03-29 15:18:12.507132: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0
2018-03-29 15:18:22.507277: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0
2018-03-29 15:18:32.507427: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0
2018-03-29 15:18:42.507560: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0
"
18080,How to combine two frozen models (Tensorflow) for object detection?,I am trying to combine two frozen models (protobuffs) for object detection. The issue is one of the models is my own dataset and the other is the prebuilt model for coco dataset (just include more classes to the dataset itself). Is this possible? or is there a better approach to perform this?
18079,Can't get the dim of input when the Dataset is from generator.,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: pip
- **TensorFlow version (use command below)**: 1.6
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: 
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

### Describe the problem

When use `from_generator` way to get dataset, it can't get the output shape of it. And then pass the features of it to the layers, the layer can't get the rank of it.

But it is wok well use `from_tensor_slices` way to get the dataset.

I am not sure if it is a bug. The tutorial mainly use `from_tensor_slices` as emamples. But I think the action should be same when use these ways to get the dataset.

### Source code / logs

```
    def csv_yield(csv_path):
        with open(csv_path, newline='') as f:
            next(f)  # skip the first line
            reader = csv.reader(f)
            features, labels = [], []
            for line in reader:
                feature, label = [float(i) for i in line[:-1]], int(line[-1])
                yield feature, label


    ds_train = tf.data.Dataset.from_generator(lambda: csv_yield(r""../data/iris/iris_training.csv""),
                                              output_types=(tf.float32, tf.int32))
    ds_train = ds_train.shuffle(1000).batch(16).repeat(5)
    features, labels = ds_train.make_one_shot_iterator().get_next()

    net = tf.layers.dense(features, units=10, activation=tf.nn.relu)
```

`ValueError: Input 0 of layer dense_1 is incompatible with the layer: its rank is undefined, but the layer requires a defined rank.`

But is is ok when use `tf.data.Dataset.from_tensor_slices`, The only difference between of them is the way of dataset. They shouldn't have different actions.

```
    def read_csv(csv_path):
        with open(csv_path, newline='') as f:
            next(f)  # skip the first line
            reader = csv.reader(f)
            features, labels = [], []
            for line in reader:
                feature, label = [float(i) for i in line[:-1]], int(line[-1])
                # yield feature, label
                features.append(feature)
                labels.append(label)
            return features, labels


    ds_train = tf.data.Dataset.from_tensor_slices(read_csv(r""../data/iris/iris_training.csv""))
    ds_train = ds_train.shuffle(1000).batch(16).repeat(5)
    features, labels = ds_train.make_one_shot_iterator().get_next()

    net = tf.layers.dense(features, units=10, activation=tf.nn.relu)
```

"
18078,How to change the session options config while load the model in the Java?,"System information
Have I written custom code (as opposed to using a stock example script provided in TensorFlow): NO
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): Master
Python version: 3.6
Bazel version (if compiling from source): N/A
GCC/Compiler version (if compiling from source): N/A
CUDA/cuDNN version: None
GPU model and memory: None
Exact command to reproduce: Run the snippet below.

I use the python to train the model and predicate use java.

See the example code as below.
`SavedModelBundle saver = SavedModelBundle.load(args[0], ""raintung"");
		Session session = saver.session();`
Session had beed created while SavedModelBundle load the model, I want change some session configuration, ex. intra_op_parallelism_threads_ , use_per_session_threads control the session thread numbers and so on, How to do it?
And I still not found the default session config that read which protocol files?

Please give me example to change the default `config.proto->message ConfigProto` value, or finger out how to do it. Appreciate your grateful help. 


"
18066,"Lite label_image with Quantized MobileNet reporting varying, incorrect labels for test image","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: OSX
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: v1.6.0-0-gd2e24b6039 1.6.0
- **Python version**: 3.6.4
- **Bazel version (if compiling from source)**: [bazel release 0.8.1-homebrew]
- **GCC/Compiler version (if compiling from source)**: Apple LLVM version 9.0.0 (clang-900.0.39.2)
- **CUDA/cuDNN version**: n/a
- **GPU model and memory**: n/a
- **Exact command to reproduce**: See below, running Lite's `label_image` example

I've set the Android SDK/NDK paths in my WORKSPACE file and I'm cross compiling the Lite `label_image` binary for my armv7a device as described in the README, without errors:
```
bazel build --config android_arm --config monolithic --cxxopt=-std=c++11   //tensorflow/contrib/lite/examples/label_image:label_image
```

When I run the resulting binary on my device with the stock `mobilenet_quant_v1_224.tflite` model and Grace Hopper image, I do not get the expected results, with ""military uniform"" at the top of the list. Instead I get:
```
 # ./label_image
nnapi error: unable to open library libneuralnetworks.so
Loaded model ./mobilenet_quant_v1_224.tflite
resolved reporter
invoked 
average time: 2153.24 ms 
0.862745: 188 Yorkshire terrier
0.0862745: 194 Australian terrier
0.0313726: 187 Norwich terrier
0.0117647: 202 silky terrier
0.00784314: 152 Chihuahua
```

I see the `nnapi` error about the lack of the `libneuralnetworks.so`, so is that the culprit here? I had hoped that if the library was missing, it would still run correctly, albeit more slowly, but perhaps that is not the case and the library is 100% required for Lite to work. (If it is truly _required_, it does seem odd/confusing that the error isn't ""more fatal"" instead of continuing to do forward inference and producing garbage output!)

Furthermore, when I run with more iterations (via the `-c` flag), I continue to get the wrong labels, but a _different_ set of incorrect labels depending on the number of iterations. For example, with two iterations:
```
# ./label_image2 -c 2
nnapi error: unable to open library libneuralnetworks.so
Loaded model ./mobilenet_quant_v1_224.tflite
resolved reporter
invoked 
average time: 2214.83 ms 
0.345098: 795 shower curtain
0.109804: 906 window shade
0.0470588: 563 fountain
0.0470588: 534 dishrag
0.0392157: 912 wool
```
And with three iterations:
```
# ./label_image2 -c 3
nnapi error: unable to open library libneuralnetworks.so
Loaded model ./mobilenet_quant_v1_224.tflite
resolved reporter
invoked 
average time: 2407.64 ms 
0.0705882: 906 window shade
0.0509804: 829 strainer
0.0509804: 734 pole
0.0431373: 795 shower curtain
0.0431373: 620 lampshade
```
And so on.

Why does the number of iterations performed affect the output? (Perhaps this is just the same issue as above, due to missing nnapi lib?)
"
18065,Feature request : warning for feeding unused values,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: custom
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04.4 LTS
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.4.1
- **Python version**:  3.6.3
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A


### Describe the problem
(It's not a bug. Just a feature discussion)

Probably it would be reasonable to add some kind of warnings for situations when the value you feed, is never used within computation?

Example:

```
a = tf.abs(2)
b = 2 * a
#a = tf.identity(a, name='a')

with tf.Session() as sess:
    print(sess.run([a, b], feed_dict={a: 3}))
```
In this everything works fine.  However if 3d line will be uncommented the feeded value will be useless. It can lead to hard debugging.
Probably it would we useful to add some warnings?

Thanx
"
18064, reorg layer ,Any implementation of the reorg layer used in many models such as yolo v2....
18063,Can't `import tensorflow` when `PYTHONOPTIMIZE=2`,"### Issue

The Python runtime admits an environment variable called [`PYTHONOPTIMIZE`](https://docs.python.org/3/using/cmdline.html#envvar-PYTHONOPTIMIZE). When `PYTHONOPTIMIZE` is set to `2` (eg. `export PYTHONOPTIMIZE=2`), Python can't `import tensorflow`, and I think the reason is that `PYTHONOPTIMIZE=2` strips away `.__doc__` strings.

### Logs

```
Python 3.6.4 (default, Feb 19 2018, 12:57:53) 
[GCC 5.4.0 20160609] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/da/git/py36/lib/python3.6/site-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *  # pylint: disable=redefined-builtin
  File ""/home/da/git/py36/lib/python3.6/site-packages/tensorflow/python/__init__.py"", line 63, in <module>
    from tensorflow.python.framework.framework_lib import *  # pylint: disable=redefined-builtin
  File ""/home/da/git/py36/lib/python3.6/site-packages/tensorflow/python/framework/framework_lib.py"", line 77, in <module>
    from tensorflow.python.framework.ops import Graph
  File ""/home/da/git/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 41, in <module>
    from tensorflow.python.eager import context
  File ""/home/da/git/py36/lib/python3.6/site-packages/tensorflow/python/eager/context.py"", line 29, in <module>
    from tensorflow.python.framework import c_api_util
  File ""/home/da/git/py36/lib/python3.6/site-packages/tensorflow/python/framework/c_api_util.py"", line 23, in <module>
    from tensorflow.python.util import compat
  File ""/home/da/git/py36/lib/python3.6/site-packages/tensorflow/python/util/compat.py"", line 153, in <module>
    remove_undocumented(__name__, _allowed_symbols)
  File ""/home/da/git/py36/lib/python3.6/site-packages/tensorflow/python/util/all_util.py"", line 103, in remove_undocumented
    should_have = make_all(module_name, doc_string_modules)
  File ""/home/da/git/py36/lib/python3.6/site-packages/tensorflow/python/util/all_util.py"", line 55, in make_all
    for m in _reference_pattern.finditer(doc_module.__doc__)
TypeError: expected string or bytes-like object
```

### Workaround

Set `PYTHONOPTIMIZE` to `0` or `1` (eg. `export PYTHONOPTIMIZE=0` or `export PYTHONOPTIMIZE=1`).

--------
**Have I written custom code.** No
**OS Platform and Distribution.** Linux 4.15 Ubuntu 16.04
**TensorFlow installed from.** Source
**TensorFlow version.** 1.7.0-rc1
**Bazel version.** N/A
**CUDA/cuDNN version.** CUDA 9.1 / cuDNN 7.0.5
**GPU model and memory.** NVIDIA Titan V 12GB
**Exact command to reproduce.** `$ export PYTHONOPTIMIZE=2 && python -c ""import tensorflow""`"
18060,Tensorflow lite c++ shared library include headers file,"Hi ,
1.I build tensorflowlite.so library as describe in https://github.com/tensorflow/tensorflow/issues/16219
2.I added lib to my Android studio project.
3.In C++ class header I added 
#include ""tensorflow/contrib/lite/kernels/register.h""
#include ""tensorflow/contrib/lite/model.h""
#include ""tensorflow/contrib/lite/string_util.h""
#include ""tensorflow/contrib/lite/tools/mutable_op_resolver.h""

4.Error compilation :
```
  ../../../../../../../3rdparty/tensorflow/tf_lite/tensorflow/contrib/lite/schema/schema_generated.h:21:37: fatal error: flatbuffers/flatbuffers.h: No such file or directory
   #include ""flatbuffers/flatbuffers.h""
                                       ^
  compilation terminated.
  ninja: build stopped: subcommand failed.
```
Please advise how to resolve it,
Thanks.


### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu
- **TensorFlow installed from (source or binary)**:
Sources
- **TensorFlow version (use command below)**:
Master
- **Python version**: 
2.7
- **Bazel version (if compiling from source)**:
0.11
- **GCC/Compiler version (if compiling from source)**:
NDK 14
- **CUDA/cuDNN version**:
n/A
- **GPU model and memory**:
n/A
- **Exact command to reproduce**:
bazel build  //tensorflow/contrib/lite:libtensorflowLite.so --crosstool_top=//external:android/crosstool --cpu=arm64-v8a --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --cxxopt=""-std=c++11""

"
18058,Large multinomial sampling on GPU causes OOM,"Sampling m samples from `tf.multinomial` with support n allocates an unnecessarily large n x m tensor when running on a GPU. For large n and m, this causes out of memory errors. It should be possible to sample from a multinomial distribution without allocating such a large tensor (output tensor is only b x m, where b is the batch size).

### Example and traceback:
```
sample_indices = tf.multinomial(tf.ones([1, 1e6]), 10000, output_dtype=tf.int32)  # sample_indices has shape [1 x 1e4]
with tf.Session() as sess:
    output = sess.run([sample_indices])
```

Traceback:

> ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[1,10000,1000000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
         [[Node: multinomial/Multinomial = Multinomial[T=DT_FLOAT, output_dtype=DT_INT32, seed=0, seed2=0,
_device=""/job:localhost/replica:0/task:0/device:GPU:0""](ones, multinomial/Multinomial/num_samples)]]


------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Springdale LInux 7.4 (Redhat)
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: 1.6.0
- **Python version**: 2.7.5
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: CUDA 9.0, cuDNN 7.0.5
- **GPU model and memory**: TITAN X (Pascal) 12GB
- **Exact command to reproduce**: (see above)"
18055,run_test_in_graph_and_eager_modes does not work,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS 10.13.3
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.6.0-0-gd2e24b6039 1.6.0
- **Python version**: 3.6.1
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: See below

I have code that was written to work in graph mode, and I am now converting it to work in eager mode as well.  I am trying to use the `run_test_in_graph_and_eager_modes` decorator to make my tests run in both modes.  When I add `@run_test_in_graph_and_eager_modes()` in front of a test method, it simply causes the test not to run at all, in either mode.  I run the tests with `nosetests` version 1.3.7.  There is no error message or any indication that something has gone wrong.  The decorated tests are just silently skipped."
18053,Lowercase tf.print when print is a function?,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: n/a
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: n/a
- **TensorFlow installed from (source or binary)**: n/a
- **TensorFlow version (use command below)**: n/a
- **Python version**: n/a
- **Bazel version (if compiling from source)**: n/a
- **GCC/Compiler version (if compiling from source)**: n/a
- **CUDA/cuDNN version**: n/a
- **GPU model and memory**: n/a
- **Exact command to reproduce**: n/a

### Describe the problem
Since TensorFlow must be compatible with Python 2.7, `tf.Print` is uppercase.  However, `tf.print` would work fine for Python 3 users and Python 2 users with `from __future__ import print_function`?  There's no difficulty adding this to the source, since all TensorFlow source files have `from __future__ import print_function`, and it wouldn't interfere with any other 2.7 users.

Objections to me adding?"
18050,what is the correct format of python command?,"Hi guys,
i am running tensorflow-gpu in windows environment of anaconda. the backslash \ doesnt work in anaconda prompt eg:
`python train_model.py \
    --training_data=rnn_tutorial_data/training.tfrecord-?????-of-????? \
    --eval_data=rnn_tutorial_data/eval.tfrecord-?????-of-????? \
    --classes_file=rnn_tutorial_data/training.tfrecord.classes`
it works in my ubuntu terminal. i dont want to mess with ubuntu cuz the cuda is 9.1 which doesnt support tensorflow1.6 yet.  what is the correct format command in windows of \ backslash?

Hope to hear your suggestions."
18045,Feature Request: Raise Error when using queue without starting it,"When using functions like `tf.train.batch()` or `tf.train.shuffle_batch()` and probably more,  one needs to start the queue with `tf.train.start_queue_runners(sess)`. If used without it, above functions are still executable but hang indefinitely. I suggest raising an error if the queue hasn't been started before, as this has costed me a lot of time to figure out.

Alternatively point more directly to this usage in the documentation of the [functions](https://www.tensorflow.org/api_docs/python/tf/train/shuffle_batch) and the [guide](https://www.tensorflow.org/api_guides/python/reading_data#batching).

This might help a lot of people!"
18044,FailedPreconditionError (see above for traceback): Failed to rename: <file_name> to: <file_name> : The process cannot access the file because it is being used by another process. ; Broken pipe,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 10 Pro 64-bit (10.0, Build 16299)
- **TensorFlow installed from (source or binary)**:
Binary
- **TensorFlow version (use command below)**:
1.6.0
- **Python version**: 
b'unknown' 1.6.0
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
I try to run a model using tf.train.MonitoredTrainingSession(), but get an error when the CheckPointSaverHook() tries to save the model. Having loked at the target saving directory, the saver seems to create a temporary directory from shards (something I assume is done because of the model being quite big) for later use. When the saver later on tries to use the sharded files in this directory, it seems to get blocked by another process accessing those files, resulting in a broken pipe error.

I assume the problem has to do with the sharding mechanism, as this is the first time I've seen the saver having to save the checkpoints in shards. I am not sure though, so if you're sure something else is causing this error, you're probably right.

### Source code / logs
Below is the error message I get when running my code. 

```
Caused by op 'save/SaveV2', defined at:
  File ""em_routing_train.py"", line 218, in <module>
    tf.app.run()
  File ""C:\Python36\lib\site-packages\tensorflow\python\platform\app.py"", line 126, in run
    _sys.exit(main(argv))
  File ""em_routing_train.py"", line 214, in main
    train()
  File ""em_routing_train.py"", line 135, in train
    log_device_placement=FLAGS.log_device_placement)) as mon_sess:
  File ""C:\Python36\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 384, in MonitoredTrainingSession
    stop_grace_period_secs=stop_grace_period_secs)
  File ""C:\Python36\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 795, in __init__
    stop_grace_period_secs=stop_grace_period_secs)
  File ""C:\Python36\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 518, in __init__
    self._sess = _RecoverableSession(self._coordinated_creator)
  File ""C:\Python36\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 981, in __init__
    _WrappedSession.__init__(self, self._create_session())
  File ""C:\Python36\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 986, in _create_session
    return self._sess_creator.create_session()
  File ""C:\Python36\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 675, in create_session
    self.tf_sess = self._session_creator.create_session()
  File ""C:\Python36\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 437, in create_session
    self._scaffold.finalize()
  File ""C:\Python36\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 212, in finalize
    self._saver = training_saver._get_saver_or_default()  # pylint: disable=protected-access
  File ""C:\Python36\lib\site-packages\tensorflow\python\training\saver.py"", line 871, in _get_saver_or_default
    saver = Saver(sharded=True, allow_empty=True)
  File ""C:\Python36\lib\site-packages\tensorflow\python\training\saver.py"", line 1293, in __init__
    self.build()
  File ""C:\Python36\lib\site-packages\tensorflow\python\training\saver.py"", line 1302, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File ""C:\Python36\lib\site-packages\tensorflow\python\training\saver.py"", line 1339, in _build
    build_save=build_save, build_restore=build_restore)
  File ""C:\Python36\lib\site-packages\tensorflow\python\training\saver.py"", line 787, in _build_internal
    save_tensor = self._AddShardedSaveOps(filename_tensor, per_device)
  File ""C:\Python36\lib\site-packages\tensorflow\python\training\saver.py"", line 411, in _AddShardedSaveOps
    return self._AddShardedSaveOpsForV2(filename_tensor, per_device)
  File ""C:\Python36\lib\site-packages\tensorflow\python\training\saver.py"", line 385, in _AddShardedSaveOpsForV2
    sharded_saves.append(self._AddSaveOps(sharded_filename, saveables))
  File ""C:\Python36\lib\site-packages\tensorflow\python\training\saver.py"", line 326, in _AddSaveOps
    save = self.save_op(filename_tensor, saveables)
  File ""C:\Python36\lib\site-packages\tensorflow\python\training\saver.py"", line 241, in save_op
    tensors)
  File ""C:\Python36\lib\site-packages\tensorflow\python\ops\gen_io_ops.py"", line 1286, in save_v2
    shape_and_slices=shape_and_slices, tensors=tensors, name=name)
  File ""C:\Python36\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""C:\Python36\lib\site-packages\tensorflow\python\framework\ops.py"", line 3271, in create_op
    op_def=op_def)
  File ""C:\Python36\lib\site-packages\tensorflow\python\framework\ops.py"", line 1650, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

FailedPreconditionError (see above for traceback): Failed to rename: 
./tmp/em_routing_train3\model.ckpt-1_temp_79c748505e6941cfa43f30080736273a/part-00000-of-
00001.index.tempstate15074727511180888636 to: ./tmp/em_routing_train3\model.ckpt-
1_temp_79c748505e6941cfa43f30080736273a/part-00000-of-00001.index : The process cannot access 
the file because it is being used by another process.
; Broken pipe
         [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., 
DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], 
_device=""/job:localhost/replica:0/task:0/device:CPU:0""](save/ShardedFilename, 
save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, Class_caps/capsule_cl_tr/beta_u/beta_u, 
Class_caps/capsule_cl_tr/beta_u/beta_u/Adam, Class_caps/capsule_cl_tr/beta_u/beta_u/Adam_1, 
Class_caps/capsule_cl_tr/weights/Class_caps/capsule_cl_tr/weights, 
Class_caps/capsule_cl_tr/weights/Class_caps/capsule_cl_tr/weights/Adam, 
Class_caps/capsule_cl_tr/weights/Class_caps/capsule_cl_tr/weights/Adam_1, ReLu_Conv1/conv2d/bias, 
ReLu_Conv1/conv2d/bias/Adam, ReLu_Conv1/conv2d/bias/Adam_1, ReLu_Conv1/conv2d/kernel, 
ReLu_Conv1/conv2d/kernel/Adam, ReLu_Conv1/conv2d/kernel/Adam_1, beta1_power, beta2_power, 
beta_a/beta_a, beta_a/beta_a/Adam, beta_a/beta_a/Adam_1, convCaps1/beta_u/beta_u, 
convCaps1/beta_u/beta_u/Adam, convCaps1/beta_u/beta_u/Adam_1, convCaps1/weights/weights, 
convCaps1/weights/weights/Adam, convCaps1/weights/weights/Adam_1, convCaps2/beta_u/beta_u, 
convCaps2/beta_u/beta_u/Adam, convCaps2/beta_u/beta_u/Adam_1, convCaps2/weights/weights, 
convCaps2/weights/weights/Adam, convCaps2/weights/weights/Adam_1, global_step, 
primaryCaps/weights1, primaryCaps/weights1/Adam, primaryCaps/weights1/Adam_1, 
primaryCaps/weights2, primaryCaps/weights2/Adam, primaryCaps/weights2/Adam_1)]]
```

The important part of this error message is, as I see it:

```
FailedPreconditionError (see above for traceback): Failed to rename: 
./tmp/em_routing_train3\model.ckpt-1_temp_79c748505e6941cfa43f30080736273a/part-00000-of-
00001.index.tempstate15074727511180888636 to: ./tmp/em_routing_train3\model.ckpt-
1_temp_79c748505e6941cfa43f30080736273a/part-00000-of-00001.index : The process cannot access 
the file because it is being used by another process.
; Broken pipe
```
"
18043,module 'tensorflow' has no attribute 'Variable',"I used to install tensorflow.  But after I found that it was cpu version, I installed tensorflow-gpu and uninstalled the original tensorflow,which is the cpu version.  But when I used this module, there was something wrong, which said module 'tensorflow' had no attribute 'Variable'.  I don't know how to fix it."
18042,AttributeError: module 'pandas' has no attribute 'core',"Hi, 

Please find the link to my [code](https://github.com/KathiravanNatarajan/MAWILAB_classfication/blob/master/Conv_1D.ipynb). 

```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-9-5960795275b2> in <module>()
     10 
     11 # Output of the model
---> 12 output = conv1D_Net1(features)
     13 
     14 # Calculating cost

<ipython-input-8-80fe61955189> in conv1D_Net1(input_1d)
      8     pool1 = tf.nn.pool(conv1d, [2], 'MAX', 'SAME', strides = [2])
      9      #Flattenning the output of ConvNets
---> 10     flat_conv2 = tf.contrib.layers.flatten(pool1)
     11 
     12     datasize = flat_conv2.get_shape().as_list()[1]

C:\Anaconda\envs\tensorflow\lib\site-packages\tensorflow\__init__.py in __getattr__(self, item)
     33     # Replace the lazy loader with the imported module itself.
     34     import importlib  # pylint: disable=g-import-not-at-top
---> 35     contrib = importlib.import_module('tensorflow.contrib')
     36     return getattr(contrib, item)
     37 

C:\Anaconda\envs\tensorflow\lib\importlib\__init__.py in import_module(name, package)
    124                 break
    125             level += 1
--> 126     return _bootstrap._gcd_import(name[level:], package, level)
    127 
    128 

C:\Anaconda\envs\tensorflow\lib\importlib\_bootstrap.py in _gcd_import(name, package, level)

C:\Anaconda\envs\tensorflow\lib\importlib\_bootstrap.py in _find_and_load(name, import_)

C:\Anaconda\envs\tensorflow\lib\importlib\_bootstrap.py in _find_and_load_unlocked(name, import_)

C:\Anaconda\envs\tensorflow\lib\importlib\_bootstrap.py in _load_unlocked(spec)

C:\Anaconda\envs\tensorflow\lib\importlib\_bootstrap_external.py in exec_module(self, module)

C:\Anaconda\envs\tensorflow\lib\importlib\_bootstrap.py in _call_with_frames_removed(f, *args, **kwds)

C:\Anaconda\envs\tensorflow\lib\site-packages\tensorflow\contrib\__init__.py in <module>()
     27 from tensorflow.contrib import deprecated
     28 from tensorflow.contrib import distributions
---> 29 from tensorflow.contrib import factorization
     30 from tensorflow.contrib import framework
     31 from tensorflow.contrib import graph_editor

C:\Anaconda\envs\tensorflow\lib\site-packages\tensorflow\contrib\factorization\__init__.py in <module>()
     22 from tensorflow.contrib.factorization.python.ops.clustering_ops import *
     23 from tensorflow.contrib.factorization.python.ops.factorization_ops import *
---> 24 from tensorflow.contrib.factorization.python.ops.gmm import *
     25 from tensorflow.contrib.factorization.python.ops.gmm_ops import *
     26 # pylint: enable=wildcard-import

C:\Anaconda\envs\tensorflow\lib\site-packages\tensorflow\contrib\factorization\python\ops\gmm.py in <module>()
     30 from tensorflow.contrib.framework.python.framework import checkpoint_utils
     31 from tensorflow.contrib.framework.python.ops import variables
---> 32 from tensorflow.contrib.learn.python.learn import graph_actions
     33 from tensorflow.contrib.learn.python.learn import monitors as monitor_lib
     34 from tensorflow.contrib.learn.python.learn.estimators import estimator as estimator_lib

C:\Anaconda\envs\tensorflow\lib\site-packages\tensorflow\contrib\learn\__init__.py in <module>()
     81 
     82 # pylint: disable=wildcard-import
---> 83 from tensorflow.contrib.learn.python.learn import *
     84 # pylint: enable=wildcard-import
     85 

C:\Anaconda\envs\tensorflow\lib\site-packages\tensorflow\contrib\learn\python\__init__.py in <module>()
     21 
     22 # pylint: disable=wildcard-import
---> 23 from tensorflow.contrib.learn.python.learn import *
     24 # pylint: enable=wildcard-import

C:\Anaconda\envs\tensorflow\lib\site-packages\tensorflow\contrib\learn\python\learn\__init__.py in <module>()
     23 from tensorflow.contrib.learn.python.learn import basic_session_run_hooks
     24 from tensorflow.contrib.learn.python.learn import datasets
---> 25 from tensorflow.contrib.learn.python.learn import estimators
     26 from tensorflow.contrib.learn.python.learn import graph_actions
     27 from tensorflow.contrib.learn.python.learn import learn_io as io

C:\Anaconda\envs\tensorflow\lib\site-packages\tensorflow\contrib\learn\python\learn\estimators\__init__.py in <module>()
    308 from tensorflow.contrib.learn.python.learn.estimators._sklearn import NotFittedError
    309 from tensorflow.contrib.learn.python.learn.estimators.constants import ProblemType
--> 310 from tensorflow.contrib.learn.python.learn.estimators.dnn import DNNClassifier
    311 from tensorflow.contrib.learn.python.learn.estimators.dnn import DNNRegressor
    312 from tensorflow.contrib.learn.python.learn.estimators.dnn_linear_combined import DNNLinearCombinedClassifier

C:\Anaconda\envs\tensorflow\lib\site-packages\tensorflow\contrib\learn\python\learn\estimators\dnn.py in <module>()
     27 from tensorflow.contrib.layers.python.layers import optimizers
     28 from tensorflow.contrib.learn.python.learn import metric_spec
---> 29 from tensorflow.contrib.learn.python.learn.estimators import dnn_linear_combined
     30 from tensorflow.contrib.learn.python.learn.estimators import estimator
     31 from tensorflow.contrib.learn.python.learn.estimators import head as head_lib

C:\Anaconda\envs\tensorflow\lib\site-packages\tensorflow\contrib\learn\python\learn\estimators\dnn_linear_combined.py in <module>()
     31 from tensorflow.contrib.layers.python.layers import optimizers
     32 from tensorflow.contrib.learn.python.learn import metric_spec
---> 33 from tensorflow.contrib.learn.python.learn.estimators import estimator
     34 from tensorflow.contrib.learn.python.learn.estimators import head as head_lib
     35 from tensorflow.contrib.learn.python.learn.estimators import model_fn

C:\Anaconda\envs\tensorflow\lib\site-packages\tensorflow\contrib\learn\python\learn\estimators\estimator.py in <module>()
     49 from tensorflow.contrib.learn.python.learn.estimators import tensor_signature
     50 from tensorflow.contrib.learn.python.learn.estimators._sklearn import NotFittedError
---> 51 from tensorflow.contrib.learn.python.learn.learn_io import data_feeder
     52 from tensorflow.contrib.learn.python.learn.utils import export
     53 from tensorflow.contrib.learn.python.learn.utils import saved_model_export_utils

C:\Anaconda\envs\tensorflow\lib\site-packages\tensorflow\contrib\learn\python\learn\learn_io\__init__.py in <module>()
     30 from tensorflow.contrib.learn.python.learn.learn_io.graph_io import read_keyed_batch_examples
     31 from tensorflow.contrib.learn.python.learn.learn_io.graph_io import read_keyed_batch_features
---> 32 from tensorflow.contrib.learn.python.learn.learn_io.numpy_io import numpy_input_fn
     33 from tensorflow.contrib.learn.python.learn.learn_io.pandas_io import extract_pandas_data
     34 from tensorflow.contrib.learn.python.learn.learn_io.pandas_io import extract_pandas_labels

C:\Anaconda\envs\tensorflow\lib\site-packages\tensorflow\contrib\learn\python\learn\learn_io\numpy_io.py in <module>()
     20 
     21 import collections
---> 22 from tensorflow.contrib.learn.python.learn.dataframe.queues import feeding_functions
     23 
     24 # Key name to pack the target into dict of `features`. See

C:\Anaconda\envs\tensorflow\lib\site-packages\tensorflow\contrib\learn\python\learn\dataframe\queues\feeding_functions.py in <module>()
     36 # pylint: disable=g-import-not-at-top
     37 try:
---> 38   import pandas as pd
     39   HAS_PANDAS = True
     40 except ImportError:

C:\Anaconda\envs\tensorflow\lib\site-packages\pandas\__init__.py in <module>()
     35 
     36 # let init-time option registration happen
---> 37 import pandas.core.config_init
     38 
     39 from pandas.core.api import *

C:\Anaconda\envs\tensorflow\lib\site-packages\pandas\core\config_init.py in <module>()
     12 import warnings
     13 
---> 14 import pandas.core.config as cf
     15 from pandas.core.config import (is_int, is_bool, is_text, is_instance_factory,
     16                                 is_one_of_factory, get_default_val,

AttributeError: module 'pandas' has no attribute 'core'
```

Regards, 
Kathir
​"
18041,The one_hot_labels in acgan is not pooled in tfgan.gan_loss function.,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.6.0
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: 9.0/7.0
- **GPU model and memory**: GTX 980M 4G
- **Exact command to reproduce**: N/A

### Describe the problem
I am trying to use tfgan.acgan_model together with tfgan.features.tensor_pool. There are three inputs to the acgan_model, i.e. real_data, generator_inputs, and one_hot_labels. While only two of the inputs (read_data, generator_inputs) are manipulated by tensor_pool in tfgan.gan_loss, which means that the one_hot_labels are incorrectly used in the acgan_discriminator_loss function.

The following is the entrance to the error function call. The one_hot_labels should be read from the tensor pool before this function call.
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/gan/python/train.py#L561"
18040,[distributed tensorflow] End of sequence after a few batch with dataset.shard,"When running distributed training, my session gets terminated after a few batches when using `dataset.shard`. The issue disappears when I run distributed training with an independent dataset object on each worker (in which case the same data gets shuffled and read on each worker).


Have I written custom code: No.
OS Platform and Distribution: ubuntu
TensorFlow installed from: standard TF1.5 distribution
Bazel version: NA
CUDA/cuDNN version: CUDA 9.1
GPU model and memory: No GPU
Exact command to reproduce: Cf Below



Dataset construction:
```
def construct_dataset(filenames, labels, batch_size, num_workers,worker_index):
    dataset = tf.data.TextLineDataset(filenames)
    dataset = tf.data.Dataset.from_tensor_slices((filenames,labels))
    dataset = dataset.shard(num_workers, worker_index) #works fine when commenting this out
    dataset = dataset.shuffle(buffer_size=10000)  # Equivalent to min_after_dequeue=10000.
    dataset = dataset.map(_parse_function)
    dataset = dataset.batch(batch_size)
    return dataset
```

main
```
with tf.device(device):
        filelist, labels = get_filelist(FLAGS.data_dir)
        dataset = construct_dataset(...)
        iterator = dataset.make_one_shot_iterator()
        batch = iterator.get_next()
        img_batch, filepath_batch, label_batch = batch
        ...

       hooks=[tf.train.StopAtStepHook(last_step=1000000)] 

    with tf.train.MonitoredTrainingSession(master=target,
        is_chief=(FLAGS.task_index == 0),checkpoint_dir=logs,hooks = hooks) as sess:
        try:
            while not sess.should_stop():
                sess.run(train_op)
        except Exception as e:
            print(e)
```

Stacktrace - 
```End of sequence
	 [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,300,300,?], [?], [?]], output_types=[DT_UINT8, DT_STRING, DT_INT32], _device=""/job:ps/replica:0/task:0/device:CPU:0""](OneShotIterator)]]
	 [[Node: Training_Loss_S17 = _HostRecv[client_terminated=false, recv_device=""/job:worker/replica:0/task:0/device:CPU:0"", send_device=""/job:ps/replica:0/task:0/device:CPU:0"", send_device_incarnation=-379211586651304706, tensor_name=""edge_133_Training_Loss"", tensor_type=DT_STRING, _device=""/job:worker/replica:0/task:0/device:CPU:0""]()]]
```
"
18039,Error building contrib/nccl on CentOS 6.5 on 1.7.0-rc1,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: CentOS 6.5
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: 1.7.0-rc1 release
- **Python version**: 3.6.4
- **Bazel version (if compiling from source)**: 0.11.1- (non-git)
- **GCC/Compiler version (if compiling from source)**: gcc (GCC) 4.8.2 20140120 (Red Hat 4.8.2-15)
- **CUDA/cuDNN version**: CUDA: 7.5 cuDNN: 6.0
- **GPU model and memory**: NVIDIA Tesla K20m
- **Exact command to reproduce**: `bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package   --action_env=""LD_LIBRARY_PATH=${LD_LIBRARY_PATH}""`


### Describe the problem
Tensorflow fails to build from source release 1.7.0-rc1 with error from nccl_ops.cc
I took the following steps:

```
source /opt/rh/devtoolset-2/enable
cd /tmp
wget https://github.com/tensorflow/tensorflow/archive/v1.7.0-rc1.tar.gz
tar -xvf v1.7.0-rc1.tar.gz
cd /tensorflow-1.7.0.-rc1
export TEST_TMPDIR=/tmp/tf-build
export JAVA_HOME=/usr/java/jdk1.8.0_66/
./configure

Found possible Python library paths:
  /home/mack0242/.pyenv/versions/3.6.4/lib/python3.6/site-packages
Please input the desired Python library path to use.  Default is [/home/mack0242/.pyenv/versions/3.6.4/lib/python3.6/site-packages]

Do you wish to build TensorFlow with jemalloc as malloc support? [Y/n]: n
No jemalloc as malloc support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Google Cloud Platform support? [Y/n]: n
No Google Cloud Platform support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Hadoop File System support? [Y/n]: n
No Hadoop File System support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Amazon S3 File System support? [Y/n]: n
No Amazon S3 File System support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Apache Kafka Platform support? [y/N]: n
No Apache Kafka Platform support will be enabled for TensorFlow.

Do you wish to build TensorFlow with XLA JIT support? [y/N]: n
No XLA JIT support will be enabled for TensorFlow.

Do you wish to build TensorFlow with GDR support? [y/N]: n
No GDR support will be enabled for TensorFlow.

Do you wish to build TensorFlow with VERBS support? [y/N]: n
No VERBS support will be enabled for TensorFlow.

Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: n
No OpenCL SYCL support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: y
CUDA support will be enabled for TensorFlow.

Please specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 9.0]: 7.5

Please specify the location where CUDA 7.5 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 

Please specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7.0]: 6.0

Please specify the location where cuDNN 6 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:

Do you wish to build TensorFlow with TensorRT support? [y/N]: n
No TensorRT support will be enabled for TensorFlow.

Please specify a list of comma-separated Cuda compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size. [Default is: 3.5,5.2]3.5

Do you want to use clang as CUDA compiler? [y/N]: n
nvcc will be used as CUDA compiler.

Please specify which gcc should be used by nvcc as the host compiler. [Default is /opt/rh/devtoolset-2/root/usr/bin/gcc]: 

Do you wish to build TensorFlow with MPI support? [y/N]: n
No MPI support will be enabled for TensorFlow.

Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native]: 

Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: n
Not configuring the WORKSPACE for Android builds.

Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See tools/bazel.rc for more details.
        --config=mkl            # Build with MKL support.
        --config=monolithic     # Config for mostly static monolithic build.
Configuration finished

export LD_LIBRARY_PATH=/opt/rh/devtoolset-2/root/usr/lib64:/opt/rh/devtoolset-2/root/usr/lib:/opt/rh/devtoolset-2/root/usr/lib64:/opt/rh/devtoolset-2/root/usr/lib:/usr/local/cuda/lib64
bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package   --action_env=""LD_LIBRARY_PATH=${LD_LIBRARY_PATH}""
```

### Source code / logs
Build fails at this point:
```
INFO: From Compiling tensorflow/contrib/nccl/kernels/nccl_ops.cc:
tensorflow/contrib/nccl/kernels/nccl_ops.cc(207): error: no instance of overloaded function ""tensorflow::TensorShapeUtils::MakeShape"" matches the argument list
            argument types are: (Eigen::TensorMap<Eigen::Tensor<const tensorflow::int32, 1, 1, long>, 16, Eigen::MakePointer>, tensorflow::TensorShape *)

1 error detected in the compilation of ""/tmp/tmpxft_00001aab_00000000-7_nccl_ops.cpp1.ii"".
ERROR: /tmp/tensorflow-1.7.0-rc1/tensorflow/contrib/nccl/BUILD:23:1: output 'tensorflow/contrib/nccl/_objs/python/ops/_nccl_ops_gpu/tensorflow/contrib/nccl/kernels/nccl_ops.pic.o' was not created
ERROR: /tmp/tensorflow-1.7.0-rc1/tensorflow/contrib/nccl/BUILD:23:1: not all outputs were created or valid
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 362.889s, Critical Path: 67.25s
FAILED: Build did NOT complete successfully
```

So it looks like a parameter type problem here: [nccl_ops.cc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/nccl/kernels/nccl_ops.cc#L207)"
18038,static graph vs dynamic graph,"since dynamic graph has so many advantages, why not tf use dynamic graph from the bey beginning? Is static graph has any advantages over the dynamic?"
18037,tf.sparse_tensor_dense_matmul makes small errors with tf.float32 matrices on GPU,"-----------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, simple short code
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: both Ubuntu 14.04 / Centos 7
- **TensorFlow installed from (source or binary)**: pip binary on Ubuntu, source  on Centos
- **TensorFlow version (use command below)**: 1.4.1
- **Python version**: 3.5.2
- **Bazel version (if compiling from source)**: release 0.8.1
- **GCC/Compiler version (if compiling from source)**: 4.8.5
- **CUDA/cuDNN version**: 6.0.21
- **GPU model and memory**: GTX 750 / GTX 1080
- **Exact command to reproduce**: tf.sparse_tensor_dense_matmul

### Describe the problem
1. Given a sparse tensor sp and a dense tensor mat, both of tf.float32,
2. Compute thier product with tf.sparse_tensor_dense_matmul(sp, mat),
3. The product varies slightly.

### Source code / logs
``` python
import tensorflow as tf
import numpy as np

s = tf.Session()

num = 10
dim = 10
total_out = 100

indices = [
    [1, 0],
    [2, 0],
    [3, 0],
    [5, 0], [5, 1], [5, 2],
    [6, 0], [6, 1], [6, 2], [6, 3], [6, 4], [6, 7],
    [7, 0], [7, 1], [7, 2], [7, 7], [7, 8],
    [8, 0],
    [9, 0], [9, 1], [9, 2], [9, 7]
]
values = np.array([1.0] * len(indices), np.float32)
feature = tf.SparseTensor(indices, values, [tf.cast(num, tf.int64), tf.cast(dim, tf.int64)])

dense = tf.sparse_tensor_to_dense(feature, validate_indices=False)
mat = tf.contrib.stateless.stateless_random_uniform([dim, total_out], seed=[1, 2], dtype=tf.float32)
prod = tf.sparse_tensor_dense_matmul(feature, mat)
# prod2 = tf.sparse_matmul(dense, mat, False, True, True, False, name='cross_sum')

T = ['dense', 'mat', 'prod']
results = s.run([dense, mat, prod])

comp0 = []
comp1 = []
for i, r in enumerate(results):
    try:
        comp0.append(np.sum(np.load('npy_{}.npy'.format(T[i]))) - np.sum(r))
        comp1.append(np.load('npy_{}.npy'.format(T[i])) - r)
    except:
        np.save('npy_{}.npy'.format(T[i]), r)
for i in range(len(comp0)):
    print(T[i])
    print(comp0[i])
    print(comp1[i])
    print('\n')
```
Run the code several times, you will see that the product will vary slightly. like this:
```
dense
0.0
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]


mat
0.0
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0.]
...
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0.]]


prod
0.0
[[ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
   2.3841858e-07 -4.7683716e-07  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
  -4.7683716e-07  0.0000000e+00  0.0000000e+00  0.0000000e+00
   2.3841858e-07  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  4.7683716e-07  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00 -2.3841858e-07
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  4.7683716e-07  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  2.3841858e-07  2.3841858e-07  0.0000000e+00
   0.0000000e+00  2.3841858e-07  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  2.3841858e-07
  -2.3841858e-07  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
  -2.3841858e-07  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00 -2.3841858e-07  0.0000000e+00
  -2.3841858e-07  4.7683716e-07  0.0000000e+00  0.0000000e+00
   0.0000000e+00 -2.3841858e-07  2.3841858e-07  0.0000000e+00
   2.3841858e-07  0.0000000e+00  4.7683716e-07  2.3841858e-07
   0.0000000e+00  4.7683716e-07  2.3841858e-07  4.7683716e-07
   0.0000000e+00  0.0000000e+00  0.0000000e+00  2.3841858e-07
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]
 [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  2.3841858e-07
   2.3841858e-07  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  2.3841858e-07  0.0000000e+00
   0.0000000e+00 -2.3841858e-07  2.3841858e-07  0.0000000e+00
   0.0000000e+00 -2.3841858e-07  0.0000000e+00 -2.3841858e-07
   0.0000000e+00  2.3841858e-07  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00 -2.3841858e-07
   0.0000000e+00  0.0000000e+00  0.0000000e+00  4.7683716e-07
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  2.3841858e-07  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00 -2.3841858e-07  0.0000000e+00  0.0000000e+00
   0.0000000e+00 -4.7683716e-07  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  2.3841858e-07]
 [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00
   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]
...
]
```
This only happens on GPU with float32. It should be a bug I guess.
"
18036,Using this issue to test TF GitHub helper. Please ignore.,I'm working on an internal extension.
18026,What are the expected performance gains when using model quantization? \ Is there support for keras models?,"[this page](https://www.tensorflow.org/performance/quantization) describes tensorflow model quantization 

* Is there a similar tool for keras models?
* are there some examples of the performance gain I can expected? ()it's probably model dependent, but some examples would be usefull"
18017,the mnist dataset in cnn_mnist.py,"I can't see how to build the dataset 'mnist' as in the [tutorials](https://www.tensorflow.org/tutorials/layers#top_of_page) below:
![image](https://user-images.githubusercontent.com/20028780/37976700-a88dffda-3214-11e8-8a22-8c45cecbb81e.png)
```
def main(unused_argv):
  # Load training and eval data
  mnist = tf.contrib.learn.datasets.load_dataset(""mnist"")
  train_data = mnist.train.images # Returns np.array
  train_labels = np.asarray(mnist.train.labels, dtype=np.int32)
  eval_data = mnist.test.images # Returns np.array
  eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)
```
My codes don't work of course. And I have downloaded the following dataset in the  [MNIST](http://yann.lecun.com/exdb/mnist/). So what can I do? 
![image](https://user-images.githubusercontent.com/20028780/37976920-32b61b0c-3215-11e8-8ef0-67b749daf448.png)
Thank you a lot.
"
18016,Feature: evaluating multiple datasets in tf.estimator.Estimator.evaluate without reloading checkpoint,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Fedora release 25 (Twenty Five)
- **TensorFlow installed from (source or binary)**: binary for CPU
- **TensorFlow version (use command below)**: v1.6.0-0-gd2e24b6039
- **Python version**: 3.5.5
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

### Describe the problem

We have several datasets on which we want to track performance during training, corresponding to multiple data splits or different types of data that are processed by the model. To do this we run `Estimator.evaluate` for each dataset after each epoch of training.

The problem with this is that `Estimator.evaluate` reconstructs the graph and loads the variables from checkpoint each time that it is called. In our case, reconstructing the large graph takes longer than doing the evaluation on the relatively small datasets. I'd propose a feature to allow evaluating on multiple datasets without reloading the graph.

Ideas:
- Add an `Estimator.evaluate_multiple` method that takes a mapping from name to input_fn.
- Add functionality to explicitly start an evaluation session for an estimator and allow passing this as input to `Estimator.evaluate`

### Source code / logs
```
model = Estimator(my_model_fn)
for epoch in range(n_epochs):
  estimator.train(train_input_fn, steps=n_steps_per_epoch)
  for name, eval_input_fn in eval_datasets:
    # eval_input_fn create one shot iterators
    estimator.evaluate(eval_input_fn, name=name)
```

"
18014,Creating a Dataset within a while_loop does not work,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:

yes

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:

Linux Ubuntu 16.04

- **TensorFlow installed from (source or binary)**:

binary

- **TensorFlow version (use command below)**:

```bash
$ python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""
('v1.7.0-rc0-12-g98c955ee73', '1.7.0-rc1')
```

- **Python version**: 

```bash
$ python --version
Python 2.7.12
```

- **Bazel version (if compiling from source)**:

N/A

- **GCC/Compiler version (if compiling from source)**:


N/A

- **CUDA/cuDNN version**:


CUDA 9.1, cuDNN 7.1

- **GPU model and memory**:

```bash
2018-03-27 14:21:38.224538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 960M major: 5 minor: 0 memoryClockRate(GHz): 1.176
```

- **Exact command to reproduce**:

```python
import tensorflow as tf

with tf.Graph().as_default() as graph:
    zero = tf.constant(0, dtype=tf.int64)
    ten = tf.constant(10, dtype=tf.int64)
    one = tf.constant(1, dtype=tf.int64)

    def condition(i, n):
        return tf.less(i, ten)

    def body(i, n):
        value = ten + i
        ds = tf.data.Dataset.from_tensors(value)
        it = ds.make_one_shot_iterator()

        return i + one, n + it.get_next()

    loop = tf.while_loop(condition, body, [zero,  zero])

    global_init_op = tf.global_variables_initializer()

with tf.Session(graph=graph) as S:
    S.run(global_init_op)
    print S.run(loop)
```

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem

The above example is trivial, but I would expect a new Dataset and Iterator to be created within each iteration of the `while_loop`. Instead it seems that only a single instance of the  Dataset/Iterator is created resulting in an `OutOfRange` error (see log in next section)

### Source code / logs

```bash
Traceback (most recent call last):
  File ""test_tf_dataset_in_graph.py"", line 24, in <module>
    print S.run(loop)
  File ""/home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 905, in run
    run_metadata_ptr)
  File ""/home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1140, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1321, in _do_run
    run_metadata)
  File ""/home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1340, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.OutOfRangeError: End of sequence
	 [[Node: while/IteratorGetNext = IteratorGetNext[output_shapes=[[]], output_types=[DT_INT64], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](while/OneShotIterator)]]
	 [[Node: while/IteratorGetNext/_17 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_23_while/IteratorGetNext"", tensor_type=DT_INT64, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](^_cloopwhile/add_2/_6)]]

Caused by op u'while/IteratorGetNext', defined at:
  File ""test_tf_dataset_in_graph.py"", line 18, in <module>
    loop = tf.while_loop(condition, body, [zero,  zero])
  File ""/home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 3202, in while_loop
    result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)
  File ""/home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2940, in BuildLoop
    pred, body, original_loop_vars, loop_vars, shape_invariants)
  File ""/home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2877, in _BuildLoop
    body_result = body(*packed_vars_for_body)
  File ""test_tf_dataset_in_graph.py"", line 16, in body
    return i + one, n + it.get_next()
  File ""/home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/data/ops/iterator_ops.py"", line 366, in get_next
    name=name)), self._output_types,
  File ""/home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 1455, in iterator_get_next
    output_shapes=output_shapes, name=name)
  File ""/home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 3290, in create_op
    op_def=op_def)
  File ""/home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1654, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

OutOfRangeError (see above for traceback): End of sequence
	 [[Node: while/IteratorGetNext = IteratorGetNext[output_shapes=[[]], output_types=[DT_INT64], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](while/OneShotIterator)]]
	 [[Node: while/IteratorGetNext/_17 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_23_while/IteratorGetNext"", tensor_type=DT_INT64, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](^_cloopwhile/add_2/_6)]]

```"
18013,TensorFlow 1.5.1 binaries use AVX instructions like 1.6.0 but unlike 1.5.0,"### System information
Linux, Python 3.6

### Describe the problem
For TensorFlow 1.6.0 and later it was announced that the official binaries on PyPI will use AVX instructions and therefore it doesn't run on old GPUs. TensorFlow 1.5.0 did not need AVX instruction support. Unfortunately, the bug fix release 1.5.1 was built with AVX instructions.

The 1.5.1 binary should be rebuild without AVX instructions such that upgrading from 1.5.0 to 1.5.1 is always possible."
18012,Error: absl.flags._exception:IllegalFlagValueError: flag --input=: cannot convert string to float in tensorflow serving,"I have written a simple program for tensorflow serving to deploy and check how it is working. I followed many tutorials on how to deploy these models using tensorflow serving inside docker environment.

```
sess = tf.InteractiveSession()
# define the tensorflow network and do some trains
x = tf.placeholder(""float"", name=""x"")
w = tf.Variable(2.0, name=""w"")
b = tf.Variable(0.0, name=""bias"")
h = tf.multiply(x, w)

sess.run(tf.global_variables_initializer())
y = tf.add(h, b, name=""y"")


export_path_base = FLAGS.work_dir
export_path = os.path.join(tf.compat.as_bytes(export_path_base),
  tf.compat.as_bytes(str(FLAGS.model_version)))
print('Exporting trained model to', export_path)
builder = tf.saved_model.builder.SavedModelBuilder(export_path)

tensor_info_x = tf.saved_model.utils.build_tensor_info(x)
tensor_info_y = tf.saved_model.utils.build_tensor_info(y)

prediction_signature = (
  tf.saved_model.signature_def_utils.build_signature_def(
  inputs={'input': tensor_info_x},
  outputs={'output': tensor_info_y},
  method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME))

legacy_init_op = tf.group(tf.tables_initializer(), name='legacy_init_op')

builder.add_meta_graph_and_variables(
  sess, [tf.saved_model.tag_constants.SERVING],
  signature_def_map={
  'prediction':
  prediction_signature,
  },
  legacy_init_op=legacy_init_op)

builder.save()
```
This saved_model of above programs is currently running inside the docker.I now want to create a client.py file to take input and produce output. I want to give a single number as input to my client file and not to declare inside . I mean

i want to give input like this

> python client.py --server=localhost:9000 --input=3

so i created a client file with input as tf.app.flags.float('input','','input for the model')

```

from grpc.beta import implementations
import numpy
import tensorflow as tf
import sys 
from datetime import datetime
from tensorflow_serving.apis import predict_pb2
from tensorflow_serving.apis import prediction_service_pb2

tf.app.flags.DEFINE_string('server', 'localhost:9000', 'PredictionService host:port')
tf.app.flags.DEFINE_float('input','', 'input for the model')
FLAGS = tf.app.flags.FLAGS

def do_inference(hostport,args):
  """"""Tests PredictionService with concurrent requests.
  Args:
  hostport: Host:port address of the Prediction Service.
  Returns:
  pred values, ground truth label
  """"""
  # create connection
  host, port = hostport.split(':')
  channel = implementations.insecure_channel(host, int(port))
  stub = prediction_service_pb2.beta_create_PredictionService_stub(channel)

  # initialize a request
  data = args
  request = predict_pb2.PredictRequest()
  request.model_spec.name = 'example_model'
  request.model_spec.signature_name = 'prediction'

  request.inputs['input'].CopyFrom(tf.contrib.util.make_tensor_proto(data))
  # predict
  result = stub.Predict(request, 5.0) # 5 seconds
  return result

def main(_):
    if not FLAGS.server:
        print('please specify server host:port')
    return

    result = do_inference(FLAGS.server,FLAGS.input)
    print('Result is: ', result)


if __name__ == '__main__':
  tf.app.run()
```
This gives error , 
Can someone tell me what i did wrong here please? How i send a float number as input to the client file?

![capture](https://user-images.githubusercontent.com/26268279/37956646-87ae7df8-31c9-11e8-99e2-11de878f1608.JPG)
"
18011,Would tensorflow lite provide python API ?,"System information
Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04.3 LTS
TensorFlow installed from (source or binary): pip
TensorFlow version (use command below): 1.6.0
Python version: 3.6.1
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:
GPU model and memory:
Exact command to reproduce:
Describe the problem
Currently, tensorflow lite provide C++/Java API , I would know about any plans for these operations  can be made available in the Python API ?"
18007,Computing gradients with tf.cond bug ,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.4.1
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: CUDA 8.0 , CUDNN 7.0.5
- **GPU model and memory**:  GTX 1060 (6 GiB Memory, 6.1 Compute Power)
- **Exact command to reproduce**: python test_cond_gradients.py (or whatever you call the file with source code)

The file test_cond_gradients.py can be found  in the source code below

### Describe the problem
I am using a tf.cond to stop gradients from being computed through one part of the graph - depending on which train cross entropy (TCE) is smaller. According to the time however, even with the tf.cond, gradients is still being computed through both parts of the graph which should not be the case.
In the source code, there are three different losses tested. The first and second losses (baseline and loss1) are computed in similar time as shown if you run the script. The third loss tested (loss2) is slower than the first two, even though gradients should only be computed through one part of the graph (depending on the cond condition). *The second loss is also using a tf.cond but the true_fn and false_fn passed to it are identical.* The third should take about the same time to compute as the first two. This problem is amplified more when the network is more complex and thus back-prop takes more time but I have just created a simple example to run.  

### Source code / logs
```
import tensorflow as tf
import numpy as np
import time

def run_test():
    x1 = tf.placeholder(tf.float32, [64,32,32,3])
    x2 = tf.placeholder(tf.float32, [64,32,32,3])

    y = tf.placeholder(tf.int64, [64])

    logits1 = simple_network(x1)
    logits2 = simple_network(x2, reuse=True)

    # TCEs
    train_cross_entropy1 = tf.reduce_mean(
            tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits1))
    train_cross_entropy2 = tf.reduce_mean(
            tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits2))

    # Losses
    loss_baseline = train_cross_entropy1 + tf.stop_gradient(train_cross_entropy2)

    loss1 = tf.cond(train_cross_entropy1 < train_cross_entropy2, lambda: train_cross_entropy1 + tf.stop_gradient(train_cross_entropy2), 
                                                                 lambda: train_cross_entropy1 + tf.stop_gradient(train_cross_entropy2))

    loss2 = tf.cond(train_cross_entropy1 < train_cross_entropy2, lambda: train_cross_entropy1 + tf.stop_gradient(train_cross_entropy2), 
                                                                 lambda: tf.stop_gradient(train_cross_entropy1) + train_cross_entropy2)
    # Train Step
    train_step = tf.train.AdamOptimizer()

    apply_gradient_op_baseline = train_step.minimize(loss_baseline)

    apply_gradient_op1 = train_step.minimize(loss1)

    apply_gradient_op2 = train_step.minimize(loss2)
    
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())

        ## Baseline
        baseline_s = time.time()
        for i in range(1000):
            sess.run(apply_gradient_op_baseline, feed_dict={x1: np.random.rand(64,32,32,3), x2: np.random.rand(64,32,32,3), y: np.random.randint(0,11,(64))})
        print(""Baseline time: "", time.time() - baseline_s)

        ## Cond 1
        cond1_s = time.time()
        for i in range(1000):
            sess.run(apply_gradient_op1, feed_dict={x1: np.random.rand(64,32,32,3), x2: np.random.rand(64,32,32,3), y: np.random.randint(0,11,(64))})
        print(""Cond1 time: "", time.time() - cond1_s)

        ## Cond 2 (Should be about the same time as Cond 1)
        cond2_s = time.time()
        for i in range(1000):
            sess.run(apply_gradient_op2, feed_dict={x1: np.random.rand(64,32,32,3), x2: np.random.rand(64,32,32,3), y: np.random.randint(0,11,(64))})
        print(""Cond2 time: "", time.time() - cond2_s)   

def simple_network(Y, reuse=False):
    with tf.variable_scope(""simple_network"", reuse=reuse):
        K1 = tf.get_variable(""K1"", shape=[3,3,3,16], initializer=tf.initializers.random_normal)
        Y = tf.nn.conv2d(Y, K1, strides=[1,1,1,1], padding='SAME')

        K2 = tf.get_variable(""K2"", shape=[3,3,16,64], initializer=tf.initializers.random_normal)
        Y = tf.nn.conv2d(Y, K2, strides=[1,1,1,1], padding='SAME')

        Y = tf.reduce_mean(Y, [1,2])

        FC_W = tf.get_variable(""FC_W"", shape=[64, 10], initializer=tf.initializers.random_normal)
        FC_B = tf.get_variable(""FC_B"", shape=[10], initializer=tf.initializers.random_normal)

        logits = tf.nn.xw_plus_b(Y, FC_W, FC_B)

        return logits

run_test()
```
Thanks for any advice or work-arounds of this bug 
"
18003,Feature Request: No U-Turn Sampler (NUTS) in tf.contrib.bayesflow,"The NUTS sampler (http://www.jmlr.org/papers/volume15/hoffman14a/hoffman14a.pdf) would be a great addition to the HMC code already in tf.contrib.bayesflow.

A reference implementation is at: https://github.com/stan-dev/stan/blob/develop/src/stan/mcmc/hmc/nuts/base_nuts.hpp, and this has already been mentioned by @jvdillon and @dustinvtran in https://github.com/tensorflow/tensorflow/issues/4965. The HMC code has been brought over, but I don't see NUTS in there.

Is someone already working on this? Is there any way I could help?

---

Have I written custom code: No
OS Platform and Distribution: N/A
TensorFlow installed from: N/A
TensorFlow version: N/A
Bazel version: N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A
Exact command to reproduce: N/A"
18000,Android NDK r16 support ,"While building TensorFlow with Android NDK r16, it failed finding system headers, such as `stdlib.h`

Full error log:

```
                                                             ^
In file included from /wd/android-ndk-r16//sources/cxx-stl/gnu-libstdc++/4.9/include/cstdlib:72:0,
                 from /wd/android-ndk-r16//sources/cxx-stl/gnu-libstdc++/4.9/include/bits/stl_algo.h:59,
                 from /wd/android-ndk-r16//sources/cxx-stl/gnu-libstdc++/4.9/include/algorithm:62,
                 from ./google/protobuf/stubs/common.h:38,
                 from ./google/protobuf/stubs/atomicops.h:59,
                 from google/protobuf/stubs/atomicops_internals_x86_msvc.cc:37:
/wd/android-ndk-r16//sources/android/support/include/stdlib.h:32:25: fatal error: stdlib.h: No such file or directory
 #include_next <stdlib.h>
                         ^
compilation terminated.
In file included from /wd/android-ndk-r16//sources/cxx-stl/gnu-libstdc++/4.9/include/cwchar:44:0,
                 from /wd/android-ndk-r16//sources/cxx-stl/gnu-libstdc++/4.9/include/bits/postypes.h:40,
                 from /wd/android-ndk-r16//sources/cxx-stl/gnu-libstdc++/4.9/include/bits/char_traits.h:40,
                 from /wd/android-ndk-r16//sources/cxx-stl/gnu-libstdc++/4.9/include/string:40,
                 from ./google/protobuf/stubs/bytestream.h:54,
                 from google/protobuf/stubs/bytestream.cc:31:
/wd/android-ndk-r16//sources/android/support/include/wchar.h:32:24: fatal error: wchar.h: No such file or directory
 #include_next <wchar.h>
                        ^
compilation terminated.
In file included from /wd/android-ndk-r16//sources/cxx-stl/gnu-libstdc++/4.9/include/cstdlib:72:0,
                 from /wd/android-ndk-r16//sources/cxx-stl/gnu-libstdc++/4.9/include/bits/stl_algo.h:59,
                 from /wd/android-ndk-r16//sources/cxx-stl/gnu-libstdc++/4.9/include/algorithm:62,
                 from ./google/protobuf/stubs/common.h:38,
                 from ./google/protobuf/message_lite.h:43,
                 from google/protobuf/stubs/common.cc:33:
/wd/android-ndk-r16//sources/android/support/include/stdlib.h:32:25: fatal error: stdlib.h: No such file or directory
 #include_next <stdlib.h>
                         ^
compilation terminated.
In file included from google/protobuf/stubs/atomicops_internals_x86_gcc.cc:34:0:
/wd/android-ndk-r16//sources/cxx-stl/gnu-libstdc++/4.9/include/cstring:42:20: fatal error: string.h: No such file or directory
 #include <string.h>
                    ^
make[3]: *** [google/protobuf/stubs/common.lo] Error 1
compilation terminated.
make[3]: *** Waiting for unfinished jobs....
make[3]: *** [google/protobuf/stubs/atomicops_internals_x86_gcc.lo] Error 1
make[3]: *** [google/protobuf/stubs/atomicops_internals_x86_msvc.lo] Error 1
make[3]: *** [google/protobuf/stubs/bytestream.lo] Error 1
make[3]: Leaving directory `/wd/tensorflow_0314/tensorflow/tensorflow/contrib/makefile/downloads/protobuf/src'
make[2]: *** [all] Error 2
make[2]: Leaving directory `/wd/tensorflow_0314/tensorflow/tensorflow/contrib/makefile/downloads/protobuf/src'
make[1]: *** [all-recursive] Error 1
make[1]: Leaving directory `/wd/tensorflow_0314/tensorflow/tensorflow/contrib/makefile/downloads/protobuf'
make: *** [all] Error 2
```"
17999,Problem installing demo app on Android Studio because of Bazel,"Hi I am trying to build the demo project on my linux pc and am getting this error. I opened the project after from the examples folder from the tensor flow library.

ERROR: /home/riya/.cache/bazel/_bazel_riya/e4d251743a4c03f32e2f3f7357bd97d7/external/bazel_tools/tools/android/BUILD:288:1: Executing genrule @bazel_tools//tools/android:no_android_sdk_repository_error failed (Exit 1)
This build requires an Android SDK. Please add the android_sdk_repository rule to your WORKSPACE.
Target //tensorflow/examples/android:tensorflow_demo failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 84.049s, Critical Path: 0.35s
FAILED: Build did NOT complete successfully

In my Android project I am getting the same error as this :
Error:Execution failed for task ':buildNativeBazel'.

A problem occurred starting process 'command '/usr/local/bin/bazel''"
17998,android demo? mask_rcnn_inception_v2_coco?,"在android demo中，使用mask_rcnn_inception_v2_coco获取到的detection_masks并不是[num_masks, mask_height, mask_width]，请问如何在android中添加mask?
Have I written custom code: YES
OS Platform and Distribution: Android
TensorFlow installed from: 1.7
TensorFlow version: 1.7
Bazel version: N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A
Exact command to reproduce: N/A"
17997,csv_with_header,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
17996,Unable to import frozen graph with RMSProp,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No 
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source 
- **TensorFlow version (use command below)**: 1.2.1
- **Python version**: 3.5
- **Bazel version (if compiling from source)**:0.5.2
- **GCC/Compiler version (if compiling from source)**:5.3.0
- **CUDA/cuDNN version**:8/5
- **GPU model and memory**:GTX 1080Ti
- **Exact command to reproduce**:

### Describe the problem
 Some errors occured when loading the frozen graph:

`
ValueError: graph_def is invalid at node 'RMSProp/update_InceptionV1/Conv2d_1a_7x7/weights/ApplyRMSProp': Input tensor 'InceptionV1/Conv2d_1a_7x7/weights:0' Cannot convert a tensor of type float32 to an input of type float32_ref.
`
"
17995,tf.igamma (lower regularized incomplete Gamma function) returns the incorrect derivative,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS X 10.11.6
- **TensorFlow installed from (source or binary)**: binary (pypi)
- **TensorFlow version (use command below)**: v1.6.0-0-gd2e24b6039
- **Python version**: 3.6
- **Bazel version**: using a precompiled version, not sure
- **CUDA/cuDNN version**: not using a GPU
- **GPU model and memory**: not using a GPU
- **Exact command to reproduce**: `python igamma_test.py`

### Describe the problem

`tf.igamma`, which is the lower regularized incomplete Gamma function, returns an incorrect derivative with respect to `a`

This is probably very low down on the list of things to fix, but I wanted to highlight it since I spent something like 5 hours trying to understand why my model wasn't converging. I was fitting a Gamma distribution, and deep into the code it turns out that `tf.igamma` doesn't return the right derivative.

I suspect the derivative wrt `a` isn't supported, but I would have much rather seen an exception being thrown. 

My workaround ended up being not fitting `a` with gradient descent, but instead just perturbing it by epsilon (luckily I only had one single value that I tried to fit)

Filing this issue mostly in the hope that anyone in the future doesn't waste the same amount of time that I spent.

### Source code / logs

```
a = tf.placeholder(dtype=tf.float32, shape=[None])
x = tf.placeholder(dtype=tf.float32, shape=[None])
y = tf.igamma(a, x)
y_grad_a = tf.gradients(y, a)  # returns None, should return a tensor
y_grad_x = tf.gradients(y, x)  # returns a tensor
```"
17994,tensorflow-gpu OOM with Geforce GTX980,"Hello there!
Sorry for the noob question, I'm new in the world of deep learning, especially with GPU processing.

I'm trying to run Tensorflow-GPU but probably I'm doing something wrong.
I tried many scripts with always the same result without any solution.
I think I installed Cuda and cuDNN properly, as well tensorflow.

This is my system:
Ubuntu 16.04
GPU: NVIDIA Geforce GTX 980
RAM: 16 GB
Cuda 9.0, cuDNN 7.0.

conda environment in the example reported below:
python==3.6
pathlib==1.0.1
scandir==1.6
h5py==2.7.1
Keras==2.1.2
opencv-python==3.3.0.10
tensorflow-gpu==1.5.0
scikit-image
dlib
face_recognition
tqdm

and basically this is what I get everytime I try to start some kind of training. In this example faceswap.py training with https://github.com/deepfakes/faceswap.
I can't see any change on nvidia-smi while this is going on, so I think the GPU is not actually used.

Thank you in advance for any kind of help, I'm going mad about this :(


```
Loading Trainer from Model_Original plugin...
Starting. Press ""Enter"" to stop training and save model
2018-03-26 02:29:53.146441: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-03-26 02:29:53.146998: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:895] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-03-26 02:29:53.147230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties: 
name: GeForce GTX 980 major: 5 minor: 2 memoryClockRate(GHz): 1.291
pciBusID: 0000:01:00.0
totalMemory: 3.95GiB freeMemory: 2.72GiB
2018-03-26 02:29:53.147248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 980, pci bus id: 0000:01:00.0, compute capability: 5.2)
2018-03-26 02:29:54.731329: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) **ran out of memory trying to allocate 1.21GiB**. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2018-03-26 02:29:54.788791: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) **ran out of memory trying to allocate 1.20GiB**. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2018-03-26 02:29:54.832066: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) **ran out of memory trying to allocate 288.00MiB**. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2018-03-26 02:29:54.832100: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) **ran out of memory trying to allocate 1.29GiB**. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2018-03-26 02:29:54.837129: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) **ran out of memory trying to allocate 220.50MiB**. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2018-03-26 02:30:04.837415: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) **ran out of memory trying to allocate 3.00MiB**.  Current allocation summary follows.
2018-03-26 02:30:04.837533: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (256): 	Total Chunks: 49, Chunks in use: 48. 12.2KiB allocated for chunks. 12.0KiB in use in bin. 504B client-requested in use in bin.
2018-03-26 02:30:04.837564: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (512): 	Total Chunks: 6, Chunks in use: 6. 3.0KiB allocated for chunks. 3.0KiB in use in bin. 3.0KiB client-requested in use in bin.
2018-03-26 02:30:04.837593: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (1024): 	Total Chunks: 13, Chunks in use: 13. 13.2KiB allocated for chunks. 13.2KiB in use in bin. 13.0KiB client-requested in use in bin.
2018-03-26 02:30:04.837620: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (2048): 	Total Chunks: 12, Chunks in use: 12. 25.5KiB allocated for chunks. 25.5KiB in use in bin. 24.0KiB client-requested in use in bin.
2018-03-26 02:30:04.837646: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (4096): 	Total Chunks: 17, Chunks in use: 17. 68.0KiB allocated for chunks. 68.0KiB in use in bin. 68.0KiB client-requested in use in bin.
2018-03-26 02:30:04.837673: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (8192): 	Total Chunks: 6, Chunks in use: 6. 48.0KiB allocated for chunks. 48.0KiB in use in bin. 48.0KiB client-requested in use in bin.
2018-03-26 02:30:04.837700: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (16384): 	Total Chunks: 9, Chunks in use: 8. 168.8KiB allocated for chunks. 150.0KiB in use in bin. 150.0KiB client-requested in use in bin.
2018-03-26 02:30:04.837727: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (32768): 	Total Chunks: 6, Chunks in use: 6. 225.0KiB allocated for chunks. 225.0KiB in use in bin. 225.0KiB client-requested in use in bin.
2018-03-26 02:30:04.837755: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (65536): 	Total Chunks: 6, Chunks in use: 6. 384.0KiB allocated for chunks. 384.0KiB in use in bin. 384.0KiB client-requested in use in bin.
2018-03-26 02:30:04.837779: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (131072): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-03-26 02:30:04.837817: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (262144): 	Total Chunks: 1, Chunks in use: 1. 256.0KiB allocated for chunks. 256.0KiB in use in bin. 256.0KiB client-requested in use in bin.
2018-03-26 02:30:04.837854: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (524288): 	Total Chunks: 1, Chunks in use: 0. 597.0KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-03-26 02:30:04.837892: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (1048576): 	Total Chunks: 6, Chunks in use: 6. 6.75MiB allocated for chunks. 6.75MiB in use in bin. 6.75MiB client-requested in use in bin.
2018-03-26 02:30:04.837931: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (2097152): 	Total Chunks: 8, Chunks in use: 8. 23.62MiB allocated for chunks. 23.62MiB in use in bin. 22.75MiB client-requested in use in bin.
2018-03-26 02:30:04.837971: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (4194304): 	Total Chunks: 13, Chunks in use: 13. 58.25MiB allocated for chunks. 58.25MiB in use in bin. 53.62MiB client-requested in use in bin.
2018-03-26 02:30:04.838012: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (8388608): 	Total Chunks: 12, Chunks in use: 12. 123.00MiB allocated for chunks. 123.00MiB in use in bin. 123.00MiB client-requested in use in bin.
2018-03-26 02:30:04.838046: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (16777216): 	Total Chunks: 13, Chunks in use: 13. 222.00MiB allocated for chunks. 222.00MiB in use in bin. 222.00MiB client-requested in use in bin.
2018-03-26 02:30:04.838075: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (33554432): 	Total Chunks: 11, Chunks in use: 11. 461.50MiB allocated for chunks. 461.50MiB in use in bin. 442.00MiB client-requested in use in bin.
2018-03-26 02:30:04.838100: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (67108864): 	Total Chunks: 23, Chunks in use: 23. 1.50GiB allocated for chunks. 1.50GiB in use in bin. 1.47GiB client-requested in use in bin.
2018-03-26 02:30:04.838124: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-03-26 02:30:04.838147: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-03-26 02:30:04.838172: I tensorflow/core/common_runtime/bfc_allocator.cc:644] Bin for 3.00MiB was 2.00MiB, Chunk State: 
2018-03-26 02:30:04.838203: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7093e0000 of size 1280
2018-03-26 02:30:04.838229: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7093e0500 of size 256
2018-03-26 02:30:04.838254: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7093e0600 of size 256
[...]
2018-03-26 02:30:04.842321: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7949c2300 of size 67108864
2018-03-26 02:30:04.842337: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7989c2300 of size 67108864
2018-03-26 02:30:04.842353: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x79c9c2300 of size 3145728
2018-03-26 02:30:04.842371: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x79ccc2300 of size 79944960
2018-03-26 02:30:04.842390: I tensorflow/core/common_runtime/bfc_allocator.cc:671] Free at 0x72ed32200 of size 19200
2018-03-26 02:30:04.842407: I tensorflow/core/common_runtime/bfc_allocator.cc:671] Free at 0x72edaed00 of size 611328
2018-03-26 02:30:04.842423: I tensorflow/core/common_runtime/bfc_allocator.cc:671] Free at 0x72ee45700 of size 256
2018-03-26 02:30:04.842442: I tensorflow/core/common_runtime/bfc_allocator.cc:677]      Summary of in-use Chunks by size: 
2018-03-26 02:30:04.842469: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 48 Chunks of size 256 totalling 12.0KiB
2018-03-26 02:30:04.842490: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 6 Chunks of size 512 totalling 3.0KiB
2018-03-26 02:30:04.842509: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 12 Chunks of size 1024 totalling 12.0KiB
2018-03-26 02:30:04.842527: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 1 Chunks of size 1280 totalling 1.2KiB
2018-03-26 02:30:04.842547: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 11 Chunks of size 2048 totalling 22.0KiB
2018-03-26 02:30:04.842565: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 1 Chunks of size 3584 totalling 3.5KiB
2018-03-26 02:30:04.842585: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 17 Chunks of size 4096 totalling 68.0KiB
2018-03-26 02:30:04.842604: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 6 Chunks of size 8192 totalling 48.0KiB
[...]
2018-03-26 02:30:04.843025: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 7 Chunks of size 75497472 totalling 504.00MiB
2018-03-26 02:30:04.843044: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 1 Chunks of size 79944960 totalling 76.24MiB
2018-03-26 02:30:04.843062: I tensorflow/core/common_runtime/bfc_allocator.cc:684] Sum Total of in-use chunks: 2.38GiB
2018-03-26 02:30:04.843086: I tensorflow/core/common_runtime/bfc_allocator.cc:686] Stats: 
Limit:                  2555510784
InUse:                  2554880000
MaxInUse:               2554880256
NumAllocs:                     303
MaxAllocSize:            364109056

2018-03-26 02:30:04.843151: W tensorflow/core/common_runtime/bfc_allocator.cc:277] ****************************************************************************************************
2018-03-26 02:30:04.843199: W tensorflow/core/framework/op_kernel.cc:1198] Resource exhausted: **OOM when allocating tensor with shape[64,3,64,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc**
Exception in thread Thread-1:
Traceback (most recent call last):
  File ""/home/hunterwolf/anaconda3/envs/faceswap/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1350, in _do_call
    return fn(*args)
  File ""/home/hunterwolf/anaconda3/envs/faceswap/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1329, in _run_fn
    status, run_metadata)
  File ""/home/hunterwolf/anaconda3/envs/faceswap/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py"", line 473, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[64,3,64,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[Node: model_2/conv2d_9/convolution = Conv2D[T=DT_FLOAT, data_format=""NHWC"", dilations=[1, 1, 1, 1], padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](model_2/pixel_shuffler_4/Reshape_1, conv2d_9/kernel/read)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

	 [[Node: loss/mul/_211 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_1608_loss/mul"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/hunterwolf/anaconda3/envs/faceswap/lib/python3.6/threading.py"", line 916, in _bootstrap_inner
    self.run()
  File ""/home/hunterwolf/anaconda3/envs/faceswap/lib/python3.6/threading.py"", line 864, in run
    self._target(*self._args, **self._kwargs)
  File ""/home/hunterwolf/AnacondaProjects/deepfakes-faceswap/scripts/train.py"", line 181, in processThread
    raise e
  File ""/home/hunterwolf/AnacondaProjects/deepfakes-faceswap/scripts/train.py"", line 161, in processThread
    trainer.train_one_step(epoch, self.show if (save_iteration or self.save_now) else None)
  File ""/home/hunterwolf/AnacondaProjects/deepfakes-faceswap/plugins/Model_Original/Trainer.py"", line 26, in train_one_step
    loss_A = self.model.autoencoder_A.train_on_batch(warped_A, target_A)
  File ""/home/hunterwolf/anaconda3/envs/faceswap/lib/python3.6/site-packages/keras/engine/training.py"", line 1839, in train_on_batch
    outputs = self.train_function(ins)
  File ""/home/hunterwolf/anaconda3/envs/faceswap/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py"", line 2357, in __call__
    **self.session_kwargs)
  File ""/home/hunterwolf/anaconda3/envs/faceswap/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 895, in run
    run_metadata_ptr)
  File ""/home/hunterwolf/anaconda3/envs/faceswap/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1128, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/hunterwolf/anaconda3/envs/faceswap/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1344, in _do_run
    options, run_metadata)
  File ""/home/hunterwolf/anaconda3/envs/faceswap/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1363, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[64,3,64,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[Node: model_2/conv2d_9/convolution = Conv2D[T=DT_FLOAT, data_format=""NHWC"", dilations=[1, 1, 1, 1], padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](model_2/pixel_shuffler_4/Reshape_1, conv2d_9/kernel/read)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

	 [[Node: loss/mul/_211 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_1608_loss/mul"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.


Caused by op 'model_2/conv2d_9/convolution', defined at:
  File ""/home/hunterwolf/anaconda3/envs/faceswap/lib/python3.6/threading.py"", line 884, in _bootstrap
    self._bootstrap_inner()
  File ""/home/hunterwolf/anaconda3/envs/faceswap/lib/python3.6/threading.py"", line 916, in _bootstrap_inner
    self.run()
  File ""/home/hunterwolf/anaconda3/envs/faceswap/lib/python3.6/threading.py"", line 864, in run
    self._target(*self._args, **self._kwargs)
  File ""/home/hunterwolf/AnacondaProjects/deepfakes-faceswap/scripts/train.py"", line 147, in processThread
    model = PluginLoader.get_model(trainer)(get_folder(self.arguments.model_dir), self.arguments.gpus)
  File ""/home/hunterwolf/AnacondaProjects/deepfakes-faceswap/plugins/Model_Original/AutoEncoder.py"", line 16, in __init__
    self.initModel()
  File ""/home/hunterwolf/AnacondaProjects/deepfakes-faceswap/plugins/Model_Original/Model.py"", line 22, in initModel
    self.autoencoder_A = KerasModel(x, self.decoder_A(self.encoder(x)))
  File ""/home/hunterwolf/anaconda3/envs/faceswap/lib/python3.6/site-packages/keras/engine/topology.py"", line 603, in __call__
    output = self.call(inputs, **kwargs)
  File ""/home/hunterwolf/anaconda3/envs/faceswap/lib/python3.6/site-packages/keras/engine/topology.py"", line 2061, in call
    output_tensors, _, _ = self.run_internal_graph(inputs, masks)
  File ""/home/hunterwolf/anaconda3/envs/faceswap/lib/python3.6/site-packages/keras/engine/topology.py"", line 2212, in run_internal_graph
    output_tensors = _to_list(layer.call(computed_tensor, **kwargs))
  File ""/home/hunterwolf/anaconda3/envs/faceswap/lib/python3.6/site-packages/keras/layers/convolutional.py"", line 164, in call
    dilation_rate=self.dilation_rate)
  File ""/home/hunterwolf/anaconda3/envs/faceswap/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py"", line 3195, in conv2d
    data_format=tf_data_format)
  File ""/home/hunterwolf/anaconda3/envs/faceswap/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py"", line 754, in convolution
    return op(input, filter)
  File ""/home/hunterwolf/anaconda3/envs/faceswap/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py"", line 838, in __call__
    return self.conv_op(inp, filter)
  File ""/home/hunterwolf/anaconda3/envs/faceswap/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py"", line 502, in __call__
    return self.call(inp, filter)
  File ""/home/hunterwolf/anaconda3/envs/faceswap/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py"", line 190, in __call__
    name=self.name)
  File ""/home/hunterwolf/anaconda3/envs/faceswap/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 639, in conv2d
    data_format=data_format, dilations=dilations, name=name)
  File ""/home/hunterwolf/anaconda3/envs/faceswap/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/home/hunterwolf/anaconda3/envs/faceswap/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3160, in create_op
    op_def=op_def)
  File ""/home/hunterwolf/anaconda3/envs/faceswap/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1625, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[64,3,64,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
[[Node: model_2/conv2d_9/convolution = Conv2D[T=DT_FLOAT, data_format=""NHWC"", dilations=[1, 1, 1, 1], padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](model_2/pixel_shuffler_4/Reshape_1, conv2d_9/kernel/read)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

[[Node: loss/mul/_211 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_1608_loss/mul"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

```"
17993,deprecation warnings in contrib.graph_editor,"Calling the method `tf.contrib.graph_editor.graph_replace` like
```
C = tf.contrib.graph_editor.graph_replace(C, {A: B})
```
returns a ton of warnings of the type:
```
WARNING:tensorflow:Operation._node_def is private, use Operation.node_def instead. Operation._node_def will eventually be removed.
WARNING:tensorflow:Operation._op_def is private, use Operation.op_def instead. Operation._op_def will eventually be removed.
WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.
```
and later a ton of warnings about `_control_input`
```
WARNING:tensorflow:Operation._control_inputs is private, use Operation.control_inputs instead. Operation._control_inputs will eventually be removed.
WARNING:tensorflow:Operation._control_inputs is private, use Operation.control_inputs instead. Operation._control_inputs will eventually be removed.
```
I'm guessing this doesn't actually require too many changes but is mostly a question of updating a few function calls to use the suggested names?

The error originally came up in 1.5, as can be seen from the system info extract below, but I also just tried it in 1.6. From inspecting the source, I also do not think it has been fixed in 1.7. 

edit: okay, some of the issues seem to have been fixed in the master branch, is this verifiable?


------------------------
== cat /etc/issue ===============================================
Linux rabo-Latitude-E7450 4.4.0-116-generic #140-Ubuntu SMP Mon Feb 12 21:23:04 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""16.04.4 LTS (Xenial Xerus)""
VERSION_ID=""16.04""
VERSION_CODENAME=xenial

== are we in docker =============================================
No

== compiler =====================================================
c++ (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux rabo-Latitude-E7450 4.4.0-116-generic #140-Ubuntu SMP Mon Feb 12 21:23:04 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy (1.12.1)
numpydoc (0.6.0)

== check for virtualenv =========================================
False

== tensorflow import ============================================
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
ImportError: No module named 'tensorflow'

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
./tf_issue_collect.sh: line 105: nvidia-smi: command not found

== cuda libs  ===================================================

== cat /etc/issue ===============================================
Linux rabo-Latitude-E7450 4.4.0-116-generic #140-Ubuntu SMP Mon Feb 12 21:23:04 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""16.04.4 LTS (Xenial Xerus)""
VERSION_ID=""16.04""
VERSION_CODENAME=xenial

== are we in docker =============================================
No

== compiler =====================================================
c++ (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux rabo-Latitude-E7450 4.4.0-116-generic #140-Ubuntu SMP Mon Feb 12 21:23:04 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy (1.14.0)
protobuf (3.5.1)
tensorflow (1.5.0)
tensorflow-tensorboard (1.5.0)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.5.0
tf.GIT_VERSION = b'v1.5.0-1846-ga58f26d'
tf.COMPILER_VERSION = b'v1.5.0-1846-ga58f26d'
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
./tf_issue_collect.sh: line 105: nvidia-smi: command not found

== cuda libs  ===================================================
/usr/local/MATLAB/R2015b/bin/glnxa64/libcudart.so.7.0.28
"
17991,Tensorflow sequence mask without reducing dimensions,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution**: Linux Ubuntu 16.04
- **TensorFlow installed from**: binary
- **TensorFlow version**: 1.4.0
- **Python version**: 3.5.2
- **Bazel version (if compiling from source)**: not compiled from source
- **GCC/Compiler version (if compiling from source)**: not compiled from source
- **CUDA/cuDNN version**: 8.0/6
- **GPU model and memory**: 8GB x 4 GTX 1080
- **Exact command to reproduce**: N/A


I have a sample code to run:
    
    import numpy a np
    import tensorflow as tf
    import tensorflow.contrib.eager as tfe
    tfe.enable_eager_execution()
    
    x = np.random.randint(100,size=(4,4))
    indexes =tf.sequence_mask([1,2,2,4],4)
    """"""
    indexes = [
    	[True,False,False,False],
    	[True,True,False,False],
    	[True,True,False,False],
    	[True,True,True,True],
    ]
    """"""
    
    y = tf.boolean_mask(x,indexes)
    # y = array([43, 78, 68, 54, 46, 28, 15, 52,  3])

Now, I don't want this as the spatial information of the original tensor is lost and I want to keep the shape intact. How can do that in tensorflow since I work with RNN data so my tensor size is = `[batch_size, max_time, feature_length]` where I would slice it such that:

`indexes = tf.sequence_mask([x_1, x_2, x_3, ..., x_batch_size], max_time)`

but still want to keep the shape intact. If its not possible, is there a way to sequence mask on multiple tensors of such size while also concatenating them so that only the extracted sequence would remain and not the masked out paddings? Paddings could be applied on the end of the concatenation."
17987,graph.pb.h missing in cc tutorial,"In tensorflow > cc > tutorials >>graph.pb.h , the code includes the header file `graph.pb.h` . However in the path it specifies (`tensorflow/core/framework/)` there is no such file.

Where is this header file located? I could not find it inside the tensorflow master branch."
17986,Tensorflow 1.6.0 on ARMv7 import error,"Hi there,

I compiled Bazel and Tensorflow 1.6.0 on an ARMv7 board (OrangePI Zero 512MB) successfully without any error and built the python wheel, Here are related info : 

### System information
- Have I written custom code : no
- OS Platform and Distribution : Armbian 5.41 (Ubuntu 16.04.3 LTS - Kernel 4.14.18-sunxi)
- TensorFlow installed from : source
- TensorFlow version : 1.6.0
- Bazel version : 0.11.1
- CUDA/cuDNN version : N/A
- GPU model and memory : N/A
- Exact command to reproduce : import tensorflow as tf
- Build command : 
`bazel build -c opt --copt=""-mfpu=neon-vfpv4"" --copt=""-funsafe-math-optimizations"" --copt=""-ftree-vectorize"" --copt=""-fomit-frame-pointer"" --local_resources 512,1.0,1.0 --verbose_failures tensorflow/tools/pip_package:build_pip_package`

In python when I import tensorflow I get this error : 
`
ImportError: /home/user/.local/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZN10tensorflow9ConcatCPUINS_8bfloat16EEEvPNS_10DeviceBaseERKSt6vectorISt10unique_ptrINS_6TTypesIT_Li2EiE11ConstMatrixESt14default_deleteIS9_EESaISC_EEPNS8_6MatrixE
`



"
17985,"name_scope problem of ""tensorflow/python/layers/normalization.py""","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 64bit
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: 1.7.0-rc1 (GPU version from pip)
- **Python version**:  3.6.2
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: 9.0
- **GPU model and memory**: GTX 1080Ti 11GB
- **Exact command to reproduce**: See below


### Describe the problem
I found this problem when I am using `tf.layers.batch_normalization()`. For example, the following code:
```python
import tensorflow as tf

inData = tf.placeholder(shape = [1,1], name = 'input', dtype = tf.float32) 
with tf.name_scope('layer1'):
    with tf.name_scope('fully_connected'):
        W = tf.Variable( [[0.]] ,name='W')
        b = tf.Variable( [0.], name='bias')
        x = tf.matmul( inData, W ) + b

    normalized = tf.layers.batch_normalization(x, fused = True, reuse = False)
    
loss = tf.reduce_sum(normalized)

with tf.Session() as sess:
    # record computation graph
    writer = tf.summary.FileWriter('BN_test', sess.graph)
    writer.close()
```
Will generate the following computation graph:
![bn_problem](https://user-images.githubusercontent.com/8580553/37874558-ae939870-3063-11e8-82f1-72349b32f369.png)

While what I expect is: the variables ""gamma"", ""beta"", ""moving_mean"" etc. should all inside the name_scope ""layer1/batch_normalization/"" but not ""batch_normalization/""

So I  refer to the code ""[tensorflow/python/layers/normalization.py](https://github.com/tensorflow/tensorflow/blob/r1.7/tensorflow/python/layers/normalization.py)""
Around line 301 ~ 361, I found:
![image](https://user-images.githubusercontent.com/8580553/37874572-041a6dbe-3064-11e8-98b7-860e7dc157eb.png)

It seems that here the name_scope was cleaned in order to support the 'reuse' option. But this should only affect ""moving_mean"" and ""moving_variance"", not ""beta"" and ""gamma"". However, as shown above, all of them was affected.
 In fact, if we add `` print(self._scope.partitioner) `` just before line 302, we will found that self._scope.partitioner is always ``None``.

### Summary
1. self._scope is probably not set correctly.
2. Suggestion: I want an option to tell the program ""I will never reuse the weights"", thus do not clean the name_scope of ""moving_mean"" and ""moving_variance"". Otherwise, the graph in tensorboard is too messy......
"
17984,Tensorflow Lite not support Siamese network with parameter sharing,"Hi,

I found that the Tensorflow Lite did not support Siamese network with parameter sharing of conv2d layers and batch normalization layers yet. (e.g. EnsureBiasVectors will fail to deal with different names of conv output layer with the same kernel.) Is there any plan to support it?

Thanks."
17983,OpKernel   for unknown op: HashTable  And   incompatible with expected float_ref,"OS Platform : Cestos7
python:2.7
gcc:4.8
TensorFlow installed from source 
tf version :  ('v1.4.0-19-ga52c8d9', '1.4.1')
Bazel version:N/A
CUDA Version 8.0.61
CUDNN_MAJOR  : 6
GPU model and memory: 22912MiB*4
Exact command to reproduce:

freeze:CUDA_VISIBLE_DEVICES=""1"" python freeze_graph.py --checkpoint_dir='./models/dpner/checkpoints/' --graph_pb='./models/dpner/checkpoints/graph.pb' --output_node_names='forward/unary_scores/shape,forward/unary_scores,loss/transitions,loss/transitions/Assign,loss/transitions/read' --output_dir='./models'

-----------------------------------------------

2018-03-25 07:49:05.497590: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""LeftShift"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT8 } } }') for unknown op: LeftShift
2018-03-25 07:49:05.497623: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""LookupTableInsert"" device_type: ""CPU""') for unknown op: LookupTableInsert
2018-03-25 07:49:05.497679: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""HashTable"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_INT32 } } }') for unknown op: HashTable


---------------------------------------------


Invalid argument: Input 0 of node loss/transitions/Assign was passed float from loss/transitions:0 incompatible with expected float_ref.


---------------------------------------------

**In my model**: 

all variable is similar

`with tf.variable_scope(""softmax"") as scope:
            self.W = tf.get_variable(
                shape=[hidden_dim * 2, num_classes], 
                initializer=tf.truncated_normal_initializer(stddev=0.01), 
                name=""weights"",
                regularizer=tf.contrib.layers.l2_regularizer(self.l2_reg_lambda))

saver = tf.train.Saver(tf.global_variables())

saver.save(sess, checkpoint_prefix, global_step=current_step)
`

**In freeze**, 
[freeze_graph.py.log](https://github.com/tensorflow/tensorflow/files/1845141/freeze_graph.py.log)

and _**in c++**_ is :
`
Session* session;

Status status = NewSession(SessionOptions(), &session);

GraphDef graph_def;

status = ReadBinaryProto(Env::Default(),  path, &graph_def);

status = session->Create(graph_def);
`


----------------------------------------------------

"
17981,AttributeError: module 'tensorflow.python.ops.nn' has no attribute 'leaky_relu',"Using https://github.com/hizhangp/yolo_tensorflow I get the following error. How should I fix it?
```
[jalal@goku yolo_tensorflow]$ /scratch/sjn/anaconda/bin/python train.py 
Traceback (most recent call last):
  File ""train.py"", line 164, in <module>
    main()
  File ""train.py"", line 151, in main
    yolo = YOLONet()
  File ""/scratch2/body_pose/yolo_tensorflow/yolo/yolo_net.py"", line 41, in __init__
    is_training=is_training)
  File ""/scratch2/body_pose/yolo_tensorflow/yolo/yolo_net.py"", line 69, in build_network
    net, 64, 7, 2, padding='VALID', scope='conv_2')
  File ""/scratch/sjn/anaconda/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py"", line 181, in func_with_args
    return func(*args, **current_args)
  File ""/scratch/sjn/anaconda/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py"", line 1039, in convolution
    outputs = activation_fn(outputs)
  File ""/scratch2/body_pose/yolo_tensorflow/yolo/yolo_net.py"", line 244, in op
    return tf.nn.leaky_relu(inputs, alpha=alpha, name='leaky_relu')
AttributeError: module 'tensorflow.python.ops.nn' has no attribute 'leaky_relu'


```"
17980,tf.einsum doesn't perform common subgraph elimination,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: RHEL 7.4
- **TensorFlow installed from (source or binary)**: Binary (pip)
- **TensorFlow version (use command below)**: 'unknown' 1.6.0
- **Python version**: 3.6
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A


### Describe the problem
When I inspect the computation graph in tensorboard, there are two separate calls to einsum and no subgraphs (ie calls to matmul) are shared. I would have expected the ""jb,abcd"" tensors to be contracted once, then contracted with (ia + ai) afterwards. 

### Source code / logs
```
tf_eri = tf.constant(np.random.random([10,10,10,10])
tf_ao = tf.constant(np.random.random([10,10])

tf_foo = tf.einsum(""ia,jb,abcd"", tf_ao, tf_ao, tf_eri)
tf_bar = tf.einsum(""ai,jb,abcd"", tf_ao, tf_ao, tf_eri)
tf_res = tf_foo + tf_bar
```

![graph](https://user-images.githubusercontent.com/1048117/37871855-3a6564d0-2fc6-11e8-961b-a34d14175e50.png)
"
17979,"tensorflow.python.framework.errors_impl.InvalidArgumentError: Invalid JPEG data or crop window, data size 15022 ","On the terminal window, it runs fine when an image is passed to tensorflow for image object recognition using:

`python run.py http://image_url.jpg`

However, with JSON data that contains stream of imageURL, it failed with the following main error:

    InvalidArgumentError: Invalid JPEG data or crop window, data size 15022
	 [[Node: DecodeJpeg = DecodeJpeg[acceptable_fraction=1, channels=3, dct_method="""", fancy_upscaling=true, ratio=1, try_recover_truncated=false, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_DecodeJpeg/contents_0_0)]]
    Caused by op u'DecodeJpeg'

Another error encountered:

`ValueError: GraphDef cannot be larger than 2GB.`


Below is my tensorflow source code as a function(again it runs with single ImageUrl passed as parameter):

    import tensorflow as tf
    import sys
    import os
    import urllib2
    
    def tensorflow_pred(imageUrl):
    
        #suppress TF log-info messages - remove to display TF logs 
        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
    
        response = urllib2.urlopen(imageUrl)
    
        image_data = response.read()
    
        # Loads label file, strips off carriage return
        label_lines = [line.rstrip() for line 
                        in tf.gfile.GFile(""./retrained_labels.txt"")]
    
        # Unpersists graph from file
        with tf.gfile.FastGFile(""./retrained_graph.pb"", 'rb') as f:
            graph_def = tf.GraphDef()
            graph_def.ParseFromString(f.read())
            _ = tf.import_graph_def(graph_def, name='')
    
        with tf.Session() as sess:
            # Feed the image_data as input to the graph and get first prediction
            softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')
            
            predictions = sess.run(softmax_tensor, \
                    {'DecodeJpeg/contents:0': image_data})
            
            # Sort to show labels of first prediction in order of confidence
            top_k = predictions[0].argsort()[-len(predictions[0]):][::-1]
            
            for node_id in top_k:
                classification = label_lines[node_id]
                score = predictions[0][node_id]
                if (score >=0.5):
                    return ('%s (score = %.5f)' % (classification, score))
            "
17978,Tensorflow not working properly in Python sub-interperters,"### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 64 bit Professional
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.5.0
- **Python version**:  3.6.3
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: None
- **GPU model and memory**: None
- **Exact command to reproduce**: import tensorflow as tf on a Python wsgi application written in Flask
- **Have I written custom code**: N/A

### Describe the problem

This is a follow-up to a problem that I described in a stackoverflow post today:
https://stackoverflow.com/questions/49471240/slow-page-loading-on-apache-when-using-flask/49471633#49471633

The summary of the issue is that when trying to import tensorflow in a web application written in Flask and hosted on Apache, the page never loads up because of the tensorflow import. 

From the reply, they suggested that Tensorflow, being a C extension does not yet provide proper support to be run on python sub-interpreters. 

They also suggested a workaround that worked for me, which was to force wsgi application to run on the primary python process.

I admit that I don't really understand the scope of the problem, but I thought it might be worth mentioning this issue and understand if it is something that could be/should be fixed.

"
17977,OOM after repeatedly evaluating inception scores,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.6
- **Python version**: 2.7



Hi, I run my generative model and evaluate the inception score of the generated images every now and then and encountered out of memory after a lot of iterations. I don't know what the cause is since I built the graph and just feed some values to it. 
My code goes as follows:

```
session=tf.InteractiveSession()

inception_samples = tf.placeholder(tf.float32, shape=[INCEPTION_BATCHES*BATCH_SIZE, DATA_DIM])

def get_inception_score_op(inception_samples=inception_samples):
    inception_samples=tf.reshape(inception_samples,[BATCH_SIZE*INCEPTION_BATCHES,NUM_CHANNELS,HEIGHT,WIDTH])
    inception_samples=tf.transpose(inception_samples,[0,2,3,1])
    return lib.classifier_score.get_inception_scores(\
    inception_samples,batch_size=BATCH_SIZE*INCEPTION_BATCHES, num_inception_images=BATCH_SIZE)

inception_score=get_inception_score_op()

def get_inception_score():
    all_samples = []
    for i in xrange(INCEPTION_BATCHES):# inception score for num_batches of fake data
        all_samples.append(session.run(fake_sample))     
    all_samples = np.concatenate(all_samples, axis=0)
    return inception_score.eval({inception_samples:all_samples})
for i in range(ITERATIONS):
    print get_inception_score()
```

where  ""lib.classifier_score.get_inception_scores"" is from the file
[# https://github.com/tensorflow/models/blob/master/research/gan/cifar/util.py](url)
that looks like this:
```
tfgan = tf.contrib.gan

def get_inception_scores(images, batch_size, num_inception_images):
  """"""Get Inception score for some images.

  Args:
    images: Image minibatch. Shape [batch size, width, height, channels]. Values
      are in [-1, 1].
    batch_size: Python integer. Batch dimension.
    num_inception_images: Number of images to run through Inception at once.

  Returns:
    Inception scores. Tensor shape is [batch size].

  Raises:
    ValueError: If `batch_size` is incompatible with the first dimension of
      `images`.
    ValueError: If `batch_size` isn't divisible by `num_inception_images`.
  """"""
  # Validate inputs.
  assert images.shape[-1]==3
  tf.TensorShape(images.shape)[0:1].assert_is_compatible_with([batch_size])
  if batch_size % num_inception_images != 0:
    raise ValueError(
        '`batch_size` must be divisible by `num_inception_images`.')

  # Resize images.
  size = 299
  resized_images = tf.image.resize_bilinear(images, [size, size])

  # Run images through Inception.
  num_batches = batch_size // num_inception_images
  inc_score = tfgan.eval.inception_score(
      resized_images, num_batches=num_batches)

  return inc_score
```
except that I made some minor changes to it.

I guess `tf.contrib.gan.eval.inception_score()` have been taking up my GPU memory."
17976,AttributeError: '_LSTMModel' object has no attribute '_get_exogenous_embedding_shape',"### System information
**Ubuntu 16.04**
**Tensorflow 1.6**

### Describe the problem

When I try to execute 

> **tensorflow/tensorflow/contrib/timeseries/examples/lstm.py**

 the next error appears:

```
WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp1pp2uy_k
Traceback (most recent call last):
  File ""lstm.py"", line 296, in <module>
    tf.app.run(main=main)
  File ""/home/proto/anaconda3/envs/tensor/lib/python3.5/site-packages/tensorflow/python/platform/app.py"", line 124, in run
    _sys.exit(main(argv))
  File ""lstm.py"", line 284, in main
    all_times, predictions) = train_and_predict()
  File ""lstm.py"", line 219, in train_and_predict
    estimator.train(input_fn=train_input_fn, steps=training_steps)
  File ""/home/proto/anaconda3/envs/tensor/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py"", line 314, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/home/proto/anaconda3/envs/tensor/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py"", line 743, in _train_model
    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)
  File ""/home/proto/anaconda3/envs/tensor/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py"", line 725, in _call_model_fn
    model_fn_results = self._model_fn(features=features, **kwargs)
  File ""/home/proto/anaconda3/envs/tensor/lib/python3.5/site-packages/tensorflow/contrib/timeseries/python/timeseries/head.py"", line 225, in create_estimator_spec
    model=self.model, input_statistics=input_statistics)
  File ""/home/proto/anaconda3/envs/tensor/lib/python3.5/site-packages/tensorflow/contrib/timeseries/python/timeseries/state_management.py"", line 147, in initialize_graph
    self._start_state = model.get_start_state()
  File ""lstm.py"", line 114, in get_start_state
    tf.zeros(self._get_exogenous_embedding_shape(), dtype=self.dtype),
AttributeError: '_LSTMModel' object has no attribute '_get_exogenous_embedding_shape'
```

Seems that the pull is coming from @gunan, @tensorflower-gardener,  authored by @allenlavoie 


EDIT: If I hard-code the 'self._get_exogenous_emebedding_shape()' (line 114 in lstm.py file) to 0, I get the next error also:

```
Traceback (most recent call last):
  File ""lstm.py"", line 296, in <module>
    tf.app.run(main=main)
  File ""/home/proto/anaconda3/envs/tensor/lib/python3.5/site-packages/tensorflow/python/platform/app.py"", line 124, in run
    _sys.exit(main(argv))
  File ""lstm.py"", line 284, in main
    all_times, predictions) = train_and_predict()
  File ""lstm.py"", line 219, in train_and_predict
    estimator.train(input_fn=train_input_fn, steps=training_steps)
  File ""/home/proto/anaconda3/envs/tensor/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py"", line 314, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/home/proto/anaconda3/envs/tensor/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py"", line 743, in _train_model
    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)
  File ""/home/proto/anaconda3/envs/tensor/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py"", line 725, in _call_model_fn
    model_fn_results = self._model_fn(features=features, **kwargs)
  File ""/home/proto/anaconda3/envs/tensor/lib/python3.5/site-packages/tensorflow/contrib/timeseries/python/timeseries/head.py"", line 228, in create_estimator_spec
    return self._train_ops(features)
  File ""/home/proto/anaconda3/envs/tensor/lib/python3.5/site-packages/tensorflow/contrib/timeseries/python/timeseries/head.py"", line 78, in _train_ops
    self.model, features, estimator_lib.ModeKeys.TRAIN)
  File ""/home/proto/anaconda3/envs/tensor/lib/python3.5/site-packages/tensorflow/contrib/timeseries/python/timeseries/state_management.py"", line 93, in define_loss
    model=model, features=features, mode=mode)
  File ""/home/proto/anaconda3/envs/tensor/lib/python3.5/site-packages/tensorflow/contrib/timeseries/python/timeseries/state_management.py"", line 182, in _define_loss_with_saved_state
    mode=mode)
  File ""/home/proto/anaconda3/envs/tensor/lib/python3.5/site-packages/tensorflow/contrib/timeseries/python/timeseries/state_management.py"", line 237, in _update_cached_states
    state=looked_up_state)
  File ""/home/proto/anaconda3/envs/tensor/lib/python3.5/site-packages/tensorflow/contrib/timeseries/python/timeseries/model.py"", line 588, in per_step_batch_loss
    features={key: value for key, value in features.items()
  File ""/home/proto/anaconda3/envs/tensor/lib/python3.5/site-packages/tensorflow/contrib/timeseries/python/timeseries/model.py"", line 296, in _process_exogenous_features
    trainable=True))
  File ""/home/proto/anaconda3/envs/tensor/lib/python3.5/site-packages/tensorflow/contrib/layers/python/layers/feature_column_ops.py"", line 221, in input_from_feature_columns
    cols_to_outs=cols_to_outs)
  File ""/home/proto/anaconda3/envs/tensor/lib/python3.5/site-packages/tensorflow/contrib/layers/python/layers/feature_column_ops.py"", line 104, in _input_from_feature_columns
    check_feature_columns(feature_columns)
  File ""/home/proto/anaconda3/envs/tensor/lib/python3.5/site-packages/tensorflow/contrib/layers/python/layers/feature_column_ops.py"", line 776, in check_feature_columns
    key = f.key
AttributeError: '_EmbeddingColumn' object has no attribute 'key'


```"
17974,QuantizedConv2D dimension mismatch,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Y
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Arch
- **TensorFlow installed from (source or binary)**: binary / source for transform_graph
- **TensorFlow version (use command below)**:  1.6
- **Python version**:  3.6
- **Bazel version (if compiling from source)**: 0.11.1-1
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: 9.1
- **GPU model and memory**: GTX  1060
- **Exact command to reproduce**: 

I have a frozen model (frozen.pb) and followed the guideline to produce `quantized.pb`.
Inference with frozen.pb is ok but with quantized.pb it crashes on `tf.import_graph_def`.

If the quantized model expects the same shape of input/output, just replacing frozen.pb with quantized.pb should work.

- I followed https://www.tensorflow.org/performance/quantization
- quantized with this command:
```
../tensorflow/bazel-bin/tensorflow/tools/graph_transforms/transform_graph \
  --in_graph=graph_def/frozen.pb \
  --out_graph=graph_def/quantized.pb \
  --inputs=img \
  --outputs=out1,out2,out3,out4,out5,out6 \
  --transforms='add_default_attributes strip_unused_nodes(type=float, shape=""1,3,256,256"")
    remove_nodes(op=Identity, op=CheckNumerics) fold_constants(ignore_errors=true)
    fold_batch_norms fold_old_batch_norms quantize_weights quantize_nodes
    strip_unused_nodes sort_by_execution_order'
```
- backtrace:
```py
Traceback (Most recent call last):
8    test_tf.py                                                                    <module>                --> detector = Detector()                              
114  /home/user/project/net_tf.py                                             __init__                --> tf.import_graph_def(graph_def, name='')            
432  /usr/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py        new_func                --> return func(*args, **kwargs)                       
663  /usr/lib/python3.6/site-packages/tensorflow/python/framework/importer.py      import_graph_def        --> ops.set_shapes_for_outputs(op)                     
2501 /usr/lib/python3.6/site-packages/tensorflow/python/framework/ops.py           set_shapes_for_outputs  --> return _set_shapes_for_outputs(op)                 
2474 /usr/lib/python3.6/site-packages/tensorflow/python/framework/ops.py           _set_shapes_for_outputs --> shapes = shape_func(op)                            
2404 /usr/lib/python3.6/site-packages/tensorflow/python/framework/ops.py           call_with_requiring     --> return call_cpp_shape_fn(op, require_shape_fn=True)
627  /usr/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py call_cpp_shape_fn       --> require_shape_fn)                                  
691  /usr/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py _call_cpp_shape_fn_impl --> raise ValueError(err.message)                      
ValueError: Dimensions must be equal, but are 32 and 64 for 'conv2_1/Conv2D/eightbit' (op: 'QuantizedConv2D') with input shapes: [1,3,?,32], [3,3,64,128], [], [], [], [].
> /usr/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py(691)_call_cpp_shape_fn_impl()
```

- related model code:
```py
    max_pool = tf.contrib.layers.max_pool2d

    x = tf.placeholder(tf.float32, shape=[1, 3, None, None], name='img')

    x = relu(conv2d(x, 64, kernel_size=3, padding='same', data_format='channels_first', name='conv1_1'))
    x = relu(conv2d(x, 64, kernel_size=3, padding='same', data_format='channels_first', name='conv1_2'))
    x = max_pool(x, kernel_size=2, data_format='NCHW')

    x = relu(conv2d(x, 128, kernel_size=3, padding='same', data_format='channels_first', name='conv2_1'))
    x = relu(conv2d(x, 128, kernel_size=3, padding='same', data_format='channels_first', name='conv2_2'))
    x = max_pool(x, kernel_size=2, data_format='NCHW')
...
```

This is fully convolutional, and the channel number goes from 3 to 64 and 128.
So 32 in the error message comes out of nowhere. (Is [1,3,?,32] a NCHW shape or conv2d kernel shape?)

Can it be related to NCHW? Somehow max_pool halves the channel number instead of spatial dimensions, then it explains how 32 appears (64/2=32).
"
17973,Losing Output Shape information of conv2d_transpose layer when importing from .pbtxt file,"- [x] This is a custom code
- [x] I'm on Mac OSX 10.11.16
- [x] TensorFlow version 1.6.0
- [x] Bazel version N/A
- [x]  Tensorflow installed from source
- [x] CUDA/cuDNN version N/A
- [x] GPU model and memory N/A

- [x] Exact command to reproduce



The output shape of the node with node. Type `Conv2DBackpropInput` seems to lose height and width information as in this:
This is denconv layer definition and conv3 layer after it
`deconv = tf.layers.conv2d_transpose(pool2 , filters = 32 ,kernel_size = [2,2],strides=(1, 1) , padding = ""same"")


conv3 = tf.layers.conv2d(inputs= deconv,filters=64,kernel_size=[1, 1],padding=""same"", activation=tf.nn.relu)`

`graph = tf.get_default_graph()` is built in the notebook

    for node in graph.get_operations():
      if node.type == ""Conv2DBackpropInput"":
        print(node.type,""---->>>>>"", ""outputsshape ----"" , node.outputs[0].get_shape())

**Output:**
 
    Conv2DBackpropInput ---->>>>> outputsshape ---- (?, 7, 7, 32)


Same graph converted to .pbtxt by:

    tf.train.write_graph(graph, ""graphx/"" , ""sample_this_1.pbtxt"")

Reading it again from .pbtxt

    tf.reset_default_graph()
    gram = tf.get_default_graph()
    gram.get_operations()
    from tensorflow.core.framework import graph_pb2
    from google.protobuf import text_format as pbtf
    
    gdef = graph_pb2.GraphDef()
    
    with open('graphx/sample_this_1.pbtxt', 'r') as f:
        graph_str = f.read()
    
    pbtf.Merge(graph_str, gdef)
    
    tf.import_graph_def(gdef)


Now doing the same for `gram` I get,

    for node in gram.get_operations():
      if node.type == ""Conv2DBackpropInput"":
        print(node.type,""---->>>>>"", ""outputsshape ----"" , node.outputs[0].get_shape())

**Output:**

    Conv2DBackpropInput ---->>>>> outputsshape ---- (?, ?, ?, 32)


So, the `outputs --- shape` went from (? ,7 ,7 ,32) to (? , ? , ? ,32) after reading from .pbtxt

Why is that? Is it a bug because output_shape is a part of model definition I guess?

Thanks."
17971,SVD example not rendering properly in docs,"

### System information

- **OS Platform and Distribution ( Linux Ubuntu 16.04)**:
- **TensorFlow version (master)**:


### Describe the problem
Tensorflow docs for `svd` example not rendering 

![image](https://user-images.githubusercontent.com/2484004/37867110-4a59f9d4-2f6a-11e8-9d46-e1f74b860622.png)
"
17969,Estimator not running custom init_op when loading from checkpoint,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Mint
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.6
- **Python version**: 3.5
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

### Describe the problem
tf.estimator does not initialize all model variables in the following scenario:
The model function provides a custom Saver that restores a subset of the GLOBAL_VARIABLES,
and a custom init_op that initializes the non-restored variables. 

In `SessionManager.prepare_session` there is the following code:
```
    if not is_loaded_from_checkpoint:
      if init_op is None and not init_fn and self._local_init_op is None:
        raise RuntimeError(""Model is not initialized and no init_op or ""
                           ""init_fn or local_init_op was given"")
      if init_op is not None:
        sess.run(init_op, feed_dict=init_feed_dict)
      if init_fn:
        init_fn(sess)

    local_init_success, msg = self._try_run_local_init_op(sess)
    if not local_init_success:
      raise RuntimeError(
          ""Init operations did not make model ready for local_init.  ""
          ""Init op: %s, init fn: %s, error: %s"" % (_maybe_name(init_op),                                               init_fn, msg))
```

The session manager does not run the `init_op` when loading from a checkpoint. It probabily would make sense to try the `init_op` at least in cases where `local_init_success` is `False` before aborting with an error.

If you agree I can create a PR, otherwise it would make sense to update the documentation to explicitely state that init won't be run in these scenarios (that should probably go in https://www.tensorflow.org/api_docs/python/tf/train/Scaffold)"
17968,tensorflow process hangs with use of cudnn_rnn,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**: 3.6.2
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: 8.0.61/6.0.21
- **GPU model and memory**: 1080 8GB
- **Exact command to reproduce**:

### Describe the problem
I ran a RNN model with tensorflow.contrib.cudnn_rnn.CudnnLSTM. After some epochs, the process hangs and never respond, even with `ctrl + c`. I also observed the volatile gpu-util fixes at 100% after the hang. This was not a problem when I ran the RNN with tensorflow.contrib.rnn.LSTMCell

### Source code / logs
call stacks of all Threads is here: 
https://pastebin.com/sNxC6fWC

"
17967,line 1: 51405 Floating point exception when using keras,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
I'm using keras at the server.
When I use it, I got this message.
What is the problem and how can I solve it.

### Source code / logs
line 1: 51405 Floating point exception
"
17965,TensorArray does not work inside `else` clause of `tf.cond`,"
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Custom code
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux 
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 'v1.5.0-0-g37aa430', '1.5.0'
- **Python version**:  2.7
- **Exact command to reproduce**:

```python
    import tensorflow as tf
    def body(v):
        m = tf.constant([v, v])
        ta = tf.TensorArray(dtype=tf.float32, size=1)
        t = ta.write(0, m)
        return t

    cond = tf.constant(False)
    t = tf.cond(cond, true_fn=lambda : body(2.0), false_fn=lambda : body(3.0))

    with tf.Session() as ss:
        print(ss.run(t.stack()))
```

The code above leads to the following error:

Traceback (most recent call last):
  File ""./array_cond.py"", line 69, in <module>
    print(ss.run(t.stack()))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 895, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1128, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1344, in _do_run
    options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1363, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Retval[0] does not have value

Interestingly if `False` is replace with `True` it works as expected."
17962,Stopping back-prop when using tf.cond,"I am trying to stop back-prop from happening through one branch of a tf.cond statement. I am doing two forward passes through a CNN and trying to only back-prop the one with lower TCE (train_cross_entropy). The code is as follows: 
```    
def f1(): 
        with tf.control_dependencies([tf.stop_gradient(train_cross_entropy2)]):
            return train_cross_entropy1
def f2():
        with tf.control_dependencies([tf.stop_gradient(train_cross_entropy1)]):
            return train_cross_entropy2
train_cross_entropy = tf.cond(train_cross_entropy1 < train_cross_entropy2, f1, f2) 
```
The speed of this approach is equivalent to writing: 
```
train_cross_entropy = tf.add(train_cross_entropy1, train_cross_entropy2)
```
Whereas I would hope that the speed would be more similar to
```
train_cross_entropy = tf.add(train_cross_entropy1, tf.stop_gradient(train_cross_entropy2))
```
which happens to compute gradients about twice as fast.
I opened up a stack overflow question (https://stackoverflow.com/questions/49436264/proper-use-of-tf-cond-in-cnn/49439351) but I haven't found any help and I am wondering if this is the expected behaviour? 
How do I go about stopping gradients from being calculated backwards through both parts of the graph? 
Thanks!"
17958,Shuffling slows down iterator at consumption,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 17.10
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.4.1 (v1.4.1-9-gc646af1957)
- **Python version**: 3.6.3
- **Bazel version (if compiling from source)**: 0.11.1
- **GCC/Compiler version (if compiling from source)**: 6.4.0
- **CUDA/cuDNN version**: 9.0
- **GPU model and memory**: NVidia GeForce GTX 1060 6GB
- **Exact command to reproduce**: python3 minimal_shuffle_bug.py

### Describe the problem
Adding shuffling during the definition of a `tf.data.Dataset` Graph results in a progressive slowdown during the iterations that consume the data, up to the start of a new epoch (when restarting an iteration over the full dataset). I believe this is a bug, or if it's a normal state of things given internal memory usage in the dataset pipeline, then I'd like to request this to be documented in the documentation, e.g., in the [Input Pipeline Performance Guide](https://www.tensorflow.org/versions/master/performance/datasets_performance).

### Source code / logs
A minimal working code example follows at the end of this post. The code does the same experiment twice, once with and once without dataset shuffling. Each experiment consumes 3 epochs of a dataset, within which one can notice slower and slower iterations (when shuffling is enabled), with a speed increase at each new start of epoch.
My command-line output is the following:

> $ python3 minimal_shuffle_bug.py

>    === START TEST WITH SHUFFLING DISABLED === 
2018-03-23 18:15:47.136029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: GeForce GTX 1060 6GB major: 6 minor: 1 memoryClockRate(GHz): 1.7715
pciBusID: 0000:01:00.0
totalMemory: 5.93GiB freeMemory: 4.91GiB
2018-03-23 18:15:47.136056: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1)
iteration 99: last 100 iterations took 2.96ms
iteration 199: last 100 iterations took 2.49ms
iteration 299: last 100 iterations took 2.47ms
iteration 399: last 100 iterations took 2.47ms
iteration 499: last 100 iterations took 2.33ms
iteration 599: last 100 iterations took 2.32ms
iteration 699: last 100 iterations took 2.06ms
iteration 799: last 100 iterations took 2.06ms
iteration 899: last 100 iterations took 2.06ms
iteration 999: last 100 iterations took 2.01ms
Start new epoch
iteration 1099: last 100 iterations took 2.08ms
iteration 1199: last 100 iterations took 2.07ms
iteration 1299: last 100 iterations took 2.07ms
iteration 1399: last 100 iterations took 2.07ms
iteration 1499: last 100 iterations took 2.07ms
iteration 1599: last 100 iterations took 2.08ms
iteration 1699: last 100 iterations took 2.04ms
iteration 1799: last 100 iterations took 2.08ms
iteration 1899: last 100 iterations took 2.07ms
iteration 1999: last 100 iterations took 2.07ms
Start new epoch
iteration 2099: last 100 iterations took 2.06ms
iteration 2199: last 100 iterations took 2.07ms
iteration 2299: last 100 iterations took 2.07ms
iteration 2399: last 100 iterations took 2.01ms
iteration 2499: last 100 iterations took 2.01ms
iteration 2599: last 100 iterations took 2.01ms
iteration 2699: last 100 iterations took 2.05ms
iteration 2799: last 100 iterations took 2.01ms
iteration 2899: last 100 iterations took 2.01ms
iteration 2999: last 100 iterations took 2.01ms

>    === START TEST WITH SHUFFLING ENABLED === 
2018-03-23 18:15:53.605928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1)
iteration 99: last 100 iterations took 12.77ms
iteration 199: last 100 iterations took 15.31ms
iteration 299: last 100 iterations took 17.66ms
iteration 399: last 100 iterations took 19.23ms
iteration 499: last 100 iterations took 20.99ms
iteration 599: last 100 iterations took 24.01ms
iteration 699: last 100 iterations took 25.48ms
iteration 799: last 100 iterations took 27.70ms
iteration 899: last 100 iterations took 28.04ms
iteration 999: last 100 iterations took 16.38ms
Start new epoch
iteration 1099: last 100 iterations took 13.95ms
iteration 1199: last 100 iterations took 16.74ms
iteration 1299: last 100 iterations took 16.82ms
iteration 1399: last 100 iterations took 20.15ms
iteration 1499: last 100 iterations took 22.53ms
iteration 1599: last 100 iterations took 23.19ms
iteration 1699: last 100 iterations took 25.38ms
iteration 1799: last 100 iterations took 25.96ms
iteration 1899: last 100 iterations took 26.20ms
iteration 1999: last 100 iterations took 18.47ms
Start new epoch
iteration 2099: last 100 iterations took 12.99ms
iteration 2199: last 100 iterations took 14.26ms
iteration 2299: last 100 iterations took 17.93ms
iteration 2399: last 100 iterations took 18.95ms
iteration 2499: last 100 iterations took 20.89ms
iteration 2599: last 100 iterations took 23.01ms
iteration 2699: last 100 iterations took 25.17ms
iteration 2799: last 100 iterations took 27.40ms
iteration 2899: last 100 iterations took 26.44ms
iteration 2999: last 100 iterations took 15.94ms

And the code to reproduce this experiment:
```import tensorflow as tf
import time

num_data = 5000000
num_epoch = 3
batch_size = 5000
num_iters = num_data*num_epoch/batch_size

def test_shuffle(enable_shuffling):
    # Define dataset
    dataset = tf.data.Dataset.range(num_data)
    if (enable_shuffling):
        dataset = dataset.shuffle(num_data)
    dataset = dataset.batch(batch_size)
    iterator = dataset.make_initializable_iterator()
    # Define next element op
    x = iterator.get_next()

    # Launch session
    sess = tf.InteractiveSession()
    sess.run(iterator.initializer)

    # Consume iterator and time
    for i in range(int(num_iters)):
        try:
            t1 = time.time()
            res = sess.run(x)

            if i%100 == 99:
                t2 = time.time()
                print ('iteration {0:d}: last 100 iterations took {1:0.2f}ms'.format(i,1000*(t2-t1)))
        except tf.errors.OutOfRangeError:
            sess.run(iterator.initializer)
            print('Start new epoch')

print ('   === START TEST WITH SHUFFLING DISABLED === ')
test_shuffle(False)
print()

print ('   === START TEST WITH SHUFFLING ENABLED === ')
test_shuffle(True)
print()
```

Note: this bug report follows comments and discussion on bug report https://github.com/tensorflow/tensorflow/issues/11591
I initially experienced this issue with the MNIST dataset (smaller dataset than the example attached, i.e., 60K iterations ;  but with more operations for dataset loading).

Final note: I also tried the variant in which I do not capture the `OutOfRangeError` followed by initializing the iterator, but rather include a line `dataset = dataset.repeat(num_epoch)` in the dataset creation Graph. The results are similar.

Thanks a lot.

Kenneth
"
17957,InvalidArgumentError when training with weight regularization with anaconda in win 10 (tensorflow-gpu 1.6.0),"Error message occurs when applying L2 loss weight decay with 1080ti gpu activated
No Error message occurs when applying weight decay with only cpu running
The error message always come out if training with all the Optimizer in anaconda, win10, gpu 1080ti, tensorflow 1.6.0. CUDA 9 CUDNN 7.0

```
Traceback (most recent call last):
  File ""train_ADAM_add1CNN.py"", line 89, in <module>
    _ = sess.run([train_step_adam],feed_dict={img_in:X_mb, label_gt:y_gt})
  File ""D:\ProgramData\Anaconda4\envs\tff\lib\site-packages\tensorflow\python\client\session.py"", line 905, in run
    run_metadata_ptr)
  File ""D:\ProgramData\Anaconda4\envs\tff\lib\site-packages\tensorflow\python\client\session.py"", line 1137, in _run
    feed_dict_tensor, options, run_metadata)
  File ""D:\ProgramData\Anaconda4\envs\tff\lib\site-packages\tensorflow\python\client\session.py"", line 1355, in _do_run
    options, run_metadata)
  File ""D:\ProgramData\Anaconda4\envs\tff\lib\site-packages\tensorflow\python\client\session.py"", line 1374, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: AttrValue must not have reference type value of float_ref
         for attr 'tensor_type'
```

Here is the example code that can duplicate the issue:

```
...
def optimize_adam(loss, learning_rate, LRdecaysteps, LRdecayrate):
    decay_learning_rate = tf.train.exponential_decay(learning_rate, global_step, LRdecaysteps, LRdecayrate, staircase=True)
    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)
    with tf.control_dependencies(update_ops):
        return tf.train.AdamOptimizer(decay_learning_rate).minimize(loss, global_step=global_step), decay_learning_rate

regularization_loss = tf.add_n(tf.losses.get_regularization_losses())
total_loss = total_loss + regularization_loss
train_step_adam,decay_learning_rate = optimize_adam(total_loss,learning_rate,LRdecaysteps,LRdecayrate)
...
```

it can be run with :
session_conf = tf.ConfigProto(
    device_count={'CPU' : 1, 'GPU' : 0},
    allow_soft_placement=True,
    log_device_placement=False
)

But it will come out this error message with:
session_conf = tf.ConfigProto(
    device_count={'CPU' : 1, 'GPU' : 1},
    allow_soft_placement=True,
    log_device_placement=False
)"
17956,Operation missing on iOS despite being added to tf_op_files.txt and ops_to_register.h,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS X 10.13.3
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: v1.7.0-rc1
- **Python version**: 2.7.10
- **Bazel version (if compiling from source)**: bazel release 0.11.1-homebrew
- **GCC/Compiler version (if compiling from source)**: Apple LLVM version 9.0.0 (clang-900.0.39.2)
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

### Describe the problem
I believe it's a bug. We're trying to run a TensorFlow model on an iOS app by performing the steps described in the [official](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile#optimization) [docs](https://www.tensorflow.org/mobile/prepare_models). I've previously successfully built and ran this graph and its related libraries on Android.

We build the libraries like this:

    tensorflow/contrib/makefile/build_all_ios.sh -a arm64 -g our_inference_graph.pb

We make sure the operations in question (`fft_ops.cc`) are built:

1. `tensorflow/core/framework/ops_to_register.h` contains `|| isequal(op, ""RFFT"")`

1. `android_extended_ops_group1` in `tensorflow/core/kernels/BUILD` contains `fft_ops.cc`

1. `tensorflow/contrib/makefile/tf_op_files.txt` contains `tensorflow/core/kernels/fft_ops.cc`

1. The fft object file is built as `tensorflow/contrib/makefile/gen/obj/fft_ops.o`

However, we get the following error when loading the graph:

    2018-03-23 13:04:06.618259: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""RFFT"" device_type: ""CPU""') for unknown op: RFFT
    2018-03-23 13:04:06.618616: E <App path>/TensorFlow/Adapter/TensorFlowUtils.mm:152] Could not create TensorFlow Graph: Not found: Op type not registered 'RFFT' in binary running on Foolish. Make sure the Op and Kernel are registered in the binary running in this process.
    2018-03-23 13:04:06.618827: F <App path>/TensorFlow/Adapter/TensorFlowProcessor.mm:73] Couldn't load model: Not found: Op type not registered 'RFFT' in binary running on Foolish. Make sure the Op and Kernel are registered in the binary running in this process.

Here's my question on SO (no repsonse): https://stackoverflow.com/questions/49452489/opkernel-op-rfft-device-type-cpu-for-unknown-op-rfft

Related issues: issues #15921 and #5518 suggest adding the operation to `tf_op_files.txt`, which we've done (see above).

### Source code / logs
Here's how we load the graph: https://gist.github.com/nerthase/22f54c040a195f87b7a9b241536be2a1
"
17955,Results inconsistent between each freeze graph,"### Describe the problem

I apologize if this is the wrong forum, but it may be a bug regarding certain operations. When freezing a graph and then running it elsewhere (mobile device), the output is of low quality compared to the inference on the server on my semantic segmentation model. It is basically a messy version of what would run on the server. It is executing successfully, but it appears as though something was not initialized prior to freezing, even though the method to load the model between the export script and inference scripts is nearly identical. 

The exported model can be run on the same images over and over and produce the same results for a given set of images, as expected. 

**Here is the really strange part:**
However, each time the model is frozen, using exactly the same script and same checkpoint, it creates a different output for a given set of images.

I went ahead and posted to stackoverflow in case this is the wrong place.
[https://stackoverflow.com/questions/49454430/tensorflow-results-inconsistent-between-each-freeze-graph](https://stackoverflow.com/questions/49454430/tensorflow-results-inconsistent-between-each-freeze-graph)

### Source code / logs

```
def main():
    args = get_arguments()
    
    if args.dataset == 'cityscapes':
        num_classes = cityscapes_class
    else:
        num_classes = ADE20k_class

    shape = [320, 320]

    x = tf.placeholder(dtype=tf.float32, shape=(shape[0], shape[1], 3), name=""input"")
    img_tf = preprocess(x)

    model = model_config[args.model]
    net = model({'data': img_tf}, num_classes=num_classes, filter_scale=args.filter_scale)

    raw_output = net.layers['conv6_cls']
    raw_output_up = tf.image.resize_bilinear(raw_output, size=shape, align_corners=True)
    raw_output_maxed = tf.argmax(raw_output_up, axis=3, name=""output"")
        
    # Init tf Session
    config = tf.ConfigProto()
    sess = tf.Session(config=config)
    init = tf.global_variables_initializer()

    sess.run(init)
    
    model_path = model_paths[args.model]
    ckpt = tf.train.get_checkpoint_state(model_path)
    if ckpt and ckpt.model_checkpoint_path:
        input_checkpoint = ckpt.model_checkpoint_path
        loader = tf.train.import_meta_graph(input_checkpoint + '.meta', clear_devices=True)
        load(loader, sess, ckpt.model_checkpoint_path)     
    else:
        print('No checkpoint file found at %s.' % model_path)
        exit()

    print(""Loaded Model"")

    # We retrieve the protobuf graph definition
    graph = tf.get_default_graph()
    input_graph_def = graph.as_graph_def()

    # We use a built-in TF helper to export variables to constants
    output_graph_def = graph_util.convert_variables_to_constants(
        sess, # The session is used to retrieve the weights
        input_graph_def, # The graph_def is used to retrieve the nodes
        output_node_names.split("","") # The output node names are used to select the usefull nodes
    )

    # Finally we serialize and dump the output graph to the filesystem
    with tf.gfile.GFile(""model/output_graph.pb"", ""wb"") as f:
        f.write(output_graph_def.SerializeToString())
    print(""%d ops in the final graph."" % len(output_graph_def.node))
```"
17952,"Feature request: in tf.train.MonitoredSession(), add operator that makes it possible to skip certain hooks","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 10 Pro 64-bit (10.0, Build 16299)
- **TensorFlow installed from (source or binary)**:
Binary
- **TensorFlow version (use command below)**:
1.6.0
- **Python version**: 
3.6.4
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
I would like an operator that makes it possible to skip a certain/multiple hooks whilst running a tf.train.MonitoredSession(). An example of how this could look is provided below.

The reason why I want this functionality, is that I sometimes want to permit a certain hook(s) from running when calling `mon_sess.run()`. One reason for this can be that the hook generates unnecessary errors when doing this particular `mon_sess.run()` call. Another one can be that I simply don't want the hook's functionality on this particular `mon_sess.run()` call.

### Source code / logs
Example code of how this operator could look:

```
with tf.train.MonitoredTrainingSession(
  hooks=[hook1, hook2, hook3, hook4]
) as mon_sess:
  mon_sess.partial_run(fetches=..., feed_dict=..., skip_hooks=[hook1, hook3])
```

Is this possible?
"
17951,Feature request: Create a function that handles errors for tf.train.SessionRunHook(),"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 10 Pro 64-bit (10.0, Build 16299)
- **TensorFlow installed from (source or binary)**:
Binary
- **TensorFlow version (use command below)**:
1.6.0
- **Python version**: 
3.6.4
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
I would like an operation for tf.train.SessionRunHook() that executes when an error is thrown from the sess.run() (it should be able to act upon a single error/multiple errors (in a list)/all errors. The reason I would like this, is because there exists use cases where a hook action should be performed only when an error is raised.

My current example of this use case is the switch between training and validation loops. I am, in a tf.train.MonitoredTrainingSession() trying to run a training loop and a validation loop that switches between each other. In order to achieve this, I'm using a tf.data.Dataset.iterator that runs in a while loop until a tf.errors.OutOfRangeError is thrown; breaking the while loop and moving on to the next. When this exception is thrown, I would like to perform hook actions, such as saving epoch summaries, print logging on the terminal, etc. My current way of doing this is to write these actions manually in the exception clause, as shown below. It would, however, be cleaner and easier if these actions could be performed in the hooks themselves when an error is thrown.

### Source code / logs
Example code I am using currently:

```
import tensorflow as tf
from functools import partial

def create_reset_metric(metric, scope='reset_metrics', **metric_args):
    with tf.variable_scope(scope) as scope:
        metric_op, update_op = metric(**metric_args)
        vars = tf.contrib.framework.get_variables(
                scope, collection=tf.GraphKeys.LOCAL_VARIABLES
            )
        reset_op = tf.variables_initializer(vars)
    return metric_op, update_op, reset_op

dataset_train = tf.data.Dataset.range(100)
iterator_train = dataset_train.make_initializable_iterator()
next_elem_train = iterator_train.get_next()
mean_batch_train, mean_update_train, mean_reset_train = create_reset_metric(
                                                            metric=tf.metrics.mean,
                                                            scope='reset_metrics_train',
                                                            values=next_elem_train)
summary_train = tf.summary.scalar('train_summary', mean_update_train, collections=['train'])

dataset_test = tf.data.Dataset.range(50)
iterator_test = dataset_test.make_initializable_iterator()
next_elem_test = iterator_test.get_next()
mean_batch_test, mean_update_test, mean_reset_test = create_reset_metric(
                                                            metric=tf.metrics.mean,
                                                            scope='reset_metrics_test',
                                                            values=next_elem_test)
summary_test = tf.summary.scalar('test_summary', mean_update_test, collections=['test'])

merged_train_summary_op = tf.summary.merge_all('train')
merged_test_summary_op = tf.summary.merge_all('test')

def step_fn(fetches, feed_dict, step_context):
    return step_context.session.run(fetches=fetches, feed_dict=feed_dict)

with tf.summary.FileWriter('./tmp/train_test_switch') as writer:
    with tf.train.MonitoredTrainingSession() as sess:
        epoch_step = 0
        while not sess.should_stop():
            sess.run_step_fn(partial(step_fn, iterator_train.initializer, {}))
            while True:
                try:
                    summary_train_, _ = sess.run([merged_train_summary_op, next_elem_train])
                except tf.errors.OutOfRangeError:
                    writer.add_summary(summary_train_, epoch_step)
                    sess.run_step_fn(partial(step_fn, mean_reset_train, {}))
                    break

            sess.run_step_fn(partial(step_fn, iterator_test.initializer, {}))
            while True:
                try:
                    summary_test_, _ = sess.run([merged_test_summary_op, next_elem_test])
                except tf.errors.OutOfRangeError:
                    writer.add_summary(summary_test_, epoch_step)
                    sess.run_step_fn(partial(step_fn, mean_reset_test, {}))
                    break
            print(""epoch_step:"", epoch_step)
            epoch_step += 1

```

Example of how I want the `tf.train.MonitoredTrainingSession()` to look (the beginning is the same as before):

```
...

with tf.summary.FileWriter('./tmp/train_test_switch') as writer:
    error_catching_hook = ErrorCatchingHook(...)
    with tf.train.MonitoredTrainingSession(hooks=[error_catching_hook]) as sess:
        epoch_step = 0
        while not sess.should_stop():
            sess.run_step_fn(partial(step_fn, iterator_train.initializer, {}))
            error_catching_hook.is_training() # Set flag to call correct params when OutOfRangeError
            while True:
                try:
                    summary_train_, _ = sess.run([merged_train_summary_op, next_elem_train])
                except tf.errors.OutOfRangeError:
                    # error_catching_hook calls writer.add_summary(...)
                    # error_catching_hook calls mean_reset_train
                    break

            sess.run_step_fn(partial(step_fn, iterator_test.initializer, {}))
            error_catching_hook.is_testing() # Set flag to call correct params when OutOfRangeError
            while True:
                try:
                    summary_test_, _ = sess.run([merged_test_summary_op, next_elem_test])
                except tf.errors.OutOfRangeError:
                    # error_catching_hook calls writer.add_summary(...)
                    # error_catching_hook calls mean_reset_test
                    break
            print(""epoch_step:"", epoch_step)
            epoch_step += 1
```

I realize that this might not be the best example of a use case for this, but I hope you get my point, and I'm sure there are other use cases for this. 

After having read my code above, I also hope that this could provide a solution for others trying to gather and summarize epoch-wise data. A common pattern of summarizing train/test data is, after all, to summarize an epoch average after each epoch. This feels like an unnecessarily painful implementation task today, and I hope that this request of mine can at least bring down the pain a little bit. Hopefully, this can lead to a tf.train.EndOfSetHook() or similar, that is only called when a dataset reaches its end!"
17950,`tf.keras.model_to_estimator` doesn't work well in evaluating,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04

- **TensorFlow installed from (source or binary)**:
I use docker tensorflow/tensorflow:1.7.0-rc1-devel-gpu-py3

- **TensorFlow version (use command below)**:
1.7.0-rc1

- **Python version**: 
3.5

- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
CUDA9.0

- **GPU model and memory**:
1080Ti(12GB)

- **Exact command to reproduce**:
see my gist below

### Describe the problem
I used networks in `tf.keras.applications` and `tf.keras.model_to_estimator`. I noticed that training loss gets low but validation loss doesn't when I don't use pretrained model and train from scratch. I doubted overfitting so I tried evalutating on training dataset. And get large validation loss althogh traing loss gets low inspite of same dataset. I think parameters of BatchNormalization are not updated when use `model_to_estimator`. Isn't it a bug?
![loss](https://user-images.githubusercontent.com/22191150/37830935-21c07af8-2ee7-11e8-9bf0-bcd2ad07eebf.png)

### Source code / logs
https://gist.github.com/dhgrs/781eb8bec824c63cc4b626bf04cd4446"
17949,incorrect description of num_sampled parameter in tf.nn.nce_loss() function: num_sampled is number of negative examples per 1 positive example (NOT per batch),"Hi all,

Looks like parameter `num_sampled` in  `tf.nn.nce_loss` function defines the number of negative examples per a positive example but not per a batch as described in tensorflow documentation (https://www.tensorflow.org/api_docs/python/tf/nn/nce_loss) 

(see the next code)

```
import tensorflow as tf
import numpy as np
# `_compute_sampled_logits` is invoked in nce_loss to generate negative sample and calculate logits
from tensorflow.python.ops.nn_impl import _compute_sampled_logits

embedding_size = 10
words_number = 300
batch_size = 3
num_sampled = 3

graph = tf.Graph()
with graph.as_default():
    # Input data.
    train_inputs = tf.placeholder(tf.int32, shape=[batch_size])
    train_labels = tf.placeholder(tf.int64, shape=[batch_size, 1])

    with tf.device('/cpu:0'):
        embeddings = tf.Variable(
                tf.random_uniform([words_number, embedding_size], -4., 4.))
        embed = tf.nn.embedding_lookup(embeddings, train_inputs)
        nce_weights = tf.Variable(
                tf.random_uniform([words_number, embedding_size], -4., 4.))
        nce_biases = tf.Variable(tf.zeros([words_number]))
        
    logits, labels = _compute_sampled_logits(
                       weights=nce_weights,
                       biases=nce_biases,
                       inputs=embed,
                       labels=train_labels,
                       num_true=1,
                       num_sampled=num_sampled,
                       num_classes=words_number,
                       remove_accidental_hits = False)
    init = tf.global_variables_initializer()


session = tf.InteractiveSession(graph=graph)
init.run(session=session)

batch_inputs = np.array([0,1,2], dtype=np.int32)
batch_labels = np.array([[3],[4],[5]], dtype=np.int32)

feed_dict = {train_inputs : batch_inputs, train_labels : batch_labels}
logits_val, labels_val = session.run([logits, labels], feed_dict=feed_dict)

print (""logits_val = {}"".format(logits_val))
print (""labels_val = {}"".format(labels_val))

```

As a result, `_compute_sampled_logits` function generated `num_sampled` examples per **1 positive example**:
```
logits_val = [[ -8.18727493   2.02518415  14.18676853   0.51900673]
 [ -8.97232056   5.60003376   4.52866602   3.68161726]
 [ -0.36226368  -5.84330416  -3.39891291   5.58423615]]
labels_val = [[ 1.  0.  0.  0.]
 [ 1.  0.  0.  0.]
 [ 1.  0.  0.  0.]]
```"
17946,Formatting issue in tf debugger documentation,"![image](https://user-images.githubusercontent.com/35289454/37821263-29a87d1c-2ea9-11e8-90b5-7f3bb5f42d49.png)
In the [FAQ section](https://www.tensorflow.org/programmers_guide/debugger#frequently_asked_questions), there seem to be some markdown formatting problems."
17945,1.7 compiled version with MKL fails unexpectedly,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 14.04.5 LTS
- **TensorFlow installed from (source or binary)**:
source
- **TensorFlow version (use command below)**:
1.7
- **Python version**: 
3.6
- **Bazel version (if compiling from source)**:
0.11.1
- **GCC/Compiler version (if compiling from source)**:
4.8.4
- **CUDA/cuDNN version**:
None
- **GPU model and memory**:
None
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem

I successfully built tensorflow with mkl, got it all installed and then tried to run a keras network (one that has run on the pre-built binary version).  It looks like it started hits 800% (8 cores), but then dies with an error.  The logs below show the error is not in keras but in tensorflow/mkl. Source code included, I believe you can run any data through the network.


### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

logs:

```
./tensorflow/core/util/mkl_util.h:1288] Non-OK-status: Status(error::Code::INVALID_ARGUMENT, ""Unsupported data format"") status: Invalid argument: Unsupported data format 
```

source code:

```
import os
os.environ[""KMP_BLOCKTIME""] = str(0)
os.environ[""KMP_SETTINGS""] = str(1)
os.environ[""KMP_AFFINITY""]= str('granularity=fine,verbose,compact,1,0')

d = datetime.datetime.utcnow()
unixtime = calendar.timegm(d.utctimetuple())

window_size = 224
nb_input_series = train_X.shape[1]
nb_outputs = 1
batch_size = 10

model = Sequential((
    Conv1D(2048, 2, activation='relu',input_shape=(window_size, nb_input_series)),
    Conv1D(2048, 2, activation='relu'),
    MaxPooling1D(2),
    Conv1D(2048, 4, activation='relu'),
    Conv1D(2048, 4, activation='relu'),
    MaxPooling1D(2),
    Conv1D(2048, 4, activation='relu'),
    Conv1D(2048, 4, activation='relu'),
    MaxPooling1D(2),
    Conv1D(2048, 4, activation='relu'),
    Conv1D(2048, 4, activation='relu'),
    MaxPooling1D(2),
    Dropout(0.1),
    Dense(4096, activation='relu'),
    Dense(4096, activation='relu'),
#     GlobalAveragePooling1D(),
    Flatten(),
    Dense(nb_outputs, activation='linear')
    ))

    
model.compile(loss='mse', optimizer=Adam(lr=0.0001), metrics=['mae'])

model.summary()
```"
17944,App getting crashed while using USB Camera,"OS Platform and Distribution: Ubuntu 14.04
TensorFlow installed from: Git cloned
TensorFlow version: N/A
Bazel version: Build label: 0.11.1
CUDA/cuDNN version: N/A
GPU model and memory: x86 8GB RAM
Exact command to reproduce: bazel build --cxxopt=--std=c++11 //tensorflow/contrib/lite/java/demo/app/src/main:TfLiteCameraDemo --config android --cpu=x86_64 --fat_apk_cpu=x86_64

I think i am getting camera id null. is it because tensorflow uses camera2? if yes then how do i fix this issue?

```
03-23 05:21:14.646  2282  2282 W /system/bin/hwservicemanager: getTransport: Cannot find entry android.hardware.configstore@1.0::ISurfaceFlingerConfigs/default in either framework or device manifest.
03-23 05:21:14.647 19595 19613 I com.example.android.tflitecamerademo: android::hardware::configstore::V1_0::ISurfaceFlingerConfigs::hasWideColorDisplay retrieved: 0
03-23 05:21:14.647 19595 19613 I OpenGLRenderer: Initialized EGL, version 1.4
03-23 05:21:14.647 19595 19613 D OpenGLRenderer: Swap behavior 2
03-23 05:21:14.647 19595 19595 I RenderThread: type=1400 audit(0.0:310): avc: denied { map } for path=2F69393135202864656C6574656429 dev=""tmpfs"" ino=918453 scontext=u:r:untrusted_app_25:s0:c512,c768 tcontext=u:object_r:untrusted_app_25_tmpfs:s0:c512,c768 tclass=file permissive=1
03-23 05:21:14.651 19595 19595 I CameraManagerGlobal: Connecting to camera service
03-23 05:21:14.652 19595 19595 D AndroidRuntime: Shutting down VM
--------- beginning of crash
03-23 05:21:14.652 19595 19595 E AndroidRuntime: FATAL EXCEPTION: main
03-23 05:21:14.652 19595 19595 E AndroidRuntime: Process: com.example.android.tflitecamerademo, PID: 19595
03-23 05:21:14.652 19595 19595 E AndroidRuntime: java.lang.IllegalArgumentException: cameraId was null
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.hardware.camera2.CameraManager.openCameraForUid(CameraManager.java:457)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.hardware.camera2.CameraManager.openCamera(CameraManager.java:433)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at com.example.android.tflitecamerademo.Camera2BasicFragment.openCamera(Camera2BasicFragment.java:479)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at com.example.android.tflitecamerademo.Camera2BasicFragment.access$000(Camera2BasicFragment.java:69)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at com.example.android.tflitecamerademo.Camera2BasicFragment$1.onSurfaceTextureAvailable(Camera2BasicFragment.java:102)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.TextureView.getHardwareLayer(TextureView.java:390)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.TextureView.draw(TextureView.java:339)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.View.updateDisplayListIfDirty(View.java:18142)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.View.draw(View.java:18920)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.ViewGroup.drawChild(ViewGroup.java:4236)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.ViewGroup.dispatchDraw(ViewGroup.java:4022)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.View.updateDisplayListIfDirty(View.java:18133)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.View.draw(View.java:18920)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.ViewGroup.drawChild(ViewGroup.java:4236)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.ViewGroup.dispatchDraw(ViewGroup.java:4022)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.View.draw(View.java:19195)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.View.updateDisplayListIfDirty(View.java:18142)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.View.draw(View.java:18920)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.ViewGroup.drawChild(ViewGroup.java:4236)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.ViewGroup.dispatchDraw(ViewGroup.java:4022)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.View.updateDisplayListIfDirty(View.java:18133)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.View.draw(View.java:18920)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.ViewGroup.drawChild(ViewGroup.java:4236)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.ViewGroup.dispatchDraw(ViewGroup.java:4022)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.View.updateDisplayListIfDirty(View.java:18133)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.View.draw(View.java:18920)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.ViewGroup.drawChild(ViewGroup.java:4236)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.ViewGroup.dispatchDraw(ViewGroup.java:4022)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.View.draw(View.java:19195)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.View.updateDisplayListIfDirty(View.java:18142)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.View.draw(View.java:18920)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.ViewGroup.drawChild(ViewGroup.java:4236)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.ViewGroup.dispatchDraw(ViewGroup.java:4022)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.View.updateDisplayListIfDirty(View.java:18133)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.View.draw(View.java:18920)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.ViewGroup.drawChild(ViewGroup.java:4236)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.ViewGroup.dispatchDraw(ViewGroup.java:4022)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.View.updateDisplayListIfDirty(View.java:18133)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.View.draw(View.java:18920)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.ViewGroup.drawChild(ViewGroup.java:4236)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.ViewGroup.dispatchDraw(ViewGroup.java:4022)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.View.draw(View.java:19195)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at com.android.internal.policy.DecorView.draw(DecorView.java:788)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.View.updateDisplayListIfDirty(View.java:18142)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.ThreadedRenderer.updateViewTreeDisplayList(ThreadedRenderer.java:669)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.ThreadedRenderer.updateRootDisplayList(ThreadedRenderer.java:675)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.ThreadedRenderer.draw(ThreadedRenderer.java:783)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.ViewRootImpl.draw(ViewRootImpl.java:2992)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.ViewRootImpl.performDraw(ViewRootImpl.java:2806)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.ViewRootImpl.performTraversals(ViewRootImpl.java:2359)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.ViewRootImpl.doTraversal(ViewRootImpl.java:1392)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.ViewRootImpl$TraversalRunnable.run(ViewRootImpl.java:6752)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.Choreographer$CallbackRecord.run(Choreographer.java:911)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.Choreographer.doCallbacks(Choreographer.java:723)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.Choreographer.doFrame(Choreographer.java:658)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.view.Choreographer$FrameDisplayEventReceiver.run(Choreographer.java:897)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.os.Handler.handleCallback(Handler.java:790)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.os.Handler.dispatchMessage(Handler.java:99)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.os.Looper.loop(Looper.java:164)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at android.app.ActivityThread.main(ActivityThread.java:6494)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at java.lang.reflect.Method.invoke(Native Method)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:438)
03-23 05:21:14.652 19595 19595 E AndroidRuntime:        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:807)
03-23 05:21:14.653 15691 16933 W ActivityManager:   Force finishing activity com.example.android.tflitecamerademo/.CameraActivity
03-23 05:21:14.654 15691 16933 W ActivityManager:   Force finishing activity com.android.settings/.Settings
03-23 05:21:14.655 15691 16933 I ActivityManager: Killing 16856:com.google.android.partnersetup/u0a23 (adj 906): empty #17
03-23 05:21:14.655 15691 15712 W system_server: kill(-16856, 9) failed: No such process
03-23 05:21:14.656  2503  2503 D CRASHLOG: sdcard_allowed : Current crashlog mode is NOMINAL MODE - SDCard storage disabled.
03-23 05:21:14.659 15691 18236 I ActivityManager: START u0 {act=android.intent.action.MAIN cat=[android.intent.category.HOME] flg=0x10000100 cmp=com.android.support.car.lenspicker/.LensPickerTrampolineActivity} from uid 0
03-23 05:21:14.660 19595 19595 I Process : Sending signal. PID: 19595 SIG: 9
03-23 05:21:14.674 15691 15758 W InputDispatcher: channel '656c0d6 com.example.android.tflitecamerademo/com.example.android.tflitecamerademo.CameraActivity (server)' ~ Consumer closed input channel or an error occurred.  events=0x9
03-23 05:21:14.674 15691 15758 E InputDispatcher: channel '656c0d6 com.example.android.tflitecamerademo/com.example.android.tflitecamerademo.CameraActivity (server)' ~ Channel is unrecoverably broken and will be disposed!
03-23 05:21:14.674 15691 16917 I ActivityManager: Process com.example.android.tflitecamerademo (pid 19595) has died: vis  +99TOP
03-23 05:21:14.674 15691 16480 I WindowManager: WIN DEATH: Window{656c0d6 u0 com.example.android.tflitecamerademo/com.example.android.tflitecamerademo.CameraActivity}
03-23 05:21:14.674 15691 16480 W InputDispatcher: Attempted to unregister already unregistered input channel '656c0d6 com.example.android.tflitecamerademo/com.example.android.tflitecamerademo.CameraActivity (server)'
03-23 05:21:14.676 15691 15717 W ActivityManager: setHasOverlayUi called on unknown pid: 19595
03-23 05:21:14.681 15691 18187 I ActivityManager: START u0 {act=android.intent.action.MAIN cat=[android.intent.category.LAUNCHER] flg=0x10000000 pkg=com.android.settings cmp=com.android.settings/.Settings} from uid 10048
```"
17942,"Many missing ops in iOS, output not consistent with linux","I have tried porting to iOS a fully working semantic segmentation nnet, which does run, but has a series of warnings and less than accurate output, although somewhat working, when compared to the same image input as our server. I am seeing a series of these errors which I suspect could be the problem. RightShift, LeftShift, BitwiseAnd, BitwiseOr, PopulationCount, LookupTableImportV2,MutableHashTable, etc. But I have set _ _ANDROID_TYPES_FULL_ _ non-ideally to try to enable as many operations as possible, and the errors listed much below are still showing up. 

I'm freezing graph and calling transform_graph with the following options:
```
add_default_attributes
strip_unused_nodes(type=float, shape=""$resolution,3"")
remove_nodes(op=Identity, op=CheckNumerics)
fold_constants(ignore_errors=true)
fold_batch_norms
fold_old_batch_norms
round_weights
quantize_nodes
strip_unused_nodes
sort_by_execution_order'
```
I've disabled optimize_for_inference because I understand that this could be a possible cause.

I understand that @petewarden might have some experience here.

Here's what I am seeing while executing in iOS:
```
2018-03-22 20:57:13.320436: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""PopulationCount"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }') for unknown op: PopulationCount
2018-03-22 20:57:13.320493: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""PopulationCount"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT64 } } }') for unknown op: PopulationCount
2018-03-22 20:57:13.320774: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""RightShift"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT8 } } }') for unknown op: RightShift
2018-03-22 20:57:13.320796: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""RightShift"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT16 } } }') for unknown op: RightShift
2018-03-22 20:57:13.320814: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""RightShift"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }') for unknown op: RightShift
2018-03-22 20:57:13.320832: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""RightShift"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT64 } } }') for unknown op: RightShift
2018-03-22 20:57:13.320849: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""RightShift"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_UINT8 } } }') for unknown op: RightShift
2018-03-22 20:57:13.320970: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""RightShift"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_UINT16 } } }') for unknown op: RightShift
2018-03-22 20:57:13.320994: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""RightShift"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_UINT32 } } }') for unknown op: RightShift
2018-03-22 20:57:13.321012: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""RightShift"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_UINT64 } } }') for unknown op: RightShift
2018-03-22 20:57:13.321030: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""LeftShift"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT8 } } }') for unknown op: LeftShift
2018-03-22 20:57:13.321048: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""LeftShift"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT16 } } }') for unknown op: LeftShift
2018-03-22 20:57:13.321103: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""LeftShift"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }') for unknown op: LeftShift
2018-03-22 20:57:13.321121: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""LeftShift"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT64 } } }') for unknown op: LeftShift
2018-03-22 20:57:13.321213: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""LeftShift"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_UINT8 } } }') for unknown op: LeftShift
2018-03-22 20:57:13.321233: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""LeftShift"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_UINT16 } } }') for unknown op: LeftShift
2018-03-22 20:57:13.321251: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""LeftShift"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_UINT32 } } }') for unknown op: LeftShift
2018-03-22 20:57:13.321306: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""LeftShift"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_UINT64 } } }') for unknown op: LeftShift
2018-03-22 20:57:13.321324: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""BitwiseAnd"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT8 } } }') for unknown op: BitwiseAnd
2018-03-22 20:57:13.321341: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""BitwiseAnd"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT16 } } }') for unknown op: BitwiseAnd
2018-03-22 20:57:13.321406: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""BitwiseAnd"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }') for unknown op: BitwiseAnd
2018-03-22 20:57:13.321458: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""BitwiseAnd"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT64 } } }') for unknown op: BitwiseAnd
2018-03-22 20:57:13.321476: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""BitwiseAnd"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_UINT8 } } }') for unknown op: BitwiseAnd
2018-03-22 20:57:13.321493: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""BitwiseAnd"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_UINT16 } } }') for unknown op: BitwiseAnd
2018-03-22 20:57:13.321510: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""BitwiseAnd"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_UINT32 } } }') for unknown op: BitwiseAnd
2018-03-22 20:57:13.321527: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""BitwiseAnd"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_UINT64 } } }') for unknown op: BitwiseAnd
2018-03-22 20:57:13.321576: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""BitwiseOr"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT8 } } }') for unknown op: BitwiseOr
2018-03-22 20:57:13.321640: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""BitwiseOr"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT16 } } }') for unknown op: BitwiseOr
2018-03-22 20:57:13.321659: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""BitwiseOr"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }') for unknown op: BitwiseOr
2018-03-22 20:57:13.321676: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""BitwiseOr"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT64 } } }') for unknown op: BitwiseOr
2018-03-22 20:57:13.321693: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""BitwiseOr"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_UINT8 } } }') for unknown op: BitwiseOr
2018-03-22 20:57:13.321802: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""BitwiseOr"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_UINT16 } } }') for unknown op: BitwiseOr
2018-03-22 20:57:13.321846: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""BitwiseOr"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_UINT32 } } }') for unknown op: BitwiseOr
2018-03-22 20:57:13.321875: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""BitwiseOr"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_UINT64 } } }') for unknown op: BitwiseOr
2018-03-22 20:57:13.321893: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""BitwiseXor"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT8 } } }') for unknown op: BitwiseXor
2018-03-22 20:57:13.322123: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""BitwiseXor"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT16 } } }') for unknown op: BitwiseXor
2018-03-22 20:57:13.322142: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""BitwiseXor"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }') for unknown op: BitwiseXor
2018-03-22 20:57:13.322159: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""BitwiseXor"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT64 } } }') for unknown op: BitwiseXor
2018-03-22 20:57:13.322176: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""BitwiseXor"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_UINT8 } } }') for unknown op: BitwiseXor
2018-03-22 20:57:13.322193: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""BitwiseXor"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_UINT16 } } }') for unknown op: BitwiseXor
2018-03-22 20:57:13.322334: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""BitwiseXor"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_UINT32 } } }') for unknown op: BitwiseXor
2018-03-22 20:57:13.322353: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""BitwiseXor"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_UINT64 } } }') for unknown op: BitwiseXor
2018-03-22 20:57:13.322420: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""Invert"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT8 } } }') for unknown op: Invert
2018-03-22 20:57:13.322463: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""Invert"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT16 } } }') for unknown op: Invert
2018-03-22 20:57:13.322500: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""Invert"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }') for unknown op: Invert
2018-03-22 20:57:13.323153: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""Invert"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT64 } } }') for unknown op: Invert
2018-03-22 20:57:13.323176: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""Invert"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_UINT8 } } }') for unknown op: Invert
2018-03-22 20:57:13.323193: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""Invert"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_UINT16 } } }') for unknown op: Invert
2018-03-22 20:57:13.323210: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""Invert"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_UINT32 } } }') for unknown op: Invert
2018-03-22 20:57:13.323367: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""Invert"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_UINT64 } } }') for unknown op: Invert
2018-03-22 20:57:13.339078: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""MutableDenseHashTableV2"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_INT64 } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_INT64 } } }') for unknown op: MutableDenseHashTableV2
2018-03-22 20:57:13.339132: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""MutableDenseHashTableV2"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_INT64 } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_FLOAT } } }') for unknown op: MutableDenseHashTableV2
2018-03-22 20:57:13.339155: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""MutableDenseHashTableV2"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_INT64 } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_DOUBLE } } }') for unknown op: MutableDenseHashTableV2
2018-03-22 20:57:13.339315: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""MutableDenseHashTableV2"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_STRING } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_FLOAT } } }') for unknown op: MutableDenseHashTableV2
2018-03-22 20:57:13.339339: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""MutableDenseHashTableV2"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_STRING } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_BOOL } } }') for unknown op: MutableDenseHashTableV2
2018-03-22 20:57:13.339360: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""MutableDenseHashTableV2"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_INT64 } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_BOOL } } }') for unknown op: MutableDenseHashTableV2
2018-03-22 20:57:13.339388: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""MutableDenseHashTable"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_INT64 } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_INT64 } } }') for unknown op: MutableDenseHashTable
2018-03-22 20:57:13.339668: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""MutableDenseHashTable"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_INT64 } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_FLOAT } } }') for unknown op: MutableDenseHashTable
2018-03-22 20:57:13.339694: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""MutableDenseHashTable"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_INT64 } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_DOUBLE } } }') for unknown op: MutableDenseHashTable
2018-03-22 20:57:13.339716: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""MutableDenseHashTable"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_STRING } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_FLOAT } } }') for unknown op: MutableDenseHashTable
2018-03-22 20:57:13.339774: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""MutableDenseHashTable"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_STRING } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_BOOL } } }') for unknown op: MutableDenseHashTable
2018-03-22 20:57:13.339795: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""MutableDenseHashTable"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_INT64 } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_BOOL } } }') for unknown op: MutableDenseHashTable
2018-03-22 20:57:13.347418: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""MutableHashTableOfTensorsV2"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_STRING } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_FLOAT } } }') for unknown op: MutableHashTableOfTensorsV2
2018-03-22 20:57:13.347522: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""MutableHashTableOfTensorsV2"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_STRING } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_INT64 } } }') for unknown op: MutableHashTableOfTensorsV2
2018-03-22 20:57:13.347571: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""MutableHashTableOfTensorsV2"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_INT64 } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_STRING } } }') for unknown op: MutableHashTableOfTensorsV2
2018-03-22 20:57:13.347596: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""MutableHashTableOfTensorsV2"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_STRING } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_BOOL } } }') for unknown op: MutableHashTableOfTensorsV2
2018-03-22 20:57:13.350735: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""MutableHashTableOfTensors"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_STRING } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_FLOAT } } }') for unknown op: MutableHashTableOfTensors
2018-03-22 20:57:13.350772: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""MutableHashTableOfTensors"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_STRING } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_INT64 } } }') for unknown op: MutableHashTableOfTensors
2018-03-22 20:57:13.350793: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""MutableHashTableOfTensors"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_INT64 } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_STRING } } }') for unknown op: MutableHashTableOfTensors
2018-03-22 20:57:13.353009: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""MutableHashTableOfTensors"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_STRING } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_BOOL } } }') for unknown op: MutableHashTableOfTensors
2018-03-22 20:57:13.353049: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""MutableHashTableV2"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_STRING } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_FLOAT } } }') for unknown op: MutableHashTableV2
2018-03-22 20:57:13.353070: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""MutableHashTableV2"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_STRING } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_INT64 } } }') for unknown op: MutableHashTableV2
2018-03-22 20:57:13.354728: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""MutableHashTableV2"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_INT64 } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_STRING } } }') for unknown op: MutableHashTableV2
2018-03-22 20:57:13.354846: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""MutableHashTableV2"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_STRING } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_BOOL } } }') for unknown op: MutableHashTableV2
2018-03-22 20:57:13.355137: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""MutableHashTableV2"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_INT64 } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_FLOAT } } }') for unknown op: MutableHashTableV2
2018-03-22 20:57:13.368009: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""HashTableV2"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_STRING } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_DOUBLE } } }') for unknown op: HashTableV2
2018-03-22 20:57:13.368077: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""HashTableV2"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_STRING } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_FLOAT } } }') for unknown op: HashTableV2
2018-03-22 20:57:13.368099: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""HashTableV2"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_STRING } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_INT32 } } }') for unknown op: HashTableV2
2018-03-22 20:57:13.369241: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""HashTableV2"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_STRING } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_INT64 } } }') for unknown op: HashTableV2
2018-03-22 20:57:13.369279: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""HashTableV2"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_INT64 } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_STRING } } }') for unknown op: HashTableV2
2018-03-22 20:57:13.369299: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""HashTableV2"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_INT64 } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_INT64 } } }') for unknown op: HashTableV2
2018-03-22 20:57:13.370155: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""HashTableV2"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_INT64 } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_FLOAT } } }') for unknown op: HashTableV2
2018-03-22 20:57:13.370224: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""HashTableV2"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_STRING } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_STRING } } }') for unknown op: HashTableV2
2018-03-22 20:57:13.370289: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""HashTableV2"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_STRING } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_BOOL } } }') for unknown op: HashTableV2
2018-03-22 20:57:13.370321: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""HashTableV2"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_INT32 } } }') for unknown op: HashTableV2
2018-03-22 20:57:13.372970: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""HashTable"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_STRING } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_DOUBLE } } }') for unknown op: HashTable
2018-03-22 20:57:13.373001: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""HashTable"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_STRING } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_FLOAT } } }') for unknown op: HashTable
2018-03-22 20:57:13.373021: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""HashTable"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_STRING } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_INT32 } } }') for unknown op: HashTable
2018-03-22 20:57:13.377387: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""HashTable"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_STRING } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_INT64 } } }') for unknown op: HashTable
2018-03-22 20:57:13.377422: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""HashTable"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_INT64 } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_STRING } } }') for unknown op: HashTable
2018-03-22 20:57:13.377890: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""HashTable"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_INT64 } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_INT64 } } }') for unknown op: HashTable
2018-03-22 20:57:13.381780: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""HashTable"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_INT64 } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_FLOAT } } }') for unknown op: HashTable
2018-03-22 20:57:13.381821: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""HashTable"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_STRING } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_STRING } } }') for unknown op: HashTable
2018-03-22 20:57:13.381840: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""HashTable"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_STRING } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_BOOL } } }') for unknown op: HashTable
2018-03-22 20:57:13.381860: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""HashTable"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_INT32 } } }') for unknown op: HashTable
2018-03-22 20:57:13.384408: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""LookupTableImportV2"" device_type: ""CPU""') for unknown op: LookupTableImportV2
2018-03-22 20:57:13.384454: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""LookupTableImport"" device_type: ""CPU""') for unknown op: LookupTableImport
2018-03-22 20:57:13.384488: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""LookupTableExportV2"" device_type: ""CPU""') for unknown op: LookupTableExportV2
2018-03-22 20:57:13.384536: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""LookupTableSize"" device_type: ""CPU""') for unknown op: LookupTableSize
2018-03-22 20:57:13.384571: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""LookupTableInsertV2"" device_type: ""CPU""') for unknown op: LookupTableInsertV2
2018-03-22 20:57:13.384605: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""LookupTableInsert"" device_type: ""CPU""') for unknown op: LookupTableInsert
2018-03-22 20:57:13.384709: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""LookupTableFindV2"" device_type: ""CPU""') for unknown op: LookupTableFindV2
2018-03-22 20:57:13.384775: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""LookupTableFind"" device_type: ""CPU""') for unknown op: LookupTableFind
2018-03-22 20:57:13.384815: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""InitializeTableFromTextFile"" device_type: ""CPU""') for unknown op: InitializeTableFromTextFile
2018-03-22 20:57:13.384852: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""InitializeTableV2"" device_type: ""CPU""') for unknown op: InitializeTableV2
2018-03-22 20:57:13.385205: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""InitializeTable"" device_type: ""CPU""') for unknown op: InitializeTable
2018-03-22 20:57:13.386101: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""LookupTableExport"" device_type: ""CPU""') for unknown op: LookupTableExport
2018-03-22 20:57:13.386266: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""InitializeTableFromTextFileV2"" device_type: ""CPU""') for unknown op: InitializeTableFromTextFileV2
2018-03-22 20:57:13.386366: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""LookupTableSizeV2"" device_type: ""CPU""') for unknown op: LookupTableSizeV2
2018-03-22 20:57:13.386434: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""MutableHashTable"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_STRING } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_FLOAT } } }') for unknown op: MutableHashTable
2018-03-22 20:57:13.386500: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""MutableHashTable"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_STRING } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_INT64 } } }') for unknown op: MutableHashTable
2018-03-22 20:57:13.386580: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""MutableHashTable"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_INT64 } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_STRING } } }') for unknown op: MutableHashTable
2018-03-22 20:57:13.386626: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""MutableHashTable"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_STRING } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_BOOL } } }') for unknown op: MutableHashTable
2018-03-22 20:57:13.386665: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: ""MutableHashTable"" device_type: ""CPU"" constraint { name: ""key_dtype"" allowed_values { list { type: DT_INT64 } } } constraint { name: ""value_dtype"" allowed_values { list { type: DT_FLOAT } } }') for unknown op: MutableHashTable
```"
17941,initial  large tf.variable error,"### System information
- **Have I written custom code: yes 
- **OS Platform and Distribution Ubuntu 16.04**:
- **TensorFlow installed from source **:
- **TensorFlow version 1.6**:
- **Python version 3.5**: 
- **Bazel version 0.11.1**:
- **GCC/Compiler version (5)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:
### Describe the problem
when i'm using same code, only the weight variable have different size
and when weight array is small everything is fine, but when too big it show shape issue

### Source code / logs
souce code:
with tf.device('/cpu:0'):
	W_fc1 = weight_variable([32768, 35000],""W_fc1"")#32768
	b_fc1 = bias_variable([35000],""b_fc1"")
	h_pool5_flat = tf.reshape(h_pool5, [-1, 16*16*128])
	h_fc1 = tf.nn.relu(tf.matmul(h_pool5_flat, W_fc1) + b_fc1,name=""h_fc1"")
	h_fc1_drop = tf.clip_by_value(tf.cast(tf.nn.dropout(tf.cast(h_fc1,tf.float32), keep_prob),tf.float16, name=""h_fc1_drop""),min_clip,max_clip, name=""h_fc1_drop"")
	h_fc1_drop_1 = tf.where(tf.is_nan(h_fc1_drop), tf.constant(min_clip,dtype=tf.float16, shape=h_fc1_drop.shape), h_fc1_drop)

##down sampleing fc2 layer##
#with tf.device('/cpu:0'):
	W_fc2 = weight_variable([35000,65536],""W_fc2"")
	b_fc2 = bias_variable([65536],""b_fc2"")
	h_fc2 = tf.clip_by_value(tf.nn.relu(tf.matmul(h_fc1_drop_1, W_fc2) + b_fc2),min_clip,max_clip, name=""h_fc2"")
	h_fc2_1 = tf.where(tf.is_nan(h_fc2), tf.constant(min_clip,dtype=tf.float16, shape=h_fc2.shape), h_fc2)
..........
loss = tf.losses.mean_squared_error(y_reshape,prediction_1)
train_step = tf.train.AdamOptimizer(lr).minimize(loss)

when W_fc1 is as big as the above 
it show the error
   File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py"", line 3271, in create_op
    op_def=op_def)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py"", line 1650, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [35000,65536] rhs shape= [32768,35000]
         [[Node: W_fc2/Adam_1/Assign = Assign[T=DT_HALF, _class=[""loc:@W_fc2""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](W_fc2/Adam_1, W_fc2/Adam/Initializer/zeros)]]
"
17939,Fail to convert TransposeConv into tflite,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:source
- **TensorFlow version (use command below)**: latest
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: Build label: 0.7.0
- **GCC/Compiler version (if compiling from source)**:N/A
- **CUDA/cuDNN version**:N/A
- **GPU model and memory**:N/A
- **Exact command to reproduce**N/A:


I try to convert my model into tflite, shows the below error:

F tensorflow/contrib/lite/toco/graph_transformations/propagate_fixed_sizes.cc:243] Check failed: weights_shape.dims(0) == 1 && weights_shape.dims(3) == 1 TransposeConv weights dimensions must begin and end with 1. Input weights ""Variable_39/read_transposed"" had shape [ 128, 3, 3, 64 ].

Does the TFLite TransposeConv weights only support [1, X, X, 1]  ?

And I checked the commit ID: 58fe7d26afa435560e7a0d8ca6fc8d670d2477da : ""Support for transpose convolution. Includes striding, and a reference implementation.""
Seems that transpose convolution is not suppoertted yet, I can not find any Register_XXX in the ops files, only a function ""inline void TransposeConv(const float* input_data, const Dims<4>& input_dims,
                          const float* filter_data, const Dims<4>& filter_dims,
                          int stride_width, int stride_height, int pad_width,
                          int pad_height, float* output_data,
                          const Dims<4>& output_dims)""
and there is no place call this function ""TransposeConv"""
17933,gRPC debug URL scheme support for Windows,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes (See below)
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.6.0
- **Python version**: 3.6.1
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: See below

### Describe the problem
Incidentally, this is both a bug report and a feature request. 

To reproduce the bug, run the following:

```python
import tensorflow as tf
from tensorflow.python import debug as tf_debug

session = tf.Session()
session = tf_debug.TensorBoardDebugWrapperSession(session, ""localhost:9898"")

current_epoch = tf.Variable(0, trainable=False, name='current_epoch')
increment_epoch = tf.assign(current_epoch, current_epoch + 1)

start_epoch = current_epoch.eval(session)
print(""start_epoch:"", start_epoch)
for cur_epoch in range(start_epoch, 10):
    session.run(increment_epoch)

```

The following is the output:
```
Traceback (most recent call last):
  File ""C:/workspace/test.py"", line 12, in <module>
    for cur_epoch in range(start_epoch, 10):
TypeError: 'UnimplementedError' object cannot be interpreted as an integer
start_epoch: grpc:// debug URL scheme is not implemented on Windows yet.
```

It's clear that the error is being assigned to a variable instead of being raised. Furthermore, the behavior is only present when evaluating a variable; this is unexpected, as it has nothing to do with the session itself.

I came across this while trying to enable debugging via TensorBoard. After some digging, it appears that the error message originates from [TensorFlow core code](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/debug/debug_io_utils.cc#L390), so that's why this issue is here and not in the TensorBoard project. Is there any status on implementation of this feature? If not, could there be a log warning or some sort of feedback to reflect this? The TensorBoard modal at http://localhost:6006/#debugger gives no indication that it is platform-dependent.
"
17932,tf.contrib.data.bucket_by_sequence_length fails for nested Dataset element,"Hello everyone,

I just tried the new function to group variable length inputs for the dataset API, namely: `tf.contrib.data.bucket_by_sequence_length`, for a small Estimator-Model.

I implemented the `input_fn` such that it returns a dataset, where each element is a tuple [(feature-dict, label)](https://www.tensorflow.org/get_started/premade_estimators#create_input_functions). However, when I run it, I get following exception:

> Traceback (most recent call last):
> ... 
>   File ""/home/leo/anaconda3/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 960, in apply
>     dataset = transformation_func(self)
>   File ""/home/leo/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/data/python/ops/grouping.py"", line 198, in _apply_fn
>     window_size_func=window_size_fn))
>   File ""/home/leo/anaconda3/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 960, in apply
>     dataset = transformation_func(self)
>   File ""/home/leo/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/data/python/ops/grouping.py"", line 90, in _apply_fn
>     window_size_func)
>   File ""/home/leo/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/data/python/ops/grouping.py"", line 239, in __init__
>     self._make_key_func(key_func, input_dataset)
>   File ""/home/leo/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/data/python/ops/grouping.py"", line 289, in _make_key_func
>     self._key_func.add_to_graph(ops.get_default_graph())
>   File ""/home/leo/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/function.py"", line 488, in add_to_graph
>     self._create_definition_if_needed()
>   File ""/home/leo/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/function.py"", line 321, in _create_definition_if_needed
>     self._create_definition_if_needed_impl()
>   File ""/home/leo/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/function.py"", line 338, in _create_definition_if_needed_impl
>     outputs = self._func(*inputs)
>   File ""/home/leo/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/data/python/ops/grouping.py"", line 279, in tf_key_func
>     ret = key_func(*nested_args)
> TypeError: element_to_bucket_id() takes 1 positional argument but 2 were given

Here is a [link](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/data/python/ops/grouping.py#L143) to the function.

Here is a code snipped to reproduce the error:

```python
import tensorflow as tf

def input_fn():
  def generator():
    text = [[1, 2, 3],
            [3, 4, 5, 6, 7],
            [1, 2],
            [8, 9, 0, 2, 3]]
    label = [1, 2, 1, 2]

    for x, y in zip(text, label):
      yield (x, y)

  dataset = tf.data.Dataset.from_generator(generator=generator,
                                           output_shapes=(tf.TensorShape([None]), tf.TensorShape([])),
                                           output_types=(tf.int32, tf.int32))

  dataset = dataset.map(parse_example)
  dataset = dataset.apply(tf.contrib.data.bucket_by_sequence_length(element_length_func=element_length_fn,
                                                                    bucket_batch_sizes=[2, 2, 2],
                                                                    bucket_boundaries=[0, 8],
                                                                    pad_to_bucket_boundary=False))

  return dataset

def parse_example(x, y):
  return dict(
    x=x
  ), y

def element_length_fn(element):
  features, label = element
  return tf.shape(features[""x""])[0]

if __name__ == '__main__':
  with tf.Session() as sess:
    dataset = input_fn()
    iter = dataset.make_one_shot_iterator()

    print(sess.run(iter.get_next()))
```

My Env-Specs are logged in: [tf_env.txt](https://github.com/tensorflow/tensorflow/files/1838947/tf_env.txt)

Thanks in advance!"
17930,Memory Leak in SavedModelBundle.load() in the TensorFlow Java API,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: 1.6.0
- **Python version**: 2.7.12
- **Java version**: OpenJDK 1.8.0_151
- **Bazel version (if compiling from source)**: 0.6.1
- **GCC/Compiler version (if compiling from source)**: gcc 5.4.0
- **CUDA/cuDNN version**: CUDA 9.0 / cuDNN 7.0
- **GPU model and memory**: name: TITAN Xp, compute capability: 6.1, total memory: 11.90GiB
- **Exact command to reproduce**: SavedModelBundle.load() and Runner.run() from Java API

### Describe the problem

There seems to be a memory leak when using the Tensorflow Java API when executing the load static method of SavedModelBundle class and the run method of the Runner class.  In the process of debugging, I've attached the VisualVM profiler and a remote Java debugger to step through code execution.  Additionally, I've been using `htop` to monitor the memory usage from active processes running on the server hosting the API.  

From this, I've been able to observe
- each time the inference is invoked, it increases my total memory consumption by about 0.18G - 0.19G, which is approximately the size of my saved model files being loaded.  
- my Java heap memory is not permanently increasing; after the inference has finished all heap memory returns to the amount before the inference started.

I've been sure to invoke the close method of each class that extends AutoCloseable that I've used.  I do not explicitly invoke the close method on the Session and Graph managed by the SavedModelBundle, as its close method invokes the close methods of its Session and Graph.  This is reflected in the code example provided below.

This memory leak occurs whether I'm building with GPU acceleration or not.

To build the native libraries and Java API from source with GPU acceleration, I'm using the following bazel command (from the 1.6.0 release tag):

```
bazel build --verbose_failures --action_env=""LD_LIBRARY_PATH=${LD_LIBRARY_PATH}"" --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0""  --config=opt --config=cuda //tensorflow/java:tensorflow //tensorflow/java:libtensorflow_jni
```

To build the native libraries and Java API from source without GPU acceleration, I'm using the following bazel command (from the 1.6.0 release tag):

```
bazel build --verbose_failures --action_env=""LD_LIBRARY_PATH=${LD_LIBRARY_PATH}"" --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0""    //tensorflow/java:tensorflow //tensorflow/java:libtensorflow_jni
```

In an attempt to get more information about the execution of the native code, I've tried to enable debug mode while building the native libraries by repliacing `--config=opt` with `-c dbg --strip=never --compilation_mode=dbg`, however this causes the following exception:

```
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorExecutor.h:262: static void Eigen::internal::TensorExecutor<Expression, Eigen::GpuDevice, Vectorizable>::run(const Expression&, const Eigen::GpuDevice&) [with Expression = const Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long int>, 16, Eigen::MakePointer>, const Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<const float, const float>, const Eigen::TensorMap<Eigen::Tensor<const float, 1, 1, long int>, 16, Eigen::MakePointer>, const Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op, const Eigen::TensorMap<Eigen::Tensor<const float, 1, 1, long int>, 16, Eigen::MakePointer> > > >; bool Vectorizable = true]: Assertion `cudaGetLastError() == cudaSuccess' failed.
```

I originally found the memory leak while using TensorFlow 1.4.0, CUDA 8.0, and cuDNN 6.0.  Before updating the versions, each inference was retaining about 1.4-1.5G of memory; by updating, I managed to reduce this significantly, however still need to eliminate the memory leak altogether.

I've spent hours trying to figure out how to profile the native code execution, most recently by following these answers from Stack Overflow:
1. [How to profile Native JNI library](https://stackoverflow.com/questions/14752459/how-to-profile-native-jni-library)
2. [gprof : How to generate call graph for functions in shared library that is linked to main program](https://stackoverflow.com/questions/1838989/gprof-how-to-generate-call-graph-for-functions-in-shared-library-that-is-linke/4959168#4959168)

I've been unable to successfully compile the native libraries with the debug flag (`-g`) to profile.  I've poked around the bazel build scripts a bit, as I don't believe that the debug mode indicated by the `--compilation_mode=dbg` flag actually compiles the libraries for debugging, however have been unable to locate where I'd add the `-g` compilation flag.


### Source code / logs

Here is my configuration output when configuring with GPU acceleration.
```
ilats-admin$ ./configure
You have bazel 0.6.1 installed.
Please specify the location of python. [Default is /usr/bin/python]: 


Found possible Python library paths:
  /usr/local/lib/python2.7/dist-packages
  /usr/lib/python2.7/dist-packages
Please input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/dist-packages]

Do you wish to build TensorFlow with jemalloc as malloc support? [Y/n]: N
No jemalloc as malloc support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Google Cloud Platform support? [Y/n]: N
No Google Cloud Platform support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Hadoop File System support? [Y/n]: N
No Hadoop File System support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Amazon S3 File System support? [Y/n]: N
No Amazon S3 File System support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Apache Kafka Platform support? [y/N]: N
No Apache Kafka Platform support will be enabled for TensorFlow.

Do you wish to build TensorFlow with XLA JIT support? [y/N]: N
No XLA JIT support will be enabled for TensorFlow.

Do you wish to build TensorFlow with GDR support? [y/N]: N
No GDR support will be enabled for TensorFlow.

Do you wish to build TensorFlow with VERBS support? [y/N]: N
No VERBS support will be enabled for TensorFlow.

Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: N
No OpenCL SYCL support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: Y
CUDA support will be enabled for TensorFlow.

Please specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 9.0]: 


Please specify the location where CUDA 9.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: /usr/local/cuda-9.0


Please specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7.0]: 


Please specify the location where cuDNN 7 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda-9.0]:


Do you wish to build TensorFlow with TensorRT support? [y/N]: N
No TensorRT support will be enabled for TensorFlow.

Please specify a list of comma-separated Cuda compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size. [Default is: 6.1]


Do you want to use clang as CUDA compiler? [y/N]: N
nvcc will be used as CUDA compiler.

Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: 


Do you wish to build TensorFlow with MPI support? [y/N]: N
No MPI support will be enabled for TensorFlow.

Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native]: 


Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: N
Not configuring the WORKSPACE for Android builds.

Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See tools/bazel.rc for more details.
	--config=mkl         	# Build with MKL support.
	--config=monolithic  	# Config for mostly static monolithic build.
	--config=tensorrt    	# Build with TensorRT support.
Configuration finished
```

I've created a sample application below that is a minimal version of my custom code, and still causes the memory leak to occur.  I've used a simple while loop to perform an inference whenever a character is entered from `stdin`, to demonstrate the memory being used not released while the application is still running.

This code is used for inference against a trained version of Object Detection model architecture found [here](https://github.com/tensorflow/models/tree/master/research/object_detection).  I've prepared a custom dataset and performed training similar to the [Quick Start guide for Training a Pet Detector](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_pets.md).  Following this guide through the section titled **Exporting the Tensorflow Graph** should produce a saved model that can be used with this code sample.  You'll need to adjust the path to the saved model, the labels to those used for the guide, and the file path to the image to detect objects in, which are all captured as static final variables towards the top of the class.

```
import java.io.*;
import org.tensorflow.Tensor;
import org.tensorflow.SavedModelBundle;
import org.tensorflow.types.UInt8;
import java.awt.image.BufferedImage;
import java.awt.image.DataBufferByte;
import javax.imageio.ImageIO;
import java.nio.ByteBuffer;
import java.nio.ByteOrder;
import java.util.List;

public class Main {
  private static final String[] LABELS = {""label1"", ""label2"", ""label3"", ""label4"", ""label5"", ""label6"", ""label7""};
  private static final String SAVED_MODEL_PATH = ""/usr/repositories/resources/models/ilats-targets-4/saved_model"";
  private static final String FILE_PATH = ""/tmp/inference_image.jpeg"";

  // Definite input and output Tensors for detection_graph
  private static final String IMAGE_TENSOR_NAME = ""image_tensor:0"";

  // Each box represents a part of the image where a particular object was detected.
  private static final String DETECTION_BOXES_NAME = ""detection_boxes:0"";

  // Each score represent how level of confidence for each of the objects.
  // Score is shown on the result image, together with the class label.
  private static final String DETECTION_SCORES_NAME = ""detection_scores:0"";

  private static final String DETECTION_CLASSES_NAME = ""detection_classes:0"";

  public static void main(String[] args) {
    int ch;
    try {

      while ((ch = System.in.read()) != -1) {
        performInference();
      }

    } catch (Exception e) {
    }
  }

  public static void performInference() {
    SavedModelBundle model = null;
    Tensor<UInt8> imageTensor = null;
    List<Tensor<?>> outputs = null;

    try {
      model = SavedModelBundle.load(SAVED_MODEL_PATH, ""serve"");
      imageTensor = makeImageTensor(FILE_PATH);
      
      outputs = model
        .session()
        .runner()
        .feed(IMAGE_TENSOR_NAME, imageTensor)
        .fetch(DETECTION_SCORES_NAME)
        .fetch(DETECTION_CLASSES_NAME)
        .fetch(DETECTION_BOXES_NAME)
        .run();

    } catch (Exception e) {
      throw new RuntimeException(e.getMessage(), e);
    } finally {
      // this closes Session and Graph that belongs to model as well
      if (model != null) {
        model.close();
      }

      if (imageTensor != null) {
        imageTensor.close();
      }

      if (outputs != null) {
        for (Tensor output : outputs) {
          if (output != null) {
            output.close();
          }
        }
      }
    }
    

  }

  public static Tensor<UInt8> makeImageTensor(String filename) throws IOException {
    BufferedImage img = ImageIO.read(new File(filename));
    if (img.getType() != BufferedImage.TYPE_3BYTE_BGR) {
      throw new IOException(
        String.format(""Expected 3-byte BGR encoding in BufferedImage, found %d (file: %s). This code could be made more robust"", img.getType(), filename)
      );
    }

    byte[] data = ((DataBufferByte) img.getData().getDataBuffer()).getData();
    // ImageIO.read seems to produce BGR-encoded images, but the model expects RGB.
    bgr2rgb(data);
    final long BATCH_SIZE = 1;
    final long CHANNELS = 3;
    long[] shape = new long[] {BATCH_SIZE, img.getHeight(), img.getWidth(), CHANNELS};
    Tensor<UInt8> imageTensor = Tensor.create(UInt8.class, shape, ByteBuffer.wrap(data));
    img.flush();
    return imageTensor;
  }

  public static void bgr2rgb(byte[] data) {
    for (int i = 0; i < data.length; i += 3) {
      byte tmp = data[i];
      data[i] = data[i + 2];
      data[i + 2] = tmp;
    }
  }

}
```

The instructions to compile and run this are similar to those found in the [TensorFlow for Java Readme](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/java/README.md).

```
$ GENFILE_DIR=/usr/repositories/tensorflow/bazel-bin/tensorflow/java
$ javac -cp ./:$GENFILE_DIR/libtensorflow.jar Main.java
$ java -cp ./:$GENFILE_DIR/libtensorflow.jar \
  -Djava.library.path=$GENFILE_DIR \
  Main
```
"
17925,MaskedAutoregressiveFlow example (tf.contrib.distributions) raises ValueError,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Google Colab (also tried on a Windows 10 machine with TF 1.6)
- **TensorFlow installed from (source or binary)**: defaults from Colab
- **TensorFlow version (use command below)**: 1.6.0
- **Python version**: 3.6.3 (default, Oct  3 2017, 21:45:48)
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: see attached file

### Describe the problem
I'm new to tf.contrib.distributions. I've just copied the example for MaskedAutoregressiveFlow from [https://www.tensorflow.org/api_docs/python/tf/contrib/distributions/bijectors/MaskedAutoregressiveFlow](https://www.tensorflow.org/api_docs/python/tf/contrib/distributions/bijectors/MaskedAutoregressiveFlow). Running the example fails with a ValueError at `maf.sample()`. See the attached file and error log below.  Running `tf.global_variables_initializer()` in the session doesn't solve it either. It looks like `masked_autoregressive_default_template` expects a tensor with `ndim>1` but `MaskedAutoregressiveFlow.forward()` passes a tensor with `ndim=1`. 

[masked_autoregressive_issue.txt](https://github.com/tensorflow/tensorflow/files/1837741/masked_autoregressive_issue.txt)


### Source code / logs
```
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-3-646c58f4e818> in <module>()
     12 sess.run(tf.global_variables_initializer())
     13 
---> 14 x = maf.sample()  # Expensive; uses `tf.while_loop`, no Bijector caching.
     15 maf.log_prob(x)   # Almost free; uses Bijector caching.
     16 maf.log_prob(0.)  # Cheap; no `tf.while_loop` despite no Bijector caching.

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/distributions/distribution.py in sample(self, sample_shape, seed, name)
    687       samples: a `Tensor` with prepended dimensions `sample_shape`.
    688     """"""
--> 689     return self._call_sample_n(sample_shape, seed, name)
    690 
    691   def _log_prob(self, value):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/distributions/transformed_distribution.py in _call_sample_n(self, sample_shape, seed, name, **kwargs)
    411       # work, it is imperative that this is the last modification to the
    412       # returned result.
--> 413       y = self.bijector.forward(x, **kwargs)
    414       y = self._set_sample_static_shape(y, sample_shape)
    415 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/distributions/bijector_impl.py in forward(self, x, name)
    618       NotImplementedError: if `_forward` is not implemented.
    619     """"""
--> 620     return self._call_forward(x, name)
    621 
    622   def _inverse(self, y):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/distributions/bijector_impl.py in _call_forward(self, x, name, **kwargs)
    599       if mapping.y is not None:
    600         return mapping.y
--> 601       mapping = mapping.merge(y=self._forward(x, **kwargs))
    602       self._cache(mapping)
    603       return mapping.y

/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/distributions/python/ops/bijectors/masked_autoregressive.py in _forward(self, x)
    245     y0 = array_ops.zeros_like(x, name=""y0"")
    246     # call the template once to ensure creation
--> 247     _ = self._shift_and_log_scale_fn(y0)
    248     def _loop_body(index, y0):
    249       """"""While-loop body for autoregression calculation.""""""

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/template.py in __call__(self, *args, **kwargs)
    358           custom_getter=self._custom_getter) as vs:
    359         self._variable_scope = vs
--> 360         result = self._call_func(args, kwargs)
    361         return result
    362 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/template.py in _call_func(self, args, kwargs)
    300       trainable_at_start = len(
    301           ops.get_collection(ops.GraphKeys.TRAINABLE_VARIABLES))
--> 302       result = self._func(*args, **kwargs)
    303 
    304       if self._variables_created:

/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/distributions/python/ops/bijectors/masked_autoregressive.py in _fn(x)
    478             activation=activation,
    479             *args,
--> 480             **kwargs)
    481       x = masked_dense(
    482           inputs=x,

/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/distributions/python/ops/bijectors/masked_autoregressive.py in masked_dense(inputs, units, num_blocks, exclusive, kernel_initializer, reuse, name, *args, **kwargs)
    386         *args,
    387         **kwargs)
--> 388     return layer.apply(inputs)
    389 
    390 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py in apply(self, inputs, *args, **kwargs)
    807       Output tensor(s).
    808     """"""
--> 809     return self.__call__(inputs, *args, **kwargs)
    810 
    811   def _add_inbound_node(self,

/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py in __call__(self, inputs, *args, **kwargs)
    671 
    672           # Check input assumptions set before layer building, e.g. input rank.
--> 673           self._assert_input_compatibility(inputs)
    674           if input_list and self._dtype is None:
    675             try:

/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py in _assert_input_compatibility(self, inputs)
   1195                            ', found ndim=' + str(ndim) +
   1196                            '. Full shape received: ' +
-> 1197                            str(x.get_shape().as_list()))
   1198       # Check dtype.
   1199       if spec.dtype is not None:

ValueError: Input 0 of layer dense_1 is incompatible with the layer: : expected min_ndim=2, found ndim=1. Full shape received: [5]

originally defined at:
  File ""<ipython-input-3-646c58f4e818>"", line 10, in <module>
    hidden_layers=[512,512])),
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/distributions/python/ops/bijectors/masked_autoregressive.py"", line 499, in masked_autoregressive_default_template
    ""masked_autoregressive_default_template"", _fn)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/template.py"", line 152, in make_template
    **kwargs)
```
edit: fixed link to TF doc"
17924,[tensorflow] Android studio doesn't fetch setUseNNAPI,"in build.gradle below dependency will not download
latest file of ./tensorflow/contrib/lite/java/src/main/java/org/tensorflow/lite/Interpreter.java

dependencies {
compile 'org.tensorflow:tensorflow-lite:+'
}

Hence we are getting unresolved symbol for new API setUseNNAPI

as gradle unable to download new API as below

  /** Turns on/off Android NNAPI for hardware acceleration when it is available. */
  public void setUseNNAPI(boolean useNNAPI) {
    if (wrapper != null) {
      wrapper.setUseNNAPI(useNNAPI);
    } else {
      throw new IllegalStateException(""NativeInterpreterWrapper has already been closed."");
    }
  }
"
17923,Does Tensorflow Lite supports LSTM?,"Hi, 

Tensorflow Lite does not supports tf.tanh according to [compatibility guide].(https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/tf_ops_compatibility.md). 
However tf.tanh is usually part of LSTM. 
Then, Does TF-Lite support LSTM or not? 
Does TF-Lite have compatible operator of BasicLSTMCell?

Thanks."
17922,'cannot import name string_int_label_map_pb2' ,"Hello there;

I am using tensorflow 1.6 cpu in windows 8.1 anaconda jupyter notebook

I want to use tensorflow object detection api and I follow the installation instruction provided in the  models tensorflow github repository

according to that instructions 

1. First I installed tensorflow and the other dependencies 
2. I did the protobuf compilation
3. The pythonpath is also being set
and the setup.py file is being run
but when I try to use the object_detection_tutorial.ipynb it still shows the ""import error cannot import name string_int_label_map_pb2"" 
please help me if I am doing something wrong, I know this issue is old but still, it causes a lot of problems. help me 

Thanking you in anticipation
"
17921,"Using Android studio, Interpreter.java is not getting picked for compiling","I am using android studio and have made changes in Imageclassifier calling setUseNNAPI. But it is not getting picked from Interpreter.java which enable developers turn on & off NNAPI. 


OS Platform and Distribution: Ubuntu 14.04
TensorFlow installed from: Git cloned
TensorFlow version: N/A
Bazel version: Build label: 0.11.1
CUDA/cuDNN version: N/A
GPU model and memory: x86 8GB RAM
Exact command to reproduce: Using Android studio as a existing project"
17919,Tensorflow Install Problem,"I installed Tensorflow 1.6 CPU only on Linux Ubuntu 17.10 use Virtualenv approach last night, follow the installing instructions 1-5, every step are success. after system response install  success, I want to validate the installation. the steps as below:
1. type the commond ""source ~/tensorflow/bin/activate"" the os system response:
(tensorflow) bruce@bruce:~$ 
2.input python response:
(tensorflow) bruce@bruce:~$ python
Python 3.6.3 (default, Oct  3 2017, 21:45:48) 
[GCC 7.2.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
3.input ""import tensorflow as tf"". the system crashed:
>>> import tensorflow as tf
非法指令 (核心已转储)
(tensorflow) bruce@bruce:~$

I try many times the result same as above descript.Even i restart my laptop the problem still here. i use the gdb open the core file, the information as below, i don't know how to handle  this problem . for i couldn't register account on stack overflow, so i couldn't ask question at that site. Who can help me solve this issue, please help me!

[Thread debugging using libthread_db enabled]
Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".
Core was generated by `python'.
Program terminated with signal SIGILL, Illegal instruction.
#0  0x00007fb0828de880 in std::pair<std::__detail::_Node_iterator<std::pair<tensorflow::StringPiece const, std::function<bool (tensorflow::Variant*)> >, false, true>, bool> std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, std::function<bool (tensorflow::Variant*)> >, std::allocator<std::pair<tensorflow::StringPiece const, std::function<bool (tensorflow::Variant*)> > >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_emplace<std::pair<tensorflow::StringPiece, std::function<bool (tensorflow::Variant*)> > >(std::integral_constant<bool, true>, std::pair<tensorflow::StringPiece, std::function<bool (tensorflow::Variant*)> >&&) () from /usr/local/lib/python3.6/dist-packages/tensorflow/python/../libtensorflow_framework.so
[Current thread is 1 (Thread 0x7fb0916f0740 (LWP 2908))]
(gdb) 


### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 17.10
- **TensorFlow installed from (source or binary)**:
from binary
- **TensorFlow version (use command below)**:
1.6
- **Python version**: 
3.6.3
- **Bazel version (if compiling from source)**:
N/A
- **GCC/Compiler version (if compiling from source)**:
N/A
- **CUDA/cuDNN version**:
N/A
- **GPU model and memory**:
N/A
- **Exact command to reproduce**:

"
17917,Bazel build FAILED on Ubuntu16.04 caused by extension file to detect MSVC for Windows,"When using BAZEL to build TF r.17 from source on Ubuntu16.04. It failed caused by the bazel extension file located at /tensorflow/tools/def_file_filter/def_file_filter_configure.bzl, which is used to export symbols from TF DLL file for Windows. The same problem occurs for building TF-Lite also.

Commend:
> bazel build --config=opt  //tensorflow/tools/pip_package:build_pip_package
> bazel build --config=opt   //tensorflow/contrib/lite/toco:toco

Bazel output:
**ERROR:** ~/tensorflow-r1.7/tensorflow/tools/def_file_filter/def_file_filter_configure.bzl:22:1: file '@bazel_tools//tools/cpp:windows_cc_configure.bzl' does not contain symbol 'find_vc_path' (did you mean '_find_vc_path'?).
**ERROR:** ~/tensorflow-r1.7/tensorflow/tools/def_file_filter/def_file_filter_configure.bzl:23:1: file '@bazel_tools//tools/cpp:windows_cc_configure.bzl' does not contain symbol 'find_msvc_tool' (did you mean '_find_msvc_tool'?).
**ERROR:** error loading package '': Extension file 'tensorflow/tools/def_file_filter/def_file_filter_configure.bzl' has errors.

"
17916, ImportError: libcublas.so.9.0: cannot,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
17914,TF 1.7.0-rc1 unable to build with TensorRT support,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.7.0-rc1
- **Python version**: Python 3.5
- **Bazel version (if compiling from source)**: 0.11.1
- **GCC/Compiler version (if compiling from source)**: 5.4.0-6ubuntu1~16.04.9
- **CUDA/cuDNN version**: 9.0 / 7.0.5
- **GPU model and memory**: GTX 1070, 8Gb
- **Exact command to reproduce**: `bazel build -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both --copt=-msse4.1 --copt=-msse4.2 --config=cuda //tensorflow/tools/pip_package:build_pip_package --verbose_failures`

### Describe the problem
Try to build TF with TensorRT support using the command above and following [this](https://github.com/tensorflow/tensorflow/tree/v1.7.0-rc1/tensorflow/contrib/tensorrt) instruction, i.e. there is no TensorRT installed from repo, only downloaded binaries for 14.04 + `echo ""<install_dir>/TensorRT-3.0.4/lib"" | sudo tee /etc/ld.so.conf.d/tensorrt304.conf && sudo ldconfig`, as suggested. 
The `libcudnn.so*` available in TensorRT `lib` dir, `/usr/local/lib` and `/usr/lib/x86_64-linux-gnu`. `LD_LIBRARY_PATH` contains all relevant paths. 
While `configure`, I pointed to TensorRT binaries dir when it asked.
`/usr/local/cuda` points to `9.0` version and this path was specified while `configure`.

### Source code / logs
```
WARNING: /home/alexandr/.cache/bazel/_bazel_alexandr/6c93df3ac6ca06598f74e718588ae6cc/external/protobuf_archive/WORKSPACE:1: Workspace name in /home/alexandr/.cache/bazel/_bazel_alexandr/6c93df3ac6ca06598f74e718588ae6cc/external/protobuf_archive/WORKSPACE (@com_google_protobuf) does not match the name given in the repository's definition (@protobuf_archive); this will cause a build error in future versions
WARNING: /home/alexandr/distr/tensorflow_tensorrt/tensorflow/core/BUILD:1955:1: in includes attribute of cc_library rule //tensorflow/core:framework_headers_lib: '../../external/nsync/public' resolves to 'external/nsync/public' not below the relative path of its package 'tensorflow/core'. This will be an error in the future. Since this rule was created by the macro 'cc_header_only_library', the error might have been caused by the macro implementation in /home/alexandr/distr/tensorflow_tensorrt/tensorflow/tensorflow.bzl:1179:30
WARNING: /home/alexandr/distr/tensorflow_tensorrt/tensorflow/core/BUILD:1955:1: in includes attribute of cc_library rule //tensorflow/core:framework_headers_lib: '../../external/nsync/public' resolves to 'external/nsync/public' not below the relative path of its package 'tensorflow/core'. This will be an error in the future. Since this rule was created by the macro 'cc_header_only_library', the error might have been caused by the macro implementation in /home/alexandr/distr/tensorflow_tensorrt/tensorflow/tensorflow.bzl:1179:30
WARNING: /home/alexandr/.cache/bazel/_bazel_alexandr/6c93df3ac6ca06598f74e718588ae6cc/external/grpc/WORKSPACE:1: Workspace name in /home/alexandr/.cache/bazel/_bazel_alexandr/6c93df3ac6ca06598f74e718588ae6cc/external/grpc/WORKSPACE (@com_github_grpc_grpc) does not match the name given in the repository's definition (@grpc); this will cause a build error in future versions
WARNING: /home/alexandr/distr/tensorflow_tensorrt/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': No longer supported. Switch to SavedModel immediately.
WARNING: /home/alexandr/distr/tensorflow_tensorrt/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': No longer supported. Switch to SavedModel immediately.
INFO: Analysed target //tensorflow/tools/pip_package:build_pip_package (0 packages loaded).
INFO: Found 1 target...
ERROR: /home/alexandr/distr/tensorflow_tensorrt/tensorflow/contrib/tensorrt/BUILD:122:1: Linking of rule '//tensorflow/contrib/tensorrt:gen_trt_engine_op_py_wrappers_cc' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command 
  (cd /home/alexandr/.cache/bazel/_bazel_alexandr/6c93df3ac6ca06598f74e718588ae6cc/execroot/org_tensorflow && \
  exec env - \
    LD_LIBRARY_PATH=:/usr/local/cuda/lib64 \
    PATH=/home/alexandr/bin:/home/alexandr/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/usr/local/cuda/bin \
    PWD=/proc/self/cwd \
  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -o bazel-out/host/bin/tensorflow/contrib/tensorrt/gen_trt_engine_op_py_wrappers_cc '-Wl,-rpath,$ORIGIN/../../../_solib_local/_U_S_Stensorflow_Scontrib_Stensorrt_Cgen_Utrt_Uengine_Uop_Upy_Uwrappers_Ucc___Utensorflow' '-Wl,-rpath,$ORIGIN/../../../_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib' '-Wl,-rpath,$ORIGIN/../../../_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccublas___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Scuda_Slib' '-Wl,-rpath,$ORIGIN/../../../_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccudnn___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Scuda_Slib' '-Wl,-rpath,$ORIGIN/../../../_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccufft___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Scuda_Slib' '-Wl,-rpath,$ORIGIN/../../../_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccurand___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Scuda_Slib' '-Wl,-rpath,$ORIGIN/../../../_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccudart___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Scuda_Slib' -Lbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Stensorrt_Cgen_Utrt_Uengine_Uop_Upy_Uwrappers_Ucc___Utensorflow -Lbazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib -Lbazel-out/host/bin/_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccublas___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Scuda_Slib -Lbazel-out/host/bin/_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccudnn___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Scuda_Slib -Lbazel-out/host/bin/_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccufft___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Scuda_Slib -Lbazel-out/host/bin/_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccurand___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Scuda_Slib -Lbazel-out/host/bin/_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccudart___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Scuda_Slib '-Wl,-rpath,$ORIGIN/,-rpath,$ORIGIN/..,-rpath,$ORIGIN/../..' -pthread -Wl,-rpath,../local_config_cuda/cuda/lib64 -Wl,-rpath,../local_config_cuda/cuda/extras/CUPTI/lib64 -Wl,-no-as-needed -B/usr/bin/ -pie -Wl,-z,relro,-z,now -no-canonical-prefixes -pass-exit-codes '-Wl,--build-id=md5' '-Wl,--hash-style=gnu' -Wl,--gc-sections -Wl,-S -Wl,@bazel-out/host/bin/tensorflow/contrib/tensorrt/gen_trt_engine_op_py_wrappers_cc-2.params)
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnCreate@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnCreatePoolingDescriptor@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnCreateConvolutionDescriptor@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnDestroyConvolutionDescriptor@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnGetReductionWorkspaceSize@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnSetPooling2dDescriptor@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnDestroyFilterDescriptor@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnSetReduceTensorDescriptor@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnLRNCrossChannelForward@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnCreateRNNDescriptor@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnDestroyRNNDescriptor@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnConvolutionBackwardData@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnCreateFilterDescriptor@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnSetTensor4dDescriptorEx@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnDestroyLRNDescriptor@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnDestroy@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnDropoutGetStatesSize@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnGetConvolutionForwardWorkspaceSize@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnSetActivationDescriptor@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnGetRNNWorkspaceSize@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnSetConvolutionGroupCount@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnSetTensorNdDescriptor@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnAddTensor@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnDestroyActivationDescriptor@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnGetConvolutionBackwardDataAlgorithmMaxCount@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnGetFilterNdDescriptor@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnSetLRNDescriptor@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnDestroyTensorDescriptor@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnDestroyDropoutDescriptor@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnCreateTensorDescriptor@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnSetStream@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnDestroyOpTensorDescriptor@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnCreateOpTensorDescriptor@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnCreateDropoutDescriptor@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnSetFilter4dDescriptor@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnDestroyPoolingDescriptor@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnCreateActivationDescriptor@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnRNNForwardInference@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnActivationForward@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnGetRNNLinLayerMatrixParams@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnGetConvolutionBackwardDataWorkspaceSize@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnReduceTensor@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnSetRNNDescriptor@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnSetDropoutDescriptor@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnSoftmaxForward@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnConvolutionForward@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnGetRNNLinLayerBiasParams@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnSetConvolution2dDescriptor@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnSetFilterNdDescriptor@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnGetRNNParamsSize@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnSetTensor4dDescriptor@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnSetOpTensorDescriptor@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnDestroyReduceTensorDescriptor@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnFindConvolutionBackwardDataAlgorithmEx@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnPoolingForward@libcudnn.so.7'
bazel-out/host/bin/_solib_local/_U@local_Uconfig_Utensorrt_S_S_Cnv_Uinfer___Uexternal_Slocal_Uconfig_Utensorrt_Stensorrt_Slib/libnvinfer.so.4: undefined reference to `cudnnCreateLRNDescriptor@libcudnn.so.7'
collect2: error: ld returned 1 exit status
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 0.642s, Critical Path: 0.22s
FAILED: Build did NOT complete successfully
```
---
The extended system info:
```
== cat /etc/issue ===============================================
Linux power-linux 4.12.0-041200-generic #201707022031 SMP Mon Jul 3 00:32:52 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""16.04.4 LTS (Xenial Xerus)""
VERSION_ID=""16.04""
VERSION_CODENAME=xenial

== are we in docker =============================================
No

== compiler =====================================================
c++ (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux power-linux 4.12.0-041200-generic #201707022031 SMP Mon Jul 3 00:32:52 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
msgpack-numpy (0.4.1)
numpy (1.14.2)
protobuf (3.5.2.post1)
tensorflow (1.6.0)
tensorflow-tensorboard (0.4.0)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.4.1
tf.GIT_VERSION = v1.4.1-0-g438604f
tf.COMPILER_VERSION = v1.4.1-0-g438604f
Sanity check: array([1], dtype=int32)
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *  # pylint: disable=redefined-builtin
  File ""tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""tensorflow/python/pywrap_tensorflow.py"", line 25, in <module>
    from tensorflow.python.platform import self_check
ImportError: No module named platform

== env ==========================================================
LD_LIBRARY_PATH :/usr/local/cuda/lib64:/home/alexandr/distr/tensorrt/lib:/usr/local/lib
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
Thu Mar 22 10:33:28 2018       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 387.26                 Driver Version: 387.26                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 1070    Off  | 00000000:01:00.0  On |                  N/A |
| N/A   57C    P0    41W /  N/A |    372MiB /  8112MiB |     39%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0      1166      G   /usr/lib/xorg/Xorg                           211MiB |
|    0      3086      G   compiz                                       150MiB |
|    0      3136      G   ...-token=69155177EA9D6BB8687BA31223F7A104     7MiB |
+-----------------------------------------------------------------------------+

== cuda libs  ===================================================
/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61
/usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart.so.9.0.176
/usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart_static.a
/usr/local/cuda-9.0/doc/man/man7/libcudart.so.7
/usr/local/cuda-9.0/doc/man/man7/libcudart.7
/usr/local/cuda-9.1/targets/x86_64-linux/lib/libcudart_static.a
/usr/local/cuda-9.1/targets/x86_64-linux/lib/libcudart.so.9.1.85
/usr/local/cuda-9.1/doc/man/man7/libcudart.so.7
/usr/local/cuda-9.1/doc/man/man7/libcudart.7
```"
17913,Tensorflow in Android: You must feed a value for placeholder tensor 'Placeholder' with dtype float issue," have a problem with importing Tensorflow model into Android Studio application. I have built a model, froze the model and optimized that frozen model in Python, and now I'm trying to use it in the Android app, but it constantly returns me that same error that I must feed a value for a placeholder. This is happening in the Android app when I run inferenceInterface.run(OUTPUT_NODES); function.

I don't know if the error is it in the model itself, but I'm assuming that python would throw me an error and won't build the model, what he did.

This is the example of rows of data I'm sending to Tensorflow (in csv file):

1,26,2091,5,2,0,0,0,0,0,85,105,6,4,0,1
1,26,47,9,4,0,0,0,0,0,85,0,7,4,1,0


This is the creating model in Python:
*************************************************************************************************
```
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
from math import floor, ceil
from pylab import rcParams


columns = [""Gender"", ""Age"", ""StepsNum"", ""Still"", ""ContinuousStill"",
           ""Running"", ""Driving"", ""Cycling"", ""Weather"", ""TargetWeight"",
           ""Calories"", ""DayOfTheWeek"", ""PartOfTheDay"",
           ""NotificationType"", ""UserInput""]

userinput = ['0','1']


activites_df = pd.read_csv(""E:\\MASTER\\PythonPrograms\\useractivityInt.csv"", header = None, names=columns)


#encode all strings
def encode(series): 
    #print(pd.get_dummies(series.astype(str)))
    return pd.get_dummies(series.astype(str))


train_x = pd.DataFrame(activites_df, columns = columns, dtype=float)
# train_x = activites_df
train_y = encode(activites_df.UserInput)
print(train_y)
# train_y = activites_df.iloc[:,-1]
# print(train_y)
# train_y = pd.DataFrame(userinput, dtype=float)


train_size = 0.9

train_cnt = floor(train_x.shape[0] * train_size)
#iloc[0] - first row, iloc[:0] - first column of data frame, iloc[0:n] - first n rows
x_train = train_x.iloc[0:train_cnt].values
y_train = train_y.iloc[0:train_cnt].values

x_test = train_x.iloc[train_cnt:].values
y_test = train_y.iloc[train_cnt:].values


def multilayer_perceptron(x, weights, biases, keep_prob):
    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])
    layer_1 = tf.nn.relu(layer_1)
    layer_1 = tf.nn.dropout(layer_1, keep_prob)
    out_layer = tf.matmul(layer_1, weights['out']) + biases['out']
    return out_layer


#shape[0] - Gives the number of rows in matrix.. shape[1] - numbers of columns 
n_hidden_1 = 38
n_input = train_x.shape[1]
n_classes = train_y.shape[1]
# n_classes = 2

weights = {
    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1]),tf.float32),
    'out': tf.Variable(tf.random_normal([n_hidden_1, n_classes]),tf.float32)
}

biases = {
    'b1': tf.Variable(tf.random_normal([n_hidden_1]),tf.float32),
    'out': tf.Variable(tf.random_normal([n_classes]),tf.float32)
}

#keep_prob: A scalar Tensor with the same type as x. The probability that each element is kept.
# keep_prob = tf.placeholder(""float"")
keep_prob = tf.placeholder(tf.float32)

training_epochs = 5000
display_step = 1000
batch_size = 32

x = tf.placeholder(tf.float32, [None, n_input], name='input')
y = tf.placeholder(tf.float32, [None, n_classes])

predictions = multilayer_perceptron(x, weights, biases, keep_prob)

#_y is name for output node
#If we take an input of [1, 2, 3, 4, 1, 2, 3], the softmax of that is [0.024, 0.064, 0.175, 0.475, 0.024, 0.064, 0.175]. 
# The output has most of its weight where the '4' was in the original input. 
# This is what the function is normally used for: to highlight the largest values and suppress values which are significantly below the maximum value.

pred_softmax = tf.nn.softmax(predictions, name=""y_"")

cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predictions, labels=y))

LEARNING_RATE = 0.0025

optimizer = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE).minimize(cost)


with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())

    for epoch in range(training_epochs):
        avg_cost = 0.0
        total_batch = int(len(x_train) / batch_size)
        x_batches = np.array_split(x_train, total_batch)
        y_batches = np.array_split(y_train, total_batch)
        for i in range(total_batch):
            batch_x, batch_y = x_batches[i], y_batches[i]
            _, c = sess.run([optimizer, cost], 
                            feed_dict={
                                x: batch_x, 
                                y: batch_y, 
                                keep_prob: 0.8
                            })
            avg_cost += c / total_batch
        if epoch % display_step == 0:
            print(""Epoch:"", '%04d' % (epoch+1), ""loss="", \
                ""{:.9f}"".format(avg_cost))
    print(""Optimization Finished!"")
    correct_prediction = tf.equal(tf.argmax(predictions, 1), tf.argmax(y, 1))
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, ""float""))
    print(""Accuracy:"", accuracy.eval({x: x_test, y: y_test, keep_prob: 1.0}))

    saver = tf.train.Saver()
    tf.train.write_graph(sess.graph_def, '.', 'E:\\MASTER\\PythonPrograms\\har.pbtxt')  
    saver.save(sess, save_path = ""E:\\MASTER\\PythonPrograms\\har.ckpt"")
```

****************************************************************************************************
The main parts of the code in Android Studio are those:

Definition of variables:
************************************************************************************************
```
private static final String MODEL_FILE = ""file:///android_asset/optimized_frozen_har.pb"";

    String INPUT_NODE = ""input"";
    String[] OUTPUT_NODES = {""y_""};
    String OUTPUT_NODE = ""y_"";
    //I don't know what is input size
    long[] INPUT_SIZE = {1, 15};
    int OUTPUT_SIZE = 2;

    private TensorFlowInferenceInterface inferenceInterface;
```
************************************************************************************************
Initialization and calling function in OnCreate:
************************************************************************************************
```
inferenceInterface = new TensorFlowInferenceInterface(appContext.getAssets(), MODEL_FILE);


 float[] data = {(float)1.0, (float)26.0, (float)1000.0, (float)3.0, (float)1.0,(float)0.0, (float) 0.0, (float)0.0, (float)0.0, (float)0.0, (float)85.0, (float)48.0, (float)7.0, (float)4.0, (float)2.0};
        float[] out = predictProbabilitiesFloat(data);
```
*************************************************************************************************
Function for returning result from TensorFlow:
*************************************************************************************************
```
public float[] predictProbabilitiesFloat(float[] data) {
        float[] result = new float[OUTPUT_SIZE];
        inferenceInterface.feed(INPUT_NODE, data, INPUT_SIZE);
        inferenceInterface.run(OUTPUT_NODES);
        inferenceInterface.fetch(OUTPUT_NODE, result);

        //for us it should be 0 or 1
        return result;
    }
```
************************************************************************************************

If somebody knows how to fix this problem, please help me, I have few more days to finish this as one part of my master thesis.

Thank you in advance!``"
17910,Timeline Logging Duplicates of Operations,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.6.0-rc1
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: 0.11.0
- **GCC/Compiler version (if compiling from source)**: 5.4
- **CUDA/cuDNN version**: 9.1/7.0
- **GPU model and memory**: Tesla k80 (11441MiB)
- **Exact command to reproduce**: python cifar10_train.py


### Describe the problem
I used timeline to profile the time taken by each operation of the standard cifar10 model available in tensorflow/models repo. After looking at the logfile, it looks like logs of some of the operations are duplicated i.e. it looks like some of the operations in the graph are ran multiple times over the single run of the complete graph. For example, Operation ""gradients/conv2/Conv2D_grad/Conv2DBackpropFilter"" (link to logfile : https://gist.github.com/xilenteyex/d54305e0448e1aa3d878872c45b8ed3a#file-timeline-1-json-L2270) is logged multiple times. Is this some sort of bug or am I missing something? 

Thanks a lot for looking into this issue!  


### Source code / logs
cifar10 example : https://github.com/tensorflow/models/tree/master/tutorials/image/cifar10
here is a the link to my modified version of cifar10_train.py in which I added logging : 
https://gist.github.com/xilenteyex/b6fab3a5abdb65bf674aa7d0a4ec4b5c
one of the sample log files is : https://gist.github.com/xilenteyex/d54305e0448e1aa3d878872c45b8ed3a

"
17909,Test cases fail on Nvidia Jetson TX2 for Tensorflow v1.4,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04 LTS
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: v1.4.0-0-gd752244
- **Python version**: Python 2.7.12
- **Bazel version (if compiling from source)**: 0.11.1
- **GCC/Compiler version (if compiling from source)**: 5.4.0
- **CUDA/cuDNN version**: V8.0.72/6.0.21
- **GPU model and memory**: NVIDIA Pascal GPU/8GB 128-bit LPDDR4
- **Exact command to reproduce**: 
bazel test --build_tests_only -c opt --local_resources 2048,1.0,2.0 --verbose_failures --config=cuda --test_verbose_timeout_warnings //tensorflow/python/...

configuration output ("".tf_configure.bazelrc"" file):

build --action_env PYTHON_BIN_PATH=""/usr/bin/python""
build --action_env PYTHON_LIB_PATH=""/usr/local/lib/python2.7/dist-packages""
build --define PYTHON_BIN_PATH=""/usr/bin/python""
build --define PYTHON_LIB_PATH=""/usr/local/lib/python2.7/dist-packages""
build --force_python=py2
build --host_force_python=py2
build --python2_path=""/usr/bin/python""
test --force_python=py2
test --host_force_python=py2
test --define PYTHON_BIN_PATH=""/usr/bin/python""
test --define PYTHON_LIB_PATH=""/usr/local/lib/python2.7/dist-packages""
run --define PYTHON_BIN_PATH=""/usr/bin/python""
run --define PYTHON_LIB_PATH=""/usr/local/lib/python2.7/dist-packages""
build --define with_jemalloc=true
build:opt --cxxopt=-march=native --copt=-march=native
build --action_env TF_NEED_CUDA=""1""
build --action_env TF_NEED_OPENCL=""0""
build --action_env TF_CUDA_CLANG=""0""
build --action_env CUDA_TOOLKIT_PATH=""/usr/local/cuda""
build --action_env TF_CUDA_VERSION=""8.0""
build --action_env GCC_HOST_COMPILER_PATH=""/usr/bin/gcc""
build --action_env TF_CUDNN_VERSION=""""
build --action_env CUDNN_INSTALL_PATH=""/usr/lib/aarch64-linux-gnu""
build --action_env TF_CUDA_COMPUTE_CAPABILITIES=""6.2""

### Describe the problem
We build Tensorflow v1.4 and install it in a Nvidia Jetson TX2. The device is equipped with ARM Cortex-A57 quad-core, Nvidia Denver 2 dual-core and 256-core Pascal GPU. Then we run the unit test cases using the above command. 26 out of 456 tensorflow test cases fail on this platform.

The failing tests are shown below. Detailed logs can be found in the attachment.

kernel_tests:string_to_hash_bucket_op_test
kernel_tests:sparse_matmul_op_test
kernel_tests:spacetobatch_op_test
kernel_tests:self_adjoint_eig_op_test: timeout
kernel_tests:lookup_ops_test
kernel_tests:large_concat_op_test
kernel_tests:large_concat_op_test
kernel_tests:depthtospace_op_test: timeout
kernel_tests:denormal_test
kernel_tests:conv_ops_test
kernel_tests:cast_op_test
eager:tensor_test
debug:tensor_format_test
debug:session_debug_grpc_test
debug:dist_session_debug_grpc_test
debug:curses_ui_test
debug:analyzer_cli_test
python:special_math_ops_test
python:session_test
python:session_list_devices_test
python:session_clusterspec_prop_test
python:saver_large_partitioned_variable_test
python:nn_fused_batchnorm_test
python:item_test
python:image_grad_test
python:framework_importer_test



### Source code / logs
See attached:

[fail.zip](https://github.com/tensorflow/tensorflow/files/1835427/fail.zip)
"
17908,contrib.nccl.broadcast raises UnimplementedError,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Docker image tensorflow/tensorflow:nightly-devel-gpu
- **TensorFlow version (use command below)**: nightly (also 1.7rc1)
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: NA
- **GCC/Compiler version (if compiling from source)**: NA
- **CUDA/cuDNN version**: 7.0.5
- **GPU model and memory**: NA
- **Exact command to reproduce**:

Copying repro from https://github.com/tensorflow/tensorflow/issues/15425#issuecomment-361835192:

```
import tensorflow as tf
import tensorflow.contrib.nccl as nccl

if __name__ == '__main__':
    devices = ['/gpu:0', '/gpu:0']
    with tf.device(devices[0]):
        data0 = tf.constant([1.1, 2.2, 3.3, 4.4])
        received_tensor = nccl.broadcast(data0)
    received_tensors = []
    for device in devices[1:]:
        with tf.device(device):
            received_tensors.append(tf.identity(received_tensor))
    sess = tf.Session()
    sess.run(received_tensors)
```

### Describe the problem

```
Traceback (most recent call last):
  File ""<stdin>"", line 11, in <module>
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 906, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1141, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1322, in _do_run
    run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1341, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.UnimplementedError: This op should be replaced during graph optimization.
	 [[Node: NcclBroadcast = NcclBroadcast[T=DT_FLOAT, shape=[4], _device=""/job:localhost/replica:0/task:0/device:GPU:0""](Const)]]

Caused by op u'NcclBroadcast', defined at:
  File ""<stdin>"", line 5, in <module>
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/nccl/python/ops/nccl_ops.py"", line 187, in broadcast
    return gen_nccl_ops.nccl_broadcast(input=tensor, shape=tensor.shape)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/nccl/ops/gen_nccl_ops.py"", line 132, in nccl_broadcast
    ""NcclBroadcast"", input=input, shape=shape, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 3305, in create_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1669, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

UnimplementedError (see above for traceback): This op should be replaced during graph optimization.
	 [[Node: NcclBroadcast = NcclBroadcast[T=DT_FLOAT, shape=[4], _device=""/job:localhost/replica:0/task:0/device:GPU:0""](Const)]]
```"
17907,Error with GDR,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Red hat
- **TensorFlow installed from (source or binary)**:
source (1.6)
- **TensorFlow version (use command below)**:
1.6
- **Python version**: 
2.7
- **Bazel version (if compiling from source)**:
0.11
- **GCC/Compiler version (if compiling from source)**:
4.85
- **CUDA/cuDNN version**:
9/7
- **GPU model and memory**:
P100
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

While building from source, I got the following error:
                                                                             ^
ERROR: /gpfshome01/u/amalik/Tensorflow/tensorflow/tensorflow/contrib/gdr/BUILD:52:1: C++ compilation of rule '//tensorflow/contrib/gdr:gdr_memory_manager' failed (Exit 1)
tensorflow/contrib/gdr/gdr_memory_manager.cc:28:27: fatal error: rdma/rdma_cma.h: No such file or directory
 #include <rdma/rdma_cma.h>
                           ^
compilation terminated.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 556.299s, Critical Path: 183.28s
FAILED: Build did NOT complete successfully

-----
I check on google but could not find any information. 


### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
17905,GPU sits idle for increasing time between consecutive training runs,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 Version 10.0.16299 
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.5.0
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: not sure (is this important here?)
- **GCC/Compiler version (if compiling from source)**: not sure (is this important here?)
- **CUDA/cuDNN version**: not sure (is this important here?)
- **GPU model and memory**: NVIDIA Quadro P5000 16GB
- **Exact command to reproduce**: Not exactly an ""exact command"", but what I'm trying to do is perform CNN training runs consecutively without the GPU stalling between subsequent runs. 

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I'm using an evolutionary algorithm to optimize the hyperparameters of a CNN. However, over time, the GPU ""waits"" for greater and greater times between training cycles (afterburner visualization):

![image](https://user-images.githubusercontent.com/37384864/37736912-93ab0f72-2d28-11e8-837b-19c4da783251.png)

I assume this is a memory issue in a similar vein to https://github.com/tensorflow/tensorflow/issues/17048 and http://forums.fast.ai/t/tip-clear-tensorflow-gpu-memory/1979, however, the fixes mentioned there are not working. 

Any ideas of a workaround? The second link above uses Keras to reset GPU memory after each run, and have tried this, but it has not solved the problem (it may have somewhat shortened the lag between training runs, but not enough to constitute a fix). 

What do you suppose is going on here? I.e. what may be the source of the problem, and resources that could help me address it?


### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
(I'm not sure source code will be helpful in this general issue; let me know if you'd like to see my code)."
17902,Allocating reusable memory in Tensorflow custom operator,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 
MaxOS 10.13 and Linux version 2.6.32-696.3.2.el6.x86_64
- **TensorFlow installed from (source or binary)**: 
source
- **TensorFlow version (use command below)**: 
1.5
- **Python version**: 
2.7
- **Bazel version (if compiling from source)**:  
0.11.0
- **GCC/Compiler version (if compiling from source)**: 
gcc 4.4.7
- **CUDA/cuDNN version**: 
8.0/5.1
- **GPU model and memory**: 
Tesla K40M


### Describe the problem
Hi, I'm having a memory related question when defining a Tensorflow custom operator with cuBLAS/C++.

I defined a custom operator which needs to be called multiple times during training, computed with a BLAS level 3 algorithm.
My algorithm (as well as many other BLAS3 algorithms) requires a 'workspace' memory to exploit the hardware efficiently. However, I cannot seem to find a way to allocate such memory and keep it throughout the training process. Instead, I have to allocate a new chunk of workspace memory and free it during each call to my operator. 

I've also tried to define a workspace variable in Tensorflow and feed it to the operator as an input. But I found that TF treats it as a const pointer and does not allow me to write to it.

So I am wondering if there is an efficient way to allocate reusable GPU memory for the operator at the beginning, and keep it throughout the training process. If there is not, would it be better to include such features in the future versions so that many well-developed linear algebra algorithms could avoid such memory allocating issue."
17901,TypeError: build() got an unexpected keyword argument 'num_workers',"I am getting this error while training 
```
python3 train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/ssd_mobilenet_v1_coco.config
/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Traceback (most recent call last):
  File ""train.py"", line 169, in <module>
    tf.app.run()
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""train.py"", line 165, in main
    worker_job_name, is_chief, FLAGS.train_dir)
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/object_detection-0.1-py3.6.egg/object_detection/trainer.py"", line 235, in train
    train_config.prefetch_queue_capacity, data_augmentation_options)
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/object_detection-0.1-py3.6.egg/object_detection/trainer.py"", line 59, in create_input_queue
    tensor_dict = create_tensor_dict_fn()
  File ""train.py"", line 122, in get_next
    worker_index=FLAGS.task)).get_next()
TypeError: build() got an unexpected keyword argument 'num_workers'

```"
17897,importing and running frozen graph from old version TF produces empty output.,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.06
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.6
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: 0.11.1
- **GCC/Compiler version (if compiling from source)**: 5.4
- **CUDA/cuDNN version**: 9.0 / 7
- **GPU model and memory**: GTX 1080 Ti
- **Exact command to reproduce**: 

I have a exported graph file in tensorflow 1.3 version with ubuntu 14.04 (CUDA 7.5 / cudnn 6), and it is working well under the same system so far. 
The graph was frozen and I cleared device names when exported it, so it can run both on cpu/gpu mode in my previous machine ubuntu 14.04.

The problem is when I try to run the same graph file in new machine (ubuntu 16.04, tensorflow 1.6, CUDA 9, cudnn 7), the output is just empty.
There were no problem of importing the graph file and no error messages when running it. 
Also the output was produced and shape is what expected except the content is empty.
My graph takes an image as input and produce an image as output. And when imported and run the graph in 16.04, the result is just black image.

I also opened the graph using tensorflow/python/tools/import_pb_to_tensorboard.py, and tensorboard visualized the right network I designed. 

Also tested with tensorflow version 1.5, 1.4 but the result was same.

Any solution for this problem?
"
17895,Failed compilation of build_all_android.sh on Ubuntu 17,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 17
- **TensorFlow installed from (source or binary)**:
Source
- **TensorFlow version (use command below)**:
Master
- **Python version**: 
2.7
- **Bazel version (if compiling from source)**:
0.10
- **GCC/Compiler version (if compiling from source)**:
4.9
- **CUDA/cuDNN version**:
No
- **GPU model and memory**:
No
- **Exact command to reproduce**:
./tensorflow/contrib/makefile/samples/build_and_run_inception_hexagon.sh

### Describe the problem
1. NDK version 16
2.after build_all_android.sh download successfully  dependencies it start  building protocol buffer from sources.
3.Compilation error:
### Source code / logs
```
libtool: compile:  aarch64-linux-android-g++ --sysroot /home//Android/Sdk/ndk-bundle/platforms/android-27/arch-arm64 -std=c++11 -DHAVE_CONFIG_H -I. -I.. -Wall -Wno-sign-compare -frtti -fexceptions -I/home/dnozik/Android/Sdk/ndk-bundle/sources/android/support/include -I/home/dnozik/Android/Sdk/ndk-bundle/sources/cxx-stl/gnu-libstdc++/4.9/include -I/home/dnozik/Android/Sdk/ndk-bundle/sources/cxx-stl/gnu-libstdc++/4.9/libs/arm64-v8a/include -MT google/protobuf/stubs/atomicops_internals_x86_gcc.lo -MD -MP -MF google/protobuf/stubs/.deps/atomicops_internals_x86_gcc.Tpo -c google/protobuf/stubs/atomicops_internals_x86_gcc.cc -o google/protobuf/stubs/atomicops_internals_x86_gcc.o
In file included from google/protobuf/stubs/atomicops_internals_x86_gcc.cc:34:0:
/home//Android/Sdk/ndk-bundle/sources/cxx-stl/gnu-libstdc++/4.9/include/cstring:42:20: fatal error: string.h: No such file or directory
 #include <string.h>
                    ^
compilation terminated.
Makefile:4123: recipe for target 'google/protobuf/stubs/atomicops_internals_x86_gcc.lo' failed
make[3]: *** [google/protobuf/stubs/atomicops_internals_x86_gcc.lo] Error 1
make[3]: Leaving directory '/home//Code/Tensorflow_Hexagon/tensorflow-master/tensorflow/contrib/makefile/downloads/protobuf/src'
Makefile:2109: recipe for target 'all' failed

```

Thanks for help"
17894,onv1d,
17892,Inconsistency in the accepted shape/data_format of Input Tensor to Conv2D in documentation.,"### Problem
The Tensorflow Layers Guide at https://www.tensorflow.org/tutorials/layers specifies:

> The methods in the layers module for creating convolutional and pooling layers for two-dimensional image data expect input tensors to have a shape of [batch_size, image_width, image_height, channels]

While, the inline documentation specified for conv2D (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/layers/convolutional.py#L444) mentions the following valid data_formats:

> data_format: A string, one of `channels_last` (default) or `channels_first`.
      The ordering of the dimensions in the inputs.
      `channels_last` corresponds to inputs with shape
      `(batch, height, width, channels)` while `channels_first` corresponds to
      inputs with shape `(batch, channels, height, width)`

Moreover, nn.bias_add, avg_pool2d (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/layers.py#L99) etc. also accept [...,height, width...] but using different strings/methodology.

> inputs: A 4-D tensor of shape `[batch_size, height, width, channels]` if
      `data_format` is `NHWC`, and `[batch_size, channels, height, width]` if
      `data_format` is `NCHW`.

Thus; shouldn't https://www.tensorflow.org/tutorials/layers be updated and the valid data_format values for Convolutional Layers be changed?"
17890,Does tf.slim out of maintenance ?,"I didn't find any tf-slim API document at www.tensorflow.org. In the meantime, TF-slim seems not user-friendly. 

I just wondering does tf.slim is of out of maintenance? "
17888,tf.nn.softmax_cross_entropy_with_logits_v2 loss function so big,"### Describe the problem
I am trying to build up a binary image classifcation project (2 classes are balanced) . There are 2 nodes in output layer. However, my loss function is starting from a high point(3000). Is my loss function okay? Should I change my loss function ? I want to use a metric similar to Sklearn's log-loss. At the end of 1st epoch, it reaches to 80% accuracy and after 10 epochs and its accuracy becomes 82 %. During 10 epochs, it decreases from 3000 to 20. The graph of _my loss function_ is as following(1 epoch = 175 steps) .
![loss](https://user-images.githubusercontent.com/33747602/37697942-0eb62702-2cf1-11e8-8ebe-cfdac4d34750.png)

The graph of _accuracy_ for 10 epochs is below:
![acc](https://user-images.githubusercontent.com/33747602/37697954-28500084-2cf1-11e8-93c6-3f514531a8f8.png)

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Windows 10 Home
- **TensorFlow installed from (source or binary)**: pip
- **TensorFlow version (use command below)**:1.6.0
- **Python version**: 3.6.0(no anaconda) 
- **CUDA/cuDNN version**:9.0 - 7.0
- **GPU model and memory**:GTX 1050
- **Bazel Version**:N/A

### Source code / logs
cross_entropy=tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_true,logits=y_pred ))
"
17887,How does the line of code ensure that total_loss are computed after finishing update_ops?,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: ('v1.7.0-rc0-11-g8fded78', '1.7.0-rc1') 
- **Python version**: Python 2.7.12
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

Hi, there may be a bug in create_train_op().

In the newest tensorflow code, the line (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/training/python/training/training.py#L428) intends to make sure that total_loss is computed after finishing update_ops.

I think it wants to make sure that the total_loss is computed with up-to-date values of variables after update_ops.

However, my question is that the total_loss is defined elsewhere. There is just a reference to total_loss, which should not make the control_dependencies effective. So how does it work? **Is it possible the total_loss is computed with stale values of variables before update_ops?**

Thank you very much:-).
"
17886,Data on GPU not garbage collected,"### System information
- No custom code written
- Linux Ubuntu 16.04)
- from source
- TF 1.6
- Python 2.7

I've also posted the question on stack overflow (https://stackoverflow.com/questions/49399495/data-on-gpu-not-garbage-collected). However this could potentially be a bug so I decided to post an issue anyway.

For our current implementation, the return value of a sess.run() will be stored in a dictionary. We do that to implement statefulness of RNN.

However, it turns out that storing data that way prevents tensorflow from garbage-collecting the data allocated on GPU. GPU memory usage simply keeps growing and it eventually blows up.

The return value from a sess.run() should be an numpy.ndarray as far as I'm concerned. And the data of an numpy.ndarray should live on good old CPU, shouldn't it?

Then why would storing the return value prevent GC? I don't think this is a reference counting problem.

Our current theory is that the returned numpy.ndarray actually has some reference to the GPU memory. Hope someone could verify/debunk this.

We actually tried commenting out the data storing part. Then the GPU memory becomes constant.

Thanks!!!"
17884,"""dangling"" iterator after freeze model","I've using tf.data.Iterator to feed in data (as suggested?)
However, when I freeze my model using tf.graph_util.convert_variables_to_constants, all the prerequisite nodes which constructs the iterator are lost.
Is this a feature or a bug?
If it's a feature, how to utilize the iterator again or what's the point?

The following code snippet shows the ""problem""

PS: I am using tf1.4-gpu installed installed on win7 using PIP 
```python
import tensorflow as tf
import numpy as np
# build graph
g = tf.Graph()
with g.as_default():
    with tf.variable_scope(""data_set""):
        # one x-y pair for single evaluation
        x = tf.placeholder(
            dtype=tf.float32, shape=(None, None, 1), name='inputs')
        y = tf.placeholder(
            dtype=tf.float32, shape=(None, None, 1), name='target')
        eval_set = tf.data.Dataset()\
            .from_tensors((x, y))
        iterator = tf.data.Iterator.from_structure(eval_set.output_types,
                                                   output_shapes=eval_set.output_shapes)
        eval_init_op = iterator.make_initializer(eval_set)
        # some other dataset for training
        # train_set = tf.data.Dataset()......
        ##training_init_op = iterator.make_initializer(train_set)
        x_in, y_in = iterator.get_next()
    with tf.variable_scope(""network""):
        var = tf.Variable(initial_value=5.0, dtype=tf.float32)
        l0 = var * tf.reduce_sum(x_in)
        l1 = tf.reduce_sum(y_in)
        with tf.variable_scope(""output""):
            out = l1 - l0
        variable_init_op = tf.initialize_all_variables()

# some eval step
'''
with tf.Session(graph=g) as sess:
    sess.run(variable_init_op)
    sess.run(eval_init_op, feed_dict={x: np.ones(
        (2, 2, 1), dtype=np.float32), y: np.ones((3, 3, 1), dtype=np.float32)})
    result = sess.run(out)
    print(""result: {}"".format(result))
'''

# freeze the graph
with tf.Session(graph=g) as sess:
    sess.run(variable_init_op)
    names = [n.name for n in g.as_graph_def().node]
    print(""oroiginal graph has {} nodes"".format(len(g.as_graph_def().node)))
    print([n.name for n in g.as_graph_def().node])
    '''
    ['data_set/inputs', 'data_set/target', 'data_set/Iterator', 'data_set/TensorDataset', 'data_set/make_initializer', 'data_set/IteratorGetNext', 'network/Variable/initial_value', 'network/Variable', 'network/Variable/Assign', 'network/Variable/read', 'network/Const', 'network/Sum', 'network/mul', 'network/Const_1', 'network/Sum_1', 'network/output/sub', 'network/init']
    '''
    frozen_graph = tf.graph_util.convert_variables_to_constants(
        sess, g.as_graph_def(), ['network/output/sub'])
    print(""new graph nodes: {}"".format(len(frozen_graph.node)))
    print([n.name for n in frozen_graph.node])
    '''
    ['data_set/Iterator', 'data_set/IteratorGetNext', 'network/Variable', 'network/Variable/read', 'network/Const', 'network/Sum', 'network/mul', 'network/Const_1', 'network/Sum_1', 'network/output/sub']
    '''
    ```"
17883,Upgrade gRPC commit in TensorFlow,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: s390x Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: v1.4.1
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**: 0.7.0
- **GCC/Compiler version (if compiling from source)**: 5.4.0
- **CUDA/cuDNN version**: NA
- **GPU model and memory**: NA
- **Exact command to reproduce**: -

### Describe the problem
There was a recent [commit ](https://github.com/grpc/grpc/commit/bce37d2785d508983f9d0501f6d711ef55ffc124) in gRPC added via [PR](https://github.com/grpc/grpc/pull/14464) to fix issues related to wrong address length calculation on big endian systems. This helps in resolving multiple test failures on big endian systems.

Will it be possible to pick this or higher commit of gRPC in TensorFlow?

"
17882,pip install TensorFlow wheel fails due to BoringSSL,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: s390x Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: v1.6.0
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**: 0.7.0
- **GCC/Compiler version (if compiling from source)**: 5.4.0
- **CUDA/cuDNN version**: NA
- **GPU model and memory**: NA
- **Exact command to reproduce**: pip install tensorflow-1.6.0-cp27-cp27mu-linux_s390x.whl

### Describe the problem
TensorFlow v1.6.0 wheel installation fails on s390x since it installs `grpcio` which fails due to BoringSSL. 
@gunan, this is similar to earlier issues related to BoringSSL on s390x. 

### Source code / logs
``` 
sudo pip install /tmp/tensorflow_wheel/tensorflow-1.6.0-cp27-cp27mu-linux_s390x.whl
.
.
.
  Running setup.py install for gast ... done
  Running setup.py install for termcolor ... done
  Running setup.py install for absl-py ... done
  Running setup.py install for grpcio ... error
.
.
.
Werror=format-security -fPIC -DOPENSSL_NO_ASM=1 -D_WIN32_WINNT=1536 -DGPR_BACKWARDS_COMPATIBILITY_MODE=1 -DHAVE_CONFIG_H=1 -DGRPC_ENABLE_FORK_SUPPORT=1 -DPyMODINIT_FUNC=__attribute__((visibility (""default""))) void -DGRPC_POSIX_FORK_ALLOW_PTHREAD_ATFORK=1 -Isrc/python/grpcio -Iinclude -I. -Ithird_party/boringssl/include -Ithird_party/zlib -Ithird_party/cares -Ithird_party/cares/cares -Ithird_party/cares/config_linux -I/usr/include/python2.7 -c src/core/lib/security/credentials/google_default/google_default_credentials.cc -o python_build/temp.linux-s390x-2.7/src/core/lib/security/credentials/google_default/google_default_credentials.o -std=c++11 -std=gnu99 -fvisibility=hidden -fno-wrapv -fno-exceptions -pthread
    cc1plus: warning: command line option '-Wstrict-prototypes' is valid for C/ObjC but not for C++
    cc1plus: warning: command line option '-std=gnu99' is valid for C/ObjC but not for C++
    In file included from third_party/boringssl/include/openssl/rsa.h:60:0,
                     from ./src/core/lib/security/credentials/jwt/json_token.h:23,
                     from ./src/core/lib/security/credentials/jwt/jwt_credentials.h:23,
                     from src/core/lib/security/credentials/google_default/google_default_credentials.cc:34:
    third_party/boringssl/include/openssl/base.h:114:2: error: #error ""Unknown target CPU""
     #error ""Unknown target CPU""
      ^
```"
17881,TensortRT Invalid data type: 'int32' when converting TF Object Detection graph,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes see gist (change line 6 to object detection frozen inference graph path): https://gist.github.com/louisquinn/0c6729a32e87e899ece317de84d02acc
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 16.04
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: 1.7
- **Python version**: 3.5
- **Bazel version (if compiling from source)**: 0.11.1
- **GCC/Compiler version (if compiling from source)**: 5.4.0
- **CUDA/cuDNN version**: CUDA 9.0 / cuDNN 7.1
- **GPU model and memory**: GTX 1080 8GB
- **Exact command to reproduce**: See gist (change line 6 to object detection frozen inference graph path): https://gist.github.com/louisquinn/0c6729a32e87e899ece317de84d02acc

### Describe the problem
Getting the following error when calling `trt.create_inference_graph` (see line 18 of gist):
`tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2503] Non-OK-status: ConvertDType(tf_dtype, &dtype) status: Invalid argument: Unsupported data type int32`

Is int32 not supported by TensorRT, not yet implemented in the Tensorflow wrap, or am I doing something incorrect? This happens with all pre-trained TF Object Detection models. "
17880,How to force Tensorflow app to use Android framework's NNAPI?,"### Describe the problem
I am using x86 (intel platform) android device to check if tensorflow apk is calling Android's NNAPI. It seems its not calling the APIs.
How can i force tensorflow apk to forcefully use Android framework's NNAPI?

Android studio project location: <src>/tensorflow/contrib/lite/java/demo/app/
Android version: 8.1"
17879,r1.3 freeze_graph.py issue,"1.
python freeze_graph.py \
--input_graph=./graph/model.graph.pbtxt \
--input_checkpoint=**./checkpoint/model.ckpt-100** \
--output_graph=./graph/model.graph.pb \
--output_node_names=out

2.
python freeze_graph.py \
--input_graph=./graph/model.graph.pbtxt \
--input_checkpoint=**./checkpoint//model.ckpt-100** \
--output_graph=./graph/model.graph.pb \
--output_node_names=out

Here, it success when I using No.1, but No2., I get the error:""Input checkpoint './checkpoint//model.ckpt-100' doesn't exist!""
The different is the path with ""/"" or ""//"", I don't know if it is a bug in r1.3.
please~~~"
17877,tf.manip.roll silently ignores negative axes,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Google Colab
- **TensorFlow installed from (source or binary)**: unknown
- **TensorFlow version (use command below)**: 1.6.0
- **Python version**: 3.6.3
- **Bazel version (if compiling from source)**: NA
- **GCC/Compiler version (if compiling from source)**: NA
- **CUDA/cuDNN version**: NA
- **GPU model and memory**: NA
- **Exact command to reproduce**:

```
import tensorflow as tf
tf.InteractiveSession()
print(tf.manip.roll(tf.range(5), -1, axis=0).eval())
# [1 2 3 4 0]
print(tf.manip.roll(tf.range(5), -1, axis=-1).eval())
# [0 1 2 3 4]
```

### Describe the problem

`axis=-1` and `axis=0` should be equivalent, if `tf.manip.roll()` works like `numpy.roll()` and other TensorFlow/NumPy functions that accept negative axes. However, instead negative axes are silently ignored. At the very least, TensorFlow should have raised an informative error."
17876,Custom optimiser based on pre-trained model,"Hello. This might be a support ticket or a feature request.

I'm trying to make an optimiser based on output of a pretrained model. Running a model requires an open session in tensorflow but there is nothing like it inside OpKernel where the existing model should be called. 

How to correctly call a model inside an opkernel? Is it possible to access already compiled functionality  of this kind? 

This feature would be very handy when it comes to complex loss functions. I'm able to write it on my own and wrap it in a PR when my questions are resolved. "
17873,I am unable to install the latest tensorflow version from pip. It always show me the following error.. ,"Please go to Stack Overflow for help and support:
tensorflow-1.0.0-cp35-cp35m-win_amd64.whl is not a supported wheel on this platform.

I am running python3.6 64 bit on windows 10 "
17869,Unable to run inference on mobilenet,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: 1.4.1
- **Python version**: 3.5.4
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

### Describe the problem
I want to run mobilenet inference on one image. I have converted the JPEG image to binary. The binary file size is 602112 bytes [3 x 224 x 224 x sizeof(float32)]

I downloaded the mobilenet model from: 
https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.md

And tried running inference on it as follows:

# init
protobuf = 'mobilenet_v1_0.25_128_frozen.pb'
img_fname = 'ILSVRC2012_val_00000001.bin'
iname = 'prefix/input:0'
oname = 'prefix/MobilenetV1/Predictions/Softmax:0'

# read graph definition
gfile = tf.gfile.GFile(protobuf, ""rb"")
graph_def = tf.GraphDef()
graph_def.ParseFromString(gfile.read())
_ = tf.import_graph_def(graph_def, name='prefix')

# load image
image_data = tf.gfile.GFile(img_fname,'rb').read()

# run inference
with tf.Session() as sess:
 output_tensor = sess.graph.get_tensor_by_name(oname)
 output = sess.run(output_tensor, {iname:image_data})

 data_fname, _ = oname.split(':0')
 data_fname = data_fname.replace(""/"", ""."") + "".bin""
 output.tofile(data_fname)
 print(data_fname, 'saved')

It doesn't seem to work. It's not crashing but printing a lot of numbers like:
\x86Bo\x13QB\x05\xf6\x89B\xeb\x01qB\x9bb\x80B\xe7\xa7VBA\xb3\x80B\xe3c\x85Bs\x03kB\xd7\xe5\x7fBs;{B\x8be\x8eB[+jB/\x08{B\xff6RB\x87\xe3&B\x15\x1f\xb3A\xc7\xfdQB\xf3\xe6UB\x0b\xa8\nB\xab\xc5GB\xef\x12JB'"
17868,Test cases fail on AWS DeepLens device for Tensorflow v1.4,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04.3 LTS
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: v1.4.0-0-gd752244
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**: 0.9.0
- **GCC/Compiler version (if compiling from source)**: 5.4.0
- **CUDA/cuDNN version**: NA
- **GPU model and memory**: NA
- **Exact command to reproduce**:
TEST_TMPDIR=$BAZEL_OUTPUT_BASE bazel test --build_tests_only --config=mkl -c opt --verbose_failures --incompatible_load_argument_is_label=false --test_verbose_timeout_warnings //tensorflow/python/...

configuration output ("".tf_configure.bazelrc"" file):

build --action_env PYTHON_BIN_PATH=""/usr/bin/python""
build --action_env PYTHON_LIB_PATH=""/usr/local/lib/python2.7/dist-packages""
build --define PYTHON_BIN_PATH=""/usr/bin/python""
build --define PYTHON_LIB_PATH=""/usr/local/lib/python2.7/dist-packages""
build --force_python=py2
build --host_force_python=py2
build --python_path=""/usr/bin/python""
test --force_python=py2
test --host_force_python=py2
test --define PYTHON_BIN_PATH=""/usr/bin/python""
test --define PYTHON_LIB_PATH=""/usr/local/lib/python2.7/dist-packages""
run --define PYTHON_BIN_PATH=""/usr/bin/python""
run --define PYTHON_LIB_PATH=""/usr/local/lib/python2.7/dist-packages""
build --define with_jemalloc=true
build:gcp --define with_gcp_support=true
build:hdfs --define with_hdfs_support=true
build:s3 --define with_s3_support=true
build:xla --define with_xla_support=true
build:gdr --define with_gdr_support=true
build:verbs --define with_verbs_support=true
build --action_env TF_NEED_OPENCL=""0""
build --action_env TF_NEED_CUDA=""0""
build --action_env TF_MKL_ROOT=$BUILD_DIR/tmp/intel/mklml_lnx_2018.0.20170425""
build --action_env TF_DOWNLOAD_MK=0
build:opt --cxxopt=-march=native --copt=-march=native
build:mkl --define using_mkl=true
build:mkl -c opt
build:mkl --copt=""-DEIGEN_USE_VML""
build:monolithic --define framework_shared_object=false
build --define framework_shared_object=true

MKL related configuration:

build --action_env TF_MKL_ROOT=$BUILD_DIR/tmp/intel/mklml_lnx_2018.0.20170425""
build --action_env TF_DOWNLOAD_MKL=0

### Describe the problem
We build Tensorflow v1.4 and install it in a AWS DeepLens device. The device is equipped with a Intel Atom Processor E3930. Then we run the unit test cases using the above command. 19 out of 456 tensorflow test cases fail on this platform. 

The errors of each failing tests are shown below. Detailed logs can be found in the attachment.

kernel_tests:conv_ops_test: assert error: numbers match but shapes of the result do not match.
nn_fused_batchnorm_test.py: AssertionError: 0.1277604103088379 not less than 0.01
layers_normalization_test.py: assert error: numbers don't match but scaled.
checkpoint_utils_test.py: checkpoint too large: 28077 > 28000
item_test.py: AssertionError: Lists differ: ['Const', 'Const_1', 'add'] != ['Const_1', 'Const', 'add']
special_math_ops_test.py: shape mismatch for sum.
timeline_test.py: cpu usage not maximum ?
analyzer_cli_test.py: testEvalExpression
curses_ui_test.py: ui output format mismatch First differing element 2:'array([[ 1.,  1.,  1.,  1.,  1.],' 'array([[1., 1., 1., 1., 1.],'
session_debug_file_test.py: mutliple failures
session_debug_grpc_test: timeout 315 seconds
stepper_test
tensor_format_test: string mismatch
tensor_test: AssertionError: '[0 ..., 9]' not found in 'tf.Tensor([0 ... 9], shape=(10,), dtype=int32)'
feature_column_test: AssertionError: OpError not raised
model_analyzer_test:
run_metadata_test: AssertionError: u'DMT' != 'MatMul'
print_selective_registration_header_test: String mismatch
convolutional_recurrent_test: tolerance

### Source code / logs
See attached:
[fail.zip](https://github.com/tensorflow/tensorflow/files/1831319/fail.zip)
"
17867,Tensorflow Projector - nearest points in original space,"In [Tensorflow Projector](http://projector.tensorflow.org), the cosine and euclidean distance, and the ranking based on that seems to be incorrect when the number of dimensions for the points is 50 or more.  It is fine when the number of dimensions is 49 or less.  Here's some code to test

```
import numpy as np
from sklearn.metrics.pairwise import cosine_distances, euclidean_distances

npoints,ndims = 4,49
nclose = npoints-1
func = cosine_distances

np.random.seed(seed=123456)
embed = np.random.uniform(size=npoints*ndims).reshape((npoints,ndims))
labels = np.array(['pt%03d'%n for n in range(1,npoints+1)])

np.savetxt('embed-%d-%d.tsv'%(npoints,ndims), embed, delimiter='\t', fmt='%.6f')
np.savetxt('labels-%d.tsv'%(npoints), labels, fmt='%s')

dist = func(embed)
ind = np.argsort(dist)[:,1:nclose+1]

names = labels[ind]
dist = dist[np.arange(labels.shape[0])[:,None],ind]

np.concatenate((labels[:,None],
                np.dstack((names,np.around(dist,4))).reshape((dist.shape[0],-1))), axis=1)
```

The output of the above code is shown below.  For `pt001`, the closest is `pt004` with cosine distance 0.1695, etc.
```
array([['pt001', 'pt004', '0.1695', 'pt003', '0.2716', 'pt002', '0.2897'],
       ['pt002', 'pt003', '0.2345', 'pt004', '0.2365', 'pt001', '0.2897'],
       ['pt003', 'pt004', '0.2099', 'pt002', '0.2345', 'pt001', '0.2716'],
       ['pt004', 'pt001', '0.1695', 'pt003', '0.2099', 'pt002', '0.2365']],
      dtype='<U32')
```
The above code also generates files which can be uploaded to the projector website for confirmation.  The output there is:
```
Nearest points in the original space:
pt004 0.169
pt003 0.272
pt002 0.290
```
Now change ndims to 50 in the above code and re-run.  The output is
```
array([['pt001', 'pt002', '0.1675', 'pt004', '0.1968', 'pt003', '0.2571'],
       ['pt002', 'pt001', '0.1675', 'pt004', '0.2444', 'pt003', '0.246'],
       ['pt003', 'pt004', '0.1943', 'pt002', '0.246', 'pt001', '0.2571'],
       ['pt004', 'pt003', '0.1943', 'pt001', '0.1968', 'pt002', '0.2444']],
      dtype='<U32')
```
Once the new files are loaded, the output from the website is:
```
Nearest points in the original space: 
pt002 1.040
pt004 1.304
pt003 1.538
```
The website does report the number of dimensions correctly at the top (first 49 and then 50).  Also, `Spherize Data` was turned on and off that makes a very slight difference."
17861,RNN no learning when operation as node as opposed to fed as calculated values,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS Sierra 10.12.6
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.4.0-19-ga52c8d9 1.4.1
- **Python version**: 3.6.3
- **Bazel version (if compiling from source)**: na
- **GCC/Compiler version (if compiling from source)**: na
- **CUDA/cuDNN version**: na
- **GPU model and memory**: na
- **Exact command to reproduce**:

### Describe the problem
I have a RNN with variable sequence lengths. To get the last non-zero output i.e. the relevant output for each sample I have a function `last.relevant()` (see below). I define a node for this operation: `rel_output = self.last_relevant(outputs, seq_lengths)`. The odd thing is, I have to evaluate this node, save the results of it in a variable and feed it to the next operation which has a placeholder for the results of the `rel_output` node. Actually, I would expect the exactly same behaviour when I use the `rel_output` node to define a new node. But when I do, the training gets stuck after the second iteration and all gradients go to zero.

This is really hard to track as no exceptions are raised, just the training getting stuck. I spent a couple of hours finding that bug.

### Source code / logs

    def last_relevant(self, output, seq_length):
        # the RNN returns outputs for every input unit, but we are just
        # interested in the last one that is not zero
        # author: Danijar Hafner
        # (https://danijar.com/variable-sequence-lengths-in-tensorflow/)
        batch_size = tf.shape(output)[0]
        max_length = tf.shape(output)[1]
        out_size = int(output.get_shape()[2])
        index = tf.range(0, batch_size) * max_length + (seq_length - 1)
        flat = tf.reshape(output, [-1, out_size])
        relevant = tf.gather(flat, index)
        return relevant

#### Training working fine
        rel_output = self.last_relevant(outputs, seq_lengths)
        last_nonzero_output = tf.placeholder(""float"", [n_samples, self.n_hidden])
        pred = tf.nn.softmax(tf.tanh(tf.matmul(last_nonzero_output, self.weights['out']) + self.biases['out']))

        ro = session.run(rel_output, feed_dict={x: data})
        _ = session.run([optimizer], feed_dict={last_nonzero_output: ro, y: labels_oh})

#### Training getting stuck
        rel_output = self.last_relevant(outputs, seq_lengths)        
        pred = tf.nn.softmax(tf.tanh(tf.matmul(rel_output, self.weights['out']) + self.biases['out']))

       _ = session.run([optimizer], feed_dict={x: data, y: labels_oh})"
17860,Failed assert in the TF native code kills JVM,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 7, Java 1.8.0_161 x64
- **TensorFlow installed from (source or binary)**: binaries downloaded from Maven repo
- **TensorFlow version (use command below)**: both org.tensorflow:tensorflow:1.4.0 and org.tensorflow:tensorflow:1.5.0
- **Python version**: N/A
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**:

### Describe the problem

I am running some experiments calling TensorFlow from Java.
And in case my code hits some assertion in the TF native code the JVM terminates immediately.

This I believe closes the door for running TensorFlow in any kind of Java server environment.

Instead the internal assertions should be propagated to JNI layer and thrown as normal Java exceptions (`IllegalStateException`, `AssertionError` and the likes).

### Source code / logs

Here are two cases of the assertions I ran into yesterday with TF 1.4.0

```
2018-03-19 17:56:00.364932: F .\tensorflow/core/lib/core/refcount.h:82] Check failed: ref_.load() >= 1 (0 vs. 1)

2018-03-19 18:30:22.390146: F .\tensorflow/core/framework/tensor_shape.h:130] Check failed: static_cast<uint32>(dt) < 256u (374 vs. 256)
```

The errors above are reproducible more or less consistently when using the same input `Tensor<Float>` in three different `Graph`'s sequentially.
It it probably not the right way to do that. But the issue in general still stands - assertions in the native code must not kill the hosting JVM.

I've been trying to reproduce the problem in an isolated minimal test project. But hasn't been able to do that so far. I believe however that this is not strictly necessary to illustrate the core problem.
It should be possible to reproduce the JVM death by adding some ""always fail"" assertion to the TF native code."
17859,`Datasets` sometimes resamples stochastic Tensors during multiple transformations,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes, to demonstrate the bug
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Mac OS X 10.13.3
- **TensorFlow installed from (source or binary)**:
Binary
- **TensorFlow version (use command below)**:
1.5.0
- **Python version**: 
2.7

### Describe the problem
Datasets can involve stochastic transformations. Sometimes random Tensors are resampled, and sometimes they're not. It's not clear when one happens and when another happens. This is likely a subtle Datasets bug, but at a minimum is a documentation bug. This is the root cause of Issue #16606, which is fixed in the resampling code by PR #17858.

### Source code / logs
The following short snippet demonstrates that `Dataset.zip` causes the random Tensors to be resampled, while a seemingly-equivalent `map` statement does not:

```
def _test_ds_consistency(tup_ds):
  get_next = tup_ds.make_one_shot_iterator().get_next()

  with tf.Session() as sess:
    while True:
      try:
        tup = sess.run(get_next)
        assert tup[0] == tup[1]
      except tf.errors.OutOfRangeError:
        break

def _get_random_0s_and_1s(num_elements):
  const_ds = tf.data.Dataset.from_tensor_slices([0] * num_elements)
  return const_ds.map(lambda _: tf.cast(tf.random_uniform([]) * 2, dtype=tf.int32))

def doesnt_work(num_elements=10):
  rand_ds = _get_random_0s_and_1s(num_elements)
  index_ds = rand_ds.map(lambda i: tf.gather([0, 1], i))
  return tf.data.Dataset.zip((index_ds, rand_ds))

def works(num_elements=10):
  rand_ds = _get_random_0s_and_1s(num_elements)
  tup_ds = rand_ds.map(lambda i: (tf.gather([0, 1], i), i))
  return tup_ds

_test_ds_consistency(works())  # works
_test_ds_consistency(doesnt_work())  # raises assert
```
"
17856,second order differential of fused_batch_norm makes a large number of nodes.,"I found that the second order differential of tf.nn.fused_batch_norm has much larger number of nodes than that of tf.nn.batch_normalization. 

I wrote a sample program which has 7 batch normalization layers. Using tf.nn.fused_batch_norm, it has about 22,000 nodes. On the other hand, using tf.nn.batch_normalization, it has only 1700 nodes (I counted with tensorboard). Is this a reasonable behavior?

### Source Code
```
import numpy as np
import tensorflow as tf

use_fused_batch_norm = False

with tf.name_scope(""network""):
    featmap = tf.constant(np.random.rand(3,3,32,32), dtype=tf.float32)

    for i in range(7):
        with tf.name_scope(""layer{}"".format(i)):
            if use_fused_batch_norm:
                beta = tf.Variable(np.zeros(3), name=""beta"", dtype=np.float32)
                gamma = tf.Variable(np.ones(3), name=""gamma"", dtype=np.float32)
                featmap, _, _ = tf.nn.fused_batch_norm(featmap, gamma, beta, data_format=""NCHW"")

            else:
                beta = tf.Variable(np.zeros([1,3,1,1]), name=""beta"", dtype=np.float32)
                gamma = tf.Variable(np.ones([1,3,1,1]), name=""gamma"", dtype=np.float32)
                mu, sigma = tf.nn.moments(featmap, axes=[0,2,3], keep_dims=True)

                featmap = tf.nn.batch_normalization(featmap, mu, sigma, beta, gamma, variance_epsilon=1e-07)

    y = tf.reduce_mean(featmap, axis=[1,2,3])

W = tf.trainable_variables()

with tf.name_scope(""rop""):
    temporary = tf.ones_like(y)
    grad      = tf.gradients(y, W, grad_ys=temporary)
    r         = [tf.ones_like(t) for t in W]
    ggrad     = tf.gradients(grad, temporary, grad_ys=r)[0]


with tf.Session() as sess:
    summary_writer = tf.summary.FileWriter(""log"",
                                           sess.graph)

```


------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
('v1.5.0-0-g37aa430d84', '1.5.0')
- **Python version**: 
2.7.12
- **CUDA/cuDNN version**:
cuda9 / cudnn 7.0.5
- **GPU model and memory**:
GTX 1080, 8GB
- **Exact command to reproduce**:
python main.py
- **Bazel version** 
N/A"
17855,why training and validation loss are always zero during the training phase of deep neural network?,"I'm new to machine learning and I'm trying to learn more about it. I have been facing many problems doing my project as DEEP NEURAL NETWORK Classifier (classes 0,1). 
I'm using windows 8.1, 4GB ram, python 3.6.4(pip installation), tensorflow cpu version v1.4 (pip installation).
All other packages required for this code also installed through pip installation and have been imported.
During training, Train loss and validation loss are always zero. I don't know why?
If anyone know the problem, please let me know asap!! My project deadline is very near!!

Things I've tried:
1. different values for hidden_units, no. of hidden layers, batch_size, learning_rate 
2. Equally distributed my sample inputs according to the class labels. 
3. I gave the same data to LDA (Linear Discriminant Analysis) and it's able to classify at the accuracy of 99.6%
4. I gave the same data to bernoulliRBM and it classifies all samples as class '0'

# here is my CODE

    def build_neural_network(hidden_units_1=8, hidden_units_2=16):
   
        tf.reset_default_graph()
        inputs = tf.placeholder(tf.float64, shape=[None, train_x.shape[1]])
        labels = tf.placeholder(tf.float64, shape=[None, 1])
        learning_rate = tf.placeholder(tf.float64)
        is_training=tf.Variable(True,dtype=tf.bool)
        initializer = tf.contrib.layers.xavier_initializer()
        fc = tf.layers.dense(inputs, hidden_units_1, activation=None,kernel_initializer=initializer)
        fc=tf.layers.batch_normalization(fc, training=is_training)
        fc=tf.nn.relu(fc)
        fc = tf.layers.dense(fc, hidden_units_2, activation=None,kernel_initializer=initializer)
        fc=tf.layers.batch_normalization(fc, training=is_training)
        fc=tf.nn.relu(fc)
        logits = tf.layers.dense(fc, 1, activation=None)
        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=logits)
        cost = tf.reduce_mean(cross_entropy)
       
        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):
             optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)
        
        predicted = tf.nn.softmax(logits)
        correct_pred = tf.equal(tf.round(predicted), labels)
        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float64))

        export_nodes = ['inputs', 'labels', 'learning_rate','is_training', 'logits',
                    'cost', 'optimizer', 'predicted', 'accuracy']
        Graph = namedtuple('Graph', export_nodes)
        local_dict = locals()
        graph = Graph(*[local_dict[each] for each in export_nodes])
        
        return graph
   
    model = build_neural_network()

    epochs = 10
    train_collect = 10
    train_print=train_collect*2
    learning_rate_value = 0.01 
    batch_size=100
    x_collect = []
    train_loss_collect = []
    train_acc_collect = []
    valid_loss_collect = []
    valid_acc_collect = []

    saver = tf.train.Saver()
    with tf.Session() as sess:
        saver.restore(sess, ""./save.ckpt"")
        iteration=0
        for e in range(epochs):
              for batch_x,batch_y in get_batch(train_x,train_y,batch_size):
                    iteration+=1
                    feed = {model.inputs: train_x,
                                model.labels: train_y,
                                model.learning_rate: learning_rate_value,
                                model.is_training:True,
                                }
                    train_loss, _, train_acc = sess.run([model.cost, model.optimizer, model.accuracy], 
                            feed_dict=feed)
                    
                    if iteration % train_collect == 0:
                        x_collect.append(e)
                        train_loss_collect.append(train_loss)
                        train_acc_collect.append(train_acc)
                    
                        if iteration % train_print==0:
                            print(""Epoch: {}/{}"".format(e + 1, epochs),
                            ""Train Loss: {:.4f}"".format(train_loss),
                            ""Train Acc: {:.4f}"".format(train_acc))
                        
                        feed = {model.inputs: valid_x,
                                    model.labels: valid_y,
                                    model.is_training:False
                                    }
                        val_loss, val_acc = sess.run([model.cost, model.accuracy], feed_dict=feed)
                        valid_loss_collect.append(val_loss)
                        valid_acc_collect.append(val_acc)
                                       
                        if iteration % train_print==0:
                            print(""Epoch: {}/{}"".format(e + 1, epochs),
                           ""Validation Loss: {:.4f}"".format(val_loss),
                           ""Validation Acc: {:.4f}"".format(val_acc))
                

    saver.save(sess, ""./save.ckpt"")

#here is the OUTPUT of training:
      
     Epoch: 1/10 Train Loss: 0.0000 Train Acc: 0.5013
     Epoch: 1/10 Validation Loss: 0.0000 Validation Acc: 0.4949
     Epoch: 1/10 Train Loss: 0.0000 Train Acc: 0.5013
     Epoch: 1/10 Validation Loss: 0.0000 Validation Acc: 0.4949
     Epoch: 1/10 Train Loss: 0.0000 Train Acc: 0.5013
     Epoch: 1/10 Validation Loss: 0.0000 Validation Acc: 0.4949
     Epoch: 1/10 Train Loss: 0.0000 Train Acc: 0.5013
     Epoch: 1/10 Validation Loss: 0.0000 Validation Acc: 0.4949
     Epoch: 1/10 Train Loss: 0.0000 Train Acc: 0.5013
     Epoch: 1/10 Validation Loss: 0.0000 Validation Acc: 0.4949
     Epoch: 1/10 Train Loss: 0.0000 Train Acc: 0.5013
     Epoch: 1/10 Validation Loss: 0.0000 Validation Acc: 0.4949
     Epoch: 1/10 Train Loss: 0.0000 Train Acc: 0.5013
     Epoch: 1/10 Validation Loss: 0.0000 Validation Acc: 0.4949
     Epoch: 1/10 Train Loss: 0.0000 Train Acc: 0.5013
     Epoch: 1/10 Validation Loss: 0.0000 Validation Acc: 0.4949
     Epoch: 1/10 Train Loss: 0.0000 Train Acc: 0.5013
     Epoch: 1/10 Validation Loss: 0.0000 Validation Acc: 0.4949
     Epoch: 1/10 Train Loss: 0.0000 Train Acc: 0.5013
     Epoch: 1/10 Validation Loss: 0.0000 Validation Acc: 0.4949
    
     Epoch: 1/10 Train Loss: 0.0000 Train Acc: 0.5013
     Epoch: 1/10 Validation Loss: 0.0000 Validation Acc: 0.4949
     Epoch: 1/10 Train Loss: 0.0000 Train Acc: 0.5013
     Epoch: 1/10 Validation Loss: 0.0000 Validation Acc: 0.4949
     Epoch: 1/10 Train Loss: 0.0000 Train Acc: 0.5013
     Epoch: 1/10 Validation Loss: 0.0000 Validation Acc: 0.4949
     Epoch: 1/10 Train Loss: 0.0000 Train Acc: 0.5013
     Epoch: 1/10 Validation Loss: 0.0000 Validation Acc: 0.4949
     Epoch: 1/10 Train Loss: 0.0000 Train Acc: 0.5013
     Epoch: 1/10 Validation Loss: 0.0000 Validation Acc: 0.4949
     Epoch: 1/10 Train Loss: 0.0000 Train Acc: 0.5013
     Epoch: 1/10 Validation Loss: 0.0000 Validation Acc: 0.4949
     Epoch: 1/10 Train Loss: 0.0000 Train Acc: 0.5013
     Epoch: 1/10 Validation Loss: 0.0000 Validation Acc: 0.4949
     Epoch: 1/10 Train Loss: 0.0000 Train Acc: 0.5013
     Epoch: 1/10 Validation Loss: 0.0000 Validation Acc: 0.4949
     Epoch: 1/10 Train Loss: 0.0000 Train Acc: 0.5013
     Epoch: 1/10 Validation Loss: 0.0000 Validation Acc: 0.4949
     Epoch: 1/10 Train Loss: 0.0000 Train Acc: 0.5013
     Epoch: 1/10 Validation Loss: 0.0000 Validation Acc: 0.4949
     Epoch: 1/10 Train Loss: 0.0000 Train Acc: 0.5013
     Epoch: 1/10 Validation Loss: 0.0000 Validation Acc: 0.4949
     Epoch: 1/10 Train Loss: 0.0000 Train Acc: 0.5013
     Epoch: 1/10 Validation Loss: 0.0000 Validation Acc: 0.4949
     Epoch: 1/10 Train Loss: 0.0000 Train Acc: 0.5013
     Epoch: 1/10 Validation Loss: 0.0000 Validation Acc: 0.4949
     Epoch: 2/10 Train Loss: 0.0000 Train Acc: 0.5013
     Epoch: 2/10 Validation Loss: 0.0000 Validation Acc: 0.4949
     Epoch: 2/10 Train Loss: 0.0000 Train Acc: 0.5013
     Epoch: 2/10 Validation Loss: 0.0000 Validation Acc: 0.4949
     Epoch: 2/10 Train Loss: 0.0000 Train Acc: 0.5013
     Epoch: 2/10 Validation Loss: 0.0000 Validation Acc: 0.4949
     Epoch: 2/10 Train Loss: 0.0000 Train Acc: 0.5013
     Epoch: 2/10 Validation Loss: 0.0000 Validation Acc: 0.4949
     Epoch: 2/10 Train Loss: 0.0000 Train Acc: 0.5013
     Epoch: 2/10 Validation Loss: 0.0000 Validation Acc: 0.4949
     Epoch: 2/10 Train Loss: 0.0000 Train Acc: 0.5013
     Epoch: 2/10 Validation Loss: 0.0000 Validation Acc: 0.4949
     Epoch: 2/10 Train Loss: 0.0000 Train Acc: 0.5013
     Epoch: 2/10 Validation Loss: 0.0000 Validation Acc: 0.4949
     Epoch: 2/10 Train Loss: 0.0000 Train Acc: 0.5013
     ...
(I'm getting the same result as above till epoch 10/10)"
17854,tf.estimator.RunConfig return worker is not a valid task_type in the cluster_spec job,"### System information
- os/ubuntu1604/x86_64
- **Exact command to reproduce**: config = tf.estimator.RunConfig()
- docker image: tensorflow/tensorflow:1.4.0-gpu

### Describe the problem
tf.estimator.RunConfig return worker is not a valid task_type in the cluster_spec job

### Source code / logs
   os.environ['TF_CONFIG'] = json.dumps({
    ##'cluster': cluster,
    'cluster': {
        ""chief"" : chief_node,
        ""ps_hosts"": ps_hosts,
        ""worker_hosts"": worker_hosts
    },
    'task' : {
        'type' : FLAGS.job_name,
        'index': FLAGS.task_index,
    }
})
config = tf.estimator.RunConfig()

-------LOG---------
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/run_config.py"", line 464, in __init__
    self._init_distributed_setting_from_environment_var(tf_config)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/run_config.py"", line 480, in _init_distributed_setting_from_environment_var
    self._cluster_spec, task_env, TaskType.CHIEF)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/run_config.py"", line 188, in _validate_task_type_and_task_id
    'variable.' % (task_type, cluster_spec))
ValueError: worker is not a valid task_type in the cluster_spec:
ClusterSpec({'chief': ['10.0.0.5:2223'], 'ps_hosts': ['10.0.0.5:2222'], 'worker_hosts': ['10.0.0.6:2222', '10.0.0.4:2222']})
"
17853,cannot decode FixedLenFeature with decode_raw,"I try to parse data from tfrecord file with Dataset, and when I try to parse image with decode_raw, it throws an error.  I use tf1.6, the code is as following:

```
def _parse_tfrecords_func(record):
    """"""
    :param record:
    :return:
    """"""
    features = {""img"": tf.FixedLenFeature([],tf.string),
                ""label"": tf.FixedLenFeature((), tf.int64, default_value=0),
                ""width"": tf.FixedLenFeature((), tf.int64, default_value=0),
                ""height"": tf.FixedLenFeature((), tf.int64, default_value=0),
                ""channel"": tf.FixedLenFeature((), tf.int64, default_value=0)}
    parsed_features = tf.parse_single_example(record, features)
    for keys in parsed_features:
        print(keys)

    print(type(features['img']))
    print(dir(features['img']))
    img = tf.decode_raw(features['img'], tf.uint8)  # TODO: fix the error
    img_reshape = tf.reshape(img, (parsed_features['width'], parsed_features['height'], parsed_features['channel']))
    return img_reshape, parsed_features['label']

def dataset_tfrecords():
    """"""
    Dataset读tfrecords
    :return:
    """"""
    tfrecords_files = ['tfrecords_example']
    dataset = tf.data.TFRecordDataset(tfrecords_files)
    dataset = dataset.map(_parse_tfrecords_func)
    dataset.repeat()

    iterator = dataset.make_initializable_iterator()
    next_elem = iterator.get_next()
    sess = tf.Session()
    sess.run(iterator.initializer)

    for i in range(1):
        next_elem = sess.run(next_elem)
        print(type(next_elem))
```
label, width, height, channel are parsed succeed, however, decode image with decode_raw causes an error, error information is as following:

```
Traceback (most recent call last):
  File ""D:\Anaconda\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 510, in _apply_op_helper
    preferred_dtype=default_dtype)
  File ""D:\Anaconda\lib\site-packages\tensorflow\python\framework\ops.py"", line 1036, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""D:\Anaconda\lib\site-packages\tensorflow\python\framework\constant_op.py"", line 235, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""D:\Anaconda\lib\site-packages\tensorflow\python\framework\constant_op.py"", line 214, in constant
    value, dtype=dtype, shape=shape, verify_shape=verify_shape))
  File ""D:\Anaconda\lib\site-packages\tensorflow\python\framework\tensor_util.py"", line 433, in make_tensor_proto
img
channel
height
label
width
<class 'tensorflow.python.ops.parsing_ops.FixedLenFeature'>
['__add__', '__class__', '__contains__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__gt__', '__hash__', '__init__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmul__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '_asdict', '_fields', '_make', '_replace', '_source', '_tf_api_names', 'count', 'default_value', 'dtype', 'index', 'shape']
    _AssertCompatible(values, dtype)
  File ""D:\Anaconda\lib\site-packages\tensorflow\python\framework\tensor_util.py"", line 344, in _AssertCompatible
    (dtype.name, repr(mismatch), type(mismatch).__name__))
TypeError: Expected string, got tf.string of type 'DType' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""test_dataset.py"", line 99, in <module>
    dataset_tfrecords()
  File ""test_dataset.py"", line 75, in dataset_tfrecords
    dataset = dataset.map(_parse_tfrecords_func)
  File ""D:\Anaconda\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py"", line 790, in map
    return MapDataset(self, map_func)
  File ""D:\Anaconda\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py"", line 1597, in __init__
    self._map_func.add_to_graph(ops.get_default_graph())
  File ""D:\Anaconda\lib\site-packages\tensorflow\python\framework\function.py"", line 486, in add_to_graph
    self._create_definition_if_needed()
  File ""D:\Anaconda\lib\site-packages\tensorflow\python\framework\function.py"", line 321, in _create_definition_if_needed
    self._create_definition_if_needed_impl()
  File ""D:\Anaconda\lib\site-packages\tensorflow\python\framework\function.py"", line 338, in _create_definition_if_needed_impl
    outputs = self._func(*inputs)
  File ""D:\Anaconda\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py"", line 1562, in tf_map_func
    ret = map_func(nested_args)
  File ""test_dataset.py"", line 64, in _parse_tfrecords_func
    img = tf.decode_raw(features['img'], tf.uint8)  # TODO: fix the error
  File ""D:\Anaconda\lib\site-packages\tensorflow\python\ops\gen_parsing_ops.py"", line 214, in decode_raw
    little_endian=little_endian, name=name)
  File ""D:\Anaconda\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 519, in _apply_op_helper
    repr(values), type(values).__name__))
TypeError: Expected string passed to parameter 'bytes' of op 'DecodeRaw', got FixedLenFeature(shape=[], dtype=tf.string, default_value=None) of type 'FixedLenFeature' instead.
```
"
17852,"TF1.6/1.7 PS/Worker Distributed Run Failed with ""UnavailableError: OS Error"" when jobs are not running on current machine","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: official 1.6.0 release binary, or build from master branch (with latest commit: 47407ccb99a61fd5115130020ff8ef5ef9272433)
- **TensorFlow version (use command below)**: 1.6.0 official release or master
- **Python version**: python 3.5 or python 2.7
- **Bazel version (if compiling from source)**:   0.11.1
- **GCC/Compiler version (if compiling from source)**: gcc (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609
- **CUDA/cuDNN version**: 9.0/7.0
- **GPU model and memory**:  Tesla K80, 12206MiB
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""
('v1.6.0-rc1-1503-g47407cc', '1.6.0')

### Describe the problem

#### The expected behavior

The below source code utilized ps/worker mode to do some training, for usage: we need to run

> python mnist_replica.py --data_dir /tmp/tensorflow/mnist/input_data --task_index 0 --ps_hosts '10.0.1.5:14416' --worker_hosts '10.0.1.4:14417' --job_name 'ps'
>  
>   python mnist_replica.py --data_dir /tmp/tensorflow/mnist/input_data --task_index 0 --ps_hosts '10.0.1.5:14416' --worker_hosts '10.0.1.4:14417' --job_name 'worker'

respectively on ""ps job"" machine and ""worker job"" machine. 

If we run the script firstly on ps, normally, it will wait for worker machine ready, before going furthur, the log is as below:

> 
>  2018-03-20 05:49:40.410488: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:14416}
> 2018-03-20 05:49:40.410614: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.1.4:14417}
> 2018-03-20 05:49:40.418149: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:324] Started server with target: grpc://localhost:14416
> ps 0, create done queue
> ps 0, running
> 2018-03-20 05:49:50.430531: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:0
> 2018-03-20 05:50:00.430728: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:0
> 2018-03-20 05:50:10.430943: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:0
> 2018-03-20 05:50:20.431080: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:0
> 2018-03-20 05:50:30.431351: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:0
> ^C2018-03-20 05:50:40.434895: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:0
> 2018-03-20 05:50:50.435104: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:0
> 2018-03-20 05:51:00.435244: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:0

Then we run the script on worker machine, the two machines communicated and coordinated to get things done. 
 
#### The problem
 It works pretty well on tf1.5/1.4 or earlier version, but on latest 1.6.0 release version (and i also tried to build from master source code), it failed for sometimes. I did some investigation and testing, here are the symptoms:

- If the specified ps/worker-hosts are having the same ip as current machine running the scripts (e.g. ps/worker are running different ports of current machine), everything is just fine, they works. 

- If the specified ps/worker-hosts are having the same ip (we call it A-IP), but different with current machine, even though current machine can ping successfully the  A-IP, but will failed. The error log after starting ps task (with **python mnist_replica.py --data_dir /tmp/tensorflow/mnist/input_data --task_index 0 --ps_hosts '10.0.1.5:14416' --worker_hosts '10.0.1.4:14417' --job_name 'ps'**):

> 2018-03-20 05:57:29.228323: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:14416}
> 2018-03-20 05:57:29.228478: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.1.4:14417}
> 2018-03-20 05:57:29.229155: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:324] Started server with target: grpc://localhost:14416
> ps 0, create done queue
> ps 0, running
> I0320 05:57:29.309552659    3803 subchannel.cc:677]          Connect failed: {""created"":""@1521525449.309441854"",""description"":""Failed to connect to remote host: OS Error"",""errno"":111,""file"":""external/grpc/src/core/lib/iomgr/tcp_client_posix.cc"",""file_line"":198,""os_error"":""Connection refused"",""syscall"":""connect"",""target_address"":""ipv4:10.0.1.4:14417""}
> I0320 05:57:29.309786369    3803 subchannel.cc:484]          Retry in 998 milliseconds
> I0320 05:57:30.307312499    3796 subchannel.cc:437]          Failed to connect to channel, retrying
> I0320 05:57:30.308555551    3804 subchannel.cc:677]          Connect failed: {""created"":""@1521525450.308464247"",""description"":""Failed to connect to remote host: OS Error"",""errno"":111,""file"":""external/grpc/src/core/lib/iomgr/tcp_client_posix.cc"",""file_line"":198,""os_error"":""Connection refused"",""syscall"":""connect"",""target_address"":""ipv4:10.0.1.4:14417""}
> I0320 05:57:30.308750759    3804 subchannel.cc:484]          Retry in 999 milliseconds
> I0320 05:57:31.307171978    3796 subchannel.cc:437]          Failed to connect to channel, retrying
> I0320 05:57:31.308303225    3802 subchannel.cc:677]          Connect failed: {""created"":""@1521525451.308214021"",""description"":""Failed to connect to remote host: OS Error"",""errno"":111,""file"":""external/grpc/src/core/lib/iomgr/tcp_client_posix.cc"",""file_line"":198,""os_error"":""Connection refused"",""syscall"":""connect"",""target_address"":""ipv4:10.0.1.4:14417""}
> I0320 05:57:31.308338927    3802 subchannel.cc:484]          Retry in 999 milliseconds
> I0320 05:57:32.307163816    3796 subchannel.cc:437]          Failed to connect to channel, retrying
> I0320 05:57:32.308250261    3801 subchannel.cc:677]          Connect failed: {""created"":""@1521525452.308164957"",""description"":""Failed to connect to remote host: OS Error"",""errno"":111,""file"":""external/grpc/src/core/lib/iomgr/tcp_client_posix.cc"",""file_line"":198,""os_error"":""Connection refused"",""syscall"":""connect"",""target_address"":""ipv4:10.0.1.4:14417""}
> I0320 05:57:32.308284662    3801 subchannel.cc:484]          Retry in 999 milliseconds
> I0320 05:57:33.307136307    3796 subchannel.cc:437]          Failed to connect to channel, retrying
> I0320 05:57:33.308314356    3806 subchannel.cc:677]          Connect failed: {""created"":""@1521525453.308215652"",""description"":""Failed to connect to remote host: OS Error"",""errno"":111,""file"":""external/grpc/src/core/lib/iomgr/tcp_client_posix.cc"",""file_line"":198,""os_error"":""Connection refused"",""syscall"":""connect"",""target_address"":""ipv4:10.0.1.4:14417""}
> I0320 05:57:33.308375658    3806 subchannel.cc:484]          Retry in 999 milliseconds
> I0320 05:57:34.307172752    3796 subchannel.cc:437]          Failed to connect to channel, retrying
> 2018-03-20 05:57:34.308793: E tensorflow/core/distributed_runtime/master.cc:269] Master init: Unavailable: OS Error
> Traceback (most recent call last):
>   File ""mnist_replica.py"", line 304, in <module>
>     main(args)
>   File ""mnist_replica.py"", line 102, in main
>     sess.run(queue.dequeue())
>   File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 905, in run
>     run_metadata_ptr)
>   File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1137, in _run
>     feed_dict_tensor, options, run_metadata)
>   File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1355, in _do_run
>     options, run_metadata)
>   File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1374, in _do_call
>     raise type(e)(node_def, op, message)
> tensorflow.python.framework.errors_impl.UnavailableError: OS Error

- If the specified ps/worker-hosts are having different ips (in the same LAN, can ping successfully each other), errors on starting on ps worker is similar with the second situation.  

- The exception happens in MasterSession initilization ( i guess there needs some communication via grpc there)

#### My personal thinking

To be honest, i am wondering whether the gRPC upgrade (that was [introduced](https://github.com/tensorflow/tensorflow/commit/cb498995bf3499d3dd4a6edad407590af12ac3bd) since v1.6rc0 ) did the trick, but since I am pretty new to this component, **besides i am not sure whether somebody else have the similar issues (while I think people using tf1.6 and master will suffer from this on distribute run).**

That would be great if any experts can share some insights or thoughts. Thanks in advance!!!

### Source code / logs

source code: 

`from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import argparse
import math
import sys
import tempfile
import time

import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data

IMAGE_PIXELS = 28

def create_done_queue(ps_task_index, worker_count):
    """"""Queue used to signal death for i'th ps shard. Intended to have 
    all workers enqueue an item onto it to signal doneness.""""""

    with tf.device(""/job:ps/task:%d/cpu:0"" % (ps_task_index)):
        return tf.FIFOQueue(worker_count, tf.int32, shared_name=""done_queue"" + str(ps_task_index))


def create_done_queues(ps_count, worker_count):
    return [create_done_queue(ps_task_index, worker_count) for ps_task_index in range(ps_count)]


def main(args):
    mnist = input_data.read_data_sets(args.input_training_data_path, one_hot=True)
    if args.download_only:
        sys.exit(0)

    if args.job_name is None or args.job_name == """":
        raise ValueError(""Must specify an explicit `job_name`"")
    if args.task_index is None or args.task_index == """":
        raise ValueError(""Must specify an explicit `task_index`"")

    print(""job name = %s"" % args.job_name)
    print(""task index = %d"" % args.task_index)

    # Construct the cluster and start the server
    ps_spec = args.ps_hosts.split("","")
    worker_spec = args.worker_hosts.split("","")

    # Get the number of workers.
    num_workers = len(worker_spec)
    num_pss = len(ps_spec)

    cluster = tf.train.ClusterSpec({
        ""ps"": ps_spec,
        ""worker"": worker_spec})

    if not args.existing_servers:
        # Not using existing servers. Create an in-process server.
        server = tf.train.Server(
            cluster, job_name=args.job_name, task_index=args.task_index, protocol=args.protocol)
        if args.job_name == ""ps"":
            config = tf.ConfigProto(log_device_placement=True, allow_soft_placement=True)
            sess = tf.Session(server.target, config=config)

            print(""ps %d, create done queue"" % args.task_index)
            queue = create_done_queue(args.task_index, num_workers)

            print(""ps %d, running"" % args.task_index)
            for i in range(num_workers):
                sess.run(queue.dequeue())
                print(""ps %d received worker %d done"" % (args.task_index, i))

            print(""all workers are done, ps %d: exit"" % (args.task_index))
            sys.exit()

    is_chief = (args.task_index == 0)
    if args.num_gpus > 0:
        # Avoid gpu allocation conflict: now allocate task_num -> #gpu
        # for each worker in the corresponding machine
        gpu = (args.task_index % args.num_gpus)
        worker_device = ""/job:worker/task:%d/gpu:%d"" % (args.task_index, gpu)
    elif args.num_gpus == 0:
        # Just allocate the CPU to worker server
        cpu = 0
        worker_device = ""/job:worker/task:%d/cpu:%d"" % (args.task_index, cpu)

    print(""worker %d, worker_device=%s"" % (args.task_index, worker_device))
    print(""worker %d, create done queue"" % args.task_index)
    queues = create_done_queues(num_pss, num_workers)
    print(""worker %d, done queue created"" % args.task_index)

    # The device setter will automatically place Variables ops on separate
    # parameter servers (ps). The non-Variable ops will be placed on the workers.
    # The ps use CPU and workers use corresponding GPU

    with tf.device(
            tf.train.replica_device_setter(
                worker_device=worker_device,
                ps_device=""/job:ps/cpu:0"",
                cluster=cluster)):
        global_step = tf.Variable(0, name=""global_step"", trainable=False)

        # Variables of the hidden layer
        hid_w = tf.Variable(
            tf.truncated_normal(
                [IMAGE_PIXELS * IMAGE_PIXELS, args.hidden_units],
                stddev=1.0 / IMAGE_PIXELS),
            name=""hid_w"")
        hid_b = tf.Variable(tf.zeros([args.hidden_units]), name=""hid_b"")

        # Variables of the softmax layer
        sm_w = tf.Variable(
            tf.truncated_normal(
                [args.hidden_units, 10],
                stddev=1.0 / math.sqrt(args.hidden_units)),
            name=""sm_w"")
        sm_b = tf.Variable(tf.zeros([10]), name=""sm_b"")

        # Ops: located on the worker specified with args.task_index
        x = tf.placeholder(tf.float32, [None, IMAGE_PIXELS * IMAGE_PIXELS])
        y_ = tf.placeholder(tf.float32, [None, 10])

        hid_lin = tf.nn.xw_plus_b(x, hid_w, hid_b)
        hid = tf.nn.relu(hid_lin)

        y = tf.nn.softmax(tf.nn.xw_plus_b(hid, sm_w, sm_b))
        cross_entropy = -tf.reduce_sum(y_ * tf.log(tf.clip_by_value(y, 1e-10, 1.0)))

        opt = tf.train.AdamOptimizer(args.learning_rate)

        if args.sync_replicas:
            if args.replicas_to_aggregate is None:
                replicas_to_aggregate = num_workers
            else:
                replicas_to_aggregate = args.replicas_to_aggregate

            opt = tf.train.SyncReplicasOptimizer(
                opt,
                replicas_to_aggregate=replicas_to_aggregate,
                total_num_replicas=num_workers,
                name=""mnist_sync_replicas"")

        train_step = opt.minimize(cross_entropy, global_step=global_step)

        if args.sync_replicas:
            local_init_op = opt.local_step_init_op
            if is_chief:
                local_init_op = opt.chief_init_op

            ready_for_local_init_op = opt.ready_for_local_init_op

            # Initial token and chief queue runners required by the sync_replicas mode
            chief_queue_runner = opt.get_chief_queue_runner()
            sync_init_op = opt.get_init_tokens_op()

        init_op = tf.global_variables_initializer()
        train_dir = tempfile.mkdtemp()

        enq_ops = []
        for q in queues:
            qop = q.enqueue(1)
            enq_ops.append(qop)
    if args.sync_replicas:
        sv = tf.train.Supervisor(
            is_chief=is_chief,
            logdir=train_dir,
            init_op=init_op,
            local_init_op=local_init_op,
            ready_for_local_init_op=ready_for_local_init_op,
            recovery_wait_secs=1,
            global_step=global_step)
    else:
        sv = tf.train.Supervisor(
            is_chief=is_chief,
            logdir=train_dir,
            init_op=init_op,
            recovery_wait_secs=1,
            global_step=global_step)

    sess_config = tf.ConfigProto(
        allow_soft_placement=True,
        log_device_placement=False,
        device_filters=[""/job:ps"", ""/job:worker/task:%d"" % args.task_index])
    if args.infer_shapes == True:
        sess_config.graph_options.infer_shapes = args.infer_shapes

    # The chief worker (task_index==0) session will prepare the session,
    # while the remaining workers will wait for the preparation to complete.
    if is_chief:
        print(""Worker %d: Initializing session..."" % args.task_index)
    else:
        print(""Worker %d: Waiting for session to be initialized..."" %
              args.task_index)

			  
    if args.existing_servers:
        server_grpc_url = ""grpc://"" + worker_spec[args.task_index]
        print(""Using existing server at: %s"" % server_grpc_url)

        sess = sv.prepare_or_wait_for_session(server_grpc_url,
                                              config=sess_config)
    else:
        sess = sv.prepare_or_wait_for_session(server.target, config=sess_config)

    print(""Worker %d: Session initialization complete."" % args.task_index)

    if args.sync_replicas and is_chief:
        # Chief worker will start the chief queue runner and call the init op.
        sess.run(sync_init_op)
        sv.start_queue_runners(sess, [chief_queue_runner])

    # Perform training
    time_begin = time.time()
    print(""Training begins @ %f"" % time_begin)

    local_step = 0
    while True:
        # Training feed
        batch_xs, batch_ys = mnist.train.next_batch(args.batch_size)
        train_feed = {x: batch_xs, y_: batch_ys}

        _, step = sess.run([train_step, global_step], feed_dict=train_feed)
        local_step += 1

        now = time.time()
        print(""%f: Worker %d: training step %d done (global step: %d)"" %
              (now, args.task_index, local_step, step))

        if step >= args.train_steps:
            break

    time_end = time.time()
    print(""Training ends @ %f"" % time_end)
    training_time = time_end - time_begin
    print(""Training elapsed time: %f s"" % training_time)

    # Validation feed
    val_feed = {x: mnist.validation.images, y_: mnist.validation.labels}
    val_xent = sess.run(cross_entropy, feed_dict=val_feed)
    print(""After %d training step(s), validation cross entropy = %g"" %
          (args.train_steps, val_xent))

    for op in enq_ops:
        sess.run(op)


if __name__ == ""__main__"":
    parser = argparse.ArgumentParser()
    parser.add_argument(""--input-training-data-path"", default=""/tmp/mnist-data"")
    parser.add_argument(""--input_training_data_path"", default=""/tmp/mnist-data"")
    parser.add_argument(""--download_only"", type=bool, default=False)
    parser.add_argument(""--task-index"", type=int)
    parser.add_argument(""--task_index"", type=int)
    parser.add_argument(""--num_gpus"", type=int, default=1)
    parser.add_argument(""--replicas_to_aggregate"", type=int)
    parser.add_argument(""--hidden_units"", type=int, default=100)
    parser.add_argument(""--train_steps"", type=int, default=200)
    parser.add_argument(""--batch_size"", type=int, default=100)
    parser.add_argument(""--learning_rate"", type=float, default=0.01)
    parser.add_argument(""--sync_replicas"", type=bool, default=False)
    parser.add_argument(""--existing_servers"", type=bool, default=False)
    parser.add_argument(""--ps-hosts"", default=""localhost:2222"")
    parser.add_argument(""--ps_hosts"", default=""localhost:2222"")
    parser.add_argument(""--worker-hosts"", default=""localhost:2223,localhost:2224"")
    parser.add_argument(""--worker_hosts"", default=""localhost:2223,localhost:2224"")
    parser.add_argument(""--job-name"")
    parser.add_argument(""--job_name"")
    parser.add_argument(""--protocol"", default=""grpc"")
    parser.add_argument(""--infer_shapes"", type=bool, default=False)

    (args, unknown) = parser.parse_known_args()
    main(args)`
"
17851,[Feature Request] Multiple GPU Training using Eager Execution,"I'm a starter in eager execution and not familiar in DL framework. However, in practice, multiple GPUs training is an important feature. PyTorch has nn.DataParallel and distributed package to support distributed training. Recently, I'm working on training model using eager execution with multiple gpus, and I have noticed that in https://hn.svelte.technology/item/15595123 @alextp said:

> We're still fairly early in the project, so _for now threading is the only supported way_.

I have two questions about it:
1. If there is an example about using threading to train with multiple gpus in eager execution? It will help a lot to starters.
2. I have concerns about performance using threading(only one thread can run python at one time in Cython implementation). Could threading speed up the training process? For example, if I have some python operations betweens tf operations(eg. [*DenseLayer*, *some operations using numpy, python list, etc.*, *DenseLayer*]), those tf operations(DenseLayer) in different threads could be parallelized, but those numpy operations in different threads are not going to be parallelizable?

Sorry for my poor english, please correct me if I'm wrong. Thank you!"
17850,Official/nightly builds for arm32 and arm64 on Linux,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux (debian:stretch) arm32v7 and arm64v7
- **TensorFlow installed from (source or binary)**:  n/a
- **TensorFlow version (use command below)**:  1.5.0 - 1.7.0
- **Python version**:  n/a
- **Bazel version (if compiling from source)**:  n/a
- **GCC/Compiler version (if compiling from source)**:  n/a
- **CUDA/cuDNN version**:  n/a
- **GPU model and memory**:  n/a
- **Exact command to reproduce**:  n/a

### Describe the problem
There has been significant community effort to build Tensorflow from source for ARM (e.g. https://github.com/samjabrahams/tensorflow-on-raspberry-pi and https://github.com/lhelontra/tensorflow-on-arm).  It would be great to get these as part of the official/nightly builds.  Python wheel/libtensorflow.so/libtensorflow_framework.so binaries.

### Source code / logs
n/a
"
17845,Latest Tensorflow-GPU installation crashes because of no found distributions for Tensorboad,"Trying to install the latest Tensorflow-GPU version gives me the following error:

pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.6.0-cp27-none-linux_x86_64.whl
Downloading/unpacking https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.6.0-cp27-none-linux_x86_64.whl
  Downloading tensorflow_gpu-1.6.0-cp27-none-linux_x86_64.whl (209.2MB): 209.2MB downloaded
Requirement already up-to-date: termcolor>=1.1.0 in ./.local/lib/python2.7/site-packages (from tensorflow-gpu==1.6.0)
Downloading/unpacking astor>=0.6.0 (from tensorflow-gpu==1.6.0)
  Downloading astor-0.6.2.tar.gz
  Running setup.py egg_info for package astor
    
    warning: no files found matching 'CHANGES'
Requirement already up-to-date: wheel in ./.local/lib/python2.7/site-packages (from tensorflow-gpu==1.6.0)
Downloading/unpacking absl-py>=0.1.6 (from tensorflow-gpu==1.6.0)
  Downloading absl-py-0.1.11.tar.gz (80kB): 80kB downloaded
  Running setup.py egg_info for package absl-py
    
Requirement already up-to-date: backports.weakref>=1.0rc1 in ./.local/lib/python2.7/site-packages (from tensorflow-gpu==1.6.0)
Downloading/unpacking tensorboard>=1.6.0,<1.7.0 (from tensorflow-gpu==1.6.0)
  Could not find any downloads that satisfy the requirement tensorboard>=1.6.0,<1.7.0 (from tensorflow-gpu==1.6.0)
Cleaning up...
No distributions at all found for tensorboard>=1.6.0,<1.7.0 (from tensorflow-gpu==1.6.0)
Storing complete log in /home/user/.pip/pip.log


In addition, I also tried installing it with pip, still unsuccessfully:

pip install --upgrade tensorflow-gpu
Could not find any downloads that satisfy the requirement tensorflow-gpu in ./.local/lib/python2.7/site-packages
Downloading/unpacking tensorflow-gpu
Cleaning up...
No distributions at all found for tensorflow-gpu in ./.local/lib/python2.7/site-packages
Storing complete log in /home/user/.pip/pip.log"
17844,Dropout training placeholder fails in tf.while_loop ," If I pass a placeholder to `training` parameter in `tf.layers.dropout`, then the model fails in `tf.while_loop`.  If I directly pass a boolean value, it works fine.  

- OS Platform and Distribution: Linux Ubuntu 17.10
- TensorFlow installed from: pip
- TensorFlow version: v1.6.0:
- Python version: 3.6
- Have I written custom code: yes
- Bazel version: N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A
- Exact command to reproduce: N/A

See the following code.
```py
import os

import numpy as np
import tensorflow as tf


os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'


print(tf.__version__)


class Config:
    def __init__(self):
        self.units = 10
        self.n_classes = 2
        self.drop_rate = 0.5


class Model:
    def __init__(self, cfg):
        self.cfg = cfg
        self.mlp = tf.layers.Dense(cfg.units)
        self.resize = tf.layers.Dense(cfg.n_classes)

    def predict(self, x):
        z = self.mlp(x)
        z = tf.layers.dropout(z, rate=self.cfg.drop_rate,
                              training=self.cfg.training)
        z = self.resize(z)
        return z


cfg = Config()
# training = tf.placeholder_with_default(False, (), 'mode')
training = False
cfg.training = training

model = Model(cfg)


def _cond(x, i):
    return tf.less(i, 20)


def _body(x, i):
    y = model.predict(x)
    dy_dx = tf.gradients(y, x)[0]
    x = dy_dx
    return x, i+1


x = tf.placeholder(tf.float32, (None, 3))
y = model.predict(x)
xx, ind = tf.while_loop(_cond, _body, [x, 0])

sess = tf.Session()
sess.run(tf.global_variables_initializer())

val = sess.run(xx, feed_dict={x: np.random.random((1, 3))})
print(val)

sess.close()
```
"
17843,[Feature Request] Add tf.extract_image_patches support on 3D inputs,"currently, [extract_image_patches](https://www.tensorflow.org/api_docs/python/tf/extract_image_patches) only support 2d image input(4d tensor) [batch, in_rows, in_cols, depth], I think it would be helpful to add 3d input support (ie 5d tensor [batch, in_rows, in_cols, in_higs, depth]. 

In recently months, 3D deep learning has become very popular. I think it's time to add 3D support on most tensorflow api.

OS Platform and Distribution: Ubuntu 16.04
TensorFlow installed from: N/A
TensorFlow version: 1.6
Bazel version: N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A
Exact command to reproduce: N/A"
17842,Fix deprecated api call in _NonAtrousConvolution,"### System information
I am using tf version `1.7.0-dev20180317, v1.6.0-rc1-1580-gc941c087a9` on OSX in standard non-eager mode.

### Describe the problem
Lines `151-156` in class `_NonAtrousConvolution` in `tensorflow/python/ops/nn_ops.py` set `nhwc` as data format when `conv_dims` is 1.  

``` python
    151     if conv_dims == 1:
    152       # conv1d uses the 2-d data format names
    153       if data_format is None or data_format == ""NWC"":
    154         data_format_2d = ""NHWC""
    155       elif data_format == ""NCW"":
    156         data_format_2d = ""NCHW""
```

But this causes a warning later on at line `2384` when `conv1d` is called from inside the `_conv1d` method at line `189`

```
WARNING:tensorflow:From ~/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.
Instructions for updating:
`NHWC` for data_format is deprecated, use `NWC` instead
```"
17841,"Hello, I am having a problem running the classify_image file from my command line. I have a recurring error and nothing I seem to do fixes it.","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:no, i was using script
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: windows
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.6.0
- **Python version**: 3.6
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**: python classify_image.py --image_file ""C:\Users\akilj\Desktop\cropped_panda.jpg""


### Describe the problem

I Ran this line of from my command line:

python classify_image.py --image_file ""C:\Users\akilj\Desktop\cropped_panda.jpg""                                                                                           
I was in this directory:
~/Desktop/models-master/tutorials/image/imagenet

### Source code / logs

The resultant error was:

Traceback (most recent call last):
  File ""C:\Users\akilj\AppData\Local\Programs\Python\Python36\lib\tarfile.py"", l                                                                                            ine 2294, in next
    tarinfo = self.tarinfo.fromtarfile(self)
  File ""C:\Users\akilj\AppData\Local\Programs\Python\Python36\lib\tarfile.py"", l                                                                                            ine 1090, in fromtarfile
    obj = cls.frombuf(buf, tarfile.encoding, tarfile.errors)
  File ""C:\Users\akilj\AppData\Local\Programs\Python\Python36\lib\tarfile.py"", l                                                                                            ine 1026, in frombuf
    raise EmptyHeaderError(""empty header"")
tarfile.EmptyHeaderError: empty header

During handling of the above exception, another exception occurred:

Traceback (most recent call last):

  File ""classify_image.py"", line 227, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""C:\Users\akilj\AppData\Local\Programs\Python\Python36\lib\site-packages\                                                                                            tensorflow\python\platform\app.py"", line 126, in run
    _sys.exit(main(argv))
  File ""classify_image.py"", line 190, in main
    maybe_download_and_extract()
  File ""classify_image.py"", line 186, in maybe_download_and_extract
    tarfile.open(filepath, 'r:gz').extractall(dest_directory)
  File ""C:\Users\akilj\AppData\Local\Programs\Python\Python36\lib\tarfile.py"", l                                                                                            ine 1586, in open
    return func(name, filemode, fileobj, **kwargs)
  File ""C:\Users\akilj\AppData\Local\Programs\Python\Python36\lib\tarfile.py"", l                                                                                            ine 1640, in gzopen
    t = cls.taropen(name, mode, fileobj, **kwargs)
  File ""C:\Users\akilj\AppData\Local\Programs\Python\Python36\lib\tarfile.py"", l                                                                                            ine 1616, in taropen
    return cls(name, mode, fileobj, **kwargs)
  File ""C:\Users\akilj\AppData\Local\Programs\Python\Python36\lib\tarfile.py"", l                                                                                            ine 1479, in __init__
    self.firstmember = self.next()
  File ""C:\Users\akilj\AppData\Local\Programs\Python\Python36\lib\tarfile.py"", l                                                                                            ine 2309, in next
    raise ReadError(""empty file"")
tarfile.ReadError: empty file

##
I tried changing up file location, checked instillation and found no issues but code wouldnt run. Please help."
17839,Beam search terminology,"(This issue is with terminology used in documentation and code. System information not applicable.)

The documentation and code in tf.contrib.seq2seq.BeamSearchDecoder and friends seems to use ""beam"" to mean ""search state"", whereas beam conventionally means ""a collection of search states"". This non-standard usage makes for confusing documentation!

Examples in documentation at https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/BeamSearchDecoder:

""The BeamSearchDecoder shuffles its beams"" 
""beam_width: Python integer, the number of beams"" 

Or in code:

https://github.com/tensorflow/tensorflow/blob/838a8f54f92452a15e3bb62a23ad5cd67e86933f/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py#L144

The conventional search algorithm terminology as I understand it, and attested by wikipedia (https://en.wikipedia.org/wiki/Beam_search) and recent academic usage (http://www.ijcai.org/Proceedings/05/Papers/0596.pdf), is that beam search is called beam search because it keeps a beam of search states in memory. The beam refers to the collection of search states, not the individual search states (I presume by the analogy that a beam of light illuminates certain objects but not others that fall outside the beam)."
17835,[Doc] Clarification on tf.contrib.lookup.MutableHashTable insert operation,"Document on [MutableHashTable](https://www.tensorflow.org/api_docs/python/tf/contrib/lookup/MutableDenseHashTable) is confusing, especially in this line:
`table.insert(keys, values)`
This code is unexecutable and misleading, it suggests insert is done inplace rather than an operation that need to be executed afterwards.

I think it shall be replaced by:
`sess.run(table.insert(keys, values))`

Reference: [tensorflow-mutablehashtable-not-updating](https://stackoverflow.com/questions/43373170/tensorflow-mutablehashtable-not-updating)"
17834,Very Large Dataset,I have very large dataset of 500GB csv single file. is there a way to batch or chunk process it?
17833,Create/Init a curl handler each time it's expensive. ,"Hi,
Nice wrapper around libcurl but... initialize/clean_up a curl handler every time can be expensive especially if you need to perform multiple call on small data chunk. I'll suggest to update the ""LibCurl"" wrapper by adding a ""static"" cache where store the connection handlers once have been initialized (and reuse it). this will really impact the performances. 

Best,
Diego"
17832,tf.contrib.estimator.add_metrics does not pass label_ids to tf.estimator.DNNClassifier evaluation,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
OSX 10.12.6

- **TensorFlow installed from (source or binary)**:
Binary

- **TensorFlow version (use command below)**:
('v1.6.0-0-gd2e24b6039', '1.6.0')

- **Python version**: 
2.7.13

- **Bazel version (if compiling from source)**:
N/A

- **GCC/Compiler version (if compiling from source)**:
N/A

- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:


### Describe the problem
Using tf.estimator.DNNClassifier as a multi-class estimator with a string label_vocabulary, tf.contrib.estimator.add_metrics will enable additional metrics functions as designed, however the label set pass to the metrics function will be the string tensor of labels, not the internal integer 'label_ids' of  DNNClassifier.  

This means the metrics do not have access to the labels used in the prediction tensor 'class_ids' (the tensor 'classes' does have the string labels).  This is a particular problem when trying to construct a confusion_matrix metric, as the confusion matrix tries to cast the labels to int64.

With the canned metrics, DNNClassifier  will simply pass in label_ids/class_ids:
https://github.com/tensorflow/tensorflow/blob/9054c9b2ac303cbd1538166d0821f389cbc75894/tensorflow/python/estimator/canned/head.py#L776


"
17828,"Bug in the TensorFlowLite pod, iOS, linker doesn't find GetSegmentPredictions function","### System information
- **I have written custom code**:
- **iOS 11.2.6**:
- **TensorFlowLite iOS pod**:
- **version: 0.0.2**:

### Describe the problem
I added the 0.0.2 version of TensorFlowLite pod to my project. I try to experiment with the Smart Reply demo. I used the Android demo code to start from. I can find the related function (GetSegmentPredictions) in one of the pod headers. but the linker doesn't find the appropriate code segment at build time.

Is there any body who could try out the Smart Reply on iOS?
When will this be added to the TensorFlowLite pod?

### Source code / logs
na

### Have I written custom code
no custom code, I implemented the Android code in objc.

### OS Platform and Distribution
iOS 11.2.6., TensorFlowLite iOS pod, version 0.0.2

### TensorFlow installed from
TensorFlowLite iOS pod

### TensorFlow version
Lite, 0.0.2

### Bazel version
na

### CUDA/cuDNN version
na

### GPU model and memory
na

### Exact command to reproduce
na

thanks!"
17827,"TensorFlowLite pod, iOS, linker doesn't find GetSegmentPredictions function","Hi,

I added the 0.0.2 version of TensorFlowLite pod to my project. I try to experiment with the Smart Reply demo. I used the Android demo code to start from. I can find the related function (GetSegmentPredictions) in one of the pod headers. but the linker doesn't find the appropriate code segment at build time.

Is there any body who could try out the Smart Reply on iOS?
When will this be added to the TensorFlowLite pod?

thanks!
"
17826,Tensorflow lite c++ shared library build steps.,"Hi , 
I like to know steps to build shared/static  c++ tensorflow lite library+ headers **WITHOUT JNI** for Android armeabi-v7a/arm64-v8a.
I search for this problem through all issues here , found couple relevant topics but all of them without complete answer. 

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 16
- **TensorFlow installed from (source or binary)**:
Source
- **TensorFlow version (use command below)**:
Master
- **Python version**: 
2.7
- **Bazel version (if compiling from source)**:
0.10.1
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
None
- **GPU model and memory**:
None

Thanks

"
17825,fft wrong results with non-power of 2 input sizes,"I have encounter problems with the tensorflow fft implementation when the input is not a power of two. If the input is real, the first entry of the output is the sum of the input and should therefore also be real. 
But tf.fft output a non-zero imaginary part. An example is given below:

```
import tensorflow as tf
import numpy as np

data = np.random.random(100)
sess = tf.Session()
fft_tf = sess.run(tf.fft(data))
print(fft_tf[0])
np.sum(data.astype(np.float32))
```

works as intended for inputs as power of two's including smaller errors:

```
data = np.random.random(128)
sess = tf.Session()
fft_tf = sess.run(tf.fft(data))
print(fft_tf[0])
np.sum(data.astype(np.float32))
```

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
    Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
    Windows 10
- **TensorFlow installed from (source or binary)**:
    Installed from Source
- **TensorFlow version (use command below)**:
    Version 1.4
- **Python version**: 
    Python 3.6.2
- **Bazel version (if compiling from source)**:
    N/A
- **GCC/Compiler version (if compiling from source)**:
    N/A
- **CUDA/cuDNN version**:
    CUDA Version 8.0, cuDNN64_6
- **GPU model and memory**:
    nvidia GTX 1050 mobile
- **Exact command to reproduce**:
    See above.
"
17824,Feature request: Return true labels from `estimator.predict(...)`,"Hello everyone,

As mentioned in the [Getting started with Tensorflow / Custom Estimators](https://www.tensorflow.org/get_started/custom_estimators#implement_training_evaluation_and_prediction) one has to know the expected label for the data, since the labels will be discarded during the `predict()` function.

```python
# Generate predictions from the model
expected = ['Setosa', 'Versicolor', 'Virginica']
predict_x = {
    'SepalLength': [5.1, 5.9, 6.9],
    'SepalWidth': [3.3, 3.0, 3.1],
    'PetalLength': [1.7, 4.2, 5.4],
    'PetalWidth': [0.5, 1.5, 2.1],
}

predictions = classifier.predict(
    input_fn=lambda:iris_data.eval_input_fn(predict_x,
                                            batch_size=args.batch_size))
```

which can be seen [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/estimator/estimator.py#L486)

```python
     features, input_hooks = self._get_features_from_input_fn(
        input_fn, model_fn_lib.ModeKeys.PREDICT)
    estimator_spec = self._call_model_fn(
        features, None, model_fn_lib.ModeKeys.PREDICT, self.config)
```

I totally agree to discard the labels, and don't pass them to the `model_fn` function. However, it would be much easier to return them also from the `input_fn`-function, if they are provided. A simplified solution, without the case distinction of given/not given labels, could be:

```python
  def predict(self,
              input_fn,
              predict_keys=None,
              hooks=None,
              checkpoint_path=None):
    """"""Yields predictions for given features.

    Args:
      input_fn: A function that constructs the features. Prediction continues
        until `input_fn` raises an end-of-input exception (`OutOfRangeError` or
        `StopIteration`).
        See @{$get_started/premade_estimators#create_input_functions} for more
        information. The function should construct and return one of
        the following:

          * A 'tf.data.Dataset' object: Outputs of `Dataset` object must have
            same constraints as below.
          * features: A `Tensor` or a dictionary of string feature name to
            `Tensor`. features are consumed by `model_fn`. They should satisfy
            the expectation of `model_fn` from inputs.
          * A tuple, in which case the first item is extracted as features.

      predict_keys: list of `str`, name of the keys to predict. It is used if
        the `EstimatorSpec.predictions` is a `dict`. If `predict_keys` is used
        then rest of the predictions will be filtered from the dictionary. If
        `None`, returns all.
      hooks: List of `SessionRunHook` subclass instances. Used for callbacks
        inside the prediction call.
      checkpoint_path: Path of a specific checkpoint to predict. If `None`, the
        latest checkpoint in `model_dir` is used.

    Yields:
      Evaluated values of `predictions` tensors.

    Raises:
      ValueError: Could not find a trained model in model_dir.
      ValueError: if batch length of predictions are not same.
      ValueError: If there is a conflict between `predict_keys` and
        `predictions`. For example if `predict_keys` is not `None` but
        `EstimatorSpec.predictions` is not a `dict`.
    """"""
    hooks = _check_hooks_type(hooks)
    # Check that model has been trained.
    if not checkpoint_path:
      checkpoint_path = saver.latest_checkpoint(self._model_dir)
    if not checkpoint_path:
      raise ValueError('Could not find trained model in model_dir: {}.'.format(
          self._model_dir))

    with ops.Graph().as_default() as g:
      random_seed.set_random_seed(self._config.tf_random_seed)
      self._create_and_assert_global_step(g)
      features, labels, input_hooks = self._get_features_and_labels_from_input_fn(
          input_fn, model_fn_lib.ModeKeys.PREDICT)
      estimator_spec = self._call_model_fn(
          features, None, model_fn_lib.ModeKeys.PREDICT, self.config)
      predictions = self._extract_keys(estimator_spec.predictions, predict_keys)
      all_hooks = list(input_hooks)
      all_hooks.extend(hooks)
      all_hooks.extend(list(estimator_spec.prediction_hooks or []))
      with training.MonitoredSession(
          session_creator=training.ChiefSessionCreator(
              checkpoint_filename_with_path=checkpoint_path,
              master=self._config.master,
              scaffold=estimator_spec.scaffold,
              config=self._session_config),
          hooks=all_hooks) as mon_sess:
        while not mon_sess.should_stop():
          preds_evaluated, gt_labels = mon_sess.run([predictions, labels])
          if not isinstance(predictions, dict):
            for pred, true_label in zip(preds_evaluated, gt_labels):
              yield pred, true_label
          else:
            for i in range(self._extract_batch_length(preds_evaluated)):
              yield {
                  key: value[i]
                  for key, value in six.iteritems(preds_evaluated)
              }, gt_labels[i]
```

OS Platform and Distribution
> Ubuntu 16.04.3 LTS

TensorFlow installed from
> pip

TensorFlow version
>  tensorflow-gpu '1.6.0'

Bazel version
> N/A

CUDA/cuDNN version
> N/A

GPU model and memory
> N/A

Exact command to reproduce
> N/A


"
17823,"[Feature Request] GPU ops for strided_slice/pad on uint8, int8 and bool","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 and Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.6.0
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: GeForce GTX 1080 Ti
- **Exact command to reproduce**: See below

### Introduction

We are trying to move the preprocessing of our tensorflow network to GPU in order to gain performance. Unfortunately it does not allow to run `strided_slice` or `pad` on GPU, thus either memcpy from/to GPU/CPU is required or everything must be computed on CPU. Also we wish not to convert these to other datatypes, because the tensors are quite large (thus every operation very memory consuming).

### Request
Implement GPU ops for datatypes such as `DT_UIN8`, `DT_INT8`, `DT_BOOL` for `strided_slice` and `pad`.
### Example

    import tensorflow as tf

    x = tf.constant(0, dtype=tf.uint8, shape=(1,))
    with tf.device('GPU:0'):
        y = x[0]
        # Or for padding:
        #y = tf.pad(x, [[0, 0]])

    # This works, because the cpu op is taken as fallback.
    #with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)).as_default():
    # This doesn't work, because the GPU op doesn't exist.
    with tf.Session().as_default():
        print(y.eval())


This example fails with the following error for slicing (as defined in [strided_slice_op_gpu.cu.cc](https://github.com/tensorflow/tensorflow/blob/3c3c0481ec087aca4fa875d6d936f19b31191fc1/tensorflow/core/kernels/strided_slice_op_gpu.cu.cc) also via [TF_CALL_GPU_NUMBER_TYPES](https://github.com/tensorflow/tensorflow/blob/1752d9c8fac5f6cf85a41e77d92e2743adbfc446/tensorflow/core/framework/register_types.h#L188)):

    InvalidArgumentError (see above for traceback): Cannot assign a device for operation 'strided_slice': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
    Registered kernels:
      device='CPU'; T in [DT_INT64]
      device='CPU'; T in [DT_INT32]
      device='CPU'; T in [DT_UINT16]
      device='CPU'; T in [DT_INT16]
      device='CPU'; T in [DT_UINT8]
      device='CPU'; T in [DT_INT8]
      device='CPU'; T in [DT_HALF]
      device='CPU'; T in [DT_BFLOAT16]
      device='CPU'; T in [DT_FLOAT]
      device='CPU'; T in [DT_DOUBLE]
      device='CPU'; T in [DT_COMPLEX64]
      device='CPU'; T in [DT_COMPLEX128]
      device='CPU'; T in [DT_BOOL]
      device='CPU'; T in [DT_STRING]
      device='CPU'; T in [DT_RESOURCE]
      device='CPU'; T in [DT_VARIANT]
      device='GPU'; T in [DT_HALF]
      device='GPU'; T in [DT_FLOAT]
      device='GPU'; T in [DT_DOUBLE]
      device='GPU'; T in [DT_COMPLEX64]
      device='GPU'; T in [DT_COMPLEX128]
      device='GPU'; T in [DT_INT64]
      device='GPU'; T in [DT_INT32]

    	 [[Node: strided_slice = StridedSlice[Index=DT_INT32, T=DT_UINT8, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1, _device=""/device:GPU:0""](Const, strided_slice/stack, strided_slice/stack_1, strided_slice/stack_2)]]

For padding (as defined in [pad_op_gpu.cu.cc](https://github.com/tensorflow/tensorflow/blob/3c3c0481ec087aca4fa875d6d936f19b31191fc1/tensorflow/core/kernels/pad_op_gpu.cu.cc) via [TF_CALL_GPU_NUMBER_TYPES](https://github.com/tensorflow/tensorflow/blob/1752d9c8fac5f6cf85a41e77d92e2743adbfc446/tensorflow/core/framework/register_types.h#L188)):

    InvalidArgumentError (see above for traceback): Cannot assign a device for operation 'Pad': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
    Registered kernels:
      device='CPU'; T in [DT_INT64]; Tpaddings in [DT_INT32]
      device='CPU'; T in [DT_INT64]; Tpaddings in [DT_INT64]
      device='CPU'; T in [DT_INT32]; Tpaddings in [DT_INT32]
      device='CPU'; T in [DT_INT32]; Tpaddings in [DT_INT64]
      device='CPU'; T in [DT_UINT16]; Tpaddings in [DT_INT32]
      device='CPU'; T in [DT_UINT16]; Tpaddings in [DT_INT64]
      device='CPU'; T in [DT_INT16]; Tpaddings in [DT_INT32]
      device='CPU'; T in [DT_INT16]; Tpaddings in [DT_INT64]
      device='CPU'; T in [DT_UINT8]; Tpaddings in [DT_INT32]
      device='CPU'; T in [DT_UINT8]; Tpaddings in [DT_INT64]
      device='CPU'; T in [DT_INT8]; Tpaddings in [DT_INT32]
      device='CPU'; T in [DT_INT8]; Tpaddings in [DT_INT64]
      device='CPU'; T in [DT_HALF]; Tpaddings in [DT_INT32]
      device='CPU'; T in [DT_HALF]; Tpaddings in [DT_INT64]
      device='CPU'; T in [DT_BFLOAT16]; Tpaddings in [DT_INT32]
      device='CPU'; T in [DT_BFLOAT16]; Tpaddings in [DT_INT64]
      device='CPU'; T in [DT_FLOAT]; Tpaddings in [DT_INT32]
      device='CPU'; T in [DT_FLOAT]; Tpaddings in [DT_INT64]
      device='CPU'; T in [DT_DOUBLE]; Tpaddings in [DT_INT32]
      device='CPU'; T in [DT_DOUBLE]; Tpaddings in [DT_INT64]
      device='CPU'; T in [DT_COMPLEX64]; Tpaddings in [DT_INT32]
      device='CPU'; T in [DT_COMPLEX64]; Tpaddings in [DT_INT64]
      device='CPU'; T in [DT_COMPLEX128]; Tpaddings in [DT_INT32]
      device='CPU'; T in [DT_COMPLEX128]; Tpaddings in [DT_INT64]
      device='CPU'; T in [DT_BOOL]; Tpaddings in [DT_INT32]
      device='CPU'; T in [DT_BOOL]; Tpaddings in [DT_INT64]
      device='GPU'; T in [DT_HALF]; Tpaddings in [DT_INT32]
      device='GPU'; T in [DT_HALF]; Tpaddings in [DT_INT64]
      device='GPU'; T in [DT_FLOAT]; Tpaddings in [DT_INT32]
      device='GPU'; T in [DT_FLOAT]; Tpaddings in [DT_INT64]
      device='GPU'; T in [DT_DOUBLE]; Tpaddings in [DT_INT32]
      device='GPU'; T in [DT_DOUBLE]; Tpaddings in [DT_INT64]
      device='GPU'; T in [DT_INT32]; Tpaddings in [DT_INT32]
      device='GPU'; T in [DT_INT32]; Tpaddings in [DT_INT64]

    	 [[Node: Pad = Pad[T=DT_UINT8, Tpaddings=DT_INT32, _device=""/device:GPU:0""](Const, Pad/paddings)]]"
17822,TF Lite: build instructions for RaspberryPi give build error,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Tested on Raspberry pi 3, Raspbian 9.3; Ubuntu 16.04 (cross-compile to arm); docker tensorflow/tensorflow:nightly-devel (cross-compile to arm)
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: latest (current master on git)
- **Python version**: -
- **Bazel version (if compiling from source)**: Build is done via makefiles
- **GCC/Compiler version (if compiling from source)**: tested with 6.3 on Raspbian, 4.8 on Raspbian, 4.8 on Ubuntu (and whatever is in the docker image)
- **CUDA/cuDNN version**: -
- **GPU model and memory**: -
- **Exact command to reproduce**: Follow instructions given in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/rpi.md

### Describe the problem
Build fails with error: 

```
+ set -e
+++ dirname ./tensorflow/contrib/lite/build_rpi_lib.sh
++ cd ./tensorflow/contrib/lite
++ pwd
+ SCRIPT_DIR=/tensorflow/tensorflow/contrib/lite
+ cd /tensorflow/tensorflow/contrib/lite/../../..
+ CC_PREFIX=arm-linux-gnueabihf-
+ make -j 3 -f tensorflow/contrib/lite/Makefile TARGET=RPI TARGET_ARCH=armv7
/bin/sh: 1: [[: not found
arm-linux-gnueabihf-gcc --std=c++11 -O3 -DNDEBUG -march=armv7-a -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize -I. -I/tensorflow/tensorflow/contrib/lite/../../../ -I/tensorflow/tensorflow/contrib/lite/downloads/ -I/tensorflow/tensorflow/contrib/lite/downloads/eigen -I/tensorflow/tensorflow/contrib/lite/downloads/gemmlowp -I/tensorflow/tensorflow/contrib/lite/downloads/neon_2_sse -I/tensorflow/tensorflow/contrib/lite/downloads/farmhash/src -I/tensorflow/tensorflow/contrib/lite/downloads/flatbuffers/include -I/tensorflow/tensorflow/contrib/lite/../../../bazel-genfiles/tensorflow/core/framework -I/tensorflow/tensorflow/contrib/lite/gen/obj/ -I/usr/local/include -c tensorflow/contrib/lite/tools/benchmark_model.cc -o /tensorflow/tensorflow/contrib/lite/gen/obj/rpi_armv7/tensorflow/contrib/lite/tools/benchmark_model.o
In file included from ./tensorflow/core/lib/core/errors.h:21:0,
                 from ./tensorflow/core/platform/env.h:24,
                 from tensorflow/contrib/lite/tools/benchmark_model.cc:29:
./tensorflow/core/lib/core/status.h:23:53: fatal error: tensorflow/core/lib/core/error_codes.pb.h: No such file or directory
compilation terminated.
tensorflow/contrib/lite/Makefile:113: recipe for target '/tensorflow/tensorflow/contrib/lite/gen/obj/rpi_armv7/tensorflow/contrib/lite/tools/benchmark_model.o' failed
make: *** [/tensorflow/tensorflow/contrib/lite/gen/obj/rpi_armv7/tensorflow/contrib/lite/tools/benchmark_model.o] Error 1
```

**Note**: The build for the tflite static library target completes, it's the benchmark program that fails.
"
17819,i not understand what matter is my code about beamsearchdecoder,"decoder_cell=[]
for _ in range(n_layers):
    decoder_c=tf.nn.rnn_cell.BasicLSTMCell(num_units)
    if train_state:
        decoder_c=tf.contrib.rnn.DropoutWrapper(decoder_c,input_keep_prob)
    decoder_cell.append(decoder_c)
decoder_cell=tf.nn.rnn_cell.MultiRNNCell(decoder_cell,state_is_tuple=True)

attention_mechanism=tf.contrib.seq2seq.BahdanauAttention(num_units,encoder_outputs)
attention_cell=tf.contrib.seq2seq.AttentionWrapper(decoder_cell,attention_mechanism)
helper=tf.contrib.seq2seq.TrainingHelper(decoder_embedded,decoder_length)
initial_state=attention_cell.zero_state(dtype=tf.float32,batch_size=50)
initial_state=initial_state.clone(cell_state=encoder_state)
training_decoder=tf.contrib.seq2seq.BasicDecoder(attention_cell,helper,
                                                     initial_state,
                                                     output_layer=None)
train_decoder_outputs,train_decoder_state,_=tf.contrib.seq2seq.dynamic_decode(training_decoder)

start_tokens=tf.placeholder(dtype=tf.int32,shape=[None])
end_token=tf.placeholder(dtype=tf.int32,shape=[])
tiled_encoder_outputs=tf.contrib.seq2seq.tile_batch(encoder_outputs,multiplier=beam_width)
tiled_encoder_state=tf.contrib.seq2seq.tile_batch(encoder_state,multiplier=beam_width)
tiled_sequence_length=tf.contrib.seq2seq.tile_batch(encoder_length,multiplier=beam_width)
attention_mechanism=tf.contrib.seq2seq.BahdanauAttention(num_units,tiled_encoder_state[-1][0])
attention_cell=tf.contrib.seq2seq.AttentionWrapper(decoder_cell,attention_mechanism)
initial_state=attention_cell.zero_state(dtype=tf.float32,batch_size=50*beam_width)
initial_state=initial_state.clone(cell_state=tiled_encoder_state)
predicting_decoder=tf.contrib.seq2seq.BeamSearchDecoder(attention_cell,
                                                        embeddings,
                                                        start_tokens,
                                                        end_token,
                                                        initial_state=initial_state,
                                                        beam_width=beam_width,
                                                        output_layer=None)

predict_decoder_ouputs,_,_=tf.contrib.seq2seq.dynamic_decode(predicting_decoder)

------------------------------------------------------------------------------------------

ndexError                                Traceback (most recent call last)
<ipython-input-43-08de1520bc78> in <module>()
----> 1 predict_decoder_ouputs,_,_=tf.contrib.seq2seq.dynamic_decode(predicting_decoder)

~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py in dynamic_decode(decoder, output_time_major, impute_finished, maximum_iterations, parallel_iterations, swap_memory, scope)
    284         ],
    285         parallel_iterations=parallel_iterations,
--> 286         swap_memory=swap_memory)
    287 
    288     final_outputs_ta = res[1]

~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py in while_loop(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name)
   2814     loop_context = WhileContext(parallel_iterations, back_prop, swap_memory)  # pylint: disable=redefined-outer-name
   2815     ops.add_to_collection(ops.GraphKeys.WHILE_CONTEXT, loop_context)
-> 2816     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)
   2817     return result
   2818 

~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py in BuildLoop(self, pred, body, loop_vars, shape_invariants)
   2638       self.Enter()
   2639       original_body_result, exit_vars = self._BuildLoop(
-> 2640           pred, body, original_loop_vars, loop_vars, shape_invariants)
   2641     finally:
   2642       self.Exit()

~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py in _BuildLoop(self, pred, body, original_loop_vars, loop_vars, shape_invariants)
   2588         structure=original_loop_vars,
   2589         flat_sequence=vars_for_body_with_tensor_arrays)
-> 2590     body_result = body(*packed_vars_for_body)
   2591     if not nest.is_sequence(body_result):
   2592       body_result = [body_result]

~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py in body(time, outputs_ta, state, inputs, finished, sequence_lengths)
    232       """"""
    233       (next_outputs, decoder_state, next_inputs,
--> 234        decoder_finished) = decoder.step(time, inputs, state)
    235       next_finished = math_ops.logical_or(decoder_finished, finished)
    236       if maximum_iterations is not None:

~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py in step(self, time, inputs, state, name)
    456           self._maybe_merge_batch_beams,
    457           cell_state, self._cell.state_size)
--> 458       cell_outputs, next_cell_state = self._cell(inputs, cell_state)
    459       cell_outputs = nest.map_structure(
    460           lambda out: self._split_batch_beams(out, out.shape[1:]), cell_outputs)

~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py in __call__(self, inputs, state, scope)
    181       with vs.variable_scope(vs.get_variable_scope(),
    182                              custom_getter=self._rnn_get_variable):
--> 183         return super(RNNCell, self).__call__(inputs, state)
    184 
    185   def _rnn_get_variable(self, getter, *args, **kwargs):

~/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py in __call__(self, inputs, *args, **kwargs)
    573         if in_graph_mode:
    574           self._assert_input_compatibility(inputs)
--> 575         outputs = self.call(inputs, *args, **kwargs)
    576 
    577         if outputs is None:

~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py in call(self, inputs, state)
   1322       attention, alignments = _compute_attention(
   1323           attention_mechanism, cell_output, previous_alignments[i],
-> 1324           self._attention_layers[i] if self._attention_layers else None)
   1325       alignment_history = previous_alignment_history[i].write(
   1326           state.time, alignments) if self._alignment_history else ()

~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py in _compute_attention(attention_mechanism, cell_output, previous_alignments, attention_layer)
    971   """"""Computes the attention and alignments for a given attention_mechanism.""""""
    972   alignments = attention_mechanism(
--> 973       cell_output, previous_alignments=previous_alignments)
    974 
    975   # Reshape from [batch_size, memory_time] to [batch_size, 1, memory_time]

~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py in __call__(self, query, previous_alignments)
    531     with variable_scope.variable_scope(None, ""bahdanau_attention"", [query]):
    532       processed_query = self.query_layer(query) if self.query_layer else query
--> 533       score = _bahdanau_score(processed_query, self._keys, self._normalize)
    534     alignments = self._probability_fn(score, previous_alignments)
    535     return alignments

~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py in _bahdanau_score(processed_query, keys, normalize)
    425   dtype = processed_query.dtype
    426   # Get the number of hidden units from the trailing dimension of keys
--> 427   num_units = keys.shape[2].value or array_ops.shape(keys)[2]
    428   # Reshape from [batch_size, ...] to [batch_size, 1, ...] for broadcasting.
    429   processed_query = array_ops.expand_dims(processed_query, 1)

~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py in __getitem__(self, key)
    519         return TensorShape(self._dims[key])
    520       else:
--> 521         return self._dims[key]
    522     else:
    523       if isinstance(key, slice):

IndexError: list index out of range

"
17817,Feature request: batch image input for exported model (image retraining),"

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 16.04
- **TensorFlow installed from (source or binary)**:  binary
- **TensorFlow version (use command below)**: 1.4.1
- **Python version**: 3.6.1
- **Bazel version (if compiling from source)**: - 
- **GCC/Compiler version (if compiling from source)**: -
- **CUDA/cuDNN version**: 7.5/6
- **GPU model and memory**: -
- **Exact command to reproduce**: 

### Describe the problem
Feature request:
I want to use the image retraining on my own image classes and then use the exported model as part of my data pipeline. But I noticed that the exported model only accepts input tensors of size (1, 299, 299, 3). It would be really great if it could accept batch images for example (32, 299, 299, 3) tensors. If you could advise me on how best to modify the code to do this that would be great too.

### Source code / logs
How I trained my model:
```
python3 tensorflow/examples/image_retraining/retrain.py --image_dir $DATA_DIR
```
Here I tried feeding (2, 299, 299, 3) tensor as input to the model
```
Traceback (most recent call last):
  File ""tensorflow/examples/label_image/label_image.py"", line 133, in <module>
    input_operation.outputs[0]: t
  File ""/home/beo/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 905, in run
    run_metadata_ptr)
  File ""/home/beo/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1113, in _run
    str(subfeed_t.get_shape())))
ValueError: Cannot feed value of shape (2, 299, 299, 3) for Tensor u'import/Mul:0', which has shape '(1, 299, 299, 3)'
```
"
17816,MKL_DNN is built during non-mkl builds.,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: 
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 14.04
- **TensorFlow installed from (source or binary)**:
Source
- **TensorFlow version (use command below)**:
master after 1.7
- **Python version**: 
2.7
- **Bazel version (if compiling from source)**:
0.11
- **GCC/Compiler version (if compiling from source)**:
does not matter
- **CUDA/cuDNN version**:
n/a
- **GPU model and memory**:
n/a
- **Exact command to reproduce**:
```
bazel test --test_tag_filters=-no_oss,-oss_serial,-gpu,-benchmark-test -k --copt='-march=skylake-avx512' - //tensorflow/... -//tensorflow/compiler/... -//tensorflow/contrib/...
```

### Describe the problem
I expected to see some test failures, or some other build failures. no MKL code should be compiled with the above command.

### Source code / logs
```
ERROR: /home/kbuilder/.cache/bazel/_bazel_kbuilder/9a46bec5c8e82ceb5b4b229201d44d70/external/mkl_dnn/BUILD:3:1: Couldn't build file external/mkl_dnn/_objs/mkl_dnn/external/mkl_dnn/src/cpu/ref_lrn.pic.o: C++ compilation of rule '@mkl_dnn//:mkl_dnn' failed (Exit 1): clang failed: error executing command 
  (cd /home/kbuilder/.cache/bazel/_bazel_kbuilder/9a46bec5c8e82ceb5b4b229201d44d70/execroot/org_tensorflow && \
  exec env - \
    PATH=/bin:/usr/bin \
    PORTSERVER_ADDRESS=@unittest-portserver \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/usr/bin/python \
    PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \
    TF_NEED_CUDA=0 \
    TF_NEED_OPENCL_SYCL=0 \
    TF_PYTHON_CONFIG_REPO=@org_tensorflow//third_party/toolchains/cpus/py \
  /usr/local/bin/clang -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/local/bin -B/usr/bin -fcolor-diagnostics -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK '-march=skylake-avx512' '-std=c++0x' -MD -MF bazel-out/k8-opt/bin/external/mkl_dnn/_objs/mkl_dnn/external/mkl_dnn/src/cpu/ref_lrn.pic.d '-frandom-seed=bazel-out/k8-opt/bin/external/mkl_dnn/_objs/mkl_dnn/external/mkl_dnn/src/cpu/ref_lrn.pic.o' -fPIC -iquote external/mkl_dnn -iquote bazel-out/k8-opt/genfiles/external/mkl_dnn -iquote external/bazel_tools -iquote bazel-out/k8-opt/genfiles/external/bazel_tools -isystem external/mkl_dnn/include -isystem bazel-out/k8-opt/genfiles/external/mkl_dnn/include -isystem external/mkl_dnn/src -isystem bazel-out/k8-opt/genfiles/external/mkl_dnn/src -isystem external/mkl_dnn/src/common -isystem bazel-out/k8-opt/genfiles/external/mkl_dnn/src/common -isystem external/mkl_dnn/src/cpu -isystem bazel-out/k8-opt/genfiles/external/mkl_dnn/src/cpu -isystem external/mkl_dnn/src/cpu/xbyak -isystem bazel-out/k8-opt/genfiles/external/mkl_dnn/src/cpu/xbyak -isystem external/bazel_tools/tools/cpp/gcc3 -fexceptions -fopenmp -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c external/mkl_dnn/src/cpu/ref_lrn.cpp -o bazel-out/k8-opt/bin/external/mkl_dnn/_objs/mkl_dnn/external/mkl_dnn/src/cpu/ref_lrn.pic.o)
external/mkl_dnn/src/cpu/ref_lrn.cpp:20:10: fatal error: 'c_types_map.hpp' file not found
#include ""c_types_map.hpp""
```

@tatianashp Could you add our Intel contacts to this issue?"
17811,Make feature column input_layer compatible with sequential data,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Debian Buster/Sid
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.7.0-rc0
- **Python version**: 3.6.5rc1
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: See source code below

### Describe the problem

Feature columns offer easy and reproducible feature encodings. It would be nice if they could be made compatible with sequential data as well. I currently would like to use them for processing inputs in a custom RNN estimator and sadly discovered that the current [`input_layer`](https://www.tensorflow.org/api_docs/python/tf/feature_column/input_layer) API doesn't support sequential inputs. It always returns a Tensor shaped `(batch_size, first_layer_dimension)`, which makes it unusable in combination with the[ `dynamic_rnn`](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn) wrapper which expects inputs of shape `(batch_size, max_time, first_layer_dimension)`

### Source code / logs
My first attempt at a workaround for this shortcoming, was mapping the `input_layer` function across the sequences of the inputs. 
```python
def model_fn(features, labels, mode, params, config):
    sequence_lengths = features.pop('session_length')
    rnn_cell, state_size, initializer = params['rnn_cell'].values()

    encoded_features = tf.map_fn(lambda input_features: tf.feature_column.input_layer(input_features, params['feature_columns']), features, dtype=tf.float32)
    encoded_labels = tf.tile(tf.map_fn(lambda seqeunce_labels: tf.feature_column.input_layer(seqeunce_labels, params['label_columns']), labels, dtype=tf.float32), sequence_lengths)

    cell = rnn_cell(num_units=state_size, initializer=initializer())
    outputs, state = tf.nn.dynamic_rnn(cell=cell, inputs=encoded_features, dtype=tf.float32, sequence_length=sequence_lengths)
    logits = tf.contrib.layers.fully_connected(outputs, num_outputs=2, activation_fn=None)
    predictions = tf.nn.softmax(logits)
    
    loss = tf.losses.softmax_cross_entropy(encoded_labels, logits)
    optimizer = tf.train.AdamOptimizer(learning_rate=params[""learning_rate""])
    train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())
    
    return tf.estimator.EstimatorSpec(mode, predictions=predictions, train_op=train_op, loss=loss)
```
Due to some kind of frame error this sadly is also not possible. Maybe I am missing something here and any tips on why this is failing would be highly appreciated.
```bash
InvalidArgumentError: The node 'group_deps_1' has inputs from different frames. 
The input 'map/while/input_layer/url_indicator/url_lookup/hash_table/table_init' is in frame 'map/while/while_context'. 
The input 'map_1/while/input_layer/label_indicator/label_lookup/hash_table/table_init' is in frame 'map_1/while/while_context'.`
```
**In my opinion a native (higher-level) solution to this problem is needed nonetheless!**"
17810,Dataset.list_files is impractical for large number of files,"I would like to use [`Dataset.list_files`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#list_files) on a large dataset. The dataset is similar to ImageNet in that it's a big list of images nested in subdirectories.

I originally guessed that under the hood the api would use queues to start training early, but that isn't the case - the implementation walks the entire directory tree and loads the filenames into memory before the next operation starts.

This means you can wait tens of minutes before training starts.

Two things would help here:
1) Use queues under the hood so downstream ops can start immediately
2) Allow specifying a limit, eg. `Dataset.list_files(""**/*.jpg"", limit=1000)`

The latter is mostly useful for quicker iteration. The former needs more work due to the different backends for `GetMatchingPaths`.

Is this something being worked on already?

I am using [`os.scandir()`](https://www.python.org/dev/peps/pep-0471/) as a workaround but the `Dataset.list_files()` is a more natural api for this task and should be faster due to not needing to pass the file names via `feed_dict`."
17809,Wrong object and switch ,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
17807,Failed to load the native tensorflow runtime,"this is the full stack trace
Traceback (most recent call last):
  File ""C:\Users\Skinet\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    return importlib.import_module(mname)
  File ""C:\Users\Skinet\AppData\Local\Programs\Python\Python35\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 666, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 577, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 906, in create_module
  File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed
ImportError: DLL load failed with error code -1073741795

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Skinet\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Skinet\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 21, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Skinet\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""C:\Users\Skinet\AppData\Local\Programs\Python\Python35\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<pyshell#1>"", line 1, in <module>
    import tensorflow as tf
  File ""C:\Users\Skinet\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""C:\Users\Skinet\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\Skinet\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\Skinet\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    return importlib.import_module(mname)
  File ""C:\Users\Skinet\AppData\Local\Programs\Python\Python35\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 666, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 577, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 906, in create_module
  File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed
ImportError: DLL load failed with error code -1073741795

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Skinet\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Skinet\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 21, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Skinet\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""C:\Users\Skinet\AppData\Local\Programs\Python\Python35\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: No module named '_pywrap_tensorflow_internal'


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help."
17804,How to read `feature_lists` from tfrecord.,"### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 17.10
- **TensorFlow version (use command below)**: v1.3.0-rc2-20-g0787eee 1.3.0
- **Python version**: 3.6.2
### Describe the problem
I save idex of chars to tfrecords, but i cant know how to read it.

### Source code / logs
```python
def make_example(words, chars, labels):
    # print(chars)
    ex = tf.train.SequenceExample()
    ex.context.feature[""len""].int64_list.value.append(len(words))

    for w, char_of_a_word, l in zip(words, chars, labels):
        ex.feature_lists.feature_list[""words""].feature.add().int64_list.value.append(w)
        ex.feature_lists.feature_list[""label""].feature.add().int64_list.value.append(l)

        chars_feature = ex.feature_lists.feature_list[""chars""].feature.add()
        for c in char_of_a_word:
            chars_feature.int64_list.value.append(c)

    return ex
```
`words` is a list of indexing, example: `[1, 2, 3]`
`chars` is list of character indexing, example: `[[1,2,3], [2], [2,3,4]]`

Parsing function:
```python
def _parse_function(example_proto):
    context_features = {
        ""len"": tf.FixedLenFeature((), dtype=tf.int64),
    }
    sequence_features = {
        ""words"": tf.FixedLenSequenceFeature((), dtype=tf.int64),
        ""chars"": tf.FixedLenSequenceFeature((1,35), dtype=tf.int64),
        ""label"": tf.FixedLenSequenceFeature((), dtype=tf.int64),
    }

    context_parsed, sequence_parsed = tf.parse_single_sequence_example(
        serialized=example_proto,
        context_features=context_features,
        sequence_features=sequence_features
    )

    len_ = tf.cast(context_parsed['len'], dtype=tf.int32)
    word = tf.cast(sequence_parsed['words'], dtype=tf.int32)
    chars = tf.cast(sequence_parsed['chars'], dtype=tf.int32)
    print(""word.shape"", word.shape)
    print(""chars.shape"", chars.shape)
    label = tf.cast(sequence_parsed['label'], dtype=tf.int32)

    return {""words"": word, ""chars"": chars, ""len"": len_}, label
```

Input function:
```python
def inputs(file_names, batch_size, num_epochs):
    dataset = tf.contrib.data.TFRecordDataset(file_names)
    dataset = dataset.map(_parse_function)
    dataset = dataset.padded_batch(batch_size=batch_size,
                                   padded_shapes=({""word"": [None], ""chars"": [None], ""len"": []}, [None]),
                                   padding_values=(
                                       {""word"": word_lookup.idx_of_pad,
                                        ""chars"": 0,
                                        ""len"": 0}, 0))
    # dataset = dataset.filter(lambda f, l: tf.equal(tf.shape(l)[0], batch_size))
    dataset = dataset.repeat(num_epochs)
    iterator = dataset.make_one_shot_iterator()
    features, label = iterator.get_next()
    return features, label
```

Error log:
```
Traceback (most recent call last):
  File ""/home/binhnq/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/173.4301.16/helpers/pydev/pydev_run_in_console.py"", line 53, in run_file
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File ""/home/binhnq/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/173.4301.16/helpers/pydev/_pydev_imps/_pydev_execfile.py"", line 18, in execfile
    exec(compile(contents+""\n"", file, 'exec'), glob, loc)
  File ""/home/binhnq/hitelli/pyvltk2/tfvltk/data_set.py"", line 62, in <module>
    _result = inputs_test(['/home/binhnq/hitelli/WordSegmentation/data/test-ws.tfrecords', ])
  File ""/home/binhnq/hitelli/pyvltk2/tfvltk/data_set.py"", line 55, in inputs_test
    ""features"": features}, n=1)
  File ""/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 128, in new_func
    return func(*args, **kwargs)
  File ""/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py"", line 644, in run_n
    restore_checkpoint_path=restore_checkpoint_path)
  File ""/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 128, in new_func
    return func(*args, **kwargs)
  File ""/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py"", line 702, in run_feeds
    return list(run_feeds_iter(*args, **kwargs))
  File ""/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py"", line 692, in run_feeds_iter
    yield session.run(output_dict, f)
  File ""/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 895, in run
    run_metadata_ptr)
  File ""/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1124, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1321, in _do_run
    options, run_metadata)
  File ""/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1340, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Name: , Key: chars, Index: 1.  Number of int64 values != expected.  values size: 2 but output shape: [1]
	 [[Node: ParseSingleSequenceExample/ParseSingleSequenceExample = ParseSingleSequenceExample[Ncontext_dense=1, Ncontext_sparse=0, Nfeature_list_dense=3, Nfeature_list_sparse=0, Tcontext_dense=[DT_INT64], context_dense_shapes=[[]], context_sparse_types=[], feature_list_dense_shapes=[[1], [], []], feature_list_dense_types=[DT_INT64, DT_INT64, DT_INT64], feature_list_sparse_types=[]](arg0, ParseSingleSequenceExample/ParseSingleSequenceExample/feature_list_dense_missing_assumed_empty, ParseSingleSequenceExample/ParseSingleSequenceExample/context_dense_keys_0, ParseSingleSequenceExample/ParseSingleSequenceExample/feature_list_dense_keys_0, ParseSingleSequenceExample/ParseSingleSequenceExample/feature_list_dense_keys_1, ParseSingleSequenceExample/ParseSingleSequenceExample/feature_list_dense_keys_2, ParseSingleSequenceExample/Const, ParseSingleSequenceExample/ParseSingleSequenceExample/debug_name)]]
```"
17803,tf throws some errors in estimator.train function when I droped additional column in input_fn,"
`sample_weight` is instance-based weight, which i wanted to pass to `tf.losses.sparse_softmax_cross_entropy`,  so I droped this column in the features. However, I still got some errors. If i removed the `sample_weight` column in `data_train`, it's OK !


`
train_input_fn = tf.estimator.inputs.pandas_input_fn(x=data_train, y=data_train_click, batch_size = 1024, num_epochs=1, shuffle=True)

classifier.train(input_fn=train_input_fn)  #, steps=500)

   def my_model(features, labels, mode, params):

    if 'order_weight' in features.keys():
        sample_weight = features.pop('sample_weight')

    net = tf.feature_column.input_layer(features, params['feature_columns'])

    for units in params['hidden_units']:
        net = tf.layers.dense(net, units=units, activation=params[""activation""])

    logits = tf.layers.dense(net, params['n_classes'], activation=None)

    if mode == tf.estimator.ModeKeys.PREDICT:
        predictions = {
            'probabilities': tf.nn.softmax(logits),
            'logits': logits
        }
        return tf.estimator.EstimatorSpec(mode, predictions=predictions)

    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)
    metrics_auc = tf.metrics.auc(labels=labels, predictions=tf.nn.softmax(logits)[:,1])
    metrics = {'auc': metrics_auc}          #tf.summary.scalar('auc', metrics_auc)
    if mode == tf.estimator.ModeKeys.EVAL:
        return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=metrics)

    # Create training op.
    assert mode == tf.estimator.ModeKeys.TRAIN
    optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)
    train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step()) 
    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)
`"
17802,Importing a meta graph which contains a SummaryWriter doesn't work,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 17.10
- **TensorFlow installed from (source or binary)**: binary via pip
- **TensorFlow version (use command below)**: v1.6.0-0-gd2e24b6039 1.6.0
- **Python version**: 3.6.4
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: 9.0/7.0
- **GPU model and memory**: GTX 1080ti 11G
- **Exact command to reproduce**:

First run this:

```python
import tensorflow as tf
v1 = tf.placeholder(tf.float32, name=""v1"")
v2 = tf.placeholder(tf.float32, name=""v2"")
v3 = v1 * v2
vx = tf.Variable(10.0, name=""vx"")
v4 = v3 * vx
writer = tf.contrib.summary.create_file_writer(""foo"")
saver = tf.train.Saver([vx])
sess = tf.Session()
sess.run(tf.initialize_all_variables())
sess.run(vx.assign(tf.add(vx, vx)))
result = sess.run(v4, feed_dict={v1:12.0, v2:3.3})
print(result)
saver.save(sess, ""./model_ex1"")
```

**Then in a different Python instance** (it works if done right after the first snippet within the same instance)

```python
import tensorflow as tf
saver = tf.train.import_meta_graph(""./model_ex1.meta"")
sess = tf.Session()
saver.restore(sess, ""./model_ex1"")
```


### Describe the problem

Trying to restore the meta graph via `import_meta_graph` does not work if the graph contains a SummaryWriter as shown in the example above. The example works if `import_meta_graph` is called within the same instance of Python, or if the `tf.contrib.summary.create_file_writer(""foo"")` call is removed from the graph.


### Source code / logs

```
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
<ipython-input-1-1661c33bc0e5> in <module>()
      1 import tensorflow as tf
----> 2 saver = tf.train.import_meta_graph(""./model_ex1.meta"")
      3 sess = tf.Session()
      4 saver.restore(sess, ""./model_ex1"")

~/.miniconda/lib/python3.6/site-packages/tensorflow/python/training/saver.py in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs)
   1907                                       clear_devices=clear_devices,
   1908                                       import_scope=import_scope,
-> 1909                                       **kwargs)
   1910   if meta_graph_def.HasField(""saver_def""):
   1911     return Saver(saver_def=meta_graph_def.saver_def, name=import_scope)

~/.miniconda/lib/python3.6/site-packages/tensorflow/python/framework/meta_graph.py in import_scoped_meta_graph(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate)
    735     importer.import_graph_def(
    736         input_graph_def, name=(import_scope or """"), input_map=input_map,
--> 737         producer_op_list=producer_op_list)
    738
    739     # Restores all the other collections.

~/.miniconda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)
    430                 'in a future version' if date is None else ('after %s' % date),
    431                 instructions)
--> 432       return func(*args, **kwargs)
    433     return tf_decorator.make_decorator(func, new_func, 'deprecated',
    434                                        _add_deprecated_arg_notice_to_docstring(

~/.miniconda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list)
    429   if producer_op_list is not None:
    430     # TODO(skyewm): make a copy of graph_def so we're not mutating the argument?
--> 431     _RemoveDefaultAttrs(op_dict, producer_op_list, graph_def)
    432
    433   graph = ops.get_default_graph()

~/.miniconda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py in _RemoveDefaultAttrs(op_dict, producer_op_list, graph_def)
    209     # Remove any default attr values that aren't in op_def.
    210     if node.op in producer_op_dict:
--> 211       op_def = op_dict[node.op]
    212       producer_op_def = producer_op_dict[node.op]
    213       # We make a copy of node.attr to iterate through since we may modify

KeyError: 'SummaryWriter'
```"
17801,Cannot find libdevice.10.bc under /usr/local/cuda-8.0,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04 LTS (GNU/Linux 4.4.38-rt49-tegra aarch64)
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.7.0-rc0, r1.7, master
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**: 0.11.1
- **GCC/Compiler version (if compiling from source)**: 5.4.0-6ubuntu1~16.04.9
- **CUDA/cuDNN version**: 8.0/6
- **GPU model and memory**: name: GP106 major: 6 minor: 1 totalMemory: 3.75GiB (as reported by some previous version of Tensorflow on the other part of the same Drive PX2)
- **Exact command to reproduce**:
`git checkout v1.7.0-rc0`
`./configure`
`bazel build //tensorflow:libtensorflow_cc.so`

### Describe the problem
Same problem for all branches listed under **TensorFlow version**.
Build fails immediately with
`Cuda Configuration Error: Cannot find libdevice.10.bc under /usr/local/cuda-8.0`
It's strange because I explicitly answered 8.0 versions and libdevice.10.bc exists only in 9.0 AFAIK.

### Source code / logs
[error.log](https://github.com/tensorflow/tensorflow/files/1822159/error.log)

[configure.log](https://github.com/tensorflow/tensorflow/files/1822155/configure.log)

[tf_configure.txt](https://github.com/tensorflow/tensorflow/files/1822157/tf_configure.txt)
"
17798,Count total number of nodes within a name scope,"Is there a way to count the total number of nodes within a name scope? In tensorboard, when you select a name scope, it automatically display the total number of nodes in that scope. However I can't find anything online that describes what is been used to count the total number of nodes in a scope.
"
17794,how to write the objectives function roc_auc_score in tflearn by keras,"Dear everyone,
                     I found the roc_auc_score function in  https://github.com/tflearn/tflearn/blob/master/tflearn/objectives.py. Now I want to write this function by keras. But failed. The following is the code:
```
def roc_auc_score(y_pred, y_true):
    """""" ROC AUC Score.
    Approximates the Area Under Curve score, using approximation based on
    the Wilcoxon-Mann-Whitney U statistic.
    Yan, L., Dodier, R., Mozer, M. C., & Wolniewicz, R. (2003).
    Optimizing Classifier Performance via an Approximation to the Wilcoxon-Mann-Whitney Statistic.
    Measures overall performance for a full range of threshold levels.
    Arguments:
        y_pred: `Tensor`. Predicted values.
        y_true: `Tensor` . Targets (labels), a probability distribution.
    """"""
    with tf.name_scope(""RocAucScore""):
        pos = tf.boolean_mask(y_pred, tf.cast(y_true, tf.bool))
        neg = tf.boolean_mask(y_pred, ~tf.cast(y_true, tf.bool))
        pos = tf.expand_dims(pos, 0)
        neg = tf.expand_dims(neg, 1)
        # original paper suggests performance is robust to exact parameter choice
        gamma = 0.2
        p     = 3
        difference = tf.zeros_like(pos * neg) + pos - neg - gamma
        masked = tf.boolean_mask(difference, difference < 0.0)
        return tf.reduce_sum(tf.pow(-masked, p))
```


**The new code was changed to the following:**

```
def roc_auc_score(y_pred, y_true):
    """""" ROC AUC Score.
    Approximates the Area Under Curve score, using approximation based on
    the Wilcoxon-Mann-Whitney U statistic.
    Yan, L., Dodier, R., Mozer, M. C., & Wolniewicz, R. (2003).
    Optimizing Classifier Performance via an Approximation to the Wilcoxon-Mann-Whitney Statistic.
    Measures overall performance for a full range of threshold levels.
    Arguments:
        y_pred: `Tensor`. Predicted values.
        y_true: `Tensor` . Targets (labels), a probability distribution.
    """"""
    pos = tf.boolean_mask(y_pred, K.cast(y_true, tf.bool))
    neg = tf.boolean_mask(y_pred, ~K.cast(y_true, tf.bool))
    pos = K.expand_dims(pos, 0)
    neg = K.expand_dims(neg, 1)
    # original paper suggests performance is robust to exact parameter choice
    gamma = 0.2
    p     = 3
    difference = K.zeros_like(pos * neg) + pos - neg - gamma
    masked = tf.boolean_mask(difference, difference < 0.0)
    return K.sum(K.pow(-masked, p))
```

**All the code are the following, it doesn't work,** 
 **The data in** 
https://pan.baidu.com/s/12yJCWdfvVW1tEKUfEU34RQ ,  password: nu98
```
# -*- coding: UTF-8 -*-
import os
os.environ[""CUDA_VISIBLE_DEVICES""] = ""0""
import numpy as np
from keras.models import Sequential
from keras.layers import Activation, Dropout, Flatten, Dense
from keras.preprocessing.image import ImageDataGenerator
from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D
from keras import optimizers
from keras import applications
from keras.models import Model
import keras
import numpy as np
from keras import backend as K
import tensorflow as tf


print(""---------------------------AUC----------------------------------------"")


# def roc_auc_score(y_pred, y_true):
#     """""" ROC AUC Score.
#     Approximates the Area Under Curve score, using approximation based on
#     the Wilcoxon-Mann-Whitney U statistic.
#     Yan, L., Dodier, R., Mozer, M. C., & Wolniewicz, R. (2003).
#     Optimizing Classifier Performance via an Approximation to the Wilcoxon-Mann-Whitney Statistic.
#     Measures overall performance for a full range of threshold levels.
#     Arguments:
#         y_pred: `Tensor`. Predicted values.
#         y_true: `Tensor` . Targets (labels), a probability distribution.
#     """"""
#     with tf.name_scope(""RocAucScore""):

#         pos = tf.boolean_mask(y_pred, tf.cast(y_true, tf.bool))
#         neg = tf.boolean_mask(y_pred, ~tf.cast(y_true, tf.bool))

#         pos = tf.expand_dims(pos, 0)
#         neg = tf.expand_dims(neg, 1)

#         # original paper suggests performance is robust to exact parameter choice
#         gamma = 0.2
#         p     = 3

#         difference = tf.zeros_like(pos * neg) + pos - neg - gamma

#         masked = tf.boolean_mask(difference, difference < 0.0)

#         return tf.reduce_sum(tf.pow(-masked, p))



def roc_auc_score(y_pred, y_true):
    """""" ROC AUC Score.
    Approximates the Area Under Curve score, using approximation based on
    the Wilcoxon-Mann-Whitney U statistic.
    Yan, L., Dodier, R., Mozer, M. C., & Wolniewicz, R. (2003).
    Optimizing Classifier Performance via an Approximation to the Wilcoxon-Mann-Whitney Statistic.
    Measures overall performance for a full range of threshold levels.
    Arguments:
        y_pred: `Tensor`. Predicted values.
        y_true: `Tensor` . Targets (labels), a probability distribution.
    """"""
    pos = tf.boolean_mask(y_pred, K.cast(y_true, tf.bool))
    neg = tf.boolean_mask(y_pred, ~K.cast(y_true, tf.bool))
    pos = K.expand_dims(pos, 0)
    neg = K.expand_dims(neg, 1)
    # original paper suggests performance is robust to exact parameter choice
    gamma = 0.2
    p     = 3
    difference = K.zeros_like(pos * neg) + pos - neg - gamma
    masked = tf.boolean_mask(difference, difference < 0.0)
    return K.sum(K.pow(-masked, p))

def roc_auc_score_loss(y_true, y_pred):
    return roc_auc_score(y_true, y_pred)
print(""---------------------------AUC----------------------------------------"")


# dimensions of our images.
img_width, img_height = 512, 512

train_data_dir = 'data/train/'
validation_data_dir = 'data/validation/'


##preprocessing
# used to rescale the pixel values from [0, 255] to [0, 1] interval
datagen = ImageDataGenerator(rescale=1./255)
batch_size = 32

# automagically retrieve images and their classes for train and validation sets
train_generator = datagen.flow_from_directory(
        train_data_dir,
        target_size=(img_width, img_height),
        batch_size=batch_size,
        class_mode='binary')

validation_generator = datagen.flow_from_directory(
        validation_data_dir,
        target_size=(img_width, img_height),
        batch_size=batch_size,
        class_mode='binary',shuffle=False)



# a simple stack of 3 convolution layers with a ReLU activation and followed by max-pooling layers.
model = Sequential()
model.add(Convolution2D(32, (3, 3), input_shape=(img_width, img_height,3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Convolution2D(32, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Convolution2D(64, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Flatten())
model.add(Dense(64))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(1))
model.add(Activation('sigmoid'))

# model.compile(loss='binary_crossentropy',
#               optimizer='rmsprop',
#               metrics=['accuracy','mae'])

model.compile(loss=roc_auc_score_loss,
              optimizer='rmsprop',
              metrics=['accuracy','mae',roc_auc_score])
epochs = 5

train_samples = 2048
validation_samples = 832


model.fit_generator(
        train_generator,
        steps_per_epoch=train_samples // batch_size,
        epochs=epochs,
        validation_data=validation_generator,
        validation_steps=validation_samples// batch_size)

model.save_weights('models/basic_cnn_30_epochs.h5')
print(model.summary())


```
**The problem is the following :**+1: 
ValueError                                Traceback (most recent call last)
<ipython-input-3-cc3e34fe5d20> in <module>()
    149         epochs=epochs,
    150         validation_data=validation_generator,
--> 151         validation_steps=validation_samples// batch_size)
    152 
    153 model.save_weights('models/basic_cnn_30_epochs.h5')

/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.pyc in wrapper(*args, **kwargs)
     85                 warnings.warn('Update your `' + object_name +
     86                               '` call to the Keras 2 API: ' + signature, stacklevel=2)
---> 87             return func(*args, **kwargs)
     88         wrapper._original_function = func
     89         return wrapper

/usr/local/lib/python2.7/dist-packages/keras/models.pyc in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, initial_epoch)
   1119                                         workers=workers,
   1120                                         use_multiprocessing=use_multiprocessing,
-> 1121                                         initial_epoch=initial_epoch)
   1122 
   1123     @interfaces.legacy_generator_methods_support

/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.pyc in wrapper(*args, **kwargs)
     85                 warnings.warn('Update your `' + object_name +
     86                               '` call to the Keras 2 API: ' + signature, stacklevel=2)
---> 87             return func(*args, **kwargs)
     88         wrapper._original_function = func
     89         return wrapper

/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)
   1924 
   1925         do_validation = bool(validation_data)
-> 1926         self._make_train_function()
   1927         if do_validation:
   1928             self._make_test_function()

/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc in _make_train_function(self)
    958                     training_updates = self.optimizer.get_updates(
    959                         params=self._collected_trainable_weights,
--> 960                         loss=self.total_loss)
    961                 updates = self.updates + training_updates
    962                 # Gets loss and metrics. Updates weights at each call.

/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.pyc in wrapper(*args, **kwargs)
     85                 warnings.warn('Update your `' + object_name +
     86                               '` call to the Keras 2 API: ' + signature, stacklevel=2)
---> 87             return func(*args, **kwargs)
     88         wrapper._original_function = func
     89         return wrapper

/usr/local/lib/python2.7/dist-packages/keras/optimizers.pyc in get_updates(self, loss, params)
    235         for p, g, a in zip(params, grads, accumulators):
    236             # update accumulator
--> 237             new_a = self.rho * a + (1. - self.rho) * K.square(g)
    238             self.updates.append(K.update(a, new_a))
    239             new_p = p - lr * g / (K.sqrt(new_a) + self.epsilon)

/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc in square(x)
   1356         A tensor.
   1357     """"""
-> 1358     return tf.square(x)
   1359 
   1360 

/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.pyc in square(x, name)
    447           indices=x.indices, values=x_square, dense_shape=x.dense_shape)
    448     else:
--> 449       return gen_math_ops.square(x, name=name)
    450 
    451 

/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.pyc in square(x, name)
   4565   if _ctx.in_graph_mode():
   4566     _, _, _op = _op_def_lib._apply_op_helper(
-> 4567         ""Square"", x=x, name=name)
   4568     _result = _op.outputs[:]
   4569     _inputs_flat = _op.inputs

/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.pyc in _apply_op_helper(self, op_type_name, name, **keywords)
    526               raise ValueError(
    527                   ""Tried to convert '%s' to a tensor and failed. Error: %s"" %
--> 528                   (input_name, err))
    529             prefix = (""Input '%s' of '%s' Op has type %s that does not match"" %
    530                       (input_name, op_type_name, observed))

ValueError: Tried to convert 'x' to a tensor and failed. Error: None values not supported.

Finally, Anyone can check this problem. Looking forward to reply. Thanks advanced!
### System information
Operating System: Ubuntu 16.04 LTS
Graphics card: Tesla K40
Installed version of CUDA: 8.0 
Installed version of cuDNN: v5 , for CUDA 8.0 
pip --version 9.0.1
pip 9.0.1 from /usr/local/lib/python2.7/dist-packages (python 2.7)
pip install tensorflow-gpu
Name: tensorflow-gpu, Version: 1.4.1"
17793,unable to find libcuda.so,"I can use  tensorflow to program, but have a problem: 

***
2018-03-17 17:33:18.848935: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: Not found: **was unable to find libcuda.so DSO loaded into this program**
***

I can see my GPU by using `nvidia-smi`.

Anyone can help me to solve this ?
Thanks !
"
17792,optimizer.apply_gradients fails inside tfe.defun,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: colab
- **TensorFlow installed from (source or binary)**: colab
- **TensorFlow version (use command below)**: `unknown 1.6.0`
- **Python version**: 3.6.3
- **Exact command to reproduce**: Colab: https://drive.google.com/file/d/1zj9IMWKF58TuEQRKt9DpETr24Z1sy9z0/view?usp=sharing

### Describe the problem
`optimizer.apply_gradients` doesn't seem to work inside eager mode's `tfe.defun`.  The colab contains full details, but the relevant part of the exception is

    /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/optimizer.py in _get_processor(v)
        180   if context.in_eager_mode():
        181     return _DenseResourceVariableProcessor(v)
    --> 182   if v.op.type == ""VarHandleOp"":
        183     return _DenseResourceVariableProcessor(v)
        184   if isinstance(v, variables.Variable):
    
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py in op(self)
        601   def op(self):
        602     """"""The op for this variable.""""""
    --> 603     return self._handle.op
        604 
        605   def eval(self, session=None):
    
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in op(self)
        836   @property
        837   def op(self):
    --> 838     raise AttributeError(""op not supported for Eager Tensors."")
        839 
        840   @property
    
    AttributeError: op not supported for Eager Tensors.

The problem is presumably that `optimizer.py`'s eager mode logic is disabled by defun's graph mode.

### Source code / logs
Reproducing colab: https://drive.google.com/file/d/1zj9IMWKF58TuEQRKt9DpETr24Z1sy9z0/view?usp=sharing"
17791,TensorFlowInferenceInterface.feed() fails to accept multi-dimensional input,"### Describe the problem

My understanding is that `TensorFlowInferenceInterface.feed()` takes a 1D float array `float[]` as input.

### Source code / logs

```java
float[] floatValues;
TensorFlowInferenceInterface inferenceInterface;
int inputSize;
String inputName;
...
inferenceInterface.feed(inputName, floatValues, 1, inputSize, inputSize, 3);
```
"
17790,Raspbian 9 (Stretch): Failed to load native TensorFlow runtime,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No. Simply calling ""import tensorflow"" already crashes.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Raspbian GNU/Linux 9 (Stretch)
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: TensorFlow 1.6.0
- **Python version**: Python 3.5.3
- **Bazel version (if compiling from source)**: Bazel 0.11.1
- **GCC/Compiler version (if compiling from source)**: GCC 6.3.0 20170124
- **CUDA/cuDNN version**: I didn't install with CUDA support
- **GPU model and memory**: n/a
- **Exact command to reproduce**: ""import tensorflow"" in the Python environment

### Describe the problem
I built TensorFlow on Raspbian Linux for the Raspberry Pi 3 Model B. The problem is that when I try to import it in Python, the program instantly crashes, saying: ""Failed to load native TensorFlow runtime."" The full traceback is below.

### Source code / logs
Only need to call ""import tensorflow"" on Python3 to reproduce the traceback below:

```
Traceback (most recent call last): File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in from tensorflow.python.pywrap_tensorflow_internal import * File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in _pywrap_tensorflow_internal = swig_import_helper() File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description) File ""/usr/lib/python3.5/imp.py"", line 242, in load_module return load_dynamic(name, filename, file) File ""/usr/lib/python3.5/imp.py"", line 342, in load_dynamic return _load(spec) ImportError: /usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZN10tensorflow9ConcatCPUINS_8bfloat16EEEvPNS_10DeviceBaseERKSt6vectorISt10unique_ptrINS_6TTypesIT_Li2EiE11ConstMatrixESt14default_deleteIS9_EESaISC_EEPNS8_6MatrixE
```

During handling of the above exception, another exception occurred:

```
Traceback (most recent call last): File ""idex.py"", line 1, in import gui File ""/home/pi/Desktop/IDEX/scripts/gui.py"", line 10, in import fun_util File ""signlang/fun_util.py"", line 3, in import tensorflow as tf File ""/usr/local/lib/python3.5/dist-packages/tensorflow/init.py"", line 24, in from tensorflow.python import * # pylint: disable=redefined-builtin File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/init.py"", line 49, in from tensorflow.python import pywrap_tensorflow File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in raise ImportError(msg) ImportError: Traceback (most recent call last): File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in from tensorflow.python.pywrap_tensorflow_internal import * File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in _pywrap_tensorflow_internal = swig_import_helper() File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description) File ""/usr/lib/python3.5/imp.py"", line 242, in load_module return load_dynamic(name, filename, file) File ""/usr/lib/python3.5/imp.py"", line 342, in load_dynamic return _load(spec) ImportError: /usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZN10tensorflow9ConcatCPUINS_8bfloat16EEEvPNS_10DeviceBaseERKSt6vectorISt10unique_ptrINS_6TTypesIT_Li2EiE11ConstMatrixESt14default_deleteIS9_EESaISC_EEPNS8_6MatrixE

Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions. Include the entire stack trace above this error message when asking for help.
```"
17789,Could not find a version that satisfies the requirement numpy>=1.13.3 (from tensorflow) ,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
17787,Manual Build libhexagon_controller.so Failed,"Hi , I follow steps in https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/hvx README.md to build manually tensorflow with Hexagon support .

step Calling ""make tree VERBOSE=1 V=android_Release"" in section ""_Build libhexagon_controller.so_""
causing :

```
/home/Qualcomm/Hexagon_SDK/3.3.3/build/make.d/rules.min:362: START
/home/Qualcomm/Hexagon_SDK/3.3.3/build/make.d/rules.min:363: DEPS=/home/dnozik/Qualcomm/Hexagon_SDK/3.3.3/libs/common/rpcmem/android_Release/ship/rpcmem.a adspmsgd.a /home/dnozik/Qualcomm/Hexagon_SDK/3.3.3/libs/common/remote/ship/android_Release/libadsprpc.so
/home/Qualcomm/Hexagon_SDK/3.3.3/build/make.d/rules.min:364: END
/home/Qualcomm/Hexagon_SDK/3.3.3/build/make.d/rules.min:581: QEXE_EXEC: 
/home/Qualcomm/Hexagon_SDK/3.3.3/build/make.d/rules.min:698: LD_INPUTS: -Wl,--start-group  -Wl,--end-group -L/home/Qualcomm/Hexagon_SDK/3.3.3/tools/android-ndk-r14b/platforms/android-21/arch-arm/usr/lib -lm -lstdc++ -lc  -lgcc
/home/Qualcomm/Hexagon_SDK/3.3.3/build/make.d/rules.min:704: LD_INPUTS: -Wl,--start-group  -Wl,--end-group -L/home/dnozik/Qualcomm/Hexagon_SDK/3.3.3/tools/android-ndk-r14b/platforms/android-21/arch-arm/usr/lib -lm -lstdc++ -lc  -lgcc
/home/Qualcomm/Hexagon_SDK/3.3.3/tools/android-ndk-r14b/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/bin/arm-linux-androideabi-gcc -mthumb  -c -fpie -fpic -fPIE -fPIC -pie -Wall -Wno-missing-braces -mword-relocations -mthumb-interwork -march=armv7-a -Werror -O2 -fno-strict-aliasing -isystem /home/dnozik/Qualcomm/Hexagon_SDK/3.3.3/tools/android-ndk-r14b/platforms/android-21/arch-arm/usr/include -D_ANDROID_ -DANDROID -std=gnu99           -D__FILENAME__=\""hexagon_controller.c\""  -I../../../libs/common/adspmsgd/ship/android_Release -Isrc_impl/include -Isrc_log/include -Isrc_soc_interface/include -I/home/Qualcomm/Hexagon_SDK/3.3.3/libs/common/adspmsgd/ship/android_Release -I/home/dnozik/Qualcomm/Hexagon_SDK/3.3.3/libs/fastcv/dspCV/android_Release/ship -I/home/dnozik/Qualcomm/Hexagon_SDK/3.3.3/incs -I/home/Qualcomm/Hexagon_SDK/3.3.3/libs/common/remote/ship/android_Release -I/home/Qualcomm/Hexagon_SDK/3.3.3/incs/stddef -I/home/Qualcomm/Hexagon_SDK/3.3.3/libs/common/rpcmem/android_Release/ship -Iandroid_Release  -oandroid_Release/hexagon_controller.o src_impl/hexagon_controller.c
src_impl/hexagon_controller.c:25:22: fatal error: adspmsgd.h: No such file or directory
 #include ""adspmsgd.h""
                      ^
compilation terminated
```.


### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 16
- **TensorFlow installed from (source or binary)**:
Master from GitHub
- **TensorFlow version (use command below)**:
- **Python version**: 
2.7
- **Bazel version (if compiling from source)**:
1.10
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
No
- **GPU model and memory**:
No
- **Exact command to reproduce**:


Thanks for help.
"
17784,tensorflow.python.framework.errors_impl.InvalidArgumentError,"### System information

-    Have I written custom code: Yes
-    OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
-   TensorFlow installed from (source or binary): pip
-    TensorFlow version (use command below): 1.6.0
- Bazel version: Build label: 0.11.1
- CUDA/cuDNN version: 9.0
- GPU model and memory:

```
== nvidia-smi ===================================================
Sun Mar 18 02:30:17 2018
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 390.30                 Driver Version: 390.30                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Quadro P400         Off  | 00000000:01:00.0 Off |                  N/A |
| 34%   35C    P0    N/A /  N/A |     35MiB /  1999MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Quadro GP100        Off  | 00000000:02:00.0 Off |                  Off |
| 26%   42C    P0    35W / 235W |  15483MiB / 16278MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
```


### Describe the problem

How can I use `tf.scatter_update` with `tf.bool`  in the eager mode?


```
tensorflow.python.framework.errors_impl.InvalidArgumentError: Value for attr 'dtype' of bool is not in the list of allowed values: float, double, int32, uint8, int16, int8, complex64, int64, qint8, quint8, qint32, bfloat16, uint16, complex128, half, uint32, uint64
	; NodeDef: ResourceScatterUpdate = ResourceScatterUpdate[Tindices=DT_INT32, dtype=DT_BOOL](dummy_input, dummy_input, dummy_input); Op<name=ResourceScatterUpdate; signature=resource:resource, indices:Tindices, updates:dtype -> ; attr=dtype:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, ..., DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; is_stateful=true> [Op:ResourceScatterUpdate]
```

### Source code / logs

```python
from tensorflow.contrib.eager.python import tfe
import tensorflow as tf


def main(_):
	ref = tfe.Variable([False, True, False], trainable=False)
	indices = tf.range(3)
	updates = tf.constant([True, True, True])
	_update = tf.scatter_update(ref, indices, updates)


if __name__ == '__main__':
	tfe.enable_eager_execution()
	tf.app.run()
```

"
17783,Segmentation fault in Eigen::internal::InnerMostDimReducer<...>::reduce when passing large tensor to sparse_softmax_cross_entropy_with_logits,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: I have written custom code. A simple reproduction script is included below.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04 (also occurring on Linux Ubuntu 14.04)
- **TensorFlow installed from (source or binary)**: TensorFlow installed from binary (also occurring after building from source)
- **TensorFlow version (use command below)**: TensorFlow v1.6 (also occurring on v1.4, v1.5, v1.7rc0)
- **Python version**: Python 2.7 (Ubuntu base and also occurring on Anaconda Python 2.7)
- **Bazel version (if compiling from source)**: Bazel version: 0.11.1
- **GCC/Compiler version (if compiling from source)**: GCC 4.9.4
- **CUDA/cuDNN version**: CUDA not used, CPU only
- **GPU model and memory**: GPU not used, CPU only (Intel(R) Xeon(R) CPU E5-2650 and Intel(R) Xeon(R) Platinum 8175M)
- **Exact command to reproduce**: Command to reproduce using script given below: ""python sfi.py 300000""

### Describe the problem
A segmentation fault is occurring with the following gdb backtrace when a ""logits"" tensor of sufficient size is passed to `sparse_softmax_cross_entropy_with_logits`. The single argument to the demonstration code below adjusts the size. I have found that there is a point below which the SegFault does not seem to ever occur and above which the SegFault always seems to occur, but around that point (e.g. within +/- 2) the SegFault behaviour is intermittent. Right on the change point I can run the same code with the same argument and it will sometimes generate a SegFault and sometimes not (though the random data generated in the demo code may be causing this randomness).

```
Program received signal SIGSEGV, Segmentation fault.
[Switching to Thread 0x7fffcdffb700 (LWP 2440)]
0x00007fffef12a590 in Eigen::internal::InnerMostDimReducer<Eigen::TensorEvaluator<Eigen::TensorReductionOp<Eigen::internal::MaxReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const, Eigen::MakePointer> const, Eigen::ThreadPoolDevice>, Eigen::internal::MaxReducer<float>, true>::reduce(Eigen::TensorEvaluator<Eigen::TensorReductionOp<Eigen::internal::MaxReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const, Eigen::MakePointer> const, Eigen::ThreadPoolDevice> const&, int, int, Eigen::internal::MaxReducer<float>&) ()
   from <home_dir>/.conda/envs/research/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
(gdb) bt
#0  0x00007fffef12a590 in Eigen::internal::InnerMostDimReducer<Eigen::TensorEvaluator<Eigen::TensorReductionOp<Eigen::internal::MaxReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const, Eigen::MakePointer> const, Eigen::ThreadPoolDevice>, Eigen::internal::MaxReducer<float>, true>::reduce(Eigen::TensorEvaluator<Eigen::TensorReductionOp<Eigen::internal::MaxReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const, Eigen::MakePointer> const, Eigen::ThreadPoolDevice> const&, int, int, Eigen::internal::MaxReducer<float>&) ()
   from <home_dir>/.conda/envs/research/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#1  0x00007fffef12a90f in Eigen::internal::EvalRange<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorReductionOp<Eigen::internal::MaxReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>, int, true>::run(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorReductionOp<Eigen::internal::MaxReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>*, int, int) () from <home_dir>/.conda/envs/research/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#2  0x00007fffedcd5541 in Eigen::ThreadPoolDevice::parallelFor(long, Eigen::TensorOpCost const&, std::function<long (long)>, std::function<void (long, long)>) const::{lambda(long, long)#1}::operator()(long, long) const () from <home_dir>/.conda/envs/research/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#3  0x00007fffedcd5511 in Eigen::ThreadPoolDevice::parallelFor(long, Eigen::TensorOpCost const&, std::function<long (long)>, std::function<void (long, long)>) const::{lambda(long, long)#1}::operator()(long, long) const () from <home_dir>/.conda/envs/research/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#4  0x00007fffedcd5511 in Eigen::ThreadPoolDevice::parallelFor(long, Eigen::TensorOpCost const&, std::function<long (long)>, std::function<void (long, long)>) const::{lambda(long, long)#1}::operator()(long, long) const () from <home_dir>/.conda/envs/research/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#5  0x00007fffedcd5511 in Eigen::ThreadPoolDevice::parallelFor(long, Eigen::TensorOpCost const&, std::function<long (long)>, std::function<void (long, long)>) const::{lambda(long, long)#1}::operator()(long, long) const () from <home_dir>/.conda/envs/research/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#6  0x00007fffedcd5511 in Eigen::ThreadPoolDevice::parallelFor(long, Eigen::TensorOpCost const&, std::function<long (long)>, std::function<void (long, long)>) const::{lambda(long, long)#1}::operator()(long, long) const () from <home_dir>/.conda/envs/research/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#7  0x00007fffedcd5511 in Eigen::ThreadPoolDevice::parallelFor(long, Eigen::TensorOpCost const&, std::function<long (long)>, std::function<void (long, long)>) const::{lambda(long, long)#1}::operator()(long, long) const () from <home_dir>/.conda/envs/research/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#8  0x00007fffedcd5511 in Eigen::ThreadPoolDevice::parallelFor(long, Eigen::TensorOpCost const&, std::function<long (long)>, std::function<void (long, long)>) const::{lambda(long, long)#1}::operator()(long, long) const () from <home_dir>/.conda/envs/research/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#9  0x00007fffedcd5511 in Eigen::ThreadPoolDevice::parallelFor(long, Eigen::TensorOpCost const&, std::function<long (long)>, std::function<void (long, long)>) const::{lambda(long, long)#1}::operator()(long, long) const () from <home_dir>/.conda/envs/research/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#10 0x00007fffebcecb70 in Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) ()
   from <home_dir>/.conda/envs/research/lib/python2.7/site-packages/tensorflow/python/../libtensorflow_framework.so
#11 0x00007fffebceb8e2 in std::_Function_handler<void (), tensorflow::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&) ()
   from <home_dir>/.conda/envs/research/lib/python2.7/site-packages/tensorflow/python/../libtensorflow_framework.so
#12 0x00007fffe20355b0 in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6
#13 0x00007ffff77e7184 in start_thread (arg=0x7fffcdffb700) at pthread_create.c:312
#14 0x00007ffff6e0703d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:111
```

The problem occurs in all of these configurations:

- Binary CPU-only install of TF: v1.4, v1.5, v1.6, and v1.7
- Build from source code: v1.6, v1.7
- Building with MKL and without MKL
- Ubuntu Python and Anaconda Python (but only Python 2.7 in both cases)
- In clean virtual/conda envs with only the minimum TF dependencies installed

### Source code / logs

I've been able to distil the problem down to the following code which reliably reproduces the problem for me on my local hardware and also on a m5.2xlarge EC2 instance running Ubuntu 16.04 Server or Amazon Linux. The following code has no external data or code dependencies other than tensorflow.

The script has a single argument which sets the ""vocabulary size"" (this was originally an RNN LM); if this value is large enough a SegFault occurs. The only operation of note is the `sparse_softmax_cross_entropy_with_logits`.

```
#!/usr/bin/env python
from __future__ import absolute_import, division, print_function, unicode_literals
import sys
import tensorflow as tf

def main():
    vocabulary_size = int(sys.argv[1])
    batch_size = 256
    step_size = 32

    print(""Vocabulary size:"", vocabulary_size)

    labels = tf.get_variable(""labels"", shape=[batch_size, step_size], dtype=tf.int32)
    logits = tf.get_variable(""logits"", shape=[batch_size, step_size, vocabulary_size])
    costs = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits)

    with tf.Session() as session:
        session.run(tf.global_variables_initializer())

        print(""Executing..."")
        session.run(costs)
        print(""SUCCESS!"")


if __name__ == ""__main__"":
    main()
```
"
17782,Compatible to 9.1 now?,"Hi there,

as in the release notes said, it is compatible to 9.0, and you said you are going to fix the bug till Februray 2018. 

So is tf now compatible to CUDA9.1?"
17778,Bad_alloc when building standalone project in Debug,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: Most recent, pulled from github
- **GCC/Compiler version (if compiling from source)**: VS 2015
- **CUDA/cuDNN version**: CPU Only
- **Bazel version**:  NA
- **GPU model and memory**:  NA
- **Exact command to reproduce**: Practically any  tensorflow command in debug

I have a large project (C++) that uses a CNN for a small part of the code. I have built tensorflow from sources as a shared library using the cmake instructions. I have linked against this built library and integrated it in our code. The project uses QTCreator and Qmake.

In currently works perfect in Release mode, however as it is a larger project there is needs to occasionally build in debug. When doing a debug build I get an exception thrown on basically the first instance of tensorflow (currently a call to ReadBinaryProto). If you comment that line out it will break on the next tensorflow call.

I have built a standalone project in visual studio 2015 that isolates the tensorflow part of the project and it behaves exactly the same way.

The exception is Microsoft C++ exception: std::bad_alloc at memory location 0x00000071F8AFC730.

I know there is no supported way to build a debug version of the library, but I need to use this library like this. I have no pressing need to debug tensorflow related code just the rest of it.

Thank you

"
17777,Should this error message be a bracket instead of parentheses ?,"> Received a label value of 1 which is outside the valid range of [0, 1).

Am I reading it wrong? or it should be `[0, 1]` insteado fo `[0, 1)` ?

https://github.com/tensorflow/tensorflow/blob/982549ea3423df4270ff154e5c764beb43d472da/tensorflow/core/kernels/sparse_xent_op.cc#L45"
17778,Bad_alloc when building standalone project in Debug,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: Most recent, pulled from github
- **GCC/Compiler version (if compiling from source)**: VS 2015
- **CUDA/cuDNN version**: CPU Only
- **Bazel version**:  NA
- **GPU model and memory**:  NA
- **Exact command to reproduce**: Practically any  tensorflow command in debug

I have a large project (C++) that uses a CNN for a small part of the code. I have built tensorflow from sources as a shared library using the cmake instructions. I have linked against this built library and integrated it in our code. The project uses QTCreator and Qmake.

In currently works perfect in Release mode, however as it is a larger project there is needs to occasionally build in debug. When doing a debug build I get an exception thrown on basically the first instance of tensorflow (currently a call to ReadBinaryProto). If you comment that line out it will break on the next tensorflow call.

I have built a standalone project in visual studio 2015 that isolates the tensorflow part of the project and it behaves exactly the same way.

The exception is Microsoft C++ exception: std::bad_alloc at memory location 0x00000071F8AFC730.

I know there is no supported way to build a debug version of the library, but I need to use this library like this. I have no pressing need to debug tensorflow related code just the rest of it.

Thank you

"
17777,Should this error message be a bracket instead of parentheses ?,"> Received a label value of 1 which is outside the valid range of [0, 1).

Am I reading it wrong? or it should be `[0, 1]` insteado fo `[0, 1)` ?

https://github.com/tensorflow/tensorflow/blob/982549ea3423df4270ff154e5c764beb43d472da/tensorflow/core/kernels/sparse_xent_op.cc#L45"
17771,"TypeError: Expected binary or unicode string, got None.  who can help me,thanks..","this is code:
# coding=utf-8
import tensorflow as tf
from PIL import Image
import matplotlib.pyplot as plt
import input_data
import numpy as np
import model
import os
from skimage import io


def get_one_image(train):
    files = os.listdir (train)
    n = len (files)
    ind = np.random.randint (0, n)
    img_dir = os.path.join (train, files[ind])
    image = io.imread (img_dir,as_grey=True)
    plt.imshow (image,cmap ='gray')
    plt.show ()
    image = image.resize ([50, 50,1])
    image = np.asarray (image)
    return image


def evaluate_one_image():
    train = './tst/'

    image_array = get_one_image (train)

    with tf.Graph ().as_default ():
        BATCH_SIZE = 1  
        N_CLASSES = 2  

        image = tf.cast (image_array, tf.float32)

        image = tf.image.per_image_standardization (image)

        image = tf.reshape (image, [1,50, 50,1])
        logit = model.inference (image, BATCH_SIZE, N_CLASSES)

        logit = tf.nn.softmax (logit)

        x = tf.placeholder (tf.float32, shape=[50, 50,1])


        logs_train_dir = './save/'

        saver = tf.train.Saver ()

        with tf.Session () as sess:

            print (""从指定的路径中加载模型。。。。"")

            ckpt = tf.train.get_checkpoint_state (logs_train_dir)
            if ckpt and ckpt.model_checkpoint_path:
                global_step = ckpt.model_checkpoint_path.split ('/')[-1].split ('-')[-1]
                saver.restore (sess, ckpt.model_checkpoint_path)
                print ('模型加载成功, 训练的步数为 %s' % global_step)
            else:
                print ('模型加载失败，，，文件没有找到')
                # 将图片输入到模型计算
            prediction = sess.run (logit, feed_dict={x: image_array})
            # 获取输出结果中最大概率的索引
            max_index = np.argmax (prediction)
            if max_index == 0:
                print ('猫的概率 %.6f' % prediction[:, 0])
            else:
                print ('狗的概率 %.6f' % prediction[:, 1])

evaluate_one_image ()
"
17770,"TypeError: Expected binary or unicode string, got None","Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
17769,SSD Resnet50 FPN ValueError: Dimensions must be equal,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: custom .config file, see below
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.7-rc0 and also tried on 1.6
- **Python version**: Tried 2.7 and 3.5
- **Bazel version (if compiling from source)**: 0.11.1
- **GCC/Compiler version (if compiling from source)**: gcc (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609
- **CUDA/cuDNN version**: 8.0 / 6.0
- **GPU model and memory**: GeForce GTX 1060 6GB
- **Exact command to reproduce**: 
```
python3 object_detection/train.py \
    --pipeline_config_path=object_detection/samples/ssd_resnet_50_fpn_drone.config \
    --train_dir=object_detection/drone \
    --num_clones=1
```

When I'm trying to run test FPN config from model_builder_test.py (see attach), I'm getting error:
```
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Use the retry module or similar alternatives.
WARNING:tensorflow:From /home/undead/reps/tf_models/object_detection/trainer.py:228: create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.create_global_step
Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/common_shapes.py"", line 686, in _call_cpp_shape_fn_impl
    input_tensors_as_shapes, status)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py"", line 516, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: Dimensions must be equal, but are 6 and 5 for 'FeatureExtractor/fpn/top_down_features/add' (op: 'Add') with input shapes: [4,6,6,256], [4,5,5,256].

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""object_detection/train.py"", line 167, in <module>
    tf.app.run()
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py"", line 126, in run
    _sys.exit(main(argv))
  File ""object_detection/train.py"", line 163, in main
    worker_job_name, is_chief, FLAGS.train_dir)
  File ""/home/undead/reps/tf_models/object_detection/trainer.py"", line 246, in train
    clones = model_deploy.create_clones(deploy_config, model_fn, [input_queue])
  File ""/home/undead/reps/tf_models/slim/deployment/model_deploy.py"", line 193, in create_clones
    outputs = model_fn(*args, **kwargs)
  File ""/home/undead/reps/tf_models/object_detection/trainer.py"", line 179, in _create_losses
    prediction_dict = detection_model.predict(images, true_image_shapes)
  File ""/home/undead/reps/tf_models/object_detection/meta_architectures/ssd_meta_arch.py"", line 350, in predict
    preprocessed_inputs)
  File ""/home/undead/reps/tf_models/object_detection/models/ssd_resnet_v1_fpn_feature_extractor.py"", line 164, in extract_features
    scope='top_down_features')
  File ""/home/undead/reps/tf_models/object_detection/models/feature_map_generators.py"", line 217, in fpn_top_down_feature_maps
    top_down = 0.5 * top_down + 0.5 * residual
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py"", line 971, in binary_op_wrapper
    return func(x, y, name=name)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_math_ops.py"", line 296, in add
    ""Add"", x=x, y=y, name=name)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py"", line 3292, in create_op
    compute_device=compute_device)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py"", line 3332, in _create_op_helper
    set_shapes_for_outputs(op)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py"", line 2496, in set_shapes_for_outputs
    return _set_shapes_for_outputs(op)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py"", line 2469, in _set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py"", line 2399, in call_with_requiring
    return call_cpp_shape_fn(op, require_shape_fn=True)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/common_shapes.py"", line 627, in call_cpp_shape_fn
    require_shape_fn)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/common_shapes.py"", line 691, in _call_cpp_shape_fn_impl
    raise ValueError(err.message)
ValueError: Dimensions must be equal, but are 6 and 5 for 'FeatureExtractor/fpn/top_down_features/add' (op: 'Add') with input shapes: [4,6,6,256], [4,5,5,256].
```
model_builder_test.py and ssd_resnet_v1_fpn_feature_extractor_test.py passes on Python2.7.
Tried TF 1.6 and 1.7, Python 2.7 and 3.5, tried different input resolutions. All the same. Seems like a bug.

[ssd_resnet_50_fpn_drone.config.zip](https://github.com/tensorflow/tensorflow/files/1819317/ssd_resnet_50_fpn_drone.config.zip)

"
17768,How to update columns in tf.Values,"OS Platform and Distribution: windows 10
TensorFlow installed from: anconda
TensorFlow version: tensorflow-gpu 1.1.0
Bazel version: N/A
CUDA/cuDNN version: 8
GPU model and memory: GTX860m 2GB
Exact command to reproduce: N/A

I use tf.scatter_nd_update() method to update lines, but I not find any method to update columns. So I was wondering whether has a convenient way to update columns? 

For example, data=tf.Values(tf.zeros([10,100])), and I want to update data with ""data[:,0]=tf.ones([10])"" or other methods like tf.scatter_nd_update.

I will appreciate it if anyone can help me!"
17765,how to set sample weight  for binary classfication,"I Know `tf.losses.sparse_softmax_cross_entropy` could set weights for different samples, But I don not know how to use it in my_custom_model

for example, in the ctr predicition, I want set 10 weights for the order samples, and the weight of click samples and the unclick sample is still 1.

Here is my unweighted code

`

def my_custom_model(features, labels, mode, params):

    net = tf.feature_column.input_layer(features, params['feature_columns'])

    for units in params['hidden_units']:
        net = tf.layers.dense(net, units=units, activation=params[""activation""])  

    logits = tf.layers.dense(net, params['n_classes'], activation=None)

    if mode == tf.estimator.ModeKeys.PREDICT:
        predictions = {
            'probabilities': tf.nn.softmax(logits),
            'logits': logits,
       }
       return tf.estimator.EstimatorSpec(mode, predictions=predictions)

    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)

    metrics = {'auc': tf.metrics.auc(labels=labels, predictions=tf.nn.softmax(logits)[:,1])}

    if mode == tf.estimator.ModeKeys.EVAL:
        return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=metrics)

    assert mode == tf.estimator.ModeKeys.TRAIN
    optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)
    train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step()) 
    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)

`
`
train_input_fn = tf.estimator.inputs.pandas_input_fn(x=data_train, y=data_train_click, batch_size = 1024, num_epochs=1, shuffle=False)
classifier.train(input_fn=train_input_fn)`

Here `data_train_click` is a Series, which the click samples are 1 and the unclicked samples are 0. 

And in the weight Series `data_train_weight` , the order samples are 10 and the others are 1.

However, I don't known how to use `data_train_weight` in my model.
"
17763,TensorFlowInferenceInterface: OutOfMemoryError on Android SDK 16,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Android SDK 16 (4.1.2)
- **TensorFlow installed from (source or binary)**: compile 'org.tensorflow:tensorflow-android:+
- **TensorFlow version (use command below)**: latest
- **Python version**: NA
- **Bazel version (if compiling from source)**: NA
- **GCC/Compiler version (if compiling from source)**: NA
- **CUDA/cuDNN version**: NA
- **GPU model and memory**: NA
- **Exact command to reproduce**: NA

### Describe the problem
I found a strange bug using the _TensorFlowInferenceInterface_ on Android SDK 16. When closing the interface once (using `inferenceInterface.close()`), the next start (using `new TensorFlowInferenceInterface()`) will cause an OutOfMemoryError, even though there is enough free RAM available. In contrast, there isn't any problem when keeping the interface alive to reuse it. The latter implies wasting resources though. The only way to prevent the OOM seems to be the manual kill of the surrounding process (`android.os.Process.killProcess(android.os.Process.myPid());`).

Just to be clear: there is really enough free RAM available. I'm not only referring to the device's RAM in general, but to the individual Java heap of the Android app. I even outsourced the TensorFlow code to a separate process to ensure that it gets its own heap.

I found this behavior using an old Samsung Galaxy S2. Couldn't reproduce it on newer Android versions. As SDK 16 is already quite old, I don't know whether anybody is willing to dig deeper into this bug. However, it costs me a lot of time to isolate the problem and I hope the workaround (using a separate process and killing it manually after closing the interface) may at least save somebody else some time.
"
17762,UnimplementedError: Broadcast between <Tensor> and <Tensor> is not supported yet.,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 10 Pro 64-bit (10.0, Build 16299)
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
b'unknown' 1.5.0
- **Python version**: 
3.6.4
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

### Describe the problem
I get 'UnimplementedError (see above for traceback): Broadcast between <Tensor> and <Tensor> is not supported yet' when trying to broadcast between different kinds of tensors.

What I take from this is that the broadcasting system in tensorflow has limits on how many dimensions that can be broadcasted. After having tried multiple tensor permutations, I have further concluded that  the constraints on broadcasting for tensors is a bit unintuitive. For example:

This works:
[1,2,1,1,2,2,2,2]*
[2,2,2,2,1,2,2,2]

This doesn't work:
[1,2,1,1,2,2,2,2]*
[2,2,2,2,1,2,2,1]

This works:
[2,2,2,2,1]*
[1,2,1,2,2]

This doesn't work:
[2,2,2,2,1,2]*
[1,2,1,2,2,2]

What I take from this is that broadcasting works for any permutation when the tensor rank is less than 6. When it is above 6, broadcasting only works when there is a maximum of 2 regions of consecutive 1's (both tensors' 1's taken into consideration). For example:

This has two regions of consecutive 1's:
[1,2,1,1,2,2,2,2]*
[2,2,2,2,1,2,2,2]

This has three regions of consecutive 1's:
[1,2,1,1,2,2,2,2]*
[2,2,2,2,2,1,2,2]

Although, this rule seems to be wrong when calculating the product below. This doesn't work:
[1,2,1,1,2,1,2,2]*
[2,2,2,2,1,2,2,2]

Maybe there is also a constraint on each individual tensor that it cannot contain more than two regions of consecutive 1's. An example of this:

This works:
[1,2,1,1,2,2,2,2]*
[2,1,2,2,1,2,2,2]

Nevertheless, I hope that I have demonstrated that the underlying constraints for broadcasting are confusing and unintuitive, so could you please show me the current constraints on broadcasting or confirm that above constraints are the only ones? 

Configurations aside, is it possible to fix the broadcasting system such that it can support any broadcasting configuration? If not, is there at least a way to increase the number of regions of consecutive 1's in the constraints for broadcastability between two tensors? I.e. is there a way to increase the maximum of 2 regions of consecutive 1's to a maximum of e.g. 4 regions?

I understand that a workaround is to tile the tensors, but I assume that this increases memory usage (by quite a lot when the tensors' ranks are high); something that is very limited in my current program.

### Source code / logs
An example of case 1 and 2 above:

```
import tensorflow as tf
t1 = tf.random_normal([1,2,1,1,2,2,2,2])
t2 = tf.random_normal([2,2,2,2,1,2,2,2])
t3 = d*e

t4 = tf.random_normal([1,2,1,1,2,2,2,2])
t5 = tf.random_normal([2,2,2,2,1,2,2,1])
t6 = d*e

sess = tf.InteractiveSession()
sess.run(t3)
sess.run(t6)
```
"
17761,Can't import TensorFlow,"### System information
- OS Platform:
    Windows 10 Pro 64bit
- Python version: 
   Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:54:40) [MSC v.1900 64 bit (AMD64)] on win32
- TensorFlow version
   1.6.0 installed using:
`pip3 install --upgrade tensorflow`

```
Collecting tensorflow
  Using cached tensorflow-1.6.0-cp36-cp36m-win_amd64.whl
Requirement already up-to-date: astor>=0.6.0 in c:\users\pc\appdata\local\programs\python\python36\lib\site-packages (from tensorflow)
Requirement already up-to-date: protobuf>=3.4.0 in c:\users\pc\appdata\local\programs\python\python36\lib\site-packages (from tensorflow)
Requirement already up-to-date: grpcio>=1.8.6 in c:\users\pc\appdata\local\programs\python\python36\lib\site-packages (from tensorflow)
Requirement already up-to-date: wheel>=0.26 in c:\users\pc\appdata\local\programs\python\python36\lib\site-packages (from tensorflow)
Requirement already up-to-date: numpy>=1.13.3 in c:\users\pc\appdata\local\programs\python\python36\lib\site-packages (from tensorflow)
Requirement already up-to-date: tensorboard<1.7.0,>=1.6.0 in c:\users\pc\appdata\local\programs\python\python36\lib\site-packages (from tensorflow)
Requirement already up-to-date: termcolor>=1.1.0 in c:\users\pc\appdata\local\programs\python\python36\lib\site-packages (from tensorflow)
Requirement already up-to-date: absl-py>=0.1.6 in c:\users\pc\appdata\local\programs\python\python36\lib\site-packages (from tensorflow)
Requirement already up-to-date: six>=1.10.0 in c:\users\pc\appdata\local\programs\python\python36\lib\site-packages (from tensorflow)
Requirement already up-to-date: gast>=0.2.0 in c:\users\pc\appdata\local\programs\python\python36\lib\site-packages (from tensorflow)
Requirement already up-to-date: setuptools in c:\users\pc\appdata\local\programs\python\python36\lib\site-packages (from protobuf>=3.4.0->tensorflow)
Requirement already up-to-date: bleach==1.5.0 in c:\users\pc\appdata\local\programs\python\python36\lib\site-packages (from tensorboard<1.7.0,>=1.6.0->tensorflow)
Requirement already up-to-date: werkzeug>=0.11.10 in c:\users\pc\appdata\local\programs\python\python36\lib\site-packages (from tensorboard<1.7.0,>=1.6.0->tensorflow)
Requirement already up-to-date: html5lib==0.9999999 in c:\users\pc\appdata\local\programs\python\python36\lib\site-packages (from tensorboard<1.7.0,>=1.6.0->tensorflow)
Requirement already up-to-date: markdown>=2.6.8 in c:\users\pc\appdata\local\programs\python\python36\lib\site-packages (from tensorboard<1.7.0,>=1.6.0->tensorflow)
Installing collected packages: tensorflow
Successfully installed tensorflow-1.6.0
```
- Have I written custom code: No
- Bazel version : I don't have
- CUDA/cuDNN version : I don't have
- GPU model and memory :N\A
- Exact command to reproduce : `import tensorflow as tf`
### The problem
Can't import TensorFlow
`import tensorflow as tf`

```
Traceback (most recent call last):
  File ""C:\Users\pc\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    return importlib.import_module(mname)
  File ""C:\Users\pc\AppData\Local\Programs\Python\Python36\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 994, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 971, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 955, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 658, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 571, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 922, in create_module
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\pc\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\pc\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 21, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\pc\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""C:\Users\pc\AppData\Local\Programs\Python\Python36\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Users\pc\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""C:\Users\pc\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\pc\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\pc\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    return importlib.import_module(mname)
  File ""C:\Users\pc\AppData\Local\Programs\Python\Python36\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 994, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 971, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 955, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 658, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 571, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 922, in create_module
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\pc\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\pc\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 21, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\pc\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""C:\Users\pc\AppData\Local\Programs\Python\Python36\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
```
I have no idea what to do.
TY in advance"
17758,tensorflow.contrib.mpi import fails even though tensorflow is compiled with mpi,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 4.9.85-37.55.amzn1.x86_64 (centOS)
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.6
- **Python version**: 3.5
- **Bazel version (if compiling from source)**: 
- **GCC/Compiler version (if compiling from source)**: 4.8.5
- **CUDA/cuDNN version**: 9.0/7.0
- **GPU model and memory**:
- **Exact command to reproduce**: import tensorflow.contrib.mpi

### Describe the problem
I have compiled tensorflow from source and used the following configuration - 

```
export JAVA_HOME=/usr/java/jdk1.8.0_121/
export TF_NEED_JEMALLOC=1
export TF_NEED_GCP=0
export TF_NEED_HDFS=1
export TF_NEED_S3=1
export TF_ENABLE_XLA=0
export TF_NEED_GDR=0
export TF_NEED_VERBS=0
export TF_NEED_OPENCL_SYCL=0
export TF_NEED_COMPUTECPP=0
export TF_NEED_CUDA=1
export CUDA_TOOLKIT_PATH=/usr/local/cuda
export CUDNN_INSTALL_PATH=/usr/local/cuda
export TF_CUDA_COMPUTE_CAPABILITIES=3.0,3.5,5.2
export TF_CUDA_CLANG=0
export TF_NEED_MPI=1
export MPI_HOME=/usr/local/mpi
export GCC_HOST_COMPILER_PATH=$(which gcc)
export CC_OPT_FLAGS=""-march=native""
export TF_NEED_MKL=0
export TF_DOWNLOAD_MKL=0
export TF_CUDA_VERSION=""$(nvcc --version | sed -n 's/^.*release \(.*\),.*/\1/p')""
export TF_CUDNN_VERSION=""$(sed -n 's/^#define CUDNN_MAJOR\s*\(.*\).*/\1/p' $CUDNN_INSTALL_PATH/include/cudnn.h)""
export PYTHON_BIN_PATH=/usr/lib/python/bin/python
export PYTHON_LIB_PATH=""$($PYTHON_BIN_PATH -c 'import site; print(site.getsitepackages()[0])')""

export OMPI_SKIP_MPICXX=1
export CC_OPT_FLAGS=""-DOMPI_SKIP_MPICXX=1 -march=native""
```
I installed tf using the wheel file generated after compiling. However, when I try to run `import tensorflow.contrib.mpi` it throws an import error -

`ImportError: No module named 'tensorflow.mpi'`
"
17757,No OpKernel was registered to support Op 'L2Loss' with these attrs,"Hello everyone!

 I'm having the following error when trying to run an iOS app I've built with tensorflow:

Non-OK-status: session->Create(graph_def) status: Invalid argument: **No OpKernel was registered to support Op 'L2Loss' with these attrs**.  Registered devices: [CPU], **Registered kernels:
  <no registered kernels>**

	 [[Node: L2Loss_1 = L2Loss[T=DT_FLOAT](sub_1)]]


 I've build tensorflow using the ./build_all_ios.sh process.

 From my research I already tried adding the flag -DANDROID_TYPES=__ANDROID_TYPES_FULL__ to the build_all_ios.sh like this:

TF_CC_FLAGS=""-O3 -DANDROID_TYPES=__ANDROID_TYPES_FULL__""

 But I still have the same issue.

 I was having even more errors before but I added a couple .cc files to tf_op_files.txt and it fixed those previous issues.

 Do I have to add more .cc files ?
 Also isn't it weird that it says I have no registered kernels ?

 I'm using the latest master.

Thank you"
17756,Failed to load the native TensorFlow runtime.,"```
Traceback (most recent call last):
  File ""C:\Users\hari\Desktop\tf_object_detection_api\models\research\object_detection\object_detection_tutorial_CONVERTED.py"", line 16, in <module>
    import tensorflow as tf
  File ""C:\Python27\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""C:\Python27\lib\site-packages\tensorflow\python\__init__.py"", line 72, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Python27\lib\site-packages\tensorflow\python\__init__.py"", line 66, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Python27\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 28, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""C:\Python27\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 20, in swig_import_helper
    import _pywrap_tensorflow
ImportError: No module named _pywrap_tensorflow


Failed to load the native TensorFlow runtime.

See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#import_error

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
```"
17754,[bug] segmentation fault happens with nested higher order function,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: OSX 10.11.6
- **TensorFlow installed from (source or binary)**: VirtualEnv
- **TensorFlow version (use command below)**: 1.6
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A (CPU only)
- **GPU model and memory**: N/A (CPU only)
- **Exact command to reproduce**: see the following

### Describe the problem
segmentation fault happens when the computation graph contains `scan` with `bidirectional_rnn` embedded. 

### Source code / logs
```python
import tensorflow as tf
import numpy as np

embed_dim = 10
hidden_dim = 10
num_class=10

words = tf.placeholder(tf.int32, [None, None], name='words')
length = tf.placeholder(tf.int32, [None], name='length')
labels = tf.placeholder(tf.int32, (), name='labels')
init_state = tf.placeholder(tf.float32, [None, hidden_dim * 2], name='initial_state')

def make_rnn_cell(): return tf.nn.rnn_cell.GRUCell(num_units=hidden_dim)

with tf.variable_scope('embeddings'):
    embedding = \
        tf.get_variable('parameter', shape=(100, embed_dim), dtype=tf.float32, trainable=True)
    embedded  = tf.nn.embedding_lookup(embedding, words, name='lookup')
with tf.variable_scope('words_lstm'):
    cell_fw = make_rnn_cell()
    cell_bw = make_rnn_cell()
    def step(state, inp):
        data = tf.expand_dims(inp[0], axis=0)
        length = tf.expand_dims(inp[1], axis=0)
        fw_state = tf.split(state[inp[1], :], 2)[0]
        bw_state = tf.split(state[0, :], 2)[1]
online training (feeding one training example at a time)
        fw_state = tf.expand_dims(fw_state, axis=0)
        bw_state = tf.expand_dims(bw_state, axis=0)
        (outputs_fw, outputs_bw), _ = \
            tf.nn.bidirectional_dynamic_rnn(
                cell_fw, cell_bw, embedded, sequence_length=length,
                initial_state_fw=fw_state, initial_state_bw=bw_state, dtype=tf.float32
            )
        outputs = tf.squeeze(tf.concat([outputs_fw, outputs_bw], axis=2), axis=[0])
        return outputs
    outputs = tf.scan(step, (embedded, length), initializer=init_state)
with tf.variable_scope('words_attention'):
    hidden = \
        tf.layers.dense(outputs, units=hidden_dim * 2, activation=tf.nn.tanh)
    attention = \
        tf.layers.dense(outputs, units=1, activation=None)
    attention = tf.transpose(tf.nn.softmax(tf.transpose(attention, perm=[0, 2, 1])), perm=[0, 2, 1])
sentence_embedding = tf.reduce_sum(outputs * attention, axis=1)
sentence_embedding = tf.expand_dims(sentence_embedding, axis=0)

with tf.variable_scope('sentence_lstm'):
    cell_fw = make_rnn_cell()
    cell_bw = make_rnn_cell()
    (outputs_fw, outputs_bw), _ = \
        tf.nn.bidirectional_dynamic_rnn(cell_fw, cell_bw, sentence_embedding, dtype=tf.float32)
outputs = tf.squeeze(tf.concat([outputs_fw, outputs_bw], axis=2), axis=[0])
with tf.variable_scope('sentence_attention'):
    hidden = \
        tf.layers.dense(outputs, units=hidden_dim * 2, activation=tf.nn.tanh)
    attention = \
        tf.layers.dense(hidden, units=1, activation=None)
    attention = tf.transpose(tf.nn.softmax(tf.transpose(attention)))
outputs = tf.reduce_sum(outputs * attention, axis=0)
outputs = tf.expand_dims(outputs, axis=0)
logits = tf.layers.dense(outputs, units=num_class, activation=None)
loss = -tf.log(tf.nn.softmax(logits)[:, labels], name='loss')
training_op = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss)

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    words_val = np.random.randint(0, 100, size=(10, 100))
    length_val = np.random.randint(0, 100, size=(10))
    labels_val = np.random.randint(0, num_class, size=())
    init_state_val = np.random.randn(10, hidden_dim * 2)

    fd = { words : words_val, length : length_val, labels : labels_val, init_state : init_state_val}
    sess.run(training_op, feed_dict=fd)
```

Running with TF 1.6, the above code ended up with the following error:
```bash
Segmentation fault: 11
```

Additional information,
I ran the program with `dtruss`, the last few lines printed on console before it crashed are as follows,
```bash
psynch_cvsignal(0x7FDED4BC4A68, 0x90000000A00, 0x900)		 = 257 0
psynch_cvwait(0x7FDED4BC4A68, 0x90100000A00, 0x900)		 = 0 0
psynch_cvsignal(0x7FDED4BC4E68, 0x1F0000002000, 0x1F00)		 = 257 0
psynch_cvwait(0x7FDED4BC4E68, 0x1F0100002000, 0x1F00)		 = 0 0
psynch_cvsignal(0x7FDED4BC4E68, 0x200000002100, 0x2000)		 = 257 0
psynch_cvwait(0x7FDED4BC4E68, 0x200100002100, 0x2000)		 = 0 0
psynch_cvsignal(0x7FDED4BC4E68, 0x210000002200, 0x2100)		 = 257 0
psynch_cvwait(0x7FDED4BC4E68, 0x210100002200, 0x2100)		 = 0 0
psynch_cvsignal(0x7FDED4BC4C68, 0x1C0000001D00, 0x1C00)		 = 257 0
psynch_cvwait(0x7FDED4BC4C68, 0x1C0100001D00, 0x1C00)		 = 0 0
psynch_cvsignal(0x7FDED4BC4A68, 0xA0000000B00, 0xA00)		 = 257 0
psynch_cvwait(0x7FDED4BC4A68, 0xA0100000B00, 0xA00)		 = 0 0
psynch_cvsignal(0x7FDED4BC4D68, 0xD0000000E00, 0xD00)		 = 257 0
psynch_cvwait(0x7FDED4BC4D68, 0xD0100000E00, 0xD00)		 = 0 0
psynch_cvwait(0x0, 0x0, 0x0)		 = 0 0
psynch_cvwait(0x7FDED4BC4F68, 0x1B0100001C00, 0x1B00)		 = 0 0
psynch_cvwait(0x7FDED4BC5068, 0x30100000400, 0x300)		 = 0 0
psynch_cvwait(0x7FDED4BC5168, 0x20100000300, 0x200)		 = 0 0
psynch_cvwait(0x7FDEDCAEFE28, 0x10100000200, 0x100)		 = -1 Err#260
psynch_cvwait(0x7FDED4BC4068, 0x100000100, 0x0)		 = -1 Err#260
psynch_cvwait(0x7FDED4BC4168, 0x100000100, 0x0)		 = -1 Err#260
psynch_cvwait(0x7FDED4BC4268, 0x100000100, 0x0)		 = -1 Err#260
psynch_cvwait(0x7FDED4BC4368, 0x100000100, 0x0)		 = -1 Err#260
psynch_cvwait(0x7FDED4BC4568, 0x100000100, 0x0)		 = -1 Err#260
psynch_cvwait(0x7FDED4BC4468, 0x100000100, 0x0)		 = -1 Err#260
psynch_cvwait(0x7FDED4BC4668, 0x100000100, 0x0)		 = -1 Err#260
psynch_cvwait(0x7FDED4BC4768, 0x100000100, 0x0)		 = -1 Err#260
```"
17753,Quantize to TFLITE mode:how to change the graph to contain min/max information for relu layer.,"== cat /etc/issue ===============================================
Linux xxxx 4.13.0-36-generic #40~16.04.1-Ubuntu SMP Fri Feb 16 23:25:58 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""16.04.3 LTS (Xenial Xerus)""
VERSION_ID=""16.04""
VERSION_CODENAME=xenial

== are we in docker =============================================
No

== compiler =====================================================
c++ (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux xxxxx 4.13.0-36-generic #40~16.04.1-Ubuntu SMP Fri Feb 16 23:25:58 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy (1.14.1)
numpydoc (0.7.0)
protobuf (3.5.2)
tensorflow (1.7.0rc0)
tensorflow-tensorboard (1.5.1)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.7.0-rc0
tf.GIT_VERSION = b'v1.7.0-rc0-2-ga6f8b22'
tf.COMPILER_VERSION = b'v1.7.0-rc0-2-ga6f8b22'
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH /home/user/software_install/TensorRT-3.0.4/lib:/usr/local/cuda/lib64:
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
Fri Mar 16 11:28:51 2018       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 384.111                Driver Version: 384.111                   |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 1080    Off  | 00000000:01:00.0  On |                  N/A |
|  0%   38C    P8     9W / 200W |    253MiB /  8110MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0      1132      G   /usr/lib/xorg/Xorg                           139MiB |
|    0      3053      G   compiz                                       111MiB |
+-----------------------------------------------------------------------------+

== cuda libs  ===================================================
/usr/local/cuda-8.0/lib64/libcudart_static.a
/usr/local/cuda-8.0/lib64/libcudart.so.8.0.61
/usr/local/cuda-8.0/doc/man/man7/libcudart.7
/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7

++++++++++Problem+++++++++++
I try to quantize my model. Computation is as follow:
pointwise_conv2d(relu(depthwise_conv2d(x)))
Then, I use tf.contrib.quantize.create_eval_graph() to quantize graph. 
However, there is an error when I use lite.toco_convert() to convert model into tflite.

I want to konw how to change the graph to contain min/max information for relu layer.

MSG:
Array conv2_depthwise_relu, which is an input to the Conv operator producing the output array conv2, is lacking min/max data, which is necessary for quantization. Either target a non-quantized output format, or change the input graph to contain min/max information, or pass --default_ranges_min= and --default_ranges_max= if you do not care about the accuracy of results.

[quant.zip](https://github.com/tensorflow/tensorflow/files/1817860/quant.zip)
"
17752,"Error:  Executor failed to create kernel. No registered 'Snapshot' OpKernel for GPU devices,while running image label example","### System information
- OS Platform: Windows10
- TensorFlow installed from source  (GPU support)
- Python version: 3.5
- Compiler version : Microsoft Visual Studio 2015 x64
- CUDA/cuDNN version:CUDA9.0/cuDNN7.0
- GPU: GTX 1070 8G
-CMake settings:  
![image](https://user-images.githubusercontent.com/13750472/37500096-84403974-2902-11e8-8e1d-2a540d3a03b5.png)

### Problem
  I successfully built tensorflow.lib and tensorflow.dll, then I linked these to my visual studio project.Everything goes well when I run the example code which does matrix multiplication (the example code on:https://joe-antognini.github.io/machine-learning/windows-tf-project)
  But when I tried to run the Label_Image example code(https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/label_image/main.cc), I got the error:
![image](https://user-images.githubusercontent.com/13750472/37500237-47decb84-2903-11e8-8bcd-670f4976fb66.png)
`E C:\tensorflow_gpu\tensorflow\tensorflow\core\common_runtime\executor.cc:644] Executor failed to create kernel. Not found: No registered 'Snapshot' OpKernel for GPU devices compatible with node Subtract = Snapshot[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](ResizeBilinear)
    .  Registered:  device='CPU'; T in [DT_INT64]device='CPU'; T in [DT_INT32]
device='CPU'; T in [DT_UINT16]
device='CPU'; T in [DT_INT16]
device='CPU'; T in [DT_UINT8]
device='CPU'; T in [DT_INT8]
device='CPU'; T in [DT_HALF]
device='CPU'; T in [DT_BFLOAT16]
device='CPU'; T in [DT_FLOAT]
device='CPU'; T in [DT_DOUBLE]
device='CPU'; T in [DT_COMPLEX64]
device='CPU'; T in [DT_COMPLEX128]
device='CPU'; T in [DT_BOOL]
     [[Node: Subtract = Snapshot[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](ResizeBilinear)]]
2018-03-14 17:13:05.408206: E Image_Label.cpp:385] Not found: No registered 'Snapshot' OpKernel for GPU devices compatible with node Subtract = Snapshot[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](ResizeBilinear)
    .  Registered:  device='CPU'; T in [DT_INT64]
device='CPU'; T in [DT_INT32]
device='CPU'; T in [DT_UINT16]
device='CPU'; T in [DT_INT16]
device='CPU'; T in [DT_UINT8]
device='CPU'; T in [DT_INT8]
device='CPU'; T in [DT_HALF]
device='CPU'; T in [DT_BFLOAT16]
device='CPU'; T in [DT_FLOAT]
device='CPU'; T in [DT_DOUBLE]
device='CPU'; T in [DT_COMPLEX64]
device='CPU'; T in [DT_COMPLEX128]
device='CPU'; T in [DT_BOOL]
     [[Node: Subtract = Snapshot[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](ResizeBilinear)]]`

I found out the code stopped at:
`TF_RETURN_IF_ERROR(session->Run({ inputs }, { output_name }, {}, out_tensors));`
in
`Status ReadTensorFromImageFile(const string& file_name, const int input_height,
    const int input_width, const float input_mean,
    const float input_std,
    std::vector<Tensor>* out_tensors)`

Does anyone know how to fix this problem??

"
17749,android Semantic segmentation ,"if i want to use my code and model network on pc to run it in mobile android for semantic segmentation that is possible ? and how ? 
thank you 

System information
**Have I written custom code : No
**OS Platform and Distribution : windows 10
**TensorFlow installed from binary
**TensorFlow version :1.6
Python version: 3
**Bazel version *:N/A
CUDA/cuDNN version: cuda 9 - cudnn 7
GPU model and memory: geforce gtx 960 - 4 GB
Exact command to reproduce: N/A
"
17748,Inability to get tensorflow output from custom_estimator,"For this costum_estimator, the related documentation on https://www.tensorflow.org/get_started/custom_estimators tells me that I can just input tensorboard --logdir=PATH in the directory and obtain TensorGraph visualisation.  However I do this and I get on the Tensorboard page ""Graph visualisation failed: the graph is empty. Make sure that the graph is passed to the tf.summary.filewriter after the graph is defined""
As far as I understood, when using custom estimators it automatically passes the data to TensorBoard. What shall I do? I would like to get the basic graphs as shown at the bottom of the tutorial I linked above.

`import pandas as pd             
import numpy as np              
import matplotlib.pyplot as plt  
import tensorflow as tf
import argparse

def train_input_fn(features, labels, batch_size):
    """"""An input function for training""""""
    # Convert the inputs to a Dataset.
    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))

    # Shuffle, repeat, and batch the examples.
    dataset = dataset.shuffle(buffer_size=1000).repeat(count=None).batch(batch_size)

    # Return the dataset.
    return dataset
	

def eval_input_fn(features, labels, batch_size):
    """"""An input function for evaluation or prediction""""""
    features=dict(features)
    if labels is None:
        # No labels, use only features.
        inputs = features
    else:
        inputs = (features, labels)

    # Convert the inputs to a Dataset.
    dataset = tf.data.Dataset.from_tensor_slices(inputs)

    # Batch the examples
    assert batch_size is not None, ""batch_size must not be None""
    dataset = dataset.batch(batch_size)

    # Return the dataset.
    return dataset

def datasetfun(dataframe,split1,split2):
    
    #split1: variable deciding the proportion of test data to training data
    #split2: variable deciding the proportion of test data to training data

    dataframe = pd.read_csv(""Supporttry.csv"") # Let's have Pandas load our dataset as a dataframe
    #dataframe = dataframe.drop([""dzclass"",""num.co"",""edu"",""income"",""scoma"",""charges"",""totcst"",""totmcst"",""avtisst"",""race"",""meanbp"",""wblc"",""hrt"",""resp"",""temp"",""pafi"",""alb"",""bili"",""crea"",""sod"",""ph"",""glucose"",""bun"",""urine"",""adlp"",""adls"",""sfdm2"",""adlsc""], axis=1) # Remove columns we don't care about
    dataframe = dataframe.drop([""crea"",""avtisst"",""wblc"",""race"",""edu"",""income"",""charges"",""totcst"",""totmcst"",""pafi"",""alb"",""bili"",""ph"",""glucose"",""bun"",""urine"",""adlp"",""adls"",""sfdm2""], axis=1)
    train = dataframe[0:split1] # use first 15 rows as training set
    test = dataframe[split1:split2] # keep some as testing
    predictdata = dataframe[split2:] # find the ones to predict

    train_features, train_labels = train, train.pop(""death"") #separate features with classification in train set
    test_features, test_labels = test, test.pop(""death"") #separate features with classification in train set
    predict_features, predict_labels = predictdata, predictdata.pop(""death"")

    categorical_column1 = tf.feature_column.categorical_column_with_vocabulary_list(key=""sex"", vocabulary_list=[""male"", ""female""], default_value=0)
    categorical_column2 = tf.feature_column.categorical_column_with_vocabulary_list(key='dzgroup',vocabulary_list=[""Lung Cancer"",""Colon Cancer"",""ARF/MOSF w/Sepsis"",""MOSF w/Malig"",""Cirrhosi"",""CHF""])
    categorical_column3 = tf.feature_column.categorical_column_with_vocabulary_list(key=""dzclass"", vocabulary_list=[""Cancer"", ""ARF/MOSF"",""COPD/CHF/Cirrhosis""], default_value=0)
    #categorical_column4 = tf.feature_column.categorical_column_with_vocabulary_list(key=""race"", vocabulary_list=[""black"", ""hispanic"",""White"",""asian"",""other""], default_value=0)

    my_feature_columns = [
    tf.feature_column.numeric_column(key='age'),
    tf.feature_column.indicator_column(categorical_column1),
    tf.feature_column.numeric_column(key='hospdead'),
    tf.feature_column.numeric_column(key='slos'),
    tf.feature_column.numeric_column(key='d.time'),
    tf.feature_column.indicator_column(categorical_column2),
    tf.feature_column.indicator_column(categorical_column3),
    tf.feature_column.numeric_column(key='scoma'),
    #tf.feature_column.numeric_column(key='avtisst'),
    #tf.feature_column.indicator_column(categorical_column4),
    tf.feature_column.numeric_column(key='meanbp'),
    tf.feature_column.numeric_column(key='hrt'),
    tf.feature_column.numeric_column(key='resp'),
    tf.feature_column.numeric_column(key='temp'),
    #tf.feature_column.numeric_column(key='crea'),
    tf.feature_column.numeric_column(key='sod'),
    tf.feature_column.numeric_column(key='adlsc')]

    return (train_features, train_labels, test_features, test_labels, predict_features, predict_labels, my_feature_columns)

def my_model(features, labels, mode, params):
    """"""DNN with three hidden layers, and dropout of 0.1 probability.""""""
    # Create three fully connected layers each layer having a dropout
    # probability of 0.1.
    net = tf.feature_column.input_layer(features, params['feature_columns']) #imput layer
    for units in params['hidden_units']: #can change type of layers!!!!
        net = tf.layers.dense(net, units=units, activation=tf.nn.relu) #can change activation function to sigmoid!!!

    # Compute logits (1 per class).

    #output layer
    logits = tf.layers.dense(net, params['n_classes'], activation=None)

    # Compute predictions.
    predicted_classes = tf.argmax(logits, 1)
    if mode == tf.estimator.ModeKeys.PREDICT:
        predictions = {
            'class_ids': predicted_classes[:, tf.newaxis],
            'probabilities': tf.nn.softmax(logits),
            'logits': logits,
        }
        return tf.estimator.EstimatorSpec(mode, predictions=predictions)

    # Compute loss.
    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)

    # Compute evaluation metrics!!!!!!!
    accuracy = tf.metrics.accuracy(labels=labels,
                                   predictions=predicted_classes,
                                   name='acc_op')
    metrics = {'accuracy': accuracy}
    tf.summary.scalar('accuracy', accuracy[1])

    if mode == tf.estimator.ModeKeys.EVAL:
        return tf.estimator.EstimatorSpec(
            mode, loss=loss, eval_metric_ops=metrics)

    # Create training op.
    assert mode == tf.estimator.ModeKeys.TRAIN
    
    optimizer = tf.train.AdagradOptimizer(learning_rate=0.1) #can change optimizer
    train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())
    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)
    




def main(m):
	
	#classification of death or no death

    dataframe = pd.read_csv(""Supporttry.csv"") # Let's have Pandas load our dataset as a dataframe

    split1=500
    split2=980

    [train_features, train_labels, test_features, test_labels, predict_features, predict_labels, my_feature_columns] = datasetfun(dataframe,split1,split2)

    classifier = tf.estimator.Estimator(
        model_fn=my_model,
        params={
            'feature_columns': my_feature_columns,
            # Two hidden layers of 10 nodes each.
            'hidden_units': [10, 10],
            # The model must choose between 3 classes.
            'n_classes': 2,
        })

    # classifier = tf.estimator.DNNClassifier(
    # 	feature_columns=my_feature_columns,
    # 	hidden_units=[10,10,5,6,7],
    # 	n_classes=2)

    batch_size=100
    train_steps=1000

    #writer = tf.summary.FileWriter(""/Users/angelicagrusovin/documents/oxford/MLSP"",graph=tf.get_default_graph())
    #writer.add_graph(sess.graph)

    classifier.train(input_fn=lambda:train_input_fn(train_features, train_labels, batch_size),steps=train_steps)

    eval_result = classifier.evaluate(
    input_fn=lambda:eval_input_fn(test_features, test_labels, batch_size))

    print('\nTest set accuracy: {accuracy:0.3f}\n'.format(**eval_result))

	#predictions = classifier.predict(
    #input_fn=lambda:eval_input_fn(predict_features,None,batch_size))

	# expected=['dead','alive']
	# STATE=['dead','alive']
	# print(zip(predictions))

	# template = ('\nPrediction is ({:.1f}%), expected {}')

	# for pred_dict in zip(predictions):
	# 	class_id = pred_dict[0]['class_ids'][0]
	# 	probability = pred_dict[0]['probabilities'][class_id]
	# 	print(template.format(100 * probability, STATE[class_id]))

    




	#print(my_feature_columns) 

    return m

if __name__ == '__main__':
    main(10)`



"
17747,Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_INSTRUCTION,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: 1.6.0
- **Python version**: 3.5.2
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: 9.0.176.2 / cudnn7.0.5
- **GPU model and memory**: GTX 1080 (8GB)
- **Exact command to reproduce**:
```
import numpy as np
import tensorflow as tf

batch_size = 64
images = tf.random_normal(shape=[batch_size, 32, 32, 3], dtype=tf.float32)
angles = tf.random_uniform([batch_size], -0.5, 0.5)
images = tf.contrib.image.rotate(images, angles)

with tf.Session() as sess:
    _ = sess.run(images)
```
### Any Idea why this small example produces the following error?
**ERROR:**
*2018-03-16 18:27:24.292665: E C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_INSTRUCTION*
*2018-03-16 18:27:24.292700: E C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:1110] could not synchronize on CUDA context: CUDA_ERROR_ILLEGAL_INSTRUCTION ::*
*2018-03-16 18:27:24.296409: F C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\common_runtime\gpu\gpu_event_mgr.cc:203] Unexpected Event status: 1*

**UPDATE:**
I think issue #17485 is very similar"
17746,tf.contrib.crf.crf_decode fails when sequence_length is 0,"These links are similar, 
* https://stackoverflow.com/questions/42798518/how-can-i-pass-sequences-of-length-1-to-tf-contrib-crf-in-tensorflow
* #7751
------------------------

### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: ('v1.6.0-0-gd2e24b6', '1.6.0')
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: Build label: 0.10.0

### Describe the problem
`crf_decode` fails when sequence length == 0. This will happen when I am doing batch evaluation and one sequence is exhausted before the others. 

### Source code / logs
```
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/crf/python/ops/crf.py"", line 517, in crf_decode
    fn2=_multi_seq_fn)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/utils.py"", line 209, in smart_cond
    return fn2()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/crf/python/ops/crf.py"", line 490, in _multi_seq_fn
    backpointers, sequence_length - 1, seq_dim=1)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py"", line 4145, in reverse_sequence
    seq_dim=seq_dim, batch_dim=batch_dim, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 3271, in create_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1650, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): seq_lens(90) < 0
```"
17744,TFSLIM UnknownError Input/Output Error.,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.


I have created tfrecord files and am getting the following error during my training:

INFO:tensorflow:global step 3338: loss: 0.4686 (2.67 sec/step)
step=1217
INFO:tensorflow:global step 3339: loss: 0.4468 (2.57 sec/step)
step=1218
INFO:tensorflow:global step 3340: loss: 0.4400 (2.66 sec/step)
step=1219
INFO:tensorflow:global step 3341: loss: 0.5029 (2.76 sec/step)
step=1220
INFO:tensorflow:global step 3342: loss: 0.3761 (43.48 sec/step)
INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.UnknownError'>, /content/drive/app/images/train/fmri_train_00000-of-00001.tfrecord; Input/output error
	 [[Node: parallel_read/ReaderReadV2 = ReaderReadV2[_device=""/job:localhost/replica:0/task:0/device:CPU:0""](parallel_read/TFRecordReaderV2, parallel_read/filenames)]]
Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 1361, in _do_call
    return fn(*args)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 1340, in _run_fn
    target_list, status, run_metadata)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/errors_impl.py"", line 516, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.OutOfRangeError: FIFOQueue '_3_batch/fifo_queue' is closed and has insufficient elements (requested 32, current size 0)
	 [[Node: batch = QueueDequeueUpToV2[component_types=[DT_FLOAT, DT_UINT8, DT_INT64], timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](batch/fifo_queue, batch/n)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/supervisor.py"", line 990, in managed_session
    yield sess
  File ""train_alz.py"", line 282, in run
    summaries = sess.run(my_summary_op)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 905, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 1137, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 1355, in _do_run
    options, run_metadata)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 1374, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.OutOfRangeError: FIFOQueue '_3_batch/fifo_queue' is closed and has insufficient elements (requested 32, current size 0)
	 [[Node: batch = QueueDequeueUpToV2[component_types=[DT_FLOAT, DT_UINT8, DT_INT64], timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](batch/fifo_queue, batch/n)]]

Caused by op 'batch', defined at:
  File ""train_alz.py"", line 304, in <module>
    run()
  File ""train_alz.py"", line 184, in run
    images, _, labels = load_batch(dataset, batch_size=batch_size)
  File ""train_alz.py"", line 168, in load_batch
    allow_smaller_final_batch = True)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py"", line 989, in batch
    name=name)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py"", line 761, in _batch
    dequeued = queue.dequeue_up_to(batch_size, name=name)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/data_flow_ops.py"", line 527, in dequeue_up_to
    self._queue_ref, n=n, component_types=self._dtypes, name=name)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_data_flow_ops.py"", line 2557, in _queue_dequeue_up_to_v2
    component_types=component_types, timeout_ms=timeout_ms, name=name)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 3271, in create_op
    op_def=op_def)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 1650, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

OutOfRangeError (see above for traceback): FIFOQueue '_3_batch/fifo_queue' is closed and has insufficient elements (requested 32, current size 0)
	 [[Node: batch = QueueDequeueUpToV2[component_types=[DT_FLOAT, DT_UINT8, DT_INT64], timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](batch/fifo_queue, batch/n)]]


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""train_alz.py"", line 304, in <module>
    run()
  File ""train_alz.py"", line 300, in run
    sv.saver.save(sess, sv.save_path, global_step = sv.global_step)
  File ""/usr/lib/python3.6/contextlib.py"", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/supervisor.py"", line 1000, in managed_session
    self.stop(close_summary_writer=close_summary_writer)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/supervisor.py"", line 828, in stop
    ignore_live_threads=ignore_live_threads)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/coordinator.py"", line 389, in join
    six.reraise(*self._exc_info_to_raise)
  File ""/usr/local/lib/python3.6/dist-packages/six.py"", line 693, in reraise
    raise value
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/queue_runner_impl.py"", line 252, in _run
    enqueue_callable()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 1259, in _single_operation_run
    None)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/errors_impl.py"", line 516, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.UnknownError: /content/drive/app/images/train/fmri_train_00000-of-00001.tfrecord; Input/output error
	 [[Node: parallel_read/ReaderReadV2 = ReaderReadV2[_device=""/job:localhost/replica:0/task:0/device:CPU:0""](parallel_read/TFRecordReaderV2, parallel_read/filenames)]]

I am a newbie to tensorflow and would really appreciate any help!"
17743,Training through an Estimator is much slower than writing a for loop when using a Dataset,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Happens with stock code
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu Server 17.10.1
- **TensorFlow installed from (source or binary)**:
Source
- **TensorFlow version (use command below)**:
b'v1.6.0-0-gd2e24b6039' 1.6.0
- **Python version**: 
3.6
- **Bazel version (if compiling from source)**:
0.11.0
- **GCC/Compiler version (if compiling from source)**:
gcc (Ubuntu 6.4.0-8ubuntu1) 6.4.0 20171010
- **CUDA/cuDNN version**:
9.1/7.0.5
- **GPU model and memory**:
not applicable
- **Exact command to reproduce**:
not applicable

I have a dataset that consists of one feature and one label, both are int64, there are 7166 steps of batches consisting of 128 and run for 10 epochs. I have tested this using two approaches, the first uses 100 tfrecord files that are read through the `tf.data.Dataset` API, the second reads the tfrecord data into memory then creates a `tf.data.Dataset` utilizing `from_tensor_slices`.

Obviously the in-memory version runs much faster than the read-from-disk method.

When I train my model using a custom while loop, 10 epochs runs 20 seconds faster than running it using the `tf.estimator.Estimator.train` API. This 20 seconds is a blanket 20 seconds, whether I am running it using the in-memory dataset or the read-from-disk method.

I thought, the overhead could be from storing checkpoints, etc. so I supplied a `RunConfig` that disables checkpoints and sets the various save/log step counts to very high numbers. This helped, but only a little bit, it went from a blanket 20 seconds to a blanket 17 seconds. 17 seconds doesn't seem like much, but if I am running for a large number of epochs, or if I use a much larger dataset, those seconds can turn into hours.

Is this something inherent with `tf.estimator.Estimator` or could I be hitting a problem?"
17739,Tensorflow does not close backgroud threads on shutdown,"### System information
- **Have I written custom code**
- **OS Linux Ubuntu 17.10)**
- **TensorFlow installed using this doc https://www.tensorflow.org/install/install_c**:

### Describe the problem
I see the bug that Tensorflow does not shutdown threads created by TF_NewSession. I do not see any functions in C API, except TF_DeleteSession, which should shutdown threads. But as the example shows TF_DeleteSession does not really close any threads. 
You may say that it happens only on shutdown so it is not an issue, but for the project with leak check, it is important to have clear Valgrind result.
### Source code 
```
int main() {
	TF_Status * status = TF_NewStatus();
	TF_SessionOptions *opt = TF_NewSessionOptions();

	TF_Graph *graph = TF_NewGraph();
	TF_Session *session = TF_NewSession(graph, opt, status);

	TF_CloseSession(session, status);
        TF_DeleteSession(session, status);
        TF_DeleteGraph(graph);
   	TF_DeleteStatus(status);
   	TF_DeleteSessionOptions(opt);
}
```
### Steps to reproduce
* `gcc -g -I/usr/local/include -L/usr/local/lib hello_tf.c -ltensorflow -o memtest`
* `valgrind --leak-check=full ./memtest`
As result valgrind report an error that threads started by tensorflow still running at the end of main.

### Logs
```
==17499== Memcheck, a memory error detector
==17499== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.
==17499== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info
==17499== Command: ./memtest
==17499== 
2018-03-15 16:37:49.446989: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
==17499== 
==17499== HEAP SUMMARY:
==17499==     in use at exit: 5,933,322 bytes in 91,227 blocks
==17499==   total heap usage: 330,638 allocs, 239,411 frees, 23,865,452 bytes allocated
==17499== 
==17499== 1,280 bytes in 4 blocks are possibly lost in loss record 53,082 of 53,144
==17499==    at 0x4C31B25: calloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)
==17499==    by 0x4013C86: allocate_dtv (dl-tls.c:290)
==17499==    by 0x4013C86: _dl_allocate_tls (dl-tls.c:538)
==17499==    by 0x9099421: allocate_stack (allocatestack.c:597)
==17499==    by 0x9099421: pthread_create@@GLIBC_2.2.5 (pthread_create.c:669)
==17499==    by 0x98CA5E2: std::thread::_M_start_thread(std::shared_ptr<std::thread::_Impl_base>, void (*)()) (in /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.24)
==17499==    by 0x8779F45: tensorflow::(anonymous namespace)::PosixEnv::StartThread(tensorflow::ThreadOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::function<void ()>) (in /usr/local/lib/libtensorflow_framework.so)
==17499==    by 0x875008F: tensorflow::thread::ThreadPool::ThreadPool(tensorflow::Env*, tensorflow::ThreadOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, int, bool) (in /usr/local/lib/libtensorflow_framework.so)
==17499==    by 0x875024F: tensorflow::thread::ThreadPool::ThreadPool(tensorflow::Env*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, int) (in /usr/local/lib/libtensorflow_framework.so)
==17499==    by 0x8AF9317: tensorflow::LocalDevice::EigenThreadPoolInfo::EigenThreadPoolInfo(tensorflow::SessionOptions const&) (in /usr/local/lib/libtensorflow_framework.so)
==17499==    by 0x8AF9487: tensorflow::LocalDevice::LocalDevice(tensorflow::SessionOptions const&, tensorflow::DeviceAttributes const&) (in /usr/local/lib/libtensorflow_framework.so)
==17499==    by 0x8B18E11: tensorflow::ThreadPoolDevice::ThreadPoolDevice(tensorflow::SessionOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::gtl::IntType<tensorflow::Bytes_tag_, long long>, tensorflow::DeviceLocality const&, tensorflow::Allocator*) (in /usr/local/lib/libtensorflow_framework.so)
==17499==    by 0x8B19289: tensorflow::ThreadPoolDeviceFactory::CreateDevices(tensorflow::SessionOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<tensorflow::Device*, std::allocator<tensorflow::Device*> >*) (in /usr/local/lib/libtensorflow_framework.so)
==17499==    by 0x8AF7979: tensorflow::(anonymous namespace)::GetCPUDevice(tensorflow::Env*) [clone .constprop.149] (in /usr/local/lib/libtensorflow_framework.so)
==17499== 
==17499== 1,280 bytes in 4 blocks are possibly lost in loss record 53,083 of 53,144
==17499==    at 0x4C31B25: calloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)
==17499==    by 0x4013C86: allocate_dtv (dl-tls.c:290)
==17499==    by 0x4013C86: _dl_allocate_tls (dl-tls.c:538)
==17499==    by 0x9099421: allocate_stack (allocatestack.c:597)
==17499==    by 0x9099421: pthread_create@@GLIBC_2.2.5 (pthread_create.c:669)
==17499==    by 0x98CA5E2: std::thread::_M_start_thread(std::shared_ptr<std::thread::_Impl_base>, void (*)()) (in /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.24)
==17499==    by 0x8779F45: tensorflow::(anonymous namespace)::PosixEnv::StartThread(tensorflow::ThreadOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::function<void ()>) (in /usr/local/lib/libtensorflow_framework.so)
==17499==    by 0x875008F: tensorflow::thread::ThreadPool::ThreadPool(tensorflow::Env*, tensorflow::ThreadOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, int, bool) (in /usr/local/lib/libtensorflow_framework.so)
==17499==    by 0x875024F: tensorflow::thread::ThreadPool::ThreadPool(tensorflow::Env*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, int) (in /usr/local/lib/libtensorflow_framework.so)
==17499==    by 0x70BE592: ??? (in /usr/local/lib/libtensorflow.so)
==17499==    by 0x70BFD89: ??? (in /usr/local/lib/libtensorflow.so)
==17499==    by 0x70BFF09: ??? (in /usr/local/lib/libtensorflow.so)
==17499==    by 0x8B107DE: tensorflow::NewSession(tensorflow::SessionOptions const&, tensorflow::Session**) (in /usr/local/lib/libtensorflow_framework.so)
==17499==    by 0x51E1EB3: TF_NewSession (in /usr/local/lib/libtensorflow.so)
==17499== 
==17499== LEAK SUMMARY:
==17499==    definitely lost: 0 bytes in 0 blocks
==17499==    indirectly lost: 0 bytes in 0 blocks
==17499==      possibly lost: 2,560 bytes in 8 blocks
==17499==    still reachable: 5,930,762 bytes in 91,219 blocks

```"
17736,worker task crashed  in distributed training if ps task or other worker task not started,"### System information
- **Have I written custom code**: yes
- **OS Platform and Distribution **: CentOS Linux release 7.4.1708
- **TensorFlow installed from **: binary
- **TensorFlow version **: 'v1.6.0-0-gd2e24b6039', '1.6.0'
- **Python version**:  2.7.5
- **CUDA/cuDNN version**:   N/A
- **GPU model and memory**:   N/A
- **Exact command to reproduce**:  N/A

### Describe the problem
worker task will crashed after 10s, if ps task or other worker task not started. not sure it's a bug or misused the api.

### Source code / logs

logs:
>2018-03-15 19:59:32.309238: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-03-15 19:59:32.312834: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> bjlt-h1269.sy:42557}
2018-03-15 19:59:32.312861: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:37060, 1 -> bjlt-h1270.sy:57571}
2018-03-15 19:59:32.315443: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:324] Started server with target: grpc://localhost:37060
Variables initialized ...
WARNING:tensorflow:From ./demo.py:75: __init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
2018-03-15 19:59:36.773767: E tensorflow/core/distributed_runtime/master.cc:269] Master init: Unavailable: OS Error
Traceback (most recent call last):
  File ""./demo.py"", line 173, in <module>
    tf.app.run(main=main)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 126, in run
    _sys.exit(main(argv))
  File ""./demo.py"", line 76, in main
    with sv.prepare_or_wait_for_session(server.target, config = tf.ConfigProto(gpu_options=gpu_options, allow_soft_placement = True, log_device_placement = True)) as sess:
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/training/supervisor.py"", line 726, in prepare_or_wait_for_session
    init_feed_dict=self._init_feed_dict, init_fn=self._init_fn)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session
    sess.run(init_op, feed_dict=init_feed_dict)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 905, in run
    run_metadata_ptr)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1137, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1355, in _do_run
    options, run_metadata)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1374, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.UnavailableError: OS Error

full code see https://github.com/Qihoo360/XLearning/blob/master/examples/tensorflow/demo.py
code:
``` python
def main(_):
  # cluster specification
  FLAGS.task_index = int(os.environ[""TF_INDEX""])
  FLAGS.job_name = os.environ[""TF_ROLE""]
  cluster_def = json.loads(os.environ[""TF_CLUSTER_DEF""])
  cluster = tf.train.ClusterSpec(cluster_def)

  print(""ClusterSpec:"", cluster_def)
  print(""current task id:"", FLAGS.task_index, "" role:"", FLAGS.job_name)
  
  gpu_options = tf.GPUOptions(allow_growth = True)
  server = tf.train.Server(cluster, job_name=FLAGS.job_name,task_index=FLAGS.task_index,config = tf.ConfigProto(gpu_options=gpu_options,allow_soft_placement = True))
  
  if FLAGS.job_name == ""ps"":
    server.join()
  elif FLAGS.job_name == ""worker"":
    # set the train parameters
    learning_rate = FLAGS.learning_rate
    training_epochs = FLAGS.training_epochs
    batch_size = FLAGS.batch_size
    iterData = trainData(FLAGS.data_path, batch_size)
    
    with tf.device(tf.train.replica_device_setter(worker_device=(""/job:worker/task:%d""%(FLAGS.task_index)),cluster=cluster)):
      # count the number of updates
      global_step = tf.get_variable('global_step', [],initializer = tf.constant_initializer(0), trainable = False)
      # input 
      with tf.name_scope('input'):
        x = tf.placeholder(tf.float32, shape=[None, 100], name=""x-input"")
        y_ = tf.placeholder(tf.float32, shape=[None, 2], name=""y-input"")
      # model parameters
      tf.set_random_seed(1)
      with tf.name_scope(""weights""):
        W1 = tf.Variable(tf.random_normal([100, 50]))
        W2 = tf.Variable(tf.random_normal([50, 2]))
      # bias
      with tf.name_scope(""biases""):
        b1 = tf.Variable(tf.zeros([50]))
        b2 = tf.Variable(tf.zeros([2]))
      # implement model
      with tf.name_scope(""softmax""):
        # y is our prediction
        z1 = tf.add(tf.matmul(x,W1),b1)
        a1 = tf.nn.softmax(z1)
        z2 = tf.add(tf.matmul(a1,W2),b2)
        y = tf.nn.softmax(z2)
      # specify cost function
      with tf.name_scope('cross_entropy'):
        # this is our cost
        cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))
      # specify optimizer
      with tf.name_scope('train'):
        # optimizer is an ""operation"" which we can execute in a session
        grad_op = tf.train.GradientDescentOptimizer(learning_rate)
        train_op = grad_op.minimize(cross_entropy, global_step=global_step)
      # init_op
      tf.summary.scalar('cross_entropy', cross_entropy )
      merged = tf.summary.merge_all()
      init_op = tf.global_variables_initializer()
      saver = tf.train.Saver()
      print(""Variables initialized ..."")
    sv = tf.train.Supervisor(is_chief = (FLAGS.task_index == 0), global_step = global_step, init_op = init_op)
    with sv.prepare_or_wait_for_session(server.target, config = tf.ConfigProto(gpu_options=gpu_options, allow_soft_placement = True, log_device_placement = True)) as sess:
      # perform training cycles
      start_time = time.time()
      if(FLAGS.task_index == 0):
        train_writer = tf.summary.FileWriter(FLAGS.log_dir, sess.graph)
      for epoch in range(training_epochs):
        # number of batches in one epoch                
        sys.stderr.write(""reporter progress:%0.4f\n""%(float(epoch)/(training_epochs)))
        totalStep = iterData.batchCount()
        for step in range(totalStep):
          iterator_curr = iterData.nextBatch()
          flag = 0
          for iter in iterator_curr:
            if 0 == flag:
                train_x = iter[1].reshape(1,100)
                train_y = oneHot(iter[0]).reshape(1,2)
            else:
                train_x = np.concatenate((train_x, iter[1].reshape(1,100)))
                train_y = np.concatenate((train_y, oneHot(iter[0]).reshape(1,2)))
            flag = 1
          _, summary, cost, gstep = sess.run(
                  [train_op, merged, cross_entropy, global_step],
                  feed_dict={x: train_x, y_: train_y})
          elapsed_time = time.time() - start_time
          start_time = time.time()
          if(FLAGS.task_index == 0):
            train_writer.add_summary(summary, gstep)
          print(""Step: %d,"" % (gstep),
                "" Epoch: %2d,"" % (epoch),                            
                "" Cost: %.4f,"" % cost,
                "" Time: %3.2fms"" % float(elapsed_time*1000))
        sys.stderr.write(""reporter progress:%0.4f\n""%(float(epoch+1)/(training_epochs)))
  
      print(""Train Completed."")
      if(FLAGS.task_index == 0):
        train_writer.close()
        print(""saving model..."")
        saver.save(sess, FLAGS.save_path+""/model.ckpt"")
    print(""done"")       
```
"
17735,FEATURE REQUEST : Kindly provide the gradient for tf.assign,"Hi, i am trying to connect a CNN to another custom layer i have created. However the custom layer that i have created requires the variables in my custom layer to be assigned from the outputs of CNN.

One may think why i need variables if its assigned from CNN at every iteration. 
Reason for variable creation is to calculate explicit gradients(via Register gradient and pyFunc) that involves sparse linear equations ,so that i can apply these gradients on my variables so that the error is back propagated all the way into CNN.

However when i call tf.gradients ,all the values are None for CNN. I found a link over stackoverflow stating that gradients are not defined for tf.assign. 

https://stackoverflow.com/questions/46984316/how-tf-assign-compute-gradients-in-tensorflow

Could you please provide gradient for tf.assign so that i can go for an end to end training.

Thanks.


### Source code / logs
     with tf.variable_scope(""xyz"", reuse=tf.AUTO_REUSE) as scope:        
     F = tf.get_variable(""FXT"",  initializer=''')
     B = tf.get_variable(""BXT"",  initializer='')   
     lambda_tf = tf.get_variable(""lamda_tf"",initializer = [100.0],dtype=tf.float32)

    
    assign_op1 = tf.assign(F,Fx)
    assign_op2 = tf.assign(B,Bx)     
    
    op=custom layer(F,B)
    grads=tf.gradients(op,tf.all_trainables())
Here Fx and Bx are values from CNN

In my backprop i have custom gradients that i have explicitly calculated and over-riden with tf.RegisterGradient and gradient overide.
When i apply calculate grads i get
[None,None,None............None{None values returned for variables in CNN},Defined Gradients{Defined Gradients returned for variables in Custom Layer}]
 "
17734,tf.flags cannot handle options contain hyphen in the middle.,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Google Cloud ML Engine (maybe Ubuntu)
- **TensorFlow installed from (source or binary)**: Pre installed on Google Cloud ML Engine
- **TensorFlow version (use command below)**: 1.5.0
- **Python version**: 2.7
- **Bazel version (if compiling from source)**:NA
- **GCC/Compiler version (if compiling from source)**:NA
- **CUDA/cuDNN version**:NA
- **GPU model and memory**:NA
- **Exact command to reproduce**:

### Describe the problem

According to the documentation of Google Cloud ML Engine [1], the ML Engine pass the option `--job-dir` to the python process and the program should be able to handle `--job-dir` option.

The snippet shown in the next section can run successfully with TensorFlow 1.4.1 but failed with 1.5.0, 1.6.0, 1.7.0.rc0.

As a result, I cannot use runtime version 1.5 on Cloud ML Engine with my package using `tf.flags` to handle option `--job-dir`.
The support of TensorFlow 1.5.0 on Cloud ML Engine training was released officially just few days before [2].


### Source code / logs

Here is a snippet to reproduce the issue.

```
import tensorflow as tf

tf.flags.DEFINE_string(""job-dir"", ""default"", ""job dir"")

def main(argv):
    print(tf.__version__)
    print(tf.flags.FLAGS.job_dir)

tf.app.run()
```

Here is the backtrace from :

```
> python snippent.py --job-dir=foo
1.5.0
Traceback (most recent call last):
  File ""snippet.py"", line 9, in <module>
    tf.app.run()
  File ""/Users/chikanaga/.anyenv/envs/pyenv/versions/2.7.12/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 124, in run
    _sys.exit(main(argv))
  File ""hoge.py"", line 7, in main
    print(tf.flags.FLAGS.job_dir)
  File ""/Users/chikanaga/.anyenv/envs/pyenv/versions/2.7.12/lib/python2.7/site-packages/tensorflow/python/platform/flags.py"", line 85, in __getattr__
    return wrapped.__getattr__(name)
  File ""/Users/chikanaga/.anyenv/envs/pyenv/versions/2.7.12/lib/python2.7/site-packages/absl/flags/_flagvalues.py"", line 470, in __getattr__
    raise AttributeError(name)
AttributeError: job_dir
```

1. https://cloud.google.com/ml-engine/docs/training-overview#job_configuration_parameters
2. https://cloud.google.com/ml-engine/docs/runtime-version-list"
17731,tf.summary.scalar error.  despairing......,"Strange error
While i was trying to tf.summary.scalar('content_loss', self.content_loss) there came an error

InvalidArgumentError (see above for traceback): Cannot assign a device for operation 'auto_loss': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.

Seems strange. However the code can be trained on GPU without the tf.summary.scalar operation"
17730,"freeze_graph.py of tensorflow1.5 without ""--restore_op_name"" function","Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:win10
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**:
- **Python version**: 3.6
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:8.0/7.1
- **GPU model and memory**:navidia GTX 1080Ti
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I use freeze_graph.py of tensorflow1.5 to convert model,but i want to use ""--restore_op_name"".
Is there this function for this version or any other method recommended?
Thanks!

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

My convert command as following:
python freeze_graph.py 
--input_graph=D:\mywork\Re3\demo\simple_as_binary.pb --input_binary=True --input_checkpoint=D:\mywork\Re3\demo\simple.ckpt.data-00000-of-00001 --output_node_names=re3/fc_output/add,re3/lstm1/rnn/while/Exit_3,re3/lstm1/rnn/while/Exit_4,re3/lstm2/rnn/while/Exit_3,re3/lstm2/rnn/while/Exit_4 --restore_op_name=re3/conv1/W_conv,re3/conv1/b_conv,re3/conv1_skip/W_conv,re3/conv1_skip/b_conv,re3/conv1_skip/prelu,re3/conv2/W_conv,re3/conv2/b_conv,re3/conv2_skip/W_conv,re3/conv2_skip/b_conv,re3/conv2_skip/prelu,re3/conv3/W_conv,re3/conv3/b_conv,re3/conv4/W_conv,re3/conv4/b_conv,re3/conv5/W_conv,re3/conv5/b_conv,re3/conv5_skip/W_conv,re3/conv5_skip/b_conv,re3/conv5_skip/prelu,re3/fc6/W_fc,re3/fc6/b_fc,re3/fc_output/W_fc,re3/fc_output/b_fc,re3/lstm1/rnn/LSTM/block_input/biases,re3/lstm1/rnn/LSTM/block_input/weights,re3/lstm1/rnn/LSTM/forget_gate/biases,re3/lstm1/rnn/LSTM/forget_gate/weights,re3/lstm1/rnn/LSTM/input_gate/biases,re3/lstm1/rnn/LSTM/input_gate/weights,re3/lstm1/rnn/LSTM/output_gate/biases,re3/lstm1/rnn/LSTM/output_gate/weights,      re3/lstm2/rnn/LSTM/block_input/biases,re3/lstm2/rnn/LSTM/block_input/weights,re3/lstm2/rnn/LSTM/forget_gate/biases,re3/lstm2/rnn/LSTM/forget_gate/weights,re3/lstm2/rnn/LSTM/input_gate/biases,re3/lstm2/rnn/LSTM/input_gate/weights,re3/lstm2/rnn/LSTM/output_gate/biases,re3/lstm2/rnn/LSTM/output_gate/weights 
--output_graph=frozen_model.pb"
17729,import frozen graph with batchnorm error,"Error when loading the frozen graph with batchnorm.
It shows: ValueError: graph_def is invalid at node u'bn_0/cond/ExponentialMovingAverage/AssignMovingAvg/Switch': Input tensor 'bn_0/bn_0/moments/Squeeze/ExponentialMovingAverage:0' Cannot convert a tensor of type float32 to an input of type float32_ref.
It is same as the question [#3628](https://github.com/tensorflow/tensorflow/issues/3628), and could anyone give me a proper solution for it?
"
17728,pb-》tflite is ok？,"bazel run --config=opt \
  //tensorflow/contrib/lite/toco:toco -- \
 --input_file=/home/ubuntu/Desktop/code/tensorflow/graph_opt.pb \
 --output_file=/home/ubuntu/Desktop/code/tensorflow/graph_opt.pb.tflite \
--input_format=TENSORFLOW_GRAPHDEF \
 --output_format=TFLITE \
--inference_type=FLOAT \
--input_shape=1,128,128,3 \
 --input_array=image \
--output_arrays=Openpose/concat_stage7
WARNING: Config values are not defined in any .rc file: opt
WARNING: /home/ubuntu/.cache/bazel/_bazel_ubuntu/bb7db75967eaf264207472309623127f/external/protobuf_archive/WORKSPACE:1: Workspace name in /home/ubuntu/.cache/bazel/_bazel_ubuntu/bb7db75967eaf264207472309623127f/external/protobuf_archive/WORKSPACE (@com_google_protobuf) does not match the name given in the repository's definition (@protobuf_archive); this will cause a build error in future versions
INFO: Analysed target //tensorflow/contrib/lite/toco:toco (0 packages loaded).
INFO: Found 1 target...
Target //tensorflow/contrib/lite/toco:toco up-to-date:
  bazel-bin/tensorflow/contrib/lite/toco/toco
INFO: Elapsed time: 0.643s, Critical Path: 0.01s
INFO: Build completed successfully, 1 total action

INFO: Running command line: bazel-bin/tensorflow/contrib/lite/toco/toco '--input_file=/home/ubuntu/Desktop/code/tensorflow/graph_opt.pb' '--output_file=/home/ubuntu/Desktop/code/tensorflow/graph_opt.pb.tflite' '--input_format=TENSORFLOW_GRAPHDEF' '--output_format=TFLITE' '--inference_type=FLOAT' '--input_shape=1,128,128,3' '--input_array=image' '--output_arrays=Openpose/concat_stage7'
2018-03-14 17:06:23.573744: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 426 operators, 649 arrays (0 quantized)
2018-03-14 17:06:23.590727: I INFO: Running command line: bazel-bin/tensorflow/contrib/lite/toco/toco '--input_file=/home/ubuntu/Desktop/code/tensorflow/graph_opt.pb' '--output_file=/home/ubuntu/Desktop/code/tensorflow/graph_opt.pb.tflite' '--input_format=TENSORFLOW_GRAPHDEF' '--output_format=TFLITE' '--inference_type=FLOAT' '--input_shape=1,128,128,3' '--input_array=image' '--output_arrays=Openpose/concat_stage7'
2018-03-14 17:06:23.573744: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 426 operators, 649 arrays (0 quantized)
2018-03-14 17:06:23.590727: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 426 operators, 649 arrays (0 quantized)
2018-03-14 17:06:23.608262: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 151 operators, 438 arrays (0 quantized)
2018-03-14 17:06:23.614578: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 151 operators, 438 arrays (0 quantized)
2018-03-14 17:06:23.620831: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:311] Total transient array allocated size: 3400704 bytes, theoretical optimal value: 1886208 bytes.
2018-03-14 17:06:23.621951: I tensorflow/contrib/lite/toco/toco_tooling.cc:309] Estimated count of arithmetic ops: 1.03065 billion (note that a multiply-add is counted as 2 ops).


————————————————————————————————————————————————————


but i run the  tflite get the error


03-15 10:26:22.109 14024-14074/android.example.com.tflitecamerademo E/AndroidRuntime: FATAL EXCEPTION: CameraBackground
                                                                                      Process: android.example.com.tflitecamerademo, PID: 14024
                                                                                      java.lang.IllegalArgumentException: Failed to get input dimensions. 0-th input should have 196608 bytes, but found 406272 bytes.
                                                                                          at org.tensorflow.lite.NativeInterpreterWrapper.getInputDims(Native Method)
                                                                                          at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:82)
                                                                                          at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:112)
                                                                                          at org.tensorflow.lite.Interpreter.run(Interpreter.java:93)
                                                                                          at com.example.android.tflitecamerademo.ImageClassifierQuantizedMobileNet.runInference(ImageClassifierQuantizedMobileNet.java:95)
                                                                                          at com.example.android.tflitecamerademo.ImageClassifier.classifyFrame(ImageClassifier.java:110)
                                                                                          at com.example.android.tflitecamerademo.Camera2BasicFragment.classifyFrame(Camera2BasicFragment.java:663)
                                                                                          at com.example.android.tflitecamerademo.Camera2BasicFragment.-wrap0(Camera2BasicFragment.java)
                                                                                          at com.example.android.tflitecamerademo.Camera2BasicFragment$4.run(Camera2BasicFragment.java:559)
                                                                                          at android.os.Handler.handleCallback(Handler.java:815)
                                                                                          at android.os.Handler.dispatchMessage(Handler.java:104)
                                                                                          at android.os.Looper.loop(Looper.java:207)
                                                                                          at android.os.HandlerThread.run(HandlerThread.java:61)
03-15 10:26:22.119 1125-1823/? E/ActivityManager: Invalid thumbnail dimensions: 0x0

"
17720,map_and_batch tensor shape does not match value of tensor in the same way that calling map and batch individually does,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Happens with stock code
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu Server 17.10.1
- **TensorFlow installed from (source or binary)**:
Source
- **TensorFlow version (use command below)**:
b'v1.6.0-0-gd2e24b6039' 1.6.0
- **Python version**: 
3.6
- **Bazel version (if compiling from source)**:
0.11.0
- **GCC/Compiler version (if compiling from source)**:
gcc (Ubuntu 6.4.0-8ubuntu1) 6.4.0 20171010
- **CUDA/cuDNN version**:
9.1/7.0.5
- **GPU model and memory**:
not applicable
- **Exact command to reproduce**:
not applicable

When I create a tf.data.Dataset from tfrecord files that utilizes a call to `map` to parse the tfrecord file and a call to `batch` to batch the dataset I am able to filter out the last small batch utilizing a straight forward call to `filter`. This same function does not work correctly when utilizing the combined `map_and_batch` function. The filter function in question is:

```
dataset = dataset.filter(
    lambda *args: tf.equal(tf.shape(args[0])[0], batch_size)
)
``` 

The reason this does not work is because every tensor passed through `tf.shape` when utilizing `map_and_batch` has the same shape even though the contents of the tensor does not. This is not the case when executing `map` and `batch` separately, the last batch has a shape returned from `tf.shape` that correctly matches the shape of the value.

My real world example has 7153 batches in 1 epoch, using `map` and `batch` separately I am returned 7152 batches that have a shape returned from `tf.shape` of 128 and the final 1 batch returned as 70, in this case the filter function works correctly. When I swap out this configuration with `map_and_batch` I am returned 7153 batches with shape returned from `tf.shape` of 128, in this case my filter function does not work and my estimator throws an exception because it receives a batch of 70 (when it was expecting a batch of 128).

I would very much like to use `map_and_batch` because it takes 1/3 the time of `map` and `batch` separately.

Here is an example script:

```python
# example.py
import tensorflow as tf

flags = tf.app.flags

flags.DEFINE_boolean('use_broken_map_and_batch', False,
                     'Directory to write the model and ')
flags.DEFINE_string('train_data', 'data.tfrecord', 'Training tfrecord file. ')

FLAGS = flags.FLAGS

def parse_fn(example):
    example_fmt = {
        'src': tf.FixedLenFeature([], tf.int64),
        'dst': tf.FixedLenFeature([], tf.int64),
    }

    features = tf.parse_single_example(
        example,
        features=example_fmt
    )

    return tuple(features[k] for k in example_fmt)


graph = tf.Graph()

with graph.as_default():
    files = tf.data.Dataset.list_files(FLAGS.train_data)
    dataset = files.interleave(tf.data.TFRecordDataset, cycle_length=4)

    if FLAGS.use_broken_map_and_batch:
        dataset = dataset.apply(
            tf.contrib.data.map_and_batch(
                map_func=parse_fn,
                batch_size=128,
                num_parallel_batches=28
            )
        )
    else:
        dataset = dataset.map(parse_fn, num_parallel_calls=28)
        dataset = dataset.batch(128)

    dataset = dataset.filter(
        lambda *args: tf.equal(tf.shape(args[0])[0], 128)
    )

    iterator = dataset.make_one_shot_iterator()
    src, dst = iterator.get_next()

    train_op = src * dst

    init_op = tf.group(tf.global_variables_initializer(),
                       tf.local_variables_initializer())

with tf.Session(graph=graph) as sess:
    sess.run(init_op)

    shapes = []

    try:
        while True:
            val = sess.run(train_op)
            shapes.append(val.shape[0])
    except tf.errors.OutOfRangeError:
        print(shapes[-10:])
```

When executed with the following parameters you should see the output:

```
$ python example.py --train_data data.tfrecord

[128, 128, 128, 128, 128, 128, 128]

$ python example.py --train_data data.tfrecord  --use_broken_map_and_batch

[128, 128, 128, 128, 128, 128, 128, 104]
```

To be clear the execution with the  ` --use_broken_map_and_batch` shows a 104 at the end, this is because that batch was not filtered out, you can recreate this by using the following code to generate a tfrecord file:

```
# data_generation.py
import numpy as np
import tensorflow as tf

flags = tf.app.flags

flags.DEFINE_string('train_data', 'data.tfrecord', 'Training tfrecord file. ')

FLAGS = flags.FLAGS

vals = np.random.randint(1, 1000, (1000, 2))

with tf.python_io.TFRecordWriter(FLAGS.train_data) as writer:
    for src, dst in vals:
        example = tf.train.Example(
            features=tf.train.Features(
                feature={
                    'src': tf.train.Feature(
                        int64_list=tf.train.Int64List(value=[src])),
                    'dst': tf.train.Feature(
                        int64_list=tf.train.Int64List(value=[dst])),
                }
            )
        )

        serialized = example.SerializeToString()
        writer.write(serialized)
```

And you can execute in this way:

```
$ python data_generation.py --train_data data.tfrecord
```

Any help on this issue is greatly appreciated."
17717,Add working example of distributed tensorflow using Estimator API for K-Means,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Redhat
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: 1.5
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: N.A.
- **GCC/Compiler version (if compiling from source)**: N.A.
- **CUDA/cuDNN version**: N.A.
- **GPU model and memory**: N.A.
- **Exact command to reproduce**: N.A.

### Describe the problem
I am using standard library-provided k-means with Estimator API for distributed tensorflow. I have a cluster of three machine and I have updated the TF_CONFIG env. variable on all three machine. I am using HDFS to store the model directory so that all machine can access that it, but when I execute the python file from the master machine, the gRPC server gets created and then ""PS server and Worker server waiting for response from master""  message is repeated after every 10 seconds or so.  

If sample code for using this Estimator-API based K-Means would had been present, it would have helped better

### Source code / logs
import tensorflow as tf
import numpy as np
import pandas as pd
k = 5
n = 100
variables = 2
points = np.random.uniform(0, 1000, [n, variables])
input_fn=lambda: tf.train.limit_epochs(tf.convert_to_tensor(points, dtype=tf.float32), num_epochs=1)
kmeans=tf.contrib.factorization.KMeansClustering(num_clusters=k, use_mini_batch=False,model_dir=""my_hdfs_path"")

train_spec = tf.estimator.TrainSpec(input_fn=input_fn, max_steps=100)
eval_spec = tf.estimator.EvalSpec(input_fn=input_fn)

tf.estimator.train_and_evaluate(kmeans, train_spec, eval_spec)
list(kmeans.predict(input_fn=input_fn))

### TF_CONFIG:
{ ""cluster"":{ ""chief"":[ ""master:22220"" ], ""ps"":[ ""slave02:22220"" ], ""worker"":[ ""slave01:22220"" ] }, ""task"":{  ""type"":""chief"", ""index"":0, } }

Error message:
CreateSession still waiting for response from worker: /job:ps/replica:0/task:0
CreateSession still waiting for response from worker: /job:worker/replica:0/task:0"
17715,GPU issue,"Hi. I am new to TensorFlow, and I installed everything as instructed. However, I get the error below after successfully importing tf. Does anyone know how to fix this? I am using a Surface Book 2 with a 1060 NVIDIA GPU.

Thanks

>>> import tensorflow as tf
>>> hello = tf.constant('Hello, TensorFlow!')
>>> sess = tf.Session()
2018-03-14 12:19:36.435333: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2018-03-14 12:19:37.605256: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1212] Found device 0 with properties:
name: GeForce GTX 1060 major: 6 minor: 1 memoryClockRate(GHz): 1.569
pciBusID: 0000:02:00.0
totalMemory: 6.00GiB freeMemory: 4.97GiB
2018-03-14 12:19:37.611418: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-03-14 12:19:39.295420: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4744 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060, pci bus id: 0000:02:00.0, compute capability: 6.1)"
17713,Manual Placement of Graph Nodes of High-level Optimizers and Loss functions,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.6.0-rc1
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: 0.11.0
- **GCC/Compiler version (if compiling from source)**: 5.4
- **CUDA/cuDNN version**: 9.1/7.0
- **GPU model and memory**: Tesla k80 (11441MiB)
- **Exact command to reproduce**: python cifar10_train.py

### Describe the problem
I want to use my own device placement algorithm to be used to place nodes across multiple devices my machine has. I looked into this : https://www.tensorflow.org/programmers_guide/using_gpu#manual_device_placement which suggests that if I figure out exact placement statically before executing the graph, I can use ""with device"" annotations to partition my graph across devices. But, if I am using some high-level optimizers and loss functions. Each of these operations are going to have a multi-node graph as well. Suppose I am running this example : https://github.com/tensorflow/models/tree/master/tutorials/image/cifar10 and want to specify where each node of the complete tensor flow graph should go given a list of compute resources (cpu cores, gpu, tpu etc.) my machine has.  

Is there any api or framework that allows you to do fine grained placement of graph nodes across multiple compute resources ? What's the best way to achieve this ?  

Thanks a lot for any help!


### Source code / logs
cifar10 example : https://github.com/tensorflow/models/tree/master/tutorials/image/cifar10"
17709,Error: C++ compilation of rule '@protobuf_archive//:protobuf_lite' failed,"I am trying to build tensorflow inference library using the instructions [here](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/android).

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04.4 LTS
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**:  Master (10be1f2377bf7aad1a4cfa306277c53e44493a57)
- **Python version**: Python 3.6.3 :: Anaconda custom (64-bit)
- **Bazel version (if compiling from source)**: 0.11.1
- **GCC/Compiler version (if compiling from source)**: 5.4.0
- **CUDA/cuDNN version**: 9.0
- **GPU model and memory**: Tesla K80 12GB
- **Exact command to reproduce**: ```bazel build -c opt //tensorflow/contrib/android:libtensorflow_inference.so    --crosstool_top=//external:android/crosstool    --host_crosstool_top=@bazel_tools//tools/cpp:toolchain    --cpu=armeabi-v7a --verbose_failures```

### Describe the problem
Bazel build is failing with the error `C++ compilation of rule '@protobuf_archive//:protobuf_lite' failed`.
The full error is pasted below. I have tried `bazel clean`.

### Source code / logs
```
ERROR: /home/ubuntu/.cache/bazel/_bazel_ubuntu/ad1e09741bb4109fbc70ef8216b59ee2/external/protobuf_archive/BUILD:66:1: C++ compilation of rule '@protobuf_archive//:protobuf_lite' failed (Exit 1): false failed: error executing command 
  (cd /home/ubuntu/.cache/bazel/_bazel_ubuntu/ad1e09741bb4109fbc70ef8216b59ee2/execroot/org_tensorflow && \
  exec env - \
    PWD=/proc/self/cwd \
  /bin/false -MD -MF bazel-out/armeabi-v7a-opt/bin/external/protobuf_archive/_objs/protobuf_lite/external/protobuf_archive/src/google/protobuf/arena.pic.d '-frandom-seed=bazel-out/armeabi-v7a-opt/bin/external/protobuf_archive/_objs/protobuf_lite/external/protobuf_archive/src/google/protobuf/arena.pic.o' -fPIC -iquote external/protobuf_archive -iquote bazel-out/armeabi-v7a-opt/genfiles/external/protobuf_archive -iquote external/bazel_tools -iquote bazel-out/armeabi-v7a-opt/genfiles/external/bazel_tools -isystem external/protobuf_archive/src -isystem bazel-out/armeabi-v7a-opt/genfiles/external/protobuf_archive/src -isystem external/bazel_tools/tools/cpp/gcc3 -DHAVE_PTHREAD -Wall -Wwrite-strings -Woverloaded-virtual -Wno-sign-compare -Wno-unused-function -Wno-writable-strings -c external/protobuf_archive/src/google/protobuf/arena.cc -o bazel-out/armeabi-v7a-opt/bin/external/protobuf_archive/_objs/protobuf_lite/external/protobuf_archive/src/google/protobuf/arena.pic.o)
Target //tensorflow/contrib/android:libtensorflow_inference.so failed to build
INFO: Elapsed time: 3.864s, Critical Path: 0.01s
FAILED: Build did NOT complete successfully
```
"
17708,Suggestion:Tensor add the finalize method to close tensor object after GC,"System information
Have I written custom code (as opposed to using a stock example script provided in TensorFlow): NO
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): Master
Python version: 3.6
Bazel version (if compiling from source): N/A
GCC/Compiler version (if compiling from source): N/A
CUDA/cuDNN version: None
GPU model and memory: None
Exact command to reproduce: Run the snippet below.

Describe the problem
Tensor object should initiative call close method to release native memory, but the document don't have any reference to mention this important function.
To avoid some guy to forget call this method, suggest invoke close method in the finalize method that let GC try compensate it at last.
`Public void finalize(){
close()
}`

  "
17707,Centered padded batch on tf.data.dataset with image-features and bounding boxes,"Hello everyone,

I have a feature request to the `tf.data.dataset` API which might also benefit many other users.
The use case is this:
Suppose you have a regular instance based segmentation dataset containing images features, image-targets (for segmentation), bounding boxes, and a class- and instance id to each bounding box. ([Mapillary](https://blog.mapillary.com/product/2017/05/03/mapillary-vistas-dataset.html) is a nice example for that, even though it natively does not contain bounding boxes, but they can be inferred, because it has pixel wise instances)

If you use the `tf.data.dataset` API to create a dataset in one or another way (for instance use a `generator` and then create the dataset with `tf.data.Dataset.from_generator`), you can create a dataset including the feature_images, target_images and bounding boxes.

Now you want to batch them together.
The problem is, that the images may have different sizes and the number of bounding boxes per image may be different for each entry of the dataset. Therefore you can not batch them unless you make sure they have the same size. To keep the aspect ratio in the images one could consider padding the images according to the biggest size in the batch. Also the bounding boxes can be padded, according to the maximum number of bounding boxes in the batch. And there already is a function that does that: `tf.data.dataset.padded_batch`. Unfortunately the padding is always applied to the end of the dimension:
A picture with
```
[[1,1,1,1]
 [1,1,1,1]
 [1,1,1,1]
 [1,1,1,1]]
```

padded by 2 would look like:
```
[[1,1,1,1,0,0]
 [1,1,1,1,0,0]
 [1,1,1,1,0,0]
 [1,1,1,1,0,0]
 [0,0,0,0,0,0]
 [0,0,0,0,0,0]]
```

This would likely lead to dead or irrelevant neurons within the receptive field at the right or bottom of the image. Therefore a centered padding would be nice:
```
[[0,0,0,0,0,0]
 [0,1,1,1,1,0]
 [0,1,1,1,1,0]
 [0,1,1,1,1,0]
 [0,1,1,1,1,0]
 [0,0,0,0,0,0]]
```

Up until here there already exists an issue that covers the behaviour [here](https://github.com/tensorflow/tensorflow/issues/13969#issuecomment-370902365) . But now comes the tricky part: If we pad the image at the top or the left, we need an offset to the bounding boxes according to the padding because the edges of the bounding boxes are in image coordinates and shift when the image is padded.

So here is my suggestion:
One could extend the `tf.data.dataset.padded_patch` to perform centered padding on each dimension with an additional `centered` flag or so, similar as suggested in the issue above, but also returns the maximum dimension within each element of the batch. This information can then be used to adjust the bounding box location.

Alternative:
One could also consider an operator to return the maximum dimensions within the bath to use that information for padding. I could imagine, to have a `self written padding function` and use `tf.data.map` and the maximum batch dimensions information to incorporate the padding to the dataset per element using `tf.pad` or similar. The nice thing about this alternative approach is, that the users can build the padding as they want since `tf.pad` already can do central padding and other styles.

I had a little dive into the functionality of `padded_batch` and it seems that the calculation of the maximum dimension is done in `tensorflow/core/kernels/data/padded_batch_dataset_op.cc` line 264 ff. This however is in the iterator class, which I presume is called when the data is actually passed through. So I'm not sure if or how to return the maximum batch dimensions from there to the point where I can use it to pad the images. If this is indeed not possible, I'd appreciate other suggestions because the way it is, the `tf.data.dataset` can not be used for this kind of data.

"
17705,Couldn't open CUDA library cublas64_80.dll,"tensorflow just run hello world
it is work, but alarms appear.
is this ok ? it is run by gpu or cpu
os: win10
GPU Toolkit version : v9.0
cudnn verson: v7.1
anaconda3 version: v5.1

image easy to view
https://drive.google.com/open?id=1ko9Le7e_2FTJRaAGohRh4I8w43c565yf

text for more detail

> (tensorflow) C:\Users\yi\Anaconda3\Scripts>python
Python 3.5.5 |Anaconda, Inc.| (default, Mar  9 2018, 12:39:44) [MSC v.1900 64 bit (AMD64)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:126] Couldn't open CUDA library cublas64_80.dll
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\cuda\cuda_blas.cc:2294] Unable to load cuBLAS DSO.
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:126] Couldn't open CUDA library cudnn64_5.dll
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\cuda\cuda_dnn.cc:3517] Unable to load cuDNN DSO
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:126] Couldn't open CUDA library cufft64_80.dll
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\cuda\cuda_fft.cc:344] Unable to load cuFFT DSO.
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:135] successfully opened CUDA library nvcuda.dll locally
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:126] Couldn't open CUDA library curand64_80.dll
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\cuda\cuda_rng.cc:338] Unable to load cuRAND DSO.
>>> import tensorflow as tf
>>> hello=tf.constant('hello, TensorFlow!')
>>> sess=tf.Session()
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:885] Found device 0 with properties:
name: GeForce GTX 1050
major: 6 minor: 1 memoryClockRate (GHz) 1.493
pciBusID 0000:01:00.0
Total memory: 2.00GiB
Free memory: 1.62GiB
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:906] DMA: 0
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:916] 0:   Y
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0)
>>> print(sess.run(hello))
E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""BestSplits"" device_type: ""CPU""') for unknown op: BestSplits
E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""CountExtremelyRandomStats"" device_type: ""CPU""') for unknown op: CountExtremelyRandomStats
E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""FinishedNodes"" device_type: ""CPU""') for unknown op: FinishedNodes
E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""GrowTree"" device_type: ""CPU""') for unknown op: GrowTree
E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""ReinterpretStringToFloat"" device_type: ""CPU""') for unknown op: ReinterpretStringToFloat
E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""SampleInputs"" device_type: ""CPU""') for unknown op: SampleInputs
E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""ScatterAddNdim"" device_type: ""CPU""') for unknown op: ScatterAddNdim
E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""TopNInsert"" device_type: ""CPU""') for unknown op: TopNInsert
E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""TopNRemove"" device_type: ""CPU""') for unknown op: TopNRemove
E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""TreePredictions"" device_type: ""CPU""') for unknown op: TreePredictions
E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""UpdateFertileSlots"" device_type: ""CPU""') for unknown op: UpdateFertileSlots
b'hello, TensorFlow!'"
17702,UnrecognizedFlagError: Unknown command line flag 'f',"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: custom code
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: tensorflow 1.5.0
- **Python version**: pyhton 3.6.3
- **Bazel version (if compiling from source)**: None
- **GCC/Compiler version (if compiling from source)**: None
- **CUDA/cuDNN version**:  None
- **GPU model and memory**: GTX960M
- **Exact command to reproduce**:

Problem Description

When trying to run this code
```
import tensorflow as tf

flags = tf.app.flags
FLAGS = flags.FLAGS
flags.DEFINE_float('learning_rate', 0.01, 'Initial learning rate.')
flags.DEFINE_integer('max_steps', 2000, 'Number of steps to run trainer.')
flags.DEFINE_integer('hidden1', 128, 'Number of units in hidden layer 1.')
flags.DEFINE_integer('hidden2', 32, 'Number of units in hidden layer 2.')
flags.DEFINE_integer('batch_size', 100, 'Batch size. '
'Must divide evenly into the dataset sizes.')
flags.DEFINE_string('train_dir', 'data', 'Directory to put the training data.')
flags.DEFINE_boolean('fake_data', False, 'If true, uses fake data '
'for unit testing.')

FLAGS = flags.FLAGS
print(FLAGS.learning_rate)
```
I got this error message
```
---------------------------------------------------------------------------
UnrecognizedFlagError                     Traceback (most recent call last)
<ipython-input-3-1ce89dff3e81> in <module>()
      1 FLAGS = flags.FLAGS
----> 2 print(FLAGS.learning_rate)

c:\users\jinsu\appdata\local\programs\python\python36\lib\site-packages\tensorflow\python\platform\flags.py in __getattr__(self, name)
     82     # a flag.
     83     if not wrapped.is_parsed():
---> 84       wrapped(_sys.argv)
     85     return wrapped.__getattr__(name)
     86 

c:\users\jinsu\appdata\local\programs\python\python36\lib\site-packages\absl\flags\_flagvalues.py in __call__(self, argv, known_only)
    628       suggestions = _helpers.get_flag_suggestions(name, list(self))
    629       raise _exceptions.UnrecognizedFlagError(
--> 630           name, value, suggestions=suggestions)
    631 
    632     self.mark_as_parsed()

UnrecognizedFlagError: Unknown command line flag 'f'
```
This is another
```
import tensorflow as tf

FLAGS = tf.app.flags.FLAGS
FLAGS.learning_rate = 0.02
FLAGS.name = 'test'

print(FLAGS.learning_rate)
print(FLAGS.name)
```
```
---------------------------------------------------------------------------
UnrecognizedFlagError                     Traceback (most recent call last)
<ipython-input-1-fe17797ba132> in <module>()
      2 
      3 FLAGS = tf.app.flags.FLAGS
----> 4 FLAGS.learning_rate = 0.02
      5 FLAGS.name = 'test'
      6 

c:\users\jinsu\appdata\local\programs\python\python36\lib\site-packages\tensorflow\python\platform\flags.py in __setattr__(self, name, value)
     86 
     87   def __setattr__(self, name, value):
---> 88     return self.__dict__['__wrapped'].__setattr__(name, value)
     89 
     90   def __delattr__(self, name):

c:\users\jinsu\appdata\local\programs\python\python36\lib\site-packages\absl\flags\_flagvalues.py in __setattr__(self, name, value)
    494       raise AttributeError(name)
    495     if name not in fl:
--> 496       return self._set_unknown_flag(name, value)
    497     fl[name].value = value
    498     self._assert_validators(fl[name].validators)

c:\users\jinsu\appdata\local\programs\python\python36\lib\site-packages\absl\flags\_flagvalues.py in _set_unknown_flag(self, name, value)
    372       except NameError:  # Flag name is not valid.
    373         pass
--> 374     raise _exceptions.UnrecognizedFlagError(name, value)
    375 
    376   def append_flag_values(self, flag_values):

UnrecognizedFlagError: Unknown command line flag 'learning_rate'

```
Did I miss anything??
I cannot figure out what the problem is."
17699,How to convert .pb file to .ckpt file,"How to convert .pb file to .ckpt file??
   as following code raise error:  ValueError: No variables to save

#!/usr/bin/env python
#coding: utf-8

import tensorflow as tf
import argparse 

# Pass the filename as an argument
parser = argparse.ArgumentParser()
parser.add_argument(""--frozen_model_filename"", default=""frozen_inference_graph.pb"", type=str, help=""Pb model file to import"")
args = parser.parse_args()

# We load the protobuf file from the disk and parse it to retrieve the 
# unserialized graph_def
with tf.gfile.GFile(args.frozen_model_filename, ""rb"") as f:
    graph_def = tf.GraphDef()
    graph_def.ParseFromString(f.read())

    #saver=tf.train.Saver()
    with tf.Graph().as_default() as graph:

        tf.import_graph_def(
            graph_def,
            input_map=None,
            return_elements=None,
            name=""prefix"",
            op_dict=None,
            producer_op_list=None
        )
        sess = tf.Session(graph=graph)
        saver = tf.train.Saver()
        save_path = saver.save(sess, ""model.ckpt"")
        print(""Model saved to chkp format"")"
17698,Session JNI interface has memory leak,"System information
Have I written custom code (as opposed to using a stock example script provided in TensorFlow): NO
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): Master
Python version: 3.6
Bazel version (if compiling from source): N/A
GCC/Compiler version (if compiling from source): N/A
CUDA/cuDNN version: None
GPU model and memory: None
Exact command to reproduce: Run the snippet below.

Describe the problem
Read the tensorflow_jni.cc code in the code section as blow.

```
  TF_Graph* graph = reinterpret_cast<TF_Graph*>(graph_handle);
  TF_Status* status = TF_NewStatus();
  TF_SessionOptions* opts = TF_NewSessionOptions();
  const char* ctarget = nullptr;
  jbyte* cconfig = nullptr;
  if (target != nullptr) {
    ctarget = env->GetStringUTFChars(target, nullptr);
  }
  if (config != nullptr) {
    cconfig = env->GetByteArrayElements(config, nullptr);
    TF_SetConfig(opts, cconfig,
                 static_cast<size_t>(env->GetArrayLength(config)), status);
    if (!throwExceptionIfNotOK(env, status)) {
      env->ReleaseByteArrayElements(config, cconfig, JNI_ABORT);
      //Not release the status, opts
      return 0;
    }
  }
```
After throw exception, it look like not release the status, opts memory.


"
17695,tf.gfile doesn't understand NTFS Unicode filenames on Windows,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows Server 2016 Datacenter, 64-bit, installed on a GCE VM
- **TensorFlow installed from (source or binary)**: binary pip package
- **TensorFlow version (use command below)**: 1.6.0
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: `python -c ""dir = '/tmp/tftest/\u8c37\u6b4c'; import tensorflow as tf; import os; os.makedirs(dir); print(os.path.exists(dir), tf.gfile.Exists(dir))""`

### Describe the problem
The tf.gfile functions that involve file paths appear not to understand Windows with NTFS filenames that contain Unicode characters, such as 谷歌 (""Google"" in Chinese).  It seems like something about the name isn't translated in a way that actually results in successful lookups, so everything behaves as if those files didn't exist.

Command to repro:
```
python -c ""dir = '/tmp/tftest/\u8c37\u6b4c'; import tensorflow as tf; import os; os.makedirs(dir); print(os.path.exists(dir), tf.gfile.Exists(dir))""
```

This command run in Windows PowerShell prints ""True False"" i.e. `os.path.exists()` returns a different result than `tf.gfile.Exists()`.  This is true even for different ways of formulating that path -
 in addition to `/tmp/tftest/\u8c37\u6b4c` I tested `C:/tmp/tftest/\u8c37\u6b4c` and `C:\\tmp\\tftest\\\u8c37\u6b4c` (double backslashes for the path separators to escape within a python string) and they both produce the same result.  If you remove the unicode characters from the path, it prints ""True True"" as expected.

In contrast, on my gLinux workstation this prints ""True True"" all the time, i.e. the results are the same.

I tested this with Exists(), IsDirectory(), and ListDirectory() but I'm assuming it applies generally to all the tf.gfile functions that take a path argument.  Note however that ListDirectory() will *return* the Unicode name just fine if run in the parent directory, the same as `os.listdir()`.

We've gotten a report about this for TensorBoard: https://github.com/tensorflow/tensorboard/issues/861
"
17694,tf.test.TestCase not working properly with tf.map_fn,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: mac OSX
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.4.0 and 1.5.0
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: None
- **GPU model and memory**: None
- **Exact command to reproduce**: Run the snippet below.

### Describe the problem

When trying to run tf.test.TestCase with a tensor of strings, tf.map_fn() throws errors that a normal tf.Session.run() does not encounter.

I am trying to create unit tests with tf.test.TestCase, but could not find a way to test tf.map_fn without Tensorflow returning an error. (This occurs in both TF 1.4 and 1.5.) My guess is it has to do with how strings are treated by map_fn as tensors...

### Source code / logs

Here is a very simple example:
```
    def identity_map(input):
      return input

    # Using tf.Session() and sess.run(). This runs without errors.
    input = ['123', 'abc']
    x = tf.map_fn(identity_map, input_tensor, dtype=tf.string)
    x = tf.stack(x)
    x = tf.reshape(tensor=x, shape=[-1])

    with tf.Session() as sess:
      result = sess.run(x, {input_tensor: input})
      print(result)
```

Now I create a unit test and try to run it:

```
    class SimpleTest(tf.test.TestCase):
      def testMapString(self):
        input = ['123', 'abc']
        with self.test_session():
          # Run map function
          x = tf.map_fn(identity_map, input, dtype=tf.string)
          x = tf.stack(x)
          x = tf.reshape(tensor=x, shape=[-1])
          result = x.eval()
          print(result)
```

I get this output. Any idea what went wrong?
```
Traceback (most recent call last):
...
  File ""/Users/bfoo/venv3/strata/lib/python3.6/site-packages/tensorflow/python/ops/functional_ops.py"", line 344, in map_fn
    n = array_ops.shape(elems_flat[0])[0]
  File ""/Users/bfoo/venv3/strata/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py"", line 538, in _SliceHelper
    name=name)
  File ""/Users/bfoo/venv3/strata/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py"", line 706, in strided_slice
    shrink_axis_mask=shrink_axis_mask)
  File ""/Users/bfoo/venv3/strata/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 5430, in strided_slice
    name=name)
  File ""/Users/bfoo/venv3/strata/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/Users/bfoo/venv3/strata/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 2958, in create_op
    set_shapes_for_outputs(ret)
  File ""/Users/bfoo/venv3/strata/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 2209, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/Users/bfoo/venv3/strata/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 2159, in call_with_requiring
    return call_cpp_shape_fn(op, require_shape_fn=True)
  File ""/Users/bfoo/venv3/strata/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py"", line 627, in call_cpp_shape_fn
    require_shape_fn)
  File ""/Users/bfoo/venv3/strata/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py"", line 691, in _call_cpp_shape_fn_impl
    raise ValueError(err.message)
ValueError: slice index 0 of dimension 0 out of bounds. for 'map_1/strided_slice' (op: 'StridedSlice') with input shapes: [0], [1], [1], [1] and with computed input tensors: input[1] = <0>, input[2] = <1>, input[3] = <1>.
```"
17693,Online Hard Example Mining,Is there a plan for OHEM in `tf.estimator.train_and_evaluate` or in combo with dataset api?
17691,tf 1.4 and tf1.5 and tf1.6 ,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:  No

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  
Mac OS

- **TensorFlow installed from (source or binary)**:
pip install from binary

- **TensorFlow version (use command below)**:
1.4 and 1.6 

- **Python version**: 
2.7 

- **Bazel version (if compiling from source)**:
N/A
- **GCC/Compiler version (if compiling from source)**:
N/A
- **CUDA/cuDNN version**:
N/A
- **GPU model and memory**:
N/A


### Describe the problem
I had a model trained (with multiple days) using tf1.4, and I want to load it in tf1.6.  and the error occurs as below: 

  File ""/Users/iyukun/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2427, in set_shapes_for_outputs
    return _set_shapes_for_outputs(op)
  File ""/Users/iyukun/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2400, in _set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/Users/iyukun/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2330, in call_with_requiring
    return call_cpp_shape_fn(op, require_shape_fn=True)
  File ""/Users/iyukun/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.py"", line 627, in call_cpp_shape_fn
    require_shape_fn)
  File ""/Users/iyukun/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.py"", line 691, in _call_cpp_shape_fn_impl
    raise ValueError(err.message)
ValueError: Dimensions must be equal, but are 900 and 600 for 'dynamic_seq2seq/decoder/decoder/while/BeamSearchDecoderStep/multi_rnn_cell/cell_1/basic_lstm_cell/MatMul' (op: 'MatMul') with input shapes: [?,900], [600,1200].

Looks like the MatMul op is changed from float16 to float32 in tf 1.5+?  If so,  is there a way to load the model in tf1.5+? 
"
17689,Installation Problem,">>> import numpy
>>> import tensorflow
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 72, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
ImportError: libcudnn.so.6: cannot open shared object file: No such file or directory


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
>>> 
What's the problem?Please give me solution.Ubuntu 16.04Lts and GPU NVIDIA 1050 Ti 4GB,CUDA -8,CuDNN-5.1"
17687,Unable to match the last equations from the nmt paper in the nmt implementation,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution**: Linux Ubuntu 16.04
- **TensorFlow installed from**: binary
- **TensorFlow version**: 1.4.0
- **Python version**: 3.5.2
- **Bazel version (if compiling from source)**: not compiled from source
- **GCC/Compiler version (if compiling from source)**: not compiled from source
- **CUDA/cuDNN version**: 8.0/6
- **GPU model and memory**: 8GB x 4 GTX 1080
- **Exact command to reproduce**: N/A

I have already asked the question over [tensorflow/nmt](https://github.com/tensorflow/nmt/issues/271) but also asking here to maybe grab some traction:

In the [NMT paper, pg 13-14](https://arxiv.org/pdf/1409.0473.pdf), they've defined the model architecture. In the Decoder section (A 2.2), they've proposed probability of a target word w.r.t the deep output (ti~) with a single maxout hidden layer.

But if I look at the source code where the [graph is built](https://github.com/tensorflow/nmt/blob/master/nmt/model.py#L274), it calls the [_build_decoder](https://github.com/tensorflow/nmt/blob/master/nmt/model.py#L358) function where the decoder section is built, I could not find the implementation of these equations: 

![image](https://user-images.githubusercontent.com/15987266/37344796-5b646920-26f1-11e8-999b-f9249b0cff51.png)

Can someone clarify as to how those equations are included in the nmt implementation?"
17684,Error converting the model to TF Lite,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Ubuntu 16.04.4
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**:  r1.6 commit: cbc658095ae228f2f557af47e4901d552573aa15
- **Python version**: 3.5.2
- **Bazel version (if compiling from source)**: 0.11.1
- **GCC/Compiler version (if compiling from source)**:  gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.9)
- **CUDA/cuDNN version**: N/A (build without support CUDA)
- **GPU model and memory**: N/A (build without support CUDA)
- **Exact command to reproduce**: 

### Describe the problem
Trained model, successfully froze, it works on the tensorflow android, using TensorFlowInferenceInterface.
I try to convert this into a TF Lite format, but I get an error.

### Source code / logs
```
bazel-bin/tensorflow/contrib/lite/toco/toco \
    --input_file=./test_model/frozen_graph.pb \
    --input_format=TENSORFLOW_GRAPHDEF \
    --output_file=./test_model/unet.tflite \
    --output_format=TFLITE \
    --input_array='input' \
    --input_data_type=FLOAT \
    --input_shape=2,192,320,1 \
    --inference_type=FLOAT \
    --inference_input_type=FLOAT \
    --output_array='final/Sigmoid' \
    --v=1
```
```
2018-03-13 21:07:12.711948: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 282 operators, 479 arrays (0 quantized)
2018-03-13 21:07:12.716274: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 282 operators, 479 arrays (0 quantized)
2018-03-13 21:07:12.716893: F tensorflow/contrib/lite/toco/graph_transformations/resolve_batch_normalization.cc:86] Check failed: mean_shape.dims() == multiplier_shape.dims()
Aborted (core dumped)
```"
17683,graph_def.ParseFromString>google.protobuf.message.DecodeError: Error parsing message," I have the model fine tuned Inception model with my images set data by tensorflow/examples/image_retraining/retrain.py. Then, running python tensorflow/examples/label_image/label_image.py  for classification the custom image I get error:        `graph_def.ParseFromString(f.read())`
`google.protobuf.message.DecodeError:` Error parsing message.
Tensorflow version 1.6.0 , GPU build. 
I have other fine tuned Inception model  that running without this error:
` 95781819 Mar 12 19:37 carvajal_model.pb`  * this run with Parser error
` 87458742 Mar  1 14:33 flow_model.pb`
` 87622663 Mar  2 17:58 grocery_model.pb`
There is not a  big difference  the size of the model files , the problem model file has size 95m and well running models have  87m.

Trace >
`Traceback (most recent call last):
  File ""./label_image.py"", line 117, in <module>
    graph = load_graph(model_file)
  File ""./label_image.py"", line 30, in load_graph
    graph_def.ParseFromString(f.read())
google.protobuf.message.DecodeError: Error parsing message`

Are some advices about ?"
17682,Wrong Library,
17679,Error with combination of 'numpy_input_fn' and 'tf.contrib.seq2seq.AttentionWrapper',"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.4 and 1.6 both
- **Python version**: 2
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: 8 for tensorflow 1.4 and 9.0 for tensorflow 1.6
- **GPU model and memory**: gtx 1080ti
- **Exact command to reproduce**: I would like to send my code via email.

**Problem description:**
I am now modeling an architecture that is related to encoder-decoder model. So, first of all, I wrote my own source code of encoder-decoder model with tensorflow api. the abstract structure of my source code(`model_fn` which is used for `tf.contrib.learn.Experiment`) is as follows:

```
def model_fn(features, labels, mode, params):
    
    start_token = 1 
    end_token = 2
    # should pay attention to this batch_size from params
    batch_size = params['batch_size']

    input = features['input'] # [batch, length]
    input_length = features['input_length']
    
    if mode != tf.estimator.ModeKeys.PREDICT:
        target = features['target'] # label
        target_length = features['target_length']
    
    # Embedding for sentence, question and rnn encoding of sentence
    with tf.variable_scope('SharedScope'):
        # Embedded inputs
        # [batch, input_length] -> [batch, input_length, hidden_size]
        embd_input = embed_op(input, params, name = 'embedded_input')
        embd_target = embed_op(target, params, name = 'embedded_target')

        # Build encoder cell
        encoder_cell = tf.nn.rnn_cell.GRUCell(hidden_size)

        # Run Dynamic RNN
        #   encoder_outputs: [max_time, batch_size, num_units]
        #   encoder_state: [batch_size, num_units]
        encoder_outputs, encoder_state = tf.nn.dynamic_rnn(
            encoder_cell, embd_input,
            sequence_length=input_length,
            dtype = tf.float32    
            )   
        
    with tf.variable_scope('SharedScope/EmbeddingScope', reuse = True):
        embedding_target = tf.get_variable('embedding_target')
    
    # Rnn decoding of sentence with attention 
    with tf.variable_scope('Decoder'):
        # Memory for attention
        attention_states = encoder_outputs

        # Create an attention mechanism
        attention_mechanism = tf.contrib.seq2seq.LuongAttention(
                hidden_size, attention_states,
                memory_sequence_length=input_length)

        # Build decoder cell
        decoder_cell = tf.nn.rnn_cell.GRUCell(hidden_size)

        decoder_cell = tf.contrib.seq2seq.AttentionWrapper(
                decoder_cell, attention_mechanism,
                attention_layer_size= hidden_size)

        # Helper for decoder cell
        if mode == tf.estimator.ModeKeys.TRAIN:
            maxlen_target = params['maxlen_target'] * tf.ones(batch_size], dtype = tf.int32)
            helper = tf.contrib.seq2seq.TrainingHelper(
                    embd_target, maxlen_target
                    )
        else: # EVAL & TEST
            start_tokens = start_token * tf.ones([batch_size], dtype = tf.int32)
            helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(
                    embedding_target, start_tokens, end_token
                    )
        # Decoder
        initial_state = decoder_cell.zero_state(dtype = tf.float32, batch_size = batch_size)
        projection_q = tf.layers.Dense(target_voca_size, use_bias = True)

        decoder = tf.contrib.seq2seq.BasicDecoder(
            decoder_cell, helper, initial_state,
            output_layer=None)

        # Dynamic decoding
        max_iter = params['maxlen_target_dev'] 

        if mode == tf.estimator.ModeKeys.TRAIN:
            outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder, impute_finished=True, maximum_iterations = None)
        else: # Test
            outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder, impute_finished=True, maximum_iterations = max_iter)

        logits_q = projection_q(outputs.rnn_output)
.
.
.
```

and the data(`features`) are feeded through `tf.estimator.inputs.numpy_input_fn`:
For evaluation data:

```
    # Evaluation input function for estimator
    eval_input_fn = tf.estimator.inputs.numpy_input_fn(
        x = {""input"": eval_input, 'target': eval_target, 
            'input_length': eval_input_length, 'len_q': eval_target_length},
        y = None,
        batch_size = model_params['batch_size'], # batch size that i specified
        num_epochs=1,
        shuffle=False)  
```


**When `batch_size` that I specified has lower value than 99(not including), it works fine**, I mean, when I run `neural_network_experiment.train_and_evaluate()`, it trains well and also evaluate without an error. **However, when I set `batch_size` bigger than 98, There is always an error only when evaluating(no matter with training period)** : 

`
InvalidArgumentError (see above for traceback): assertion failed: [When applying AttentionWrapper attention_wrapper_1: Non-matching batch sizes between the memory (encoder output) and the query (decoder output).  Are you using
the BeamSearchDecoder?  You may need to tile your memory input via the tf.contrib.seq2seq.tile_batch function with argument multiple=beam_width.] [Condition x == y did not hold element-wise:] [x (QuestionGeneration/decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/x:0) = ] [99] [y (QuestionGeneration/LuongAttention/strided_slice_3:0) = ] [14]
         [[Node: QuestionGeneration/decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Assert = Assert[T=[DT_STRING, DT_STRING, DT_STRING, DT_INT32, DT_STRING, DT_INT32], summarize=3, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](QuestionGeneration/decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/All/_389, QuestionGeneration/decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Assert/data_0, QuestionGeneration/decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Assert/data_1, QuestionGeneration/decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Assert/data_2, QuestionGeneration/decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/x/_391, QuestionGeneration/decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Assert/data_4, QuestionGeneration/decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Equal/Enter/_393)]]
         [[Node: QuestionGeneration/AttentionWrapperZeroState/assert_equal/Assert/Assert/_384 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_397_QuestionGeneration/AttentionWrapperZeroState/assert_equal/Assert/Assert"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]
`

I solved this error by change the `batch_size` value in `model_fn` by `attention_mechanism._batch_size`.
The problem may caused from the redundant data that can't be divided by `batch_size`( if i have 1004 lines of data and my `batch_size` is 10, than 4 lines data will be left). So when I change the `batch_size` value in `model_fn` to `attention_mechanism._batch_size` from specified value, the last iteration's batch size will be 4 and no error anymore. About the error message above, I used batch size of 99, and there will be 14 lines of data left. Then, I want to ask for 2 questions that may related to error:

1. when I fixed the `batch_size` by specified value smaller than 99, why no error(both training and evaluate)
2. when I fixed the 'batch_size' by specified value bigger than 98, why no error in training period and does have error in evaluation period.

I think there may be some errors in tensorflow api related to this. Or maybe I was wrong in some part.

Also, I hope to see the details of `numpy_input_fn`, such as: when used with `tf.estimator`, How will it treat the redundant data that can't be divided by batch_size"
17677,Tensorflow installation problem,"Hello, 
I trie to install tensorflow on a SSH server and uisng the following command: pip install tensorflow. They give me that the installataion was Successfully done. When i execute my code i get the following error, any help will be so appreciated:
Traceback (most recent call last):
  ```
File ""/gs/project/tws-462-aa/Python_directory/src/TripleArray.py"", line 6, in <module>
    from config import invert
  File ""/gs/project/tws-462-aa/Python_directory/src/config.py"", line 5, in <module>
    import tensorflow as tf
  File ""/gs/project/tws-462-aa/Python_directory/ENV2.7/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/gs/project/tws-462-aa/Python_directory/ENV2.7/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/gs/project/tws-462-aa/Python_directory/ENV2.7/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/gs/project/tws-462-aa/Python_directory/ENV2.7/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/gs/project/tws-462-aa/Python_directory/ENV2.7/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/gs/project/tws-462-aa/Python_directory/ENV2.7/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
ImportError: /lib64/libc.so.6: version `GLIBC_2.17' not found (required by /gs/project/tws-462-aa/Python_directory/ENV2.7/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
```
"
17676,Logging frequency hardcoded in tf.estimator,"
### Describe the problem

The logging frequency of the default LoggingTensorHook of tf.Estimator is hardcoded to 100 steps (see lines 828-837 in [https://github.com/tensorflow/tensorflow/blob/r1.6/tensorflow/python/estimator/estimator.py]). It would really help me to unclutter my logs if I had access to this value (my training is fast)."
17675,from tensorflow.contrib import *  导入失败，求教,"在将tensorflow封装成c服务的过程中，出现如下问题：
from tensorflow.contrib import * ------>失败（由于水平问题，不知怎么捕获错误信息，现象就是c服务无法返回正确结果） 
from tensorflow.models import *  -------->成功（c服务能够正常返回结果，下同）
from tensorflow.core import * ---------->成功
from tensorflow.examples import *  --------->成功

tensorflow安装包下：contrib、models、core、examples等目录都是存在的。tensorflow版本：1.2
"
17674,"tf1.6 error: tf.train.BytesList(""string"") ---> expected one of: bytes","OS Platform and Distribution-->Linux Ubuntu 14.04
TensorFlow installed from-->binary
TensorFlow version -->1.6
Python version--> 3.5.5
GCC/Compiler version -->GCC 4.8.4
CUDA/cuDNN version-->cuda9/cuDNN7
GPU model and memory-->Tesla K20c/Tesla K20m

code to reproduce:
```
import tensorflow as tf

print(tf.GIT_VERSION, tf.VERSION)

all_record = str(""abc"")
output_filename = ""tfrecord_test""

writer = tf.python_io.TFRecordWriter(output_filename)

example = tf.train.Example(
    features = tf.train.Features(
        feature = {
            ""features"": tf.train.Feature(
                #int32_list = tf.train.Int32List(value = all_record)
                bytes_list=tf.train.BytesList(value = all_record)
            )
        }
    )
)
writer.write(example.SerializeToString())

writer.close()
```

error log:
```
$ python tf_record_test.py
/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
v1.6.0-0-gd2e24b6039 1.6.0
Traceback (most recent call last):
  File ""tf_record_test.py"", line 15, in <module>
    bytes_list=tf.train.BytesList(value = all_record)
TypeError: 'a' has type str, but expected one of: bytes
```"
17673,tf1.6 error: ,"OS Platform and Distribution-->Linux Ubuntu 14.04
TensorFlow installed from-->binary
TensorFlow version -->1.6
Python version--> 3.5.5
GCC/Compiler version -->GCC 4.8.4
CUDA/cuDNN version-->cuda9/cuDNN7
GPU model and memory-->Tesla K20c/Tesla K20m

code to reproduce(tf_record_test.py):
`import tensorflow as tf

print(tf.GIT_VERSION, tf.VERSION)

all_record = str(""abc"")
output_filename = ""tfrecord_test""

writer = tf.python_io.TFRecordWriter(output_filename)

example = tf.train.Example(
    features = tf.train.Features(
        feature = {
            ""features"": tf.train.Feature(
                #int32_list = tf.train.Int32List(value = all_record)
                bytes_list=tf.train.BytesList(value = all_record)
            )
        }
    )
)
writer.write(example.SerializeToString())

writer.close()
`
error log:
`$ python tf_record_test.py
/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
v1.6.0-0-gd2e24b6039 1.6.0
Traceback (most recent call last):
  File ""tf_record_test.py"", line 15, in <module>
    bytes_list=tf.train.BytesList(value = all_record)
TypeError: 'a' has type str, but expected one of: bytes`"
17671,concat puts gradients as 0.0,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.5.0
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: 0.11.0
- **GCC/Compiler version (if compiling from source)**: 5.4.0
- **CUDA/cuDNN version**: CuDA 9.0
- **GPU model and memory**: 4Gb, Nvidia GTX960M
- **Exact command to reproduce**:

### Describe the problem
When I write delt to get gradients of pi with respect to v, I get the gradients. Same for rem with respect to v. However, when I ask for gradients of z with respect to v, I get a matrix of 0s, which is clearly not the gradient as z is just the concatenation of pi and rem, both of which have non-zero gradients. Why is this happening?


### Source code / logs

	def latent_space(v):
		# Calculate pi
		with tf.name_scope('pi'):
			def fn(previous_output,current_input):
				[stick,remaining] = previous_output
				i = current_input
				stick = v[:,i]*remaining
				remaining *= (1-v[:,i])
				return [stick,remaining]

			elems = tf.Variable(tf.range(latent-1))
			[pi,rem] = tf.scan(fn,elems,initializer=[tf.ones([bs]),tf.ones([bs])])
			rem = tf.reshape(rem[-1,:],[1,bs])
			z = tf.concat([pi,rem],axis=0)
			z = tf.transpose(z)
			delt = tf.gradients(z,v)
		return z,delt"
17669,"ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[1,5095,3729,3]","When I encountered the following error while performing the training, can someone help me? I am a beginner of tensorflow.

`ssh://root@xxx.xxx.xxx.xxx:22/usr/local/python3/bin/python3 -u /xxx/xxx/object_detection/train.py --logtostderr
WARNING:tensorflow:From /xxx/xxx/object_detection/trainer.py:210: create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.create_global_step
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:Summary name /clone_loss is illegal; using clone_loss instead.
2018-03-13 21:57:41.631427: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-03-13 21:57:42.286105: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-03-13 21:57:42.286417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.6575
pciBusID: 0000:01:00.0
totalMemory: 10.91GiB freeMemory: 10.75GiB
2018-03-13 21:57:42.286455: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
INFO:tensorflow:Restoring parameters from train/model.ckpt-0
INFO:tensorflow:Starting Session.
INFO:tensorflow:Saving checkpoint to path train/model.ckpt
INFO:tensorflow:Starting Queues.
INFO:tensorflow:global_step/sec: 0
INFO:tensorflow:Recording summary at step 0.
INFO:tensorflow:global step 1: loss = 243.3368 (9.080 sec/step)
INFO:tensorflow:global step 2: loss = 220.1394 (0.513 sec/step)
INFO:tensorflow:global step 3: loss = 206.3998 (0.430 sec/step)
INFO:tensorflow:global step 4: loss = 195.3873 (0.486 sec/step)
INFO:tensorflow:global step 5: loss = 182.0547 (0.427 sec/step)
INFO:tensorflow:global step 6: loss = 166.7800 (0.434 sec/step)
INFO:tensorflow:global step 7: loss = 151.5283 (0.474 sec/step)
INFO:tensorflow:global step 8: loss = 135.1360 (0.429 sec/step)
INFO:tensorflow:global step 9: loss = 120.5486 (0.425 sec/step)
INFO:tensorflow:global step 10: loss = 105.3057 (0.499 sec/step)
INFO:tensorflow:global step 11: loss = 91.5549 (0.514 sec/step)
INFO:tensorflow:global step 12: loss = 78.9669 (0.434 sec/step)
INFO:tensorflow:global step 13: loss = 68.9649 (0.439 sec/step)
INFO:tensorflow:global step 14: loss = 59.8189 (0.423 sec/step)
INFO:tensorflow:global step 15: loss = 52.2898 (0.458 sec/step)
INFO:tensorflow:global step 16: loss = 44.7254 (0.418 sec/step)
INFO:tensorflow:global step 17: loss = 39.1479 (0.499 sec/step)
INFO:tensorflow:global step 18: loss = 35.2444 (0.468 sec/step)
INFO:tensorflow:global step 19: loss = 32.0060 (0.454 sec/step)
INFO:tensorflow:global step 20: loss = 27.3901 (0.437 sec/step)
INFO:tensorflow:global step 21: loss = 25.8307 (0.432 sec/step)
INFO:tensorflow:global step 22: loss = 23.7690 (0.454 sec/step)
INFO:tensorflow:global step 23: loss = 21.4071 (0.430 sec/step)
INFO:tensorflow:global step 24: loss = 20.4954 (0.590 sec/step)
INFO:tensorflow:global step 25: loss = 18.6025 (0.440 sec/step)
INFO:tensorflow:global step 26: loss = 17.7907 (0.434 sec/step)
INFO:tensorflow:global step 27: loss = 17.7660 (0.489 sec/step)
INFO:tensorflow:global step 28: loss = 16.7211 (0.512 sec/step)
INFO:tensorflow:global step 29: loss = 16.5738 (0.429 sec/step)
INFO:tensorflow:global step 30: loss = 15.5000 (0.490 sec/step)
INFO:tensorflow:global step 31: loss = 15.0663 (0.412 sec/step)
INFO:tensorflow:global step 32: loss = 14.5887 (0.442 sec/step)
INFO:tensorflow:global step 33: loss = 14.8037 (0.563 sec/step)
INFO:tensorflow:global step 34: loss = 13.5137 (0.489 sec/step)
INFO:tensorflow:global step 35: loss = 13.0228 (0.427 sec/step)
INFO:tensorflow:global step 36: loss = 13.4710 (0.428 sec/step)
INFO:tensorflow:global step 37: loss = 13.7616 (0.419 sec/step)
INFO:tensorflow:global step 38: loss = 13.2861 (0.427 sec/step)
INFO:tensorflow:global step 39: loss = 12.2581 (0.505 sec/step)
INFO:tensorflow:global step 40: loss = 12.7339 (0.429 sec/step)
INFO:tensorflow:global step 41: loss = 13.2387 (0.444 sec/step)
INFO:tensorflow:global step 42: loss = 12.3722 (0.439 sec/step)
INFO:tensorflow:global step 43: loss = 12.8192 (0.428 sec/step)
INFO:tensorflow:global step 44: loss = 12.0361 (0.488 sec/step)
INFO:tensorflow:global step 45: loss = 12.1655 (0.566 sec/step)
INFO:tensorflow:global step 46: loss = 11.7112 (0.425 sec/step)
INFO:tensorflow:global step 47: loss = 11.3097 (0.464 sec/step)
INFO:tensorflow:global step 48: loss = 12.2162 (0.435 sec/step)
INFO:tensorflow:global step 49: loss = 11.7511 (0.428 sec/step)
INFO:tensorflow:global step 50: loss = 11.2281 (0.425 sec/step)
INFO:tensorflow:global step 51: loss = 10.9219 (0.477 sec/step)
INFO:tensorflow:global step 52: loss = 11.8307 (0.430 sec/step)
INFO:tensorflow:global step 53: loss = 11.4977 (0.486 sec/step)
INFO:tensorflow:global step 54: loss = 11.5908 (0.436 sec/step)
INFO:tensorflow:global step 55: loss = 11.7416 (0.450 sec/step)
INFO:tensorflow:global step 56: loss = 10.8136 (0.441 sec/step)
INFO:tensorflow:global step 57: loss = 10.9873 (0.482 sec/step)
INFO:tensorflow:global step 58: loss = 11.0574 (0.470 sec/step)
INFO:tensorflow:global step 59: loss = 11.4761 (0.454 sec/step)
INFO:tensorflow:global step 60: loss = 11.7182 (0.427 sec/step)
INFO:tensorflow:global step 61: loss = 11.6872 (0.461 sec/step)
INFO:tensorflow:global step 62: loss = 10.8746 (0.462 sec/step)
INFO:tensorflow:global step 63: loss = 10.6988 (0.438 sec/step)
INFO:tensorflow:global step 64: loss = 10.5077 (0.615 sec/step)
INFO:tensorflow:global step 65: loss = 11.0472 (0.432 sec/step)
INFO:tensorflow:global step 66: loss = 10.6191 (0.444 sec/step)
INFO:tensorflow:global step 67: loss = 10.3630 (0.453 sec/step)
INFO:tensorflow:global step 68: loss = 10.0935 (0.565 sec/step)
INFO:tensorflow:global step 69: loss = 10.5869 (0.446 sec/step)
INFO:tensorflow:global step 70: loss = 10.6263 (0.435 sec/step)
INFO:tensorflow:global step 71: loss = 10.4292 (0.479 sec/step)
INFO:tensorflow:global step 72: loss = 10.5870 (0.474 sec/step)
INFO:tensorflow:global step 73: loss = 10.6465 (0.476 sec/step)
INFO:tensorflow:global step 74: loss = 10.8363 (0.559 sec/step)
INFO:tensorflow:global step 75: loss = 10.9429 (0.486 sec/step)
INFO:tensorflow:global step 76: loss = 10.3226 (0.419 sec/step)
INFO:tensorflow:global step 77: loss = 10.7447 (0.638 sec/step)
INFO:tensorflow:global step 78: loss = 10.1083 (0.491 sec/step)
INFO:tensorflow:global step 79: loss = 10.7905 (0.450 sec/step)
INFO:tensorflow:global step 80: loss = 10.6255 (0.657 sec/step)
INFO:tensorflow:global step 81: loss = 10.9287 (0.657 sec/step)
INFO:tensorflow:global step 82: loss = 10.2799 (0.439 sec/step)
INFO:tensorflow:global step 83: loss = 10.1767 (0.425 sec/step)
INFO:tensorflow:global step 84: loss = 10.3393 (0.639 sec/step)
INFO:tensorflow:global step 85: loss = 10.6420 (0.466 sec/step)
INFO:tensorflow:global step 86: loss = 10.5353 (1.067 sec/step)
INFO:tensorflow:global step 87: loss = 9.7251 (0.483 sec/step)
INFO:tensorflow:global step 88: loss = 9.9586 (0.491 sec/step)
INFO:tensorflow:global step 89: loss = 10.5869 (0.435 sec/step)
INFO:tensorflow:global step 90: loss = 10.6093 (0.428 sec/step)
INFO:tensorflow:global step 91: loss = 10.6009 (1.195 sec/step)
INFO:tensorflow:global step 92: loss = 10.1688 (0.654 sec/step)
INFO:tensorflow:global step 93: loss = 10.5646 (0.751 sec/step)
INFO:tensorflow:global step 94: loss = 10.0194 (0.449 sec/step)
INFO:tensorflow:global step 95: loss = 9.9471 (0.458 sec/step)
INFO:tensorflow:global step 96: loss = 10.1529 (0.429 sec/step)
INFO:tensorflow:global step 97: loss = 10.2420 (0.715 sec/step)
INFO:tensorflow:global step 98: loss = 10.2819 (0.435 sec/step)
INFO:tensorflow:global step 99: loss = 10.1969 (0.625 sec/step)
INFO:tensorflow:global step 100: loss = 9.9485 (0.478 sec/step)
INFO:tensorflow:global step 101: loss = 9.9312 (0.568 sec/step)
INFO:tensorflow:global step 102: loss = 10.0179 (0.415 sec/step)
INFO:tensorflow:global step 103: loss = 9.9705 (0.419 sec/step)
INFO:tensorflow:global step 104: loss = 9.8582 (0.484 sec/step)
INFO:tensorflow:global step 105: loss = 10.4639 (0.431 sec/step)
INFO:tensorflow:global step 106: loss = 10.2900 (0.413 sec/step)
INFO:tensorflow:global step 107: loss = 10.3138 (0.430 sec/step)
INFO:tensorflow:global step 108: loss = 9.6482 (0.461 sec/step)
INFO:tensorflow:global step 109: loss = 9.5792 (0.422 sec/step)
INFO:tensorflow:global step 110: loss = 9.7901 (0.466 sec/step)
INFO:tensorflow:global step 111: loss = 10.4787 (0.472 sec/step)
INFO:tensorflow:global step 112: loss = 10.6505 (0.434 sec/step)
INFO:tensorflow:global step 113: loss = 9.7728 (0.435 sec/step)
INFO:tensorflow:global step 114: loss = 9.7048 (0.431 sec/step)
INFO:tensorflow:global step 115: loss = 10.3138 (0.439 sec/step)
INFO:tensorflow:global step 116: loss = 9.5181 (0.428 sec/step)
INFO:tensorflow:global step 117: loss = 10.2000 (0.914 sec/step)
INFO:tensorflow:global step 118: loss = 10.3344 (0.462 sec/step)
INFO:tensorflow:global step 119: loss = 9.5471 (0.442 sec/step)
INFO:tensorflow:global step 120: loss = 9.4061 (0.427 sec/step)
INFO:tensorflow:global step 121: loss = 9.5720 (0.488 sec/step)
INFO:tensorflow:global step 122: loss = 9.3800 (0.462 sec/step)
INFO:tensorflow:global step 123: loss = 9.4855 (0.426 sec/step)
INFO:tensorflow:global step 124: loss = 8.9675 (0.526 sec/step)
INFO:tensorflow:global step 125: loss = 9.4995 (0.487 sec/step)
INFO:tensorflow:global step 126: loss = 9.2938 (0.539 sec/step)
INFO:tensorflow:global step 127: loss = 9.7230 (0.433 sec/step)
INFO:tensorflow:global step 128: loss = 9.8149 (0.510 sec/step)
INFO:tensorflow:global step 129: loss = 10.1299 (0.466 sec/step)
INFO:tensorflow:global step 130: loss = 9.7078 (0.477 sec/step)
INFO:tensorflow:global step 131: loss = 10.0769 (1.196 sec/step)
INFO:tensorflow:global step 132: loss = 9.4188 (0.543 sec/step)
INFO:tensorflow:global step 133: loss = 8.9409 (0.443 sec/step)
INFO:tensorflow:global step 134: loss = 9.3117 (0.472 sec/step)
INFO:tensorflow:global step 135: loss = 8.9357 (0.477 sec/step)
INFO:tensorflow:global step 136: loss = 10.4331 (0.681 sec/step)
INFO:tensorflow:global step 137: loss = 9.3650 (0.418 sec/step)
INFO:tensorflow:global step 138: loss = 9.1549 (0.455 sec/step)
INFO:tensorflow:global step 139: loss = 9.2574 (0.420 sec/step)
INFO:tensorflow:global step 140: loss = 9.2772 (0.448 sec/step)
INFO:tensorflow:global step 141: loss = 9.6754 (0.442 sec/step)
INFO:tensorflow:global step 142: loss = 10.1184 (0.602 sec/step)
INFO:tensorflow:global step 143: loss = 9.1427 (0.477 sec/step)
INFO:tensorflow:global step 144: loss = 9.2105 (0.754 sec/step)
INFO:tensorflow:global step 145: loss = 9.1641 (0.421 sec/step)
INFO:tensorflow:global step 146: loss = 9.6503 (0.490 sec/step)
INFO:tensorflow:global step 147: loss = 10.1134 (0.430 sec/step)
INFO:tensorflow:global step 148: loss = 9.3111 (0.475 sec/step)
INFO:tensorflow:global step 149: loss = 10.0336 (0.427 sec/step)
INFO:tensorflow:global step 150: loss = 8.5716 (0.463 sec/step)
INFO:tensorflow:global step 151: loss = 9.5126 (0.427 sec/step)
INFO:tensorflow:global step 152: loss = 9.9572 (0.480 sec/step)
INFO:tensorflow:global step 153: loss = 9.0432 (0.444 sec/step)
INFO:tensorflow:global step 154: loss = 8.7378 (0.500 sec/step)
INFO:tensorflow:global step 155: loss = 9.2020 (0.487 sec/step)
INFO:tensorflow:global step 156: loss = 9.8456 (0.528 sec/step)
INFO:tensorflow:global step 157: loss = 8.7925 (0.429 sec/step)
INFO:tensorflow:global step 158: loss = 8.8295 (0.435 sec/step)
INFO:tensorflow:global step 159: loss = 8.9335 (0.509 sec/step)
INFO:tensorflow:global step 160: loss = 9.1799 (0.444 sec/step)
INFO:tensorflow:global step 161: loss = 9.4383 (0.433 sec/step)
INFO:tensorflow:global step 162: loss = 9.5451 (0.484 sec/step)
INFO:tensorflow:global step 163: loss = 9.8775 (0.460 sec/step)
INFO:tensorflow:global step 164: loss = 9.1774 (0.462 sec/step)
INFO:tensorflow:global step 165: loss = 8.8758 (0.757 sec/step)
INFO:tensorflow:global step 166: loss = 9.2932 (0.428 sec/step)
INFO:tensorflow:global step 167: loss = 9.1967 (0.441 sec/step)
INFO:tensorflow:global step 168: loss = 9.6125 (0.760 sec/step)
INFO:tensorflow:global step 169: loss = 9.0119 (0.644 sec/step)
INFO:tensorflow:global step 170: loss = 9.7965 (0.429 sec/step)
INFO:tensorflow:global step 171: loss = 8.8230 (0.548 sec/step)
INFO:tensorflow:global step 172: loss = 8.6981 (0.482 sec/step)
INFO:tensorflow:global step 173: loss = 8.4844 (0.491 sec/step)
INFO:tensorflow:global step 174: loss = 9.4706 (0.431 sec/step)
INFO:tensorflow:global step 175: loss = 8.5126 (0.478 sec/step)
INFO:tensorflow:global step 176: loss = 9.2941 (0.443 sec/step)
INFO:tensorflow:global step 177: loss = 8.9967 (0.597 sec/step)
INFO:tensorflow:global step 178: loss = 9.5142 (0.640 sec/step)
INFO:tensorflow:global step 179: loss = 9.4251 (0.487 sec/step)
INFO:tensorflow:global step 180: loss = 9.5026 (0.469 sec/step)
INFO:tensorflow:global step 181: loss = 9.3916 (0.504 sec/step)
INFO:tensorflow:global step 182: loss = 9.7789 (0.485 sec/step)
INFO:tensorflow:global step 183: loss = 8.8342 (0.530 sec/step)
INFO:tensorflow:global step 184: loss = 9.1194 (0.661 sec/step)
2018-03-13 21:59:44.843954: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 217.43MiB.  Current allocation summary follows.
2018-03-13 21:59:44.845715: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (256): 	Total Chunks: 709, Chunks in use: 709. 177.2KiB allocated for chunks. 177.2KiB in use in bin. 6.8KiB client-requested in use in bin.
2018-03-13 21:59:44.845777: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (512): 	Total Chunks: 59, Chunks in use: 59. 29.8KiB allocated for chunks. 29.8KiB in use in bin. 18.4KiB client-requested in use in bin.
2018-03-13 21:59:44.845822: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (1024): 	Total Chunks: 21, Chunks in use: 17. 25.2KiB allocated for chunks. 20.8KiB in use in bin. 19.6KiB client-requested in use in bin.
2018-03-13 21:59:44.845941: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (2048): 	Total Chunks: 14, Chunks in use: 12. 35.8KiB allocated for chunks. 30.2KiB in use in bin. 27.1KiB client-requested in use in bin.
2018-03-13 21:59:44.845986: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (4096): 	Total Chunks: 323, Chunks in use: 323. 2.34MiB allocated for chunks. 2.34MiB in use in bin. 2.33MiB client-requested in use in bin.
2018-03-13 21:59:44.846031: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (8192): 	Total Chunks: 17, Chunks in use: 15. 189.2KiB allocated for chunks. 159.0KiB in use in bin. 136.9KiB client-requested in use in bin.
2018-03-13 21:59:44.846103: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (16384): 	Total Chunks: 22, Chunks in use: 20. 600.0KiB allocated for chunks. 540.0KiB in use in bin. 539.4KiB client-requested in use in bin.
2018-03-13 21:59:44.846149: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (32768): 	Total Chunks: 7, Chunks in use: 7. 318.8KiB allocated for chunks. 318.8KiB in use in bin. 249.9KiB client-requested in use in bin.
2018-03-13 21:59:44.846193: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (65536): 	Total Chunks: 6, Chunks in use: 6. 448.0KiB allocated for chunks. 448.0KiB in use in bin. 448.0KiB client-requested in use in bin.
2018-03-13 21:59:44.846304: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (131072): 	Total Chunks: 13, Chunks in use: 13. 2.13MiB allocated for chunks. 2.13MiB in use in bin. 2.04MiB client-requested in use in bin.
2018-03-13 21:59:44.846346: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (262144): 	Total Chunks: 10, Chunks in use: 10. 3.69MiB allocated for chunks. 3.69MiB in use in bin. 3.46MiB client-requested in use in bin.
2018-03-13 21:59:44.846388: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (524288): 	Total Chunks: 19, Chunks in use: 19. 11.10MiB allocated for chunks. 11.10MiB in use in bin. 10.88MiB client-requested in use in bin.
2018-03-13 21:59:44.846449: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (1048576): 	Total Chunks: 8, Chunks in use: 8. 9.67MiB allocated for chunks. 9.67MiB in use in bin. 9.17MiB client-requested in use in bin.
2018-03-13 21:59:44.846491: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-03-13 21:59:44.846548: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-03-13 21:59:44.846593: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (8388608): 	Total Chunks: 2, Chunks in use: 2. 24.57MiB allocated for chunks. 24.57MiB in use in bin. 24.57MiB client-requested in use in bin.
2018-03-13 21:59:44.846631: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-03-13 21:59:44.846668: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-03-13 21:59:44.846734: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-03-13 21:59:44.846771: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-03-13 21:59:44.846812: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (268435456): 	Total Chunks: 1, Chunks in use: 1. 10.16GiB allocated for chunks. 10.16GiB in use in bin. 5.10GiB client-requested in use in bin.
2018-03-13 21:59:44.846855: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin for 217.43MiB was 128.00MiB, Chunk State: 
2018-03-13 21:59:44.846889: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da00000 of size 1280
2018-03-13 21:59:44.846915: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da00500 of size 256
2018-03-13 21:59:44.846938: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da00600 of size 256
2018-03-13 21:59:44.846960: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da00700 of size 256
2018-03-13 21:59:44.846983: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da00800 of size 256
2018-03-13 21:59:44.847006: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da00900 of size 256
2018-03-13 21:59:44.847031: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da00a00 of size 512
2018-03-13 21:59:44.847054: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da00c00 of size 256
2018-03-13 21:59:44.847077: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da00d00 of size 256
2018-03-13 21:59:44.847100: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da00e00 of size 256
2018-03-13 21:59:44.847122: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da00f00 of size 256
2018-03-13 21:59:44.847172: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da01000 of size 256
2018-03-13 21:59:44.847199: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da01100 of size 256
2018-03-13 21:59:44.847231: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da01200 of size 256
2018-03-13 21:59:44.847255: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da01300 of size 256
2018-03-13 21:59:44.847277: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da01400 of size 512
2018-03-13 21:59:44.847300: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da01600 of size 256
2018-03-13 21:59:44.847322: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da01700 of size 256
2018-03-13 21:59:44.847345: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da01800 of size 256
2018-03-13 21:59:44.847367: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da01900 of size 256
2018-03-13 21:59:44.847390: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da01a00 of size 256
2018-03-13 21:59:44.847412: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da01b00 of size 256
2018-03-13 21:59:44.847435: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da01c00 of size 256
2018-03-13 21:59:44.847458: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da01d00 of size 512
2018-03-13 21:59:44.847480: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da01f00 of size 256
2018-03-13 21:59:44.847502: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da02000 of size 512
2018-03-13 21:59:44.847525: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da02200 of size 256
2018-03-13 21:59:44.847547: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da02300 of size 256
2018-03-13 21:59:44.847570: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da02400 of size 256
2018-03-13 21:59:44.847592: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da02500 of size 256
2018-03-13 21:59:44.847614: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da02600 of size 256
2018-03-13 21:59:44.847637: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da02700 of size 256
2018-03-13 21:59:44.847659: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da02800 of size 256
2018-03-13 21:59:44.847709: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da02900 of size 512
2018-03-13 21:59:44.847735: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da02b00 of size 256
2018-03-13 21:59:44.847757: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da02c00 of size 256
2018-03-13 21:59:44.847781: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da02d00 of size 256
2018-03-13 21:59:44.847803: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da02e00 of size 256
2018-03-13 21:59:44.847826: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da02f00 of size 256
2018-03-13 21:59:44.847848: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da03000 of size 256
2018-03-13 21:59:44.847872: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da03100 of size 256
2018-03-13 21:59:44.847921: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da03200 of size 256
2018-03-13 21:59:44.847947: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da03300 of size 256
2018-03-13 21:59:44.847969: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da03400 of size 256
2018-03-13 21:59:44.847991: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da03500 of size 256
2018-03-13 21:59:44.848014: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da03600 of size 256
2018-03-13 21:59:44.848036: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da03700 of size 256
2018-03-13 21:59:44.848058: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da03800 of size 512
2018-03-13 21:59:44.848081: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da03a00 of size 256
2018-03-13 21:59:44.848103: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da03b00 of size 512
2018-03-13 21:59:44.848125: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da03d00 of size 256
2018-03-13 21:59:44.848176: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da03e00 of size 256
2018-03-13 21:59:44.848200: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da03f00 of size 256
2018-03-13 21:59:44.848229: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da04000 of size 256
2018-03-13 21:59:44.852565: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da04100 of size 256
2018-03-13 21:59:44.852644: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da04200 of size 256
2018-03-13 21:59:44.852684: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da04300 of size 256
2018-03-13 21:59:44.852710: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da04400 of size 512
2018-03-13 21:59:44.852742: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da04600 of size 256
2018-03-13 21:59:44.852771: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da04700 of size 256
2018-03-13 21:59:44.852800: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da04800 of size 256
2018-03-13 21:59:44.852831: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da04900 of size 256
2018-03-13 21:59:44.852866: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da04a00 of size 256
2018-03-13 21:59:44.852902: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da04b00 of size 256
2018-03-13 21:59:44.852934: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da04c00 of size 256
2018-03-13 21:59:44.852962: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da04d00 of size 512
2018-03-13 21:59:44.852988: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da04f00 of size 256
2018-03-13 21:59:44.853019: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da05000 of size 256
2018-03-13 21:59:44.853049: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da05100 of size 256
2018-03-13 21:59:44.853077: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da05200 of size 256
2018-03-13 21:59:44.853105: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da05300 of size 256
2018-03-13 21:59:44.853144: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da05400 of size 256
2018-03-13 21:59:44.853177: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da05500 of size 256
2018-03-13 21:59:44.853202: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da05600 of size 256
2018-03-13 21:59:44.853248: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da05700 of size 256
2018-03-13 21:59:44.853278: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da05800 of size 256
2018-03-13 21:59:44.853305: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da05900 of size 256
2018-03-13 21:59:44.853335: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da05a00 of size 256
2018-03-13 21:59:44.853362: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da05b00 of size 256
2018-03-13 21:59:44.853399: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da05c00 of size 512
2018-03-13 21:59:44.853448: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da05e00 of size 256
2018-03-13 21:59:44.853495: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da05f00 of size 256
2018-03-13 21:59:44.853537: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da06000 of size 256
2018-03-13 21:59:44.853570: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da06100 of size 256
2018-03-13 21:59:44.853613: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da06200 of size 512
2018-03-13 21:59:44.853654: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da06400 of size 256
2018-03-13 21:59:44.853696: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da06500 of size 256
2018-03-13 21:59:44.853736: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da06600 of size 256
2018-03-13 21:59:44.853771: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da06700 of size 256
2018-03-13 21:59:44.853810: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da06800 of size 512
2018-03-13 21:59:44.853848: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da06a00 of size 256
2018-03-13 21:59:44.853884: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da06b00 of size 256
2018-03-13 21:59:44.853918: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da06c00 of size 256
2018-03-13 21:59:44.853957: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da06d00 of size 256
2018-03-13 21:59:44.853988: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da06e00 of size 256
2018-03-13 21:59:44.854033: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da06f00 of size 256
2018-03-13 21:59:44.854068: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da07000 of size 256
2018-03-13 21:59:44.854100: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da07100 of size 256
2018-03-13 21:59:44.854142: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da07200 of size 256
2018-03-13 21:59:44.854179: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da07300 of size 256
2018-03-13 21:59:44.854215: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da07400 of size 512
2018-03-13 21:59:44.854267: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da07600 of size 256
2018-03-13 21:59:44.854311: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da07700 of size 256
2018-03-13 21:59:44.854351: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da07800 of size 256
2018-03-13 21:59:44.854379: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da07900 of size 256
2018-03-13 21:59:44.854415: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da07a00 of size 256
2018-03-13 21:59:44.854444: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da07b00 of size 256
2018-03-13 21:59:44.854483: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da07c00 of size 256
2018-03-13 21:59:44.854524: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da07d00 of size 256
2018-03-13 21:59:44.854578: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da07e00 of size 256
2018-03-13 21:59:44.854621: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da07f00 of size 512
2018-03-13 21:59:44.854659: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da08100 of size 256
2018-03-13 21:59:44.854704: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da08200 of size 256
2018-03-13 21:59:44.854740: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da08300 of size 512
2018-03-13 21:59:44.854772: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da08500 of size 256
2018-03-13 21:59:44.854819: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da08600 of size 256
2018-03-13 21:59:44.854856: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da08700 of size 256
2018-03-13 21:59:44.854892: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da08800 of size 256
2018-03-13 21:59:44.854929: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da08900 of size 256
2018-03-13 21:59:44.854965: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da08a00 of size 256
2018-03-13 21:59:44.855000: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da08b00 of size 256
2018-03-13 21:59:44.855038: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da08c00 of size 256
2018-03-13 21:59:44.855070: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da08d00 of size 256
2018-03-13 21:59:44.855103: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da08e00 of size 256
2018-03-13 21:59:44.855142: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da08f00 of size 256
2018-03-13 21:59:44.855187: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da09000 of size 256
2018-03-13 21:59:44.855234: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da09100 of size 256
2018-03-13 21:59:44.855281: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da09200 of size 256
2018-03-13 21:59:44.855321: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da09300 of size 512
2018-03-13 21:59:44.855362: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da09500 of size 256
2018-03-13 21:59:44.855406: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da09600 of size 512
2018-03-13 21:59:44.855445: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da09800 of size 256
2018-03-13 21:59:44.855494: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da09900 of size 256
2018-03-13 21:59:44.855535: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da09a00 of size 256
2018-03-13 21:59:44.855582: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da09b00 of size 256
2018-03-13 21:59:44.855616: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da09c00 of size 256
2018-03-13 21:59:44.855652: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da09d00 of size 256
2018-03-13 21:59:44.855691: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da09e00 of size 256
2018-03-13 21:59:44.855726: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da09f00 of size 256
2018-03-13 21:59:44.855773: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0a000 of size 256
2018-03-13 21:59:44.855814: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0a100 of size 256
2018-03-13 21:59:44.855859: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0a200 of size 256
2018-03-13 21:59:44.855895: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0a300 of size 512
2018-03-13 21:59:44.855929: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0a500 of size 256
2018-03-13 21:59:44.855974: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0a600 of size 256
2018-03-13 21:59:44.856024: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0a700 of size 256
2018-03-13 21:59:44.856066: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0a800 of size 256
2018-03-13 21:59:44.856107: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0a900 of size 512
2018-03-13 21:59:44.856149: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0ab00 of size 256
2018-03-13 21:59:44.856189: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0ac00 of size 256
2018-03-13 21:59:44.856250: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0ad00 of size 256
2018-03-13 21:59:44.856284: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0ae00 of size 256
2018-03-13 21:59:44.856322: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0af00 of size 256
2018-03-13 21:59:44.856357: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0b000 of size 256
2018-03-13 21:59:44.856395: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0b100 of size 256
2018-03-13 21:59:44.856431: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0b200 of size 256
2018-03-13 21:59:44.856471: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0b300 of size 512
2018-03-13 21:59:44.856515: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0b500 of size 256
2018-03-13 21:59:44.856555: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0b600 of size 256
2018-03-13 21:59:44.856596: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0b700 of size 256
2018-03-13 21:59:44.856643: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0b800 of size 256
2018-03-13 21:59:44.856681: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0b900 of size 512
2018-03-13 21:59:44.856715: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0bb00 of size 256
2018-03-13 21:59:44.856749: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0bc00 of size 256
2018-03-13 21:59:44.856790: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0bd00 of size 256
2018-03-13 21:59:44.856823: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0be00 of size 256
2018-03-13 21:59:44.856855: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0bf00 of size 256
2018-03-13 21:59:44.856896: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0c000 of size 256
2018-03-13 21:59:44.856929: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0c100 of size 256
2018-03-13 21:59:44.856965: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0c200 of size 256
2018-03-13 21:59:44.856999: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0c300 of size 256
2018-03-13 21:59:44.857036: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0c400 of size 256
2018-03-13 21:59:44.857078: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0c500 of size 512
2018-03-13 21:59:44.857110: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0c700 of size 256
2018-03-13 21:59:44.857147: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0c800 of size 256
2018-03-13 21:59:44.857193: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0c900 of size 256
2018-03-13 21:59:44.857235: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0ca00 of size 256
2018-03-13 21:59:44.857280: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0cb00 of size 256
2018-03-13 21:59:44.857322: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0cc00 of size 256
2018-03-13 21:59:44.857357: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0cd00 of size 256
2018-03-13 21:59:44.857406: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0ce00 of size 256
2018-03-13 21:59:44.857438: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0cf00 of size 256
2018-03-13 21:59:44.857475: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0d000 of size 256
2018-03-13 21:59:44.857510: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0d100 of size 512
2018-03-13 21:59:44.857554: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0d300 of size 256
2018-03-13 21:59:44.857593: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0d400 of size 256
2018-03-13 21:59:44.857633: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0d500 of size 256
2018-03-13 21:59:44.857669: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0d600 of size 256
2018-03-13 21:59:44.857690: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0d700 of size 256
2018-03-13 21:59:44.857699: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0d800 of size 256
2018-03-13 21:59:44.857706: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0d900 of size 256
2018-03-13 21:59:44.857712: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0da00 of size 512
2018-03-13 21:59:44.857717: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0dc00 of size 256
2018-03-13 21:59:44.857723: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0dd00 of size 256
2018-03-13 21:59:44.857743: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0de00 of size 256
2018-03-13 21:59:44.857752: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0df00 of size 256
2018-03-13 21:59:44.857758: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0e000 of size 256
2018-03-13 21:59:44.857764: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0e100 of size 256
2018-03-13 21:59:44.857769: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0e200 of size 256
2018-03-13 21:59:44.857775: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0e300 of size 256
2018-03-13 21:59:44.857782: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0e400 of size 256
2018-03-13 21:59:44.857791: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020da0e500 of size 12882432
2018-03-13 21:59:44.857798: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e657700 of size 256
2018-03-13 21:59:44.857804: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e657800 of size 7680
2018-03-13 21:59:44.857809: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e659600 of size 7680
2018-03-13 21:59:44.857815: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e65b400 of size 7680
2018-03-13 21:59:44.857820: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e65d200 of size 7680
2018-03-13 21:59:44.857826: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e65f000 of size 7680
2018-03-13 21:59:44.857835: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e660e00 of size 7680
2018-03-13 21:59:44.857842: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e662c00 of size 7680
2018-03-13 21:59:44.857847: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e664a00 of size 7680
2018-03-13 21:59:44.857853: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e666800 of size 7680
2018-03-13 21:59:44.857858: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e668600 of size 7680
2018-03-13 21:59:44.857864: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e66a400 of size 7680
2018-03-13 21:59:44.857869: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e66c200 of size 7680
2018-03-13 21:59:44.857874: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e66e000 of size 7680
2018-03-13 21:59:44.857880: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e66fe00 of size 7680
2018-03-13 21:59:44.857887: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e671c00 of size 7680
2018-03-13 21:59:44.857895: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e673a00 of size 7680
2018-03-13 21:59:44.857900: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e675800 of size 7680
2018-03-13 21:59:44.857906: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e677600 of size 7680
2018-03-13 21:59:44.857912: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e679400 of size 7680
2018-03-13 21:59:44.857918: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e67b200 of size 7680
2018-03-13 21:59:44.857923: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e67d000 of size 7680
2018-03-13 21:59:44.857929: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e67ee00 of size 7680
2018-03-13 21:59:44.857934: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e680c00 of size 7680
2018-03-13 21:59:44.857941: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e682a00 of size 7680
2018-03-13 21:59:44.857947: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e684800 of size 7680
2018-03-13 21:59:44.857952: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e686600 of size 7680
2018-03-13 21:59:44.857958: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e688400 of size 7680
2018-03-13 21:59:44.857964: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e68a200 of size 7680
2018-03-13 21:59:44.857968: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e68c000 of size 7680
2018-03-13 21:59:44.857974: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e68de00 of size 7680
2018-03-13 21:59:44.857980: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e68fc00 of size 7680
2018-03-13 21:59:44.857985: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e691a00 of size 7680
2018-03-13 21:59:44.857992: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e693800 of size 7680
2018-03-13 21:59:44.858000: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e695600 of size 7680
2018-03-13 21:59:44.858006: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e697400 of size 7680
2018-03-13 21:59:44.858012: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e699200 of size 7680
2018-03-13 21:59:44.858017: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e69b000 of size 7680
2018-03-13 21:59:44.858023: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e69ce00 of size 7680
2018-03-13 21:59:44.858028: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e69ec00 of size 7680
2018-03-13 21:59:44.858034: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6a0a00 of size 7680
2018-03-13 21:59:44.858040: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6a2800 of size 7680
2018-03-13 21:59:44.858046: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6a4600 of size 7680
2018-03-13 21:59:44.858052: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6a6400 of size 7680
2018-03-13 21:59:44.858057: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6a8200 of size 7680
2018-03-13 21:59:44.858063: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6aa000 of size 7680
2018-03-13 21:59:44.858068: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6abe00 of size 7680
2018-03-13 21:59:44.858074: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6adc00 of size 7680
2018-03-13 21:59:44.858080: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6afa00 of size 7680
2018-03-13 21:59:44.858085: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6b1800 of size 7680
2018-03-13 21:59:44.858091: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6b3600 of size 7680
2018-03-13 21:59:44.858098: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6b5400 of size 7680
2018-03-13 21:59:44.858105: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6b7200 of size 7680
2018-03-13 21:59:44.858111: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6b9000 of size 7680
2018-03-13 21:59:44.858116: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6bae00 of size 7680
2018-03-13 21:59:44.858121: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6bcc00 of size 7680
2018-03-13 21:59:44.858127: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6bea00 of size 7680
2018-03-13 21:59:44.858133: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6c0800 of size 7680
2018-03-13 21:59:44.858137: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6c2600 of size 7680
2018-03-13 21:59:44.858143: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6c4400 of size 7680
2018-03-13 21:59:44.858151: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6c6200 of size 7680
2018-03-13 21:59:44.858159: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6c8000 of size 7680
2018-03-13 21:59:44.858164: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6c9e00 of size 7680
2018-03-13 21:59:44.858170: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6cbc00 of size 7680
2018-03-13 21:59:44.858175: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6cda00 of size 7680
2018-03-13 21:59:44.858180: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6cf800 of size 7680
2018-03-13 21:59:44.858186: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6d1600 of size 7680
2018-03-13 21:59:44.858191: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6d3400 of size 7680
2018-03-13 21:59:44.858197: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6d5200 of size 7680
2018-03-13 21:59:44.858204: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6d7000 of size 7680
2018-03-13 21:59:44.858210: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6d8e00 of size 7680
2018-03-13 21:59:44.858215: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6dac00 of size 7680
2018-03-13 21:59:44.858222: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6dca00 of size 7680
2018-03-13 21:59:44.858243: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6de800 of size 7680
2018-03-13 21:59:44.858248: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6e0600 of size 7680
2018-03-13 21:59:44.858255: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6e2400 of size 7680
2018-03-13 21:59:44.858277: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6e4200 of size 7680
2018-03-13 21:59:44.858283: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6e6000 of size 7680
2018-03-13 21:59:44.858288: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6e7e00 of size 7680
2018-03-13 21:59:44.858294: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6e9c00 of size 7680
2018-03-13 21:59:44.858299: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6eba00 of size 7680
2018-03-13 21:59:44.858307: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6ed800 of size 7680
2018-03-13 21:59:44.858312: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6ef600 of size 7680
2018-03-13 21:59:44.858318: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6f1400 of size 7680
2018-03-13 21:59:44.858324: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6f3200 of size 7680
2018-03-13 21:59:44.858329: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6f5000 of size 7680
2018-03-13 21:59:44.858335: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6f6e00 of size 7680
2018-03-13 21:59:44.858340: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6f8c00 of size 7680
2018-03-13 21:59:44.858346: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6faa00 of size 7680
2018-03-13 21:59:44.858351: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6fc800 of size 7680
2018-03-13 21:59:44.858357: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e6fe600 of size 7680
2018-03-13 21:59:44.858364: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e700400 of size 7680
2018-03-13 21:59:44.858370: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e702200 of size 7680
2018-03-13 21:59:44.858375: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e704000 of size 7680
2018-03-13 21:59:44.858381: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e705e00 of size 7680
2018-03-13 21:59:44.858386: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e707c00 of size 7680
2018-03-13 21:59:44.858392: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e709a00 of size 7680
2018-03-13 21:59:44.858397: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e70b800 of size 7680
2018-03-13 21:59:44.858403: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e70d600 of size 7680
2018-03-13 21:59:44.858408: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e70f400 of size 7680
2018-03-13 21:59:44.858415: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e711200 of size 7680
2018-03-13 21:59:44.858422: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e713000 of size 7680
2018-03-13 21:59:44.858427: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e714e00 of size 7680
2018-03-13 21:59:44.858433: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e716c00 of size 7680
2018-03-13 21:59:44.858438: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e718a00 of size 7680
2018-03-13 21:59:44.858444: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e71a800 of size 7680
2018-03-13 21:59:44.858448: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e71c600 of size 7680
2018-03-13 21:59:44.858454: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e71e400 of size 7680
2018-03-13 21:59:44.858459: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e720200 of size 7680
2018-03-13 21:59:44.858467: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e722000 of size 7680
2018-03-13 21:59:44.858476: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e723e00 of size 7680
2018-03-13 21:59:44.858483: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e725c00 of size 7680
2018-03-13 21:59:44.858489: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e727a00 of size 7680
2018-03-13 21:59:44.858494: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e729800 of size 7680
2018-03-13 21:59:44.858500: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e72b600 of size 7680
2018-03-13 21:59:44.858506: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e72d400 of size 7680
2018-03-13 21:59:44.858511: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e72f200 of size 7680
2018-03-13 21:59:44.858519: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e731000 of size 7680
2018-03-13 21:59:44.858525: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e732e00 of size 7680
2018-03-13 21:59:44.858531: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e734c00 of size 7680
2018-03-13 21:59:44.858537: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e736a00 of size 7680
2018-03-13 21:59:44.858541: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e738800 of size 7680
2018-03-13 21:59:44.858547: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e73a600 of size 7680
2018-03-13 21:59:44.858552: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e73c400 of size 7680
2018-03-13 21:59:44.858558: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e73e200 of size 7680
2018-03-13 21:59:44.858563: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e740000 of size 7680
2018-03-13 21:59:44.858570: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e741e00 of size 7680
2018-03-13 21:59:44.858580: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e743c00 of size 7680
2018-03-13 21:59:44.858586: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e745a00 of size 7680
2018-03-13 21:59:44.858592: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e747800 of size 7680
2018-03-13 21:59:44.858597: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e749600 of size 7680
2018-03-13 21:59:44.858603: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e74b400 of size 7680
2018-03-13 21:59:44.858608: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e74d200 of size 7680
2018-03-13 21:59:44.858614: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e74f000 of size 7680
2018-03-13 21:59:44.858619: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e750e00 of size 7680
2018-03-13 21:59:44.858627: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e752c00 of size 7680
2018-03-13 21:59:44.858632: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e754a00 of size 7680
2018-03-13 21:59:44.858638: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e756800 of size 7680
2018-03-13 21:59:44.858643: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e758600 of size 7680
2018-03-13 21:59:44.858649: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e75a400 of size 7680
2018-03-13 21:59:44.858654: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e75c200 of size 7680
2018-03-13 21:59:44.858659: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e75e000 of size 7680
2018-03-13 21:59:44.858665: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e75fe00 of size 7680
2018-03-13 21:59:44.858671: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e761c00 of size 7680
2018-03-13 21:59:44.858678: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e763a00 of size 7680
2018-03-13 21:59:44.858685: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e765800 of size 736256
2018-03-13 21:59:44.858690: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e819400 of size 184064
2018-03-13 21:59:44.858696: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e846300 of size 184064
2018-03-13 21:59:44.858701: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e873200 of size 184064
2018-03-13 21:59:44.858707: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8a0100 of size 184064
2018-03-13 21:59:44.858712: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8cd000 of size 30720
2018-03-13 21:59:44.858717: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d4800 of size 256
2018-03-13 21:59:44.858723: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d4900 of size 256
2018-03-13 21:59:44.858731: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d4a00 of size 256
2018-03-13 21:59:44.858739: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d4b00 of size 256
2018-03-13 21:59:44.858745: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d4c00 of size 256
2018-03-13 21:59:44.858750: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d4d00 of size 256
2018-03-13 21:59:44.858770: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d4e00 of size 256
2018-03-13 21:59:44.858776: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d4f00 of size 256
2018-03-13 21:59:44.858785: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d5000 of size 256
2018-03-13 21:59:44.858790: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d5100 of size 256
2018-03-13 21:59:44.858795: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d5200 of size 256
2018-03-13 21:59:44.858814: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d5300 of size 256
2018-03-13 21:59:44.858819: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d5400 of size 256
2018-03-13 21:59:44.858825: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d5500 of size 256
2018-03-13 21:59:44.858830: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d5600 of size 256
2018-03-13 21:59:44.858840: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d5700 of size 256
2018-03-13 21:59:44.858846: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d5800 of size 256
2018-03-13 21:59:44.858851: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d5900 of size 256
2018-03-13 21:59:44.858856: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d5a00 of size 256
2018-03-13 21:59:44.858862: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d5b00 of size 256
2018-03-13 21:59:44.858867: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d5c00 of size 256
2018-03-13 21:59:44.858873: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d5d00 of size 256
2018-03-13 21:59:44.858878: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d5e00 of size 256
2018-03-13 21:59:44.858884: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d5f00 of size 256
2018-03-13 21:59:44.858889: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d6000 of size 256
2018-03-13 21:59:44.858895: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d6100 of size 256
2018-03-13 21:59:44.858900: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d6200 of size 256
2018-03-13 21:59:44.858906: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d6300 of size 256
2018-03-13 21:59:44.858911: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d6400 of size 256
2018-03-13 21:59:44.858916: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d6500 of size 256
2018-03-13 21:59:44.858922: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d6600 of size 256
2018-03-13 21:59:44.858927: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d6700 of size 256
2018-03-13 21:59:44.858933: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d6800 of size 256
2018-03-13 21:59:44.858939: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d6900 of size 256
2018-03-13 21:59:44.858944: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d6a00 of size 256
2018-03-13 21:59:44.858950: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d6b00 of size 256
2018-03-13 21:59:44.858955: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d6c00 of size 256
2018-03-13 21:59:44.858961: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d6d00 of size 256
2018-03-13 21:59:44.858965: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d6e00 of size 256
2018-03-13 21:59:44.858972: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d6f00 of size 256
2018-03-13 21:59:44.858977: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d7000 of size 256
2018-03-13 21:59:44.858982: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d7100 of size 256
2018-03-13 21:59:44.858988: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d7200 of size 256
2018-03-13 21:59:44.858993: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d7300 of size 256
2018-03-13 21:59:44.858999: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d7400 of size 256
2018-03-13 21:59:44.859004: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d7500 of size 256
2018-03-13 21:59:44.859010: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d7600 of size 256
2018-03-13 21:59:44.859015: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d7700 of size 256
2018-03-13 21:59:44.859021: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d7800 of size 256
2018-03-13 21:59:44.859026: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d7900 of size 256
2018-03-13 21:59:44.859031: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d7a00 of size 256
2018-03-13 21:59:44.859037: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d7b00 of size 256
2018-03-13 21:59:44.859043: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d7c00 of size 256
2018-03-13 21:59:44.859048: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d7d00 of size 256
2018-03-13 21:59:44.859053: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d7e00 of size 256
2018-03-13 21:59:44.859059: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d7f00 of size 256
2018-03-13 21:59:44.859064: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d8000 of size 256
2018-03-13 21:59:44.859070: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d8100 of size 256
2018-03-13 21:59:44.859076: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d8200 of size 256
2018-03-13 21:59:44.859081: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d8300 of size 256
2018-03-13 21:59:44.859087: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d8400 of size 256
2018-03-13 21:59:44.859094: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d8500 of size 256
2018-03-13 21:59:44.859103: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d8600 of size 256
2018-03-13 21:59:44.859109: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d8700 of size 256
2018-03-13 21:59:44.859114: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d8800 of size 256
2018-03-13 21:59:44.859120: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d8900 of size 256
2018-03-13 21:59:44.859125: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d8a00 of size 256
2018-03-13 21:59:44.859131: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d8b00 of size 256
2018-03-13 21:59:44.859136: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d8c00 of size 256
2018-03-13 21:59:44.859142: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d8d00 of size 256
2018-03-13 21:59:44.859147: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d8e00 of size 256
2018-03-13 21:59:44.859153: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d8f00 of size 256
2018-03-13 21:59:44.859158: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d9000 of size 256
2018-03-13 21:59:44.859164: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d9100 of size 256
2018-03-13 21:59:44.859169: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d9200 of size 256
2018-03-13 21:59:44.859175: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d9300 of size 256
2018-03-13 21:59:44.859180: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d9400 of size 256
2018-03-13 21:59:44.859185: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d9500 of size 256
2018-03-13 21:59:44.859191: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d9600 of size 256
2018-03-13 21:59:44.859196: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d9700 of size 256
2018-03-13 21:59:44.859202: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d9800 of size 256
2018-03-13 21:59:44.859210: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d9900 of size 256
2018-03-13 21:59:44.859215: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d9a00 of size 256
2018-03-13 21:59:44.859224: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d9b00 of size 256
2018-03-13 21:59:44.859245: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d9c00 of size 256
2018-03-13 21:59:44.859250: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d9d00 of size 256
2018-03-13 21:59:44.859256: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d9e00 of size 256
2018-03-13 21:59:44.859261: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8d9f00 of size 256
2018-03-13 21:59:44.859280: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8da000 of size 256
2018-03-13 21:59:44.859289: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8da100 of size 256
2018-03-13 21:59:44.859294: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8da200 of size 256
2018-03-13 21:59:44.859300: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8da300 of size 256
2018-03-13 21:59:44.859305: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8da400 of size 256
2018-03-13 21:59:44.859310: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8da500 of size 256
2018-03-13 21:59:44.859316: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8da600 of size 256
2018-03-13 21:59:44.859322: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8da700 of size 256
2018-03-13 21:59:44.859326: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8da800 of size 256
2018-03-13 21:59:44.859332: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8da900 of size 256
2018-03-13 21:59:44.859337: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8daa00 of size 256
2018-03-13 21:59:44.859343: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8dab00 of size 512
2018-03-13 21:59:44.859348: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8dad00 of size 1024
2018-03-13 21:59:44.859354: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8db100 of size 256
2018-03-13 21:59:44.859359: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8db200 of size 256
2018-03-13 21:59:44.859365: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8db300 of size 256
2018-03-13 21:59:44.859370: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8db400 of size 24576
2018-03-13 21:59:44.859376: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8e1400 of size 98304
2018-03-13 21:59:44.859381: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8f9400 of size 256
2018-03-13 21:59:44.859387: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8f9500 of size 24576
2018-03-13 21:59:44.859392: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e8ff500 of size 49152
2018-03-13 21:59:44.859398: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e90b500 of size 98304
2018-03-13 21:59:44.859404: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e923500 of size 524288
2018-03-13 21:59:44.859408: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e9a3500 of size 256
2018-03-13 21:59:44.859414: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e9a3600 of size 256
2018-03-13 21:59:44.859419: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e9a3700 of size 512
2018-03-13 21:59:44.859425: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e9a3900 of size 24576
2018-03-13 21:59:44.859430: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e9a9900 of size 256
2018-03-13 21:59:44.859436: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e9a9a00 of size 9216
2018-03-13 21:59:44.859442: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e9abe00 of size 18432
2018-03-13 21:59:44.859447: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e9b0600 of size 256
2018-03-13 21:59:44.859453: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e9b0700 of size 24576
2018-03-13 21:59:44.859458: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e9b6700 of size 256
2018-03-13 21:59:44.859464: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e9b6800 of size 262144
2018-03-13 21:59:44.859469: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e9f6800 of size 256
2018-03-13 21:59:44.859475: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e9f6900 of size 65536
2018-03-13 21:59:44.859480: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ea06900 of size 12288
2018-03-13 21:59:44.859486: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ea09900 of size 9216
2018-03-13 21:59:44.859491: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ea0bd00 of size 256
2018-03-13 21:59:44.859497: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ea0be00 of size 131072
2018-03-13 21:59:44.859503: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ea2be00 of size 12288
2018-03-13 21:59:44.859509: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ea2ee00 of size 4608
2018-03-13 21:59:44.859514: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ea30000 of size 65536
2018-03-13 21:59:44.859520: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ea40000 of size 4608
2018-03-13 21:59:44.859526: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ea41200 of size 2048
2018-03-13 21:59:44.859531: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ea41a00 of size 32768
2018-03-13 21:59:44.859539: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ea49a00 of size 49152
2018-03-13 21:59:44.859547: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ea55a00 of size 524288
2018-03-13 21:59:44.859554: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ead5a00 of size 2304
2018-03-13 21:59:44.859560: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ead6300 of size 9216
2018-03-13 21:59:44.859566: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ead8700 of size 1179648
2018-03-13 21:59:44.859571: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ebf8700 of size 8192
2018-03-13 21:59:44.859577: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ebfa700 of size 1280
2018-03-13 21:59:44.859583: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ebfac00 of size 1024
2018-03-13 21:59:44.859588: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ebfb000 of size 3584
2018-03-13 21:59:44.859594: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ebfbe00 of size 430080
2018-03-13 21:59:44.859599: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ec64e00 of size 8192
2018-03-13 21:59:44.859605: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ec66e00 of size 256
2018-03-13 21:59:44.859611: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ec66f00 of size 24576
2018-03-13 21:59:44.859617: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ec6cf00 of size 1024
2018-03-13 21:59:44.859622: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ec6d300 of size 1048576
2018-03-13 21:59:44.859627: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ed6d300 of size 1280
2018-03-13 21:59:44.859632: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ed6d800 of size 65536
2018-03-13 21:59:44.859638: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ed7d800 of size 32768
2018-03-13 21:59:44.859643: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ed85800 of size 430080
2018-03-13 21:59:44.859649: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020edee800 of size 262144
2018-03-13 21:59:44.859654: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ee2e800 of size 18432
2018-03-13 21:59:44.859660: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ee33000 of size 9216
2018-03-13 21:59:44.859665: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ee35400 of size 24576
2018-03-13 21:59:44.859671: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ee3b400 of size 1179648
2018-03-13 21:59:44.859676: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ef5b400 of size 1024
2018-03-13 21:59:44.859681: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ef5b800 of size 3584
2018-03-13 21:59:44.859687: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ef5c600 of size 2304
2018-03-13 21:59:44.859692: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ef5cf00 of size 2048
2018-03-13 21:59:44.859698: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ef5d700 of size 1792
2018-03-13 21:59:44.859703: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ef5de00 of size 1048576
2018-03-13 21:59:44.859709: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f05de00 of size 4608
2018-03-13 21:59:44.859714: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f05f000 of size 1720320
2018-03-13 21:59:44.859720: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f203000 of size 131072
2018-03-13 21:59:44.859726: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f223000 of size 65536
2018-03-13 21:59:44.859731: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f233000 of size 1024
2018-03-13 21:59:44.859736: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f233400 of size 1792
2018-03-13 21:59:44.859742: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f233b00 of size 4608
2018-03-13 21:59:44.859748: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f234d00 of size 430080
2018-03-13 21:59:44.859753: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f29dd00 of size 1792
2018-03-13 21:59:44.859758: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f29e400 of size 1024
2018-03-13 21:59:44.859764: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f29e800 of size 430080
2018-03-13 21:59:44.859770: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f307800 of size 1024
2018-03-13 21:59:44.859775: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f307c00 of size 1792
2018-03-13 21:59:44.859781: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f308300 of size 430080
2018-03-13 21:59:44.859786: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f371300 of size 1024
2018-03-13 21:59:44.859793: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f371700 of size 1024
2018-03-13 21:59:44.859803: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f371b00 of size 512
2018-03-13 21:59:44.859810: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f371d00 of size 7424
2018-03-13 21:59:44.859816: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f373a00 of size 430080
2018-03-13 21:59:44.859821: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f3dca00 of size 512
2018-03-13 21:59:44.859826: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f3dcc00 of size 2048
2018-03-13 21:59:44.859847: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f3dd400 of size 512
2018-03-13 21:59:44.859852: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f3dd600 of size 512
2018-03-13 21:59:44.859858: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f3dd800 of size 1024
2018-03-13 21:59:44.859864: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f3ddc00 of size 4096
2018-03-13 21:59:44.859870: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f3dec00 of size 256
2018-03-13 21:59:44.859888: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f3ded00 of size 256
2018-03-13 21:59:44.859894: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f3dee00 of size 256
2018-03-13 21:59:44.859899: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f3def00 of size 512
2018-03-13 21:59:44.859905: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f3df100 of size 256
2018-03-13 21:59:44.859910: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f3df600 of size 256
2018-03-13 21:59:44.859916: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f3df700 of size 256
2018-03-13 21:59:44.859921: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f3df800 of size 256
2018-03-13 21:59:44.859926: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f3df900 of size 256
2018-03-13 21:59:44.859931: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f3dfa00 of size 256
2018-03-13 21:59:44.859936: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f3dfb00 of size 256
2018-03-13 21:59:44.859943: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f3dfc00 of size 256
2018-03-13 21:59:44.859947: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f3dfd00 of size 256
2018-03-13 21:59:44.859953: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f3dfe00 of size 256
2018-03-13 21:59:44.859958: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f3dff00 of size 256
2018-03-13 21:59:44.859963: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f3e0000 of size 512
2018-03-13 21:59:44.859969: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f3e0200 of size 256
2018-03-13 21:59:44.859974: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f3e0300 of size 256
2018-03-13 21:59:44.859979: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f3e0400 of size 256
2018-03-13 21:59:44.859985: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f3e0500 of size 131072
2018-03-13 21:59:44.859990: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f400500 of size 512
2018-03-13 21:59:44.859995: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f400700 of size 2048
2018-03-13 21:59:44.860001: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f400f00 of size 3584
2018-03-13 21:59:44.860006: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f401d00 of size 256
2018-03-13 21:59:44.860012: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f401e00 of size 256
2018-03-13 21:59:44.860018: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f401f00 of size 256
2018-03-13 21:59:44.860023: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f402000 of size 256
2018-03-13 21:59:44.860029: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f402100 of size 256
2018-03-13 21:59:44.860035: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f402200 of size 256
2018-03-13 21:59:44.860039: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f402300 of size 256
2018-03-13 21:59:44.860046: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f402400 of size 256
2018-03-13 21:59:44.860051: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f403300 of size 256
2018-03-13 21:59:44.860061: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f403400 of size 131072
2018-03-13 21:59:44.860068: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f423400 of size 5376
2018-03-13 21:59:44.860074: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f424900 of size 5376
2018-03-13 21:59:44.860080: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f426200 of size 677888
2018-03-13 21:59:44.860086: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f4cba00 of size 2048
2018-03-13 21:59:44.860092: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f4cca00 of size 4096
2018-03-13 21:59:44.860097: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f4cda00 of size 10240
2018-03-13 21:59:44.860103: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f4d0200 of size 5120
2018-03-13 21:59:44.860108: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f4d1600 of size 256
2018-03-13 21:59:44.860114: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f4d1700 of size 7680
2018-03-13 21:59:44.860120: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f4d3500 of size 14592
2018-03-13 21:59:44.860125: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f4d6e00 of size 7680
2018-03-13 21:59:44.860130: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f4d8c00 of size 7680
2018-03-13 21:59:44.860135: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f4daa00 of size 7680
2018-03-13 21:59:44.860141: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f4dc800 of size 7680
2018-03-13 21:59:44.860146: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f4de600 of size 7680
2018-03-13 21:59:44.860152: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f4e0400 of size 7680
2018-03-13 21:59:44.860158: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f4e2200 of size 1720320
2018-03-13 21:59:44.860163: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f686200 of size 1179648
2018-03-13 21:59:44.860168: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7a6200 of size 7680
2018-03-13 21:59:44.860173: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7a8000 of size 7680
2018-03-13 21:59:44.860179: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7a9e00 of size 7680
2018-03-13 21:59:44.860184: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7abc00 of size 7680
2018-03-13 21:59:44.860190: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7ada00 of size 30720
2018-03-13 21:59:44.860196: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7b5200 of size 30720
2018-03-13 21:59:44.860201: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7bca00 of size 7680
2018-03-13 21:59:44.860207: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7be800 of size 7680
2018-03-13 21:59:44.860212: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7c0600 of size 7680
2018-03-13 21:59:44.860218: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7c2400 of size 7680
2018-03-13 21:59:44.860240: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7c4200 of size 11776
2018-03-13 21:59:44.860246: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7c7000 of size 256
2018-03-13 21:59:44.860251: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7c7100 of size 256
2018-03-13 21:59:44.860257: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7c7200 of size 256
2018-03-13 21:59:44.860274: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7c7300 of size 2816
2018-03-13 21:59:44.860280: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7c8300 of size 2560
2018-03-13 21:59:44.860285: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7c8d00 of size 256
2018-03-13 21:59:44.860291: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7c8e00 of size 7936
2018-03-13 21:59:44.860296: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7cad00 of size 8192
2018-03-13 21:59:44.860301: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7ccd00 of size 9984
2018-03-13 21:59:44.860308: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7cf400 of size 256
2018-03-13 21:59:44.860318: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7cf500 of size 256
2018-03-13 21:59:44.860325: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7cf600 of size 256
2018-03-13 21:59:44.860330: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7cf700 of size 256
2018-03-13 21:59:44.860336: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7cf800 of size 256
2018-03-13 21:59:44.860341: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7cf900 of size 256
2018-03-13 21:59:44.860347: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7cfa00 of size 256
2018-03-13 21:59:44.860353: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7cfb00 of size 256
2018-03-13 21:59:44.860358: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7cfc00 of size 256
2018-03-13 21:59:44.860364: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7cfd00 of size 256
2018-03-13 21:59:44.860368: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7cfe00 of size 256
2018-03-13 21:59:44.860374: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7cff00 of size 256
2018-03-13 21:59:44.860379: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7d0000 of size 256
2018-03-13 21:59:44.860385: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7d0100 of size 256
2018-03-13 21:59:44.860391: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7d0200 of size 256
2018-03-13 21:59:44.860395: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7d0300 of size 512
2018-03-13 21:59:44.860401: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7d0500 of size 256
2018-03-13 21:59:44.860405: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7d0600 of size 256
2018-03-13 21:59:44.860411: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7d0700 of size 7680
2018-03-13 21:59:44.860416: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7d2500 of size 7680
2018-03-13 21:59:44.860422: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7d4300 of size 256
2018-03-13 21:59:44.860427: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7d4400 of size 768
2018-03-13 21:59:44.860433: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7d4c00 of size 7680
2018-03-13 21:59:44.860438: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7d6a00 of size 15104
2018-03-13 21:59:44.860444: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7da500 of size 7680
2018-03-13 21:59:44.860449: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7dc300 of size 7680
2018-03-13 21:59:44.860454: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7de100 of size 7680
2018-03-13 21:59:44.860459: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7dff00 of size 7680
2018-03-13 21:59:44.860464: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7e1d00 of size 7680
2018-03-13 21:59:44.860470: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7e3b00 of size 7680
2018-03-13 21:59:44.860475: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7e5900 of size 60928
2018-03-13 21:59:44.860481: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7f4700 of size 30720
2018-03-13 21:59:44.860486: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f7fbf00 of size 15104
2018-03-13 21:59:44.860491: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f803700 of size 30720
2018-03-13 21:59:44.860497: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f80af00 of size 46080
2018-03-13 21:59:44.860502: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f819f00 of size 30720
2018-03-13 21:59:44.860507: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f821700 of size 30720
2018-03-13 21:59:44.860512: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f828f00 of size 30720
2018-03-13 21:59:44.860517: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f830700 of size 30720
2018-03-13 21:59:44.860522: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f837f00 of size 30720
2018-03-13 21:59:44.860528: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f846f00 of size 55552
2018-03-13 21:59:44.860533: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f854800 of size 860160
2018-03-13 21:59:44.860539: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f926800 of size 860160
2018-03-13 21:59:44.860545: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f9f8800 of size 532224
2018-03-13 21:59:44.860550: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020fa7a700 of size 262144
2018-03-13 21:59:44.860556: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020faba700 of size 30720
2018-03-13 21:59:44.860562: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020fac1f00 of size 240128
2018-03-13 21:59:44.860568: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020fafc900 of size 534016
2018-03-13 21:59:44.860578: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020fb86700 of size 499712
2018-03-13 21:59:44.860584: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020fc00700 of size 536832
2018-03-13 21:59:44.860590: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020fc83800 of size 536320
2018-03-13 21:59:44.860595: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020fd06700 of size 536832
2018-03-13 21:59:44.860600: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020fd89800 of size 536832
2018-03-13 21:59:44.860606: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020fe0c900 of size 1067520
2018-03-13 21:59:44.860611: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ff11300 of size 536832
2018-03-13 21:59:44.860616: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ff94400 of size 536832
2018-03-13 21:59:44.860622: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210017500 of size 536832
2018-03-13 21:59:44.860627: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021009a600 of size 536832
2018-03-13 21:59:44.860632: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021011d700 of size 625664
2018-03-13 21:59:44.860638: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102101b6300 of size 256
2018-03-13 21:59:44.860643: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102101b6400 of size 256
2018-03-13 21:59:44.860649: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102101b6500 of size 256
2018-03-13 21:59:44.860655: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102101b6600 of size 512
2018-03-13 21:59:44.860660: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102101b6800 of size 256
2018-03-13 21:59:44.860665: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102101b6900 of size 256
2018-03-13 21:59:44.860670: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102101b6a00 of size 256
2018-03-13 21:59:44.860675: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102101b6b00 of size 256
2018-03-13 21:59:44.860681: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102101b6c00 of size 256
2018-03-13 21:59:44.860686: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102101b6d00 of size 256
2018-03-13 21:59:44.860692: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102101b6e00 of size 256
2018-03-13 21:59:44.860697: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102101b6f00 of size 256
2018-03-13 21:59:44.860703: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102101b7000 of size 256
2018-03-13 21:59:44.860708: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102101b7100 of size 256
2018-03-13 21:59:44.860714: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102101b7200 of size 256
2018-03-13 21:59:44.860719: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102101b7300 of size 512
2018-03-13 21:59:44.860725: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102101b7500 of size 256
2018-03-13 21:59:44.860731: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102101b7600 of size 256
2018-03-13 21:59:44.860736: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102101b7700 of size 256
2018-03-13 21:59:44.860741: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102101b7800 of size 256
2018-03-13 21:59:44.860747: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102101b7900 of size 256
2018-03-13 21:59:44.860752: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102101b7a00 of size 256
2018-03-13 21:59:44.860757: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102101b7b00 of size 256
2018-03-13 21:59:44.860763: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102101b7c00 of size 256
2018-03-13 21:59:44.860769: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102101b7d00 of size 512
2018-03-13 21:59:44.860774: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102101b7f00 of size 256
2018-03-13 21:59:44.860780: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102101b8000 of size 256
2018-03-13 21:59:44.860785: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102101b8100 of size 256
2018-03-13 21:59:44.860790: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102101b8200 of size 256
2018-03-13 21:59:44.860796: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102101b8300 of size 256
2018-03-13 21:59:44.860801: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102101b8400 of size 256
2018-03-13 21:59:44.860807: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102101b8500 of size 256
2018-03-13 21:59:44.860812: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102101b8600 of size 256
2018-03-13 21:59:44.860817: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102101b8700 of size 256
2018-03-13 21:59:44.860823: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102101b8800 of size 256
2018-03-13 21:59:44.860828: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102101b8900 of size 256
2018-03-13 21:59:44.860836: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102101b8a00 of size 512
2018-03-13 21:59:44.860845: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102101b8c00 of size 256
2018-03-13 21:59:44.860852: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102101b8d00 of size 256
2018-03-13 21:59:44.860857: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102101b8e00 of size 256
2018-03-13 21:59:44.860863: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102101b8f00 of size 256
2018-03-13 21:59:44.860867: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102101b9000 of size 736256
2018-03-13 21:59:44.860873: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026cc00 of size 256
2018-03-13 21:59:44.860879: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026cd00 of size 256
2018-03-13 21:59:44.860884: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026ce00 of size 512
2018-03-13 21:59:44.860890: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026d000 of size 256
2018-03-13 21:59:44.860895: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026d100 of size 256
2018-03-13 21:59:44.860901: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026d200 of size 256
2018-03-13 21:59:44.860921: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026d300 of size 256
2018-03-13 21:59:44.860926: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026d400 of size 256
2018-03-13 21:59:44.860932: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026d500 of size 512
2018-03-13 21:59:44.860937: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026d700 of size 256
2018-03-13 21:59:44.860943: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026d800 of size 256
2018-03-13 21:59:44.860948: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026d900 of size 256
2018-03-13 21:59:44.860954: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026da00 of size 256
2018-03-13 21:59:44.860972: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026db00 of size 256
2018-03-13 21:59:44.860978: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026dc00 of size 256
2018-03-13 21:59:44.860983: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026dd00 of size 256
2018-03-13 21:59:44.860989: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026de00 of size 256
2018-03-13 21:59:44.860995: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026df00 of size 512
2018-03-13 21:59:44.861000: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026e100 of size 256
2018-03-13 21:59:44.861006: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026e200 of size 256
2018-03-13 21:59:44.861011: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026e300 of size 256
2018-03-13 21:59:44.861016: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026e400 of size 256
2018-03-13 21:59:44.861022: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026e500 of size 256
2018-03-13 21:59:44.861027: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026e600 of size 256
2018-03-13 21:59:44.861033: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026e700 of size 512
2018-03-13 21:59:44.861038: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026e900 of size 256
2018-03-13 21:59:44.861043: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026ea00 of size 256
2018-03-13 21:59:44.861049: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026eb00 of size 256
2018-03-13 21:59:44.861054: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026ec00 of size 256
2018-03-13 21:59:44.861059: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026ed00 of size 256
2018-03-13 21:59:44.861065: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026ee00 of size 256
2018-03-13 21:59:44.861070: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026ef00 of size 256
2018-03-13 21:59:44.861076: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026f000 of size 256
2018-03-13 21:59:44.861080: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026f100 of size 256
2018-03-13 21:59:44.861089: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026f200 of size 256
2018-03-13 21:59:44.861095: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026f300 of size 256
2018-03-13 21:59:44.861101: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026f400 of size 256
2018-03-13 21:59:44.861106: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026f500 of size 256
2018-03-13 21:59:44.861111: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026f600 of size 512
2018-03-13 21:59:44.861116: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026f800 of size 256
2018-03-13 21:59:44.861121: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026f900 of size 512
2018-03-13 21:59:44.861126: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026fb00 of size 256
2018-03-13 21:59:44.861131: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026fc00 of size 256
2018-03-13 21:59:44.861137: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026fd00 of size 256
2018-03-13 21:59:44.861143: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026fe00 of size 256
2018-03-13 21:59:44.861148: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021026ff00 of size 256
2018-03-13 21:59:44.861153: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210270000 of size 256
2018-03-13 21:59:44.861159: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210270100 of size 256
2018-03-13 21:59:44.861164: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210270200 of size 256
2018-03-13 21:59:44.861169: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210270300 of size 512
2018-03-13 21:59:44.861175: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210270500 of size 256
2018-03-13 21:59:44.861180: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210270600 of size 256
2018-03-13 21:59:44.861186: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210270700 of size 256
2018-03-13 21:59:44.861191: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210270800 of size 256
2018-03-13 21:59:44.861197: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210270900 of size 256
2018-03-13 21:59:44.861202: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210270a00 of size 256
2018-03-13 21:59:44.861208: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210270b00 of size 512
2018-03-13 21:59:44.861213: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210270d00 of size 256
2018-03-13 21:59:44.861219: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210270e00 of size 256
2018-03-13 21:59:44.861240: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210270f00 of size 256
2018-03-13 21:59:44.861247: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210271000 of size 256
2018-03-13 21:59:44.861252: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210271100 of size 256
2018-03-13 21:59:44.861258: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210271200 of size 256
2018-03-13 21:59:44.861276: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210271300 of size 256
2018-03-13 21:59:44.861281: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210271400 of size 256
2018-03-13 21:59:44.861286: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210271500 of size 256
2018-03-13 21:59:44.861292: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210271600 of size 256
2018-03-13 21:59:44.861297: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210271700 of size 256
2018-03-13 21:59:44.861302: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210271800 of size 256
2018-03-13 21:59:44.861308: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210271900 of size 512
2018-03-13 21:59:44.861313: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210271b00 of size 256
2018-03-13 21:59:44.861319: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210271c00 of size 256
2018-03-13 21:59:44.861324: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210271d00 of size 256
2018-03-13 21:59:44.861330: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210271e00 of size 256
2018-03-13 21:59:44.861335: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210271f00 of size 256
2018-03-13 21:59:44.861341: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210272000 of size 512
2018-03-13 21:59:44.861347: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210272200 of size 256
2018-03-13 21:59:44.861356: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210272300 of size 256
2018-03-13 21:59:44.861363: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210272400 of size 256
2018-03-13 21:59:44.861369: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210272500 of size 256
2018-03-13 21:59:44.861375: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210272600 of size 256
2018-03-13 21:59:44.861380: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210272700 of size 512
2018-03-13 21:59:44.861385: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210272900 of size 256
2018-03-13 21:59:44.861391: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210272a00 of size 256
2018-03-13 21:59:44.861396: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210272b00 of size 256
2018-03-13 21:59:44.861401: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210272c00 of size 256
2018-03-13 21:59:44.861407: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210272d00 of size 256
2018-03-13 21:59:44.861412: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210272e00 of size 256
2018-03-13 21:59:44.861418: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210272f00 of size 256
2018-03-13 21:59:44.861423: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210273000 of size 256
2018-03-13 21:59:44.861429: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210273100 of size 256
2018-03-13 21:59:44.861434: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210273200 of size 512
2018-03-13 21:59:44.861440: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210273400 of size 256
2018-03-13 21:59:44.861444: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210273500 of size 256
2018-03-13 21:59:44.861451: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210273600 of size 256
2018-03-13 21:59:44.861456: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210273700 of size 256
2018-03-13 21:59:44.861462: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210273800 of size 256
2018-03-13 21:59:44.861466: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210273900 of size 256
2018-03-13 21:59:44.861472: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210273a00 of size 256
2018-03-13 21:59:44.861478: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210273b00 of size 256
2018-03-13 21:59:44.861483: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210273c00 of size 256
2018-03-13 21:59:44.861488: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210273d00 of size 256
2018-03-13 21:59:44.861495: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210273e00 of size 256
2018-03-13 21:59:44.861500: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210273f00 of size 512
2018-03-13 21:59:44.861506: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210274100 of size 256
2018-03-13 21:59:44.861510: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210274200 of size 256
2018-03-13 21:59:44.861516: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210274300 of size 256
2018-03-13 21:59:44.861521: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210274400 of size 512
2018-03-13 21:59:44.861526: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210274600 of size 256
2018-03-13 21:59:44.861531: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210274700 of size 256
2018-03-13 21:59:44.861537: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210274800 of size 256
2018-03-13 21:59:44.861542: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210274900 of size 256
2018-03-13 21:59:44.861548: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210274a00 of size 256
2018-03-13 21:59:44.861553: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210274b00 of size 256
2018-03-13 21:59:44.861558: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210274c00 of size 256
2018-03-13 21:59:44.861564: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210274d00 of size 256
2018-03-13 21:59:44.861569: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210274e00 of size 256
2018-03-13 21:59:44.861575: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210274f00 of size 256
2018-03-13 21:59:44.861579: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210275000 of size 256
2018-03-13 21:59:44.861585: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210275100 of size 512
2018-03-13 21:59:44.861590: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210275300 of size 256
2018-03-13 21:59:44.861595: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210275400 of size 256
2018-03-13 21:59:44.861601: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210275500 of size 256
2018-03-13 21:59:44.861606: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210275600 of size 256
2018-03-13 21:59:44.861612: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210275700 of size 256
2018-03-13 21:59:44.861617: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210275800 of size 256
2018-03-13 21:59:44.861622: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210275900 of size 512
2018-03-13 21:59:44.861628: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210275b00 of size 256
2018-03-13 21:59:44.861633: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210275c00 of size 256
2018-03-13 21:59:44.861639: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210275d00 of size 256
2018-03-13 21:59:44.861643: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210275e00 of size 256
2018-03-13 21:59:44.861649: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210275f00 of size 256
2018-03-13 21:59:44.861654: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210276000 of size 256
2018-03-13 21:59:44.861659: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210276100 of size 256
2018-03-13 21:59:44.861665: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210276200 of size 512
2018-03-13 21:59:44.861670: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210276400 of size 256
2018-03-13 21:59:44.861675: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210276500 of size 256
2018-03-13 21:59:44.861681: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210276600 of size 256
2018-03-13 21:59:44.861687: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210276700 of size 256
2018-03-13 21:59:44.861693: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210276800 of size 256
2018-03-13 21:59:44.861700: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210276900 of size 256
2018-03-13 21:59:44.861706: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210276a00 of size 512
2018-03-13 21:59:44.861712: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210276c00 of size 256
2018-03-13 21:59:44.861718: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210276d00 of size 256
2018-03-13 21:59:44.861723: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210276e00 of size 256
2018-03-13 21:59:44.861729: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210276f00 of size 256
2018-03-13 21:59:44.861734: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210277000 of size 256
2018-03-13 21:59:44.861739: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210277100 of size 256
2018-03-13 21:59:44.861745: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210277200 of size 256
2018-03-13 21:59:44.861751: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210277300 of size 256
2018-03-13 21:59:44.861755: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210277400 of size 256
2018-03-13 21:59:44.861761: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210277500 of size 512
2018-03-13 21:59:44.861767: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210277700 of size 256
2018-03-13 21:59:44.861772: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210277800 of size 256
2018-03-13 21:59:44.861777: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210277900 of size 256
2018-03-13 21:59:44.861783: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210277a00 of size 256
2018-03-13 21:59:44.861788: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210277b00 of size 256
2018-03-13 21:59:44.861793: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210277c00 of size 512
2018-03-13 21:59:44.861799: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210277e00 of size 256
2018-03-13 21:59:44.861804: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210277f00 of size 256
2018-03-13 21:59:44.861810: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210278000 of size 7680
2018-03-13 21:59:44.861815: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210279e00 of size 7680
2018-03-13 21:59:44.861821: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021027bc00 of size 7680
2018-03-13 21:59:44.861826: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021027da00 of size 7680
2018-03-13 21:59:44.861832: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021027f800 of size 7680
2018-03-13 21:59:44.861837: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210281600 of size 7680
2018-03-13 21:59:44.861843: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210283400 of size 7680
2018-03-13 21:59:44.861848: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210285200 of size 7680
2018-03-13 21:59:44.861853: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210287000 of size 7680
2018-03-13 21:59:44.861859: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210288e00 of size 7680
2018-03-13 21:59:44.861864: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021028ac00 of size 7680
2018-03-13 21:59:44.861870: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021028ca00 of size 7680
2018-03-13 21:59:44.861875: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021028e800 of size 7680
2018-03-13 21:59:44.861881: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210290600 of size 7680
2018-03-13 21:59:44.861885: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210292400 of size 7680
2018-03-13 21:59:44.861892: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210294200 of size 7680
2018-03-13 21:59:44.861897: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210296000 of size 7680
2018-03-13 21:59:44.861902: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210297e00 of size 7680
2018-03-13 21:59:44.861908: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210299c00 of size 7680
2018-03-13 21:59:44.861913: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021029ba00 of size 7680
2018-03-13 21:59:44.861918: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021029d800 of size 7680
2018-03-13 21:59:44.861924: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021029f600 of size 7680
2018-03-13 21:59:44.861929: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102a1400 of size 7680
2018-03-13 21:59:44.861935: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102a3200 of size 7680
2018-03-13 21:59:44.861940: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102a5000 of size 7680
2018-03-13 21:59:44.861946: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102a6e00 of size 7680
2018-03-13 21:59:44.861951: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102a8c00 of size 7680
2018-03-13 21:59:44.861957: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102aaa00 of size 7680
2018-03-13 21:59:44.861962: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102ac800 of size 7680
2018-03-13 21:59:44.861968: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102ae600 of size 7680
2018-03-13 21:59:44.861973: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102b0400 of size 7680
2018-03-13 21:59:44.861978: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102b2200 of size 7680
2018-03-13 21:59:44.861999: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102b4000 of size 7680
2018-03-13 21:59:44.862005: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102b5e00 of size 7680
2018-03-13 21:59:44.862010: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102b7c00 of size 7680
2018-03-13 21:59:44.862015: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102b9a00 of size 7680
2018-03-13 21:59:44.862021: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102bb800 of size 7680
2018-03-13 21:59:44.862038: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102bd600 of size 7680
2018-03-13 21:59:44.862044: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102bf400 of size 7680
2018-03-13 21:59:44.862050: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102c1200 of size 7680
2018-03-13 21:59:44.862055: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102c3000 of size 7680
2018-03-13 21:59:44.862060: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102c4e00 of size 7680
2018-03-13 21:59:44.862066: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102c6c00 of size 7680
2018-03-13 21:59:44.862071: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102c8a00 of size 7680
2018-03-13 21:59:44.862077: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102ca800 of size 7680
2018-03-13 21:59:44.862082: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102cc600 of size 7680
2018-03-13 21:59:44.862087: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102ce400 of size 7680
2018-03-13 21:59:44.862093: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102d0200 of size 7680
2018-03-13 21:59:44.862098: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102d2000 of size 7680
2018-03-13 21:59:44.862104: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102d3e00 of size 7680
2018-03-13 21:59:44.862109: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102d5c00 of size 7680
2018-03-13 21:59:44.862115: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102d7a00 of size 7680
2018-03-13 21:59:44.862120: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102d9800 of size 7680
2018-03-13 21:59:44.862127: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102db600 of size 7680
2018-03-13 21:59:44.862132: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102dd400 of size 7680
2018-03-13 21:59:44.862138: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102df200 of size 7680
2018-03-13 21:59:44.862143: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102e1000 of size 7680
2018-03-13 21:59:44.862149: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102e2e00 of size 7680
2018-03-13 21:59:44.862154: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102e4c00 of size 7680
2018-03-13 21:59:44.862159: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102e6a00 of size 7680
2018-03-13 21:59:44.862165: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102e8800 of size 7680
2018-03-13 21:59:44.862170: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102ea600 of size 7680
2018-03-13 21:59:44.862176: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102ec400 of size 7680
2018-03-13 21:59:44.862181: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102ee200 of size 7680
2018-03-13 21:59:44.862187: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102f0000 of size 7680
2018-03-13 21:59:44.862191: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102f1e00 of size 7680
2018-03-13 21:59:44.862197: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102f3c00 of size 7680
2018-03-13 21:59:44.862202: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102f5a00 of size 7680
2018-03-13 21:59:44.862208: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102f7800 of size 7680
2018-03-13 21:59:44.862213: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102f9600 of size 7680
2018-03-13 21:59:44.862219: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102fb400 of size 7680
2018-03-13 21:59:44.862239: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102fd200 of size 7680
2018-03-13 21:59:44.862244: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102102ff000 of size 7680
2018-03-13 21:59:44.862250: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210300e00 of size 7680
2018-03-13 21:59:44.862255: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210302c00 of size 7680
2018-03-13 21:59:44.862274: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210304a00 of size 7680
2018-03-13 21:59:44.862279: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210306800 of size 7680
2018-03-13 21:59:44.862285: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210308600 of size 7680
2018-03-13 21:59:44.862290: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021030a400 of size 7680
2018-03-13 21:59:44.862296: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021030c200 of size 7680
2018-03-13 21:59:44.862300: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021030e000 of size 7680
2018-03-13 21:59:44.862306: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021030fe00 of size 7680
2018-03-13 21:59:44.862312: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210311c00 of size 7680
2018-03-13 21:59:44.862317: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210313a00 of size 7680
2018-03-13 21:59:44.862326: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210315800 of size 7680
2018-03-13 21:59:44.862332: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210317600 of size 7680
2018-03-13 21:59:44.862337: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210319400 of size 7680
2018-03-13 21:59:44.862343: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021031b200 of size 7680
2018-03-13 21:59:44.862348: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021031d000 of size 7680
2018-03-13 21:59:44.862353: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021031ee00 of size 7680
2018-03-13 21:59:44.862359: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210320c00 of size 7680
2018-03-13 21:59:44.862364: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210322a00 of size 7680
2018-03-13 21:59:44.862369: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210324800 of size 7680
2018-03-13 21:59:44.862375: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210326600 of size 7680
2018-03-13 21:59:44.862380: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210328400 of size 7680
2018-03-13 21:59:44.862386: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021032a200 of size 7680
2018-03-13 21:59:44.862391: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021032c000 of size 7680
2018-03-13 21:59:44.862396: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021032de00 of size 7680
2018-03-13 21:59:44.862402: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021032fc00 of size 7680
2018-03-13 21:59:44.862407: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210331a00 of size 7680
2018-03-13 21:59:44.862412: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210333800 of size 7680
2018-03-13 21:59:44.862418: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210335600 of size 7680
2018-03-13 21:59:44.862424: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210337400 of size 7680
2018-03-13 21:59:44.862429: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210339200 of size 7680
2018-03-13 21:59:44.862434: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021033b000 of size 7680
2018-03-13 21:59:44.862440: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021033ce00 of size 7680
2018-03-13 21:59:44.862446: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021033ec00 of size 7680
2018-03-13 21:59:44.862451: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210340a00 of size 7680
2018-03-13 21:59:44.862457: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210342800 of size 7680
2018-03-13 21:59:44.862462: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210344600 of size 7680
2018-03-13 21:59:44.862467: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210346400 of size 7680
2018-03-13 21:59:44.862473: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210348200 of size 7680
2018-03-13 21:59:44.862478: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021034a000 of size 7680
2018-03-13 21:59:44.862484: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021034be00 of size 7680
2018-03-13 21:59:44.862489: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021034dc00 of size 7680
2018-03-13 21:59:44.862494: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021034fa00 of size 7680
2018-03-13 21:59:44.862500: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210351800 of size 7680
2018-03-13 21:59:44.862505: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210353600 of size 7680
2018-03-13 21:59:44.862510: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210355400 of size 7680
2018-03-13 21:59:44.862516: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210357200 of size 7680
2018-03-13 21:59:44.862521: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210359000 of size 7680
2018-03-13 21:59:44.862527: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021035ae00 of size 7680
2018-03-13 21:59:44.862533: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021035cc00 of size 7680
2018-03-13 21:59:44.862538: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021035ea00 of size 7680
2018-03-13 21:59:44.862543: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210360800 of size 7680
2018-03-13 21:59:44.862549: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210362600 of size 7680
2018-03-13 21:59:44.862554: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210364400 of size 7680
2018-03-13 21:59:44.862560: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210366200 of size 7680
2018-03-13 21:59:44.862565: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210368000 of size 7680
2018-03-13 21:59:44.862570: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210369e00 of size 7680
2018-03-13 21:59:44.862577: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021036bc00 of size 7680
2018-03-13 21:59:44.862586: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021036da00 of size 7680
2018-03-13 21:59:44.862591: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021036f800 of size 7680
2018-03-13 21:59:44.862597: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210371600 of size 7680
2018-03-13 21:59:44.862602: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210373400 of size 7680
2018-03-13 21:59:44.862608: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210375200 of size 7680
2018-03-13 21:59:44.862613: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210377000 of size 7680
2018-03-13 21:59:44.862618: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210378e00 of size 7680
2018-03-13 21:59:44.862624: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021037ac00 of size 7680
2018-03-13 21:59:44.862629: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021037ca00 of size 7680
2018-03-13 21:59:44.862635: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021037e800 of size 7680
2018-03-13 21:59:44.862640: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210380600 of size 7680
2018-03-13 21:59:44.862646: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210382400 of size 7680
2018-03-13 21:59:44.862651: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210384200 of size 7680
2018-03-13 21:59:44.862657: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210386000 of size 30720
2018-03-13 21:59:44.862662: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021038d800 of size 736256
2018-03-13 21:59:44.862668: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10210441400 of size 184064
2018-03-13 21:59:44.862673: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021046e300 of size 184064
2018-03-13 21:59:44.862678: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021049b200 of size 184064
2018-03-13 21:59:44.862684: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102104c8100 of size 184064
2018-03-13 21:59:44.862689: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102104f5000 of size 256
2018-03-13 21:59:44.862694: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102104f5100 of size 256
2018-03-13 21:59:44.862699: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102104f5200 of size 12882432
2018-03-13 21:59:44.862705: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021113e400 of size 256
2018-03-13 21:59:44.862710: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021113e500 of size 256
2018-03-13 21:59:44.862716: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021113e600 of size 256
2018-03-13 21:59:44.862722: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021113e700 of size 256
2018-03-13 21:59:44.862727: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021113e800 of size 256
2018-03-13 21:59:44.862733: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021113e900 of size 256
2018-03-13 21:59:44.862738: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021113ea00 of size 256
2018-03-13 21:59:44.862744: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021113eb00 of size 256
2018-03-13 21:59:44.862749: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021113ec00 of size 256
2018-03-13 21:59:44.862754: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021113ed00 of size 256
2018-03-13 21:59:44.862759: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021113ee00 of size 256
2018-03-13 21:59:44.862764: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021113ef00 of size 256
2018-03-13 21:59:44.862770: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021113f000 of size 256
2018-03-13 21:59:44.862775: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021113f100 of size 256
2018-03-13 21:59:44.862781: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021113f200 of size 256
2018-03-13 21:59:44.862786: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021113f300 of size 256
2018-03-13 21:59:44.862792: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021113f400 of size 256
2018-03-13 21:59:44.862797: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021113f500 of size 256
2018-03-13 21:59:44.862802: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021113f600 of size 256
2018-03-13 21:59:44.862806: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021113f700 of size 256
2018-03-13 21:59:44.862812: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021113f800 of size 256
2018-03-13 21:59:44.862817: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021113f900 of size 256
2018-03-13 21:59:44.862823: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021113fa00 of size 256
2018-03-13 21:59:44.862828: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021113fb00 of size 256
2018-03-13 21:59:44.862834: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021113fc00 of size 256
2018-03-13 21:59:44.862839: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021113fd00 of size 256
2018-03-13 21:59:44.862845: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021113fe00 of size 256
2018-03-13 21:59:44.862850: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021113ff00 of size 256
2018-03-13 21:59:44.862856: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211140000 of size 256
2018-03-13 21:59:44.862861: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211140100 of size 256
2018-03-13 21:59:44.862867: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211140200 of size 256
2018-03-13 21:59:44.862872: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211140300 of size 256
2018-03-13 21:59:44.862878: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211140400 of size 256
2018-03-13 21:59:44.862883: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211140500 of size 256
2018-03-13 21:59:44.862889: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211140600 of size 256
2018-03-13 21:59:44.862894: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211140700 of size 256
2018-03-13 21:59:44.862900: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211140800 of size 256
2018-03-13 21:59:44.862904: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211140900 of size 256
2018-03-13 21:59:44.862910: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211140a00 of size 256
2018-03-13 21:59:44.862916: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211140b00 of size 256
2018-03-13 21:59:44.862921: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211140c00 of size 256
2018-03-13 21:59:44.862927: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211140d00 of size 256
2018-03-13 21:59:44.862932: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211140e00 of size 256
2018-03-13 21:59:44.862938: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211140f00 of size 256
2018-03-13 21:59:44.862943: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211141000 of size 256
2018-03-13 21:59:44.862949: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211141100 of size 256
2018-03-13 21:59:44.862954: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211141200 of size 256
2018-03-13 21:59:44.862959: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211141300 of size 256
2018-03-13 21:59:44.862964: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211141400 of size 256
2018-03-13 21:59:44.862969: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211141500 of size 256
2018-03-13 21:59:44.862975: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211141600 of size 256
2018-03-13 21:59:44.862980: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211141700 of size 256
2018-03-13 21:59:44.862985: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211141800 of size 256
2018-03-13 21:59:44.862990: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211141900 of size 256
2018-03-13 21:59:44.862995: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211141a00 of size 256
2018-03-13 21:59:44.863000: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211141b00 of size 256
2018-03-13 21:59:44.863006: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211141c00 of size 256
2018-03-13 21:59:44.863010: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211141d00 of size 256
2018-03-13 21:59:44.863016: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211141e00 of size 256
2018-03-13 21:59:44.863021: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211141f00 of size 256
2018-03-13 21:59:44.863027: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211142000 of size 256
2018-03-13 21:59:44.863032: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211142100 of size 256
2018-03-13 21:59:44.863038: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211142200 of size 256
2018-03-13 21:59:44.863043: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211142300 of size 256
2018-03-13 21:59:44.863049: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211142400 of size 256
2018-03-13 21:59:44.863053: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211142500 of size 256
2018-03-13 21:59:44.863074: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211142600 of size 256
2018-03-13 21:59:44.863079: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211142700 of size 256
2018-03-13 21:59:44.863085: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211142800 of size 256
2018-03-13 21:59:44.863091: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211142900 of size 256
2018-03-13 21:59:44.863097: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211142a00 of size 256
2018-03-13 21:59:44.863103: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211142b00 of size 256
2018-03-13 21:59:44.863107: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211142c00 of size 256
2018-03-13 21:59:44.863113: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211142d00 of size 256
2018-03-13 21:59:44.863117: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211142e00 of size 256
2018-03-13 21:59:44.863123: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211142f00 of size 256
2018-03-13 21:59:44.863129: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211143000 of size 256
2018-03-13 21:59:44.863134: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211143100 of size 256
2018-03-13 21:59:44.863139: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211143200 of size 256
2018-03-13 21:59:44.863145: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211143300 of size 256
2018-03-13 21:59:44.863150: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211143400 of size 256
2018-03-13 21:59:44.863156: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211143500 of size 256
2018-03-13 21:59:44.863161: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211143600 of size 256
2018-03-13 21:59:44.863167: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211143700 of size 256
2018-03-13 21:59:44.863172: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211143800 of size 256
2018-03-13 21:59:44.863178: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211143900 of size 256
2018-03-13 21:59:44.863183: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211143a00 of size 256
2018-03-13 21:59:44.863188: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211143b00 of size 256
2018-03-13 21:59:44.863193: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211143c00 of size 256
2018-03-13 21:59:44.863199: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211143d00 of size 256
2018-03-13 21:59:44.863204: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211143e00 of size 256
2018-03-13 21:59:44.863210: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211143f00 of size 256
2018-03-13 21:59:44.863216: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211144000 of size 256
2018-03-13 21:59:44.863223: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211144100 of size 256
2018-03-13 21:59:44.863228: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211144200 of size 256
2018-03-13 21:59:44.863234: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211144300 of size 256
2018-03-13 21:59:44.863239: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211144400 of size 256
2018-03-13 21:59:44.863257: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211144500 of size 256
2018-03-13 21:59:44.863262: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211144600 of size 256
2018-03-13 21:59:44.863268: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211144700 of size 256
2018-03-13 21:59:44.863274: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211144800 of size 256
2018-03-13 21:59:44.863279: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211144900 of size 256
2018-03-13 21:59:44.863284: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211144a00 of size 256
2018-03-13 21:59:44.863290: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211144b00 of size 256
2018-03-13 21:59:44.863295: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211144c00 of size 256
2018-03-13 21:59:44.863300: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211144d00 of size 256
2018-03-13 21:59:44.863306: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211144e00 of size 256
2018-03-13 21:59:44.863312: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211144f00 of size 256
2018-03-13 21:59:44.863317: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211145000 of size 256
2018-03-13 21:59:44.863322: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211145100 of size 256
2018-03-13 21:59:44.863328: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211145200 of size 256
2018-03-13 21:59:44.863333: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211145300 of size 256
2018-03-13 21:59:44.863339: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211145400 of size 256
2018-03-13 21:59:44.863344: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211145500 of size 256
2018-03-13 21:59:44.863350: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211145600 of size 256
2018-03-13 21:59:44.863359: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211145700 of size 256
2018-03-13 21:59:44.863366: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211145800 of size 256
2018-03-13 21:59:44.863373: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211145900 of size 256
2018-03-13 21:59:44.863378: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211145a00 of size 256
2018-03-13 21:59:44.863383: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211145b00 of size 256
2018-03-13 21:59:44.863389: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211145c00 of size 256
2018-03-13 21:59:44.863394: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211145d00 of size 256
2018-03-13 21:59:44.863400: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211145e00 of size 256
2018-03-13 21:59:44.863405: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211145f00 of size 256
2018-03-13 21:59:44.863411: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211146000 of size 256
2018-03-13 21:59:44.863416: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211146100 of size 256
2018-03-13 21:59:44.863422: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211146200 of size 256
2018-03-13 21:59:44.863427: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211146300 of size 256
2018-03-13 21:59:44.863433: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211146400 of size 256
2018-03-13 21:59:44.863438: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211146500 of size 256
2018-03-13 21:59:44.863444: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211146600 of size 256
2018-03-13 21:59:44.863448: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211146700 of size 256
2018-03-13 21:59:44.863455: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211146800 of size 256
2018-03-13 21:59:44.863460: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211146900 of size 256
2018-03-13 21:59:44.863466: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211146a00 of size 256
2018-03-13 21:59:44.863470: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211146b00 of size 256
2018-03-13 21:59:44.863476: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211146c00 of size 256
2018-03-13 21:59:44.863481: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211146d00 of size 256
2018-03-13 21:59:44.863487: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211146e00 of size 256
2018-03-13 21:59:44.863492: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211146f00 of size 256
2018-03-13 21:59:44.863498: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211147000 of size 256
2018-03-13 21:59:44.863503: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211147100 of size 256
2018-03-13 21:59:44.863509: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211147200 of size 256
2018-03-13 21:59:44.863514: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211147300 of size 256
2018-03-13 21:59:44.863520: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211147400 of size 256
2018-03-13 21:59:44.863525: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211147500 of size 256
2018-03-13 21:59:44.863531: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211147600 of size 256
2018-03-13 21:59:44.863536: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211147700 of size 256
2018-03-13 21:59:44.863542: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211147800 of size 256
2018-03-13 21:59:44.863546: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211147900 of size 256
2018-03-13 21:59:44.863553: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211147a00 of size 256
2018-03-13 21:59:44.863557: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211147b00 of size 256
2018-03-13 21:59:44.863562: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211147c00 of size 256
2018-03-13 21:59:44.863567: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211147d00 of size 256
2018-03-13 21:59:44.863573: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211147e00 of size 256
2018-03-13 21:59:44.863578: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211147f00 of size 256
2018-03-13 21:59:44.863584: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211148000 of size 256
2018-03-13 21:59:44.863588: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211148100 of size 256
2018-03-13 21:59:44.863594: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211148200 of size 256
2018-03-13 21:59:44.863600: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211148300 of size 256
2018-03-13 21:59:44.863607: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211148400 of size 256
2018-03-13 21:59:44.863615: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211148500 of size 256
2018-03-13 21:59:44.863622: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211148600 of size 256
2018-03-13 21:59:44.863627: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211148700 of size 256
2018-03-13 21:59:44.863633: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211148800 of size 256
2018-03-13 21:59:44.863638: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211148900 of size 256
2018-03-13 21:59:44.863643: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211148a00 of size 256
2018-03-13 21:59:44.863649: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211148b00 of size 256
2018-03-13 21:59:44.863653: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211148c00 of size 256
2018-03-13 21:59:44.863659: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211148d00 of size 256
2018-03-13 21:59:44.863664: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211148e00 of size 256
2018-03-13 21:59:44.863670: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211148f00 of size 256
2018-03-13 21:59:44.863675: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211149000 of size 256
2018-03-13 21:59:44.863681: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211149100 of size 256
2018-03-13 21:59:44.863686: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211149200 of size 256
2018-03-13 21:59:44.863691: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211149300 of size 256
2018-03-13 21:59:44.863697: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211149400 of size 256
2018-03-13 21:59:44.863702: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211149500 of size 256
2018-03-13 21:59:44.863706: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211149600 of size 256
2018-03-13 21:59:44.863712: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211149700 of size 256
2018-03-13 21:59:44.863718: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211149800 of size 256
2018-03-13 21:59:44.863723: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211149900 of size 256
2018-03-13 21:59:44.863728: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211149a00 of size 256
2018-03-13 21:59:44.863734: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211149b00 of size 256
2018-03-13 21:59:44.863740: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211149c00 of size 256
2018-03-13 21:59:44.863744: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211149d00 of size 256
2018-03-13 21:59:44.863750: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211149e00 of size 256
2018-03-13 21:59:44.863755: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10211149f00 of size 256
2018-03-13 21:59:44.863761: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021114a000 of size 256
2018-03-13 21:59:44.863766: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021114a100 of size 256
2018-03-13 21:59:44.863771: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021114a200 of size 256
2018-03-13 21:59:44.863777: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021114a300 of size 256
2018-03-13 21:59:44.863782: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021114a400 of size 256
2018-03-13 21:59:44.863788: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021114a500 of size 10910600704
2018-03-13 21:59:44.863796: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x1020f3df200 of size 1024
2018-03-13 21:59:44.863802: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x1020f402500 of size 3584
2018-03-13 21:59:44.863807: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x1020f425e00 of size 1024
2018-03-13 21:59:44.863813: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x1020f4cc200 of size 2048
2018-03-13 21:59:44.863819: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x1020f7c7e00 of size 1280
2018-03-13 21:59:44.863825: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x1020f7d4700 of size 1280
2018-03-13 21:59:44.863830: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x1020f7ffa00 of size 15616
2018-03-13 21:59:44.863835: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x1020f816300 of size 15360
2018-03-13 21:59:44.863841: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x1020f83f700 of size 30720
2018-03-13 21:59:44.863847: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x1020fb7ef00 of size 30720
2018-03-13 21:59:44.863853: I tensorflow/core/common_runtime/bfc_allocator.cc:676]      Summary of in-use Chunks by size: 
2018-03-13 21:59:44.863862: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 709 Chunks of size 256 totalling 177.2KiB
2018-03-13 21:59:44.863869: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 58 Chunks of size 512 totalling 29.0KiB
2018-03-13 21:59:44.863875: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 768 totalling 768B
2018-03-13 21:59:44.863881: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 10 Chunks of size 1024 totalling 10.0KiB
2018-03-13 21:59:44.863887: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 3 Chunks of size 1280 totalling 3.8KiB
2018-03-13 21:59:44.863892: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 4 Chunks of size 1792 totalling 7.0KiB
2018-03-13 21:59:44.863898: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 5 Chunks of size 2048 totalling 10.0KiB
2018-03-13 21:59:44.863904: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 2 Chunks of size 2304 totalling 4.5KiB
2018-03-13 21:59:44.863910: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 2560 totalling 2.5KiB
2018-03-13 21:59:44.863915: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 2816 totalling 2.8KiB
2018-03-13 21:59:44.863920: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 3 Chunks of size 3584 totalling 10.5KiB
2018-03-13 21:59:44.863927: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 2 Chunks of size 4096 totalling 8.0KiB
2018-03-13 21:59:44.863932: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 4 Chunks of size 4608 totalling 18.0KiB
2018-03-13 21:59:44.863938: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 5120 totalling 5.0KiB
2018-03-13 21:59:44.863944: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 2 Chunks of size 5376 totalling 10.5KiB
2018-03-13 21:59:44.863950: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 7424 totalling 7.2KiB
2018-03-13 21:59:44.863956: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 312 Chunks of size 7680 totalling 2.29MiB
2018-03-13 21:59:44.863961: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 7936 totalling 7.8KiB
2018-03-13 21:59:44.863967: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 3 Chunks of size 8192 totalling 24.0KiB
2018-03-13 21:59:44.863973: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 4 Chunks of size 9216 totalling 36.0KiB
2018-03-13 21:59:44.863979: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 9984 totalling 9.8KiB
2018-03-13 21:59:44.863985: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 10240 totalling 10.0KiB
2018-03-13 21:59:44.863990: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 11776 totalling 11.5KiB
2018-03-13 21:59:44.863996: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 2 Chunks of size 12288 totalling 24.0KiB
2018-03-13 21:59:44.864003: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 14592 totalling 14.2KiB
2018-03-13 21:59:44.864009: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 2 Chunks of size 15104 totalling 29.5KiB
2018-03-13 21:59:44.864016: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 2 Chunks of size 18432 totalling 36.0KiB
2018-03-13 21:59:44.864022: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 6 Chunks of size 24576 totalling 144.0KiB
2018-03-13 21:59:44.864029: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 12 Chunks of size 30720 totalling 360.0KiB
2018-03-13 21:59:44.864035: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 2 Chunks of size 32768 totalling 64.0KiB
2018-03-13 21:59:44.864041: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 46080 totalling 45.0KiB
2018-03-13 21:59:44.864047: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 2 Chunks of size 49152 totalling 96.0KiB
2018-03-13 21:59:44.864053: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 55552 totalling 54.2KiB
2018-03-13 21:59:44.864058: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 60928 totalling 59.5KiB
2018-03-13 21:59:44.864064: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 4 Chunks of size 65536 totalling 256.0KiB
2018-03-13 21:59:44.864070: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 2 Chunks of size 98304 totalling 192.0KiB
2018-03-13 21:59:44.864076: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 4 Chunks of size 131072 totalling 512.0KiB
2018-03-13 21:59:44.864081: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 8 Chunks of size 184064 totalling 1.40MiB
2018-03-13 21:59:44.864087: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 240128 totalling 234.5KiB
2018-03-13 21:59:44.864094: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 3 Chunks of size 262144 totalling 768.0KiB
2018-03-13 21:59:44.864100: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 6 Chunks of size 430080 totalling 2.46MiB
2018-03-13 21:59:44.864106: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 499712 totalling 488.0KiB
2018-03-13 21:59:44.864111: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 2 Chunks of size 524288 totalling 1.00MiB
2018-03-13 21:59:44.864117: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 532224 totalling 519.8KiB
2018-03-13 21:59:44.864123: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 534016 totalling 521.5KiB
2018-03-13 21:59:44.864129: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 536320 totalling 523.8KiB
2018-03-13 21:59:44.864149: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 7 Chunks of size 536832 totalling 3.58MiB
2018-03-13 21:59:44.864155: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 625664 totalling 611.0KiB
2018-03-13 21:59:44.864163: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 677888 totalling 662.0KiB
2018-03-13 21:59:44.864169: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 3 Chunks of size 736256 totalling 2.11MiB
2018-03-13 21:59:44.864174: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 2 Chunks of size 860160 totalling 1.64MiB
2018-03-13 21:59:44.864180: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 2 Chunks of size 1048576 totalling 2.00MiB
2018-03-13 21:59:44.864186: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 1067520 totalling 1.02MiB
2018-03-13 21:59:44.864192: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 3 Chunks of size 1179648 totalling 3.38MiB
2018-03-13 21:59:44.864198: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 2 Chunks of size 1720320 totalling 3.28MiB
2018-03-13 21:59:44.864203: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 2 Chunks of size 12882432 totalling 24.57MiB
2018-03-13 21:59:44.864209: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 10910600704 totalling 10.16GiB
2018-03-13 21:59:44.864215: I tensorflow/core/common_runtime/bfc_allocator.cc:683] Sum Total of in-use chunks: 10.21GiB
2018-03-13 21:59:44.864228: I tensorflow/core/common_runtime/bfc_allocator.cc:685] Stats: 
Limit:                 10968576820
InUse:                 10968474112
MaxInUse:              10968477952
NumAllocs:                  779120
MaxAllocSize:          10910600704

2018-03-13 21:59:44.864302: W tensorflow/core/common_runtime/bfc_allocator.cc:277] ***************************************************xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
2018-03-13 21:59:44.865043: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
2018-03-13 21:59:44.866899: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.867009: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.867294: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.867331: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.867488: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.867525: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.867646: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.868072: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.868157: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.868303: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.868351: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.868670: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.869464: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.869526: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.869538: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.869852: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.870282: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.870358: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.870575: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.870704: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.870971: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.871354: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.871392: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.871426: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.871736: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.871936: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.872103: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.872924: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.872974: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.875581: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.879603: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.880900: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.880959: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.882434: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.883553: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.883996: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.884396: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.884762: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.884811: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.886082: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.887126: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.887543: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.888555: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.889075: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.890308: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.893012: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.895479: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.897031: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.897207: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.897935: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.898023: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.898068: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.898086: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.898795: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.899419: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.899428: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.899505: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.899899: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.900093: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.900400: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.900661: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.900722: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.900786: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.900812: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.900906: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.900960: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.901567: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.902509: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.902827: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.903117: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.903427: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.903817: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.904486: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.904768: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.905273: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.906383: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.906688: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.907023: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.907185: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.907518: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.908547: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.909451: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.909776: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.909979: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.911313: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.911635: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.911738: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.911775: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.911849: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.911860: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.911893: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.911933: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.912020: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.912103: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.912264: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.912579: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.912669: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.912776: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.913080: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.913158: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.913218: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.913334: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.913411: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.913490: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.913875: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.913895: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.914029: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.914081: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.914315: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.914388: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.914504: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.914577: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.914618: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.914699: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.914702: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.914749: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.914750: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.914958: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
2018-03-13 21:59:44.915987: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.ResourceExhaustedError'>, OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
	 [[Node: FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/gamma/read/_5248 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_13633_FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/gamma/read"", _device=""/job:localhost/replica:0/task:0/device:CPU:0""](FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/gamma/read)]]

Caused by op 'unstack_2', defined at:
  File ""/xxx/xxx/object_detection/train.py"", line 163, in <module>
    tf.app.run()
  File ""/usr/local/python3/lib/python3.5/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""/xxx/xxx/object_detection/train.py"", line 159, in main
    worker_job_name, is_chief, FLAGS.train_dir)
  File ""/xxx/xxx/object_detection/trainer.py"", line 228, in train
    clones = model_deploy.create_clones(deploy_config, model_fn, [input_queue])
  File ""/xxx/xxx/slim/deployment/model_deploy.py"", line 194, in create_clones
    outputs = model_fn(*args, **kwargs)
  File ""/xxx/xxx/object_detection/trainer.py"", line 153, in _create_losses
    train_config.merge_multiple_label_boxes)
  File ""/xxx/xxx/object_detection/trainer.py"", line 112, in get_inputs
    read_data_list = input_queue.dequeue()
  File ""/xxx/xxx/object_detection/core/batcher.py"", line 116, in dequeue
    unbatched_tensor_list = tf.unstack(batched_tensor)
  File ""/usr/local/python3/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py"", line 1027, in unstack
    return gen_array_ops._unpack(value, num=num, axis=axis, name=name)
  File ""/usr/local/python3/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 5868, in _unpack
    ""Unpack"", value=value, num=num, axis=axis, name=name)
  File ""/usr/local/python3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/usr/local/python3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 2956, in create_op
    op_def=op_def)
  File ""/usr/local/python3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1470, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
	 [[Node: FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/gamma/read/_5248 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_13633_FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/gamma/read"", _device=""/job:localhost/replica:0/task:0/device:CPU:0""](FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/gamma/read)]]

Traceback (most recent call last):
  File ""/usr/local/python3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1323, in _do_call
    return fn(*args)
  File ""/usr/local/python3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1302, in _run_fn
    status, run_metadata)
  File ""/usr/local/python3/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py"", line 473, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
	 [[Node: FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/gamma/read/_5248 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_13633_FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/gamma/read"", _device=""/job:localhost/replica:0/task:0/device:CPU:0""](FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/gamma/read)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/xxx/xxx/object_detection/train.py"", line 163, in <module>
    tf.app.run()
  File ""/usr/local/python3/lib/python3.5/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""/xxx/xxx/object_detection/train.py"", line 159, in main
    worker_job_name, is_chief, FLAGS.train_dir)
  File ""/xxx/xxx/object_detection/trainer.py"", line 332, in train
    saver=saver)
  File ""/usr/local/python3/lib/python3.5/site-packages/tensorflow/contrib/slim/python/slim/learning.py"", line 763, in train
    sess, train_op, global_step, train_step_kwargs)
  File ""/usr/local/python3/lib/python3.5/site-packages/tensorflow/contrib/slim/python/slim/learning.py"", line 487, in train_step
    run_metadata=run_metadata)
  File ""/usr/local/python3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 889, in run
    run_metadata_ptr)
  File ""/usr/local/python3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1120, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/usr/local/python3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1317, in _do_run
    options, run_metadata)
  File ""/usr/local/python3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1336, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
	 [[Node: FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/gamma/read/_5248 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_13633_FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/gamma/read"", _device=""/job:localhost/replica:0/task:0/device:CPU:0""](FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/gamma/read)]]

Caused by op 'unstack_2', defined at:
  File ""/xxx/xxx/object_detection/train.py"", line 163, in <module>
    tf.app.run()
  File ""/usr/local/python3/lib/python3.5/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""/xxx/xxx/object_detection/train.py"", line 159, in main
    worker_job_name, is_chief, FLAGS.train_dir)
  File ""/xxx/xxx/object_detection/trainer.py"", line 228, in train
    clones = model_deploy.create_clones(deploy_config, model_fn, [input_queue])
  File ""/xxx/xxx/slim/deployment/model_deploy.py"", line 194, in create_clones
    outputs = model_fn(*args, **kwargs)
  File ""/xxx/xxx/object_detection/trainer.py"", line 153, in _create_losses
    train_config.merge_multiple_label_boxes)
  File ""/xxx/xxx/object_detection/trainer.py"", line 112, in get_inputs
    read_data_list = input_queue.dequeue()
  File ""/xxx/xxx/object_detection/core/batcher.py"", line 116, in dequeue
    unbatched_tensor_list = tf.unstack(batched_tensor)
  File ""/usr/local/python3/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py"", line 1027, in unstack
    return gen_array_ops._unpack(value, num=num, axis=axis, name=name)
  File ""/usr/local/python3/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 5868, in _unpack
    ""Unpack"", value=value, num=num, axis=axis, name=name)
  File ""/usr/local/python3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/usr/local/python3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 2956, in create_op
    op_def=op_def)
  File ""/usr/local/python3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1470, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[1,5095,3729,3]
	 [[Node: unstack_2 = Unpack[T=DT_FLOAT, axis=0, num=24, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefetch_queue_Dequeue/_3249)]]
	 [[Node: FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/gamma/read/_5248 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_13633_FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/gamma/read"", _device=""/job:localhost/replica:0/task:0/device:CPU:0""](FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/gamma/read)]]


Process finished with exit code 1
`"
17666,iOS: Library that made for a specific model doesn't include all needed operators (RandomStandardNormal is missing),"I created a quantized PB file, here is its detail:
![screenshot from 2018-03-13 08-14-27](https://user-images.githubusercontent.com/11812805/37319105-56c7618e-26a0-11e8-9bc9-cdc696c5267f.png)

Then I followed the instruction [here](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile) to create the iOS library for that model only. The command I used:
`tensorflow/contrib/makefile/build_all_ios.sh -g mobile_quantized.pb`

Here is the generated ops_to_register.h file:

```
// This file was autogenerated by print_selective_registration_header.py
#ifndef OPS_TO_REGISTER
#define OPS_TO_REGISTER

    namespace {
      constexpr const char* skip(const char* x) {
        return (*x) ? (*x == ' ' ? skip(x + 1) : x) : x;
      }

      constexpr bool isequal(const char* x, const char* y) {
        return (*skip(x) && *skip(y))
                   ? (*skip(x) == *skip(y) && isequal(skip(x) + 1, skip(y) + 1))
                   : (!*skip(x) && !*skip(y));
      }

      template<int N>
      struct find_in {
        static constexpr bool f(const char* x, const char* const y[N]) {
          return isequal(x, y[0]) || find_in<N - 1>::f(x, y + 1);
        }
      };

      template<>
      struct find_in<0> {
        static constexpr bool f(const char* x, const char* const y[]) {
          return false;
        }
      };
    }  // end namespace
    constexpr const char* kNecessaryOpKernelClasses[] = {
""BinaryOp< CPUDevice, functor::add<float>>"",
""BinaryOp< CPUDevice, functor::add<int32>>"",
""BiasOp<CPUDevice, float>"",
""ConstantOp"",
""DequantizeOp<CPUDevice, quint8>"",
""EnterOp"",
""ExitOp"",
""UnaryOp< CPUDevice, functor::exp<float>>"",
""ExpandDimsOp<int32>"",
""BinaryOp< CPUDevice, functor::greater_equal<float>>"",
""IdentityOp"",
""BinaryOp< CPUDevice, functor::less<int32>>"",
""LoopCondOp"",
""MatMulOp<CPUDevice, float, false >"",
""BinaryOp< CPUDevice, functor::maximum<float>>"",
""ReductionOp<CPUDevice, float, int32, Eigen::internal::MeanReducer<float>>"",
""MergeOp"",
""BinaryOp< CPUDevice, functor::minimum<float>>"",
""BinaryOp< CPUDevice, functor::mul<float>>"",
""NextIterationOp"",
""NoOp"",
""PlaceholderOp"",
""PhiloxRandomOp<CPUDevice, random::NormalDistribution<random::PhiloxRandom, float>>"",
""RangeOp<::tensorflow::int32>"",
""BinaryOp< CPUDevice, functor::div<float>>"",
""ReshapeOp"",
""ShapeOp<int32>"",
""UnaryOp< CPUDevice, functor::sigmoid<float>>"",
""UnaryOp< CPUDevice, functor::square<float>>"",
""StridedSliceOp<CPUDevice, ::tensorflow::int32>"",
""StridedSliceOp<CPUDevice, float>"",
""BinaryOp< CPUDevice, functor::sub<float>>"",
""BinaryOp< CPUDevice, functor::sub<int32>>"",
""ReductionOp<CPUDevice, float, int32, Eigen::internal::SumReducer<float>>"",
""SwitchOp"",
""UnaryOp< CPUDevice, functor::tanh<float>>"",
""TensorArrayPackOrGatherOp<CPUDevice, float, false >"",
""TensorArrayReadOp<CPUDevice, float>"",
""TensorArrayUnpackOrScatterOp<CPUDevice, float, false >"",
""TensorArraySizeOp"",
""TensorArrayOp"",
""TensorArrayWriteOp<CPUDevice, float>"",
""TileOp<CPUDevice, int32>"",
""TransposeCpuOp"",
""ZerosLikeOp< CPUDevice, float>"",
""RecvOp"",
""SendOp"",
};
#define SHOULD_REGISTER_OP_KERNEL(clz) (find_in<sizeof(kNecessaryOpKernelClasses) / sizeof(*kNecessaryOpKernelClasses)>::f(clz, kNecessaryOpKernelClasses))

constexpr inline bool ShouldRegisterOp(const char op[]) {
  return false
     || isequal(op, ""Add"")
     || isequal(op, ""BiasAdd"")
     || isequal(op, ""Const"")
     || isequal(op, ""Dequantize"")
     || isequal(op, ""Enter"")
     || isequal(op, ""Exit"")
     || isequal(op, ""Exp"")
     || isequal(op, ""ExpandDims"")
     || isequal(op, ""GreaterEqual"")
     || isequal(op, ""Identity"")
     || isequal(op, ""Less"")
     || isequal(op, ""LoopCond"")
     || isequal(op, ""MatMul"")
     || isequal(op, ""Maximum"")
     || isequal(op, ""Mean"")
     || isequal(op, ""Merge"")
     || isequal(op, ""Minimum"")
     || isequal(op, ""Mul"")
     || isequal(op, ""NextIteration"")
     || isequal(op, ""NoOp"")
     || isequal(op, ""Placeholder"")
     || isequal(op, ""RandomStandardNormal"")
     || isequal(op, ""Range"")
     || isequal(op, ""RealDiv"")
     || isequal(op, ""Reshape"")
     || isequal(op, ""Shape"")
     || isequal(op, ""Sigmoid"")
     || isequal(op, ""Square"")
     || isequal(op, ""StridedSlice"")
     || isequal(op, ""Sub"")
     || isequal(op, ""Sum"")
     || isequal(op, ""Switch"")
     || isequal(op, ""Tanh"")
     || isequal(op, ""TensorArrayGatherV3"")
     || isequal(op, ""TensorArrayReadV3"")
     || isequal(op, ""TensorArrayScatterV3"")
     || isequal(op, ""TensorArraySizeV3"")
     || isequal(op, ""TensorArrayV3"")
     || isequal(op, ""TensorArrayWriteV3"")
     || isequal(op, ""Tile"")
     || isequal(op, ""Transpose"")
     || isequal(op, ""ZerosLike"")
     || isequal(op, ""_Recv"")
     || isequal(op, ""_Send"")
  ;
}
#define SHOULD_REGISTER_OP(op) ShouldRegisterOp(op)

#define SHOULD_REGISTER_OP_GRADIENT false
#endif
```

But when I tried it within my project, it couldn't load the mobile_quantized.pb file and thrown this

<img width=""745"" alt=""screen shot 2018-03-13 at 9 44 18 am"" src=""https://user-images.githubusercontent.com/11812805/37319803-2d88f064-26a3-11e8-974b-a57a43792055.png"">

It's strange because I saw `""PhiloxRandomOp<CPUDevice, random::NormalDistribution<random::PhiloxRandom, float>>""` and `|| isequal(op, ""RandomStandardNormal"")` in the generated header file.

---------
OS Platform and Distribution: MacOS 10.13.3
TensorFlow installed from: Source code
TensorFlow version: 1.6.0
Bazel version: 0.11.1-homebrew
CUDA/cuDNN version: None
GPU model and memory: None
Exact command to reproduce: Described above"
17663,tf.matrix_solve_ls: Documentation corrupt?,"Hi,
I just found tf.matrix_solve_ls and read its documentation at https://www.tensorflow.org/api_docs/python/tf/matrix_solve_ls :
![grafik](https://user-images.githubusercontent.com/1200058/37315800-cbf13e16-265b-11e8-9ead-727fd6d95c7d.png)
Seems like there are some markdown errors...

Have I written custom code: No
OS Platform and Distribution: N/A
TensorFlow installed from: N/A
TensorFlow version: N/A
Bazel version: N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A
Exact command to reproduce: N/A"
17662,tfdbg: Feature Request: enable and disable during run,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux XX 3.10.0-514.6.1.el7.x86_64 #1 SMP Sat Dec 10 11:15:38 EST 2016 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""7 (Core)""
VERSION_ID=""7""
CENTOS_MANTISBT_PROJECT_VERSION=""7""
REDHAT_SUPPORT_PRODUCT_VERSION=""7""
- **TensorFlow installed from (source or binary)**:
Binary
- **TensorFlow version (use command below)**:
1.4.0
- **Python version**: 
3.5.2
- **Bazel version**:
N/A
- **CUDA/cuDNN version**:
CUDA 8.0
- **GPU model and memory**:
P100, 16G
- **Exact command to reproduce**:
N/A

### Describe the problem
I would like to enable and disable tfdbg while running my python code.  At the moment, every time a <code>sess.run()</code> is encountered I get to the <code>tfdbg></code> prompt.

I am able to run tfdbg by wrapping my session:

    sess = tf_debug.LocalCLIDebugWrapperSession(sess)

This works fine.  However, I'm performing an optimization.  I'd like to, on occasion, enter tfdbg.  But mostly, I don't want to.  It appears like its an either/or proposition at the moment.  I could work-around but would rather have a way to stop or start.  An implementation detail is that I've captured \<ctrl\>-C which allows me to make changes to the running optimization.  There I would enable or disable tfdbg such that the next time a sess.run() is hit, tfdbg works as requested.

I apologize in advance if there is already a way to do this.  I couldn't find it if its there.
"
17654,"2D tf.nn.convolution() output is inconsistent between inputs 1x1 and 2x2 with kernel=3x3, strides=2, padding='SAME'.","Output of Keras `Conv2D()`, which is a passthrough to `tf.nn.convolution()`, is inconsistent between inputs 1x1 and 2x2 with kernel=3x3, strides=2, padding='SAME'.

The following code with 2x2 input produces wrong output `8.`, which is inconsistent with correct output `4.` if the input is 1x1. 
```
import numpy as np
from keras.layers import Conv2D
from keras.models import Sequential

w = np.arange(3*3*1*1).reshape(3, 3, 1, 1)

model = Sequential()
model.add(Conv2D(1, kernel_size=3, strides=2, input_shape=(2, 2, 1),
                 padding='SAME', use_bias=False))
model.set_weights([w])
print(model.predict(np.ones((1, 2, 2, 1))))
```"
17653,Tensorflow distributed training: CPU usage difference,"Hi,
Good day. I have a question that I hope someone could help. 
Please forgive my grammar errors and missing words.

I have tried to combine the Cifar10 training examples 
https://github.com/tensorflow/models/tree/master/tutorials/image/cifar10
and  example in Distributed TensorFlow website:
https://www.tensorflow.org/deploy/distributed
to do the cifar10 distributed training. 
I am a little bit confused on the tf.train.MonitoredTrainingSession implementation. 
Servers are ok to communicate with each other. 

### System information
- Linux Ubuntu 16.04:
- Python3
- CPU
### Describe the problem
I used two servers, each of them are used as 1 PS and 1 Worker and no other programs. So total 2 PS and 2 Workers are trained in this experiment. What I expected is 2 Workers have the same CPU percentage usage when the training is going on. But I found that only one of the server ( with PS 1 and Worker 1) was running with 100% CPU usage, the other server( with PS 2 and Worker 2) only used 3% CPU. 
### Source code / logs
The commands I used are
python3 cifar10_train.py --ps_hosts=Server IP1:2222,Server IP2:2222 --worker_hosts=Server IP1:2223,Server IP2:2000 --job_name=ps --task_index=0

python3 cifar10_train.py --ps_hosts=Server IP1:2222,Server IP2:2222 --worker_hosts=Server IP1:2223,Server IP2:2000 --job_name=ps --task_index=1

python3 cifar10_train.py --ps_hosts=Server IP1:2222,Server IP2:2222 --worker_hosts=Server IP1:2223,Server IP2:2000 --job_name=worker --task_index=0

python3 cifar10_train.py --ps_hosts=Server IP1:2222,Server IP2:2222 --worker_hosts=Server IP1:2223,Server IP2:2000 --job_name=worker --task_index=1

 The f.train.MonitoredTrainingSession is set as:
      with tf.train.MonitoredTrainingSession(master=server.target,
                                               is_chief=(FLAGS.task_index == 0),
                                               checkpoint_dir=""/tmp/train_logs"",
                                               hooks=hooks) as mon_sess:
          while not mon_sess.should_stop():
            mon_sess.run(train_op)"
17650,Allow tf.estimator.train_and_evaluate evaluation frequency in steps,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**:  `v1.6.0-0-gd2e24b6039 1.6.0`
- **Python version**: Python 3.5.2
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: 9.0/7.0
- **GPU model and memory**: GTX 1080/1080Ti, P100
- **Exact command to reproduce**: N/A

### Describe the problem
We're using `tf.estimator.train_and_evaluate` for running our training, but we're running into an issue with getting it to run evaluation at the correct frequency. Because the training input pipeline is fully reset after evaluation, we're attempting to follow the docs recommendation of running evaluation after an epoch or two. 

This is a problem for us because we can only figure out how to set the evaluation frequency using `tf.estimator.EvalSpec.throttle_secs`, which runs evaluation every `throttle_secs` seconds (since our evaluation takes less time than `throttle_secs`).  We run on a few different hardware platforms and configurations that all alter the training speed, so the only way to ensure that we perform evaluation after finishing an epoch is to calculate a value for `throttle_secs` that incorporates that training's training speed. This is obviously suboptimal compared to setting the evaluation frequency in steps rather than seconds.

Here are the approaches to solving this problem that I've been able to find after a little poking around:

1. Prevent evaluations triggered by `throttle_secs` passing from saving a new checkpoint, and only run if there is a new checkpoint. This lets the user specify `tf.estimator.RunConfig.save_checkpoints_steps` to set the evaluation frequency. This is actually how I thought `throttle_secs` worked based on my reading of the documentation
2. Allow the user to set `throttle_steps` as a part of the `EvalSpec`. This value would could be used by the `SecondOrStepTimer` to run the evaluation based on how many steps have elapsed instead of seconds.


I'd be willing to submit a PR with either fix, but I'm not sure which one would be correct/best, so I'd appreciate any feedback or alternate solutions :smile: "
17648,"when i add hard_example_miner to faster_rcnn config,i face resource exhaust problem","Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
17647,How can I gdb tfcompile by using bazel build?,"tfcompile is a binary file to compile an inference graph into executable code for tensorflow XLA which created by bazel build.
If I want to gdb tfcompile file on ubuntu 16.04,  it will return message 

    Reading symbols from /PWD/tfcompile...(no debugging symbols found)...done.

It seem that should make bazel compile with something flag like -g?
I have tried to use 
   
    bazel build XXX --compilation_mode=dbg

but there seems not change anything.

How can I resolve this question?

by the way , I'm working on Ubuntu 16.04, bazel version 0.8.1 tensorflow r1.0

Thanks for any help!"
17645,r1.6 broken link to nasm package in workspace.bzl,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: 1.6.0
- **Python version**: 2.7/3.5
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: 9.0/7
- **GPU model and memory**: NVidia GeForce 1060 6GB
- **Exact command to reproduce**: 

```
bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package 
```

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I had an issue when trying to build due to the broken nasm link in `tensorflow/workspace.bzl`.

I was trying to build tensorflow from source (Ubuntu 16.04, x64). I checked out r1.6.  I am following all of the instructions in the install guide. Everything  seems to work fine. Once bazel is installed and I run the build command and I receive a error 

```
no such package '@nasm//': java.io.IOException: Error downloading [https://mirror.bazel.build/www.nasm.us/pub/nasm/releasebuilds/2.12.02/nasm-2.12.02.tar.bz2, http://pkgs.fedoraproject.org/repo/pkgs/nasm/nasm-2.12.02.tar.bz2/d15843c3fb7db39af80571ee27ec6fad/nasm-2.12.02.tar.bz2]
```

The build is unable to continue at this point. I've run it multiple  times, all with the same error. I've found that this is because there is  only one working mirror link for the nasm package inside of the bazel  config.

I can confirm that link [http://pkgs.fedoraproject.org/repo/pkgs/nasm/nasm-2.12.02.tar.bz2/d15843c3fb7db39af80571ee27ec6fad/nasm-2.12.02.tar.bz2](http://pkgs.fedoraproject.org/repo/pkgs/nasm/nasm-2.12.02.tar.bz2/d15843c3fb7db39af80571ee27ec6fad/nasm-2.12.02.tar.bz2) is dead (403 response). Adding another mirror such as ""[http://www.nasm.us/pub/nasm/releasebuilds/2.12.02/nasm-2.12.02.tar.bz2](http://www.nasm.us/pub/nasm/releasebuilds/2.12.02/nasm-2.12.02.tar.bz2)""  to `tensorflow/workspace.bzl` allowed the build to continue This is all done on the r1.6 branch

Note this is a duplicate of #16862 

In order to repro just try to build tensorflow from source using the instructions at [https://www.tensorflow.org/install/install_sources](https://www.tensorflow.org/install/install_sources) while working on the r1.6 branch. 

--


### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
17644,The value changes incorrectly after assignment using tf.assign,"**System information**
Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
TensorFlow installed from (source or binary): Binary
TensorFlow version (use command below): 1.4.0
Python version: Python 2.7.12
Bazel version (if compiling from source): N/A
GCC/Compiler version (if compiling from source): N/A
CUDA/cuDNN version: 8.0/6.0
GPU model and memory: GTX 960, 2G
Exact command to reproduce: N/A

**ISSUE**
data = load(""new.mat"")
print data
tf.assign(old, data)
print old

But：    old!=data
Ex. 0.081345705——>0.081345707
"
17643,Failed to import the TensorFlow module,"I tried to install TensorFlow (CPU only) on windows 10 and python 3.6 (64 bit) and after write
import tensorflow as tf
{ hello = tf.constant('Hello, TensorFlow!')
sess = tf.Session()
print(sess.run(hello)) }
on visual studio 2017 I got this

Traceback (most recent call last):
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    return importlib.import_module(mname)
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 994, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 971, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 955, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 658, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 571, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 922, in create_module
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 21, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""E:\PythonApplication3\PythonApplication3\PythonApplication3.py"", line 228, in <module>
    import tensorflow as tf
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\lib\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    return importlib.import_module(mname)
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 994, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 971, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 955, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 658, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 571, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 922, in create_module
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 21, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
 
 ,I used this script 
https://gist.github.com/mrry/ee5dbcfdd045fa48a27d56664411d41c  to know the proplem
and I got this
ERROR: Failed to import the TensorFlow module.
=============================================
Since TensorFlow 1.4, the self-check has been integrated with TensorFlow itself,
and any missing DLLs will be reported when you execute the `import tensorflow`
statement. The error messages printed below refer to TensorFlow 1.3 and earlier,
and are inaccurate for later versions of TensorFlow.

- Python version is 3.6.

- TensorFlow is installed at: C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\lib\site-packages\tensorflow

- Could not load 'cudart64_80.dll'. The GPU version of TensorFlow
  requires that this DLL be installed in a directory that is named in
  your %PATH% environment variable. Download and install CUDA 8.0 from
  this URL: https://developer.nvidia.com/cuda-toolkit

- Could not load 'nvcuda.dll'. The GPU version of TensorFlow requires that
  this DLL be installed in a directory that is named in your %PATH%
  environment variable. Typically it is installed in 'C:\Windows\System32'.
  If it is not present, ensure that you have a CUDA-capable GPU with the
  correct driver installed.

- Could not find cuDNN 6.

  The GPU version of TensorFlow requires that the correct cuDNN DLL be installed
  in a directory that is named in your %PATH% environment variable. Note that
  installing cuDNN is a separate step from installing CUDA, and it is often
  found in a different directory from the CUDA DLLs. The correct version of
  cuDNN depends on your version of TensorFlow:

  * TensorFlow 1.2.1 or earlier requires cuDNN 5.1. ('cudnn64_5.dll')
  * TensorFlow 1.3 or later requires cuDNN 6. ('cudnn64_6.dll')

  You may install the necessary DLL by downloading cuDNN from this URL:
  https://developer.nvidia.com/cudnn
"
17641,Feature request: tf.as_dtype(float) should work just as tf.as_dtype('float'),"In NumPy, `np.dtype(float)` works just the same as `np.dtype(""float"")`.

In TensorFlow `tf.as_dtype(""float"")` works but `tf.as_dtype(float)` crashes with `TypeError: Cannot convert value <class 'float'> to a TensorFlow DType.`.

Is there a particular reason for this behaviour or was it just overlooked?

(same error for other builtins such as `int` and `complex`)"
17639,How can we define different rate for different layer?,"Is there any API or operator supports to  define different rate for different layer like caffe?
"
17635,tensorflow lite build error ,"**System information**
Have I written custom code (as opposed to using a stock example script provided in TensorFlow):No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu16.04
TensorFlow installed from (source or binary):source
TensorFlow version (use command below): last master
Python version: Python 2.7
Bazel version (if compiling from source): bazel 0.11.1
GCC/Compiler version (if compiling from source): N/A
CUDA/cuDNN version: N/A
GPU model and memory: No GPU model
**Describe the problem**
I try to build tensorflow lite demo.
Here is my WORKSPACE:
android_sdk_repository(
    name = ""androidsdk"",
    api_level = 24,
    # Ensure that you have the build_tools_version below installed in the
    # SDK manager as it updates periodically.
    build_tools_version = ""26.0.2"",
    # Replace with path to Android SDK on your system
    path = ""/home/lucas/Android/Sdk"",
)

android_ndk_repository(
    name=""androidndk"",
    path=""/home/lucas/android/android-ndk-r14b"",
    # This needs to be 14 or higher to compile TensorFlow.
    # Please specify API level to >= 21 to build for 64-bit
    # archtectures or the Android NDK will automatically select biggest
    # API level that it supports without notice.
    # Note that the NDK version is not the API level.
    api_level=14)
 Build the demo app:
 bazel build --cxxopt=--std=c++11 //tensorflow/contrib/lite/java/demo/app/src/main:TfLiteCameraDemo

lucas@lucas:~/github/tensorflow$ bazel build --cxxopt=--std=c++11 //tensorflow/contrib/lite/java/demo/app/src/main:TfLiteCameraDemo
WARNING: /home/lucas/.cache/bazel/_bazel_lucas/41d00bd91f3cd94eb33af93ba59b3c39/external/protobuf_archive/WORKSPACE:1: Workspace name in /home/lucas/.cache/bazel/_bazel_lucas/41d00bd91f3cd94eb33af93ba59b3c39/external/protobuf_archive/WORKSPACE (@com_google_protobuf) does not match the name given in the repository's definition (@protobuf_archive); this will cause a build error in future versions
INFO: Analysed target //tensorflow/contrib/lite/java/demo/app/src/main:TfLiteCameraDemo (0 packages loaded).
INFO: Found 1 target...
ERROR: /home/lucas/github/tensorflow/tensorflow/contrib/lite/kernels/internal/BUILD:268:1: C++ compilation of rule '//tensorflow/contrib/lite/kernels/internal:portable_tensor_utils' failed (Exit 1)
src/main/tools/process-wrapper-legacy.cc:58: ""execvp(external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/bin/clang, ...)"": No such file or directory
Target //tensorflow/contrib/lite/java/demo/app/src/main:TfLiteCameraDemo failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 0.644s, Critical Path: 0.04s
FAILED: Build did NOT complete successfully

How to fix this error?
thx.


"
17634,error importing tensorflow after install,"**System information**
**Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:No
**OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 7 64bit service pack 1
**TensorFlow installed from (source or binary)**:source
**TensorFlow version (use command below)**: 1.6
**Python version**: Python 3.5.2
**Bazel version (if compiling from source)**: N/A
**GCC/Compiler version (if compiling from source)**: N/A
**CUDA/cuDNN version**: N/A
**GPU model and memory**: No GPU model
**Exact command to reproduce**:import tensor flow

**Describe the problem**
I'm getting the following error when importing tensorflow after following the pip install directions here [](https://www.tensorflow.org/install/install_windows) . When I try to verify the installation, I receive the following error when I try to import tensorflow. Thanks for the help.

> Traceback (most recent call last):
>   File ""C:\Users\Nhan\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
>     return importlib.import_module(mname)
>   File ""C:\Users\Nhan\AppData\Local\Programs\Python\Python35\lib\importlib\__init__.py"", line 126, in import_module
>     return _bootstrap._gcd_import(name[level:], package, level)
>   File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import
>   File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load
>   File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked
>   File ""<frozen importlib._bootstrap>"", line 666, in _load_unlocked
>   File ""<frozen importlib._bootstrap>"", line 577, in module_from_spec
>   File ""<frozen importlib._bootstrap_external>"", line 906, in create_module
>   File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed
> ImportError: DLL load failed with error code -1073741795
> 
> During handling of the above exception, another exception occurred:
> 
> Traceback (most recent call last):
>   File ""C:\Users\Nhan\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
>     from tensorflow.python.pywrap_tensorflow_internal import *
>   File ""C:\Users\Nhan\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 21, in <module>
>     _pywrap_tensorflow_internal = swig_import_helper()
>   File ""C:\Users\Nhan\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
>     return importlib.import_module('_pywrap_tensorflow_internal')
>   File ""C:\Users\Nhan\AppData\Local\Programs\Python\Python35\lib\importlib\__init__.py"", line 126, in import_module
>     return _bootstrap._gcd_import(name[level:], package, level)
> ImportError: No module named '_pywrap_tensorflow_internal'
> 
> During handling of the above exception, another exception occurred:
> 
> Traceback (most recent call last):
>   File ""<pyshell#0>"", line 1, in <module>
>     import tensorflow
>   File ""C:\Users\Nhan\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
>     from tensorflow.python import *
>   File ""C:\Users\Nhan\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
>     from tensorflow.python import pywrap_tensorflow
>   File ""C:\Users\Nhan\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 74, in <module>
>     raise ImportError(msg)
> ImportError: Traceback (most recent call last):
>   File ""C:\Users\Nhan\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
>     return importlib.import_module(mname)
>   File ""C:\Users\Nhan\AppData\Local\Programs\Python\Python35\lib\importlib\__init__.py"", line 126, in import_module
>     return _bootstrap._gcd_import(name[level:], package, level)
>   File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import
>   File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load
>   File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked
>   File ""<frozen importlib._bootstrap>"", line 666, in _load_unlocked
>   File ""<frozen importlib._bootstrap>"", line 577, in module_from_spec
>   File ""<frozen importlib._bootstrap_external>"", line 906, in create_module
>   File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed
> ImportError: DLL load failed with error code -1073741795
> 
> During handling of the above exception, another exception occurred:
> 
> Traceback (most recent call last):
>   File ""C:\Users\Nhan\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
>     from tensorflow.python.pywrap_tensorflow_internal import *
>   File ""C:\Users\Nhan\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 21, in <module>
>     _pywrap_tensorflow_internal = swig_import_helper()
>   File ""C:\Users\Nhan\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
>     return importlib.import_module('_pywrap_tensorflow_internal')
>   File ""C:\Users\Nhan\AppData\Local\Programs\Python\Python35\lib\importlib\__init__.py"", line 126, in import_module
>     return _bootstrap._gcd_import(name[level:], package, level)
> ImportError: No module named '_pywrap_tensorflow_internal'
> 
> 
> Failed to load the native TensorFlow runtime.
> 
> See https://www.tensorflow.org/install/install_sources#common_installation_problems
> 
> for some common reasons and solutions.  Include the entire stack trace
> above this error message when asking for help.

Thanks for the help."
17633,Keras plot_model() giving error 'Model' object has no attribute '_container_nodes',"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
     TensorFlow Keras code
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
     Windows 10
- **TensorFlow installed from (source or binary)**:
     Binary
- **TensorFlow version (use command below)**:
     1.6, Keras version: 2.1.3-tf
- **Python version**: 
     3.5
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
     9/7
- **GPU model and memory**:
       GeForce 860M
- **Exact command to reproduce**:
     plot_model(model1, to_file='model1.png')
You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
 I am getting the following error with the  Keras plot_model()  command. 
'Model' object has no attribute '_container_nodes'
This error was first reported in #14542 and fixed in #14553. But it seems to have not carried over.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

```
input_X1 = Input(shape=(32,))
y1 = Dense(units=64, activation='relu')(input_X1)
y1 = Dense(units=32, activation='relu')(y1)
prediction1 = Dense(units=1, activation='relu',name='prediction_2')(y1) #
model1 = Model(inputs=input_X1,outputs=prediction1,name='model1')
plot_model(model1, to_file='mobilenet1.png')
```"
17632,got Nan when powered float32 tensors,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **Windows 10 Pro**
- **TensorFlow installed from (prebuild version here https://github.com/fo40225/tensorflow-windows-wheel  with avx2)**
- **TensorFlow version 1.6.0**
- **Python version 3.6.4**:
- **Bazel version (if compiling from source)**
- **GCC/Compiler version (if compiling from source)**
- **CUDA 9.1.85/cuDNN 1.7.1 version**
- **GPU Nvidia MX150 2GB**
- **Exact command to reproduce**:

### Describe the problem
On my setup tensorflow get nan when I powered tensors with float32 type, but with float64 it's ok.

But if just product tensors by itself in float32 it's ok too.

### Source code / logs

## Scenario 1
```
X = tf.placeholder('float32')

x = np.linspace(-3, 3)

s = tf.Session()

X_pow2 = tf.pow(X, 2)
X_pow3 = tf.pow(X, 3)
X_prod = X*X

print('X_pow2 =', X_pow2.eval({X:x}, session=s), '\n')
print('X_pow3 =', X_pow3.eval({X:x},session=s),'\n')
print('X_prod =', X_prod.eval({X:x},session=s),'\n')
```

I get this 

```
X_pow2 = [          nan           nan           nan           nan           nan
           nan           nan           nan           nan           nan
           nan           nan           nan           nan           nan
           nan           nan           nan           nan           nan
           nan           nan           nan           nan           nan
 3.7484397e-03 3.3735953e-02 9.3710966e-02 1.8367349e-01 3.0362350e-01
 4.5356098e-01 6.3348603e-01 8.4339863e-01 1.0832988e+00 1.3531864e+00
 1.6530614e+00 1.9829239e+00 2.3427739e+00 2.7326119e+00 3.1524367e+00
 3.6022491e+00 4.0820494e+00 4.5918374e+00 5.1316123e+00 5.7013750e+00
 6.3011241e+00 6.9308624e+00 7.5905871e+00 8.2803001e+00 9.0000000e+00] 

X_pow3 = [          nan           nan           nan           nan           nan
           nan           nan           nan           nan           nan
           nan           nan           nan           nan           nan
           nan           nan           nan           nan           nan
           nan           nan           nan           nan           nan
 2.2949636e-04 6.1964002e-03 2.8687032e-02 7.8717217e-02 1.6730276e-01
 3.0545944e-01 5.0420320e-01 7.7454978e-01 1.1275151e+00 1.5741148e+00
 2.1253648e+00 2.7922804e+00 3.5858786e+00 4.5171747e+00 5.5971832e+00
 6.8369217e+00 8.2474060e+00 9.8396511e+00 1.1624674e+01 1.3613489e+01
 1.5817106e+01 1.8246557e+01 2.0912844e+01 2.3826992e+01 2.7000002e+01] 

X_prod = [9.0000000e+00 8.2803001e+00 7.5905881e+00 6.9308619e+00 6.3011246e+00
 5.7013745e+00 5.1316123e+00 4.5918365e+00 4.0820489e+00 3.6022491e+00
 3.1524365e+00 2.7326117e+00 2.3427739e+00 1.9829239e+00 1.6530612e+00
 1.3531862e+00 1.0832986e+00 8.4339857e-01 6.3348603e-01 4.5356098e-01
 3.0362347e-01 1.8367347e-01 9.3710959e-02 3.3735946e-02 3.7484383e-03
 3.7484383e-03 3.3735946e-02 9.3710959e-02 1.8367347e-01 3.0362347e-01
 4.5356098e-01 6.3348603e-01 8.4339857e-01 1.0832986e+00 1.3531862e+00
 1.6530612e+00 1.9829239e+00 2.3427739e+00 2.7326117e+00 3.1524365e+00
 3.6022491e+00 4.0820489e+00 4.5918365e+00 5.1316123e+00 5.7013745e+00
 6.3011246e+00 6.9308619e+00 7.5905881e+00 8.2803001e+00 9.0000000e+00] 

```

## Scenario 2
```
X = tf.placeholder('float64')

x = np.linspace(-3, 3)

s = tf.Session()

X_pow2 = tf.pow(X, 2)
X_pow3 = tf.pow(X, 3)

print('X_pow2 =', X_pow2.eval({X:x}, session=s), '\n')
print('X_pow3 =', X_pow3.eval({X:x},session=s),'\n')
```

get this 

```
X_pow2 = [9.00000000e+00 8.28029988e+00 7.59058726e+00 6.93086214e+00
 6.30112453e+00 5.70137443e+00 5.13161183e+00 4.59183673e+00
 4.08204915e+00 3.60224906e+00 3.15243648e+00 2.73261141e+00
 2.34277384e+00 1.98292378e+00 1.65306122e+00 1.35318617e+00
 1.08329863e+00 8.43398584e-01 6.33486047e-01 4.53561016e-01
 3.03623490e-01 1.83673469e-01 9.37109538e-02 3.37359434e-02
 3.74843815e-03 3.74843815e-03 3.37359434e-02 9.37109538e-02
 1.83673469e-01 3.03623490e-01 4.53561016e-01 6.33486047e-01
 8.43398584e-01 1.08329863e+00 1.35318617e+00 1.65306122e+00
 1.98292378e+00 2.34277384e+00 2.73261141e+00 3.15243648e+00
 3.60224906e+00 4.08204915e+00 4.59183673e+00 5.13161183e+00
 5.70137443e+00 6.30112453e+00 6.93086214e+00 7.59058726e+00
 8.28029988e+00 9.00000000e+00] 

X_pow3 = [-2.70000000e+01 -2.38269854e+01 -2.09128424e+01 -1.82465554e+01
 -1.58171085e+01 -1.36134859e+01 -1.16246717e+01 -9.83965015e+00
 -8.24740542e+00 -6.83692169e+00 -5.59718315e+00 -4.51717397e+00
 -3.58587833e+00 -2.79228043e+00 -2.12536443e+00 -1.57411453e+00
 -1.12751490e+00 -7.74549720e-01 -5.04203181e-01 -3.05459460e-01
 -1.67302740e-01 -7.87172012e-02 -2.86870267e-02 -6.19639776e-03
 -2.29496213e-04  2.29496213e-04  6.19639776e-03  2.86870267e-02
  7.87172012e-02  1.67302740e-01  3.05459460e-01  5.04203181e-01
  7.74549720e-01  1.12751490e+00  1.57411453e+00  2.12536443e+00
  2.79228043e+00  3.58587833e+00  4.51717397e+00  5.59718315e+00
  6.83692169e+00  8.24740542e+00  9.83965015e+00  1.16246717e+01
  1.36134859e+01  1.58171085e+01  1.82465554e+01  2.09128424e+01
  2.38269854e+01  2.70000000e+01] 
```

So on more serious or complicated tasks this give unpredictable behavior and optimizers don't optimize, losses get NaN, everything going crazy or just NaN everywhere.

So I exactly had the same problem on tensorflow version 1.5.0 with CuDNN 7.0.5

And I can't understand, is it my setup and maybe videocard just bad, or is it really bug?"
17631,"Eager mode in multithreaded environment v1.6 generates : ""All graphs are building functions, and no eager context was previously active""","### The problem
Scope initialization assumes that the  'context_stack' must be in the same stacktrace thread. while in some cases the user might use the eager context from a different thread. For example, the code below fails in version 1.6  , but not in 1.5.
Also, in version 1.6 it does not fail if ""foo"" is called from main thread, or if enable_eager_execution is called from the child thread.

### Source code 
```
from tensorflow.contrib.eager.python import tfe
import tensorflow as tf
from threading import Thread

class MNISTModel(tfe.Network):
    def __init__(self):
        super(MNISTModel, self).__init__()
        self.layer1 = self.track_layer(tf.layers.Dense(units=10))
        self.layer2 = self.track_layer(tf.layers.Dense(units=10))
    def call(self, input):
        result = self.layer1(input)
        result = self.layer2(result)
        return result

tfe.enable_eager_execution()


def foo():
    model = MNISTModel()
    batch = tf.zeros([1, 1, 784])
    print(batch.shape)
    result = model(batch)
    print(result)


t1 = Thread(target=foo)
t1.start()
t1.join()

```
### logs (exception) : 

```
Traceback (most recent call last):
  File ""/opt/anaconda3/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/opt/anaconda3/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/data/dopamine/dopapy/uriy_tests/dnn4/test_eager_1.py"", line 23, in foo
    result = model(batch)
  File ""/opt/anaconda3/lib/python3.5/site-packages/tensorflow/python/layers/base.py"", line 696, in __call__
    outputs = self.call(inputs, *args, **kwargs)
  File ""/data/dopamine/dopapy/uriy_tests/dnn4/test_eager_1.py"", line 11, in call
    result = self.layer1(input)
  File ""/opt/anaconda3/lib/python3.5/site-packages/tensorflow/python/layers/base.py"", line 680, in __call__
    self.build(input_shapes)
  File ""/opt/anaconda3/lib/python3.5/site-packages/tensorflow/python/layers/core.py"", line 134, in build
    trainable=True)
  File ""/opt/anaconda3/lib/python3.5/site-packages/tensorflow/python/layers/base.py"", line 533, in add_variable
    partitioner=partitioner)
  File ""/opt/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py"", line 1297, in get_variable
    constraint=constraint)
  File ""/opt/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py"", line 1093, in get_variable
    constraint=constraint)
  File ""/opt/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py"", line 439, in get_variable
    constraint=constraint)
  File ""/opt/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py"", line 408, in _true_getter
    use_resource=use_resource, constraint=constraint)
  File ""/opt/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py"", line 775, in _get_single_variable
    with ops.init_scope():
  File ""/opt/anaconda3/lib/python3.5/contextlib.py"", line 59, in __enter__
    return next(self.gen)
  File ""/opt/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 5034, in init_scope
    raise AssertionError(""All graphs are building functions, and no ""
AssertionError: All graphs are building functions, and no eager context was previously active.

```
### System information
- Have I written custom code : no
- OS Platform and Distribution :  Linux Ubuntu 16
- TensorFlow installed from  : binary
- TensorFlow version : v1.6.0-0-gd2e24b6039 1.6.0
- Python version:  3.5
"
17629,ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory,"OS Platform and Distribution:
Linux Ubuntu 17.10

TensorFlow installed using pip
TensorFlow version: 1.6, with GPU support
Python Version: 3.6.4
CUDA version: 9.1
GPU model and memory: NVidia GEForce 940MX 2GB
command to reproduce:
~$ python3
>>> import tensorflow as tf
(basically run any tensorflow program to reproduce)

Problem:
Whenever you run a tensorflow program, you get a huge error log, but the main problem is this:
`ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory`
So, the reason this is happening is because TensorFlow wants Cuda 9.0, but I have Cuda 9.1. This problem can be fixed by installing Cuda 9.0, but I have a few requests. Seeing that a couple of people have this problem (see https://github.com/tensorflow/tensorflow/issues/15604, https://github.com/tensorflow/tensorflow/issues/15817, https://github.com/tensorflow/tensorflow/issues/15817), I think that TensorFlow could be updated so that it works with Cuda 9.1 (but I think this issue is only with Ubuntu), or the following could be done:
Update the TensorFlow documentation, saying that you specifically need Cuda 9.0 for TensorFlow 1.6, and Cuda 8.0 for TensorFlow 1.4, and so on
And also, include this in the errors list at https://www.tensorflow.org/install/install_linux#common_installation_problems.

Edit: If a Pull Request is required to update the documentation, I am fine with doing that."
17628,"iOS error: Running model failed:Invalid argument: NodeDef mentions attr 'dilations' not in Op<name=Conv2D; signature=input:T, filter:T ->","
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS
- **TensorFlow installed from (source or binary)**: pip
- **TensorFlow version (use command below)**: 1.6
- **Python version**: 3.6
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: none
- **GPU model and memory**:none
- **Exact command to reproduce**:

### Describe the problem
I was just trying to make a classifier iOS app by simply replacing the inception pb file to my pb file for my classifier.
The iOS app example I was using is camera. It worked well with the original inception.
But when I changed the pb file I got an error as listed below. The pb file was generated with [tensorflow-for-poest-2](https://github.com/googlecodelabs/tensorflow-for-poets-2). 
Then the model doesn't work. The camera is working but no classification message.

I assume there is some mismatch between versions of TF?

### Source code / logs
2018-03-11 20:33:41.906421: E /Users/apple/OneDrive/P/tensorflow/tensorflow/examples/ios/camera/CameraExampleViewController.mm:327] Running model failed:Invalid argument: NodeDef mentions attr 'dilations' not in Op<name=Conv2D; signature=input:T, filter:T -> output:T; attr=T:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=strides:list(int); attr=use_cudnn_on_gpu:bool,default=true; attr=padding:string,allowed=[""SAME"", ""VALID""]; attr=data_format:string,default=""NHWC"",allowed=[""NHWC"", ""NCHW""]>; NodeDef: conv/Conv2D = Conv2D[T=DT_FLOAT, data_format=""NHWC"", dilations=[1, 1, 1, 1], padding=""VALID"", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/cpu:0""](_recv_Mul_0, conv/conv2d_params). (Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).
	 [[Node: conv/Conv2D = Conv2D[T=DT_FLOAT, data_format=""NHWC"", dilations=[1, 1, 1, 1], padding=""VALID"", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/cpu:0""](_recv_Mul_0, conv/conv2d_params)]]
"
17627,Unknown Issue in working Tensorflow,"I use tensorflow as backend in keras. Implementation is done in R. Everything was working properly but today I got an error calling lstm model. Could you please help inrectifying the problem. Below is the message I get and then R stops working

2018-03-11 11:12:48.620511: W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-03-11 11:12:48.977900: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:955] Found device 0 with properties: 
name: Quadro K2000
major: 3 minor: 0 memoryClockRate (GHz) 0.954
pciBusID 0000:03:00.0
Total memory: 2.00GiB
Free memory: 1.64GiB
2018-03-11 11:12:48.978254: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:976] DMA: 0 
2018-03-11 11:12:48.978386: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:986] 0:   Y 
2018-03-11 11:12:48.978612: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Quadro K2000, pci bus id: 0000:03:00.0)"
17626,'unsupported/Eigen/CXX11/Tensor' file not found on iOS,"when I ran this two projects( https://github.com/yjmade/ios_camera_object_detection )( https://github.com/jeffxtang/yolov2_tf_ios ) on ios. I met this warning.

Stack Overflow didn't give any help, case #4680 is for Raspberry Pi. It didn't help me.

### Describe the problem

warning like this!
'unsupported/Eigen/CXX11/Tensor' file not found

- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
macOS10.13.4 Xcode9.2 iOS11.2
- **TensorFlow installed from (source or binary)**:
install from github source.
- **TensorFlow version (use command below)**:
version 1.6.0

why you close a different issue which isn't solved?"
17625,tf.layers.batch_normalization shape bug,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ubuntu 16.04 / archlinux
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**:v1.6.0-0-gd2e24b6039 1.6.0
- **Python version**: 3.6
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:
```python
x = tf.placeholder(tf.float32, [100,100,100,100])
y = tf.layers.batch_normalization(x, axis=1, renorm=True, training=True, virtual_batch_size=2)
```
It throws:
```
ValueError: Dimension 1 in both shapes must be equal, but are 1 and 50. Shapes are [1,1,100,1,1] and [1,50,100,1,1]. for 'batch_normalization/AssignMovingAvg' (op: 'AssignSub') with input shapes:
[1,1,100,1,1], [1,50,100,1,1].
```
However, 
```python
x = tf.placeholder(tf.float32, [None,100,100,100])
y = tf.layers.batch_normalization(x, axis=1, renorm=True, training=True, virtual_batch_size=2)
```
works fine."
17623, AttributeError: 'module' object has no attribute 'LookupTensor' ,
17621,Does TensorFlow 1.1 support CUDA 9.1?  ,"Does TensorFlow 1.5 support CUDA 9.1? if not , shoud i degrade my cuda or upgrade tensorflow?"
17620,tensorflow.python.framework.errors_impl.NotFoundError: ; No such file or directory,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
 Mac OS Sierra 10.12.6
- **TensorFlow installed from (source or binary)**:
 source
- **TensorFlow version (use command below)**:
1.4.0
- **Python version**: 
python3
- **Bazel version (if compiling from source)**:
sorry, I don't know
- **GCC/Compiler version (if compiling from source)**:
sorry, I don't know
- **CUDA/cuDNN version**:
sorry, I don't know
- **GPU model and memory**:
radeon pro 560 4G


### Describe the problem
I try to use object detection using tensorflow API 
I follow this youtube
https://www.youtube.com/watch?v=JR8CmWyh2E8
but there is a error

### Source code / logs
MacBook-Pro-de-Jongwun:~ jongwuni$ cd /Users/jongwuni/Documents/Jongwunibang/Neural_network/models
MacBook-Pro-de-Jongwun:models jongwuni$ cd object_detection
MacBook-Pro-de-Jongwun:object_detection jongwuni$ python3 train.py --logtostderr --train_dir=""/Users/jongwuni/Documents/Jongwunibang/Neural_network/models/object_detection/training"" --pipline_config_path=""/Users/jongwuni/Documents/Jongwunibang/Neural_network/models/object_detection/training/faster_rcnn_inception_resnet_v2_atrous_coco.config""

Traceback (most recent call last):
  File ""train.py"", line 163, in <module>
    tf.app.run()
  File ""/anaconda/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""train.py"", line 106, in main
    overwrite=True)
  File ""/anaconda/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py"", line 385, in copy
    compat.as_bytes(oldpath), compat.as_bytes(newpath), overwrite, status)
  File ""/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py"", line 473, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.NotFoundError: ; No such file or directory
"
17619,undefined symbol error for _dataset_ops.so on rasp pi,"

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:

```
$ uname -a
Linux pi_c 4.4.13-v7+ #894 SMP Mon Jun 13 13:13:27 BST 2016 armv7l GNU/Linux
$ cat /etc/issue
Raspbian GNU/Linux 8 \n \l
```

- **TensorFlow installed from (source or binary)**: 

installed from nightly wheel `http://ci.tensorflow.org/view/Nightly/job/nightly-pi-python3/`

- **TensorFlow version (use command below)**:

```
$ python3 -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""
v1.6.0-rc1-1295-g851c289 1.6.0
```

- **Python version**: 

```
$ python3 --version
Python 3.4.2
```

- **CUDA/cuDNN version**:  N/A   running cpu on pi

Have I written custom code NA

Bazel version NA

GPU model and memory NA

- **Exact command to reproduce**:

```
$ python3 -c ""import tensorflow.contrib.slim as slim""
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/contrib/__init__.py"", line 33, in <module>
    from tensorflow.contrib import data
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/contrib/data/__init__.py"", line 63, in <module>
    from tensorflow.contrib.data.python.ops.error_ops import ignore_errors
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/contrib/data/python/ops/error_ops.py"", line 20, in <module>
    from tensorflow.contrib.data.python.ops import contrib_op_loader  # pylint: disable=unused-import
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/contrib/data/python/ops/contrib_op_loader.py"", line 24, in <module>
    resource_loader.get_path_to_datafile(""../../_dataset_ops.so""))
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/contrib/util/loader.py"", line 56, in load_op_library
    ret = load_library.load_op_library(path)
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/load_library.py"", line 58, in load_op_library
    lib_handle = py_tf.TF_LoadLibrary(library_filename, status)
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/errors_impl.py"", line 516, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.4/dist-packages/tensorflow/contrib/data/python/ops/../../_dataset_ops.so: undefined symbol: _ZN6google8protobuf8internal9ArenaImpl15AllocateAlignedEj
```

### Describe the problem

Import of slim fails with .so error (as described above). doubt it's actually slim, it was just the first import to reference `_dataset_ops.so`

"
17618,Raspberry Pi 3 C++ compiling issue,"### System information
Raspberry Pi 3 running a clean install of latest Raspbian (version November 2017)

Have I written custom code: No
OS Platform and Distribution : Raspbian (version November 2017)
TensorFlow installed from : git cloned the latest version
TensorFlow version: git cloned the latest version
Bazel version: N/A
CUDA/cuDNN version : N/A
GPU model and memory: N/A
Exact command to reproduce: [Tensorflow Makefile for Raspberry Pi](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile#raspberry-pi)

### Problem
I am having a problem building the C++ library of Tensorflow.

First I use a USB as a swap by follwing the instructions here:
https://github.com/samjabrahams/tensorflow-on-raspberry-pi/blob/master/GUIDE.md#2-install-a-memory-drive-as-swap-for-compiling

Then continued on building tensorflow with the instructions below:
https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile#raspberry-pi

I followed all the steps and believed that everything went successfull, 
until I build the library and example using the command below:
```
make -f tensorflow/contrib/makefile/Makefile HOST_OS=PI TARGET=PI \
 OPTFLAGS=""-Os -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize"" CXX=g++-4.8
```

### Logs
It will ran for quite few hours until it stops and outputs the error below:
```
collect2: error: ld returned 1 exit status
tensorflow/contrib/makefile/Makefile:730: recipe for target '/home/pi/tensorflow/tensorflow/contrib/makefile/gen/bin/benchmark' failed
make: *** [/home/pi/tensorflow/tensorflow/contrib/makefile/gen/bin/benchmark] Error 1
```

The rest of the log can be seen here:
[output_log.txt](https://github.com/tensorflow/tensorflow/files/1799928/output_log.txt)
"
17615,Tensorflow.python.framework.errors_impl.NotFoundError: ; No such file or directory,"
Hi I try to use tensorflow object_detection API

My computer is Mac book pro(version Sierra 10.12.6 )

I follow this youtube :'https://www.youtube.com/watch?v=JR8CmWyh2E8'

and final step, error show up

MacBook-Pro-de-Jongwun:object_detection jongwuni$ python3 train.py --logtostderr --train_dir=""/Users/jongwuni/Documents/Jongwunibang/Neural_network/models/object_detection/training"" --pipline_config_path=""/Users/jongwuni/Documents/Jongwunibang/Neural_network/models/object_detection/training/faster_rcnn_inception_resnet_v2_atrous_coco.config""
Traceback (most recent call last):
  File ""train.py"", line 163, in <module>
    tf.app.run()
  File ""/anaconda/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""train.py"", line 106, in main
    overwrite=True)
  File ""/anaconda/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py"", line 385, in copy
    compat.as_bytes(oldpath), compat.as_bytes(newpath), overwrite, status)
  File ""/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py"", line 473, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.NotFoundError: ; No such file or directory"
17614,Error command in installation guild,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

There is an small error in the [installation guild](https://www.tensorflow.org/install/install_mac#determine_which_tensorflow_to_install)
which is 7th step under the **Installing with Virtualenv** section.

The site give an example command of installing TensorFlow in the active Virtualenv for macOS, python which is actually for py3 with pip3 command. 
```
 $ pip3 install --upgrade \
 https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.6.0-py3-none-any.whl
```
"
17613,Error with Installing tensorflow error using Virtualenv,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information


- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No custom code was written steps followed from the installtensorflow webpage:
https://www.tensorflow.org/install/install_mac 
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OSX El Capitan version 10.11.6
- **TensorFlow installed from (source or binary)**: error in installing tensorflow
- **TensorFlow version (use command below)**: 
- **Python version**: Python 3.6 
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: not sure
- **CUDA/cuDNN version**: 
- **GPU model and memory**: MacBook Pro 13 inch(early 2011), Processor: 2.3 GHz Intel Core I5, Memory: 16GB 1333 MHz DDR3, Graphics: Intel HD Graphics 3000 512 MB
- **Exact command to reproduce**:  error when using the following command 
                                                     $ virtualenv --system-site-packages -p python3 ~/tensorflow
                                          
![screen shot 2018-03-10 at 12 01 49 am](https://user-images.githubusercontent.com/28227010/37238611-23339db0-23f8-11e8-8b4c-37d743b1474a.png)


You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
I am trying to install tensorflow for mac os El Capitan, using Virtualenv as instructed in the tensorflow installation webpage: https://www.tensorflow.org/install/install_mac these are the steps i have taken and errors recieved:

1.Start a terminal (a shell). You'll perform all subsequent steps in this shell.

2. Installed pip and Virtualenv sucessfully by issuing the following commands:

 $ sudo easy_install pip
 $ pip install --upgrade virtualenv 

3. successfully Created a Virtualenv environment by issuing a command of one of the python 3 format:

 $ virtualenv --system-site-packages -p python3 ~/tensorflow

the following e4 errors were displayed in terminal after step 3:

ERROR: The executable /Users/User/tensorflow/bin/python3 is not functioning
ERROR: It thinks sys.prefix is '/Users/User' (should be '/Users/User/tensorflow')
ERROR: virtualenv is not compatible with this system or executable


4. I get an error when doing step 4 :Activate the Virtualenv environment by issuing one of the    following commands:

$ cd targetDirectory
$ source ./bin/activate      # If using bash, sh, ksh, or zsh
$ source ./bin/activate.csh  # If using csh or tcsh 

the error i ger is: -bash: ./bin/activate: No such file or directory

Please help with this problem is greatly appreciated,  I have tried 1 other times using different methods to install tensorflow and it hasn't worked. Next ill try native pip method.

i have attached a terminal screenshot of the whole process:

![screen shot 2018-03-10 at 12 01 49 am](https://user-images.githubusercontent.com/28227010/37238654-fb964c0c-23f8-11e8-8da0-d290523c9287.png)


### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
17612,Changing parallel_iterations of dynamic_rnn doesn't affect GPU memory consumption,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary (through pip)
- **TensorFlow version (use command below)**: tensorflow-gpu 1.6
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: 9.0
- **GPU model and memory**: Tesla P100
- **Exact command to reproduce**: Download mnist dataset to dir ""input_data/"" and run the source code provided as below


### Describe the problem
I'm using dynamic_rnn to train an RNN on mnist dataset. I run a simple test (code as below) to find the best parallel_iterations number. However, checking with nvidia-smi, it seems that the GPU memory consumption remains the same, which infers dynamic_rnn doesn't run in parallel.

Looking forward to your reply!

### Source code / logs
Test Code:
```
import tensorflow as tf
from tensorflow.contrib.layers import fully_connected
from tensorflow.examples.tutorials.mnist import input_data
from tensorflow.contrib import rnn
import sys
import numpy as np


def train(batch_size, parallel_iterations, mnist):
	lr = 1e-3
	batch_size_holder = tf.placeholder(tf.int32) 
	input_size = 28
	timestep_size = 28
	hidden_size = 28
	layer_num = 50
	class_num = 10

	_X = tf.placeholder(tf.float32, [None, 784])
	y = tf.placeholder(tf.float32, [None, class_num])
	keep_prob = tf.placeholder(tf.float32)
	X = tf.reshape(_X, [-1, 28, 28])

	rnn_cell = rnn.BasicRNNCell(num_units=hidden_size)
	rnn_cell = rnn.DropoutWrapper(cell=rnn_cell, input_keep_prob=1.0, output_keep_prob=keep_prob)
	mrnn_cell = rnn.MultiRNNCell([rnn_cell] * layer_num, state_is_tuple=True)
	outputs, state = tf.nn.dynamic_rnn(mrnn_cell, inputs=X, dtype=tf.float32, time_major=False, parallel_iterations=parallel_iterations)
	h_state = outputs[:, -1, :]

	W = tf.Variable(tf.truncated_normal([hidden_size, class_num], stddev=0.1), dtype=tf.float32)
	bias = tf.Variable(tf.constant(0.1,shape=[class_num]), dtype=tf.float32)
	y_pre = tf.nn.softmax(tf.matmul(h_state, W) + bias)
	cross_entropy = -tf.reduce_mean(y * tf.log(y_pre))
	train_op = tf.train.AdamOptimizer(lr).minimize(cross_entropy)

	correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(y,1))
	accuracy = tf.reduce_mean(tf.cast(correct_prediction, ""float""))

	session_config = tf.ConfigProto()
	session_config.gpu_options.allow_growth = True

	with tf.Session(config=session_config) as sess:
		sess.run(tf.global_variables_initializer())
		for i in range(50):
			batch = mnist.train.next_batch(batch_size)
			onehot_labels = np.eye(class_num)[batch[1]]
			sess.run(train_op, feed_dict={_X: batch[0], y: onehot_labels, keep_prob: 0.5, batch_size_holder: batch_size}, options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE), run_metadata=run_metadata)

	tf.reset_default_graph()



def main(_):
	mnist = input_data.read_data_sets(""input_data/"")

	for num in range(1,10):
		train(128, num*10, mnist)
	for num in range(10,-1,-1):
		if (num >0):
			train(128, num*10, mnist)

if __name__ == '__main__':
	tf.app.run(main=main, argv=[sys.argv[0]])


```

nvidia-smi result:
```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 384.81                 Driver Version: 384.81                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla P100-PCIE...  Off  | 00000000:03:00.0 Off |                    0 |
| N/A   25C    P0    37W / 250W |    517MiB / 16276MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla P100-PCIE...  Off  | 00000000:82:00.0 Off |                    0 |
| N/A   23C    P0    37W / 250W |    359MiB / 16276MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0      2893      C   python                                       507MiB |
|    1      2893      C   python                                       349MiB |
+-----------------------------------------------------------------------------+
```"
17611,TypeError: __new__() got an unexpected keyword argument 'output_alternatives',"### System information
- OS Distribution: Linux Ubuntu 16.04.3 LTS
- TensorFlow is installed from binary
- TensorFlow version: v1.6.0-0-gd2e24b6039 1.6.0
- Python version: 3.6.1
- CUDA/cuDNN version: 9.0
- GPU model and memory: GeForce GTX 850m

and

- OS Distribution: CentOS Linux release 7.3.1611 (Core) 
- TensorFlow is installed from binary
- TensorFlow version: v1.6.0-0-gd2e24b6039 1.6.0
- Python version: 3.6.0

### Describe the problem
`TypeError: __new__() got an unexpected keyword argument 'output_alternatives'` is thrown on line 611 in `_scale_tower_loss` function in tensorflow/contrib/estimator/python/estimator/replicate_model_fn.py

It can be resolved by adding `del estimator_spec['output_alternatives']`:
```def _scale_tower_loss(tower_spec, loss_reduction, number_of_towers):
  """"""Produce an EstimatorSpec with approproriately scaled loss.""""""
  if tower_spec.loss is None:
    return tower_spec

  estimator_spec = _asdict(tower_spec)
  estimator_spec['loss'] = _scale_loss(tower_spec.loss, loss_reduction,
                                       number_of_towers)
  del estimator_spec['output_alternatives'] # RESOLVES THE ISSUE
  return model_fn_lib.EstimatorSpec(**estimator_spec)
```

After running `grep` command, I have noticed that `output_alternatives` variable is mostly used in tensorflow/contrib/learn. My guess is that `output_alternatives`  was forgotten to be removed from the new  tf.estimator.Estimator as it is only used by the old tf.contrib.learn.Estimator.


### Source code / logs
Unfortunately cannot be provided.
"
