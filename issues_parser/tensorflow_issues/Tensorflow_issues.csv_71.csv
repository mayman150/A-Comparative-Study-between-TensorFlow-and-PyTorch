Issue Number,Issue Title,Issue Body
4124,"""ValueError: No gradients provided for any variable"" when using bidirectional_dynamic_rnn","I got the following error when using `tf.nn.bidirectional_dynamic_rnn`. 

```
Traceback (most recent call last):
  File ""main_cnn.py"", line 63, in <module>
    main()
  File ""main_cnn.py"", line 50, in main
    model.run(num_epoch, learning_rate=learning_rate)
  File ""/home/s1510032/research/programs/textsum-cnn/model.py"", line 266, in run
    self.optim = self.opt.apply_gradients(zip(grads, params), global_step=self.global_step)
  File ""/home/s1510032/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py"", line 298, in apply_gradients
    (grads_and_vars,))
ValueError: No gradients provided for any variable: ((None, <tensorflow.python.ops.variables.Variable object at 0x7f1e11c570d0>), (None, <tensorflow.python.ops.variables.Variable object at 0x7f1dfdd58e10>), (None, <tensorflow.python.ops.variables.Variable object at 0x7f1dfdd63690>), (None, <tensorflow.python.ops.variables.Variable object at 0x7f1dfdd7c5d0>), (None, <tensorflow.python.ops.variables.Variable object at 0x7f1e11c0f1d0>), (None, <tensorflow.python.ops.variables.Variable object at 0x7f1e11c22890>), (None, <tensorflow.python.ops.variables.Variable object at 0x7f1e11c35850>), (None, <tensorflow.python.ops.variables.Variable object at 0x7f1f103da890>), (None, <tensorflow.python.ops.variables.Variable object at 0x7f1f103dac50>), (None, <tensorflow.python.ops.variables.Variable object at 0x7f1f103dad10>), (None, <tensorflow.python.ops.variables.Variable object at 0x7f1f103e13d0>), (None, <tensorflow.python.ops.variables.Variable object at 0x7f1f1038cf10>), (None, <tensorflow.python.ops.variables.Variable object at 0x7f1f103aabd0>), (None, <tensorflow.python.ops.variables.Variable object at 0x7f1e119ecf90>), (None, <tensorflow.python.ops.variables.Variable object at 0x7f1e1197f150>), (None, <tensorflow.python.ops.variables.Variable object at 0x7f1d9f2c3d50>), (None, <tensorflow.python.ops.variables.Variable object at 0x7f1d9f2c3dd0>))

```

If I keep everything and use `tf.nn.bidirectional_rnn` instead, this problem goes away. Here is the working code and non-working code. Loss is calculated based on outputs and that part is the same for both cases.

Working code:

```
outputs, fw_states, _ = tf.nn.bidirectional_rnn(self.lstm_fw_cell,
                         self.lstm_bw_cell,
                         self.sent_cnn_outputs,
                         dtype=tf.float32)

 # calculate loss using outputs
```

Non-working code:

```
outputs, output_states = tf.nn.bidirectional_dynamic_rnn(self.lstm_fw_cell, 
                    self.lstm_bw_cell,
                    self.sent_cnn_outputs,
                    time_major=True,
                    sequence_length=self.sequence_length,
                    dtype=tf.float32)

outputs = tf.concat(2, outputs)
outputs = tf.unpack(outputs, 0)

# calculate loss using outputs
```

I suspect the issue here could because of `tf.unpack` function, which I use to make `outputs` become a list (for using in `zip` function in python with other list. Do you have any suggestion to resolve this?
"
4122,rnn/translate: IOError: [Errno 2] No such file or directory: '/mnt/tf1/translate/giga-fren.release2.fr.gz',"### Environment info

Operating System:

```
$ lsb_release -a
No LSB modules are available.
Distributor ID: Ubuntu
Description:    Ubuntu 14.04.4 LTS
Release:    14.04
Codename:   trusty
```

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
`NONE`
If installed from binary pip package, provide:
1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   `$ python -c ""import tensorflow; print(tensorflow.__version__)""
   0.10.0rc0`
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

```
$ cd tensorflow/tensorflow/models/rnn/translate/
$ python translate.py --data_dir /mnt/tf1/translate
Preparing WMT data in /mnt/tf1/translate
Downloading http://www.statmt.org/wmt10/training-giga-fren.tar to /mnt/tf1/translate/training-giga-fren.tar
Succesfully downloaded training-giga-fren.tar 2595102720 bytes
Extracting tar file /mnt/tf1/translate/training-giga-fren.tar
Unpacking /mnt/tf1/translate/giga-fren.release2.fr.gz to /mnt/tf1/translate/giga-fren.release2.fr
Traceback (most recent call last):
  File ""translate.py"", line 290, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""translate.py"", line 287, in main
    train()
  File ""translate.py"", line 147, in train
    FLAGS.data_dir, FLAGS.en_vocab_size, FLAGS.fr_vocab_size)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/models/rnn/translate/data_utils.py"", line 265, in prepare_wmt_data
    train_path = get_wmt_enfr_train_set(data_dir)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/models/rnn/translate/data_utils.py"", line 83, in get_wmt_enfr_train_set
    gunzip_file(train_path + "".fr.gz"", train_path + "".fr"")
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/models/rnn/translate/data_utils.py"", line 68, in gunzip_file
    with gzip.open(gz_path, ""rb"") as gz_file:
  File ""/usr/lib/python2.7/gzip.py"", line 34, in open
    return GzipFile(filename, mode, compresslevel)
  File ""/usr/lib/python2.7/gzip.py"", line 94, in __init__
    fileobj = self.myfileobj = __builtin__.open(filename, mode or 'rb')
IOError: [Errno 2] No such file or directory: '/mnt/tf1/translate/giga-fren.release2.fr.gz'
ubuntu@ip-10-169-182-86:~/tensorflow/tensorflow/tensorflow/models/rnn/translate$ ls /mnt/tf1/translate/training-giga-fren.tar 
```

```
$ ls -l /mnt/tf1/translate/training-giga-fren.tar 
-rw-rw-r-- 1 ubuntu ubuntu 2595102720 Aug 31 10:53 /mnt/tf1/translate/training-giga-fren.tar
```
### What other attempted solutions have you tried?

```
$ python translate.py --data_dir /mnt/tf1/translate
Preparing WMT data in /mnt/tf1/translate
Extracting tar file /mnt/tf1/translate/training-giga-fren.tar
...(same error)
```

```
$ ls -l /mnt/tf1/translate/
total 5073524
-rw-rw-r-- 1 ubuntu ubuntu 1214224978 Aug 30 19:55 giga-fren.release2.fixed.en.gz
-rw-rw-r-- 1 ubuntu ubuntu 1380871453 Aug 29 21:43 giga-fren.release2.fixed.fr.gz
-rw-rw-r-- 1 ubuntu ubuntu 2595102720 Aug 31 10:53 training-giga-fren.tar
```
### Logs or other output that would be helpful

(If logs are large, please upload as attachment or provide link).
"
4121,Lack of 'name' argument in the tf.contrib.learn.Classifier.evaluate method,"Tensorflow version 0.10.0rc0 (Installed today by pip from https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl)

I'm working with examples from [here](https://www.tensorflow.org/versions/r0.10/tutorials/tflearn/index.html) and [here](https://www.tensorflow.org/versions/r0.10/tutorials/monitors/index.html):

```
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import tensorflow as tf
import numpy as np

tf.logging.set_verbosity(tf.logging.INFO)

# Data sets
IRIS_TRAINING = ""iris_training.csv""
IRIS_TEST = ""iris_test.csv""

# Load datasets.
training_set = tf.contrib.learn.datasets.base.load_csv(filename=IRIS_TRAINING,
                                                       target_dtype=np.int)
test_set = tf.contrib.learn.datasets.base.load_csv(filename=IRIS_TEST,
                                                   target_dtype=np.int)

# Specify that all features have real-value data
feature_columns = [tf.contrib.layers.real_valued_column("""", dimension=4)]

# Build 3 layer DNN with 10, 20, 10 units respectively.
classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,
                                            hidden_units=[10, 20, 10],
                                            n_classes=3,
                                            model_dir=""/tmp/iris_model"",
                                            config=tf.contrib.learn.RunConfig(
                                                save_checkpoints_secs=1))

validation_metrics = {(""metrics/accuracy"", ""classes""): tf.contrib.metrics.streaming_accuracy,
                      (""metrics/precision"", ""classes""): tf.contrib.metrics.streaming_precision,
                      (""metrics/recall"", ""classes""): tf.contrib.metrics.streaming_recall}

validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(
    test_set.data,
    test_set.target,
    every_n_steps=50,
    metrics=validation_metrics)

# Fit model.
classifier.fit(x=training_set.data,
               y=training_set.target,
               steps=2000,
               monitors=[validation_monitor])

# Evaluate accuracy.
accuracy_score = classifier.evaluate(x=test_set.data,
                                     y=test_set.target)[""accuracy""]
print('Accuracy: {0:f}'.format(accuracy_score))

# Classify two new flower samples.
new_samples = np.array(
    [[6.4, 3.2, 4.5, 1.5], [5.8, 3.1, 5.0, 1.7]], dtype=float)
y = classifier.predict(new_samples)
print('Predictions: {}'.format(str(y)))
```

and everything is fine for now, but if I use my own model:

```
def my_model(x, y, mode):
    net = tf.contrib.layers.fully_connected(x, num_outputs=10)
    net = tf.contrib.layers.fully_connected(net, num_outputs=20)
    net = tf.contrib.layers.fully_connected(net, num_outputs=10)

    logits = tf.contrib.layers.fully_connected(net, 3)
    prediction = tf.nn.softmax(logits)

    if mode == tf.contrib.learn.ModeKeys.INFER:
        return prediction, None, None

    loss = tf.contrib.losses.softmax_cross_entropy(logits, tf.one_hot(y, 3))
    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)
    train_op = tf.contrib.slim.learning.create_train_op(loss, optimizer)

    return prediction, loss, train_op


classifier = tf.contrib.learn.Classifier(model_fn=my_model,
                                         n_classes=3,
                                         model_dir=""/tmp/iris_model"",
                                         config=tf.contrib.learn.RunConfig(
                                            save_checkpoints_secs=1))
```

instead of:

```
classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,
                                            hidden_units=[10, 20, 10],
                                            n_classes=3,
                                            model_dir=""/tmp/iris_model"",
                                            config=tf.contrib.learn.RunConfig(
                                                save_checkpoints_secs=1))
```

Following error occurs:

```
Traceback (most recent call last):
  File ""/mnt/nfs/dnn/workspace/deep-learning/test/minimal_working_example.py"", line 70, in <module>
    monitors=[validation_monitor])
  File ""/***/deep-learning/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 240, in fit
    max_steps=max_steps)
  File ""/***/deep-learning/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 578, in _train_model
    max_steps=max_steps)
  File ""/***/deep-learning/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py"", line 280, in _supervised_train
    None)
  File ""/***/deep-learning/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/supervised_session.py"", line 270, in run
    run_metadata=run_metadata)
  File ""/***/deep-learning/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/recoverable_session.py"", line 54, in run
    run_metadata=run_metadata)
  File ""/***/deep-learning/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/coordinated_session.py"", line 70, in run
    self._coord.join(self._coordinated_threads_to_join)
  File ""/***/deep-learning/lib/python2.7/site-packages/tensorflow/python/training/coordinator.py"", line 357, in join
    six.reraise(*self._exc_info_to_raise)
  File ""/***/deep-learning/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/coordinated_session.py"", line 66, in run
    return self._sess.run(*args, **kwargs)
  File ""/***/deep-learning/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/monitored_session.py"", line 107, in run
    induce_stop = monitor.step_end(monitors_step, monitor_outputs)
  File ""/***/deep-learning/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/monitors.py"", line 396, in step_end
    return self.every_n_step_end(step, output)
  File ""/***/deep-learning/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/monitors.py"", line 687, in every_n_step_end
    steps=self.eval_steps, metrics=self.metrics, name=self.name)
TypeError: evaluate() got an unexpected keyword argument 'name'
```
### Solution

Add `name` argument to the Classifier.evaluate method.
"
4120,"Document ""How to adding new customized file system""","Adding customized file system is supported but not well documented:
TF_INC=$(python -c 'import tensorflow as tf; print(tf.sysconfig.get_include())')
g++ -std=c++11 -shared test_file_system.cc -o test_file_system.so -fPIC -I $TF_INC

Adding a section in how_tos will help.
"
4119,Implementing gradient for user op in C++?," I'd ideally like the operation to be wholly self-contained (gradient and operation defined in same file). The official tutorial only highlights a python implementation. Does anyone know if it's possible to implement the gradient in C++, and how to go about it?
"
4118,Undefined Symbols When Compiling User Op for GPU,"## Summary

I can compile, but not load, a user-defined TF shared library using CUDA. The library is based off of the TF [`zero_out`](https://www.tensorflow.org/versions/master/how_tos/adding_an_op/index.html#adding-a-new-op) example. I've modified the example to support CPU and GPU devices. Upon loading the shared library I get the following error: `tensorflow.python.framework.errors.NotFoundError: zero_out.so: undefined symbol: _ZN10tensorflow7functor14ZeroOutFunctorIN5Eigen9GpuDeviceEEclERKS3_NS2_9TensorMapINS2_6TensorIKfLi1ELi1ElEELi16EEENS7_INS8_IfLi1ELi1ElEELi16EEEi`.

I suspect that the problem has something to do with my particular combination of compiler and OS environment. However after trying many ideas I've hit a wall.
## Similar Issues

https://github.com/tensorflow/tensorflow/issues/2097: My problem looks similat to this one.
https://github.com/tensorflow/tensorflow/issues/1569: There are two suggestions made in this issue:
1. Try a `gcc-4.*` compiler
2. Use the compiler variable `D_GLIBCXX_USE_CXX11_ABI=0`

Neither of these suggestions are working for me.
## Detailed Explanation

I give details below about my environment, the source code, the steps I've taken to compile, and the error.
### Environment

OS: Ubuntu 16.04 LTS
Kernel : 4.4.0-34-generic
Compiler: gcc (Ubuntu 5.4.0-6ubuntu1~16.04.2) 5.4.0 20160609
Cuda: 7.5
Cudnn:  5.1.3

My problem exists whether I use a TF binary or compile my own version from source. Note that in order to successfully compile TF from source I must add the following three lines to `CROSSTOOL.tpl`:

```
cxx_flag: ""-D_MWAITXINTRIN_H_INCLUDED""
cxx_flag: ""-D_FORCE_INLINES""
cxx_builtin_include_directory: ""/usr/local/cuda-7.5/include""
```
### Source Code

I have three source files and a Makefile:
#### `zero_out.h`

``` c++
#ifndef TENSORFLOW_KERNELS_ZERO_OUT_OP_H_
#define TENSORFLOW_KERNELS_ZERO_OUT_OP_H_

namespace tensorflow {

namespace functor {

// Generic helper functor for the ZeroOut Op.
template <typename Device>
struct ZeroOutFunctor;

}  // namespace functor
}  // namespace tensorflow

#endif  // TENSORFLOW_KERNELS_ZERO_OUT_OP_H_
```
#### `zero_out.cc`

``` c++
#define EIGEN_USE_THREADS
#include ""zero_out.h""
#include ""tensorflow/core/framework/op_kernel.h""
#include ""tensorflow/core/framework/tensor.h""

namespace tensorflow {

REGISTER_OP(""ZeroOut"")
.Input(""to_zero: float"")
.Output(""zeroed: float"")
.Doc(R""doc(
Zeros all elements of the tensor except the first.
zeroed: A Tensor.
  output[0] = input[0]
  output[1:N] = 0
)doc"");;

typedef Eigen::ThreadPoolDevice CPUDevice;
typedef Eigen::GpuDevice GPUDevice;

namespace functor {

template <typename Device>
struct ZeroOutFunctor {
  void operator()(const Device& d,
          typename TTypes<float>::ConstFlat input,
          typename TTypes<float>::Flat output,
          const int N);
};

template <>
struct ZeroOutFunctor<CPUDevice> {
  void operator()(const CPUDevice& d,
          typename TTypes<float>::ConstFlat input,
          typename TTypes<float>::Flat output,
          const int N) {
    for (int i = 1; i < N; i++) {
      output(i) = 0;
    }

    // Preserve the first input value if possible.
    if (N > 0) output(0) = input(0);
  }
};
} // namespace functor    

template <typename Device>
class ZeroOutOp : public OpKernel {
public:
  explicit ZeroOutOp(OpKernelConstruction* context) : OpKernel(context) {}

  void Compute(OpKernelContext* context) override {
    // Grab the input tensor
    const Tensor& input_tensor = context->input(0);
    auto input = input_tensor.flat<float>();

    // Create an output tensor
    Tensor* output_tensor = NULL;
    OP_REQUIRES_OK(context, context->allocate_output(0, input_tensor.shape(),
                             &output_tensor));

    auto output = output_tensor->template flat<float>();
    const int N = input.size();
    functor::ZeroOutFunctor<Device>()(context->eigen_device<Device>(),
                      input, output, N);
  }
};

REGISTER_KERNEL_BUILDER(Name(""ZeroOut"")                 \
            .Device(DEVICE_CPU),        \
            ZeroOutOp<CPUDevice>);

#if GOOGLE_CUDA
REGISTER_KERNEL_BUILDER(Name(""ZeroOut"")                 \
            .Device(DEVICE_GPU),        \
            ZeroOutOp<GPUDevice>);
#endif // GOOGLE_CUDA
} // namespace tensoroflow

```
#### `zero_out_gpu.cu.cc`

``` c++
#if GOOGLE_CUDA

#define EIGEN_USE_GPU

#include ""zero_out.h""

#include ""third_party/eigen3/unsupported/Eigen/CXX11/Tensor""
#include ""tensorflow/core/framework/tensor.h""
#include ""tensorflow/core/framework/tensor_types.h""


namespace tensorflow {

namespace functor {

using GPUDevice = Eigen::GpuDevice;

__global__ void ZeroOutKernel(const float* in, float* out, const int N) {
  for (int i = blockIdx.x * blockDim.x + threadIdx.x; i < N;
       i += blockDim.x * gridDim.x) {
    if (i == 0) {
      out[i] = in[i];
    } else {
      out[i] = 0;
    }
  }
}

template <>
struct ZeroOutFunctor<GPUDevice> {
  void operator()(const GPUDevice& d,
          typename TTypes<float>::ConstFlat input,
          typename TTypes<float>::Flat output,
          const int N) {
    // How to compute the optimal block count and threads per block?
    // tensorflow/core/util/cuda_kernel_helper.h isn;t included in the binary
    // distribution
    ZeroOutKernel<<<32, 256, 0, d.stream()>>>(input.data(), output.data(), N);
  }
};

template struct ZeroOutFunctor<GPUDevice>;  
} // namespace functor 
} // namespace tensorflow
#endif // GOOGLE_CUDA
```
#### `Makefile`

``` make
INCLUDE += -I /usr/local/cuda-7.5/include
INCLUDE += -I $(shell python -c \
    'import tensorflow as tf; print(tf.sysconfig.get_include())')

CXX = gcc -std=c++11
CXXFLAGS =                          \
    -D_MWAITXINTRIN_H_INCLUDED  \
    -D_FORCE_INLINES            \
    $(INCLUDE) -fPIC -lcudart   \

NVCC = nvcc -std=c++11 -c
NVCCFLAGS =                         \
    -D_MWAITXINTRIN_H_INCLUDED  \
    -D_FORCE_INLINES            \
    $(INCLUDE) -x cu -Xcompiler -fPIC

LDFLAGS = -shared
CUDA_SRCS = zero_out_gpu.cu.cc
SRCS = zero_out.cc
RM = rm -f
TARGET_LIB = zero_out.so
CUDA_OBJ = zero_out.cu.o

all: $(TARGET_LIB)

# This target (CPU and GPU) does not find the right symbols
$(TARGET_LIB): $(SRCS) $(CUDA_OBJ) 
    $(CXX) $(LDFLAGS) -o $@ $^ $(CXXFLAGS) -DGOOGLE_CUDA=1

# This target (CPU only) is fine
# $(TARGET_LIB): $(SRCS) 
#   $(CXX) $(LDFLAGS) -o $@ $^ $(CXXFLAGS) -DGOOGLE_CUDA=0

$(CUDA_OBJ): $(CUDA_SRCS)
    $(NVCC) -o $@ $^ $(NVCCFLAGS) -DGOOGLE_CUDA=1

.PHONY: clean
clean:
    -$(RM) $(TARGET_LIB)
    -$(RM) *~
    -$(RM) *.o
```
### Compilation

Compilation runs without errors:

``` bash
$ make
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally
nvcc -std=c++11 -c -o zero_out.cu.o zero_out_gpu.cu.cc -D_MWAITXINTRIN_H_INCLUDED -D_FORCE_INLINES -I /usr/local/cuda-7.5/include -I /home/sarroff/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/include -x cu -Xcompiler -fPIC -DGOOGLE_CUDA=1
/home/sarroff/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/allocator.h(155): warning: missing return statement at end of non-void function ""tensorflow::Allocator::RequestedSize""

/home/sarroff/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/allocator.h(155): warning: missing return statement at end of non-void function ""tensorflow::Allocator::RequestedSize""

I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally
gcc -std=c++11 -shared -o zero_out.so zero_out.cc zero_out.cu.o -D_MWAITXINTRIN_H_INCLUDED -D_FORCE_INLINES -I /usr/local/cuda-7.5/include -I /home/sarroff/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/include -fPIC -lcudart  -DGOOGLE_CUDA=1
```
## Error When Loading the Library:

``` bash
$ python -c ""import tensorflow as tf; tf.load_op_library('zero_out.so')t.so')""
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/home/sarroff/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/load_library.py"", line 75, in load_op_library
    raise errors._make_specific_exception(None, None, error_msg, error_code)
tensorflow.python.framework.errors.NotFoundError: zero_out.so: undefined symbol: _ZN10tensorflow7functor14ZeroOutFunctorIN5Eigen9GpuDeviceEEclERKS3_NS2_9TensorMapINS2_6TensorIKfLi1ELi1ElEELi16EEENS7_INS8_IfLi1ELi1ElEELi16EEEi
```
## Notes and Some Things I've Tried
1. I have no difficulties compiling and loading a shared library for CPU-only. (See the commented target in the Makefile.)
2. My problem persists whether using a TF bleeding-edge source (with `bazel`) or TF binary installation (with `make`)
3. I've tried compiling the shared library with `g++`, as well as using some earlier `gcc-4.*` compilers
4. I've tried mimicking the nvcc and gcc options provided in `CROSSTOOL.tpl`
5. I don't have immediate access to an earlier Linux distro, otherwise I would have tried it

Any help is greatly appreciated!
"
4117,Use shallow git clone in Dockerfiles,"`git clone --depth 1 --shallow-submodules ...`

_EDIT_: Looks like have to omit `--shallow-submodules` for the version of git in the image. This does not seem to affect the size or the speed.
"
4116,Cleanup Bazel Cache in Dockerfile,"Right now I see the following in the Docker image:

```
--- /root/.cache/bazel/_bazel_root ---------------------------------------------------------------------------------------------------------------------------------------------------------
                        /..
    2.3GiB [##########] /68a62076e91007a7908bc42a32e4cff9
   84.3MiB [          ] /install
```

which leads to a very large Docker image.
"
4114,Train DNN model efficiently with sparse features and missing data,"We have used TensorFlow for recommend systems to replace the logistic regression model. The train data is quite sparse and we have to do it efficiently. Now we have the problem to train the model without sparse tensor's multiplication.

We have read `word2vec` and the example of `wide_n_deep` models. Their inputs are sparse but not suitable for general recommend systems. Our inputs are sparse and we need to encode the features like ages, colleges with one-hot encoding. The examples may have different number of valid features because of unknown values and the train data looks like this.

```
label         gender        age        college       
------------------------------------------------
0             2:1           8:1       (unknown)
1             1:1           5:1         25:1
0             1:1           8:1       (unknown)
```

With this dataset, we have to build `SparseTensor` object for each example data like this.

```
example1 = tf.SparseTensor(indices=[[2], [8]], values=[1, 1], shape=[100])
example2 = tf.SparseTensor(indices=[[1], [5], [25]], values=[1, 1, 1], shape=[100])
example3 = tf.SparseTensor(indices=[[1], [8]], values=[1, 1], shape=[100])
```

For `word2vec` and `wide_n_deep` models, we can use `tf.nn.embedding_lookup()` to lookup the variables to train and no need to fill up the whole matrix with zeros. This works for each example but we have problems if using batch because the valid `ids` has different shape to train. The code  looks like this. 

```
vocabulary_size = 100
embedding_size = 1
embeddings = tf.Variable(tf.ones([vocabulary_size, embedding_size]))

batch_size = 3
feature_number = 3 # ERROR: should be 2 or 3
train_inputs = tf.placeholder(tf.int32, shape=[batch_size, feature_number])

batch_data = np.array([[2, 8], [1, 5, 25], [1, 8]]) # EROOR: should be dense

with tf.Session() as sess:
    sess.run(tf.initialize_all_variables())
    print(sess.run(embed, feed_dict={train_inputs: batch_data}))
```

The code could not work until we make `example1`, `example2` and `example3` have the same number of valid featue, such as 3 in this case. This is one solution but we have to fill up the examples with zeros(notice that this is different from filling up the one-hot encoding).

Maybe supporting sparse tensor's multiplication is quit more efficient. Now we have only `embedding_lookup` op for SpareTensor and I don't know how to use `embedding_lookup_sparse` or `safe_embedding_lookup_sparse` for this scenario. It could be great if anyone has any suggestion for this use case.

Related to https://github.com/tensorflow/tensorflow/issues/1241
"
4112,op LogUniformCandidateSampler should raise ValueError when range_max < num_sampled,"This Op registration should have a modified Attr

instead of 

```
REGISTER_OP(""LogUniformCandidateSampler"")
    .Input(""true_classes: int64"")
    .Output(""sampled_candidates: int64"")
    .Output(""true_expected_count: float"")
    .Output(""sampled_expected_count: float"")
    .Attr(""num_true: int >= 1"")
    .Attr(""num_sampled: int >= 1"")
```

this

```
REGISTER_OP(""LogUniformCandidateSampler"")
    .Input(""true_classes: int64"")
    .Output(""sampled_candidates: int64"")
    .Output(""true_expected_count: float"")
    .Output(""sampled_expected_count: float"")
    .Attr(""num_true: int >= 1"")
    .Attr(""num_sampled: int <=range_max"")
```

I ran into this issue when training a word2vec with noise contrastive estimate algorithm where the size of vocabulary was smaller than the size of negative samples used to train the logistic classifier.

Currently core/kernels/range_sampler.cc throws this error

```
F tensorflow/core/kernels/range_sampler.cc:86] Check failed: batch_size + avoided_values.size() <= range_ (5 vs. 4)
```

The error does not describe the variable which is the cause of this error.
"
4111,CUDNN_STATUS_BAD_PARAM   tensorflow/stream_executor/cuda/cuda_dnn.cc:423,"NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

CUDNN_STATUS_BAD_PARAM
### Environment info

Operating System:OS: Ubuntu 14.04

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
-rw-r--r-- 1 root root   322936 Aug 16  2015 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Aug 16  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root       19 Aug 16  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root   383336 Aug 16  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root   720192 Aug 16  2015 /usr/local/cuda/lib64/libcudart_static.a
lrwxrwxrwx 1 root root       13 Aug 30 22:56 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.4
lrwxrwxrwx 1 root root       17 Aug 30 22:56 /usr/local/cuda/lib64/libcudnn.so.4 -> libcudnn.so.4.0.7
-rwxr-xr-x 1 root root 61272736 Jan 12  2016 /usr/local/cuda/lib64/libcudnn.so.4.0.4
-rwxr-xr-x 1 root root 61453024 Aug 30 22:55 /usr/local/cuda/lib64/libcudnn.so.4.0.7
-rw-r--r-- 1 root root 62025862 Aug 30 22:55 /usr/local/cuda/lib64/libcudnn_static.a

If installed from binary pip package, provide:
1. A link to the pip package you installed:
   https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
   I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
   I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
   I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally
   I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
   0.10.0rc0
   If installed from source, provide 
3. The commit hash (`git rev-parse HEAD`)
4. The output of `bazel version`
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

I also used data from hd5f file, before the tf.Session I extract the data first. 
It works for the 200000 iterations, but when it comes more than 200000 the program will be terminated.
### What other attempted solutions have you tried?

I tried to re-install cudnn 4.0 
### Logs or other output that would be helpful

(If logs are large, please upload as attachment or provide link).
Iteration: 240640
F tensorflow/stream_executor/cuda/cuda_dnn.cc:423] could not set cudnn tensor descriptor: CUDNN_STATUS_BAD_PARAM
Aborted (core dumped)
Strange thing happens after the iteration:240640 every time
"
4110,r0.10: function 'repository_rule' does not exist,"Hi,

I previously installed tensorflow 0.8 and 0.9 on a GPU cluster with several local patches to circumvent non-standard paths for crosstool files and swig. Our users are now requesting an upgrade to 0.10 but I have the following error... Installing tensorflow on a cluster is so painful....

ERROR: ~/tensorflow_0.10/tensorflow/third_party/gpus/cuda_configure.bzl:415:18: function 'repository_rule' does not exist.

I suppose this is related to bazel. repository_rule is an experimental feature of bazel. What version of bazel is required to install 0.10? bazel is also painful to install to so we try to avoid upgrades as much as possible. This is very costly in terms of sys admin time.

verbose logs:

```
Do you wish to build TensorFlow with GPU support? [y/N] y
GPU support will be enabled for TensorFlow
Please specify which gcc should be used by nvcc as the host compiler. [Default is /global/software/Core/GCC/4.9.2-binutils-2.25/bin/gcc]: 
Please specify the Cuda SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 7.5.18
Please specify the location where CUDA 7.5.18 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: /global/software/Core/CUDA/7.5.18
Please specify the Cudnn version you want to use. [Leave empty to use system default]: 5.0
Please specify the location where cuDNN 5.0 library is installed. Refer to README.md for more details. [Default is /global/software/Core/CUDA/7.5.18]: /global/software/Core/cuDNN/5.0-CUDA-7.5.18
Invalid path to cuDNN  toolkit. Neither of the following two files can be found:
/global/software/Core/cuDNN/5.0-CUDA-7.5.18/lib64/libcudnn.so.5.0
/global/software/Core/cuDNN/5.0-CUDA-7.5.18/libcudnn.so.5.0
.5.0
Please specify the Cudnn version you want to use. [Leave empty to use system default]: 5   
Please specify the location where cuDNN 5 library is installed. Refer to README.md for more details. [Default is /global/software/Core/CUDA/7.5.18]: /global/software/Core/cuDNN/5.0-CUDA-7.5.18
Please specify a list of comma-separated Cuda compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size.
[Default is: ""3.5,5.2""]: 3.7
WARNING: Output base '~/.cache/bazel/_bazel_hidden/2a1b98729d2f817402a27341162b0ab6' is on NFS. This may lead to surprising failures and undetermined behavior.
.....................
INFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.
ERROR: ~/.cache/bazel/_bazel_hidden/2a1b98729d2f817402a27341162b0ab6/server (Directory not empty).
WARNING: Output base '~/.cache/bazel/_bazel_hidden/2a1b98729d2f817402a27341162b0ab6' is on NFS. This may lead to surprising failures and undetermined behavior.
..............
ERROR: ~/tensorflow_0.10/tensorflow/third_party/gpus/cuda_configure.bzl:415:18: function 'repository_rule' does not exist.
ERROR: com.google.devtools.build.lib.packages.BuildFileContainsErrorsException: error loading package 'external': Extension 'third_party/gpus/cuda_configure.bzl' has errors.
Configuration finished
```
### Environment info

Operating System: RHEL 6.7

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```
ls /global/software/Core/CUDA/7.5.18/lib/libcud*
/global/software/Core/CUDA/7.5.18/lib/libcudadevrt.a
/global/software/Core/CUDA/7.5.18/lib/libcudart.so
/global/software/Core/CUDA/7.5.18/lib/libcudart.so.7.5
/global/software/Core/CUDA/7.5.18/lib/libcudart.so.7.5.18
/global/software/Core/CUDA/7.5.18/lib/libcudart_static.a
```

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)

```
$ git rev-parse HEAD
6ce5b5c8298273e3861a75fb6ccde63b9dd157c5
```
1. The output of `bazel version`

bazel is 0.2.0 but `bazel version` doesn't seem to work...

```
$ bazel version
WARNING: Output base '~/.cache/bazel/_bazel_hidden/2a1b98729d2f817402a27341162b0ab6' is on NFS. This may lead to surprising failures and undetermined behavior.
Build target: bazel-out/local_linux-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Thu Jan 01 00:00:00 1970 (0)
Build timestamp: Thu Jan 01 00:00:00 1970 (0)
Build timestamp as int: 0
```
"
4107, While training first TensorFlow neural net model,"I build tensorflow for Mac OSX from sources following the Download and Setup guide from tensorflow.org. 

```
$ which python
/usr/local/bin/python
$ pip --version
pip 8.1.2 from /usr/local/lib/python2.7/site-packages (python 2.7)
```

Created the pip package and installed it with NO GPU support. 

```
$ bazel build -c opt //tensorflow/tools/pip_package:build_pip_package

$ bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg

# The name of the .whl file will depend on your platform.
$ sudo pip install /tmp/tensorflow_pkg/tensorflow-0.10.0rc0-py2-none-any.whl
```

When attempting to Train first neural net model from the root of the source tree:

```
$ cd tensorflow/models/image/mnist
$ python convolutional.py

Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

Traceback (most recent call last):
  File ""convolutional.py"", line 326, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/platform/default/_app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""convolutional.py"", line 243, in main
    batch = tf.Variable(0, dtype=data_type())

TypeError: __init__() got an unexpected keyword argument 'dtype'
```
"
4106,Feature request: ability to sample from seq2seq decoder given input,"Given some particular encoder input, it would be great to be able to sample sequences from the embedding_tied_rnn_seq2seq decoder. To my understanding, at present, this is possible with the tied_rnn_seqw2seq decoder, by passing in a custom loop_function, but it isn't possible in the embedding version. It appears that only argmax is supported with the feed_previous parameter. This would be useful in dialog/conversation applications, and perhaps others.

.
"
4105,ERROR: no such package '@local_config_cuda//crosstool': BUILD file not found on package path. ,"### Environment info

Operating System:
OS  10.10.5

Installed version of CUDA and cuDNN: 

```
$ ls -l /usr/local/cuda/lib/libcud*
-rwxr-xr-x  1 root           wheel      8280 Apr 13 01:02 /usr/local/cuda/lib/libcuda.dylib
lrwxr-xr-x  1 root           wheel        45 Apr 13 01:03 /usr/local/cuda/lib/libcudadevrt.a -> /Developer/NVIDIA/CUDA-7.5/lib/libcudadevrt.a
lrwxr-xr-x  1 root           wheel        50 Apr 13 01:03 /usr/local/cuda/lib/libcudart.7.5.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart.7.5.dylib
lrwxr-xr-x  1 root           wheel        46 Apr 13 01:03 /usr/local/cuda/lib/libcudart.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart.dylib
lrwxr-xr-x  1 root           wheel        49 Apr 13 01:03 /usr/local/cuda/lib/libcudart_static.a -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart_static.a
-rwxr-xr-x@ 1 production204  staff  60108616 Feb  8  2016 /usr/local/cuda/lib/libcudnn.4.dylib
lrwxr-xr-x  1 root           admin        47 Aug 29 18:08 /usr/local/cuda/lib/libcudnn.5.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudnn.5.dylib
lrwxr-xr-x  1 root           admin        45 Aug 29 18:08 /usr/local/cuda/lib/libcudnn.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudnn.dylib
-rw-r--r--@ 1 production204  staff  59311504 Feb  8  2016 /usr/local/cuda/lib/libcudnn_static.a
```
1. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`. 
   (can't get that far, but i'm using 0.10)

```
>>> import tensorflow
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.dylib locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.dylib locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.dylib locally
Segmentation fault: 11

```

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)

```
4c49dbebef05442c7e72d6129a30574fcd13f0e1
```
1. The output of `bazel version`

```
$ bazel version
Build label: 0.3.1-homebrew
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Thu Aug 4 09:59:58 2016 (1470304798)
Build timestamp: 1470304798
Build timestamp as int: 1470304798
```
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

```
$ bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer
ERROR: no such package '@local_config_cuda//crosstool': BUILD file not found on package path.
ERROR: no such package '@local_config_cuda//crosstool': BUILD file not found on package path.
INFO: Elapsed time: 0.076s

```
### What other attempted solutions have you tried?
- Downgrading to cuDNN4, switching between 4 and 5
- Re-installing bazel
- Modifying CROSSTOOL file according to various threads
- Manually linking CUDA libraries during `./configure` to not use symlinked libraries
- Various other hacks over the last week 😭
"
4104,Feature request: Tensor decomposition,"( Related to issue https://github.com/tensorflow/tensorflow/issues/2207 )

Tensors can be used for a whole lot more than implementing a NN. One of the useful operations in multidimensional arrays is its decomposition into smaller components. Tucker / CP native implementations would allow the use of tensorflow in other ML contexts...

refs: 
https://en.wikipedia.org/wiki/Tensor_rank_decomposition
https://en.wikipedia.org/wiki/Higher-order_singular_value_decomposition
"
4103,Build failure while following TensorFlow from source following TF documentation,"### Problem

TensorFlow build  of the pip package with CUDA support using the following command, taken from the [TensorFlow documentation](https://www.tensorflow.org/versions/r0.10/get_started/os_setup.html#installing-from-sources), fails:

`bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package`
### Error message

```
/usr/include/string.h: In function 'void* __mempcpy_inline(void*, const void*, size_t)':
/usr/include/string.h:652:42: error: 'memcpy' was not declared in this scope
   return (char *) memcpy (__dest, __src, __n) + __n;
                                          ^
ERROR: /home/marek/src/tensorflow/tensorflow/contrib/rnn/BUILD:63:1: output 'tensorflow/contrib/rnn/_objs/python/ops/_gru_ops_gpu/tensorflow/contrib/rnn/kernels/gru_ops_gpu.cu.pic.o' was not created.
ERROR: /home/marek/src/tensorflow/tensorflow/contrib/rnn/BUILD:63:1: not all outputs were created.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
```
### Environment
- OS: Ubuntu 16.04 (64-bit)
- CUDA 8.0
- GCC 4.9.3
- Java 1.8 (r101_b13)
- Python 2.7.12 (Anaconda 4.1.1)
- Bazel 0.3.1
### Related problems for CUDA-based frameworks reported on StackOverflow and Github

https://github.com/tensorflow/tensorflow/issues/1346
https://github.com/torch/torch7/issues/670
https://github.com/BVLC/caffe/issues/4046
https://github.com/opencv/opencv/issues/6500
### Solutions tried (none of them worked)
- downgrading to CUDA 7.5 and CUDNN 4
- changing downgrading and upgrading GCC away from 4.9.3
- changing GCC and cmake options to include `-D_FORCE_INLINES` flag (see related Github issues above)
### Solution that worked

Build succeeds when the `-c opt` option is removed from the Bazel build command. That is, the final command should be

`bazel build --config=cuda //tensorflow/tools/pip_package:build_pip_package`
"
4102,ImportError: cannot import name pywrap_tensorflow,"I have upgraded `protobuf` as explained: `Successfully installed protobuf-3.0.0 setuptools-26.1.1`

Then

``` shell
admin@macbookproloreto:~$ python
Python 2.7.10 (default, Oct 23 2015, 19:19:21) 
[GCC 4.2.1 Compatible Apple LLVM 7.0.0 (clang-700.0.59.5)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/Library/Python/2.7/site-packages/tensorflow/__init__.py"", line 23, in <module>
    from tensorflow.python import *
  File ""/Library/Python/2.7/site-packages/tensorflow/python/__init__.py"", line 52, in <module>
    from tensorflow.core.framework.graph_pb2 import *
  File ""/Library/Python/2.7/site-packages/tensorflow/core/framework/graph_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2
  File ""/Library/Python/2.7/site-packages/tensorflow/core/framework/attr_value_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2
  File ""/Library/Python/2.7/site-packages/tensorflow/core/framework/tensor_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import tensor_shape_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2
  File ""/Library/Python/2.7/site-packages/tensorflow/core/framework/tensor_shape_pb2.py"", line 22, in <module>
    serialized_pb=_b('\n,tensorflow/core/framework/tensor_shape.proto\x12\ntensorflow\""z\n\x10TensorShapeProto\x12-\n\x03\x64im\x18\x02 \x03(\x0b\x32 .tensorflow.TensorShapeProto.Dim\x12\x14\n\x0cunknown_rank\x18\x03 \x01(\x08\x1a!\n\x03\x44im\x12\x0c\n\x04size\x18\x01 \x01(\x03\x12\x0c\n\x04name\x18\x02 \x01(\tB2\n\x18org.tensorflow.frameworkB\x11TensorShapeProtosP\x01\xf8\x01\x01\x62\x06proto3')
TypeError: __init__() got an unexpected keyword argument 'syntax'
>>> 
```
"
4101,Numerical issues with automatic matrix derivatives,"While it is my impression that automatic differentiation generally enjoys numerical stability, this does not seem to extend directly to complicated expressions involving matrix calculus. 
In particular, for objectives involving matrix inverses the error can grow disproportionately large, leading to e.g. scipy optimization routines failing to converge. 
In my case I see TF with absolute element-wise gradient errors (comparing to the numerical Jacobian from tf.test.compute_gradient) around 10e-4 when my analytical gradient (also written using TF, only explicitly) gets errors near 10e-15. 
The problem likely boils down to the TF graph computing the inverses naively and not exploiting e.g. Cholesky and/or triangle structure or reframing multiplications as more stable linear system solves.

I'm not sure I can readily provide a MWE as the code is somewhat complicated, but it is basically Gaussian process regression with a heavily parameterized kernel function. 
The objective itself has a form similar to what is found in the snippet below, with the callable instance `kernel` holding several tuneable parameters. 

```
   #kernel computations
    self.K = self.kernel(self.Xtrain) + self.kernel.diag(self.Xtrain) + self.kernel.noise(self.Xtrain)  +    self.kernel.jitter(Xtrain)
    self.Ktest = self.kernel(self.Xtest) + self.kernel.noise(self.Xtest)  + self.kernel.jitter(self.Xtest)
    self.Kx = self.kernel(self.Xtrain, self.Xtest)
    self.L = tf.cholesky(self.K)

    self.Ly = tf.matrix_triangular_solve(self.L, self.ytrain, lower = True)
    self.LKx = tf.matrix_triangular_solve(self.L, self.Kx, lower = True)
    self.llk = -0.5*tf.reduce_sum(self.Ly**2.) - 0.5*logdet_chol(self.L) 
    self.objective = - self.llk
```

Continued matrix calculus support was one of the primary reasons I picked TF over the alternatives, so I am really hoping this is something that can be fixed in the future.
"
4100,About tf.slim ，Any plan to release pretrained checkpoint?,"About tf.contrib. slim ，Any plan to release pretrained checkpoint?
"
4099,Build Error Keeps Coming,"vyraun@vyraun:~/tensorflow$ bazel build //tensorflow/examples/android:tensorflow_demo
WARNING: Bazel Android NDK crosstools are based on Android NDK revision 11. The revision of the Android NDK given in android_ndk_repository rule 'androidndk' is '12.1.2977051'.
WARNING: /home/vyraun/tensorflow/tensorflow/core/BUILD:646:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/debug:debug_graph_utils.cc' directly. You should either move the file to this package or depend on an appropriate rule there.
WARNING: /home/vyraun/tensorflow/tensorflow/core/BUILD:646:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/debug:debug_graph_utils.h' directly. You should either move the file to this package or depend on an appropriate rule there.
WARNING: /home/vyraun/tensorflow/tensorflow/core/BUILD:646:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:avgpooling_op.h' directly. You should either move the file to this package or depend on an appropriate rule there.
WARNING: /home/vyraun/tensorflow/tensorflow/core/BUILD:646:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:bounds_check.h' directly. You should either move the file to this package or depend on an appropriate rule there.
WARNING: /home/vyraun/tensorflow/tensorflow/core/BUILD:646:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_activations.h' directly. You should either move the file to this package or depend on an appropriate rule there.
WARNING: /home/vyraun/tensorflow/tensorflow/core/BUILD:646:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_attention.h' directly. You should either move the file to this package or depend on an appropriate rule there.
WARNING: /home/vyraun/tensorflow/tensorflow/core/BUILD:646:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_backward_cuboid_convolutions.h' directly. You should either move the file to this package or depend on an appropriate rule there.
WARNING: /home/vyraun/tensorflow/tensorflow/core/BUILD:646:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_backward_spatial_convolutions.h' directly. You should either move the file to this package or depend on an appropriate rule there.
WARNING: /home/vyraun/tensorflow/tensorflow/core/BUILD:646:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_cuboid_convolution.h' directly. You should either move the file to this package or depend on an appropriate rule there.
WARNING: /home/vyraun/tensorflow/tensorflow/core/BUILD:646:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_patch_3d.h' directly. You should either move the file to this package or depend on an appropriate rule there.
WARNING: /home/vyraun/tensorflow/tensorflow/core/BUILD:646:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_pooling.h' directly. You should either move the file to this package or depend on an appropriate rule there.
WARNING: /home/vyraun/tensorflow/tensorflow/core/BUILD:646:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_softmax.h' directly. You should either move the file to this package or depend on an appropriate rule there.
WARNING: /home/vyraun/tensorflow/tensorflow/core/BUILD:646:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_spatial_convolutions.h' directly. You should either move the file to this package or depend on an appropriate rule there.
WARNING: /home/vyraun/tensorflow/tensorflow/core/BUILD:646:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:maxpooling_op.h' directly. You should either move the file to this package or depend on an appropriate rule there.
WARNING: /home/vyraun/tensorflow/tensorflow/core/BUILD:646:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:ops_util.cc' directly. You should either move the file to this package or depend on an appropriate rule there.
WARNING: /home/vyraun/tensorflow/tensorflow/core/BUILD:646:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:ops_util.h' directly. You should either move the file to this package or depend on an appropriate rule there.
WARNING: /home/vyraun/tensorflow/tensorflow/core/BUILD:646:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:pooling_ops_common.cc' directly. You should either move the file to this package or depend on an appropriate rule there.
WARNING: /home/vyraun/tensorflow/tensorflow/core/BUILD:646:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:pooling_ops_common.h' directly. You should either move the file to this package or depend on an appropriate rule there.
WARNING: /home/vyraun/tensorflow/tensorflow/core/BUILD:646:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_entry.h' directly. You should either move the file to this package or depend on an appropriate rule there.
WARNING: /home/vyraun/tensorflow/tensorflow/core/BUILD:646:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_scorer.h' directly. You should either move the file to this package or depend on an appropriate rule there.
WARNING: /home/vyraun/tensorflow/tensorflow/core/BUILD:646:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_search.h' directly. You should either move the file to this package or depend on an appropriate rule there.
WARNING: /home/vyraun/tensorflow/tensorflow/core/BUILD:646:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_decoder.h' directly. You should either move the file to this package or depend on an appropriate rule there.
WARNING: /home/vyraun/tensorflow/tensorflow/core/BUILD:646:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_loss_util.h' directly. You should either move the file to this package or depend on an appropriate rule there.
INFO: Found 1 target...
ERROR: missing input file '@androidsdk//:build-tools/23.0.1/aapt'.
ERROR: /home/vyraun/.cache/bazel/_bazel_vyraun/b219210c52a294104956e4ed70d84022/external/androidsdk/BUILD:5:1: @androidsdk//:aapt_binary: missing input file '@androidsdk//:build-tools/23.0.1/aapt'.
Target //tensorflow/examples/android:tensorflow_demo failed to build
Use --verbose_failures to see the command lines of failed build steps.
ERROR: /home/vyraun/.cache/bazel/_bazel_vyraun/b219210c52a294104956e4ed70d84022/external/androidsdk/BUILD:5:1 1 input file(s) do not exist.
INFO: Elapsed time: 2.821s, Critical Path: 0.03s
vyraun@vyraun:~/tensorflow$ bazel clean
INFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.
vyraun@vyraun:~/tensorflow$ bazel build //tensorflow/examples/android:tensorflow_demo
ERROR: no such package '@androidndk//': Could not read RELEASE.TXT in Android NDK: /home/vyraun/.cache/bazel/_bazel_vyraun/b219210c52a294104956e4ed70d84022/external/androidndk/ndk/RELEASE.TXT (No such file or directory).
ERROR: no such package '@androidndk//': Could not read RELEASE.TXT in Android NDK: /home/vyraun/.cache/bazel/_bazel_vyraun/b219210c52a294104956e4ed70d84022/external/androidndk/ndk/RELEASE.TXT (No such file or directory).
INFO: Elapsed time: 2.406s

I tried changing the api levels in workspace. Didn't work. I do not have any folder for 23.0.1 in my build-tools directory. I guess there is some configuration issue. How could I resolve them? Thanks for your help.
"
4098,breakpoints not working in tf_ios_makefile_example,"### Environment info

Operating System: OS X El Capitan
Xcode v7.3.1
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

I'm able to build and the run the tf_ios_makefile_example according to https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/ios_examples but while debugging the app, the breakpoints I set in the app (RunModelViewController.mm even in AppDelegate.mm) doesn't work - NSLog statements next to the breakpoints work fine. 

Anyone has the problem? Any solutions or ideas? Thanks!
### What other attempted solutions have you tried?

I verified new Xcode project or other existing Xcode projects work fine with pause at set breakpoints. I also Googled ""xcode 7 breakpoints not working"" but didn't see helpful info. I noticed 
the line CFLAGS=""-DNDEBUG..."" in compile_ios_protobuf.sh but am not sure if it's the cause.
"
4097,tf.nn.log_poisson_loss missing from tf.nn,"On Ubuntu 14.04: pip freeze is

```
funcsigs==1.0.2
mock==2.0.0
numpy==1.11.1
pbr==1.10.0
protobuf==3.0.0b2
six==1.10.0
tensorflow==0.10.0rc0
```

Trying to import tf.nn.log_poisson_loss fails

```
>>> import tensorflow as tf
>>> 'log_poisson_loss' in tf.nn.__dict__
False
>>> tf.nn.log_poisson_loss(tf.constant(1), tf.constant(1))
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
AttributeError: 'module' object has no attribute 'log_poisson_loss'
```

Looking at the source, it looks fine to me, not sure why it's missing. 
"
4095,How to use pre-trained word embeddings in seq2seq?,"I am building a seq2seq model using functions in seq2seq.py, where they have a function like this:

```
embedding_rnn_seq2seq(encoder_inputs, decoder_inputs, cell,
                          num_encoder_symbols, num_decoder_symbols,
                          embedding_size, output_projection=None,
                          feed_previous=False, dtype=dtypes.float32,
                          scope=None)
```

however, it seems that this function does not take pre-trained embeddings as input, are there any ways that I can take pre-trained word embeddings as input in this function?
"
4094,"Queue operation in conditional execution context fails with ""operation has been marked as not fetchable""","Hey TensorFlow Community,
a while ago I wrote some code for doing gradient descent in a distributed environment. I adapted code from `tensorflow/tensorflow/python/training/sync_replicas_optimizer.py` and wrote my own `apply_gradients` method. Crucially, I included a conditional op, that either performed (distributed, synchronised) gradient descent or returned the `apply_gradients` op from the original optimizer. 
This code worked well when I used it with TensorFlow 0.8, but it broke with 0.9 and is still broken in my current installation from source (see below). The QueueRunner that is responsible for the synchronization op between the workers now fails with the error message ""operation has been marked as not fetchable"".
A bit of searching in the execution stack led me to the lines 
`if self._control_flow_context is not None:`
      `self._control_flow_context.AddOp(self)`
in `tensorflow/tensorflow/python/framework/ops.py`
from which I take that the error comes from the fact that the queue operations are placed inside the conditional execution context. 

Out of curiosity: What is the idea behind ""fetchable"" ops - and why should enqueuing and dequeueing be ""dangerous to fetch""? 

Any help would be appreciated!

Matthias
### Environment info

Operating System: 
Distributor ID: LinuxMint
Description:    Linux Mint 17.2 Rafaela
Release:    17.2
Codename:   rafaela

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

cuda/lib64/libcudadevrt.a
cuda/lib64/libcudart.so -> libcudart.so.8.0
cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.27
cuda/lib64/libcudart.so.8.0.27
cuda/lib64/libcudart_static.a
cuda/lib64/libcudnn.so
cuda/lib64/libcudnn.so.5
cuda/lib64/libcudnn.so.5.1.5
cuda/lib64/libcudnn_static.a
If installed from binary pip package, provide:

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)
   `57ff9d9be2f1faaba9598a3d99ef6c3af02342a4`
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
### What other attempted solutions have you tried?

Removing the conditional execution clause removes the error
### Logs or other output that would be helpful

(If logs are large, please upload as attachment or provide link).
"
4093,While running test cases of SVHN data using Tensor Flow I get Resource exhausted : OOM when allocating tensor with shapedim { size: 73257 } dim { size: 32 } dim { size: 32 } dim { size: 32 },"groove@groove-VirtualBox:~/Udacity-Nanodegree-Project5-Capstone$ python Capstone-project.py
(32, 32, 3, 26032)
(26032, 1)
(32, 32, 3, 73257)
(73257, 1)
(26032, 32, 32, 3)
(73257, 32, 32, 3)
I tensorflow/core/common_runtime/local_device.cc:25] Local device intra op parallelism threads: 4
I tensorflow/core/common_runtime/local_session.cc:45] Local session inter op parallelism threads: 4
started at :  2016-08-29 19:06:23.180157
Exception AssertionError: AssertionError() in <bound method InteractiveSession.__del__ of <tensorflow.python.client.session.InteractiveSession object at 0x7f4db351d690>> ignored
step 0, training accuracy 0.109375
step 250, training accuracy 0.328125
step 500, training accuracy 0.640625
step 750, training accuracy 0.6875
step 1000, training accuracy 0.6875
step 1250, training accuracy 0.8125
step 1500, training accuracy 0.8125
step 1750, training accuracy 0.828125
W tensorflow/core/kernels/conv_ops.cc:162] Resource exhausted: OOM when allocating tensor with shapedim { size: 73257 } dim { size: 32 } dim { size: 32 } dim { size: 32 }
W tensorflow/core/common_runtime/executor.cc:1027] 0x3399fd0 Compute status: Resource exhausted: OOM when allocating tensor with shapedim { size: 73257 } dim { size: 32 } dim { size: 32 } dim { size: 32 }
     [[Node: Conv2D = Conv2D[T=DT_FLOAT, padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/cpu:0""](Reshape, Variable)]]
Traceback (most recent call last):
  File ""Capstone-project.py"", line 272, in <module>
    x: testDataX, y_:testDataY , keep_prob: 1.0}))
  File ""/home/groove/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 405, in eval
    return _eval_using_default_session(self, feed_dict, self.graph, session)
  File ""/home/groove/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2728, in _eval_using_default_session
    return session.run(tensors, feed_dict)
  File ""/home/groove/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 345, in run
    results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)
  File ""/home/groove/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 419, in _do_run
    e.code)
tensorflow.python.framework.errors.ResourceExhaustedError: OOM when allocating tensor with shapedim { size: 73257 } dim { size: 32 } dim { size: 32 } dim { size: 32 }
     [[Node: Conv2D = Conv2D[T=DT_FLOAT, padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/cpu:0""](Reshape, Variable)]]
Caused by op u'Conv2D', defined at:
  File ""Capstone-project.py"", line 150, in <module>
    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)
  File ""Capstone-project.py"", line 117, in conv2d
    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')
  File ""/home/groove/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 207, in conv2d
    use_cudnn_on_gpu=use_cudnn_on_gpu, name=name)
  File ""/home/groove/local/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py"", line 633, in apply_op
    op_def=op_def)
  File ""/home/groove/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1710, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/home/groove/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 988, in __init__
    self._traceback = _extract_stack()

groove@groove-VirtualBox:~/Udacity-Nanodegree-Project5-Capstone$ 
"
4092,the learning_rate became nan in seq2seq model,"I use the seq2seq provided by tensorflow, a very curious problem is that the learning_rate will become nan only when the length of the bucket is more than 40 with 4 layers.
The learning_rate should be decaied and more and more smaller, why it will became nan?
The init learning_rate is 0.01 and the learning_rate_decay_factor is 0.5
The training data is nist
The training is in a centos with four K40 together.
"
4091,Add TF_AllocateTensor to version 0.10,"Recently there was [added](https://github.com/tensorflow/tensorflow/commit/ae7b1310c5b2bbb333191d0def7985202dee382a) a very useful function to the C API—namely, `TF_AllocateTensor`. Currently the commit is not present on branch `r0.10`. I’m wondering if it’s possible to cherry-pick the commit to `r0.10` so that the function is available already in version 0.10. Thank you.

Regards,
Ivan 
"
4090,Make CUDA library version numbers available from python,"Hi!

Is it possible to make the versions of the CUDA libraries available as a python variable? Currently, after importing, there is the following output:

```
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so.5.1.5 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so.8.0 locally
```

So apparently the versioning information is loaded, I just couldn't find an API to access it.

I would like to record the CUDA as meta-information along with my checkpoint and event files, to be able to 100% reproduce any runs.
"
4089,Bake TF git commit hash into TensorFlow build,"Hi, is it possible to record the Git commit hash, when building from source and making it available as a variable?

Currently, there is only 

`tensorflow.__version__`

which is nice, but with a fast-moving codebase is not quite granular enough. Something like 

`tensorflow.__commit__` would make each build uniquely identifiable which is important for me to produce reproducible runs.
"
4086,Exception when restore DNN model,"I am using skflow of tensorflow(0.10.0rc0), I create a TensorFlowDNNRegressor model and saved to local, when I try to restore it gives me exception:
new_regressor = skflow.TensorFlowEstimator.restore('/Users/yichen.wei/Desktop/xiaoxiang_ml/model') File ""/Users/yichen.wei/project/vscienv/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/base.py"", line 326, in restore raise ValueError(""Restore folder doesn't contain model definition."").

Then I add a file model.def to my model directory and restore again it gives me
new_regressor = skflow.TensorFlowEstimator.restore('/Users/yichen.wei/Desktop/xiaoxiang_ml/model') File ""/Users/yichen.wei/project/vscienv/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/base.py"", line 331, in restore model_def = json.loads(fmodel.read()) File ""/usr/local/Cellar/python3/3.5.2/Frameworks/Python.framework/Versions/3.5/lib/python3.5/json/**init**.py"", line 319, in loads return _default_decoder.decode(s) File ""/usr/local/Cellar/python3/3.5.2/Frameworks/Python.framework/Versions/3.5/lib/python3.5/json/decoder.py"", line 339, in decode obj, end = self.raw_decode(s, idx=_w(s, 0).end()) File ""/usr/local/Cellar/python3/3.5.2/Frameworks/Python.framework/Versions/3.5/lib/python3.5/json/decoder.py"", line 357, in raw_decode raise JSONDecodeError(""Expecting value"", s, err.value) from None json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

It seems need json model definition in model.def file but it didn't create when saving.
Could someone help with this issue? Thanks!

PS: dir of saved model :
checkpoint
events.out.tfevents
graph.pbtxt
model.ckpt-xxxx-xxxxx-of-xxxxx
model.ckpt-xxxx.meta

env: 
OS X EI Capitan 10.11.6
Python: 3.5.2
tensorflow: 0.10.0rc0
"
4085,Building Issue: Is it possible to download everything before building from source?,"I am trying to build Tensorflow from source on Ubuntu 16.04 with CUDA 8.0 and CUDNN 5.

However, since I am blocked by the firewall, I encountered a bunch of network issues after running `./configure`, for example:

`ERROR: /home/icstpie/lbf/tensorflow/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@iron_form_element_behavior//': Error cloning repository: https://github.com/polymerelements/iron-form-element-behavior.git: cannot open git-upload-pack caused by https://github.com/polymerelements/iron-form-element-behavior.git: cannot open git-upload-pack caused by Connection refused github.com and referenced by '//tensorflow/tensorboard/bower:bower'.`
`
ERROR: /home/icstpie/lbf/tensorflow/tensorflow/core/platform/default/build_config/BUILD:56:1: no such package '@gif_archive//': Error downloading from http://ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz to /home/icstpie/.cache/bazel/_bazel_root/2510eb67c1daed69b89d219166d8dadf/external/gif_archive: Error downloading http://ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz to /home/icstpie/.cache/bazel/_bazel_root/2510eb67c1daed69b89d219166d8dadf/external/gif_archive/giflib-5.1.4.tar.gz: Expected 721KB, got 294KB and referenced by '//tensorflow/core/platform/default/build_config:platformlib'.`
`
ERROR: Evaluation of query ""deps((//... union @bazel_tools//tools/jdk:toolchain))"" failed: errors were encountered while computing transitive closure.`

I think these errors are caused by the command `bazel fetch //...` in the configure file.

Since bazel ignores the proxy environment LD_PRELOAD, I'm wondering that if I can manually download these things with my proxy and put them somewhere so that bazel can find them? I've tried putting the protobuf repository (the first thing bazel will download) in the root directory of tensorflow but bazel still tries to download it anyway.

I'm not sure if there is any workaround to use proxy with bazel. However, since my GPU server has a slow network and I can use faster network elsewhere, it will be nice if I can download these things manually instead of running `bazel fetch //...` on my server.
"
4084,Process hanging when using TF_SessionRun with multiple times the same input,"It seems that if the same input appears multiple times in the inputs argument of TF_SessionRun (from c_api.h) then the TF_SessionRun call never returns.
This issue can be reproduced by modifying c_api_test.cc and replacing the line:
   csession.SetInputs({{feed, Int32Tensor(3)}});
With:
   csession.SetInputs({{feed, Int32Tensor(3)}, {feed, Int32Tensor(3)}});
According to gdb, the process is waiting for a mutex in the RunState destructor from DirectSession.
### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

none
### Environment info

Operating System: Linux 4.4

Installed version of CUDA and cuDNN: none

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)
   008bcaea38815f46804fc3f56492f4dd93837a56
2. The output of `bazel version`
   Build label: 0.3.1
   Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
   Build time: Fri Jul 29 09:09:52 2016 (1469783392)
   Build timestamp: 1469783392
   Build timestamp as int: 1469783392
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

See above.
### What other attempted solutions have you tried?
### Logs or other output that would be helpful

(If logs are large, please upload as attachment or provide link).
"
4083,ar,"NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
### Environment info

Operating System:

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
### What other attempted solutions have you tried?
### Logs or other output that would be helpful

(If logs are large, please upload as attachment or provide link).
"
4081,Error while running CIFAR-10 example from the site.,"When I run the CIFAR-10 code from [https://www.tensorflow.org/versions/r0.10/tutorials/deep_cnn/index.html#convolutional-neural-networks](here) I get the error
 `argparse.ArgumentError: argument --batch_size: conflicting option string: --batch_size`

I didn't modify anything in the code. Just ran the code with `python cifar10.py`  after cloning the tensorflow repo. Python version is 3.5 , and tensorflow version  0.10.0rc0
"
4079,LeakyReLU uses up too much memory.,"Right now I am implementing leaky relus like this tf.maximum(0.1 \* x, x).  This works fine except when it comes to memory usage.  Networks which will fit on my GPU when using tf.nn.relu or tf.nn.elu fail when I am using my leaky relu implementation.  I think this is because it needs to store both the intermediate 0.1 \* x and x values of the activations to compute the gradients which essentially does the memory usage.  However, I do not think this would be an issue if there were a dedicated tf.nn.leaky_relu.  Can someone consider adding this to a future tensorflow release.
"
4078,Installation Issue:  Couldn't open CUDA library libcuda.so.1.,"In the step where I have to run
`bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu`
I get the following messages:
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so.7.0 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so.7.0 locally
I tensorflow/stream_executor/dso_loader.cc:102] Couldn't open CUDA library libcuda.so.1. LD_LIBRARY_PATH:...
...
...
...
failed to find libcuda.so on this system: Failed precondition: could not dlopen DSO: libcuda.so.1; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
...
...
...
E tensorflow/stream_executor/cuda/cuda_driver.cc:491] failed call to cuInit: CUDA_ERROR_NO_DEVICE
...
...
...
I tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No GPU devices available on machine.
### Environment info

Operating System: Debian 8

Installed version of CUDA and cuDNN: CUDA 7.0, cuDNN 4.0.7
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
/usr/local/cuda/lib/libcudadevrt.a
/usr/local/cuda/lib/libcudart.so -> libcudart.so.7.0
/usr/local/cuda/lib/libcudart.so.7.0 -> libcudart.so.7.0.28
/usr/local/cuda/lib/libcudart.so.7.0.28
/usr/local/cuda/lib/libcudart_static.a
1. The commit hash (`git rev-parse HEAD`) 
   `554ddd9ad2d4abad5a9a31f2d245f0b1012f0d10`
2. The output of `bazel version`
   Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
   Build time: Thu Jan 01 00:00:00 1970 (0)
   Build timestamp: Thu Jan 01 00:00:00 1970 (0)
   Build timestamp as int: 0

P.S. I have two GPUs installed on my server. One is used for GUI (AMD) and the other is used for computation (NVIDIA).
Should I do anything to make sure the second GPU is being used?
"
4076,"Gradients error when using while_loop: ""ValueError: None values not supported""","Working on Tensorflow version 0.10, I am getting the following error when using `tf.gradients`:

```
.../python2.7/site-packages/tensorflow/python/ops/gradients.py"", line 478, in gradients
...
.../python2.7/site-packages/tensorflow/python/framework/tensor_util.py"", line 346, in make_tensor_proto
    raise ValueError(""None values not supported."")
```

The error occurs due to the use of the function `tf.while_loop` . When I turn off its use, the gradients are calculated with no error.

A similar issue was related to in https://github.com/tensorflow/tensorflow/issues/783, but I can't fix the error using the suggested solutions.
"
4075,Error while using makefile,"Hello. I  tried to us TF using the method described [here](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile)  on Linux. 

After installin protobuf ( as instructed),  I get these two errors after using the last command ( make -f tensorflow/contrib/makefile/Makefile) 

> tensorflow/core/util/example_proto_fast_parsing.cc:177:38: error: invalid conversion from ‘tensorflow::uint64\* {aka long long unsigned int_}’ to ‘google::protobuf::uint64_ {aka long unsigned int_}’ [-fpermissive]
>            if (!stream.ReadVarint64(&n)) return false;
> and
> tensorflow/core/util/example_proto_fast_parsing.cc:186:38: error: invalid conversion from ‘tensorflow::uint64_ {aka long long unsigned int_}’ to ‘google::protobuf::uint64_ {aka long unsigned int*}’ [-fpermissive]
>            if (!stream.ReadVarint64(&n)) return false;

BTW: the commit hash I am using is: f9ae4fe749c5d7dbf1851cffc94730086e588c35
and CUDA isn't installed. 
"
4074,Gradients Not Being Computed Correctly While Using tf.contrib.distributions.Categorical,"Hello, there appears to be an issue with how TensorFlow gradients are being computed while using Categorical in the graph.  In particular, let's say we were computing the gradient through a single logit of a vector, we would expect only the corresponding column of the weight matrix affecting that logit value to update with gradients. This is indeed the case when I keep this index fixed, say `tf.constant(0, dtype=tf.int32)`, however, this is not the case while using Categorical.  The code below should clarify further.

Thanks!
Liam
### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

I have not found this particular bug in a quick search.
### Environment info

Operating System:  Ubuntu 14.04.4 LTS

Installed version of CUDA and cuDNN:  
-rw-r--r-- 1 root root 189170 Mar 17 17:29 /usr/local/cuda/lib/libcudadevrt.a
lrwxrwxrwx 1 root root     16 Mar 17 17:29 /usr/local/cuda/lib/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root     19 Mar 17 17:29 /usr/local/cuda/lib/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root 311596 Mar 17 17:29 /usr/local/cuda/lib/libcudart.so.7.5.18
-rw-r--r-- 1 root root 558020 Mar 17 17:29 /usr/local/cuda/lib/libcudart_static.a

TensorFlow from source.
1.  Commit hash:  1b50845ff01200b3f6fc78a2780df49baea674ff
2.  bazel version:

Build label: 0.2.2b
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Mon Apr 25 08:08:53 2016 (1461571733)
Build timestamp: 1461571733
Build timestamp as int: 1461571733
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

```
import tensorflow as tf
from tensorflow.contrib.distributions import Categorical
tf.reset_default_graph()

input_dim = 3
hidden_dim = 5
output_dim = 3
lr = 1e-1
num_iterations = 50
print_every = 1

x = tf.fill([1, input_dim], 1.)
y = tf.fill([1, output_dim], 1.)

with tf.name_scope('Model'):
    W_gen = tf.Variable(tf.random_uniform([input_dim, hidden_dim]), name = 'W_gen')
    logits = tf.matmul(x, W_gen)

    sample_op = tf.stop_gradient(Categorical(logits).sample(n=1))
    index = tf.squeeze(sample_op)
    one_hot = tf.one_hot(index, hidden_dim, dtype = tf.float32)
    logits = logits * one_hot

    W_dis = tf.Variable(tf.random_uniform([hidden_dim, output_dim]), name = 'W_dis')
    output = tf.matmul(logits, W_dis)


with tf.name_scope('Loss'):
    loss_op = tf.reduce_mean(tf.squared_difference(output, y))

with tf.name_scope('Train'):
    train_vars = [W_gen]
    train_op = tf.train.AdamOptimizer(lr).minimize(loss_op, var_list = train_vars)


with tf.Session() as sess:
    init_op = tf.initialize_all_variables()
    sess.run(init_op)

    for i in xrange(num_iterations):
        if i % print_every == 0:
            print('Loss at iteration %d: %f' % (i, sess.run(loss_op)))
            print('Sample: [%d]' % sess.run(index))
            print sess.run(W_gen)
        sess.run(train_op)
    print sess.run(output)
```
### Logs or other output that would be helpful

Here I show you the Sample generated by Categorical and then the corresponding change to the weight matrix.  Notice, that the first training step operates as expected, only the '1th' column is affected. 

However, the second training step both column 1 and 2 change.  

```
Sample: [1]
[[ 0.81418228  0.8655349   0.16064     0.55864608  0.35103011]
 [ 0.26089203  0.69035411  0.64020491  0.02805829  0.99758911]
 [ 0.56620026  0.52124786  0.23499095  0.59907818  0.44014001]]

Sample: [1]
[[ 0.81418228  0.76553494  0.16064     0.55864608  0.35103011]
 [ 0.26089203  0.59035414  0.64020491  0.02805829  0.99758911]
 [ 0.56620026  0.4212479   0.23499095  0.59907818  0.44014001]]

Sample: [0]
[[ 0.81418228  0.69852936  0.23505335  0.55864608  0.35103011]
 [ 0.26089203  0.52334857  0.71461827  0.02805829  0.99758911]
 [ 0.56620026  0.35424232  0.30940431  0.59907818  0.44014001]]
```
"
4073,Trouble running Tensorflow on Xcode 8 beta 5,"I get the following message, I don't know if this will be fixed in an upcoming version or if I need to add more configuration (it's running fine on the latest Xcode 7 though):

```
Undefined symbols for architecture arm64:
  ""_deflate"", referenced from:
      tensorflow::io::ZlibOutputBuffer::Deflate(int) in libtensorflow-core.a(zlib_outputbuffer.o)
  ""_inflate"", referenced from:
      tensorflow::io::ZlibInputBuffer::Inflate() in libtensorflow-core.a(zlib_inputbuffer.o)
  ""_deflateInit2_"", referenced from:
      tensorflow::io::ZlibOutputBuffer::ZlibOutputBuffer(tensorflow::WritableFile*, int, int, tensorflow::io::ZlibCompressionOptions const&) in libtensorflow-core.a(zlib_outputbuffer.o)
  ""_inflateEnd"", referenced from:
      tensorflow::io::ZlibInputBuffer::~ZlibInputBuffer() in libtensorflow-core.a(zlib_inputbuffer.o)
      tensorflow::io::ZlibInputBuffer::~ZlibInputBuffer() in libtensorflow-core.a(zlib_inputbuffer.o)
  ""_deflateEnd"", referenced from:
      tensorflow::io::ZlibOutputBuffer::Close() in libtensorflow-core.a(zlib_outputbuffer.o)
  ""_inflateInit2_"", referenced from:
      tensorflow::io::ZlibInputBuffer::ZlibInputBuffer(tensorflow::RandomAccessFile*, unsigned long, unsigned long, tensorflow::io::ZlibCompressionOptions const&) in libtensorflow-core.a(zlib_inputbuffer.o)
ld: symbol(s) not found for architecture arm64
clang: error: linker command failed with exit code 1 (use -v to see invocation)
```
"
4072,relatively slower performance on FCN,"according to the paper http://arxiv.org/abs/1608.07249,
TensorFlow is good at CNN and RNN, however relatively slower on FCN, is this because of using python loop to feed data each mini-batch? Can we solve this since FCN is always important in general use of Deep Learning like competitions in kaggle.

![image](https://cloud.githubusercontent.com/assets/11470826/18024624/9230e594-6c41-11e6-989e-f5a7ba9e927f.png)

![image](https://cloud.githubusercontent.com/assets/11470826/18024628/9e3ad430-6c41-11e6-91b9-89347dabc1ce.png)

![image](https://cloud.githubusercontent.com/assets/11470826/18024630/b0d5abd8-6c41-11e6-8584-877b5fa45d88.png)
"
4071,"""Default session has been garbage collected""","The following three lines give an error: ""RuntimeError: Default session has been garbage collected."" One line above the line that raises the RuntimeError, there's a comment saying ""This should never happen with the current session implementations."" Clearly, it did happen. The situation doesn't bother me greatly, and I'm only mentioning this because clearly something unintended happened here. 

import tensorflow as tf
with tf.Session().as_default():
    tf.get_default_session()

The following four lines do not give the error:

import tensorflow as tf
sess = tf.Session()
with sess.as_default():
    tf.get_default_session()

This suggests that the Session.as_default() method doesn't store <self> in any way that keeps it from being garbage collected.

NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

None.
### Environment info

Operating System:

Mac OS X 10.11.6

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

None.

If installed from binary pip package, provide:
1. A link to the pip package you installed: I don't recall the link; I installed following the standard installation instructions.
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

0.10.0rc0

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

See above.
### What other attempted solutions have you tried?

See above.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment or provide link).
"
4070,How to install tensorflow on the NVIDIA Jetson TK1 developer kit?,"We are trying to install tensorflow on the [NVIDIA Jetson TK1 developer kit](http://www.nvidia.com/object/jetson-tk1-embedded-dev-kit.html).

The platform has ..

a GPU
[Tegra-K1](http://www.nvidia.com/object/tegra-k1-processor.html)

a 64-bit ARM CPU
[NVIDIA 4-Plus-1™ Quad-Core ARM® Cortex™-A15 CPU](http://www.nvidia.com/docs/io/116757/nvidia_quad_a15_whitepaper_finalv2.pdf)

ubuntu 14
(Note: It originally came installed with a 32-bit version of ubuntu 14, but this caused problems so we installed the 64-bit version.)
64-bit version of ubuntu 14

```
ubuntu@tegra-ubuntu:~/grpc-java3/grpc-java$ java -version
java version ""1.8.0_101""
Java(TM) SE Runtime Environment (build 1.8.0_101-b13)
Java HotSpot(TM) 64-Bit Server VM (build 25.101-b13, mixed mode)

ubuntu@tegra-ubuntu:~/grpc-java3/grpc-java$ uname -a
Linux tegra-ubuntu 3.10.96-tegra #1 SMP PREEMPT Tue May 17 16:29:05 PDT 2016 aarch64 aarch64 aarch64 GNU/Linux

ubuntu@tegra-ubuntu:~/grpc-java3/grpc-java$ lsb_release -d
Description:    Ubuntu 14.04.5 LTS
ubuntu@tegra-ubuntu:~/grpc-java3/grpc-java$ 

ubuntu@tegra-ubuntu:~/grpc-java3/grpc-java$ ldconfig -p | grep cuda
    libicudata.so.52 (libc6,AArch64) => /usr/lib/aarch64-linux-gnu/libicudata.so.52
    libcuda.so.1 (libc6,AArch64) => /usr/lib/aarch64-linux-gnu/tegra/libcuda.so.1
    libcuda.so (libc6,AArch64) => /usr/lib/aarch64-linux-gnu/libcuda.so
    libcuda.so (libc6,AArch64) => /usr/lib/aarch64-linux-gnu/tegra/libcuda.so
```

Because it is an ARM processor rather than an X86 processor, we have to build from source.

The problem we are having is 
the tensorflow build requires the protoc plugin for gRPC Java
but we are having difficulties compiling the protoc plugin for gRPC Java on this platform.
the grpc-java team does not support arm64.
[they suggested editing the gradle script ...](https://github.com/grpc/grpc-java/issues/2202)

[We’re having problems trying to do so ...](https://discuss.gradle.org/t/tool-chain-gcc-gnu-gcc-dont-know-how-to-build-for-platform-linux-aarch64/19232)

Is there something we are missing?

It would be nice if it were a little easier to install tensorflow on this nvidia GPU device.
"
4067,GPU usage level and training speed is very different for different tensorflow version,"### Environment info

Operating System: Ubuntu 14.04, AWS g2.2xlarge

Installed version of CUDA and cuDNN:  CUDA 7.5, cuDNN 4

Tried 3 different version using pip package:
0.8.0:
sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl

0.9.0:
sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.9.0-cp27-none-linux_x86_64.whl

0.10.0 rc
sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

On the same machine, install different version of tf and run the [cifar10_train.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/cifar10/cifar10_train.py)
### Logs or other output that would be helpful

For version 0.8.0 and 0.9.0, the GPU usage is about 30%

```
+------------------------------------------------------+                       
| NVIDIA-SMI 352.99     Driver Version: 352.99         |                       
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GRID K520           Off  | 0000:00:03.0     Off |                  N/A |
| N/A   37C    P0    51W / 125W |   3854MiB /  4095MiB |     35%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0     16558    C   python                                        3841MiB |
+-----------------------------------------------------------------------------+
```

But the speed is about ~0.24 sec/batch for version 0.8.0 and ~0.22 sec/batch for version 0.9.0

```
2016-08-26 21:20:41.309814: step 230, loss = 4.28 (522.0 examples/sec; 0.245 sec/batch)
2016-08-26 21:20:43.625017: step 240, loss = 4.26 (582.3 examples/sec; 0.220 sec/batch)
2016-08-26 21:20:45.953772: step 250, loss = 4.24 (544.4 examples/sec; 0.235 sec/batch)
2016-08-26 21:20:48.302202: step 260, loss = 4.23 (540.1 examples/sec; 0.237 sec/batch)
2016-08-26 21:20:50.643760: step 270, loss = 4.21 (554.6 examples/sec; 0.231 sec/batch)
2016-08-26 21:20:52.955326: step 280, loss = 4.20 (545.6 examples/sec; 0.235 sec/batch)
2016-08-26 21:20:55.399758: step 290, loss = 4.18 (476.4 examples/sec; 0.269 sec/batch)
2016-08-26 21:20:57.825254: step 300, loss = 4.17 (548.0 examples/sec; 0.234 sec/batch)
2016-08-26 21:21:00.453533: step 310, loss = 4.15 (543.6 examples/sec; 0.235 sec/batch)
2016-08-26 21:21:02.876055: step 320, loss = 4.14 (513.9 examples/sec; 0.249 sec/batch)
2016-08-26 21:21:05.229421: step 330, loss = 4.13 (580.3 examples/sec; 0.221 sec/batch)
2016-08-26 21:21:07.614095: step 340, loss = 4.11 (528.6 examples/sec; 0.242 sec/batch)
```

---

For 0.10.0.rc0, the GPU usage is ~90％：

```
+------------------------------------------------------+                       
| NVIDIA-SMI 352.99     Driver Version: 352.99         |                       
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GRID K520           Off  | 0000:00:03.0     Off |                  N/A |
| N/A   35C    P0    46W / 125W |   3818MiB /  4095MiB |     90%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0     16702    C   python                                        3805MiB |
+-----------------------------------------------------------------------------+
```

But the speed is only ~0.34 sec/batch:

```
016-08-26 21:24:11.512601: step 30, loss = 4.38 (371.3 examples/sec; 0.345 sec/batch)
2016-08-26 21:24:14.875387: step 40, loss = 4.42 (379.0 examples/sec; 0.338 sec/batch)
2016-08-26 21:24:18.248093: step 50, loss = 4.27 (368.0 examples/sec; 0.348 sec/batch)
2016-08-26 21:24:21.609797: step 60, loss = 4.24 (379.8 examples/sec; 0.337 sec/batch)
2016-08-26 21:24:24.987058: step 70, loss = 4.25 (376.4 examples/sec; 0.340 sec/batch)
2016-08-26 21:24:28.387080: step 80, loss = 4.38 (381.0 examples/sec; 0.336 sec/batch)
2016-08-26 21:24:31.775519: step 90, loss = 4.18 (377.8 examples/sec; 0.339 sec/batch)
```
"
4066,retrying_file_system does not use exponential backoff,"In tensorflow-0.10.0rc0/tensorflow/core/platform/cloud/retrying_file_system.cc,
the retry logic does not insert a delay between successive attempts.

Status CallWithRetries(const std::function<Status()>& f) {
  int attempts = 0;
  while (true) {
    attempts++;
    auto status = f();
    if (!IsRetriable(status) || attempts >= kMaxAttempts) {
      return status;
    }
    LOG(ERROR) << ""The operation resulted in an error and will be retried: ""
               << status.ToString();
  }
}
"
4062,Tensorboard icons invisible when building from source,"The refresh, configure, and plot buttons (expand, log/linear) are not visible when building tensorboard from source. However, they are clickable.
<img width=""1438"" alt=""screen shot 2016-08-26 at 8 10 32 am"" src=""https://cloud.githubusercontent.com/assets/1794423/18010495/9a428d32-6b65-11e6-8f7f-23a490ae05fb.png"">
### Environment info

Build/execute operating System: Ubuntu 16.04
Viewing operating System: OS X 10.11.6
Viewing browsers: Chrome 52 & Safari 9.1.2
Installed from source from a recent master commit 99ce233191920fb0dde2d823cf493e28b89618c7
Bazel 0.3.0
### Steps to reproduce
1. git clone https://github.com/tensorflow/tensorflow.git
2. cd tensorflow
3. ./configure
4. bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer
5. pushd tensorflow/tensorboard
6. npm run prepare
7. npm run compile
8. gulp regenerate
9. popd
10. bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
11. bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg
12. pip install /tmp/tensorflow_pkg/tensorflow-0.10.0rc0-py3-none-any.whl
13. tensorboard
### What have you tried?
1. Building from r0.10 branch but it doesn't work either.
"
4060,Nightly binary links in README are broken.,"Following the links in the README. CPU-only builds work, but both Mac and Linux GPU builds return 404.
"
4059,"Building for iOs fails with ""ld: 44 duplicate symbols for architecture armv7"" error","Hi all,

Trying to build Tensorflow for [iOs.](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile#ios) The step `tensorflow/contrib/makefile/build_all_ios.sh` after around 20 minutes of building returns errors including `duplicate symbols for architecture armv7`. Please find the details bellow.
### Environment info

Operating System: Mac OS X 10.11.6 (15G31)
Xcode 7.3.1 (7D1014)
### Steps to reproduce

In terminal:
1. `git clone git@github.com:tensorflow/tensorflow.git`
2. `cd tensorflow`
3. `tensorflow/contrib/makefile/download_dependencies.sh`
4. `tensorflow/contrib/makefile/build_all_ios.sh`
### What have you tried?
1. Removing the repository directory and going through the steps again.
2. Going through ""Building by hand"" steps described [here](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile#building-by-hand). Error: `ld: 44 duplicate symbols for architecture armv7s` ([Error log](https://github.com/tensorflow/tensorflow/files/439452/tensorflow-error-log2.txt)).
### Error log ([Full log](https://github.com/tensorflow/tensorflow/files/439413/tensorflow-error-log.txt))

`...`
`ld: 44 duplicate symbols for architecture armv7`
`clang: error: linker command failed with exit code 1 (use -v to see invocation)`
`make: *** [/Users/b0915218/Xcode/tensorflow/tensorflow/contrib/makefile/gen/bin/ios_ARMV7/benchmark]` `Error 1`
`+ '[' 2 -ne 0 ']'`
`+ echo 'armv7 compilation failed.'`
`armv7 compilation failed.`
`+ exit 1`
"
4058,Use header include directories auto-detected from host compiler,"As mentioned by @akors in #2109 and #3980, we should generate `cxx_builtin_include_directory` entries for the header include directories used by the user's host compiler of choice rather than hard-coding them as we are currently doing.
"
4056,Adding more layers decreases model accuracy. ,"Here are two different reproducible codes, one has two conv layers and other has 10 conv layers. Model with two conv layers reaches the result in few iterations whereas model with 10 conv layers reaches the result in more iterations, and moreover they both produce same result 62.5 % accuracy. Model with 10 conv layers should provide better accuracy(because it has more layers) but it gives same accuracy as 2 conv layer model and reaches the same result after more iterations, so adding more layers is degrading performance.

 Here is 2 conv layer code:

```
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import tensorflow as tf
import numpy as np
import math
import os
import nltk
import random
batch_size = 100
start = 0
end = batch_size
learning_rate = 0.001
num_classes = 2
time_steps = 4
embedding = 2
step = 1
_units = 1
num_of_filters = 2

train_set_x = [[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]]]
train_set_y = [0,1,1,1,1,1,1,1,1,1,1,1,0,0,0,1,1,1,1,1,0,0,0,0,0,0,1,0,1,0,1,1,1,0,1,0,1,0,1,1]

X = tf.placeholder(tf.float32, [None,time_steps,embedding])
Y = tf.placeholder(tf.int32, [None])


x = tf.expand_dims(X,3)

filter_shape = [1, embedding, 1, 64]
conv_weights = tf.get_variable(""conv_weights1"" , filter_shape, tf.float32, tf.truncated_normal_initializer(mean=0.0, stddev=1.0))
conv_biases = tf.Variable(tf.constant(0.1, shape=[64]))
conv = tf.nn.conv2d(x, conv_weights, strides=[1,1,1,1], padding = ""VALID"")
normalize = tf.nn.elu(conv + conv_biases)
tf_normalize = tf.contrib.layers.batch_norm(inputs = normalize,is_training = True)
outputs_fed_lstm = tf_normalize

filter_shape2 = [1, 1, 64, 64]
conv_weights2 = tf.get_variable(""conv_weights2"" , filter_shape2, tf.float32,tf.truncated_normal_initializer(mean=0.0, stddev=1.0))
conv_biases2 = tf.Variable(tf.constant(0.1, shape=[64]))
conv2 = tf.nn.conv2d(outputs_fed_lstm, conv_weights2, strides=[1,1,1,1], padding = ""VALID"")
normalize2 = tf.nn.elu(conv2 + conv_biases2)
tf_normalize2 = tf.contrib.layers.batch_norm(inputs = normalize2,is_training = True)
outputs_fed_lstm2 = tf_normalize2

x = tf.squeeze(outputs_fed_lstm2, [2])     
x = tf.transpose(x, [1, 0, 2])
x = tf.reshape(x, [-1, 64])
x = tf.split(0, time_steps, x)

lstm = tf.nn.rnn_cell.LSTMCell(num_units = _units)

# multi_lstm = tf.nn.rnn_cell.MultiRNNCell([lstm] * lstm_layers, state_is_tuple = True)

outputs , state = tf.nn.rnn(lstm,x, dtype = tf.float32)     

weights = tf.Variable(tf.random_normal([_units,num_classes]))
biases  = tf.Variable(tf.random_normal([num_classes]))

logits = tf.matmul(outputs[-1], weights) + biases



c_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits,Y)
loss = tf.reduce_mean(c_loss)


global_step = tf.Variable(0, name=""global_step"", trainable=False)
# decayed_learning_rate = tf.train.exponential_decay(learning_rate,0,10000,0.9)
optimizer= tf.train.AdamOptimizer(learning_rate)
minimize_loss = optimizer.minimize(loss, global_step=global_step)   
#grads_and_vars = optimizer.compute_gradients(loss,[conv_weights2]) 
correct_predict = tf.nn.in_top_k(logits, Y, 1)
accuracy = tf.reduce_mean(tf.cast(correct_predict, tf.float32))


init = tf.initialize_all_variables()

with tf.Session() as sess:
     sess.run(init)
     for i in range(1000):
         for j in range(1000):
             x = train_set_x
             y = train_set_y
             sess.run(minimize_loss,feed_dict={X : x, Y : y})
             step += 1  
             #gr_print = sess.run([grad for grad, _ in grads_and_vars], feed_dict={X : x, Y : y})
             #print (gr_print)
             cost = sess.run(loss,feed_dict = {X: x,Y: y})
             accu = sess.run(accuracy,feed_dict = {X: x, Y: y})
             print (""Loss after one Epoch(Training) = "" + ""{:.6f}"".format(cost) + "", Training Accuracy= "" + ""{:.5f}"".format(accu))
```

Here is code for 10 layer conv model:

```
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import tensorflow as tf
import numpy as np
import math
import os
import nltk
import random
batch_size = 100
start = 0
end = batch_size
learning_rate = 0.001
num_classes = 2
time_steps = 4
embedding = 2
step = 1
_units = 100
num_of_filters = 2

train_set_x = [[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]]]
train_set_y = [0,1,1,1,1,1,1,1,1,1,1,1,0,0,0,1,1,1,1,1,0,0,0,0,0,0,1,0,1,0,1,1,1,0,1,0,1,0,1,1]

X = tf.placeholder(tf.float32, [None,time_steps,embedding])
Y = tf.placeholder(tf.int32, [None])


x = tf.expand_dims(X,3)

filter_shape = [1, embedding, 1, 64]
conv_weights = tf.get_variable(""conv_weights1"" , filter_shape, tf.float32, tf.truncated_normal_initializer(mean=0.0, stddev=1.0))
conv_biases = tf.Variable(tf.constant(0.1, shape=[64]))
conv = tf.nn.conv2d(x, conv_weights, strides=[1,1,1,1], padding = ""VALID"")
normalize = tf.nn.elu(conv + conv_biases)
tf_normalize = tf.contrib.layers.batch_norm(inputs = normalize,is_training = True)
outputs_fed_lstm = tf_normalize

filter_shape2 = [1, 1, 64, 64]
conv_weights2 = tf.get_variable(""conv_weights2"" , filter_shape2, tf.float32,tf.truncated_normal_initializer(mean=0.0, stddev=1.0))
conv_biases2 = tf.Variable(tf.constant(0.1, shape=[64]))
conv2 = tf.nn.conv2d(outputs_fed_lstm, conv_weights2, strides=[1,1,1,1], padding = ""VALID"")
normalize2 = tf.nn.elu(conv2 + conv_biases2)
tf_normalize2 = tf.contrib.layers.batch_norm(inputs = normalize2,is_training = True)
outputs_fed_lstm2 = tf_normalize2

filter_shape3 = [1, 1, 64, 64]
conv_weights3 = tf.get_variable(""conv_weights3"" , filter_shape3, tf.float32,tf.truncated_normal_initializer(mean=0.0, stddev=1.0))
conv_biases3 = tf.Variable(tf.constant(0.1, shape=[64]))
conv3 = tf.nn.conv2d(outputs_fed_lstm2, conv_weights3, strides=[1,1,1,1], padding = ""VALID"")
normalize3 = tf.nn.elu(conv3 + conv_biases3)
tf_normalize3 = tf.contrib.layers.batch_norm(inputs = normalize3,is_training = True)
outputs_fed_lstm3 = tf_normalize3

filter_shape4 = [1, 1, 64, 128]
conv_weights4 = tf.get_variable(""conv_weights4"" , filter_shape4, tf.float32,tf.truncated_normal_initializer(mean=0.0, stddev=1.0))
conv_biases4 = tf.Variable(tf.constant(0.1, shape=[128]))
conv4 = tf.nn.conv2d(outputs_fed_lstm3, conv_weights4, strides=[1,1,1,1], padding = ""VALID"")
normalize4 = tf.nn.elu(conv4 + conv_biases4)
tf_normalize4 = tf.contrib.layers.batch_norm(inputs = normalize4,is_training = True)
outputs_fed_lstm4 = tf_normalize4

filter_shape5 = [1, 1, 128, 128]
conv_weights5 = tf.get_variable(""conv_weights5"" , filter_shape5, tf.float32,tf.truncated_normal_initializer(mean=0.0, stddev=1.0))
conv_biases5 = tf.Variable(tf.constant(0.1, shape=[128]))
conv5 = tf.nn.conv2d(outputs_fed_lstm4, conv_weights5, strides=[1,1,1,1], padding = ""VALID"")
normalize5 = tf.nn.elu(conv5 + conv_biases5)
tf_normalize5 = tf.contrib.layers.batch_norm(inputs = normalize5,is_training = True)
outputs_fed_lstm5 = tf_normalize5

filter_shape6 = [1, 1, 128, 128]
conv_weights6 = tf.get_variable(""conv_weights6"" , filter_shape6, tf.float32,tf.truncated_normal_initializer(mean=0.0, stddev=1.0))
conv_biases6 = tf.Variable(tf.constant(0.1, shape=[128]))
conv6 = tf.nn.conv2d(outputs_fed_lstm5, conv_weights6, strides=[1,1,1,1], padding = ""VALID"")
normalize6 = tf.nn.elu(conv6 + conv_biases6)
tf_normalize6 = tf.contrib.layers.batch_norm(inputs = normalize6,is_training = True)
outputs_fed_lstm6 = tf_normalize6  

filter_shape7 = [1, 1, 128, 256]
conv_weights7 = tf.get_variable(""conv_weights7"" , filter_shape7, tf.float32,tf.truncated_normal_initializer(mean=0.0, stddev=1.0))
conv_biases7 = tf.Variable(tf.constant(0.1, shape=[256]))
conv7 = tf.nn.conv2d(outputs_fed_lstm6, conv_weights7, strides=[1,1,1,1], padding = ""VALID"")
normalize7 = tf.nn.elu(conv7 + conv_biases7)
tf_normalize7 = tf.contrib.layers.batch_norm(inputs = normalize7,is_training = True)
outputs_fed_lstm7 = tf_normalize7 

filter_shape8 = [1, 1, 256, 256]
conv_weights8 = tf.get_variable(""conv_weights8"" , filter_shape8, tf.float32,tf.truncated_normal_initializer(mean=0.0, stddev=1.0))
conv_biases8 = tf.Variable(tf.constant(0.1, shape=[256]))
conv8 = tf.nn.conv2d(outputs_fed_lstm7, conv_weights8, strides=[1,1,1,1], padding = ""VALID"")
normalize8 = tf.nn.elu(conv8 + conv_biases8)
tf_normalize8 = tf.contrib.layers.batch_norm(inputs = normalize8,is_training = True)
outputs_fed_lstm8 = tf_normalize8 

filter_shape9 = [1, 1, 256, 256]
conv_weights9 = tf.get_variable(""conv_weights9"" , filter_shape9, tf.float32,tf.truncated_normal_initializer(mean=0.0, stddev=1.0))
conv_biases9 = tf.Variable(tf.constant(0.1, shape=[256]))
conv9 = tf.nn.conv2d(outputs_fed_lstm8, conv_weights9, strides=[1,1,1,1], padding = ""VALID"")
normalize9 = tf.nn.elu(conv9 + conv_biases9)
tf_normalize9 = tf.contrib.layers.batch_norm(inputs = normalize9,is_training = True)
outputs_fed_lstm9 = tf_normalize9 

filter_shape0 = [1, 1, 256, 512]
conv_weights0 = tf.get_variable(""conv_weights0"" , filter_shape0, tf.float32,tf.truncated_normal_initializer(mean=0.0, stddev=1.0))
conv_biases0 = tf.Variable(tf.constant(0.1, shape=[512]))
conv0 = tf.nn.conv2d(outputs_fed_lstm9, conv_weights0, strides=[1,1,1,1], padding = ""VALID"")
normalize0 = tf.nn.elu(conv0 + conv_biases0)
tf_normalize0 = tf.contrib.layers.batch_norm(inputs = normalize0,is_training = True)
outputs_fed_lstm0 = tf_normalize0 

x = tf.squeeze(outputs_fed_lstm0, [2])     
x = tf.transpose(x, [1, 0, 2])
x = tf.reshape(x, [-1, 512])
x = tf.split(0, time_steps, x)

lstm = tf.nn.rnn_cell.LSTMCell(num_units = _units)

# multi_lstm = tf.nn.rnn_cell.MultiRNNCell([lstm] * lstm_layers, state_is_tuple = True)

outputs , state = tf.nn.rnn(lstm,x, dtype = tf.float32)     

weights = tf.Variable(tf.random_normal([_units,num_classes]))
biases  = tf.Variable(tf.random_normal([num_classes]))

logits = tf.matmul(outputs[-1], weights) + biases



c_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits,Y)
loss = tf.reduce_mean(c_loss)


global_step = tf.Variable(0, name=""global_step"", trainable=False)
# decayed_learning_rate = tf.train.exponential_decay(learning_rate,0,10000,0.9)
optimizer= tf.train.AdamOptimizer(learning_rate)
minimize_loss = optimizer.minimize(loss, global_step=global_step)   
#grads_and_vars = optimizer.compute_gradients(loss,[conv_weights2]) 
correct_predict = tf.nn.in_top_k(logits, Y, 1)
accuracy = tf.reduce_mean(tf.cast(correct_predict, tf.float32))


init = tf.initialize_all_variables()

with tf.Session() as sess:
     sess.run(init)
     for i in range(1000):
         for j in range(1000):
             x = train_set_x
             y = train_set_y
             sess.run(minimize_loss,feed_dict={X : x, Y : y})
             step += 1  
             #gr_print = sess.run([grad for grad, _ in grads_and_vars], feed_dict={X : x, Y : y})
             #print (gr_print)
             cost = sess.run(loss,feed_dict = {X: x,Y: y})
             accu = sess.run(accuracy,feed_dict = {X: x, Y: y})
             print (""Loss after one Epoch(Training) = "" + ""{:.6f}"".format(cost) + "", Training Accuracy= "" + ""{:.5f}"".format(accu))
```
"
4053,encounter error when session run in c++:Invalid argument: No OpKernel was registered to support Op 'Sub' with these attrs,"tensorflow version :0.8.0

1) use python to train model
2) use freeze_graph.py to freeze the mode and graph def as freeze.pb
3) load the  freeze.pb  is ok . but when  run session get this error

'''CreateGlobalVariables ...
pn predict fail:Invalid argument: No OpKernel was registered to support Op 'Sub' with these attrs
         [[Node: train_correct/dp_11/random_uniform/sub = Sub[T=DT_FLOAT](train_correct/dp_11/random_uniform/max, train_correct/dp_11/random_uniform/min)]] '''
"
4052,Can not compile on Mac OS X Yosemite,"### Environment info

Operating System: Mac OS X Yosemite
### Steps to reproduce
1. `git clone https://github.com/grpc/grpc.git`
2. `git checkout 0e43d67602096a5c4aeab4632579bc56cf692553`
3. `cd grpc`
4. `git submodule update --init --recursive`
5. `make`
### Make linking errors related to protobuf (first errors)

```
[CXX]     Compiling src/cpp/ext/reflection.pb.cc
src/cpp/ext/reflection.pb.cc:719:7: error: no member named 'InternalWriteMessageNoVirtualToArray' in
      'google::protobuf::internal::WireFormatLite'
      InternalWriteMessageNoVirtualToArray(
      ^
src/cpp/ext/reflection.pb.cc:809:35: error: no member named 'MergeFromFail' in namespace 'google::protobuf::internal'
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
src/cpp/ext/reflection.pb.cc:826:35: error: no member named 'MergeFromFail' in namespace 'google::protobuf::internal'
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
src/cpp/ext/reflection.pb.cc:1536:35: error: no member named 'MergeFromFail' in namespace 'google::protobuf::internal'
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
src/cpp/ext/reflection.pb.cc:1553:35: error: no member named 'MergeFromFail' in namespace 'google::protobuf::internal'
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
src/cpp/ext/reflection.pb.cc:1958:7: error: no member named 'InternalWriteMessageNoVirtualToArray' in
      'google::protobuf::internal::WireFormatLite'
      InternalWriteMessageNoVirtualToArray(
```
"
4050,Possible improvement in documentation,"I'm following the documentation [here](https://www.tensorflow.org/versions/r0.10/how_tos/adding_an_op/index.html#compiling_the_kernel_for_the_gpu_device). Specifically, I find that running the second command in the code block of the section ""Compiling the kernel for the GPU device"" returns a linker error complaining about the lack of the `lcudart` library. I have solved this issue by adding the option `-L /usr/local/cuda-8.0/lib64/` to the command, since the `libcudart.so` library is located in that folder on my machine. I'm not sure how else this library would be located (LD_LIBRARY_PATH is only searched on execution, not compile-time), so I'm thinking this problem might not be specific to my configuration. If so, adding mention of this option on the documentation might be valuable.
"
4048,Compute Capability 3.0 not working with latest docker builds,"Using the most recent docker image 'tensorflow/tensorflow:nightly-devel-gpu' doesn't work on AWS EC2 anymore, it results in the below error:

Ignoring gpu device (device: 0, name: GRID K520, pci bus id: 0000:00:03.0) with Cuda compute capability 3.0. The minimum required Cuda capability is 3.5.
"
4047,GPU usage is extremely unstable in distributed setup on aws,"### Environment info

Operating System: Ubuntu 14.04

Installed version of CUDA and cuDNN:  CUDA 7.5, cuDNN 4.0

If installed from binary pip package, provide:
Installed from the following pip package: (0.10.0rc)
https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl
### Steps to reproduce

I'm running distributed tf with GPU on 3 machines (the ps machine doesn't have GPU). The commands to start the cluster:
On ps machine0:

```
python async.py \
--job_name='ps' \
--task_id=0 \
--ps_hosts='machine0:2222' \
--worker_hosts='machine1:2222,machine2:2222'
```

On g2.2xlarge machine 1:

```
python async.py \
--job_name='worker' \
--task_id=0 \
--ps_hosts='machine0:2222' \
--worker_hosts='machine1:2222,machine2:2222'
```

On g2.2xlarge machine 2:

```
python async.py \
--job_name='worker' \
--task_id=1 \
--ps_hosts='machine0:2222' \
--worker_hosts='machine1:2222,machine2:2222'
```

The code:  [async.txt](https://github.com/tensorflow/tensorflow/files/437980/cifar10_async_dist_train.txt)

For the first few thousands of iteration, it worked perfectly fine, but the GPU usage drop to almost 0 after that. (actually it fluctuated a lot from 80 -> 50 ->0 ->80)
### What have you tried?
1.  I tried to restart the works and it worked for a few rounds then the problem come over again.
### Logs or other output that would be helpful

The log after restart. The speed for the first few rounds is ~0.36 sec/batch and the GPU usage is ~90%. But the speed drop down to ~1 sec/batch quickly.

```
2016-08-25 20:04:08.950429: step 110 (global_step 8318), loss = 0.85 (354.3 examples/sec; 0.361 sec/batch)
2016-08-25 20:04:12.356555: step 120 (global_step 8338), loss = 0.77 (381.3 examples/sec; 0.336 sec/batch)
2016-08-25 20:04:15.832075: step 130 (global_step 8358), loss = 0.93 (369.8 examples/sec; 0.346 sec/batch)
2016-08-25 20:04:19.269496: step 140 (global_step 8377), loss = 0.92 (345.1 examples/sec; 0.371 sec/batch)
2016-08-25 20:04:22.709284: step 150 (global_step 8398), loss = 1.00 (383.3 examples/sec; 0.334 sec/batch)
2016-08-25 20:04:26.071762: step 160 (global_step 8418), loss = 0.75 (464.1 examples/sec; 0.276 sec/batch)
2016-08-25 20:04:29.580850: step 170 (global_step 8438), loss = 0.99 (359.5 examples/sec; 0.356 sec/batch)
2016-08-25 20:04:33.029791: step 180 (global_step 8457), loss = 1.04 (357.4 examples/sec; 0.358 sec/batch)
2016-08-25 20:04:36.491314: step 190 (global_step 8478), loss = 0.93 (358.7 examples/sec; 0.357 sec/batch)
2016-08-25 20:04:39.939553: step 200 (global_step 8498), loss = 1.08 (358.7 examples/sec; 0.357 sec/batch)
2016-08-25 20:04:43.318268: step 210 (global_step 8518), loss = 1.09 (363.6 examples/sec; 0.352 sec/batch)
2016-08-25 20:04:46.716990: step 220 (global_step 8538), loss = 0.98 (411.3 examples/sec; 0.311 sec/batch)
2016-08-25 20:04:50.069852: step 230 (global_step 8557), loss = 0.95 (433.2 examples/sec; 0.295 sec/batch)
2016-08-25 20:04:53.607222: step 240 (global_step 8577), loss = 1.02 (364.5 examples/sec; 0.351 sec/batch)
2016-08-25 20:04:57.162343: step 250 (global_step 8597), loss = 0.96 (357.5 examples/sec; 0.358 sec/batch)
2016-08-25 20:05:00.765804: step 260 (global_step 8617), loss = 1.07 (329.9 examples/sec; 0.388 sec/batch)
2016-08-25 20:05:04.435059: step 270 (global_step 8637), loss = 0.85 (332.6 examples/sec; 0.385 sec/batch)
2016-08-25 20:05:08.196024: step 280 (global_step 8656), loss = 0.89 (306.1 examples/sec; 0.418 sec/batch)
2016-08-25 20:05:12.412322: step 290 (global_step 8676), loss = 1.10 (268.2 examples/sec; 0.477 sec/batch)
2016-08-25 20:05:21.793992: step 300 (global_step 8696), loss = 0.72 (119.5 examples/sec; 1.071 sec/batch)
2016-08-25 20:05:32.548282: step 310 (global_step 8716), loss = 0.80 (119.6 examples/sec; 1.070 sec/batch)
2016-08-25 20:05:43.400207: step 320 (global_step 8736), loss = 1.03 (116.0 examples/sec; 1.104 sec/batch)
2016-08-25 20:05:54.547412: step 330 (global_step 8755), loss = 0.84 (114.6 examples/sec; 1.117 sec/batch)
2016-08-25 20:06:05.457404: step 340 (global_step 8775), loss = 1.09 (119.4 examples/sec; 1.072 sec/batch)
2016-08-25 20:06:16.434271: step 350 (global_step 8795), loss = 0.83 (115.2 examples/sec; 1.111 sec/batch)
2016-08-25 20:06:27.296998: step 360 (global_step 8815), loss = 0.90 (116.7 examples/sec; 1.097 sec/batch)
2016-08-25 20:06:38.130229: step 370 (global_step 8835), loss = 0.99 (119.2 examples/sec; 1.074 sec/batch)
2016-08-25 20:06:48.918992: step 380 (global_step 8855), loss = 1.09 (115.5 examples/sec; 1.108 sec/batch)
2016-08-25 20:07:00.132937: step 390 (global_step 8874), loss = 0.87 (119.0 examples/sec; 1.076 sec/batch)
```
"
4044,tf.import_graph_def: graph_def is invalid at node,"I've been trying to import a frozen graph into a new program, and do a simple forward pass, but `tf.import_graph_def` has been throwing a ValueError that I really can't make sense of.
### Environment info

Operating System: Ubuntu 14.04 LTS 64-bit

Installed version of CUDA and cuDNN: none

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`): fc9162975e52978d3af38549b570cc3cc5f0ab66
2. The output of `bazel version`

```
Build label: 0.3.0
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Jun 10 11:38:23 2016 (1465558703)
Build timestamp: 1465558703
Build timestamp as int: 1465558703
```
### Steps to reproduce
1. Copy the IPython Notebook from [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/udacity/6_lstm.ipynb)
2. Change `sample_prediction = tf.nn.softmax(tf.nn.xw_plus_b(sample_output, w, b))` to `sample_prediction = tf.nn.softmax(tf.nn.xw_plus_b(sample_output, w, b), name=""sample_prediction"")`
3. Modify the code like so:

``` python
with tf.Session(graph=graph) as session:
  tf.initialize_all_variables().run()
  print('Initialized')
  mean_loss = 0
  # code omitted (no changes)
  # new code below:
  saver = tf.train.Saver(tf.all_variables())
  saver.save(session, '/home/me/Documents/checkpoint.ckpt', write_meta_graph=False)
  tf.train.write_graph(graph.as_graph_def(), '/home/me/Documents', 'graph.pb')
```
1. Run, and verify that `checkpoint.ckpt` and `graph.pb` have been created
2. Run `bazel build tensorflow/python/tools:freeze_graph && bazel-bin/tensorflow/python/tools/freeze_graph --input_graph=/home/me/Documents/graph.pb --input_checkpoint=/home/me/Documents/checkpoint.ckpt --output_graph=/home/me/Documents/frozen_graph.pb --output_node_names=sample_prediction`
3. Verify that `frozen_graph.pb` has been created
4. Create a new IPython Notebook with the following code:

``` python
from __future__ import print_function
import os
import numpy as np
import random
import string
import tensorflow as tf
from tensorflow.python.platform import gfile
import zipfile
from six.moves import range
from six.moves.urllib.request import urlretrieve

graph = tf.Graph()
with graph.as_default():
    graph_def = tf.GraphDef()
    with open('/home/me/Documents/frozen_graph.pb', ""rb"") as f:
        graph_def.ParseFromString(f.read())
        sample_prediction = tf.import_graph_def(graph_def, name="""", return_elements=['sample_prediction:0'])
```
1. Run
### What have you tried?
1. Originally, the graph also contained a node named `saved_sample_output`, and when I tried importing that frozen graph, the error complained about `saved_sample_output:0`. I tried removing the name, re-writing the checkpoint and graph files, re-freezing, and re-running the code. It then complained about `Variable_17:0`, which, after checking `graph.pb`, was what had originally been named `saved_sample_output`. Other than that, I haven't been able to find anything else out.
2. Checked out #616 and looked at the solutions suggested for similar errors, but my `import_graph_def` never had an input map to begin with.
3. Removing the name parameter, or the return_elements parameter, or both, hasn't made a difference.
### Logs or other output that would be helpful

```
ValueError                                Traceback (most recent call last)
<ipython-input-46-3423c2073e62> in <module>()
     53     with open('/home/me/Documents/frozen_graph.pb', ""rb"") as f:
     54         graph_def.ParseFromString(f.read())
---> 55         sample_prediction = tf.import_graph_def(graph_def, name="""", return_elements=['sample_prediction:0'])

/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.pyc in import_graph_def(graph_def, input_map, return_elements, name, op_dict)
    318           except TypeError as te:
    319             raise ValueError(_InvalidNodeMessage(
--> 320                 node, 'Input tensor %r %s' % (input_name, te)))
    321 
    322       # pylint: disable=protected_access

ValueError: graph_def is invalid at node u'Assign_4': Input tensor 'Variable_17:0' Cannot convert a tensor of type float32 to an input of type float32_ref.
```
"
4036,"distributed tensorflow “socket error, connection refused”","When I run the following  distributed tensorflow code.  It always show the error:  ""socket error: connection refused."" 

import tensorflow as tf
import input_data

def weight_variable(shape):
  initial = tf.truncated_normal(shape, stddev=0.1)
  return tf.Variable(initial)

def bias_variable(shape):
  initial = tf.constant(0.1, shape=shape)
  return tf.Variable(initial)

tf.app.flags.DEFINE_string(""ps_hosts"", """", 
                           ""Comma-separated list of hostname:port pairs"")
tf.app.flags.DEFINE_string(""worker_hosts"", """", 
                           ""Comma-separated list of hostname:port pairs"")
tf.app.flags.DEFINE_string(""job_name"", """", ""One of 'ps', 'worker'"")
tf.app.flags.DEFINE_integer(""task_index"", 0, ""Index of task within the job"")

FLAGS = tf.app.flags.FLAGS

def main(_):
  ps_hosts = FLAGS.ps_hosts.split("","")
  worker_hosts = FLAGS.worker_hosts.split("","")

  cluster = tf.train.ClusterSpec({""ps"": ps_hosts, ""worker"": worker_hosts})

  server = tf.train.Server(cluster.as_cluster_def(), 
                           job_name=FLAGS.job_name, 
                           task_index=FLAGS.task_index)

  if FLAGS.job_name == ""ps"" :
    server.join()
  elif FLAGS.job_name == ""worker"":
    with tf.device(tf.train.replica_device_setter(
        worker_device=""/job:worker/task:%d"" % FLAGS.task_index, 
        cluster=cluster)):
      x = tf.placeholder(tf.float32, [None, 28_28])
      y_ = tf.placeholder(tf.float32, [None, 10])
      W_h1 = weight_variable([28_28, 512])
      b_h1 = bias_variable([512])
      h1 = tf.nn.sigmoid(tf.matmul(x, W_h1) + b_h1)
      W_out = weight_variable([512, 10])
      b_out = bias_variable([10])
      y = tf.nn.softmax(tf.matmul(h1, W_out) + b_out)

```
  loss = tf.reduce_mean(-tf.reduce_sum(y_*tf.log(y)))
  global_step = tf.Variable(0)
  train_op = tf.train.AdagradOptimizer(0.01).minimize(
      loss, global_step=global_step)
  correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))
  accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

  saver = tf.train.Saver()
  summary_op = tf.merge_all_summaries()
  init_op = tf.initialize_all_variables()

sv = tf.train.Supervisor(is_chief=(FLAGS.task_index == 0),
                         logdir=""./train_logs"",
                         init_op=init_op,
                         summary_op=summary_op,
                         saver=saver,
                         global_step=global_step,
                         save_model_secs=600)

sess = sv.prepare_or_wait_for_session(server.target)

sv.start_queue_runners(sess)

mnist = input_data.read_data_sets(""./MNIST_data/"", one_hot=True)
step = 0
while not sv.should_stop() and step < 20000:
  batch_xs, batch_ys = mnist.train.next_batch(50)
  if step % 100 == 0:
    print ""job : %s/%s"" % (FLAGS.job_name,FLAGS.task_index), ""step : "", step, "",training accuracy :"", sess.run(accuracy, feed_dict={x: batch_xs, y_: batch_ys})
  _, step = sess.run([train_op, global_step], feed_dict={x: batch_xs, y_: batch_ys})

saver.save(sess, ""./train_logs/mlp.ckpt"")
```

if **name** == ""**main**"":
  tf.app.run()

Here is a worker log: 

`I0825 17:17:56.155537454   42583 socket_utils_common_posix.c:170] Disabling AF_INET6 sockets because ::1 is not available.
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job ps -> {10.51.145.204:30125, 10.51.147.155:30145, 10.51.147.206:30133, 10.51.81.205:30109, 10.51.145.207:30131, 10.51.148.205:30132, 10.50.85.231:30133, 10.51.147.208:30103, 10.51.147.195:30130, 10.51.150.71:30121}
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job worker -> {localhost:30129, 10.51.145.204:30109, 10.51.150.8:30138, 10.51.81.205:30121, 10.51.151.134:30111, 10.51.148.143:30135, 10.51.148.148:30103, 10.51.150.205:30140, 10.51.150.9:30113, 10.51.145.131:30116, 10.51.145.200:30105, 10.51.147.144:30138, 10.51.147.155:30102, 10.50.216.39:30147, 10.51.145.198:30111, 10.51.151.135:30133, 10.50.145.197:30130, 10.51.147.143:30135, 10.50.146.231:30143, 10.50.146.221:30100}
I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:30129
E0825 17:17:56.489036676   42954 tcp_client_posix.c:173]     failed to connect to 'ipv4:10.51.145.204:30125': socket error: connection refused
E0825 17:17:56.489142227   42954 tcp_client_posix.c:173]     failed to connect to 'ipv4:10.51.147.155:30145': socket error: connection refused
E0825 17:17:56.489182927   42954 tcp_client_posix.c:173]     failed to connect to 'ipv4:10.51.147.206:30133': socket error: connection refused
E0825 17:17:56.489211389   42954 tcp_client_posix.c:173]     failed to connect to 'ipv4:10.51.81.205:30109': socket error: connection refused
E0825 17:17:56.489271981   42954 tcp_client_posix.c:173]     failed to connect to 'ipv4:10.51.145.207:30131': socket error: connection refused
E0825 17:17:56.489308098   42954 tcp_client_posix.c:173]     failed to connect to 'ipv4:10.51.148.205:30132': socket error: connection refused
E0825 17:17:56.489330266   42954 tcp_client_posix.c:173]     failed to connect to 'ipv4:10.50.85.231:30133': socket error: connection refused
E0825 17:17:56.489361511   42954 tcp_client_posix.c:173]     failed to connect to 'ipv4:10.51.147.208:30103': socket error: connection refused
E0825 17:17:56.489796035   42954 tcp_client_posix.c:173]     failed to connect to 'ipv4:10.51.150.71:30121': socket error: connection refused
E0825 17:17:56.489996076   42954 tcp_client_posix.c:173]     failed to connect to 'ipv4:10.51.151.134:30111': socket error: connection refused
E0825 17:17:56.490013575   42954 tcp_client_posix.c:173]     failed to connect to 'ipv4:10.51.148.143:30135': socket error: connection refused
E0825 17:17:56.490021842   42954 tcp_client_posix.c:173]     failed to connect to 'ipv4:10.51.150.205:30140': socket error: connection refused
E0825 17:17:56.490028295   42954 tcp_client_posix.c:173]     failed to connect to 'ipv4:10.51.148.148:30103': socket error: connection refused
E0825 17:17:56.490035855   42954 tcp_client_posix.c:173]     failed to connect to 'ipv4:10.51.150.9:30113': socket error: connection refused
E0825 17:17:56.490275270   42954 tcp_client_posix.c:173]     failed to connect to 'ipv4:10.51.145.131:30116': socket error: connection refused`

All the workers are seemed to be connected to each other.  It makes me confused. 

Anyone can help with this? Thank you!
"
4035,build tensorflow from source sufferring from slow network,"this is not a bug, but really puzzle me. When everytime I try to build tf from source, bazel keep cloning grpc, protobuf and download something else, as my network is too slow....so this takes really a long time, is there a better way to do this?
"
4033,tensorflow.python.framework.errors.InvalidArgumentError: WhereOp: Race condition between counting the number of true elements and writing them,"I am running `distributed tensorflow` version of `deep mnist` [(link)](https://www.tensorflow.org/versions/r0.10/tutorials/mnist/pros/index.html) (`asynchronous` data parallelism on different machines with gpu). The batch_size I have taken for one epoch is 1000 images and I am running 1000 epochs. My architecture has one `ps` on machine 1 and two workers, with `worker task_index=0` as `chief` on machine 2 and machine 1 has `worker task_index=1`.

I really don't understand why I get this error sometimes when I run `worker task_index=1` on machine 1. The error does not persist though if I try running it a couple of times.

```
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so.7.5 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so.7.5 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so.7.5 locally
cannot import name hashtable
cannot import name hashtable
cannot import name hashtable
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:118] Found device 0 with properties: 
name: GeForce GTX 750 Ti
major: 5 minor: 0 memoryClockRate (GHz) 1.124
pciBusID 0000:02:00.0
Total memory: 2.00GiB
Free memory: 125.53MiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:138] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:148] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:868] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 750 Ti, pci bus id: 0000:02:00.0)
E tensorflow/stream_executor/cuda/cuda_driver.cc:965] failed to allocate 125.53M (131629056 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job ps -> {172.25.1.127:2223}
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job worker -> {172.25.1.108:2222, localhost:2222}
I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:203] Started server with target: grpc://localhost:2222
Extracting MNIST_data/train-images-idx3-ubyte.gz
Extracting MNIST_data/train-labels-idx1-ubyte.gz
Extracting MNIST_data/t10k-images-idx3-ubyte.gz
Extracting MNIST_data/t10k-labels-idx1-ubyte.gz
Traceback (most recent call last):
  File ""dist_trainer_deepMnist_v2.py"", line 205, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""dist_trainer_deepMnist_v2.py"", line 157, in main
    with sv.managed_session(server.target) as sess:
  File ""/usr/lib/python2.7/contextlib.py"", line 17, in __enter__
    return self.gen.next()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py"", line 969, in managed_session
    self.stop(close_summary_writer=close_summary_writer)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py"", line 797, in stop
    stop_grace_period_secs=self._stop_grace_secs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/coordinator.py"", line 386, in join
    six.reraise(*self._exc_info_to_raise)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py"", line 958, in managed_session
    start_standard_services=start_standard_services)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py"", line 722, in prepare_or_wait_for_session
    max_wait_secs=max_wait_secs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 351, in wait_for_session
    is_ready, not_ready_msg = self._model_ready(sess)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 437, in _model_ready
    return self._ready(self._ready_op, sess, ""Model not ready"")
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 406, in _ready
    ready_value = sess.run(op)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 710, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 908, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 958, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 978, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.InvalidArgumentError: WhereOp: Race condition between counting the number of true elements and writing them.  When counting, saw 2402 elements; but when writing their indices, saw 19 elements.
     [[Node: report_uninitialized_variables/Where = Where[_device=""/job:ps/replica:0/task:0/cpu:0""](report_uninitialized_variables/Reshape_1)]]
Caused by op u'report_uninitialized_variables/Where', defined at:
  File ""dist_trainer_deepMnist_v2.py"", line 205, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""dist_trainer_deepMnist_v2.py"", line 153, in main
    save_model_secs=600)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py"", line 310, in __init__
    ready_op=ready_op, ready_for_local_init_op=ready_for_local_init_op)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py"", line 399, in _init_ready_op
    ready_op = variables.report_uninitialized_variables()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py"", line 1031, in report_uninitialized_variables
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py"", line 888, in boolean_mask
    return _apply_mask_1d(tensor, mask)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py"", line 863, in _apply_mask_1d
    indices = squeeze(where(mask), squeeze_dims=[1])
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py"", line 2663, in where
    result = _op_def_lib.apply_op(""Where"", input=input, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 703, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2333, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1252, in __init__
    self._traceback = _extract_stack()
```

I tried looking for a reason as to why this error occurs, but couldn't find one. One clue is this part in the error

```
tensorflow.python.framework.errors.InvalidArgumentError: WhereOp: Race condition between counting the number of true elements and writing them.  When counting, saw 2402 elements; but when writing their indices, saw 19 elements.
 [[Node: report_uninitialized_variables/Where = Where[_device=""/job:ps/replica:0/task:0/cpu:0""](report_uninitialized_variables/Reshape_1)]]
Caused by op u'report_uninitialized_variables/Where',
```

Another clue is 

```
E tensorflow/stream_executor/cuda/cuda_driver.cc:965] failed to allocate 125.53M (131629056 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
```

this is there when I am running the ps on the same machine which is also using the gpu. It'll be great if someone can explain why this happens?

(Asked the same on [stack overflow](http://stackoverflow.com/questions/39130553/tensorflow-python-framework-errors-invalidargumenterror-whereop-race-condition?noredirect=1#comment65613229_39130553))
"
4032,To be able to epoch num info from tf.train.string_input_producer,"In cifar10 example, we want learning rate decay base on epoch num, the code there use NUM_INSTANCES/batch_size to get steps per epoch, but I wonder if we can directly use epoch num during training ?
It is usefull when you have big train data you do not know it's size pre, like on hdfs.
I've posted one quesion on stack overflow

[(http://stackoverflow.com/questions/39101150/how-to-get-epoch-num-info-from-tf-train-string-input-producer)]

looks like 
tf.get_default_graph().get_tensor_by_name('input_train/input_producer/limit_epochs/epochs:0')
does not fit the need.

Any suggestions, or it is not possible to get epoch num directly ?
"
4031,SupervisedSession cannot run dict fetchs.,"### Installed from source, 0.10.0rc0.
### `supervised_session.SupervisedSession`  under  `contrib.learn` cannot run dict fetchs:

 1.Document says that it's same as `tf.Session.run()` and confused.  

```
    def run(self, fetches, feed_dict=None, options=None, run_metadata=None):
    """"""Run ops in the supervised session.
        This method is completely compatible with the `tf.Session.run()` method.

        Args:
        fetches: Same as `tf.Session.run()`.
        feed_dict: Same as `tf.Session.run()`.
        options: Same as `tf.Session.run()`.
        run_metadata: Same as `tf.Session.run()`.

        Returns:
        Same as `tf.Session.run()`.
        """"""
        return self._sess.run(fetches, feed_dict=feed_dict, options=options,
                          run_metadata=run_metadata)
```

2.it is constructed with MonitoredSession, so it can only run `one` or a `list`.

```
    actual_fetches = {
        caller': fetches,
        self._global_step_tensor: self._global_step_tensor,
        'monitors': [_as_graph_element(f, self.graph) for f in monitor_fetches]
    }
```

Could you support for running a dict as tf.Session.run()? Or modify the document more clearly?
"
4030,cuda8.0 cudnn5 binary release?,"I've encountered lots of build errors and none of the solutions I found online can solve my problems. I'm just wondering when can you offer binary release for cuda 8.0 and cuDNN5? I think it's very important for those who don't want to get their hands dirty on building issues.
"
4029,ptb language modeling example broken with --use_fp16 and dropout other than 0,"### Environment info

Operating System: Ubuntu 16.04 LTS
GPU: GTX 1080
Nvidia driver: 370.23
CUDA: 8.0
cuDNN: 5
bazel: 

```
Build label: 0.3.1- (@non-git)
Build target: bazel-out/local- fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Wed Aug 24 00:13:09 2016 (1471997589)
Build timestamp: 1471997589
Build timestamp as int: 1471997589
```

git commit hash: cc3153a7a0a23533d14ead34db37e4ccd7892079
### Description

When run using the `--use_fp16` flag and either `--model medium` or `--model large`, the PTB language model example fails:

```
Traceback (most recent call last):
  File ""ptb_word_lm.py"", line 339, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""ptb_word_lm.py"", line 316, in main
    m = PTBModel(is_training=True, config=config)
  File ""ptb_word_lm.py"", line 117, in __init__
    inputs = tf.nn.dropout(inputs, config.keep_prob)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.py"", line 1121, in dropout
    if tensor_util.constant_value(keep_prob) == 1:
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.py"", line 634, in constant_value
    ret = _ConstantValue(tensor)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.py"", line 549, in _ConstantValue
    return MakeNdarray(tensor.op.get_attr(""value""))
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.py"", line 517, in MakeNdarray
    raise TypeError(""Unsupported tensor type: %s"" % tensor.dtype)
TypeError: Unsupported tensor type: 19
```

Modifying the model configs so that keep probability is 1 eliminates the problem, while any value other than 1 results in a call to `tf.nn.dropout` and, in turn, a call to `tensor_util.constant_value`, which results in a `TypeError`.
### What have you tried?

I have another machine running Ubuntu 14.04, CUDA 7.5, and a slightly older version of TensorFlow that does not have this issue. Details for this other set up:

Operating System: Ubuntu 14.04 LTS
GPU: Titan X
Nvidia driver: 352.39 
CUDA: 7.5
cuDNN: 5
bazel: 

```
Build label: 0.3.0-2016-07-25 (@e671d29)
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Mon Jul 25 17:47:58 2016 (1469468878)
Build timestamp: 1469468878
Build timestamp as int: 1469468878
```

git commit hash: 27eeb441bad8bcaa1bcba42a4b4ee49fb50ea0d3
"
4027,[cmake] Build error in dependency re2,"Somehow the re2 dependency does not get build correctly.
I think its because of `re2_INCLUDE_DIR` in re.cmake holding two directories. Then `COMMAND ${CMAKE_COMMAND} -E make_directory ${re2_INCLUDE_DIR}` fails since `cmake -E make_directory` only takes one arg. I'm just comiping and might add a PR if it works.
"
4026,TensorFlow SKFlow Estimators Fail when Using read_batch_examples,"### Environment info

Operating System: Ubuntu

Package: https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl
Version: 0.10.0rc0

I'm currently trying to use `tf.contrib.learn.read_batch_examples` working while using a TensorFlow (SKFlow/tf.contrib) Estimator, specifically the `LinearClassifier`. I create a `read_batch_examples` op feeding in a CSV file with a `tf.decode_csv` for the `parse_fn` parameter with appropriate default records. I then feed that op to my `input_fn` for fitting the Estimator, but when that's run I receive the following error:
### Error Message

```
ValueError: Tensor(""centered_bias_weight:0"", shape=(1,), dtype=float32_ref) must be from the same graph as Tensor(""linear/linear/BiasAdd:0"", shape=(?, 1), dtype=float32).
```
### What I've Tried

The code works if I run the op beforehand and then feed the input instead as an array of values. While this workaround exists, it is unhelpful because I am working with large datasets in which I need to batch in my inputs. Currently going over `Estimator.fit` (currently equivalent to `Estimator.partial_fit` in iterations isn't nearly as fast as being able to feed in data as it trains, so having this working is ideal.  Additionally I've tried wrapping everything with `with tf.Graph().asdefault()`. Any ideas? The non-functioning code is below.
### Shortened Source Code to Reproduce

[read_batch_examples_fails_with_estimator.txt](https://github.com/tensorflow/tensorflow/files/435736/read_batch_examples_fails_with_estimator.txt)

Any alternatives for batching would be appreciated as well!
"
4025,TensorForest Fails in Modified wide_n_deep SKFlow Tutorial,"### Environment info

Operating System: Ubuntu

Package: https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl
Version: 0.10.0rc0

Edit: See update at bottom for stuff I found wrong

I cannot get TensorForest to work using the input_fn parameter as input. It failed in my code, so I tried using it in the wide_n_deep tutorial which failed for the same reasons. Categorical inputs using Sparse tensors are rejected saying the wrong dtype is being used (they're all String). Without using categorical inputs, it gets further but fails saying that it cannot concat Tensors. I was able to run the tests for the TensorForest successfully with the Iris dataset ([link here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/estimators/random_forest_test.py)), but I would like to use the input_fn ability with a similar style to the tutorial if possible. I can provide the source but the only thing changed was using the `tf.contrib.learn.TensorForestEstimator` with the number of classes and features specified in `tf.contrib.tensor_forest.tensor_forest.ForestHParams` as the params input. Can someone look into this?
### Steps to reproduce
1. Modify wide_n_deep tutorial to use a `TensorForestEstimator`
### What I've tried
1. Running using input_fn as parameter to fit
2. Running using input_fn without categorical inputs to fit
### Output that would be helpful
#### Output including categorical sparse tensors

```
Traceback (most recent call last):
  File ""wide_n_deep_tutorial.py"", line 224, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""wide_n_deep_tutorial.py"", line 220, in main
    train_and_eval()
  File ""wide_n_deep_tutorial.py"", line 213, in train_and_eval
    m.fit(input_fn=lambda: input_fn(df_train), steps=FLAGS.train_steps)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 240, in fit
    max_steps=max_steps)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 550, in _train_model
    train_op, loss_op = self._get_train_ops(features, targets)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/random_forest.py"", line 149, in _get_train_ops
    features, spec = data_ops.ParseDataTensorOrDict(features)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tensor_forest/data/data_ops.py"", line 169, in ParseDataTensorOrDict
    return _ParseSparse(data)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tensor_forest/data/data_ops.py"", line 101, in _ParseSparse
    raise ValueError('Only sparse tensors of type string are supported.')
ValueError: Only sparse tensors of type string are supported.
```
#### Output without categorical sparse tensors

```
Traceback (most recent call last):
  File ""wide_n_deep_tutorial.py"", line 224, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""wide_n_deep_tutorial.py"", line 220, in main
    train_and_eval()
  File ""wide_n_deep_tutorial.py"", line 213, in train_and_eval
    m.fit(input_fn=lambda: input_fn(df_train), steps=FLAGS.train_steps)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 240, in fit
    max_steps=max_steps)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 550, in _train_model
    train_op, loss_op = self._get_train_ops(features, targets)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/random_forest.py"", line 149, in _get_train_ops
    features, spec = data_ops.ParseDataTensorOrDict(features)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tensor_forest/data/data_ops.py"", line 171, in ParseDataTensorOrDict
    return _ParseDense(data)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tensor_forest/data/data_ops.py"", line 144, in _ParseDense
    else data[k] for k in sorted(data.keys())
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py"", line 759, in concat
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py"", line 414, in _concat
    values=values, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 703, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2312, in create_op
    set_shapes_for_outputs(ret)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1704, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py"", line 815, in _ConcatShape
    (value_shape.ndims, concat_dim))
ValueError: Expected concat_dim in range [0, 1), but got 1
```
### UPDATE

I've fooled around with more stuff and been sifting through the source and have found the following.
1. Tensor Forest doesn't support both categorical and continuous inputs (only Sparse OR Dense)? Why is that, and can we expect that being implemented soon?
2. If solely sparse tensors are inputted, `_ParseSparse` fails because `constants.DATA_ALL_CATEGORICAL` is not defined (I believe it should be `constants.DATA_CATEGORICAL`)
3. Upon changing that variable to `constants.DATA_CATEGORICAL`, everything seems ok until my terminal gets flooded with these warnings:

```
W tensorflow/contrib/tensor_forest/core/ops/sample_inputs_op.cc:164] Could not find any values for input 1 inside sparse_input_indices
W tensorflow/contrib/tensor_forest/core/ops/sample_inputs_op.cc:164] Could not find any values for input 2 inside sparse_input_indices
W tensorflow/contrib/tensor_forest/core/ops/sample_inputs_op.cc:164] Could not find any values for input 1 inside sparse_input_indices
W tensorflow/contrib/tensor_forest/core/ops/sample_inputs_op.cc:164] Could not find any values for input 2 inside sparse_input_indices
```

Those warnings repeat over and over and eventually the model runs successfully.
4. I tried messing with `_Parse_Dense` and changed the `array_ops.concat` to `array_ops.pack` with `axis=1`, which returns the expected 2-D tensor. `concat` doesn't work as it is unable to create the dimension, whereas `pack` can. This resolved the continuous input issue, but I received a negligible error

```
Traceback (most recent call last):
  File ""wide_n_deep_tutorial.py"", line 224, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""wide_n_deep_tutorial.py"", line 220, in main
    train_and_eval()
  File ""wide_n_deep_tutorial.py"", line 213, in train_and_eval
    m.fit(input_fn=lambda: input_fn(df_train), steps=FLAGS.train_steps)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 240, in fit
    max_steps=max_steps)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 550, in _train_model
    train_op, loss_op = self._get_train_ops(features, targets)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/random_forest.py"", line 163, in _get_train_ops
    **self.training_args),
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tensor_forest/python/tensor_forest.py"", line 378, in training_graph
    **tree_kwargs))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tensor_forest/python/tensor_forest.py"", line 570, in training_graph
    regression=self.params.regression))
  File ""<string>"", line 219, in count_extremely_random_stats
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 463, in apply_op
    (prefix, dtypes.as_dtype(input_arg.type).name))
TypeError: Input 'input_data' of 'CountExtremelyRandomStats' Op has type int64 that does not match expected type of float32.
```

I easily fixed above error by changing all continuous inputs to tf.float32 from tf.int64, so that might be a feature request of interest.
5. After these modifications to source, I was able to use `input_fn` successfully with solely the continuous features of the census data set of the wide_n_deep tutorial (obtained ~82% on the testing set with 10 training steps). Not sure why but it took a while for that to run, didn't really look into it though.
6. I tried including the categorical inputs via tf.string dtype constant tensors, but received another error saying input to StringToFloat was not 2-D.

```
     tensorflow.python.framework.errors.InvalidArgumentError: input_data should be two-dimensional
```

I was able to resolve it by changing `convert_ops.string_to_float` to `tf.string_to_number`, but I am still unable to input via Sparse Tensors.
7. Another issue I found: not all metrics seem to work when passed in (I passed in `streaming_precision`, `streaming_recall`, `streaming_accuracy`, and `confusion_matrix`)

```
    Traceback (most recent call last):  
      File ""read.py"", line 336, in <module>
        tf.app.run()
      File ""/usr/local/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
        sys.exit(main(sys.argv))
      File ""read.py"", line 315, in main
        eval_steps=1
      File ""/usr/local/tensorflow/heartwood/cross_validation/evaluate.py"", line 37, in evaluate
        'cm': tf.contrib.metrics.confusion_matrix
      File ""/usr/local/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 356, in evaluate
        name=name)
      File ""/usr/local/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 630, in _evaluate_model
        eval_dict = self._get_eval_ops(features, targets, metrics)
      File ""/usr/local/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/random_forest.py"", line 198, in _get_eval_ops
        result[name] = metric(probabilities, labels)
      File ""/usr/local/python2.7/dist-packages/tensorflow/contrib/metrics/python/ops/confusion_matrix_ops.py"", line 73, in confusion_matrix
        predictions, name='predictions', dtype=dtypes.int64),
      File ""/usr/local/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 621, in convert_to_tensor
        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
      File ""/usr/local/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 564, in _TensorTensorConversionFunction
        % (dtype.name, t.dtype.name, str(t)))
    ValueError: Tensor conversion requested dtype int64 for Tensor with dtype float32: 'Tensor(""probabilities:0"", shape=(?, 2), dtype=float32)'
```
"
4024,How to link the TensorFlow static library for Android using the Gradle Experimental Plugin,"Hi all,

Context: we want to link TensorFlow against our C++ platform-independent code and load a model to run some classification relevant for our application. We use SWIG to generate the Java bindings and in the end it builds an Android .aar file that we push to a private maven repository that our other packages (Android apps, we also have an Android SDK) can consume downstream. Moving our project to Bazel is not ideal given our packaging / distribution pipeline. That's why we are trying the Gradle integration before moving the project to Bazel if there is no way around. For now, I followed https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/makefile/README.md and I was successfully able to build the .a libs (tensorflow-core and protobufs) and ran the benchmark.

Then I have a lot of undefined reference in TensorFlow / Protobuf, see [output.txt](https://github.com/tensorflow/tensorflow/files/435701/output.txt)

And for info, here's my build.gradle

``` groovy
apply plugin: 'com.android.model.library'
apply plugin: 'com.jfrog.artifactory'
apply plugin: 'com.github.dcendents.android-maven'
apply plugin: 'com.jfrog.bintray'
apply plugin: 'maven-publish'

def VERSION_NAME = '1.0.0-alpha.3-SNAPSHOT'
def GROUP_ID = 'io.cens'
def REPO_KEY = VERSION_NAME.endsWith('SNAPSHOT') ? 'libs-snapshot-local' : 'libs-release-local'

def ARTIFACT_FILENAME = ARTIFACT_ID + '-' + VERSION_NAME + '.aar'

version = VERSION_NAME
group = GROUP_ID

model {
    android {
        compileSdkVersion 23
        buildToolsVersion ""23.0.3""

        defaultConfig {
            minSdkVersion.apiLevel 14
            targetSdkVersion.apiLevel 23
            versionCode 1
            versionName VERSION_NAME
            project.archivesBaseName = ARTIFACT_FILENAME
        }

        buildTypes {
            release {
                minifyEnabled false
                proguardFiles.add(file(""proguard-rules.pro""))
            }
        }

        ndk {
            moduleName = ""censio_crash""
            stl = ""gnustl_shared"" // see https://developer.android.com/ndk/guides/cpp-support.html#stl

            // TensorFlow artifacts (it is assumed that the tensorflow repo is a peer of the crash repo)
            cppFlags.add('-I' + file('../../../../../tensorflow').absolutePath)
            cppFlags.add('-I' + file('../../../../../tensorflow/tensorflow/contrib/makefile/gen/proto').absolutePath)
            cppFlags.add('-I' + file('../../../../../tensorflow/tensorflow/contrib/makefile/gen/protobuf/include').absolutePath)
            cppFlags.add('-I' + file('../../../../../tensorflow/tensorflow/contrib/makefile/downloads/eigen-eigen-6f952374ef2b').absolutePath)
            ldFlags.add('../../../../../tensorflow/tensorflow/contrib/makefile/gen/protobuf/lib/libprotobuf-lite.a')
            ldFlags.add('../../../../../tensorflow/tensorflow/contrib/makefile/gen/lib/libtensorflow-core.a')

            // Our sources
            cppFlags.add('-I' + file(""../../../../src"").absolutePath)
            cppFlags.add(""-std=gnu++11"")
            cppFlags.addAll([""-fexceptions"", ""-frtti""])
            ldLibs.addAll(['android', 'log', 'z'])
            abiFilters.addAll(['armeabi-v7a']) // only build for main architecture subset
        }

        sources {
            main {
                jni {
                    source {
                        srcDir '../../../../src'
                        exclude ""**/Logger.cpp"" // Android impl is generated by SWIG instead
                    }
                }
            }
        }
    }
}

def siteUrl = 'https://github.com/Censio/mobile-crash-sdk'
def gitUrl = 'https://github.com/Censio/mobile-crash-sdk.git'

install {
    repositories.mavenInstaller {
        // This generates POM.xml with proper parameters
        pom {
            project {
                packaging 'aar'

                name 'TrueMotion Android On-board SDK - Crash package.'
                url siteUrl

                // Set your license
                licenses {
                    license {
                        name 'Copyright (C) 2016 TrueMotion - All Rights Reserved'
                        url 'http://gotruemotion.com'
                    }
                }
                developers {
                    developer {
                        id 'antoine-dbr'
                        name 'Antoine-Dubois-Rande'
                        email 'antoine@cens.io'
                    }
                }
                scm {
                    connection gitUrl
                    developerConnection gitUrl
                    url siteUrl
                }
            }
        }
    }
}

dependencies {
}

publishing {
    publications {
        aar(MavenPublication) {
            groupId GROUP_ID
            version = VERSION_NAME
            artifactId ARTIFACT_ID

            // Tell maven to prepare the generated ""*.aar"" file for publishing
            artifact(""$buildDir/outputs/aar/"" + ARTIFACT_FILENAME)

            pom.withXml {
                def dependencies = asNode().appendNode('dependencies')
                configurations.getByName(""_releaseCompile"").getResolvedConfiguration().getFirstLevelModuleDependencies().each {
                    def dependency = dependencies.appendNode('dependency')
                    dependency.appendNode('groupId', it.moduleGroup)
                    dependency.appendNode('artifactId', it.moduleName)
                    dependency.appendNode('version', it.moduleVersion)
                }
            }
        }
    }
}

artifactory {
    contextUrl = 'https://censiodev.artifactoryonline.com/censiodev'
    publish {
        repository {
            // The Artifactory repository key to publish to
            repoKey = REPO_KEY

            username = ARTIFACTORY_USERNAME
            password = ARTIFACTORY_PASSWORD
        }
        defaults {
            publications('aar')
            publishArtifacts = true
            publishPom = true
        }
    }
}

bintray {
    user = BINTRAY_USER
    key = BINTRAY_API_KEY

    configurations = ['archives']
    pkg {
        userOrg = 'censio'
        repo = VERSION_NAME.endsWith('SNAPSHOT') ? '' : 'maven' // This will error out if we attempt to push a snapshot build
        name = ARTIFACT_ID
        websiteUrl = siteUrl
        vcsUrl = gitUrl
        licenses = ['Censio']
        dryRun = false
        publish = true
    }
}

task rename(type: Copy) {
    from 'build/outputs/aar'
    into 'build/outputs/aar'
    rename { String fileName ->
        fileName.replace('-release.aar', '')
    }
}
```

Since the benchmark works, I think it's probably an issue on my end. In any case, any help appreciated. Thanks!
"
4023,Problems when running compile_ios_tensorflow.sh,"On running compile_ios_tensorflow.sh, I am the following problems:

Undefined symbols for architecture armv7:
  ""tensorflow::functor::ReduceAndReshape<Eigen::ThreadPoolDevice, int, 6, 1>::operator()(Eigen::ThreadPoolDevice const&, Eigen::TensorMap<Eigen::Tensor<int, 6, 1, int>, 16>, Eigen::TensorMap<Eigen::Tensor<int const, 6, 1, int>, 16>, Eigen::DSizes<int, 1> const&, Eigen::DSizes<int, 6> const&) const"", referenced from:
      void tensorflow::TileGradientOpEigen::ThreadPoolDevice::HandleReduce<int, 6, 1>(tensorflow::OpKernelContext_, std::__1::vector<int, std::__1::allocator<int> > const&, tensorflow::Tensor_) in libtensorflow-core-armv7.a(tile_ops.o)
  ""tensorflow::functor::ReduceAndReshape<Eigen::ThreadPoolDevice, float, 6, 1>::operator()(Eigen::ThreadPoolDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 6, 1, int>, 16>, Eigen::TensorMap<Eigen::Tensor<float const, 6, 1, int>, 16>, Eigen::DSizes<int, 1> const&, Eigen::DSizes<int, 6> const&) const"", referenced from:
      void tensorflow::TileGradientOpEigen::ThreadPoolDevice::HandleReduce<float, 6, 1>(tensorflow::OpKernelContext_, std::__1::vector<int, std::__1::allocator<int> > const&, tensorflow::Tensor_) in libtensorflow-core-armv7.a(tile_ops.o)
  ""tensorflow::functor::TileGrad<Eigen::ThreadPoolDevice, int, 6>::operator()(Eigen::ThreadPoolDevice const&, Eigen::TensorMap<Eigen::Tensor<int, 6, 1, int>, 16>, Eigen::TensorMap<Eigen::Tensor<int const, 6, 1, int>, 16>, Eigen::DSizes<int, 6> const&, Eigen::DSizes<int, 6> const&, bool) const"", referenced from:
      void tensorflow::TileGradientOpEigen::ThreadPoolDevice::HandleCaseImpl<(tensorflow::DataType)3, 6>(tensorflow::OpKernelContext_, std::__1::vector<int, std::__1::allocator<int> > const&, tensorflow::gtl::ArraySlice<int> const&, tensorflow::Tensor_) in libtensorflow-core-armv7.a(tile_ops.o)
  ""tensorflow::functor::TileGrad<Eigen::ThreadPoolDevice, float, 6>::operator()(Eigen::ThreadPoolDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 6, 1, int>, 16>, Eigen::TensorMap<Eigen::Tensor<float const, 6, 1, int>, 16>, Eigen::DSizes<int, 6> const&, Eigen::DSizes<int, 6> const&, bool) const"", referenced from:
      void tensorflow::TileGradientOpEigen::ThreadPoolDevice::HandleCaseImpl<(tensorflow::DataType)1, 6>(tensorflow::OpKernelContext_, std::__1::vector<int, std::__1::allocator<int> > const&, tensorflow::gtl::ArraySlice<int> const&, tensorflow::Tensor_) in libtensorflow-core-armv7.a(tile_ops.o)
  ""tensorflow::functor::Tile<Eigen::ThreadPoolDevice, int, 6>::operator()(Eigen::ThreadPoolDevice const&, Eigen::TensorMap<Eigen::Tensor<int, 6, 1, int>, 16>, Eigen::TensorMap<Eigen::Tensor<int const, 6, 1, int>, 16>, std::__1::array<int, 6ul> const&) const"", referenced from:
      void tensorflow::TileOpEigen::ThreadPoolDevice::HandleCaseImpl<(tensorflow::DataType)3, 6>(tensorflow::OpKernelContext_, tensorflow::gtl::ArraySlice<int> const&, tensorflow::Tensor_) in libtensorflow-core-armv7.a(tile_ops.o)
  ""tensorflow::functor::Tile<Eigen::ThreadPoolDevice, float, 6>::operator()(Eigen::ThreadPoolDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 6, 1, int>, 16>, Eigen::TensorMap<Eigen::Tensor<float const, 6, 1, int>, 16>, std::__1::array<int, 6ul> const&) const"", referenced from:
      void tensorflow::TileOpEigen::ThreadPoolDevice::HandleCaseImpl<(tensorflow::DataType)1, 6>(tensorflow::OpKernelContext_, tensorflow::gtl::ArraySlice<int> const&, tensorflow::Tensor_) in libtensorflow-core-armv7.a(tile_ops.o)
ld: symbol(s) not found for architecture armv7
clang: error: linker command failed with exit code 1 (use -v to see invocation)
make: **\* [/Users/jiq/tensorflow/tensorflow/contrib/makefile/gen/bin/ios_ARMV7/benchmark] Error 1
- '[' 2 -ne 0 ']'
- echo 'armv7 compilation failed.'
  armv7 compilation failed.
- exit 1

I have looked at the #3382 commit. But I still had this problem. Does any one can help?
"
4022,train.batch with dynamic_pad=True and input as list of tensors not working as expected,"### Environment info

Operating System: 
Ubuntu 14.04.4 LTS (running in Virtual Box 5.0.22 r108108)

Installed version of CUDA and cuDNN: 
None

If installed from binary pip package, provide:
1. Which pip package you installed.
pip 8.1.2
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
0.10.0rc0
### Preface

This issue arose from attempting to expand on an example using dynamic padding as written in: http://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features/
the necessary code is copied below.
### Steps to reproduce

Run the following minimal example:

``` python
import tensorflow as tf

# [0, 1, 2, 3, 4 ,...]
x = tf.range(1, 10, name=""x"")

# A queue that outputs 0,1,2,3,...
range_q = tf.train.range_input_producer(limit=5, shuffle=False)
slice_end = range_q.dequeue()

# Slice x to variable length, i.e. [0], [0, 1], [0, 1, 2], ....
y = tf.slice(x, [0], [slice_end], name=""y"")

batched_data = tf.train.batch(
    tensors=[y],
    batch_size=5,
    dynamic_pad=True,
    name=""y_batch""
)

# Run the graph
# tf.contrib.learn takes care of starting the queues for us
res = tf.contrib.learn.run_n({""y"": batched_data}, n=1, feed_dict=None)

# Print the result
print(""Batch shape: {}"".format(res[0][""y""].shape))
print(res[0][""y""])
```

Output (correct behavior):

```
Batch shape: (5, 4)
[[0 0 0 0]
 [1 0 0 0]
 [1 2 0 0]
 [1 2 3 0]
 [1 2 3 4]]
```

When attempted with different input (list of tensors of different lengths)

``` python
import tensorflow as tf

y = [tf.constant(range(n)) for n in range(1,10)]

batched_data = tf.train.batch(
    tensors=[y],
    batch_size=5,
    dynamic_pad=True,
    name=""y_batch""
)

# Run the graph
# tf.contrib.learn takes care of starting the queues for us
res = tf.contrib.learn.run_n({""y"": batched_data}, n=1, feed_dict=None)

# Print the result
print(""Batch shape: {}"".format(res[0][""y""].shape))
print(res[0][""y""])
```

Output:

```
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-12-8b4d52a4df68> in <module>()
     19     batch_size=5,
     20     dynamic_pad=True,
---> 21     name=""y_batch""
     22 )
     23 

/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.pyc in batch(tensors, batch_size, num_threads, capacity, enqueue_many, shapes, dynamic_pad, allow_smaller_final_batch, shared_name, name)
    577   tensor_list = _as_tensor_list(tensors)
    578   with ops.op_scope(tensor_list, name, ""batch"") as name:
--> 579     tensor_list = _validate(tensor_list)
    580     (tensor_list, sparse_info) = _serialize_sparse_tensors(
    581         tensor_list, enqueue_many)

/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.pyc in _validate(tensor_list)
    411 
    412 def _validate(tensor_list):
--> 413   tensor_list = ops.convert_n_to_tensor_or_indexed_slices(tensor_list)
    414   if not tensor_list:
    415     raise ValueError(""Expected at least one tensor in batch()."")

/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc in convert_n_to_tensor_or_indexed_slices(values, dtype, name, as_ref)
    735       ret.append(
    736           convert_to_tensor_or_indexed_slices(value, dtype=dtype, name=n,
--> 737                                               as_ref=as_ref))
    738   return ret
    739 

/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc in convert_to_tensor_or_indexed_slices(value, dtype, name, as_ref)
    696     return value
    697   else:
--> 698     return convert_to_tensor(value, dtype=dtype, name=name, as_ref=as_ref)
    699 
    700 

/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc in convert_to_tensor(value, dtype, name, as_ref)
    619     for base_type, conversion_func in funcs_at_priority:
    620       if isinstance(value, base_type):
--> 621         ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
    622         if ret is NotImplemented:
    623           continue

/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.pyc in _autopacking_conversion_function(v, dtype, name, as_ref)
    628   if dtype is not None and dtype != inferred_dtype:
    629     return NotImplemented
--> 630   return _autopacking_helper(v, inferred_dtype, name or ""packed"")
    631 # pylint: enable=invalid-name
    632 

/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.pyc in _autopacking_helper(list_or_tuple, dtype, name)
    591           elems_as_tensors.append(
    592               constant_op.constant(elem, dtype=dtype, name=str(i)))
--> 593       return gen_array_ops._pack(elems_as_tensors, name=scope)
    594     else:
    595       return converted_elems

/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.pyc in _pack(values, axis, name)
   1452     A `Tensor`. Has the same type as `values`. The packed tensor.
   1453   """"""
-> 1454   result = _op_def_lib.apply_op(""Pack"", values=values, axis=axis, name=name)
   1455   return result
   1456 

/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.pyc in apply_op(self, op_type_name, name, **keywords)
    701           op = g.create_op(op_type_name, inputs, output_types, name=scope,
    702                            input_types=input_types, attrs=attr_protos,
--> 703                            op_def=op_def)
    704           outputs = op.outputs
    705           return _Restructure(ops.convert_n_to_tensor(outputs),

/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc in create_op(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)
   2310                     original_op=self._default_original_op, op_def=op_def)
   2311     if compute_shapes:
-> 2312       set_shapes_for_outputs(ret)
   2313     self._add_op(ret)
   2314     self._record_op_seen_by_control_dependencies(ret)

/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc in set_shapes_for_outputs(op)
   1702       raise RuntimeError(""No shape function registered for standard op: %s""
   1703                          % op.type)
-> 1704   shapes = shape_func(op)
   1705   if shapes is None:
   1706     raise RuntimeError(

/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.pyc in _PackShape(op)
    767 
    768   for inp in op.inputs[1:]:
--> 769     input_shape = input_shape.merge_with(inp.get_shape())
    770 
    771   input_shape = input_shape.as_list()

/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.pyc in merge_with(self, other)
    568       except ValueError:
    569         raise ValueError(""Shapes %s and %s are not compatible"" %
--> 570                          (self, other))
    571 
    572   def concatenate(self, other):

ValueError: Shapes (1,) and (2,) are not compatible
```

Expected same result as previous script.
### What have you tried?
- Attempted transforming `y` into a tensor but have not found a way. Given the first example, it appears possible to construct tensors with variable size in some dimension, but given a dataset in the form of List of List of primitive (with inner lists being of varying lengths), I don't know how to transform this into a tensor without padding the entire dataset.

``` python
import tensorflow as tf

# [0, 1, 2, 3, 4 ,...]
x = tf.range(1, 10, name=""x"")

# A queue that outputs 0,1,2,3,...
range_q = tf.train.range_input_producer(limit=5, shuffle=False)
slice_end = range_q.dequeue()

# Slice x to variable length, i.e. [0], [0, 1], [0, 1, 2], ....
y = tf.slice(x, [0], [slice_end], name=""y"")

print 'Dynamic shape of y:', tf.shape(y)
print 'Static shape of y:', y.get_shape()
```

Output:

```
Dynamic shape of y: Tensor(""Shape_16:0"", shape=(1,), dtype=int32)
Static shape of y: (?,)
```
- Attempted replacing `tf.train.batch` line with the `tf.PaddingFIFOQueue` as follows

``` python
# Creating a new queue
padding_q = tf.PaddingFIFOQueue(
    capacity=10,
    dtypes=tf.int32,
    shapes=[[None]])

# Enqueue the examples
enqueue_op = padding_q.enqueue([y])

# Add the queue runner to the graph
qr = tf.train.QueueRunner(padding_q, [enqueue_op])
tf.train.add_queue_runner(qr)

# Dequeue padded data
batched_data = padding_q.dequeue_many(5)
```

Output: identical to above
- Using placeholders: tried replacing `y` with a placeholder of shape `[None]` and feeding it the data, cannot seem to get this to work either.
- Padding entire dataset: this works, but defeats the purpose of dynamic padding
- Todo: am going to try passing dataset through `tf.train.SequenceExample()`, constructing an example for each sequence, but I would rather this not be necessary.
"
4021,Improving Google Indexing for the Documentation,"Whenever I run a Google search on a TensorFlow functionality, say, `tf.reshape`, it gives me the entire documentation, not the specific documentation related to that functionality. 

Currently the way I use is  to run a search with `ctrl` + `f` to find specific documentation related to what I search for. 

Numpy has that property, i.e. when you run a Google search on `np.reshape`, you get the specific page.

It would be a nice improvement for the documentation if someone fixes the Google indexing for the documentation page, especially for the users who frequently use Google search for the documentation.
"
4019,./configure cannot find Python libraries,"I can't get the configure step to work:

```
(py35) [david@SQUIDS tensorflow]$ ./configure 
Please specify the location of python. [Default is /home/david/.virtualenvs/py35/bin/python]: 
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N] n
No Google Cloud Platform support will be enabled for TensorFlow
Traceback (most recent call last):
  File ""<stdin>"", line 14, in <module>
AttributeError: module 'site' has no attribute 'getsitepackages'
Found possible Python library paths:
Please input the desired Python library path to use.  Default is []


ln: failed to create symbolic link 'util/python/python_lib' -> '': No such file or directory
(py35) [david@SQUIDS tensorflow]$ ./configure 
Please specify the location of python. [Default is /home/david/.virtualenvs/py35/bin/python]: 
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N] y
Google Cloud Platform support will be enabled for TensorFlow
Traceback (most recent call last):
  File ""<stdin>"", line 14, in <module>
AttributeError: module 'site' has no attribute 'getsitepackages'
Found possible Python library paths:
Please input the desired Python library path to use.  Default is []


ln: failed to create symbolic link 'util/python/python_lib' -> '': No such file or directory
```

The repo is clean, at this exact commt:

```
(py35) [david@SQUIDS tensorflow]$ git status 
On branch master
Your branch is up-to-date with 'origin/master'.
nothing to commit, working directory clean
(py35) [david@SQUIDS tensorflow]$ git log | head
commit 8a3107801d15bf8af36221ff5bca0b94bf44d6d3
Author: Derek Murray <derek.murray@gmail.com>
Date:   Tue Aug 23 21:58:57 2016 -0700

    Disable tf_stream_executor in the CMake build. (#4000)

    Temporary workaround for issue #3996.

commit cc3153a7a0a23533d14ead34db37e4ccd7892079
Author: Egor-Krivov <egor.krivov@frtk.ru>

```

The system is Fedora Linux with Python 3.5 installed in a virtualenv. Giving it
`/home/david/.virtualenvs/py35/lib64/python3.5` seems to work, but I can't be sure (it is stuck trying to download http://pilotfiber.dl.sourceforge.net/project/boost/boost/1.61.0/boost_1_61_0.tar.gz, but with Firefox I can get it in 5 s).
"
4018,GPU build configuration doesn't work with Debian-packaged cuda/cudnn packages,"I'm on a Debian 'sid' linux computer and I am attempting to build a GPU-enabled version of TensorFlow using the Debian-packaged versions of the Nvidia libraries.

The CUDA packages are from Debian's non-free repository, e.g. https://packages.debian.org/sid/nvidia-cuda-toolkit and cuDNN I installed from using the .deb packages available from Nvidia's site (libcudnn5_5.1.3-1+cuda7.5_amd64.deb  and libcudnn5-dev_5.1.3-1+cuda7.5_amd64.deb).

These packages put the libraries and include files in standard system locations, so there is no CUDA_TOOLKIT_PATH or CUDNN_INSTALL_PATH to speak of, as this ldconfig output shows:

forrest@makemake:~$ /sbin/ldconfig -p | grep 'cud'
    libicudata.so.57 (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libicudata.so.57
    libicudata.so.55 (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libicudata.so.55
    libicudata.so.55 (libc6) => /usr/lib/i386-linux-gnu/libicudata.so.55
    libicudata.so (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libicudata.so
    libcudnn.so.5 (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libcudnn.so.5
    libcudnn.so (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libcudnn.so
    libcudart.so.7.5 (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libcudart.so.7.5
    libcudart.so (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libcudart.so
    libcuda.so.1 (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libcuda.so.1
    libcuda.so.1 (libc6) => /usr/lib/i386-linux-gnu/libcuda.so.1
    libcuda.so (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libcuda.so
    libcuda.so (libc6) => /usr/lib/i386-linux-gnu/libcuda.so

I have attempted to hack the configure file to support this default Debian configuration, but so far bazel always seems to expect CUDA_INSTALL_DIR to be set.
"
4016,Initialize layers.convolution2d from numpy array,"I can't find a way to pass a numpy tensor to layers.convolution2d weights/bias initialization arguments.
I added support for this by modifying convolution2d, code is below. I need this feature in order  If you like this solution I can add this feature to other ops also and create a pull request.

First I tried this:

```
import tensorflow as tf
import tensorflow.contrib.layers as layers
import numpy as np

conv1_1 = np.random.rand(3, 3, 3, 64).astype(dtype=np.float32)
inputs = tf.placeholder(tf.float32, shape=(32, 96, 96, 3))
net = layers.convolution2d(inputs, 64, 3, weights_initializer=conv1_1, scope='conv1_1')
```

but get_variable method doesn't allow redundant shape argument when initializing from constant.

```
Traceback (most recent call last):
  File ""tf1.py"", line 16, in <module>
    net = layers.convolution2d(inputs, 64, 3, weights_initializer=conv1_1, scope='conv1_1')
  File ""/usr/lib/python3.5/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py"", line 171, in func_with_args
    return func(*args, **current_args)
  File ""/usr/lib/python3.5/site-packages/tensorflow/contrib/layers/python/layers/layers.py"", line 406, in convolution2d
    trainable=trainable)
  File ""/usr/lib/python3.5/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py"", line 171, in func_with_args
    return func(*args, **current_args)
  File ""/usr/lib/python3.5/site-packages/tensorflow/contrib/framework/python/ops/variables.py"", line 266, in model_variable
    caching_device=caching_device, device=device)
  File ""/usr/lib/python3.5/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py"", line 171, in func_with_args
    return func(*args, **current_args)
  File ""/usr/lib/python3.5/site-packages/tensorflow/contrib/framework/python/ops/variables.py"", line 230, in variable
    caching_device=caching_device)
  File ""/usr/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py"", line 873, in get_variable
    custom_getter=custom_getter)
  File ""/usr/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py"", line 700, in get_variable
    custom_getter=custom_getter)
  File ""/usr/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py"", line 217, in get_variable
    validate_shape=validate_shape)
  File ""/usr/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py"", line 202, in _true_getter
    caching_device=caching_device, validate_shape=validate_shape)
  File ""/usr/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py"", line 479, in _get_single_variable
    raise ValueError(""If initializer is a constant, do not specify shape."")
ValueError: If initializer is a constant, do not specify shape.
```

I removed redundant arguments but then convolution2d doesn't have default value for them. 

```
net = layers.convolution2d(inputs, weights_initializer=conv1_1, scope='conv1_1')
```

```
Traceback (most recent call last):
  File ""tf1.py"", line 14, in <module>
    net = layers.convolution2d(inputs, weights_initializer=conv1_1, scope='conv1_1')
  File ""/usr/lib/python3.5/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py"", line 171, in func_with_args
    return func(*args, **current_args)
TypeError: convolution2d() missing 2 required positional arguments: 'num_outputs' and 'kernel_size'
```

I fixed the problem by adding support inside convolution2d code here:
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/layers.py#L322
It works now and I don't have to pass redundant arguments.

```
@add_arg_scope
def convolution2d(inputs,
                  num_outputs=None,
                  kernel_size=None,
                  stride=1,
                  padding='SAME',
                  rate=1,
                  activation_fn=nn.relu,
                  normalizer_fn=None,
                  normalizer_params=None,
                  weights_initializer=initializers.xavier_initializer(),
                  weights_regularizer=None,
                  biases_initializer=init_ops.zeros_initializer,
                  biases_regularizer=None,
                  reuse=None,
                  variables_collections=None,
                  outputs_collections=None,
                  trainable=True,
                  scope=None):
  with variable_scope.variable_op_scope([inputs],
                                        scope, 'Conv', reuse=reuse) as sc:
    inputs = ops.convert_to_tensor(inputs)
    dtype = inputs.dtype.base_dtype
    stride_h, stride_w = utils.two_element_tuple(stride)
    if rate > 1 and (stride_h > 1 or stride_w > 1):
      raise ValueError('Only one of rate or stride can be larger than one')
    num_filters_in = utils.last_dimension(inputs.get_shape(), min_rank=4)

    initializing_from_value = False
    if weights_initializer is not None and not callable(weights_initializer):
      initializing_from_value = True
      weights_shape = None
    else:
      if kernel_size == None or num_outputs == None:
        raise ValueError('Kernel size and number of outputs must be defined')
      kernel_h, kernel_w = utils.two_element_tuple(kernel_size)
      weights_shape = [kernel_h, kernel_w,
                       num_filters_in, num_outputs]
    if biases_initializer is not None and not callable(biases_initializer):
      bias_shape = None
    else:
      if num_outputs == None:
        raise ValueError('Number of outputs must be defined')
      bias_shape = [num_outputs]

    weights_collections = utils.get_variable_collections(
        variables_collections, 'weights')
    weights = variables.model_variable('weights',
                                       shape=weights_shape,
                                       dtype=dtype,
                                       initializer=weights_initializer,
                                       regularizer=weights_regularizer,
                                       collections=weights_collections,
                                       trainable=trainable)
    if rate > 1:
      outputs = nn.atrous_conv2d(inputs, weights, rate, padding=padding)
    else:
      outputs = nn.conv2d(inputs, weights, [1, stride_h, stride_w, 1],
                          padding=padding)
    if normalizer_fn:
      normalizer_params = normalizer_params or {}
      outputs = normalizer_fn(outputs, **normalizer_params)
    else:
      if biases_initializer is not None:
        biases_collections = utils.get_variable_collections(
            variables_collections, 'biases')
        biases = variables.model_variable('biases',
                                          shape=bias_shape,
                                          dtype=dtype,
                                          initializer=biases_initializer,
                                          regularizer=biases_regularizer,
                                          collections=biases_collections,
                                          trainable=trainable)
        outputs = nn.bias_add(outputs, biases)
    if activation_fn:
      outputs = activation_fn(outputs)
    return utils.collect_named_outputs(outputs_collections, sc.name, outputs)
```
"
4013,different types of GPUs,"I have 4 GPUS, which are
gpu0, GTX 1080
gpu1, old TITAN X
gpu2, old TITAN X
gpu3, GTX 1080
when I run a CNN, it shows the information below, what does `cannot enable peer access from device ordinal 0 to device ordinal 1` mean?
Does it mean that I cannot use multiple GPUs since they are not identical(I noticed that I only have one gpu running during the training)?
What is the consequence of this info?

```
I tensorflow/core/common_runtime/gpu/gpu_init.cc:61] cannot enable peer access from device ordinal 0 to device ordinal 1
I tensorflow/core/common_runtime/gpu/gpu_init.cc:61] cannot enable peer access from device ordinal 0 to device ordinal 2
I tensorflow/core/common_runtime/gpu/gpu_init.cc:61] cannot enable peer access from device ordinal 1 to device ordinal 0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:61] cannot enable peer access from device ordinal 1 to device ordinal 3
I tensorflow/core/common_runtime/gpu/gpu_init.cc:61] cannot enable peer access from device ordinal 2 to device ordinal 0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:61] cannot enable peer access from device ordinal 2 to device ordinal 3
I tensorflow/core/common_runtime/gpu/gpu_init.cc:61] cannot enable peer access from device ordinal 3 to device ordinal 1
I tensorflow/core/common_runtime/gpu/gpu_init.cc:61] cannot enable peer access from device ordinal 3 to device ordinal 2
I tensorflow/core/common_runtime/gpu/gpu_init.cc:138] DMA: 0 1 2 3 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:148] 0:   Y N N Y 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:148] 1:   N Y Y N 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:148] 2:   N Y Y N 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:148] 3:   Y N N Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:867] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:02:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:867] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX TITAN X, pci bus id: 0000:01:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:867] Creating TensorFlow device (/gpu:2) -> (device: 2, name: GeForce GTX TITAN X, pci bus id: 0000:03:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:867] Creating TensorFlow device (/gpu:3) -> (device: 3, name: GeForce GTX 1080, pci bus id: 0000:04:00.0)
```
"
4012,Add favicon to TensorBoard,"Adding `favicon.ico` (TensorFlow's, I imagine) would avoid the following warning on launch and beautify TensorBoard. ;)

`WARNING:tensorflow:IOError [Errno 2] No such file or directory: '.../tensorflow/tensorboard/favicon.ico' on path .../tensorflow/tensorboard/favicon.ico`
"
4011,Is there anyway to run a tensorflow graph (.pb or .meta) generated by single node tf.sess on a distributed environments with multiple ps nodes and worker nodes?,"Will future versions of tensorflow provide a way to run the tensorflow graph generated by single node tf.sess on a distributed environments with multiple ps nodes and worker nodes through python interfaces?
Or is it supported right now?

I am trying to build my tf.graph on my notebook (single node) and save then graph into a binary file, 
and then loading the binary graph into a distributed environment (with multiply ps and worker nodes) to train and verify it. It seems it is not supported now.

I tried it on tensorflow-0.10 and failed.
By using tf.train.write_graph(sess.graph_def, path, pb_name) interface: The graph saved is not trainable as loading the .pb file through import_graph_def will only g.create_ops according to the '.bp' file but not add then into ops.collections. So the graph loaded is not trainable
By using tf.saver.save to save a "".meta"" file: The loaded graph cannot fit into the distributed environment as devices assignment is messy. 
I tried the tf.train.import_meta_graph('test_model.meta', clear_devices=True) interface to let the load clean the original device assignment and let the ""with tf.device(device_setter)"" reassign the device for each variable, but there is a problem as operations belonging to ""Saver"" and ""Restore"" still can not be assigned correctly. When creating operations for ""Saver"" and ""Restore"" ops through g.create_op inside import_graph_def called by import_meta_graph, the device_setter will not assign ps node to these ops as their name is not ""Variable"".
Is there any way to do so?
"
4009,tf.image.decode_image would be nice (handling both png and jpeg),"`tf.image.decode_jpeg` crashes on a seemingly valid input image with an  `InvalidArgumentError: Invalid JPEG data, size 107746`. I've used both the current nightly from tonight, as well as TF 0.9.0, using Python 3.5.2 on CentOS 7 on two different machines.

The image  can be opened/displayed without problems in Firefox, GIMP and other image viewers, as well as with the `PIL` image library within Python. The image is part of the ILSVRC2015 dataset, `n02105855/n02105855_2933.JPEG`. I've  uploaded it to http://imgur.com/a/pblKL for your reference (i hope imgur doesn't recode the image, let me know). 

This is a minimal code example:

```
import tensorflow as tf
fn = './imagenet/ILSVRC2015/Data/CLS-LOC/train/n02105855/n02105855_2933.JPEG'
with tf.Graph().as_default():
    image_contents = tf.read_file(fn)
    image = tf.image.decode_jpeg(image_contents, channels=3)
    init_op = tf.initialize_all_tables()
    with tf.Session() as sess:
        sess.run(init_op)
        tmp = sess.run(image)
```

Which crashes with the following error:

```
InvalidArgumentError: Invalid JPEG data, size 107746
 [[Node: DecodeJpeg = DecodeJpeg[acceptable_fraction=1, channels=3, fancy_upscaling=true, ratio=1, try_recover_truncated=false, _device=""/job:localhost/replica:0/task:0/cpu:0""](ReadFile)]]
Caused by op 'DecodeJpeg', defined at:
```

For reference, here the full stack trace is here: http://pastebin.com/GZMWDjge
"
4007,"Request for TF example  ""DeepMind : Teaching Machines to Read and Comprehend"" ","Deepmind's paper:Teaching Machines to Read and Comprehend
[http://arxiv.org/pdf/1506.03340v3.pdf](url)
 will be a good example for RNN with **attention**. 
However, an unofficial Tensorflow implementation has been suspended over 7 months.
[https://github.com/carpedm20/attentive-reader-tensorflow](url)

Other theano implementations do not demonstrate how to visualize the attention weight:
[https://github.com/thomasmesnard/DeepMind-Teaching-Machines-to-Read-and-Comprehend](url)
[https://github.com/adbrebs/rnn_reader](url)
"
4006,"Possible bug in tensorboard ""EVENT"" display?","Hi, I wanted to display the training accuracy of my model. However, I found that it could't display when I updated with tensorflow 0.10 rc version. 

I checked two different situations:
Firstly, it do have values when I download the csv file, as show in below figure.
![tensorboard_v0 10](https://cloud.githubusercontent.com/assets/7037235/17919903/803c2bf4-6a03-11e6-969e-d23358c40387.PNG)

Secondly, it can display the accuracy successfully when I rollback tensorflow version to 0.9, as show in below figure.
![tensorboard_v0 9](https://cloud.githubusercontent.com/assets/7037235/17920056/991e1f5a-6a04-11e6-8782-23d7bac342b8.PNG)

Is that a bug in tensorflow 0.10? 
"
4005,Can we have a feature for max out activation function?,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System:

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`
### Steps to reproduce

1.
2.
3.
### What have you tried?

1.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
4003,Print Version of cuDNN Being Used,"Right now what you get is device info for example:

```
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:
name: GRID K520
major: 3 minor: 0 memoryClockRate (GHz) 0.797
pciBusID 0000:00:03.0
Total memory: 4.00GiB
Free memory: 3.95GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y
```

Theano prints:

```
Using gpu device 0: GRID K520 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 4007)
```

giving you device info but also info on the version of cuDNN.
"
4002,Ignoring gpu device with Cuda compute capability 3.0. The minimum required Cuda capability is 3.5.,"I build TF with: 

```
TF_UNOFFICIAL_SETTING=1
TF_CUDA_COMPUTE_CAPABILITIES=3.0
```

which used to work but within the last few days I now get:

```
Ignoring gpu device (device: 0, name: GRID K520, pci bus id: 0000:00:03.0) with Cuda compute capability 3.0. The minimum required Cuda capability is 3.5.
```

I wonder if this got broken with: https://github.com/tensorflow/tensorflow/commit/353235e0b2b35f3df43f42ef84ca00ccda7a3a6d
"
4001,iOS ld error,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System:

Installed version of CUDA and cuDNN:  No
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. Which pip package you installed.  
   from source
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   0.10.0rc0

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`) 
   cc3153a7a0a23533d14ead34db37e4ccd7892079
2. The output of `bazel version`  
   0.3.1-homebrew
### Steps to reproduce
1. ./configure
2.  sh tensorflow/contrib/makefile/build_all_ios.sh
   or sh sh tensorflow/contrib/makefile/compile_ios_tensorflow.sh
### What have you tried?
1.   only compile the libtensorflow-core-<arm arch>.a  on different platform and lipo them to get libtensorflow-core.a
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
all arm arch have got these logs.

""tensorflow::functor::ReduceAndReshape<Eigen::ThreadPoolDevice, float, 6, 1>::operator()(Eigen::ThreadPoolDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 6, 1, long>, 16>, Eigen::TensorMap<Eigen::Tensor<float const, 6, 1, long>, 16>, Eigen::DSizes<long, 1> const&, Eigen::DSizes<long, 6> const&) const"", referenced from:
      void tensorflow::TileGradientOpEigen::ThreadPoolDevice::HandleReduce<float, 6, 1>(tensorflow::OpKernelContext_, std::__1::vector<int, std::__1::allocator<int> > const&, tensorflow::Tensor_) in libtensorflow-core-arm64.a(tile_ops.o)
  ""tensorflow::functor::TileGrad<Eigen::ThreadPoolDevice, int, 6>::operator()(Eigen::ThreadPoolDevice const&, Eigen::TensorMap<Eigen::Tensor<int, 6, 1, long>, 16>, Eigen::TensorMap<Eigen::Tensor<int const, 6, 1, long>, 16>, Eigen::DSizes<long, 6> const&, Eigen::DSizes<long, 6> const&, bool) const"", referenced from:
      void tensorflow::TileGradientOpEigen::ThreadPoolDevice::HandleCaseImpl<(tensorflow::DataType)3, 6>(tensorflow::OpKernelContext_, std::__1::vector<int, std::__1::allocator<int> > const&, tensorflow::gtl::ArraySlice<int> const&, tensorflow::Tensor_) in libtensorflow-core-arm64.a(tile_ops.o)
  ""tensorflow::functor::TileGrad<Eigen::ThreadPoolDevice, float, 6>::operator()(Eigen::ThreadPoolDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 6, 1, long>, 16>, Eigen::TensorMap<Eigen::Tensor<float const, 6, 1, long>, 16>, Eigen::DSizes<long, 6> const&, Eigen::DSizes<long, 6> const&, bool) const"", referenced from:
      void tensorflow::TileGradientOpEigen::ThreadPoolDevice::HandleCaseImpl<(tensorflow::DataType)1, 6>(tensorflow::OpKernelContext_, std::__1::vector<int, std::__1::allocator<int> > const&, tensorflow::gtl::ArraySlice<int> const&, tensorflow::Tensor_) in libtensorflow-core-arm64.a(tile_ops.o)
  ""tensorflow::functor::Tile<Eigen::ThreadPoolDevice, int, 6>::operator()(Eigen::ThreadPoolDevice const&, Eigen::TensorMap<Eigen::Tensor<int, 6, 1, long>, 16>, Eigen::TensorMap<Eigen::Tensor<int const, 6, 1, long>, 16>, std::__1::array<int, 6ul> const&) const"", referenced from:
      void tensorflow::TileOpEigen::ThreadPoolDevice::HandleCaseImpl<(tensorflow::DataType)3, 6>(tensorflow::OpKernelContext_, tensorflow::gtl::ArraySlice<int> const&, tensorflow::Tensor_) in libtensorflow-core-arm64.a(tile_ops.o)
  ""tensorflow::functor::ReduceAndReshape<Eigen::ThreadPoolDevice, int, 6, 1>::operator()(Eigen::ThreadPoolDevice const&, Eigen::TensorMap<Eigen::Tensor<int, 6, 1, long>, 16>, Eigen::TensorMap<Eigen::Tensor<int const, 6, 1, long>, 16>, Eigen::DSizes<long, 1> const&, Eigen::DSizes<long, 6> const&) const"", referenced from:
      void tensorflow::TileGradientOpEigen::ThreadPoolDevice::HandleReduce<int, 6, 1>(tensorflow::OpKernelContext_, std::__1::vector<int, std::__1::allocator<int> > const&, tensorflow::Tensor_) in libtensorflow-core-arm64.a(tile_ops.o)
  ""tensorflow::functor::Tile<Eigen::ThreadPoolDevice, float, 6>::operator()(Eigen::ThreadPoolDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 6, 1, long>, 16>, Eigen::TensorMap<Eigen::Tensor<float const, 6, 1, long>, 16>, std::__1::array<int, 6ul> const&) const"", referenced from:
      void tensorflow::TileOpEigen::ThreadPoolDevice::HandleCaseImpl<(tensorflow::DataType)1, 6>(tensorflow::OpKernelContext_, tensorflow::gtl::ArraySlice<int> const&, tensorflow::Tensor_) in libtensorflow-core-arm64.a(tile_ops.o)
ld: symbol(s) not found for architecture arm64
clang: error: linker command failed with exit code 1 (use -v to see invocation)
make: **\* [/Users/chh/Dev_Ling/tensorflow/tensorflow/contrib/makefile/gen/bin/ios_ARM64/benchmark] Error 1
arm64 compilation failed.
"
3999,The problem about data flow graph?,"Hi everyone:
     I am a beginner for tensorflow, and do not understand something about the demo in tutorial files, like following:
![image](https://cloud.githubusercontent.com/assets/12611573/17914869/688d864a-69d8-11e6-8692-4c3e41e695bf.png)
     During testing, how can accuracy call the trained model for mnist.test.images and mnist.test.labels.
     Does the trained model flow to the accuracy?
     Can anyone help me? Thanks a lot!
"
3998,Enable building tensorflow as a submodule in cuda_configure,"Add support for path_prefix and tf_repo_name so that projects importing tf as a submodule can build with the new CUDA autoconf.
"
3996,Fix CMake build due to cuda_configure changes,"The new changes from #3269 broke the CMake build due to the header include path changes and the new `cuda_config.h` file generated by `cuda_configure`.
"
3994,Cannot use Variables as gradients in apply_gradients,"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/optimizer.py#L287 prevents the user from using a variable as a gradient when calling apply_gradients.

I'd like to do this to accumulate gradients over multiple minibatches, and then do a single gradient update.

The current code I have is

``` python
opt = tf.train.AdamOptimizer()                                                                                                   

tvs = tf.trainable_variables()
accum_vars = [tf.Variable(tf.zeros_like(tv.initialized_value()), trainable=False) for tv in tvs]                                        
zero_ops = [tv.assign(tf.zeros_like(tv)) for tv in accum_vars]

gvs = opt.compute_gradients(rmse, tvs)
accum_ops = [accum_vars[i].assign_add(gv[0]) for i, gv in enumerate(gvs)]

train_step = opt.apply_gradients([(accum_vars[i], gv[1]) for i, gv in enumerate(gvs)])  
```

that I'd like to run with logic like

```
while True:
    sess.run(zero_ops)

    for i in xrange(n_minibatches):
        sess.run(accum_ops, feed_dict=dict(X: Xs[i], y: ys[i]))

    sess.run(train_step)
```

Is there any reason variables cannot be used as arguments to apply_gradients? It seems to me that they should be able to be used as gradients. If there is a good reason, is there a recommended way to have the pattern I desire? I'm currently using the ugly hack of replacing the `train_step` definition with 

```
train_step = opt.apply_gradients([(accum_vars[i].assign(accum_vars[i]), gv[1]) 
                                  for i, gv in enumerate(gvs)])
```

because `Variable.assign` returns a tensor.
"
3992,Add support for pyx_library in the open-source build.,"I have a model that has a lot of big constant Tensors (2048x2048), and building the graph is extremely slow. After profiling my code, I see that the bottlenecks are the functions `SlowAppend<TYPE>ArrayToTensorProto`  defined in `tensorflow/python/framework/tensor_util.py` which take 98% of the time. 

Reviewing the source code I see the following lines:

```
# TODO(opensource): Add support for pyx_library in the open-source build.
# For now, we use the slow versions that fast_tensor_util replaces.
# pylint: disable=g-import-not-at-top
```

So I was wondering if it is planned to add this feature in the short term, and if not, any advice on how to speed up the graph building process? 

Thanks
"
3991,import tensorflow: Library not loaded: libcudart 7.5 (Mac OSX),"### Environment info

Operating System: Mac OSX El Capitan

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

What is CUDA and cuDNN? I didn't notice any mention of these!?

`Optional: Install CUDA (GPUs on Linux)` but I'm on a Mac!!

```
$ ls -l /path/to/cuda/lib/libcud*
ls: /path/to/cuda/lib/libcud*: No such file or directory
```

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

`ImportError ... Library not loaded: @rpath/libcudart.7.5.dylib`

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`
### Steps to reproduce

Following install instructions for Mac OSX: http://learningtensorflow.com/lesson1/
https://www.tensorflow.org/versions/r0.8/get_started/os_setup.html

Just realised there is one for 0.10 as well: https://www.tensorflow.org/versions/r0.10/get_started/os_setup.html
### What have you tried?

I tried to follow the install instructions.

```
21:37 $ source activate tensorflow
(tensorflow) ✔ 
21:38 $ pip install --ignore-installed --upgrade $TF_BINARY_URL
Collecting tensorflow==0.10.0rc0 from https://storage.googleapis.com/tensorflow/mac/gpu/tensorflow-0.10.0rc0-py3-none-any.whl
  Downloading https://storage.googleapis.com/tensorflow/mac/gpu/tensorflow-0.10.0rc0-py3-none-any.whl (94.1MB)
    100% |████████████████████████████████| 94.1MB 7.1kB/s 
Collecting numpy>=1.10.1 (from tensorflow==0.10.0rc0)
  Using cached numpy-1.11.1-cp35-cp35m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl
Collecting six>=1.10.0 (from tensorflow==0.10.0rc0)
  Using cached six-1.10.0-py2.py3-none-any.whl
Collecting protobuf==3.0.0b2 (from tensorflow==0.10.0rc0)
  Using cached protobuf-3.0.0b2-py2.py3-none-any.whl
Collecting wheel>=0.26 (from tensorflow==0.10.0rc0)
  Using cached wheel-0.29.0-py2.py3-none-any.whl
Collecting setuptools (from protobuf==3.0.0b2->tensorflow==0.10.0rc0)
  Using cached setuptools-26.0.0-py2.py3-none-any.whl
Installing collected packages: numpy, six, setuptools, protobuf, wheel, tensorflow
Successfully installed numpy-1.11.1 protobuf-3.0.0b2 setuptools-25.1.6 six-1.10.0 tensorflow-0.10.0rc0 wheel-0.29.0
(tensorflow) ✔ ~/repos/aurelia-projs/ai/ai-component [master|✔] 

21:40 $ python
Python 3.5.2 |Continuum Analytics, Inc.| (default, Jul  2 2016, 17:52:12) 
[GCC 4.2.1 Compatible Apple LLVM 4.2 (clang-425.0.28)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.

>>> import tensorflow as tf
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/Users/kristianmandrup/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/__init__.py"", line 23, in <module>
    from tensorflow.python import *
  File ""/Users/kristianmandrup/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/__init__.py"", line 48, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/Users/kristianmandrup/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 28, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""/Users/kristianmandrup/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)
  File ""/Users/kristianmandrup/anaconda/envs/tensorflow/lib/python3.5/imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""/Users/kristianmandrup/anaconda/envs/tensorflow/lib/python3.5/imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: dlopen(/Users/kristianmandrup/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow.so, 10): Library not loaded: @rpath/libcudart.7.5.dylib
  Referenced from: /Users/kristianmandrup/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow.so
  Reason: image not found
```
"
3990,TypeError: evaluate() got an unexpected keyword argument 'batch_size',"ok，When I run this code as follow, I have some error.
**Code:**
This code is from https://github.com/mouradmourafiq/tensorflow-lstm-regression ,
I found  the error may be result from some code:
_validation_monitor = learn.monitors.ValidationMonitor(X['val'], y['val'],
                                                      every_n_steps=PRINT_STEPS,
                                                      early_stopping_rounds=1000)
regressor.fit(X['train'], y['train'], monitors=[validation_monitor], logdir=LOG_DIR)_

**Then, here is the error message:**
INFO:tensorflow:Error reported to Coordinator: <type 'exceptions.TypeError'>, evaluate() got an unexpected keyword argument 'batch_size'
INFO:tensorflow:Error reported to Coordinator: <type 'exceptions.TypeError'>, evaluate() got an unexpected keyword argument 'batch_size'
Traceback (most recent call last):
  File ""model.py"", line 178, in <module>
    regressor.fit(X['train'], y['train'],monitors=[validation_monitor], logdir=LOG_DIR)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/base.py"", line 166, in fit
    monitors=monitors)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 578, in _train_model
    max_steps=max_steps)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/graph_actions.py"", line 280, in _supervised_train
    None)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/supervised_session.py"", line 270, in run
    run_metadata=run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/recoverable_session.py"", line 54, in run
    run_metadata=run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/coordinated_session.py"", line 70, in run
    self._coord.join(self._coordinated_threads_to_join)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/coordinator.py"", line 357, in join
    six.reraise(_self._exc_info_to_raise)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/coordinated_session.py"", line 66, in run
    return self._sess.run(_args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/monitored_session.py"", line 107, in run
    induce_stop = monitor.step_end(monitors_step, monitor_outputs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py"", line 396, in step_end
    return self.every_n_step_end(step, output)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py"", line 687, in every_n_step_end
    steps=self.eval_steps, metrics=self.metrics, name=self.name)
TypeError: evaluate() got an unexpected keyword argument 'batch_size'
@mouradmourafiq  
### Environment info

Operating System: 
ubuntu14.04 python2.7 tensorflow with only CPU
"
3989,Error Building Docker Image,"Using `Dockerfile.devel-gpu` branched from 459c2fed498530b794c4871892fd68d1e6834ac6.

```
Configuration finished
INFO: Reading 'startup' options from /root/.bazelrc: --batch
ERROR: com.google.devtools.build.lib.packages.BuildFileContainsErrorsException: error loading package '': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):
    File ""/tensorflow/third_party/gpus/cuda_configure.bzl"", line 406
        _create_cuda_repository(repository_ctx)
    File ""/tensorflow/third_party/gpus/cuda_configure.bzl"", line 340, in _create_cuda_repository
        _find_cudnn_lib_path(repository_ctx, cudnn_install_base..., ...)
    File ""/tensorflow/third_party/gpus/cuda_configure.bzl"", line 249, in _find_cudnn_lib_path
        fail(""Cannot find %s or %s under %s"" ...))
Cannot find lib64/libcudnn.so.5 or libcudnn.so.5 under /usr/local/cuda.
____Elapsed time: 1.274s
The command '/bin/sh -c ./configure &&     bazel build --local_resources 3072,3.0,1.0 -c opt --config=cuda tensorflow/tools/pip_package:build_pip_package &&     bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/pip &&     pip install --upgrade /tmp/pip/tensorflow-*.whl' returned a non-zero code: 1

./build-all.sh returned exit code 1
```
"
3987,About tf.contrib.slim data prepare documentation,"I have spend much time to understand how to prepare my data to feed into Slim Net. 
But I still can't quiet understand how to prepare my training data.
Is there a more detailed method for processing the training data, like Caffe ImageNet tutorial:http://caffe.berkeleyvision.org/gathered/examples/imagenet.html
"
3986,Freeze graph: node is not in graph (even though it's been named),"### Environment info

Operating System: Ubuntu 14.04 LTS 64-bit

Installed version of CUDA and cuDNN: none

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`): fc9162975e52978d3af38549b570cc3cc5f0ab66
2. The output of `bazel version`

```
Build label: 0.3.0
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Jun 10 11:38:23 2016 (1465558703)
Build timestamp: 1465558703
Build timestamp as int: 1465558703
```
### Steps to reproduce
1. Copy the IPython Notebook for Assignment 6 of Udacity's deep learning course ([here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/udacity/6_lstm.ipynb))
2. Change `saved_sample_output = tf.Variable(tf.zeros([1, num_nodes]))` to `saved_sample_output = tf.Variable(tf.zeros([1, num_nodes]), name=""saved_sample_output"")`
3. Modify the code like so:

``` python
with tf.Session(graph=graph) as session:
  tf.initialize_all_variables().run()
  print('Initialized')
  mean_loss = 0
  # code omitted (no changes)
  # new code below:
  saver = tf.train.Saver(tf.all_variables())
  saver.save(session, '/home/me/Documents/checkpoint.ckpt', write_meta_graph=False)
  tf.train.write_graph(graph.as_graph_def(), '/home/me/Documents', 'graph.pb')
```
1. Run.
2. Verify that `checkpoint.ckpt` and `graph.pb` have been successfully created in the directory.
3. In the tensorflow source directory, run:

```
bazel build tensorflow/python/tools:freeze_graph && bazel-bin/tensorflow/python/tools/freeze_graph --input_graph=/home/me/Documents/graph.pb --input_checkpoint=/home/me/Documents/checkpoint.ckpt --output_graph=/home/me/Documents/frozen_graph.pb --output_node_names=saved_sample_output
```
### What have you tried?

Checked the `graph.pb` file to make sure that node had actually been named properly. Seems like it was:

```
# other stuff
node {
  name: ""saved_sample_output""
  op: ""Variable""
  attr {
    key: ""container""
    value {
      s: """"
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 1
        }
        dim {
          size: 64
        }
      }
    }
  }
  attr {
    key: ""shared_name""
    value {
      s: """"
    }
  }
}
# etc.
```

I'm pretty much stumped with this one since [this](https://stackoverflow.com/questions/38958662/tensorflow-what-are-the-output-node-names-for-freeze-graph-py-in-the-model-wi) issue on StackOverflow says to pass in a name parameter for the node you want, which is what I did, to no avail (even without the name parameter, it still gave the same error).
**Edit:** Got freeze_graph to run successfully with the `sample_prediction` node (changed `sample_prediction = tf.nn.softmax(tf.nn.xw_plus_b(sample_output, w, b))` to `sample_prediction = tf.nn.softmax(tf.nn.xw_plus_b(sample_output, w, b), name=""sample_prediction"")`). However, I still haven't figured out why that worked, and this didn't.
### Logs or other output that would be helpful

```
Traceback (most recent call last):
  File ""/home/me/tf_m/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py"", line 134, in <module>
    tf.app.run()
  File ""/home/me/tf_m/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""/home/me/tf_m/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py"", line 131, in main
    FLAGS.output_graph, FLAGS.clear_devices, FLAGS.initializer_nodes)
  File ""/home/me/tf_m/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py"", line 120, in freeze_graph
    sess, input_graph_def, output_node_names.split("",""))
  File ""/home/me/tf_m/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/framework/graph_util.py"", line 232, in convert_variables_to_constants
    inference_graph = extract_sub_graph(input_graph_def, output_node_names)
  File ""/home/me/tf_m/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/framework/graph_util.py"", line 156, in extract_sub_graph
    assert d in name_to_node_map, ""%s is not in graph"" % d
AssertionError: saved_sample_output is not in graph
```
"
3985,Refactored GPU installation from source issue (Ubuntu 16.04) ,"It looks like the GPU installation from source got refactored and is failing to compile on my Ubuntu 16.04, CUDA 8.0, cuDNN 5.0, with GTX 1080 GPU.

I had the GTX 1080 working with the build from a few days ago, but just pulled from the head and now cannot compile so I am not sure if this is the auto_configure for the GPU or not I saw going though.

$ git rev-parse HEAD
6d04d601e9e8758ec4642fa9d548b7321d804d63

$ bazel version
Build label: 0.3.1
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Jul 29 09:09:52 2016 (1469783392)
Build timestamp: 1469783392
Build timestamp as int: 1469783392

$ ./configure

GPU configured

INFO: All external dependencies fetch successfully.
Configuration finished

$ bazel build -c opt --config=cuda --verbose_failures //tensorflow/tools/pip_package:build_pip_package  1>~/initial_output.txt 2>&1 
[initial_output.txt](https://github.com/tensorflow/tensorflow/files/432724/initial_output.txt)

GPU CUDA includes were not found so I added line to new file: CROSSTOOL.tpl @ line 66

  cxx_builtin_include_directory: ""/usr/local/cuda-8.0/include""

$ bazel build -c opt --config=cuda --verbose_failures //tensorflow/tools/pip_package:build_pip_package  1>~/second_output.txt 2>&1 
[second_output.txt](https://github.com/tensorflow/tensorflow/files/432726/second_output.txt)

I think it is complaining about not finding ""crosstool_wrapper_driver_is_not_gcc"".

I did a ""locate"" and my version seems to be at the following:
$ locate crosstool_wrapper_driver_is_not_gcc
/home/greg/serving/tensorflow/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc
/home/greg/serving/tf_models/syntaxnet/tensorflow/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc
/home/greg/tensorflow/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.tpl

Let me know where the file is that has the path to the crosstool_wrapper.... and I can update the path to test that as a fix unless you know the root cause...

EDIT: BTW, the build works fine without the GPU configuration
"
3984,ERROR: no such package '@local_config_cuda//crosstool': BUILD file not found on package path.,"I am trying to build tensorflow from source
When building the pip package with bazel, I got this error:   invalid command 'bdist_wheel'

But I have python 2.7.5 and wheel 0.29.0 in my linux, could you help me out？
1. The commit hash (`git rev-parse HEAD`):6d04d601e9e8758ec4642fa9d548b7321d804d63
2. The output of `bazel version`:0.3.1
### Logs:

[yxwang@gpu02 tensorflow]$ wheel version
wheel 0.29.0
[yxwang@gpu02 tensorflow]$ python -V
Python 2.7.5
[yxwang@gpu02 tensorflow]$ bazel-bin/tensorflow/tools/pip_package/build_pip_package  /tmp/tensorflow_pkg
Tue Aug 23 10:37:26 EDT 2016 : === Using tmpdir: /tmp/tmp.OMZ3S3VXj1
/tmp/tmp.OMZ3S3VXj1 ~/local/tensorflow
Tue Aug 23 10:37:27 EDT 2016 : === Building wheel
usage: setup.py [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]
   or: setup.py --help [cmd1 cmd2 ...]
   or: setup.py --help-commands
   or: setup.py cmd --help

error: invalid command 'bdist_wheel'
"
3983,Installation failed on Mac OS X with protobuf 3.0.0b2,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System:
Mac OS X 10.11.6

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
No CUDA

If installed from binary pip package, provide:
1. Which pip package you installed.
# Mac OS X, CPU only, Python 2.7:

$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.10.0rc0-py2-none-any.whl

log:
Requirement already satisfied (use --upgrade to upgrade): tensorflow==0.10.0rc0 from https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.10.0rc0-py2-none-any.whl in ./tensorflow/lib/python2.7/site-packages
Requirement already satisfied (use --upgrade to upgrade): mock>=2.0.0 in /usr/local/lib/python2.7/site-packages (from tensorflow==0.10.0rc0)
Requirement already satisfied (use --upgrade to upgrade): six>=1.10.0 in /usr/local/lib/python2.7/site-packages/six-1.10.0-py2.7.egg (from tensorflow==0.10.0rc0)
Requirement already satisfied (use --upgrade to upgrade): protobuf==3.0.0b2 in /usr/local/lib/python2.7/site-packages (from tensorflow==0.10.0rc0)
Requirement already satisfied (use --upgrade to upgrade): wheel in ./tensorflow/lib/python2.7/site-packages (from tensorflow==0.10.0rc0)
Requirement already satisfied (use --upgrade to upgrade): numpy>=1.10.1 in /usr/local/lib/python2.7/site-packages/numpy-1.11.1-py2.7-macosx-10.11-x86_64.egg (from tensorflow==0.10.0rc0)
Requirement already satisfied (use --upgrade to upgrade): funcsigs>=1; python_version < ""3.3"" in /usr/local/lib/python2.7/site-packages (from mock>=2.0.0->tensorflow==0.10.0rc0)
Requirement already satisfied (use --upgrade to upgrade): pbr>=0.11 in /usr/local/lib/python2.7/site-packages (from mock>=2.0.0->tensorflow==0.10.0rc0)
Requirement already satisfied (use --upgrade to upgrade): setuptools in /usr/local/lib/python2.7/site-packages/setuptools-26.0.0-py2.7.egg (from protobuf==3.0.0b2->tensorflow==0.10.0rc0)

And the version of the protobuf is 3.0.0b2.
1. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   Traceback (most recent call last):
   File ""<string>"", line 1, in <module>
   File ""/Users/ttomato/tensorflow/lib/python2.7/site-packages/tensorflow/**init**.py"", line 23, in <module>
     from tensorflow.python import *
   File ""/Users/ttomato/tensorflow/lib/python2.7/site-packages/tensorflow/python/**init**.py"", line 52, in <module>
     from tensorflow.core.framework.graph_pb2 import *
   File ""/Users/ttomato/tensorflow/lib/python2.7/site-packages/tensorflow/core/framework/graph_pb2.py"", line 16, in <module>
     from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2
   File ""/Users/ttomato/tensorflow/lib/python2.7/site-packages/tensorflow/core/framework/attr_value_pb2.py"", line 16, in <module>
     from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2
   File ""/Users/ttomato/tensorflow/lib/python2.7/site-packages/tensorflow/core/framework/tensor_pb2.py"", line 16, in <module>
     from tensorflow.core.framework import tensor_shape_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2
   File ""/Users/ttomato/tensorflow/lib/python2.7/site-packages/tensorflow/core/framework/tensor_shape_pb2.py"", line 22, in <module>
     serialized_pb=_b('\n,tensorflow/core/framework/tensor_shape.proto\x12\ntensorflow\""z\n\x10TensorShapeProto\x12-\n\x03\x64im\x18\x02 \x03(\x0b\x32 .tensorflow.TensorShapeProto.Dim\x12\x14\n\x0cunknown_rank\x18\x03 \x01(\x08\x1a!\n\x03\x44im\x12\x0c\n\x04size\x18\x01 \x01(\x03\x12\x0c\n\x04name\x18\x02 \x01(\tB2\n\x18org.tensorflow.frameworkB\x11TensorShapeProtosP\x01\xf8\x01\x01\x62\x06proto3')
   TypeError: __init__() got an unexpected keyword argument 'syntax'
### Steps to reproduce
1. Pip install.
   2.
   3.
### What have you tried?
1. Tried a lot of times with ""pip install --upgrade portobuf"". And make sure the version of protobuf is correct.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
3982,Can not configure by new commit,"the new version 6d04d601e9e8758ec4642fa9d548b7321d804d63
./configure  on Mac platform

cuda_configure.bzl:409:18: function 'repository_rule' does not exist.
"
3981,Clang host compiler support?,"Hi all, 

I couldn't help but notice that currently TensorFlow is tightly coupled with GCC. Is there a plan to make it more flexible with the choice for host compiler? like clang? 
Is there any effort or plans for that?

Thanks,
Luke
"
3980,CUDA autoconf improvements,"Some improvements to the new CUDA autoconf mechanism from the discussion in #3269 and #3966:
- Autodetect `nvcc` version and:
  - Set `CUDA_TOOLKIT_PATH` based on detected version
  - Set `--expt-relaxed-constexpr` iff detected version is >= 7.5.
- Set `cxx_builtin_include_directory` for CUDA headers based on detected include directories, similar to [`_get_cxx_inc_directories`](https://github.com/bazelbuild/bazel/blob/master/tools/cpp/cc_configure.bzl#L125)
- Move remaining checks in `configure` script into `cuda_configure` so that the `configure` script only contains the user interface.
"
3979,Quantization ops missing from benchmark program,"### Environment info

Operating System: Mac OS X 10.11.4
CUDA: No
TF installed from source
`git rev-parse HEAD`: `6d04d601e9e8758ec4642fa9d548b7321d804d63`

```
bazel version
Build label: 0.2.3-homebrew
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Tue May 17 15:07:52 2016 (1463497672)
Build timestamp: 1463497672
Build timestamp as int: 1463497672
```
### Problem

I want to run inference on mobile and thought quantization would be a good idea. I also want to use the [benchmark program](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/benchmark) to see speed and memory consumption of different models before starting to train them.

However the benchmark seems to be missing the quantization ops needed (it doesn't matter which quantization mode I use):

```
E tensorflow/tools/benchmark/benchmark_model.cc:72] Could not create TensorFlow Session: Not found: Op type not registered 'QuantizeV2'
```

I realize that I should modify this [BUILD](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/benchmark/BUILD) file somehow to include the missing ops but I can't figure out Bazel's name of the built library or how to link it statically into the benchmark program. Or are the ops missing for a reason (incompatible with the normals ops etc)?

I know that this is more of a question than a bug report, but I don't think I'm the only one with problem so perhaps you can treat is as a documentation bug?
"
3978,Tensorflow hangs when enqueueing with session timeout specified,"I am creating a simple `FIFOQueue` and enqueueing elements to it. Everything works fine when the session timeout is not specified (code as below, with timeout commented out):

```
$ time python ex.py
enqueue
enqueue
enqueue
enqueue
enqueue
1.56user 0.24system 0:01.70elapsed 105%CPU 
```

Everything finishes correctly. But when I run the same code with timeout specified (to 60 seconds):

```
import tensorflow as tf
import numpy as np

tf.reset_default_graph()
data = np.array([1, 2])
num_epochs = 5
queue1 = tf.FIFOQueue(capacity=50, dtypes=[tf.int32], shapes=[()])

def create_session():
    config = tf.ConfigProto()
    config.operation_timeout_in_ms=60000
    return tf.InteractiveSession(config=config)

enqueue_op = queue1.enqueue_many(data)
sess = create_session()
tf.train.start_queue_runners()
for i in range(num_epochs):
    print(""enqueue"")
    sess.run(enqueue_op)
```

```
$ time python ex.py
enqueue
enqueue
E tensorflow/core/client/tensor_c_api.cc:485] Timed out waiting for notification
Traceback (most recent call last):
  File ""ex.py"", line 21, in <module>
    sess.run(enqueue_op)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 382, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 655, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 723, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 743, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.DeadlineExceededError: Timed out waiting for notification
Command exited with non-zero status 1
1.57user 0.24system 1:01.71elapsed 2%CPU
```

The number of ""enqueue""s is not deterministic, but the code never finishes. Note that with timeout specified the code didn't manage to finish in a minute (in comparison to less than 2 seconds with no timeout).
### Environment info

Operating System: lubuntu 14.04, kernel 3.13.0-32-generic

Installed version of CUDA and cuDNN: no CUDA, using just CPU
If installed from binary pip package, provide:
1. Which pip package you installed: https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`: 0.10.0rc0
"
3977,Installation failed on Mac OS X,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System:
OS X EI Capitan 10.11.6

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
ls: /path/to/cuda/lib/libcud*: No such file or directory

If installed from binary pip package, provide:
install from pip package
# Mac OS X, CPU only, Python 2.7:

$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.10.0rc0-py2-none-any.whl
1. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   Traceback (most recent call last):
   File ""<string>"", line 1, in <module>
   File ""/usr/local/lib/python2.7/site-packages/tensorflow/**init**.py"", line 23, in <module>
     from tensorflow.python import *
   File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/**init**.py"", line 52, in <module>
     from tensorflow.core.framework.graph_pb2 import *
   File ""/usr/local/lib/python2.7/site-packages/tensorflow/core/framework/graph_pb2.py"", line 16, in <module>
     from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2
   File ""/usr/local/lib/python2.7/site-packages/tensorflow/core/framework/attr_value_pb2.py"", line 16, in <module>
     from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2
   File ""/usr/local/lib/python2.7/site-packages/tensorflow/core/framework/tensor_pb2.py"", line 16, in <module>
     from tensorflow.core.framework import tensor_shape_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2
   File ""/usr/local/lib/python2.7/site-packages/tensorflow/core/framework/tensor_shape_pb2.py"", line 22, in <module>
     serialized_pb=_b('\n,tensorflow/core/framework/tensor_shape.proto\x12\ntensorflow\""z\n\x10TensorShapeProto\x12-\n\x03\x64im\x18\x02 \x03(\x0b\x32 .tensorflow.TensorShapeProto.Dim\x12\x14\n\x0cunknown_rank\x18\x03 \x01(\x08\x1a!\n\x03\x44im\x12\x0c\n\x04size\x18\x01 \x01(\x03\x12\x0c\n\x04name\x18\x02 \x01(\tB2\n\x18org.tensorflow.frameworkB\x11TensorShapeProtosP\x01\xf8\x01\x01\x62\x06proto3')
   TypeError: __init__() got an unexpected keyword argument 'syntax'
### Steps to reproduce
1. Install tensorflow from pip
2. Test installation.
### What have you tried?
1. uninstall protobuf and reinstall tensorflow again.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
3974,Regression in Performance between r0.9.0 and r0.10.0rc0.,"### Environment info

Operating System:

```
Linux 4.4.11-23.53
```
### Observations

I am testing on a Tesla K80 (details below) using the following lines:
- `nvidia-docker run --rm -it -v /tmp/cifar10_data:/tmp/cifar10_data tensorflow/tensorflow:0.9.0-devel-gpu  bash -c 'ln -s /usr/local/nvidia/lib64/libcuda.so.1 /usr/lib/x86_64-linux-gnu/libcuda.so && python /usr/local/lib/python2.7/dist-packages/tensorflow/models/image/cifar10/cifar10_multi_gpu_train.py'`
- `nvidia-docker run --rm -it -v /tmp/cifar10_data:/tmp/cifar10_data tensorflow/tensorflow:0.10.0rc0-devel-gpu python /usr/local/lib/python2.7/dist-packages/tensorflow/models/image/cifar10/cifar10_multi_gpu_train.py`

On r0.0.9, I get: ~`575 examples/sec`.
On r0.10.0rc0 I get ~`425 examples/sec`.

Here are the device stats:

```
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:04.0
Total memory: 11.17GiB
Free memory: 11.11GiB
```

I have the: Nvidia Driver Version: 367.35
"
3973,cifar10 train runs 50% slower than r0.9 in r0.10rc0,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System:

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`
### Steps to reproduce

1.
2.
3.
### What have you tried?

1.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
3972,tf.gradients returns None in tf.map_fn,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System:
Mac OS 10.10

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
None

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   0.10.0rc0

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`
### Steps to reproduce

I want to evaluate the diagonal of Hessian with `tf.map_fn`, which takes a function that maps each dimension (scalar) to its Hessian

```
import tensorflow as tf


def hessian_factory(f):
    def hessian1(x):
        g = tf.gradients(f, x)[0]
        h = tf.gradients(g, x)[0]
        return h

    return hessian1

sess = tf.Session()
x = tf.Variable(1.0)
sess.run(tf.initialize_all_variables())

f = 1. / (1 + tf.exp(-x))
func = hessian_factory(f)
h = tf.map_fn(func, x)

print(sess.run(h))
```

However, it seems `tf.gradients(f, x)` produces `None`.

Even the following statements gives `None`

```
import tensorflow as tf

sess = tf.Session()
x = tf.Variable(1.0)
sess.run(tf.initialize_all_variables())

f = 1. / (1 + tf.exp(-x))
h = tf.map_fn(lambda x: tf.gradients(f, x)[0], x)
```
### What have you tried?

1.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
3971,tf.contrib.metrics.streaming_auc evaluation exception,"I used `tf.contrib.metrics.streaming_auc` to evaluate DNN rank model, 

```
auc,  opts = tf.contrib.metrics.streaming_auc(logits, labels)
```

`logits` are my predicted results, `labels` are true labels, they have format:

```
Tensor(""Sigmoid:0"", shape=(100, 1), dtype=float32)
Tensor(""labels_placeholder:0"", shape=(100, ?), dtype=float32)
```

Errors as following:

```
Traceback (most recent call last):
  File ""/Users/nali/Workspace/tensorflow_example/search_click/MLP.py"", line 200, in <module>
    dnn.run(training_data=[x, y], epochs=10)
  File ""/Users/nali/Workspace/tensorflow_example/search_click/MLP.py"", line 135, in run
    feed_dict={self.x: x[samples], self.y: y[samples]})
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 372, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 636, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 708, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 728, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.FailedPreconditionError: Attempting to use uninitialized value auc/true_positives
     [[Node: auc/true_positives/read = Identity[T=DT_FLOAT, _class=[""loc:@auc/true_positives""], _device=""/job:localhost/replica:0/task:0/cpu:0""](auc/true_positives)]]
Caused by op u'auc/true_positives/read', defined at:
  File ""/Users/nali/Workspace/tensorflow_example/search_click/MLP.py"", line 200, in <module>
    dnn.run(training_data=[x, y], epochs=10)
  File ""/Users/nali/Workspace/tensorflow_example/search_click/MLP.py"", line 126, in run
    cross_entropy, accuracy, logits = self.training()
  File ""/Users/nali/Workspace/tensorflow_example/search_click/MLP.py"", line 100, in training
    accuracy = self.evaluation(logits, self.y)
  File ""/Users/nali/Workspace/tensorflow_example/search_click/MLP.py"", line 146, in evaluation
    auc, opt = tf.contrib.metrics.streaming_auc(logits, labels)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/contrib/metrics/python/ops/metric_ops.py"", line 718, in streaming_auc
    predictions, labels, thresholds, ignore_mask)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/contrib/metrics/python/ops/metric_ops.py"", line 600, in _tp_fn_tn_fp
    true_positives = _create_local('true_positives', shape=[num_thresholds])
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/contrib/metrics/python/ops/metric_ops.py"", line 75, in _create_local
    collections=collections)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/variables.py"", line 211, in __init__
    dtype=dtype)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/variables.py"", line 319, in _init_from_args
    self._snapshot = array_ops.identity(self._variable, name=""read"")
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 831, in identity
    result = _op_def_lib.apply_op(""Identity"", input=input, name=name)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py"", line 704, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2260, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1230, in __init__
    self._traceback = _extract_stack()
```

Thanks in advance.
"
3967,Document checkpoint file format,"Hi,
As far I can find, the internal structure of checkpoint files is not documented on tensorflow.org. I'm trying to write bindings to TensorFlow which can load checkpoints without making use of the Python API, so I was wondering if that information is available somewhere.
"
3965,Conv2d issue with GPU,"I have extracted the activations of a neural net at a certain layer with size [1,28,28,128] and I have a corresponding kernel that I want to convolve with these activations. The kernel shape is [3,3,128,256]. 
I am using:
- 2 GTX-1080 GPUs
- Cuda-8.0 (The problem persists with Cuda-7.5 as well)
- Graphics Driver: NVIDIA-367
- Python 2.7

When I perform 2D convolution using the CPU I get the correct answer but when I run it through the GPU I get all zeros. Note that, there is no ReLu operator involved here and the output should not be zero (as confirmed by the CPU output). In addition, I do not think this is a numerical precision error. 

I have included the codes, activations and the kernel files for reproducing the problem here: 

https://github.com/skolouri/GTX-1080_CNN_Issue
### Environment info

Operating System: Linux 14.04

Installed version of CUDA and cuDNN: Cuda-8.0.27 and cudNN-4.0.7
### Steps to reproduce

The steps are included here:

https://github.com/skolouri/GTX-1080_CNN_Issue
### What have you tried?
1. I have tried Cuda-7.5 
2. CPU works fine, GPU returns all zeros! 
"
3963,add threadpool.h to the files exported to the sysconfig.get_include() directory with a binary install,"### Environment info

Operating System: ubuntu 14.04

Installed version of CUDA and cuDNN: 7.5, v4
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
-rw-r--r-- 1 root root   322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root       19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root   383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root   720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a
-rwxr-xr-x 1 root root 61453024 Feb 23 16:00 /usr/local/cuda/lib64/libcudnn.so
-rwxr-xr-x 1 root root 61453024 Feb 23 16:00 /usr/local/cuda/lib64/libcudnn.so.4
-rwxr-xr-x 1 root root 61453024 Feb 23 16:00 /usr/local/cuda/lib64/libcudnn.so.4.0.7
-rw-r--r-- 1 root root 62025862 Feb 23 16:00 /usr/local/cuda/lib64/libcudnn_static.a

If installed from binary pip package, provide:
1. Which pip package you installed.
   https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
   I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
   I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
   I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally
   I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
   0.10.0rc0
### Steps to reproduce

1.pip install tensorflow version 0.10.0rc0
2.ls /usr/local/lib/python2.7/dist-packages/tensorflow/include/tensorflow/core/lib/core
error_codes.pb.h  errors.h  notification.h  refcount.h  status.h  stringpiece.h

threadpool.h is not included in the exported header files with a binary install. This means this one can't implement a multi-threaded custom operator using the tensorflow threadpool. 

Note, the files that threadpool.h includes, 
# include ""tensorflow/core/platform/env.h""
# include ""tensorflow/core/platform/macros.h""
# include ""tensorflow/core/platform/types.h""

ARE installed and the threadpool functionality is included in the core library. 

I can work around this by copying threadpool.h into my own custom operator library include directory, and everything works fine, but this is a fragile solution. 
"
3962,strip_unused on TensorFlow 0.10.0rc0 outputs ImportError: No module named tools,"### Environment info

Operating System: Mac OS X El Capitan

Installed version of CUDA and cuDNN: N/A

Installed from binary pip package, TensorFlow version is 0.10.0rc0.

Python 2.7.11
### Steps to reproduce
1. `git clone https://github.com/tensorflow/tensorflow.git`
2. `cd tensorflow`
3. `bazel build tensorflow/python/tools:strip_unused`
4. I got the same error as in step 3 (shown in Logs below) when running the full command with the Inception V3 or V1 model. This is with the V3 model: 

`bazel-bin/tensorflow/python/tools/strip_unused --input_graph=/tmp/tensorflow_inception_graph_v3.pb --output_graph=/tmp/stripped_graph.pb --input_node_names=Mul --output_node_names=softmax --input_binary=true` 
### What have you tried?
1. I tried the same procedure previously on TensorFlow 0.8.0 on a different Mac (also running OS X El Capitan), and the above commands work perfectly: the `strip_unused` itself without any parameters outputs `Input graph file '' does not exist!` and the full command outputs the stripped data model.
2. I took a look at the `strip_unused_lib.py` file, unable to be imported when running `strip_unused`, on github and saw it's created first on Aug. 7:
   https://github.com/tensorflow/tensorflow/commits/master/tensorflow/python/tools/strip_unused_lib.py
3. I also looked at a similar issue: https://github.com/tensorflow/tensorflow/issues/3881 but it doesn't solve my problem.
4. I tried to add . to PYTHONPATH before running `bazel-bin/tensorflow/python/tools/strip_unused` and still got the same error. 
5. I did a fresh new install of TensorFlow 0.10.0rc0 on another Mac OS X El Capitan, and it's still the same.
### Logs or other output that would be helpful

```
Traceback (most recent call last):
  File ""/Users/zero2one/tensorflow-src/latest/tensorflow/bazel-bin/tensorflow/python/tools/strip_unused.runfiles/tensorflow/python/tools/strip_unused.py"", line 46, in <module>
    from tensorflow.python.tools import strip_unused_lib
ImportError: No module named tools
```
"
3958,"tensorboard: graph visualization failed, undefined","In Chrome it says: ""Graph visualization failed: TypeError: Connot read property 'length' of undefined.

In Firefox it says: ""Graph visualization failed: TypeError: rawNodes is undefined""

I have attached the events file (appended '.txt' so it Github would accept it.)
[events.out.tfevents.1471882692.JMugan.local.txt](https://github.com/tensorflow/tensorflow/files/430670/events.out.tfevents.1471882692.JMugan.local.txt)

When I run with inspect, I get

```
======================================================================
Processing event files... (this can take a few minutes)
======================================================================

Found event files in:
/Users/jmugan/tensorlog

These tags are in /Users/jmugan/tensorlog:
audio -
histograms -
images -
scalars
   exp_cost
   perplexity
   train_cost
======================================================================

Event statistics for /Users/jmugan/tensorlog:
audio -
graph
   first_step           0
   last_step            0
   max_step             0
   min_step             0
   num_steps            1
   outoforder_steps     []
histograms -
images -
scalars
   first_step           23210
   last_step            23230
   max_step             23230
   min_step             23210
   num_steps            3
   outoforder_steps     []
sessionlog:checkpoint -
sessionlog:start -
sessionlog:stop -
======================================================================
```
"
3957,Optimizer + tf.reduce_prod() + GPU = Cannot assign a device to node 'gradients/Prod_grad/ListDiff',"### Environment info

Operating System: _Ubuntu 14.4.5 LTS_

Installed version of CUDA and cuDNN: 
_CUDA 7.5.18_ and _cuDNN 4.0.7_

```
-rw-r--r-- 1 root root 322936 Aug 15  2015 libcudadevrt.a
lrwxrwxrwx 1 root root     16 Jul 12 08:24 libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root     19 Jul 12 08:24 libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root 383336 Aug 15  2015 libcudart.so.7.5.18
-rw-r--r-- 1 root root 720192 Aug 15  2015 libcudart_static.a

-rw-r--r-- 1 sauterme tumuser        0 Aug 22 18:29 libcudart.so.7.5
-rw-r--r-- 1 sauterme tumuser        0 Aug 22 18:29 libcudart.so.7.5.18
lrwxrwxrwx 1 sauterme tumuser       13 Feb  9  2016 libcudnn.so -> libcudnn.so.4
lrwxrwxrwx 1 sauterme tumuser       17 Feb  9  2016 libcudnn.so.4 -> libcudnn.so.4.0.7
-rwxr-xr-x 1 sauterme tumuser 61453024 Feb  8  2016 libcudnn.so.4.0.7
-rw-r--r-- 1 sauterme tumuser 62025862 Feb  8  2016 libcudnn_static.a
```

If installed from binary pip package, provide:
1. Which pip package you installed:
   pip package version 0.10 for Python 2.7 with GPU support:
   _https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl_
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   _0.10.0rc0_
### Steps to reproduce
1. Use a system with GPU
2. Use this code snippet
   
   ```
   import tensorflow as tf
   
   g = tf.Graph()
   with g.as_default():
       with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:
   
           with tf.device('/gpu:0'):
   
               a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')
               b = tf.Variable([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]], name='b')
   
               c = tf.matmul(a, b)
               res = tf.reduce_prod(c)
   
               #with tf.device('/cpu:0'): # <<< adding this solves the issue!
               train_op = tf.train.AdagradOptimizer(1e-3).minimize(res)
   
           sess.run(tf.initialize_all_variables())    
   
           print sess.run(res)
           print sess.run(train_op)
   
   ```
3. You will get an InvalidArgumentError:
   _InvalidArgumentError: Cannot assign a device to node 'gradients/Prod_grad/ListDiff': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
    [[Node: gradients/Prod_grad/ListDiff = ListDiff[T=DT_INT32, _device=""/device:GPU:0""](gradients/Prod_grad/range_1, Const)]]
   Caused by op u'gradients/Prod_grad/ListDiff', defined at:
   File ""/usr/lib/python2.7/runpy.py"", line 162, in _run_module_as_main
     ""__main__"", fname, loader, pkg_name)
   File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code
     exec code in run_globals_ 
4. Cause of the issue: tf.reduce_prod() when running the train_op. So, the problem takes place while back-propagation through this op.
### What have you tried?
1. Wrapping the tf.reduce_prod() with tf.device('/cpu:0'):
   
   Result: still getting this error!
2. Exchangeing tf.reduce_prod() with other reduce_*() ops:
   
   Result: no error!
3. Wrapping the Optimizer with  tf.device('/cpu:0'):
   
   **Result: Solves the error!**
"
3956,wide_n_deep_tutorial.py won't work on Python 3,"@tiagonj notes that wide_n_deep_tutorial.py will not work on Python 3 because it calls urllib.urlretrieve directly, and suggests using the maybe_download function from tensorflow.contrib.learn.python.learn.datasets.base.
"
3954,Linux Shell does not appear when installing Tensorflow in Dockers (Win7),"Following these instructions:
http://www.netinstructions.com/how-to-install-and-run-tensorflow-on-a-windows-pc/`

executing the last command in cmd shell (Win7):
`docker run -it -p 8888:8888 gcr.io/tensorflow/tensorflow`

cmd is downloading, pulling, then Jupyiter notebook services gets started..., but then I get warnings and the linux shell does not appear:

`C:\Users\user>docker` run -it b.gcr.io/tensorflow/tensorflow
Unable to find image 'b.gcr.io/tensorflow/tensorflow:latest' locally
latest: Pulling from tensorflow/tensorflow
a64038a0eeaa: Pull complete
2ec6e7edf8a8: Pull complete
0a5fb6c3c94b: Pull complete
a3ed95caeb02: Pull complete
067b43ae9d67: Pull complete
3d200b674fb1: Pull complete
88dd2043900b: Pull complete
3ea4a014aa1c: Pull complete
ed48f1cb940c: Pull complete
34a0da2387dd: Pull complete
aa5acc667d66: Pull complete
Digest: sha256:d320d2da9c958ee42e61f810f296de602c674319b7a87b163a42329ac903a12c
Status: Downloaded newer image for b.gcr.io/tensorflow/tensorflow:latest
[I 15:44:31.744 NotebookApp] Writing notebook server cookie secret to /root/.loc
al/share/jupyter/runtime/notebook_cookie_secret
[W 15:44:31.790 NotebookApp] WARNING: The notebook server is listening on all IP
 addresses and not using encryption. This is not recommended.
[W 15:44:31.791 NotebookApp] WARNING: The notebook server is listening on all IP
 addresses and not using authentication. This is highly insecure and not recomme
nded.
[I 15:44:31.799 NotebookApp] Serving notebooks from local directory: /notebooks
[I 15:44:31.800 NotebookApp] 0 active kernels
[I 15:44:31.801 NotebookApp] The Jupyter Notebook is running at: http://[all ip
addresses on your system]:8888/
[I 15:44:31.801 NotebookApp] Use Control-C to stop this server and shut down all
 kernels (twice to skip `confirmation).`

What do I need to do to get the Linux Shell?
"
3953,error loading package 'tensorflow/core': Encountered error while reading extension file 'protobuf.bzl': no such package '@protobuf//',"Operating System: Scientific Linux release 7.2 (Nitrogen)
CUDA 7.5

I'm trying to install tensorflow from source (with debug options in order to solve another issue), from GItHub branch r0.10 . 

Using bazel 0.3.1-2016-08-22

Apparently related to #3437 

After configuring tensorflow, I ran `bazel build -c dbg --config=cuda //tensorflow/cc:tutorials_example_trainer` and got the following errors:

```
ERROR: /hltsrv0/rocha/deps/tensorflow/tensorflow/cc/BUILD:199:1: error loading package 'tensorflow/core': Encountered error while reading extension file 'protobuf.bzl': no such package '@protobuf//': Error cloning repository: https://github.com/google/protobuf: cannot open git-upload-pack caused by https://github.com/google/protobuf: cannot open git-upload-pack caused by Connection timed out github.com and referenced by '//tensorflow/cc:tutorials_example_trainer'.
ERROR: /hltsrv0/rocha/deps/tensorflow/tensorflow/cc/BUILD:199:1: error loading package 'tensorflow/core': Encountered error while reading extension file 'protobuf.bzl': no such package '@protobuf//': Error cloning repository: https://github.com/google/protobuf: cannot open git-upload-pack caused by https://github.com/google/protobuf: cannot open git-upload-pack caused by Connection timed out github.com and referenced by '//tensorflow/cc:tutorials_example_trainer'.
ERROR: /hltsrv0/rocha/deps/tensorflow/tensorflow/cc/BUILD:199:1: error loading package 'tensorflow/core': Encountered error while reading extension file 'protobuf.bzl': no such package '@protobuf//': Error cloning repository: https://github.com/google/protobuf: cannot open git-upload-pack caused by https://github.com/google/protobuf: cannot open git-upload-pack caused by Connection timed out github.com and referenced by '//tensorflow/cc:tutorials_example_trainer'.
ERROR: /hltsrv0/rocha/deps/tensorflow/tensorflow/cc/BUILD:199:1: error loading package 'tensorflow/core': Encountered error while reading extension file 'protobuf.bzl': no such package '@protobuf//': Error cloning repository: https://github.com/google/protobuf: cannot open git-upload-pack caused by https://github.com/google/protobuf: cannot open git-upload-pack caused by Connection timed out github.com and referenced by '//tensorflow/cc:tutorials_example_trainer'.
ERROR: /hltsrv0/rocha/deps/tensorflow/tensorflow/cc/BUILD:199:1: error loading package 'tensorflow/core': Encountered error while reading extension file 'protobuf.bzl': no such package '@protobuf//': Error cloning repository: https://github.com/google/protobuf: cannot open git-upload-pack caused by https://github.com/google/protobuf: cannot open git-upload-pack caused by Connection timed out github.com and referenced by '//tensorflow/cc:tutorials_example_trainer'.
ERROR: /hltsrv0/rocha/deps/tensorflow/tensorflow/cc/BUILD:199:1: error loading package 'tensorflow/core': Encountered error while reading extension file 'protobuf.bzl': no such package '@protobuf//': Error cloning repository: https://github.com/google/protobuf: cannot open git-upload-pack caused by https://github.com/google/protobuf: cannot open git-upload-pack caused by Connection timed out github.com and referenced by '//tensorflow/cc:tutorials_example_trainer'.
ERROR: Analysis of target '//tensorflow/cc:tutorials_example_trainer' failed; build aborted.
```

I'm using a server where I have no root privileges and there's no internet access. 

I understand the building process is trying to clone a repository, so, would it be possible to clone it and download any other necessary files in another machine and then copy them to the server? If so, what exactly do I need to copy and where?
"
3952,Poor results with tensorflow DNNClassifier and cross_val_score,"I am using python 3.5, tensorflow 0.10 and its DNNClassifier. If I perform a single training and testing stage, as below, the test result is decent: accuracy = 0.9333

import tensorflow as tf
from tensorflow.contrib import learn
from sklearn.cross_validation import cross_val_score, ShuffleSplit, train_test_split
from sklearn.metrics import accuracy_score
import numpy as np
from sklearn.metrics import accuracy_score
from sklearn import datasets, cross_validation

iris = datasets.load_iris()

feature_columns = learn.infer_real_valued_columns_from_input(iris.data)

x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.20, random_state = 20)

model = learn.DNNClassifier(hidden_units=[5], 
                             n_classes=3, 
                             feature_columns=feature_columns, 
                            )

model.fit(x_train, y_train, steps=1000)
predicted = model.predict(x_test)

print('Accuracy on test set: %f' % accuracy_score(y_test, predicted))
If I use sklearn's cross_val_score, then the final results is much poorer, about 0.33 accuracy:

model = learn.DNNClassifier(hidden_units=[5], 
                             n_classes=3, 
                             feature_columns=feature_columns, 
                            )

scores = cross_val_score(estimator=model, 
                         X=iris.data, 
                         y=iris.target, 
                         scoring = 'accuracy',
                         cv=5,
                         fit_params={'steps': 1000},
                        )

print(scores)
print(np.mean(scores))
The scores ad their mean are:

[ 0.          0.33333333  1.          0.33333333  0.        ]
0.333333333333
What's wrong with my code in cross validation estimation?
"
3951,"when I try to install tensorflow from source by bazel, I got this new problem:","/home/scw4150/Documents/tensorflow/tensorflow/tensorflow/stream_executor/BUILD:5:1: C++ compilation of rule '//tensorflow/stream_executor:stream_executor' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object ... (remaining 112 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
tensorflow/stream_executor/cuda/cuda_dnn.cc: In function 'cudnnConvolutionFwdAlgo_t perftools::gputools::cuda::{anonymous}::ToConvForwardAlgo(perftools::gputools::dnn::AlgorithmType)':
tensorflow/stream_executor/cuda/cuda_dnn.cc:266:10: error: 'CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING' was not declared in this scope
     case CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING:
          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
tensorflow/stream_executor/cuda/cuda_dnn.cc: In function 'cudnnConvolutionBwdDataAlgo_t perftools::gputools::cuda::{anonymous}::ToConvBackwardDataAlgo(perftools::gputools::dnn::AlgorithmType)':
tensorflow/stream_executor/cuda/cuda_dnn.cc:284:10: error: 'CUDNN_CONVOLUTION_BWD_DATA_ALGO_FFT_TILING' was not declared in this scope
     case CUDNN_CONVOLUTION_BWD_DATA_ALGO_FFT_TILING:
          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
tensorflow/stream_executor/cuda/cuda_dnn.cc: In member function 'virtual bool perftools::gputools::cuda::CudnnSupport::GetConvolveAlgorithms(std::vector<long long int>*)':
tensorflow/stream_executor/cuda/cuda_dnn.cc:942:7: error: 'CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING' was not declared in this scope
       CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING,
       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
tensorflow/stream_executor/cuda/cuda_dnn.cc:947:4: error: no matching function for call to 'std::vector<long long int>::assign(<brace-enclosed initializer list>)'
   });

any suggestions?
"
3949,Standard input pipeline logs errors,"The following code:

```
    init_op = tf.group(tf.initialize_all_variables(),
                       tf.initialize_local_variables())
    sess = tf.Session()
    sess.run(init_op)
    coord = tf.train.Coordinator()
    threads = tf.train.start_queue_runners(sess=sess, coord=coord)
    try:
        HERE COMES THE OP READING FROM THE INPUT PIPELINE
    except tf.errors.OutOfRangeError:
        print('Epoch limit reached')
    finally:
        coord.request_stop()
    coord.join(threads)
    sess.close()
```

Finishes without an exception, but generates two log messages marked as errors. 

```
E tensorflow/core/client/tensor_c_api.cc:485] Reached limit of 2
     [[Node: input_producer/limit_epochs/CountUpTo = CountUpTo[T=DT_INT64, _class=[""loc:@input_producer/limit_epochs/epochs""], limit=2, _device=""/job:localhost/replica:0/task:0/cpu:0""](input_producer/limit_epochs/epochs)]]
E tensorflow/core/client/tensor_c_api.cc:485] FIFOQueue '_0_input_producer' is closed and has insufficient elements (requested 1, current size 0)
     [[Node: ReaderRead = ReaderRead[_class=[""loc:@TextLineReader"", ""loc:@input_producer""], _device=""/job:localhost/replica:0/task:0/cpu:0""](TextLineReader, input_producer)]]
Epoch limit reached
```

Shouldn't these be warnings or simply hidden?
### Environment info

Operating System: Ubuntu 16.04

Installed version of CUDA and cuDNN: 
8.0.27 and 5.0.5

Installed from source: 
Commit hash: 3cb39956e622b322e43547cf2b6e337020643f21 (v0.10.0rc0)

Bazel:
Build label: 0.3.0
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Jun 10 11:38:23 2016 (1465558703)
Build timestamp: 1465558703
Build timestamp as int: 1465558703
"
3948,how solve : ImportError: cannot import name nest,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System:Ubuntu 16.04

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`
### Steps to reproduce

1.
2.
3.
### What have you tried?

1.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
3947,Slicing a Sparse Tensor?,"Currently, sparse tensors don't support indexing, and the tf.sparse_split() operation can't split a sparse tensor according to a given proportion. If I want to select a portion of the training set (which is a sparse tensor) as the validation set, is it possible? 
"
3945,Feature request: extend tf.select to broadcast a scalar condition,"Consider allowing tensorflow.select to accept scalar conditions.  I.e., `tf.select(condition, t, e, name=None)` with `condition` a scalar, and `t`, `e` having the same shape.
"
3944,Not found: Op type not registered 'SigmoidGrad',"### Environment info

Operating System:
Mac OS X 10.11.6 (15G31)

Installed version of CUDA and cuDNN: 
no cuda

Installed from sources,
git clone https://github.com/tensorflow/tensorflow.git --branch v0.10.0rc0 --single-branch Tensorflow
1. The commit hash (`git rev-parse HEAD`)
   3cb39956e622b322e43547cf2b6e337020643f21
2. The output of `bazel version`
   ........
   Build label: 0.2.1-homebrew
   Build target: bazel-out/local_darwin-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
   Build time: Fri Apr 1 00:35:17 2016 (1459470917)
   Build timestamp: 1459470917
   Build timestamp as int: 1459470917
3. create pip package and install
4. make tensorflow graph.ph file
5. make libtensorflow.so with
   bazel build :libtensorflow.so
6. create c++ program and try to load this pb file
   status = ReadBinaryProto(Env::Default(), dir + ""/"" + tfGraphFilename, &graph_def);
7. error at runtime
   Not found: Op type not registered 'SigmoidGrad'

I tried tf.sigmoid and tf.nn.sigmoid, same error
tensorflow version 0.8 works fine
"
3943,"Link to ""iris_monitor.py"" broken ","The link to [iris_monitor.py](https://www.tensorflow.org/versions/examples/tutorials/monitors/iris_monitors.py) returns `not found` on Tensorflow tutorial [logging-and-monitoring-basics](https://www.tensorflow.org/versions/r0.10/tutorials/monitors/index.html#logging-and-monitoring-basics-with-tf-contrib-learn). Should it be redirected to Github [there](https://github.com/tensorflow/tensorflow/raw/r0.10/tensorflow/examples/tutorials/monitors/iris_monitors.py) ?
"
3942,tf.app.flags issue for multiple file AttributeError(name),"python train.py 
messi
Traceback (most recent call last):
  File ""train.py"", line 24, in <module>
    import model 
  File ""/home/gezi/mine/tensorflow-exp/tests/flags/model.py"", line 23, in <module>
    print(FLAGS.batch_size)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/platform/flags.py"", line 43, in **getattr**
    raise AttributeError(name)
AttributeError: batch_size
gezi:~/mine/tensorflow-exp/test
AttributeError: batch_size

I have 3 .pys, running tensorlow 0.10
# -----------------------------------------train.py

from **future** import absolute_import
from **future** import division
from **future** import print_function

import sys,os
import tensorflow as tf

flags = tf.app.flags 
FLAGS = tf.app.flags.FLAGS 

flags.DEFINE_integer('step', 5, '')

import util
import model 
# ------------------------model.py

from **future** import absolute_import
from **future** import division
from **future** import print_function

import sys,os
import tensorflow as tf

flags = tf.app.flags 
FLAGS = tf.app.flags.FLAGS 

flags.DEFINE_integer('batch_size', 100, '')

print(FLAGS.batch_size)
# --------------------------util.py

from **future** import absolute_import
from **future** import division
from **future** import print_function

import tensorflow as tf

flags = tf.app.flags 
FLAGS = tf.app.flags.FLAGS 

flags.DEFINE_string('name', 'messi', '')

print(FLAGS.name)

These demo code will not cause error, if I switch to use gflags.
Another problem:
 python train.py --help
usage: train.py [-h] [--step STEP] [--name NAME]

optional arguments:
  -h, --help   show this help message and exit
  --step STEP
  --name NAME

Why not show default values as c version gflags do ?
"
3941,cifar10_train can't use all CPUs,"### Environment info

Operating System: Linux 14.04

Installed version of CUDA and cuDNN:  No

If installed from binary pip package, provide:
1. Which pip package you installed.

https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl
1. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

0.10.0rc
### Steps to reproduce
1. clone the tensorflow main repo
2. run `python cifar10_train.py`
   This will only occupy ~6 CPUs on a machine with 8 CPUs (`top` command shows the CPU usage is ~600%)
### What have you tried?
1. set  `intra_op_parallelism_threads` and  `inter_op_parallelism_threads` in the `ConfigProto` when creating the session.  This doesn't help at all.
2. use multi-thread training like:

```
class Cifar10(object):
  def __init__(self, sess):
    print(""In construction"")
    self.global_step = tf.Variable(0, trainable=False)
    self.images, self.labels = cifar10.distorted_inputs()
    self.logits = cifar10.inference(self.images)
    self.loss = cifar10.loss(self.logits, self.labels)
    self.train_op = cifar10.train(self.loss, self.global_step)

    self.sess = sess
    init = tf.initialize_all_variables()
    self.sess.run(init)
    self.start = time.time()
    tf.train.start_queue_runners(sess=self.sess)
    print(""Construction Done"")
    self.saver = tf.train.Saver()

  def train(self):
    for step in xrange(FLAGS.max_steps):
      self.sess.run(self.train_op)

  def run(self, sess):
    workers = []
    for _ in xrange(4):
      t = threading.Thread(target=self.train)
      t.start()
      workers.append(t)

    for t in workers:
      t.join()

def main(argv=None):  # pylint: disable=unused-argument
  cifar10.maybe_download_and_extract()
  with tf.Graph().as_default(): 
    with tf.Session() as sess:
      model = Cifar10(sess)
      for _ in xrange(10000):
        gs = sess.run(model.global_step)
        checkpoint_path = os.path.join(FLAGS.train_dir, 'model.ckpt')
        model.saver.save(sess, checkpoint_path, global_step=gs)
        model.run(sess)

if __name__ == '__main__':
  tf.app.run()
```

The complete code:
[cifar10_multi_thread.txt](https://github.com/tensorflow/tensorflow/files/428362/cifar10_multi_thread.txt)

This did help. The CPU usage became 800% and the training process did go faster.

I assume that the data feeding process should not be the bottleneck because in the multi-thread training the input queue is not adjusted. Then how does TensorFlow parallelize the training process? Is there any parameter I should try to increase the CPU usage with the original code?

I also observed that if I train the multi-threads version in a distributed setting (I'm running 3 workers async, each runs a multi-threads training process), the precision on testing data looks like:
![image](https://cloud.githubusercontent.com/assets/7953637/17831863/d1d4b4d8-6727-11e6-8501-441796b8a70e.png)

But if I use the original version, the performance looks like:
![image](https://cloud.githubusercontent.com/assets/7953637/17831884/a478c1c2-6728-11e6-988b-59f51e9284a1.png)

I guess that might be caused by the async updates, is there any suggestion to avoid this?

Thanks
"
3940,one more import error(new),"Here is the error messages:

```
In [1]: import tensorflow
---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
<ipython-input-1-a649b509054f> in <module>()
----> 1 import tensorflow

/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py in <module>()
     21 from __future__ import print_function
     22 
---> 23 from tensorflow.python import *

/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py in <module>()
     96 from tensorflow.python.platform import resource_loader
     97 from tensorflow.python.platform import sysconfig
---> 98 from tensorflow.python.platform import test
     99 
    100 from tensorflow.python.util.all_util import make_all

/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/test.py in <module>()
     75 import sys
     76 if sys.version_info.major == 2:
---> 77   import mock                # pylint: disable=g-import-not-at-top,unused-import
     78 else:
     79   from unittest import mock  # pylint: disable=g-import-not-at-top

/usr/local/lib/python2.7/dist-packages/mock/__init__.py in <module>()
      1 from __future__ import absolute_import
----> 2 import mock.mock as _mock
      3 from mock.mock import *
      4 __all__ = _mock.__all__
      5 #import mock.mock as _mock

/usr/local/lib/python2.7/dist-packages/mock/mock.py in <module>()
     67 import six
     68 from six import wraps
---> 69 from pbr.version import VersionInfo
     70 
     71 _v = VersionInfo('mock').semantic_version()

ImportError: No module named pbr.version
```

Please help. According to the related no module alike errors I have updated the mock module and six(now 1.10.0), but the same error appears. Thanks very much. 
"
3939,"when I try to install tensorflow from source by bazel, I got this problem:","the commond is : bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
ERROR is:
undeclared inclusion(s) in rule '@zlib_archive//:zlib':
this rule is missing dependency declarations for the following files included by 'external/zlib_archive/zlib-1.2.8/uncompr.c':
  '/usr/local/lib/gcc/x86_64-pc-linux-gnu/6.1.0/include-fixed/limits.h'
  '/usr/local/lib/gcc/x86_64-pc-linux-gnu/6.1.0/include-fixed/syslimits.h'
  '/usr/local/lib/gcc/x86_64-pc-linux-gnu/6.1.0/include/stddef.h'
  '/usr/local/lib/gcc/x86_64-pc-linux-gnu/6.1.0/include/stdarg.h'.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
how can I deal with it?Thanks!
"
3938,"After upgrade protobuf for the 64Mb limited , segment fault occurred","After doing ""pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/protobuf-3.0.0b2.post2-cp27-none-linux_x86_64.whl"" as said in ""https://www.tensorflow.org/versions/r0.10/get_started/os_setup.html#protobuf-library-related-issues""
, my tensorflow did not work and got a segment fault after import tensorflow.
Could some one give me a right pip install version of >64MB limited protobuf?Thanks!
"
3937,tf.add_check_numerics_ops() causes numeric errors for gradients of tf.pow,"### Environment info

Operating System: Ubuntu 16.04

Installed version of CUDA and cuDNN: None
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. Which pip package you installed.
   [`https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl`](https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl)
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   `0.10.0rc0`
### Steps to reproduce

``` python
import tensorflow as tf
x = tf.Variable(0.)
x_grad = tf.gradients(x**2, x)
init = tf.initialize_all_variables()
check_op = tf.add_check_numerics_ops()
sess = tf.InteractiveSession()
sess.run(init)
sess.run(x_grad + [check_op])
# => InvalidArgumentError: gradients/pow_grad/Log:0 : Tensor had Inf values
sess.run(x_grad)
# => [0.0]
```

My guess is that the check_op forces the two factors in `grad(x**2) = (e**(2log x)) * (1./x)` to separately evaluate. Then 1./x causes an `Inf`.
"
3936,Video summary,"Hey, 
Just wondering if there are any plans to add video summaries to tensorboard??
Alex
"
3933, configure script crashing in virtuealenv due to issues with site.getsitepackages(),"In the current master, the line https://github.com/tensorflow/tensorflow/blob/master/util/python/python_config.sh#L63

causes a crash stating 

> AttributeError: module 'site' has no attribute 'getsitepackages'

 if running confgure inside virtualenv Python environment.

The underlying issue is that virtualenv uses an older site package that doesn't have getsitepackages. It is still an open bug in virtualenv after 4 years (!): https://github.com/pypa/virtualenv/issues/355.

For reference, I am using Python 3, virtualenv and virtualenvwrapper on Ubuntu 16.04 with CUDA 8.0. The v0.10.0rc0 release works for me, but this recent fix in python_config.sh breaks virtualenv usage.
"
3932,l2_normalize broken in master,"`tf.nn.l2_normalize(tf.constant(np.ones([2, 2, 2, 2])), [0, 1, 2])` crashes with the following error:
`ValueError: Shape (1, 3) must have rank at most 1`

The problem is that l2_normalize function converts the dimension list into `[[0, 1, 2]]` (double brackets) and it stopped being supported recently. It works fine in 0.10 branch as far as I can tell.

Shorter repro to get the same error:
`tf.reduce_sum(tf.constant(np.ones([2, 2, 2, 2])), [[0, 1, 2]])`
"
3931,tensorflow protobuf problem about:A protocolmessage was rejected because it was too big (more than 67108864 bytes) ,"I got this problem when trying to run a chief worker of distribute tensorflow. The tensorflow was installed by pip,not from source. Then I uninstalled protobuf by pip and then download the source and changed 256 << 20 in coded_stream.h .
And I installed protobuf as Readme said.But the same problem occurred, It seems that tensorflow did not use the new compiled libprotobuf.  How could I fixed this issue? If I have to reinstall tensorflow? Or someone can give me a updated protobuf that can fix the 64m limit? Thanks If someone could help me, I am going to mad about this issue(T_T)
"
3930,missing API documentation to write user ops,"For example, how to fill a tensor with all zeros. Is it built in with `context -> allocate_output` or we can get the internal memory and do `memset`?
"
3929,No giflib at ufpr.dl.sourceforge.net - because no ufpr.dl.sourceforge.net,"Maybe this is a transient issue and I'll try again later.

```
patfla@patfla-N550JV:~/code/tensorflow$ bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer
Sending SIGTERM to previous Bazel server (pid=12785)... done.
.
ERROR: /home/patfla/code/tensorflow/tensorflow/core/platform/default/build_config/BUILD:56:1: no such package '@gif_archive//': Error downloading from http://ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz to /home/patfla/.cache/bazel/_bazel_patfla/411134e9cd8b53ea4deaf22318a2a19e/external/gif_archive: Error downloading http://ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz to /home/patfla/.cache/bazel/_bazel_patfla/411134e9cd8b53ea4deaf22318a2a19e/external/gif_archive/giflib-5.1.4.tar.gz: ufpr.dl.sourceforge.net and referenced by '//tensorflow/core/platform/default/build_config:platformlib'.
ERROR: Analysis of target '//tensorflow/cc:tutorials_example_trainer' failed; build aborted.
INFO: Elapsed time: 12.010s
```

```
patfla@patfla-N550JV:~/code/tensorflow/tensorflow$ grep -ir ufpr *
contrib/cmake/external/gif.cmake:set(gif_URL http://ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz)
workspace.bzl:    url = ""http://ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz"",

```

```
patfla@patfla-N550JV:~/code/tensorflow/tensorflow$ ping ufpr.dl.sourceforge.net
ping: unknown host ufpr.dl.sourceforge.net

```
"
3926,Failing to restore net,"### Environment info

Operating System:
Mac OS X 10.11.4
Tensorflow installed from pre-built pip (no CUDA):
0.10.0rc0
### Problem

I have problems with restoring my net [(from SO)](http://stackoverflow.com/questions/39035041/trouble-restoring-checkpointed-tensorflow-net). I have created a short [test program](https://github.com/tensorflow/tensorflow/files/427240/bug_report.zip) that have the same problem as my real program.

The program train a net, run one inference with it and then checkpoints the model. Then it loads the checkpointed model and run the inference with the same data and compare the result. I expected the results to be very similar but they weren't:

```
Restoring graph from /tmp/bugreport/model.ckpt-0
Inference after training gave 2.40740537643
Inference after restoring net gave 62579.6210938
```

``` python
import os

import numpy as np
import tensorflow as tf
import tensorflow.contrib.layers as contrib

FLAGS = tf.app.flags.FLAGS

tf.app.flags.DEFINE_string('tmp_dir', '/tmp/bugreport', """"""Temp dir"""""")

SIZE = 5
NUM_DATA = 10
BATCH_SIZE = 1
DEPTH = 1

def inference(input_tensor, is_training):
    ""Define a stupid net""
    bn_params = {
            ""is_training"": is_training,
            ""center"": True,
            ""scale"": True
            }
    tensor = contrib.convolution2d(input_tensor, 8, 3,
            normalizer_fn=contrib.batch_norm,
            normalizer_params=bn_params,
            scope=""conv1"")
    tensor = tf.reduce_sum(tensor)
    return tensor

def training(input_data, label_data, test_data):
    """"""1. Train the net
    2. Do an inference pass with the trained net
    3. Checkpoint the trained net
    """"""
    with tf.Graph().as_default():
        input_tensor = tf.placeholder(tf.float32, [BATCH_SIZE, SIZE, SIZE, DEPT#
        label_tensor = tf.placeholder(tf.float32, [BATCH_SIZE, DEPTH], name=""la#

        output = inference(input_tensor, tf.constant(True))
        loss = tf.nn.l2_loss(output - label_tensor, name=""loss"")
        train_op = tf.train.AdamOptimizer(0.9999).minimize(loss)
        init = tf.initialize_all_variables()
        saver = tf.train.Saver(tf.all_variables())

        with tf.Session() as sess:
            sess.run([init])
            for i in range(NUM_DATA):
                _ = sess.run(train_op, { input_tensor: input_data[i],
                                         label_tensor: label_data[i] })
            training_out = sess.run(output, { input_tensor: test_data })
            cp_path = os.path.join(FLAGS.tmp_dir, ""model.ckpt"")
            saver.save(sess, cp_path,
                       global_step=0, write_meta_graph=None)
    return training_out

def use_restored_net(test_data):
    """"""1. Load checkpointed net
    2. Do an inference pass with the trained net
    """"""
    with tf.Graph().as_default():
        input_tensor = tf.placeholder(tf.float32, [BATCH_SIZE, SIZE, SIZE, DEPT#

        output = inference(input_tensor, tf.constant(False))
        init = tf.initialize_all_variables()

        ckpt = tf.train.get_checkpoint_state(FLAGS.tmp_dir)
        if ckpt and ckpt.model_checkpoint_path:
            print ""Restoring graph from {}"".format(ckpt.model_checkpoint_path)
        else:
            raise ValueError(""Could not find a checkpointed model"")
        saver = tf.train.Saver(tf.all_variables())
        with tf.Session() as sess:
            sess.run([init])
            saver.restore(sess, ckpt.model_checkpoint_path)
            inference_out = sess.run(output, { input_tensor: test_data })
    return inference_out

def main(argv):
    if tf.gfile.Exists(FLAGS.tmp_dir):
        tf.gfile.DeleteRecursively(FLAGS.tmp_dir)
    tf.gfile.MakeDirs(FLAGS.tmp_dir)

    input_data = np.random.rand(NUM_DATA, BATCH_SIZE, SIZE, SIZE, DEPTH)
    label_data = np.random.rand(NUM_DATA, BATCH_SIZE, DEPTH)
    test_data = np.random.rand(BATCH_SIZE, SIZE, SIZE, DEPTH)

    training_out = training(input_data, label_data, test_data)
    inference_out = use_restored_net(test_data)
    print ""Inference after training gave {}"".format(training_out)
    print ""Inference after restoring net gave {}"".format(inference_out)


if __name__ == '__main__':
    tf.app.run()

```
"
3925,[bug] tensorflow/models/image/mnist/convolutional.py doesn't converge with CUDA7.5+cuDNN4,"### Environment info

Operating System: Ubuntu 14.04 64bit
Actually it is a docker env
nvidia/cuda:7.5-cudnn4-devel

Installed version of CUDA and cuDNN: CUDA7.5 and cuDNN4
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

``` bash
# ls -l /usr/lib/x86_64-linux-gnu/libcud* 
lrwxrwxrwx 1 root root       29 Aug 12 05:12 /usr/lib/x86_64-linux-gnu/libcudnn.so -> /etc/alternatives/libcudnn_so
lrwxrwxrwx 1 root root       17 Feb  9  2016 /usr/lib/x86_64-linux-gnu/libcudnn.so.4 -> libcudnn.so.4.0.7
-rw-r--r-- 1 root root 61453024 Feb  9  2016 /usr/lib/x86_64-linux-gnu/libcudnn.so.4.0.7
lrwxrwxrwx 1 root root       32 Aug 12 05:12 /usr/lib/x86_64-linux-gnu/libcudnn_static.a -> /etc/alternatives/libcudnn_stlib
-rw-r--r-- 1 root root 62025862 Feb  9  2016 /usr/lib/x86_64-linux-gnu/libcudnn_static_v4.a
```

``` bash
# ls -la /usr/local/nvidia/lib64/libcud*   
lrwxrwxrwx 1  999  998      17 Aug 16 13:46 /usr/local/nvidia/lib64/libcuda.so -> libcuda.so.367.35
lrwxrwxrwx 1  999  998      17 Aug 16 13:46 /usr/local/nvidia/lib64/libcuda.so.1 -> libcuda.so.367.35
-rw-r--r-- 2 root root 8121032 Jul 12 05:51 /usr/local/nvidia/lib64/libcuda.so.367.35
```

If installed from binary pip package, provide:
1. Which pip package you installed.

Ubuntu/Linux 64-bit, GPU enabled, Python 2.7
Requires CUDA toolkit 7.5 and CuDNN v4. For other versions, see ""Install from sources"" below.
$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl
1. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

``` bash
# python -c ""import tensorflow; print(tensorflow.__version__)""
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
0.10.0rc0
```
### Steps to reproduce
1. run docker
   docker run -it nvidia/cuda:7.5-cudnn4-devel
2. install tensorflow as described in the doc using pip
3. run the example, and it does not converge, logs are pasted in the end
   `python /usr/local/lib/python2.7/dist-packages/tensorflow/models/image/mnist/convolution.py`
### What have you tried?
1. Install and use the CPU version
   The mnist example converges well
### Logs or other output that would be helpful

``` bash
# python /usr/local/lib/python2.7/dist-packages/tensorflow/models/image/mnist/convolutional.py
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: GeForce GTX 1080
major: 6 minor: 1 memoryClockRate (GHz) 1.8225
pciBusID 0000:01:00.0
Total memory: 7.92GiB
Free memory: 7.17GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:839] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)
Initialized!
Step 0 (epoch 0.00), 184.2 ms
Minibatch loss: 12.054, learning rate: 0.010000
Minibatch error: 90.6%
Validation error: 90.2%
Step 100 (epoch 0.12), 4.6 ms
Minibatch loss: 5.381, learning rate: 0.010000
Minibatch error: 85.9%
Validation error: 88.7%
Step 200 (epoch 0.23), 4.1 ms
Minibatch loss: 5.389, learning rate: 0.010000
Minibatch error: 89.1%
Validation error: 88.7%
Step 300 (epoch 0.35), 4.2 ms
Minibatch loss: 5.360, learning rate: 0.010000
Minibatch error: 93.8%
Validation error: 88.7%
Step 400 (epoch 0.47), 4.2 ms
Minibatch loss: 5.287, learning rate: 0.010000
Minibatch error: 85.9%
Validation error: 88.7%
Step 500 (epoch 0.58), 4.1 ms
Minibatch loss: 5.267, learning rate: 0.010000
Minibatch error: 85.9%
Validation error: 88.7%

... ... (too long so deleted)

Step 8000 (epoch 9.31), 4.6 ms
Minibatch loss: 3.924, learning rate: 0.006302
Minibatch error: 89.1%
Validation error: 88.7%
Step 8100 (epoch 9.43), 4.9 ms
Minibatch loss: 3.925, learning rate: 0.006302
Minibatch error: 93.8%
Validation error: 88.7%
Step 8200 (epoch 9.54), 5.0 ms
Minibatch loss: 3.898, learning rate: 0.006302
Minibatch error: 82.8%
Validation error: 88.7%
Step 8300 (epoch 9.66), 4.6 ms
Minibatch loss: 3.882, learning rate: 0.006302
Minibatch error: 81.2%
Validation error: 88.7%
Step 8400 (epoch 9.77), 4.9 ms
Minibatch loss: 3.881, learning rate: 0.006302
Minibatch error: 85.9%
Validation error: 88.7%
Step 8500 (epoch 9.89), 4.7 ms
Minibatch loss: 3.877, learning rate: 0.006302
Minibatch error: 87.5%
Validation error: 88.7%
Test error: 88.7%
```
"
3924,max of two tf.Dimension objects undetermined,"### Environment info

Operating System: ubuntu 16.04

Installed version of CUDA and cuDNN: None
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. Which pip package you installed.
   https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   0.10.0rc0
### Steps to reproduce

``` python
import tensorflow as tf
max(tf.Dimension(1), tf.Dimension(None))
# => Dimension(1)
max(tf.Dimension(None), tf.Dimension(1))
# => Dimension(None)
```

I've looked at the code of Dimension class. It defines the comparison between integers and None to return None, causing this undetermined behavior when using max. I suggest that a better way could be to raise an Error when comparing with None or to always set integers to be larger, like python does. 
"
3923,How to let tensorflow uses the new installed protobuf?,"When I installed tensorflow with ""pip install"",I meet the ""A protocol message was rejected because it was too big (more than 67108864 bytes) "",and I uninstall protobuf with pip,then download a new protobuf,install it with changing 256 << 20 in coded_stream.h as ""Readme"" said,but the same problem occurred,it seems that tensorflow hasn't used the new protobuf,how could I deal with this problem?
"
3922,Loaded runtime CuDNN library error,"### Problem

First I was having this problem

```
E tensorflow/stream_executor/cuda/cuda_dnn.cc:347] Loaded runtime CuDNN library: 5103 (compatibility version 5100) but source was compiled with 4007 (compatibility version 4000).  If using a binary install, upgrade your CuDNN library to match.  If building from sources, make sure the library loaded at runtime matches a compatible version specified during compile configuration.
```

And I run configure script again, and this time I made sure I input specific version.
And compile. And here we are again.

```
E tensorflow/stream_executor/cuda/cuda_dnn.cc:347] Loaded runtime CuDNN library: 5103 (compatibility version 5100) but source was compiled with 5005 (compatibility version 5000).  If using a binary install, upgrade your CuDNN library to match.  If building from sources, make sure the library loaded at runtime matches a compatible version specified during compile configuration.
```

So I doubt there are some problems with configuration. So I open configure script and read. It says configuration is stored in cuda.config file.
Here is cuda.config

```
# CUDA_TOOLKIT_PATH refers to the CUDA toolkit.
CUDA_TOOLKIT_PATH=""/usr/local/cuda""
# CUDNN_INSTALL_PATH refers to the cuDNN toolkit. The cuDNN header and library
# files can be either in this directory, or under include/ and lib64/
# directories separately.
CUDNN_INSTALL_PATH=""/usr/local/cuda-7.5""

# The Cuda SDK version that should be used in this build (empty to use libcudart.so symlink)
TF_CUDA_VERSION=7.5

# The Cudnn version that should be used in this build
TF_CUDNN_VERSION=5.1.3
```

So **why** I have that problem? I already input version, but it failed **again**. I really can't understand.
### Environment info

Operating System: Ubuntu 14.04

Installed version of CUDA and cuDNN:  7.5 5.1.3
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```
dst@dst-desktop:~$ ls -l /usr/local/cuda/lib64/libcud*
-rw-r--r-- 1 root root   322936  8月 16  2015 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16  8月 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root       19  8月 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root   383336  8月 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root   720192  8月 16  2015 /usr/local/cuda/lib64/libcudart_static.a
-rwxr-xr-x 1 root root 60696704  8月 19 12:50 /usr/local/cuda/lib64/libcudnn.so
-rwxr-xr-x 1 root root 60696704  8月 19 12:50 /usr/local/cuda/lib64/libcudnn.so.5
-rwxr-xr-x 1 root root 59823168  7月  4 20:17 /usr/local/cuda/lib64/libcudnn.so.5.0.4
-rwxr-xr-x 1 root root 59909104  7月  4 21:22 /usr/local/cuda/lib64/libcudnn.so.5.0.5
-rwxr-xr-x 1 root root 60696704  8月 19 12:50 /usr/local/cuda/lib64/libcudnn.so.5.1.3
-rwxr-xr-x 1 root root 48217000  9月 27  2015 /usr/local/cuda/lib64/libcudnn.so.7.0
-rwxr-xr-x 1 root root 48217000  9月 27  2015 /usr/local/cuda/lib64/libcudnn.so.7.0.64
-rw-r--r-- 1 root root 59715990  8月 19 12:50 /usr/local/cuda/lib64/libcudnn_static.a
```

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)

```
dst@dst-desktop:~/Github/tensorflow$ git rev-parse HEAD
d8dddca5b11212ec6e8fe372d774d60f452dab24
```
1. The output of `bazel version`

```
dst@dst-desktop:~/Github/tensorflow$ bazel version
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Thu Jan 01 00:00:00 1970 (0)
Build timestamp: Thu Jan 01 00:00:00 1970 (0)
Build timestamp as int: 0
```
### Steps to reproduce
1. ./configure
2. bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
3. bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg
   4.pip install that package
### What have you tried?
1. recompile
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
3921,"MemoryError in ubuntu, not mac","Hello, my script gets killed by MemoryError, running in an aws EC2 instance, with 7.5G memory.
However, it has no problem running in my Mac (8g memory) !!! they use same TF, but numpy version is slightly different.

Python 2.7.10 (default, Oct 23 2015, 19:19:21) 
[GCC 4.2.1 Compatible Apple LLVM 7.0.0 (clang-700.0.59.5)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.

> > > import numpy as np
> > > np.**version**
> > > '1.11.1'

Python 2.7.6 (default, Jun 22 2015, 17:58:13) 
[GCC 4.8.2] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.

> > > import numpy as np
> > > np.**version**
> > > '1.11.0'

I have absolutely no idea what happened... and my data is not likely to require that much memory either...  i did memory profiling in EC2, error occurs at line 290.
# Line #    Mem usage    Increment   Line Contents

   275  412.289 MiB    0.000 MiB       @profile
   276                                 def test_naive(self, mx, yls, fn_model=None, W=None, b=None):
   277                                     """"""load variables and calculate acc""""""
   278 5117.520 MiB 4705.230 MiB           mx_array = mx.toarray()
   279 5117.520 MiB    0.000 MiB           if fn_model is not None:
   280                                         reader = tf.train.NewCheckpointReader(fn_model)
   281                                         logger.info(""loaded saved param from "" + fn_model)
   282                                         W, b = reader.get_tensor(""W""), reader.get_tensor(""b"")
   283                                     else:
   284 5117.520 MiB    0.000 MiB               assert (W is not None) and (b is not None)
   285  
   286 5117.523 MiB    0.004 MiB           print 'read', type(W), type(b), mx_array.shape
   287 5117.523 MiB    0.000 MiB           x, _ = self.init_placeholder()
   288 5117.523 MiB    0.000 MiB           with tf.Session() as sess:
   289 5117.523 MiB    0.000 MiB               tf.initialize_all_variables()
   290 5130.176 MiB   12.652 MiB               y = sess.run(tf.nn.softmax(tf.matmul(x, W) + b), feed_dict={x: mx_array})

  File ""meshtags/model_bow.py"", line 290, in test_naive
    y = sess.run(tf.nn.softmax(tf.matmul(x, W) + b), feed_dict={x: mx_array})
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 372, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 619, in _run
    np_val = np.array(subfeed_val, dtype=subfeed_dtype)
MemoryError

any comments are welcome ! thanks a lot.
"
3920,about attention_seq2seq function without embedding,"we already have a function tf.nn.seq2seq.embedding_attention_seq2seq(), but if i want to use an embedding trained from other model, the function is not convenient, do we have a function like tf.nn.seq2seq.attention_seq2seq() that need an embedding para or the inputs embedded.
Thanks!
"
3919,Tutorial Sample not working : TypeError: argument of type 'float' is not iterable,"Running the python code with the following syntax
python wide_n_deep_tutorial.py --model_type=wide_n_deep

Produces the below error

` python wide_n_deep_tutorial.py --model_type=wide_n_deep

Training data is downloaded to /tmp/tmpMD6Clq
Test data is downloaded to /tmp/tmpfG7CwC
Traceback (most recent call last):
  File ""wide_n_deep_tutorial.py"", line 210, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""wide_n_deep_tutorial.py"", line 206, in main
    train_and_eval()
  File ""wide_n_deep_tutorial.py"", line 192, in train_and_eval
    df_train[LABEL_COLUMN] = (df_train['income_bracket'].apply(lambda x: '>50K' in x)).astype(int)
  File ""/usr/lib/python2.7/dist-packages/pandas/core/series.py"", line 2023, in apply
    mapped = lib.map_infer(values, f, convert=convert_dtype)
  File ""inference.pyx"", line 920, in pandas.lib.map_infer (pandas/lib.c:44780)
  File ""wide_n_deep_tutorial.py"", line 192, in <lambda>
    df_train[LABEL_COLUMN] = (df_train['income_bracket'].apply(lambda x: '>50K' in x)).astype(int)
TypeError: argument of type 'float' is not iterable'
"
3918,global_step/sec is always zeros in the tensorflow distributed log,"When I use the tensorflow distributed version to train a model of classify of the text.
I find the global_step variable in the log of parameter server is always zero. At the same time, the worker log doesn't update any more.
After 30 minutes, there is no change in the situation.
But when I use the nvidia-smi to check the situation of the gpu, I find the process which is working in the gpu.

this is my global_step code:
global_step = tf.Variable(0, name=""global_step"", trainable=False)

Does anyone who know how to solve it?
"
3917,Floating point exception (core dumped) when running tutorials_example_trainer using gpu,"I'm trying build latest tensorflow but I got a Floating point exception as follow:

> zhipeng@tu567:~/apps/tensorflow$ bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu
> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so.5 locally
> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally
> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
> I tensorflow/core/common_runtime/gpu/gpu_init.cc:118] Found device 0 with properties: 
> name: GeForce GTX 1070
> major: 6 minor: 1 memoryClockRate (GHz) 1.7845
> pciBusID 0000:82:00.0
> Total memory: 7.92GiB
> Free memory: 7.84GiB
> I tensorflow/core/common_runtime/gpu/gpu_init.cc:138] DMA: 0 
> I tensorflow/core/common_runtime/gpu/gpu_init.cc:148] 0:   Y 
> I tensorflow/core/common_runtime/gpu/gpu_device.cc:868] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:82:00.0)
> I tensorflow/core/common_runtime/gpu/gpu_device.cc:868] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:82:00.0)
> I tensorflow/core/common_runtime/gpu/gpu_device.cc:868] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:82:00.0)
> I tensorflow/core/common_runtime/gpu/gpu_device.cc:868] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:82:00.0)
> I tensorflow/core/common_runtime/gpu/gpu_device.cc:868] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:82:00.0)
> I tensorflow/core/common_runtime/gpu/gpu_device.cc:868] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:82:00.0)
> I tensorflow/core/common_runtime/gpu/gpu_device.cc:868] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:82:00.0)
> I tensorflow/core/common_runtime/gpu/gpu_device.cc:868] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:82:00.0)
> I tensorflow/core/common_runtime/gpu/gpu_device.cc:868] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:82:00.0)
> I tensorflow/core/common_runtime/gpu/gpu_device.cc:868] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:82:00.0)
> Floating point exception (core dumped)
## Enviroment info

> Ubuntu 14.04
> GPU: GTX GeForce 1070
> CUDA 8.0RC
> Cudnn v5
> bazel: 0.3.1-jdk7
## gdb

> (gdb) r --use_gpu
> Starting program: /home/zhipeng/.cache/bazel/_bazel_zhipeng/97115ed19a1a63c4345ae364363ad69b/execroot/tensorflow/bazel-out/local_linux-opt/bin/tensorflow/cc/tutorials_example_trainer --use_gpu
> [Thread debugging using libthread_db enabled]
> Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".
> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so.5 locally
> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally
> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
> [New Thread 0x7fffe1bf4700 (LWP 96027)]
> [New Thread 0x7fffe13f3700 (LWP 96028)]
> [New Thread 0x7fffe0bf2700 (LWP 96029)]
> [New Thread 0x7fffe03f1700 (LWP 96030)]
> [New Thread 0x7fffdfbf0700 (LWP 96031)]
> [New Thread 0x7fffdf3ef700 (LWP 96032)]
> [New Thread 0x7fffdebee700 (LWP 96033)]
> [New Thread 0x7fffde3ed700 (LWP 96034)]
> [New Thread 0x7fffddbec700 (LWP 96035)]
> [New Thread 0x7fffdd3eb700 (LWP 96036)]
> [New Thread 0x7fffdcbea700 (LWP 96037)]
> [New Thread 0x7fffbffff700 (LWP 96038)]
> [New Thread 0x7fffbf7fe700 (LWP 96039)]
> [New Thread 0x7fffbeffd700 (LWP 96040)]
> [New Thread 0x7fffbe7fc700 (LWP 96041)]
> [New Thread 0x7fffbdffb700 (LWP 96042)]
> [New Thread 0x7fffbd7fa700 (LWP 96043)]
> [New Thread 0x7fffbcff9700 (LWP 96044)]
> [New Thread 0x7fffaffff700 (LWP 96045)]
> [New Thread 0x7fffaf7fe700 (LWP 96046)]
> [New Thread 0x7fffaeffd700 (LWP 96047)]
> [New Thread 0x7fffae7fc700 (LWP 96048)]
> [New Thread 0x7fffadffb700 (LWP 96049)]
> [New Thread 0x7fffad7fa700 (LWP 96050)]
> [New Thread 0x7fffacff9700 (LWP 96051)]
> [New Thread 0x7fffac7f8700 (LWP 96052)]
> [New Thread 0x7fffabff7700 (LWP 96053)]
> [New Thread 0x7fffab7f6700 (LWP 96054)]
> [New Thread 0x7fffaaff5700 (LWP 96055)]
> [New Thread 0x7fffaa7f4700 (LWP 96056)]
> [New Thread 0x7fffa9ff3700 (LWP 96057)]
> [New Thread 0x7fffa97f2700 (LWP 96058)]
> [New Thread 0x7fffa8ff1700 (LWP 96059)]
> [New Thread 0x7fffa87f0700 (LWP 96060)]
> [New Thread 0x7fffa7fef700 (LWP 96061)]
> [New Thread 0x7fffa77ee700 (LWP 96062)]
> [New Thread 0x7fffa6fed700 (LWP 96063)]
> [New Thread 0x7fffa67ec700 (LWP 96064)]
> [New Thread 0x7fffa5feb700 (LWP 96065)]
> [New Thread 0x7fffa57ea700 (LWP 96066)]
> [New Thread 0x7fffa4fe9700 (LWP 96067)]
> [New Thread 0x7fffa47e8700 (LWP 96068)]
> [New Thread 0x7fffa3fe7700 (LWP 96069)]
> [New Thread 0x7fffa37e6700 (LWP 96070)]
> [New Thread 0x7fffa2fe5700 (LWP 96071)]
> [New Thread 0x7fffa27e4700 (LWP 96072)]
> [New Thread 0x7fffa1fe3700 (LWP 96073)]
> [New Thread 0x7fffa17e2700 (LWP 96074)]
> [New Thread 0x7fffa0fe1700 (LWP 96075)]
> [New Thread 0x7fffa07e0700 (LWP 96076)]
> [New Thread 0x7fff9ffdf700 (LWP 96077)]
> [New Thread 0x7fff9f7de700 (LWP 96078)]
> [New Thread 0x7fff9efdd700 (LWP 96079)]
> [New Thread 0x7fff9e7dc700 (LWP 96080)]
> [New Thread 0x7fff9dfdb700 (LWP 96081)]
> [New Thread 0x7fff9d7da700 (LWP 96082)]
> [New Thread 0x7fff9cfd9700 (LWP 96083)]
> [New Thread 0x7fff9c7d8700 (LWP 96084)]
> [New Thread 0x7fff9bfd7700 (LWP 96085)]
> [New Thread 0x7fff9b7d6700 (LWP 96086)]
> [New Thread 0x7fff9afd5700 (LWP 96087)]
> [New Thread 0x7fff9a7d4700 (LWP 96088)]
> [New Thread 0x7fff99fd3700 (LWP 96089)]
> [New Thread 0x7fff997d2700 (LWP 96090)]
> [New Thread 0x7fff98fd1700 (LWP 96091)]
> [New Thread 0x7fff987d0700 (LWP 96092)]
> [New Thread 0x7fff97fcf700 (LWP 96093)]
> [New Thread 0x7fff977ce700 (LWP 96094)]
> [New Thread 0x7fff96fcd700 (LWP 96097)]
> [New Thread 0x7fff967cc700 (LWP 96098)]
> [New Thread 0x7fff95fcb700 (LWP 96099)]
> [New Thread 0x7fff957ca700 (LWP 96100)]
> [New Thread 0x7fff94fc9700 (LWP 96101)]
> [New Thread 0x7fff947c8700 (LWP 96102)]
> [New Thread 0x7fff93fc7700 (LWP 96103)]
> [New Thread 0x7fff937c6700 (LWP 96104)]
> [New Thread 0x7fff92fc5700 (LWP 96105)]
> [New Thread 0x7fff927c4700 (LWP 96106)]
> [New Thread 0x7fff91fc3700 (LWP 96107)]
> [New Thread 0x7fff917c2700 (LWP 96108)]
> [New Thread 0x7fff90fc1700 (LWP 96109)]
> [New Thread 0x7fff907c0700 (LWP 96110)]
> [New Thread 0x7fff89fbf700 (LWP 96114)]
> [New Thread 0x7fff897be700 (LWP 96115)]
> [New Thread 0x7fff88fbd700 (LWP 96116)]
> I tensorflow/core/common_runtime/gpu/gpu_init.cc:118] Found device 0 with properties: 
> name: GeForce GTX 1070
> major: 6 minor: 1 memoryClockRate (GHz) 1.7845
> pciBusID 0000:82:00.0
> Total memory: 7.92GiB
> Free memory: 7.84GiB
> I tensorflow/core/common_runtime/gpu/gpu_init.cc:138] DMA: 0 
> I tensorflow/core/common_runtime/gpu/gpu_init.cc:148] 0:   Y 
> I tensorflow/core/common_runtime/gpu/gpu_device.cc:868] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:82:00.0)
> I tensorflow/core/common_runtime/gpu/gpu_device.cc:868] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:82:00.0)
> I tensorflow/core/common_runtime/gpu/gpu_device.cc:868] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:82:00.0)
> I tensorflow/core/common_runtime/gpu/gpu_device.cc:868] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:82:00.0)
> I tensorflow/core/common_runtime/gpu/gpu_device.cc:868] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:82:00.0)
> I tensorflow/core/common_runtime/gpu/gpu_device.cc:868] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:82:00.0)
> I tensorflow/core/common_runtime/gpu/gpu_device.cc:868] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:82:00.0)
> I tensorflow/core/common_runtime/gpu/gpu_device.cc:868] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:82:00.0)
> I tensorflow/core/common_runtime/gpu/gpu_device.cc:868] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:82:00.0)
> I tensorflow/core/common_runtime/gpu/gpu_device.cc:868] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:82:00.0)
> [New Thread 0x7fff83fff700 (LWP 96117)]
> [New Thread 0x7fff82ffd700 (LWP 96119)]
> [New Thread 0x7fff837fe700 (LWP 96118)]
> [New Thread 0x7fff817fa700 (LWP 96121)]
> [New Thread 0x7fff827fc700 (LWP 96120)]
> [New Thread 0x7fff81ffb700 (LWP 96122)]
> [New Thread 0x7fff79ffb700 (LWP 96126)]
> [New Thread 0x7fff7b7fe700 (LWP 96124)]
> [New Thread 0x7fff7bfff700 (LWP 96125)]
> [New Thread 0x7fff80ff9700 (LWP 96123)]
> [New Thread 0x7fff7a7fc700 (LWP 96128)]
> [New Thread 0x7fff7affd700 (LWP 96127)]
> [New Thread 0x7fff797fa700 (LWP 96129)]
> [New Thread 0x7fff78ff9700 (LWP 96130)]
> [New Thread 0x7fff710d3700 (LWP 96131)]
> [New Thread 0x7fff708d2700 (LWP 96132)]
> [New Thread 0x7fff700d1700 (LWP 96133)]
> [New Thread 0x7fff6f8d0700 (LWP 96134)]
> [New Thread 0x7fff6f0cf700 (LWP 96135)]
> [New Thread 0x7fff6e8ce700 (LWP 96136)]
> [New Thread 0x7fff6e0cd700 (LWP 96137)]
> [New Thread 0x7fff6d8cc700 (LWP 96138)]
> [New Thread 0x7fff6d0cb700 (LWP 96139)]
> [New Thread 0x7fff6c8ca700 (LWP 96140)]
> [New Thread 0x7fff6c0c9700 (LWP 96141)]
> [New Thread 0x7fff6b8c8700 (LWP 96142)]
> [New Thread 0x7fff6b0c7700 (LWP 96143)]
> [New Thread 0x7fff6a8c6700 (LWP 96144)]
> [New Thread 0x7fff6a0c5700 (LWP 96145)]
> [New Thread 0x7fff698c4700 (LWP 96146)]
> [New Thread 0x7fff690c3700 (LWP 96147)]
> [New Thread 0x7fff688c2700 (LWP 96148)]
> [New Thread 0x7fff680c1700 (LWP 96149)]
> [New Thread 0x7fff678c0700 (LWP 96150)]
> [New Thread 0x7fff670bf700 (LWP 96151)]
> [New Thread 0x7fff668be700 (LWP 96152)]
> [New Thread 0x7fff660bd700 (LWP 96153)]
> [New Thread 0x7fff658bc700 (LWP 96154)]
> [New Thread 0x7fff650bb700 (LWP 96155)]
> [New Thread 0x7fff648ba700 (LWP 96156)]
> [New Thread 0x7fff640b9700 (LWP 96157)]
> [New Thread 0x7fff638b8700 (LWP 96158)]
> [New Thread 0x7fff630b7700 (LWP 96159)]
> [New Thread 0x7fff628b6700 (LWP 96160)]
> [New Thread 0x7fff620b5700 (LWP 96161)]
> [New Thread 0x7fff618b4700 (LWP 96162)]
> [New Thread 0x7fff610b3700 (LWP 96163)]
> [New Thread 0x7fff608b2700 (LWP 96164)]
> [New Thread 0x7fff600b1700 (LWP 96165)]
> [New Thread 0x7fff5f8b0700 (LWP 96166)]
> [New Thread 0x7fff5f0af700 (LWP 96167)]
> [New Thread 0x7fff5e8ae700 (LWP 96168)]
> [New Thread 0x7fff5e0ad700 (LWP 96169)]
> [New Thread 0x7fff5d8ac700 (LWP 96170)]
> [New Thread 0x7fff5d0ab700 (LWP 96171)]
> [New Thread 0x7fff5c8aa700 (LWP 96172)]
> [New Thread 0x7fff5c0a9700 (LWP 96173)]
> [New Thread 0x7fff5b8a8700 (LWP 96174)]
> [New Thread 0x7fff5b0a7700 (LWP 96175)]
> [New Thread 0x7fff5a8a6700 (LWP 96176)]
> [New Thread 0x7fff5a0a5700 (LWP 96177)]
> [New Thread 0x7fff598a4700 (LWP 96178)]
> [New Thread 0x7fff590a3700 (LWP 96179)]
> [New Thread 0x7fff588a2700 (LWP 96180)]
> [New Thread 0x7fff580a1700 (LWP 96181)]
> [New Thread 0x7fff578a0700 (LWP 96182)]
> [New Thread 0x7fff5709f700 (LWP 96183)]
> [New Thread 0x7fff5689e700 (LWP 96184)]
> [New Thread 0x7fff5609d700 (LWP 96185)]
> [New Thread 0x7fff5589c700 (LWP 96186)]
> [New Thread 0x7fff5509b700 (LWP 96187)]
> [New Thread 0x7fff5489a700 (LWP 96188)]
> [New Thread 0x7fff54099700 (LWP 96189)]
> [New Thread 0x7fff53898700 (LWP 96190)]
> [New Thread 0x7fff53097700 (LWP 96191)]
> [New Thread 0x7fff52896700 (LWP 96192)]
> [New Thread 0x7fff52095700 (LWP 96193)]
> [New Thread 0x7fff51894700 (LWP 96194)]
> [New Thread 0x7fff51093700 (LWP 96195)]
> [New Thread 0x7fff50892700 (LWP 96196)]
> [New Thread 0x7fff50091700 (LWP 96197)]
> [New Thread 0x7fff4f890700 (LWP 96198)]
> [New Thread 0x7fff4f08f700 (LWP 96199)]
> [New Thread 0x7fff4e88e700 (LWP 96200)]
> [New Thread 0x7fff4e08d700 (LWP 96201)]
> [New Thread 0x7fff4d88c700 (LWP 96202)]
> [New Thread 0x7fff4d08b700 (LWP 96203)]
> [New Thread 0x7fff4c88a700 (LWP 96204)]
> [New Thread 0x7fff4c089700 (LWP 96205)]
> [New Thread 0x7fff4b888700 (LWP 96206)]
> [New Thread 0x7fff4b087700 (LWP 96207)]
> [New Thread 0x7fff4a886700 (LWP 96208)]
> [New Thread 0x7fff4a085700 (LWP 96209)]
> [New Thread 0x7fff48882700 (LWP 96213)]
> [New Thread 0x7fff49884700 (LWP 96210)]
> [New Thread 0x7fff48081700 (LWP 96212)]
> [New Thread 0x7fff49083700 (LWP 96211)]
> [New Thread 0x7fff47880700 (LWP 96215)]
> [New Thread 0x7fff4687e700 (LWP 96216)]
> [New Thread 0x7fff4587c700 (LWP 96217)]
> [New Thread 0x7fff4707f700 (LWP 96214)]
> [New Thread 0x7fff4607d700 (LWP 96218)]
> [New Thread 0x7fff4487a700 (LWP 96220)]
> [New Thread 0x7fff4507b700 (LWP 96219)]
> [New Thread 0x7fff44079700 (LWP 96221)]
> [New Thread 0x7fff43878700 (LWP 96222)]
> [New Thread 0x7fff43077700 (LWP 96223)]
> [New Thread 0x7fff42876700 (LWP 96224)]
> [New Thread 0x7fff42075700 (LWP 96225)]
> [New Thread 0x7fff41874700 (LWP 96226)]
> [New Thread 0x7fff41073700 (LWP 96227)]
> [New Thread 0x7fff40872700 (LWP 96228)]
> [New Thread 0x7fff40071700 (LWP 96229)]
> [New Thread 0x7fff3f870700 (LWP 96230)]
> [New Thread 0x7fff3f06f700 (LWP 96231)]
> [New Thread 0x7fff3e86e700 (LWP 96232)]
> [New Thread 0x7fff3d86c700 (LWP 96234)]
> [New Thread 0x7fff3e06d700 (LWP 96233)]
> [New Thread 0x7fff3d06b700 (LWP 96235)]
> [New Thread 0x7fff3c069700 (LWP 96237)]
> [New Thread 0x7fff3c86a700 (LWP 96236)]
> [New Thread 0x7fff3b868700 (LWP 96238)]
> [New Thread 0x7fff3b067700 (LWP 96239)]
> [New Thread 0x7fff3a866700 (LWP 96240)]
> [New Thread 0x7fff3a065700 (LWP 96241)]
> [New Thread 0x7fff39864700 (LWP 96242)]
> [New Thread 0x7fff39063700 (LWP 96243)]
> [New Thread 0x7fff38862700 (LWP 96244)]
> [New Thread 0x7fff37860700 (LWP 96246)]
> [New Thread 0x7fff38061700 (LWP 96245)]
> [New Thread 0x7fff3705f700 (LWP 96247)]
> [New Thread 0x7fff3685e700 (LWP 96248)]
> [New Thread 0x7fff3605d700 (LWP 96249)]
> [New Thread 0x7fff3585c700 (LWP 96250)]
> [New Thread 0x7fff3505b700 (LWP 96251)]
> [New Thread 0x7fff3485a700 (LWP 96252)]
> [New Thread 0x7fff34059700 (LWP 96253)]
> [New Thread 0x7fff33057700 (LWP 96255)]
> [New Thread 0x7fff33858700 (LWP 96254)]
> [New Thread 0x7fff32856700 (LWP 96256)]
> [New Thread 0x7fff32055700 (LWP 96257)]
> [New Thread 0x7fff31854700 (LWP 96258)]
> [New Thread 0x7fff31053700 (LWP 96259)]
> [New Thread 0x7fff30852700 (LWP 96260)]
> [New Thread 0x7fff30051700 (LWP 96261)]
> [New Thread 0x7fff2f850700 (LWP 96262)]
> [New Thread 0x7fff2f04f700 (LWP 96263)]
> [New Thread 0x7fff2e84e700 (LWP 96264)]
> [New Thread 0x7fff2e04d700 (LWP 96265)]
> [New Thread 0x7fff2d84c700 (LWP 96266)]
> [New Thread 0x7fff2d04b700 (LWP 96267)]
> [New Thread 0x7fff2c84a700 (LWP 96268)]
> [New Thread 0x7fff2c049700 (LWP 96269)]
> [New Thread 0x7fff2b848700 (LWP 96270)]
> [New Thread 0x7fff2b047700 (LWP 96271)]
> [New Thread 0x7fff2a846700 (LWP 96272)]
> [New Thread 0x7fff2a045700 (LWP 96273)]
> [New Thread 0x7fff29043700 (LWP 96275)]
> [New Thread 0x7fff29844700 (LWP 96274)]
> [New Thread 0x7fff28842700 (LWP 96276)]
> [New Thread 0x7fff28041700 (LWP 96277)]
> [New Thread 0x7fff27840700 (LWP 96278)]
> [New Thread 0x7fff2703f700 (LWP 96279)]
> [New Thread 0x7fff2683e700 (LWP 96280)]
> [New Thread 0x7fff2603d700 (LWP 96281)]
> [New Thread 0x7fff2583c700 (LWP 96282)]
> [New Thread 0x7fff2503b700 (LWP 96283)]
> [New Thread 0x7fff2483a700 (LWP 96284)]
> [New Thread 0x7fff07fff700 (LWP 96285)]
> [New Thread 0x7fff077fe700 (LWP 96286)]
> [New Thread 0x7fff06ffd700 (LWP 96287)]
> [New Thread 0x7fff067fc700 (LWP 96288)]
> [New Thread 0x7fff05ffb700 (LWP 96289)]
> [New Thread 0x7fff057fa700 (LWP 96290)]
> [New Thread 0x7fff04ff9700 (LWP 96291)]
> [New Thread 0x7ffea7fff700 (LWP 96292)]
> [New Thread 0x7ffea77fe700 (LWP 96293)]
> [New Thread 0x7ffea6ffd700 (LWP 96294)]
> [New Thread 0x7ffea67fc700 (LWP 96295)]
> [New Thread 0x7ffea5ffb700 (LWP 96296)]
> [New Thread 0x7ffea4ff9700 (LWP 96298)]
> [New Thread 0x7ffea57fa700 (LWP 96297)]
> [New Thread 0x7ffe27576700 (LWP 96299)]
> [New Thread 0x7ffe26d75700 (LWP 96300)]
> [New Thread 0x7ffe26574700 (LWP 96301)]
> [New Thread 0x7ffe25d73700 (LWP 96302)]
> [New Thread 0x7ffe25572700 (LWP 96303)]
> [New Thread 0x7ffe24d71700 (LWP 96304)]
> [New Thread 0x7ffd17fff700 (LWP 96305)]
> Program received signal SIGFPE, Arithmetic exception.
> [Switching to Thread 0x7fff4a886700 (LWP 96208)]
> 0x000055555600f22a in tensorflow::functor::CastFunctor<Eigen::GpuDevice, float, int>::operator()(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16>, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16>) ()

And it can make successful execution without 'use_gpu' parameter, I can't find the problem.
"
3916,some change to Mnist_softmax.py,"### Environment info

Operating System:
ubuntu 14.0
Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
_ls -l /path/to/cuda/lib/libcud_
If installed from binary pip package, provide:
_-rw-r--r-- 1 root root 322936  8月 16  2015 /usr/local/cuda-7.5/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root     16  8月 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root     19  8月 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root 383336  8月 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root 720192  8月 16  2015 /usr/local/cuda-7.5/lib64/libcudart_static.a_
1. Which pip package you installed.
_pip 1.5.4 from /usr/lib/python2.7/dist-packages (python 2.7)_
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
_0.10.0rc0_
### Steps to reproduce

1.When i run the original ~/Tensorflow Modles/tensorflow-master/tensorflow/examples/tutorials/mnist/mnist_softmax.py ,i got accuray :91.9%
2.But after i change follow code:
W = tf.Variable(tf.zeros([784, 10]))
b = tf.Variable(tf.zeros([10]))
y = tf.nn.softmax(tf.matmul(x, W) + b)
to:
W1 = tf.Variable(tf.zeros([784, 1000]))
b1 = tf.Variable(tf.zeros([1000]))
W2 = tf.Variable(tf.zeros([1000, 10]))
b2 = tf.Variable(tf.zeros([10]))
h1=tf.nn.sigmoid(tf.matmul(x, W1) + b1)
y = tf.nn.softmax(tf.matmul(h1, W2) + b2)
the accuracy was down to about 30%
and it seemed that no or very little convergence happened even after changed the learning rate.

why?what happened?Could somebody help me?
"
3913,Error during build: no such package '@paper_radio_group//',"Hi All. Building python bindings gives me error:

`
root@host# bazel build -c opt --verbose_failures --config=cuda //tensorflow/tools/pip_package:build_pip_package
...

WARNING: /root/.cache/bazel/_bazel_root/4b98d0d2e8f34611cfd0d274c46b2eaf/external/gemmlowp/BUILD:102:12: in hdrs attribute of cc_library rule @gemmlowp//:eight_bit_int_gemm: Artifact 'external/gemmlowp/profiling/profiler.h' is duplicated (through '@gemmlowp//:eight_bit_int_gemm_public_headers' and '@gemmlowp//:gemmlowp_headers').
ERROR: /data/github/google/tensorflow/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@paper_radio_group//': Error cloning repository: Unexpected end of file from server caused by Unexpected end of file from server caused by Unexpected end of file from server and referenced by '//tensorflow/tensorboard/bower:bower'.
ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted.
INFO: Elapsed time: 1.857s
`
Is there a workaround for this problem?
"
3912,Tensorflow Data Corruption after Training,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System: Mac OSX El Capitan

If installed from binary pip package, provide:
1. Which pip package you installed.

The latest tensorflow.
1. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

0.10.0rc0
### Steps to reproduce
1. In order to reproduce, I have used the main function:
   
   import Input
   import Process
   
   import time
   import numpy as np
   import os
   
   import tensorflow as tf
   from datetime import datetime
   
   FLAGS = tf.app.flags.FLAGS
   
   def train():
   
   ```
   with tf.Session() as sess:
   
       images, labels = Process.inputs()
   
       forward_propgation_results = Process.forward_propagation(images)
   
       cost, train_loss = Process.error(forward_propgation_results, labels)
   
       image_summary_t = tf.image_summary(images.name, images, max_images = 2)
   
       summary_op = tf.merge_all_summaries()
   
       init = tf.initialize_all_variables()
   
       saver = tf.train.Saver()
   
       sess.run(init)
   
       saver = tf.train.Saver(tf.all_variables())
   
       tf.train.start_queue_runners(sess = sess)
   
       train_dir = ""/Users/Zanhuang/Desktop/NNP/model.ckpt""
   
       summary_writer = tf.train.SummaryWriter(train_dir, sess.graph)
   
       for step in range(100):
           start_time = time.time()
           print(sess.run([train_loss, cost]))
           duration = time.time() - start_time
           if step % 1 == 0:
               num_examples_per_step = FLAGS.batch_size
               examples_per_sec = num_examples_per_step / duration
               sec_per_batch = float(duration)
   
               format_str = ('%s: step %d, (%.1f examples/sec; %.3f ''sec/batch)')
               print (format_str % (datetime.now(), step, examples_per_sec, sec_per_batch))
   
               summary_str = sess.run(summary_op)
               summary_writer.add_summary(summary_str, step)
   
   
               if step % 2 == 0:
                   checkpoint_path = os.path.join(FLAGS.data_dir, 'model.ckpt')
                   saver.save(sess, checkpoint_path, global_step = step)
   ```
   
   def main(argv = None):
       train()
   
   if **name** == '**main**':
     tf.app.run()

Then the computation graph seems normal while running but after a few minutes after, the displayed images (in a similar to cifar10 format) shifts and turns into weird unrecognizable colors and the training loss which is normally descending normally is now displayed chaotically. This is all sudden after a few reloads a few minutes after training. I am absolutely sure there is nothing wrong with my hard drive.
### What have you tried?
1. I have tried retraining.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
3909,libstdc++ cannot be found,"I receive the following error when executing:

`bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer --verbose_failures`

> ERROR: /home/XX/.cache/bazel/_bazel_XX/2e273cfba15d637070500a6c0bde03c6/external/protobuf/BUILD:331:1: Linking of rule '@protobuf//:protoc' failed: gcc failed: error executing command 
>   (cd /home/XX/.cache/bazel/_bazel_XX/2e273cfba15d637070500a6c0bde03c6/execroot/tensorflow && \
>   exec env - \
>   /software/gcc/4.9.3/bin/gcc -o bazel-out/host/bin/external/protobuf/protoc bazel-out/host/bin/external/protobuf/_objs/protoc/external/protobuf/src/google/protobuf/compiler/main.o bazel-out/host/bin/external/protobuf/libprotoc_lib.a bazel-out/host/bin/external/protobuf/libprotobuf.a bazel-out/host/bin/external/protobuf/libprotobuf_lite.a -lpthread -L/software/gcc/4.9.3/lib64/ -Wl,-rpath,/software/gcc/4.9.3/lib64/ -B/usr/bin/ '-lstdc++ -L/software/gcc/4.9.3/lib64/' -pie -Wl,-z,relro,-z,now -no-canonical-prefixes -pass-exit-codes '-Wl,--build-id=md5' '-Wl,--hash-style=gnu' -Wl,-S -Wl,--gc-sections): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
> /usr/bin/ld: cannot find -lstdc++ -L/software/gcc/4.9.3/lib64/

I know for sure that in /software/gcc/4.9.3/lib64/ libstdc++ exists. I cannot find the source of the problem.

Here is an excerpt of my CROSSTOOl

> tool_path { name: ""ar"" path: ""/usr/bin/ar"" }
>   tool_path { name: ""compat-ld"" path: ""/usr/bin/ld"" }
>   tool_path { name: ""cpp"" path: ""/software/gcc/4.9.3/bin/cpp"" }
>   tool_path { name: ""dwp"" path: ""/usr/bin/dwp"" }
>   tool_path { name: ""gcc"" path: ""/software/gcc/4.9.3/bin/gcc"" }
> 
>   cxx_flag: ""-std=c++11""
>   #linker_flag: ""-L/software/gcc/4.9.3/lib/
>   linker_flag: ""-L/software/gcc/4.9.3/lib64/""
>   #linker_flag: ""-Wl,-rpath,/software/gcc/4.9.3/lib/
>   linker_flag: ""-Wl,-rpath,/software/gcc/4.9.3/lib64/""
>   linker_flag: ""-B/usr/bin/""
>   #linker_flag: ""-B/software/gcc/4.9.3/bin/""
>   linker_flag: ""-lstdc++ -L/software/gcc/4.9.3/lib64/""
> 
> cxx_builtin_include_directory: ""/software/gcc/4.9.3/lib64/gcc/""
>   #""/usr/lib/gcc/""
>   cxx_builtin_include_directory: ""/software/gcc/4.9.3/lib64/""
>   #cxx_builtin_include_directory: ""/software/gcc/4.9.3/lib/""
>   cxx_builtin_include_directory: ""/software/gcc/4.9.3/include/""
>   cxx_builtin_include_directory: ""/usr/local/include""
>   cxx_builtin_include_directory: ""/usr/include""
>   cxx_builtin_include_directory: ""/software/nvidia/7.5.18/cuda/include""

I tested every possible configuration but cannot figure out why it does not work. I am using the latest. I am using:
bazel release 0.3.1 and TF 0.10
"
3907,Feature Request: Sparse Variables,"I want to train a sparse model like this:

```
Param=tf.Variable(tf.SparceTensor(indices,values,shape))
cost=some_function_of_Params
```

tf.Variable(tf.SparseTensor) generates error:

`Expected binary or unicode string, got <tensorflow.python.framework.ops.SparseTensor object at 0x7f994788a550>`

My solution was to use dense matrices as variables, mask the gradients and then apply them (mask is a tensor containing zeros and ones):

```
init=a_dense_matrix

param=tf.variable(init)

cost=some_function_of_param

mask=a_dense_matrix_shaped_just_like_param

mask=tf.constant(mask)

optimizer=tf.GradientDescentOptimizer(learning_rate=0.01)

grad=optimizer.compute_gradients(cost)

masked_grad=tf.mul(grad,mask)

update_rule=optimizer.apply_gradients(masked_grad)
```

This however includes lots of redundant gradient computations and zero_masking multiplications. Doing updates on sparse variables instead of dense variables can speedup the training. Is there a plan to make it possible that sparse tensors could be used as variables in the graph? 
"
3906,unterminated substitute pattern in download_dependencies.sh,"### Environment info

Operating System:
OS X (El capitan)

I'm trying to build a static library with the end goal of using tensorflow for mobile apps. When I run the download_dependencies script I get this terminal log:
<img width=""775"" alt=""screen shot 2016-08-18 at 2 10 30 pm"" src=""https://cloud.githubusercontent.com/assets/12484426/17785182/b8263b96-654d-11e6-890b-44f9beb6750f.png"">

To an untrained eye it seems like a potentially easy fix but I have no experience with what would be required to fix it so if anyone has any suggestions/could point me in the right direction that would be dope.

Thanks
"
3903,conversion to graph_def lose tensor shapes,"If i convert a tensorflow model to graph_def using
`tf.get_default_graph().as_graph_def()`
And later import it again, i lose the information regarding the tensor shapes
### Code

``` python
import tensorflow as tf

# import any tensorflow model
net = __import__ ('mynet')
images = tf.placeholder(tf.float32, [32,28,28,3])
net = getattr(net, 'LeNet')({'data': images})

# iterate through the graph
graph = tf.get_default_graph()
for i in graph.get_operations():
    print i.name
    print 'OUTPUTS ',
    for j in i.outputs:
        print j.get_shape(),
    print 

print ""*************** CONVERT MODEL TO GRAPH_DEF AND IMPORT AGAIN ***************""

# Graph as graph_def
graph_def = tf.get_default_graph().as_graph_def()

# reset everything
tf.reset_default_graph()

# Import the graph_def
tf.import_graph_def(graph_def,name='')

# iterate through the graph again
graph = tf.get_default_graph()
for i in graph.get_operations():
    print i.name
    print 'OUTPUTS ',
    for j in i.outputs:
        print j.get_shape(),
    print
```
### Output

```
Placeholder
OUTPUTS  (32, 28, 28, 3)
conv1/weights
OUTPUTS  (5, 5, 3, 20)
conv1/weights/Initializer/random_uniform/shape
OUTPUTS  (4,)
conv1/weights/Initializer/random_uniform/min
OUTPUTS  ()
conv1/weights/Initializer/random_uniform/max
OUTPUTS  ()
conv1/weights/Initializer/random_uniform/RandomUniform
OUTPUTS  (5, 5, 3, 20)
conv1/weights/Initializer/random_uniform/sub
OUTPUTS  ()
conv1/weights/Initializer/random_uniform/mul
OUTPUTS  (5, 5, 3, 20)
conv1/weights/Initializer/random_uniform
OUTPUTS  (5, 5, 3, 20)
conv1/weights/Assign
OUTPUTS  (5, 5, 3, 20)
conv1/weights/read
OUTPUTS  (5, 5, 3, 20)
conv1/Conv2D
OUTPUTS  (32, 24, 24, 20)
conv1/biases
OUTPUTS  (20,)
conv1/biases/Initializer/random_uniform/shape
OUTPUTS  (1,)
conv1/biases/Initializer/random_uniform/min
OUTPUTS  ()
conv1/biases/Initializer/random_uniform/max
OUTPUTS  ()
conv1/biases/Initializer/random_uniform/RandomUniform
OUTPUTS  (20,)
conv1/biases/Initializer/random_uniform/sub
OUTPUTS  ()
conv1/biases/Initializer/random_uniform/mul
OUTPUTS  (20,)
conv1/biases/Initializer/random_uniform
OUTPUTS  (20,)
conv1/biases/Assign
OUTPUTS  (20,)
conv1/biases/read
OUTPUTS  (20,)
conv1/BiasAdd
OUTPUTS  (32, 24, 24, 20)
pool1
OUTPUTS  (32, 12, 12, 20)
conv2/weights
OUTPUTS  (5, 5, 20, 50)
conv2/weights/Initializer/random_uniform/shape
OUTPUTS  (4,)
conv2/weights/Initializer/random_uniform/min
OUTPUTS  ()
conv2/weights/Initializer/random_uniform/max
OUTPUTS  ()
conv2/weights/Initializer/random_uniform/RandomUniform
OUTPUTS  (5, 5, 20, 50)
conv2/weights/Initializer/random_uniform/sub
OUTPUTS  ()
conv2/weights/Initializer/random_uniform/mul
OUTPUTS  (5, 5, 20, 50)
conv2/weights/Initializer/random_uniform
OUTPUTS  (5, 5, 20, 50)
conv2/weights/Assign
OUTPUTS  (5, 5, 20, 50)
conv2/weights/read
OUTPUTS  (5, 5, 20, 50)
conv2/Conv2D
OUTPUTS  (32, 8, 8, 50)
conv2/biases
OUTPUTS  (50,)
conv2/biases/Initializer/random_uniform/shape
OUTPUTS  (1,)
conv2/biases/Initializer/random_uniform/min
OUTPUTS  ()
conv2/biases/Initializer/random_uniform/max
OUTPUTS  ()
conv2/biases/Initializer/random_uniform/RandomUniform
OUTPUTS  (50,)
conv2/biases/Initializer/random_uniform/sub
OUTPUTS  ()
conv2/biases/Initializer/random_uniform/mul
OUTPUTS  (50,)
conv2/biases/Initializer/random_uniform
OUTPUTS  (50,)
conv2/biases/Assign
OUTPUTS  (50,)
conv2/biases/read
OUTPUTS  (50,)
conv2/BiasAdd
OUTPUTS  (32, 8, 8, 50)
pool2
OUTPUTS  (32, 4, 4, 50)
ip1/Reshape/shape
OUTPUTS  (2,)
ip1/Reshape
OUTPUTS  (32, 800)
ip1/weights
OUTPUTS  (800, 500)
ip1/weights/Initializer/random_uniform/shape
OUTPUTS  (2,)
ip1/weights/Initializer/random_uniform/min
OUTPUTS  ()
ip1/weights/Initializer/random_uniform/max
OUTPUTS  ()
ip1/weights/Initializer/random_uniform/RandomUniform
OUTPUTS  (800, 500)
ip1/weights/Initializer/random_uniform/sub
OUTPUTS  ()
ip1/weights/Initializer/random_uniform/mul
OUTPUTS  (800, 500)
ip1/weights/Initializer/random_uniform
OUTPUTS  (800, 500)
ip1/weights/Assign
OUTPUTS  (800, 500)
ip1/weights/read
OUTPUTS  (800, 500)
ip1/biases
OUTPUTS  (500,)
ip1/biases/Initializer/random_uniform/shape
OUTPUTS  (1,)
ip1/biases/Initializer/random_uniform/min
OUTPUTS  ()
ip1/biases/Initializer/random_uniform/max
OUTPUTS  ()
ip1/biases/Initializer/random_uniform/RandomUniform
OUTPUTS  (500,)
ip1/biases/Initializer/random_uniform/sub
OUTPUTS  ()
ip1/biases/Initializer/random_uniform/mul
OUTPUTS  (500,)
ip1/biases/Initializer/random_uniform
OUTPUTS  (500,)
ip1/biases/Assign
OUTPUTS  (500,)
ip1/biases/read
OUTPUTS  (500,)
ip1/ip1/MatMul
OUTPUTS  (32, 500)
ip1/ip1/BiasAdd
OUTPUTS  (32, 500)
ip1/ip1
OUTPUTS  (32, 500)
ip2/weights
OUTPUTS  (500, 10)
ip2/weights/Initializer/random_uniform/shape
OUTPUTS  (2,)
ip2/weights/Initializer/random_uniform/min
OUTPUTS  ()
ip2/weights/Initializer/random_uniform/max
OUTPUTS  ()
ip2/weights/Initializer/random_uniform/RandomUniform
OUTPUTS  (500, 10)
ip2/weights/Initializer/random_uniform/sub
OUTPUTS  ()
ip2/weights/Initializer/random_uniform/mul
OUTPUTS  (500, 10)
ip2/weights/Initializer/random_uniform
OUTPUTS  (500, 10)
ip2/weights/Assign
OUTPUTS  (500, 10)
ip2/weights/read
OUTPUTS  (500, 10)
ip2/biases
OUTPUTS  (10,)
ip2/biases/Initializer/random_uniform/shape
OUTPUTS  (1,)
ip2/biases/Initializer/random_uniform/min
OUTPUTS  ()
ip2/biases/Initializer/random_uniform/max
OUTPUTS  ()
ip2/biases/Initializer/random_uniform/RandomUniform
OUTPUTS  (10,)
ip2/biases/Initializer/random_uniform/sub
OUTPUTS  ()
ip2/biases/Initializer/random_uniform/mul
OUTPUTS  (10,)
ip2/biases/Initializer/random_uniform
OUTPUTS  (10,)
ip2/biases/Assign
OUTPUTS  (10,)
ip2/biases/read
OUTPUTS  (10,)
ip2/ip2/MatMul
OUTPUTS  (32, 10)
ip2/ip2
OUTPUTS  (32, 10)
prob
OUTPUTS  (32, 10)
*************** CONVERT MODEL TO GRAPH_DEF AND IMPORT AGAIN ***************
Placeholder
OUTPUTS  (32, 28, 28, 3)
conv1/weights
OUTPUTS  <unknown>
conv1/weights/Initializer/random_uniform/shape
OUTPUTS  (4,)
conv1/weights/Initializer/random_uniform/min
OUTPUTS  ()
conv1/weights/Initializer/random_uniform/max
OUTPUTS  ()
conv1/weights/Initializer/random_uniform/RandomUniform
OUTPUTS  (5, 5, 3, 20)
conv1/weights/Initializer/random_uniform/sub
OUTPUTS  ()
conv1/weights/Initializer/random_uniform/mul
OUTPUTS  (5, 5, 3, 20)
conv1/weights/Initializer/random_uniform
OUTPUTS  (5, 5, 3, 20)
conv1/weights/Assign
OUTPUTS  (5, 5, 3, 20)
conv1/weights/read
OUTPUTS  <unknown>
conv1/Conv2D
OUTPUTS  (32, ?, ?, ?)
conv1/biases
OUTPUTS  <unknown>
conv1/biases/Initializer/random_uniform/shape
OUTPUTS  (1,)
conv1/biases/Initializer/random_uniform/min
OUTPUTS  ()
conv1/biases/Initializer/random_uniform/max
OUTPUTS  ()
conv1/biases/Initializer/random_uniform/RandomUniform
OUTPUTS  (20,)
conv1/biases/Initializer/random_uniform/sub
OUTPUTS  ()
conv1/biases/Initializer/random_uniform/mul
OUTPUTS  (20,)
conv1/biases/Initializer/random_uniform
OUTPUTS  (20,)
conv1/biases/Assign
OUTPUTS  (20,)
conv1/biases/read
OUTPUTS  <unknown>
conv1/BiasAdd
OUTPUTS  (32, ?, ?, ?)
pool1
OUTPUTS  (32, ?, ?, ?)
conv2/weights
OUTPUTS  <unknown>
conv2/weights/Initializer/random_uniform/shape
OUTPUTS  (4,)
conv2/weights/Initializer/random_uniform/min
OUTPUTS  ()
conv2/weights/Initializer/random_uniform/max
OUTPUTS  ()
conv2/weights/Initializer/random_uniform/RandomUniform
OUTPUTS  (5, 5, 20, 50)
conv2/weights/Initializer/random_uniform/sub
OUTPUTS  ()
conv2/weights/Initializer/random_uniform/mul
OUTPUTS  (5, 5, 20, 50)
conv2/weights/Initializer/random_uniform
OUTPUTS  (5, 5, 20, 50)
conv2/weights/Assign
OUTPUTS  (5, 5, 20, 50)
conv2/weights/read
OUTPUTS  <unknown>
conv2/Conv2D
OUTPUTS  (32, ?, ?, ?)
conv2/biases
OUTPUTS  <unknown>
conv2/biases/Initializer/random_uniform/shape
OUTPUTS  (1,)
conv2/biases/Initializer/random_uniform/min
OUTPUTS  ()
conv2/biases/Initializer/random_uniform/max
OUTPUTS  ()
conv2/biases/Initializer/random_uniform/RandomUniform
OUTPUTS  (50,)
conv2/biases/Initializer/random_uniform/sub
OUTPUTS  ()
conv2/biases/Initializer/random_uniform/mul
OUTPUTS  (50,)
conv2/biases/Initializer/random_uniform
OUTPUTS  (50,)
conv2/biases/Assign
OUTPUTS  (50,)
conv2/biases/read
OUTPUTS  <unknown>
conv2/BiasAdd
OUTPUTS  (32, ?, ?, ?)
pool2
OUTPUTS  (32, ?, ?, ?)
ip1/Reshape/shape
OUTPUTS  (2,)
ip1/Reshape
OUTPUTS  (?, 800)
ip1/weights
OUTPUTS  <unknown>
ip1/weights/Initializer/random_uniform/shape
OUTPUTS  (2,)
ip1/weights/Initializer/random_uniform/min
OUTPUTS  ()
ip1/weights/Initializer/random_uniform/max
OUTPUTS  ()
ip1/weights/Initializer/random_uniform/RandomUniform
OUTPUTS  (800, 500)
ip1/weights/Initializer/random_uniform/sub
OUTPUTS  ()
ip1/weights/Initializer/random_uniform/mul
OUTPUTS  (800, 500)
ip1/weights/Initializer/random_uniform
OUTPUTS  (800, 500)
ip1/weights/Assign
OUTPUTS  (800, 500)
ip1/weights/read
OUTPUTS  <unknown>
ip1/biases
OUTPUTS  <unknown>
ip1/biases/Initializer/random_uniform/shape
OUTPUTS  (1,)
ip1/biases/Initializer/random_uniform/min
OUTPUTS  ()
ip1/biases/Initializer/random_uniform/max
OUTPUTS  ()
ip1/biases/Initializer/random_uniform/RandomUniform
OUTPUTS  (500,)
ip1/biases/Initializer/random_uniform/sub
OUTPUTS  ()
ip1/biases/Initializer/random_uniform/mul
OUTPUTS  (500,)
ip1/biases/Initializer/random_uniform
OUTPUTS  (500,)
ip1/biases/Assign
OUTPUTS  (500,)
ip1/biases/read
OUTPUTS  <unknown>
ip1/ip1/MatMul
OUTPUTS  (?, ?)
ip1/ip1/BiasAdd
OUTPUTS  (?, ?)
ip1/ip1
OUTPUTS  (?, ?)
ip2/weights
OUTPUTS  <unknown>
ip2/weights/Initializer/random_uniform/shape
OUTPUTS  (2,)
ip2/weights/Initializer/random_uniform/min
OUTPUTS  ()
ip2/weights/Initializer/random_uniform/max
OUTPUTS  ()
ip2/weights/Initializer/random_uniform/RandomUniform
OUTPUTS  (500, 10)
ip2/weights/Initializer/random_uniform/sub
OUTPUTS  ()
ip2/weights/Initializer/random_uniform/mul
OUTPUTS  (500, 10)
ip2/weights/Initializer/random_uniform
OUTPUTS  (500, 10)
ip2/weights/Assign
OUTPUTS  (500, 10)
ip2/weights/read
OUTPUTS  <unknown>
ip2/biases
OUTPUTS  <unknown>
ip2/biases/Initializer/random_uniform/shape
OUTPUTS  (1,)
ip2/biases/Initializer/random_uniform/min
OUTPUTS  ()
ip2/biases/Initializer/random_uniform/max
OUTPUTS  ()
ip2/biases/Initializer/random_uniform/RandomUniform
OUTPUTS  (10,)
ip2/biases/Initializer/random_uniform/sub
OUTPUTS  ()
ip2/biases/Initializer/random_uniform/mul
OUTPUTS  (10,)
ip2/biases/Initializer/random_uniform
OUTPUTS  (10,)
ip2/biases/Assign
OUTPUTS  (10,)
ip2/biases/read
OUTPUTS  <unknown>
ip2/ip2/MatMul
OUTPUTS  (?, ?)
ip2/ip2
OUTPUTS  (?, ?)
prob
OUTPUTS  (?, ?)
```

It can be clearly seen that the shape of the last tensor (and others as well) in the model was `(32, 10)` and after conversion to graph_def and import again it becomes `(?, ?)`.

Is there any other way to get output shapes out of any graph_def?
"
3902,Issues running TensorFlow module in a Python sub-interpreter,"I'm using the tensorflow Python module in a custom C++ application, by instantiating the Python interpreter and then running Python code that imports tensorflow.

The Python code is run in a sub-interpreter (created using Py_NewInterpreter). This works fine the first time around, but when I end the sub-interpreter and create a second one, the call to 'import tensorflow' fails with the exception shown below. Looks like the TensorFlow module is either not being cleaned up properly when it de-initializes, and/or it has some global state that is shared between multiple interpreters? In particular it looks it tries to load a shared object that has already been loaded.

Is there a way to fix this and to make TensorFlow compatible with Python sub-interpreters, or is this just the tip of the iceberg and more issues would pop up once this particular one is resolved?

Thanks!
Peter

--- C++ code to reproduce the problem:

```
#include <cassert>
#include <python/Python.h>

// set this to the folder containing a virtual env with TensorFlow:
static char g_pythonHome[] = ""/Users/peter/tf101"";

void create_sub_interpreter_import_tensorflow()
{
    // acquire global interpreter lock and create new sub-interpreter:
    PyEval_AcquireLock();
    PyThreadState* pThreadState = Py_NewInterpreter();
    assert(pThreadState);

    // set sys.argv because TensorFlow needs it:
    int ret = PyRun_SimpleString(""import sys\n""
                                 ""sys.argv = ['']\n"");
    assert(ret == 0);

    // import TensorFlow, say hello.
    // !!! this fails when it is called the second time:
    ret = PyRun_SimpleString(""import tensorflow\n""
                             ""print 'hello world'\n"");
    assert(ret == 0);

    // end sub-interpreter and release global interpreter lock:
    Py_EndInterpreter(pThreadState);
    PyEval_ReleaseLock();
}

int main(int argc, const char * argv[]) {
    // set Python home to a virtual env containing TensorFlow:
    Py_SetPythonHome(g_pythonHome);

    // initialise Python and threads:
    Py_Initialize();
    PyEval_InitThreads();

    // store current thread state, release global interpreter lock:
    PyThreadState* pMainThreadState = PyEval_SaveThread();
    assert(pMainThreadState);

    create_sub_interpreter_import_tensorflow();
    create_sub_interpreter_import_tensorflow();

    // acquire global interpreter lock, restore main thread state, finalize Python:
    PyEval_RestoreThread(pMainThreadState);
    Py_Finalize();

    return 0;
}
```

--- Python error message:

```
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/Users/peter/tf101/lib/python2.7/site-packages/tensorflow/__init__.py"", line 23, in <module>
    from tensorflow.python import *
  File ""/Users/peter/tf101/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 65, in <module>
    import tensorflow.contrib as contrib
  File ""/Users/peter/tf101/lib/python2.7/site-packages/tensorflow/contrib/__init__.py"", line 26, in <module>
    from tensorflow.contrib import grid_rnn
  File ""/Users/peter/tf101/lib/python2.7/site-packages/tensorflow/contrib/grid_rnn/__init__.py"", line 27, in <module>
    from tensorflow.contrib.grid_rnn.python.ops.grid_rnn_cell import *
  File ""/Users/peter/tf101/lib/python2.7/site-packages/tensorflow/contrib/grid_rnn/python/ops/grid_rnn_cell.py"", line 28, in <module>
    from tensorflow.contrib import layers
  File ""/Users/peter/tf101/lib/python2.7/site-packages/tensorflow/contrib/layers/__init__.py"", line 77, in <module>
    from tensorflow.contrib.layers.python.layers import *
  File ""/Users/peter/tf101/lib/python2.7/site-packages/tensorflow/contrib/layers/python/layers/__init__.py"", line 22, in <module>
    from tensorflow.contrib.layers.python.layers.feature_column import *
  File ""/Users/peter/tf101/lib/python2.7/site-packages/tensorflow/contrib/layers/python/layers/feature_column.py"", line 79, in <module>
    from tensorflow.contrib.layers.python.ops import bucketization_op
  File ""/Users/peter/tf101/lib/python2.7/site-packages/tensorflow/contrib/layers/python/ops/bucketization_op.py"", line 25, in <module>
    resource_loader.get_path_to_datafile(""_bucketization_op.so""))
  File ""/Users/peter/tf101/lib/python2.7/site-packages/tensorflow/python/framework/load_library.py"", line 71, in load_op_library
    raise errors._make_specific_exception(None, None, error_msg, error_code)
tensorflow.python.framework.errors.AlreadyExistsError: /Users/peter/tf101/lib/python2.7/site-packages/tensorflow/contrib/layers/python/ops/_bucketization_op.so has already been loaded
```

--- Environment:
OS: OSX El Capitan (10.11.5)
tensorflow version: 0.9.0
installed using: pip install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.9.0-py2-none-any.whl
"
3900,translate.py not found in tensorflow libs on osx,"OSX 10.11.6 (15G31)
Tensorflow: 0.10.0rc0
Python 3.5

I'm following https://www.tensorflow.org/versions/r0.10/tutorials/seq2seq/index.html but translate.py is not in the tensorflow/models/rnn/translate directory.

```
cd tensorflow/models/rnn/translate
python translate.py --data_dir [your_data_directory]
```

When I ls in ""/usr/local/lib/python3.5/site-packages/tensorflow/models/rnn/translate"", I see the following files:
`__init__.py        __pycache__     data_utils.py       seq2seq_model.py
`
Is my installation broken somehow? I installed tensorflow with this code:

```
export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.10.0rc0-py3-none-any.whl
sudo pip3 install --upgrade $TF_BINARY_URL
```
"
3899,where is the location of grpc library installed by pip ,"Could you someone can tell me where the grpc c++ lib location?

I can find the python part in site-packages, but cannot find where the grpc installed?

My system is centos 7, and install it by pip over  anaconda

```
[root@nodel]# pip show tensorflow

---
Metadata-Version: 2.0
Name: tensorflow
Version: 0.9.0
Summary: TensorFlow helps the tensors flow
Home-page: http://tensorflow.org/
Author: Google Inc.
Author-email: opensource@google.com
Installer: pip
License: Apache 2.0
Location: /usr/local/anaconda2/lib/python2.7/site-packages
Requires: numpy, six, protobuf, wheel
Classifiers:
  Development Status :: 4 - Beta
  Intended Audience :: Developers
  Intended Audience :: Education
  Intended Audience :: Science/Research
  License :: OSI Approved :: Apache Software License
  Programming Language :: Python :: 2.7
  Topic :: Scientific/Engineering :: Mathematics
  Topic :: Software Development :: Libraries :: Python Modules
  Topic :: Software Development :: Libraries
Entry-points:
  [console_scripts]
  tensorboard = tensorflow.tensorboard.tensorboard:main
```

Thanks a lot!
"
3898,Inception model error on upgrading Tensorflow,"I am loading the Inception model as,

```
def load_network(png=False):
        with gfile.FastGFile(CONFIG_PATH + '/data/network.pb', 'rb') as f:
            graph_def = tf.GraphDef()
            data = f.read()
            graph_def.ParseFromString(data)
            if png:
                png_data = tf.placeholder(tf.string, shape=[])
                decoded_png = tf.image.decode_png(png_data, channels=3)
                _ = tf.import_graph_def(graph_def, name='', input_map={'DecodeJpeg': decoded_png})
                return png_data
            else:
                _ = tf.import_graph_def(graph_def, name='')
```

However, after upgrading from Tensorflow 0.8 to 0.10, this is giving an error,

```
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.py"", line 241, in import_graph_def
    raise ValueError('tf.import_graph_def() requires a non-empty `name` '
ValueError: tf.import_graph_def() requires a non-empty `name` if `input_map` is used.
```

I then removed the `name=''` part as,

```
                _ = tf.import_graph_def(graph_def, input_map={'DecodeJpeg': decoded_png})
                return png_data
            else:
                _ = tf.import_graph_def(graph_def)

```

This part then runs fine, however later on in my code when I am trying to get the pool3 layer's output I get the following error,

```
    pool3 = sess.graph.get_tensor_by_name('pool_3:0')
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2531, in get_tensor_by_name
    return self.as_graph_element(name, allow_tensor=True, allow_operation=False)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2385, in as_graph_element
    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2427, in _as_graph_element_locked
    ""graph."" % (repr(name), repr(op_name)))
KeyError: ""The name 'pool_3:0' refers to a Tensor which does not exist. The operation, 'pool_3', does not exist in the graph.""
```

What could be the problem?
"
3897,Tensorflow gradients are always zero!,"Tensorflow gradients are always zero with respect to conv layers that are after first conv layer. I've tried different ways to check that but gradients are always zero! Here is the small reproducible code that can be run to check that.

```
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import tensorflow as tf
import numpy as np
import math
import os
import random
import tflearn
batch_size = 100
start = 0
end = batch_size
learning_rate = 0.000001
num_classes = 4
time_steps = 4
embedding = 2
step = 1
_units = 500
num_of_filters = 1000

train_set_x = [[[1,2],[3,4],[5,6],[7,8]],[[1,2],[3,4],[5,6],[7,8]]]
train_set_y = [0,1]

X = tf.placeholder(tf.float32, [None,time_steps,embedding])
Y = tf.placeholder(tf.int32, [None])


x = tf.expand_dims(X,3)

filter_shape = [1, embedding, 1, num_of_filters]
conv_weights = tf.get_variable(""conv_weights1"" , filter_shape, tf.float32, tf.contrib.layers.xavier_initializer())
conv_biases = tf.Variable(tf.constant(0.1, shape=[num_of_filters]))
conv = tf.nn.conv2d(x, conv_weights, strides=[1,1,1,1], padding = ""VALID"")
normalize = conv + conv_biases
tf_normalize = tflearn.layers.normalization.batch_normalization(normalize)
relu = tf.nn.elu(tf_normalize)
pooling = tf.reduce_max(relu, reduction_indices = 3, keep_dims = True)
outputs_fed_lstm = pooling

filter_shape2 = [1, 1, 1, num_of_filters]
conv_weights2 = tf.get_variable(""conv_weights2"" , filter_shape2, tf.float32, tf.contrib.layers.xavier_initializer())
conv_biases2 = tf.Variable(tf.constant(0.1, shape=[num_of_filters]))
conv2 = tf.nn.conv2d(outputs_fed_lstm, conv_weights2, strides=[1,1,1,1], padding = ""VALID"")
normalize2 = conv2 + conv_biases2
tf_normalize2 = tflearn.layers.normalization.batch_normalization(normalize2)
relu2 = tf.nn.elu(tf_normalize2)
pooling2 = tf.reduce_max(relu2, reduction_indices = 3, keep_dims = True)
outputs_fed_lstm2 = pooling2

x = tf.squeeze(outputs_fed_lstm2, [2])     
x = tf.transpose(x, [1, 0, 2])
x = tf.reshape(x, [-1, 1])
x = tf.split(0, time_steps, x)

lstm = tf.nn.rnn_cell.LSTMCell(num_units = _units)

# multi_lstm = tf.nn.rnn_cell.MultiRNNCell([lstm] * lstm_layers, state_is_tuple = True)

outputs , state = tf.nn.rnn(lstm,x, dtype = tf.float32)     

weights = tf.Variable(tf.random_normal([_units,num_classes]))
biases  = tf.Variable(tf.random_normal([num_classes]))

logits = tf.matmul(outputs[-1], weights) + biases



c_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits,Y)
loss = tf.reduce_mean(c_loss)


global_step = tf.Variable(0, name=""global_step"", trainable=False)
# decayed_learning_rate = tf.train.exponential_decay(learning_rate,0,10000,0.9)
optimizer= tf.train.AdamOptimizer(learning_rate)
minimize_loss = optimizer.minimize(loss, global_step=global_step)   
grads_and_vars = optimizer.compute_gradients(loss,[conv_weights2]) 
correct_predict = tf.nn.in_top_k(logits, Y, 1)
accuracy = tf.reduce_mean(tf.cast(correct_predict, tf.float32))


init = tf.initialize_all_variables()

with tf.Session() as sess:
     sess.run(init)
     for i in range(1):
         for j in range(1):
             x = train_set_x
             y = train_set_y
             sess.run(minimize_loss,feed_dict={X : x, Y : y})
             step += 1  
             gr_print = sess.run([grad for grad, _ in grads_and_vars], feed_dict={X : x, Y : y})
             print (gr_print)
             cost = sess.run(loss,feed_dict = {X: x,Y: y})
             accu = sess.run(accuracy,feed_dict = {X: x, Y: y})
             print (""Loss after one Epoch(Training) = "" + ""{:.6f}"".format(cost) + "", Training Accuracy= "" + ""{:.5f}"".format(accu))
```

And here is the output

```
[array([[[[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  5.21326828,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ]]]], dtype=float32)]
```
"
3895,MultiRNNCell with state_is_tuple=True got Error!,"Running MultiRNN, when I set 

```
cell = tf.nn.rnn_cell.LSTMCell(state_size, state_is_tuple=True)
cell = tf.nn.rnn_cell.MultiRNNCell([cell] * num_layers, state_is_tuple=True)
```

got following error:

```
Traceback (most recent call last):
  File ""/Users/nali/Workspace/tensorflow_example/search_click/RNN/lstm.py"", line 175, in <module>
    train_network(g, 3)
  File ""/Users/nali/Workspace/tensorflow_example/search_click/RNN/lstm.py"", line 140, in train_network
    [g['total_loss'], g['final_state'], g['train_step']], feed_dict)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 372, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 584, in _run
    processed_fetches = self._process_fetches(fetches)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 540, in _process_fetches
    % (subfetch, fetch, type(subfetch), str(e)))
TypeError: Fetch argument (LSTMStateTuple(c=<tf.Tensor 'RNN/while/Exit_2:0' shape=(32, 100) dtype=float32>, h=<tf.Tensor 'RNN/while/Exit_3:0' shape=(32, 100) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'RNN/while/Exit_4:0' shape=(32, 100) dtype=float32>, h=<tf.Tensor 'RNN/while/Exit_5:0' shape=(32, 100) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'RNN/while/Exit_6:0' shape=(32, 100) dtype=float32>, h=<tf.Tensor 'RNN/while/Exit_7:0' shape=(32, 100) dtype=float32>)) of (LSTMStateTuple(c=<tf.Tensor 'RNN/while/Exit_2:0' shape=(32, 100) dtype=float32>, h=<tf.Tensor 'RNN/while/Exit_3:0' shape=(32, 100) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'RNN/while/Exit_4:0' shape=(32, 100) dtype=float32>, h=<tf.Tensor 'RNN/while/Exit_5:0' shape=(32, 100) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'RNN/while/Exit_6:0' shape=(32, 100) dtype=float32>, h=<tf.Tensor 'RNN/while/Exit_7:0' shape=(32, 100) dtype=float32>)) has invalid type <type 'tuple'>, must be a string or Tensor. (Can not convert a tuple into a Tensor or Operation.)
```

But when I set state_is_tuple=False(Default), it works fine.
However, state_is_tuple=True is recommended to faster LSTM states.
"
3894,Failure to build tensorflow on centos 5.7 with gcc 4.8.5,"### Environment info

Operating System:
CENTOS 5.7 with gcc 4.8.5

Bazel 0.1.3 without namespace-sandbox
### Problems:

When I build tensorflow using 

> bazel build -c opt --verbose_failures //tensorflow/tools/pip_package:build_pip_package

The error occurs :

> .............
> Unhandled exception thrown during build; message: namespace-sandbox not in [embedded_tools/WORKSPACE, embedded_tools/src/tools/android/java/com/google/devtools/build/android/README, embedded_tools/src/tools/android/java/com/google/devtools/build/android/AndroidResourceProcessor.java, embedded_tools/src/tools/android/java/com/google/devtools/build/android/MergedAndroidData.java, embedded_tools/src/tools/android/java/com/google/devtools/build/android/Converters.java, embedded_tools/src/tools/android/java/com/google/devtools/build/androi

It seems that the problems is due to disabling namespace-sandbox of bazel, anyone can help me with this?
"
3891,Very low accuracy in the mnist dataset with cnn when running on a GPU using tensorflow,"hi everyone:
I tried to run an examples of MNIST with cnn and when i only use cpu the code can work well  **but when i use gpu it is not working well and  it has very low accuracy**. 
## environment like this

 GPU:Geforce GTX1070
 Cuda toolkit version：7.5
 cuDNN version：7.0
tensorflow version：0.9r
## code like this:

``` python
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data

def weight_varible(shape):
    initial = tf.truncated_normal(shape, stddev=0.1)
    return tf.Variable(initial)

def bias_variable(shape):
    initial = tf.constant(0.1, shape=shape)
    return tf.Variable(initial)

def conv2d(x, W):
    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')

def max_pool_2x2(x):
    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')


mnist = input_data.read_data_sets(""MNIST_data/"", one_hot=True)
print(""Download Done!"")

sess = tf.InteractiveSession()

# paras
W_conv1 = weight_varible([5, 5, 1, 32])
b_conv1 = bias_variable([32])

# conv layer-1
x = tf.placeholder(tf.float32, [None, 784])
x_image = tf.reshape(x, [-1, 28, 28, 1])

h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)
h_pool1 = max_pool_2x2(h_conv1)

# conv layer-2
W_conv2 = weight_varible([5, 5, 32, 64])
b_conv2 = bias_variable([64])

h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)
h_pool2 = max_pool_2x2(h_conv2)

# full connection
W_fc1 = weight_varible([7 * 7 * 64, 1024])
b_fc1 = bias_variable([1024])

h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64])
h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)

# dropout
keep_prob = tf.placeholder(tf.float32)
h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)

# output layer: softmax
W_fc2 = weight_varible([1024, 10])
b_fc2 = bias_variable([10])

y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)
y_ = tf.placeholder(tf.float32, [None, 10])

# model training
cross_entropy = -tf.reduce_sum(y_ * tf.log(y_conv))
train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)

correct_prediction = tf.equal(tf.arg_max(y_conv, 1), tf.arg_max(y_, 1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

sess.run(tf.initialize_all_variables())

for i in range(20000):
    batch = mnist.train.next_batch(50)

    if i % 100 == 0:
        train_accuacy = accuracy.eval(feed_dict={x: batch[0], y_: batch[1], keep_prob: 1.0})
        print(""step %d, training accuracy %g""%(i, train_accuacy))
    train_step.run(feed_dict = {x: batch[0], y_: batch[1], keep_prob: 0.5})

# accuacy on test
print(""test accuracy %g""%(accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0})))
```
### on cpu

step 0, training accuracy 0.06
step 100, training accuracy 0.8
step 200, training accuracy 0.94
step 300, training accuracy 0.9
step 400, training accuracy 0.92
step 500, training accuracy 0.84
step 600, training accuracy 1
step 700, training accuracy 0.96
step 800, training accuracy 0.94
step 900, training accuracy 1
step 1000, training accuracy 0.98
step 1100, training accuracy 0.92
step 1200, training accuracy 0.96
step 1300, training accuracy 1
step 1400, training accuracy 1
step 1500, training accuracy 1
......
test accuracy 0.9671
### on gpu

step 0, training accuracy 0.1
step 100, training accuracy 0.08
step 200, training accuracy 0.02
step 300, training accuracy 0.12
step 400, training accuracy 0.1
step 500, training accuracy 0.1
step 600, training accuracy 0.12
step 700, training accuracy 0.12
step 800, training accuracy 0.1
step 900, training accuracy 0.04
step 1000, training accuracy 0.12
step 1100, training accuracy 0.3
step 1200, training accuracy 0.1
step 1300, training accuracy 0.08
step 1400, training accuracy 0.12
step 1500, training accuracy 0.2
......
test accuracy 0.1160
"
3890,GPU Profiling: does the OP include the data transferring time from host to gpu device and gpu device to host?,"@prb12 
Hi Paul,
I just do the profiling following: https://github.com/tensorflow/tensorflow/issues/1824. And it works quite well. I detect that Conv2D costs a lot of time in my case, and it is run by nvidia GPU, does the timing for Conv2D include the H2D/D2H time or just the time run on GPU.

Thanks!
"
3889,Control flow gradient problem with `tf.float16` datatype,"### Environment info

Operating System:
Linux

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)
   3cb39956e622b322e43547cf2b6e337020643f21
2. The output of `bazel version`

```
Build label: 0.3.1
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Jul 29 09:09:52 2016 (1469783392)
Build timestamp: 1469783392
Build timestamp as int: 1469783392

```
### Steps to reproduce

```
# Minimal example to reproduce the error.
import tensorflow as tf
from tensorflow.contrib.layers import conv2d, batch_norm
sess = tf.InteractiveSession()
is_train_var = tf.placeholder(tf.bool)
# If `tf.float32` is used here, it works flawlessly. Alternatively,
# if a constant instead of a variable is used for `is_training`,
# everything works as expected.
inp = tf.placeholder(tf.float16, [1, 5, 5, 3], name='data')
conv1 = conv2d(inp, 1, 5, padding='VALID',
               normalizer_fn=batch_norm,
               normalizer_params={'is_training': is_train_var})
optimizer = tf.train.MomentumOptimizer(learning_rate=0.1, momentum=0.9)
optimizer.compute_gradients(conv1)
```

This results in the error

```
Traceback (most recent call last):
  File ""repr.py"", line 10, in <module>
    optimizer.compute_gradients(conv1)
  File ""/lustre/home/classner/git/tensorflow/_python_build/tensorflow/python/training/optimizer.py"", line 253, in compute_gradients
    colocate_gradients_with_ops=colocate_gradients_with_ops)
  File ""/lustre/home/classner/git/tensorflow/_python_build/tensorflow/python/ops/gradients.py"", line 478, in gradients
    in_grads = _AsList(grad_fn(op, *out_grads))
  File ""/lustre/home/classner/git/tensorflow/_python_build/tensorflow/python/ops/control_flow_grad.py"", line 69, in _SwitchGrad
    return merge([good_grad, zero_grad], name=""cond_grad"")[0], None
  File ""/lustre/home/classner/git/tensorflow/_python_build/tensorflow/python/ops/control_flow_ops.py"", line 361, in merge
    return gen_control_flow_ops._merge(inputs, name)
  File ""/lustre/home/classner/git/tensorflow/_python_build/tensorflow/python/ops/gen_control_flow_ops.py"", line 153, in _merge
    result = _op_def_lib.apply_op(""Merge"", inputs=inputs, name=name)
  File ""/lustre/home/classner/git/tensorflow/_python_build/tensorflow/python/framework/op_def_library.py"", line 437, in apply_op
    raise TypeError(""%s that don't all match."" % prefix)
TypeError: Tensors in list passed to 'inputs' of 'Merge' Op have types [float16, float32] that don't all match.
```
### What have you tried?

I am currently using constant variables as a workaround as described.
"
3888,Tensorflow loss not changing and also computed gradients and applied batch norm but still loss is not changing?,"Tensorflow loss is not changing. This is my code.

```
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import tensorflow as tf
import numpy as np
import math
import os
import nltk
import random
import tflearn
batch_size = 100
start = 0
end = batch_size
learning_rate = 0.01
num_classes = 8
path1 = ""/home/indy/Downloads/aclImdb/train/pos""
path2 = ""/home/indy/Downloads/aclImdb/train/neg""
path3 = ""/home/indy/Downloads/aclImdb/test/pos""
path4 = ""/home/indy/Downloads/aclImdb/test/neg""
time_steps = 300
embedding = 50
step = 1


def get_embedding():
    gfile_path = os.path.join(""/home/indy/Downloads/glove.6B"", ""glove.6B.50d.txt"")
    f = open(gfile_path,'r')
    embeddings = {}
    for line in f:
        sp_value = line.split()
        word = sp_value[0]
        embedding = [float(value) for value in sp_value[1:]]
        assert len(embedding) == 50
        embeddings[word] = embedding
    return embeddings

ebd = get_embedding()

def get_y(file_path):
    y_value = file_path.split('_')
    y_value = y_value[1].split('.')
    if y_value[0] == '1':
       return 0
    elif y_value[0] == '2':
         return 1
    elif y_value[0] == '3':
          return 2
    elif y_value[0] == '4':
          return 3
    elif y_value[0] == '7':
          return 4
    elif y_value[0] == '8':
          return 5
    elif y_value[0] == '9':
          return 6
    elif y_value[0] == '10':
          return 7 

def get_x(file_path):
    x_value = open(file_path,'r')
    for line in x_value:
        x_value = line.replace(""<br /><br />"","""") 
        x_value = x_value.lower()
    x_value = nltk.word_tokenize(x_value.decode('utf-8'))
    padding = 300 - len(x_value)
    if padding > 0:
       p_value = ['pad' for i in range(padding)]
       x_value = np.concatenate((x_value,p_value))
    if padding < 0:
       x_value = x_value[:300]
    for i in x_value:
        if ebd.get(i) == None:
           ebd[i] = [float(np.random.normal(0.0,1.0)) for j in range(50)]
    x_value = [ebd[value] for value in x_value]
    assert len(x_value) == 300
    return x_value


def get_total_files(path1,path2,path3,path4):
    directory1 = os.listdir(path1)
    file_path1 = [os.path.join(path1,file) for file in directory1]
    directory2 = os.listdir(path2)
    file_path2 = [os.path.join(path2,file) for file in directory2]
    directory3 = os.listdir(path3)
    file_path3 = [os.path.join(path3,file) for file in directory3]
    directory4 = os.listdir(path4)
    file_path4 = [os.path.join(path4,file) for file in directory4]
    total_files_train = np.concatenate((file_path1,file_path2))
    total_files_test = np.concatenate((file_path3,file_path4))
    random.shuffle(total_files_train)
    random.shuffle(total_files_test)    
    x1 = [get_x(file) for file in total_files_train]
    y1 = [get_y(file) for file in total_files_train]
    x2 = [get_x(file) for file in total_files_test]
    y2 = [get_y(file) for file in total_files_test]
    return x1 , y1 , x2 , y2

total_files_train_x, total_files_train_y, total_files_test_x, total_files_test_y = get_total_files(path1,path2,path3,path4)


train_set_x = total_files_train_x[:10000]
validate_set_x = total_files_train_x[10000:15000]
test_set_x = total_files_test_x[0:5000]
train_set_y = total_files_train_y[:10000]
validate_set_y = total_files_train_y[10000:15000]
test_set_y = total_files_test_y[0:5000]


X = tf.placeholder(tf.float32, [None,time_steps,embedding])
Y = tf.placeholder(tf.int32, [None])

def build_nlp_model(x, _units,num_classes,num_of_filters):
    x = tf.expand_dims(x,3)
    with tf.variable_scope(""one""):      
         filter_shape = [1, embedding, 1, num_of_filters]
         conv_weights = tf.get_variable(""conv_weights"" , filter_shape, tf.float32, tf.truncated_normal_initializer(mean=0.0, stddev=1.0))
         conv_biases = tf.Variable(tf.constant(0.1, shape=[num_of_filters]))
         conv = tf.nn.conv2d(x, conv_weights, strides=[1,1,1,1], padding = ""VALID"")
         normalize = conv + conv_biases
         tf_normalize = tflearn.layers.normalization.batch_normalization(normalize)
         relu = tf.nn.elu(tf_normalize)
         pooling = tf.reduce_max(relu, reduction_indices = 3, keep_dims = True)
         outputs_fed_lstm = pooling

    with tf.variable_scope(""two""):         
         filter_shape = [1, 1, 1, 1000]
         conv_weights = tf.get_variable(""conv_weights"" , filter_shape, tf.float32, tf.truncated_normal_initializer(mean=0.0, stddev=1.0))
         conv_biases = tf.Variable(tf.constant(0.1, shape=[1000]))
         conv = tf.nn.conv2d(outputs_fed_lstm, conv_weights, strides=[1,1,1,1], padding = ""VALID"")
         normalize = conv + conv_biases
         tf_normalize = tflearn.layers.normalization.batch_normalization(normalize)
         relu = tf.nn.elu(tf_normalize)
         pooling = tf.reduce_max(relu, reduction_indices = 3, keep_dims = True)
         outputs_fed_lstm = pooling

    with tf.variable_scope(""three""):        
         filter_shape = [1, 1, 1, 1000]
         conv_weights = tf.get_variable(""conv_weights"" , filter_shape, tf.float32, tf.truncated_normal_initializer(mean=0.0, stddev=1.0))
         conv_biases = tf.Variable(tf.constant(0.1, shape=[1000]))
         conv = tf.nn.conv2d(outputs_fed_lstm, conv_weights, strides=[1,1,1,1], padding = ""VALID"")
         normalize = conv + conv_biases
         tf_normalize = tflearn.layers.normalization.batch_normalization(normalize)
         relu = tf.nn.elu(tf_normalize)
         pooling = tf.reduce_max(relu, reduction_indices = 3, keep_dims = True)
         outputs_fed_lstm = pooling

    with tf.variable_scope(""four""):         
         filter_shape = [1, 1, 1, num_of_filters]
         conv_weights = tf.get_variable(""conv_weights"" , filter_shape, tf.float32, tf.truncated_normal_initializer(mean=0.0, stddev=1.0))
         conv_biases = tf.Variable(tf.constant(0.1, shape=[num_of_filters]))
         conv = tf.nn.conv2d(outputs_fed_lstm, conv_weights, strides=[1,1,1,1], padding = ""VALID"")
         normalize = conv + conv_biases
         tf_normalize = tflearn.layers.normalization.batch_normalization(normalize)
         relu = tf.nn.elu(tf_normalize)
         pooling = tf.reduce_max(relu, reduction_indices = 3, keep_dims = True)
         outputs_fed_lstm = pooling

    with tf.variable_scope(""five""):         
         filter_shape = [1, 1, 1, num_of_filters]
         conv_weights = tf.get_variable(""conv_weights"" , filter_shape, tf.float32, tf.truncated_normal_initializer(mean=0.0, stddev=1.0))
         conv_biases = tf.Variable(tf.constant(0.1, shape=[num_of_filters]))
         conv = tf.nn.conv2d(outputs_fed_lstm, conv_weights, strides=[1,1,1,1], padding = ""VALID"")
         normalize = conv + conv_biases
         tf_normalize = tflearn.layers.normalization.batch_normalization(normalize)
         relu = tf.nn.elu(tf_normalize)
         pooling = tf.reduce_max(relu, reduction_indices = 3, keep_dims = True)
         outputs_fed_lstm = pooling

    x = tf.squeeze(outputs_fed_lstm, [2])     
    x = tf.transpose(x, [1, 0, 2])
    x = tf.reshape(x, [-1, 1])
    x = tf.split(0, time_steps, x)

    lstm = tf.nn.rnn_cell.LSTMCell(num_units = _units)

     # multi_lstm = tf.nn.rnn_cell.MultiRNNCell([lstm] * lstm_layers, state_is_tuple = True)

    outputs , state = tf.nn.rnn(lstm,x, dtype = tf.float32)     

    weights = tf.Variable(tf.random_normal([_units,num_classes]))
    biases  = tf.Variable(tf.random_normal([num_classes]))

    logits = tf.matmul(outputs[-1], weights) + biases
    return logits

logits = build_nlp_model(X,500,num_classes,1000)
c_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits,Y)
loss = tf.reduce_mean(c_loss)


global_step = tf.Variable(0, name=""global_step"", trainable=False)
# decayed_learning_rate = tf.train.exponential_decay(learning_rate,0,10000,0.9)
optimizer= tf.train.AdamOptimizer(learning_rate)
minimize_loss = optimizer.minimize(loss, global_step=global_step)   
with tf.variable_scope(""four"", reuse = True):
     weights = tf.get_variable(""conv_weights"") 
     grads_and_vars = optimizer.compute_gradients(loss,[weights]) 
correct_predict = tf.nn.in_top_k(logits, Y, 1)
accuracy = tf.reduce_mean(tf.cast(correct_predict, tf.float32))


init = tf.initialize_all_variables()

with tf.Session() as sess:
     sess.run(init)
     for i in range(10):
         for j in range(100):
             x = train_set_x[start:end]
             y = train_set_y[start:end]
             start = end
             end += batch_size
             if start >= 10000:
                start = 0
                end = batch_size  
             sess.run(minimize_loss,feed_dict={X : x, Y : y})
             step += 1  
             gr_print = sess.run([grad for grad, _ in grads_and_vars], feed_dict={X : x, Y : y})
             print (gr_print)
         print (""One Epoch Finished"")
         cost = sess.run(loss,feed_dict = {X: x,Y: y})
         accu = sess.run(accuracy,feed_dict = {X: x, Y: y})
         print (""Loss after one Epoch(Training) = "" + ""{:.6f}"".format(cost) + "", Training Accuracy= "" + ""{:.5f}"".format(accu))
         q = validate_set_x[:100]
         w = validate_set_y[:100]
         cost = sess.run(loss,feed_dict = {X: q,Y: w})
         accu = sess.run(accuracy,feed_dict = {X: q, Y: w})
```

My loss remains the same after many Epochs. So I think that I'm having vanishing gradient problem and so I applied batch normalization but I got no difference in results.I also tried overfitting the model, but I'm getting same results. I'm using `optimizer.compute_gradients` for computing gradients. Below are the results of gradients of loss with respect to different conv layers, and how they look like. Here is how my gradients look like with respect to first conv layers and with respect to 4th conv layer.

Code for gradients with respect to first conv layer:

```
with tf.variable_scope(""one"", reuse = True):
     weights = tf.get_variable(""conv_weights"") 
     grads_and_vars = optimizer.compute_gradients(loss,[weights])


gr_print = sess.run([grad for grad, _ in grads_and_vars], feed_dict={X : x, Y : y})
           print (gr_print)
```

 And this is what I get after one iteration:

```
[array([[[[  2.38197345e-06,  -1.04135906e-04,   2.60035231e-05, ...,
           -1.01550373e-04,   0.00000000e+00,   1.01060732e-06]],

        [[ -1.98007251e-06,   8.13827137e-05,  -8.14055747e-05, ...,
           -6.40711369e-05,   0.00000000e+00,   1.05516607e-04]],

        [[  4.51127789e-06,   2.21654373e-05,  -4.99439229e-05, ...,
            9.87191743e-05,   0.00000000e+00,   1.70595697e-04]],

        ..., 
        [[ -4.70160239e-06,  -8.67914496e-05,   2.50699850e-05, ...,
            1.18909593e-04,   0.00000000e+00,   2.43308150e-05]],

        [[ -1.18101923e-06,  -7.71943451e-05,  -3.41630148e-05, ...,
           -3.28040805e-05,   0.00000000e+00,  -6.01144784e-05]],

        [[ -1.98778321e-06,  -3.23160748e-05,  -5.44797731e-05, ...,
            2.23019324e-05,   0.00000000e+00,  -3.29296927e-05]]]], dtype=float32)]
```

Code for gradients with respect to 4th conv layer:

```
with tf.variable_scope(""four"", reuse = True):
     weights = tf.get_variable(""conv_weights"") 
     grads_and_vars = optimizer.compute_gradients(loss,[weights])
gr_print = sess.run([grad for grad, _ in grads_and_vars], feed_dict={X : x, Y : y})
           print (gr_print)
```

And this what I get after one iteration:

```
[array([[[[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        , -6.21198082,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.                ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.              ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ,  0.        ]]]], dtype=float32)]
```

After first layer, gradients with respect to 2nd,3rd,4th,5th conv layers all look like above. But there's one thing common among all the gradients with respect to conv layers which are after first conv layer, they all have one number in the entire gradient array,that is not zero as shown above in the output. And I also applied batch norm and I'm still getting the above results.

I'm totally confused, I don't know where the problem is?
"
3887,tf.fill should accept dtype argument,"The signature of `tf.fill` is  `tf.fill(dims, value, name=None)`, which not does allow to configure the dtype of the result. As opposed to `tf.ones`, `tf.ones(shape, dtype=tf.float32, name=None)`.

Shouldn't `tf.fill` also accept a dtype argument?
"
3886,control_dependencies() maybe fails to mfence when an assign() with different shape occurs,"### Environment info

Operating System: OS X El Capitan

Installed CPU version (OSX pip package)
tensorflow version: 0.10.0rc0
### Steps to reproduce

Consider the following code snippet:

``` python
x = tf.Variable(0.)
x_op = tf.assign(x, [1.], validate_shape=False)

with tf.control_dependencies([x_op]):
    plus_op = x+2

tf.initialize_variables([x]).run()
print plus_op.eval()
```

The expected output is `[3]`, but instead I get `2`
### What have you tried?

If we don't assign an inconsistent shape (e.g. assign `1` instead of `[1]`), then things work the way one would expect (output is `3`)

If we replace

`plus_op = x+2`

with

`plus_op=x.ref() + 2`

then we get the expected output of `[3]` instead of `2`.

I suspect this is because calling `ref()` may somehow trigger a memory fence which fixes the broken behavior.

Also, it is possible that this is the intended behavior and that I misunderstood control_dependencies(), in which case I apologize.
"
3885,Issues #2099 has become a problem again: using empty variables,"The code below fails with ""Attempting to use uninitialized value Variable"".  See #2099. I presume that this was fixed in the past but regressed subsequently. I understand that the past stance was that it is fine to use variables with shapes that contain a 0 in one of the dimensions.

```
sess = tf.InteractiveSession()
empty = np.zeros(shape=(0, 0) )
a = tf.Variable(empty)
sess.run(tf.initialize_all_variables())
sess.run(tf.reduce_sum(a))
```
"
3882,dynamic_rnn time_major=False does not support rank>3 input,"https://github.com/tensorflow/tensorflow/blob/33b336ada58529d5e0398feea423785f1c3d57c1/tensorflow/python/ops/rnn.py#L782

```
flat_input = tuple(array_ops.transpose(input_, [1, 0, 2])
for input_ in flat_input)
```

Here seems we can only transpose matrix of size batch_size \* time_size \* input_size. It doesn't work if my input at each time step is a matrix.
In torch you can just specify the two dimensions (0 and 1 here) to be swapped instead of perm. Is there a similar functionality?
"
3881,ImportError: No module named tools (missing __init__.py?),"### Environment info

Operating System: Ubuntu 14.04 LTS 64-bit

Installed version of CUDA and cuDNN: none

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`): fc9162975e52978d3af38549b570cc3cc5f0ab66
2. The output of `bazel version`:

```
Build label: 0.3.0
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Jun 10 11:38:23 2016 (1465558703)
Build timestamp: 1465558703
Build timestamp as int: 1465558703
```
### Steps to reproduce
1. Create a new IPython Notebook
2. Run the following:

```
import tensorflow as tf
from tensorflow.python.tools import freeze_graph
```
### What have you tried?

It seems that the tools directory is missing an `__init__.py` (though there is one in the python directory), and so tools isn't being recognized as a module. However, this is a bit baffling, because [`freeze_graph_test.py`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph_test.py) uses these exact same import statements. Just to be sure, I tried copying in all the import statements in `freeze_graph_test.py`:

```
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import os

import tensorflow as tf

from tensorflow.python.framework import test_util
from tensorflow.python.tools import freeze_graph
```

and sure enough, `freeze_graph` was the only one that gave an error.

`__init__.py` doesn't appear in the repository on GitHub as well. I noticed there's a Bazel BUILD file instead, but as far as I know, Bazel is only used to build the Android demo. Am I missing something?
### Logs or other output that would be helpful

```
ImportError                               Traceback (most recent call last)
<ipython-input-10-039cb956bb5c> in <module>()
      1 import tensorflow as tf
----> 2 from tensorflow.python.tools import freeze_graph

ImportError: No module named tools
```
"
3879,Strange behavior of tf.control_dependencies,"Consider the following code:

```
import tensorflow as tf

with tf.variable_scope('a'):
    a = tf.get_variable('v', [], initializer=tf.constant_initializer(0), dtype=tf.int32)
    a_assign = a.assign(a+100)

with tf.variable_scope('a', reuse=True):
    b = tf.get_variable('v', [], initializer=tf.constant_initializer(0), dtype=tf.int32)
    b_assign = b.assign(b+1)

with tf.control_dependencies([a_assign, b_assign]):
    c = tf.constant(0)

sess = tf.InteractiveSession()
sess.run(tf.initialize_all_variables())
print(sess.run([c, a, b]))

```

I expected this piece of code to return [0, 101, 101], but instead it returns [0, 100, 100]. 

Then I ran the ""print(sess.run([c, a, b]))"" line 10 times, the outputs were:

[0, 100, 100]
[0, 200, 200]
[0, 201, 201]
[0, 202, 202]
[0, 303, 303]
[0, 403, 403]
[0, 404, 404]
[0, 405, 405]
[0, 406, 406]
[0, 506, 506]

Then I re-ran the program again and the outputs were:

[0, 1, 1]
[0, 2, 2]
[0, 3, 3]
[0, 4, 4]
[0, 5, 5]
[0, 6, 6]
[0, 7, 7]
[0, 8, 8]
[0, 108, 108]
[0, 208, 208]

So it seems like in this case tf.control_dependencies randomly executes either a_assign or b_assign and not both at each sess.run. Could anyone explain this behavior?
### Environment info

Operating System:
Ubuntu 14.04
Installed version of CUDA and cuDNN: 
-rw-r--r-- 1 root root 189170 Jun  6 15:17 /usr/local/cuda/lib/libcudadevrt.a
lrwxrwxrwx 1 root root     16 Jun  6 15:17 /usr/local/cuda/lib/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root     19 Jun  6 15:17 /usr/local/cuda/lib/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root 311596 Jun  6 15:17 /usr/local/cuda/lib/libcudart.so.7.5.18
-rw-r--r-- 1 root root 558020 Jun  6 15:17 /usr/local/cuda/lib/libcudart_static.a

TensorFlow version 0.9.0
"
3875,Core dump running examples w/gpu,"Running the post-build test throws a Floating point exception:

```
$ bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so.7.5 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so.7.5 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so.7.5 locally
I tensorflow/core/common_runtime/gpu/gpu_init.cc:118] Found device 0 with properties: 
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.076
pciBusID 0000:81:00.0
Total memory: 12.00GiB
Free memory: 11.87GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:138] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:148] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:868] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:81:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:868] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:81:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:868] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:81:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:868] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:81:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:868] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:81:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:868] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:81:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:868] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:81:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:868] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:81:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:868] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:81:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:868] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:81:00.0)
Floating point exception (core dumped)

```
### Environment info

Operating System: Ubuntu 14.04 x86_64

Installed version of CUDA and cuDNN: 

```
-rw-r--r-- 1 root root   322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root       19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root   383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root   720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a
-rwxr-xr-x 1 root root 59909104 Aug 17 11:12 /usr/local/cuda/lib64/libcudnn.so
-rwxr-xr-x 1 root root 59909104 Aug 17 11:12 /usr/local/cuda/lib64/libcudnn.so.5
-rwxr-xr-x 1 root root 59909104 Aug 17 11:12 /usr/local/cuda/lib64/libcudnn.so.5.0.5
-rw-r--r-- 1 root root 58775484 Aug 17 11:12 /usr/local/cuda/lib64/libcudnn_static.a

```

If installed from source, provide:
1. TF commit hash 33b336ada58529d5e0398feea423785f1c3d57c1
2. Bazel 0.3.1

```
$ bazel version
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Thu Jan 01 00:00:00 1970 (0)
Build timestamp: Thu Jan 01 00:00:00 1970 (0)
Build timestamp as int: 0
$ apt show bazel
Package: bazel
Version: 0.3.1
Depends: google-jdk | java8-jdk | java8-sdk, pkg-config, zip, g++,
 zlib1g-dev, unzip, bash-completion
...
```
### Steps to reproduce

(steps taken from https://www.tensorflow.org/versions/r0.10/get_started/os_setup.html#installing-from-sources)
1. Install CUDA 7.5 under x86_64 for Ubuntu 14.04 using deb (network)
2. Install cuDNN 5.0 for Linux (Nvidia no longer supplies cudnn4.0 for CUDA 7.5, only for 7.0)
3. Install Bazel
4. Build tensorflow using Bazel
5. Run $ bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu
### What have you tried?
1. Taking off the --use_gpu flag leads to successful execution
2. The nvidia CUDA examples for deviceQuery and bandwidthTest work OK
3. The GPU is not in exclusive mode (#1534); logs of nvidia-smi -a below
4. gdb output is included below, too
### Logs or other output that would be helpful

[tf-gdb.txt](https://github.com/tensorflow/tensorflow/files/422383/tf-gdb.txt)
[tf-nvsmi.txt](https://github.com/tensorflow/tensorflow/files/422382/tf-nvsmi.txt)
"
3874,SVD not accepting complex matrices,"Just with a small test case on the Eigen BDCSVD which should work with complex matrices, I  get `TypeError: DataType complex128 for attr 'T' not in list of allowed values: float64, float32`. I know that TensorFlow SVD is very new, but where would I look to enable complex types?

Here was my test code:

``` python
x = np.array([[0, -1j], [1j, 0]])
a = tf.placeholder(tf.complex128, [None, None])
s, u, v = tf.svd(a)
sess = tf.Session()
print(sess.run(u, feed_dict={a: x}))
```
"
3870,DNNLinearCombinedClassifier in distributed system on cpu. Worker1 costs 1000% of CPU and other workers cost 30%~50%.,"#### Installed from source, r0.10 branch.
### Steps to reproduce

I use multi-ps & multi-worker to train. Model is DNNLinearCombinedClassifier under `contrib.learn`.
#### Distributed code:

 ps & worker entrance:

```
  server = tf.train.Server(
    {'ps': ps_hosts,
     'worker': worker_hosts},
    job_name=FLAGS.job_name,
    task_index=task_id)

  if FLAGS.job_name == 'ps':
    # `ps` jobs wait for incoming connections from the workers.
    server.join()
  else:      
      # `worker` jobs will actually do the work.
      self.worker_do(server.targer, cluster_spec, task_id)
```

self.worker_do:

```
num_workers = len(cluster_spec.as_dict()['worker'])
num_parameter_servers = len(cluster_spec.as_dict()['ps']) 
run_config = RunConfig(master=target, task=task_id, num_ps_replicas=num_parameter_servers,
                     num_cores=8)
classifier = DNNLinearCombinedClassifier(dnn_hidden_units=[1024, 512, 256], config=run_config, dnn_feature_columns=deep, model_dir=FLAGS.train_dir)
classifier.fit(input_fn=_input, steps=FLAGS.max_steps)
```

Start ps1...N, then worker1...N

`When training begin, I found worker1 cost 1000% CPU and other workers cost less on 100%.`
### What have you tried?

code in BaseEstimator when `__init__`:

```
 # Set device function depending if there are replicas or not.
if self._config.num_ps_replicas > 0:
  ps_ops = ['Variable', 'AutoReloadVariable']
  self._device_fn = device_setter.replica_device_setter(
      ps_tasks=self._config.num_ps_replicas,
      merge_devices=False, ps_ops=ps_ops)
else:
  self._device_fn = None
```

I tried to add a param to `device_setter.replica_device_setter`

```
worker_device='/job:worker/task:%d' % self._config.task 
```

And it works. Cpu balances.
### Suggesting

Could you consider adding an API to place `_device_fn` to BaseEstimator. Then, tf users can customize their own `_device_fn`.

Thanks.
"
3869,"Run ""bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu"", got ""No such file or directory""","Hi everyone:
### Environment info

Ubuntu 14.04 LTS

Installed version of CUDA and cuDNN: 
CUDA 7.5, cuDNN v5.1
![image](https://cloud.githubusercontent.com/assets/12611573/17721639/5e9f7f32-645e-11e6-8ba6-ec7f37b1e139.png)
I try to build tensorflow with CUDA 7.5, cuDNN v5.1 and bazel-0.3.1-installer-linux-x86_64.sh. When I run 'bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer', it seems good. But when I run 'bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu', I got the error 'No such file or directory'. So I find the tutorials_example_trainer in following path:
![image](https://cloud.githubusercontent.com/assets/12611573/17721729/13e19b5a-645f-11e6-91e7-73667ea0905d.png)
I tried to run '/home/caffe/.cache/bazel/_bazel_caffe/5954a53028453a61b395a19127f3e1cf/execroot/tensorflow/bazel-out/local_linux-opt/bin/tensorflow/cc/tutorials_example_trainer.runfiles/org_tensorflow/tensorflow/cc/tutorials_example_trainer --use_gpu' and got the result like following:
![image](https://cloud.githubusercontent.com/assets/12611573/17721744/349e1ba2-645f-11e6-80a8-9746ac31a43a.png)
It seems ok, but I do not know why cann't I run 'bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu'.
Can anyone help me ?
Thanks!
"
3867,parallel_iterations option behaves differently if per_process_gpu_memory_fraction is set,"I'm seeing inconsistent behavior with the `parallel_iterations` option in dynamic RNNs. For large RNNs, if I set `parallel_iterations` to too high a number, I run out of memory. However, setting `parallel_iterations` to 1 or 2 solves the problem. This is only true however if `per_process_gpu_memory_fraction` is not set. If it is set, even to 1.0, then no matter what value I set `parallel_iterations` to, I always run out of memory (for this large RNN).

I am not sure if this is related to #2610 or not.
"
3864,"Tensorflow r.0.10, CUDA 8.0, cuDNN 5.1 core dumped, CUDA_ERROR_OUT_OF_MEMORY","On running a benchmark with MNIST data on a CNN (source below) tensorflow first complains about memory allocation and then appears to have trouble using cuDNN 5.1
Detailed script and output at the bottom. 
Problem appears to affect cuDNN specifically as I could run CUDA examples as well as matmul on tensorflow without problems. 
### Environment info

Operating System: ubuntu 16.04
uname -a
Linux <Name> 4.4.0-34-generic #53-Ubuntu SMP Wed Jul 27 16:06:39 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux

Installed version of CUDA and cuDNN: 
ls -l $CUDA_HOME/lib64/libcud*
-rw-r--r-- 1 root root   560184 Aug 15 22:51 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Aug 15 22:51 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root       19 Aug 15 22:51 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.27
-rwxr-xr-x 1 root root   394472 Aug 15 22:51 /usr/local/cuda/lib64/libcudart.so.8.0.27
-rw-r--r-- 1 root root   737516 Aug 15 22:51 /usr/local/cuda/lib64/libcudart_static.a
lrwxrwxrwx 1 root root       13 Aug 15 23:39 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5
lrwxrwxrwx 1 root root       17 Aug 15 23:39 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5
-rwxr-xr-x 1 root root 79337624 Aug 15 23:39 /usr/local/cuda/lib64/libcudnn.so.5.1.5
-rw-r--r-- 1 root root 69756172 Aug 15 23:39 /usr/local/cuda/lib64/libcudnn_static.a
### Environment variables

echo $LD_LIBRARY_PATH
/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64
echo $CUDA_HOME
/usr/local/cuda
echo $PATH
/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/usr/local/cuda/bin/:/usr/local/cuda/bin/
### Tensorflow version

Compiled from source, r0.10, built into pip package and installed this pip wheel
Configured with cuDNN path and version set to system default
1. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   see /// OUTPUT /// at the end

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)
   n.a.
   version r0.10
2. The output of `bazel version`
   bazel version
   Build label: 0.3.1-2016-08-15 (@936c2c2)
   Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
   Build time: Sun Aug 14 23:07:32 2016 (1471216052)
   Build timestamp: 1471216052
   Build timestamp as int: 1471216052
### Steps to reproduce: run this script

import numpy
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Dropout
from keras.layers import Flatten
from keras.layers.convolutional import Convolution2D
from keras.layers.convolutional import MaxPooling2D
from keras.utils import np_utils
##### fix random seed for reproducibility

seed = 7
numpy.random.seed(seed)
##### load data

(X_train, y_train), (X_test, y_test) = mnist.load_data()
##### reshape to be [samples][channels][width][height]

X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')
X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')
##### normalize inputs from 0-255 to 0-1

X_train = X_train / 255
X_test = X_test / 255
##### one hot encode outputs

y_train = np_utils.to_categorical(y_train)
y_test = np_utils.to_categorical(y_test)
num_classes = y_test.shape[1]
##### define a simple CNN model

def baseline_model():
    ##### create model
    model = Sequential()
    model.add(Convolution2D(32, 5, 5, border_mode='valid', input_shape=(1, 28, 28), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.2))
    model.add(Flatten())
    model.add(Dense(128, activation='relu'))
    model.add(Dense(num_classes, activation='softmax'))
    ##### Compile model
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model
##### build the model

model = baseline_model()
##### Fit the model

model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=200, verbose=2)
##### Final evaluation of the model

scores = model.evaluate(X_test, y_test, verbose=0)
print(""CNN Error: %.2f%%"" % (100-scores[1]*100))
### ///////////// OUTPUT /////////////////

Using TensorFlow backend.
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so.8.0 locally
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: GeForce GTX 1070
major: 6 minor: 1 memoryClockRate (GHz) 1.683
pciBusID 0000:01:00.0
Total memory: 7.91GiB
Free memory: 148.69MiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:840] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)
E tensorflow/stream_executor/cuda/cuda_driver.cc:965] failed to allocate 148.69M (155910144 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
Train on 60000 samples, validate on 10000 samples
Epoch 1/10
E tensorflow/stream_executor/cuda/cuda_dnn.cc:354] could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
E tensorflow/stream_executor/cuda/cuda_dnn.cc:321] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM
F tensorflow/core/kernels/conv_ops.cc:457] Check failed: stream->parent()->GetConvolveAlgorithms(&algorithms) 
Aborted (core dumped)
"
3862,tf.cumprod's gradient produces nans given zeros,"Example:

```
tf.reset_default_graph()
var = tf.Variable([0.])
cumprod = tf.cumprod(var)
grad = tf.gradients(cumprod, var)
init = tf.initialize_all_variables()
with tf.Session() as sess:
  sess.run(init)
  print(sess.run(grad))

---> [array([ nan], dtype=float32)]
```

@ibab Do you know the right way to fix this?
"
3860,"dynamic_rnn error: cannot set initial_state, could before","So, I've come back to my code after a week, I was using dynamic_rnn and have the initial_state parameter set to a tuple, everything was working fine training worked beautifully... 

Anyway, now today I get this error:
TypeError: The two structures don't have the same sequence type. First structure has type type 'tuple', while second structure has type class 'tensorflow.python.ops.rnn_cell.LSTMStateTuple'.

I suspect there was an update somewhere, so If someone could point me to where/how I can make an LSTMStateTuple object I would be greatly appreciated. 
"
3859,Error from loading model when running /examples/skflow/iris_save_restore.py,"I am running the example code [iris_save_restore.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/skflow/iris_save_restore.py):

In particular when running

```
ipython iris_save_restore.py
```

I get the error:

```
WARNING:tensorflow:TensorFlowLinearClassifier class is deprecated. Please consider using LinearClassifier as an alternative.
WARNING:tensorflow:Using temporary folder as model directory: /var/folders/k7/x_ddt3gn57z7x452wglt9brh0000gn/T/tmpgOl66O
WARNING:tensorflow:Setting feature info to TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(4)]), is_sparse=False)
WARNING:tensorflow:Setting targets info to TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False)
Accuracy: 0.966667
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
/Users/brad/Downloads/iris_save_restore.py in <module>()
     49 ## Restore everything
     50 new_classifier = learn.TensorFlowEstimator.restore(
---> 51     '/tmp/skflow_examples/iris_custom_model')
     52 score = metrics.accuracy_score(y_test, new_classifier.predict(x_test))
     53 print('Accuracy: {0:f}'.format(score))

/Users/brad/anaconda/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/base.pyc in restore(cls, path, config)
    324     model_def_filename = os.path.join(path, 'model.def')
    325     if not os.path.exists(model_def_filename):
--> 326       raise ValueError(""Restore folder doesn't contain model definition."")
    327     # list of parameters that are allowed to be reconfigured
    328     reconfigurable_params = ['_config']

ValueError: Restore folder doesn't contain model definition.
```

But in the model directory `/var/folders/k7/x_ddt3gn57z7x452wglt9brh0000gn/T/tmpgOl66O`, there are the following files:
- `checkpoint`
- `graph.pbtxt`
- `model.ckpt-200.meta`
- `events.out.tfevents.1471384242.ip-192-168-100-142.ec2.internal`
- `model.ckpt-200-00000-of-00001`

Thanks so much for the help. 
### Environment info

Operating System: OS X 10.11.6

If installed from binary pip package, provide:
1. Which pip package you installed.
   sudo pip install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.10.0rc0-py2-none-any.whl
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   0.10.0rc0
"
3857,(Eigen thirdparty) Can't compile fixed point matrix matrix multiply,"I can't get the Eigen fixed point backend to compile a simple matrix matrix multiply with Intel AVX2.
Anyone got a working example? I think the PacketMathAVX2.h is either missing something or I need to tell Eigen to align the matrices somehow. But I'm at a loss.

Here is a simple C++ code that highlights the issue. 

```
#include <Eigen/Dense>
#define EIGEN_VECTORIZE_AVX
#define EIGEN_VECTORIZE_AVX2
#include <unsupported/Eigen/CXX11/Tensor>
#include <unsupported/Eigen/CXX11/FixedPoint>

int main(int argc, char* argv[])
{
    Eigen::QInt8 dbg((float)1.5), dbg2((float)2.5), dbg3;
    Eigen::Matrix<Eigen::QInt32,32,32>one,two,three;

    dbg3 = dbg + dbg2;
    dbg3 = dbg * dbg2;
    dbg3 = dbg - dbg2; //OK
    three = one * two;   //Does not compile
    return 0;
}
```
### Environment info

Operating System: Ubuntu 14.04 lts, Eigen3.3-beta2 gcc 4.9.3 cmake 3.2.2

Installed version of CUDA and cuDNN: 
libcudart.so.7.5.18
1. The commit hash:  da41c02
2. The output of `bazel version` NA
### Steps to reproduce
1. Install Eigen3.3-beta2
2. Merge tensorflow/thirdparty/eigen3/unsupported/Eigen with Eigen3.3-beta2root/unsupported/Eigen
3. build the example code listing following these steps https://eigen.tuxfamily.org/dox/GettingStarted.html  
### What have you tried?
1. building without AVX defines 
2. confirmed that non-matrix algebra works ok
### Logs or other output that would be helpful

attached

[tensoreigenlog.txt](https://github.com/tensorflow/tensorflow/files/421290/tensoreigenlog.txt)
"
3856,"Need Protobuf pip wheel package for Python 3.4, which is missing the setup doc","Current documentation only gives `protobuf-3.0.0b2.post2-cp35-none-any.whl` but nothing for `python 3.4`.
### Environment info

Operating System: Mac OS X El Capitan 10.11.6

Installed version of CUDA and cuDNN: None (Intel Iris Graphics 6100)

If installed from binary pip package, provide:
TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.10.0rc0-py3-none-any.whl
#### pip package you installed: `tensorflow-0.10.0rc0-py3-none-any.whl`
### Steps to reproduce
1. Follow the Mac [setup steps here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md)
2. Installation completed fine.  
3. Protobuf's package is the pure python one, which is VERY SLOW. The [setup guide](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#protobuf-library-related-issues) only gives a pip wheel package for Python 3.5
### What steps you have tried

``` bash
$ pip3 install --upgrade https://storage.googleapis.com/tensorflow/mac/protobuf-3.0.0b2.post2-cp35-none-any.whl
protobuf-3.0.0b2.post2-cp35-none-any.whl is not a supported wheel on this platform.

$ pip3 install --upgrade https://storage.googleapis.com/tensorflow/mac/protobuf-3.0.0b2.post2-cp34-none-any.whl
Collecting protobuf==3.0.0b2.post2 from https://storage.googleapis.com/tensorflow/mac/protobuf-3.0.0b2.post2-cp34-none-any.whl
  HTTP error 404 while getting https://storage.googleapis.com/tensorflow/mac/protobuf-3.0.0b2.post2-cp34-none-any.whl
  Could not install requirement protobuf==3.0.0b2.post2 from https://storage.googleapis.com/tensorflow/mac/protobuf-3.0.0b2.post2-cp34-none-any.whl because of error 404 Client Error: Not Found for url: https://storage.googleapis.com/tensorflow/mac/protobuf-3.0.0b2.post2-cp34-none-any.whl
Could not install requirement protobuf==3.0.0b2.post2 from https://storage.googleapis.com/tensorflow/mac/protobuf-3.0.0b2.post2-cp34-none-any.whl because of HTTP error 404 Client Error: Not Found for url: https://storage.googleapis.com/tensorflow/mac/protobuf-3.0.0b2.post2-cp34-none-any.whl for URL https://storage.googleapis.com/tensorflow/mac/protobuf-3.0.0b2.post2-cp34-none-any.whl

```
"
3855,[SOLVED] How to save TensorForest Model?,"Thanks for reading. 

I am trying to save a `TensorForestEstimatorModel` and am not sure how to do so. 

I run:

``` python
import tensorflow as tf
import tensorflow.contrib.learn

hparams = tf.contrib.tensor_forest.python.tensor_forest.ForestHParams(
        num_trees=3, max_nodes=1000, num_classes=3, num_features=4)
classifier = tf.contrib.learn.TensorForestEstimator(hparams)

iris = tf.contrib.learn.datasets.load_iris()
data = iris.data.astype(np.float32)
target = iris.target.astype(np.float32)

classifier.fit(x=data, y=target, steps=100)
```

And everything works great but I see no method to save the model. That is if I run:

``` python
classifier.save('/tmp/tf_examples/my_model_1/')
```

I get the error:

```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-62-0079ac3a857d> in <module>()
----> 1 classifier.save('/tmp/tf_examples/my_model_1/')

AttributeError: 'TensorForestEstimator' object has no attribute 'save'
```

Thanks so much!
### Environment info

Operating System: OS X 10.11.6

If installed from binary pip package, provide:
1. Which pip package you installed.
   sudo pip install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.10.0rc0-py2-none-any.whl
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   0.10.0rc0
"
3854,Peculiar behavior with tf.self_adjoint_eig,"Hi, 

I've come across a really peculiar bug that I think is actually a sign of a much larger problem, but what that is, I have no idea.  The following code:

```
x = np.random.randn(10, 10)

x = (x+x.T)/2

X = tf.placeholder(dtype=tf.float32, shape=[10, 10])

E, V = tf.self_adjoint_eig(X)

with tf.Session() as sess:
    e, v = sess.run([E, V], feed_dict={X: x})

    print(e.shape)
```

throws the error:

```
raise TypeError(""'Tensor' object is not iterable."")
```

but curiously:

```
x = np.random.randn(10, 10)

x = (x+x.T)/2

X = tf.placeholder(dtype=tf.float32, shape=[10, 10])

E = tf.self_adjoint_eig(X)

with tf.Session() as sess:
    e = sess.run(E, feed_dict={X: x})

    print(e.shape)
```

returns (11, 10), and I have no idea how that's even possible, since the docs say that tf.self_adjoint_eig returns two tensors.  While investigating this, I discovered that a lot of my install (from pip) differs substantially from what's documented here even though I have the latest version (tensorflow==0.10.0rc0 from pip freeze).  In particular, tf.self_adjoint_eig is not defined in linalg_ops.py, and I can't find where it's being called from.  Any ideas?

Thanks,
Shawn

**Update:**

I just found it where it's called from.  According to the comment in gen_linalg_ops.py:

```
  The result is a M+1 x M matrix whose first row is the eigenvalues, and
  subsequent rows are eigenvectors.
```

This is different than the API docs.  One or the other (from a usefulness standpoint, probably the code) should be changed.

**Further Update:**

This actually might be an install problem as mentioned above.  The code here calls self_adjoint_eig_v2 which doesn't exist in the latest install.  Why is that?
"
3853,Options for sparse gradients?,"Does `compute_gradients()` support outputs in sparse form? I'm working on a large-scale linear model with sparse inputs. It's quite inefficient to use gradients as dense `Tensor`, especially in distributed training.

It seems that `apply_gradients()` of some optimisers supports gradient inputs as `IndexedSlices` type. But currently I've not found a clear way to convert gradients into this form. 

I've try sth like below to get X indices from mini-batch inputs, and then feed into IndexedSlices with gradient slices. But it doesn't seem to be good because `tf.unique` does not make `x_indices` sorted.

```
new_grads_and_vars = []
x_indices, _ = tf.unique(tf.reshape(tf.slice(X.indices, [0, 1], [-1, 1]), shape=[-1]))  # <- not sorted
for grad, var in grads_and_vars:
   grad_vals = tf.gather(grad, indices=x_indices)
   grad_slice = tf.IndexedSlices(indices=x_indices, values=grad_vals)
   new_grads_and_vars.append((grad_slice, var))
grads_and_vars = new_grads_and_vars
```

Any ideas? Thx.
"
3852,cifar10_eval.py Error,"python cifar10_eval.py
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.076
pciBusID 0000:01:00.0
Total memory: 12.00GiB
Free memory: 281.36MiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:839] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:01:00.0)
W tensorflow/core/common_runtime/bfc_allocator.cc:213] Ran out of memory trying to allocate 68.02MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
"
3851,CSV decode error,"I am using Tensorflow 0.9.0. I have CUDA Driver Version = 7.5 and CUDNN 4 on Ubuntu 14.04
This maybe related to another issue I found [here](https://github.com/tensorflow/tensorflow/issues/633)

I have a simple csv file which has a single line like this

```
""field with
newline"",0
```

where the newline has been added by pressing Enter key in vim on Ubuntu.
I am able to read this file in pandas using the read_csv function where the text field is shown as containing a single \n character.

But when I try to read it in tensorflow, I get the following error:
`tensorflow.python.framework.errors.InvalidArgumentError: Quoted field has to end with quote followed by delim or end`

My tensorflow code to read the csv uses this function to read a single row.

```
def read_single_example(filename_queue, skip_header_lines, record_defaults, feature_index, label_index):
    reader = tf.TextLineReader(skip_header_lines=skip_header_lines)
    key, value = reader.read(filename_queue)
    record = tf.decode_csv(
            value,
            record_defaults=record_defaults)
    features, label = record[feature_index], record[label_index]
    return features, label
```

If I read using pandas and replace all newlines with spaces, the tensorflow code is able to parse the csv successfully.

But it will be really helpful if newlines can be handled within the Tensorflow CSV pipeline itself.
"
3850,real gradients of complex-valued functions,"I am experiencing _unexpected_ behaviour when taking gradients of a complex-valued function parametrised with real variables. It looks like the gradient with respect to the complex part of the function is (erroneously) zero.

Example:

```
> x = tf.constant(0.0)    # real-valued parameters of a complex-valued function
> y = tf.constant(0.0)
> z = tf.complex(x, y)    # the complex-valued function

> session.run(tf.gradients(z, x), {x:1.0, y:2.0})    # value of x and y don't matter
[1.0]    # good, expected
> session.run(tf.gradients(z, y), {x:1.0, y:2.0})
[0.0]    # bad, expecting 1j
```

Is the result being silently cast to real before being returned, or am I misusing `tf.gradients` somehow?

Using tensorflow version 0.9.0 with GPU on RedHat 4.8.6-4.
"
3849,"I like add some functions in deep MNIST but I get the error as tensorflow.python.pywrap_tensorflow.StatusNotOK: Invalid argument: Node 'multiplelayer error/initial_value': Node name contains invalid characters [[Node: multiplelayer error = Variablecontainer="""", dtype=DT_INT32, shape=[], shared_name=""""]]?","GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System:

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`
### Steps to reproduce

1.
2.
3.
### What have you tried?

1.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
3848,Using epochs in tf.train.slice_input_producer gives uninitialized value when combined with batching,"### Environment info

MacOS X 10.11.4 no CUDA
Tensorflow 0.10.0rc0, installed precompiled pip
### Problem

I have my test data saved as `XXX_input.png` and `XXX_cb.png` (for label) and tried to use the
python code below to create the batched input tensors:

``` python
def _load_png_file(path, name):
    file_content = tf.read_file(path)
    png = tf.image.decode_png(file_content, channels=3)
    png = tf.slice(png, [0, 0, 0], [ 128, 128, 3])
    return tf.image.convert_image_dtype(png, dtype=tf.float32, name=name)

def load_data(path):
    if not tf.gfile.Exists(path):
        raise ValueError(""Datadir {} don't exists!"".format(path))
    photo_files = []                                                                
    cb_files = []
    for file_name in os.listdir(path):                                                  
        if file_name.endswith(""_input.png""):
            file_path = os.path.join(path, file_name)                                        
            photo_files.append(file_path)
            cb_files.append(file_path.replace(""_input.png"", ""_cb.png""))

    photos = tf.convert_to_tensor(photo_files, dtype=tf.string)
    cbs = tf.convert_to_tensor(cb_files, dtype=tf.string)
    input_queue = tf.train.slice_input_producer([photos, cbs],          
            num_epochs=FLAGS.num_epochs, # <-- delete this line to make it work
            shuffle=True)

    photo = _load_png_file(input_queue[0], ""photo"")
    cb = _load_png_file(input_queue[1], ""cb"")
    capacity = FLAGS.min_after_dequeue + 3 * FLAGS.batch_size                       
    photo_batch, cb_batch = tf.train.batch([photo, cb],
            capacity=capacity,                                                             
            batch_size=FLAGS.batch_size)
    return photo_batch, cb_batch
```

When I try to use it it will generate an error as below. When I remove the `num_epochs` argument to `tf.train.slice_input_producer` everything works as expected (net converge etc) so I don't there is something wrong with the rest of the code.

```
E tensorflow/core/client/tensor_c_api.cc:485] Attempting to use uninit[221/1918]
lue input_producer/input_producer/fraction_of_32_full/limit_epochs/epochs
         [[Node: input_producer/input_producer/fraction_of_32_full/limit_epochs/
CountUpTo = CountUpTo[T=DT_INT64, _class=[""loc:@input_producer/input_producer/fraction_of_32_full/limit_epochs/epochs""], limit=2, _device=""/job:localhost/replic
a:0/task:0/cpu:0""](input_producer/input_producer/fraction_of_32_full/limit_epochs/epochs)]]
ERROR:tensorflow:Exception in QueueRunner: Attempting to use uninitialized value
 input_producer/input_producer/fraction_of_32_full/limit_epochs/epochs
         [[Node: input_producer/input_producer/fraction_of_32_full/limit_epochs/CountUpTo = CountUpTo[T=DT_INT64, _class=[""loc:@input_producer/input_producer/fr
action_of_32_full/limit_epochs/epochs""], limit=2, _device=""/job:localhost/replic
a:0/task:0/cpu:0""](input_producer/input_producer/fraction_of_32_full/limit_epoch
s/epochs)]]
Caused by op u'input_producer/input_producer/fraction_of_32_full/limit_epochs/Co
untUpTo', defined at:
  File ""train.py"", line 94, in <module>
    tf.app.run()
  File ""/Users/kalle/Development/tensorflow_cbnet/.env/lib/python2.7/site-packag
es/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""train.py"", line 91, in main
    train()
  File ""train.py"", line 30, in train
    x, y = cbnet.load_data(""/Users/kalle/Development/nn_data/train"")
  File ""/Users/kalle/Development/tensorflow_cbnet/cbnet.py"", line 42, in load_data
    shuffle=True)
  File ""/Users/kalle/Development/tensorflow_cbnet/.env/lib/python2.7/site-packag
es/tensorflow/python/training/input.py"", line 266, in slice_input_producer
    shared_name=shared_name)
  File ""/Users/kalle/Development/tensorflow_cbnet/.env/lib/python2.7/site-packages/tensorflow/python/training/input.py"", line 223, in range_input_producer
    shared_name, name, ""fraction_of_%d_full"" % capacity)
  File ""/Users/kalle/Development/tensorflow_cbnet/.env/lib/python2.7/site-packag
es/tensorflow/python/training/input.py"", line 133, in input_producer
    input_tensor = limit_epochs(input_tensor, num_epochs)
  File ""/Users/kalle/Development/tensorflow_cbnet/.env/lib/python2.7/site-packages/tensorflow/python/training/input.py"", line 84, in limit_epochs
    counter = epochs.count_up_to(num_epochs)
  File ""/Users/kalle/Development/tensorflow_cbnet/.env/lib/python2.7/site-packag
es/tensorflow/python/ops/variables.py"", line 577, in count_up_to
    return state_ops.count_up_to(self._variable, limit=limit)
  File ""/Users/kalle/Development/tensorflow_cbnet/.env/lib/python2.7/site-packages/tensorflow/python/ops/gen_state_ops.py"", line 127, in count_up_to
    result = _op_def_lib.apply_op(""CountUpTo"", ref=ref, limit=limit, name=name)
  File ""/Users/kalle/Development/tensorflow_cbnet/.env/lib/python2.7/site-packag
es/tensorflow/python/framework/op_def_library.py"", line 703, in apply_op
    op_def=op_def)
  File ""/Users/kalle/Development/tensorflow_cbnet/.env/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2310, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/Users/kalle/Development/tensorflow_cbnet/.env/lib/python2.7/site-packag
es/tensorflow/python/framework/ops.py"", line 1232, in __init__
    self._traceback = _extract_stack()
```
"
3847,Java compilation in rule '//tensorflow/examples/android:tensorflow_demo' failed,"### Issue

`$ bazel build //tensorflow/examples/android:tensorflow_demo` fails with the following error:

```
ERROR: /home/milan/tools/tensorflow/tensorflow/tensorflow/examples/android/BUILD:47:1: Java compilation in rule '//tensorflow/examples/android:tensorflow_demo' failed: java failed: error executing command external/local_jdk/bin/java -Xbootclasspath/p:external/bazel_tools/third_party/java/jdk/langtools/javac.jar -XX:+TieredCompilation '-XX:TieredStopAtLevel=1' -jar ... (remaining 2 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
tensorflow/examples/android/src/org/tensorflow/demo/CameraActivity.java:50: error: method does not override or implement a method from a supertype

```

(Verbose output below)
### Environment info

Operating System: Ubuntu 14.04 LTS 64-bit

Installed version of CUDA and cuDNN: CUDA 7.5.18, CUDNN 5.0.5.  (Not essential for the issue)

TF installed from source, commit hash f646559f5d7f15f2403c472d1b031a3fbc981fa1

Bazel version 0.3.1 installed from repository.

Android settings in WORKSPACE:

```
android_sdk_repository(
    name = ""androidsdk"",
    api_level = 21,
    build_tools_version = ""24.0.0"",
    # Replace with path to Android SDK on your system
    path = ""/home/milan/tools/Android/Sdk/"",
)

android_ndk_repository(
    name=""androidndk"",
    path=""/home/milan/tools/Android/Sdk/ndk-bundle/"",
    api_level=21)
```
### Steps to reproduce
1. (Build TF from branch r0.10)
2. `bazel build //tensorflow/examples/android:tensorflow_demo --verbose_failures`
### What have you tried?
1. Originally, I had the same issue with Bazel 0.3.0. `bazel clean` and rebuilding didn't help.
2. `sudo apt-get upgrade bazel` to Bazel 0.3.1, `bazel clean` and rebuilding didn't help.
### Logs or other output that would be helpful

```
(tfsource) milan@stroj:~/tools/tensorflow/tensorflow$ bazel build //tensorflow/examples/android:tensorflow_demo --verbose_failures
WARNING: Bazel Android NDK crosstools are based on Android NDK revision 11. The revision of the Android NDK given in android_ndk_repository rule 'androidndk' is '12.1.2977051'.
WARNING: /home/milan/tools/tensorflow/tensorflow/tensorflow/core/BUILD:638:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/debug:debug_graph_utils.cc' directly. You should either move the file to this package or depend on an appropriate rule there.
 .. a number of similar warnings, skipping ..
WARNING: /home/milan/tools/tensorflow/tensorflow/tensorflow/core/BUILD:638:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_loss_util.h' directly. You should either move the file to this package or depend on an appropriate rule there.
INFO: Found 1 target...
ERROR: /home/milan/tools/tensorflow/tensorflow/tensorflow/examples/android/BUILD:47:1: Java compilation in rule '//tensorflow/examples/android:tensorflow_demo' failed: java failed: error executing command 
  (cd /home/milan/.cache/bazel/_bazel_milan/2849cb88d02d6f4c5e9ffcff64d240c6/execroot/tensorflow && \
  exec env - \
    LC_CTYPE=en_US.UTF-8 \
  external/local_jdk/bin/java -Xbootclasspath/p:external/bazel_tools/third_party/java/jdk/langtools/javac.jar -XX:+TieredCompilation '-XX:TieredStopAtLevel=1' -jar external/bazel_tools/tools/jdk/JavaBuilder_deploy.jar @bazel-out/local-fastbuild/bin/tensorflow/examples/android/libtensorflow_demo.jar-2.params): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
tensorflow/examples/android/src/org/tensorflow/demo/CameraActivity.java:50: error: method does not override or implement a method from a supertype
  @Override
  ^
tensorflow/examples/android/src/org/tensorflow/demo/CameraActivity.java:66: error: cannot find symbol
    if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.M) {
                                                    ^
  symbol:   variable M
  location: class VERSION_CODES
tensorflow/examples/android/src/org/tensorflow/demo/CameraActivity.java:67: error: cannot find symbol
      return checkSelfPermission(PERMISSION_CAMERA) == PackageManager.PERMISSION_GRANTED && checkSelfPermission(PERMISSION_STORAGE) == PackageManager.PERMISSION_GRANTED;
             ^
  symbol:   method checkSelfPermission(String)
  location: class CameraActivity
tensorflow/examples/android/src/org/tensorflow/demo/CameraActivity.java:67: error: cannot find symbol
      return checkSelfPermission(PERMISSION_CAMERA) == PackageManager.PERMISSION_GRANTED && checkSelfPermission(PERMISSION_STORAGE) == PackageManager.PERMISSION_GRANTED;
                                                                                            ^
  symbol:   method checkSelfPermission(String)
  location: class CameraActivity
tensorflow/examples/android/src/org/tensorflow/demo/CameraActivity.java:74: error: cannot find symbol
    if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.M) {
                                                    ^
  symbol:   variable M
  location: class VERSION_CODES
tensorflow/examples/android/src/org/tensorflow/demo/CameraActivity.java:75: error: cannot find symbol
      if (shouldShowRequestPermissionRationale(PERMISSION_CAMERA) || shouldShowRequestPermissionRationale(PERMISSION_STORAGE)) {
          ^
  symbol:   method shouldShowRequestPermissionRationale(String)
  location: class CameraActivity
tensorflow/examples/android/src/org/tensorflow/demo/CameraActivity.java:75: error: cannot find symbol
      if (shouldShowRequestPermissionRationale(PERMISSION_CAMERA) || shouldShowRequestPermissionRationale(PERMISSION_STORAGE)) {
                                                                     ^
  symbol:   method shouldShowRequestPermissionRationale(String)
  location: class CameraActivity
tensorflow/examples/android/src/org/tensorflow/demo/CameraActivity.java:78: error: cannot find symbol
      requestPermissions(new String[] {PERMISSION_CAMERA, PERMISSION_STORAGE}, PERMISSIONS_REQUEST);
      ^
  symbol:   method requestPermissions(String[],int)
  location: class CameraActivity
8 errors
Target //tensorflow/examples/android:tensorflow_demo failed to build
INFO: Elapsed time: 3.327s, Critical Path: 2.99s
```
"
3846, 'module' object has no attribute 'sparse_column_with_keys',"i try to run the example  came with the linear model tutorial but i get the error below
 attributeerror :  'module' object has no attribute 'sparse_column_with_keys' in the
gender = tf.contrib.layers.sparse_column_with_keys(column_name=""gender"", keys=[""female"",""male""])

my environmenent : i run tensorflow with docker on Windows 10

output when running:

Traceback (most recent call last):
  File ""tensor3.py"", line 54, in <module>
    gender = tf.contrib.layers.sparse_column_with_keys(column_name=""gender"", keys=[""female"", ""male""])
AttributeError: 'module' object has no attribute 'sparse_column_with_keys'
"
3845,"Build fails Tensorflow 0.9, with cuda 8.0 on Ubuntu 16.04, ppc64le","Tensorflow 0.9, with cuda 8.0 fails to build on Ubuntu 16.04 linux ppc64le. Without cuda, it does build successfully. Is this NVIDIA driver issue? Or some eigen issue. Kindly help.

The error I get is as below -
external/eigen_archive/eigen-eigen-d02e6a705c30/unsupported/Eigen/CXX11/src/Tensor/TensorBroadcasting.h(192): internal error: assertion failed at: ""/dvs/p4/build/sw/rel/gpu_drv/r361/r361_00/drivers/compiler/edg/EDG_4.10/src/folding.c"", line 9819

1 catastrophic error detected in the compilation of ""/tmp/tmpxft_00020696_00000000-9_cwise_op_gpu_select.cu.compute_52.cpp1.ii"".
Compilation aborted.
Aborted
ERROR: /home/nishidha/pkgbuild/tensorflow/tensorflow/tensorflow/core/kernels/BUILD:973:1: output 'tensorflow/core/kernels/_objs/cwise_op_gpu/tensorflow/core/kernels/cwise_op_gpu_select.cu.pic.o' was not created.
ERROR: /home/nishidha/pkgbuild/tensorflow/tensorflow/tensorflow/core/kernels/BUILD:973:1: not all outputs were created.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
### Environment info

Operating System: Ubuntu 16.04, ppc64le
NVIDIA Driver: 361.78

Installed version of CUDA and cuDNN: Cuda 8.0 with cudnn 5.1
$ ls -s /usr/local/cuda/lib64
total 1239696
 48080 libcublas_device.a        0 libcufftw.so.8.0            0 libnppc.so.8.0         20320 libnppig.so.8.0.35    10864 libnpps_static.a
     0 libcublas.so            556 libcufftw.so.8.0.35       536 libnppc.so.8.0.35          0 libnppim.so               0 libnvblas.so
     0 libcublas.so.8.0         48 libcufftw_static.a         28 libnppc_static.a           0 libnppim.so.8.0           0 libnvblas.so.8.0
 37884 libcublas.so.8.0.35       0 libcuinj64.so               0 libnppial.so            4296 libnppim.so.8.0.35      584 libnvblas.so.8.0.35
 43936 libcublas_static.a        0 libcuinj64.so.8.0           0 libnppial.so.8.0           0 libnppi.so                0 libnvgraph.so
   552 libcudadevrt.a         5572 libcuinj64.so.8.0.35     9684 libnppial.so.8.0.35        0 libnppi.so.8.0            0 libnvgraph.so.8.0
     0 libcudart.so             36 libculibos.a                0 libnppicc.so          105316 libnppi.so.8.0.35      4568 libnvgraph.so.8.0.35
     0 libcudart.so.8.0          0 libcurand.so                0 libnppicc.so.8.0      131588 libnppi_static.a       6824 libnvgraph_static.a
   464 libcudart.so.8.0.35       0 libcurand.so.8.0         3864 libnppicc.so.8.0.35        0 libnppist.so              0 libnvrtc-builtins.so
   936 libcudart_static.a    57768 libcurand.so.8.0.35         0 libnppicom.so              0 libnppist.so.8.0          0 libnvrtc-builtins.so.8.0
     4 libcudnn5.0.5         57820 libcurand_static.a          0 libnppicom.so.8.0      13860 libnppist.so.8.0.35    9400 libnvrtc-builtins.so.8.0.35
     0 libcudnn.so               0 libcusolver.so           1104 libnppicom.so.8.0.35       0 libnppisu.so              0 libnvrtc.so
     0 libcudnn.so.5             0 libcusolver.so.8.0          0 libnppidei.so              0 libnppisu.so.8.0          0 libnvrtc.so.8.0
 76296 libcudnn.so.5.0.5     50916 libcusolver.so.8.0.35       0 libnppidei.so.8.0        528 libnppisu.so.8.0.35   19380 libnvrtc.so.8.0.34
 67748 libcudnn_static.a     21528 libcusolver_static.a     6912 libnppidei.so.8.0.35       0 libnppitc.so              0 libnvToolsExt.so
     0 libcufft.so               0 libcusparse.so              0 libnppif.so                0 libnppitc.so.8.0          0 libnvToolsExt.so.1
     0 libcufft.so.8.0           0 libcusparse.so.8.0          0 libnppif.so.8.0         2916 libnppitc.so.8.0.35      44 libnvToolsExt.so.1.0.0
143232 libcufft.so.8.0.35    42080 libcusparse.so.8.0.35   46544 libnppif.so.8.0.35         0 libnpps.so                4 stubs
126244 libcufft_static.a     50268 libcusparse_static.a        0 libnppig.so                0 libnpps.so.8.0
     0 libcufftw.so              0 libnppc.so                  0 libnppig.so.8.0         8564 libnpps.so.8.0.35

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`) - v0.9.0 (and cherry-pick two commits - 2c3385523f00ea7de97ec16a7c060b39b834a7f5 and ea9e00a630f91a459dd5858cb22e8cd1a666ba4e)
2. The output of `bazel version` - 0.2.0
### Steps to reproduce
1. ./configure - Enable GPU support, Cloud Platform support, and rest all with default
2. bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
### What have you tried?
1. Building without GPU support works.
"
3844,Missing documentation: Distribution Dashboard,"The new _Distributions Dashboard_ lacks written documentation:

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tensorboard/README.md
"
3843,Can't invoke TF_NewSession with C API of tensorflow.,"Operating System:Ubuntu 16.04 LTS
Steps to reproduce
1.bazel build  -c opt //tensorflow/c:c_api

2.gcc -g c_api_test.cc -I. -L. ./libc_api.a ./libcore_cpu_internal.lo ./libframework_internal.lo ./libproto_text.a ./liblib_internal.a ./libprotos_all_cc.a ./libprotobuf.a ./liblib_proto_parsing.a ./libprotobuf_lite.a   ./libarray_grad.lo ./libarray_ops_op_lib.lo ./libcandidate_sampling_ops_op_lib.lo ./libcontrol_flow_ops_op_lib.lo  ./libctc_ops_op_lib.lo ./libdata_flow_ops_op_lib.lo ./libdirect_session_internal.lo ./libexample_parser_configuration.lo  ./libfunctional_grad.lo ./libfunctional_ops_op_lib.lo ./libfunction_ops_op_lib.lo ./libgpu_runtime.lo ./libimage_ops_op_lib.lo ./libio_ops_op_lib.lo ./liblinalg_ops_op_lib.lo ./liblogging_ops_op_lib.lo ./libmath_grad.lo ./libmath_ops_op_lib.lo ./libnn_grad.lo ./libnn_ops_op_lib.lo ./libno_op_op_lib.lo ./libparsing_ops_op_lib.lo ./librandom_ops_op_lib.lo ./libsendrecv_ops_op_lib.lo ./libsparse_ops_op_lib.lo ./libstate_ops_op_lib.lo ./libstring_ops_op_lib.lo ./libtraining_ops_op_lib.lo ./libuser_ops_op_lib.lo  -lstdc++ -lpthread -lm -lz -ldl -lgcc_s -lc
the static library 'lo' and 'a' above within the directory 'bazel-bin'

c_api_test.cc src:
# include ""./c_api.h""
# include<stdio.h>
# include<string.h>

int main(int argc, char _argv[]){
  printf(""---- -------start"");
  TF_Status_ s = TF_NewStatus();
  TF_SessionOptions\* opt = TF_NewSessionOptions();
  TF_Session\* session = TF_NewSession(opt, s);
  TF_DeleteSessionOptions(opt);
  TF_CloseSession(session,s);
  TF_DeleteStatus(s);

  printf(""---- -------end"");
  return 1;
}

but always get the wrong messages as below:
E tensorflow/core/common_runtime/session.cc:69] Not found: No session factory registered for the given session options: {target: """" config: } Registered factories are {}.
"
3842,can't deal with nii data using tensorflow ,"Hi all：
    I'd like to use tensorflow to resize nii data(This kind of data is using in medical for example ct fmri and so on).Any information is appreciate .
"
3841,This rule is missing dependency declarations error on build.,"I am using Ubuntu 16.04 with Cuda 8.0.  I am building for pyhon3.5 with a GTX 1080 GPU.  I get the following error.

```
ERROR: /home/chase/Desktop/tensorflow-master/tensorflow/core/kernels/BUILD:1529:1: undeclared inclusion(s) in rule '//tensorflow/core/kernels:depth_space_ops_gpu':
this rule is missing dependency declarations for the following files included by 'tensorflow/core/kernels/spacetodepth_op_gpu.cu.cc':
  '/usr/local/cuda-8.0/include/cuda_runtime.h'
  '/usr/local/cuda-8.0/include/host_config.h'
  '/usr/local/cuda-8.0/include/builtin_types.h'
  '/usr/local/cuda-8.0/include/device_types.h'
  '/usr/local/cuda-8.0/include/host_defines.h'
  '/usr/local/cuda-8.0/include/driver_types.h'
  '/usr/local/cuda-8.0/include/surface_types.h'
  '/usr/local/cuda-8.0/include/texture_types.h'
  '/usr/local/cuda-8.0/include/vector_types.h'
  '/usr/local/cuda-8.0/include/library_types.h'
  '/usr/local/cuda-8.0/include/channel_descriptor.h'
  '/usr/local/cuda-8.0/include/cuda_runtime_api.h'
  '/usr/local/cuda-8.0/include/cuda_device_runtime_api.h'
  '/usr/local/cuda-8.0/include/driver_functions.h'
  '/usr/local/cuda-8.0/include/vector_functions.h'
  '/usr/local/cuda-8.0/include/vector_functions.hpp'
  '/usr/local/cuda-8.0/include/common_functions.h'
  '/usr/local/cuda-8.0/include/math_functions.h'
  '/usr/local/cuda-8.0/include/math_functions.hpp'
  '/usr/local/cuda-8.0/include/math_functions_dbl_ptx3.h'
  '/usr/local/cuda-8.0/include/math_functions_dbl_ptx3.hpp'
  '/usr/local/cuda-8.0/include/cuda_surface_types.h'
  '/usr/local/cuda-8.0/include/cuda_texture_types.h'
  '/usr/local/cuda-8.0/include/device_functions.h'
  '/usr/local/cuda-8.0/include/device_functions.hpp'
  '/usr/local/cuda-8.0/include/device_atomic_functions.h'
  '/usr/local/cuda-8.0/include/device_atomic_functions.hpp'
  '/usr/local/cuda-8.0/include/device_double_functions.h'
  '/usr/local/cuda-8.0/include/device_double_functions.hpp'
  '/usr/local/cuda-8.0/include/sm_20_atomic_functions.h'
  '/usr/local/cuda-8.0/include/sm_20_atomic_functions.hpp'
  '/usr/local/cuda-8.0/include/sm_32_atomic_functions.h'
  '/usr/local/cuda-8.0/include/sm_32_atomic_functions.hpp'
  '/usr/local/cuda-8.0/include/sm_35_atomic_functions.h'
  '/usr/local/cuda-8.0/include/sm_60_atomic_functions.h'
  '/usr/local/cuda-8.0/include/sm_60_atomic_functions.hpp'
  '/usr/local/cuda-8.0/include/sm_20_intrinsics.h'
  '/usr/local/cuda-8.0/include/sm_20_intrinsics.hpp'
  '/usr/local/cuda-8.0/include/sm_30_intrinsics.h'
  '/usr/local/cuda-8.0/include/sm_30_intrinsics.hpp'
  '/usr/local/cuda-8.0/include/sm_32_intrinsics.h'
  '/usr/local/cuda-8.0/include/sm_32_intrinsics.hpp'
  '/usr/local/cuda-8.0/include/sm_35_intrinsics.h'
  '/usr/local/cuda-8.0/include/surface_functions.h'
  '/usr/local/cuda-8.0/include/texture_fetch_functions.h'
  '/usr/local/cuda-8.0/include/texture_indirect_functions.h'
  '/usr/local/cuda-8.0/include/surface_indirect_functions.h'
  '/usr/local/cuda-8.0/include/device_launch_parameters.h'
  '/usr/local/cuda-8.0/include/cuda_fp16.h'
  '/usr/local/cuda-8.0/include/math_constants.h'
  '/usr/local/cuda-8.0/include/curand_kernel.h'
  '/usr/local/cuda-8.0/include/curand.h'
  '/usr/local/cuda-8.0/include/curand_discrete.h'
  '/usr/local/cuda-8.0/include/curand_precalc.h'
  '/usr/local/cuda-8.0/include/curand_mrg32k3a.h'
  '/usr/local/cuda-8.0/include/curand_mtgp32_kernel.h'
  '/usr/local/cuda-8.0/include/cuda.h'
  '/usr/local/cuda-8.0/include/curand_mtgp32.h'
  '/usr/local/cuda-8.0/include/curand_philox4x32_x.h'
  '/usr/local/cuda-8.0/include/curand_globals.h'
  '/usr/local/cuda-8.0/include/curand_uniform.h'
  '/usr/local/cuda-8.0/include/curand_normal.h'
  '/usr/local/cuda-8.0/include/curand_normal_static.h'
  '/usr/local/cuda-8.0/include/curand_lognormal.h'
  '/usr/local/cuda-8.0/include/curand_poisson.h'
  '/usr/local/cuda-8.0/include/curand_discrete2.h'.
nvcc warning : option '--relaxed-constexpr' has been deprecated and replaced by option '--expt-relaxed-constexpr'.
nvcc warning : option '--relaxed-constexpr' has been deprecated and replaced by option '--expt-relaxed-constexpr'.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 243.911s, Critical Path: 154.80s
```
"
3840,missing return statement at end of non-void function,"Since TensorFlow uses C++11 I think it would be good style to fix the errors such as:

```
framework/allocator.h(155): warning: missing return statement at end of non-void function ""tensorflow::Allocator::RequestedSize""
```

The code is not harmful in this instance but the compiler would have to parse and trust comments:

``` cpp
// CHECK dies with a fatal error if condition is not true.  It is *not*
// controlled by NDEBUG, so the check will be executed regardless of
// compilation mode.
```

A simple patch for the problem would be:

``` cpp
  virtual size_t RequestedSize(void* ptr) {
    CHECK(false) << ""allocator doesn't track sizes"";
  }
```

-->

``` cpp
  virtual size_t RequestedSize  [[ noreturn ]] (void* ptr) {
    CHECK(false) << ""allocator doesn't track sizes"";
  }
```

Reference: http://www.stroustrup.com/C++11FAQ.html#attributes
"
3839,"TensorFlow works with python, Jupyter notebook, but not iPython","Operating System: OS X EL Capitan 10.11.5

I installed TensorFlow with Anaconda following https://www.tensorflow.org/versions/r0.10/get_started/index.html

Specifically, I created a `tensorflow` environment, and used `pip` to install the one with **GPU support**.

After activating the environment, I am able to use TensowFlow in `python` and `jupyter notebook` (actually, I have to _turn off the hard ware acceleration of the Chrome browser_ to run TensorFlow correctly), but not in `ipython`:

`which ipython`
~/anaconda/envs/tensorflow/bin/ipython

`ipython --version`
5.1.0

`ipython -c ""import tensorflow; print(tensorflow.__version__)""`
...
ImportError: dlopen(~/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so, 10): Library not loaded: @rpath/libcudart.7.5.dylib
  Referenced from: ~/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
  Reason: image not found

`ls -l /Developer/NVIDIA/CUDA-7.5/lib/libcud*`

-rw-r--r-- 1 root wheel 563K Apr 13 02:02 ""/Developer/NVIDIA/CUDA-7.5/lib/libcudart_static.a""
lrwxr-xr-x 1 root wheel   19 Apr 13 02:02 ""/Developer/NVIDIA/CUDA-7.5/lib/libcudart.dylib"" -> ""libcudart.7.5.dylib""
-rwxr-xr-x 1 root wheel 272K Apr 13 02:02 ""/Developer/NVIDIA/CUDA-7.5/lib/libcudart.7.5.dylib""
-rw-r--r-- 1 root wheel 299K Apr 13 02:02 ""/Developer/NVIDIA/CUDA-7.5/lib/libcudadevrt.a""

`ls -l /usr/local/cuda/lib/`
total 165M
-rwxr-xr-x 1 root wheel 8.1K Apr 13 02:02 ""libcuda.dylib""
lrwxr-xr-x 1 root wheel   36 Apr 13 02:03 ""stubs"" -> ""/Developer/NVIDIA/CUDA-7.5/lib/stubs""
...
-rw-r--r-- 1 root wheel  53M Aug 15 21:17 ""libcudnn_static.a""
-rwxr-xr-x 1 root wheel  56M Aug 15 21:17 ""libcudnn.dylib""
-rwxr-xr-x 1 root wheel  56M Aug 15 21:17 ""libcudnn.5.dylib""
lrwxr-xr-x 1 root wheel   13 Aug 15 21:29 ""libcuda.1.dylib"" -> ""libcuda.dylib""

`which python`
~/anaconda/envs/tensorflow/bin/python

`python -c ""import tensorflow; print(tensorflow.__version__)""`

I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.dylib locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.dylib locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.dylib locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.1.dylib locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.dylib locally
0.10.0rc0
"
3838,Tensorflow: cannot install custom user_op for roi_pooling,"I experimented with a user-op for ROI_pooling in this fork: https://github.com/yuxng/tensorflow/, 

I tried several ways to make it work:

Attempt 1:

1) uninstalled tensorflow
2) placed the roi_pooling files (roi_pooling_op.cc, roi_pooling_op_gpu.cu.cc, roi_pooling_op_gpu.h, roi_pooling_op_grad.py, roi_pooling_op_test.py) in //tensorflow/core/user_ops/ (without BUILD so that they get incorporated with the install)
3) reinstalled tensorflow using bazel with bazel build -c opt --config=cuda ...

I then get this error with attempt 1: 

ERROR: /home/fishdrop/tensorflow/tensorflow/cc/BUILD:116:1: Linking of rule '//tensorflow/cc:ops/user_ops_gen_cc' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -o bazel-out/host/bin/tensorflow/cc/ops/user_ops_gen_cc ... (remaining 41 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
bazel-out/host/bin/tensorflow/core/libuser_ops_op_lib.lo(roi_pooling_op.o): In function `RoiPoolGradOp<Eigen::GpuDevice, float>::Compute(tensorflow::OpKernelContext*)':
roi_pooling_op.cc:(.text._ZN13RoiPoolGradOpIN5Eigen9GpuDeviceEfE7ComputeEPN10tensorflow15OpKernelContextE[_ZN13RoiPoolGradOpIN5Eigen9GpuDeviceEfE7ComputeEPN10tensorflow15OpKernelContextE]+0x3ea): undefined reference to`ROIPoolBackwardLaucher(float const_, float, int, int, int, int, int, int, int, float const_, float_, int const_, Eigen::GpuDevice const&)'
bazel-out/host/bin/tensorflow/core/libuser_ops_op_lib.lo(roi_pooling_op.o): In function `RoiPoolOp<Eigen::GpuDevice, float>::Compute(tensorflow::OpKernelContext*)':
roi_pooling_op.cc:(.text._ZN9RoiPoolOpIN5Eigen9GpuDeviceEfE7ComputeEPN10tensorflow15OpKernelContextE[_ZN9RoiPoolOpIN5Eigen9GpuDeviceEfE7ComputeEPN10tensorflow15OpKernelContextE]+0x392): undefined reference to`ROIPoolForwardLaucher(float const_, float, int, int, int, int, int, int, float const_, float_, int_, Eigen::GpuDevice const&)'
collect2: error: ld returned 1 exit status
Target //tensorflow/cc:tutorials_example_trainer failed to build
Use --verbose_failures to see the command lines of failed build steps.
ERROR: /home/fishdrop/tensorflow/tensorflow/cc/BUILD:116:1 Linking of rule '//tensorflow/cc:ops/user_ops_gen_cc' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -o bazel-out/host/bin/tensorflow/cc/ops/user_ops_gen_cc ... (remaining 41 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.

Attempt 2:

1) re-install tensorflow
2) place files (with BUILD) in //tensorflow/core/user_ops/
3) use bazel build -c opt //tensorflow/core/user_ops:roi_pooling.so

This successfully built roi_pooling.so, but when I tried to load the module with tf.load_op_library, I get this error: 

tensorflow.python.framework.errors.NotFoundError: /home/fishdrop/tensorflow/bazel-bin/tensorflow/core/user_ops/roi_pooling.so: undefined symbol: _Z21ROIPoolForwardLaucherPKffiiiiiiS0_PfPiRKN5Eigen9GpuDeviceE

The error seems to be related with Eigen, but I read in this Link: http://stackoverflow.com/questions/38618960/tensorflow-how-to-insert-custom-input-to-existing-graph, that the user_op is supposed to work.. 

I am using Ubuntu 14.04 LTS, and I tried these procedures in both Tensorflow 0.10 and Tensorflow 0.08, and got the same errors.. Anyone who could help?
"
3835,Some types of fetches in tf.Session.run are not supported and it behaves strange in container,"There're two issues I have found when giving different type of fetches in `tf.Session.run()`.

The [doc](https://www.tensorflow.org/versions/master/api_docs/python/client.html) says that we can pass the nested list or tuple to `run()` but it doesn't work.

```
tf.Session.run(fetches, feed_dict=None, options=None, run_metadata=None)

Runs operations and evaluates tensors in fetches.

This method runs one ""step"" of TensorFlow computation, by running the necessary graph fragment to execute every Operation and evaluate every Tensor in fetches, substituting the values in feed_dict for the corresponding input values.

The fetches argument may be a single graph element, or an arbitrarily nested list, tuple, namedtuple, or dict containing graph elements at its leaves. A graph element can be one of the following types:
```

It's easy to test with this script.

```
import tensorflow as tf

a = tf.placeholder(""float"")
b = tf.placeholder(""float"")
add_op = tf.add(a, b)
mul_op = tf.mul(a, b)

output_array = [[add_op, mul_op]]

with tf.Session() as sess:
    output_array = sess.run(output_array, feed_dict={a: 1, b: 2})
    print(output_array)
```

And I found it works if I pass the `array` or `dict`. But what's strange is that the `dict` doesn't work in docker container which is also easy to reproduce by creating the tensorflow container to run the same script. You can find my test code and error log below.

![screen shot 2016-08-16 at 11 52 31](https://cloud.githubusercontent.com/assets/2715000/17687714/3e4a83a8-63aa-11e6-98be-e20a7099f77b.png)
### Environment info

Operating System: Ubuntu 16.04

If installed from binary pip package, provide:
TensorFlow 0.8
"
3834,cannot connect to https://www.tensorflow.org/,"hi, i cannot connect to the home site of tensorflow for long. Can you fix this? My location is China, i can visit Google , tweet,facebook and so on,but no access to tensorflow ,Neither   can my friends do.
"
3833,/home/myubuntu/tensorflow/tensorflow/examples/android/BUILD:47:1: Processing Android resources for //tensorflow/examples/android:tensorflow_demo failed: linux-sandbox failed: error executing command ,"ubuntu 14.04 
bazel build give the error:
/home/myubuntu/tensorflow/tensorflow/examples/android/BUILD:47:1: Processing Android resources for //tensorflow/examples/android:tensorflow_demo failed: linux-sandbox failed: error executing command 
"
3829,Tensorboard not showing any curves,"No curves appear in Tensorboard 25 when I click on a heading to open one.
Maybe related to #3782
### Environment info

Operating System: Ubuntu 14.04

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`): 008bcaea38815f46804fc3f56492f4dd93837a56
2. The output of `bazel version` 0.3.0
"
3828,Estimator raises spurious error with dynamic_rnn model,"I'm trying to train an RNN and I'm playing with the dynamic_rnn model inside an skflow Estimator and trying to traing it sequences of increasing length.

So I end up passing in data of the form [batch_size, seq_length, seq_entry_size]

Where seq_length varies, but is constant each time I call partial_fit.

I am constructing my dynamic_rnn model like so:

```
def rnn_model2(x, y):
  cell = tf.nn.rnn_cell.GRUCell(250)

  _, encoding = tf.nn.dynamic_rnn(cell, x, dtype=tf.float32)

  target = tf.one_hot(y, 2, 1, 0)

  prediction, loss = learn.models.logistic_regression(encoding, target)

  # Create a training op.
  train_op = tf.contrib.layers.optimize_loss(
      loss, tf.contrib.framework.get_global_step(),
      optimizer='Adam', learning_rate=0.01)

  return {'class': tf.argmax(prediction, 1), 'prob': prediction}, loss, train_op

classifier = learn.Estimator(model_fn=rnn_model2)
```
### Environment info

Operating System:
Ubuntu on Windows 10

If installed from binary pip package, provide:
0.10.rc0
### Steps to reproduce
1. Create an Estimator with a model_fn that uses a dynamic_rnn
2. Pass variable length data through partial_fit
3. Error
### What have you tried?
1. I commented out the checks in estimator.py and things work
### Logs or other output that would be helpful

WARNING:tensorflow:Given features: Tensor(""input:0"", shape=(?, 2, 3), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(1), Dimension(3)]), is_sparse=False).
Traceback (most recent call last):
  File ""mouse.py"", line 136, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""mouse.py"", line 126, in main
    classifier.partial_fit(x_train, y_train, steps=3)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 262, in partial_fit
    batch_size=batch_size, monitors=monitors)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 219, in fit
    max_steps=max_steps)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 478, in _train_model
    self._check_inputs(features, targets)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 427, in _check_inputs
    (str(features), str(self._features_info)))
ValueError: Features are incompatible with given information. Given features: Tensor(""input:0"", shape=(?, 2, 3), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(1), Dimension(3)]), is_sparse=False).
"
3826,GPU-enabled Mac build of TensorFlow version 0.10.0rc0-py2 was compiled against cuDNN v5,"### Environment info

Operating System: OS X 'El Capitan' Version 10.11.6 (15G31)

Installed version of CUDA and cuDNN: cuda_7.5.27_mac, cudnn-7.5-osx-x64-v5.0-ga (I explain why I am using cuDNN v5 rather than cuDNN v4 below.)
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

<pre>
lrwxr-xr-x@ 1 root  wheel    50 Apr 13 02:03 libcublas.7.5.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcublas.7.5.dylib
lrwxr-xr-x@ 1 root  wheel    46 Apr 13 02:03 libcublas.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcublas.dylib
lrwxr-xr-x@ 1 root  wheel    49 Apr 13 02:03 libcublas_device.a -> /Developer/NVIDIA/CUDA-7.5/lib/libcublas_device.a
lrwxr-xr-x@ 1 root  wheel    49 Apr 13 02:03 libcublas_static.a -> /Developer/NVIDIA/CUDA-7.5/lib/libcublas_static.a
-rwxr-xr-x  2 root  wheel  8280 May 11 04:59 libcuda.1.dylib
-rwxr-xr-x  2 root  wheel  8280 May 11 04:59 libcuda.dylib
lrwxr-xr-x@ 1 root  wheel    45 Apr 13 02:03 libcudadevrt.a -> /Developer/NVIDIA/CUDA-7.5/lib/libcudadevrt.a
lrwxr-xr-x@ 1 root  wheel    50 Apr 13 02:03 libcudart.7.5.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart.7.5.dylib
lrwxr-xr-x@ 1 root  wheel    46 Apr 13 02:03 libcudart.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart.dylib
lrwxr-xr-x@ 1 root  wheel    49 Apr 13 02:03 libcudart_static.a -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart_static.a
lrwxr-xr-x  1 root  admin    47 Aug 15 14:24 libcudnn.5.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudnn.5.dylib
lrwxr-xr-x  1 root  admin    45 Aug 15 14:24 libcudnn.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudnn.dylib
lrwxr-xr-x  1 root  admin    48 Aug 15 14:24 libcudnn_static.a -> /Developer/NVIDIA/CUDA-7.5/lib/libcudnn_static.a
</pre>


`libcuda.1.dylib` is a hard link to `libcuda.dylib` per [this comment](https://github.com/tensorflow/tensorflow/issues/2940#issuecomment-238952433).

If installed from binary pip package, provide:
1. Which pip package you installed: `export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/gpu/tensorflow-0.10.0rc0-py2-none-any.whl`
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`: 0.10.0rc0

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`
### Steps to reproduce
1. Set up TensorFlow according to the instructions at https://www.tensorflow.org/versions/r0.10/get_started/os_setup.html#prepare_environment_for_mac_os_x
   
   In particular, the page says to install cuDNN v4, which is labeled ""cuDNN v4 (Feb 10, 2016), for CUDA 7.0 and later."" on the [cuDNN Download page](https://developer.nvidia.com/rdp/cudnn-download).
2. Test the installation by running:
   
   `python -m tensorflow.models.image.mnist.convolutional`
   
   You should see:
   
   > E tensorflow/stream_executor/cuda/cuda_dnn.cc:354] could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR  
   > E tensorflow/stream_executor/cuda/cuda_dnn.cc:321] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM
3. Now run the test under `cuda-memcheck`:
   
   `cuda-memcheck python -m tensorflow.models.image.mnist.convolutional`
   
   You should see:
   
   > E tensorflow/stream_executor/cuda/cuda_dnn.cc:347] Loaded runtime CuDNN library: 4007 (compatibility version 4000) but source was compiled with 5005 (compatibility version 5000).  If using a binary install, upgrade your CuDNN library to match.  If building from sources, make sure the library loaded at runtime matches a compatible version specified during compile configuration.
### What have you tried?

Uninstalling cuDNN v4 and installing cuDNN v5 (labeled ""cuDNN v5 (May 12, 2016), for CUDA 7.5"" on the cuDNN Download page) fixes the issue.

I think that either TensorFlow should be built with cuDNN v4 or the installation instructions should be corrected to specify that cuDNN v5 should be installed.
"
3825,A bug with a default initialiser and tf.nn.rnn_cell.LSTMCell/tf.contrib.rnn.LSTMFusedCell,"### Environment info

Operating System:
Mac OS X 10.9.5 

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
No CUDA

If installed from binary pip package, provide:
pip install http://ci.tensorflow.org/view/Nightly/job/nightly-matrix-cpu/TF_BUILD_CONTAINER_TYPE=CPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=mac1-slave/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow-0.10.0rc0-py2-none-any.whl
1. Which pip package you installed.
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   0.10.0rc0
### Steps to reproduce
1. A minimum example to reproduce the bug:

```
import numpy as np
import tensorflow as tf

with tf.variable_scope(""rnn"", initializer=tf.contrib.layers.xavier_initializer()):
    out_cell = tf.nn.rnn_cell.LSTMCell(num_units=100, state_is_tuple=True, use_peepholes=True)
    #out_cell = tf.contrib.rnn.LSTMFusedCell(num_units=100)
    input_var = tf.placeholder(dtype=tf.float32, shape=(32, 50, 100))

    d, _ = tf.nn.dynamic_rnn(out_cell, input_var, dtype=tf.float32, parallel_iterations=32,
                                 scope=""output_rnn"")
    init = tf.initialize_all_variables()
    with tf.Session() as sess:
        input = np.random.uniform(-1.0, 1.0, [32, 50, 100])
        sess.run(init)
        o = sess.run([d], {input_var: input})

```
1. The same bug if you comment LSTMCell and uncomment LSTMFusedCell which was renamed to LSTMBlockCell recently
2. If I remove "", initializer=tf.contrib.layers.xavier_initializer()"" in tf.variable_scope code will work without errrors with normal distribution by default. Or if I remove use_peepholes=True in LSTMCell the bug will disappear too.
### What have you tried?

1.
### Logs or other output that would be helpful

Traceback (most recent call last):
....
  File ""/Users/vostryakov/projects/senses/env/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py"", line 848, in dynamic_rnn
    dtype=dtype)
  File ""/Users/vostryakov/projects/senses/env/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py"", line 1015, in _dynamic_rnn_loop
    swap_memory=swap_memory)
  File ""/Users/vostryakov/projects/senses/env/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 1992, in while_loop
    result = context.BuildLoop(cond, body, loop_vars)
  File ""/Users/vostryakov/projects/senses/env/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 1877, in BuildLoop
    pred, body, original_loop_vars, loop_vars)
  File ""/Users/vostryakov/projects/senses/env/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 1827, in _BuildLoop
    body_result = body(*packed_vars_for_body)
  File ""/Users/vostryakov/projects/senses/env/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py"", line 1000, in _time_step
    (output, new_state) = call_cell()
  File ""/Users/vostryakov/projects/senses/env/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py"", line 986, in <lambda>
    call_cell = lambda: cell(input_t, state)
  File ""/Users/vostryakov/projects/senses/env/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/lstm_ops.py"", line 443, in __call__
    wci = vs.get_variable(""wci"", [self._num_units])
  File ""/Users/vostryakov/projects/senses/env/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 830, in get_variable
    custom_getter=custom_getter)
  File ""/Users/vostryakov/projects/senses/env/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 673, in get_variable
    custom_getter=custom_getter)
  File ""/Users/vostryakov/projects/senses/env/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 217, in get_variable
    validate_shape=validate_shape)
  File ""/Users/vostryakov/projects/senses/env/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 202, in _true_getter
    caching_device=caching_device, validate_shape=validate_shape)
  File ""/Users/vostryakov/projects/senses/env/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 536, in _get_single_variable
    validate_shape=validate_shape)
  File ""/Users/vostryakov/projects/senses/env/lib/python2.7/site-packages/tensorflow/python/ops/variables.py"", line 211, in __init__
    dtype=dtype)
  File ""/Users/vostryakov/projects/senses/env/lib/python2.7/site-packages/tensorflow/python/ops/variables.py"", line 281, in _init_from_args
    self._initial_value = ops.convert_to_tensor(initial_value(),
  File ""/Users/vostryakov/projects/senses/env/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 526, in <lambda>
    init_val = lambda: initializer(shape.as_list(), dtype=dtype)
  File ""/Users/vostryakov/projects/senses/env/lib/python2.7/site-packages/tensorflow/contrib/layers/python/layers/initializers.py"", line 114, in _initializer
    fan_in = float(shape[-2])
IndexError: list index out of range
Exception TypeError: TypeError(""'NoneType' object is not callable"",) in <function _remove at 0x10248b6e0> ignored
"
3824,Unclear documentation and behavior for sampler in Tensorflow,"For the samplers implemented in tensorflow, e.g. tf.nn.fixed_unigram_candidate_sampler. The behavior is not well-defined in the document. For instance, I would expect the labels specified in true_classes will be excluded from the sampling pool, and the sampling will be conducted for each batch. But according to my experiments, neither of above is true.

Consider the following code:

`import tensorflow as tf

labels_matrix = tf.reshape(tf.constant([1, 2, 3, 4], dtype=tf.int64), [-1, 1])

sampled_ids, _, _ = tf.nn.fixed_unigram_candidate_sampler(
    true_classes = labels_matrix,
    num_true = 1,
    num_sampled = 1,
    unique = True,
    range_max = 5,
    distortion = 0.0,
    unigrams = range(5)
)

init = tf.initialize_all_variables()
with tf.Session() as sess:
    sess.run(init)
    print sess.run([sampled_ids])
`

The output can be 3, which actually belongs to the set of true classes. - Also, the output has the dimension [1], which basically means that the sampling is only conducted once, not for each batch.

Can someone help to clarify this?
"
3821,Tensorflow Checkpoint and CKPT is not working and does not give any readable error.,"### Environment info

Operating System:

Mac OSX El Capitan

If installed from binary pip package, provide:
1. Which pip package you installed.

The latest version of Tensorflow
1. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

0.10.0rc0
### Steps to reproduce

I have trained a convolutional model through the main program and stored it into a checkpoint and ckpt file. The problem lies in the evaluation program. The ckpt file seems to not output anything but a bunch of errors. The program does not complete either.

The code for main is:

```
import Input
import Process

import time
import numpy as np

import tensorflow as tf
from datetime import datetime

FLAGS = tf.app.flags.FLAGS

def train():
    with tf.Session() as sess:
        images, labels = Process.inputs()

        forward_propgation_results = Process.forward_propagation(images)

        train_loss, cost = Process.error(forward_propgation_results, labels)

        image_summary_t = tf.image_summary(images.name, images, max_images = 2)

        summary_op = tf.merge_all_summaries()

        init = tf.initialize_all_variables()

        saver = tf.train.Saver()

        sess.run(init)

        saver = tf.train.Saver(tf.all_variables())

        tf.train.start_queue_runners(sess = sess)

        train_dir = ""/Users/Zanhuang/Desktop/NNP/model.ckpt""

        summary_writer = tf.train.SummaryWriter(train_dir, sess.graph)

        for step in range(100):
            start_time = time.time()
            print(sess.run([train_loss, cost]))
            duration = time.time() - start_time
            if step % 1 == 0:
                num_examples_per_step = FLAGS.batch_size
                examples_per_sec = num_examples_per_step / duration
                sec_per_batch = float(duration)

                format_str = ('%s: step %d, (%.1f examples/sec; %.3f ''sec/batch)')
                print (format_str % (datetime.now(), step, examples_per_sec, sec_per_batch))

                summary_str = sess.run(summary_op)
                summary_writer.add_summary(summary_str, step)

                if step % 2 == 0:
                    checkpoint_path = train_dir
                    saver.save(sess, checkpoint_path, global_step = step)


def main(argv = None):
    train()

if __name__ == '__main__':
  tf.app.run()
```

and the eval is 

```
import tensorflow as tf

import main
import Process
import Input

eval_dir = ""/Users/Zanhuang/Desktop/NNP/model.ckpt-98""
checkpoint_dir = ""/Users/Zanhuang/Desktop/NNP/checkpoint""


def evaluate():
  with tf.Graph().as_default() as g:
    images, labels = Process.eval_inputs()
    forward_propgation_results = Process.forward_propagation(images)
    init_op = tf.initialize_all_variables()
    saver = tf.train.Saver()
    top_k_op = tf.nn.in_top_k(forward_propgation_results, labels, 1)

  with tf.Session(graph = g) as sess:
    tf.train.start_queue_runners(sess = sess)
    sess.run(init_op)
    saver.restore(sess, eval_dir)
    for i in range(100):
        print(sess.run(top_k_op))

def main(argv = None):
    evaluate()

if __name__ == '__main__':
  tf.app.run()
```
### What have you tried?
1. I tried initializing the variables before running the queue's but that only removed the errors. The errors also do not point to any problem thats in the code.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).

The output is:

[error.txt](https://github.com/tensorflow/tensorflow/files/418658/error.txt)
"
3819,Chains of queues not working in 0.10.0 rc0,"### Environment info

Operating System: Ubuntu 14.04, Mac OS X

Installed version of CUDA and cuDNN: None

If installed from binary pip package, provide: 
CPU only, Python 2.7 packages for 0.9.0 and 0.10.0 rc0

I am working with a scheme in which I feed several batch queues into a `batch_join` to multiplex them.

The following code works in 0.9.0 (prints several batches before encountering `OutOfRange`, but fails in 0.10.0 rc0 (first run of `sess.run(c)` produces `OutOfRange`).

``` python
import tensorflow as tf
import numpy as np
import string

sess = tf.Session()

a = tf.train.batch([tf.train.input_producer(list(string.ascii_lowercase), shuffle=False, num_epochs=1).dequeue()], 10)
b = tf.train.batch([tf.train.input_producer(list(string.ascii_uppercase), shuffle=False, num_epochs=1).dequeue()], 10)

c = tf.squeeze(tf.train.batch_join([(a,), (b,)], 1, enqueue_many=False), [0])

sess.run(tf.initialize_all_variables())
coord = tf.train.Coordinator()
threads = tf.train.start_queue_runners(sess=sess, coord=coord)

for _ in range(20):
    print sess.run(c)
```
### Steps to reproduce
1. Run in 0.9.0
2. Run in 0.10rc1
### What have you tried?
1. Noticed this behaviour in Mac OS X
2. Double checked by creating two Docker images having TF 0.9.0 and 0.10.0 rc0 respectively installed on top of Ubuntu 14.04.
### Logs or other output that would be helpful

TensorFlow 0.9.0 output

```
['a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j']
['k' 'l' 'm' 'n' 'o' 'p' 'q' 'r' 's' 't']
['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J']
['K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R' 'S' 'T']
Traceback (most recent call last):
  File ""/Untitled11.py"", line 23, in <module>
    print sess.run(c)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 372, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 636, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 708, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 728, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.OutOfRangeError: PaddingFIFOQueue '_4_batch_join/padding_fifo_queue' is closed and has insufficient elements (requested 1, current size 0)
     [[Node: batch_join = QueueDequeueMany[_class=[""loc:@batch_join/padding_fifo_queue""], component_types=[DT_STRING], timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""](batch_join/padding_fifo_queue, batch_join/n)]]
Caused by op u'batch_join', defined at:
  File ""/Untitled11.py"", line 16, in <module>
    c = tf.squeeze(tf.train.batch_join([(a,), (b,)], 1, enqueue_many=False, dynamic_pad=True), [0])
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py"", line 682, in batch_join
    dequeued = queue.dequeue_many(batch_size, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/data_flow_ops.py"", line 434, in dequeue_many
    self._queue_ref, n=n, component_types=self._dtypes, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_data_flow_ops.py"", line 465, in _queue_dequeue_many
    timeout_ms=timeout_ms, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py"", line 704, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2260, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1230, in __init__
    self._traceback = _extract_stack()
```

TensorFlow 0.10.0 rc0 Output:

```
E tensorflow/core/client/tensor_c_api.cc:485] Attempting to use uninitialized value input_producer/limit_epochs/epochs
     [[Node: input_producer/limit_epochs/CountUpTo = CountUpTo[T=DT_INT64, _class=[""loc:@input_producer/limit_epochs/epochs""], limit=1, _device=""/job:localhost/replica:0/task:0/cpu:0""](input_producer/limit_epochs/epochs)]]
E tensorflow/core/client/tensor_c_api.cc:485] PaddingFIFOQueue '_4_batch_join/padding_fifo_queue' is closed and has insufficient elements (requested 1, current size 0)
     [[Node: batch_join = QueueDequeueMany[_class=[""loc:@batch_join/padding_fifo_queue""], component_types=[DT_STRING], timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""](batch_join/padding_fifo_queue, batch_join/n)]]
Traceback (most recent call last):
  File ""/Untitled11.py"", line 23, in <module>
    print sess.run(c)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 382, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 655, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 723, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 743, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.OutOfRangeError: PaddingFIFOQueue '_4_batch_join/padding_fifo_queue' is closed and has insufficient elements (requested 1, current size 0)
     [[Node: batch_join = QueueDequeueMany[_class=[""loc:@batch_join/padding_fifo_queue""], component_types=[DT_STRING], timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""](batch_join/padding_fifo_queue, batch_join/n)]]
Caused by op u'batch_join', defined at:
  File ""/Untitled11.py"", line 16, in <module>
    c = tf.squeeze(tf.train.batch_join([(a,), (b,)], 1, enqueue_many=False, dynamic_pad=True), [0])
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py"", line 708, in batch_join
    dequeued = queue.dequeue_many(batch_size, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/data_flow_ops.py"", line 435, in dequeue_many
    self._queue_ref, n=n, component_types=self._dtypes, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_data_flow_ops.py"", line 867, in _queue_dequeue_many
    timeout_ms=timeout_ms, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 703, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2310, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1232, in __init__
    self._traceback = _extract_stack()
```
"
3816,Bug in tf.image.random_contrast() ?,"TensorFlow v. 0.10.0rc0 CPU on Linux.

In this file for the CIFAR-10 example:

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/cifar10/cifar10_input.py

Lines 178-179 are:

```
distorted_image = tf.image.random_contrast(distorted_image, lower=0.2, upper=1.8)
```

But this gives the following result. Is this the intended behaviour of this function? Perhaps this should be explained better in the doc-string?

There is a similar problem with `tf.image.random_brightness()` and `adjust_brightness()` and its use in `cifar10_input.py`

![random_contrast](https://cloud.githubusercontent.com/assets/13588114/17666469/889ffc9e-6300-11e6-8163-9d7e23ca0f75.png)
"
3815,reduce_prod shape bug ,"Installed TensorFlow using pip package for v0.10.0rc0 on Ubuntu with python 2.7

Pip package https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl

The same error appears in the GPU build.

The following minimal code example produces raise an exception at the definition of z

```
u = tf.placeholder(dtype=tf.float64, shape=(30,30))
v = tf.reduce_prod(u, reduction_indices=[0]) 
w = tf.gradients( v, u )

x = tf.placeholder(dtype=tf.float64, shape=(30,30))
y = tf.reduce_prod(x, reduction_indices=0) 
z = tf.gradients( y, x )
```

>  z = tf.gradients( y, x )
>   File ""HOME/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gradients.py"", line 478, in gradients
>     in_grads = _AsList(grad_fn(op, *out_grads))
>   File ""HOME/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/math_grad.py"", line 130, in _ProdGrad
>     other, _ = array_ops.listdiff(idx, reduced)
>   File ""HOME/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 1201, in list_diff
>     result = _op_def_lib.apply_op(""ListDiff"", x=x, y=y, name=name)
>   File ""HOME/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 703, in apply_op
>     op_def=op_def)
>   File ""HOME/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2312, in create_op
>     set_shapes_for_outputs(ret)
>   File ""HOME/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1704, in set_shapes_for_outputs
>     shapes = shape_func(op)
>   File ""HOME/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py"", line 1981, in _ListDiffShape
>     op.inputs[1].get_shape().assert_has_rank(1)
>   File ""HOME/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/tensor_shape.py"", line 621, in assert_has_rank
>     raise ValueError(""Shape %s must have rank %d"" % (self, rank))
> ValueError: Shape () must have rank 1

The top code for u,v and w does not raise an error but the similar code for x,y, and z does. It looks like the shape code for reduce_prod cannot cope with the case where the reduction_indices is a single integer rather than a list. If you replace reduce_prod with reduce_sum in the above snippet then it does not raise an error. 
"
3814,Add a build target for a shared library that contains the c api symbols,"Since r0.10, the library created by build target tensorflow:libtensorflow.so does not contain the c api symbols anymore (whereas this was the case in previous releases). I imagine that this was caused by the c api moving from tensorflow/core to tensorflow/c. This is a little inconvenient for our [ocaml tensorflow bindings](https://github.com/LaurentMazare/tensorflow-ocaml) as they rely on these symbols.

Would it be possible to add back this dependency ? Something as simple as adding ""//tensorflow/c:c_api"" to the deps list worked for me.
If this dependency has been avoided on purpose for tensorflow:libtensorflow.so, could we add a different build target, e.g. libtensorflow_c.so, that would include it ?
I'm happy to write a pull request for either of these if this helps.
"
3813,wide_n_deep model deal with large dataset got ValueError: GraphDef cannot be larger than 2GB.,"wide_n_deep seems like unable to fit large dataset, when I put 1 million data, I got:

```
Traceback (most recent call last):
  File ""search_click.py"", line 207, in <module>
    tf.app.run()
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""search_click.py"", line 204, in main
    train_and_eval()
  File ""search_click.py"", line 181, in train_and_eval
    m.fit(input_fn=lambda: input_fn(df_train), steps=FLAGS.train_steps)
  File ""/usr/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 182, in fit
    monitors=monitors)
  File ""/usr/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 458, in _train_model
    summary_writer=graph_actions.get_summary_writer(self._model_dir))
  File ""/usr/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py"", line 76, in get_summary_writer
    graph=ops.get_default_graph())
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/training/summary_io.py"", line 113, in __init__
    self.add_graph(graph=graph, graph_def=graph_def)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/training/summary_io.py"", line 204, in add_graph
    true_graph_def = graph.as_graph_def(add_shapes=True)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2117, in as_graph_def
    raise ValueError(""GraphDef cannot be larger than 2GB."")
ValueError: GraphDef cannot be larger than 2GB.
```

```
def input_fn(df):
  """"""Input builder function.""""""
  # Creates a dictionary mapping from each continuous feature column name (k) to
  # the values of that column stored in a constant Tensor.
  continuous_cols = {k: tf.constant(df[k].values) for k in CONTINUOUS_COLUMNS}
  # Creates a dictionary mapping from each categorical feature column name (k)
  # to the values of that column stored in a tf.SparseTensor.
  categorical_cols = {k: tf.SparseTensor(
      indices=[[i, 0] for i in range(df[k].size)],
      values=df[k].values,
      shape=[df[k].size, 1])
                      for k in CATEGORICAL_COLUMNS}
  # Merges the two dictionaries into one.
  feature_cols = dict(continuous_cols)
  feature_cols.update(categorical_cols)
  # Converts the label column into a constant Tensor.
  label = tf.constant(df[LABEL_COLUMN].values)
  # Returns the feature columns and the label.
  return feature_cols, label
```

Is there a replacement of tf.constant and tf.SparseTensor, so we can load a batch once a time?
Any help would be appreciated!
"
3812,Tensorflow distributed training question: Do we have to manually copy ckpt files from worker 0  to ps servers? ,"Operating System:
Linux XNLPEXP2 4.4.0-24-generic #43-Ubuntu SMP Wed Jun 8 19:27:37 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux
Azure VM 8 cores, 56GB memory
If installed from binary pip package, provide:
pip 8.1.2 from /home/xubixiong/.local/lib/python2.7/site-packages (python 2.7)
0.10.0rc0

When I am trying to restore training from latest checkpoint, I found that I have to copy checkpoint files to ps servers, from worker 0. 

Is it the right and recommended way? Or I did something wrong? ? 
"
3810,How can I download TF API document?,"How can i download TF API document?
Search in webpage is not so convenient.
"
3806,Tensorboard not showing any visuals in summaries but is loading everything correctly,"Ubuntu 14.04 64bit Firefox and Chromium
Built from source, master branch.
**Edit: There appear to be no issues when building from the 0.10RC github release source.**

The GRAPHS tab displays all correctly, all the summary titles are displayed correctly, it even lets me download CSV/JSON in EVENTS but it doesn't actually display the visuals.

In HISTOGRAMS all I see are dots instead of the visuals, in EVENTS I see the ""cost_function"" and when I click on it I see it repeated but no accompanying visual.

All the visuals appear to have empty space allocated to them, nothing appears collapsed.

Screenshots:
http://i.imgur.com/i3B3Rdk.png
http://i.imgur.com/NBhxoNR.png
Screenshot with the option to download CSV/JSON (they do contain valid data):
http://i.imgur.com/NaTMaTb.png

Terminal output:

```
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET / HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/webcomponentsjs/webcomponents-lite.min.js HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /lib/css/global.css HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/lodash/lodash.min.js HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/d3/d3.min.js HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/plottable/plottable.css HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/plottable/plottable.min.js HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/graphlib/dist/graphlib.core.min.js HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/dagre/dist/dagre.core.min.js HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/polymer/polymer.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/iron-ajax/iron-ajax.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/iron-collapse/iron-collapse.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/iron-list/iron-list.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-button/paper-button.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-checkbox/paper-checkbox.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-dialog/paper-dialog.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-dropdown-menu/paper-dropdown-menu.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-header-panel/paper-header-panel.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-icon-button/paper-icon-button.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-input/paper-input.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-item/paper-item.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-menu/paper-menu.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-progress/paper-progress.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-radio-button/paper-radio-button.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-radio-group/paper-radio-group.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-slider/paper-slider.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-styles/paper-styles.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-toggle-button/paper-toggle-button.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-toolbar/paper-toolbar.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-tabs/paper-tabs.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /dist/tf-tensorboard.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/polymer/polymer-mini.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/iron-ajax/iron-request.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/iron-resizable-behavior/iron-resizable-behavior.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-material/paper-material.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-ripple/paper-ripple.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-behaviors/paper-button-behavior.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/iron-flex-layout/iron-flex-layout.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-styles/default-theme.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-behaviors/paper-checked-element-behavior.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/neon-animation/neon-animation-runner-behavior.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-dialog-behavior/paper-dialog-behavior.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-dialog-behavior/paper-dialog-shared-styles.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/iron-a11y-keys-behavior/iron-a11y-keys-behavior.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/iron-behaviors/iron-button-state.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/iron-behaviors/iron-control-state.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/iron-form-element-behavior/iron-form-element-behavior.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/iron-icon/iron-icon.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-menu-button/paper-menu-button.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/iron-validatable-behavior/iron-validatable-behavior.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-dropdown-menu/paper-dropdown-menu-icons.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-dropdown-menu/paper-dropdown-menu-shared-styles.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-behaviors/paper-inky-focus-behavior.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/iron-input/iron-input.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-input/paper-input-char-counter.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-input/paper-input-behavior.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-input/paper-input-container.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-input/paper-input-error.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-item/paper-item-behavior.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/iron-menu-behavior/iron-menu-behavior.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-item/paper-item-shared-styles.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-menu/paper-menu-shared-styles.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-styles/color.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/iron-range-behavior/iron-range-behavior.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/iron-selector/iron-selectable.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/iron-flex-layout/classes/iron-flex-layout.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-styles/shadow.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-styles/typography.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/iron-menu-behavior/iron-menubar-behavior.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-tabs/paper-tabs-icons.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-tabs/paper-tab.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/polymer/polymer-micro.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/promise-polyfill/promise-polyfill-lite.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-material/paper-material-shared-styles.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-behaviors/paper-ripple-behavior.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/iron-checked-element-behavior/iron-checked-element-behavior.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/iron-meta/iron-meta.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/neon-animation/neon-animatable-behavior.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/promise-polyfill/Promise.js HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/iron-overlay-behavior/iron-overlay-behavior.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/iron-iconset-svg/iron-iconset-svg.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/iron-dropdown/iron-dropdown.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/neon-animation/animations/fade-in-animation.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/neon-animation/animations/fade-out-animation.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-menu-button/paper-menu-button-animations.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/iron-a11y-announcer/iron-a11y-announcer.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/paper-input/paper-input-addon-behavior.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/iron-selector/iron-multi-selectable.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/iron-selector/iron-selection.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/iron-flex-layout/classes/iron-shadow-flex-layout.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/font-roboto/roboto.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/iron-fit-behavior/iron-fit-behavior.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/neon-animation/animations/opaque-animation.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/iron-overlay-behavior/iron-overlay-manager.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/iron-dropdown/iron-dropdown-scroll-manager.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/neon-animation/neon-animation-behavior.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/neon-animation/web-animations.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/iron-overlay-behavior/iron-overlay-backdrop.html HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:14] ""GET /external/web-animations-js/web-animations-next-lite.min.js HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:15] ""GET /data/runs HTTP/1.1"" 200 -
127.0.0.1 - - [14/Aug/2016 13:49:15] ""GET /data/runs HTTP/1.1"" 200 -
```
"
3805,Errors Building with Cuda 8 and CuDNN 5.1,"System:
Ubuntu 16.04
NVidia Driver Version: 367.35
Cuda 8.0
CuDNN 5.1.5
1.  Have to add into third_party/gpus/crosstool/CROSSTOOL an extra line to point to cuda-8.0 include
   cxx_builtin_include_directory: ""/usr/local/cuda-8.0/include""
2.  When building: 
   bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer

Explicit Error Received:
1 error detected in the compilation of ""/tmp/tmpxft_00005521_00000000-7_depthtospace_op_gpu.cu.cpp1.ii"".
ERROR: /home/drcrook/TensorFlow/tensorflow/tensorflow/core/kernels/BUILD:1529:1: output 'tensorflow/core/kernels/_objs/depth_space_ops_gpu/tensorflow/core/kernels/depthtospace_op_gpu.cu.pic.o' was not created.
ERROR: /home/drcrook/TensorFlow/tensorflow/tensorflow/core/kernels/BUILD:1529:1: not all outputs were created.
Target //tensorflow/cc:tutorials_example_trainer failed to build
Use --verbose_failures to see the command lines of failed build steps.
"
3801,Unclear documentation on dynamic_rnn vs rnn for efficient dynamic sequence length computation,"It looks like from the latest documentation that `rnn` performs early stopping for dynamic length sequences whereas `dynamic_rnn` does not? This would seem to be the reverse of the intuition. 

So it looks like in commit 855d3b56014780a90143b3e0c0865334b188c2df, the definition of `dynamic_rnn` was changed from:

> The parameter `sequence_length` is required and dynamic calculation is
> automatically performed.

to:

>  The parameter `sequence_length` is optional and is used to copy-through state
>  and zero-out outputs when past a batch element's sequence length. So it's more
>  for correctness than performance, unlike in rnn().

Whereas the `rnn` documentation states:

>   If the sequence_length vector is provided, dynamic calculation is performed.
>   This method of calculation does not compute the RNN steps past the maximum
>   sequence length of the minibatch (thus saving computational time),

For me this makes it very unclear. In this context, does `rnn` do ""more dynamic"" unrolling than `dynamic_rnn` because it actually uses sequence_length to stop early. So if I want to do efficient variable length sequences dynamically, I should use `rnn` instead of `dynamic_rnn`. 

In this case, what does `dynamic_rnn` actually do (what is ""dynamic unrolling"" explicitly defined), except for accept input in a different format?
"
3800,Problems in Tensorflow Seq2Seq Tutorial,"### Environment info

Operating System: Ubuntu 14.04

Installed version of CUDA and cuDNN: 
Cuda 7.5 and CuDNN v4
Output of ls -l /path/to/cuda/lib/cuda*:

```
-rwxrwxrwx 1 root root   322936 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root       19 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxrwxrwx 1 root root   383336 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5.18
-rwxrwxrwx 1 root root   720192 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart_static.a
-rwxrwxrwx 1 root root 61272736 Jul 31 21:45 /usr/local/cuda-7.5/lib64/libcudnn.so
-rwxrwxrwx 1 root root 61272736 Jul 31 21:45 /usr/local/cuda-7.5/lib64/libcudnn.so.4
-rwxrwxrwx 1 root root 61272736 Jul 31 21:45 /usr/local/cuda-7.5/lib64/libcudnn.so.4.0.4
```

pip package installed from:

```
export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl
```

The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

```
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
0.10.0rc0
```

The problem:
I'm trying out the seq2seq tutorial on natural language translation. 
The documentation of [seq2seq.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/seq2seq.py#L1086)
mentions that the output consists of per bucket output with each bucket containing tensors of shape 
""batch_size x num_decoder_symbols"". This seems to be incorrect because when i print the tensorflow sizes inside the function, they turn out to be (?, 1024). In other words, (batch_size, layer_size). I think either the documentation or the code is wrong, and there is certainly a mismatch. I'm wondering which is the case?
### Steps to reproduce
1. Install Tensorflow
2. Clone this repo
3. edit ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/seq2seq.py""
   to include the following print statement after [this line](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/seq2seq.py#L1113)

```
print(bucket_outputs[0].get_shape())
```
### What have you tried?
1. Filed this bug.
"
3799,"distributed tensorflow on localhosts failed by “socket error, connection refused”","I am experimenting distributed tensorflow using a slight modification of an [official example](https://www.tensorflow.org/versions/r0.10/how_tos/distributed/index.html).

My experiment code is (you can skip this for now and scroll down to the problem),

```
import tensorflow as tf
import numpy as np

# Flags for defining the tf.train.ClusterSpec
tf.app.flags.DEFINE_string(""ps_hosts"", """",
                           ""Comma-separated list of hostname:port pairs"")
tf.app.flags.DEFINE_string(""worker_hosts"", """",
                           ""Comma-separated list of hostname:port pairs"")

# Flags for defining the tf.train.Server
tf.app.flags.DEFINE_string(""job_name"", """", ""One of 'ps', 'worker'"")
tf.app.flags.DEFINE_integer(""task_index"", 0, ""Index of task within the job"")

FLAGS = tf.app.flags.FLAGS


def main(_):
    ps_hosts = FLAGS.ps_hosts.split("","")
    worker_hosts = FLAGS.worker_hosts.split("","")

    # Create a cluster from the parameter server and worker hosts.
    cluster = tf.train.ClusterSpec({""ps"": ps_hosts, ""worker"": worker_hosts})

    # Create and start a server for the local task.
    server = tf.train.Server(cluster,
                             job_name=FLAGS.job_name,
                             task_index=FLAGS.task_index)

    if FLAGS.job_name == ""ps"":
        server.join()
    elif FLAGS.job_name == ""worker"":
        # Assigns ops to the local worker by default.
        with tf.device(tf.train.replica_device_setter(
                worker_device=""/job:worker/task:%d"" % FLAGS.task_index,
                cluster=cluster)):

            # Build model...
            x = tf.placeholder(""float"", [10, 10], name=""x"")
            y = tf.placeholder(""float"", [10, 1], name=""y"")
            initial_w = np.zeros((10, 1))
            w = tf.Variable(initial_w, name=""w"", dtype=""float32"")
            loss = tf.pow(tf.add(y,-tf.matmul(x,w)),2,name=""loss"")
            global_step = tf.Variable(0)

            saver = tf.train.Saver()
            summary_op = tf.merge_all_summaries()
            init_op = tf.initialize_all_variables()

        # Create a ""supervisor"", which oversees the training process.
        sv = tf.train.Supervisor(is_chief=(FLAGS.task_index == 0),
                                 logdir=""/tmp/train_logs"",
                                 init_op=init_op,
                                 summary_op=summary_op,
                                 saver=saver,
                                 global_step=global_step,
                                 save_model_secs=600)

        # The supervisor takes care of session initialization, restoring from
        # a checkpoint, and closing when done or an error occurs.
        with sv.managed_session(server.target) as sess:
            # Loop until the supervisor shuts down or 1000000 steps have completed.
            step = 0
            while not sv.should_stop() and step < 1000000:
                # Run a training step asynchronously.
                # See `tf.train.SyncReplicasOptimizer` for additional details on how to
                # perform *synchronous* training.
                _, step = sess.run([loss, global_step])
                print(""job_name: %s; task_index: %s; step: %d"" % (FLAGS.job_name,FLAGS.task_index,step))

        # Ask for all the services to stop.
        sv.stop()


if __name__ == ""__main__"":
    tf.app.run()
```

Then I run the following commands as instructed by the official document, changing the example host names to ""localhost"" (the script is named hello_distributed.py),

```
localhost:2223 --worker_hosts=localhost:2777,localhost:2778 --job_name=ps --task_index=0

sudo python3 hello_distributed.py --ps_hosts=localhost:2222,localhost:2223 --worker_hosts=localhost:2777,localhost:2778 --job_name=ps --task_index=1

sudo python3 hello_distributed.py --ps_hosts=localhost:2222,localhost:2223 --worker_hosts=localhost:2777,localhost:2778 --job_name=worker --task_index=0

sudo python3 hello_distributed.py --ps_hosts=localhost:2222,localhost:2223 --worker_hosts=localhost:2777,localhost:2778 --job_name=worker --task_index=1
```

The first two lines for running ""ps"" are good. The last two lines get the following ""connection refused"" error.

![image](https://cloud.githubusercontent.com/assets/18235797/17646308/036f3360-6192-11e6-9e1a-4a4ef88f8264.png)

Anyone can help with this? Thank you!
"
3798,More easier setup for building and using Tensorflow from source for mods and adds,"Why does tensorflow use bazel instead of ./configure; make; make install?

Could you please make the building from source much more streamlined?

Thanks!
"
3797,RMSProp errors with embedding_lookup,"I've been trying to train an LSTM with a word embedding and got some errors that seem related to https://github.com/tensorflow/tensorflow/issues/1117
### Environment info

Operating System:
If installed from binary pip package, provide:

Linux CPU Only
0.10.0rc0
### Steps to reproduce

This is the code I've been running, which should repro the issue:

```
import tensorflow as tf
import numpy as np
import pandas
import tensorflow as tf
from tensorflow.contrib import learn
#from preprocessing import VocabularyProcessor
VocabularyProcessor = learn.preprocessing.VocabularyProcessor

def partition_length(x_train, y_train):
  #Partition the training data by length of sequences
  x_train_dict = {}
  y_train_dict = {}
  for i in range(x_train.shape[0]):
    x = x_train[i]
    y = y_train[i]

    l = len(x)
    if l not in x_train_dict:
      x_train_dict[l] = []
      y_train_dict[l] = []
    x_train_dict[l].append(x)
    y_train_dict[l].append(y)


  x_train_np = {}
  y_train_np = {}
  for l in x_train_dict:
    x_train_np[l] = np.asarray(x_train_dict[l])
    y_train_np[l] = np.asarray(y_train_dict[l])

  return (x_train_np, y_train_np)

n_words = 0
MAX_DOCUMENT_LENGTH = 10
EMBEDDING_SIZE = 50

# Prepare training and testing data
dbpedia = learn.datasets.load_dataset('dbpedia')

x_train = pandas.DataFrame(dbpedia.train.data)[1]
y_train = dbpedia.train.target
x_test = pandas.DataFrame(dbpedia.test.data)[1]
y_test = dbpedia.test.target

print x_train.shape, y_train.shape
print x_test.shape, y_test.shape

# Process vocabulary
vocab_processor = VocabularyProcessor(10)
x_train = np.array(list(vocab_processor.fit_transform(x_train)))
x_test = np.array(list(vocab_processor.transform(x_test)))
n_words = len(vocab_processor.vocabulary_)
print('Total words: %d' % n_words)

print x_train.shape, y_train.shape

(x_train_part, y_train_part) = partition_length(x_train, y_train)

data = tf.placeholder(tf.int32, [None, None], name='data')
word_vectors = learn.ops.categorical_variable(data, n_classes=n_words,
  embedding_size=EMBEDDING_SIZE, name='words')

print('data: ', data.get_shape())
print('word_vectors: ', word_vectors.get_shape())
print('word_vectors: ', tf.shape(word_vectors))

target = tf.placeholder(tf.int32, [None], name='target')
one_hot = tf.one_hot(target, 15, 1.0, 0.0, dtype=tf.float32)

print('target: ', target.get_shape())
print('one_hot: ', one_hot.get_shape())

num_hidden = 250

_, state = tf.nn.dynamic_rnn(
    tf.nn.rnn_cell.GRUCell(num_hidden),
    word_vectors,
    dtype=tf.float32,
)

print('state: ', state.get_shape())

in_size, out_size = (num_hidden, 15)

weight = tf.Variable(tf.truncated_normal([in_size, out_size], stddev=0.01))
bias = tf.Variable(tf.constant(0.1, shape=[out_size]))

prediction = tf.nn.softmax(tf.matmul(state, weight) + bias)
#prediction = tf.contrib.losses.softmax_cross_entropy(logits, onehot_labels, weight=1.0, label_smoothing=0, scope=None)
prediction_idx = tf.argmax(prediction, 1)
one_hot_idx = tf.argmax(one_hot, 1)

print('prediction: ', prediction.get_shape())
print('prediction_idx: ', prediction_idx.get_shape())
print('one_hot_idx: ', one_hot_idx.get_shape())

mistakes = tf.not_equal(one_hot_idx, prediction_idx)
error =  tf.reduce_mean(tf.cast(mistakes, tf.float32))

cross_entropy = -tf.reduce_sum(one_hot * tf.log(prediction))

learning_rate = 0.003
optimizer = tf.train.RMSPropOptimizer(learning_rate)
optimize = optimizer.minimize(cross_entropy)

sess = tf.Session()
sess.run(tf.initialize_all_variables())



batch_size = 5
for length in x_train_part:
  x_train = x_train_part[length]
  y_train = y_train_part[length]

  print ""Training on length "", length, "" # elements: "", x_train.shape[0]

  error_pct = sess.run(error, {data: x_test, target: y_test})
  print('Epoch {:2d} error {:3.1f}%'.format(0, 100 * error_pct))

  for epoch in range(10):
    print('Epoch {:2d}'.format(epoch+1))
    for i in range(x_train.shape[0]/batch_size):
      sess.run(optimize, {data: x_train[i:i+batch_size], target: y_train[i:i+batch_size]})

    error_pct = sess.run(error, {data: x_test, target: y_test})
    print('Epoch {:2d} error {:3.1f}%'.format(epoch + 1, 100 * error_pct))

```
### What have you tried?

Using any non-RMSProp Optimizer works
### Logs or other output that would be helpful

This is the exception I get:

```
Traceback (most recent call last):
  File ""lstm.py"", line 131, in <module>
    sess.run(optimize, {data: x_train[i:i+batch_size], target: y_train[i:i+batch_size]})
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 710, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 908, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 958, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 978, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.InvalidArgumentError: var and grad do not have the same shape[7664,50] [50,50]
         [[Node: RMSProp/update_words/words_embeddings/SparseApplyRMSProp = SparseApplyRMSProp[T=DT_FLOAT, Tindices=DT_INT32, _class=[""loc:@words/words_embeddings""], use_locking=false, _device=""/job:localhost/replica:0/task:0/cpu:0""](words/words_embeddings, words/words_embeddings/RMSProp, words/words_embeddings/RMSProp_1, RMSProp/learning_rate, RMSProp/decay, RMSProp/momentum, RMSProp/epsilon, gradients/words/embedding_lookup/embedding_lookup_grad/Reshape, gradients/words/embedding_lookup/embedding_lookup_grad/Reshape_1)]]
Caused by op u'RMSProp/update_words/words_embeddings/SparseApplyRMSProp', defined at:
  File ""lstm.py"", line 111, in <module>
    optimize = optimizer.minimize(cross_entropy)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py"", line 198, in minimize
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py"", line 313, in apply_gradients
    update_ops.append(self._apply_sparse(grad, var))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/rmsprop.py"", line 122, in _apply_sparse
    use_locking=self._use_locking)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/gen_training_ops.py"", line 664, in sparse_apply_rms_prop
    use_locking=use_locking, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 703, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2317, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1239, in __init__
    self._traceback = _extract_stack()
```
"
3796,ERROR [PATH]/tensorflow/tensorflow/stream_executor/BUILD:5:1: C++ compilation of rule '//tensorflow/stream_executor:stream_executor' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command ,"Hello,

I get the following errors when compiling:

____[110 / 2,641] Compiling external/png_archive/libpng-1.2.53/pngerror.c
external/protobuf/src/google/protobuf/util/internal/field_mask_utility.cc:47:14: warning: 'google::protobuf::util::Status google::protobuf::util::converter::{anonymous}::CreatePublicError(google::protobuf::util::error::Code, const string&)' defined but not used [-Wunused-function]
 util::Status CreatePublicError(util::error::Code code,
external/protobuf/src/google/protobuf/util/internal/field_mask_utility.cc:47:14: warning: 'google::protobuf::util::Status google::protobuf::util::converter::{anonymous}::CreatePublicError(google::protobuf::util::error::Code, const string&)' defined but not used [-Wunused-function]
 util::Status CreatePublicError(util::error::Code code,
external/protobuf/src/google/protobuf/util/internal/field_mask_utility.cc:47:14: warning: 'google::protobuf::util::Status google::protobuf::util::converter::{anonymous}::CreatePublicError(google::protobuf::util::error::Code, const string&)' defined but not used [-Wunused-function]
 util::Status CreatePublicError(util::error::Code code,
                         == )  // Compilation error with CHECK_EQ(NULL, x)?
                         == )  // Compilation error with CHECK_EQ(NULL, x)?
ERROR: /home/user/Downloads/tensorflow/tensorflow/stream_executor/BUILD:5:1: C++ compilation of rule '//tensorflow/stream_executor:stream_executor' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command 
tensorflow/stream_executor/cuda/cuda_dnn.cc:266:10: error: 'CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING' was not declared in this scope
tensorflow/stream_executor/cuda/cuda_dnn.cc:284:10: error: 'CUDNN_CONVOLUTION_BWD_DATA_ALGO_FFT_TILING' was not declared in this scope
tensorflow/stream_executor/cuda/cuda_dnn.cc:942:7: error: 'CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING' was not declared in this scope
tensorflow/stream_executor/cuda/cuda_dnn.cc:947:4: error: no matching function for call to 'std::vector<long long int>::assign(<brace-enclosed initializer list>)'
tensorflow/stream_executor/cuda/cuda_dnn.cc:958:7: error: 'CUDNN_CONVOLUTION_BWD_DATA_ALGO_FFT_TILING' was not declared in this scope
tensorflow/stream_executor/cuda/cuda_dnn.cc:963:4: error: no matching function for call to 'std::vector<long long int>::assign(<brace-enclosed initializer list>)'
tensorflow/stream_executor/cuda/cuda_dnn.cc:166:39: error: too many arguments to function

Complete log of build: http://pastebin.com/NzpiwmGm

The compilation command that I am using is:
bazel build --verbose_failures --genrule_strategy=standalone --spawn_strategy=standalone -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer >& build.log &

My systems information is as follows
### Environment info

Operating System:
Distributor ID: Ubuntu
Description:    Ubuntu 16.04.1 LTS
Release:    16.04
Codename:   xenial

Installed version of CUDA and cuDNN:
/usr/lib/x86_64-linux-gnu/libcudart.so.7.5.18
/usr/lib/x86_64-linux-gnu/libcudnn.so.7.0

If installed from source, provide 
1. The commit hash: bf31051225ce53c1c88fd45ee117a49645153770
2. The output of `bazel version`
   Build time: Thu Jan 01 00:00:00 1970 (0)
   Build timestamp: Thu Jan 01 00:00:00 1970 (0)
   Build timestamp as int: 0

I installed cudatoolkit, and cudann following this instructions:

> sudoapt-get install nvidia-cuda-toolkit
> sudo apt-get install nvidia-cuda-361-updates
> sudo apt-get install nvidia-nsight
> sudo apt-get install nvidia-profiler
> sudo apt-get install libcupti-dev zlib1g-dev
> # Put symlinks in /usr/local/cuda
> 
> sudo mkdir /usr/local/cuda
> cd /usr/local/cuda
> sudo ln -s  /usr/lib/x86_64-linux-gnu/ lib64
> sudo ln -s  /usr/include/ include
> sudo ln -s  /usr/bin/ bin
> sudo ln -s  /usr/lib/x86_64-linux-gnu/ nvvm
> sudo mkdir -p extras/CUPTI
> cd extras/CUPTI
> sudo ln -s  /usr/lib/x86_64-linux-gnu/ lib64
> sudo ln -s  /usr/include/ include
> # Install cudann
> # http://askubuntu.com/questions/767269/how-can-i-install-cudnn-on-ubuntu-16-04
> # Download cudann as detailed above and extract
> 
> cd ~/Downloads/cuda
> sudo cp include/cudnn.h /usr/include
> sudo cp lib64/libcudnn\* /usr/lib/x86_64-linux-gnu/
> sudo chmod a+r /usr/lib/x86_64-linux-gnu/libcudnn*
> # ... Install TensorFlow from source ...

instruction found at  https://devtalk.nvidia.com/default/topic/936212/cuda-setup-and-installation/tensorflow-cannot-find-cudnn-ubuntu-16-04-cuda7-5-/post/4880549/#4880549

I ecounter the problems described in issue  #1066. I solved it using the solution described by @chrisburr: @drufat I ran into a similar issue when compiling on Arch and found the solution in #1346. I'm unsure if -D__STRICT_ANSI__ is actually required but the following patch worked for me:

diff --git a/third_party/gpus/crosstool/CROSSTOOL b/third_party/gpus/crosstool/CROSSTOOL
index dfde7cd..15fa9fd 100644
--- a/third_party/gpus/crosstool/CROSSTOOL
+++ b/third_party/gpus/crosstool/CROSSTOOL
@@ -46,6 +46,9 @@ toolchain {
   # Use ""-std=c++11"" for nvcc. For consistency, force both the host compiler
   # and the device compiler to use ""-std=c++11"".
   cxx_flag: ""-std=c++11""
-  cxx_flag: ""-D_MWAITXINTRIN_H_INCLUDED""
-  cxx_flag: ""-D_FORCE_INLINES""
-  cxx_flag: ""-D__STRICT_ANSI__""
  linker_flag: ""-lstdc++""
  linker_flag: ""-B/usr/bin/""

Next, I got the issue #698.

Solved it by compiling with --genrule_strategy=standalone --spawn_strategy=standalone, as suggested by @damienmg 
"
3795,Unable to connect jupyter notebook within tensorflow container in AWS,"Currently we found that the [tensorflow/tensorflow](https://hub.docker.com/r/tensorflow/tensorflow/) does not work in AWS. I can access the port and open the jupyter website but could not `connect to the kernel`.

![image](https://cloud.githubusercontent.com/assets/2715000/17644038/a3160972-61ae-11e6-8ef6-1bbca7804cc2.png)

![image](https://cloud.githubusercontent.com/assets/2715000/17644040/a9745ed6-61ae-11e6-8cf0-c9b772cc9f0e.png)

The logs of that container look like these.

```
root# docker run -p 30100:8888 tensorflow/tensorflow
[I 15:09:48.070 NotebookApp] Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret
/usr/local/lib/python2.7/dist-packages/widgetsnbextension/__init__.py:30: UserWarning: To use the jupyter-js-widgets nbextension, you'll need to update
    the Jupyter notebook to version 4.2 or later.
  the Jupyter notebook to version 4.2 or later."""""")
[W 15:09:48.114 NotebookApp] WARNING: The notebook server is listening on all IP addresses and not using encryption. This is not recommended.
[W 15:09:48.114 NotebookApp] WARNING: The notebook server is listening on all IP addresses and not using authentication. This is highly insecure and not recommended.
[I 15:09:48.120 NotebookApp] Serving notebooks from local directory: /notebooks
[I 15:09:48.120 NotebookApp] 0 active kernels
[I 15:09:48.120 NotebookApp] The Jupyter Notebook is running at: http://[all ip addresses on your system]:8888/
[I 15:09:48.120 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 15:09:59.446 NotebookApp] 302 GET / (10.2.201.72) 0.79ms
[I 15:10:25.276 NotebookApp] Writing notebook-signing key to /root/.local/share/jupyter/notebook_secret
[W 15:10:25.283 NotebookApp] Notebook 3_mnist_from_scratch.ipynb is not trusted
[W 15:10:25.611 NotebookApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20160813150948 (10.2.201.72) 7.44ms referer=http://10.69.1.246:30100/notebooks/3_mnist_from_scratch.ipynb
[I 15:10:28.037 NotebookApp] Kernel started: b2421ec2-2411-4b3a-9d49-83f4ec41a3ed
```

It doesn't work even if I try with `--net=host`. But it works for my local Linux server. The logs look like similar and I'm not sure if it is related to AWS's network or jupyter's configuration.

```
➜  sudo docker run -p 30100:8888 tensorflow/tensorflow
[I 15:16:47.063 NotebookApp] Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret
/usr/local/lib/python2.7/dist-packages/widgetsnbextension/__init__.py:30: UserWarning: To use the jupyter-js-widgets nbextension, you'll need to update
    the Jupyter notebook to version 4.2 or later.
  the Jupyter notebook to version 4.2 or later."""""")
[W 15:16:47.100 NotebookApp] WARNING: The notebook server is listening on all IP addresses and not using encryption. This is not recommended.
[W 15:16:47.100 NotebookApp] WARNING: The notebook server is listening on all IP addresses and not using authentication. This is highly insecure and not recommended.
[I 15:16:47.106 NotebookApp] Serving notebooks from local directory: /notebooks
[I 15:16:47.106 NotebookApp] 0 active kernels
[I 15:16:47.106 NotebookApp] The Jupyter Notebook is running at: http://[all ip addresses on your system]:8888/
[I 15:16:47.106 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 15:17:25.033 NotebookApp] 302 GET / (10.235.212.35) 1.53ms
[I 15:17:35.355 NotebookApp] Writing notebook-signing key to /root/.local/share/jupyter/notebook_secret
[W 15:17:35.361 NotebookApp] Notebook 3_mnist_from_scratch.ipynb is not trusted
[W 15:17:35.408 NotebookApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20160813151647 (10.235.212.35) 5.66ms referer=http://tomi:30100/notebooks/3_mnist_from_scratch.ipynb
[I 15:17:37.307 NotebookApp] Kernel started: 952cac82-1a79-4446-b73e-728d5505d8a5
```
### Environment info

Operating System: AWS ubuntu 14.04

TensorFlow 0.9
### Steps to reproduce
1. `docker run -p 30100:8888 tensorflow/tensorflow` in AWS instances
2. Go to `$ip:30100` in the browser
3. Click any notebook
### What have you tried?
1. Trying in local Linux server rather than AWS instances should work.
"
3794,Unable to pull 0.10.0 Docker tag for gcr.io/tensorflow/tensorflow,"Looks like there is no Docker tag `0.10.0`:

```
➜  ~ docker pull gcr.io/tensorflow/tensorflow:0.10.0
Pulling repository gcr.io/tensorflow/tensorflow
Tag 0.10.0 not found in repository gcr.io/tensorflow/tensorflow
```

While for example `docker pull gcr.io/tensorflow/tensorflow:0.7.0` (and `0.7.0-gpu`, `0.7.0-devel`, `0.7.0-devel-gpu`) works great.
"
3793,will tensorflow support building and running model on tensorboard,"It may be too far ahead, but It'll be great to support building and running model on tensorboard directly. Writing code for deep learning tasks is interesting, but It costs much time even if you just need to copy and paste from other's code or modify on other's code. Since Deep learning programs share much similarity to each other, and tensorflow's internal mechanism is suitable for visual programming, it's not hard to do this. It'll benefit many kinds of users. Researchers and engineers don't need to spend a lot of time to code a model already exists or design a new model, a person not skilled at coding can do cool things just like a skilled programer. 
"
3791,Python 2 pip install fails with CERTIFICATE_VERIFY_FAILED - fixed by using http instead of https,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System:

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. Which pip package you installed. 

The install is failing from CentOS 7 with:

```
Step 10 : RUN pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl
 ---> Running in 882f8c6e9398
Collecting tensorflow==0.10.0rc0 from https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl
Exception:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/site-packages/pip/basecommand.py"", line 215, in main
    status = self.run(options, args)
  File ""/usr/lib/python2.7/site-packages/pip/commands/install.py"", line 299, in run
    requirement_set.prepare_files(finder)
  File ""/usr/lib/python2.7/site-packages/pip/req/req_set.py"", line 370, in prepare_files
    ignore_dependencies=self.ignore_dependencies))
  File ""/usr/lib/python2.7/site-packages/pip/req/req_set.py"", line 587, in _prepare_file
    session=self.session, hashes=hashes)
  File ""/usr/lib/python2.7/site-packages/pip/download.py"", line 810, in unpack_url
    hashes=hashes
  File ""/usr/lib/python2.7/site-packages/pip/download.py"", line 649, in unpack_http_url
    hashes)
  File ""/usr/lib/python2.7/site-packages/pip/download.py"", line 842, in _download_http_url
    stream=True,
  File ""/usr/lib/python2.7/site-packages/pip/_vendor/requests/sessions.py"", line 487, in get
    return self.request('GET', url, **kwargs)
  File ""/usr/lib/python2.7/site-packages/pip/download.py"", line 378, in request
    return super(PipSession, self).request(method, url, *args, **kwargs)
  File ""/usr/lib/python2.7/site-packages/pip/_vendor/requests/sessions.py"", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File ""/usr/lib/python2.7/site-packages/pip/_vendor/requests/sessions.py"", line 585, in send
    r = adapter.send(request, **kwargs)
  File ""/usr/lib/python2.7/site-packages/pip/_vendor/cachecontrol/adapter.py"", line 46, in send
    resp = super(CacheControlAdapter, self).send(request, **kw)
  File ""/usr/lib/python2.7/site-packages/pip/_vendor/requests/adapters.py"", line 477, in send
    raise SSLError(e, request=request)
SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:765)
```
1. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 

Tensorflow was not installed.
### Steps to reproduce
1. 
   `pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl`
### What have you tried?
1. The fix for me was to use **http://** instead of **https://**

```
Step 10 : RUN pip install --upgrade http://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl
 ---> Running in 064f19cad960
Collecting tensorflow==0.10.0rc0 from http://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl
  Downloading http://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl (33.3MB)
Requirement already up-to-date: six>=1.10.0 in /usr/lib/python2.7/site-packages (from tensorflow==0.10.0rc0)
Collecting protobuf==3.0.0b2 (from tensorflow==0.10.0rc0)
  Downloading protobuf-3.0.0b2-py2.py3-none-any.whl (326kB)
Collecting wheel (from tensorflow==0.10.0rc0)
  Downloading wheel-0.29.0-py2.py3-none-any.whl (66kB)
Collecting mock>=2.0.0 (from tensorflow==0.10.0rc0)
  Downloading mock-2.0.0-py2.py3-none-any.whl (56kB)
Requirement already up-to-date: numpy>=1.8.2 in /usr/lib64/python2.7/site-packages (from tensorflow==0.10.0rc0)
Requirement already up-to-date: setuptools in /usr/lib/python2.7/site-packages (from protobuf==3.0.0b2->tensorflow==0.10.0rc0)
Requirement already up-to-date: funcsigs>=1; python_version < ""3.3"" in /usr/lib/python2.7/site-packages (from mock>=2.0.0->tensorflow==0.10.0rc0)
Requirement already up-to-date: pbr>=0.11 in /usr/lib/python2.7/site-packages (from mock>=2.0.0->tensorflow==0.10.0rc0)
Installing collected packages: protobuf, wheel, mock, tensorflow
Successfully installed mock-2.0.0 protobuf-3.0.0b2 tensorflow-0.10.0rc0 wheel-0.29.0
 ---> a374951fbf58
```
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
3790,Issue: install ,"I am trying to install tensorflow on Fedora 23. I use python 3.4. So, I follow the guide:
$export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.10.0rc0-cp34-cp34m-linux_x86_64.whl
$pip3 install --upgrade $TF_BINARY_URL

But it doesn't work. Here is the log:

Collecting tensorflow==0.10.0rc0 from https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.10.0rc0-cp34-cp34m-linux_x86_64.whl
  Using cached https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.10.0rc0-cp34-cp34m-linux_x86_64.whl
Collecting numpy>=1.8.2 (from tensorflow==0.10.0rc0)
  Using cached numpy-1.11.1.zip
Requirement already up-to-date: wheel>=0.26 in /usr/lib/python3.4/site-packages (from tensorflow==0.10.0rc0)
Requirement already up-to-date: six>=1.10.0 in /usr/lib/python3.4/site-packages (from tensorflow==0.10.0rc0)
Requirement already up-to-date: protobuf==3.0.0b2 in /usr/lib/python3.4/site-packages (from tensorflow==0.10.0rc0)
Collecting setuptools (from protobuf==3.0.0b2->tensorflow==0.10.0rc0)
  Using cached setuptools-25.2.0-py2.py3-none-any.whl
Building wheels for collected packages: numpy
  Running setup.py bdist_wheel for numpy
  Complete output from command /usr/bin/python3 -c ""import setuptools;**file**='/tmp/pip-build-vtpn0vsk/numpy/setup.py';exec(compile(open(**file**).read().replace('\r\n', '\n'), **file**, 'exec'))"" bdist_wheel -d /tmp/tmpo1ev1azppip-wheel-:
  blas_opt_info:
  blas_mkl_info:
    libraries mkl,vml,guide not found in ['/usr/local/lib64', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/']
    NOT AVAILABLE

  openblas_info:
    libraries openblas not found in ['/usr/local/lib64', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/']
    NOT AVAILABLE

  atlas_3_10_blas_threads_info:
  Setting PTATLAS=ATLAS
    libraries tatlas not found in ['/usr/local/lib64', '/usr/local/lib', '/usr/lib64/sse2', '/usr/lib64', '/usr/lib/sse2', '/usr/lib', '/usr/lib/sse2', '/usr/lib/']
    NOT AVAILABLE

  atlas_3_10_blas_info:
    libraries satlas not found in ['/usr/local/lib64', '/usr/local/lib', '/usr/lib64/sse2', '/usr/lib64', '/usr/lib/sse2', '/usr/lib', '/usr/lib/sse2', '/usr/lib/']
    NOT AVAILABLE

  atlas_blas_threads_info:
  Setting PTATLAS=ATLAS
    libraries ptf77blas,ptcblas,atlas not found in ['/usr/local/lib64', '/usr/local/lib', '/usr/lib64/sse2', '/usr/lib64', '/usr/lib/sse2', '/usr/lib', '/usr/lib/sse2', '/usr/lib/']
    NOT AVAILABLE

  atlas_blas_info:
    libraries f77blas,cblas,atlas not found in ['/usr/local/lib64', '/usr/local/lib', '/usr/lib64/sse2', '/usr/lib64', '/usr/lib/sse2', '/usr/lib', '/usr/lib/sse2', '/usr/lib/']
    NOT AVAILABLE

  blas_info:
  customize UnixCCompiler
  C compiler: gcc -pthread -Wno-unused-result -DDYNAMIC_ANNOTATIONS_ENABLED=1 -DNDEBUG -O2 -g -pipe -Wall -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -specs=/usr/lib/rpm/redhat/redhat-hardened-cc1 -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC

  creating /tmp/tmpwhgndlax/tmp
  creating /tmp/tmpwhgndlax/tmp/tmpwhgndlax
  compile options: '-I/usr/local/include -I/usr/include -c'
  gcc: /tmp/tmpwhgndlax/source.c
  gcc: error: /usr/lib/rpm/redhat/redhat-hardened-cc1: No such file or directory
  gcc: error: /usr/lib/rpm/redhat/redhat-hardened-cc1: No such file or directory
    libraries blas not found in ['', '']
  Runtime library blas was not found. Ignoring
    FOUND:
      libraries = ['blas', 'blas']
      library_dirs = ['/usr/lib64']

```
FOUND:
  define_macros = [('NO_ATLAS_INFO', 1)]
  libraries = ['blas', 'blas']
  library_dirs = ['/usr/lib64']
```

  non-existing path in 'numpy/distutils': 'site.cfg'
  F2PY Version 2
  lapack_opt_info:
  openblas_lapack_info:
    libraries openblas not found in ['/usr/local/lib64', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/']
    NOT AVAILABLE

  lapack_mkl_info:
  mkl_info:
    libraries mkl,vml,guide not found in ['/usr/local/lib64', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/']
    NOT AVAILABLE

```
NOT AVAILABLE
```

  atlas_3_10_threads_info:
  Setting PTATLAS=ATLAS
    libraries tatlas,tatlas not found in /usr/local/lib64
    libraries lapack_atlas not found in /usr/local/lib64
    libraries tatlas,tatlas not found in /usr/local/lib
    libraries lapack_atlas not found in /usr/local/lib
    libraries tatlas,tatlas not found in /usr/lib64/sse2
    libraries lapack_atlas not found in /usr/lib64/sse2
    libraries tatlas,tatlas not found in /usr/lib64
    libraries lapack_atlas not found in /usr/lib64
    libraries tatlas,tatlas not found in /usr/lib/sse2
    libraries lapack_atlas not found in /usr/lib/sse2
    libraries tatlas,tatlas not found in /usr/lib
    libraries lapack_atlas not found in /usr/lib
    libraries tatlas,tatlas not found in /usr/lib/sse2
    libraries lapack_atlas not found in /usr/lib/sse2
    libraries tatlas,tatlas not found in /usr/lib/
    libraries lapack_atlas not found in /usr/lib/
  <class 'numpy.distutils.system_info.atlas_3_10_threads_info'>
    NOT AVAILABLE

  atlas_3_10_info:
    libraries satlas,satlas not found in /usr/local/lib64
    libraries lapack_atlas not found in /usr/local/lib64
    libraries satlas,satlas not found in /usr/local/lib
    libraries lapack_atlas not found in /usr/local/lib
    libraries satlas,satlas not found in /usr/lib64/sse2
    libraries lapack_atlas not found in /usr/lib64/sse2
    libraries satlas,satlas not found in /usr/lib64
    libraries lapack_atlas not found in /usr/lib64
    libraries satlas,satlas not found in /usr/lib/sse2
    libraries lapack_atlas not found in /usr/lib/sse2
    libraries satlas,satlas not found in /usr/lib
    libraries lapack_atlas not found in /usr/lib
    libraries satlas,satlas not found in /usr/lib/sse2
    libraries lapack_atlas not found in /usr/lib/sse2
    libraries satlas,satlas not found in /usr/lib/
    libraries lapack_atlas not found in /usr/lib/
  <class 'numpy.distutils.system_info.atlas_3_10_info'>
    NOT AVAILABLE

  atlas_threads_info:
  Setting PTATLAS=ATLAS
    libraries ptf77blas,ptcblas,atlas not found in /usr/local/lib64
    libraries lapack_atlas not found in /usr/local/lib64
    libraries ptf77blas,ptcblas,atlas not found in /usr/local/lib
    libraries lapack_atlas not found in /usr/local/lib
    libraries ptf77blas,ptcblas,atlas not found in /usr/lib64/sse2
    libraries lapack_atlas not found in /usr/lib64/sse2
    libraries ptf77blas,ptcblas,atlas not found in /usr/lib64
    libraries lapack_atlas not found in /usr/lib64
    libraries ptf77blas,ptcblas,atlas not found in /usr/lib/sse2
    libraries lapack_atlas not found in /usr/lib/sse2
    libraries ptf77blas,ptcblas,atlas not found in /usr/lib
    libraries lapack_atlas not found in /usr/lib
    libraries ptf77blas,ptcblas,atlas not found in /usr/lib/sse2
    libraries lapack_atlas not found in /usr/lib/sse2
    libraries ptf77blas,ptcblas,atlas not found in /usr/lib/
    libraries lapack_atlas not found in /usr/lib/
  <class 'numpy.distutils.system_info.atlas_threads_info'>
    NOT AVAILABLE

  atlas_info:
    libraries f77blas,cblas,atlas not found in /usr/local/lib64
    libraries lapack_atlas not found in /usr/local/lib64
    libraries f77blas,cblas,atlas not found in /usr/local/lib
    libraries lapack_atlas not found in /usr/local/lib
    libraries f77blas,cblas,atlas not found in /usr/lib64/sse2
    libraries lapack_atlas not found in /usr/lib64/sse2
    libraries f77blas,cblas,atlas not found in /usr/lib64
    libraries lapack_atlas not found in /usr/lib64
    libraries f77blas,cblas,atlas not found in /usr/lib/sse2
    libraries lapack_atlas not found in /usr/lib/sse2
    libraries f77blas,cblas,atlas not found in /usr/lib
    libraries lapack_atlas not found in /usr/lib
    libraries f77blas,cblas,atlas not found in /usr/lib/sse2
    libraries lapack_atlas not found in /usr/lib/sse2
    libraries f77blas,cblas,atlas not found in /usr/lib/
    libraries lapack_atlas not found in /usr/lib/
  <class 'numpy.distutils.system_info.atlas_info'>
    NOT AVAILABLE

  lapack_info:
    libraries lapack not found in ['', '']
  Runtime library lapack was not found. Ignoring
    FOUND:
      libraries = ['lapack', 'lapack']
      library_dirs = ['/usr/lib64']
      language = f77

```
FOUND:
  define_macros = [('NO_ATLAS_INFO', 1)]
  libraries = ['lapack', 'lapack', 'blas', 'blas']
  library_dirs = ['/usr/lib64']
  language = f77
```

  running bdist_wheel
  running build
  running config_cc
  unifing config_cc, config, build_clib, build_ext, build commands --compiler options
  running config_fc
  unifing config_fc, config, build_clib, build_ext, build commands --fcompiler options
  running build_src
  build_src
  building py_modules sources
  creating build
  creating build/src.linux-x86_64-3.4
  creating build/src.linux-x86_64-3.4/numpy
  creating build/src.linux-x86_64-3.4/numpy/distutils
  building library ""npymath"" sources
  customize Gnu95FCompiler
  Found executable /usr/bin/gfortran
  customize Gnu95FCompiler
  customize Gnu95FCompiler using config
  C compiler: gcc -pthread -Wno-unused-result -DDYNAMIC_ANNOTATIONS_ENABLED=1 -DNDEBUG -O2 -g -pipe -Wall -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -specs=/usr/lib/rpm/redhat/redhat-hardened-cc1 -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC

  compile options: '-Inumpy/core/src/private -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/usr/include/python3.4m -c'
  gcc: _configtest.c
  gcc: error: /usr/lib/rpm/redhat/redhat-hardened-cc1: No such file or directory
  gcc: error: /usr/lib/rpm/redhat/redhat-hardened-cc1: No such file or directory
  failure.
  removing: _configtest.c _configtest.o
  Running from numpy source directory.
  /tmp/pip-build-vtpn0vsk/numpy/numpy/distutils/system_info.py:1646: UserWarning:
      Atlas (http://math-atlas.sourceforge.net/) libraries not found.
      Directories to search for the libraries can be specified in the
      numpy/distutils/site.cfg file (section [atlas]) or by setting
      the ATLAS environment variable.
    warnings.warn(AtlasNotFoundError.__doc__)
  /tmp/pip-build-vtpn0vsk/numpy/numpy/distutils/system_info.py:1548: UserWarning:
      Atlas (http://math-atlas.sourceforge.net/) libraries not found.
      Directories to search for the libraries can be specified in the
      numpy/distutils/site.cfg file (section [atlas]) or by setting
      the ATLAS environment variable.
    warnings.warn(AtlasNotFoundError.**doc**)
  /usr/lib64/python3.4/distutils/dist.py:260: UserWarning: Unknown distribution option: 'define_macros'
    warnings.warn(msg)
  Traceback (most recent call last):
    File ""<string>"", line 1, in <module>
    File ""/tmp/pip-build-vtpn0vsk/numpy/setup.py"", line 386, in <module>
      setup_package()
    File ""/tmp/pip-build-vtpn0vsk/numpy/setup.py"", line 378, in setup_package
      setup(**metadata)
    File ""/tmp/pip-build-vtpn0vsk/numpy/numpy/distutils/core.py"", line 169, in setup
      return old_setup(**new_attr)
    File ""/usr/lib64/python3.4/distutils/core.py"", line 148, in setup
      dist.run_commands()
    File ""/usr/lib64/python3.4/distutils/dist.py"", line 955, in run_commands
      self.run_command(cmd)
    File ""/usr/lib64/python3.4/distutils/dist.py"", line 974, in run_command
      cmd_obj.run()
    File ""/usr/lib/python3.4/site-packages/wheel/bdist_wheel.py"", line 179, in run
      self.run_command('build')
    File ""/usr/lib64/python3.4/distutils/cmd.py"", line 313, in run_command
      self.distribution.run_command(command)
    File ""/usr/lib64/python3.4/distutils/dist.py"", line 974, in run_command
      cmd_obj.run()
    File ""/tmp/pip-build-vtpn0vsk/numpy/numpy/distutils/command/build.py"", line 47, in run
      old_build.run(self)
    File ""/usr/lib64/python3.4/distutils/command/build.py"", line 126, in run
      self.run_command(cmd_name)
    File ""/usr/lib64/python3.4/distutils/cmd.py"", line 313, in run_command
      self.distribution.run_command(command)
    File ""/usr/lib64/python3.4/distutils/dist.py"", line 974, in run_command
      cmd_obj.run()
    File ""/tmp/pip-build-vtpn0vsk/numpy/numpy/distutils/command/build_src.py"", line 147, in run
      self.build_sources()
    File ""/tmp/pip-build-vtpn0vsk/numpy/numpy/distutils/command/build_src.py"", line 158, in build_sources
      self.build_library_sources(*libname_info)
    File ""/tmp/pip-build-vtpn0vsk/numpy/numpy/distutils/command/build_src.py"", line 293, in build_library_sources
      sources = self.generate_sources(sources, (lib_name, build_info))
    File ""/tmp/pip-build-vtpn0vsk/numpy/numpy/distutils/command/build_src.py"", line 376, in generate_sources
      source = func(extension, build_dir)
    File ""numpy/core/setup.py"", line 654, in get_mathlib_info
      raise RuntimeError(""Broken toolchain: cannot link a simple C program"")
  RuntimeError: Broken toolchain: cannot link a simple C program

---

Failed to build numpy
Installing collected packages: numpy, tensorflow, setuptools
  Running setup.py install for numpy
    Complete output from command /usr/bin/python3 -c ""import setuptools, tokenize;**file**='/tmp/pip-build-vtpn0vsk/numpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(**file**).read().replace('\r\n', '\n'), **file**, 'exec'))"" install --record /tmp/pip-ong2pih1-record/install-record.txt --single-version-externally-managed --compile:

```
Note: if you need reliable uninstall behavior, then install
with pip instead of using `setup.py install`:

  - `pip install .`       (from a git repo or downloaded source
                           release)
  - `pip install numpy`   (last Numpy release on PyPi)


blas_opt_info:
blas_mkl_info:
  libraries mkl,vml,guide not found in ['/usr/local/lib64', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/']
  NOT AVAILABLE

openblas_info:
  libraries openblas not found in ['/usr/local/lib64', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/']
  NOT AVAILABLE

atlas_3_10_blas_threads_info:
Setting PTATLAS=ATLAS
  libraries tatlas not found in ['/usr/local/lib64', '/usr/local/lib', '/usr/lib64/sse2', '/usr/lib64', '/usr/lib/sse2', '/usr/lib', '/usr/lib/sse2', '/usr/lib/']
  NOT AVAILABLE

atlas_3_10_blas_info:
  libraries satlas not found in ['/usr/local/lib64', '/usr/local/lib', '/usr/lib64/sse2', '/usr/lib64', '/usr/lib/sse2', '/usr/lib', '/usr/lib/sse2', '/usr/lib/']
  NOT AVAILABLE

atlas_blas_threads_info:
Setting PTATLAS=ATLAS
  libraries ptf77blas,ptcblas,atlas not found in ['/usr/local/lib64', '/usr/local/lib', '/usr/lib64/sse2', '/usr/lib64', '/usr/lib/sse2', '/usr/lib', '/usr/lib/sse2', '/usr/lib/']
  NOT AVAILABLE

atlas_blas_info:
  libraries f77blas,cblas,atlas not found in ['/usr/local/lib64', '/usr/local/lib', '/usr/lib64/sse2', '/usr/lib64', '/usr/lib/sse2', '/usr/lib', '/usr/lib/sse2', '/usr/lib/']
  NOT AVAILABLE

blas_info:
customize UnixCCompiler
C compiler: gcc -pthread -Wno-unused-result -DDYNAMIC_ANNOTATIONS_ENABLED=1 -DNDEBUG -O2 -g -pipe -Wall -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -specs=/usr/lib/rpm/redhat/redhat-hardened-cc1 -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC

creating /tmp/tmpf19ke2cs/tmp
creating /tmp/tmpf19ke2cs/tmp/tmpf19ke2cs
compile options: '-I/usr/local/include -I/usr/include -c'
gcc: /tmp/tmpf19ke2cs/source.c
gcc: error: /usr/lib/rpm/redhat/redhat-hardened-cc1: No such file or directory
gcc: error: /usr/lib/rpm/redhat/redhat-hardened-cc1: No such file or directory
  libraries blas not found in ['', '']
Runtime library blas was not found. Ignoring
  FOUND:
    libraries = ['blas', 'blas']
    library_dirs = ['/usr/lib64']

  FOUND:
    libraries = ['blas', 'blas']
    define_macros = [('NO_ATLAS_INFO', 1)]
    library_dirs = ['/usr/lib64']

non-existing path in 'numpy/distutils': 'site.cfg'
F2PY Version 2
lapack_opt_info:
openblas_lapack_info:
  libraries openblas not found in ['/usr/local/lib64', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/']
  NOT AVAILABLE

lapack_mkl_info:
mkl_info:
  libraries mkl,vml,guide not found in ['/usr/local/lib64', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/']
  NOT AVAILABLE

  NOT AVAILABLE

atlas_3_10_threads_info:
Setting PTATLAS=ATLAS
  libraries tatlas,tatlas not found in /usr/local/lib64
  libraries lapack_atlas not found in /usr/local/lib64
  libraries tatlas,tatlas not found in /usr/local/lib
  libraries lapack_atlas not found in /usr/local/lib
  libraries tatlas,tatlas not found in /usr/lib64/sse2
  libraries lapack_atlas not found in /usr/lib64/sse2
  libraries tatlas,tatlas not found in /usr/lib64
  libraries lapack_atlas not found in /usr/lib64
  libraries tatlas,tatlas not found in /usr/lib/sse2
  libraries lapack_atlas not found in /usr/lib/sse2
  libraries tatlas,tatlas not found in /usr/lib
  libraries lapack_atlas not found in /usr/lib
  libraries tatlas,tatlas not found in /usr/lib/sse2
  libraries lapack_atlas not found in /usr/lib/sse2
  libraries tatlas,tatlas not found in /usr/lib/
  libraries lapack_atlas not found in /usr/lib/
<class 'numpy.distutils.system_info.atlas_3_10_threads_info'>
  NOT AVAILABLE

atlas_3_10_info:
  libraries satlas,satlas not found in /usr/local/lib64
  libraries lapack_atlas not found in /usr/local/lib64
  libraries satlas,satlas not found in /usr/local/lib
  libraries lapack_atlas not found in /usr/local/lib
  libraries satlas,satlas not found in /usr/lib64/sse2
  libraries lapack_atlas not found in /usr/lib64/sse2
  libraries satlas,satlas not found in /usr/lib64
  libraries lapack_atlas not found in /usr/lib64
  libraries satlas,satlas not found in /usr/lib/sse2
  libraries lapack_atlas not found in /usr/lib/sse2
  libraries satlas,satlas not found in /usr/lib
  libraries lapack_atlas not found in /usr/lib
  libraries satlas,satlas not found in /usr/lib/sse2
  libraries lapack_atlas not found in /usr/lib/sse2
  libraries satlas,satlas not found in /usr/lib/
  libraries lapack_atlas not found in /usr/lib/
<class 'numpy.distutils.system_info.atlas_3_10_info'>
  NOT AVAILABLE

atlas_threads_info:
Setting PTATLAS=ATLAS
  libraries ptf77blas,ptcblas,atlas not found in /usr/local/lib64
  libraries lapack_atlas not found in /usr/local/lib64
  libraries ptf77blas,ptcblas,atlas not found in /usr/local/lib
  libraries lapack_atlas not found in /usr/local/lib
  libraries ptf77blas,ptcblas,atlas not found in /usr/lib64/sse2
  libraries lapack_atlas not found in /usr/lib64/sse2
  libraries ptf77blas,ptcblas,atlas not found in /usr/lib64
  libraries lapack_atlas not found in /usr/lib64
  libraries ptf77blas,ptcblas,atlas not found in /usr/lib/sse2
  libraries lapack_atlas not found in /usr/lib/sse2
  libraries ptf77blas,ptcblas,atlas not found in /usr/lib
  libraries lapack_atlas not found in /usr/lib
  libraries ptf77blas,ptcblas,atlas not found in /usr/lib/sse2
  libraries lapack_atlas not found in /usr/lib/sse2
  libraries ptf77blas,ptcblas,atlas not found in /usr/lib/
  libraries lapack_atlas not found in /usr/lib/
<class 'numpy.distutils.system_info.atlas_threads_info'>
  NOT AVAILABLE

atlas_info:
  libraries f77blas,cblas,atlas not found in /usr/local/lib64
  libraries lapack_atlas not found in /usr/local/lib64
  libraries f77blas,cblas,atlas not found in /usr/local/lib
  libraries lapack_atlas not found in /usr/local/lib
  libraries f77blas,cblas,atlas not found in /usr/lib64/sse2
  libraries lapack_atlas not found in /usr/lib64/sse2
  libraries f77blas,cblas,atlas not found in /usr/lib64
  libraries lapack_atlas not found in /usr/lib64
  libraries f77blas,cblas,atlas not found in /usr/lib/sse2
  libraries lapack_atlas not found in /usr/lib/sse2
  libraries f77blas,cblas,atlas not found in /usr/lib
  libraries lapack_atlas not found in /usr/lib
  libraries f77blas,cblas,atlas not found in /usr/lib/sse2
  libraries lapack_atlas not found in /usr/lib/sse2
  libraries f77blas,cblas,atlas not found in /usr/lib/
  libraries lapack_atlas not found in /usr/lib/
<class 'numpy.distutils.system_info.atlas_info'>
  NOT AVAILABLE

lapack_info:
  libraries lapack not found in ['', '']
Runtime library lapack was not found. Ignoring
  FOUND:
    libraries = ['lapack', 'lapack']
    library_dirs = ['/usr/lib64']
    language = f77

  FOUND:
    libraries = ['lapack', 'lapack', 'blas', 'blas']
    define_macros = [('NO_ATLAS_INFO', 1)]
    library_dirs = ['/usr/lib64']
    language = f77

running install
running build
running config_cc
unifing config_cc, config, build_clib, build_ext, build commands --compiler options
running config_fc
unifing config_fc, config, build_clib, build_ext, build commands --fcompiler options
running build_src
build_src
building py_modules sources
building library ""npymath"" sources
customize Gnu95FCompiler
Found executable /usr/bin/gfortran
customize Gnu95FCompiler
customize Gnu95FCompiler using config
C compiler: gcc -pthread -Wno-unused-result -DDYNAMIC_ANNOTATIONS_ENABLED=1 -DNDEBUG -O2 -g -pipe -Wall -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -specs=/usr/lib/rpm/redhat/redhat-hardened-cc1 -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC

compile options: '-Inumpy/core/src/private -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/usr/include/python3.4m -c'
gcc: _configtest.c
gcc: error: /usr/lib/rpm/redhat/redhat-hardened-cc1: No such file or directory
gcc: error: /usr/lib/rpm/redhat/redhat-hardened-cc1: No such file or directory
failure.
removing: _configtest.c _configtest.o
Running from numpy source directory.
/tmp/pip-build-vtpn0vsk/numpy/numpy/distutils/system_info.py:1646: UserWarning:
    Atlas (http://math-atlas.sourceforge.net/) libraries not found.
    Directories to search for the libraries can be specified in the
    numpy/distutils/site.cfg file (section [atlas]) or by setting
    the ATLAS environment variable.
  warnings.warn(AtlasNotFoundError.__doc__)
/tmp/pip-build-vtpn0vsk/numpy/numpy/distutils/system_info.py:1548: UserWarning:
    Atlas (http://math-atlas.sourceforge.net/) libraries not found.
    Directories to search for the libraries can be specified in the
    numpy/distutils/site.cfg file (section [atlas]) or by setting
    the ATLAS environment variable.
  warnings.warn(AtlasNotFoundError.__doc__)
/usr/lib64/python3.4/distutils/dist.py:260: UserWarning: Unknown distribution option: 'define_macros'
  warnings.warn(msg)
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/tmp/pip-build-vtpn0vsk/numpy/setup.py"", line 386, in <module>
    setup_package()
  File ""/tmp/pip-build-vtpn0vsk/numpy/setup.py"", line 378, in setup_package
    setup(**metadata)
  File ""/tmp/pip-build-vtpn0vsk/numpy/numpy/distutils/core.py"", line 169, in setup
    return old_setup(**new_attr)
  File ""/usr/lib64/python3.4/distutils/core.py"", line 148, in setup
    dist.run_commands()
  File ""/usr/lib64/python3.4/distutils/dist.py"", line 955, in run_commands
    self.run_command(cmd)
  File ""/usr/lib64/python3.4/distutils/dist.py"", line 974, in run_command
    cmd_obj.run()
  File ""/tmp/pip-build-vtpn0vsk/numpy/numpy/distutils/command/install.py"", line 62, in run
    r = self.setuptools_run()
  File ""/tmp/pip-build-vtpn0vsk/numpy/numpy/distutils/command/install.py"", line 36, in setuptools_run
    return distutils_install.run(self)
  File ""/usr/lib64/python3.4/distutils/command/install.py"", line 539, in run
    self.run_command('build')
  File ""/usr/lib64/python3.4/distutils/cmd.py"", line 313, in run_command
    self.distribution.run_command(command)
  File ""/usr/lib64/python3.4/distutils/dist.py"", line 974, in run_command
    cmd_obj.run()
  File ""/tmp/pip-build-vtpn0vsk/numpy/numpy/distutils/command/build.py"", line 47, in run
    old_build.run(self)
  File ""/usr/lib64/python3.4/distutils/command/build.py"", line 126, in run
    self.run_command(cmd_name)
  File ""/usr/lib64/python3.4/distutils/cmd.py"", line 313, in run_command
    self.distribution.run_command(command)
  File ""/usr/lib64/python3.4/distutils/dist.py"", line 974, in run_command
    cmd_obj.run()
  File ""/tmp/pip-build-vtpn0vsk/numpy/numpy/distutils/command/build_src.py"", line 147, in run
    self.build_sources()
  File ""/tmp/pip-build-vtpn0vsk/numpy/numpy/distutils/command/build_src.py"", line 158, in build_sources
    self.build_library_sources(*libname_info)
  File ""/tmp/pip-build-vtpn0vsk/numpy/numpy/distutils/command/build_src.py"", line 293, in build_library_sources
    sources = self.generate_sources(sources, (lib_name, build_info))
  File ""/tmp/pip-build-vtpn0vsk/numpy/numpy/distutils/command/build_src.py"", line 376, in generate_sources
    source = func(extension, build_dir)
  File ""numpy/core/setup.py"", line 654, in get_mathlib_info
    raise RuntimeError(""Broken toolchain: cannot link a simple C program"")
RuntimeError: Broken toolchain: cannot link a simple C program

----------------------------------------
```

Well, I also installed blas-devel and lapack-devel. 
Thanks for your help.
"
3788,building issue with cuda 8.0RC and computing capability 6.1,"```
external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/CUDA/PacketMathHalf.h(279): error: identifier ""h2log1p"" is undefined

1 error detected in the compilation of ""/tmp/tmpxft_00000170_00000000-9_depthtospace_op_gpu.cu.compute_61.cpp1.ii"".
ERROR: /home/wenjian/pkgs/tensorflow/tensorflow/core/kernels/BUILD:1529:1: output 'tensorflow/core/kernels/_objs/depth_space_ops_gpu/tensorflow/core/kernels/depthtospace_op_gpu.cu.pic.o' was not created.
ERROR: /home/wenjian/pkgs/tensorflow/tensorflow/core/kernels/BUILD:1529:1: not all outputs were created.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 112.094s, Critical Path: 108.68s
```

so `error: identifier ""h2log1p"" is undefined` is the cause, there must be something new in the Eigen library
"
3786,Issue installing.,"I get the following error when I try to build the latest tensorflow from source.  I am on Ubuntu 16.04.  I am using GCC 5.4 with CUDA 8.0 RC (GCC 5.4 patch installed).

> external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/CUDA/PacketMathHalf.h(279): error: identifier ""h2log1p"" is undefined
> 
> 1 error detected in the compilation of ""/tmp/tmpxft_00007e16_00000000-7_depthtospace_op_gpu.cu.cpp1.ii"".
> Target //tensorflow/tools/pip_package:build_pip_package failed to build
> Use --verbose_failures to see the command lines of failed build steps.
> INFO: Elapsed time: 270.294s, Critical Path: 152.97s
"
3782,"Tensorboard overlays the legend on top of curve, making it hard to see the curve itself","**Feature Request** (This is not super high-priority, but would be nice to have)
Tensorboard overlays the legend on top of the graph, sometimes making it hard to see parts of the graph. It would be better that the legend location can be at the top/bottom depending on the mouse position, so it does not overlap on the graph itself. Example:
![screen shot 2016-08-10 at 10 01 25 am](https://cloud.githubusercontent.com/assets/1893429/17637456/7b4db6ae-6098-11e6-9458-93a5beea19c8.png)
### Environment info

Operating System: Ubuntu 14.04

Installed version of CUDA and cuDNN: CUDA 7.5.18, cuDNN 5
If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`): 056db850614e0a06ce6f65b30f877c5789ab74f5
2. The output of `bazel version`: Build label: 0.3.0
"
3777,Problems in TensorFlow Linear Model Tutorial,"I believe the [TensorFlow Linear Model tutorial](https://www.tensorflow.org/versions/r0.10/tutorials/wide/index.html) incorrectly points to [wide_n_deep_tutorial.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/learn/wide_n_deep_tutorial.py) code. For example that code does not put in place the [L1 and L2 regularization](https://www.tensorflow.org/versions/r0.10/tutorials/wide/index.html#adding-regularization-to-prevent-overfitting) that is mentioned (and for which the code is shown) in the tutorial text.

I assume the tutorial was written up based on a different python script?

Also, [wide_n_deep_tutorial.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/learn/wide_n_deep_tutorial.py) will not work on Python 3 as it calls `urllib.urlretrieve` directly. Perhaps it should use the `maybe_download` function from `tensorflow.contrib.learn.python.learn.datasets.base`?
"
3776,error with wide_n_deep_tutorial.py,"I'm running into problems when trying to run the wide and deep tutorial code example. Here's my info:
### Environment info

Operating System: OSX 10.11.4 

Installed version of CUDA and cuDNN: CUDA-7.5,
-rwxr-xr-x@ 2 root  wheel      8280 Apr 12 23:02 /usr/local/cuda/lib/libcuda.1.dylib
-rwxr-xr-x@ 2 root  wheel      8280 Apr 12 23:02 /usr/local/cuda/lib/libcuda.dylib
lrwxr-xr-x@ 1 root  wheel        45 Apr 12 23:03 /usr/local/cuda/lib/libcudadevrt.a -> /Developer/NVIDIA/CUDA-7.5/lib/libcudadevrt.a
lrwxr-xr-x@ 1 root  wheel        50 Apr 12 23:03 /usr/local/cuda/lib/libcudart.7.5.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart.7.5.dylib
lrwxr-xr-x@ 1 root  wheel        46 Apr 12 23:03 /usr/local/cuda/lib/libcudart.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart.dylib
lrwxr-xr-x@ 1 root  wheel        49 Apr 12 23:03 /usr/local/cuda/lib/libcudart_static.a -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart_static.a
-rwxr-xr-x@ 1 root  admin  58270280 Aug  2 21:26 /usr/local/cuda/lib/libcudnn.5.dylib
-rwxr-xr-x@ 1 root  admin  58270280 Aug  2 21:26 /usr/local/cuda/lib/libcudnn.dylib
-rw-r--r--@ 1 root  admin  55551064 Aug  2 21:26 /usr/local/cuda/lib/libcudnn_static.a
### Steps to reproduce
1. Open the script, set the ""model_type"" FLAG to ""deep"" or to ""wide_n_deep"", and run interactively with an open Python compiler.
### What have you tried?
1. Running it with FLAGS.model_type = ""wide"" works fine. 
### Logs or other output that would be helpful

Here is the log from running it with FLAGS.model_type = ""deep""

```
Training data is downloaded to /var/folders/_x/ssxr2t2144v_2vr8w0yywpvw0000gn/T/tmpbVSoKV
Test data is downloaded to /var/folders/_x/ssxr2t2144v_2vr8w0yywpvw0000gn/T/tmp8ojlXf
model directory = .
WARNING:tensorflow:Setting feature info to {'hours_per_week': TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(32561)]), is_sparse=False), 'workclass': TensorSignature(dtype=tf.string, shape=None, is_sparse=True), 'relationship': TensorSignature(dtype=tf.string, shape=None, is_sparse=True), 'gender': TensorSignature(dtype=tf.string, shape=None, is_sparse=True), 'age': TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(32561)]), is_sparse=False), 'marital_status': TensorSignature(dtype=tf.string, shape=None, is_sparse=True), 'race': TensorSignature(dtype=tf.string, shape=None, is_sparse=True), 'education_num': TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(32561)]), is_sparse=False), 'native_country': TensorSignature(dtype=tf.string, shape=None, is_sparse=True), 'capital_loss': TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(32561)]), is_sparse=False), 'education': TensorSignature(dtype=tf.string, shape=None, is_sparse=True), 'capital_gain': TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(32561)]), is_sparse=False), 'occupation': TensorSignature(dtype=tf.string, shape=None, is_sparse=True)}
WARNING:tensorflow:Setting targets info to TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(32561)]), is_sparse=False)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:839] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GT 750M, pci bus id: 0000:01:00.0)
W tensorflow/core/framework/op_kernel.cc:936] Not found: Tensor name ""hiddenlayer_1/biases/Adagrad"" not found in checkpoint files ./model.ckpt-200-?????-of-00001
     [[Node: save/restore_slice_12 = RestoreSlice[dt=DT_FLOAT, preferred_shard=0, _device=""/job:localhost/replica:0/task:0/cpu:0""](_recv_save/Const_0, save/restore_slice_12/tensor_name, save/restore_slice_12/shape_and_slice)]]
W tensorflow/core/framework/op_kernel.cc:936] Not found: Tensor name ""hiddenlayer_1/biases/Adagrad"" not found in checkpoint files ./model.ckpt-200-?????-of-00001
     [[Node: save/restore_slice_12 = RestoreSlice[dt=DT_FLOAT, preferred_shard=0, _device=""/job:localhost/replica:0/task:0/cpu:0""](_recv_save/Const_0, save/restore_slice_12/tensor_name, save/restore_slice_12/shape_and_slice)]]
W tensorflow/core/framework/op_kernel.cc:936] Not found: Tensor name ""hiddenlayer_1/biases/Adagrad"" not found in checkpoint files ./model.ckpt-200-?????-of-00001
     [[Node: save/restore_slice_12 = RestoreSlice[dt=DT_FLOAT, preferred_shard=0, _device=""/job:localhost/replica:0/task:0/cpu:0""](_recv_save/Const_0, save/restore_slice_12/tensor_name, save/restore_slice_12/shape_and_slice)]]
E tensorflow/core/client/tensor_c_api.cc:485] Tensor name ""hiddenlayer_1/biases/Adagrad"" not found in checkpoint files ./model.ckpt-200-?????-of-00001
     [[Node: save/restore_slice_12 = RestoreSlice[dt=DT_FLOAT, preferred_shard=0, _device=""/job:localhost/replica:0/task:0/cpu:0""](_recv_save/Const_0, save/restore_slice_12/tensor_name, save/restore_slice_12/shape_and_slice)]]
     [[Node: save/Assign_22/_84 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_179_save/Assign_22"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""]()]]
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""<stdin>"", line 23, in train_and_eval
  File ""/usr/local/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 240, in fit
    max_steps=max_steps)
  File ""/usr/local/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 578, in _train_model
    max_steps=max_steps)
  File ""/usr/local/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py"", line 276, in _supervised_train
    scaffold=scaffold) as super_sess:
  File ""/usr/local/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/supervised_session.py"", line 212, in __init__
    self._sess = recoverable_session.RecoverableSession(self._create_session)
  File ""/usr/local/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/recoverable_session.py"", line 46, in __init__
    WrappedSession.__init__(self, sess_factory())
  File ""/usr/local/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/supervised_session.py"", line 232, in _create_session
    init_fn=self._scaffold.init_fn)
  File ""/usr/local/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 164, in prepare_session
    max_wait_secs=max_wait_secs, config=config)
  File ""/usr/local/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 224, in recover_session
    saver.restore(sess, ckpt.model_checkpoint_path)
  File ""/usr/local/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1129, in restore
    {self.saver_def.filename_tensor_name: save_path})
  File ""/usr/local/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 382, in run
    run_metadata_ptr)
  File ""/usr/local/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 655, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 723, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 743, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.NotFoundError: Tensor name ""hiddenlayer_1/biases/Adagrad"" not found in checkpoint files ./model.ckpt-200-?????-of-00001
     [[Node: save/restore_slice_12 = RestoreSlice[dt=DT_FLOAT, preferred_shard=0, _device=""/job:localhost/replica:0/task:0/cpu:0""](_recv_save/Const_0, save/restore_slice_12/tensor_name, save/restore_slice_12/shape_and_slice)]]
     [[Node: save/Assign_22/_84 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_179_save/Assign_22"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""]()]]
Caused by op u'save/restore_slice_12', defined at:
  File ""<stdin>"", line 1, in <module>
  File ""<stdin>"", line 23, in train_and_eval
  File ""/usr/local/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 240, in fit
    max_steps=max_steps)
  File ""/usr/local/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 578, in _train_model
    max_steps=max_steps)
  File ""/usr/local/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py"", line 252, in _supervised_train
    keep_checkpoint_max=keep_checkpoint_max)
  File ""/usr/local/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/supervised_session.py"", line 152, in __init__
    lambda: training_saver.Saver(sharded=True,
  File ""/usr/local/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/supervised_session.py"", line 164, in _get_or_default
    op = default_constructor()
  File ""/usr/local/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/supervised_session.py"", line 153, in <lambda>
    max_to_keep=keep_checkpoint_max))
  File ""/usr/local/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 861, in __init__
    restore_sequentially=restore_sequentially)
  File ""/usr/local/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 515, in build
    filename_tensor, per_device, restore_sequentially, reshape)
  File ""/usr/local/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 312, in _AddShardedRestoreOps
    name=""restore_shard""))
  File ""/usr/local/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 272, in _AddRestoreOps
    values = self.restore_op(filename_tensor, vs, preferred_shard)
  File ""/usr/local/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 187, in restore_op
    preferred_shard=preferred_shard)
  File ""/usr/local/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/io_ops.py"", line 203, in _restore_slice
    preferred_shard, name=name)
  File ""/usr/local/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_io_ops.py"", line 359, in _restore_slice
    preferred_shard=preferred_shard, name=name)
  File ""/usr/local/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 703, in apply_op
    op_def=op_def)
  File ""/usr/local/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2310, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1232, in __init__
    self._traceback = _extract_stack()

```
"
3775,reduce_mean is not numerically accurate on GPU,"For smaller size matrix tf.reduce_mean works fine. 
But for larger size matrix floating point results are not accurate.

I am running on CUDA 7.0, Titan X.

``` python
import tensorflow as tf

mat3 = tf.get_variable(""mat3"", [4500,4500], initializer=tf.constant_initializer(-1.))
reduce_mat3_ref = tf.reduce_mean(mat3)
with tf.Session('') as sess:
    tf.initialize_all_variables().run()
    reduce1 = sess.run(reduce_mat3_ref)
    print(reduce1) # on CPU this is -1.0, on GPU this produces -1.00006
    assert(reduce1 == -1.) 
```
"
3771,Please consolidate the builder API's,"In my opinion, a simple builder API is essential to TensorFlow programming because the procedure of constructing Neural Networks is otherwise complicated, repetitive and error-prone. But there are at least 5 different builder API's being developed in parallel:
- tf.contrib.layers
  https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/layers
- tf.contrib.slim
  https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim
- tf.contrib.learn (aka. TF Learn)
  https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/learn/python/learn
- TF Learn (same name, but apparently different from the above):
  https://github.com/tflearn/tflearn
- Pretty Tensor
  https://github.com/google/prettytensor

All of these add-on packages seem to be more or less in the early stages of development and lacking good documentation. But the API's appear to be very similar. So why not consolidate them into a single builder API that can become an integrated part of TensorFlow? It is very confusing for new users the way it is done now, and the development would get much further if people would work on a single builder API rather than 5 almost identical ones. The builder API is how most people will use TensorFlow so it shouldn't be in limbo like this.

Furthermore, I'm trying to put together some tutorials on YouTube, but I'm concerned that the API I'm using (Pretty Tensor) might become deprecated at some point.

I hope that a consolidated and official builder API will receive more attention from the dev-team. 

Thanks!
"
3769,Assigning Multiple Embeddings per Word in Tensorflow,"I am trying to reproduce the results described in the EMNLP 2014 paper ""Efficient Non-parametric Estimation of Multiple Embeddings per Word in Vector Space"". The authors proposed a way of handling multiple senses per word through the use of multiple embeddings associated with it. Each word is assigned a global context embedding and several sense-specific embeddings, and which sense the word belongs to in the current context is determined by the argmax index of the cosine similarity between the target word's sense-specific embeddings and the average of the global vectors in the context window.

While the authors have made their Scala code publicly available on their website, I have found no similar implementations with a high level deep learning library like Tensorflow. Since I am new to Tensorflow, I am not sure whether such model can be built with the Python API. My main concern is how one can use the argmax operation as an intermediate layer in Tensorflow, and then to decide which embedding to use in the following layers. In addition, as each word might have different number of senses, is there an efficient way to handle this using embedding_lookup?

Does anyone have ideas?

Regards,
Zenong
"
3768,TF_OperationOpType,"Hi,

`TF_Node` [has been renamed](https://github.com/tensorflow/tensorflow/commit/b2c21f7e15cb61d2b1b2ca4154b1da45662f4747) to `TF_Operation`, which involved changing the names of a lot of functions. In particular, `TF_NodeOpType` has been changed to `TF_OperationOpType`. Before it’s been released, I just want to confirm that `Op` in `TF_OperationOpType` is not redundant. Thanks!

Regards,
Ivan
"
3767,Incorrect Hessian of the tf.nn.sigmoid function,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System: Linux 3.13.0-85-generic #129-Ubuntu SMP Thu Mar 17 20:50:15 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
-rw-r--r-- 1 root root 322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root     16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root     19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root 383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root 720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a

If installed from binary pip package, provide:
1. Which pip package you installed.
   tensorflow
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   0.10.0rc0

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`
### Steps to reproduce

I am trying to evaluate hessian of a logistic function via the following program.

```
# x = 1
# logistic(x) = 0.7310585786300049
# gradient(x) = logistic(x) * (1 - logistic(x)) = 0.19661193324148185
# hessian(x) = logistic(x) * (1 - logistic(x)) ^ 2 + -logistic(x) * (1 - logistic(x)) * logistic(x) = -0.09085774767294841
import tensorflow as tf

x = tf.Variable(1, name='x', dtype=tf.float32)
#logistic = 1. / (1 + tf.exp(-x))
logistic = tf.nn.sigmoid(x, name='logistic')

gradient = tf.gradients(logistic, x, name='gradient')[0]
hessian = tf.gradients(gradient, x, name='hessian')[0]

sess = tf.Session()
sess.run(tf.initialize_all_variables())
print(sess.run([logistic, gradient, hessian]))
```

I directly run the program, it produce the wrong result. 

`TypeError: Fetch argument None of None has invalid type <type 'NoneType'>, must be a string or Tensor`

It seems that `hessian` is `None`.

However, if I write the logistic function manually `logistic = 1. / (1 + tf.exp(-x))`, it produces the correct result.  `[0.7310586, 0.19661197, -0.090857767]`
### What have you tried?

1.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
3766,Tensorflow distributed RNN crashed on ProtoBuf when using 3*512 rnn. ,"### Environment info

Operating System:
Linux XNLPEXP2 4.4.0-24-generic #43-Ubuntu SMP Wed Jun 8 19:27:37 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux
Azure VM 8 cores, 56GB memory

If installed from binary pip package, provide:
pip 8.1.2 from /home/xubixiong/.local/lib/python2.7/site-packages (python 2.7)
0.10.0rc0
### Steps to reproduce
1. Create 2_PS + 2_worker, 
2. Try 3 \* 512 RNN, (I changed some code in rnn/translate to make it distributed), worker0 will 100% crash on some code related to TensorBuf and run global_step, the stack is at the end of this post, same everytime
3. Smaller the RNN, make it 1*128, it works fine. 
### What have you tried?
1.  tensorflow.python.framework.errors.UnavailableError is said to not used in the document. 
2. The crashing line is TensorBuffer\* buf = tensorflow::TensorCApi::Buffer(src); in tensorflow/core/client/tensor_c_api.cc:
3. I try to smaller the RNN size and layers, then there is no problem. 
4. Is it a known issue, I did find some issue relating to TensorBuf, but not the exactly same case. 
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
E tensorflow/core/client/tensor_c_api.cc:485]
Traceback (most recent call last):
  File ""/home/xubixiong/soulmate/intent_trainer/rnn/translate/translate.py"", line 346, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""/home/xubixiong/soulmate/intent_trainer/rnn/translate/translate.py"", line 343, in main
    train()
  File ""/home/xubixiong/soulmate/intent_trainer/rnn/translate/translate.py"", line 215, in train
    with sv.managed_session(server.target, config=sess_config) as sess:
  File ""/usr/lib/python2.7/contextlib.py"", line 17, in **enter**
    return self.gen.next()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py"", line 942, in managed_session
    self.stop(close_summary_writer=close_summary_writer)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py"", line 768, in stop
    stop_grace_period_secs=self._stop_grace_secs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/coordinator.py"", line 357, in join
    six.reraise(*self._exc_info_to_raise)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py"", line 931, in managed_session
    start_standard_services=start_standard_services)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py"", line 683, in prepare_or_wait_for_session
    self.start_standard_services(sess)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py"", line 624, in start_standard_services
    current_step = training_util.global_step(sess, self._global_step)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/training_util.py"", line 50, in global_step
    return int(sess.run(global_step_tensor))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 382, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 655, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 723, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 743, in _do_call    raise type(e)(node_def, op, message)tensorflow.python.framework.errors.UnavailableError
"
3765,Don't know if tensorflow supports this type of restoring a model.,"I am new here so I have a basic question. I want to train a cnn for 20000 steps. In the 100th step I want to save all variables and after that I want to re-run my code restoring model and starting from the 101- step. I am trying to make it work with tensorflow documentation: https://www.tensorflow.org/versions/r0.10/how_tos/variables/index.html
but I don't know if I am right. When I re-run my code I don't initialize again variables because I run saver.restore and according to my accuracy it works. I achieve big accuracy from the beginning so I think model is restored. Although, I would like to start the loop from the 101 - step. So:
1st question: Am I saving and restoring in the right way?
2nd question: How can I start from the 101-step when re-running?
"
3764,iOS: No OpKernel was registered to support Op 'RandomShuffleQueue' with these attrs,"I am trying to load the simple trained model, but I am facing the following issue:

```
No OpKernel was registered to support Op 'RandomShuffleQueue' with these attrs

[[Node: shuffle_batch_1/random_shuffle_queue = RandomShuffleQueue[capacity=1003, 
component_types=[DT_FLOAT, DT_FLOAT, DT_FLOAT], container="""", min_after_dequeue=1000,
seed=0, seed2=0, shapes=[[227,227,3], [10], [18]], shared_name=""""]()]]
```

Thanks,
"
3763,contrib.learn.LinearClassifier steps not working as tutorial instructs,"In tutorial it is written

classifier.fit(x=x_train, y=y_train, steps=200)
The state of the model is preserved in the classifier, which means you can train iteratively if you like. For example, the above is equivalent to the following:
classifier.fit(x=x_train, y=y_train, steps=100)
classifier.fit(x=x_train, y=y_train, steps=100)

But whne I try on my own, the same step parameter and evaluate the model, the results are all the time the same, only when I increase the parameter, the accuracy changes. Based on the behavior I believe the steps are rememebered and only new steps are fitted/performed.
So the equivalent is
classifier.fit(x=x_train, y=y_train, steps=100)
classifier.fit(x=x_train, y=y_train, steps=200)

Can anybody check this?
"
3762,"PS is bound in GPU:0 by default, we can't change!","I modified the seq2seq , mnist_replica and ptb model into distributed training model. But all of them have the same problem, that is when I start the server and `server.join()` the ps. The ps was bound in GPU:0 by default, and I can't change the setting. I follow the tutorial of distributed tensorflow [here](https://www.tensorflow.org/versions/r0.10/how_tos/distributed/index.html#putting-it-all-together-example-trainer-program). 
This is part of my translate.py :

```
def train():

  # set distributed configs
  ps_hosts = [""9.91.9.130:2222""]
  worker_hosts = [""9.91.9.130:2223"", ""9.91.9.130:2224""]
  #worker_hosts = [""9.91.9.130:2223""]

  cluster = tf.train.ClusterSpec({""ps"":ps_hosts, ""worker"":worker_hosts})
  server = tf.train.Server(cluster,
                            job_name=FLAGS.job_name,
                            task_index=FLAGS.task_index)
  if FLAGS.job_name == ""ps"":
        server.join()
  elif FLAGS.job_name == ""worker"":
      # Worker server 
      is_chief = (FLAGS.task_index == 0)      
      gpu_num = FLAGS.task_index + 1
      #with tf.Graph().as_default():
      with tf.device(tf.train.replica_device_setter(cluster=cluster,
          worker_device=""/job:worker/task:%d/gpu:%d"" % (FLAGS.task_index, gpu_num))):
      #with tf.device(""/gpu:%d"" % FLAGS.task_index):
          """"""Train a en->fr translation model using WMT data.""""""
```

This is the GPU info:

```
Fri Aug 12 09:17:07 2016
+------------------------------------------------------+
| NVIDIA-SMI 352.39     Driver Version: 352.39         |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K80           On   | 0000:06:00.0     Off |                    0 |
| N/A   67C    P0    63W / 149W |  11099MiB / 11519MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla K80           On   | 0000:07:00.0     Off |                    0 |
| N/A   45C    P0    72W / 149W |  10986MiB / 11519MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  Tesla K80           On   | 0000:85:00.0     Off |                    0 |
| N/A   76C    P0    66W / 149W |  11049MiB / 11519MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  Tesla K80           On   | 0000:86:00.0     Off |                    0 |
| N/A   57C    P0    75W / 149W |    223MiB / 11519MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0      9198    C   python                                       10940MiB |
|    0     29865    C   python                                          64MiB |
|    0     29961    C   python                                          64MiB |
|    1      9198    C   python                                          64MiB |
|    1     29865    C   python                                          64MiB |
|    1     29961    C   python                                       10827MiB |
|    2      9198    C   python                                          64MiB |
|    2     29865    C   python                                       10891MiB |
|    2     29961    C   python                                          64MiB |
|    3      9198    C   python                                          64MiB |
|    3     29865    C   python                                          64MiB |
|    3     29961    C   python                                          64MiB |
+-----------------------------------------------------------------------------+
```

As you can see, the pid 9198 is the `ps server` process, cause it occupied the GPU:0, I have to bind the `worker server` in GPU:1 and GPU:2.
Could we add a function or API to set the `ps server device` by configuration or arguments?
"
3760,Ubuntu 16.04 / Gpu 1080 Version compile Error (Tensorflow installation),"Hello, I recently got a new machine gpu 1080 and I did follow most of instructions via http://textminingonline.com/dive-into-tensorflow-part-iii-gtx-1080-ubuntu16-04-cuda8-0-cudnn5-0-tensorflow.
Anyone successfully installed Ubuntu 16.04 GPU with that version?? Let me know

But the Issue is it doesn't let me complie via bazel.

The following code...

ERROR: /home/ryan/git_ryan/tensorflow/tensorflow/core/kernels/BUILD:1655:1: undeclared inclusion(s) in rule '//tensorflow/core/kernels:dense_update_ops_gpu':
this rule is missing dependency declarations for the following files included by 'tensorflow/core/kernels/dense_update_ops_gpu.cu.cc':
  '/usr/local/cuda-8.0/include/cuda_runtime.h'
  '/usr/local/cuda-8.0/include/host_config.h'
  '/usr/local/cuda-8.0/include/builtin_types.h'
  '/usr/local/cuda-8.0/include/device_types.h'
  '/usr/local/cuda-8.0/include/host_defines.h'
  '/usr/local/cuda-8.0/include/driver_types.h'
  '/usr/local/cuda-8.0/include/surface_types.h'
  '/usr/local/cuda-8.0/include/texture_types.h'
  '/usr/local/cuda-8.0/include/vector_types.h'
  '/usr/local/cuda-8.0/include/library_types.h'
  '/usr/local/cuda-8.0/include/channel_descriptor.h'
  '/usr/local/cuda-8.0/include/cuda_runtime_api.h'
  '/usr/local/cuda-8.0/include/cuda_device_runtime_api.h'
  '/usr/local/cuda-8.0/include/driver_functions.h'
  '/usr/local/cuda-8.0/include/vector_functions.h'
  '/usr/local/cuda-8.0/include/vector_functions.hpp'
  '/usr/local/cuda-8.0/include/common_functions.h'
  '/usr/local/cuda-8.0/include/math_functions.h'
  '/usr/local/cuda-8.0/include/math_functions.hpp'
  '/usr/local/cuda-8.0/include/math_functions_dbl_ptx3.h'
  '/usr/local/cuda-8.0/include/math_functions_dbl_ptx3.hpp'
  '/usr/local/cuda-8.0/include/cuda_surface_types.h'
  '/usr/local/cuda-8.0/include/cuda_texture_types.h'
  '/usr/local/cuda-8.0/include/device_functions.h'
  '/usr/local/cuda-8.0/include/device_functions.hpp'
  '/usr/local/cuda-8.0/include/device_atomic_functions.h'
  '/usr/local/cuda-8.0/include/device_atomic_functions.hpp'
  '/usr/local/cuda-8.0/include/device_double_functions.h'
  '/usr/local/cuda-8.0/include/device_double_functions.hpp'
  '/usr/local/cuda-8.0/include/sm_20_atomic_functions.h'
  '/usr/local/cuda-8.0/include/sm_20_atomic_functions.hpp'
  '/usr/local/cuda-8.0/include/sm_32_atomic_functions.h'
  '/usr/local/cuda-8.0/include/sm_32_atomic_functions.hpp'
  '/usr/local/cuda-8.0/include/sm_35_atomic_functions.h'
  '/usr/local/cuda-8.0/include/sm_60_atomic_functions.h'
  '/usr/local/cuda-8.0/include/sm_60_atomic_functions.hpp'
  '/usr/local/cuda-8.0/include/sm_20_intrinsics.h'
  '/usr/local/cuda-8.0/include/sm_20_intrinsics.hpp'
  '/usr/local/cuda-8.0/include/sm_30_intrinsics.h'
  '/usr/local/cuda-8.0/include/sm_30_intrinsics.hpp'
  '/usr/local/cuda-8.0/include/sm_32_intrinsics.h'
  '/usr/local/cuda-8.0/include/sm_32_intrinsics.hpp'
  '/usr/local/cuda-8.0/include/sm_35_intrinsics.h'
  '/usr/local/cuda-8.0/include/surface_functions.h'
  '/usr/local/cuda-8.0/include/texture_fetch_functions.h'
  '/usr/local/cuda-8.0/include/texture_indirect_functions.h'
  '/usr/local/cuda-8.0/include/surface_indirect_functions.h'
  '/usr/local/cuda-8.0/include/device_launch_parameters.h'
  '/usr/local/cuda-8.0/include/cuda_fp16.h'
  '/usr/local/cuda-8.0/include/math_constants.h'
  '/usr/local/cuda-8.0/include/curand_kernel.h'
  '/usr/local/cuda-8.0/include/curand.h'
  '/usr/local/cuda-8.0/include/curand_discrete.h'
  '/usr/local/cuda-8.0/include/curand_precalc.h'
  '/usr/local/cuda-8.0/include/curand_mrg32k3a.h'
  '/usr/local/cuda-8.0/include/curand_mtgp32_kernel.h'
  '/usr/local/cuda-8.0/include/cuda.h'
  '/usr/local/cuda-8.0/include/curand_mtgp32.h'
  '/usr/local/cuda-8.0/include/curand_philox4x32_x.h'
  '/usr/local/cuda-8.0/include/curand_globals.h'
  '/usr/local/cuda-8.0/include/curand_uniform.h'
  '/usr/local/cuda-8.0/include/curand_normal.h'
  '/usr/local/cuda-8.0/include/curand_normal_static.h'
  '/usr/local/cuda-8.0/include/curand_lognormal.h'
  '/usr/local/cuda-8.0/include/curand_poisson.h'
  '/usr/local/cuda-8.0/include/curand_discrete2.h'.
nvcc warning : option '--relaxed-constexpr' has been deprecated and replaced by option '--expt-relaxed-constexpr'.
nvcc warning : option '--relaxed-constexpr' has been deprecated and replaced by option '--expt-relaxed-constexpr'.
Target //tensorflow/cc:tutorials_example_trainer failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 50.107s, Critical Path: 49.88s

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System: Linux 64bit / GPU 1080

Installed version of CUDA and cuDNN:  Cuda 8 / cuDNN: 8.0
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
"
3759,LSTMFusedCell ops only running on CPU,"Operating System: Ubuntu 14.04

Installed version of CUDA and cuDNN: 8.0.27 and v5
394472 Jul 26 13:26 /usr/local/cuda/lib64/libcudart.so.8.0.27
78065952 Jul 26 13:33 /usr/local/cuda/lib64/libcudnn.so.5.0.5
1. TF commit : c5f94b10bbb30e525fa3ca313e7ccb173040c90a
2. bazel version :  0.3.0

We switched over a working Seq2Seq model to use the LSTMFusedCell (previously GRUCell).  The graph build is a lot faster, but the step times are slower.

By profiling the ops (using timeline to generate a chrome trace file) we discovered that most of the processing was occurring on the GPU, as specified, but the LSTMFusedCell ops were all running on the CPU.

There may be a known issue, as referenced by @wchan in #2002  - however that PR is closed.
"
3754,Unresolved RNN performance issue,"My previous issue was closed without resolution: https://github.com/tensorflow/tensorflow/issues/3738#issuecomment-239050102

The tf RNN approach of running up to the maximum length seems to be fundamentally flawed compared to the pycnn approach. 

Even when only calling the LSTM cell on the relevant steps like below the performance issue persists:

```
flat_state = nest.flatten(state)
    flat_zero_output = nest.flatten(zero_output)

    def select_relevant_state(state, mask):
        c = tf.boolean_mask(state[0], mask)
        h = tf.boolean_mask(state[1], mask)
        return (c, h)

    # Function to Perform at Each Time Step
    def time_step(time, output_ta, state):

        mask = (time < sequence_length)
        indices = tf.squeeze(tf.to_int32(tf.where(mask)))
        invert_indices = tf.squeeze(tf.to_int32(tf.where(invert_mask)))
        invert_indices = tf.to_int32(tf.where(invert_mask))
        input_t = tuple(ta.read(time) for ta in input_ta)

        # Restore Shape Information
        for input_, shape in zip(input_t, inputs_got_shape):
            input_.set_shape(shape[1:])

        input_t = nest.pack_sequence_as(structure=inputs, flat_sequence=input_t)

        # Select Only Relevant at This Time Step
        input_t = tf.boolean_mask(input_t, mask)
        state = select_relevant_state(state, mask)
        call_cell = lambda: cell(input_t, state)

        # Call Cell
        (output, new_state) = call_cell()

        # Fill Unprocessed Steps
        filler_output = tf.boolean_mask(zero_output, invert_mask)
        filler_state = select_relevant_state(state, invert_mask)

        output = tf.dynamic_stitch([indices, invert_indices], [output, filler_output])
        new_state_c = tf.dynamic_stitch([indices, invert_indices], [new_state[0], filler_state[0]])
        new_state_h = tf.dynamic_stitch([indices, invert_indices], [new_state[1], filler_state[1]])
        new_state = tf.pack([new_state_c, new_state_h], axis=0)

        # Pack State if Using State Tuples
        output = nest.flatten(output)

        output_ta = tuple(ta.write(time, out) for ta, out in zip(output_ta, output))

        return (time + 1, output_ta, new_state)
```

Bucketing is not a reasonable approach in this situation as a LSTM is applied to each token and then a higher level LSTM is applied across combined word and character embeddings for actual tagging. This means that the only available inputs at each training step are the tokens in the sentence and therefore bucketing is not possible.
"
3752,Error: OK vs. Unimplemented: Explict cast of a non-empty tensor not implemented yet,"```
bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so.8.0 locally
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: GeForce GTX 980
major: 5 minor: 2 memoryClockRate (GHz) 1.367
pciBusID 0000:01:00.0
Total memory: 3.95GiB
Free memory: 3.33GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:866] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980, pci bus id: 0000:01:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:866] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980, pci bus id: 0000:01:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:866] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980, pci bus id: 0000:01:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:866] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980, pci bus id: 0000:01:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:866] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980, pci bus id: 0000:01:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:866] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980, pci bus id: 0000:01:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:866] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980, pci bus id: 0000:01:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:866] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980, pci bus id: 0000:01:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:866] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980, pci bus id: 0000:01:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:866] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980, pci bus id: 0000:01:00.0)
F tensorflow/cc/tutorials/example_trainer.cc:80] Check failed: ::tensorflow::Status::OK() == (root.ToGraphDef(&def)) (OK vs. Unimplemented: Explict cast of a non-empty tensor not implemented yet)
F tensorflow/cc/tutorials/example_trainer.cc:80] Check failed: ::tensorflow::Status::OK() == (root.ToGraphDef(&def)) (OK vs. Unimplemented: Explict cast of a non-empty tensor not implemented yet)
Abort (core dumped)
```
### Environment info

Operating System: Ubuntu 16.04 
Cuda Toolkit 8.0 and cudnn 5 
Driver Version: 361.77 

ls -l /usr/local/cuda/lib64/libcud*
-rw-r--r-- 1 root root   560184 Mai 18 21:44 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Mai 18 21:47 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root       19 Mai 18 21:47 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.27
-rw-r--r-- 1 root root   394472 Mai 18 21:44 /usr/local/cuda/lib64/libcudart.so.8.0.27
-rw-r--r-- 1 root root   737516 Mai 18 21:44 /usr/local/cuda/lib64/libcudart_static.a
-rwxr-xr-x 1 root root 78065952 Ago 11 06:26 /usr/local/cuda/lib64/libcudnn.so
-rwxr-xr-x 1 root root 78065952 Ago 11 06:26 /usr/local/cuda/lib64/libcudnn.so.5
-rwxr-xr-x 1 root root 78065952 Ago 11 06:26 /usr/local/cuda/lib64/libcudnn.so.5.0.5
-rw-r--r-- 1 root root 68709594 Ago 11 06:26 /usr/local/cuda/lib64/libcudnn_static.a
"
3751,Grid3LSTMCell running out of memory ,"Here are my specs:
- NVIDIA GTX 1070
- Tensorflow from source (bazel 0.3.0)
- CUDA 8.0
- Cudnn 5

I am trying to implement a 3D Grid LSTM network. My network is actually a CNN-LSTM end-to-end system, but I know that the `Grid3LSTMCell` is what is causing the issue (I have tested without and it functions fine). 

Typically this would be an appropriate SO post, but I think I have exhausted my GPU options so maybe this is a bug in the `GridRNNCell` itself. I have included... 

```
# Initializing the variables
with tf.name_scope(""initialize-and-config"") as scope:
    init = tf.initialize_all_variables()
    saver = tf.train.Saver()
    #gpu_options = tf.GPUOptions()
    #config = tf.ConfigProto(gpu_options=gpu_options)
    config = tf.ConfigProto()
    config.gpu_options.allow_growth = True
    #config.gpu_options.per_process_gpu_memory_fraction = 0.1

# Launch the graph
with tf.Session(config=config) as sess:
```

I commented out `config.gpu_options.per_process_gpu_memory_fraction = 0.1` because I have tried including it. I have tried excluding `config.gpu_options.allow_growth` and including `config.gpu_options.per_process_gpu_memory_fraction = 0.1`. I have tried different fraction values. And I have tried including both GPU options

I have also tried finalizing the graph before `sess.run()` by using `tf.get_default_graph().finalize()`

I should note that the RNN initialization step alone takes roughly 10 minutes to intialize -- `outputs, states = rnn.rnn(lstm_cell, x, dtype=tf.float32)`.

I am able to run the network on a cropped image of size 20x20, but when I train the network on the full 396x396 image I get the following...

```
 totalling 86.14MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 301086720 totalling 287.14MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] Sum Total of in-use chunks: 6.57GiB
I tensorflow/core/common_runtime/bfc_allocator.cc:698] Stats: 
Limit:                  7531433165
InUse:                  7054675456
MaxInUse:               7054689536
NumAllocs:                  369387
MaxAllocSize:            301086720

W tensorflow/core/common_runtime/bfc_allocator.cc:270] ****************************************************************************************************
W tensorflow/core/common_runtime/bfc_allocator.cc:271] Ran out of memory trying to allocate 768.0KiB.  See logs for memory state.
W tensorflow/core/framework/op_kernel.cc:940] Resource exhausted: OOM when allocating tensor with shape[384,512]
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=140010 evicted_count=140000 eviction_rate=0.999929 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=150010 evicted_count=150000 eviction_rate=0.999933 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=160010 evicted_count=160000 eviction_rate=0.999938 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=170010 evicted_count=170000 eviction_rate=0.999941 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=180010 evicted_count=180000 eviction_rate=0.999944 and unsatisfied allocation rate=0
Traceback (most recent call last):
  File ""3D-CNN-LSTM-reg.py"", line 225, in <module>
    keep_prob: dropout})
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 710, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 908, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 958, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 978, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.ResourceExhaustedError: OOM when allocating tensor with shape[396,128]
     [[Node: opt/gradients/net/RNN/Grid3LSTMCell_537/MatMul_1_grad/MatMul_1 = MatMul[T=DT_FLOAT, transpose_a=true, transpose_b=false, _device=""/job:localhost/replica:0/task:0/gpu:0""](net/RNN/Grid3LSTMCell_537/split, opt/gradients/net/RNN/Grid3LSTMCell_537/concat_4_grad/tuple/control_dependency)]]
Caused by op u'opt/gradients/net/RNN/Grid3LSTMCell_537/MatMul_1_grad/MatMul_1', defined at:
  File ""3D-CNN-LSTM-reg.py"", line 191, in <module>
    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py"", line 196, in minimize
    grad_loss=grad_loss)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py"", line 253, in compute_gradients
    colocate_gradients_with_ops=colocate_gradients_with_ops)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients.py"", line 476, in gradients
    in_grads = _AsList(grad_fn(op, *out_grads))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_grad.py"", line 637, in _MatMulGrad
    math_ops.matmul(op.inputs[0], grad, transpose_a=True))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py"", line 1352, in matmul
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py"", line 1296, in _mat_mul
    transpose_b=transpose_b, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 703, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2317, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1239, in __init__
    self._traceback = _extract_stack()

...which was originally created as op u'net/RNN/Grid3LSTMCell_537/MatMul_1', defined at:
  File ""3D-CNN-LSTM-reg.py"", line 176, in <module>
    pred = conv_net(x, weights, biases, keep_prob)
  File ""3D-CNN-LSTM-reg.py"", line 135, in conv_net
    outputs, states = rnn.rnn(lstm_cell, x, dtype=tf.float32)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py"", line 219, in rnn
    (output, state) = call_cell()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py"", line 206, in <lambda>
    call_cell = lambda: cell(input_, state)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/grid_rnn/python/ops/grid_rnn_cell.py"", line 150, in __call__
    c_prev[j] = math_ops.matmul(input_splits[i], input_project_c)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py"", line 1352, in matmul
    name=name)
```

The full code is as follows...

```

#Kendall Weihe
#This is a CNN that handles 3D data
#Adjust network parameters below, also adjust data directory

import tensorflow as tf
import pdb
import numpy as np
from numpy import genfromtxt
from PIL import Image
from tensorflow.python.ops import rnn, rnn_cell
from tensorflow.contrib.grid_rnn.python.ops import grid_rnn_cell
from tensorflow.tensorflow.scroll import scroll_data

# Parameters
learning_rate = 0.001
training_iters = 1000000
batch_size = 3
display_step = 1

# Network Parameters
n_input_x = 396 # Input image x-dimension
n_input_y = 396 # Input image y-dimension
n_input_z = 5
n_hidden = 128
n_classes = 2 # Binary classification -- on a surface or not
n_output = n_input_x * n_classes

dropout = 0.75 # Dropout, probability to keep units

# tf Graph input
x = tf.placeholder(tf.float32, [batch_size, n_input_z, n_input_x, n_input_y])
temp_x = tf.placeholder(tf.float32, [1, n_input_z, n_input_x, n_input_y])
y = tf.placeholder(tf.float32, [batch_size, n_input_z, n_input_x, n_input_y, n_classes], name=""ground_truth"")
keep_prob = tf.placeholder(tf.float32) #dropout (keep probability)

# This function converts the ground truth data into a
    #2 channel classification -- n_input_x x n_input_y x 2
    # one layer for 0's and the other for 1's
def convert_to_2_channel(x):
    #assume input has dimension (batch_size,x,y)
    #output will have dimension (batch_size,x,y,2)
    output = np.empty((batch_size, n_input_z, n_input_x, n_input_y, n_classes))
    for i in range(batch_size):
        for j in range(n_input_z):
            for k in range(n_input_x):
                for l in range(n_input_y):
                    for m in range(n_classes):
                        if m == 0:
                            output[i][j][k][l][m] = x[i][j][k][l]
                        else:
                            output[i][j][k][l][m] = 1 - x[i][j][k][l]

    return output


# Create some wrappers for simplicity
def conv3d(x, W, b, strides=1):
    # Conv2D wrapper, with bias and relu activation
    x = tf.nn.conv3d(x, W, strides=[1, strides, strides, strides, 1], padding='SAME')
    x = tf.nn.bias_add(x, b)
    return tf.nn.relu(x)

def maxpool3d(x, k=2):
    # MaxPool2D wrapper
    return tf.nn.max_pool3d(x, ksize=[1, k, k, k, 1], strides=[1, k, k, k, 1],
                          padding='SAME')

def deconv3d(prev_layer, w, b, output_shape, strides):
    # Deconv layer
    deconv = tf.nn.conv3d_transpose(prev_layer, w, output_shape=output_shape, strides=strides, padding=""VALID"")
    deconv = tf.nn.bias_add(deconv, b)
    deconv = tf.nn.relu(deconv)
    return deconv

# Create model
def conv_net(x, weights, biases, dropout):
    # Reshape input picture
    x = tf.reshape(x, shape=[batch_size, n_input_z, n_input_x, n_input_y, 1])

    with tf.name_scope(""conv1"") as scope:
    # Convolution Layer
        conv1 = conv3d(x, weights['wc1'], biases['bc1'])
        # Max Pooling (down-sampling)
        #conv1 = tf.nn.local_response_normalization(conv1)
        conv1 = maxpool3d(conv1, k=2)

    # Convolution Layer
    with tf.name_scope(""conv2"") as scope:
        conv2 = conv3d(conv1, weights['wc2'], biases['bc2'])
        # Max Pooling (down-sampling)
        # conv2 = tf.nn.local_response_normalization(conv2)
        conv2 = maxpool3d(conv2, k=2)

    # Convolution Layer
    with tf.name_scope(""conv3"") as scope:
        conv3 = conv3d(conv2, weights['wc3'], biases['bc3'])
        # Max Pooling (down-sampling)
        # conv3 = tf.nn.local_response_normalization(conv3)
        conv3 = maxpool3d(conv3, k=2)

    # pdb.set_trace()

    temp_batch_size = tf.shape(x)[0] #batch_size shape
    with tf.name_scope(""deconv1"") as scope:
        output_shape = [temp_batch_size, 2, n_input_x / 4, n_input_y / 4, 64]
        strides = [1,2,2,2,1]
        #conv4 = deconv3d(conv3, weights['wdc1'], biases['bdc1'], output_shape, strides)
        # conv4 = tf.nn.local_response_normalization(conv4)
        conv4 = tf.nn.conv3d_transpose(conv3, weights['wdc1'], output_shape=output_shape, strides=strides, padding=""SAME"")
        conv4 = tf.nn.bias_add(conv4, biases['bdc1'])
        conv4 = tf.nn.relu(conv4)

    with tf.name_scope(""deconv2"") as scope:
        output_shape = [temp_batch_size, 3, n_input_x / 2, n_input_y / 2, 32]
        strides = [1,1,2,2,1]
        conv5 = deconv3d(conv4, weights['wdc2'], biases['bdc2'], output_shape, strides)
        # conv5 = tf.nn.local_response_normalization(conv5)

    with tf.name_scope(""deconv3"") as scope:
        output_shape = [temp_batch_size, 5, n_input_x, n_input_y, 1]
        #this time don't use ReLu -- since output layer
        conv6 = tf.nn.conv3d_transpose(conv5, weights['wdc3'], output_shape=output_shape, strides=[1,1,2,2,1], padding=""VALID"")
        x = tf.nn.bias_add(conv6, biases['bdc3'])
        x = tf.reshape(x, [batch_size, n_input_z, n_input_x, n_input_y])
        # conv6 = tf.nn.relu(conv6)

    # pdb.set_trace()

    x = tf.reshape(conv6, [batch_size * n_input_y * n_input_z, n_input_x])
    x = tf.split(0, n_input_y * n_input_z, x)

    lstm_cell = grid_rnn_cell.Grid3LSTMCell(n_hidden)

    outputs, states = rnn.rnn(lstm_cell, x, dtype=tf.float32)

    output = []
    for i in xrange(n_input_y * n_input_z):
        output.append(tf.matmul(outputs[i], lstm_weights[i]) + lstm_biases[i])

    return output

weights = {
    # 5x5 conv, 1 input, 32 outputs
    'wc1' : tf.Variable(tf.random_normal([5, 5, 5, 1, 32])),
    # 5x5 conv, 32 inputs, 64 outputs
    'wc2' : tf.Variable(tf.random_normal([3, 5, 5, 32, 64])),
    # 5x5 conv, 32 inputs, 64 outputs
    'wc3' : tf.Variable(tf.random_normal([2, 5, 5, 64, 128])),

    'wdc1' : tf.Variable(tf.random_normal([2, 2, 2, 64, 128])),

    'wdc2' : tf.Variable(tf.random_normal([2, 2, 2, 32, 64])),

    'wdc3' : tf.Variable(tf.random_normal([3, 2, 2, 1, 32])),
}

biases = {
    'bc1': tf.Variable(tf.random_normal([32])),
    'bc2': tf.Variable(tf.random_normal([64])),
    'bc3': tf.Variable(tf.random_normal([128])),
    'bdc1': tf.Variable(tf.random_normal([64])),
    'bdc2': tf.Variable(tf.random_normal([32])),
    'bdc3': tf.Variable(tf.random_normal([n_input_z])),
}

lstm_weights = {}
lstm_biases = {}

for i in xrange(n_input_y * n_input_z):
    lstm_weights[i] = tf.Variable(tf.random_normal([n_hidden, n_output]))
    lstm_biases[i] = tf.Variable(tf.random_normal([n_output]))

# Construct model
with tf.name_scope(""net"") as scope:
    pred = conv_net(x, weights, biases, keep_prob)
    # pdb.set_trace()
    pred = tf.transpose(tf.pack(pred),[1,0,2])
    pred = tf.reshape(pred, [-1, n_input_z, n_input_x, n_input_y, n_classes])

    # Define loss and optimizer
    # Reshape for cost function
    temp_pred = tf.reshape(pred, [-1, 2])
    temp_y = tf.reshape(y, [-1, 2])

with tf.name_scope(""loss"") as scope:
    # cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(pred, y))
    cost = (tf.nn.sigmoid_cross_entropy_with_logits(temp_pred, temp_y))

with tf.name_scope(""opt"") as scope:
    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)

# Evaluate model
with tf.name_scope(""acc"") as scope:
    # accuracy is the difference between prediction and ground truth matrices
    correct_pred = tf.equal(0,tf.cast(tf.sub(tf.nn.sigmoid(temp_pred),temp_y), tf.int32))
    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))

# Initializing the variables
with tf.name_scope(""initialize-and-config"") as scope:
    init = tf.initialize_all_variables()
    saver = tf.train.Saver()
    gpu_options = tf.GPUOptions()
    config = tf.ConfigProto(gpu_options=gpu_options)
    config.gpu_options.allow_growth = True
    #config.gpu_options.per_process_gpu_memory_fraction = 0.1

# Launch the graph
with tf.Session(config=config) as sess:
    sess.run(init)
    summary = tf.train.SummaryWriter('/tmp/logdir/', sess.graph) #initialize graph for tensorboard
    step = 1
1
    # Import data
    data = scroll_data.read_data('/home/volcart/Documents/Data/', 100, n_input_x, n_input_y)
    # Keep training until reach max iterations
    while step * batch_size < training_iters:
        batch_x, batch_y = data.train.next_batch(batch_size * n_input_z)
        # Run optimization op (backprop)
        batch_x = batch_x.reshape((batch_size, n_input_z, n_input_x, n_input_y))
        batch_y = batch_y.reshape((batch_size, n_input_z, n_input_x, n_input_y))
        batch_y = convert_to_2_channel(batch_y) # Converts the 3960x3960 ground truth to a 3960x3960x2 classification
        batch_y = batch_y.reshape(batch_size, n_input_z, n_input_x, n_input_y, n_classes)
        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y,
                                       keep_prob: dropout})

        step = step + 1
        if step % display_step == 0:
            batch_y = batch_y.reshape(batch_size, n_input_z, n_input_x, n_input_y, n_classes)
            loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,
                                                              y: batch_y,
                                                              keep_prob: 1.0})
            print ""Step = "" + str(step) + "" Accuracy = "" + str(acc)
            #print ""Loss = "" + str(loss)
            # Save network
            if step % 50 == 0:
                save_path = ""/home/volcart/Documents/3D-CNN-LSTM-reg-model/3D-CNN-LSTM-seg-step-"" + str(step) + ""-model.ckpt""
                saver.save(sess, save_path)
```
"
3750,TensorBoard doesn't show Events on TensorFlow v0.10 RC,"After a clean install of TensorFlow v0.10 (from `master`) my TensorBoard is suddenly broken. The scalar event plots do not show upon clicking (see screenshow below). While the logs in the terminal do not show any errors, the Chrome Developer console shows the following error upon opening a figure:

```
tf-tensorboard.html:1517 Uncaught Error: tf-chart-scaffold's content doesn't implement the required interfaceinsertBefore @ VM2478 polymer-mini.html:560
```

I am running Chrome Version 52.0.2743.116 (64-bit) on Linux Mint 17.

![TensorBoard](http://i.imgur.com/GnR46NL.png)
"
3749,error: can't copy 'tensorflow/python/ops/gen_sparse_ops.py': doesn't exist or not a regular file,"After I compiled the source code of TF0.10 (the latest version) using command ""bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package"", I tried to generate the .whl package using the following command:
""bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg""
However, errors occured:
Thu Aug 11 20:10:14 EDT 2016 : === Using tmpdir: /tmp/tmp.r1OX0vuucW
/tmp/tmp.r1OX0vuucW ~/bxl/tf1.0
Thu Aug 11 20:10:14 EDT 2016 : === Building wheel
error: can't copy 'tensorflow/python/ops/gen_sparse_ops.py': doesn't exist or not a regular file

Anyone knows how to solve this? Thx
"
3748,unexpected names in `NamedOutputs` tuples when using `outputs_collections` with some layers,"We are getting unexpected names (they lack outer name scope) in `NamedOutputs` tuples added to collections using `tf.contrib.layers` `outputs_collections`. The following code demonstrates the issue:

```
import tensorflow as tf
from tensorflow.contrib import slim


with tf.name_scope(""train""):
    with slim.arg_scope([slim.fully_connected, slim.flatten],
                        outputs_collections=tf.GraphKeys.ACTIVATIONS):
        ph = tf.placeholder(tf.float32, [2, 2])
        fc = slim.fully_connected(ph, 10)
        flat = slim.flatten(ph)

{print(""name in tuple: "", no.name, "", tensor name:"", no.outputs.name)
 for no in tf.get_collection(tf.GraphKeys.ACTIVATIONS)}
```

The output is:

```
name in tuple:  fully_connected , tensor name: train/fully_connected/Relu:0
name in tuple:  train/Flatten , tensor name: train/Flatten/Reshape:0
```

We have tracked the cause of this down in to `tf.contrib.layers`. For layers that use internal variables (fully_connected, conv2d, ...), final outputs are added to collections based on internal variable_scope name. Please see:

 tensorflow/tensorflow/contrib/layers/python/layers/layers.py lines 758, 835 (version 0.10, commit 1df3fb0b4ae5915364f09e233496e98a99a4a886)

It is our understanding that activation names generally fall under name_scopes, which is consistent with actual op names in the output above.

This issue makes it impossible to retrieve items from collections filtered down with a name scope, an approach that we are trying to use for decoupling op creation and summarizing. It seems a valid use-case.
"
3747,Segmentation fault when importing TensorFlow,"After installing TensorFlow 0.10.0rc0 with pip in a virtualenv
import tensorflow as tf
results in 
Segmentation fault (core dumped)

Importing numpy before tensorflow results in the same segfault

OS: RedHat 6, 64-bit
(Installed glibc 2.1.4 from source)
Python Version 3.4.5

pip packages (cpu versions):
tensorflow-0.10.0rc0-cp34-cp34m-linux_x86_64.whl
protobuf-3.0.0b2.post2-cp34-none-linux_x86_64.whl
six-1.10.0-py2.py3-none-any.whl
numpy-1.11.1-cp34-cp34m-manylinux1_x86_64.whl
(same problem with numpy-1.8.2-cp34-cp34m-manylinux1_x86_64.whl)

Debugger Output:
gdb python
run tf.py
(tf.py contains: import tensorflow as tf)

[Thread debugging using libthread_db enabled]
Missing separate debuginfo for /home/rolf/tfenv3/lib/python3.4/site-packages/numpy/core/../.libs/libgfortran-ed201abd.so.3.0.0
[New Thread 0x7ffff352a700 (LWP 2920)]
[New Thread 0x7ffff2b29700 (LWP 2921)]
[New Thread 0x7ffff0128700 (LWP 2922)]
[New Thread 0x7fffed727700 (LWP 2923)]
[New Thread 0x7fffead26700 (LWP 2924)]
[New Thread 0x7fffe8325700 (LWP 2925)]
[New Thread 0x7fffe5924700 (LWP 2926)]

Program received signal SIGSEGV, Segmentation fault.
0x00007ffff793878b in init_one_static_tls (map=0x0) at allocatestack.c:1171
1171      void *dest = (char *) curp - map->l_tls_offset;
Missing separate debuginfos, use: debuginfo-install bzip2-libs-1.0.5-7.el6_0.x86_64 glibc-2.12-1.192.el6.x86_64 keyutils-libs-1.4-5.el6.x86_64 krb5-libs-1.10.3-57.el6.x86_64 libcom_err-1.41.12-22.el6.x86_64 libselinux-2.0.94-7.el6.x86_64 openssl-1.0.1e-48.el6_8.1.x86_64 zlib-1.2.3-29.el6.x86_64
"
3746,underperformed test of inception-v3 retraining result,"Hello, I'am do the retraining of inceptionv3 following tensorflow official [tutorial](https://www.tensorflow.org/versions/master/how_tos/image_retraining/index.html). Everything goes fine and it gives a `output_graph.pb` finally, but when I test the `output_graph.pb` with `label_image` module, it gives me quite odd result like below. Even when I test it with the flower images provided by the tutorial, it performs oddly as well.

Did anyone meet with the same problem? or what did I miss? thanks a lot for any information.
### Environment info

ubuntu 1404LST
tensorflow 0.9.0-GPU
CUDA: 7.5
cuDNN: 5.0
GPU: tesla K40
### Logs or other output that would be helpful

```
Ubuntu:~/tensorflow$ bazel-bin/tensorflow/examples/label_image/label_image  --graph=tensorflow/examples/label_image/data/v3_retrained.pb   --output_layer=final_result  
W tensorflow/core/framework/op_def_util.cc:332] Op BatchNormWithGlobalNormalization is deprecated. It will cease to work in GraphDef version 9. Use tf.nn.batch_normalization().
I tensorflow/examples/label_image/main.cc:207] dummy (0): 0.387557
I tensorflow/examples/label_image/main.cc:207] Siberian husky (3): 0.255237
I tensorflow/examples/label_image/main.cc:207] kit fox (1): 0.254475
I tensorflow/examples/label_image/main.cc:207] Australian terrier (4): 0.059399
I tensorflow/examples/label_image/main.cc:207] English setter (2): 0.0433322

Ubuntu:~/tensorflow$ bazel-bin/tensorflow/examples/label_image/label_image  --graph=tensorflow/examples/label_image/data/v3_retrained.pb   --output_layer=final_result  --image=rose.jpg
W tensorflow/core/framework/op_def_util.cc:332] Op BatchNormWithGlobalNormalization is deprecated. It will cease to work in GraphDef version 9. Use tf.nn.batch_normalization().
I tensorflow/examples/label_image/main.cc:207] kit fox (1): 0.97847
I tensorflow/examples/label_image/main.cc:207] dummy (0): 0.0214963
I tensorflow/examples/label_image/main.cc:207] English setter (2): 1.68903e-05
I tensorflow/examples/label_image/main.cc:207] Siberian husky (3): 1.2378e-05
I tensorflow/examples/label_image/main.cc:207] Australian terrier (4): 4.45126e-06

Ubuntu:~/tensorflow$ bazel-bin/tensorflow/examples/label_image/label_image  --graph=tensorflow/examples/label_image/data/v3_retrained.pb   --output_layer=final_result  --image=daisy.jpg
W tensorflow/core/framework/op_def_util.cc:332] Op BatchNormWithGlobalNormalization is deprecated. It will cease to work in GraphDef version 9. Use tf.nn.batch_normalization().
I tensorflow/examples/label_image/main.cc:207] English setter (2): 0.903881
I tensorflow/examples/label_image/main.cc:207] Siberian husky (3): 0.0819594
I tensorflow/examples/label_image/main.cc:207] dummy (0): 0.00714857
I tensorflow/examples/label_image/main.cc:207] Australian terrier (4): 0.00495803
I tensorflow/examples/label_image/main.cc:207] kit fox (1): 0.00205291
```

FYI: the `v3_retrained.pb` is the `output_graph.pb` produced by retraining. and `rose, daisy` are two images I picked from flower_photos provided by the tutorial.
"
3745,Tensorflow and import IPython errors,"When I use a thread-based data queue in Tensorflow and also include `import IPython`, I get various errors thrown at the very end of the Tensorflow session. Since I am offering a ""solution"" (do not import IPython), I am fine closing this immediately and re-opening if necessary. I am filing this mostly to have these errors and the cause on file in case it happens to someone else.
### Environment info

64-bit CentOS / cuda 7.5.18 / cudnn 5.0.5 / bazel 0.2.1 / python 3.4.4 / ipython 4.0.3

Tensorflow installed from source: 83fe2a5b7328e1b754b53cbbcf9b313450a2f863
### Steps to reproduce
1. Create file `files.txt` (lines omitted): 
   
   ```
   file0
   file1
   ...
   file10
   ```
2. Create file `bug.py`
   
   ```
   import tensorflow as tf
   import IPython  # <-- remove and errors stop happening
   
   with tf.Session() as sess:
       filename_queue = tf.train.string_input_producer(['files.txt'], shuffle=True)
       reader = tf.TextLineReader()
       key, value = reader.read(filename_queue)
       batch_size = 3
       min_after_dequeue = 10
       capacity = min_after_dequeue + 3 * batch_size
       batch_fn = tf.train.shuffle_batch(
               [value], batch_size=batch_size, capacity=capacity,
               min_after_dequeue=min_after_dequeue)
   
       sess.run(tf.initialize_all_variables())
       coord = tf.train.Coordinator()
       threads = tf.train.start_queue_runners(sess=sess, coord=coord)
       try:
           while not coord.should_stop():
               print(sess.run(batch_fn))
               break
       except tf.errors.OutOfRangeError:
           pass
       finally:
           coord.request_stop()
       coord.join(threads)
   ```
3. Run `python bug.py` (repeatedly if no error occurs) 
### What have you tried?

Removing `import IPython` fixes it. I have only tested it on one platform, so I do not know if this is a universal problem.

Of course, this might also happen if packages that import IPython are imported. It originally happened to me when I imported ipdb.
### Errors

In the tradition of thread-related bugs, the error message is not deterministic and 100 runs breaks down as follows (I am being thorough here to make these searchable):

| Occurrences | Error |
| --- | --- |
| 35 | No error |
| 34 | Error 1 |
| 29 | Error 2 |
| 2 | Error 3 |

Investigating these errors further leads nowhere, since it is clear that Python is behaving erratically and variables that are clearly set one line can be corrupted the next.
#### Error 1

```
Exception ignored in: <bound method Session.__del__ of <tensorflow.python.client.session.Session object at 0x7f12d1d75908>>
Traceback (most recent call last):
  File ""/.../python3.4/site-packages/tensorflow/python/client/session.py"", line 524, in __del__
AttributeError: 'NoneType' object has no attribute 'raise_exception_on_not_ok_status'
```
#### Error 2

```
Exception ignored in: <bound method Session.__del__ of <tensorflow.python.client.session.Session object at 0x7fde89961908>>
Traceback (most recent call last):
  File ""/.../python3.4/site-packages/tensorflow/python/client/session.py"", line 524, in __del__
  File ""/share/data/vision-greg/common/anaconda3/lib/python3.4/contextlib.py"", line 126, in helper
TypeError: 'NoneType' object is not callable
```
#### Error 3

```
Exception ignored in: <bound method Session.__del__ of <tensorflow.python.client.session.Session object at 0x7feec524b908>>
Traceback (most recent call last):
  File ""/.../python3.4/site-packages/tensorflow/python/client/session.py"", line 524, in __del__
  File ""/share/data/vision-greg/common/anaconda3/lib/python3.4/contextlib.py"", line 59, in __enter__
  File ""/.../python3.4/site-packages/tensorflow/python/framework/errors.py"", line 452, in raise_exception_on_not_ok_status
UnboundLocalError: local variable 'status' referenced before assignment
```
"
3743,Bazel missing dependency declaration for Eigen,"Compilation error that suggests Bazel is not recognizing the Eigen header files. Occurs consistently for me on all versions starting from 21716d8f6e175cd6e8cd97a84e48497574268b0c up until the current master (00726750c9f7dedfc57685c5011e21df3b5b3706).
### Environment info

64-bit CentOS / cuda 7.5.18 / cudnn 5.0.5 / bazel 0.2.1 / java 1.8.0_91
### Steps to reproduce

Run `./configure` and set up compilation with CUDA 7.5 and CuDNN 5.0.

```
bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
```

Compiles fine without `--config=cuda`.
### What have you tried?

I ran a `git bisect` and traced it to 21716d8f6e175cd6e8cd97a84e48497574268b0c. More specifically, it is moving Eigen out of the `eigen-eigen-b4fa9622b809` folder that for some reason is causing this. Reverting only these changes from the master makes it compile just fine (see https://github.com/gustavla/tensorflow/commit/058a6517576171bb0c7dcf11ec1aac04bd59aedf). I have so far been unable to fix it while keeping the `strip_prefix` in.

It suspect it might be a quirk in bazel 0.2.1. It would be great if anyone else running that version can confirm.
### Error

The error message (abridged and personal paths removed):

```
ERROR: /.../tensorflow/core/kernels/BUILD:1527:1: undeclared inclusion(s) in rule '//tensorflow/core/kernels:depth_space_ops_gpu':
this rule is missing dependency declarations for the following files included by 'tensorflow/core/kernels/spacetodepth_op_gpu.cu.cc':
  '/.../.cache/external/eigen_archive/Eigen/Core'
  '/.../.cache/external/eigen_archive/Eigen/src/Core/util/DisableStupidWarnings.h'
  '/.../.cache/external/eigen_archive/Eigen/src/Core/util/Macros.h'
  ...
  '/.../.cache/external/eigen_archive/Eigen/src/Core/ArrayWrapper.h'
  '/.../.cache/external/eigen_archive/Eigen/src/Core/GlobalFunctions.h'
  '/.../.cache/external/eigen_archive/Eigen/src/Core/util/ReenableStupidWarnings.h'.
```

Issues with related error messages include #1157 and  #3589.
"
3739,Cross entropy should give targets out of range error as given by tf.nn.in_top_k,"I ran the tensorflow code(given below) and it gave me error(error stack is below code) targets out of range.

I have figured out what was causing this error, it was due to mismatch between labels and outputs, like I'm doing 8 class sentiment classification and my labels are `(1,2,3,4,7,8,9,10)` so it was unable to match predictions`(1,2,3,4,5,6,7,8)` with my labels, so that's why it was giving out of range error. My question is, why it didn't gave me error in this line `c_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits,Y)` , how it's matching labels with predictions in this case as opposed to in in_top_k? I think c_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits,Y) should give me error because predictions and labels are not same. Why I'm not getting targets out of range error in cross entropy function? 

```
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import tensorflow as tf
import numpy as np
import math
import os
from nltk.tokenize import TweetTokenizer
batch = 500
start = 0
end = batch - 1
learning_rate = 0.2
num_classes = 8
path = ""/home/indy/Downloads/aclImdb/train/pos""
time_steps = 250
embedding = 50

def get_embedding():
    gfile_path = os.path.join(""/home/indy/Downloads/glove.6B"", ""glove.6B.50d.txt"")
    f = open(gfile_path,'r')
    embeddings = {}
    for line in f:
        sp_value = line.split()
        word = sp_value[0]
        embedding = [float(value) for value in sp_value[1:]]
        embeddings[word] = embedding
    return embeddings

ebd = get_embedding()

def get_y(file_name):
    y_value = file_name.split('_')
    y_value = y_value[1].split('.')
    return y_value[0] 

def get_x(path,file_name):
    file_path = os.path.join(path,file_name)
    x_value = open(file_path,'r')
    for line in x_value:
        x_value = line.replace(""<br /><br />"","""") 
        x_value = x_value.lower()
    tokeniz = TweetTokenizer()
    x_value = tokeniz.tokenize(x_value)
    padding = 250 - len(x_value)
    if padding > 0:
       p_value = ['pad' for i in range(padding)]
       x_value = np.concatenate((x_value,p_value))
    x_value = [ebd['value'] for value in x_value]

    return x_value

def  batch_f(path):
     directory = os.listdir(path)
     y = [get_y(directory[i]) for i in range(len(directory))]
     x = [get_x(path,directory[i]) for i in range(len(directory))]    
     return x,y


X = tf.placeholder(tf.float32, [batch,time_steps,embedding])
Y = tf.placeholder(tf.int32, [batch])

def build_nlp_model(x, _units, lstm_layers,num_classes):

     x = tf.transpose(x, [1, 0, 2])
     x = tf.reshape(x, [-1, embedding])
     x = tf.split(0, time_steps, x)


     lstm = tf.nn.rnn_cell.LSTMCell(num_units = _units, state_is_tuple = True)

     multi_lstm = tf.nn.rnn_cell.MultiRNNCell([lstm] * lstm_layers, state_is_tuple = True)

     outputs , state = tf.nn.rnn(multi_lstm,x, dtype = tf.float32)     

     weights = tf.Variable(tf.random_normal([_units,num_classes]))
     biases  = tf.Variable(tf.random_normal([num_classes]))

     logits = tf.matmul(outputs[-1], weights) + biases
     return logits

logits = build_nlp_model(X,400,4,num_classes)
c_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits,Y)
loss = tf.reduce_mean(c_loss)



decayed_learning_rate = tf.train.exponential_decay(learning_rate,0,10000,0.9)
optimizer= tf.train.AdamOptimizer(decayed_learning_rate)
minimize_loss = optimizer.minimize(loss)



correct_predict = tf.nn.in_top_k(logits, Y, 1)
accuracy = tf.reduce_mean(tf.cast(correct_predict, tf.float32))


init = tf.initialize_all_variables()

with tf.Session() as sess:
     sess.run(init)
     for i in range(25):
         x, y = batch_f(path)
         sess.run(minimize_loss,feed_dict={X : x, Y : y})
         accu = sess.run(accuracy,feed_dict = {X: x, Y: y})
         cost = sess.run(loss,feed_dict = {X: x,Y: y})
         start = end 
         end = (start + batch)
         print (""Minibatch Loss = "" + ""{:.6f}"".format(cost) + "", Training Accuracy= "" + ""{:.5f}"".format(accu))
```

This is the error stack that is caused by tf.nn.in_top_k.

```
(500, 250, 50)
(500,)
Traceback (most recent call last):
  File ""nlp.py"", line 115, in <module>
    accu = sess.run(accuracy,feed_dict = {X: x, Y: y})
  File ""/home/indy/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 372, in run
    run_metadata_ptr)
  File ""/home/indy/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 636, in _run
    feed_dict_string, options, run_metadata)
  File ""/home/indy/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 708, in _do_run
    target_list, options, run_metadata)
  File ""/home/indy/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 728, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.InvalidArgumentError: targets[0] is out of range
     [[Node: InTopK = InTopK[T=DT_INT32, k=1, _device=""/job:localhost/replica:0/task:0/cpu:0""](add, _recv_Placeholder_1_0)]]
Caused by op u'InTopK', defined at:
  File ""nlp.py"", line 102, in <module>
    correct_predict = tf.nn.in_top_k(logits, Y, 1)
  File ""/home/indy/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 890, in in_top_k
    targets=targets, k=k, name=name)
  File ""/home/indy/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py"", line 704, in apply_op
    op_def=op_def)
  File ""/home/indy/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2260, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/home/indy/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1230, in __init__
    self._traceback = _extract_stack()
```

And I think this type of error(targets out of range) should be given by cross entropy also, when labels don't match with predictions.
"
3738,Bidirectional_dynamic_rnn in while_loop results in: AttributeError: 'GradLoopState' object has no attribute 'forward_ctxt',"I'm attempting to recreate this [model](https://github.com/bplank/bilstm-aux) in TensorFlow but I can not seem to get anywhere close to the speed of the original code. On average the TensorFlow implementation is taking 60 ms per document on a GPU, while the pycnn is taking 12 ms per document on a CPU.

What appears to be the issue is that _rnn_step will call the LSTM cell on every time step regardless of whether the input at that position is padding or not and then simply fill those values with zeros after the fact using sequence_length. This seems like a lot of unnecessary calculations. 

Processing the tokens sequentially in multiple session.run calls with one token per batch in a similar performance to the original code but the embeddings do not update as the flow is broken.

Current working (but slow) code is below.

```
def char_encoding(config, graph, doc_len):
    """"""Create graph nodes for character encoding""""""

    c2i = config[""c2i""]
    max_tokens = config[""max_tokens""]

    with graph.as_default():

        # Character Embedding
        word_lengths = tf.placeholder(tf.int64, [None], name=""word_lengths"")
        word_lengths = tf.gather(word_lengths, tf.range(tf.to_int32(doc_len)))
        char_inputs = tf.placeholder(tf.int32, [None, max_tokens], name=""char_inputs"")
        cembed_matrix = tf.Variable(tf.random_uniform([len(c2i.keys()), config[""ce_dim""]], -0.25, 0.25), name=""cembeds"")

        char_inputs = tf.transpose(char_inputs, perm=[1,0])
        cembeds = tf.nn.embedding_lookup(cembed_matrix, char_inputs, name=""ce_lookup"")
        cembeds = tf.gather(cembeds, tf.range(tf.to_int32(doc_len)))
        cembeds = tf.transpose(cembeds, perm=[1,0,2])

        # Create LSTM for Character Encoding
        fw_lstm = tf.nn.rnn_cell.BasicLSTMCell(config[""ce_dim""], state_is_tuple=True)
        bw_lstm = tf.nn.rnn_cell.BasicLSTMCell(config[""ce_dim""], state_is_tuple=True)

        # Encode Characters with LSTM
        options = {
            ""dtype"": tf.float32,
            ""sequence_length"": word_lengths,
            ""time_major"": True
        }

        (output_fw, output_bw), output_states = tf.nn.bidirectional_dynamic_rnn(fw_lstm, bw_lstm, cembeds, **options)
        output_fw = tf.transpose(output_fw, perm=[1,0,2])
        output_bw = tf.transpose(output_bw, perm=[1,0,2])

        return output_fw, output_bw, word_lengths

```

An alternate approach where I loop through the tokens in the graph itself seems like it should be faster but is throwing an odd error: 

Code:

```
def char_encoding(config, graph, doc_len):
    """"""Create graph nodes for character encoding""""""

    c2i = config[""c2i""]
    max_tokens = config[""max_tokens""]

    with graph.as_default():

        # Character Embedding
        word_lengths = tf.placeholder(tf.int64, [None], name=""word_lengths"")
        word_lengths = tf.gather(word_lengths, tf.range(tf.to_int32(doc_len)))
        char_inputs = tf.placeholder(tf.int32, [None, max_tokens], name=""char_inputs"")
        char_inputs = tf.transpose(char_inputs, perm=[1, 0])
        cembed_matrix = tf.Variable(tf.random_uniform([len(c2i.keys()), config[""ce_dim""]], -0.25, 0.25), name=""cembeds"")

        # Create LSTM for Character Encoding
        fw_lstm = tf.nn.rnn_cell.BasicLSTMCell(config[""ce_dim""], state_is_tuple=True)
        bw_lstm = tf.nn.rnn_cell.BasicLSTMCell(config[""ce_dim""], state_is_tuple=True)

        def one_pass(i, o_fw, o_bw):

            int_i = tf.to_int32(i)

            options = {
                ""dtype"": tf.float32,
                ""sequence_length"": tf.expand_dims(tf.gather(word_lengths, int_i), 0),
                ""time_major"": True
            }

            cembeds_invert = tf.nn.embedding_lookup(cembed_matrix, tf.gather(char_inputs, int_i))
            cembeds_invert = tf.transpose(tf.expand_dims(cembeds_invert, 0), perm=[1,0,2])

            (output_fw, output_bw), output_states = tf.nn.bidirectional_dynamic_rnn(fw_lstm, bw_lstm, cembeds_invert, **options)

            # Get Last Relevant
            output_fw = tf.gather(output_fw, tf.gather(word_lengths, int_i) - 1)
            output_bw = tf.gather(output_bw, tf.gather(word_lengths, int_i) - 1)

            # Append to Previous Token Encodings
            o_fw = o_fw.write(int_i, tf.squeeze(output_fw))
            o_bw = o_bw.write(int_i, tf.squeeze(output_bw))

            return tf.add(i, 1), o_fw, o_bw

        # Build Loop in Graph
        i = tf.constant(0.0)
        float_doc_len = tf.to_float(doc_len)
        o_fw = tensor_array_ops.TensorArray(dtype=tf.float32, size=tf.to_int32(doc_len))
        o_bw = tensor_array_ops.TensorArray(dtype=tf.float32, size=tf.to_int32(doc_len))
        cond = lambda i, *_: tf.less(i, float_doc_len)
        i, char_embeds, rev_char_embeds = tf.while_loop(cond, one_pass, [i, o_fw, o_bw])

        return char_embeds.pack(), rev_char_embeds.pack()
```

Error:

```
Traceback (most recent call last):
  File ""/usr/lib/python3.4/runpy.py"", line 170, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""/usr/lib/python3.4/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/home/ubuntu/git/Meerkat/meerkat/longtail/bilstm_tagger.py"", line 445, in <module>
    run_from_command_line()
  File ""/home/ubuntu/git/Meerkat/meerkat/longtail/bilstm_tagger.py"", line 441, in run_from_command_line
    graph, saver = build_graph(config)
  File ""/home/ubuntu/git/Meerkat/meerkat/longtail/bilstm_tagger.py"", line 311, in build_graph
    optimizer = tf.train.GradientDescentOptimizer(config[""learning_rate""]).minimize(loss, name=""optimizer"")
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/optimizer.py"", line 196, in minimize
    grad_loss=grad_loss)
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/optimizer.py"", line 253, in compute_gradients
    colocate_gradients_with_ops=colocate_gradients_with_ops)
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/gradients.py"", line 478, in gradients
    in_grads = _AsList(grad_fn(op, *out_grads))
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/control_flow_grad.py"", line 202, in _EnterGrad
    result = grad_ctxt.AddBackPropAccumulator(op, grad)
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 1646, in AddBackPropAccumulator
    forward_ctxt = self.grad_state.forward_ctxt
AttributeError: 'GradLoopState' object has no attribute 'forward_ctxt'
```

Let me know if seeing the full graph will help at all. Right now that higher level LSTM isn't causing issues because I can just run one document at a time.
"
3735,Giving `name` attributes to `Graph` and `Session`,"I wanted to gauge thoughts on adding a string `name` attribute to `Graph` and `Session` objects. Currently, there's no programmatic way to identify specific Graphs or Sessions from a generic handle. 

There's no mechanism to ensure unique graph/session names (unless I'm mistaken), but it should still be beneficial even without guaranteeing unique names. In a larger system that may be tossing around multiple sessions and graphs, it would be good to have a way to know what graph is being handled (or what family of graphs, if multiple graphs have the same name). The uses for this could also be extended out to TensorBoard, exporting graphs/models, etc.

Perhaps it would be better off being called `tag`, but I went with `name` to keep it consistent with current code.

Good idea, terrible idea, somewhere in the middle?
"
3732,"partial_run, feed placeholder already been fed","The following code gives this error: 'InvalidArgumentError: The feed Placeholder:0 had already been fed.' I'm not sure if it is expected behaviour. 

```
import tensorflow as tf

sess = tf.Session()

a = tf.placeholder(tf.float32)
b = tf.placeholder(tf.float32)
c = tf.placeholder(tf.float32)
r1 = tf.add(a, b)
r2 = tf.mul(a, c)
r3 = tf.sub(r1, r2)

h = sess.partial_run_setup([r1, r2, r3], [a, b, c])
res1 = sess.partial_run(h, r1, feed_dict={a: 1, b: 2})
res2 = sess.partial_run(h, r2, feed_dict={a: 2, c: 3})
res3 = sess.partial_run(h, r3)
```

I get the error both on version '0.9.0' and on a yesterday's GitHub snapshot.
"
3731,0.10.0rc0: tf.pack uses the wrong negative axis,"When supplied a negative axis, tf.pack() actually operates on `(axis - 1)`. For example, providing `axis=-1` operates on the second-to-last axis, not the last axis.

This code illustrates the issue:

``` python
import tensorflow as tf
import numpy as np

#10 tensors with shape 2, 3, 4, 5
x = [tf.convert_to_tensor(np.zeros((2, 3, 4, 5)))] * 10

# pack along last axis explicitly
tf.pack(x, 4).get_shape().as_list() # [2, 3, 4, 5, 10]

# pack along last axis with negative axis, doesn't work
tf.pack(x, -1).get_shape().as_list() # [2, 3, 4, 10, 5]

# this doesn't match the behavior of unpack(), so packing/unpacking 
# along the same negative axis fails
len(tf.unpack(tf.pack(x, axis=-1), axis=-1)) == 10 # False

```
### Environment info

Operating System: 
macOS 10.11

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`): 
N/A

If installed from binary pip package, provide:
1. Which pip package you installed.
   https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.10.0rc0-py3-none-any.whl
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   0.10.0rc0
"
3730,tf.round != np.round,"Looks like tensorflow and numpy use different tie-breaking rules:

```
tf.round(0.5) => 1
np.round(0.5) => 0
```

Both are sound, so actually there's no bug, however since tf and np are tightly coupled is worth considering to uniform them or at least to explictly mention it in the doc.
Especially because np is often used as ground truth for tf tests.
### Environment info
- Operating System: Mac OS X
- TensorFlow: 0.10.0rc0 
- https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.10.0rc0-py2-none-any.whl
### Steps to reproduce

```
import tensorflow as tf
import numpy as np

with tf.Session() as S:
    tf_round = S.run(tf.round(0.5))

np_round = np.round(0.5)

print ""round(0.5) => tf: {:.2f}\t np:{:.2}"".format(tf_round, np_round)

assert np_round == tf_round
```
"
3729,[started] convert to records example in tutorial?,"As far as i know, the started document only provide a example with mnist example, however, really confused about how tensorflow handle an sparse example.
when it comes to linear model, the libsvm format always be a popular format in research and industry. But how to convert libsvm format entries to tensorflow records? How will an entry represent in tensorflow? in column ways or in row ways?

e.g.

```
label, key:value, key:value, ....

```

whereas the key is index, value is the feature value in sparse format. 
Can anyone kindly to add such an example to tutorial ? Thanks
"
3728,contrib.learn.DNNRegressor not compatible for e.g. GridSearchCV,"Imho the new architecture of contrib.learn.DNNRegressor (compared to the old contrib.learn.TensorflowDNNRegressor) makes it impossible to properly use things like GridSearchCV from sklearn. To use GridSearchCV I have to pass all parameters to be tuned to the constructor. In the new architecture of DNNRegressor some parameters are passed to the fit-method which is quite untypical for sklearns architecture usually expecting only X and y as parameters of the fit-method. For example I can no longer tune steps and batch_size (now part of the fit-method) with GridSearchCV. I can only pass them as fixed fit_params. Or am I getting something wrong?
"
3727,distributed seq2seq: too much device placement logs,"I'm trying the distributed seq2seq model. But when I run the program, there are too much device placement logs. Just like this below:

```
sync_replicas/fifo_queue_4_enqueue/component_0: /job:ps/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:818] sync_replicas/fifo_queue_4_enqueue/component_0: /job:ps/replica:0/task:0/cpu:0
sync_replicas/fifo_queue_2_enqueue/component_0: /job:ps/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:818] sync_replicas/fifo_queue_2_enqueue/component_0: /job:ps/replica:0/task:0/cpu:0
ScatterUpdate_3/indices: /job:ps/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:818] ScatterUpdate_3/indices: /job:ps/replica:0/task:0/cpu:0
ScatterUpdate_2/indices: /job:ps/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:818] ScatterUpdate_2/indices: /job:ps/replica:0/task:0/cpu:0
ScatterUpdate_1/indices: /job:ps/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:818] ScatterUpdate_1/indices: /job:ps/replica:0/task:0/cpu:0
ScatterUpdate/indices: /job:ps/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:818] ScatterUpdate/indices: /job:ps/replica:0/task:0/cpu:0
Variable_1/initial_value: /job:ps/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:818] Variable_1/initial_value: /job:ps/replica:0/task:0/cpu:0
mul/y: /job:worker/replica:0/task:1/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:818] mul/y: /job:worker/replica:0/task:1/gpu:0
GradientDescent_3/value: /job:ps/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:818] GradientDescent_3/value: /job:ps/replica:0/task:0/cpu:0
Fill_3/dims: /job:ps/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:818] Fill_3/dims: /job:ps/replica:0/task:0/gpu:0
GradientDescent_2/value: /job:ps/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:818] GradientDescent_2/value: /job:ps/replica:0/task:0/cpu:0
Fill_2/dims: /job:ps/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:818] Fill_2/dims: /job:ps/replica:0/task:0/gpu:0
GradientDescent_1/value: /job:ps/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:818] GradientDescent_1/value: /job:ps/replica:0/task:0/cpu:0
Fill_1/dims: /job:ps/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:818] Fill_1/dims: /job:ps/replica:0/task:0/gpu:0
GradientDescent/value: /job:ps/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:818] GradientDescent/value: /job:ps/replica:0/task:0/cpu:0
Fill/dims: /job:ps/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:818] Fill/dims: /job:ps/replica:0/task:0/gpu:0
Variable/initial_value: /job:ps/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:818] Variable/initial_value: /job:ps/replica:0/task:0/gpu:0
```

While when I run the original seq2seq model in single machine, I don't have the problem. I locate the `simple_placer.cc:818`, finding they are really log ouputs. 
## Why does it output in the distributed model?

simple_placer.cc

```
void SimplePlacer::AssignAndLog(const string& assigned_device,
                                Node* node) const {
  node->set_assigned_device_name(assigned_device);
  // Log placement if log_device_placement is set.
  if (options_ && options_->config.log_device_placement()) {
    printf(""%s: %s\n"", node->name().c_str(),
           node->assigned_device_name().c_str());
    LOG(INFO) << node->name() << "": "" << node->assigned_device_name();
  }
}
```
"
3726,"nested scan functions break in gradient calculation, bug?","I tried to produce some code to read out the values at multiple locations from a vector of results. To do this I used two nested scan functions to go through the batches and the vector of the multiple locations. 
This function correctly calculates the values when used alone, but when I want to calculate gradients, the code breaks at initialisation of the variables in the session with a error message I do not feel responsible for.
## Environment info

Operating System: iOS 10.11.5 

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
-rwxr-xr-x  1 root  wheel  8280 Aug  9 18:11 /usr/local/cuda/lib/libcuda.1.dylib
-rwxr-xr-x  1 root  wheel  8280 Apr 13 08:02 /usr/local/cuda/lib/libcuda.dylib
lrwxr-xr-x  1 root  wheel    45 Apr 13 08:03 /usr/local/cuda/lib/libcudadevrt.a -> /Developer/NVIDIA/CUDA-7.5/lib/libcudadevrt.a
lrwxr-xr-x  1 root  wheel    50 Apr 13 08:03 /usr/local/cuda/lib/libcudart.7.5.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart.7.5.dylib
lrwxr-xr-x  1 root  wheel    46 Apr 13 08:03 /usr/local/cuda/lib/libcudart.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart.dylib
lrwxr-xr-x  1 root  wheel    49 Apr 13 08:03 /usr/local/cuda/lib/libcudart_static.a -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart_static.a
lrwxr-xr-x  1 root  wheel    47 Aug  9 18:38 /usr/local/cuda/lib/libcudnn.5.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudnn.5.dylib
lrwxr-xr-x  1 root  wheel    45 Aug  9 18:38 /usr/local/cuda/lib/libcudnn.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudnn.dylib
lrwxr-xr-x  1 root  wheel    48 Aug  9 18:38 /usr/local/cuda/lib/libcudnn_static.a -> /Developer/NVIDIA/CUDA-7.5/lib/libcudnn_static.a

If installed from source, provide 
1. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   '0.10.0rc0'
2. The commit hash (`git rev-parse HEAD`)
   056db850614e0a06ce6f65b30f877c5789ab74f5
3. The output of `bazel version`
   Build label: 0.3.1-homebrew
   Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
   Build time: Thu Aug 4 09:58:27 2016 (1470304707)
   Build timestamp: 1470304707
   Build timestamp as int: 1470304707
## Steps to reproduce
1. run code 

```
import tensorflow as tf
import numpy 

def saliency_loss(y_true, y_pred):
    def saliency_loss_1(oldL,y):
        select = tf.slice(tf.squeeze(y),[5],[-1])
        def subindex(old,select1):
            return tf.slice(y,tf.reshape(tf.cast(select1,dtype='int32'),(1,)),tf.reshape(tf.constant(1),(1,))) 
        prob = tf.scan(subindex,select,initializer = tf.reshape(tf.constant(0.0),(1,)))
        return -tf.reshape(tf.reduce_sum(tf.log(prob)),(1,))
    y = tf.concat(1,(y_pred,y_true),name = 'y')
    L = tf.scan(saliency_loss_1,y,initializer = tf.reshape(tf.constant(0.0),(1,)))
    return tf.reduce_mean(L)

y_true = tf.Variable([[0.0,0.0,0.0],[1.0,4.0,1.0],[0.0,0.0,0.0],[1.0,4.0,1.0]])
y_pred = tf.Variable([[1.0,2.0,3.0,4.0,5.0],[11.0,12.0,13.0,14.0,15.0],[1.0,2.0,3.0,4.0,5.0],[11.0,12.0,13.0,14.0,15.0]])
y = tf.concat(1,(y_pred,y_true),name = 'y')
print(-(numpy.log(12.0)+numpy.log(15.0)+numpy.log(12.0))/2.0)


with tf.Session() as sess:
    sess.run(tf.initialize_all_variables())
    print(sess.run(saliency_loss(y_true, y_pred)))

loss = saliency_loss(y_true, y_pred)
grad = tf.gradients(loss,y_pred)

print(grad)

with tf.Session() as sess:
    sess.run(tf.initialize_all_variables())
    #print(sess.run(grad))

```
## What have you tried?
1. all orders of initialisation and running only gradient calculation
## Logs or other output that would be helpful
### Errortrace:

---

InvalidArgumentError                      Traceback (most recent call last)
/Users/heiko/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, _args)
    964     try:
--> 965       return fn(_args)
    966     except errors.OpError as e:

/Users/heiko/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata)
    946                                  feed_dict, fetch_list, target_list,
--> 947                                  status, run_metadata)
    948 

/Users/heiko/anaconda/lib/python3.5/contextlib.py in **exit**(self, type, value, traceback)
     65             try:
---> 66                 next(self.gen)
     67             except StopIteration:

/Users/heiko/anaconda/lib/python3.5/site-packages/tensorflow/python/framework/errors.py in raise_exception_on_not_ok_status()
    449           compat.as_text(pywrap_tensorflow.TF_Message(status)),
--> 450           pywrap_tensorflow.TF_GetCode(status))
    451   finally:

InvalidArgumentError: Input 0 of node gradients/scan_1/while/scan/TensorArrayPack_grad/TensorArrayGrad/TensorArrayGrad was passed string from gradients/scan_1/while/scan/TensorArrayPack_grad/TensorArrayGrad/TensorArrayGrad/StackPop:0 incompatible with expected string_ref.

During handling of the above exception, another exception occurred:

InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-1-d5cce368f52a> in <module>()
     29 
     30 with tf.Session() as sess:
---> 31     sess.run(tf.initialize_all_variables())
     32     #print(sess.run(grad))

/Users/heiko/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)
    708     try:
    709       result = self._run(None, fetches, feed_dict, options_ptr,
--> 710                          run_metadata_ptr)
    711       if run_metadata:
    712         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/Users/heiko/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
    906     if final_fetches or final_targets:
    907       results = self._do_run(handle, final_targets, final_fetches,
--> 908                              feed_dict_string, options, run_metadata)
    909     else:
    910       results = []

/Users/heiko/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
    956     if handle is None:
    957       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,
--> 958                            target_list, options, run_metadata)
    959     else:
    960       return self._do_call(_prun_fn, self._session, handle, feed_dict,

/Users/heiko/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
    976         except KeyError:
    977           pass
--> 978       raise type(e)(node_def, op, message)
    979 
    980   def _extend_graph(self):

InvalidArgumentError: Input 0 of node gradients/scan_1/while/scan/TensorArrayPack_grad/TensorArrayGrad/TensorArrayGrad was passed string from gradients/scan_1/while/scan/TensorArrayPack_grad/TensorArrayGrad/TensorArrayGrad/StackPop:0 incompatible with expected string_ref.
"
3725,FTRL implementation in tensorflow V.S. FTRL in Google's research paper,"Hello, every one! 

I am interested in digging the details how FTRL is implemented in tensorflow. I find some information in the file ""gen_training_ops.py"" in the folder /tensorflow/python/training. In this file, the formula of FTRL algorithm is described as follows:

```
def apply_ftrl(var, accum, linear, grad, lr, l1, l2, lr_power,
use_locking=None, name=None):
r""""""Update '*var' according to the Ftrl-proximal scheme
accum_new = accum + grad * grad      ------ (1)
linear += grad + (accum_new^(-lr_power) - accum^(-lr_power)) / lr * var        ------ (2)
quadratic = 1.0 / (accum_new^(lr_power) * lr) + 2 * l2              ------ (3)
var = (sign(linear) * l1 - linear) / quadratic if |linear| > l1 else 0.0           ------(4)
accum = accum_new        ------(5)
```

I am also reading the paper ""Ad Click Prediction: a View from the Trenches"" by Google in KDD'13. The formula of FTRL algorithm is given in page 2 of this paper. Comparing this two implementations, we find some connections:
var is w_{t,i} in the paper; l1 is lambda1 in the paper; linear is zi in the paper; lr is alpha in the paper; grad is gi in the paper; accum is ni in the paper.

But also, there are some inconsistent points:
according to the paper, the Equation (2) above should be 
`linear += grad - (accum_new^(-lr_power) - accum^(-lr_power)) / lr * var`
also we can get the following equation by comparing the two implementations:
`2l2  *alpha = beta + alpha * lambda2`

For any expert who is familiar with the FTRL implementation in the tensorflow, can you help us to clarify the meaning the parameters given in tensorflow, and the connections with the FTRL code in Google's research paper ""Ad Click Prediction: a View from the Trenches"".

Thanks!
"
3724,Source-compiled .whl package is much slower in training,"Recently, from my experiment, I found that running inception model using the .whl file generated by myself is much slower than using .whl file downloaded directly from the $TF_BINARY_URL.
### Environment info

Operating System: ubuntu14.04
CUDA: cuda7.5
CUDNN: cudnn 5

I followed the instructions
./configure
bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg
And I got tensorflow-0.9.0-py2-none-any.whl to install using:
pip install /home/dl/bxl/tensorflow/tensorflow_pkg/tensorflow-0.9.0-py2-none-any.whl
 (the name of this .whl file is automatically generated )

Then I downloaded the inception model related files to train following the instructions:
cd ~/models/inception
bazel build inception/imagenet_train
bazel-bin/inception/imagenet_train --num_gpus=1 --batch_size=64 --train_dir=/tmp/imagenet_train --data_dir=/data1/ImageNet

From the information printed out, I found that the speed is 8.5 samples/sec. (In the first several lines printed out, it says：
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so.7.5 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so.7.5 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so.7.5 locally,
from which I guess CUDA/CuDNN are automatically loaded)

However, if I replace the .whl file by that directly downloaded from the $TF_BINARY_URL provided in www.tensorflow.org ( tensorflow-0.9.0-cp27-none-linux_x86_64.whl, which uses CuDNN4 and cuda7.5), and reinstall it using pip, and restart a new process to train the inception model using the same code. 

I got that the training speed was 20.2 samples/sec, which is nearly 2.5x faster than my first training using the .whl package generated by myself. 

So it is very difficult to explain. Because I use CUDNN5, I expect my version is faster, but in fact, it is 2.5x slower....

Does anyone know why??

Thanks in advance.
"
3723,_pywrap_tensorflow module not found on OS X 10.11.6 after compiling and building a package,"I compiled tensorflow from the source with CUDA support. After installing the wheel I was greeted with an error(listed below). The compilation without CUDA support is successful.

I cant figure out what the problem is.

**All of this was done in a Virtualenv Python version: 2.7.12**
### Environment info

Operating System:
Mac OS X(10.11.6)
Installed version of CUDA and cuDNN: 
`-rwxr-xr-x  1 root  wheel   8.1K Jun 10 01:58 /usr/local/cuda/lib/libcuda.dylib*
lrwxr-xr-x  1 root  wheel    45B Sep 25  2015 /usr/local/cuda/lib/libcudadevrt.a@ -> /Developer/NVIDIA/CUDA-7.5/lib/libcudadevrt.a
lrwxr-xr-x  1 root  wheel    50B Sep 25  2015 /usr/local/cuda/lib/libcudart.7.5.dylib@ -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart.7.5.dylib
lrwxr-xr-x  1 root  wheel    46B Sep 25  2015 /usr/local/cuda/lib/libcudart.dylib@ -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart.dylib
lrwxr-xr-x  1 root  wheel    49B Sep 25  2015 /usr/local/cuda/lib/libcudart_static.a@ -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart_static.a
lrwxr-xr-x  1 root  wheel    47B Aug  9 21:51 /usr/local/cuda/lib/libcudnn.5.dylib@ -> /Developer/NVIDIA/CUDA-7.5/lib/libcudnn.5.dylib
lrwxr-xr-x  1 root  wheel    45B Aug  9 21:51 /usr/local/cuda/lib/libcudnn.dylib@ -> /Developer/NVIDIA/CUDA-7.5/lib/libcudnn.dylib
lrwxr-xr-x  1 root  wheel    48B Aug  9 21:51 /usr/local/cuda/lib/libcudnn_static.a@ -> /Developer/NVIDIA/CUDA-7.5/lib/libcudnn_static.a`

If installed from source, provide 
1. 32bd3d024f33e920a67a1081bc0ae0048350fdee
2. The output of `bazel version`:
   `Build label: 0.3.1-homebrew
   Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
   Build time: Thu Aug 4 09:58:27 2016 (1470304707)
   Build timestamp: 1470304707
   Build timestamp as int: 1470304707`
### Steps to reproduce
1. Configure with CUDA v7.5 and Cudnn v5.1 
2. Compile with CUDA support enabled.
3. Build pip package and then install.
### What have you tried?
1. Tried installing the binary, but I was then greeted with a different error. 
### Logs or other output that would be helpful

`Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/Users/ojas/.pyenv/versions/ve2/lib/python2.7/site-packages/tensorflow/__init__.py"", line 23, in <module>
    from tensorflow.python import *
  File ""/Users/ojas/.pyenv/versions/ve2/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 48, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/Users/ojas/.pyenv/versions/ve2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 21, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""/Users/ojas/.pyenv/versions/ve2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow')
  File ""/Users/ojas/.pyenv/versions/2.7.12/Python.framework/Versions/2.7/lib/python2.7/importlib/__init__.py"", line 37, in import_module
    __import__(name)
ImportError: No module named _pywrap_tensorflow`
"
3722,Tensorflow build fails due to farmhash build failure on ppc64le,"Tensorflow's external dependency named farmhash fails to build on Ubuntu 14.04 linux ppc64le. If I manually edit the config.guess of farmhash to add a case for ppc64le, then it works. So, I wanted to know how can I contribute this fix back to repo as farmhash is not git cloned by tensorflow, rather a zip archive is downloaded from [farmhash download url](https://github.com/google/farmhash/archive/34c13ddfab0e35422f4c3979f360635a8c050260.zip.)
Even if I generate the a pull request for google/farmhash, how tensorflow will fetch that?
### Environment info

Operating System: Ubuntu 14.04 linux ppc64le

Installed version of CUDA and cuDNN: 7.5
$ ls -l /usr/local/cuda-7.5/lib64/libcud*
-rw-r--r-- 1 root root   326744 Nov  9  2015 /usr/local/cuda-7.5/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Nov  5  2015 /usr/local/cuda-7.5/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root       19 Nov  5  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5 -> libcudart.so.7.5.23
-rwxr-xr-x 1 root root   445192 Nov  5  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5.23
-rw-r--r-- 1 root root   902750 Nov  9  2015 /usr/local/cuda-7.5/lib64/libcudart_static.a
lrwxrwxrwx 1 root root       13 Apr 24 20:17 /usr/local/cuda-7.5/lib64/libcudnn.so -> libcudnn.so.5
-rwxr-xr-x 1 root root 60068392 Apr 22 19:18 /usr/local/cuda-7.5/lib64/libcudnn.so.5.0.5
-rw-r--r-- 1 root root 59436124 Apr 22 19:30 /usr/local/cuda-7.5/lib64/libcudnn_static.a

**1. The commit hash (`git rev-parse HEAD`)** - v0.9.0 (problem also seen in the latest master branch)
**2. The output of `bazel version`** 
Build label: head (@f7d9417)
Build target: bazel-out/local_linux-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Tue Aug 9 13:56:57 2016 (1470751017)
Build timestamp: 1470751017
Build timestamp as int: 1470751017
### Steps to reproduce
1. git clone https://github.com/tensorflow/tensorflow
2. cd  tensorflow && git checkout v0.9.0
3. ./configure && bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
### What have you tried?
1. Manually modifying config.guess of farmhash to add a case of ppc64le fixes the problem.
### Logs or other output that would be helpful

ERROR: /home/user/.cache/bazel/_bazel_user/9138b14b59b57ff6760f108ab5f6a562/external/farmhash_archive/BUILD:5:1: Executing genrule @farmhash_archive//:configure failed: bash failed: error executing command /bin/bash -c ... (remaining 1 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
/home/user/.cache/bazel/_bazel_user/9138b14b59b57ff6760f108ab5f6a562/tensorflow_upstream/external/farmhash_archive/farmhash-34c13ddfab0e35422f4c3979f360635a8c050260 /home/user/.cache/bazel/_bazel_user/9138b14b59b57ff6760f108ab5f6a562/tensorflow_upstream
/tmp/tmp.um0vY1ktLs /home/user/.cache/bazel/_bazel_user/9138b14b59b57ff6760f108ab5f6a562/tensorflow_upstream/external/farmhash_archive/farmhash-34c13ddfab0e35422f4c3979f360635a8c050260 /home/user/.cache/bazel/_bazel_user/9138b14b59b57ff6760f108ab5f6a562/tensorflow_upstream
checking for a BSD-compatible install... /usr/bin/install -c
checking whether build environment is sane... yes
checking for a thread-safe mkdir -p... /bin/mkdir -p
checking for gawk... no
checking for mawk... mawk
checking whether make sets $(MAKE)... yes
checking whether make supports nested variables... yes
checking build system type... /tmp/tmp.um0vY1ktLs/missing: Unknown `--is-lightweight' option
Try`/tmp/tmp.um0vY1ktLs/missing --help' for more information
configure: WARNING: 'missing' script is too old or missing
./config.guess: unable to guess system type

This script, last modified 2010-08-21, has failed to recognize
the operating system you are using. It is advised that you
download the most up to date version of the config scripts from

  http://git.savannah.gnu.org/gitweb/?p=config.git;a=blob_plain;f=config.guess;hb=HEAD
and
  http://git.savannah.gnu.org/gitweb/?p=config.git;a=blob_plain;f=config.sub;hb=HEAD

If the version you run (./config.guess) is already up to date, please
send the following data and any information you think might be
pertinent to config-patches@gnu.org in order to provide the needed
information to handle your system.

config.guess timestamp = 2010-08-21

uname -m = ppc64le
uname -r = 3.19.0-58-generic
uname -s = Linux
uname -v = #64~14.04.1-Ubuntu SMP Fri Mar 18 19:05:01 UTC 2016

/usr/bin/uname -p =
/bin/uname -X     =

hostinfo               =
/bin/universe          =
/usr/bin/arch -k       =
/bin/arch              =
/usr/bin/oslevel       =
/usr/convex/getsysinfo =

UNAME_MACHINE = ppc64le
UNAME_RELEASE = 3.19.0-58-generic
UNAME_SYSTEM  = Linux
UNAME_VERSION = #64~14.04.1-Ubuntu SMP Fri Mar 18 19:05:01 UTC 2016
configure: error: cannot guess build type; you must specify one
"
3721,contrib outputs_collections bug,"# Problem description

TensorFlow version r0.10

It seems to me that there is a bug with the outputs_collections in tensorflow/tensorflow/contrib/layers. When trying to add the outputs of the layers (say, conv2d) to the tf.GraphKeys.ACTIVATIONS collection, I run into errors with NamedOutputs such as the following:

```
...
Run summarize_activations() from tensorflow/tensorflow/contrib/layers/python/layers/summaries.py
...
/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/summaries.pyc in summarize_collection(collection, name_filter, summarizer)
    160     if name_filter is None or re.match(name_filter, op.op.name):
    161       tensors.append(op)
--> 162   return summarize_tensors(tensors, summarizer)
    163
    164

/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/summaries.pyc in summarize_tensors(tensors, summarizer)
    150 def summarize_tensors(tensors, summarizer=summarize_tensor):
    151   """"""Summarize a set of tensors.""""""
--> 152   return [summarizer(tensor) for tensor in tensors]
    153
    154

/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/summaries.pyc in summarize_tensor(tensor, tag)
    135   """"""
    136   # Skips string tensors and boolean tensors (not handled by the summaries).
--> 137   if (tensor.dtype.is_compatible_with(dtypes.string) or
    138       tensor.dtype.base_dtype == dtypes.bool):
    139     return None

AttributeError: 'NamedOutputs' object has no attribute 'dtype'
```
# Root of problem
## README and code are not consistent

The readme (located at tensorflow/tensorflow/contrib/layers/README.md) indicates that ""weights, biases, and activations (i.e., outputs) are, by default, added to the specified collections."" They even show a piece of code such as `output_collections=(tf.GraphKeys.ACTIVATIONS,)`. However, looking into the code in tensorflow/tensorflow/contrib/layers/python/layers/layers.py it seems to me that there is nothing adding activations to the tf.GraphKeys.ACTIVATIONS collection. I believe one solution to this problem is to use the `_apply_activation` function already written in the file:

```
def _apply_activation(y, activation_fn, output_collections):
  if activation_fn:
    y = activation_fn(y)
  ops.add_to_collections(list(output_collections or []) +
                         [ops.GraphKeys.ACTIVATIONS], y)
  return y
```

instead of using only

```
if activation_fn:
      outputs = activation_fn(outputs)
return utils.collect_named_outputs(outputs_collections, sc.name, outputs)
```
## Code walkthrough

tensorflow/tensorflow/contrib/layers/python/layers/layers.py uses this line several times (such as in conv2d):
`utils.collect_named_outputs(outputs_collections, sc, outputs)`

Opening tensorflow/tensorflow/contrib/layers/python/layers/utils.py we see that this ultimately calls:
`ops.add_to_collections(collections, NamedOutputs(name, outputs))`

However, it seems to me that when using the summarize_activations function in https://github.com/tensorflow/tensorflow/blob/r0.10/tensorflow/contrib/layers/python/layers/summaries.py, it expects the value to be `outputs` rather than `NamedOutputs(name, outputs)`. In other words, the summarize_activations function seems to expect something along the lines of:
`ops.add_to_collections(collections, outputs)`
rather than
`ops.add_to_collections(collections, NamedOutputs(name, outputs))`
### Further description (not particularly informative if you are already familiar with the tensorflow repo)

If we look into what `ops.add_to_collections` is doing, we see that in tensorflow/tensorflow/python/framework/ops.py this ultimately calls:
`self.add_to_collection(name, value)`

`add_to_collection(...)` is described in the same file as:

```
  def add_to_collection(self, name, value):
    """"""Stores `value` in the collection with the given `name`.
    Note that collections are not sets, so it is possible to add a value to
    a collection several times.
    Args:
      name: The key for the collection. The `GraphKeys` class
        contains many standard names for collections.
      value: The value to add to the collection.
```

So, our `value` here is `value = NamedOutputs(name, outputs)` from earlier.

However, if we look at the summarize_activations in tensorflow/tensorflow/contrib/layers/python/layers/summaries.py, we see that:

```
def summarize_activations(name_filter=None, summarizer=summarize_activation):
  """"""Summarize activations, using `summarize_activation` to summarize.""""""
  return summarize_collection(ops.GraphKeys.ACTIVATIONS, name_filter,
                              summarizer)

def summarize_collection(collection, name_filter=None,
                         summarizer=summarize_tensor):
  """"""Summarize a graph collection of tensors, possibly filtered by name.""""""
  tensors = []
  for op in ops.get_collection(collection):
    if name_filter is None or re.match(name_filter, op.op.name):
      tensors.append(op)
  return summarize_tensors(tensors, summarizer)
```

In other words, `summarize_collection(...)` expects the collection to contain tensors instead of NamedOutputs(name, outputs).
"
3719,Log sigmoid,"It would be nice to have a numerically stable log_sigmoid similar to the existing log_softmax.
"
3717,Undefined Inputs on MatMul in Trace File (GPU Only),"I am still working on solving my performance issue with a Reinforcement Learning system as stated in #3320 and have a question about reading the trace files in Chrome with ""chrome:trace"".

I am trying to debug and speed up my graph.  I am seeing multiple copies of some of the graph ops with ""undefined"" for both inputs for MatMul when GPU is in use, but not for CPU.  This seems to be the only Op I see this ""undefined"" input value.

For example, ""taking_action/mydnn/DNNLayer_1/MatMul"" has 3 MatMul.  1 with the appropriate inputs and 2 copies with ""undefined"" inputs.  Is this expected or do I have a problem with my graph?  Are the 2 ""undefined"" some optimization of the original ""MatMul""?

![screenshot 2016-08-09 15 30 21](https://cloud.githubusercontent.com/assets/18412448/17531049/41bc30ca-5e48-11e6-8de4-2ace42ebd192.png)

EDIT: Using the latest HEAD, 0.10.0 RC
"
3716,Seq2Seq - Place different LSTM layers on separate GPUs,"Dears 

Based on the discussion on https://github.com/tensorflow/tensorflow/issues/600, I would like to place different LSTM layers on separate GPUs to improve the accuracy and speed. 
Can someone help me?

With Best Wishes,
Siamak
"
3715,convert_to_records meet a bug,"When I run the convert_to_records in how_to demo, show me the message. 
I just trash the reshape parameter and meet other bugs, it seems simple to fix.

```
Traceback (most recent call last):
  File ""convert_to_records.py"", line 91, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""convert_to_records.py"", line 82, in main
    reshape=False)
TypeError: read_data_sets() got an unexpected keyword argument 'reshape'
```
"
3714,Tensorflow fails to install with python 2 (CPU-only) on MacOS 10.11.6.  What to do?,"### Environment info

Operating System: MacOS 10.11.6

Installed version of CUDA and cuDNN: 
n/a -- I chose the non-GPU edition of TensorFlow

If installed from binary pip package, provide:

See below...

If installed from source, provide 

n/a
### Steps to reproduce
1. Try to install tensorflow with python 2 on MacOSX 10.11.6.

```
Shyamals-iMac-174:~ shyamalchandra$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.10.0rc0-py2-none-any.whl
Shyamals-iMac-174:~ shyamalchandra$ 
Shyamals-iMac-174:~ shyamalchandra$ sudo pip install --upgrade $TF_BINARY_URL
Password:
Sorry, try again.
Password:
The directory '/Users/shyamalchandra/Library/Caches/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.
The directory '/Users/shyamalchandra/Library/Caches/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.
Collecting tensorflow==0.10.0rc0 from https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.10.0rc0-py2-none-any.whl
  Downloading https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.10.0rc0-py2-none-any.whl (30.6MB)
    100% |████████████████████████████████| 30.6MB 45kB/s 
Collecting mock>=2.0.0 (from tensorflow==0.10.0rc0)
  Downloading mock-2.0.0-py2.py3-none-any.whl (56kB)
    100% |████████████████████████████████| 61kB 905kB/s 
Collecting protobuf==3.0.0b2 (from tensorflow==0.10.0rc0)
  Downloading protobuf-3.0.0b2-py2.py3-none-any.whl (326kB)
    100% |████████████████████████████████| 327kB 2.1MB/s 
Requirement already up-to-date: six>=1.10.0 in /Library/Python/2.7/site-packages/six-1.10.0-py2.7.egg (from tensorflow==0.10.0rc0)
Collecting wheel (from tensorflow==0.10.0rc0)
  Downloading wheel-0.29.0-py2.py3-none-any.whl (66kB)
    100% |████████████████████████████████| 71kB 5.6MB/s 
Collecting numpy>=1.10.1 (from tensorflow==0.10.0rc0)
  Downloading numpy-1.11.1-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (3.9MB)
    100% |████████████████████████████████| 3.9MB 324kB/s 
Collecting funcsigs>=1; python_version < ""3.3"" (from mock>=2.0.0->tensorflow==0.10.0rc0)
  Downloading funcsigs-1.0.2-py2.py3-none-any.whl
Collecting pbr>=0.11 (from mock>=2.0.0->tensorflow==0.10.0rc0)
  Downloading pbr-1.10.0-py2.py3-none-any.whl (96kB)
    100% |████████████████████████████████| 102kB 5.2MB/s 
Collecting setuptools (from protobuf==3.0.0b2->tensorflow==0.10.0rc0)
  Downloading setuptools-25.1.6-py2.py3-none-any.whl (442kB)
    100% |████████████████████████████████| 450kB 960kB/s 
Installing collected packages: funcsigs, pbr, mock, setuptools, protobuf, wheel, numpy, tensorflow
  Found existing installation: setuptools 1.1.6
    Uninstalling setuptools-1.1.6:
Exception:
Traceback (most recent call last):
  File ""/Library/Python/2.7/site-packages/pip/basecommand.py"", line 215, in main
    status = self.run(options, args)
  File ""/Library/Python/2.7/site-packages/pip/commands/install.py"", line 317, in run
    prefix=options.prefix_path,
  File ""/Library/Python/2.7/site-packages/pip/req/req_set.py"", line 736, in install
    requirement.uninstall(auto_confirm=True)
  File ""/Library/Python/2.7/site-packages/pip/req/req_install.py"", line 742, in uninstall
    paths_to_remove.remove(auto_confirm)
  File ""/Library/Python/2.7/site-packages/pip/req/req_uninstall.py"", line 115, in remove
    renames(path, new_path)
  File ""/Library/Python/2.7/site-packages/pip/utils/__init__.py"", line 267, in renames
    shutil.move(old, new)
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py"", line 299, in move
    copytree(src, real_dst, symlinks=True)
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py"", line 208, in copytree
    raise Error, errors
Error: [('/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/__init__.py', '/tmp/pip-iSKbnn-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/__init__.py', ""[Errno 1] Operation not permitted: '/tmp/pip-iSKbnn-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/__init__.py'""), ('/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/__init__.pyc', '/tmp/pip-iSKbnn-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/__init__.pyc', ""[Errno 1] Operation not permitted: '/tmp/pip-iSKbnn-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/__init__.pyc'""), ('/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/markers.py', '/tmp/pip-iSKbnn-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/markers.py', ""[Errno 1] Operation not permitted: '/tmp/pip-iSKbnn-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/markers.py'""), ('/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/markers.pyc', '/tmp/pip-iSKbnn-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/markers.pyc', ""[Errno 1] Operation not permitted: '/tmp/pip-iSKbnn-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/markers.pyc'""), ('/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib', '/tmp/pip-iSKbnn-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib', ""[Errno 1] Operation not permitted: '/tmp/pip-iSKbnn-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib'"")]
```
### What have you tried?

Nothing yet; what should I do?
### Logs or other output that would be helpful

n/a
"
3712,gather_nd not working with API examples,"### Environment info

Operating System: Ubuntu 14.04

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
cuda 7.5
cudnn 4.0

python3
tensorflow version 0.9
#### Code:

```
import tensorflow as tf
x = tf.constant([[1,1,1,1],[1,2,3,4]],shape=(2,4))
indices = [[0],[0]]
y = tf.gather_nd(x,indices)
```
#### Error log messages

  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/gen_array_ops.py"", line 814, in gather_nd
    name=name)
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/op_def_library.py"", line 704, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py"", line 2262, in create_op
    set_shapes_for_outputs(ret)
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py"", line 1702, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/array_ops.py"", line 1090, in _GatherNdShape
    indices_shape[-1].merge_with(params_shape.ndims)
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/tensor_shape.py"", line 133, in merge_with
    self.assert_is_compatible_with(other)
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/tensor_shape.py"", line 108, in assert_is_compatible_with
    % (self, other))
#### Error

ValueError: Dimensions 1 and 2 are not compatible
"
3711,mnist_with_summaries.py error 'module' object has no attribute 'DT_HALF',"when $python mnist_with_summaries.py
File ""mnist_with_summaries.py"", line 29, in <module>
    from tensorflow.examples.tutorials.mnist import input_data
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/examples/tutorials/mnist/**init**.py"", line 21, in <module>
    from tensorflow.examples.tutorials.mnist import input_data
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/examples/tutorials/mnist/input_data.py"", line 29, in <module>
    from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/**init**.py"", line 23, in <module>
    from tensorflow.contrib import distributions
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/distributions/**init**.py"", line 25, in <module>
    from tensorflow.contrib.distributions.python.ops import gaussian_conjugate_posteriors
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/distributions/python/ops/gaussian_conjugate_posteriors.py"", line 25, in <module>
    from tensorflow.contrib.distributions.python.ops.gaussian import Gaussian  # pylint: disable=line-too-long
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/distributions/python/ops/gaussian.py"", line 26, in <module>
    from tensorflow.contrib.framework.python.framework import tensor_util as contrib_tensor_util  # pylint: disable=line-too-long
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/framework/**init**.py"", line 43, in <module>
    from tensorflow.contrib.framework.python.framework import *
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/framework/python/framework/**init**.py"", line 22, in <module>
    from tensorflow.contrib.framework.python.framework.tensor_util import *
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/framework/python/framework/tensor_util.py"", line 40, in <module>
    from tensorflow.python.framework import dtypes
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/dtypes.py"", line 274, in <module>
    float16 = DType(types_pb2.DT_HALF)
AttributeError: 'module' object has no attribute 'DT_HALF'
"
3710,function.Defun can't be applied to tf.Variable,"I need to specify a custom gradient for my custom_op() function. I've written the following example.

```
import numpy as np
import tensorflow as tf
from tensorflow.python.framework import function

def custom_op_grad(op, grad):
    return grad

@function.Defun(x=tf.float32, python_grad_func=custom_op_grad)
def custom_op(x):
    exp = tf.exp(x)
    constant = tf.constant(1., dtype=tf.float32)
    add1 = tf.add(constant, exp)
    log = tf.log(add1)
    return log

x = tf.Variable(np.array(np.arange(6)).reshape(3, 2), dtype=tf.float32)

sess = tf.Session()
sess.run(tf.initialize_all_variables())

x = tf.identity(x)

grad = tf.gradients(custom_op(x), [x])[0]

res = sess.run(grad)

print(res)

sess.close()
```

If I run the above example as it is I get the following result:

```
[[ 1.  1.]
 [ 1.  1.]
 [ 1.  1.]]
```

If I comment out the @function.Defun(...) decorator (with I use to specify a custom gradient function) I get a different result:

```
[[ 0.5         0.7310586 ]
 [ 0.88079709  0.95257413]
 [ 0.98201376  0.99330717]]
```

That is strange because custom_op_grad(op, grad) just returns grad, which I guess should be the same as the gradient calculated in the second case.

Moreover, if I keep the decorator I also need to do this: x = tf.identity(x). If I comment out this line, I get the following error and I don't understand why:

```
Traceback (most recent call last):
  File ""custom_op3.py"", line 42, in <module>
    grad = tf.gradients(custom_op(x), [x])[0]
  File ""/Users/zeis/tfm/lib/python3.5/site-packages/tensorflow/python/framework/function.py"", line 528, in __call__
    return call_function(self._definition, *args, **kwargs)
  File ""/Users/zeis/tfm/lib/python3.5/site-packages/tensorflow/python/framework/function.py"", line 267, in call_function
    compute_shapes=False)
  File ""/Users/zeis/tfm/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 2285, in create_op
    raise TypeError(""Input #%d is not a tensor: %s"" % (idx, a))
TypeError: Input #0 is not a tensor: <tensorflow.python.ops.variables.Variable object at 0x10eb7d710>
```

I'm using the GitHub version of TensofFlow.
"
3709,random_uniform for int32 broken on GPU,"`tf.random_uniform` with `dtype=tf.int32` always produces `106199773` on GPU.

```
In [3]: with tf.device('/cpu'): print(tf.random_uniform([], 0, 10, dtype=tf.int32).eval())
6

In [4]: with tf.device('/gpu'): print(tf.random_uniform([], 0, 10, dtype=tf.int32).eval())
1061997773
```

Environment:
CentOS 7
TensorFlow 0.9.0
GTX TITAN X
CUDA 7.5
NVIDIA 367.27
"
3708,Can not access GPU when run python script with bazel,"When we're using TensorFlow serving to train our model, we have found that the program is not able to access all the GPUs in that machine. This can be 100% reproduced and we add the following code for testing.

```
from tensorflow.python.client import device_lib

def get_available_gpus():
    local_device_protos = device_lib.list_local_devices()
    return [x.name for x in local_device_protos if x.device_type == 'GPU']

print(get_available_gpus())
```

If we run the script with `python`, it prints all the GPUs normally. If we run with `bazel build` and `bazel run` for the same script, it prints the empty list.
### Environment info

Operating System: Ubuntu 14.04

Installed version of CUDA and cuDNN: 
CUDA 7.5 and cuDNN 4.0

If installed from binary pip package, provide:
TensorFlow 0.9.0
### Steps to reproduce
1. `git clone https://github.com/tensorflow/tensorflow && cd tensorflow/`
2. Add the code to print GPUs or placements of the operations in mnist_with_summaries.py
3. `python tensorflow/examples/tutorials/mnist/mnist_with_summaries.py` and we can see all the GPUs in this server.
4. `bazel build //tensorflow/examples/tutorials/mnist:mnist_with_summaries`
5. `bazel-bin/tensorflow/examples/tutorials/mnist/mnist_with_summaries` and it use CPU only and print nothing about GPUs.
"
3706,Error: the tensor's graph is different from the session's graph,"I am using my previously trained models to generate deep dream images as decscribe in one of the [tutorials](https://render.githubusercontent.com/view/ipynb?commit=0685152a02f1fd4dbd711a023c1ccea5a8b8262b&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f74656e736f72666c6f772f74656e736f72666c6f772f303638353135326130326631666434646264373131613032336331636365613561386238323632622f74656e736f72666c6f772f6578616d706c65732f7475746f7269616c732f64656570647265616d2f64656570647265616d2e6970796e62&nwo=tensorflow%2Ftensorflow&path=tensorflow%2Fexamples%2Ftutorials%2Fdeepdream%2Fdeepdream.ipynb&repository_id=45717250#deepdream). But when I try to call the render_deepdream method I am getting below error:

> I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 
> I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y 
> I tensorflow/core/common_runtime/gpu/gpu_device.cc:806] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:83:00.0)
> # Succesfully loaded model from /data/model_cache/model.ckpt-39 at step=39.
> 
> (3648, 5472)
> Traceback (most recent call last):
>   File ""imagenet_eval.py"", line 46, in <module>
>     tf.app.run()
>   File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
>     sys.exit(main(sys.argv))
>   File ""imagenet_eval.py"", line 42, in main
>     inception_eval.evaluate(dataset)
>   File ""/home/ubuntu/experiment/models/inception/inception/inception_eval.py"", line 192, in evaluate
>     _eval_once(saver, summary_writer, top_1_op, top_5_op, summary_op)
>   File ""/home/ubuntu/experiment/models/inception/inception/inception_eval.py"", line 156, in _eval_once
>     render_deepdream(tf.square(T('inception_v3/mixed_8x8x2048b/concat',graph)), img0=img0, session=sess)
>   File ""/home/ubuntu/experiment/models/inception/inception/inception_eval.py"", line 94, in render_deepdream
>     lo = resize(img, np.int32(np.float32(hw)/octave_scale), session=session)
>   File ""/home/ubuntu/experiment/models/inception/inception/inception_eval.py"", line 66, in wrapper
>     return out.eval(dict(zip(placeholders, args)), session=kw.get('session'))
>   File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 555, in eval
>     return _eval_using_default_session(self, feed_dict, self.graph, session)
>   File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 3495, in _eval_using_default_session
>     raise ValueError(""Cannot use the given session to evaluate tensor: ""
> ValueError: Cannot use the given session to evaluate tensor: the tensor's graph is different from the session's graph.

---

Below is the code that is causing the issue:

```
def tffunc(*argtypes):
    '''Helper that transforms TF-graph generating function into a regular one.
    See ""resize"" function below.
    '''
    placeholders = list(map(tf.placeholder, argtypes))
    def wrap(f):
        out = f(*placeholders)
        def wrapper(*args, **kw):
            #from IPython import embed
            #embed()
            return out.eval(dict(zip(placeholders, args)), session=kw.get('session'))
        return wrapper
    return wrap

def resize(img, size):
    img = tf.expand_dims(img, 0)
    return tf.image.resize_bilinear(img, size)[0,:,:,:]
resize = tffunc(np.float32, np.int32)(resize)
```

This is the line causing issue: https://github.com/umerebryx/Inference/blob/master/inference_eval.py#L60
You can also view full code in above mentioned repo. Any help would be much appreciated as I am stuck at this for days now. Thanks in advance. 
"
3705,Distributed seq2seq model stuck at the session.run(),"I'm applying the distributed seq2seq model:
   1 ps
   2 workers
but stuck at the 

> sess.run(output_feed, input_feed) 
> in the seq2seq_model.py, even though my params are very small(1 layers of 10 units)

my problem like the question on the below in stackoverflow:
(http://stackoverflow.com/questions/38319953/tensorflow-applying-syncreplicasoptimizer-to-seq2seq-model-with-buckets).

Tensorflow version: 0.9-GPU_Support

This is the log output:

> start running session
> I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 7293 get requests, put_count=3583 evicted_count=1000 eviction_rate=0.279096 and unsatisfied allocation rate=0.659537
> I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 100 to 110

And it seems like it's still running , the events file is updated as well:

> total 85560
> drwxr-xr-x 2 dl dl     4096 Aug  9 16:04 .
> drwxrwxr-x 9 dl dl     4096 Aug  9 15:59 ..
> -rw-rw-r-- 1 dl dl      129 Aug  9 16:03 checkpoint
> -rw-rw-r-- 1 dl dl 23232412 Aug  9 **16:09 events.out.tfevents.1470772996.dl129**
> -rw-rw-r-- 1 dl dl 40464613 Aug  9 16:02 graph.pbtxt
> -rw-rw-r-- 1 dl dl   645001 Aug  9 16:03 model.ckpt-0
> -rw-rw-r-- 1 dl dl 23249486 Aug  9 16:04 model.ckpt-0.meta
> dl@dl129:~/PJT/train_logs$ ll
> total 85560
> drwxr-xr-x 2 dl dl     4096 Aug  9 16:13 .
> drwxrwxr-x 9 dl dl     4096 Aug  9 15:59 ..
> -rw-rw-r-- 1 dl dl      129 Aug  9 16:13 checkpoint
> -rw-rw-r-- 1 dl dl 23232512 Aug  9 **16:13 events.out.tfevents.1470772996.dl129**
> -rw-rw-r-- 1 dl dl 40464613 Aug  9 16:02 graph.pbtxt
> -rw-rw-r-- 1 dl dl   645001 Aug  9 16:13 model.ckpt-0
> -rw-rw-r-- 1 dl dl 23249486 Aug  9 16:14 model.ckpt-0.meta
> dl@dl129:~/PJT/train_logs$ 
"
3704,scalar_summary within map_fn hangs when run. ,"On tf 0.9, it seems that I cannot collect summaries from within map_fn. The following code would reproduce the problem: 

```

import tensorflow as tf

summaries = []
def summarize_and_plus_one(inp):
    summaries.append(tf.scalar_summary('inp_%s' % inp, inp))
    inp += 1
    return inp

a = tf.constant([1,2,3,4])
b = tf.map_fn(summarize_and_plus_one, a)

with tf.Session() as sess:
    print(sess.run(b))
    sess.run(tf.merge_all_summaries()) # The code would hang here. 

```

If I unpack first and apply the function without map_fn, the code finishes as expected: 

```

import tensorflow as tf

summaries = []
def summarize_and_plus_one(inp):
    summaries.append(tf.scalar_summary('inp_%s' % inp, inp))
    inp += 1
    return inp

a = tf.constant([1,2,3,4])

res = []
for x in tf.unpack(a):
    res.append(summarize_and_plus_one(x))
b = tf.pack(res)

with tf.Session() as sess:
    print(sess.run(b))
    sess.run(tf.merge_all_summaries())

```

Is this a known issue? It seems the problem is with map_fn (or while_loop). 
"
3703,"tf.contrib.learn.TensorFlowRNNRegressor: ""inputs must be a list!""","> import numpy as np
> from tensorflow.contrib.learn import TensorFlowRNNRegressor
> import tensorflow as tf
> X = [[1, 2, 3, 4, 5], [1, 2, 3, 4, 5], [1, 2, 3, 4, 5]]
> y = [1, 1, 1]
> regr = TensorFlowRNNRegressor(rnn_size=5)
> regr.fit(np.array(X), np.array(y))

**throws error:
Traceback (most recent call last):
  File ""rnn_test.py"", line 9, in <module>
    regr.fit(np.array(X), np.array(y))
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/contrib/learn/python/learn/estimators/base.py"", line 160, in fit
    monitors=monitors)
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 449, in _train_model
    train_op, loss_op = self._get_train_ops(features, targets)
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 673, in _get_train_ops
    _, loss, train_op = self._call_model_fn(features, targets, ModeKeys.TRAIN)
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 656, in _call_model_fn
    features, targets, mode=mode)
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/contrib/learn/python/learn/estimators/base.py"", line 369, in _model_fn
    predictions, loss = model_fn(features, targets)
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/contrib/learn/python/learn/estimators/rnn.py"", line 205, in _model_fn
    self.initial_state)(X, y)
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/contrib/learn/python/learn/models.py"", line 399, in rnn_estimator
    initial_state=initial_state)
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/rnn.py"", line 98, in rnn
    raise TypeError(""inputs must be a list"")
TypeError: inputs must be a list**

But no problem with DNNRegressor
Thank you in advance for your time
"
3701,tensorflow won't release system memroy,"Hi all,

I started to use tensorflow one month ago. I briefly use it to train neural machine translation models.
I find that after several times of training,  there were a huge amount of memory not released. I have to reboot my machine after some numbers of training to release those memory.

I use the sample code( tensorflow/models/rnn/translate python translate.py) to train the model.
### Environment info

Operating System: Ubuntu 14.04.4 LTS

tensorflow version: r.0.10

CUDA version: libcudnn.so.4.0
If installed from binary pip package, provide:
### What have you tried?

1.
Add a maximum step number to terminate training normally.
1. replace 
   
   with tf.Session() as sess:

with the following code:

  config = tf.ConfigProto()
  config.gpu_options.allow_growth=True
  sess = tf.Session(config=config)

  with tf.Graph().as_default(),sess:
1. close the session after training
   sess.close()
   del sess
2. the version of my nvidia driver is 352.79 now.
   I will update it to the latest version next week. 

I have no idea what to do now.

Thanks!
Best,
xiaorongfan
"
3699,inline compiler switch for __memcpy_inline?,"Trying to build tensorflow on Ubuntu 16.04 with cuda 7.5 and gcc 4.9.3.

```
INFO: From Compiling tensorflow/core/kernels/batchtospace_op_gpu.cu.cc:
nvcc warning : option '--relaxed-constexpr' has been deprecated and replaced by option '--expt-relaxed-constexpr'.
nvcc warning : option '--relaxed-constexpr' has been deprecated and replaced by option '--expt-relaxed-constexpr'.
/usr/include/string.h: In function 'void* __mempcpy_inline(void*, const void*, size_t)':
/usr/include/string.h:652:42: error: 'memcpy' was not declared in this scope
   return (char *) memcpy (__dest, __src, __n) + __n;
                                          ^
```

I think __memcpy_inline needs an inline compiler switch turned on but this is the first time I've used bazel, and just what where?
"
3696,conv3d_transpose not freeing memory,"This issue might be the same as #3128 (which is still awaiting Googler), but it is occurring in a different way. The above issue was run on a CPU. I have since upgrade to a GTX 1070 with 8GB RAM. 

Instead of a Segmentation Fault, the program now runs until it runs out of memory -- in my case it runs for roughly 2000 iterations. Running on a CPU was spitting our a `free()` error, which leads me to believe this is the same underlying issue. 

The error log looks like this...

```
I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (134217728):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (268435456):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:656] Bin for 14.36MiB was 8.00MiB, Chunk State: 
I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0x10005a00000 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0x10005a00100 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0x10005a00200 of size 256


... a ton of other chunks

I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0x101a1686e00 of size 100362240
I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0x101a763d600 of size 15054336
I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0x101a8498c00 of size 199075840
I tensorflow/core/common_runtime/bfc_allocator.cc:683] Free at 0x10005c7cd00 of size 64000
I tensorflow/core/common_runtime/bfc_allocator.cc:683] Free at 0x10005d66600 of size 1638400
I tensorflow/core/common_runtime/bfc_allocator.cc:683] Free at 0x100063fcc00 of size 196608
I tensorflow/core/common_runtime/bfc_allocator.cc:683] Free at 0x10193467b00 of size 6272768
I tensorflow/core/common_runtime/bfc_allocator.cc:689]      Summary of in-use Chunks by size: 
I tensorflow/core/common_runtime/bfc_allocator.cc:692] 30 Chunks of size 256 totalling 7.5KiB
I tensorflow/core/common_runtime/bfc_allocator.cc:692] 4 Chunks of size 512 totalling 2.0KiB
I tensorflow/core/common_runtime/bfc_allocator.cc:692] 4 Chunks of size 3072 totalling 12.0KiB
I tensorflow/core/common_runtime/bfc_allocator.cc:692] 4 Chunks of size 16128 totalling 63.0KiB
I tensorflow/core/common_runtime/bfc_allocator.cc:692] 4 Chunks of size 65536 totalling 256.0KiB
I tensorflow/core/common_runtime/bfc_allocator.cc:692] 4 Chunks of size 262144 totalling 1.00MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:692] 5 Chunks of size 614400 totalling 2.93MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:692] 4 Chunks of size 1638400 totalling 6.25MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 3136512 totalling 2.99MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1061 Chunks of size 6272768 totalling 6.20GiB
I tensorflow/core/common_runtime/bfc_allocator.cc:692] 3 Chunks of size 15054336 totalling 43.07MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:692] 3 Chunks of size 100362240 totalling 287.14MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 199075840 totalling 189.85MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] Sum Total of in-use chunks: 6.72GiB
I tensorflow/core/common_runtime/bfc_allocator.cc:698] Stats: 
Limit:                  7223063348
InUse:                  7214891776
MaxInUse:               7214891776
NumAllocs:                  312188
MaxAllocSize:            199075840

W tensorflow/core/common_runtime/bfc_allocator.cc:270] ***************************************************************************************************x
W tensorflow/core/common_runtime/bfc_allocator.cc:271] Ran out of memory trying to allocate 14.36MiB.  See logs for memory state.
W tensorflow/core/framework/op_kernel.cc:940] Resource exhausted: OOM when allocating tensor with shape[1,32,3,198,198]
Traceback (most recent call last):
  File ""CNN-seg-3D.py"", line 208, in <module>
    keep_prob: dropout})
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 710, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 908, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 958, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 978, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.ResourceExhaustedError: OOM when allocating tensor with shape[1,32,3,198,198]
     [[Node: opt/gradients/conv1/MaxPool3D_grad/MaxPool3DGrad = MaxPool3DGrad[T=DT_FLOAT, ksize=[1, 2, 2, 2, 1], padding=""SAME"", strides=[1, 2, 2, 2, 1], _device=""/job:localhost/replica:0/task:0/gpu:0""](conv1/Relu, conv1/MaxPool3D, opt/gradients/conv2/Conv3D_grad/tuple/control_dependency)]]
Caused by op u'opt/gradients/conv1/MaxPool3D_grad/MaxPool3DGrad', defined at:
  File ""CNN-seg-3D.py"", line 181, in <module>
    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py"", line 196, in minimize
    grad_loss=grad_loss)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py"", line 253, in compute_gradients
    colocate_gradients_with_ops=colocate_gradients_with_ops)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients.py"", line 476, in gradients
    in_grads = _AsList(grad_fn(op, *out_grads))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_grad.py"", line 130, in _MaxPool3DGrad
    padding=op.get_attr(""padding""))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py"", line 1182, in max_pool3d_grad
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 703, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2317, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1239, in __init__
    self._traceback = _extract_stack()

...which was originally created as op u'conv1/MaxPool3D', defined at:
  File ""CNN-seg-3D.py"", line 168, in <module>
    pred = conv_net(x, weights, biases, keep_prob)
  File ""CNN-seg-3D.py"", line 97, in conv_net
    conv1 = maxpool3d(conv1, k=2)
  File ""CNN-seg-3D.py"", line 78, in maxpool3d
    padding='SAME')
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py"", line 1150, in max_pool3d
    strides=strides, padding=padding, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 703, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2317, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1239, in __init__
    self._traceback = _extract_stack()
```
"
3694,Fail to build from source ,"Hi all,

I just try to build tensorflow from source according to the steps described step by step, but I get the following error, anyone can help on it?
Thanks!

alvin@hal-dev:~/tensorflow-r0.9$ bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer
Found stale PID file (pid=29629). Server probably died abruptly, continuing...
.
unexpected pipe read status: Connection refused
Server presumed dead. Now printing '/home/alvin/.cache/bazel/_bazel_alvin/098c27509f757cf22af83c9a7d1d8ec7/server/jvm.out':
java.lang.AssertionError: java.security.NoSuchAlgorithmException: MD5 MessageDigest not available
    at com.google.common.hash.MessageDigestHashFunction.getMessageDigest(MessageDigestHashFunction.java:79)
    at com.google.common.hash.MessageDigestHashFunction.<init>(MessageDigestHashFunction.java:40)
    at com.google.common.hash.Hashing$Md5Holder.<clinit>(Hashing.java:191)
    at com.google.common.hash.Hashing.md5(Hashing.java:187)
    at com.google.devtools.build.lib.analysis.BlazeDirectories.checkMD5(BlazeDirectories.java:95)
    at com.google.devtools.build.lib.analysis.BlazeDirectories.<init>(BlazeDirectories.java:74)
    at com.google.devtools.build.lib.runtime.BlazeRuntime.newRuntime(BlazeRuntime.java:926)
    at com.google.devtools.build.lib.runtime.BlazeRuntime.createBlazeRPCServer(BlazeRuntime.java:781)
    at com.google.devtools.build.lib.runtime.BlazeRuntime.serverMain(BlazeRuntime.java:726)
    at com.google.devtools.build.lib.runtime.BlazeRuntime.main(BlazeRuntime.java:519)
    at com.google.devtools.build.lib.bazel.BazelMain.main(BazelMain.java:56)
Caused by: java.security.NoSuchAlgorithmException: MD5 MessageDigest not available
    at sun.security.jca.GetInstance.getInstance(GetInstance.java:159)
    at java.security.Security.getImpl(Security.java:695)
    at java.security.MessageDigest.getInstance(MessageDigest.java:167)
    at com.google.common.hash.MessageDigestHashFunction.getMessageDigest(MessageDigestHashFunction.java:77)
    ... 10 more
"
3693,MNIST TensorFlow Website Example problem,"Hi! When i run the example of MNIST Deep model (got on the tensorflow website) in a jupyter notebook i get this error: The kernel appears to have died. It will restart automatically.
This happens in the line: 
print(""test accuracy %g""%accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))

COMPLETE CODE TENSORFLOW WEBSITE:
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets(""MNIST_data/"", one_hot=True)

from **future** import absolute_import
from **future** import division
from **future** import print_function

import gzip
import os
import tempfile

import numpy
from six.moves import urllib
from six.moves import xrange  # pylint: disable=redefined-builtin
import tensorflow as tf
from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets

sess = tf.InteractiveSession()

x = tf.placeholder(tf.float32, shape=[None, 784])
y_ = tf.placeholder(tf.float32, shape=[None, 10])
W = tf.Variable(tf.zeros([784,10]))
b = tf.Variable(tf.zeros([10]))
sess.run(tf.initialize_all_variables())

y = tf.nn.softmax(tf.matmul(x,W) + b)
cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ \* tf.log(y), reduction_indices=[1]))
train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)
for i in range(1000):
  batch = mnist.train.next_batch(100)
  train_step.run(feed_dict={x: batch[0], y_: batch[1]})

correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
print(accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels}))

def weight_variable(shape):
  initial = tf.truncated_normal(shape, stddev=0.1)
  return tf.Variable(initial)

def bias_variable(shape):
  initial = tf.constant(0.1, shape=shape)
  return tf.Variable(initial)
def conv2d(x, W):
  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')

def max_pool_2x2(x):
  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],
                        strides=[1, 2, 2, 1], padding='SAME')

W_conv1 = weight_variable([5, 5, 1, 32])
b_conv1 = bias_variable([32])

x_image = tf.reshape(x, [-1,28,28,1])

h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)
h_pool1 = max_pool_2x2(h_conv1)

W_conv2 = weight_variable([5, 5, 32, 64])
b_conv2 = bias_variable([64])

h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)
h_pool2 = max_pool_2x2(h_conv2)

W_fc1 = weight_variable([7 \* 7 \* 64, 1024])
b_fc1 = bias_variable([1024])

h_pool2_flat = tf.reshape(h_pool2, [-1, 7_7_64])
h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)

keep_prob = tf.placeholder(tf.float32)
h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)

W_fc2 = weight_variable([1024, 10])
b_fc2 = bias_variable([10])

y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)

cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ \* tf.log(y_conv), reduction_indices=[1]))
train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)
correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

sess.run(tf.initialize_all_variables())

for i in range(200):
  batch = mnist.train.next_batch(50)
  if i%100 == 0:
    train_accuracy = accuracy.eval(feed_dict={
        x:batch[0], y_: batch[1], keep_prob: 1.0})
    print(""step %d, training accuracy %g""%(i, train_accuracy))
  train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})

print(""test accuracy %g""%accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))

Please, help! Thanks!!
"
3692,tf.tile() doesn't propagate shapes when `multiples` argument depends on a placeholder,"From [this Stack Overflow question](http://stackoverflow.com/q/38806136/3574081):

> I have a variable a of dimension (1, 5) which I want to 'tile' as many times as the size of my mini-batch. For example, if the mini-batch size is 32 then I want to construct a tensor `c` of dimension (32, 5) where each row has values the same as the original (1, 5) variable `a`.
> 
> But I only know the mini-batch size at run time: it's the size of dimension 0 of a placeholder `b`: `tf.shape(b)[0]`
> 
> Here's my code to construct c:
> 
> ``` python
> a  = tf.Variable(np.random.uniform(size=(1,5)))
> b = tf.placeholder(shape=[None, 12], dtype=tf.float32)
> batch_size = tf.shape(b)[0]
> c = tf.tile(a, tf.pack([batch_size, 1]))
> ```
> 
> This runs fine. However `c.get_shape()` returns `(?, ?)`. I don't understand why this doesn't return `(?, 5)` instead.
> 
> This is causing an issue later in my code when I construct a matrix variable `W` with number of columns `c.get_shape()[1]` which I expect to return 5 rather than ?.
> 
> Any help would be appreciated. Thanks.

The solution is to use `tensor_util.constant_value_as_shape()` in the shape function for `tf.tile()`. I have a fix pending.
"
3690,MNIST Prediction,"I used the MNIST-EXPERT.py to create a model by adding this to the end:

`save_path = saver.save(sess, ""model.ckpt"")`
`print (""Model saved in file: "", save_path)`

Now that I have saved a model, how do I give it a picture of handwriting so it can figure it out?

Thanks
"
3689,AttributeError: 'module' object has no attribute 'session',"not an issue. please delete
"
3688,Error when trying to run tensorboard --logdir=some_path,"Hi,

I am using python 2.7 on Mac 10.11.4.

I get errors when I am trying to run tensorboard --logdir=path

where path is some path I have specified, i.e. 'visualizations'

It correctly creates the directory visualizations in my current working directory, but

if I run: tensorboard --logdir=path, I get:
SyntaxError: can't assign to operator

If I try: tensorboard --logdir=visualizations, I get:
SyntaxError: can't assign to operator

If I try: tensorboard --logdir=/visualizations/, I get:
SyntaxError: invalid syntax

Please help me! And I would really appreciate an explanation for this, as I am relatively new to all this.

Thanks a lot in advance!
"
3687,slice shape inference bug,"At current HEAD 32bd3d024f33e920a67a1081bc0ae0048350fdee with the following code,

```
A = tf.placeholder(tf.float32, [None, 10])
B = A[:5, :]
B.get_shape()
```

The first dimension of B is unknown, but should be known. I have to use the `tf.slice` function to get the shape back:

```
A = tf.placeholder(tf.float32, [None, 10])
B = tf.slice(A, [0,0], [5, -1])
B.get_shape()
```
"
3686,C++ API Usage :No such file or directory,"Hello

I am trying to run the image recognition library but have the error below. 

I run :

wget https://storage.googleapis.com/download.tensorflow.org/models/inception_dec_2015.zip -O tensorflow/examples/label_image/data/inception_dec_2015.zip

Error 

tensorflow/examples/label_image/data/inception_dec_2015.zip: No such file or directory
"
3685,Unable to generate signed APK for project based on Android demo,"I wrote a simple app based on the Android demo that I got running successfully on my own device for debugging, using Bazel, and I'm planning on releasing it, but generating a signed APK fails.
### Environment info

Operating System: Ubuntu 14.04 LTS 64-bit

Installed version of CUDA and cuDNN: none

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`): fc9162975e52978d3af38549b570cc3cc5f0ab66
2. The output of `bazel version`

```
Build label: 0.3.0
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Jun 10 11:38:23 2016 (1465558703)
Build timestamp: 1465558703
Build timestamp as int: 1465558703
```
### Steps to reproduce
1. Follow instructions in #3444 up to setting up the Android Studio project
2. Run `./studio.sh` to open Android Studio
3. Open the Android demo as existing Android Studio project
4. (no prompt to configure appears)
5. Open ""File/Project Structure""
6. If src and res aren't set as source and resource directories respectively, do so
7. Select ""Generate Signed APK"" under Build, fails
### What have you tried?
1. Found the apks built by Bazel and tried to upload them. They were rejected by the Play Store.
2. Originally, the ""Generate Signed APK"" option wasn't available, but was fixed by deleting the project, reinstalling Android Studio, and then copying the project back in from a backup.
3. Cleaning. No change.
4. Solutions for similar errors suggest modifying the build tools version in the Gradle file, but this project doesn't use Gradle...
### Logs or other output

```
Error:Android Dex: [android] Exception in thread ""main"" java.lang.UnsupportedClassVersionError: com/android/dx/command/dexer/Main : Unsupported major.minor version 52.0
Error:Android Dex: [android] at java.lang.ClassLoader.defineClass1(Native Method)
Error:Android Dex: [android] at java.lang.ClassLoader.defineClass(ClassLoader.java:803)
Error:Android Dex: [android] at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
Error:Android Dex: [android] at java.net.URLClassLoader.defineClass(URLClassLoader.java:449)
Error:Android Dex: [android] at java.net.URLClassLoader.access$100(URLClassLoader.java:71)
Error:Android Dex: [android] at java.net.URLClassLoader$1.run(URLClassLoader.java:361)
Error:Android Dex: [android] at java.security.AccessController.doPrivileged(Native Method)
Error:Android Dex: [android] at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
Error:Android Dex: [android] at java.lang.ClassLoader.loadClass(ClassLoader.java:358)
Error:Android Dex: [android] at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
Error:Android Dex: [android] at java.lang.ClassLoader.loadClass(ClassLoader.java:425)
Error:Android Dex: [android] at org.jetbrains.android.compiler.tools.AndroidDxRunner.loadDex(AndroidDxRunner.java:79)
Error:Android Dex: [android] at org.jetbrains.android.compiler.tools.AndroidDxRunner.runDex(AndroidDxRunner.java:136)
Error:Android Dex: [android] at org.jetbrains.android.compiler.tools.AndroidDxRunner.main(AndroidDxRunner.java:336)
```
"
3684,ExponentialMovingAverage.variables_to_restore() treats all vars like they have averages,"Use:

```
ema = tf.train.ExponentialMovingAverage(0.9)
test = tf.Variable(0.1)
print(ema.variables_to_restore([test])
```

outputs `{u'Variable/ExponentialMovingAverage': <tensorflow.python.ops.variables.Variable object at 0x1139d1bd0>}`

I expect `variables_to_restore` not to append `/ExponentialMovingAverage` to the names of variables that do not have averages tracked.

I checked that `ema._averages` and `tf.get_collection(tf.GraphKeys.MOVING_AVERAGE_VARIABLES)` were indeed both empty.  Calling `ema.average_name(test)` produces the modified name and this appears to be done [specifically](https://github.com/tensorflow/tensorflow/blob/73ced9d797056c7e67a06ed2098dd809d85ec44a/tensorflow/python/training/moving_averages.py#L344) (perhaps for another reason).  So `variables_to_restore` incorrectly modifies the name because [it uses](https://github.com/tensorflow/tensorflow/blob/73ced9d797056c7e67a06ed2098dd809d85ec44a/tensorflow/python/training/moving_averages.py#L387) `average_name`.
"
3683,query - neuraltranslation.py,"I was trying to execute neural_translation.py but it is generating the below error
![aa3385a2-5c29-11e6-8cd4-90113fca1e45](https://cloud.githubusercontent.com/assets/18217467/17460473/ca2b6b7a-5c85-11e6-83fc-01191ba64098.png)
"
3682,Consider adding expm1 and log1p,"`expm1` is useful for inverting `tf.nn.softplus`:

```
def inverse_softplus(x):
    return tf.select(tf.gt(x, 80.0),
                     x,
                     tf.log(tf.expm1(x)))
```

`log1p` is useful for implementing `logaddexp`:

```
def logaddexp(x, y):
    temp = x - y
    return tf.select(tf.gt(temp, 0.0),
                     x + tf.log1p(tf.exp(-temp)),
                     y + tf.log1p(tf.exp(temp)))
```
"
3681,Segmentation Fault When Importing Tensorflow,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System: CentOS 6.8/RedHat 6.8

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
CUDA 7.5 + cuDNN v4

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`
### Steps to reproduce
1. Install tensorflow by using anaconda (conda command)
2. Install glibc ""locally"" and add the path /glibc-2.14/lib to LD_LIBRARY_PATH
3. Open python and use the command ""import tensorflow as tf"", and then you will get the message ""Segmentation Fault"". No other messages.
### What have you tried?
1. Use gdb to see what causes the segmentation fault.
### Logs or other output that would be helpful

gdb messages:
[New Thread 0x7f653bf9f700 (LWP 71825)]
[New Thread 0x7f653b59e700 (LWP 71826)]
[New Thread 0x7f6538b9d700 (LWP 71827)]
[New Thread 0x7f653619c700 (LWP 71828)]
[New Thread 0x7f653379b700 (LWP 71829)]
[New Thread 0x7f6530d9a700 (LWP 71830)]
[New Thread 0x7f652e399700 (LWP 71831)]
[New Thread 0x7f652b998700 (LWP 71832)]
[New Thread 0x7f6528f97700 (LWP 71833)]
[New Thread 0x7f6526596700 (LWP 71834)]
[New Thread 0x7f6523b95700 (LWP 71835)]
[New Thread 0x7f6521194700 (LWP 71836)]
[New Thread 0x7f651e793700 (LWP 71837)]
[New Thread 0x7f651bd92700 (LWP 71838)]
[New Thread 0x7f6519391700 (LWP 71839)]
[New Thread 0x7f6516990700 (LWP 71840)]
[New Thread 0x7f6513f8f700 (LWP 71841)]
[New Thread 0x7f651158e700 (LWP 71842)]
[New Thread 0x7f650eb8d700 (LWP 71843)]
[New Thread 0x7f650c18c700 (LWP 71844)]
[New Thread 0x7f650978b700 (LWP 71845)]
[New Thread 0x7f6506d8a700 (LWP 71846)]
[New Thread 0x7f6504389700 (LWP 71847)]
[New Thread 0x7f6501988700 (LWP 71848)]
[New Thread 0x7f64fef87700 (LWP 71849)]
[New Thread 0x7f64fc586700 (LWP 71850)]
[New Thread 0x7f64f9b85700 (LWP 71851)]
[New Thread 0x7f64f5184700 (LWP 71852)]
[New Thread 0x7f64f4783700 (LWP 71853)]
[New Thread 0x7f64f1d82700 (LWP 71854)]
[New Thread 0x7f64ef381700 (LWP 71855)]
[New Thread 0x7f64ec980700 (LWP 71856)]
[New Thread 0x7f64e9f7f700 (LWP 71857)]
[New Thread 0x7f64e757e700 (LWP 71858)]
[New Thread 0x7f64e4b7d700 (LWP 71859)]
[New Thread 0x7f64e217c700 (LWP 71860)]
[New Thread 0x7f64df77b700 (LWP 71861)]
[New Thread 0x7f64dcd7a700 (LWP 71862)]
[New Thread 0x7f64da379700 (LWP 71863)]
[New Thread 0x7f64d7978700 (LWP 71864)]
[New Thread 0x7f64d4f77700 (LWP 71865)]
[New Thread 0x7f64d2576700 (LWP 71866)]
[New Thread 0x7f64cfb75700 (LWP 71867)]
[New Thread 0x7f64cd174700 (LWP 71868)]
[New Thread 0x7f64ca773700 (LWP 71869)]
[New Thread 0x7f64c7d72700 (LWP 71870)]
[New Thread 0x7f64c5371700 (LWP 71871)]
[New Thread 0x7f64c2970700 (LWP 71872)]
[New Thread 0x7f64bff6f700 (LWP 71873)]
[New Thread 0x7f64bd56e700 (LWP 71874)]
[New Thread 0x7f64bab6d700 (LWP 71875)]
[New Thread 0x7f64b816c700 (LWP 71876)]
[New Thread 0x7f64b576b700 (LWP 71877)]
[New Thread 0x7f64b2d6a700 (LWP 71878)]
[New Thread 0x7f64b0369700 (LWP 71879)]

Program received signal SIGSEGV, Segmentation fault.
__pthread_init_static_tls (map=0x0) at allocatestack.c:1196
1196        init_one_static_tls (list_entry (runp, struct pthread, list), map);
from /home/abc/Libraries/glibc-2.14/install/lib/libpthread.so.0

Because they are clusters, it is hard (or nearly impossible in the near future) to upgrade the OSs. I also have no root privilege.
At first, I got an error telling that I don't have glibc_2.14.so because RedHat/CentOS 6.8 only comes with glibc 2.12. Therefore, I locally compiled the glibc and added it to LD_LIBRARY_PATH. After then, the glibc_2.14 error disappeared and was replaced by another error ""Segmentation Fault"" (no other messages). Something like this:
import tensorflow as tf
Segmentation Fault
(tensorflow) bash-4.1$

I tried to use gdb to see what causes this error, and it turns out it is ""libpthread.so.0"".

Any ideas?

Thanks.
"
3680,error: can't copy 'tensorflow/models/embedding/gen_word2vec.py': doesn't exist,"I was installing TF from source like I always did but I'm having the following issue this time when running `bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg` I got

``` bash
~/python/tensorflow$ bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg
Sat Aug 6 16:07:12 EDT 2016 : === Using tmpdir: /tmp/tmp.TNJr7rCgpe
/tmp/tmp.TNJr7rCgpe ~/python/tensorflow
Sat Aug 6 16:07:12 EDT 2016 : === Building wheel
error: can't copy 'tensorflow/models/embedding/gen_word2vec.py': doesn't exist or not a regular file
```

plus, I can't find that file anywhere... did anything change or am I missing something?
"
3678,"New Feature:  Pascal, Cuda 8, Unified memory","Hi,

As Cuda 8 enables unified memory for Pascal GPU, combining CPU and GPU on the same address level, and enhancing the memory size available for GPU (with limited latency), using CPU RAM.

1) Is there a possibility to have larger than GPU ram NN+data (lower than CPU ram) for training in tensor flow ? (it would help reducing distributed computing/network latency) ?

ie, using the idea of  Oversubscribe GPU memory for large dataset/models.

here, CUDA API :  
http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-simplifying

Example of 64GB allocation on GPU:

```
void foo() {
// Allocate 64 GB on GPU, using CPU RAM
char *data;
size_t size = 64*1024*1024*1024;
cudaMallocManaged(&data, size);
}
```
"
3677,"TFLearn estimators not passing ""save_summary_steps""","I think this should be an easy fix (or it was to hack it in locally), but it looks like [supervisor.py:L560](https://github.com/tensorflow/tensorflow/blob/r0.10/tensorflow/contrib/learn/python/learn/estimators/estimator.py#L560) for release **r0.10** is calling `graph_actions._supervised_train` without passing the `save_summary_steps` parameter now configurable in RunConfig.

I was able to correct by adding `supervisor_save_summaries_steps=self._config.save_summary_steps` in the call to graph_actions._supervised_train and this worked as expected, with events showing in TensorBoard on a higher configured frequency than the default 100 steps.
"
3676,BatchNorm on GPU become very slow in latest TF,"Nightly built, python2 gpu, cuda 7.5, cudnn 4.0.7, archlinux. TitanX.
I run [batch_norm_benchmark.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/batch_norm_benchmark.py) and got the following output:

```
Forward convolution (lower layers).
cpu shape:4/3 #layers:10 mode:op scale:True train:False - 0.043865 secs
cpu shape:4/3 #layers:10 mode:py scale:True train:False - 0.053864 secs
cpu shape:4/3 #layers:10 mode:slow scale:True train:False - 0.088060 secs
=== op vs py: 22.8% ===
=== py vs slow: 63.5% ===
gpu shape:4/3 #layers:10 mode:op scale:True train:False - 0.287913 secs
gpu shape:4/3 #layers:10 mode:py scale:True train:False - 0.284179 secs
gpu shape:4/3 #layers:10 mode:slow scale:True train:False - 0.287409 secs
=== op vs py: -1.3% ===
=== py vs slow: 1.1% ===
Forward/backward convolution (lower layers).
cpu shape:4/3 #layers:10 mode:op scale:True train:True - 0.220112 secs
cpu shape:4/3 #layers:10 mode:py scale:True train:True - 0.201284 secs
cpu shape:4/3 #layers:10 mode:slow scale:True train:True - 0.295103 secs
=== op vs py: -8.6% ===
=== py vs slow: 46.6% ===
gpu shape:4/3 #layers:10 mode:op scale:True train:True - 2.108785 secs
gpu shape:4/3 #layers:10 mode:py scale:True train:True - 0.578407 secs
gpu shape:4/3 #layers:10 mode:slow scale:True train:True - 0.863753 secs
=== op vs py: -59.0% ===
=== py vs slow: -96.6% ===
Forward convolution (higher layers).
cpu shape:4/3 #layers:10 mode:op scale:True train:False - 0.025443 secs
cpu shape:4/3 #layers:10 mode:py scale:True train:False - 0.033344 secs
cpu shape:4/3 #layers:10 mode:slow scale:True train:False - 0.048162 secs
=== op vs py: 31.1% ===
=== py vs slow: 44.4% ===
gpu shape:4/3 #layers:10 mode:op scale:True train:False - 0.164241 secs
gpu shape:4/3 #layers:10 mode:py scale:True train:False - 0.161473 secs
gpu shape:4/3 #layers:10 mode:slow scale:True train:False - 0.163212 secs
=== op vs py: -1.7% ===
=== py vs slow: 1.1% ===
Forward/backward convolution (higher layers).
cpu shape:4/3 #layers:10 mode:op scale:True train:True - 0.111931 secs
cpu shape:4/3 #layers:10 mode:py scale:True train:True - 0.118556 secs
cpu shape:4/3 #layers:10 mode:slow scale:True train:True - 0.163289 secs
=== op vs py: 5.9% ===
=== py vs slow: 37.7% ===
gpu shape:4/3 #layers:10 mode:op scale:True train:True - 1.194288 secs
gpu shape:4/3 #layers:10 mode:py scale:True train:True - 0.329403 secs
gpu shape:4/3 #layers:10 mode:slow scale:True train:True - 0.491005 secs
=== op vs py: -72.4% ===
=== py vs slow: 49.1% ===
Forward fully-connected.
cpu shape:2/1 #layers:10 mode:py scale:True train:False - 0.001866 secs
cpu shape:2/1 #layers:10 mode:slow scale:True train:False - 0.002859 secs
=== py vs slow: 53.2% ===
gpu shape:2/1 #layers:10 mode:py scale:True train:False - 0.002420 secs
gpu shape:2/1 #layers:10 mode:slow scale:True train:False - 0.002523 secs
=== py vs slow: 4.3% ===
Forward/backward fully-connected.
cpu shape:2/1 #layers:10 mode:py scale:True train:True - 0.004973 secs
cpu shape:2/1 #layers:10 mode:slow scale:True train:True - 0.006781 secs
=== py vs slow: 36.4% ===
gpu shape:2/1 #layers:10 mode:py scale:True train:True - 0.006370 secs
gpu shape:2/1 #layers:10 mode:slow scale:True train:True - 0.008182 secs
=== py vs slow: 28.4% ===
```

Although `sess.run` in a loop might not be an accurate way to benchmark, I think the performance regression exists because running the same script with an earlier binary built (not sure which commit it is) is 10x-20x faster.
"
3675,Source-compiled 0.9.0 version performs worse than binary-installed one,"I'm running my ResNet-32 benchmark model. My code looks quite similar with the code in TensorFlow GitHub:

https://github.com/tensorflow/tensorflow/tree/master/tensorflow/models/image/cifar10

but the model is changed into my own ResNet-32 implementation. 

I'm measuring how long it takes to train a minibatch with size 128, and here are brief results. I used one GPU, 64bit Ubuntu 14.04 and Python 2.7 for all experiments.

| TensorFlow Version | CUDA/cuDNN Version | GPU | Elapsed Time (ms) |
| :-: | :-: | :-: | :-: |
| 0.9.0 (pip installed) | 7.5 / 4.0.7 | GTX Titan X | 75 |
| 0.9.0 (745f16f790d2f9abf2c6a70d6b383b152cca3cff) | 8.0 RC / 5.0.5 | GTX 1080 | 330 |
| 0.8.0 (ea9e00a630f91a459dd5858cb22e8cd1a666ba4e) | 8.0 RC / 5.0.5 | GTX 1080 | 60 |

The 0.8.0 version commit contains the first support for CUDA 8.0 RC as far as I know and I found this to use my GTX 1080 without performance drop. Now I can use it with reasonable performance, but I want to figure out why the 0.9.0 compiled version is 4 times slower than before.
"
3674,PIP installation error due to libcuda.so.1 not found,"I encountered a strange error after installing tensorflow through pip: the tensorflow says it cannot find libcuda.so.1, which should not exist. Does anyone know how to fix it? Thanks for help!
### Environment info

Operating System:
CentOS 6
Installed version of CUDA and cuDNN: 
Cuda 7.5 and cudnnv4

If installed from binary pip package, provide:
1. Which pip package you installed.
   https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.10.0rc0-cp34-cp34m-linux_x86_64.whl
### Logs or other output that would be helpful

I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:102] Couldn't open CUDA library libcuda.so.1. LD_LIBRARY_PATH: /usr/local/GNU/gcc-4.9.2/lib64:/usr/local/cuda-7.5/lib64:/csproject/dygroup2/czeng/venv/lib:/usr/lib64/:/csproject/dygroup2/czeng/venv/cudnnv4/lib64
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:160] hostname: client108
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:185] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:356] driver version file contents: """"""NVRM version: NVIDIA UNIX x86_64 Kernel Module  352.93  Tue Apr  5 18:18:24 PDT 2016
GCC version:  gcc version 4.4.7 20120313 (Red Hat 4.4.7-17) (GCC)
""""""
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] kernel reported version is: 352.93.0
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1077] LD_LIBRARY_PATH: /usr/local/GNU/gcc-4.9.2/lib64:/usr/local/cuda-7.5/lib64:/csproject/dygroup2/czeng/venv/lib:/usr/lib64/:/csproject/dygroup2/czeng/venv/cudnnv4/lib64
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1078] failed to find libcuda.so on this system: Failed precondition: could not dlopen DSO: libcuda.so.1; dlerror: libcuda.so.1: cannot enable executable stack as shared object requires: Operation not permitted
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
E tensorflow/stream_executor/cuda/cuda_driver.cc:491] failed call to cuInit: CUDA_ERROR_NO_DEVICE
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:153] retrieving CUDA diagnostic information for host: client108
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:160] hostname: client108
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:185] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:356] driver version file contents: """"""NVRM version: NVIDIA UNIX x86_64 Kernel Module  352.93  Tue Apr  5 18:18:24 PDT 2016
GCC version:  gcc version 4.4.7 20120313 (Red Hat 4.4.7-17) (GCC)
""""""
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] kernel reported version is: 352.93.0
"
3673,Android demo crashes when package name is changed,"### Environment info

Operating System: Ubuntu 14.04 LTS 64-bit
Installed version of CUDA and cuDNN: none (not using GPU)

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`): fc9162975e52978d3af38549b570cc3cc5f0ab66
2. The output of `bazel version`

```
Build label: 0.3.0
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Jun 10 11:38:23 2016 (1465558703)
Build timestamp: 1465558703
Build timestamp as int: 1465558703
```
### Steps to reproduce
1. Open Android demo in Android Studio (not imported)
2. Change org/tensorflow/demo folder names to any other package name
3. Use replace in path to replace org.tensorflow.demo with the new package name
4. Run `bazel mobile-install //tensorflow/examples/android:tensorflow_demo --start_app`
5. The demo crashes on startup with the message ""Unfortunately, TensorFlow Demo has stopped.""
### What have you tried?
1. Importing the demo into Android Studio instead of simply opening it. Was unable to build/run, even without changing package name.
2. Modifying the `tensorflow_jni.h` file to remove occurrences of `ORG_TENSORFLOW`, etc. with the changed package name in the same format, e.g. `COM_ME`.
3. Looked through other possibly relevant files for references to the old package name, didn't find anything else, though I might've overlooked some.
### Logs or other output that would be helpful

(no output)

Also, as a general question, if I wanted to create my own Android app using TensorFlow, what sort of configuration would I need to do? I haven't found any explanation of how the demo works.
"
3670,Update CUDA/cuDNN in Dockerfiles,"Currently, the Dockerfiles are using CUDA 7.5 and cuDNN v4:
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/docker/Dockerfile.devel-gpu#L1

Any chance of updating the Dockerfile to cuDNN v5 as a first step? It might be just a single-character fix :) cuDNN v5 is RC but stable AFAIK.

Ideally, it would be also useful for users with Pascal boards to also update to CUDA 8.0 as the next step (we now provide CUDA 8.0 RC on CentOS 7, ubuntu 14.04 and ubuntu 16.04). But I would understand if you prefer to wait until CUDA 8.0 is out of RC.

Related:
https://github.com/NVIDIA/nvidia-docker/pull/131

cc: @cbiffle @jendap @thatguymike
"
3669,Update Docker instructions,"Docker is supported as a way of using TensorFlow:
https://www.tensorflow.org/versions/r0.10/get_started/os_setup.html#docker-installation

> We provide 4 Docker images:
> 
> ```
> gcr.io/tensorflow/tensorflow: TensorFlow CPU binary image.
> gcr.io/tensorflow/tensorflow:latest-devel: CPU Binary image plus source code.
> gcr.io/tensorflow/tensorflow:latest-gpu: TensorFlow GPU binary image.
> gcr.io/tensorflow/tensorflow:latest-devel-gpu: GPU Binary image plus source code.
> ```

However, all those Docker images are 0.8, more than 3000 commits behind. An eon for TF ;)

```
$ nvidia-docker run -it --rm gcr.io/tensorflow/tensorflow:latest-devel-gpu python -c 'import tensorflow as tf; print tf.__version__'
[...]
0.8.0
```

Just below, you also mention the following:

> We also have tags with latest replaced by a released version (e.g., 0.10.0rc0-gpu).

However, I couldn't make it work for 0.10.0rc0 or 0.9.0:

```
$ docker run -it --rm gcr.io/tensorflow/tensorflow:0.10.0rc0-gpu
Unable to find image 'gcr.io/tensorflow/tensorflow:0.10.0rc0-gpu' locally
Pulling repository gcr.io/tensorflow/tensorflow
docker: Tag 0.10.0rc0-gpu not found in repository gcr.io/tensorflow/tensorflow.

$ docker run -it --rm gcr.io/tensorflow/tensorflow:0.9.0-gpu
Unable to find image 'gcr.io/tensorflow/tensorflow:0.9.0-gpu' locally
Pulling repository gcr.io/tensorflow/tensorflow
docker: Tag 0.9.0-gpu not found in repository gcr.io/tensorflow/tensorflow.

$ docker run -it --rm gcr.io/tensorflow/tensorflow:0.8.0-gpu
[I 17:56:59.525 NotebookApp] Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret
[... OK ...]
```

On GitHub, you have another set of [instructions](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/docker/README.md):

> We currently maintain three Docker container images:
> 
> ```
> gcr.io/tensorflow/tensorflow - TensorFlow with all dependencies - CPU only!
> 
> gcr.io/tensorflow/tensorflow:latest-gpu - TensorFlow with all dependencies and support for Nvidia Cuda
> ```
> 
> Note: We also publish the same containers into Docker Hub.

Same problem, `gcr.io/tensorflow/tensorflow:latest-gpu` is `0.8.0`
But in this case, the link to the DockerHub is useful. `latest` is still `0.8.0`:

```
$ nvidia-docker run -it --rm tensorflow/tensorflow:latest-devel-gpu python -c 'import tensorflow as tf; print tf.__version__'
0.8.0
```

But you do have version tags, and even nightly builds:

```
$ nvidia-docker run -it --rm tensorflow/tensorflow:0.9.0-devel-gpu python -c 'import tensorflow as tf; print tf.__version__'
0.9.0

$ nvidia-docker run -it --rm tensorflow/tensorflow:0.10.0rc0-devel-gpu python -c 'import tensorflow as tf; print tf.__version__'
0.10.0rc0

$ nvidia-docker run -it --rm tensorflow/tensorflow:nightly-devel-gpu python -c 'import tensorflow as tf; print tf.__version__'
0.10.0rc0
```

Can we fix `gcr.io`? Or the instructions?

Related:
https://github.com/tensorflow/tensorflow/issues/3482#issuecomment-235314786

cc @jendap @girving @thatguymike 
"
3667,convert tf.cond to constants failed by convert_variables_to_constants.,"### Environment info

Operating System:
Ubuntu 14.04.4 LTS

If installed from binary pip package, provide:
0.9.0
### Steps to reproduce

import tensorflow as tf
from tensorflow.python.framework.graph_util import convert_variables_to_constants

def save_model(sess, output_node_names, path = ""predict.pb""):
    output_list =  output_node_names
    output_graph_def = convert_variables_to_constants(sess, sess.graph_def, output_list)

X1 = tf.Variable(1.)
X2 = tf.Variable(1.)

cond_value = tf.Variable(True)
**cond_result = tf.cond(cond_value, lambda: tf.assign(X1, 2.), lambda: tf.assign(X2, 2.), name=""cond_result"")**
X3 = tf.add(X1, X2,""X3"")

with tf.Session() as sesh:
    sesh.run(tf.initialize_all_variables())
    #sesh.run(cond_result)
    save_model(sesh, [""X3"",])
### What have you tried?
1. Test above code, convert_variables_to_constants failed.
2.  If comment the line of tf.cond, call save model will be OK.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).

  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/graph_util.py"", line 226, in convert_variables_to_constants
    returned_variables = sess.run(variable_names)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 382, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 598, in _run
    processed_fetches = self._process_fetches(fetches)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 553, in _process_fetches
    'Tensor. (%s)' % (subfetch, fetch, str(e)))
ValueError: Fetch argument u'cond_result/Assign/Switch:1:0' of u'cond_result/Assign/Switch:1:0' cannot be interpreted as a Tensor. (The name 'cond_result/Assign/Switch:1:0' looks a like a Tensor name, but is not a valid one. Tensor names must be of the form ""<op_name>:<output_index>"".)

refer to: [https://github.com/tensorflow/tensorflow/issues/3287](url)
"
3665,cannot generate visual studio solution file on Windows 7,"### Environment info

Operating System:
Windows 7
### What have you tried?

1.on Windows 7 follow https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/cmake/README.md
when try to generate visual  studio sln file, error occurred.
### Logs or other output that would be helpful

CMakeError.log

Determining if the include file pthread.h exists failed with the following output:
Change Dir: C:/tensorflow/tensorflow/contrib/cmake/build/solution/CMakeFiles/CMakeTmp

Run Build Command:""C:/Program Files (x86)/MSBuild/12.0/bin/MSBuild.exe"" ""cmTC_184bb.vcxproj"" ""/p:Configuration=Debug"" ""/p:VisualStudioVersion=12.0""
Microsoft (R) Build Engine version 12.0.40629.0

[Microsoft .NET Framework, version 4.0.30319.42000]

Copyright (C) Microsoft Corporation. All rights reserved.

Build started 8/5/2016 8:36:31 PM.

Project ""C:\tensorflow\tensorflow\contrib\cmake\build\solution\CMakeFiles\CMakeTmp\cmTC_184bb.vcxproj"" on node 1 (default targets).

PrepareForBuild:

  Creating directory ""cmTC_184bb.dir\Debug\"".

  Creating directory ""C:\tensorflow\tensorflow\contrib\cmake\build\solution\CMakeFiles\CMakeTmp\Debug\"".

  Creating directory ""cmTC_184bb.dir\Debug\cmTC_184bb.tlog\"".

InitializeBuildStatus:

  Creating ""cmTC_184bb.dir\Debug\cmTC_184bb.tlog\unsuccessfulbuild"" because ""AlwaysCreate"" was specified.

ClCompile:

  C:\Program Files (x86)\Microsoft Visual Studio 12.0\VC\bin\x86_amd64\CL.exe /c /Zi /W3 /WX- /Od /Ob0 /D WIN32 /D _WINDOWS /D _DEBUG /D ""CMAKE_INTDIR=\""Debug\"""" /D _MBCS /Gm- /RTC1 /MDd /GS /fp:precise /Zc:wchar_t /Zc:forScope /Fo""cmTC_184bb.dir\Debug\"" /Fd""cmTC_184bb.dir\Debug\vc120.pdb"" /Gd /TC /errorReport:queue C:\tensorflow\tensorflow\contrib\cmake\build\solution\CMakeFiles\CMakeTmp\CheckIncludeFile.c

  Microsoft (R) C/C++ Optimizing Compiler Version 18.00.40629 for x64

  Copyright (C) Microsoft Corporation.  All rights reserved.

  cl /c /Zi /W3 /WX- /Od /Ob0 /D WIN32 /D _WINDOWS /D _DEBUG /D ""CMAKE_INTDIR=\""Debug\"""" /D _MBCS /Gm- /RTC1 /MDd /GS /fp:precise /Zc:wchar_t /Zc:forScope /Fo""cmTC_184bb.dir\Debug\"" /Fd""cmTC_184bb.dir\Debug\vc120.pdb"" /Gd /TC /errorReport:queue C:\tensorflow\tensorflow\contrib\cmake\build\solution\CMakeFiles\CMakeTmp\CheckIncludeFile.c

  CheckIncludeFile.c

C:\tensorflow\tensorflow\contrib\cmake\build\solution\CMakeFiles\CMakeTmp\CheckIncludeFile.c(1): fatal error C1083: Cannot open include file: 'pthread.h': No such file or directory [C:\tensorflow\tensorflow\contrib\cmake\build\solution\CMakeFiles\CMakeTmp\cmTC_184bb.vcxproj]

Done Building Project ""C:\tensorflow\tensorflow\contrib\cmake\build\solution\CMakeFiles\CMakeTmp\cmTC_184bb.vcxproj"" (default targets) -- FAILED.

Build FAILED.

""C:\tensorflow\tensorflow\contrib\cmake\build\solution\CMakeFiles\CMakeTmp\cmTC_184bb.vcxproj"" (default target) (1) ->

(ClCompile target) -> 

  C:\tensorflow\tensorflow\contrib\cmake\build\solution\CMakeFiles\CMakeTmp\CheckIncludeFile.c(1): fatal error C1083: Cannot open include file: 'pthread.h': No such file or directory [C:\tensorflow\tensorflow\contrib\cmake\build\solution\CMakeFiles\CMakeTmp\cmTC_184bb.vcxproj]

```
0 Warning(s)

1 Error(s)
```

Time Elapsed 00:00:00.36
"
3663,Error when using TensorArray and variables in nested loops,"Hi, I use r0.9 version but still have an error when use nested map_fn and a variable involved in calculations of inner function.

The error is 

tensorflow.python.framework.errors.InvalidArgumentError: Input 0 of node gradients/map/while/map/TensorArrayPack_grad/TensorArrayGrad/TensorArrayGrad was passed string from gradients/map/while/map/TensorArrayPack_grad/TensorArrayGrad/TensorArrayGrad/StackPop:0 incompatible with expected string_ref.

The code is

```
import tensorflow as tf

def inner_loop(t):
    def fn(n): return n + var # using var here leads to the error.
    return tf.map_fn(fn=fn, elems=t, parallel_iterations=1)

def outer_loop(input):
    def fn(n): return inner_loop(n) #if I would return inner_loop(n)+var here no errors appear.
    return tf.map_fn(fn=fn, elems=input, parallel_iterations=1)

with tf.Session() as sess:
    var = tf.Variable(tf.constant(1.0))
    input = tf.to_float(tf.convert_to_tensor([[1,2],[3,4],[5,6]]))
    res = outer_loop(input)
    optimizer = tf.train.AdamOptimizer(learning_rate=0.001)
    trainOperation = optimizer.minimize(tf.reduce_mean(tf.square(res)))
    sess.run(tf.initialize_all_variables())
    sess.run(trainOperation)
```
"
3660,cannot run on x86 emulator android example,"Linux Sabayon 4.3 on intel x86_64 platform 
- cannot build and run an apk for x86_64 cpu android emulator.
- bazel release 0.3.1-2016-08-02 (@8b4df1b)

I run this command in order to build the apk package that I would like to run on x86_64 emulator

bazel build --android_cpu=x86_64 //tensorflow/examples/android:tensorflow_demo

But in 
bazel-bin/tensorflow/examples/android/_dx/tensorflow_demo/native_symlinks/MANIFEST
I
 still see a link to an arm library...

I've  built the library for x86_64 with this

bazel build //tensorflow/examples/android:tensorflow_native_libs --crosstool_top=//external:android/crosstool --cpu=x86_64 --host_crosstool_top=@bazel_tools//tools/cpp:toolchain

I thought that specifying --android_cpu=x86_64 was enough to link the apk towards x86_64 native library

Kind regards.
Seba
"
3658,API for getting hidden layer state,"I'm using `tf.contrib.learn.TensorFlowDNNRegressor` and I'd like to get the hidden layers state after forward propagation (calling predict()). There doesn't seem to be an API to do this. Will one be provided in the future, or would I need to avoid `tf.contrib.learn`?
"
3657,"0.10.0rc0: Contrib distributions crash when sampling ""n"" is scalar","GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System: 
macOS 10.11

Installed version of CUDA and cuDNN: 
7.5 / 4

If installed from binary pip package, provide:
1. Which pip package you installed. 
   mac os / Python 3.5 / GPU / 0.10rc0
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   0.10.0rc0
### Steps to reproduce

``` python
import numpy as np
import tensorflow as tf
# this works
tf.contrib.distributions.MultivariateNormalDiag(np.ones(5), np.ones(5)).sample([1])
# crashes; scalar case is not handled
tf.contrib.distributions.MultivariateNormalDiag(np.ones(5), np.ones(5)).sample(1)
```
"
3654,archive.openswitch.net ssl cert path fails when installing syntaxnet.,"Hey guys,
We've been using your default bazel shell script, `https://github.com/bazelbuild/bazel/releases/download/0.2.2b/bazel-0.2.2b-installer-linux-x86_64.sh` for a while to create a syntaxnet docker image for internal use, and it's been working great. However recently (past couple of days) we've tried a rebuild that started failing with the following error message:

```
ERROR: /tmp/tensorflow/models/syntaxnet/tensorflow/tensorflow/workspace.bzl:84:3: no such package '@gmock_archive//': Error downloading from https://archive.open
switch.net/gmock-1.7.0.zip to /tmp/bazel/external/gmock_archive: Error downloading https://archive.openswitch.net/gmock-1.7.0.zip to /tmp/bazel/external/gmock_ar
chive/gmock-1.7.0.zip: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable t
o find valid certification path to requested target and referenced by '//external:gtest'.
```

From quick inspection, it looks like the ssl cert path failed for https://archive.openswitch.net within the bazel build operation, IE it might have a self-signed certificate.

This is a brand new bug for us with no changes to our image or infrastructure, which makes us think that it's related specifically to the external file hosting you guys have designated in the shell script.

Let me know if you need any other information to help
Thanks,
James
"
3652,No such package '@iron_list (Device or resource busy),"### Environment info

**Operating System:** Ubuntu 12.04

**Installed from source:**
**Commit Hash:** c5f94b10bbb30e525fa3ca313e7ccb173040c90a
**Output of ""bazel version"":**
WARNING: Output base '/home/user1/.cache/bazel/_bazel_user1/d49ce44fa50589aa9a9d880466ef1baf' is on NFS. This may lead to surprising failures and undetermined behavior.
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Thu Jan 01 00:00:00 1970 (0)
Build timestamp: Thu Jan 01 00:00:00 1970 (0)
Build timestamp as int: 0

Note: Not sure why the actual version doesn't appear in the output, but it is 0.2.2b.

**### Steps to reproduce**
1. git clone https://github.com/tensorflow/tensorflow
2. Installed Bazel
3. Installed other dependencies
4. ./configure
5. /usr/bin/python
6. N
7. N (Note: After this, the configuration ended.)
8. bazel build -c opt //tensorflow/tools/pip_package:build_pip_package

**Error Message:**
ERROR: /home/user1/Documents/tensorflow/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@iron_list//': /home/user1/.cache/bazel/_bazel_user1/d49ce44fa50589aa9a9d880466ef1baf/external/iron_list/.git/objects/pack/.nfs000000000189638500000904 (Device or resource busy) and referenced by '//tensorflow/tensorboard/bower:bower'.
ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted.
### What have you tried?
1. Downloaded the necessary files locally and linked to them in tensorflow/WORKSPACE, as well as in tensorflow/tensorflow/tensorboard/bower/BUILD, with no success (Note: This is my first time using bazel, so I may not have done this correctly.).
2. Googled the error; although many people seem to have bower-related errors with respect to downloading the files from GitHub, this seems to be a different type of error.
3. Reran the command many times.
4. Reinstalled nodejs, npm, and then bower on the computer and reran the command again.
### Logs or other output that would be helpful

**Full Log:**

> bazel build -c opt //tensorflow/tools/pip_package:build_pip_package
> WARNING: Output base '/home/user1.cache/bazel/_bazel_user1/d49ce44fa50589aa9a9d880466ef1baf' is on NFS. This may lead to surprising failures and undetermined behavior.
> WARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.io/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.
> WARNING: /home/user1/Documents/tensorflow/util/python/BUILD:11:16: in includes attribute of cc_library rule //util/python:python_headers: 'python_include' resolves to 'util/python/python_include' not in 'third_party'. This will be an error in the future.
> WARNING: /home/user1/.cache/bazel/_bazel_user1/d49ce44fa50589aa9a9d880466ef1baf/external/gemmlowp/BUILD:102:12: in hdrs attribute of cc_library rule @gemmlowp//:eight_bit_int_gemm: Artifact 'external/gemmlowp/public/bit_depth.h' is duplicated (through '@gemmlowp//:eight_bit_int_gemm_public_headers' and '@gemmlowp//:gemmlowp_headers').
> WARNING: /home/user1/.cache/bazel/_bazel_user1/d49ce44fa50589aa9a9d880466ef1baf/external/gemmlowp/BUILD:102:12: in hdrs attribute of cc_library rule @gemmlowp//:eight_bit_int_gemm: Artifact 'external/gemmlowp/public/gemmlowp.h' is duplicated (through '@gemmlowp//:eight_bit_int_gemm_public_headers' and '@gemmlowp//:gemmlowp_headers').
> WARNING: /home/user1/.cache/bazel/_bazel_user1/d49ce44fa50589aa9a9d880466ef1baf/external/gemmlowp/BUILD:102:12: in hdrs attribute of cc_library rule @gemmlowp//:eight_bit_int_gemm: Artifact 'external/gemmlowp/public/map.h' is duplicated (through '@gemmlowp//:eight_bit_int_gemm_public_headers' and '@gemmlowp//:gemmlowp_headers').
> WARNING: /home/user1/.cache/bazel/_bazel_user1/d49ce44fa50589aa9a9d880466ef1baf/external/gemmlowp/BUILD:102:12: in hdrs attribute of cc_library rule @gemmlowp//:eight_bit_int_gemm: Artifact 'external/gemmlowp/public/output_stages.h' is duplicated (through '@gemmlowp//:eight_bit_int_gemm_public_headers' and '@gemmlowp//:gemmlowp_headers').
> WARNING: /home/user1/.cache/bazel/_bazel_user1/d49ce44fa50589aa9a9d880466ef1baf/external/gemmlowp/BUILD:102:12: in hdrs attribute of cc_library rule @gemmlowp//:eight_bit_int_gemm: Artifact 'external/gemmlowp/profiling/instrumentation.h' is duplicated (through '@gemmlowp//:eight_bit_int_gemm_public_headers' and '@gemmlowp//:gemmlowp_headers').
> WARNING: /home/user1/.cache/bazel/_bazel_user1/d49ce44fa50589aa9a9d880466ef1baf/external/gemmlowp/BUILD:102:12: in hdrs attribute of cc_library rule @gemmlowp//:eight_bit_int_gemm: Artifact 'external/gemmlowp/profiling/profiler.h' is duplicated (through '@gemmlowp//:eight_bit_int_gemm_public_headers' and '@gemmlowp//:gemmlowp_headers').
> ERROR: /home/user1/Documents/tensorflow/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@iron_list//': /home/user1/.cache/bazel/_bazel_user1/d49ce44fa50589aa9a9d880466ef1baf/external/iron_list/.git/objects/pack/.nfs000000000189638500000904 (Device or resource busy) and referenced by '//tensorflow/tensorboard/bower:bower'.
> ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted.
> INFO: Elapsed time: 0.374s

**Additional Information:**
The package name in the error message rotates between iron_list, iron_icon, and iron_icons each new time the command is run.

Not sure whether this is relevant, but I am able to run the following commands for syntaxnet:
git clone --recursive https://github.com/tensorflow/models.git
cd models/syntaxnet/tensorflow
./configure
cd ..
bazel test syntaxnet/... util/utf8/...

with all tests reported as being passed.  The only changes made to the included files in order to pass all tests successfully were to:
1. Download gmock-1.7.0.zip manually, run the command: ""python -m SimpleHTTPServer 8000"", and change line 79 of workspace.bzl to: ""url = ""http://localhost:8000/gmock-1.7.0.zip"",""
2. Change line 25 of models/syntaxnet/syntaxnet/parser_trainer_test.sh to: ""BINDIR=$TEST_SRCDIR/$TEST_WORKSPACE/syntaxnet""

Please let me know if you require any other information!  Thanks in advance for your help.

-Natalie
"
3651,GTX 1070 source install bazel build -- Unsupported gpu architecture 'compute_61',"Here are my specs:
- Ubuntu 15.10 (potential conflict with CUDA 7.5?)
- NVIDIA GTX 1070 (compute capability 6.1)
- CUDA 7.5
- Cudnn v5.0

Error message:

```

ERROR: /usr/local/lib/python2.7/dist-packages/tensorflow/tensorflow/core/kernels/BUILD:1496:1: error while parsing .d file: /home/volcart/.cache/bazel/_bazel_root/109ad80a732aaece8a87d1e3693889e7/execroot/tensorflow/bazel-out/local_linux-opt/bin/tensorflow/core/kernels/_objs/batchtospace_op_gpu/tensorflow/core/kernels/batchtospace_op_gpu.cu.d (No such file or directory).
nvcc warning : option '--relaxed-constexpr' has been deprecated and replaced by option '--expt-relaxed-constexpr'.
nvcc fatal   : Unsupported gpu architecture 'compute_61'
Target //tensorflow/cc:tutorials_example_trainer failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 86.269s, Critical Path: 84.86s
```

It is clearly complaining about the compute capability. Is a compute capability of 6.1 supported? Surely.  

I am installing from source. 

Some dependency versions:

```
volcart@volcart-Precision-Tower-7910:/usr/local/lib/python2.7/dist-packages/tensorflow_src$ bazel version
Extracting Bazel installation...
.
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Thu Jan 01 00:00:00 1970 (0)
Build timestamp: Thu Jan 01 00:00:00 1970 (0)
Build timestamp as int: 0

volcart@volcart-Precision-Tower-7910:/usr/local/lib/python2.7/dist-packages/tensorflow_src$ gcc -v
Using built-in specs.
COLLECT_GCC=gcc
COLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-linux-gnu/4.9/lto-wrapper
Target: x86_64-linux-gnu
Configured with: ../src/configure -v --with-pkgversion='Ubuntu 4.9.3-5ubuntu1' --with-bugurl=file:///usr/share/doc/gcc-4.9/README.Bugs --enable-languages=c,c++,java,go,d,fortran,objc,obj-c++ --prefix=/usr --program-suffix=-4.9 --enable-shared --enable-linker-build-id --libexecdir=/usr/lib --without-included-gettext --enable-threads=posix --with-gxx-include-dir=/usr/include/c++/4.9 --libdir=/usr/lib --enable-nls --with-sysroot=/ --enable-clocale=gnu --enable-libstdcxx-debug --enable-libstdcxx-time=yes --enable-gnu-unique-object --disable-vtable-verify --enable-plugin --with-system-zlib --disable-browser-plugin --enable-java-awt=gtk --enable-gtk-cairo --with-java-home=/usr/lib/jvm/java-1.5.0-gcj-4.9-amd64/jre --enable-java-home --with-jvm-root-dir=/usr/lib/jvm/java-1.5.0-gcj-4.9-amd64 --with-jvm-jar-dir=/usr/lib/jvm-exports/java-1.5.0-gcj-4.9-amd64 --with-arch-directory=amd64 --with-ecj-jar=/usr/share/java/eclipse-ecj.jar --enable-objc-gc --enable-multiarch --disable-werror --with-arch-32=i686 --with-abi=m64 --with-multilib-list=m32,m64,mx32 --enable-multilib --with-tune=generic --enable-checking=release --build=x86_64-linux-gnu --host=x86_64-linux-gnu --target=x86_64-linux-gnu
Thread model: posix
gcc version 4.9.3 (Ubuntu 4.9.3-5ubuntu1) 


volcart@volcart-Precision-Tower-7910:/usr/local/lib/python2.7/dist-packages/tensorflow_src$ nvcc -V
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2015 NVIDIA Corporation
Built on Tue_Aug_11_14:27:32_CDT_2015
Cuda compilation tools, release 7.5, V7.5.17
```

When I execute `sudo ./configure` I have tried different varients. Namely, the default for all options -- I only have one version of CUDA and Cudnn installed. 

I've also tried the following confirguration -- to the same end...

```
volcart@volcart-Precision-Tower-7910:/usr/local/lib/python2.7/dist-packages/tensorflow_src$ sudo ./configure 
Please specify the location of python. [Default is /usr/bin/python]: 
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N] n
No Google Cloud Platform support will be enabled for TensorFlow
Do you wish to build TensorFlow with GPU support? [y/N] y
GPU support will be enabled for TensorFlow
Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: 
Please specify the Cuda SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 7.5
Please specify the location where CUDA 7.5 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 
Please specify the Cudnn version you want to use. [Leave empty to use system default]: 5
Please specify the location where cuDNN 5 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 
Please specify a list of comma-separated Cuda compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size.
[Default is: ""3.5,5.2""]: 6.1
Setting up Cuda include
Setting up Cuda lib64
Setting up Cuda bin
Setting up Cuda nvvm
Setting up CUPTI include
Setting up CUPTI lib64
Configuration finished

```

I noticed CUDA 7.5 only supports Ubuntu 15.04 -- could this be a problem since I'm on Ubuntu 15.10?
"
3649,Boolean operations on GPU are extremely slow,"ArchLinux. Cuda7.5. NIghtly TF built for Python2.

``` python
import tensorflow as tf
import time

v = tf.get_variable('test', shape=[100, 100, 100])
vb = tf.get_variable('test2', shape=[100, 100, 100], dtype=tf.bool,
        initializer=tf.constant_initializer(False))

b1 = tf.reduce_sum(v)
b2 = tf.reduce_all(vb)
b3 = tf.reduce_all(tf.cast(v, tf.bool))

sess = tf.Session()
sess.run(tf.initialize_all_variables())
with sess.as_default():
    start = time.time()
    for k in range(100):
        sess.run(b1)
    print time.time() - start   # 0.02s

    start = time.time()
    for k in range(100):
        sess.run(b2)
    print time.time() - start   # 7s!

    start = time.time()
    for k in range(100):
        sess.run(b3)
    print time.time() - start   # 17s!
```

CPU version of the same operation is also much faster than this.
"
3648,SKFlow - RNN - Tuple does not have dtype,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System: gcr docker image running in Ubuntu 16.04
### Steps to reproduce

Contact me via private message or twitter (@Data4Bots) and I can give you access to my Python Notebook to replicate full issue and let you see the entire thing.
### What have you tried?
1.  Not really sure where to begin with this one, it seems pretty odd on the surface to me.  I'll be digging in and taking suggestions.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).

$$$$$$$$$
$ Output $
$$$$$$$$$
AttributeErrorTraceback (most recent call last)
<ipython-input-9-ad53b65c4640> in <module>()
     22                         continue_training=True)
     23 
---> 24 classifier.fit(zip(_train)[0], zip(_test)[1])

/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/base.pyc in fit(self, X, y, monitor, logdir)
    216         self._data_feeder = setup_train_data_feeder(X, y,
    217                                                     self.n_classes,
--> 218                                                     self.batch_size)
    219 
    220         if monitor is None:

/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/io/data_feeder.pyc in setup_train_data_feeder(X, y, n_classes, batch_size)
     97                              ""streaming learning to work."")
     98         data_feeder_cls = StreamingDataFeeder
---> 99     return data_feeder_cls(X, y, n_classes, batch_size)
    100 
    101 

/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/io/data_feeder.pyc in **init**(self, X, y, n_classes, batch_size, random_state)
    187 
    188     def **init**(self, X, y, n_classes, batch_size, random_state=None):
--> 189         x_dtype = np.int64 if X.dtype == np.int64 else np.float32
    190         y_dtype = np.int64 if n_classes > 1 else np.float32
    191         self.X = check_array(X, dtype=x_dtype)

AttributeError: 'tuple' object has no attribute 'dtype'

$$$$$$$$$$$$$$$
$ Data Snapshot $
$$$$$$$$$$$$$$$
Labeled

 [array([128, 128, 128, ..., 128, 128, 128], dtype=uint8) 1]
 [array([128, 128, 128, ..., 128, 128, 128], dtype=uint8) 3]
 [array([128, 128, 128, ..., 128, 128, 128], dtype=uint8) 3]
 [array([128, 128, 128, ..., 128, 128, 128], dtype=uint8) 2]

Split using zip(_data)[0] to grab the list of arrays and zip(_data)[1] to grab the labels

$$$$$$$$$$$$
$ Some Code $
$$$$$$$$$$$$$
indices = np.random.permutation(data)
valid_cnt = int(len(data) \* 0.25)

test, train = indices[:valid_cnt], indices[valid_cnt:]

def listify(x):
    return [x]

num_classes = 3
# Hyper Params

state_size = 3
num_layers = 4
steps = 100
learningRate = 0.01
# One line model

classifier = skflow.TensorFlowRNNClassifier(
                        rnn_size=state_size, 
                        n_classes = num_classes, 
                        cell_type='rnn',
                        input_op_fn = listify,
                        num_layers = num_layers,
                        steps = steps,
                        optimizer = 'Adam',
                        learning_rate = learningRate,
                        continue_training=True)

classifier.fit(zip(_train)[0], zip(_test)[1])

$$$$$$$$$$$$
$ Final Notes $
$$$$$$$$$$$$
I'm just learning this thing, so bear with it.  Let me know what I can do to help.  Again, get hold of me and I'll open up the Jupyter notebook to you.
"
3647,Mismatch in gradient of 'abs' for complex values,"... in the `def abs(x, name=None):` [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/math_ops.py)

The abs correctly returns complex abs if the input is complex, but the gradient always returns `math_ops.sign(x)`. There seems to be a `_ComplexAbsGrad` though, so maybe that should be used?

Anyone have time for this? Clearly it's not that urgent (how many people are using complex valued tensors anyway), but maybe it should at least be flagged in the code...
"
3645,"TensorShape dimensions size should be of type uint64, not int64","According to core/framework/tensor_shape.cc:171:

``` cpp
void TensorShape::AddDim(int64 size) {
    CHECK_GE(size, 0);
```

TensorShape dimensions size can only be greater or equal to 0. **Thus, its type should be uint64_t.**

I even wonder if **size_t** would not be more appropriate.
"
3644,Multiple tasks in the same server may cause OOM in distributed mode with GPUs,"Following the [official tutorial](https://www.tensorflow.org/versions/master/how_tos/distributed/index.html) of distributed TensorFlow, we find that the ps and works will use the first GPU by default which may cause OOM in distributed mode.

If we don't set `CUDA_VISIBLE_DEVICES`, all the ps tasks may see all the GPUs and use the first one by default. And when I start all the ps and worker processes, OOM occurs and ps uses most of GPU's memory even though no job running.

Is that possible to optimize the algorithm of scheduler for more intelligence, such as using CPU for ps task and place operations in different GPUs instead of the first one?

One of the solution is specifying `CUDA_VISIBLE_DEVICES` for each task. Or we can use `with tf.device()` which may be only use for model parallel in distributed mode.
### Environment info

Operating System: 

```
Ubuntu 14.04
```

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```
# ls -l /usr/local/cuda/lib64/libcud*
-rw-r--r-- 1 root root   322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root       19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root   383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root   720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a
-rwxr-xr-x 1 root root 61453024 Jun 30 04:17 /usr/local/cuda/lib64/libcudnn.so
-rwxr-xr-x 1 root root 61453024 Jun 30 04:17 /usr/local/cuda/lib64/libcudnn.so.4
-rwxr-xr-x 1 root root 61453024 Jun 30 04:17 /usr/local/cuda/lib64/libcudnn.so.4.0.7
-rw-r--r-- 1 root root 62025862 Jun 30 04:17 /usr/local/cuda/lib64/libcudnn_static.a
```

If installed from binary pip package, provide:

```
0.9.0
```
"
3641,1171 (reopen),"undefined reference to symbol 'ceil@@GLIBC_2.2.5'
I get the same and a great many Info/Warnings.
this issue was patched and merged, but I simply follow the syntaxnet instructions (from the readme.md):

git clone --recursive https://github.com/tensorflow/models.git
cd models/syntaxnet/tensorflow
./configure
cd ..
bazel test syntaxnet/... util/utf8/...

it still gives:
/home/tf/.cache/bazel/_bazel_sam/5cd71b2b91989f3dd022ee2c43ab916c/external/org_tensorflow/tensorflow/tools/proto_text/BUILD:31:1: Linking of rule '@org_tensorflow//tensorflow/tools/proto_text:gen_proto_text_functions' failed: gcc failed: error executing command /usr/bin/gcc -o bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/proto_text/gen_proto_text_functions -pthread -no-canonical-prefixes -B/usr/bin -B/usr/bin -pass-exit-codes '-Wl,--build-id=md5' ... (remaining 12 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
/usr/bin/ld: bazel-out/host/bin/external/org_tensorflow/tensorflow/core/liblib_internal.a(numbers.o): undefined reference to symbol 'ceil@@GLIBC_2.2.5'
//lib/x86_64-linux-gnu/libm.so.6: error adding symbols: DSO missing from command line

is this a Bazel issue? that's a fairly obscure build system, what should I do?
(Ubuntu 16.04, w cudnn and cuda 8 bazel versionBuild label: 0.2.2b)
"
3640,Output for tfrecords files is not reproducible,"### Environment info

Operating System:
OS: Debian testing stretch  
Kernel: x86_64 Linux 4.5.0-1-amd64

Tensorflow
Version: 0.9.0
### Steps to reproduce

Running this script gives a ~/test.tfrecords file. 
Running the script repeatedly gives different hashes for the file. 

``` python
import os
import argparse

import tensorflow as tf
import numpy as np

MAXIMUM_SEQUENCE_LENGTH = 1000

def export(data, name, args):
    num_examples = len(data)

    fh_output = os.path.join(os.path.expandvars(args.output_directory), name + '.tfrecords')
    print('Writing', fh_output)
    writer = tf.python_io.TFRecordWriter(fh_output)
    for index in range(num_examples):
        ## prepare things to save
        seq_x1 = data[index][0].tostring()
        seq_x2 = data[index][1].tostring()

        example = tf.train.Example(features=tf.train.Features(feature={
            'x1': _bytes_feature(seq_x1),
            'x2': _bytes_feature(seq_x2),
            }))
        writer.write(example.SerializeToString())
    writer.close()

def _int64_feature(value):
    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))

def _bytes_feature(value):
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))


if __name__ == '__main__':
    tf.set_random_seed(11)
    np.random.seed(11)

    parser = argparse.ArgumentParser()
    parser.add_argument('--output_directory', type=str, default='$HOME/', help='Directory to write the converted result')
    # parser.add_argument('--validation_size', type=int, default=3000, help='Number of examples to separate from the training data for the validation set.')
    args = parser.parse_args()

    train = [( np.zeros(1000), np.ones(1000), 500 )]

    ## Write data to training file
    export(train, 'test', args)
```

I wonder why I cannot produce the same binary file again, if I rerun the script. Does this mean the content is different? I didn't find any option to set a seed either. 
"
3639,TensorFlow master build failing:  error: 'Packet4f' does not name a type,"I am trying to build TensorFlow master on big endian architecture and I am facing build issues related to EIGEN_VECTORIZE_SSE2 as mentioned below:

```
In file included from tensorflow/core/kernels/sparse_matmul_op.cc:20:0:
./tensorflow/core/kernels/sparse_matmul_op.h:46:26: error: 'Packet4f' does not name a type
 EIGEN_DEVICE_FUNC inline Packet4f pexpand_bf16_l(const Packet4f& from) {

./tensorflow/core/kernels/sparse_matmul_op.h:59:26: error: 'Packet4f' does not name a type
 EIGEN_DEVICE_FUNC inline Packet4f pexpand_bf16_u(const Packet4f& from) {

./tensorflow/core/kernels/sparse_matmul_op.h:117:21: error: 'Packet4f' does not name a type
 EIGEN_STRONG_INLINE Packet4f pload4bf16<Packet4f>(const float* from) {

./tensorflow/core/kernels/sparse_matmul_op.h:128:21: error: 'Packet4f' does not name a type
 EIGEN_STRONG_INLINE Packet4f pload2bf16<Packet4f>(const float* from) {

```

Looks like this issue is caused due to a recent commit [fix build for PPC](https://github.com/tensorflow/tensorflow/pull/2911/commits/a1de95f38b442b0534f1f8871bc5cb16390725ae)
This commit includes fix for PPC however its breaking build for other non SSE platform. 
### Environment info

Operating System: **Ubuntu/Red Hat**

Installed version of CUDA and cuDNN: **Not installed**

The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.  **master** 

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)   [98d63de](https://github.com/tensorflow/tensorflow/commit/98d63de3bb2bab7c9a81f83c8ca864741399300c)  
2. The output of `bazel version`  **0.3.0**
### Steps to reproduce
1. bazel build -c opt //tensorflow/tools/pip_package:build_pip_package
### What have you tried?
1. Could build tensorflow master by removing condition for `#ifndef EIGEN_VECTORIZE_SSE2` from tensorflow/core/kernels/sparse_matmul_op.h file. 
"
3638,tf.gather produces zeros for invalid indices on GPU,"### Environment info

Operating System: Ubuntu 16.04 LTS (64 bit)

```
$ dpkg -l | grep cuda | grep ^ii
ii  libcuda1-361                                361.42-0ubuntu2                                             amd64        NVIDIA CUDA runtime library
ii  libcudart7.5:amd64                          7.5.18-0ubuntu1                                             amd64        NVIDIA CUDA Runtime Library
ii  libcudnn5                                   5.0.5-1+cuda7.5                                             amd64        cuDNN runtime libraries
ii  libcudnn5-dev                               5.0.5-1+cuda7.5                                             amd64        cuDNN development libraries and headers
ii  libcudnn5-doc                               5.0.5-1+cuda7.5                                             amd64        cuDNN documents and samples
ii  nvidia-cuda-dev                             7.5.18-0ubuntu1                                             amd64        NVIDIA CUDA development files
ii  nvidia-cuda-doc                             7.5.18-0ubuntu1                                             all          NVIDIA CUDA and OpenCL documentation
ii  nvidia-cuda-gdb                             7.5.18-0ubuntu1                                             amd64        NVIDIA CUDA Debugger (GDB)
ii  nvidia-cuda-toolkit                         7.5.18-0ubuntu1                                             amd64        NVIDIA CUDA development toolkit
```

```
$ find /usr/lib -name libcud\*
/usr/lib/i386-linux-gnu/libcuda.so.1
/usr/lib/i386-linux-gnu/libcuda.so.361.42
/usr/lib/i386-linux-gnu/libcuda.so
/usr/lib/x86_64-linux-gnu/libcudnn_static.a
/usr/lib/x86_64-linux-gnu/libcudnn_static_v5.a
/usr/lib/x86_64-linux-gnu/libcuda.so.1
/usr/lib/x86_64-linux-gnu/libcudart.so.7.5.18
/usr/lib/x86_64-linux-gnu/libcudnn.so
/usr/lib/x86_64-linux-gnu/libcuda.so.361.42
/usr/lib/x86_64-linux-gnu/libcudnn.so.5.0.5
/usr/lib/x86_64-linux-gnu/libcudart.so
/usr/lib/x86_64-linux-gnu/libcudart.so.7.5
/usr/lib/x86_64-linux-gnu/libcudadevrt.a
/usr/lib/x86_64-linux-gnu/libcudnn.so.5
/usr/lib/x86_64-linux-gnu/stubs/libcuda.so
/usr/lib/x86_64-linux-gnu/libcuda.so
/usr/lib/x86_64-linux-gnu/libcudart_static.a
```

```
$ python -c ""import tensorflow; print(tensorflow.__version__)""
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
0.10.0rc0
```
### Steps to reproduce

```
In [23]: x = tf.constant([1.1,2.2,3.3])

In [24]: a = tf.constant(123,dtype=tf.int32)

In [25]: tf.gather(x,a,validate_indices=True).eval()
Gather_8: /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:818] Gather_8: /job:localhost/replica:0/task:0/gpu:0
Const_8: /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:818] Const_8: /job:localhost/replica:0/task:0/gpu:0
Const_7: /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:818] Const_7: /job:localhost/replica:0/task:0/gpu:0
Out[25]: 0.0

In [26]: 
```
"
3636,Inception retraining / transfer learning can only utilize one CPU core and one GPU,"The retraining code is example code, but it does seem like there are many people experimenting with retraining and improving performance could make the example code much more useful as a launchpad for others if it can scale across GPUs and multiple CPU cores.

At the moment, running
`bazel-bin/tensorflow/examples/image_retraining/retrain --num_gpus=2 --image_dir /images`
will only result in a single GPU performing computations in `nvidia-smi`, even though both GPUs are running `python` in nvidia-smi.  GPU #2 will see zero memory/power utilization during the computation beyond idle levels.  GPU #1 will utilize all memory TensorFlow and an additional 30 watts or so.

The other related issue is that, during training, a single CPU core will be maxed out at 100% running python; given the capabilities of the card, I'm guessing removing this bottleneck would increase retraining speed by perhaps 200-400%.  `nmon` shows that disk IO is not a bottleneck.

Thanks for your time and for making TensorFlow available to everyone!
### Environment info

Operating System: Ubuntu 14.04

Installed version of CUDA and cuDNN: 8.0 and 5 with two GTX 1080 cards

retrain.py: `train_batch_size` is 20000 and `learning_rate` is 0.5
1. The commit hash (`git rev-parse HEAD`): r0.9.0
2. The output of `bazel version`: Build label: 0.2.3
   Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
   Build time: Tue May 17 14:21:13 2016 (1463494873)
   Build timestamp: 1463494873
   Build timestamp as int: 1463494873
"
3632,Not finding cuda library for jobs that do NOT require GPU,"I am having this error when I use the slurm (http://slurm.schedmd.com/) workload manager. When I run some tensorflow python scripts, sometimes it results in an error (attached). It seems that it can't find cuda library installed but I am running scripts that do **not** require GPUs.  Therefore, I find it very confusing why cuda would be an issue at all. Why is cuda installation an issue if I don't need it?

---

Operating System:   CentOS Linux release 7.2.1511

Installed version of CUDA and cuDNN (calling ls -l /usr/lib/libcuda.so.352.63): 
-rwxr-xr-x 1 root root 14272428 Dec 15  2015 /usr/lib/libcuda.so.352.63

If installed from binary pip package, provide:
tensorflow (0.9.0)
1. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`. running this seems to produce different results from the error I expected. what it outputs:

```
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:102] Couldn't open CUDA library libcudnn.so. LD_LIBRARY_PATH: /cm/shared/openmind/cuda/7.5/lib64:/cm/shared/openmind/cuda/7.5/lib
I tensorflow/stream_executor/cuda/cuda_dnn.cc:2092] Unable to load cuDNN DSO
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
```

 the error I expected:

```
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:102] Couldn't open CUDA library libcudnn.so. LD_LIBRARY_PATH: /cm/shared/openmind/cuda/7.5/lib64:/cm/shared/openmind/cuda/7.5/lib
I tensorflow/stream_executor/cuda/cuda_dnn.cc:2092] Unable to load cuDNN DSO
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
E tensorflow/stream_executor/cuda/cuda_driver.cc:491] failed call to cuInit: CUDA_ERROR_NO_DEVICE
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:153] retrieving CUDA diagnostic information for host: node047
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:160] hostname: node047
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:185] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:347] driver version file contents: """"""NVRM version: NVIDIA UNIX x86_64 Kernel Module  352.63  Sat Nov  7 21:25:42 PST 2015
GCC version:  gcc version 4.8.5 20150623 (Red Hat 4.8.5-4) (GCC)
""""""
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] kernel reported version is: 352.63.0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No GPU devices available on machine.
```
### Steps to reproduce
1. run the sbatch command in slurm and dispatch about 1000 jobs running an idential tensorflow script. Returns that error.
### What have you tried?
1. I've tried logging into the node directly throwing the error and run tensorflow jobs but it seems when I do that there are no errors.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).

```
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:102] Couldn't open CUDA library libcudnn.so. LD_LIBRARY_PATH: /cm/shared/openmind/cuda/7.5/lib64:/cm/shared/openmind/cuda/7.5/lib
I tensorflow/stream_executor/cuda/cuda_dnn.cc:2092] Unable to load cuDNN DSO
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
E tensorflow/stream_executor/cuda/cuda_driver.cc:491] failed call to cuInit: CUDA_ERROR_NO_DEVICE
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:153] retrieving CUDA diagnostic information for host: node047
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:160] hostname: node047
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:185] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:347] driver version file contents: """"""NVRM version: NVIDIA UNIX x86_64 Kernel Module  352.63  Sat Nov  7 21:25:42 PST 2015
GCC version:  gcc version 4.8.5 20150623 (Red Hat 4.8.5-4) (GCC)
""""""
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] kernel reported version is: 352.63.0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No GPU devices available on machine.
```
"
3631,Unable to build from source for TensorFlow r0.10 C++ compilation of rule '//tensorflow/core:lib_internal' failed: gcc failed: error executing command,"I have followed this tutorial (https://github.com/samjabrahams/tensorflow-on-raspberry-pi) trying to install the latest tensorflow with quantization enabled, on raspberry pi 3. So I followed every step in it except for the tensorflow version, instead of Tensorflow 0.9 I used the latest 0.10. 

But I ran into the following error

```
ERROR: /home/pi/tf2/bazel/tensorflow/tensorflow/core/BUILD:826:1: C++ compilation of rule '//tensorflow/core:lib_internal' failed: gcc failed: error executing command 
  (cd /home/pi/.cache/bazel/_bazel_pi/b1a0eb2b93fc558ac1cbf83f2cf3a5f1/tensorflow && \
  exec env - \
    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/games:/usr/games:/opt/hadoop/bin:/opt/hadoop/sbin:/home/pi/opt/Cypress/arm-2013.11/bin:/home/pi/opt/Cypress/eclipse:/home/pi/opt \
  /usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-mfpu=neon' '-std=c++0x' -DHAVE_CONFIG_H -iquote . -iquote bazel-out/local_linux-opt/genfiles -iquote external/protobuf -iquote bazel-out/local_linux-opt/genfiles/external/protobuf -iquote external/bazel_tools -iquote bazel-out/local_linux-opt/genfiles/external/bazel_tools -iquote external/farmhash_archive -iquote bazel-out/local_linux-opt/genfiles/external/farmhash_archive -iquote external/gif_archive -iquote bazel-out/local_linux-opt/genfiles/external/gif_archive -iquote external/highwayhash -iquote bazel-out/local_linux-opt/genfiles/external/highwayhash -iquote external/jpeg_archive -iquote bazel-out/local_linux-opt/genfiles/external/jpeg_archive -iquote external/png_archive -iquote bazel-out/local_linux-opt/genfiles/external/png_archive -iquote external/re2 -iquote bazel-out/local_linux-opt/genfiles/external/re2 -iquote external/eigen_archive -iquote bazel-out/local_linux-opt/genfiles/external/eigen_archive -iquote external/zlib_archive -iquote bazel-out/local_linux-opt/genfiles/external/zlib_archive -isystem external/protobuf/src -isystem bazel-out/local_linux-opt/genfiles/external/protobuf/src -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/farmhash_archive/farmhash-34c13ddfab0e35422f4c3979f360635a8c050260 -isystem bazel-out/local_linux-opt/genfiles/external/farmhash_archive/farmhash-34c13ddfab0e35422f4c3979f360635a8c050260 -isystem external/gif_archive/giflib-5.1.4/lib -isystem bazel-out/local_linux-opt/genfiles/external/gif_archive/giflib-5.1.4/lib -isystem external/highwayhash -isystem bazel-out/local_linux-opt/genfiles/external/highwayhash -isystem external/jpeg_archive/jpeg-9a -isystem bazel-out/local_linux-opt/genfiles/external/jpeg_archive/jpeg-9a -isystem external/png_archive/libpng-1.2.53 -isystem bazel-out/local_linux-opt/genfiles/external/png_archive/libpng-1.2.53 -isystem external/re2 -isystem bazel-out/local_linux-opt/genfiles/external/re2 -isystem external/eigen_archive -isystem bazel-out/local_linux-opt/genfiles/external/eigen_archive -isystem external/zlib_archive/zlib-1.2.8 -isystem bazel-out/local_linux-opt/genfiles/external/zlib_archive/zlib-1.2.8 -fno-exceptions -DEIGEN_AVOID_STL_ARRAY -pthread -no-canonical-prefixes -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' '-frandom-seed=bazel-out/local_linux-opt/bin/tensorflow/core/_objs/lib_internal/tensorflow/core/lib/png/png_io.pic.o' -MD -MF bazel-out/local_linux-opt/bin/tensorflow/core/_objs/lib_internal/tensorflow/core/lib/png/png_io.pic.d -fPIC -c tensorflow/core/lib/png/png_io.cc -o bazel-out/local_linux-opt/bin/tensorflow/core/_objs/lib_internal/tensorflow/core/lib/png/png_io.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
In file included from ./tensorflow/core/lib/png/png_io.h:39:0,
                 from tensorflow/core/lib/png/png_io.cc:27:
./tensorflow/core/platform/png.h:26:2: error: #error Define the appropriate PLATFORM_<foo> macro for this platform
 #error Define the appropriate PLATFORM_<foo> macro for this platform
  ^
In file included from tensorflow/core/lib/png/png_io.cc:27:0:
./tensorflow/core/lib/png/png_io.h:48:3: error: 'png_structp' does not name a type
   png_structp png_ptr;
   ^
./tensorflow/core/lib/png/png_io.h:49:3: error: 'png_infop' does not name a type
   png_infop info_ptr;
   ^
./tensorflow/core/lib/png/png_io.h:50:3: error: 'png_uint_32' does not name a type
   png_uint_32 width, height;
   ^
./tensorflow/core/lib/png/png_io.h: In constructor 'tensorflow::png::DecodeContext::DecodeContext()':
./tensorflow/core/lib/png/png_io.h:57:21: error: class 'tensorflow::png::DecodeContext' does not have any field named 'png_ptr'
   DecodeContext() : png_ptr(NULL), info_ptr(NULL) {}
                     ^
./tensorflow/core/lib/png/png_io.h:57:36: error: class 'tensorflow::png::DecodeContext' does not have any field named 'info_ptr'
   DecodeContext() : png_ptr(NULL), info_ptr(NULL) {}
                                    ^
./tensorflow/core/lib/png/png_io.h: At global scope:
./tensorflow/core/lib/png/png_io.h:78:25: error: 'png_bytep' was not declared in this scope
 bool CommonFinishDecode(png_bytep data, int row_bytes, DecodeContext* context);
                         ^
./tensorflow/core/lib/png/png_io.h:78:41: error: expected primary-expression before 'int'
 bool CommonFinishDecode(png_bytep data, int row_bytes, DecodeContext* context);
                                         ^
./tensorflow/core/lib/png/png_io.h:78:69: error: expected primary-expression before '*' token
 bool CommonFinishDecode(png_bytep data, int row_bytes, DecodeContext* context);
                                                                     ^
./tensorflow/core/lib/png/png_io.h:78:71: error: 'context' was not declared in this scope
 bool CommonFinishDecode(png_bytep data, int row_bytes, DecodeContext* context);
                                                                       ^
./tensorflow/core/lib/png/png_io.h:78:78: error: expression list treated as compound expression in initializer [-fpermissive]
 bool CommonFinishDecode(png_bytep data, int row_bytes, DecodeContext* context);
                                                                              ^
tensorflow/core/lib/png/png_io.cc:77:19: error: variable or field 'ErrorHandler' declared void
 void ErrorHandler(png_structp png_ptr, png_const_charp msg) {
                   ^
tensorflow/core/lib/png/png_io.cc:77:19: error: 'png_structp' was not declared in this scope
tensorflow/core/lib/png/png_io.cc:77:40: error: 'png_const_charp' was not declared in this scope
 void ErrorHandler(png_structp png_ptr, png_const_charp msg) {
                                        ^
tensorflow/core/lib/png/png_io.cc:85:21: error: variable or field 'WarningHandler' declared void
 void WarningHandler(png_structp png_ptr, png_const_charp msg) {
                     ^
tensorflow/core/lib/png/png_io.cc:85:21: error: 'png_structp' was not declared in this scope
tensorflow/core/lib/png/png_io.cc:85:42: error: 'png_const_charp' was not declared in this scope
 void WarningHandler(png_structp png_ptr, png_const_charp msg) {
                                          ^
tensorflow/core/lib/png/png_io.cc:89:19: error: variable or field 'StringReader' declared void
 void StringReader(png_structp png_ptr, png_bytep data, png_size_t length) {
                   ^
tensorflow/core/lib/png/png_io.cc:89:19: error: 'png_structp' was not declared in this scope
tensorflow/core/lib/png/png_io.cc:89:40: error: 'png_bytep' was not declared in this scope
 void StringReader(png_structp png_ptr, png_bytep data, png_size_t length) {
                                        ^
tensorflow/core/lib/png/png_io.cc:89:56: error: 'png_size_t' was not declared in this scope
 void StringReader(png_structp png_ptr, png_bytep data, png_size_t length) {
                                                        ^
tensorflow/core/lib/png/png_io.cc:398:1: error: expected '}' at end of input
 }  // namespace tensorflow
 ^
tensorflow/core/lib/png/png_io.cc:398:1: error: expected '}' at end of input
tensorflow/core/lib/png/png_io.cc:398:1: error: expected '}' at end of input
tensorflow/core/lib/png/png_io.cc:48:13: warning: 'void tensorflow::png::{anonymous}::Convert8to16(const uint8*, int, int, int, int, tensorflow::uint16*, int)' defined but not used [-Wunused-function]
 static void Convert8to16(const uint8* p8, int num_comps, int p8_row_bytes,
             ^
Target //tensorflow/tools/pip_package:build_pip_package failed to build
```

my gcc version is 4.9.2

I appreciate any help and suggestion!
"
3630,TF works in python3.4 for some users but not for others under RedHat7 ,"We have a RedHat7 machine where our sysadmin, per my request, has installed TF 0.9.0 for both python2.7 and python3.4. Both versions of python are installed centrally under /usr/bin. 

When installing, he followed the ""pip install"" instructions from the TF page for CPU-only 64-bit 2.7 and 3.4 installs.

For both me and him, importing tenserflow in python2.7 works fine.

For him, importing TF in python3.4 works fine as well.

But for me, it generates an error. For some reason, it attempts to load the 2.7 version of the TF package. For him, it loads the 3.4 version as expected.

When I ran the command `python3 -v -c 'import tensorflow'`, I get, among other things, this:

`# /usr/lib/python2.7/site-packages/tensorflow/__pycache__/__init__.cpython-34.pyc matches /usr/lib/python2.7/site-packages/tensorflow/__init__.py`
`# code object from '/usr/lib/python2.7/site-packages/tensorflow/__pycache__/__init__.cpython-34.pyc'`
`# /usr/lib/python2.7/site-packages/tensorflow/python/__pycache__/__init__.cpython-34.pyc matches /usr/lib/python2.7/site-packages/tensorflow/python/__init__.py`
`# code object from '/usr/lib/python2.7/site-packages/tensorflow/python/__pycache__/__init__.cpython-34.pyc'`

When he runs the same command, he gets:

`# /usr/lib/python3.4/site-packages/tensorflow/__pycache__/__init__.cpython-34.pyc matches /usr/lib/python3.4/site-packages/tensorflow/__init__.py`
`# code object from '/usr/lib/python3.4/site-packages/tensorflow/__pycache__/__init__.cpython-34.pyc'`
`# /usr/lib/python3.4/site-packages/tensorflow/python/__pycache__/__init__.cpython-34.pyc matches /usr/lib/python3.4/site-packages/tensorflow/python/__init__.py`
`# code object from '/usr/lib/python3.4/site-packages/tensorflow/python/__pycache__/__init__.cpython-34.pyc'`

`PYTHONPATH` is defined for neither of us. 

Why is there this difference and how can it be fixed?

Thank you!
"
3629,"Problems in ""Implement the gradient in Python"" docs","Referring to the docs [here](https://www.tensorflow.org/versions/r0.10/how_tos/adding_an_op/index.html#implement-the-gradient-in-python)

First of all, the chain rule is completely wrong. Also the `ZeroOut` example is not a very good one IMO... would be much better to give e.g. a simple derivative of a polynomial or something. Just a FYI.

EDIT: I'd like to emphasize that the chain rule is _embarrasingly_ wrong...
"
3628,Unable to import frozen graph with batchnorm,"Error when loading the frozen graph with [tensorflow.contrib.layers.python.layers.batch_norm](https://github.com/tensorflow/tensorflow/blob/88d9bc16d6a16e5b660cda548b74944f27ddcd1b/tensorflow/contrib/layers/python/layers/layers.py)
`
ValueError: graph_def is invalid at node u'BatchNorm/cond/AssignMovingAvg/Switch': Input tensor 'BatchNorm/moving_mean:0' Cannot convert a tensor of type float32 to an input of type float32_ref
`
[freeze_graph.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph.py)  doesn't seem to store moving_mean and moving_variance properly
"
3627,Tensorflow inability to kill processes using more than 1 GPU,"### Environment info

Operating System: Ubuntu 14.04

Installed version of CUDA and cuDNN: 
CUDA 7.5
CUDNNv4

GPUs:
2x Tesla K40x
2x GeForce GTX K40c

The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`:
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
0.9.0

This problem is specific to running tensorflow with multiple GPUs. When I try to restart the notebook in jupyter, if I have more than one GPU visible via `os.environ[""CUDA_VISIBLE_DEVICES""]`, the notebook freezes up, and I can no longer run nvidia-smi. 

This problem does not exist when using a single GPU or no GPU on the same network.
"
3626,contrib/makefile:  error: conflicting return type,"### Environment info

OS:   I'm running on Docker with an Ubuntu 14.04.4 LTS x86_64 (gcc/g++ version is 4.8.4)
No CUDA or cuDNN installed

installed from source
1. The commit hash (`git rev-parse HEAD`)
   $ git rev-parse HEAD
   27eeb441bad8bcaa1bcba42a4b4ee49fb50ea0d3
   (note: I also tried with branch  r0.9 and  r0.10 with the same issue about conflicting return type)
### Steps to reproduce

```
$ mkdir /opt/tensor-build/
$ cd /opt/tensor-build/
$ git clone https://github.com/tensorflow/tensorflow
$ cd tensorflow
$ ./tensorflow/contrib/makefile/download_dependencies.sh
$ sudo apt-get install autoconf automake libtool curl make g++ unzip
$ pushd .
$ cd tensorflow/contrib/makefile/downloads/protobuf
$ ./autogen.sh
$ ./configure
$ make
$ make check
$ sudo make install
$ sudo ldconfig # refresh shared library cache
$ popd
```

So far, no issue, then:

```
$ make -f tensorflow/contrib/makefile/Makefile
PROTOC = ""protoc""
CC_PREFIX = """"
protoc  tensorflow/core/util/test_log.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/proto/
protoc  tensorflow/core/util/saved_tensor_slice.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/proto/
protoc  tensorflow/core/util/memmapped_file_system.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/proto/
protoc  tensorflow/core/util/event.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/proto/
protoc  tensorflow/core/protobuf/tensorflow_server.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/proto/
protoc  tensorflow/core/protobuf/saver.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/proto/
protoc  tensorflow/core/protobuf/queue_runner.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/proto/
protoc  tensorflow/core/protobuf/named_tensor.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/proto/
protoc  tensorflow/core/protobuf/meta_graph.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/proto/
protoc  tensorflow/core/protobuf/config.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/proto/
protoc  tensorflow/core/lib/core/error_codes.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/proto/
protoc  tensorflow/core/framework/versions.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/proto/
protoc  tensorflow/core/framework/variable.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/proto/
protoc  tensorflow/core/framework/types.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/proto/
protoc  tensorflow/core/framework/tensor_slice.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/proto/
protoc  tensorflow/core/framework/tensor_shape.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/proto/
protoc  tensorflow/core/framework/tensor_description.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/proto/
protoc  tensorflow/core/framework/tensor.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/proto/
protoc  tensorflow/core/framework/summary.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/proto/
protoc  tensorflow/core/framework/step_stats.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/proto/
protoc  tensorflow/core/framework/op_def.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/proto/
protoc  tensorflow/core/framework/log_memory.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/proto/
protoc  tensorflow/core/framework/kernel_def.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/proto/
protoc  tensorflow/core/framework/graph.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/proto/
protoc  tensorflow/core/framework/function.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/proto/
protoc  tensorflow/core/framework/device_attributes.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/proto/
protoc  tensorflow/core/framework/cost_graph.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/proto/
protoc  tensorflow/core/framework/attr_value.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/proto/
protoc  tensorflow/core/framework/allocation_description.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/proto/
protoc  tensorflow/core/example/feature.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/proto/
protoc  tensorflow/core/example/example.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/proto/
protoc  tensorflow/core/util/test_log.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/
protoc  tensorflow/core/util/saved_tensor_slice.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/
protoc  tensorflow/core/util/memmapped_file_system.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/
protoc  tensorflow/core/util/event.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/
protoc  tensorflow/core/protobuf/tensorflow_server.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/
protoc  tensorflow/core/protobuf/saver.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/
protoc  tensorflow/core/protobuf/queue_runner.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/
protoc  tensorflow/core/protobuf/named_tensor.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/
protoc  tensorflow/core/protobuf/meta_graph.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/
protoc  tensorflow/core/protobuf/config.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/
protoc  tensorflow/core/lib/core/error_codes.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/
protoc  tensorflow/core/framework/versions.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/
protoc  tensorflow/core/framework/variable.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/
protoc  tensorflow/core/framework/types.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/
protoc  tensorflow/core/framework/tensor_slice.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/
protoc  tensorflow/core/framework/tensor_shape.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/
protoc  tensorflow/core/framework/tensor_description.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/
protoc  tensorflow/core/framework/tensor.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/
protoc  tensorflow/core/framework/summary.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/
protoc  tensorflow/core/framework/step_stats.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/
protoc  tensorflow/core/framework/op_def.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/
protoc  tensorflow/core/framework/log_memory.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/
protoc  tensorflow/core/framework/kernel_def.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/
protoc  tensorflow/core/framework/graph.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/
protoc  tensorflow/core/framework/function.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/
protoc  tensorflow/core/framework/device_attributes.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/
protoc  tensorflow/core/framework/cost_graph.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/
protoc  tensorflow/core/framework/attr_value.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/
protoc  tensorflow/core/framework/allocation_description.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/
protoc  tensorflow/core/example/feature.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/
protoc  tensorflow/core/example/example.proto --cpp_out /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/
gcc --std=c++11 -I. -I/opt/tensor-build/tensorflow/tensorflow/contrib/makefile/downloads/ -I/opt/tensor-build/tensorflow/tensorflow/contrib/makefile/download
s/eigen-eigen-b4fa9622b809 -I/opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/ -I/usr/local/include -c tensorflow/tools/proto_text/gen_p
roto_text_functions_lib.cc -o /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/tensorflow/tools/proto_text/gen_proto_text_functions_lib.
o
gcc --std=c++11 -I. -I/opt/tensor-build/tensorflow/tensorflow/contrib/makefile/downloads/ -I/opt/tensor-build/tensorflow/tensorflow/contrib/makefile/download
s/eigen-eigen-b4fa9622b809 -I/opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/ -I/usr/local/include -c tensorflow/tools/proto_text/gen_p
roto_text_functions.cc -o /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/tensorflow/tools/proto_text/gen_proto_text_functions.o
gcc --std=c++11 -I. -I/opt/tensor-build/tensorflow/tensorflow/contrib/makefile/downloads/ -I/opt/tensor-build/tensorflow/tensorflow/contrib/makefile/download
s/eigen-eigen-b4fa9622b809 -I/opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/ -I/usr/local/include -c tensorflow/core/platform/tracing.
cc -o /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/tensorflow/core/platform/tracing.o
gcc --std=c++11 -I. -I/opt/tensor-build/tensorflow/tensorflow/contrib/makefile/downloads/ -I/opt/tensor-build/tensorflow/tensorflow/contrib/makefile/download
s/eigen-eigen-b4fa9622b809 -I/opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/ -I/usr/local/include -c tensorflow/core/platform/tensor_c
oding.cc -o /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/tensorflow/core/platform/tensor_coding.o
gcc --std=c++11 -I. -I/opt/tensor-build/tensorflow/tensorflow/contrib/makefile/downloads/ -I/opt/tensor-build/tensorflow/tensorflow/contrib/makefile/download
s/eigen-eigen-b4fa9622b809 -I/opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/ -I/usr/local/include -c tensorflow/core/platform/protobuf
_util.cc -o /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/tensorflow/core/platform/protobuf_util.o
gcc --std=c++11 -I. -I/opt/tensor-build/tensorflow/tensorflow/contrib/makefile/downloads/ -I/opt/tensor-build/tensorflow/tensorflow/contrib/makefile/download
s/eigen-eigen-b4fa9622b809 -I/opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/ -I/usr/local/include -c tensorflow/core/platform/posix/po
six_file_system.cc -o /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/tensorflow/core/platform/posix/posix_file_system.o
gcc --std=c++11 -I. -I/opt/tensor-build/tensorflow/tensorflow/contrib/makefile/downloads/ -I/opt/tensor-build/tensorflow/tensorflow/contrib/makefile/download
s/eigen-eigen-b4fa9622b809 -I/opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/ -I/usr/local/include -c tensorflow/core/platform/posix/po
rt.cc -o /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/tensorflow/core/platform/posix/port.o
gcc --std=c++11 -I. -I/opt/tensor-build/tensorflow/tensorflow/contrib/makefile/downloads/ -I/opt/tensor-build/tensorflow/tensorflow/contrib/makefile/download
s/eigen-eigen-b4fa9622b809 -I/opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/ -I/usr/local/include -c tensorflow/core/platform/posix/en
v.cc -o /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/tensorflow/core/platform/posix/env.o
gcc --std=c++11 -I. -I/opt/tensor-build/tensorflow/tensorflow/contrib/makefile/downloads/ -I/opt/tensor-build/tensorflow/tensorflow/contrib/makefile/download
s/eigen-eigen-b4fa9622b809 -I/opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/ -I/usr/local/include -c tensorflow/core/platform/load_lib
rary.cc -o /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/tensorflow/core/platform/load_library.o
gcc --std=c++11 -I. -I/opt/tensor-build/tensorflow/tensorflow/contrib/makefile/downloads/ -I/opt/tensor-build/tensorflow/tensorflow/contrib/makefile/download
s/eigen-eigen-b4fa9622b809 -I/opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/ -I/usr/local/include -c tensorflow/core/platform/file_sys
tem.cc -o /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/tensorflow/core/platform/file_system.o
gcc --std=c++11 -I. -I/opt/tensor-build/tensorflow/tensorflow/contrib/makefile/downloads/ -I/opt/tensor-build/tensorflow/tensorflow/contrib/makefile/download
s/eigen-eigen-b4fa9622b809 -I/opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/ -I/usr/local/include -c tensorflow/core/platform/env.cc -
o /opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/tensorflow/core/platform/env.o
tensorflow/core/platform/env.cc:304:9: error: conflicting return type specified for 'virtual tensorflow::int64 tensorflow::{anonymous}::FileStream::ByteCount
() const'
   int64 ByteCount() const override { return pos_; }
         ^
In file included from ./tensorflow/core/platform/default/protobuf.h:26:0,
                 from ./tensorflow/core/platform/protobuf.h:31,
                 from ./tensorflow/core/platform/file_system.h:28,
                 from ./tensorflow/core/platform/env.h:27,
                 from tensorflow/core/platform/env.cc:23:
/usr/include/google/protobuf/io/zero_copy_stream.h:172:17: error:   overriding 'virtual google::protobuf::int64 google::protobuf::io::ZeroCopyInputStream::By
teCount() const'
   virtual int64 ByteCount() const = 0;
                 ^
make: *** [/opt/tensor-build/tensorflow/tensorflow/contrib/makefile/gen/host_obj/tensorflow/core/platform/env.o] Error 1
```
"
3625,iOS CameraExample KVO mismatching keys,"I got a KVO error when switching views and noticed: 

In CameraExampleViewController.mm, `setupAVCapture`uses

```
[stillImageOutput
     addObserver:self
     forKeyPath:@""capturingStillImage""
     options:NSKeyValueObservingOptionNew
     context:(void *)(AVCaptureStillImageIsCapturingStillImageContext)];
```

while `teardownAVCapture` uses

```
[stillImageOutput removeObserver:self forKeyPath:@""isCapturingStillImage""];
```

 `forKeyPath:@""capturingStillImage""` and `forKeyPath:@""isCapturingStillImage""` do not match.
"
3624,Basic Element-wise Complex Number Calculations Not Available On GPU,"Basic element-wise addition, subtraction, multiplication or division for any Tensor of type tf.complex64 is not implemented on GPU.
### Environment info

Operating System: Centos 7,  3.10.0-327.22.2.el7.x86_64

Installed version of CUDA and cuDNN:  CUDA 7.5 and cuDNN 7.0-v4
-rw-r--r--. 1 root root 189170 Jul 22 16:14 /usr/local/cuda-7.5/lib/libcudadevrt.a
lrwxrwxrwx. 1 root root     16 Jul 22 16:14 /usr/local/cuda-7.5/lib/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx. 1 root root     19 Jul 22 16:14 /usr/local/cuda-7.5/lib/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x. 1 root root 311596 Jul 22 16:14 /usr/local/cuda-7.5/lib/libcudart.so.7.5.18
-rw-r--r--. 1 root root 558020 Jul 22 16:14 /usr/local/cuda-7.5/lib/libcudart_static.a

Tensorflow installed from source: 
1. Commit hash 00700f00fdf71baec1342d1afd7849e16fbd2a33
2. Bazel information:
Build label: 0.3.0-2016-07-22 (@ca36b06)
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Jul 22 19:23:10 2016 (1469215390)
Build timestamp: 1469215390
Build timestamp as int: 1469215390
### Steps to reproduce
1. Add, subtract, multiply or divide any Tensor of type tf.complex64. A code example is shown here for element-wise addition:

```
import tensorflow as tf

if __name__ == '__main__':

    with tf.device('/gpu:0'):
        N = 100
        a = tf.complex(tf.random_normal((N,)), tf.random_normal((N,)))
        b = tf.complex(tf.random_normal((N,)), tf.random_normal((N,)))
        c = a + b

        with tf.Session() as sess:
            c = sess.run(c)
```

The code returns the following output if run on GPU (works well on CPU):

I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so.7.5 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so.4.0.7 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so.7.5 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so.7.5 locally
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: Tesla K40c
major: 3 minor: 5 memoryClockRate (GHz) 0.745
pciBusID 0000:02:00.0
Total memory: 12.00GiB
Free memory: 11.90GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x5168890
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties: 
name: GeForce GT 610
major: 2 minor: 1 memoryClockRate (GHz) 1.62
pciBusID 0000:01:00.0
Total memory: 1023.19MiB
Free memory: 396.98MiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 0 to device ordinal 1
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 1 to device ordinal 0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 1 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y N 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 1:   N Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:839] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40c, pci bus id: 0000:02:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:814] Ignoring gpu device (device: 1, name: GeForce GT 610, pci bus id: 0000:01:00.0) with Cuda compute capability 2.1. The minimum required Cuda capability is 3.5.
E tensorflow/core/client/tensor_c_api.cc:485] Cannot assign a device to node 'add': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
     [[Node: add = Add[T=DT_COMPLEX64, _device=""/device:GPU:0""](Complex, Complex_1)]]
Traceback (most recent call last):
  File ""test_div_gpu_prob.py"", line 12, in <module>
    c = sess.run(c)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 382, in run
    run_metadata_ptr)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 655, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 723, in _do_run
    target_list, options, run_metadata)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 743, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'add': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
     [[Node: add = Add[T=DT_COMPLEX64, _device=""/device:GPU:0""](Complex, Complex_1)]]
Caused by op u'add', defined at:
  File ""test_div_gpu_prob.py"", line 9, in <module>
    c = a + b
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py"", line 755, in binary_op_wrapper
    return func(x, y, name=name)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py"", line 70, in add
    result = _op_def_lib.apply_op(""Add"", x=x, y=y, name=name)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 703, in apply_op
    op_def=op_def)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2310, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1232, in __init__
    self._traceback = _extract_stack()
### What have you tried?
1.  Implementation using builtin Tensorflow functions works, if the real and imaginary parts are separated. See the code below:

```
import numpy as np
import tensorflow as tf

def complex_add(x, y):
    xr, xi = tf.real(x), tf.imag(x)
    yr, yi = tf.real(y), tf.imag(y)
    return tf.complex(xr + yr, xi + yi)

def complex_sub(x, y):
    xr, xi = tf.real(x), tf.imag(x)
    yr, yi = tf.real(y), tf.imag(y)
    return tf.complex(xr - yr, xi - yi)

def complex_mul(x, y):
    xr, xi = tf.real(x), tf.imag(x)
    yr, yi = tf.real(y), tf.imag(y)
    return tf.complex(xr*yr - xi*yi, xr*yi + xi*yr)

def complex_div(x, y):
    xr, xi = tf.real(x), tf.imag(x)
    yr, yi = tf.real(y), tf.imag(y)
    d = tf.square(yr) + tf.square(yi)
    return tf.complex((xr*yr+xi*yi)/d, (xi*yr-xr*yi)/d)

if __name__ == '__main__':

    with tf.device('/gpu:0'):
        N = 100
        a = tf.complex(tf.random_normal((N,)), tf.random_normal((N,)))
        b = tf.complex(tf.random_normal((N,)), tf.random_normal((N,)))

        with tf.Session() as sess:

            a_, b_, c = sess.run([a,b,complex_add(a,b)])
            assert np.allclose(c, a_ + b_)

            a_, b_, c = sess.run([a,b,complex_sub(a,b)])
            assert np.allclose(c, a_ - b_)

            a_, b_, c = sess.run([a,b,complex_mul(a,b)])
            assert np.allclose(c, a_ * b_)

            a_, b_, c = sess.run([a,b,complex_div(a,b)])
            assert np.allclose(c, a_ / b_)
```

It would be nice to have such functions transparent with the built-in CPU implementations.
"
3623,Adding a new gate to LSTM,"I am trying to reimplement this paper [Semantically Conditioned LSTM-based Natural Language Generation for Spoken Dialogue Systems](http://mi.eng.cam.ac.uk/~thw28/papers/EMNLP15.pdf), in which they add a gate to the LSTM cell and change how the state is computed.

How can I do this in tensorflow? Do I need to add a new OP ?
"
3622,Missing doc: tf.contrib.layers.embedding_column,"Tutorial https://www.tensorflow.org/versions/r0.10/tutorials/wide_and_deep/index.html refers to tf.contrib.layers.embedding_column.

 No documentation for this is available at API docs https://www.tensorflow.org/versions/master/api_docs/python/contrib.layers.html

The same applies for tf.contrib.learn.DNNLinearCombinedClassifier used later in that tutorial.
"
3621,layer normalization,"recently Hinton published layer normalization on [arxiv layer normalization](https://arxiv.org/pdf/1607.06450v1.pdf?), any plan to add an Op?
"
3620,Building Android version on Ubuntu 16.04 failed.,"Error message as below:

``` gcc
tensorflow/core/platform/env.cc:304:9:
error: conflicting return type specified for ‘virtual tensorflow::int64 tensorflow::{anonymous}::FileStream::ByteCount() const’
   int64 ByteCount() const override { return pos_; }
         ^
In file included from ./tensorflow/core/platform/default/protobuf.h:26:0,
                 from ./tensorflow/core/platform/protobuf.h:31,
                 from ./tensorflow/core/platform/file_system.h:28,
                 from ./tensorflow/core/platform/env.h:27,
                 from tensorflow/core/platform/env.cc:23:
/usr/local/include/google/protobuf/io/zero_copy_stream.h:172:17: error:   overriding ‘virtual google::protobuf::int64 google::protobuf::io::ZeroCopyInputStream::ByteCount() const’
   virtual int64 ByteCount() const = 0;
```

I was trying to build an Android version Tensorflow on Ubuntu 16.04 according to   [Tensorflow's docs](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile) .

This error happened, after I executed this:
`make -f tensorflow/contrib/makefile/Makefile TARGET=ANDROID` 
"
3619,Running Quantized model in iOS failed: Couldn't load model: Not found: Op type not registered 'Dequantize',"### Environment info

Operating System:
Building on Mac OS X
Running on iOS 9.2.1
1. The commit hash (`git rev-parse HEAD`)
   27eeb441bad8bcaa1bcba42a4b4ee49fb50ea0d3 
2. The output of `bazel version`

```
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Tue Jul 12 11:11:47 2016 (1468321907)
Build timestamp: 1468321907
Build timestamp as int: 1468321907
```
### Steps to reproduce
1. I compile tf for iOS with the makefile
2. I follow https://www.tensorflow.org/versions/master/how_tos/quantization/index.html to quantize a model which run perfectly in iOS
3. Replace the frozen model file with the quantized one, iOS throw the Error

```
F /Users/yjmade/Documents/code/labs/tensorflow/tf_master1/tensorflow/contrib/ios_examples/camera_object_detect/CameraExampleViewController.mm:436] Couldn't load model: Not found: Op type not registered 'Dequantize'
```

I think it maybe is the same problem with #3543 
"
3618,gcc: error: unrecognized command line option '-fno-canonical-system-headers',"when I run : 
bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer --verbose_failures
 then the output is 

duan@duan:~/tensorflow$ bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer --verbose_failures
WARNING: /home/duan/.cache/bazel/_bazel_duan/9f3780f2ce96d65830e33f06d4dd8a47/external/protobuf/WORKSPACE:1: Workspace name in /home/duan/.cache/bazel/_bazel_duan/9f3780f2ce96d65830e33f06d4dd8a47/external/protobuf/WORKSPACE (@__main__) does not match the name given in the repository's definition (@protobuf); this will cause a build error in future versions.
WARNING: /home/duan/.cache/bazel/_bazel_duan/9f3780f2ce96d65830e33f06d4dd8a47/external/highwayhash/WORKSPACE:1: Workspace name in /home/duan/.cache/bazel/_bazel_duan/9f3780f2ce96d65830e33f06d4dd8a47/external/highwayhash/WORKSPACE (@__main__) does not match the name given in the repository's definition (@highwayhash); this will cause a build error in future versions.
WARNING: /home/duan/.cache/bazel/_bazel_duan/9f3780f2ce96d65830e33f06d4dd8a47/external/re2/WORKSPACE:1: Workspace name in /home/duan/.cache/bazel/_bazel_duan/9f3780f2ce96d65830e33f06d4dd8a47/external/re2/WORKSPACE (@__main__) does not match the name given in the repository's definition (@re2); this will cause a build error in future versions.
INFO: Found 1 target...
ERROR: /home/duan/.cache/bazel/_bazel_duan/9f3780f2ce96d65830e33f06d4dd8a47/external/protobuf/BUILD:111:1: C++ compilation of rule '@protobuf//:protobuf' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command 
  (cd /home/duan/.cache/bazel/_bazel_duan/9f3780f2ce96d65830e33f06d4dd8a47/execroot/tensorflow && \
  exec env - \
    PATH=/home/duan/bin:/usr/local/cuda-8.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/duan/.bazel/bin \
  third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections -g0 '-std=c++11' '-frandom-seed=bazel-out/host/bin/external/protobuf/_objs/protobuf/external/protobuf/src/google/protobuf/message.o' -iquote external/protobuf -iquote bazel-out/host/genfiles/external/protobuf -iquote external/bazel_tools -iquote bazel-out/host/genfiles/external/bazel_tools -isystem external/protobuf/src -isystem bazel-out/host/genfiles/external/protobuf/src -isystem external/bazel_tools/tools/cpp/gcc3 -DHAVE_PTHREAD -Wall -Wwrite-strings -Woverloaded-virtual -Wno-sign-compare '-Wno-error=unused-function' -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -fno-canonical-system-headers -MD -MF bazel-out/host/bin/external/protobuf/_objs/protobuf/external/protobuf/src/google/protobuf/message.d -c external/protobuf/src/google/protobuf/message.cc -o bazel-out/host/bin/external/protobuf/_objs/protobuf/external/protobuf/src/google/protobuf/message.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
gcc: error: unrecognized command line option '-fno-canonical-system-headers'
Target //tensorflow/cc:tutorials_example_trainer failed to build
INFO: Elapsed time: 0.784s, Critical Path: 0.14s
"
3616,ImportError: libcudart.so.7.0: cannot open shared object file: No such file or directory,"I installed Cuda 7.5 and cudnn v4. after making the symlinks for cudnn and changing the path variables, when I import tensorflow I get the error : ImportError: libcudart.so.7.0: cannot open shared object file: No such file or directory. ?

Any advice on how to proceed?
"
3613,Running LinearClassifier.fit with SparseTensor,"I'm trying to create a LinearClassifer with a sparse binary numpy coo matrix (reports) using a SparseTensor.  This is with TensorFlow 0.9.0

I do this as follows:

```
reports_indices = list()
rows,cols = reports.nonzero()
for row,col in zip(rows,cols):
   reports_indices.append([row,col])

x_sparsetensor = tf.SparseTensor(
  indices=reports_indices,
  values=[1] * len(reports_indices),
  shape=[reports.shape[0],reports.shape[1]])
```

The dimensions of reports is 10K by 1.5K.

I then setup the LinearClassifier as follows:

```
m = tf.contrib.learn.LinearClassifier()

m.fit(x=drug_cols,y=(1*y_vec).todense(),input_fn=None)
```

This results in the following error:
`TypeError: object of type 'Tensor' has no len()
`

Is my construction incorrect for some reason?  Thanks in advance for any help.
"
3612,Cuda error: creating context when one is currently active,"### Environment info
- Operating System: Ubuntu 14.04, 
- GPU server with 8 **Tesla K80** GPUs,
- Python 2.7 (Anaconda)

Installed version of CUDA and cuDNN: 
- Cuda 7.5, cuDNN v4

If installed from binary pip package, provide:
1. Pip package: GPU-enabled, Python 2.7
   https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`:

I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
0.9.0
### Steps to reproduce

```
import tensorflow as tf
sess = tf.Session()
```

yields the error:
**W tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active;**
see the detailed logs below please:
### What have you tried?
1. I checked the output of the `nvidia-smi`. There are other processes run by other users currently. Below is the output.
2. I re-installed tensorflow again using pip, it didn't solve the problem.

```
+------------------------------------------------------+                       
| NVIDIA-SMI 352.39     Driver Version: 352.39         |                       
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K80           Off  | 0000:05:00.0     Off |                    0 |
| N/A   33C    P0    59W / 149W |    190MiB / 11519MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla K80           Off  | 0000:06:00.0     Off |                    0 |
| N/A   30C    P8    30W / 149W |     22MiB / 11519MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  Tesla K80           Off  | 0000:09:00.0     Off |                    0 |
| N/A   25C    P8    27W / 149W |     22MiB / 11519MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  Tesla K80           Off  | 0000:0A:00.0     Off |                    0 |
| N/A   28C    P8    31W / 149W |     22MiB / 11519MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   4  Tesla K80           Off  | 0000:84:00.0     Off |                    0 |
| N/A   24C    P8    28W / 149W |     22MiB / 11519MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   5  Tesla K80           Off  | 0000:85:00.0     Off |                    0 |
| N/A   54C    P0   106W / 149W |  11461MiB / 11519MiB |     58%      Default |
+-------------------------------+----------------------+----------------------+
|   6  Tesla K80           Off  | 0000:88:00.0     Off |                    0 |
| N/A   49C    P0   134W / 149W |  11461MiB / 11519MiB |     97%      Default |
+-------------------------------+----------------------+----------------------+
|   7  Tesla K80           Off  | 0000:89:00.0     Off |                    0 |
| N/A   69C    P0   131W / 149W |  11462MiB / 11519MiB |     57%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0    155948    C   ../../../build/tools/caffe                      82MiB |
|    0    196261    C   .build_release/test/test_all.testbin            81MiB |
|    5     19542    C   python                                       11436MiB |
|    6     18802    C   python                                       11436MiB |
|    7     85515    C   python                                       11437MiB 
```
### Logs

```
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:05:00.0
Total memory: 11.25GiB
Free memory: 11.00GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x2f85bd0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:06:00.0
Total memory: 11.25GiB
Free memory: 11.16GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x339e320
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 2 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:09:00.0
Total memory: 11.25GiB
Free memory: 11.16GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x37b5f60
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 3 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:0a:00.0
Total memory: 11.25GiB
Free memory: 11.16GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x3bd1860
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 4 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:84:00.0
Total memory: 11.25GiB
Free memory: 11.16GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x3ff0cd0
Segmentation fault (core dumped)
```
"
3611,Feature request: Support for non-minibatch data for intrinsic functions,"Some functions in the TensorFlow standard library makes an assumption that we're always feeding minibatches. 

One example is `tf.nn.softmax` which assumes a 2-D input of shape `[batch_size, num_classes]`. It would be nice to have a second API to such subroutines that work also without an assumption of a minibatch dimension in the input tensor.
"
3610,Graph optimization and other features,"I've been using Theano for about 4 years now and love its flexibility due to the many available low-level ops that allow me to implement complicated and possibly non-standard models without needing to write C++/CUDA code (most of the time). In addition, I can focus almost exclusively on the model design and don't need to think much about numerical stability or suboptimal graph design leading to increased execution times because the graph optimization framework takes care of this. One common example is computing the log-loss of a categorical classifier which I can express naïvely in Theano, but in most (all?) other tools including TensorFlow I need to use an op like `tf.nn.softmax_cross_entropy_with_logits`. In my opinion, the fact that I need to call these kinds of specialized ops **manually**, i.e. I need to know about them and think about when and how to use them in all kinds of situations, takes away many of the advantages of TensorFlow. Similarly, implementing model optimizers in C++/CUDA directly introduces unnecessary implementation complexity and does not take advantage of the fact that (most likely) all mathematical ops needed to specify the update formulas are already available (CPU and GPU kernels).

I believe TensorFlow has a superior framework design in terms of keeping C++ and Python clearly separated and the inherent multi-device computing capabilities, but the aspects I described above make me very hesitant to use TensorFlow. Are there any plans to add a proper graph optimization framework similar to the one in Theano? And what are your reasons for implementing the model optimizers as individual kernels instead of reusing ops (like using the updates-dictionary in Theano)?
"
3608,How To Upgrade Tensorflow,"I have tensorflow v 0.9. How I can upgrade it without uninstall it?  
"
3607,missing doc for SyncReplicasOptimizer,"doc not found in official website, description is in `tensorflow/python/training/sync_replicas_optimizer.py`
"
3605,scikit flow - race condition when trying to fit,"I'm probably missing something obvious but I did a fresh build tonight and when trying to run the MNIST examples, every time I run them I'm getting the below errors. I have tried a few of the examples and can't seem to get around it (even when updating the depreciated bits still in the examples.) Am I missing something?

Code:
`
from **future** import absolute_import
from **future** import division
from **future** import print_function

from sklearn import metrics
import tensorflow as tf
from tensorflow.contrib import learn
import numpy as np
### Download and load MNIST data.

mnist = learn.datasets.load_dataset('mnist')
y = np.array(mnist.train.labels, dtype='int32')
### Linear classifier.

feature_columns = learn.infer_real_valued_columns_from_input(mnist.train.images)
classifier = learn.TensorFlowLinearClassifier(
    feature_columns=feature_columns, n_classes=10, batch_size=100, steps=1000,
    learning_rate=0.01)
classifier.fit(mnist.train.images,y)
score = metrics.accuracy_score(
    mnist.test.labels, classifier.predict(mnist.test.images))
print('Accuracy: {0:f}'.format(score))
`

Error:
I tensorflow/core/common_runtime/gpu/gpu_device.cc:839] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GT 750M, pci bus id: 0000:07:00.0)
E tensorflow/c/c_api.cc:485] WhereOp: Race condition between counting the number of true elements and writing them.  When counting, saw 1287 elements; but when writing their indices, saw 7 elements.
     [[Node: report_uninitialized_variables/Where = Where[_device=""/job:localhost/replica:0/task:0/cpu:0""](report_uninitialized_variables/Reshape_1)]]
     [[Node: report_uninitialized_variables/Where/_28 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_30_report_uninitialized_variables/Where"", tensor_type=DT_INT64, _device=""/job:localhost/replica:0/task:0/gpu:0""]()]]
"
3603,RC 0.10 3X Slower than 0.9 and Error Compiling From Source Under Certain Conditions,"This issue is a follow-up to [this posting](http://stackoverflow.com/questions/38704095/tensorflow-rc-0-10-3x-slower-than-0-9) on stack overflow. As noted, the 0.10 version is ~3x slower than version 0.9 for a particular training script I am using. The same slow-down is observed when using the pip version with CuDNN4 or with a version compiled from source and CuDNN 5.1.

I'm not sure what information about the training script would help. It is a fairly complex script that is training a network for object detection using methods similar to YOLO and SSD. It won't be possible to post the entire set of code, but if there is a way to isolate the source of the delay I may be able to modify it and post that portion.

While trying to get insight into the source of the slow-down I also noted that I wasn't able to compile from source using CuDNN4 as noted in the SO posting. This is a secondary issue, but may also warrant investigation.
"
3601,"Tensorflow basic_rnn_seq2seq TypeError: Expected int32, got -0.1 of type 'float' instead","Original issue here: http://stackoverflow.com/q/38695086/2082009
"
3600,failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED,"With the current master branch I receive the following error 20% of the time when training an RNN.

> I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
> name: GeForce GTX TITAN X
> major: 5 minor: 2 memoryClockRate (GHz) 1.076
> pciBusID 0000:83:00.0
> Total memory: 12.00GiB
> Free memory: 11.86GiB
> I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 
> I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y 
> I tensorflow/core/common_runtime/gpu/gpu_device.cc:843] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:83:00.0)
> E tensorflow/stream_executor/cuda/cuda_blas.cc:367] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
> W tensorflow/stream_executor/stream.cc:1334] attempting to perform BLAS operation using StreamExecutor without BLAS support
> I tensorflow/stream_executor/stream.cc:1282] stream 0x76b6890 did not wait for stream: 0x76b5d60
> I tensorflow/stream_executor/stream.cc:3732] stream 0x76b6890 did not memcpy host-to-device; source: 0x204570900
> W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12
>          [[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/gpu:0""](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]
> W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12
>          [[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/gpu:0""](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]
> W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12
>          [[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/gpu:0""](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]
> W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12
>          [[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/gpu:0""](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]
> W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12
>          [[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/gpu:0""](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]
> W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12
>          [[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/gpu:0""](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]
> I tensorflow/stream_executor/stream.cc:3732] stream 0x76b6890 did not memcpy host-to-device; source: 0x204570b00
> W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12
>          [[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/gpu:0""](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]
> W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12
>          [[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/gpu:0""](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]
> W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12
>          [[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/gpu:0""](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]
> W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12
>          [[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/gpu:0""](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]
> W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12
>          [[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/gpu:0""](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]
> F tensorflow/core/common_runtime/gpu/gpu_util.cc:343] CPU->GPU Memcpy failed
### Environment info

Scientific Linux 7
cuda 7.5.18
cudnn 5.0.5

$ bazel version
....
Build label: 0.3.0
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Jun 10 11:38:23 2016 (1465558703)
Build timestamp: 1465558703
Build timestamp as int: 1465558703
$ git rev-parse HEAD
88d9bc16d6a16e5b660cda548b74944f27ddcd1b

$ nvidia-smi -L
GPU 0: GeForce GTX TITAN X
"
3599,Use Retrained categories in Android Camera Demo,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System: Docker on Windows

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`
### Steps to reproduce
1. Successfully retrain new data with Docker. Get the two retrained files retrained_graph.pb and retrained_labels.txt
   https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/index.html?index=..%2F..%2Findex#5
2. Try to install Bazel on windows but failed. But I found an Android Demo which doesn't need Bazel. This one works well on Windows. It can recognize images into 1000 classes provided by ImageNet in an Android real-time camera.
   https://github.com/miyosuda/TensorFlowAndroidDemo
### What have you tried?

Reference； https://github.com/tensorflow/tensorflow/issues/1269
Based on the suggestions, I tried the following things:
1.Find the coded_stream.h in the google/protobuf section of your tensorflow build and modify the 64 to 256 in the following line:
static const int kDefaultTotalBytesLimit = 64 << 20; // Change the 64 to 256 MB
2.Modify only the input_size to 299 and the image_mean to 128 in the TensorflowImageListener.java
3.Go to tensorflow_jni.cc in the android demo and modify as follows:

```
  input_tensor_mapped(0, i, j, 0) =
      (static_cast<float>(src->red) - g_image_mean)/g_image_mean;
  input_tensor_mapped(0, i, j, 1) =
      (static_cast<float>(src->green) - g_image_mean)/g_image_mean;
  input_tensor_mapped(0, i, j, 2) =
      (static_cast<float>(src->blue) - g_image_mean)/g_image_mean;
  ++src;
```

std::vector<std::pair<std::string, tensorflow::Tensor> > input_tensors(
      {{""Mul"", input_tensor}});

std::vectorstd::string output_names({""softmax""});
4.Do the following changes in TensorflowImageListerner.java:
 private static final String MODEL_FILE = ""file:///android_asset/retrained_graph.pb"";
  private static final String LABEL_FILE =
      ""file:///android_asset/retrained_labels.txt"";
5. Build the android demo 
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
08-01 17:36:50.015 14978-15121/org.tensorflow.tensorflowdemo A/native: jni_utils.cc:107 Check failed: message->ParseFromZeroCopyStream(&adaptor) 
08-01 17:36:50.015 14978-15121/org.tensorflow.tensorflowdemo A/libc: Fatal signal 6 (SIGABRT), code -6 in tid 15121 (ImageListener)

I know this is a problem due to the incompatible variables of Inception v3 and Inception 5h. The Android Demo model I use is Inception 5h, But the model I used to train my new data is Inception 3v.  I've tried to edit the variables mentioned here: https://github.com/tensorflow/tensorflow/issues/1269.
But I still get the same errors. Anyone could help me explain how to adapt my new trained data running in the Android Demo?
"
3598,"gather_nd doesnt work for batched slicing,(even for documented examples)","gather_nd doesn't work for batched slicing
Steps to Reproduce

Run the following code

``` python
import tensorflow as tf
cons_indices=tf.constant([[[1]], [[0]]])
batch=tf.constant([['a', 'b'], ['c', 'd']])
gathered=tf.gather_nd(batch,cons_indices)
sess = tf.Session()
result = sess.run(gathered)
print(result)
sess.close()
```

Always gives an error regarding incompatible dimensions.

Either the documentation needs to be updated to indicate proper argument format or function implementation is buggy
"
3596,Unable to run the tensorflow/tensorflow/examples/skflow/multipul_gpu.py ,"Hi, 

when i run the tensorflow/tensorflow/examples/skflow/multipul_gpu.py example, I got the following error. Any helps would be great!

```
  File ""/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 723, in _do_run
    target_list, options, run_metadata)
  File ""/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 743, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'save/ShardedFilename_2': Could not satisfy explicit device specification '/device:GPU:2' be$
Colocation Debug Info:
Colocation group had the following types and devices:
Identity: CPU
ShardedFilename: CPU
         [[Node: save/ShardedFilename_2 = ShardedFilename[_device=""/device:GPU:2""](save/Const, save/ShardedFilename_2/shard, save/num_shards)]]
Caused by op u'save/ShardedFilename_2', defined at:
  File ""multiple_gpu.py"", line 39, in <module>
    classifier.fit(X_train, y_train)
  File ""/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/base.py"", line 166, in fit
    monitors=monitors)
  File ""/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 577, in _train_model
    max_steps=max_steps)
  File ""/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py"", line 232, in train
    max_steps)
  File ""/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py"", line 309, in _train_internal
    saver=_make_saver(graph, keep_checkpoint_max),
  File ""/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py"", line 95, in _make_saver
    max_to_keep=keep_checkpoint_max)
  File ""/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 854, in __init__
    restore_sequentially=restore_sequentially)
  File ""/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 512, in build
    save_tensor = self._AddShardedSaveOps(filename_tensor, per_device)
  File ""/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 232, in _AddShardedSaveOps
    filename_tensor, shard, num_shards_tensor)
  File ""/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 200, in sharded_filename
    return gen_io_ops._sharded_filename(filename_tensor, shard, num_shards)
  File ""/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_io_ops.py"", line 460, in _sharded_filename
    shard=shard, num_shards=num_shards, name=name)
  File ""/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 703, in apply_op
    op_def=op_def)
  File ""/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2298, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1232, in __init__
    self._traceback = _extract_stack()

```
### Environment info

Operating System:  Ubuntu 16.04

Installed version of CUDA and cuDNN: CUDA 8.0, cuDNN 5

(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```
/usr/local/cuda/lib64/libcudadevrt.a
/usr/local/cuda/lib64/libcudart.so
/usr/local/cuda/lib64/libcudart.so.8.0
/usr/local/cuda/lib64/libcudart.so.8.0.27
/usr/local/cuda/lib64/libcudart_static.a
/usr/local/cuda/lib64/libcudnn.so
/usr/local/cuda/lib64/libcudnn.so.5
/usr/local/cuda/lib64/libcudnn.so.5.0.5
```

If installed from sources, provide the commit hash:
e95f4e760c6b6713b6b686ebeff9a1586a5831dd
### Steps to reproduce
1. run multipul_gpu.py
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
3595,Unable to replicate RNN results on a different dataset,"### What is the problem?

[This RNN tutorial script ](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/ptb/ptb_word_lm.py) works perfectly fine until the contents of the files are unchanged, but once changed a **KeyError** is encountered. (see the error log below)
### Environment info

Operating System:

Installed version of CUDA and cuDNN: 

lrwxrwxrwx 1 root root       12 May 24 00:01 libcuda.so -> libcuda.so.1
lrwxrwxrwx 1 root root       17 May 24 00:01 libcuda.so.1 -> libcuda.so.352.41
-rwxr-xr-x 1 root root 14280360 May 24 00:01 libcuda.so.352.41
lrwxrwxrwx 1 root root       29 May 24 00:02 libcudnn.so -> /etc/alternatives/libcudnn_so
lrwxrwxrwx 1 root root       17 Feb  9 07:47 libcudnn.so.4 -> libcudnn.so.4.0.7
-rw-r--r-- 1 root root 61453024 Feb  9 07:47 libcudnn.so.4.0.7
lrwxrwxrwx 1 root root       32 May 24 00:02 libcudnn_static.a -> /etc/alternatives/libcudnn_stlib
-rw-r--r-- 1 root root 62025862 Feb  9 07:47 libcudnn_static_v4.a

If installed from binary pip package, provide:
1. Which pip package you installed: 
   **_Ubuntu/Linux 64-bit, GPU enabled, Python 2.7**_
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
0.9.0
### Steps to reproduce
1. Download data from here: http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz 
2. Cloned the tensorflow git repository, and be in the root of the git tree.
3. cd tensorflow/models/rnn/ptb
4. python ptb_word_lm.py --data_path=/tmp/simple-examples/data/ --model small
### What have you tried?
1. Change the contents of the file ptb.train.txt OR ptb.valid.txt OR ptb.test.txt
### Logs or other output that would be helpful

Traceback (most recent call last):
  File ""ptb_word_lm.py"", line 350, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""ptb_word_lm.py"", line 289, in main
    raw_data = reader.ptb_raw_data(FLAGS.data_path)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/models/rnn/ptb/reader.py"", line 76, in ptb_raw_data
    valid_data = _file_to_word_ids(valid_path, word_to_id)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/models/rnn/ptb/reader.py"", line 48, in _file_to_word_ids
    return [word_to_id[word] for word in data]
KeyError: '[The'

**_NOTE**_: For this specific example, the contents of ptb.valid.txt were changed and the first line of this file is ""[The Parent's Assistant, by Maria Edgeworth]""
"
3593,How to run custom encoder-decoder in Tensorflow using available APIs?,"I need to run a encoder-decoder model in Tensorflow. I see that using the available APIs `basic_rnn_seq2seq(encoder_input_data, decoder_input_data, lstm_cell)` etc., an encoder-decoder system can be created. However, few pertaining issues are:
1. How can we enter the embeddings such as word2vec in such model? I am
   aware that we can do embedding lookup but as per the API
   `encoder_input_data` is a list of 2D Tensor of size batch_size x
   input_size. How can each word be represented using its respective word embedding in this setup? Even `embedding_rnn_seq2seq` internally extracts the embeddings. How to give pre-calculated word embeddings as input? 
2. How can we get the cost and perplexity through the API?
3. In case of test instances, we may not know the corresponding decoder inputs. How to handle such case?
"
3592,Regex tag and zoom in for histogram summary does not work properly,"Since ResNet could create hundreds of layers and the initial activation value of layers are also very large, I found I need to zoom in multiple times, and also have hundreds of histogram summary in one tag group. So it would be critical to be able to zoom, and also break summary down according to regex.

However, I found though for scalar summary, it works pretty well, for histogram summary, I can only zoom in once in 0.9.0, and not even once in 0.10.0. Also the regex group function seems to not work at all (see the photo below, it seems all summary comes in whatever the regex is --- I write a ""###"" in this case). 

At first I though it is just there are too many graphs, so my computer stuck. But after I tried some small network, the phenomenon held. Could it be fixed? Thanks a lot.

![image](https://cloud.githubusercontent.com/assets/2428233/17275589/b6d748b4-573f-11e6-8a96-f95decbefc7e.png)
"
3591, How to use python code about  the mnist  to  build the android apk ,"just as the title said .
I just want to come true the mnist  on the android like the tensorflow android_demo
now I just know how to build the model with python
and what I should do the next.
"
3589,bazel 0.3.1 compilation failure on master branch,"**Edit: There is no problem with bazel 0.3.1 and TF 0.9, problem present with master branch and 0.10 RC**

Ubuntu 14 x64 MSI GS60 (860M - compute score 3.0)

```
printf ""\nn\ny\n\n7.5\n\n\n\n3.0\n"" | ./configure
bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
```

:

```
[several minutes of successful compiling]
...
ERROR: /home/ggg/000/tensorflow/tensorflow/core/kernels/BUILD:1515:1: undeclared inclusion(s) in rule '//tensorflow/core/kernels:depth_space_ops_gpu':
this rule is missing dependency declarations for the following files included by 'tensorflow/core/kernels/depthtospace_op_gpu.cu.cc':
  '/usr/local/cuda-7.5/include/cuda_runtime.h'
  '/usr/local/cuda-7.5/include/host_config.h'
  '/usr/local/cuda-7.5/include/builtin_types.h'
  '/usr/local/cuda-7.5/include/device_types.h'
  '/usr/local/cuda-7.5/include/host_defines.h'
  '/usr/local/cuda-7.5/include/driver_types.h'
  '/usr/local/cuda-7.5/include/surface_types.h'
  '/usr/local/cuda-7.5/include/texture_types.h'
  '/usr/local/cuda-7.5/include/vector_types.h'
  '/usr/local/cuda-7.5/include/channel_descriptor.h'
  '/usr/local/cuda-7.5/include/cuda_runtime_api.h'
  '/usr/local/cuda-7.5/include/cuda_device_runtime_api.h'
  '/usr/local/cuda-7.5/include/driver_functions.h'
  '/usr/local/cuda-7.5/include/vector_functions.h'
  '/usr/local/cuda-7.5/include/vector_functions.hpp'
  '/usr/local/cuda-7.5/include/common_functions.h'
  '/usr/local/cuda-7.5/include/math_functions.h'
  '/usr/local/cuda-7.5/include/math_functions.hpp'
  '/usr/local/cuda-7.5/include/math_functions_dbl_ptx3.h'
  '/usr/local/cuda-7.5/include/math_functions_dbl_ptx3.hpp'
  '/usr/local/cuda-7.5/include/cuda_surface_types.h'
  '/usr/local/cuda-7.5/include/cuda_texture_types.h'
  '/usr/local/cuda-7.5/include/device_functions.h'
  '/usr/local/cuda-7.5/include/device_functions.hpp'
  '/usr/local/cuda-7.5/include/device_atomic_functions.h'
  '/usr/local/cuda-7.5/include/device_atomic_functions.hpp'
  '/usr/local/cuda-7.5/include/device_double_functions.h'
  '/usr/local/cuda-7.5/include/device_double_functions.hpp'
  '/usr/local/cuda-7.5/include/sm_20_atomic_functions.h'
  '/usr/local/cuda-7.5/include/sm_20_atomic_functions.hpp'
  '/usr/local/cuda-7.5/include/sm_32_atomic_functions.h'
  '/usr/local/cuda-7.5/include/sm_32_atomic_functions.hpp'
  '/usr/local/cuda-7.5/include/sm_35_atomic_functions.h'
  '/usr/local/cuda-7.5/include/sm_20_intrinsics.h'
  '/usr/local/cuda-7.5/include/sm_20_intrinsics.hpp'
  '/usr/local/cuda-7.5/include/sm_30_intrinsics.h'
  '/usr/local/cuda-7.5/include/sm_30_intrinsics.hpp'
  '/usr/local/cuda-7.5/include/sm_32_intrinsics.h'
  '/usr/local/cuda-7.5/include/sm_32_intrinsics.hpp'
  '/usr/local/cuda-7.5/include/sm_35_intrinsics.h'
  '/usr/local/cuda-7.5/include/surface_functions.h'
  '/usr/local/cuda-7.5/include/surface_functions.hpp'
  '/usr/local/cuda-7.5/include/texture_fetch_functions.h'
  '/usr/local/cuda-7.5/include/texture_fetch_functions.hpp'
  '/usr/local/cuda-7.5/include/texture_indirect_functions.h'
  '/usr/local/cuda-7.5/include/texture_indirect_functions.hpp'
  '/usr/local/cuda-7.5/include/surface_indirect_functions.h'
  '/usr/local/cuda-7.5/include/surface_indirect_functions.hpp'
  '/usr/local/cuda-7.5/include/device_launch_parameters.h'
  '/usr/local/cuda-7.5/include/cuda_fp16.h'
  '/usr/local/cuda-7.5/include/math_constants.h'
  '/usr/local/cuda-7.5/include/curand_kernel.h'
  '/usr/local/cuda-7.5/include/curand.h'
  '/usr/local/cuda-7.5/include/curand_discrete.h'
  '/usr/local/cuda-7.5/include/curand_precalc.h'
  '/usr/local/cuda-7.5/include/curand_mrg32k3a.h'
  '/usr/local/cuda-7.5/include/curand_mtgp32_kernel.h'
  '/usr/local/cuda-7.5/include/cuda.h'
  '/usr/local/cuda-7.5/include/curand_mtgp32.h'
  '/usr/local/cuda-7.5/include/curand_philox4x32_x.h'
  '/usr/local/cuda-7.5/include/curand_globals.h'
  '/usr/local/cuda-7.5/include/curand_uniform.h'
  '/usr/local/cuda-7.5/include/curand_normal.h'
  '/usr/local/cuda-7.5/include/curand_normal_static.h'
  '/usr/local/cuda-7.5/include/curand_lognormal.h'
  '/usr/local/cuda-7.5/include/curand_poisson.h'
  '/usr/local/cuda-7.5/include/curand_discrete2.h'.
nvcc warning : option '--relaxed-constexpr' has been deprecated and replaced by option '--expt-relaxed-constexpr'.
nvcc warning : option '--relaxed-constexpr' has been deprecated and replaced by option '--expt-relaxed-constexpr'.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 464.576s, Critical Path: 281.74s
```
"
3587,In my town people obsess about digital life.,"In my town people **obsess** about digital life. Every passing conversation is couched in **software vernacular**. Enthusiasm for the unrealized potential of information automation is explained as an ever expanding frontier. Technology has brought us great fortune but even greater things in common. For every fan of Larry Ellison there are twenty aspiring Zuckerbergs. People who visualize technology not just as intellectual property, but as an expanding commons. While tech serfdom abounds in the libertarian haven of Silicon Valley there are those whose fantasy is a digital utopia. 
"
3586,Bug involving tf.train.Saver and num_epochs parameter in tf.train.string_input_producer,"I've run into a strange problem involving both `tf.train.Saver` and an input pipeline based on `tf.train.string_input_producer()`. It seems as though the `num_epochs` parameter to `tf.train.string_input_producer()` stops working as intended after loading a saved model.

I'm currently using v0.8 but I suspect this is still an issue on v0.9 and above.
### Environment info

Operating System: Mac OSX (10.11.6)
Tensorflow version: 0.8
pip version: 8.1.1
### Steps to reproduce

1 - Create a new directory and add to it the files from the following gist: https://gist.github.com/6d730e1b3d331c4be34c9a57b0a39ccf . The `1.txt` and `2.txt` files simulate training data. The `training.py` file implements a simple input pipeline, taking in text files, and printing them line by line. Notice that the `num_epochs` parameter on line 28 is set to 1.

2 - Run `$ python training.py test 1.txt`. The output should resemble the following: 

```
The multiplying villanies of nature
Do swarm upon him--from the western isles
And fortune, on his damned quarrel smiling,
Show'd like a rebel's whore: but all's too weak:
For brave Macbeth--well he deserves that name--
Model saved to ./model-test-0
As two spent swimmers, that do cling together
Disdaining fortune, with his brandish'd steel,
And fix'd his head upon our battlements.
Like valour's minion carved out his passage
Which smoked with bloody execution,
Model saved to ./model-test-1
Till he unseam'd him from the nave to the chaps,
And choke their art. The merciless Macdonwald--
Of kerns and gallowglasses is supplied;
Worthy to be a rebel, for to that
Doubtful it stood;
Model saved to ./model-test-2
Done training!
Model saved to ./model-test-3
```

3 - Run `$ python training.py test 2.txt`. The output should be:

```
Done training!
Model saved to ./model-test-3
```

4 - Now, change the `num_epochs` parameter on line 28 from 1 to 2, and run `$ python training.py test 2.txt` again. In this case, we have something that resembles:

```
Letting 'I dare not' wait upon 'I would,'
As thou art in desire? Wouldst thou have that
Such I account thy love. Art thou afeard
Which thou esteem'st the ornament of life,
And wakes it now, to look so green and pale
Model saved to ./model-test-3
And live a coward in thine own esteem,
At what it did so freely? From this time
Like the poor cat i' the adage?
Wherein you dress'd yourself? hath it slept since?
To be the same in thine own act and valour
Model saved to ./model-test-4
Done training!
Model saved to ./model-test-5
```

5 - To cleanup, run `$ rm checkpoint model-test-*`.

There are two problems: First, the model does not continue to ""train"" in step 3. Second, when the `num_epochs` parameter is modified and it does continue to train, it doesn't reproduce the input twice, as it should (step 4).

Playing around with this, I notice that the initial value of `num_epochs` works as expected, e.g. if at step 1, `num_epochs` is set to 3, three copies of the input file will be produced. Further, step 4 yields similar results when the new value for `num_epochs` is larger than the previous value.
"
3585,Bidirectional encoder for seq2seq in Tensorflow,"All methods in `seq2seq.py` library supports encoder-decoder system with the input in forward sequence. How can we construct a bi-directional encoder-decoder using the libraries or else, much like the concept in bi-directional LSTM?
"
3583,Dying Threads?,"### Environment info

Operating System: Ubuntu trusty

Installed version of CUDA and cuDNN: Cuda compilation tools, release 7.5, V7.5.17
1. Which ~~pip~~ package you installed.  Docker gpu-devel image
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
0.9.0
### Steps to reproduce
1. Run inception model on training with inception_train.py
   
   bazel-bin/inception/(pick your data)_train \
     --train_dir=""${TRAIN_DIR}"" \
     --data_dir=""${DATA_DIR}"" \
     --pretrained_model_checkpoint_path=""${PRETRAINED_DIR}"" \
     --fine_tune=True \
     --initial_learning_rate=0.01 \
     --input_queue_memory_factor=12 \
     --batch_size=64 \
     --max_steps=100000 \
     --num_epochs_per_decay=30 \
     --num_preprocess_threads=4 \
     --num_readers=4 \
     --log_device_placement=True
### What have you tried?
1. This is ironic, because I have been wrestling with the problem for a few days, and serendipitously came to a conclusion. I was training the model and testing it out, and always
   after 1000~ steps the training slows to a crawl utilizing my GPU only every 10s - 15s and the CPU seems to be only utilizing 2 threads to 100% at this point for preprocessing , when i specified 4 & 4 readers, but all threads kick in right before/at the GPU utilization. I tried restarted and playing with the threads and readers and other things, no luck, it still slowed after 1000~ steps. I left it running for whatever reason and later started running a Tensorflow bazel build, which used significant CPU for some time and after/during the build my training magically picked up to the original speed at the beginning, and by picked up i mean went from 1-4 exp/s not steady to 15 exp/s steady, hmm thats strange, because it had been crawling for hours at 1-4 exp/s? 
### Logs or other output that would be helpful

None 
"
3582,"Loss not decreasing, GTX 1070, cuDNN 5.0 for RC 8.0, Cuda 8.0 RC","I've spent about 12 hours monkeying around before throwing in the towel here. I've checked the other similar threads on this and done the steps there. This includes #3068 and #3507. 
### Environment info

Operating System: Ubuntu 14.04

Installed version of CUDA and cuDNN: 
Cuda 8.0 RC
cuDNN 5.0 RC
Output of libcudn*:
/usr/local/cuda/lib64/libcudadevrt.a       /usr/local/cuda/lib64/libcudnn.so
/usr/local/cuda/lib64/libcudart.so         /usr/local/cuda/lib64/libcudnn.so.5
/usr/local/cuda/lib64/libcudart.so.8.0     /usr/local/cuda/lib64/libcudnn.so.5.0.5
/usr/local/cuda/lib64/libcudart.so.8.0.27  /usr/local/cuda/lib64/libcudnn_static.a
/usr/local/cuda/lib64/libcudart_static.a

Built from source
1. The commit hash: 5161e4c51b994b3feb93cdb851479c29a3450f31
2. The output of `bazel version`:
Build label: 0.3.0
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Jun 10 11:38:23 2016 (1465558703)
Build timestamp: 1465558703
Build timestamp as int: 1465558703
### Notes

I've built and thrown out, built and thrown out, cleaned the slate and reinstalled in about as many permutations as I can think. However, with training, the loss freezes. I simplified my network all the way down to a shallow autoencoder where there is only one image in the training set, and still the loss freezes. This worked completely fine using the CPU for similar code from a regular old pip distro. I'm using the MSE loss on a 224*224 image scaled between 0 and 1 to try to keep things as regular as possible.

Something odd to note is that no matter what my loss starts at, it always tends to 11893.53125. Ironically, if it starts below there, it goes up to it. Example of several 40 epoch runs: 11893.52930, 11893.53223, 11893.52930, 11893.52930, 11893.52930.

My theory was that it was outputting 0s -- assuming an even distribution, the summed MSE loss would be 224x224x.5^2 = 12544, which is pretty close to our 11893.52930. Since regular images won't have an even pixel distribution, this makes sense. In practice, after testing the network, it outputs all 1s.

A side note is that when running the trainer test, the lambda value was not always exactly 2 -- every few iterations it was off by a fraction.

I'm really scratching my head here -- any folks with combat experience see any telltale signs of a solution? Thank you very much in advance for your time.
"
3580,Image retraining example: unable to run,"### Environment info

Operating System: Ubuntu 14.04 LTS 64-bit

Installed version of CUDA and cuDNN: none (not using GPU)

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`): fc9162975e52978d3af38549b570cc3cc5f0ab66
2. The output of `bazel version`

```
Build label: 0.3.0
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Jun 10 11:38:23 2016 (1465558703)
Build timestamp: 1465558703
Build timestamp as int: 1465558703
```
### Steps to reproduce

(instructions from [here](https://www.tensorflow.org/versions/r0.9/how_tos/image_retraining/index.html))
1. Run `cd ~`
2. Run `curl -O http://download.tensorflow.org/example_images/flower_photos.tgz
tar xzf flower_photos.tgz`
3. Move to root of TensorFlow source directory
4. Run `bazel build tensorflow/examples/image_retraining:retrain`
5. Run `bazel-bin/tensorflow/examples/image_retraining/retrain --image_dir ~/flower_photos`
### What have you tried?
1. The StackOverflow question [here](http://stackoverflow.com/questions/33622842/error-in-python-after-import-tensorflow-typeerror-init-got-an-unexpect) suggested uninstalling protobuf and reinstalling it with a version greater than or equal to 3.0.0a3. However, when I ran `pip uninstall protobuf`, I got this output:
   `Can't uninstall 'protobuf'. No files were found to uninstall.`
   I then tried to just run `pip install protobuf`, however, this was the output:

```
Requirement already satisfied (use --upgrade to upgrade): protobuf in /usr/local/lib/python2.7/dist-packages
Requirement already satisfied (use --upgrade to upgrade): setuptools in /usr/local/lib/python2.7/dist-packages (from protobuf)
Cleaning up...
```

I then tried to run `pip install 'protobuf>=3.0.0a3'` as suggested on the StackOverflow thread, but this was the output:

```
Downloading/unpacking protobuf>=3.0.0a3
  Downloading protobuf-3.0.0-py2.py3-none-any.whl (342kB): 342kB downloaded
Requirement already satisfied (use --upgrade to upgrade): six>=1.9 in /usr/local/lib/python2.7/dist-packages (from protobuf>=3.0.0a3)
Requirement already satisfied (use --upgrade to upgrade): setuptools in /usr/local/lib/python2.7/dist-packages (from protobuf>=3.0.0a3)
Installing collected packages: protobuf
  Found existing installation: protobuf 2.6.1
    Can't uninstall 'protobuf'. No files were found to uninstall.
  Can't roll back protobuf; was not uninstalled
Cleaning up...
Exception:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/dist-packages/pip/basecommand.py"", line 122, in main
    status = self.run(options, args)
  File ""/usr/lib/python2.7/dist-packages/pip/commands/install.py"", line 283, in run
    requirement_set.install(install_options, global_options, root=options.root_path)
  File ""/usr/lib/python2.7/dist-packages/pip/req.py"", line 1436, in install
    requirement.install(install_options, global_options, *args, **kwargs)
  File ""/usr/lib/python2.7/dist-packages/pip/req.py"", line 672, in install
    self.move_wheel_files(self.source_dir, root=root)
  File ""/usr/lib/python2.7/dist-packages/pip/req.py"", line 902, in move_wheel_files
    pycompile=self.pycompile,
  File ""/usr/lib/python2.7/dist-packages/pip/wheel.py"", line 206, in move_wheel_files
    clobber(source, lib_dir, True)
  File ""/usr/lib/python2.7/dist-packages/pip/wheel.py"", line 193, in clobber
    os.makedirs(destsubdir)
  File ""/usr/lib/python2.7/os.py"", line 157, in makedirs
    mkdir(name, mode)
OSError: [Errno 13] Permission denied: '/usr/local/lib/python2.7/dist-packages/protobuf-3.0.0.dist-info'

Storing debug log for failure in /home/me/.pip/pip.log
```

Some answers have suggested uninstalling and reinstalling TensorFlow along with protobuf, but I haven't tried that yet, since I wanted to avoid possibly messing anything up.
### Logs or other output that would be helpful

(output when I tried to run `bazel-bin/tensorflow/examples/image_retraining/retrain --image_dir ~/flower_photos`)

```
Traceback (most recent call last):
  File ""/home/me/tf_m/tensorflow/bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/examples/image_retraining/retrain.py"", line 78, in <module>
    import tensorflow as tf
  File ""/home/me/tf_m/tensorflow/bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/__init__.py"", line 23, in <module>
    from tensorflow.python import *
  File ""/home/me/tf_m/tensorflow/bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/python/__init__.py"", line 52, in <module>
    from tensorflow.core.framework.graph_pb2 import *
  File ""/home/me/tf_m/tensorflow/bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/core/framework/graph_pb2.py"", line 16, in <module>2. 
    from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2
  File ""/home/me/tf_m/tensorflow/bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/core/framework/attr_value_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2
  File ""/home/me/tf_m/tensorflow/bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/core/framework/tensor_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import tensor_shape_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2
  File ""/home/me/tf_m/tensorflow/bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/core/framework/tensor_shape_pb2.py"", line 22, in <module>
    serialized_pb=_b('\n,tensorflow/core/framework/tensor_shape.proto\x12\ntensorflow\""z\n\x10TensorShapeProto\x12-\n\x03\x64im\x18\x02 \x03(\x0b\x32 .tensorflow.TensorShapeProto.Dim\x12\x14\n\x0cunknown_rank\x18\x03 \x01(\x08\x1a!\n\x03\x44im\x12\x0c\n\x04size\x18\x01 \x01(\x03\x12\x0c\n\x04name\x18\x02 \x01(\tB2\n\x18org.tensorflow.frameworkB\x11TensorShapeProtosP\x01\xf8\x01\x01\x62\x06proto3')
TypeError: __init__() got an unexpected keyword argument 'syntax'
```
"
3579,Shape resizing of input in tf.batch_self_adjoint_eig,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System: Linux
### Steps to reproduce
1. Create any tensor (tf.Variable or tf.constant) containing batches of self adjoint matrices (call this B) and note its shape
2. run something like alpha_U = tf.batch_self_adjoint_eig(B)
3. look at B's shape again - the second to last dimension increments by 1
### What have you tried?
1. selecting all but the last element of the second to last dimension solves the problem, but is hacky
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
 B
<tf.Tensor 'Const_15:0' shape=(1, 3, 3) dtype=float32>
sess.run(B)
array([[[ 8.,  5.,  3.],
        [ 5.,  2.,  4.],
        [ 3.,  4.,  4.]]], dtype=float32)
alpha_U = tf.batch_self_adjoint_eig(B)
 B
<tf.Tensor 'Const_15:0' shape=(1, 4, 3) dtype=float32>
 sess.run(B)
array([[[ 8.,  5.,  3.],
        [ 5.,  2.,  4.],
        [ 3.,  4.,  4.]]], dtype=float32)
"
3574,Numerical differences between self.test_session and regular sessions?,"I'm trying to use the test suite to create tests that verify various aspects of my model. Strangely, I'm getting numerical differences between the exact same model run on the exact same machine if I use `self.test_session` inside `tf.test.TestCase` versus if I just run the same piece of code in a regular session. Most models work fine, it's just that certain flavors that use dropout show big discrepancies, usually after 4 or 5 steps of training. Is this expected behavior? If so what's the cause of the discrepancy and can it be removed?
"
3571,Building tensorflow from source,"Operating System: CentOS-7
CUDA: 8.0
cuDNN: 5.0
bazel: 0.3.0-2016-07-29
gcc: 4.8.5

When I try to build tensorflow from source following the instructions in https://www.tensorflow.org/versions/r0.9/get_started/os_setup.html, in particular, when executing:
bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer

I get the following error:

ERROR: /home/fjrodriguez/tensorflow/tensorflow/core/kernels/BUILD:854:1: undeclared inclusion(s) in rule '//tensorflow/core/kernels:crop_and_resize_op_gpu':
this rule is missing dependency declarations for the following files included by 'tensorflow/core/kernels/crop_and_resize_op_gpu.cu.cc':

I have tried many times, the error is always similar, undeclared inclusion(s) in rule xxxx, but the xxxx is changing depending on the execution.

I've tried the solution proposed at https://github.com/tensorflow/tensorflow/issues/2413 without any luck

Thanks in advance!
"
3569,Tensorflow testing script cannot import numpy whereas it is installed,"Hello,

I have the following error when I try to compile the pip package from the source code.
### Environment info

Operating System: Ubuntu 14.04

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```
ls -l /usr/local/cuda/lib64/libcud*
-rw-r--r-- 1 root root   322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root       19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root   383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root   720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a
lrwxrwxrwx 1 root root       13 Feb  9 18:48 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.4
lrwxrwxrwx 1 root root       17 Feb  9 18:48 /usr/local/cuda/lib64/libcudnn.so.4 -> libcudnn.so.4.0.7
-rwxrwxr-x 1 root root 61453024 Feb  8 23:12 /usr/local/cuda/lib64/libcudnn.so.4.0.7
-rw-rw-r-- 1 root root 62025862 Feb  8 23:12 /usr/local/cuda/lib64/libcudnn_static.a
```

If installed from sources, provide the commit hash: 5c44302d778f43a13bf1b97bffd0b2b6be46ae2f
### Steps to reproduce
1. git clone https://github.com/tensorflow/tensorflow
2. cd tensorflow
3. ./configure
4. bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer
5. bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
6. bazel test -c opt --config=cuda //tensorflow/python:graph_util_test
### Logs or other output that would be helpful

```
bazel test -c opt --config=cuda //tensorflow/python:graph_util_test
WARNING: Output base '/homes/plu/.cache/bazel/_bazel_plu/5fecb6612d2e95475ff53a54e377c3f7' is on NFS. This may lead to surprising failures and undetermined behavior.
WARNING: /homes/plu/.cache/bazel/_bazel_plu/5fecb6612d2e95475ff53a54e377c3f7/external/protobuf/WORKSPACE:1: Workspace name in /homes/plu/.cache/bazel/_bazel_plu/5fecb6612d2e95475ff53a54e377c3f7/external/protobuf/WORKSPACE (@__main__) does not match the name given in the repository's definition (@protobuf); this will cause a build error in future versions.
WARNING: /homes/plu/.cache/bazel/_bazel_plu/5fecb6612d2e95475ff53a54e377c3f7/external/re2/WORKSPACE:1: Workspace name in /homes/plu/.cache/bazel/_bazel_plu/5fecb6612d2e95475ff53a54e377c3f7/external/re2/WORKSPACE (@__main__) does not match the name given in the repository's definition (@re2); this will cause a build error in future versions.
WARNING: /homes/plu/.cache/bazel/_bazel_plu/5fecb6612d2e95475ff53a54e377c3f7/external/highwayhash/WORKSPACE:1: Workspace name in /homes/plu/.cache/bazel/_bazel_plu/5fecb6612d2e95475ff53a54e377c3f7/external/highwayhash/WORKSPACE (@__main__) does not match the name given in the repository's definition (@highwayhash); this will cause a build error in future versions.
WARNING: /homes/plu/.cache/bazel/_bazel_plu/5fecb6612d2e95475ff53a54e377c3f7/external/gemmlowp/WORKSPACE:1: Workspace name in /homes/plu/.cache/bazel/_bazel_plu/5fecb6612d2e95475ff53a54e377c3f7/external/gemmlowp/WORKSPACE (@__main__) does not match the name given in the repository's definition (@gemmlowp); this will cause a build error in future versions.
WARNING: /homes/plu/.cache/bazel/_bazel_plu/5fecb6612d2e95475ff53a54e377c3f7/external/gemmlowp/BUILD:102:12: in hdrs attribute of cc_library rule @gemmlowp//:eight_bit_int_gemm: Artifact 'external/gemmlowp/public/bit_depth.h' is duplicated (through '@gemmlowp//:eight_bit_int_gemm_public_headers' and '@gemmlowp//:gemmlowp_headers').
WARNING: /homes/plu/.cache/bazel/_bazel_plu/5fecb6612d2e95475ff53a54e377c3f7/external/gemmlowp/BUILD:102:12: in hdrs attribute of cc_library rule @gemmlowp//:eight_bit_int_gemm: Artifact 'external/gemmlowp/public/gemmlowp.h' is duplicated (through '@gemmlowp//:eight_bit_int_gemm_public_headers' and '@gemmlowp//:gemmlowp_headers').
WARNING: /homes/plu/.cache/bazel/_bazel_plu/5fecb6612d2e95475ff53a54e377c3f7/external/gemmlowp/BUILD:102:12: in hdrs attribute of cc_library rule @gemmlowp//:eight_bit_int_gemm: Artifact 'external/gemmlowp/public/map.h' is duplicated (through '@gemmlowp//:eight_bit_int_gemm_public_headers' and '@gemmlowp//:gemmlowp_headers').
WARNING: /homes/plu/.cache/bazel/_bazel_plu/5fecb6612d2e95475ff53a54e377c3f7/external/gemmlowp/BUILD:102:12: in hdrs attribute of cc_library rule @gemmlowp//:eight_bit_int_gemm: Artifact 'external/gemmlowp/public/output_stages.h' is duplicated (through '@gemmlowp//:eight_bit_int_gemm_public_headers' and '@gemmlowp//:gemmlowp_headers').
WARNING: /homes/plu/.cache/bazel/_bazel_plu/5fecb6612d2e95475ff53a54e377c3f7/external/gemmlowp/BUILD:102:12: in hdrs attribute of cc_library rule @gemmlowp//:eight_bit_int_gemm: Artifact 'external/gemmlowp/profiling/instrumentation.h' is duplicated (through '@gemmlowp//:eight_bit_int_gemm_public_headers' and '@gemmlowp//:gemmlowp_headers').
WARNING: /homes/plu/.cache/bazel/_bazel_plu/5fecb6612d2e95475ff53a54e377c3f7/external/gemmlowp/BUILD:102:12: in hdrs attribute of cc_library rule @gemmlowp//:eight_bit_int_gemm: Artifact 'external/gemmlowp/profiling/profiler.h' is duplicated (through '@gemmlowp//:eight_bit_int_gemm_public_headers' and '@gemmlowp//:gemmlowp_headers').
WARNING: /home/plu/git/tensorflow/util/python/BUILD:11:16: in includes attribute of cc_library rule //util/python:python_headers: 'python_include' resolves to 'util/python/python_include' not in 'third_party'. This will be an error in the future.
INFO: Found 1 test target...
Slow read: a 160721045-byte read from /homes/plu/.cache/bazel/_bazel_plu/5fecb6612d2e95475ff53a54e377c3f7/tensorflow/bazel-out/local_linux-opt/bin/tensorflow/python/_pywrap_tensorflow.so took 13761ms.
FAIL: //tensorflow/python:graph_util_test (see /homes/plu/.cache/bazel/_bazel_plu/5fecb6612d2e95475ff53a54e377c3f7/tensorflow/bazel-out/local_linux-opt/testlogs/tensorflow/python/graph_util_test/test.log).
Target //tensorflow/python:graph_util_test up-to-date:
  bazel-bin/tensorflow/python/graph_util_test
INFO: Elapsed time: 57.357s, Critical Path: 44.71s
//tensorflow/python:graph_util_test                                      FAILED in 0.5s
  /homes/plu/.cache/bazel/_bazel_plu/5fecb6612d2e95475ff53a54e377c3f7/tensorflow/bazel-out/local_linux-opt/testlogs/tensorflow/python/graph_util_test/test.log
```

And here the content of the `test.log` file:

```
exec ${PAGER:-/usr/bin/less} ""$0"" || exit 1
-----------------------------------------------------------------------------
Traceback (most recent call last):
  File ""/homes/plu/.cache/bazel/_bazel_plu/5fecb6612d2e95475ff53a54e377c3f7/tensorflow/bazel-out/local_linux-opt/bin/tensorflow/python/graph_util_test.runfiles/org_tensorflow/tensorflow/python/framework/graph_util_test.py"", line 21, in <module>
    import tensorflow as tf
  File ""/homes/plu/.cache/bazel/_bazel_plu/5fecb6612d2e95475ff53a54e377c3f7/tensorflow/bazel-out/local_linux-opt/bin/tensorflow/python/graph_util_test.runfiles/org_tensorflow/tensorflow/__init__.py"", line 23, in <module>
    from tensorflow.python import *
  File ""/homes/plu/.cache/bazel/_bazel_plu/5fecb6612d2e95475ff53a54e377c3f7/tensorflow/bazel-out/local_linux-opt/bin/tensorflow/python/graph_util_test.runfiles/org_tensorflow/tensorflow/python/__init__.py"", line 45, in <module>
    import numpy as np
ImportError: No module named numpy
```

But, I do have numpy installed:

```
python 
Python 2.7.6 (default, Jun 22 2015, 17:58:13) 
[GCC 4.8.2] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import numpy;numpy.version.version
'1.11.1'
>>>
```

I do not understand why I get this Python error. Any idea of what is going wrong?

Thanks in advance for any help!
"
3567,KeyError Tensorflow,"Traceback (most recent call last):
  File ""ptb_word_lm.py"", line 326, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""ptb_word_lm.py"", line 291, in main
    raw_data = reader.ptb_raw_data(FLAGS.data_path)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/models/rnn/ptb/reader.py"", line 76, in ptb_raw_data
    valid_data = _file_to_word_ids(valid_path, word_to_id)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/models/rnn/ptb/reader.py"", line 48, in _file_to_word_ids
    return [word_to_id[word] for word in data]
KeyError: 'FLOOR\n<eos>\n//'
"
3565,"Tensorboard unable to generate result, IOError [Errno 2] No such file or directory: '/usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/TAG' on path /usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/TAG","I use tensorboard in docker, when I type the command： 

tensorboard --logdir='logs/'

the following error showed up:

IOError [Errno 2] No such file or directory: '/usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/TAG' on path /usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/TAG

is there anyone can help me?
"
3563,[BUG?] Memory overflow (?) on Nvidia Quadro M6000 using feed dictionary with conv2d,"Hi everybody,

we just got several machines with Quadro M6000 (12G RAM) for our lab, and they all seem to suffer the same problem when feeding too much data to a convolution via a feed dictionary. The problem does not appear when using CPU on the same machine, and neither when using an equivalent machine with a different GPU (GeForce GTX Titan X).

It looks like when using a feed dictionary to provide data for the evaluation of a graph, part of the weights in the graph may be overwritten depending on the size of the data fed through the dictionary.
#### Two ways to reproduce
##### A minimal example

```
import tensorflow as tf
import numpy as np
x = tf.placeholder(tf.float32, shape=(None, 1024))
x_r = tf.reshape(x, (-1, 32, 32, 1))
W = tf.Variable(tf.ones((5, 5, 1, 32)))
W_sum = tf.reduce_sum(W)
conv = tf.nn.conv2d(x_r, W, strides=(1, 1, 1, 1), padding='SAME')
sess = tf.Session()
sess.run(tf.initialize_all_variables())
data = np.ones((5001, 1024), dtype='float32')
print(sess.run(W_sum))
c = sess.run(conv, feed_dict={x: data})
print(sess.run(W_sum))
sess.close()
```

It outputs

```
800.0
0.0
```

which indicates that `W` has changed through the feed-dictionary evaluation of the convolution.

Note that
- By reducing `data.shape[0]` to 5000 or less, the problem disappears
- Going up to 5070, the second value stays at 0.0. 
- at exactly 5080 the problem seems to disappear (we get `800.0 800.0`)
- from 5100 the second number can take arbitrary values (not zero)
- The problem does not arise when replacing the `tf.nn.conv2d` operation by an equivalently sized  `matmul` operation (same dimensions of weight vector, not same dimensionality of output)
- EDIT: (that said, see below, in the MNIST tutorial all weight vectors are affected, not only ones pertaining to convolution. But that doesn't necessarily contradict the convolution being the culprit)
##### The expert MNIST tutorial

The problem also arises in one of the very first tutorials https://www.tensorflow.org/versions/r0.9/tutorials/mnist/pros/index.html

Everything works perfect until the last line of the tutorial, where a large array is fed by feed-dictionary for test accuracy. This modifies all the weight vectors of the convnet!

Again, the error disappears when feeding only 5000 test examples instead of 10000 to the architecture.
#### Environment
- OS: Ubuntu 1504
- CUDA version 7.5
- cuDNN version 4
- library files

```
(tensorflow) meickenb@g-1504:~/code/tensorflow$ ls -l /usr/local/cuda/lib64/libcud*
-rw-r--r-- 1 root root 322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root     16 Aug  15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root     19 Aug  15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root 383336 Aug  15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root 720192 Aug  15  2015 /usr/local/cuda/lib64/libcudart_static.a

(tensorflow) meickenb@g-1504:/usr/lib/x86_64-linux-gnu$ ls -l libcudnn*
lrwxrwxrwx 1 root root       13 Jul 21 18:22 libcudnn.so -> libcudnn.so.4
lrwxrwxrwx 1 root root       17 Jul 21 18:22 libcudnn.so.4 -> libcudnn.so.4.0.7
-rwxr-xr-x 1 root root 61453024 Jul 21 18:22 libcudnn.so.4.0.7
-rw-r--r-- 1 root root 62025862 Jul 21 18:22 libcudnn_static.a
```
- Anaconda 3
- pip install from wheel `https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.9.0-cp35-cp35m-linux_x86_64.whl`
- tf version 0.9.0

```
(tensorflow) meickenb@g-1504:~$ python -c ""import tensorflow; print(tensorflow.__version__)""
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
0.9.0

```

Please let me know if you need any other info, or what else I could try to narrow down the reason for this overflow.

CC @tmanglesl @CarmineCella @andreuxmath @beedotkiran
"
3562,Locate operations on parameter server,"Hi,

I'm working on a distributed tensorflow, and I want to do some preprocess on the variables before the workers retrieve the variable. The preprocessing will trim the model and consequently reduce the amount of network traffic that transfer the variable from parameter server to workers. 

Is that possible to put operations on parameter servers? Thank you
"
3560,Inception retraining / transfer learning fails when running with GPU,"Thanks so much for releasing TensorFlow.  We're experimenting with the image retraining example as described here: https://www.tensorflow.org/versions/r0.9/how_tos/image_retraining/index.html

Everything in TensorFlow has worked perfectly for us, including the test and GPU setup validation samples.  However, when running the Inception retraining code and using the GPU, TensorFlow errors.  Since the error occurs in `check_numerics_op.cc`, I thought it might be worth reporting.  

For example, CPU-only bottleneck generation for 600 classes on a recent 36-core machine takes nearly a month, so working multi-GPU support for bottleneck creation would be really great.  It would help us learn faster and hopefully contribute to the project sooner.

Abbreviated output (full output is attached): 
[TensorFlow_Retraining_Error.txt](https://github.com/tensorflow/tensorflow/files/389942/TensorFlow_Retraining_Error.txt)

python tensorflow/examples/image_retraining/retrain.py --image_dir ~/flower_photos
Mon Jul 25 00:54:39 PDT 2016
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: GeForce GTX 1080
...
Creating bottleneck at /tmp/bottleneck/dandelion/3365850019_8158a161a8_n.jpg.txt
**E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x1000e000300 = {1, 0} activation input is not finite.**
Traceback (most recent call last):
  File ""tensorflow/examples/image_retraining/retrain.py"", line 824, in <module>
    tf.app.run()
### Environment info

Operating System: Ubuntu 14.04
GPU: GTX 1080 (two cards)

Installed version of CUDA and cuDNN: 
 /usr/local/cuda/lib/libcudadevrt.a
 /usr/local/cuda/lib/libcudart.so -> libcudart.so.7.5
 /usr/local/cuda/lib/libcudart.so.7.5 -> libcudart.so.7.5.18
 /usr/local/cuda/lib/libcudart.so.7.5.18
 /usr/local/cuda/lib/libcudart_static.a
1. The commit hash (`git rev-parse HEAD`)
   v0.9.0 25023df
2. The output of `bazel version`
   Build label: 0.2.3
   Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
   Build time: Tue May 17 14:21:13 2016 (1463494873)
   Build timestamp: 1463494873
   Build timestamp as int: 1463494873
### Steps to reproduce
1. Build tensorflow from source with GPU support; all demos and tests working properly
2. `bazel-bin/tensorflow/examples/image_retraining/retrain --image_dir ~/flower_photos` runs properly but only uses CPU when generating bottleneck files
3. `python tensorflow/examples/image_retraining/retrain.py --image_dir ~/flower_photos` utilizes the GPU, but crashes during bottleneck file generation due to ""irregular"" response from GPU.  If the /tmp/bottlenecks directory has not yet been generated, image retraining using the gpu will fail almost immediately after processing a few files.
### What have you tried?
1.  If cached bottleneck files already exist in /tmp/bottlenecks, then the retraining on GPU works properly.  However, building those bottleneck files in the first place depends on the CPU to generate those bottlenecks, which takes forever (nearly a month for a dual socket E5-2699 v3 36-core machine for around 600 classes)
"
3559,Can I add a py_func to a queue?,"Is it possible to add a custom py_func to load non-image data in a FIFOQueue? It appears that the Queue does not support py_func objects. Specifically can you enqueue a py_func object? When trying this Tensor Flow gives the following error:

`tensorflow/core/framework/op_kernel.cc:909] Unimplemented: Unsupported object type Tensor`

I've tried calling `set_shape` on the `py_func` output
"
3557,What would be required to submit an implementation of the Hungarian algorithm to tf.contrib,"@Russell91 and I have an interest in contributing an implementation of the Hungarian algorithm, perhaps based off of the implementation he has [here](https://github.com/Russell91/TensorBox/tree/master/utils/hungarian).

What do we need to do to make this happen? Is there a document covering this somewhere (besides the one that says we need to sign the CLA). 
"
3554,Different outputs using tensorflow.contrib.learn.Estimator.predict(),"I trained a tensorflow model using skflow, but when I tried to predict some new value of my data, things didn't work. This is what is happening.

I have X, the matrix containing the observations.

When I run

`y_predicted = classifier.predict(X, batch_size=128)`

I'm interested in the output of indexes 855, 15035, 49536, 856, 857

so

`y_predicted['class'][(855, 15035, 49536, 856, 857), ]`

the results are exactly what I have expected

`array([0, 0, 0, 3, 3])`

Everything is fine up to here, but if I pass to predict function just the indexes of interest, the results are different. Here is an example:

`y_predicted = classifier.predict(X[(855, 15035, 49536, 856, 857), :], batch_size=128)`

Then, the output is wrong

`y_predicted['class']``

gives

`array([0, 0, 0, 2, 0])`

I tried several ways to do this, and I always get the wrong results.

Thank you.
"
3550,Error during building tensorflow ? ,"Operating System: Ubuntu 16.04
Installed version of CUDA and cuDNN:  Cuda 8.0 RC , cuDNN 5 for 8.0RC

(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

`-rw-r--r-- 1 root root   560184 জুল    28 20:29 libcudadevrt.a
lrwxrwxrwx 1 root root       16 জুল    28 20:29 libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root       19 জুল    28 20:29 libcudart.so.8.0 -> libcudart.so.8.0.27
-rwxr-xr-x 1 root root   394472 জুল    28 20:29 libcudart.so.8.0.27
-rw-r--r-- 1 root root   737516 জুল    28 20:29 libcudart_static.a
-rwxr-xr-x 1 root root 78065952 জুল    28 20:45 libcudnn.so
-rwxr-xr-x 1 root root 78065952 জুল    28 20:45 libcudnn.so.5
-rwxr-xr-x 1 root root 78065952 জুল    28 20:45 libcudnn.so.5.0.5
-rw-r--r-- 1 root root 68709594 জুল    28 20:45 libcudnn_static.a
`

Ran the command with `bazel build -c opt  --verbose_failures --config=cuda //tensorflow/cc:tutorials_example_trainer`
### What have you tried?
1. Tried adding /usr/lib/gcc/x86_64-linux-gnu/4.9 to the path. Then it fails `/usr/include/stdlib.h:32:20: fatal error: stddef.h: No such file or directory` .

Error Message : 
ERROR: /home/tamim/.cache/bazel/_bazel_tamim/2f3c0cf2059f53bbcd160daf720cb6e9/external/highwayhash/BUILD:17:1: C++ compilation of rule '@highwayhash//:sip_hash' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command 
  (cd /home/tamim/.cache/bazel/_bazel_tamim/2f3c0cf2059f53bbcd160daf720cb6e9/execroot/tensorflow && \
  exec env - \
    PATH=/home/tamim/bin:/usr/local/cuda/bin:/home/tamim/anaconda3/bin:/home/tamim/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin \
  third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections -g0 '-std=c++11' '-frandom-seed=bazel-out/host/bin/external/highwayhash/_objs/sip_hash/external/highwayhash/highwayhash/sip_hash.o' -iquote external/highwayhash -iquote bazel-out/host/genfiles/external/highwayhash -iquote external/bazel_tools -iquote bazel-out/host/genfiles/external/bazel_tools -isystem external/highwayhash -isystem bazel-out/host/genfiles/external/highwayhash -isystem external/bazel_tools/tools/cpp/gcc3 -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -fno-canonical-system-headers -MD -MF bazel-out/host/bin/external/highwayhash/_objs/sip_hash/external/highwayhash/highwayhash/sip_hash.d -c external/highwayhash/highwayhash/sip_hash.cc -o bazel-out/host/bin/external/highwayhash/_objs/sip_hash/external/highwayhash/highwayhash/sip_hash.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
gcc: error trying to exec 'cc1plus': execvp: No such file or directory
Target //tensorflow/cc:tutorials_example_trainer failed to build

Feature Request: A prebuilt wheel for cuda8 release candidate.
"
3549,Android: NoOpKernel was registered to support Op 'TensorflowArray' DynamicRNN,"I'm trying to load a graph I trained in python, which includes only using dynamicRNN, and the most basic RNN cell. 

When I try execute the graph on the Android, I get the following error message:

```
Invalid argument: No OpKernel was registered to support Op 'TensorArray' with these attrs
     [[Node: c96ce52cccd5408aad2fb356a8246023/RNN/TensorArray_1 = TensorArray[clear_after_read=true, dtype=DT_FLOAT, dynamic_size=false, tensor_array_name=""c96ce52cccd5408aad2fb356a8246023/RNN/dynamic_rnn/input""](c96ce52cccd5408aad2fb356a8246023/RNN/unpack)]]
```
### Environment info

Operating System:
Ubuntu x64 14.04
Android 6.0

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)
   tag v0.9.0
2. The output of `bazel version`
   0.3.0
### Steps to reproduce
1. Create RNN model in python
2. Compile it with tensorflow_android_lib targeting armv7
3. Try run the model on android
### What have you tried?
1. 
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
3548,"Display the graph on tensorboard horizontally from left to right, or vertically from top to bottom","Dear community, 

May I ask is there any option that enables us to change the orientation of the current layout of graphs in tensorboard? 
By default it is vertically from bottom to top in the current form. 

Best,
"
3546,iOS: No OpKernel was registered to support Op 'Div' with these attrs,"I'm trying to build graph in iOS but i have following error:

```
Invalid argument: No OpKernel was registered to support Op 'Div' with these attrs
     [[Node: conv1/conv/moments/sufficient_statistics/truediv = Div[T=DT_DOUBLE](conv1/conv/moments/sufficient_statistics/truediv/Cast, conv1/conv/moments/sufficient_statistics/truediv/Cast_1)]]
```

In Python if I run this code: 
`batch_mean, batch_var = tf.nn.moments(x, [0, 1, 2], keep_dims=True)`
I'm getting the error above, otherwise works fine.
I'm trying to find ops (core/ops, core/kernels).
"
3545,Tensorflow unable to detect no. of CPU cores,"### Environment info

**Operating System:**
Ubuntu 14.04 Linux ppc64le

**Installed version of CUDA and cuDNN: 7.5**
ls -l /usr/local/cuda-7.5/lib64/libcud*
-rw-r--r-- 1 root root   326744 Nov  9  2015 /usr/local/cuda-7.5/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Nov  5  2015 /usr/local/cuda-7.5/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root       19 Nov  5  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5 -> libcudart.so.7.5.23
-rwxr-xr-x 1 root root   445192 Nov  5  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5.23
-rw-r--r-- 1 root root   902750 Nov  9  2015 /usr/local/cuda-7.5/lib64/libcudart_static.a
lrwxrwxrwx 1 root root       13 Apr 24 20:17 /usr/local/cuda-7.5/lib64/libcudnn.so -> libcudnn.so.5
-rwxr-xr-x 1 root root 60068392 Apr 22 19:18 /usr/local/cuda-7.5/lib64/libcudnn.so.5.0.5
-rw-r--r-- 1 root root 59436124 Apr 22 19:30 /usr/local/cuda-7.5/lib64/libcudnn_static.a
**

**Tensorflow 0.8 built and installed from source. (v0.8.0 tag)**
1. The commit hash (`git rev-parse HEAD`) : 4b7bc3174ed67b4a0eb1803537c9d00f132e9ae7
2. The output of `bazel version`: 0.2.0
Note: Same issue also exists with tensorflow 0.9

**Steps to reproduce:**
On python prompt, 
1. import tensorflow as tf
2. tf.Session()

In a large output of above statement, there is a line that says ""can't determine no. of CPU cores, assuming 4"".

After looking into the tensorflow code, I found that __linux macro in tensorflow/core/platform/posix/port.cc is found to be not defined and hence sched_getaffinity is not called, and returns 4 as default value. I checked that usually on linux, __linux is defined but if we compile using -std=c++11, then this macro gets undefined. 
Anyway, even if sched_getaffinity is called, it returns logical no. of CPU cores i.e. maximum threads possible. On POWER, usually this count is pretty higher and having so many threads degrades the performance. Ideally, we should have physical core size as the max possible thread count in thread pool for optimum performance. I tried looking for a built-in function that gives me physical core size, but unfortunately, all of the functions I found gives me logical core size. Then I found another library ""[libhwloc](https://www.open-mpi.org/projects/hwloc/)"" that gives C API to get this information. This library in general is very useful with nice documentation. It is also available on canonical and one can install it using ""apt-get install libhwloc-dev"" on Ubuntu system or on RHEL using ""yum install hwloc-devel"". 
So, I wanted to know if Tensorflow can accept this additional dependency on hwloc library.  
"
3544,Should *.pb.h files be generated in cross-compile cases?,"A few days ago, I have tried to import the tensorflow project directly into Android Studio on Windows and use Gradle to build the project. Header files with suffix "".pb.h"" are not generated. Google says bazel should be used to build the project. Now I use bazel on Linux to build it again with CPU=arm64-v8a using the following command

bazel build //tensorflow/examples/android:tensorflow_native_libs --crosstool_top=//external:android/crosstool --cpu=$CPU --host_crosstool_top=@bazel_tools//tools/cpp:toolchain

as in the issue #3444 .

However header files with suffix "".pb.h"" are still not generated. Android Studio cannot find the include file and hence the build procedure cannot be continued. Is there any method to use tensorflow C++ library in Android Studio?
"
3543,boolean_mask failed in iOS: Running model failed:Invalid argument: No OpKernel was registered to support Op 'Gather' with these attrs,"### Environment info

Operating System:
Building on Mac OS X
Running on iOS 9.2.1
1. The commit hash (`git rev-parse HEAD`)
   71f6bb336e5e11d6da2cedac6ba1c992ad9992bd
2. The output of `bazel version`

```
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Tue Jul 12 11:11:47 2016 (1468321907)
Build timestamp: 1468321907
Build timestamp as int: 1468321907
```
### Steps to reproduce
1. I compile tf for iOS with the makefile
2. I frozen a model with last step as  a boolean_mask (that prozen pb file runs perfectly with TF 0.9.0 python api )
3. I run it in iOS, log report 

```
Running model failed:Invalid argument: No OpKernel was registered to support Op 'Gather' with these attrs
     [[Node: classes_num_filtered/Gather = Gather[Tindices=DT_INT64, Tparams=DT_INT64, validate_indices=true](classes_num_filtered/Reshape, classes_num_filtered/Squeeze)]]
```

so it happens with the gather op inside the boolean_mask, when I removed this operation, it runs without problem in iOS.
Is that means gather op is not currently support in iOS? 
Do I have a work around for now? I need to filter the data with porbs > threhold.

``` python
        mask = self.classes_prob > self.threshold
        self.classes_prob_filtered = tf.boolean_mask(self.classes_prob, mask, name=""probs_filtered"") 
        self.classes_arg_filtered = tf.boolean_mask(self.classes_arg, mask, name=""classes_num_filtered"") 
        self.boxes_filtered = tf.boolean_mask(self.boxes, mask, name=""boxes_filtered"") 
```

I checked the  tf_cc_files.txt, tensorflow/core/kernels/gather_op.cc do exist.
"
3541,Constant folding seems to cause error with ImmutableConst ops,"Using memory-mapped ImmutableConst ops seems to cause the initial constant folding process to fail.
## Reproduction steps:
- Load a graph containing ImmutableConst ops.
- Create a memory-mapped environment and session like this:

``` c++
 // Create and initialize MemmappedEnv from the converted file.
  MemmappedEnv memmapped_env(Env::Default());
  TF_ASSERT_OK(memmapped_env.InitializeFromFile(filename_mmap));

  // Load the graph and run calculations.
  SessionOptions session_options;
  session_options.env = &memmapped_env;
  std::unique_ptr<Session> session(NewSession(session_options));
```
- Run the graph using session->Run().
## Expected results:

The graph should execute successfully with no error messages.
## Actual results:

The graph seems to execute correctly, but the following is printed to the console:

```
E tensorflow/core/common_runtime/executor.cc:334] Executor failed to create kernel. Unimplemented: File system scheme memmapped_package not implemented
     [[Node: W_conv23 = ImmutableConst[dtype=DT_FLOAT, memory_region_name=""memmapped_package://W_conv23"", shape=[9,9,32,3], _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
```
## Notes

From investigation, it seems like the constant folding code creates a new device with empty session options, which means a default Env is used instead of the memory-map-aware one the client passes in:

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/common_runtime/constant_folding.cc#L166
"
3540,Variable.assign throws expection randomly,"I'm trying to copy weights between two graphs which are running in two different processes simply by fetching the values from one, sending them to the second process and assigning the values there.

The code I have is pretty simple and straight forward:

```
def get_all_variable_values(self):
    vars = list(self.sess.graph.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES))
    names = [v.name for v in vars]
    values = self.sess.run(vars)
    return dict(zip(names, values))

def set_all_variable_values(self, update_dict):
    for var in self.sess.graph.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES):
        self.sess.run(var.assign(update_dict[var.name]))
```

But time to time (seems to be completely random), the following exception happens.
I also tried replacing `Variable.assign` with `tf.assign` and the same problem happens.

Any idea why?

```
Traceback (most recent call last):
  File ""/home/mbz/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 715, in _do_call
    return fn(*args)
  File ""/home/mbz/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 697, in _run_fn
    status, run_metadata)
  File ""/home/mbz/anaconda3/lib/python3.5/contextlib.py"", line 66, in __exit__
    next(self.gen)
  File ""/home/mbz/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/errors.py"", line 450, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors.NotFoundError: FetchOutputs node Assign_404:0: not found

During handling of the above exception, another exception occurred.

Traceback (most recent call last):
  File ""/home/mbz/anaconda3/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/home/mbz/anaconda3/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/home/mbz/projects/pacman_multi_gpu/ProcessServer.py"", line 50, in update_model
    self.model.set_all_variable_values(update_dict)
  File ""/home/mbz/projects/pacman_multi_gpu/NetworkVP.py"", line 258, in set_all_variable_values
    self.sess.run(var.assign(update_dict[var.name]))
  File ""/home/mbz/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 372, in run
    run_metadata_ptr)
  File ""/home/mbz/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 636, in _run
    feed_dict_string, options, run_metadata)
  File ""/home/mbz/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 708, in _do_run
    target_list, options, run_metadata)
  File ""/home/mbz/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 728, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.NotFoundError: FetchOutputs node Assign_404:0: not found

```
"
3539,parallelize OneVsRestClassifier,"Hi,

I have implemented a CNN model in a TensorFlowEstimator and I use it with a OneVsRestClassifier.
It works good.
When I am trying to parallelize it by putting n_jobs=2 in the OneVsRestClassifier, I got a strange error that I don't understand : 

MaybeEncodingError: Error sending result: '[TensorFlowEstimator(batch_size=32, class_weight=None, clip_gradients=5.0,
          config=None, continue_training=True, learning_rate=0.001,
          model_fn=<function cnn_model at 0x11f22d500>, n_classes=16,
          optimizer='Adam', steps=200, verbose=1)]'. Reason: 'PicklingError(""Can't pickle <type 'module'>: it's not found as **builtin**.module"",)'

Do you have an idea of what does it mean ?

Thanks
"
3537,Cannot build a simple C++ TensorFlow example for Android x86,"Operating System: Ubuntu 14.04 LTS 64bit

Installed:
Android NDK (r12b), 
Android SDK (Latest), 
Tensorflow (0.9) (configured for CPU only),  
Bazel (0.3.0)

I faced the same problem of the issue #2753, then I changed to use ""//tensorflow/core:android_tensorflow_lib"", now the error is:

```
external/eigen_archive/eigen-eigen-d02e6a705c30/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/CUDA/TypeCasting.h: In function 'TgtPacket Eigen::internal::pcast(const SrcPacket&) [with SrcPacket = Eigen::internal::Packet4h; TgtPacket = __vector(4) float]':
external/eigen_archive/eigen-eigen-d02e6a705c30/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/CUDA/TypeCasting.h:143:38: error: '_mm_cvtm64_si64' was not declared in this scope
   __int64_t a64 = _mm_cvtm64_si64(a.x);
                                      ^
Target //tensorflow/mydemo:mydemo failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 174.487s, Critical Path: 168.61s
```

I'm building with the following command:

`bazel build :mydemo --crosstool_top=//external:android/crosstool --cpu=x86 --host_crosstool_top=@bazel_tools//tools/cpp:toolchain`

And with the following BUILD file:

```
cc_binary(
    name = ""mydemo"",
    srcs = [""mydemo.cc""],
    deps = [
        ""//tensorflow/core:android_tensorflow_lib"",
    ]
)
```

My WORKSPACE configuration:

```
android_sdk_repository(
    name = ""androidsdk"",
    api_level = 22,
    build_tools_version = ""24.0.1"",
    path = ""/myandroid/sdk"",
)

android_ndk_repository(
    name=""androidndk"",
    path=""/myandroid/android-ndk-r12b"",
    api_level=22)
```

I'm just trying to build a very simple C++ TensorFlow example for Android x86.
"
3536,Bazel target to create C++ library headers,"Thanks to the `//tensorflow:libtensorflow.so` target, I can now build a shared library that I can use in my C++ programs.  I want to install that library in `/usr/local/lib` and put the headers for it in `/usr/local/include`, but there is no target to build and install those headers.  In particular, building the library doesn't build the headers from the proto files, so I have `error_codes.proto`, but not `error_codes.pb.h`, so I can't even use the source directory for the headers.
"
3535,SGD only? What about other algorithms like L-BFGS?,"This is simply a question, not an issue, as this seemed like the best place to ask:

I was looking at the video an model on the site, and it appeared to only have SGD as an algorithm for machine learning.  I was wondering if other algorithms are also included in tensorflow.

An interested student,
William
"
3534,Document exceptions to broadcasting semantics ,"## Environment info

Operating System: Ubuntu 14.04, OSX 10.11

Installed from `1b7b7703c8449769ba1cfb7553494c9b472925d7`

Output of `bazel version`:

```
Build label: 0.3.0
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Jun 10 11:38:23 2016 (1465558703)
Build timestamp: 1465558703
Build timestamp as int: 1465558703
```
### Steps to reproduce

Running this script:

```
import tensorflow as tf

shape_1 = (50, 1, 20, 10)
shape_2 = (50, 30, 20, 1)

A = tf.Variable(tf.random_normal(shape_1))
B = tf.Variable(tf.random_normal(shape_2))

with tf.Session() as S:
    S.run(tf.initialize_all_variables())
    C = S.run(A+B)
```

produces

`UnimplementedError: Broadcast between [50,1,20,10] and [50,30,20,1] is not supported yet.`
### What did you try?

Moving the broadcast dimensions to the results in success

```
shape_1 = (50, 20, 10, 1)
shape_2 = (50, 30, 1, 20)
```

The following also works

```
shape_1 = (1, 1, 20, 10)
shape_2 = (1, 30, 20, 1)
```

as does

```
shape_1 = (1, 20, 10)
shape_2 = (30, 20, 1)
```
### Discussion

I am aware of #508 and #1519 however this does not appear to be covered by #1519. It would be very nice if the exceptions to normal numpy broadcasting rules were documented somewhere. 

A tentative list would include
- number of broadcasting dimensions limited to 2
- broadcasting dimensions must (sometimes??) be relegated to the last dimensions
"
3533,Problems with quantization. Op type not registered 'Dequantize' and other problems,"Hi Everyone,

I did quantization with tensorflow following this manual: https://www.tensorflow.org/versions/master/how_tos/quantization/index.html

Here detailed description of my current problem: 
http://stackoverflow.com/questions/38615558/bug-in-tensorflow-tuttorial-about-quantization

And here parent problem: 
http://stackoverflow.com/questions/38595600/notfounderror-op-type-not-registered-dequantize

I use pip install tensorflow. Python2.7, tensorflow=0.9.0
Also I have git-master repository and use bazel-build for other tools like freezing and so on. 
bazel version=0.3.0
OS: Ubuntu 16.04 LTS
gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.1) 

@petewarden 

I am ready to give you any additional information 

Thanks, 
 Artem 
"
3532,Dask Integration with tf.learn,"Current `DaskDataFeeder` is no longer working due to recent refactoring. It will be switched to use `tf.DataFrame`. 

@davidsoergel what's the status on replacing data feeders with `tf.DataFrame` in estimators? Do you want to take a look at dask as well?

cc: @jcrist @mrocklin @ogrisel @shoyer 
"
3528,rnn.bidirectional_dynamic_rnn doesn't really take sequence_length of int32s,"The docstring for rnn.bidirectional_dynamic_rnn indicates that the sequence_length argument can be an int32/int64 vector, but array_ops.reverse_sequence only accepts an int64 vector as its seq_lengths argument.  I'll leave it to you whether the solution is to modify reverse_sequence or just amend the docstring.
"
3527,//tensorflow/python:Sparse_split_op_test  is failing on Big Endian,"### Environment info

Operating System: Ubuntu/Red Hat

Installed version of CUDA and cuDNN:  Not installed 

The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`. **0.8.0**

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`) [ [4b7bc31](https://github.com/tensorflow/tensorflow/commit/4b7bc3174ed67b4a0eb1803537c9d00f132e9ae7)]
2. The output of `bazel version`  **0.3.0**
### Steps to reproduce
1.  Run `bazel test //tensorflow/python:Sparse_split_op_test`
### Logs or other output that would be helpful

It was observed that this particular test consists of row-wise and column-wise split of tensor.
Test is failing on execution of column wise tensor split in case of Big Endian. 
Please check attached stack-trace. 

[sparse_split_test_log.txt](https://github.com/tensorflow/tensorflow/files/385847/sparse_split_test_log.txt)

I checked the test is passing in case of  Little Endian (Ubuntu, Red Hat)
"
3526,"Build fails on Ubuntu 16.04 LTS, CUDA Toolkit 8.0, cuDNN 5.0.5, and Bazel 0.3.0-jdk7","Hi Everyone,

I've downgraded my gcc to 5.3.0 by building from source in order to install CUDA Toolkit 8.0 with cuDNN 5.0.5. I also installed OpenCL freeglut3 and mesa libraries via apt-get. I then built Bazel from source using the installer script. Next, I installed the TensorFlow and Google Cloud Platform Python dependencies. I then cloned the tensorflow GitHub repository and modified the CROSSTOOL file variable cxx_builtin_include_directory to include the gcc location for 5.3.0. I then ran ./configure with default settings and tried to build with Bazel, but it always fails with an error like this, which appears to be a gcc issue:

WARNING: /root/.cache/bazel/_bazel_root/fbc06f9baef46cade6e35d9e4137e37c/external/protobuf/WORKSPACE:1: Workspace name in /root/.cache/bazel/_bazel_root/fbc06f9baef46cade6e35d9e4137e37c/external/protobuf/WORKSPACE (@__main__) does not match the name given in the repository's definition (@protobuf); this will cause a build error in future versions.

ERROR: /root/.cache/bazel/_bazel_root/fbc06f9baef46cade6e35d9e4137e37c/external/zlib_archive/BUILD:7:1: undeclared inclusion(s) in rule '@zlib_archive//:zlib'

This rule is missing dependency declarations for the following files included by 'external/zlib_archive/zlib-1.2.8/inftrees.c':
  '/usr/local/lib/gcc/x86_64-unknown-linux-gnu/5.3.0/include-fixed/limits.h'
  '/usr/local/lib/gcc/x86_64-unknown-linux-gnu/5.3.0/include-fixed/syslimits.h'
  '/usr/local/lib/gcc/x86_64-unknown-linux-gnu/5.3.0/include/stddef.h'
  '/usr/local/lib/gcc/x86_64-unknown-linux-gnu/5.3.0/include/stdarg.h'.
Target //tensorflow/cc:tutorials_example_trainer failed to build

If I change the gcc version to 4.8 (installed via apt-get) in ./configure and revert CROSSTOOL I get many warnings:
  INFO: ... warning: variable 'parsed_colon' set but not used

This warning is followed by an error:
ERROR: /opt/tensorflow/tensorflow/core/kernels/BUILD:1527:1: undeclared inclusion(s) in rule '//tensorflow/core/kernels:depth_space_ops_gpu':
this rule is missing dependency declarations for the following files included by 'tensorflow/core/kernels/spacetodepth_op_gpu.cu.cc':
  '/usr/local/cuda-8.0/include/cuda_runtime.h'
  '/usr/local/cuda-8.0/include/host_config.h'
  '/usr/local/cuda-8.0/include/builtin_types.h'
  '/usr/local/cuda-8.0/include/device_types.h'
  '/usr/local/cuda-8.0/include/host_defines.h'
  '/usr/local/cuda-8.0/include/driver_types.h'
  ...

This time, it appears to be an issue with CUDA Toolkit 8.0. Everything seems to work flawlessly up until building tensorflow from source.

Thanks,

Adam
"
3525,core dump when initializing gpu,"I have the same problem with [#2620](https://github.com/tensorflow/tensorflow/issues/2620), like this:

``` shell
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: Tesla K20c
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:02:00.0
Total memory: 4.69GiB
Free memory: 4.54GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x9568510
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties: 
name: Tesla K20c
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:04:00.0
Total memory: 4.69GiB
Free memory: 4.61GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x99b29a0
Segmentation fault (core dumped)
```

In fact, gpu 2 is busy:

``` shell
+------------------------------------------------------+                       
| NVIDIA-SMI 352.79     Driver Version: 352.79         |                       
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K20c          Off  | 0000:02:00.0     Off |                    0 |
| 30%   42C    P0    48W / 225W |     80MiB /  4799MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla K20c          Off  | 0000:04:00.0     Off |                    0 |
| 30%   24C    P8    15W / 225W |     14MiB /  4799MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  Tesla K20c          Off  | 0000:83:00.0     Off |                    0 |
| 46%   60C    P0   111W / 225W |   4768MiB /  4799MiB |     99%      Default |
+-------------------------------+----------------------+----------------------+
|   3  Tesla K20c          Off  | 0000:84:00.0     Off |                    0 |
| 40%   53C    P0   100W / 225W |    648MiB /  4799MiB |     97%      Default |
+-------------------------------+----------------------+----------------------+
```

 I only want to use gpu 1, but tensorflow want to init all gpus.
"
3524,Undefined symbols for architecture x86_64: _deflate (zlib),"Hi!

I was trying to reproduce one of my previous work on tensorflow on IOS when I stumble upon this error:

```
Undefined symbols for architecture x86_64:
  ""_deflate"", referenced from:
      tensorflow::io::ZlibOutputBuffer::Deflate(int) in libtensorflow-core.a(zlib_outputbuffer.o)
  ""_deflateEnd"", referenced from:
      tensorflow::io::ZlibOutputBuffer::Close() in libtensorflow-core.a(zlib_outputbuffer.o)
  ""_deflateInit2_"", referenced from:
      tensorflow::io::ZlibOutputBuffer::ZlibOutputBuffer(tensorflow::WritableFile*, int, int, tensorflow::io::ZlibCompressionOptions const&) in libtensorflow-core.a(zlib_outputbuffer.o)
  ""_inflate"", referenced from:
      tensorflow::io::ZlibInputBuffer::Inflate() in libtensorflow-core.a(zlib_inputbuffer.o)
  ""_inflateEnd"", referenced from:
      tensorflow::io::ZlibInputBuffer::~ZlibInputBuffer() in libtensorflow-core.a(zlib_inputbuffer.o)
      tensorflow::io::ZlibInputBuffer::~ZlibInputBuffer() in libtensorflow-core.a(zlib_inputbuffer.o)
  ""_inflateInit2_"", referenced from:
      tensorflow::io::ZlibInputBuffer::ZlibInputBuffer(tensorflow::RandomAccessFile*, unsigned long, unsigned long, tensorflow::io::ZlibCompressionOptions const&) in libtensorflow-core.a(zlib_inputbuffer.o)
```

Step i did:
- I cloned tensorflow at 10am 27/07/2016, paris timezone
- I ran gen_files_list.sh
- I compile tensorflow on IOS using the compile_all_ios.sh script on my project: ❌
- I git reset --hard HEAD
- I compile tensorflow on IOS using the compile_all_ios.sh script on my project: ❌

It works on the simple IOS examples.
Do you have any hint on this one ?

Other info:
- Mac OSX v 10.11.5
- Tensorflow on master branch
"
3523,Do you really guys calculate the gates values in LSTM?,"Hello guys, I was checking at the code in the classes BasicLSTMCell  as well as LSTMCell and I don't see you use formulas to get the values of the gates (output, input and forget) is this procedure you guys use really valid (since gates have their own calculation)?

in the _linear method (which you use) I just see matmul, concat and some functions from variable_scope.py However if you did it in another way, I would like to know it.
"
3520,verify_tensor_all_finite does not handle list of tensors of different shape,"`tf.verify_tensor_all_finite` works on lists of tensors that have the same shape.

but it does not seem to work on lists of tensors that have different shapes.
### Environment info

Operating System: Mac OSX 10.10.5

Installed version of CUDA and cuDNN: None

If installed from binary pip package, provide: 0.9.0rc0
### Steps to reproduce

``` Python
import tensorflow as tf

sess = tf.Session()

x0 = tf.Variable(tf.random_normal([1], dtype=tf.float32))
x1 = tf.Variable(tf.random_normal([1], dtype=tf.float32))
x2 = tf.Variable(tf.random_normal([3], dtype=tf.float32))

sess.run(tf.initialize_all_variables())

# works
assert_ops = [tf.verify_tensor_all_finite(x1, msg='')]
with tf.control_dependencies(assert_ops):
    y = tf.mul(x0, tf.mul(x1, tf.reduce_sum(x2)))
print(y.eval(session=sess))

# works
assert_ops = [tf.verify_tensor_all_finite(x1, msg=''),
              tf.verify_tensor_all_finite(x2, msg='')]
with tf.control_dependencies(assert_ops):
    y = tf.mul(x0, tf.mul(x1, tf.reduce_sum(x2)))
print(y.eval(session=sess))

# works (x0 and x1 have same shape)
assert_ops = [tf.verify_tensor_all_finite([x0, x1], msg='')]
with tf.control_dependencies(assert_ops):
    y = tf.mul(x0, tf.mul(x1, tf.reduce_sum(x2)))
print(y.eval(session=sess))

# fails (x0 and x2 have different shapes)
assert_ops = [tf.verify_tensor_all_finite([x0, x2], msg='')]
with tf.control_dependencies(assert_ops):
    y = tf.mul(x0, tf.mul(x1, tf.reduce_sum(x2)))
print(y.eval(session=sess))
```
"
3519,Suggestions for simplifying directory structure,"(version/machine agnostic)

I just want to say that after using TF for a while, I still have to fire too many brain cells to remember which directory certain files are in.  

The shortest way I can say this is that I suggest placing **all** instructional/non-source files in the same directory, _probably at the top_ of tensorflow so  visitors can easily find them.

Right now there are:
- `tensorflow[org]/models` (separate repo containing pre-trained models)
- `tensorflow[org]/tensorflow/tensorflow/examples/`
  -`tensorflow[org]/tensorflow/tensorflow/models`
- `tensorflow[org]/tensorflow/tensorflow/tutorials` (these are Tensorflow website tutorials)
- `tensorflow[org]/tensorflow/tensorflow/examples/how_tos`

Hopefully I am not the only one that sometimes finds this confusing, probably because of the same words being used repeatedly to describe different things.

Suggestion 1 is to place the tensorflow/[examples & models] directories into the root of `tensorflow[org]/tensorflow` and renaming that directory to examples_tutorials, to make where to look obvious for those not digging through the source (which is probably a majority of visitors).  I think that single, simple change would simplify this directory structure quite a bit.

I have a couple of additional suggestions for renaming the tensorflow/tensorflow/models directory (note not the pre-trained repo).
1. Rename the separate tensorflow/models **repo** (that contains code pertaining to pre-trained models) to `pre-trained-models` or `pre-trained-weights` and rename the `tensorflow/examples/models` **directory** to something that conveys the fact that it contains research paper models and not pre-trained ones.
2. Rename `models/embedding` to `word2vec` or something else more descriptive

Happy to submit a PR or two if the team wants to make these changes.
"
3517,Error when running distributed MNIST example,"Hi I am new to tensorflow and distributed tensorflow. I was trying to run an example from #2726 

Right now I am using tensorflow 0.9 on a cluster of Raspberry Pi3, using slurm to manage the nodes in the cluster, the script is below:
# !/bin/bash
# SBATCH -N 4
# SBATCH --nodelist=piw[25-28]

node1=piw25
node2=piw26
node3=piw27
node4=piw28
# On node1:

srun -N 1 -n 1 python mnist_yetanother.py \
     --ps_hosts=$node1:2223 \
     --worker_hosts=$node2:2223,$node3:2223,$node4:2223 \
     --job_name=ps --task_index=0 &
# On node2:

srun -N 1 -n 1 python mnist_yetanother.py \
     --ps_hosts=$node1:2223 \
     --worker_hosts=$node2:2223,$node3:2223,$node4:2223 \
     --job_name=worker --task_index=0 &
# On node3:

srun -N 1 -n 1 python mnist_yetanother.py \
     --ps_hosts=$node1:2223 \
     --worker_hosts=$node2:2223,$node3:2223,$node4:2223 \
     --job_name=worker --task_index=1 &
# On node4:

srun -N 1 -n 1 python mnist_yetanother.py \
     --ps_hosts=$node1:2223 \
     --worker_hosts=$node2:2223,$node3:2223,$node4:2223 \
     --job_name=worker --task_index=2
wait

And this is the error message:

I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job ps -> {piw25:2223}
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job worker -> {piw26:2223, piw27:2223, localhost:2223}
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job ps -> {localhost:2223}
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job worker -> {piw26:2223, piw27:2223, piw28:2223}
I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:2223
I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:2223
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job ps -> {piw25:2223}
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job ps -> {piw25:2223}
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job worker -> {localhost:2223, piw27:2223, piw28:2223}
I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:2223
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job worker -> {piw26:2223, localhost:2223, piw28:2223}
I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:2223
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz
Initialized!
Traceback (most recent call last):
  File ""mnist_yetanother.py"", line 351, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""mnist_yetanother.py"", line 310, in main
    with sv.prepare_or_wait_for_session(server.target, config=None) as sess:
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py"", line 684, in prepare_or_wait_for_session
    init_feed_dict=self._init_feed_dict, init_fn=self._init_fn)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 176, in prepare_session
    sess.run(init_op, feed_dict=init_feed_dict)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 372, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 636, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 708, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 728, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.InvalidArgumentError: /job:worker/replica:0/task:0/cpu:0 unknown device.
     [[Node: truncated_normal_2_S5 = _Recv[client_terminated=false, recv_device=""/job:ps/replica:0/task:0/cpu:0"", send_device=""/job:worker/replica:0/task:0/cpu:0"", send_device_incarnation=-8305312558883263444, tensor_name=""edge_62_truncated_normal_2"", tensor_type=DT_FLOAT, _device=""/job:ps/replica:0/task:0/cpu:0""]()]]
srun: error: piw28: task 0: Exited with exit code 1
E0726 15:08:58.966743325   10814 tcp_client_posix.c:173]     failed to connect to 'ipv4:192.168.50.38:2223': socket error: connection refused
E tensorflow/core/distributed_runtime/master.cc:202] Master init: Unavailable: 
E0726 15:09:04.384147901   10819 tcp_client_posix.c:191]     failed to connect to 'ipv4:192.168.50.38:2223': timeout occurred
E0726 15:09:09.463843371   10814 tcp_client_posix.c:191]     failed to connect to 'ipv4:192.168.50.38:2223': timeout occurred
E0726 15:09:18.410973793   10820 tcp_client_posix.c:191]     failed to connect to 'ipv4:192.168.50.38:2223': timeout occurred
E0726 15:09:29.903416857   10814 tcp_client_posix.c:173]     failed to connect to 'ipv4:192.168.50.38:2223': socket error: connection refused
E tensorflow/core/distributed_runtime/master.cc:202] Master init: Unavailable: 
E0726 15:10:00.977546704   10814 tcp_client_posix.c:173]     failed to connect to 'ipv4:192.168.50.38:2223': socket error: connection refused
E0726 15:10:47.956032631   10814 tcp_client_posix.c:191]     failed to connect to 'ipv4:192.168.50.38:2223': timeout occurred
E0726 15:11:48.090654174   10814 tcp_client_posix.c:191]     failed to connect to 'ipv4:192.168.50.38:2223': timeout occurred
E0726 15:13:21.260355773   10814 tcp_client_posix.c:191]     failed to connect to 'ipv4:192.168.50.38:2223': timeout occurred
E0726 15:15:21.261626939   10814 tcp_client_posix.c:191]     failed to connect to 'ipv4:192.168.50.38:2223': timeout occurred
E0726 15:17:21.263101653   10819 tcp_client_posix.c:191]     failed to connect to 'ipv4:192.168.50.38:2223': timeout occurred
E0726 15:19:21.264292261   10814 tcp_client_posix.c:191]     failed to connect to 'ipv4:192.168.50.38:2223': timeout occurred
E0726 15:21:21.265185108   10820 tcp_client_posix.c:191]     failed to connect to 'ipv4:192.168.50.38:2223': timeout occurred
E0726 15:23:21.265939820   10801 tcp_client_posix.c:191]     failed to connect to 'ipv4:192.168.50.38:2223': timeout occurred

I killed the program after a while. I'm not sure why I would get ""[Node: truncated_normal_2_S5 = _Recv[client_terminated=false, recv_device=""/job:ps/replica:0/task:0/cpu:0"", send_device=""/job:worker/replica:0/task:0/cpu:0"", send_device_incarnation=-8305312558883263444, tensor_name=""edge_62_truncated_normal_2"", tensor_type=DT_FLOAT, _device=""/job:ps/replica:0/task:0/cpu:0""]()]"" such error message. Searching online does not help too much...

Any help or advice will be greatly appreciated!
"
3515,Language Modeling: Test Sentence Probability,"I have trained and saved an RNN model using the tutorial given [here in the Tensorflow docs](https://www.tensorflow.org/versions/r0.9/tutorials/recurrent/index.html). I want to evaluate this model by finding **log probability of each test sentence**. I would really appreciate if someone can help me out with this.
Thanks!
"
3510,`tf.reduce_min/max/mean` returns uninitialized value on tensors with zero-size dimension,"I find that `tf.reduce_min/max/mean` returns uninitialized value (`nan` for example) on tensors with a zero-size dimension. This would cause problems, for example, when computing loss in an object detection problem, where an input image may contain no object. Please consider defining its behaviour on such inputs, e.g. outputing zeros, raising errors, etc.
### Environment info
- Operating System: Ubuntu 14.04 LTS
- CUDA 7.5, cuDNN 4.0
- TF version: 0.9.0rc0, pip version (gpu, python 2.7)
### Steps to reproduce

```
import tensorflow as tf
with tf.Session():
  print(tf.reduce_max(tf.constant(-1.0, shape=[0, 10])).eval())
```

Output:

```
-3.40282e+38
```

Also works for `tf.reduce_min`, `tf.reduce_mean`, but not for `tf.reduce_sum`.
"
3509,"Check failed,  cuCtxSetCurrent(context). training cifar10 multi-gpu example on 2 gpus.","I'm having trouble getting the multiple GPU example to work. Here is the full output:

```
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locallyeonitemd/tmrn python cifar10_multi_gpu_train.py --n                                                            
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locallyeonitemd/tmrn python cifar10_multi_gpu_train.py --n                                                             
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally                                                                                                                
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally                                                                                                               
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally                                                                                                               
>> Downloading cifar-10-binary.tar.gz 100.0%                                                                                                                                            
Successfully downloaded cifar-10-binary.tar.gz 170052171 bytes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.076
pciBusID 0000:02:00.0
Total memory: 12.00GiB
Free memory: 11.87GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties: 
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.076
pciBusID 0000:03:00.0
Total memory: 12.00GiB
Free memory: 11.87GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 1 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y Y 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 1:   Y Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:02:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX TITAN X, pci bus id: 0000:03:00.0)
F tensorflow/stream_executor/cuda/cuda_driver.cc:383] Check failed: CUDA_SUCCESS == dynload::cuCtxSetCurrent(context) (0 vs. 216)
F tensorflow/stream_executor/cuda/cuda_driver.cc:383] Check failed: CUDA_SUCCESS == dynload::cuCtxSetCurrent(context) (0 vs. 216)
F tensorflow/stream_executor/cuda/cuda_driver.cc:383] Check failed: CUDA_SUCCESS == dynload::cuCtxSetCurrent(context) (0 vs. 216)
F tensorflow/stream_executor/cuda/cuda_driver.cc:383] Check failed: CUDA_SUCCESS == dynload::cuCtxSetCurrent(context) (0 vs. 216)
F tensorflow/stream_executor/cuda/cuda_driver.cc:383] Check failed: CUDA_SUCCESS == dynload::cuCtxSetCurrent(context) (0 vs. 216)
F tensorflow/stream_executor/cuda/cuda_driver.cc:383] Check failed: CUDA_SUCCESS == dynload::cuCtxSetCurrent(context) (0 vs. 216)
```
### Environment info

Operating System: CentOS release 6.7 (Final). Using a docker image available here: [gideonitemd/hal-tf](https://hub.docker.com/r/gideonitemd/hal-tf/).

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

cudnn/7.0/lib64/libcudnn.so
cudnn/7.0/lib64/libcudnn.so.7.0.64  
cudnn/7.0/lib64/libcudnn.so.7.0
cudnn/7.0/lib64/libcudnn_static.a  

/usr/lib/libcuda.so 
/usr/lib/libcuda.so.1 
/usr/lib/libcuda.so.352.39

(should be libcuda v7.5)

Running `python -c ""import tensorflow; print(tensorflow.__version__)""` yields 0.8.0
### Steps to reproduce

Run this (the output of the `docker_run_gpu.sh` script):

```
docker run -it -v /usr/lib64/libcuda.so:/usr/lib64/libcuda.so -v /usr/lib64/libcuda.so.1:/usr/lib64/libcuda.so.1 -v /usr/lib64/libcuda.so.352.39:/usr/lib64/libcuda.so.352.39 -v /lib/modules/2.6.32-573.7.1.el6.x86_64/kernel/drivers/video/nvidia.ko:/lib/modules/2.6.32-573.7.1.el6.x86_64/kernel/drivers/video/nvidia.ko -v /lib/modules/2.6.32-573.7.1.el6.x86_64/modules.dep.bin,:/lib/modules/2.6.32-573.7.1.el6.x86_64/modules.dep.bin, --device /dev/nvidia0:/dev/nvidia0 --device /dev/nvidia1:/dev/nvidia1 --device /dev/nvidia2:/dev/nvidia2 --device /dev/nvidia3:/dev/nvidia3 --device /dev/nvidiactl:/dev/nvidiactl --device /dev/nvidia-uvm:/dev/nvidia-uvm --env LD_LIBRARY_PATH=/cbio/shared/software/cudnn/7.0/lib64:/usr/local/cuda-7.5/lib64:/usr/local/cuda-7.5/lib:/usr/local/cuda-7.5/targets/x86_64-linux/lib/:/opt/mpich2/gcc/eth/lib:/opt/gnu/gcc/4.8.1/lib64:/opt/gnu/gcc/4.8.1/lib:/opt/gnu/gmp/lib:/opt/gnu/mpc/lib:/opt/gnu/mpfr/lib:/usr/lib64/ --env CUDA_VISIBLE_DEVICES=0,1 -v /cbio/ski/fuchs/projects/tissue-microarray-resnet/:/mnt/data -v /cbio/ski/fuchs/home/dresdnerg/software/tensorflow/tensorflow/models/image/cifar10:/mnt/code -it gideonitemd/tmrn python cifar10_multi_gpu_train.py --num_gpus 2
```
### What have you tried?
1. Messing with `CUDA_VISIBLE_DEVICES`: empty, `=0`, `=0,1`. All failed.
2. Looking at other issues with the same error, none address this specific problem since it works fine on a single GPU.
3. `nvidia-smi` shows no other jobs accessing the GPU
4. `docker ps` shows no zombie images
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
3508,"Training on a GTX 1080 does not work, produces random labels","Hi! 
I have come across a very very strange issue. Namely, training on an NVIDIA GTX 1080 does not work at all, and judging from the error rate, the predicted labels are completely random.

I have 2 almost identical systems (see below), and while on the System with the GTX 960 the training runs perfectly fine, on the system with the GTX 1080, the training simply doesn't work.

To test this, I ran
the following code: 

`python -m tensorflow.models.image.mnist.convolutional`

On the System 1 (GTX 960), i get to an error rate below 4% within 2-3 batches, and at the end, it's below 1%:

```
Step 0 (epoch 0.00), 7.6 ms
Minibatch loss: 12.054, learning rate: 0.010000
Minibatch error: 90.6%
Validation error: 84.6%
Step 100 (epoch 0.12), 13.0 ms
Minibatch loss: 3.296, learning rate: 0.010000
Minibatch error: 4.7%
Validation error: 7.3%
Step 200 (epoch 0.23), 13.1 ms
Minibatch loss: 3.459, learning rate: 0.010000
Minibatch error: 12.5%
Validation error: 3.9%
...
Step 8500 (epoch 9.89), 13.0 ms
Minibatch loss: 1.604, learning rate: 0.006302
Minibatch error: 1.6%
Validation error: 0.9%
Test error: 0.8%
```

On the GTX 1080 system, the performance simply _never_ improves! Error rate is steady at around 90%.

```
Step 8400 (epoch 9.77), 5.5 ms
Minibatch loss: 3.881, learning rate: 0.006302
Minibatch error: 85.9%
Validation error: 88.7%
Step 8500 (epoch 9.89), 5.5 ms
Minibatch loss: 3.877, learning rate: 0.006302
Minibatch error: 87.5%
Validation error: 88.7%
Test error: 89.7%
```

I tested this with TensorFlow 0.9, from the release PIP package for Python 3.5 with GPU support.
I also tested this with TensorFlow master from a week ago (fc9162975e52978d3af38549b570cc3cc5f0ab66), compiled to a PIP package on one machine, installed on both machines.

Here are the full system Specs, but the difference between them is only the GPU (1080 vs 960) and the Driver (367.35 vs 361.42)

System 1
- OS: Ubuntu 16.04.1 LTS
- Kernel: 4.4.0-31-generic
- NVIDIA Driver Version: 361.42 
- CPU: Intel(R) Core(TM) i7 CPU         930  @ 2.80GHz
- RAM: 12 GB Ram
- GPU: NVIDIA GTX 960, 4GB VRAM (edition: MSI GTX 960 Gaming 4G)

System 2:
- OS: Ubuntu 16.04.1 LTS
- Kernel: 4.4.0-31-generic
- NVIDIA Driver Version: 367.35
- CPU: Intel(R) Core(TM) i7 CPU         930  @ 2.80GHz
- RAM: 12 GB Ram
- GPU: NVIDIA GTX 1080, 8GB VRAM

My LD_LIBRARY_PATH on both machines is:
`:/usr/local/cuda/lib64:/usr/local/cuda-7.5/extras/CUPTI/lib64/`

My Cuda version is 7.5, cudnn is 4.0.7 on BOTH machines. 

Output of `ls -l /usr/local/cuda/lib64` on the Machine with the GTX 960 and GTX 1080
https://gist.github.com/akors/30f5fbe3994e3ac40a4adbb6f76eb756#file-cudalibs-gtx960-txt
https://gist.github.com/akors/30f5fbe3994e3ac40a4adbb6f76eb756#file-cudalibs-gtx1080-txt

Does anyone know what could cause this and how to fix this?
"
3507,"Training on a GTX 1080 does not work, produces random labels","Hi! 
I have come across a very very strange issue. Namely, training on an NVIDIA GTX 1080 does not work at all, and judging from the error rate, the predicted labels are completely random.

I have 2 almost identical systems (see below), and while on the System with the GTX 960 the training runs perfectly fine, on the system with the GTX 1080, the training simply doesn't work.

To test this, I ran
the following code: 

`python -m tensorflow.models.image.mnist.convolutional`

On the System 1 (GTX 960), i get to an error rate below 4% within 2-3 batches, and at the end, it's below 1%:

```
Step 0 (epoch 0.00), 7.6 ms
Minibatch loss: 12.054, learning rate: 0.010000
Minibatch error: 90.6%
Validation error: 84.6%
Step 100 (epoch 0.12), 13.0 ms
Minibatch loss: 3.296, learning rate: 0.010000
Minibatch error: 4.7%
Validation error: 7.3%
Step 200 (epoch 0.23), 13.1 ms
Minibatch loss: 3.459, learning rate: 0.010000
Minibatch error: 12.5%
Validation error: 3.9%
...
Step 8500 (epoch 9.89), 13.0 ms
Minibatch loss: 1.604, learning rate: 0.006302
Minibatch error: 1.6%
Validation error: 0.9%
Test error: 0.8%
```

On the GTX 1080 system, the performance simply _never_ improves! Error rate is steady at around 90%.

```
Step 8400 (epoch 9.77), 5.5 ms
Minibatch loss: 3.881, learning rate: 0.006302
Minibatch error: 85.9%
Validation error: 88.7%
Step 8500 (epoch 9.89), 5.5 ms
Minibatch loss: 3.877, learning rate: 0.006302
Minibatch error: 87.5%
Validation error: 88.7%
Test error: 89.7%
```

I tested this with TensorFlow 0.9, from the release PIP package for Python 3.5 with GPU support.
I also tested this with TensorFlow master from a week ago (fc9162975e52978d3af38549b570cc3cc5f0ab66), compiled to a PIP package on one machine, installed on both machines.

Here are the full system Specs, but the difference between them is only the GPU (1080 vs 960) and the Driver (367.35 vs 361.42)

System 1
- OS: Ubuntu 16.04.1 LTS
- Kernel: 4.4.0-31-generic
- NVIDIA Driver Version: 361.42 
- CPU: Intel(R) Core(TM) i7 CPU         930  @ 2.80GHz
- RAM: 12 GB Ram
- GPU: NVIDIA GTX 960, 4GB VRAM (edition: MSI GTX 960 Gaming 4G)

System 2:
- OS: Ubuntu 16.04.1 LTS
- Kernel: 4.4.0-31-generic
- NVIDIA Driver Version: 367.35
- CPU: Intel(R) Core(TM) i7 CPU         930  @ 2.80GHz
- RAM: 12 GB Ram
- GPU: NVIDIA GTX 1080, 8GB VRAM

My LD_LIBRARY_PATH on both machines is:
`:/usr/local/cuda/lib64:/usr/local/cuda-7.5/extras/CUPTI/lib64/`

My Cuda version is 7.5, cudnn is 4.0.7 on BOTH machines. 

Output of `ls -l /usr/local/cuda/lib64` on the Machine with the GTX 960 and GTX 1080
https://gist.github.com/akors/30f5fbe3994e3ac40a4adbb6f76eb756#file-cudalibs-gtx960-txt
https://gist.github.com/akors/30f5fbe3994e3ac40a4adbb6f76eb756#file-cudalibs-gtx1080-txt

Does anyone know what could cause this and how to fix this?
"
3506,functional ops are not exposed in documentation,"It appears that functional ops are now fully documented, given /tensorflow/g3doc/api_docs/python/functional_ops.md, but they are not exposed in the main documentation (index.md does not link to functional_ops.md)
"
3505,Enable fully_connected to uniquify the scope name,"The implementation of `tf.contrib.layers.fully_connected` uses `variable_op_scope` to handle the name scope of the variables, the problem is that the name scope is only _uniquified_ if `scope` is `None`, that is, if you dont pass a custom name, by default it will be `""fully_connected""`. 

However, in the library I am building I create tons of shorcut methods like `relu_layer`, `sigmoid_layer`, etc, which are implemented using `fully_connected` plus their corresponding activation function. I'd like these names to be uniquified automatically so I don't get these kind of errors:

> ValueError: Variable relu_layer/weights already exists, disallowed. Did you mean to set reuse=True in VarScope?

In the mean time, could you give me a hint of how to uniquify a variable name scope myself? Is there a function that does this already?

Thanks!
"
3504,Inception v3 model crashes with out of memory with batch size of 128 on a GPU with 12 GB memory..,"When I run the inception v3 network, with a _batch size of 32_ , from [here](https://github.com/tensorflow/models/tree/master/inception) on an nVidia GPU with 12 GB memory, I get the below messages during initialization about raising pool_size_limit. The initialization takes a long time. But it eventually manages to run. Is there a way to speed this up ? The pool limit starts from 100 and keeps increasing until it reaches 2997, is there a way to increase the pool limit ? Perhaps, some sort of an environment variable ?

If I try running with batch_size of 128, it crashes with out of memory. The log of which is attached to this report. Is there a way to fix this ?
[tensorflow-inception-v3-bs128.txt](https://github.com/tensorflow/tensorflow/files/383534/tensorflow-inception-v3-bs128.txt)
### Environment info

Operating System:
Stock gpu-dev Docker image on CentOS 7

Installed version of CUDA and cuDNN: 
root@d4239a28fc92:~# ls /usr/local/cuda-7.5/lib64/libcud*
/usr/local/cuda-7.5/lib64/libcuda.so         /usr/local/cuda-7.5/lib64/libcudart.so
/usr/local/cuda-7.5/lib64/libcuda.so.1       /usr/local/cuda-7.5/lib64/libcudart.so.7.5
/usr/local/cuda-7.5/lib64/libcuda.so.352.93  /usr/local/cuda-7.5/lib64/libcudart.so.7.5.18
/usr/local/cuda-7.5/lib64/libcudadevrt.a     /usr/local/cuda-7.5/lib64/libcudart_static.a

If installed from binary pip package, provide:
1. Which pip package you installed.
   tensorflow-0.8.0-cp27-none-linux_x86_64.whl
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   0.8.0
### Steps to reproduce

bazel-bin/inception/imagenet_train --num_gpus=1 --batch_size=32 --max_steps=100
### What have you tried?
1. Running with a smaller batch size of 32 instead of 128 to get the model to run successfully.
2. Pass the command -m 240000000000 to nvidia-docker.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 3857 get requests, put_count=2169 evicted_count=1000 eviction_rate=0.461042 and unsatisfied allocation rate=0.722842
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 100 to 110
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 3857 get requests, put_count=4230 evicted_count=3000 eviction_rate=0.70922 and unsatisfied allocation rate=0.68447
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 146 to 160
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=2019 evicted_count=2000 eviction_rate=0.990589 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=2028 evicted_count=2000 eviction_rate=0.986193 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 3857 get requests, put_count=3560 evicted_count=2000 eviction_rate=0.561798 and unsatisfied allocation rate=0.605911
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 449 to 493
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=1065 evicted_count=1000 eviction_rate=0.938967 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 3857 get requests, put_count=3333 evicted_count=1000 eviction_rate=0.30003 and unsatisfied allocation rate=0.422349
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 1158 to 1273
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 65569 get requests, put_count=65760 evicted_count=1000 eviction_rate=0.0152068 and unsatisfied allocation rate=0.0161052
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 2725 to 2997
2016-07-26 13:27:52.039502: step 0, loss = 13.02 (2.4 examples/sec; 13.434 sec/batch)
2016-07-26 13:28:21.119108: step 10, loss = 14.07 (25.9 examples/sec; 1.234 sec/batch)
2016-07-26 13:28:33.393687: step 20, loss = 14.80 (26.0 examples/sec; 1.229 sec/batch)
2016-07-26 13:28:45.642208: step 30, loss = 14.68 (26.3 examples/sec; 1.217 sec/batch)
2016-07-26 13:28:57.914613: step 40, loss = 13.67 (26.0 examples/sec; 1.229 sec/batch)
2016-07-26 13:29:10.188971: step 50, loss = 13.41 (26.1 examples/sec; 1.226 sec/batch)
2016-07-26 13:29:22.507990: step 60, loss = 13.20 (25.9 examples/sec; 1.235 sec/batch)
2016-07-26 13:29:34.767687: step 70, loss = 13.15 (26.2 examples/sec; 1.223 sec/batch)
2016-07-26 13:29:47.051145: step 80, loss = 13.08 (26.0 examples/sec; 1.229 sec/batch)
2016-07-26 13:29:59.302955: step 90, loss = 13.09 (26.1 examples/sec; 1.228 sec/batch)
"
3503,Installing tensorflow on windows through Docker,"Hi,

I've successfully installed docker toolbox and created a container but when I enter 

docker run -it b.gcr.io/tensorflow/tensorflow

I get ""Unable to find image 'docker run -it b.gcr.io/tensorflow/tensorflow' loally""

I have read on other threads that this might be due to space allocation so this container already has 20gb.

What do I do? I've got a Windows 10 Pro.

Thanks a lot!
"
3502,Streaming_mean along specific dimension,"Currently the streaming_mean function computes the mean for all tensor values. It would be interesting to have the possibility to specify the axis along with we want to compute the mean. 
"
3501,build fail with nvcc_options?,"I build tensorflow in virtualenv , it says :
    gcc: error: unrecognized command line option '-nvcc_options=relaxed-constexpr'
    gcc: error: unrecognized command line option '-nvcc_options=ftz=true'

 gcc is 4.8.2
 cuda is 7.0
 cudnn is 4.0.7 
more detail:

```
ERROR: /u01/qianming/tensorflow/tensorflow/core/kernels/BUILD:1575:1: C++ compilation of rule '//tensorflow/core/kernels:training_ops_gpu' failed: gcc failed: error executing command
(cd /home/hongpengfei.lhpf/.cache/bazel/_bazel_hongpengfei.lhpf/072f5a261c0f2d9a7bd6ffe5c05ae7b2/execroot/tensorflow && \
exec env - \
LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/local/lib:/usr/local/cuda/lib64:/usr/local/cuda-7.5/lib64::/usr/lib/toolchains/lib:/usr/local/lib:/usr/local/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib \
       PATH=/u01/qianming/tensor_env/bin:/home/hongpengfei.lhpf/.usr/local/bin/:/u01/mysql/bin:/usr/local/cuda-7.5/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/usr/X11R6/bin:/opt/dell/srvadmin/bin:/home/hongpengfei.lhpf/bin:/home/mysql/bin:/usr/local/toolchains/bin:/usr/local/cuda/bin:/home/hongpengfei.lhpf/bin \
/home/hongpengfei.lhpf/.usr/local/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++11' -MD -MF bazel-out/local_linux-opt/bin/tensorflow/core/kernels/_objs/training_ops_gpu/tensorflow/core/kernels/training_ops_gpu.cu.d '-frandom-seed=bazel-out/local_linux-opt/bin/tensorflow/core/kernels/_objs/training_ops_gpu/tensorflow/core/kernels/training_ops_gpu.cu.o' -iquote . -iquote bazel-out/local_linux-opt/genfiles -iquote external/protobuf -iquote bazel-out/local_linux-opt/genfiles/external/protobuf -iquote external/bazel_tools -iquote bazel-out/local_linux-opt/genfiles/external/bazel_tools -iquote external/farmhash_archive -iquote bazel-out/local_linux-opt/genfiles/external/farmhash_archive -iquote external/jpeg_archive -iquote bazel-out/local_linux-opt/genfiles/external/jpeg_archive -iquote external/png_archive -iquote bazel-out/local_linux-opt/genfiles/external/png_archive -iquote external/highwayhash -iquote bazel-out/local_linux-opt/genfiles/external/highwayhash -iquote external/re2 -iquote bazel-out/local_linux-opt/genfiles/external/re2 -iquote external/eigen_archive -iquote bazel-out/local_linux-opt/genfiles/external/eigen_archive -isystem external/protobuf/src -isystem bazel-out/local_linux-opt/genfiles/external/protobuf/src -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/farmhash_archive/farmhash-34c13ddfab0e35422f4c3979f360635a8c050260 -isystem bazel-out/local_linux-opt/genfiles/external/farmhash_archive/farmhash-34c13ddfab0e35422f4c3979f360635a8c050260 -isystem external/jpeg_archive/jpeg-9a -isystem bazel-out/local_linux-opt/genfiles/external/jpeg_archive/jpeg-9a -isystem external/png_archive/libpng-1.2.53 -isystem bazel-out/local_linux-opt/genfiles/external/png_archive/libpng-1.2.53 -isystem external/highwayhash -isystem bazel-out/local_linux-opt/genfiles/external/highwayhash -isystem external/re2 -isystem bazel-out/local_linux-opt/genfiles/external/re2 -isystem third_party/eigen3 -isystem bazel-out/local_linux-opt/genfiles/third_party/eigen3 -isystem external/eigen_archive/eigen-eigen-d02e6a705c30 -isystem bazel-out/local_linux-opt/genfiles/external/eigen_archive/eigen-eigen-d02e6a705c30 -isystem third_party/gpus/cuda/include -isystem bazel-out/local_linux-opt/genfiles/third_party/gpus/cuda/include -isystem third_party/gpus/cuda -isystem bazel-out/local_linux-opt/genfiles/third_party/gpus/cuda -x cuda '-DGOOGLE_CUDA=1' '-nvcc_options=relaxed-constexpr' '-nvcc_options=ftz=true' -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -fno-canonical-system-headers -c tensorflow/core/kernels/training_ops_gpu.cu.cc -o bazel-out/local_linux-opt/bin/tensorflow/core/kernels/_objs/training_ops_gpu/tensorflow/core/kernels/training_ops_gpu.cu.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
gcc: error: unrecognized command line option '-nvcc_options=relaxed-constexpr'
gcc: error: unrecognized command line option '-nvcc_options=ftz=true'
```
"
3499,Placeholder names are inconsistent when re-entering a scope,"```
    with tf.Graph().as_default() as g:
        for name in [""a"",""b""]:
            with tf.variable_scope(""fc""):
                x = tf.placeholder(tf.float32, shape=[1], name=name)
                print(x)
```

gives

```
Tensor(""fc/a:0"", shape=(1,), dtype=float32)
Tensor(""fc_1/b:0"", shape=(1,), dtype=float32)
```

The variable ""b"" unexpectedly has the name ""fc_1/b:0"" rather than ""fc/b:0"". This makes it difficult to refer to placeholders by name in my program.
"
3498,'tensorflow.contrib.learn' has no attribute 'infer_real_valued_columns_from_input',"## Environment info: 

Operating System:
Ubuntu 16.04 , Python3.5.2, tensorflow version '0.9.0'
## I try to run boston_house_prices data but it failed with no attribute 'infer_real_valued_columns_from_input' in tensorflow.contrib.learn. I wrote this script according to https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/skflow/boston.py

import pandas as pd
import numpy as np
import random
from sklearn import cross_validation, metrics, preprocessing
import tensorflow as tf
from tensorflow.contrib import learn

df = pd.read_csv('boston_house_prices.csv')
df.fillna(-99999, inplace = True)

X = np.array(df.drop(['MEDV'], 1))
X = preprocessing.StandardScaler().fit_transform(X)
y = np.array(df['MEDV'], dtype = int)

X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size = 0.2, random_state = 42)
random.seed(42)

feature_columns = learn.infer_real_valued_columns_from_input(X_train)
regressor = learn.DNNRegressor(feature_columns=feature_columns, hidden_units = [10, 10])

regressor.fit(X_train, y_train, steps = 5000, batch_size =1)
score = metrics.mean_squared_error(regressor.predict(X_test), y_test)
print(""Accuracy %f"" % score)
## Logs or other output that would be helpful:

Traceback (most recent call last):
  File ""2DNN.py"", line 26, in <module>
    feature_columns = learn.infer_real_valued_columns_from_input(X_train)
AttributeError: module 'tensorflow.contrib.learn' has no attribute 'infer_real_valued_columns_from_input'
"
3496," android studio api19:   System.loadLibrary(""tensorflow_demo""); <----what can i do ㅠㅠ"," android studio api19:  
TensorflowClassifier.java: 
static {
    System.loadLibrary(""tensorflow_demo"");
  }
<----this is problem
plz helpㅠㅠ i am korean ㅠㅠ
Couldn't load tensorFlow_demo from loader dalvik.system.PathClassLoader[DexPathList[[zip file ""/data/app/org.tensorflow.demo-2.apk""],nativeLibraryDirectories=[/data/app-lib/org.tensorflow.demo-2, /vendor/lib, /system/lib]]]: findLibrary returned null

what should i do?ㅠㅠ plz
## error log

07-25 14:15:28.049 3164-3164/org.tensorflow.demo E/AndroidRuntime: FATAL EXCEPTION: main
                                                                   Process: org.tensorflow.demo, PID: 3164
                                                                   java.lang.UnsatisfiedLinkError: Couldn't load tensorFlow_demo from loader dalvik.system.PathClassLoader[DexPathList[[zip file ""/data/app/org.tensorflow.demo-2.apk""],nativeLibraryDirectories=[/data/app-lib/org.tensorflow.demo-2, /vendor/lib, /system/lib]]]: findLibrary returned null
                                                                       at java.lang.Runtime.loadLibrary(Runtime.java:358)
                                                                       at java.lang.System.loadLibrary(System.java:526)
                                                                       at org.tensorflow.demo.TensorflowClassifier.<clinit>(TensorflowClassifier.java:46)
                                                                       at org.tensorflow.demo.TensorflowImageListener.<init>(TensorflowImageListener.java:54)
                                                                       at org.tensorflow.demo.CameraConnectionFragment.<init>(CameraConnectionFragment.java:240)
                                                                       at org.tensorflow.demo.CameraConnectionFragment.newInstance(CameraConnectionFragment.java:170)
                                                                       at org.tensorflow.demo.CameraActivity.onCreate(CameraActivity.java:30)
                                                                       at android.app.Activity.performCreate(Activity.java:5231)
                                                                       at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1087)
                                                                       at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2159)
                                                                       at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2245)
                                                                       at android.app.ActivityThread.access$800(ActivityThread.java:135)
                                                                       at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1196)
                                                                       at android.os.Handler.dispatchMessage(Handler.java:102)
                                                                       at android.os.Looper.loop(Looper.java:136)
                                                                       at android.app.ActivityThread.main(ActivityThread.java:5017)
                                                                       at java.lang.reflect.Method.invokeNative(Native Method)
                                                                       at java.lang.reflect.Method.invoke(Method.java:515)
                                                                       at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:779)
                                                                       at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:595)
                                                                       at dalvik.system.NativeStart.main(Native Method)
## .
"
3495,Show the collection that a variable belongs to in TensorBoard,"This is specially useful when using functions like `tf.contrib.layers.fully_connected` that generate the weight and bias variables on their own. With this you could simply inspect in TensorBoard and get that information right away, no need to look in the docs or ask.
"
3494,Tensorflow Import on OSX 10.11.5 fails ,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System: 10.11.5
Python Version: 2.7.12 (installed from homebrew)

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
 /usr/local/cuda/lib/libcuda.dylib
 /usr/local/cuda/lib/libcudadevrt.a -> /Developer/NVIDIA/CUDA-7.5/lib/libcudadevrt.a
/usr/local/cuda/lib/libcudart.7.5.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart.7.5.dylib
/usr/local/cuda/lib/libcudart.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart.dylib
/usr/local/cuda/lib/libcudart_static.a -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart_static.a
/usr/local/cuda/lib/libcudnn.5.dylib
/usr/local/cuda/lib/libcudnn.dylib -> libcudnn.5.dylib
/usr/local/cuda/lib/libcudnn_static.a
If installed from binary pip package, provide:
1. Which pip package you installed.
   I tried both install from source using the OSX guide. 
   And, the nightly binary with GPU support. 0.90
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.dylib locally
   I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.dylib locally
   I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.dylib locally
   fish: 'python -c ""import tensorflow""' terminated by signal SIGSEGV (Address boundary error)

Python quits 

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)
   5161e4c51b994b3feb93cdb851479c29a3450f31
2. The output of `bazel version`
   Build label: 0.3.0-homebrew
   Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
   Build time: Tue Jul 12 11:11:47 2016 (1468321907)
   Build timestamp: 1468321907
   Build timestamp as int: 1468321907
### Steps to reproduce
1. Install tensorflow from source or nightly using pip install
2. python -c ""import tensorflow""
### What have you tried?
1. import numpy, import scipy etc looking at previous errors. 
2. dtruss output attached for import tensorflow
### Logs or other output that would be helpful

(If logs are large, please upload 
[dtruss_python_tensorflow.txt](https://github.com/tensorflow/tensorflow/files/382028/dtruss_python_tensorflow.txt)
as attachment).
"
3493,Building issues,"ERROR: /home/wenjian/pkgs/tensorflow/tensorflow/core/kernels/BUILD:1517:1: undeclared inclusion(s) in rule '//tensorflow/core/kernels:spacetobatch_op_gpu':
this rule is missing dependency declarations for the following files included by 'tensorflow/core/kernels/spacetobatch_op_gpu.cu.cc':
  '/usr/local/cuda-8.0/include/cuda_runtime.h'
  '/usr/local/cuda-8.0/include/host_config.h'
  '/usr/local/cuda-8.0/include/builtin_types.h'
  '/usr/local/cuda-8.0/include/device_types.h'
  '/usr/local/cuda-8.0/include/host_defines.h'
  '/usr/local/cuda-8.0/include/driver_types.h'
  '/usr/local/cuda-8.0/include/surface_types.h'
  '/usr/local/cuda-8.0/include/texture_types.h'
  '/usr/local/cuda-8.0/include/vector_types.h'
  '/usr/local/cuda-8.0/include/library_types.h'
  '/usr/local/cuda-8.0/include/channel_descriptor.h'
  '/usr/local/cuda-8.0/include/cuda_runtime_api.h'
  '/usr/local/cuda-8.0/include/cuda_device_runtime_api.h'
  '/usr/local/cuda-8.0/include/driver_functions.h'
  '/usr/local/cuda-8.0/include/vector_functions.h'
  '/usr/local/cuda-8.0/include/vector_functions.hpp'
  '/usr/local/cuda-8.0/include/common_functions.h'
  '/usr/local/cuda-8.0/include/math_functions.h'
  '/usr/local/cuda-8.0/include/math_functions.hpp'
  '/usr/local/cuda-8.0/include/math_functions_dbl_ptx3.h'
  '/usr/local/cuda-8.0/include/math_functions_dbl_ptx3.hpp'
  '/usr/local/cuda-8.0/include/cuda_surface_types.h'
  '/usr/local/cuda-8.0/include/cuda_texture_types.h'
  '/usr/local/cuda-8.0/include/device_functions.h'
  '/usr/local/cuda-8.0/include/device_functions.hpp'
  '/usr/local/cuda-8.0/include/device_atomic_functions.h'
  '/usr/local/cuda-8.0/include/device_atomic_functions.hpp'
  '/usr/local/cuda-8.0/include/device_double_functions.h'
  '/usr/local/cuda-8.0/include/device_double_functions.hpp'
  '/usr/local/cuda-8.0/include/sm_20_atomic_functions.h'
  '/usr/local/cuda-8.0/include/sm_20_atomic_functions.hpp'
  '/usr/local/cuda-8.0/include/sm_32_atomic_functions.h'
  '/usr/local/cuda-8.0/include/sm_32_atomic_functions.hpp'
  '/usr/local/cuda-8.0/include/sm_35_atomic_functions.h'
  '/usr/local/cuda-8.0/include/sm_60_atomic_functions.h'
  '/usr/local/cuda-8.0/include/sm_60_atomic_functions.hpp'
  '/usr/local/cuda-8.0/include/sm_20_intrinsics.h'
  '/usr/local/cuda-8.0/include/sm_20_intrinsics.hpp'
  '/usr/local/cuda-8.0/include/sm_30_intrinsics.h'
  '/usr/local/cuda-8.0/include/sm_30_intrinsics.hpp'
  '/usr/local/cuda-8.0/include/sm_32_intrinsics.h'
  '/usr/local/cuda-8.0/include/sm_32_intrinsics.hpp'
  '/usr/local/cuda-8.0/include/sm_35_intrinsics.h'
  '/usr/local/cuda-8.0/include/surface_functions.h'
  '/usr/local/cuda-8.0/include/texture_fetch_functions.h'
  '/usr/local/cuda-8.0/include/texture_indirect_functions.h'
  '/usr/local/cuda-8.0/include/surface_indirect_functions.h'
  '/usr/local/cuda-8.0/include/device_launch_parameters.h'
  '/usr/local/cuda-8.0/include/cuda_fp16.h'
  '/usr/local/cuda-8.0/include/math_constants.h'
  '/usr/local/cuda-8.0/include/curand_kernel.h'
  '/usr/local/cuda-8.0/include/curand.h'
  '/usr/local/cuda-8.0/include/curand_discrete.h'
  '/usr/local/cuda-8.0/include/curand_precalc.h'
  '/usr/local/cuda-8.0/include/curand_mrg32k3a.h'
  '/usr/local/cuda-8.0/include/curand_mtgp32_kernel.h'
  '/usr/local/cuda-8.0/include/cuda.h'
  '/usr/local/cuda-8.0/include/curand_mtgp32.h'
  '/usr/local/cuda-8.0/include/curand_philox4x32_x.h'
  '/usr/local/cuda-8.0/include/curand_globals.h'
  '/usr/local/cuda-8.0/include/curand_uniform.h'
  '/usr/local/cuda-8.0/include/curand_normal.h'
  '/usr/local/cuda-8.0/include/curand_normal_static.h'
  '/usr/local/cuda-8.0/include/curand_lognormal.h'
  '/usr/local/cuda-8.0/include/curand_poisson.h'
  '/usr/local/cuda-8.0/include/curand_discrete2.h'.
nvcc warning : option '--relaxed-constexpr' has been deprecated and replaced by option '--expt-relaxed-constexpr'.
nvcc warning : option '--relaxed-constexpr' has been deprecated and replaced by option '--expt-relaxed-constexpr'.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 261.225s, Critical Path: 89.69s
"
3492,"Dilated Convolution, Dilated Pooling and 2D/3D Sliding Window CNNs","Could you please implement 2D/3D dilated convolution and 2D/3D dilated pooling in tensorflow?

Please see http://arxiv.org/pdf/1511.07122.pdf for a reference on dilated convolution.

Dilated max-pooling is simply regular max-pooling but the pixels/voxels you use in each ""application"" of the max-pooling operation are exactly the same pixels/voxels you would select with dilated convolution.

Dilated convolution/pooling are useful for connectomics and 3D shape datasets (3D deep learning).
"
3491,Unified file system support implementation for C++/Python,"Currently the C++ code has file system interface and provides POSIX and GCS implementation. However, part of the Python code also using another file system abstraction (tensorflow/python/summary/impl/gcs.py). This is annoying and tedious to supporting new type of file systems. So what is the consideration here and whether this is plan to make the Python code depending on C++ IO abstraction only.
"
3489,Timeline only produced for the last invocation on Session.run,"Hi!

First of all, thanks for the great profiling/timeline feature! I think it can be really amazing to debug model performance.

I do have a question though: is it possible to create a timeline for _multiple_ invocations of `Session.run`?

In all the examples that I saw, timeline creation looks something along the lines of this:

```
run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)
run_metadata = tf.RunMetadata()

sess.run(result, options=run_options, run_metadata=run_metadata)

tl = timeline.Timeline(run_metadata.step_stats)
ctf = tl.generate_chrome_trace_format()
```

This is all good and well, but this generates the trace only for _one_ invocation of Session.run. If it is invoked multiple times (for example in batch training), the `step_stats` in the run_metadata are always overwritten by the last run.

Is there a way to aggregate the timing data to create a timeline that spans over multiple invocations?

I would need this to debug performance decay over long periods.
"
3487,seq2seq multidimensional regression,"Hi, I am facing an issue while trying to train an RNN to do a multidimensional regression.  

**The Tensorflow loss function built for RNNs seems to address the cases where we directly want to train labels or words embeddings, so I tried to compute the loss myself for a regression and it failed or seems not done for that.** 

The question is also more detailed with my actual code and Tensorflow Graph on [StackOverflow](http://stackoverflow.com/questions/38549040/tensorflow-seq2seq-multidimensional-regression).
_This seems more like a missing feature, so this is why I ask the question here too._ 

What would be a nice workaround? There **should** be one.

If there is already code for that, I would really like to see it, because what I want to do seems undocumented yet and I would like to do it, I am probably not alone. In the end, I would like to predict the N next coeficients of some [STFT](https://www.youtube.com/watch?v=TZzS52OplYs&index=5&list=PLlp-GWNOd6m6gSz0wIcpvl4ixSlS-HEmr), but for now I focus on making the regression model with simple sinusoidal data. 

Many thanks!!!
"
3486,import tensorflow as tf error,"### Environment info

Operating System: OS X EI Capitan Version 10.11.1
### Steps to reproduce
1. run `import tensorflow as tf'
### Logs or other output that would be helpful

```
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 23, in <module>
    from tensorflow.python import *
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 52, in <module>
    from tensorflow.core.framework.graph_pb2 import *
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/core/framework/graph_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/core/framework/attr_value_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/core/framework/tensor_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import tensor_shape_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/core/framework/tensor_shape_pb2.py"", line 22, in <module>
    serialized_pb=_b('\n,tensorflow/core/framework/tensor_shape.proto\x12\ntensorflow\""z\n\x10TensorShapeProto\x12-\n\x03\x64im\x18\x02 \x03(\x0b\x32 .tensorflow.TensorShapeProto.Dim\x12\x14\n\x0cunknown_rank\x18\x03 \x01(\x08\x1a!\n\x03\x44im\x12\x0c\n\x04size\x18\x01 \x01(\x03\x12\x0c\n\x04name\x18\x02 \x01(\tB/\n\x18org.tensorflow.frameworkB\x11TensorShapeProtosP\x01\x62\x06proto3')
TypeError: __init__() got an unexpected keyword argument 'syntax'
```

Please advice. Thank you.
"
3483,Slicing error: Using a `tf.Tensor` as a Python `bool` is not allowed,"### Environment info

Operating System:
MacOSX, Python3, tensorflow version '0.9.0'
### Steps to reproduce
1. I am trying to slice a tensor (I want to remove boundaries for purpose of error evaluation)

```
# vector_loss  = tf.Variable(...)
pad = 8
width = tf.shape(vector_loss,)[2]
vector_loss = vector_loss[:,:,pad:width-pad, :]
```
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).

```
Traceback (most recent call last):
  File ""./footprint_poisson.py"", line 445, in <module>
    epochs=50)
  File ""./footprint_poisson.py"", line 263, in fit
    tot_loss = self._create_loss()
  File ""./footprint_poisson.py"", line 220, in _create_loss
    poisson_loss_ = poisson_loss(self.vars.y, self.vars.y_predicted, pad = 8)
  File ""./footprint_poisson.py"", line 28, in poisson_loss
    vector_loss = vector_loss[:,:,pad:width-pad, :]
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py"", line 176, in _SliceHelper
    if s.stop is not None and s.stop < 0:
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 515, in __bool__
    raise TypeError(""Using a `tf.Tensor` as a Python `bool` is not allowed. ""
TypeError: Using a `tf.Tensor` as a Python `bool` is not allowed. Use `if t is not None:` instead of `if t:` to test if a tensor is defined, and use the logical TensorFlow ops to test the value of a tensor.
```
"
3482,Update Docker Image,"Hey All,

There are a variety of issues I'm running into with the docker image, just basic stuff.
1.  sudo apt-get update
2.  Python3 support
3.  Nano is not installed (vim is the worst)
   3a.  I want this so I can easily edit the notebook config for setting passwords.
4.  The jupyter notebook needs to be updated to the latest
5.  Pip updates
6.  Maybe ship with Anaconda as well.

Its just a variety of things that aren't working quite well.  I'm trying to put together a Jupyter Notebook our machine learning meetup group can use and share, and its just a pain in the neck. 

I tried to do just a fresh setup from a fresh linux vm, but I was having issues getting Jupyter to actually recognize the TensorFlow install; so now I'm trying the docker image again.  The biggest issue with the docker image in its current state is that after a while the auto-save starts breaking, json formats for posting to save break and then it messes up the encoding of the notebook, which then becomes more or less un-recoverable (without extensive effort).

I beleive (not sure) that updating everything in the supported image would fix at least some of these issues.
"
3481,Failed to do 8-bit quantization following the tutorial: Op type not registered 'Dequantize',"hello, I'm learning to do 8-bit quantization following the [How-to-tutorial](https://www.tensorflow.org/versions/master/how_tos/quantization/index.html) step-by-step, after I managed to output the `quantized_graph.pb`, then I was trying to test it, just like the tutorial:

```
>> bazel build tensorflow/examples/label_image:label_image
>> bazel-bin/tensorflow/examples/label_image/label_image \
--input_graph=/tmp/quantized_graph.pb \
--input_width=299 \
--input_height=299 \
--mean_value=128 \
--std_value=128 \
--input_layer_name=""Mul:0"" \
--output_layer_name=""softmax:0""
```

( a not-so-important change is, in fact, I found the script above didn't work, so I changed some parameter names as below: )

```
>> bazel-bin/tensorflow/examples/label_image/label_image 
--graph=/tmp/imagenet/quantized_graph.pb \
--input_width=299 \
--input_height=299 \
--input_mean=128 \
--input_std=128 \
--input_layer=""Mul:0""\
--output_layer=""softmax:0""
```

However, I got the error:

```
E tensorflow/examples/label_image/main.cc:281] Not found: Op type not registered 'Dequantize'
```

Do anyone know how to fix this? thanks a lot in advance :)
"
3480,Errors loading inception v3 in iOS example,"### Environment info

Operating System: Mac OS X / iOS

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`) : fc9162975e52978d3af38549b570cc3cc5f0ab66
2. The output of `bazel version`: Build label: 0.3.0-homebrew
### Steps to reproduce
1. Download the .pb file from  https://storage.googleapis.com/download.tensorflow.org/models/inception_dec_2015.zip
2. Insert the .pb file in the data folder of the `camera` iOS project
3. Launch the project from Xcode, console outputs following errors:

`Running model failed:Invalid argument: Session was not created with a graph before Run()!`

`Running model failed:Invalid argument: No OpKernel was registered to support Op 'DecodeJpeg' with these attrs
     [[Node: DecodeJpeg = DecodeJpeg[acceptable_fraction=1, channels=3, fancy_upscaling=true, ratio=1, try_recover_truncated=false](DecodeJpeg/contents)]]`
### What have you tried?
1. ran the following script referenced in #2883:

`bazel build tensorflow/python/tools:strip_unused && \
bazel-bin/tensorflow/python/tools/strip_unused \
--input_graph=your_retrained_graph.pb \
--output_graph=stripped_graph.pb \
--input_node_names=Mul \
--output_node_names=final_result \
--input_binary=true`

However, I receive the following error:

`/tensorflow/bazel-bin/tensorflow/python/tools/strip_unused.runfiles/org_tensorflow/tensorflow/python/framework/graph_util.py"", line 156, in extract_sub_graph
    assert d in name_to_node_map, ""%s is not in graph"" % d
AssertionError: final_result is not in graph`
"
3479,Build error with CUDA,"I'm able to build tensorflow trainer example successfully with

`bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer`

But I get the following build error when trying to build the tensorflow pip package:

`bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package`

```
ERROR: /home/charlesq/projects/tensorflow/tensorflow/core/kernels/BUILD:1646:1: undeclared inclusion(s) in rule '//tensorflow/core/kernels:scatter_op_gpu':
this rule is missing dependency declarations for the following files included by 'tensorflow/core/kernels/scatter_op_gpu.cu.cc':
  '/usr/local/cuda-8.0/include/cuda_runtime.h'
  '/usr/local/cuda-8.0/include/host_config.h'
  '/usr/local/cuda-8.0/include/builtin_types.h'
  '/usr/local/cuda-8.0/include/device_types.h'
  '/usr/local/cuda-8.0/include/host_defines.h'
  '/usr/local/cuda-8.0/include/driver_types.h'
  '/usr/local/cuda-8.0/include/surface_types.h'
  '/usr/local/cuda-8.0/include/texture_types.h'
  '/usr/local/cuda-8.0/include/vector_types.h'
  '/usr/local/cuda-8.0/include/library_types.h'
  '/usr/local/cuda-8.0/include/channel_descriptor.h'
  '/usr/local/cuda-8.0/include/cuda_runtime_api.h'
  '/usr/local/cuda-8.0/include/cuda_device_runtime_api.h'
  '/usr/local/cuda-8.0/include/driver_functions.h'
  '/usr/local/cuda-8.0/include/vector_functions.h'
  '/usr/local/cuda-8.0/include/vector_functions.hpp'
  '/usr/local/cuda-8.0/include/common_functions.h'
  '/usr/local/cuda-8.0/include/math_functions.h'
  '/usr/local/cuda-8.0/include/math_functions.hpp'
  '/usr/local/cuda-8.0/include/math_functions_dbl_ptx3.h'
  '/usr/local/cuda-8.0/include/math_functions_dbl_ptx3.hpp'
  '/usr/local/cuda-8.0/include/cuda_surface_types.h'
  '/usr/local/cuda-8.0/include/cuda_texture_types.h'
  '/usr/local/cuda-8.0/include/device_functions.h'
  '/usr/local/cuda-8.0/include/device_functions.hpp'
  '/usr/local/cuda-8.0/include/device_atomic_functions.h'
  '/usr/local/cuda-8.0/include/device_atomic_functions.hpp'
  '/usr/local/cuda-8.0/include/device_double_functions.h'
  '/usr/local/cuda-8.0/include/device_double_functions.hpp'
  '/usr/local/cuda-8.0/include/sm_20_atomic_functions.h'
  '/usr/local/cuda-8.0/include/sm_20_atomic_functions.hpp'
  '/usr/local/cuda-8.0/include/sm_32_atomic_functions.h'
  '/usr/local/cuda-8.0/include/sm_32_atomic_functions.hpp'
  '/usr/local/cuda-8.0/include/sm_35_atomic_functions.h'
  '/usr/local/cuda-8.0/include/sm_60_atomic_functions.h'
  '/usr/local/cuda-8.0/include/sm_60_atomic_functions.hpp'
  '/usr/local/cuda-8.0/include/sm_20_intrinsics.h'
  '/usr/local/cuda-8.0/include/sm_20_intrinsics.hpp'
  '/usr/local/cuda-8.0/include/sm_30_intrinsics.h'
  '/usr/local/cuda-8.0/include/sm_30_intrinsics.hpp'
  '/usr/local/cuda-8.0/include/sm_32_intrinsics.h'
  '/usr/local/cuda-8.0/include/sm_32_intrinsics.hpp'
  '/usr/local/cuda-8.0/include/sm_35_intrinsics.h'
  '/usr/local/cuda-8.0/include/surface_functions.h'
  '/usr/local/cuda-8.0/include/texture_fetch_functions.h'
  '/usr/local/cuda-8.0/include/texture_indirect_functions.h'
  '/usr/local/cuda-8.0/include/surface_indirect_functions.h'
  '/usr/local/cuda-8.0/include/device_launch_parameters.h'
  '/usr/local/cuda-8.0/include/cuda_fp16.h'
  '/usr/local/cuda-8.0/include/math_constants.h'
  '/usr/local/cuda-8.0/include/curand_kernel.h'
  '/usr/local/cuda-8.0/include/curand.h'
  '/usr/local/cuda-8.0/include/curand_discrete.h'
  '/usr/local/cuda-8.0/include/curand_precalc.h'
  '/usr/local/cuda-8.0/include/curand_mrg32k3a.h'
  '/usr/local/cuda-8.0/include/curand_mtgp32_kernel.h'
  '/usr/local/cuda-8.0/include/cuda.h'
  '/usr/local/cuda-8.0/include/curand_mtgp32.h'
  '/usr/local/cuda-8.0/include/curand_philox4x32_x.h'
  '/usr/local/cuda-8.0/include/curand_globals.h'
  '/usr/local/cuda-8.0/include/curand_uniform.h'
  '/usr/local/cuda-8.0/include/curand_normal.h'
  '/usr/local/cuda-8.0/include/curand_normal_static.h'
  '/usr/local/cuda-8.0/include/curand_lognormal.h'
  '/usr/local/cuda-8.0/include/curand_poisson.h'
  '/usr/local/cuda-8.0/include/curand_discrete2.h'.
nvcc warning : option '--relaxed-constexpr' has been deprecated and replaced by option '--expt-relaxed-constexpr'.
nvcc warning : option '--relaxed-constexpr' has been deprecated and replaced by option '--expt-relaxed-constexpr'.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 6000.817s, Critical Path: 170.00s
```

Operating system: Linux Mint Rosa 17.3 (Ubuntu 14.04.3 Trusty)

Cuda version 8.0. Compute capability 6.1 (GTX 1080 GPU)

Path of cuda libs is /usr/local/cuda. The folder /usr/local/cuda/lib does not exist, however there is lib64/

```
 $ ls /usr/local/cuda/lib64/libcud*
/usr/local/cuda/lib64/libcudadevrt.a    /usr/local/cuda/lib64/libcudart.so.8.0.27  /usr/local/cuda/lib64/libcudnn.so.5
/usr/local/cuda/lib64/libcudart.so      /usr/local/cuda/lib64/libcudart_static.a   /usr/local/cuda/lib64/libcudnn.so.5.0.5
/usr/local/cuda/lib64/libcudart.so.8.0  /usr/local/cuda/lib64/libcudnn.so          /usr/local/cuda/lib64/libcudnn_static.a

$ git rev-parse HEAD
36d056acd92ca2f7e97fec82fd09f36c42c05338

$ bazel version
.......
Build label: 0.2.1
Build target: bazel-out/local_linux-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Thu Mar 31 19:30:01 2016 (1459452601)
Build timestamp: 1459452601
Build timestamp as int: 1459452601
```
"
3478,How to restore a distributed model and continue to train it with more workers?,"### Environment info

Running distributed tensorflow on kubernetes.

Installed version of CUDA and cuDNN:  No
### Steps to reproduce
1. Train a model with 3 workers
2. restore the model with 4 workers
### Logs or other output that would be helpful

```
tensorflow.python.framework.errors.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [4] rhs shape= [3]
     [[Node: save/Assign_103 = Assign[T=DT_INT64, _class=[""loc:@local_steps""], use_locking=true, validate_shape=true, _device=""/job:ps/replica:0/task:0/cpu:0""](local_steps, save/restore_slice_103)]]
     [[Node: save/restore_all/NoOp_S6 = _Recv[client_terminated=false, recv_device=""/job:worker/replica:0/task:0/cpu:0"", send_device=""/job:ps/replica:0/task:0/cpu:0"", send_device_incarnation=6655275555388235088, tensor_name=""edge_9844_save/restore_all/NoOp"", tensor_type=DT_FLOAT, _device=""/job:worker/replica:0/task:0/cpu:0""]()]]
```

It seems that we need to have the same number of workers to restore a model. Is it possible to increase the number of workers without retraining the model from beginning?
"
3476,How to initialize LSTMStateTuple ?,"In ptb_word_lm.py tutorial. When I set tf.nn.rnn_cell.BasicLSTMCell to  `state_is_tuple=True`, it fail initialise the state at the begining of each epoch. What is the way to initialise a `LSTMStateTuple` ?

I did use cell.zero_state to get the varible for the initial state, which works fine. However, when I want to get initial values of the initial state using `initial_state.eval()`, I got an error saying that AttributeError: `LSTMStateTuple` object has no attribute 'eval'.

Please see a simplified version of my code below (this code works well when `state_is_tuple=False`)

```
    state = lstm.initial_state.eval()
    for step, (x, y) in enumerate(reader.ptb_iterator(train_data,
                                                    batch_size, num_steps)):
        feed_dict = {
            input_data: x, targets: y,
            lstm.initial_state: state
        }
        _cost, state, _ = sess.run(
            [cost, lstm.final_state, train_op],
            feed_dict=feed_dict
        )
```

The main reason for feeding this initial_state into feed_dict is to propagate the cell's state to the next iteration.

Many Thank
"
3475,Device placement error while using multi gpus on single machine by distributed version," I follow [Distributed TensorFlow](https://www.tensorflow.org/versions/r0.9/how_tos/distributed/index.html#distributed-tensorflow) to try the distributed version of tensorflow, my code is [here](https://github.com/guolinke/temp/blob/master/mnist_expert_dist.py).

I try to run it on mulit machines with mutil gpus, and every worker will start multi instances of tensorflow.

To simplify problem, i only run it on single machine with multi-gpu(8*k40m), and only start one ps and one worker. Following is my scripts:

```
python ./mnist_expert_dist.py --ps_hosts=localhost:12222 --worker_hosts=localhost:12223 --job_name=ps --task_index=0 --gpu_index=0 --iteration_count=5000 --verbose=true

python ./mnist_expert_dist.py --ps_hosts=localhost:12222 --worker_hosts=localhost:12223 --job_name=worker --task_index=0 --gpu_index=1 --iteration_count=5000 --verbose=true
```

Following is my error messages:

```
Traceback (most recent call last):
  File ""./mnist_expert_dist.py"", line 187, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""./mnist_expert_dist.py"", line 184, in main
    run_training(cluster, server)
  File ""./mnist_expert_dist.py"", line 121, in run_training
    sess = sv.prepare_or_wait_for_session(server.target)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py"", line 684, in prepare_or_wait_for_session
    init_feed_dict=self._init_feed_dict, init_fn=self._init_fn)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 170, in prepare_session
    max_wait_secs=max_wait_secs, config=config)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 209, in recover_session
    sess.run([self._local_init_op])
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 372, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 636, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 708, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 728, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'save/Const': Could not satisfy explicit device specification '/job:worker/task:0/device:GPU:1' because no supported kernel for GPU devices is available.
Colocation Debug Info:
Colocation group had the following types and devices:
Identity: CPU
Const: CPU
         [[Node: save/Const = Const[dtype=DT_STRING, value=Tensor<type: string shape: [] values: model>, _device=""/job:worker/task:0/device:GPU:1""]()]]
Caused by op u'save/Const', defined at:
  File ""./mnist_expert_dist.py"", line 187, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""./mnist_expert_dist.py"", line 184, in main
    run_training(cluster, server)
  File ""./mnist_expert_dist.py"", line 113, in run_training
    init_op=init_op)#,
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py"", line 300, in __init__
    self._init_saver(saver=saver)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py"", line 429, in _init_saver
    saver = saver_mod.Saver()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 845, in __init__
    restore_sequentially=restore_sequentially)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 504, in build
    filename_tensor = constant_op.constant(""model"")
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/constant_op.py"", line 166, in constant
    attrs={""value"": tensor_value, ""dtype"": dtype_value}, name=name).outputs[0]
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2260, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1230, in __init__
    self._traceback = _extract_stack()
```

I use nvidia-smi to see the status of gpu, it seems ps will take all gpus, and worker cannot access any gpus.
How can I solve this problem?
Can i start the ps only with one gpu? or only use cpu?

Thanks.
"
3474,Cannot import name 'pywrap_tensorflow',"Hi, I have tried almost every methods in Stackoverflow and here, but am still struggling with the problem. Please help me to solve it.
### Environment info

Operating System: **Ubuntu 16.04 64bit (GTX 1070)** 

Installed version of CUDA and cuDNN: **CUDA 8.0 RC & cuDNN 5.0**
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
dongyoung@dkpc:~$ ls /usr/local/cuda/lib64/libcud*
/usr/local/cuda/lib64/libcudadevrt.a    /usr/local/cuda/lib64/libcudart.so.8.0.27  /usr/local/cuda/lib64/libcudnn.so.5
/usr/local/cuda/lib64/libcudart.so      /usr/local/cuda/lib64/libcudart_static.a   /usr/local/cuda/lib64/libcudnn.so.5.0.5
/usr/local/cuda/lib64/libcudart.so.8.0  /usr/local/cuda/lib64/libcudnn.so          /usr/local/cuda/lib64/libcudnn_static.a

If installed from binary pip package, provide
1. Which pip package you installed.
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`) 
   Sorry, but I don't know how to do this. I just downloaded the tensorflow-master.zip file from Github
2. The output of `bazel version`
   **[bazel release 0.3.0]**
### Steps to reproduce
1. In my home directory, type 'ipython3', then change directory to tensorflow that I installed which is ~/tensorflow
2. then type 'import tensorflow as tf'
3. It shows ImportError: cannot import name 'pywrap_tensorflow'
### Logs or other output that would be helpful

![screenshot from 2016-07-23 12-18-14](https://cloud.githubusercontent.com/assets/673965/17075477/8e5fbdf6-50cf-11e6-8e7e-0ede795a251b.png)

(If logs are large, please upload as attachment).

One more question is that how can I make a path 'tensorflow' to use globally?

Thank you :)
"
3473,Incompatibility with Python modules that mutually import each other,"I came across the following issue. It probably isn't very urgent.
### Environment info

I can produce the following error on:
1. Operating System: OS X El Capitan, 10.11.3 (15D21)
2. Ubuntu 14.04 (the default Ubuntu AMI on EC2)

I am using the CPU version of TensorFlow, installed from

```
# Ubuntu/Linux 64-bit, CPU only, Python 2.7
$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.9.0-cp27-none-linux_x86_64.whl
```

```
> python -c ""import tensorflow; print(tensorflow.__version__)""
0.9.0
```
### Steps to reproduce
1. Create `file1.py` with contents:
   
   ``` python
   import file2 # Can also reproduce the error with a single file by having file1 import itself
   import tensorflow as tf # The order of these two imports doesn't matter
   sess = tf.Session() # Removing the assignment fixes the problem
   ```
2. Create `file2.py` with contents
   
   ``` python
   import file1
   ```
3. Then run
   
   ```
   > python file1.py
   Exception AttributeError: ""'NoneType' object has no attribute 'raise_exception_on_not_ok_status'"" in <bound method Session.__del__ of <tensorflow.python.client.session.Session object at 0x1172b7cd0>> ignored
   ```
"
3472,Zero value warning message in quantized convolution op is wrong?,"This warning message [in this quantized ops code snippet](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/quantization/kernels/quantized_conv_ops.cc#L201-L206) is output when `input_offset < 0`:

> Zero is not representable in the quantized range used by the input. This means QuantizedConv2d has to fall back to a slow implementation, since the border of zero values can't be represented easily. You should try to construct graphs that avoid this situation.

Is that really what's going on there? What does that have to do with `input_offset < 0`? Secondly, there is a code comment about gemmlowp needing support for a specific code path (perhaps it's the `input_offset < 0` path?). What's going on here? 

Adding @petewarden as he's probably the most familiar with this code.
"
3471,C++ api runs much slower than Python API (compile flags),"My graph run in Python only takes 6 seconds for one batch, but when I run the identical batch on the same graph (graph_freeze) in the C++ Api, the time is 80 seconds. I'm guessing this 13x slowdown is probably from using the wrong C flags during compilation. This is all running on CPU only. 

I'm loading the graphs using the same way as in the label_images example. 

I took a look at: https://github.com/tensorflow/tensorflow/issues/2721, and added the -mavx C flag, which increased it by about double, but still 13x slower than the python.

The graph is a mostly a large multi layered regular RNN but with some feedforward as well. 

Any ideas on how to get it to the same speed as python? Is there somewhere I can see what flags tensorflow installed from source is compiled with?
### Environment info

Operating System: Linux ubuntu 64 bit 14.04

Installed version of CUDA and cuDNN:  None (CPU Only)
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. Which pip package you installed.
   Linux 64 Bit CPU Python 3.5
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   0.9.0

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`
### Steps to reproduce
1. Create graph in python
2. freeze_graph.py
3. Load graph in C++
### What have you tried?
1. adding -mavx C flag
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
3470,TensorFlow r0.9rc0 and r0.10rc0 cluster memory leak and core dump,"### Environment info

Operating System: 

```
$ uname -svm
Linux #50-Ubuntu SMP Wed Jul 13 00:07:12 UTC 2016 x86_64
$ lsb_release -a
Distributor ID: Ubuntu
Description:    Ubuntu 16.04.1 LTS
Release:        16.04
Codename:       xenial
```

Installed version of CUDA and cuDNN: 

```
$ find /usr/lib -name libcud\*
/usr/lib/i386-linux-gnu/libcuda.so.1
/usr/lib/i386-linux-gnu/libcuda.so.361.42
/usr/lib/i386-linux-gnu/libcuda.so
/usr/lib/x86_64-linux-gnu/libcudnn_static.a
/usr/lib/x86_64-linux-gnu/libcudnn_static_v5.a
/usr/lib/x86_64-linux-gnu/libcuda.so.1
/usr/lib/x86_64-linux-gnu/libcudart.so.7.5.18
/usr/lib/x86_64-linux-gnu/libcudnn.so
/usr/lib/x86_64-linux-gnu/libcuda.so.361.42
/usr/lib/x86_64-linux-gnu/libcudnn.so.5.0.5
/usr/lib/x86_64-linux-gnu/libcudart.so
/usr/lib/x86_64-linux-gnu/libcudart.so.7.5
/usr/lib/x86_64-linux-gnu/libcudadevrt.a
/usr/lib/x86_64-linux-gnu/libcudnn.so.5
/usr/lib/x86_64-linux-gnu/stubs/libcuda.so
/usr/lib/x86_64-linux-gnu/libcuda.so
/usr/lib/x86_64-linux-gnu/libcudart_static.a
```

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

Built from source:

```
* No Google Cloud Platform support
* GPU support
* CUDA Compute Capability: 3.0, 3.5 and 5.2

printf '\n\nY\n\n\n/usr\n\n\n3.0,3.5,5.2\n' | ./configure
```

```
tensorflow-0.9.0rc0-py3-none-any.whl
```

```
0.9.0rc0
```

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`

```
$ git rev-parse HEAD
2f5ca43750dcd052843fd02a841bf041c3958670
```

```
$ bazel version
...............
Build label: 0.2.2
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Thu Apr 21 13:01:41 2016 (1461243701)
Build timestamp: 1461243701
Build timestamp as int: 1461243701
```
### Steps to reproduce
1. I'll provide a gist with an example and update.
### What have you tried?
1. Tried disabling summary and checkpoint restart.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).

On 16 worker processes the memory consumption on the (single) PS process grows with >1MB/s. The worker processes also grows in memory size but not as much. My workers are only executing a sequence of ""sess.run(..)"" commands in the loop so I don't think its even possible to add stuff to the graph. We'll try to prove me wrong in the gist if I can get a usable repro.
### Update (TensorFlow r0.10 and debugging)

I just checked with the latest version of TensorFlow (r0.10) and it seems to leaks memory in the same way. Disclaimer: I used the TensorFlow package from TensorFlow.org but I have cuDNN 5 installed right now.

The TensorFlow package I used (in a Python 3.5 conda environment called `tf-r0.10`):

```
$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.10.0rc0-cp35-cp35m-linux_x86_64.whl
$ pip install --upgrade $TF_BINARY_URL
```
1. I tried adding a `sess.graph.finalize()` and I got no exceptions, thus I make the assumption that the code does not create any new nodes in each iteration.
2. If I use the tmalloc from Ubuntu 16.04 (`libtcmalloc-minimal4`) the memory leak just got worse, but I did not get any output that I could try and examine why?

```
pre_window: source activate tf-r0.10 && export CUDA_VISIBLE_DEVICES='' LD_PRELOAD=/usr/lib/libtcmalloc_minimal_debug.so.4 HEAPPROFILE=/tmp/heapprofile HEAPCHECK=1
```

I can still reproduce the core dump with the `for _ in range(100)` change:

```
terminate called after throwing an instance of 'std::system_error'
  what():  Resource temporarily unavailable
Aborted (core dumped)
```
"
3469,"Raspberry Pi Bazel Build ""Define appropriate PLATFORM macro"" error","When building TensorFlow on Raspberry Pi with Bazel, the pre-compiler end up throwing this error:

```
Define the appropriate PLATFORM_<foo> macro for this platform
```

From what I've been able to gather, here's the cause of the issue:
1. Because Raspberry Pi uses an ARM CPU, the `IS_MOBILE_PLATFORM` macro is defined [in `tensorflow/core/platform/platform.h](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/platform.h#L45)
2. Later, when trying to compile [png.h](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/png.h#L23-L26), [gif.h](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/gif.h), or [jpeg.h](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/jpeg.h), the if/else statements fall through, leaving with the default option to throw an error.
### Environment info

Operating System: Raspbian GNU/Linux, version 8.0

Installed version of CUDA and cuDNN: N/A

Installed from source.
1. The commit hash : e95f4e760c6b6713b6b686ebeff9a1586a5831dd
2. The output of `bazel version` : 

```
Build label: 0.2.1-2016-06-13 (@447f7f3)
Build target: bazel-out/local_linux-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Mon Jun 13 19:05:24 2016 (1465844724)
Build timestamp: 1465844724
Build timestamp as int: 1465844724
```
### Steps to reproduce
1. Build TensorFlow from source on Raspberry Pi [as described in this guide](https://github.com/samjabrahams/tensorflow-on-raspberry-pi/blob/master/GUIDE.md) _without_ deleting [this line from `tensorflow/core/platform/platform.h`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/platform.h#L45), which defines `IS_MOBILE_PLATFORM` when compiling on ARM devices.
### What have you tried?
1. Deleted the line mentioned above, which fixes the problem for local builds
### Logs or other output that would be helpful

[define_macro_error.txt](https://github.com/tensorflow/tensorflow/files/378789/define_macro_error.txt)
"
3467,Docker Image with Python 3?,"This is more a feature request.  Any chance we can get support for this?
"
3464,Extract the element from the output list of tf.py_func when length 1,"`tf.py_func` could extract the element from the list when the length is 1.

In this example:

```
def func(x):
    return 2*x

x = tf.constant(1.)
res = tf.py_func(func, [x], [tf.float32])
```

`res` is a list containing 1 Tensor. This can be confusing, because users expect to get only one tensor as output.

`tf.cond` handles this case well:

> **Returns:**
> Tensors returned by the call to either fn1 or fn2. If the callables return a singleton list, the element is extracted from the list.
"
3463,Dev request -- LSTM RNN,"I previously [posted](https://github.com/tensorflow/tensorflow/issues/3278) about processing 3D data in an LSTM network with Tensorflow. It turns out Grid LSTM networks are what would work best. Already applied in contrib gridd_rnn.py. [This](http://arxiv.org/abs/1507.01526) paper (Grid LSTM) outlines Grid LSTM, but they also mentioned something I found to be a great idea.

I don't believe there is a way for Tensorflow to currently support this natively. 

The idea goes, in between each LSTM RNN step, instead of simply passing outputs to the next step, outputs are first passed through a single layer MLP. In other words there is a `tf.matmul` in between each step.

What do you think? It seems like a simple enough feature to implement in the `RNN` initialization. 
"
3460,Exponential Moving Average of trained variables in tf.contrib.learn.estimators.estimator,"Hi,

As mentioned in the cifar10 tutorial, it is often useful to use an exponential moving average of the trained variables at prediction time.

From my understanding, in it's current form, the class BaseEstimator does not allow to do so. 

The _infer_model method of BaseEstimator would need to create a saver object that restores the averaged version of the trained variables, and the saver object would then need to be cascaded into graph_actions.infer and ultimately down to graph_actions.run_feeds.

Whilst overriding a class method is not a big deal, I was wondering if there was a neat way of achieving the end goal without having to refactor the graph_actions.

Best Regards,

Marco
"
3459,tf.cond blocks forever when one branch calls tf.random_crop trough tf.map_fn,"I'm running tensorflow 0.9.0 on Python 3.5.2 using CUDA 7.5 on CentOS 7, and I keep running into very weird behaviour: tf.cond seems to stall forever when the non-active branch calls tf.random_crop. I've reduced my code to the following minimal example:

```
import numpy as np
import tensorflow as tf

IMG_WIDTH = 32
IMG_HEIGHT = 32
IMG_CHANNELS = 3

def distort_image(image):
    # this should crop the whole image, i.e. do nothing!
    return tf.random_crop(image, [IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS])

xx = np.random.normal(size=(4, IMG_HEIGHT, IMG_WIDTH, 3)).astype(np.float32)

tf.reset_default_graph()
x = tf.placeholder(tf.float32, shape=(None, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))
is_training = tf.placeholder(tf.bool)
xp = tf.cond(is_training,  
        lambda: tf.map_fn(distort_image, x, back_prop=False),  
        lambda: tf.identity(x))  

init = tf.initialize_all_variables()
with tf.Session() as sess:
    sess.run(init)
    p = sess.run(xp, feed_dict={x: xx, is_training: False})
```

The weird thing is that if `is_training` is set to True, the function runs through without problems. I.e., when you actually call the `tf.map_fn` branch, everything works out fine.
"
3457,Problem in distributed tensorflow demo?,"### Environment info

Operating System:
Kubernetes (using the 0.8.0 server image)

Installed version of CUDA and cuDNN: 
No

When I start the [mnist_replica demo](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dist_test/python/mnist_replica.py), it stuck after `prepare_or_wait_for_session`

But if I run `start_queue_runners` for both chief worker and all other workers, it runs successfully. (By removing `and is_chief` part [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dist_test/python/mnist_replica.py#L224) and [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dist_test/python/mnist_replica.py#L193))

Is this a bug in the demo?
"
3455,Feature Request: support sparse tensor in conv2d operator,"It looks like TF doesn't support conv2d as another thread mentioned (https://github.com/tensorflow/tensorflow/issues/1604). This is critical for us since we are implementing CDSSM (from microsoft https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/www2014_cdssm_p07.pdf). Miscrosoft's library supports it and the training speed is dramatically faster than using TF. So we strongly feel this feature is important. 
"
3453,Saver (sharded) ignores number of checkpoints to keep,"`tf.train.Saver()` has a default limit of 5 most recent checkpoints to keep (`max_to_keep=5`). When I use a Saver with `sharded=True` option, only one machine performs this check and keeps ALL the checkpoints without removing any of them.
### Environment info

Operating System: Ubuntu 14.04 LTS
Built from source; commit hash: aa2cacd6627ffb296bedc910c957a0fd4a2f957f
### Steps to reproduce
- Init a sharded saver and pass it to the Supervisor for distributed training and auto-model saving after every `save_model_secs`.

```
saver = tf.train.Saver(sharded=True)
sv = tf.train.Supervisor(is_chief=is_chief,
                                 logdir=FLAGS.train_dir,
                                 init_op=init_op,
                                 summary_op=None,
                                 global_step=global_step,
                                 saver=saver,
                                 save_model_secs=FLAGS.save_interval_secs)
```
- Start two workers and one ps on machine 0. Start two more workers and one ps on machine 1.
- The saver keeps the 5 most recent sharded checkpoints on machine 0 (where the chief worker also runs). But machine 1 keeps all sharded checkpoints from beginning.
"
3451,retrain.py validation and testing evaluation seems incorrect,"While retrain new final layer is added which has name defined by FLAGS.final_tensor_name. Strangely while evaluating against ground truths instead of using final_tensor_name or final_matmul it still uses output of ''validation_bottlenecks'. 

validation_accuracy = sess.run(
          evaluation_step,
          feed_dict={bottleneck_input: validation_bottlenecks,
                     ground_truth_input: validation_ground_truth})
"
3449,IPython Notebook kernel dies when importing tensorflow,"### Environment info

Operating System: nvidia-docker (Docker version 1.11.2, build b9f10c9)
Tensorflow version 0.8.0
### Steps to reproduce
1. Run ipyhton notebook from nvidia-docker
2. import tensorflow
3. Kernel dies with Kernel Restarting dialog and message ""The kernel appears to have died. It will restart automatically""
4. importing numpy package before importing tensorflow solves the issue.
"
3446,iOS example with Image Retraining model always gives the same prediction,"## Environment info

Running on: iOS 9.1
Building on OS X El Capitan version 10.11, Xcode version 7.3.1
TensorFlow release 0.9
## Steps to reproduce

Follow the contrib/makefile/README to install the tensorflow iOS core lib
Create my own model with the Image Retraining tutorial
Run the iOS example, same error as #2883 is logged.
After fixing errors as suggested same prediction is always given. 
Logs or other output that would be helpful

```
2016-07-21 18:20:06.582 tf_ios_makefile_example[949:323060] Unable to simultaneously satisfy constraints.
    Probably at least one of the constraints in the following list is one you don't want. 
    Try this: 
        (1) look at each constraint and try to figure out which you don't expect; 
        (2) find the code that added the unwanted constraint or constraints and fix it. 
(
    ""<NSLayoutConstraint:0x17594000 V:|-(20)-[UIInputSetContainerView:0x176b59d0]   (Names: '|':UITextEffectsWindow:0x17597ab0 )>"",
    ""<NSLayoutConstraint:0x17593e30 'UIInputWindowController-top' V:|-(0)-[UIInputSetContainerView:0x176b59d0]   (Names: '|':UITextEffectsWindow:0x17597ab0 )>""
)

Will attempt to recover by breaking constraint 
<NSLayoutConstraint:0x17594000 V:|-(20)-[UIInputSetContainerView:0x176b59d0]   (Names: '|':UITextEffectsWindow:0x17597ab0 )>

Make a symbolic breakpoint at UIViewAlertForUnsatisfiableConstraints to catch this in the debugger.
The methods in the UIConstraintBasedLayoutDebugging category on UIView listed in <UIKit/UIView.h> may also be helpful.
2016-07-21 18:20:08.017 tf_ios_makefile_example[949:323060] 1
2016-07-21 18:20:16.855 tf_ios_makefile_example[949:323060] Image path: /var/mobile/Containers/Data/Application/3AEB6ED8-B068-45FA-85D3-36FCFFA21DD1/Documents/photos/image.jpg
I ../tensorflow/contrib/ios_examples/simple/RunModelViewController.mm:302] Session created.
I ../tensorflow/contrib/ios_examples/simple/RunModelViewController.mm:305] Graph created.
I ../tensorflow/contrib/ios_examples/simple/RunModelViewController.mm:310] Creating session.
W tensorflow/core/framework/op_def_util.cc:332] Op BatchNormWithGlobalNormalization is deprecated. It will cease to work in GraphDef version 9. Use tf.nn.batch_normalization().
2016-07-21 18:20:25.542 tf_ios_makefile_example[949:323060] Received memory warning.
2016-07-21 18:20:25.653 tf_ios_makefile_example[949:323060] Received memory warning.
2016-07-21 18:20:38.698 tf_ios_makefile_example[949:323060] Received memory warning.
I ../tensorflow/contrib/ios_examples/simple/RunModelViewController.mm:410] Predictions: 259 4.32 n01342269  moneran, moneron
10 3.69 n00141669   check-in
800 3.67 n01601410  great bowerbird, Chlamydera nuchalis
552 3.59 n01531811  redpoll, Carduelis flammea
0 3.58 n00004475    organism, being
```
## Related to
#2883 I encountered the same error related to DecodeJpeg and then followed the fixes suggested there, but I get the same prediction no matter what I point the camera at. Similarly if i work with the ""simple"" project and change the photo being identified I still get the same prediction that in the log output above
"
3445,Where to download updated apks from the jenkin builds,"where to get the artifacts from daily builds?
http://ci.tensorflow.org/job/tensorflow-master-android/
"
3444,Is it possible to import the project int android Studio and compile using NDK?,"I was trying to import the project into android studio and work on it.
Getting lot of compilation issues on jni compilation.
Is it possible to do that?
Any constraints we have ?
"
3443,step_stats.pb.h and types.pb.h missing,"These two files are missing in the repo.
core/framework/step_stats.pb.h
core/framework/types.pb.h

Compilation of tensorflow_jni.cc is failing due to this.
Is it due to any issue?
"
3442,Error malloc(): memory corruption,"Hi All
### Environment info

OS: Linux raspberrypi 4.4.11-v7+ #888 SMP Mon May 23 20:10:33 BST 2016 armv7l GNU/Linux
Device: Raspberry PI 3

Installed version of CUDA and cuDNN: N/A

Tensorflow installed from source: 
git clone --recurse-submodules https://github.com/tensorflow/tensorflow
commit c5983f87f0402f2cb8c627807917ebdf8e4d4bb6
### Steps to reproduce
1.   `make -f tensorflow/contrib/makefile/Makefile HOST_OS=PI TARGET=PI OPTFLAGS=""-Os -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize"" CXX=g++-4.8`
2. `sudo apt-get install -y libjpeg-dev`
3. make -f tensorflow/contrib/pi_examples/label_image/Makefile
   returns:

```
I tensorflow/contrib/pi_examples/label_image/label_image.cc:142] Loaded JPEG: 512x600x3
*** Error in `tensorflow/contrib/pi_examples/label_image/gen/bin/label_image': malloc(): memory corruption: 0x00e94520 ***
Aborted

```

I've tried also
`tensorflow/contrib/pi_examples/label_image/gen/bin/label_image --image=tensorflow/tensorflow/contrib/pi_examples/label_image/data/grace_hopper.jpg
`
Is there a way to understand which line of code caused the memory corruption?
How can I increase the debug level?

Thanks
Giovanni
"
3441,Documentation for 'Adding a new op',"This is a feature request. Currently, I find the documentation for 'Adding an Op' quite minimal. There are a few important questions that remain unanswered:
- How should one use multithreaded CPU code in an operation? Can we use OpenMP? How many threads should an op use? It is hard to find this in the implementations of existing ops, because they are all based on _Eigen_.
- How should a GPU version of the op be written? Should it be a cuda kernel, or the code spawning cuda kernels? Maybe there could be a simple example for both CPU and GPU code not using Eigen.
"
3440,How to modify the seq2seq cost function for padded vectors?,"Tensorflow supports dynamic length sequence by use of the parameter: `sequence_length` while constructing the RNN layer, wherein the model does not learn the sequence after the sequence size = 'sequence_length' i.e, returns zero vector.

However, how can the cost function at https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/seq2seq.py#L890 be modified to encounter the masked sequences, so that cost and perplexity are calculated only on the actual sequences rather than whole padded sequence? 

```
def sequence_loss_by_example(logits, targets, weights, average_across_timesteps=True,  softmax_loss_function=None, name=None):

    if len(targets) != len(logits) or len(weights) != len(logits):
        raise ValueError(""Lengths of logits, weights, and targets must be the same ""
                         ""%d, %d, %d."" % (len(logits), len(weights), len(targets)))
      with ops.op_scope(logits + targets + weights, name,
                        ""sequence_loss_by_example""):
        log_perp_list = []
        for logit, target, weight in zip(logits, targets, weights):
          if softmax_loss_function is None:
            # TODO(irving,ebrevdo): This reshape is needed because
            # sequence_loss_by_example is called with scalars sometimes, which
            # violates our general scalar strictness policy.
            target = array_ops.reshape(target, [-1])
            crossent = nn_ops.sparse_softmax_cross_entropy_with_logits(
                logit, target)
          else:
            crossent = softmax_loss_function(logit, target)
          log_perp_list.append(crossent * weight)
        log_perps = math_ops.add_n(log_perp_list)
        if average_across_timesteps:
          total_size = math_ops.add_n(weights)
          total_size += 1e-12  # Just to avoid division by 0 for all-0 weights.
          log_perps /= total_size
    return log_perps
```
"
3439,"""tensorflow: Input iterator is exhausted"" when passing numpy arrays in validation monitor","I'm not sure if this is a bug or whether I just don't understand the usage of monitors (in which case I apologize for posting here). I'm trying to use a validation monitor by passing my validation set as numpy array.

```
val_monitor = learn.monitors.ValidationMonitor(X_val, Y_val, every_n_steps=100)
reg.fit(X_train, Y_train, steps=1000, batch_size=200, monitors=[val_monitor])
```

(X_val and Y_val are numpy arrays)

The code runs but only the first validation step is done properly, then I get the following message in the logs:
`INFO:tensorflow:Input iterator is exhausted.`

Any help is welcome!
"
3438,Discussion: A possible Profiling method for TensorFlow,"Goals:
1. Get the timing run on CPU & GPU.
2. Get the timing for each OP (run on GPU or CPU) or a serial of OPs.

Identify the performance bottlenecks to do the optimization.

I just review some code for TF, and I find it should be possible to add some profiling code in tensorflow/core or tensorflow/stream_executor.

How about the idea? Any comments?
"
3437,google/protobuf/any.proto: File not found,"### Environment info

Operating System: ubuntu14.04

I have install java8 and the latest version of bazel ([bazel release 0.3.0-2016-07-21 (@2e1dbd7)]) pulled from github. After then, I pulled the tensorflow.igt using the command: git clone --recurse-submodules https://github.com/tensorflow/tensorflow.

Then, I intended to install tensorflow following the steps:
1) Install java8.
2) Install bazel ([bazel release 0.3.0-2016-07-21 (@2e1dbd7)])  pulled from github.
3) git clone --recurse-submodules https://github.com/tensorflow/tensorflow.
4) ./configure (in the root dir of tensorflow, without using google cloud, without configuration of gpu)
5) bazel build -c opt //tensorflow/tools/pip_package:build_pip_package

Unfortunately, error prompted in Step 5:
      "".. tensorflow/tensorflow/tools/pip_package/BUILD:23:1: error loading package 'tensorflow/core': Encountered error while reading extension file 'protobuf.bzl': no such package '@protobuf//': Error cloning repository: https://github.com/google/protobuf: cannot open git-upload-pack caused by https://github.com/google/protobuf: cannot open git-upload-pack caused by sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target caused by PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target caused by unable to find valid certification path to requested target and referenced by '//tensorflow/tools/pip_package:build_pip_package'.
ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted.
INFO: 
Elapsed time: 0.102s""

I have confirmed that git clone can be used normally to pull the code from https://github.com/google/protobuf.

Anyone knows how this problem can be fixed ?
"
3436,serving tretrained inception model with different number of lables to initial training,"I'm struggling to serve a 'fine tuned' retrained inceptions model. After retraining on just two classes/labels. I get an error when trying to export to model:

File ""/home/ubuntu/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/org_tensorflow/tensorflow/python/clie nt/session.py"", line 743, in _do_call raise type(e)(node_def, op, message) tensorflow.python.framework.errors.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [1001] rhs s hape= [3] [[Node: save/Assign_30 = Assign[T=DT_FLOAT, _class=[""loc:@logits/logits/biases""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/cpu:0""](logits/logits/biases, save/restore_slice_30)]] Caused by op u'save/Assign_30', defined at:
"
3435,Segmentation fault in Diagnostician on MacOS,"I get segmentation fault on MacOS on creating new session if GPU is unavailable (ie, through `export CUDA_VISIBLE_DEVICES=`)

It's due to this [line](https://github.com/tensorflow/tensorflow/blob/d42facc3cc9611f0c9722c81551a7404a0bd3f6b/tensorflow/stream_executor/cuda/cuda_diagnostics.cc#L319)

```
    const char * version = CFStringGetCStringPtr((CFStringRef)CFDictionaryGetValue(cuda_driver_info,   kCFBundleVersionKey), kCFStringEncodingUTF8);
    CFRelease(kext_infos);
    return StringToDriverVersion(version);

```

`version` is a NULL, which causes SEGSERV during conversion to string. 

Documentation for `CFStringGetCStringPtr` says that [one should check for NULL](https://developer.apple.com/library/mac/documentation/CoreFoundation/Conceptual/CFStrings/Articles/AccessingContents.html#//apple_ref/doc/uid/20001184-100980-TPXREF112) and call `CFStringGetCString` if so

```
bazel build -c dbg --config=cuda //tensorflow/tools/pip_package:build_pip_package
export CUDA_VISIBLE_DEVICES=
cat > simple.py
import tensorflow as tf
sess = tf.Session()
^D

lldb python
(lldb) r simple.py

Process 48123 stopped
* thread #1: tid = 0x37a6a8, 0x00007fff9b24d152 libsystem_c.dylib`strlen + 18, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x0)
    frame #0: 0x00007fff9b24d152 libsystem_c.dylib`strlen + 18
libsystem_c.dylib`strlen:
->  0x7fff9b24d152 <+18>: pcmpeqb (%rdi), %xmm0
    0x7fff9b24d156 <+22>: pmovmskb %xmm0, %esi
    0x7fff9b24d15a <+26>: andq   $0xf, %rcx
    0x7fff9b24d15e <+30>: orq    $-0x1, %rax

(lldb) up
up
frame #1: 0x00000001036ecb05 _pywrap_tensorflow.so`std::__1::char_traits<char>::length(__s=0x0000000000000000) + 21 at string:640
   637  
   638      static inline int compare(const char_type* __s1, const char_type* __s2, size_t __n)
   639          {return __n == 0 ? 0 : memcmp(__s1, __s2, __n);}
-> 640      static inline size_t length(const char_type* __s) {return strlen(__s);}
   641      static inline const char_type* find(const char_type* __s, size_t __n, const char_type& __a)
   642          {return __n == 0 ? NULL : (const char_type*) memchr(__s, to_int_type(__a), __n);}
   643      static inline char_type* move(char_type* __s1, const char_type* __s2, size_t __n)
(lldb) up
up
frame #2: 0x0000000107725ac5 _pywrap_tensorflow.so`perftools::gputools::cuda::Diagnostician::FindKernelDriverVersion() [inlined] std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::basic_string(this="""", __s=0x0000000000000000) + 81 at string:2005
   2002 basic_string<_CharT, _Traits, _Allocator>::basic_string(const value_type* __s)
   2003 {
   2004     _LIBCPP_ASSERT(__s != nullptr, ""basic_string(const char*) detected nullptr"");
-> 2005     __init(__s, traits_type::length(__s));
   2006 #if _LIBCPP_DEBUG_LEVEL >= 2
   2007     __get_db()->__insert_c(this);
   2008 #endif
(lldb) up
up
frame #3: 0x0000000107725a74 _pywrap_tensorflow.so`perftools::gputools::cuda::Diagnostician::FindKernelDriverVersion() [inlined] std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::basic_string(this="""", __s=0x0000000000000000) + 21 at string:2003
   2000 template <class _CharT, class _Traits, class _Allocator>
   2001 inline _LIBCPP_INLINE_VISIBILITY
   2002 basic_string<_CharT, _Traits, _Allocator>::basic_string(const value_type* __s)
-> 2003 {
   2004     _LIBCPP_ASSERT(__s != nullptr, ""basic_string(const char*) detected nullptr"");
   2005     __init(__s, traits_type::length(__s));
   2006 #if _LIBCPP_DEBUG_LEVEL >= 2
(lldb) up
up
frame #4: 0x0000000107725a5f _pywrap_tensorflow.so`perftools::gputools::cuda::Diagnostician::FindKernelDriverVersion() + 287 at cuda_diagnostics.cc:319
   316      // in kCFBundleVersionKey as is returned by cuDriverGetVersion
   317      const char * version = CFStringGetCStringPtr((CFStringRef)CFDictionaryGetValue(cuda_driver_info, kCFBundleVersionKey), kCFStringEncodingUTF8);
   318      CFRelease(kext_infos);
-> 319      return StringToDriverVersion(version);
(lldb) frame variable --no-args
frame variable --no-args
(CFStringRef [1]) kext_ids = ([0] = 0x0000000108767208)
(CFArrayRef) kext_id_query = 0x000000013e1f2190
(CFDictionaryRef) kext_infos = 0x000000013e1f21d0
(CFDictionaryRef) cuda_driver_info = 0x000000013f322700
(tensorflow::Status) status = {
  state_ = 0x000000011ec8000a
}
(const char *) version = 0x0000000000000000

```

related #2980 
"
3432,missing 'train' module,"trying to follow this document: https://www.tensorflow.org/versions/r0.9/how_tos/distributed/index.html

can't import tf.train because train doesn't exist.

i looked through the repo; it appears that's a correct appraisal. TF does not have a train package.

??
"
3431,"Getting ""missing dependency declarations"" with bazel 0.3.0","I just upgraded Bazel/synced and now I'm getting same errors as in #1157 

```
bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer

ERROR: /home/yaroslavvb/tensorflow.git/tensorflow/tensorflow/core/kernels/BUILD:1080:1: undeclared inclusion(s) in rule '//tensorflow/core/kernels:cwise_op_gpu':
this rule is missing dependency declarations for the following files included by 'tensorflow/core/kernels/cwise_op_gpu_floor.cu.cc':
  '/usr/local/cuda-8.0/include/cuda_runtime.h'
  '/usr/local/cuda-8.0/include/host_config.h'
  '/usr/local/cuda-8.0/include/builtin_types.h'
  '/usr/local/cuda-8.0/include/device_types.h'
  '/usr/local/cuda-8.0/include/host_defines.h'
  '/usr/local/cuda-8.0/include/driver_types.h'
  '/usr/local/cuda-8.0/include/surface_types.h'
  '/usr/local/cuda-8.0/include/texture_types.h'
...
```
"
3430,Ignoring gpu device with Cuda multiprocessor count: 7.,"I am unable to run TF on a GPU, despite the fact that I have 2 CUDA-enabled K4200 NVIDIA QUATTRO (Compute Capability 3.0)
### Environment info

Operating System: linux 14.04 x64

Installed version of CUDA and cuDNN: 
1. CUDA 7.5
2. cuDNN 4

If installed from binary pip package, provide:
1. Ubuntu/Linux 64-bit, GPU enabled, Python 2.7
2. TF v0.9.0
### Steps to reproduce
1. Run IPython Notebook
2. Run a tensorflow session (I was doing Udacity DL course)
3. In IPython log, observe:

I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:924] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:
name: Quadro K4200
major: 3 minor: 0 memoryClockRate (GHz) 0.784
pciBusID 0000:03:00.0
Total memory: 4.00GiB
Free memory: 3.96GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x3b717e0
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:924] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties:
name: Quadro K4200
major: 3 minor: 0 memoryClockRate (GHz) 0.784
pciBusID 0000:04:00.0
Total memory: 4.00GiB
Free memory: 3.86GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 1
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y Y
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 1:   Y Y
I tensorflow/core/common_runtime/gpu/gpu_device.cc:793] Ignoring gpu device (device: 0, name: Quadro K4200, pci bus id: 0000:03:00.0) with Cuda multiprocessor count: 7. The minimum required count is 8. You can adjust this requirement with the env var TF_MIN_GPU_MULTIPROCESSOR_COUNT.
I tensorflow/core/common_runtime/gpu/gpu_device.cc:793] Ignoring gpu device (device: 1, name: Quadro K4200, pci bus id: 0000:04:00.0) with Cuda multiprocessor count: 7. The minimum required count is 8. You can adjust this requirement with the env var TF_MIN_GPU_MULTIPROCESSOR_COUNT.
### What have you tried?
1. Setting TF_MIN_GPU_MULTIPROCESSOR_COUNT to 4, both locally and system-wide
### Logs or other output that would be helpful

echo $TF_MIN_GPU_MULTIPROCESSOR_COUNT
4

Am I missing something? Setting the environment variable seems to have no effect.
"
3429,[Python][Quantized Inference] 'Zero is not representable' when doing inference from quantized const graph def,"I used the checkpoint file and the graph def file to generate the const graph def file using the freeze_graph script. Then I used the quantize_graph tool to generate a quantized model. The output file sizes from these steps seem reasonable. But I failed to run a inference using the generated quantized model.

Tried both tensorflow 0.8.0 and 0.9.0, they both failed but with different errors though. For 0.80, it will output:

W tensorflow/contrib/quantization/kernels/quantized_conv_ops.cc:201] Zero is not representable in the quantized range used by the input. This means QuantizedConv2d has to fall back to a slow implementation, since the border of zero values can't be represented easily. You should try to construct graphs that avoid this situation.""

For 0.9.0, it wouldn't load the lib with:
_quantized_kernels = tf.load_op_library(PATH_TO_KERNAL_OS)
_quantized_ops = tf.load_op_library(PATH_TO_OPS_OS)
I got some signature errors.
### Environment info

Operating System:
Ubuntu 14.04

If installed from binary pip package, provide:
Installed the 0.8.0, but tried with 0.9.0 as well.
### Steps to reproduce
1. Generate a checkpoint file and graph def file
2. Using freeze_graph and quantize_graph to generate a quantized const graph def binary file
3. Build the quantized_kernels.so and quantized_ops.so
4. tf.load_op_library() to load the two libraries. version 0.9.0 will fail at this step
5. Extract the input and output node names, feed the input properly and run the session 
6. version 0.8.0 will fail at this step with the following errors:

W tensorflow/contrib/quantization/kernels/quantized_conv_ops.cc:201] Zero is not representable in the quantized range used by the input. This means QuantizedConv2d has to fall back to a slow implementation, since the border of zero values can't be represented easily. You should try to construct graphs that avoid this situation.
W tensorflow/contrib/quantization/kernels/quantized_conv_ops.cc:201] Zero is not representable in the quantized range used by the input. This means QuantizedConv2d has to fall back to a slow implementation, since the border of zero values can't be represented easily. You should try to construct graphs that avoid this situation.
terminate called after throwing an instance of 'std::bad_alloc'
  what():  std::bad_alloc
Aborted (core dumped)
### What have you tried?

Described above
### Logs or other output that would be helpful

Added above.
"
3427,Failing dependency downloads in latest,"### Environment info

Operating System: OSX El Capitan
Latest pull on 20th July 2016: c5983f87f0402f2cb8c627807917ebdf8e4d4bb6

Run: tensorflow/contrib/makefile/download_dependencies.sh

Failing output:
- DOWNLOADS_DIR=tensorflow/contrib/makefile/downloads
- mkdir tensorflow/contrib/makefile/downloads
  ++ cat eigen.BUILD
  ++ grep archive_dir
  ++ head -1
  ++ cut -f3 -d-
  ++ cut -f1 '-d""'
- EIGEN_HASH=
- curl https://bitbucket.org/eigen/eigen/get/.tar.gz -o /tmp/eigen-.tar.gz
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  100 26011  100 26011    0     0  34718      0 --:--:-- --:--:-- --:--:-- 34727
- tar xzf /tmp/eigen-.tar.gz -C tensorflow/contrib/makefile/downloads
  tar: Unrecognized archive format
  tar: Error exit delayed from previous errors.
"
3426,How to get the last timestep of the output of an RNN?,"Just a general question which might also help others, namely what is the correct way to extract the last timestep of the output of an RNN. Is it as simple as 

`outputs, state = tf.nn.dynamic_rnn(cell=dropout_cell, inputs=outputs1, initial_state=initial_state, sequence_length=s)`
`last = tf.gather(outputs, int(outputs.get_shape()[0]) - 1)`

Or should i transpose the output before performing gather, as per this example

`outputs, state = tf.nn.dynamic_rnn(cell=dropout_cell, inputs=outputs1, initial_state=initial_state, sequence_length=s)`
`outputs = tf.transpose(outputs, [1, 0, 2])`
`last = tf.gather(outputs, int(outputs.get_shape()[0]) - 1)`

Thank you
"
3422,CUDA_ERROR_ILLEGAL_ADDRESS on GTX 1080,"On training a model on cifar 10 I am getting following error after couple of epochs.

 tensorflow/stream_executor/cuda/cuda_driver.cc:1140] could not synchronize on CUDA context: CUDA_ERROR_ILLEGAL_ADDRESS :: No stack trace availablech: 034 | loss: 0.21259 - acc: 0.9223 -- iter: 08128/50000
F tensorflow/core/common_runtime/gpu/gpu_util.cc:370] GPU sync failed
Aborted (core dumped)
### Environment info

Operating System:
Ubuntu 14.04
4.2.0-27-generic #32~14.04.1-Ubuntu SMP Fri Jan 22 15:32:26 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
-rw-r--r-- 1 root root   560184 Jul 18 17:20 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Jul 18 17:20 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root       19 Jul 18 17:20 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.27
-rwxr-xr-x 1 root root   394472 Jul 18 17:20 /usr/local/cuda/lib64/libcudart.so.8.0.27
-rw-r--r-- 1 root root   737516 Jul 18 17:20 /usr/local/cuda/lib64/libcudart_static.a
-rwxr-xr-x 1 root root 78065952 Jul 18 18:03 /usr/local/cuda/lib64/libcudnn.so
-rwxr-xr-x 1 root root 78065952 Jul 18 18:03 /usr/local/cuda/lib64/libcudnn.so.5
-rwxr-xr-x 1 root root 78065952 Jul 18 18:03 /usr/local/cuda/lib64/libcudnn.so.5.0.5
-rw-r--r-- 1 root root 68709594 Jul 18 18:03 /usr/local/cuda/lib64/libcudnn_static.a

If installed from sources, provide the commit hash:
commit a3f61c1d5c76339e6c9655dac426bb3822659772
### Steps to reproduce
1. I have a model to train on cifar10,  which mainly consists of convolutions, PReLU and data augmentation.andaround r epoch  34 it get the above error. 
   I have similar model running  simultaneously on  same GPU which run fine. Each of the model roughly
   use 50% of GTX 1080 memory(TOTAL 8GB)
### What have you tried?
1. I tried to to run my model twice and getting same error.
"
3421,Scope Reusability in tf.nn.dynamic_rnn,"I am getting this error when I try to run the code for RNN:

ValueError: Variable RNN/MultiRNNCell/Cell0/BasicLSTMCell/Linear/Matrix does not exist, disallowed. Did you mean to set reuse=None in VarScope?

Here is a snippet of my code for RNN:

lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(self._num_hidden, forget_bias=0.0)
cell = tf.nn.rnn_cell.MultiRNNCell([lstm_cell] \* self._num_layers)
self._initial_state = cell.zero_state(batch_size, tf.float32)

inputs=[tf.reshape(data_,[batch_size,num_cat]) for data_ in tf.split(0,max_length,tf.transpose(data,[1,0,2]))]
output,_=tf.nn.dynamic_rnn(cell,inputs,initial_state=self._initial_state,sequence_length=self.length)

The error seems to be in line:
output,_=tf.nn.dynamic_rnn(cell,inputs,initial_state=self._initial_state,sequence_length=self.length)

My input is a tensor with dimensions : batch_size x max_ seq_length x feature_vector_size
I am reshaping it to a list of dimensions : batch_size x feature_vector_size

I am assuming that the reusability of scope is handled internally by tf.nn.dynamic_rnn function. Any idea why this would happen? What could be the solution?
"
3420,Running Bidirectional RNN cells on parallel,"is there any method to run Bidirectional RNNs on parallel as they should (they have no dependency on each other)
I noticed that stacking 2 LSTM layer has the exact same performance as bidirection LSTM (BLSTM)
even 4 stacked LSTM has same performance as 2 parallel BLSTMs (which simply means  that TF runtime doesn't parallelize BLSTMs at all, I also notice the same behavior on both the CPU and the GPU)

Note: I am using small cells that are trivial to fit simultaneously

Thanks,
"
3418,cannot install tensorflow from source,"Hi, trying to build tensorflow from source. Getting the error message below -

""/home/lec/Downloads/tensorflow/tensorflow/tools/proto_text/BUILD:31:1: Linking of rule '//tensorflow/tools/proto_text:gen_proto_text_functions' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -o bazel-out/host/bin/tensorflow/tools/proto_text/gen_proto_text_functions ... (remaining 31 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1""
"
3413,tutorial image resolution ,"Hi,
is there a higher image resolution of this?

https://www.tensorflow.org/images/tensors_flowing.gif

Thank you, 
"
3411,Building error: ptxas fatal   : Internal error: writing file ERROR: /disk1/caina2/tensorflow/tensorflow/core/kernels/BUILD:1509:1: output 'tensorflow/core/kernels/_objs/depth_space_ops_gpu/tensorflow/core/kernels/depthtospace_op_gpu.cu.pic.o' was not created.,"when build_pip_package, ending with 

ptxas fatal   : Internal error: writing file
ERROR: /disk1/caina2/tensorflow/tensorflow/core/kernels/BUILD:1509:1: output 'tensorflow/core/kernels/_objs/depth_space_ops_gpu/tensorflow/core/kernels/depthtospace_op_gpu.cu.pic.o' was not created.

Does anyone have the same problem?
### Environment info

Operating System:
centos 6.2
glibc 2.23
Installed version of CUDA and cuDNN: 
cuda 7.5
libcudnn.so.5.0.4
bazel-0.3.0
install from source
### What have you tried?

/disk1/caina2/bazel-0.3.0/output/bazel build -c opt --config=cuda --verbose_failures //tensorflow/tools/pip_package:build_pip_package
### Logs or other output that would be helpful

INFO: From Compiling tensorflow/core/kernels/depthtospace_op_gpu.cu.cc:
nvcc warning : option '--relaxed-constexpr' has been deprecated and replaced by option '--expt-relaxed-constexpr'.
In file included from third_party/gpus/cuda/include/host_config.h:161:0,
                 from third_party/gpus/cuda/include/cuda_runtime.h:76,
                 from <command-line>:0:
/usr/include/features.h:331:4: warning: #warning _FORTIFY_SOURCE requires compiling with optimization (-O) [-Wcpp]
 #  warning _FORTIFY_SOURCE requires compiling with optimization (-O)
    ^
In file included from third_party/gpus/cuda/include/host_config.h:161:0,
                 from third_party/gpus/cuda/include/cuda_runtime.h:76,
                 from <command-line>:0:
/usr/include/features.h:331:4: warning: #warning _FORTIFY_SOURCE requires compiling with optimization (-O) [-Wcpp]
 #  warning _FORTIFY_SOURCE requires compiling with optimization (-O)
    ^
In file included from third_party/gpus/cuda/include/host_config.h:161:0,
                 from third_party/gpus/cuda/include/cuda_runtime.h:76,
                 from <command-line>:0:
/usr/include/features.h:331:4: warning: #warning _FORTIFY_SOURCE requires compiling with optimization (-O) [-Wcpp]
 #  warning _FORTIFY_SOURCE requires compiling with optimization (-O)
    ^
nvcc warning : option '--relaxed-constexpr' has been deprecated and replaced by option '--expt-relaxed-constexpr'.
ptxas fatal   : Internal error: writing file
ERROR: /disk1/caina2/tensorflow/tensorflow/core/kernels/BUILD:1509:1: output 'tensorflow/core/kernels/_objs/depth_space_ops_gpu/tensorflow/core/kernels/depthtospace_op_gpu.cu.pic.o' was not created.
ERROR: /disk1/caina2/tensorflow/tensorflow/core/kernels/BUILD:1509:1: not all outputs were created.
ERROR: /disk1/caina2/tensorflow/tensorflow/core/kernels/BUILD:1509:1: output 'tensorflow/core/kernels/_objs/depth_space_ops_gpu/tensorflow/core/kernels/spacetodepth_op_gpu.cu.pic.o' was not created.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 242.863s, Critical Path: 236.90s
"
3410,Histogramme,"Hi, 
This is not a problem but rather a question about the quantile ""histogram"". I see that Tensorflow can plot almost everything (W, dW, b, db,...).

But what is in it actually ? Knowing that b is a vector, W is a matrix. I assumed that Tensorflow has calculated the norm (L2 et Frobenius) of these tensors to view their evolution through time, right ?

Of course, a probability density function is more than welcome than just a quantile region to treat multimodal, but then, how we can view large multidimensional variables in just a unique graphic ?

Many thanks,
Hoa
"
3408,How To Image Retraining : ImportError: No module named mock,"### Environment info

Operating System:
cat /proc/version
Linux version 4.4.0-31-generic (buildd@lgw01-16) (gcc version 5.3.1 20160413 (Ubuntu 5.3.1-14ubuntu2.1) ) #50-Ubuntu SMP Wed Jul 13 00:07:12 UTC 2016
1. Which pip package you installed.
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   0.9.0
### Steps to reproduce
1. Following this tutorial : https://www.tensorflow.org/versions/r0.9/how_tos/image_retraining/index.html
2. Executing this command after having completed the flower images download : (tensorflow) paddlescoot@paddlescoot-Satellite-P870:~/tensorflow_source/tensorflow$ bazel build tensorflow/examples/image_retraining:retrain
3. See terminal output text [file here for details of error.](https://drive.google.com/open?id=0B0Oci8Q1NdEuUDJ4R2FHTkYtXzQ)
### What have you tried?
1. Searched for similar issues.
"
3407,//util/python:python_headers: 'python_include' resolves to 'util/python/python_include' not in 'third_party',"I am installing TensorFlow on **Unbutu 12.04** with source code. I can build `bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu` successfully, but where i create pip package, i get the warnning:

WARNING: /root/.cache/bazel/_bazel_root/f23957347b508b087abaf4db43031df3/external/protobuf/WORKSPACE:1: Workspace name in /root/.cache/bazel/_bazel_root/f23957347b508b087abaf4db43031df3/external/protobuf/WORKSPACE (@__main__) does not match the name given in the repository's definition (@protobuf); this will cause a build error in future versions.
WARNING: /root/.cache/bazel/_bazel_root/f23957347b508b087abaf4db43031df3/external/re2/WORKSPACE:1: Workspace name in /root/.cache/bazel/_bazel_root/f23957347b508b087abaf4db43031df3/external/re2/WORKSPACE (@__main__) does not match the name given in the repository's definition (@re2); this will cause a build error in future versions.
WARNING: /root/.cache/bazel/_bazel_root/f23957347b508b087abaf4db43031df3/external/highwayhash/WORKSPACE:1: Workspace name in /root/.cache/bazel/_bazel_root/f23957347b508b087abaf4db43031df3/external/highwayhash/WORKSPACE (@__main__) does not match the name given in the repository's definition (@highwayhash); this will cause a build error in future versions.
WARNING: /data1/web/soft/tensorflow/tensorflow/tensorflow/util/python/BUILD:11:16: in includes attribute of cc_library rule //util/python:python_headers: 'python_include' resolves to 'util/python/python_include' not in 'third_party'. This will be an error in the future.

I build failed with error:

/tensorflow/tensorflow/tensorflow/python/BUILD:87:1: C++ compilation of rule '//tensorflow/python:py_func_lib' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object ... (remaining 121 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
tensorflow/python/lib/core/py_func.cc: In function 'tensorflow::Status tensorflow::{anonymous}::ConvertNdarrayToTensor(PyObject_, tensorflow::Tensor_)':
tensorflow/python/lib/core/py_func.cc:164:37: error: 'PyArray_SHAPE' was not declared in this scope
     shape.AddDim(PyArray_SHAPE(input)[i]);
                                     ^
Target //tensorflow/tools/pip_package:build_pip_package failed to build

I have run **./configure** like this:

Please specify the location of python. [Default is /usr/bin/python]: 
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N] n
No Google Cloud Platform support will be enabled for TensorFlow
Do you wish to build TensorFlow with GPU support? [y/N] y
GPU support will be enabled for TensorFlow
Please specify which gcc nvcc should use as the host compiler. [Default is /usr/bin/gcc]: /usr/bin/gcc-4.9
Please specify the Cuda SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 7.0
Please specify the location where CUDA 7.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 
Please specify the Cudnn version you want to use. [Leave empty to use system default]: 7.0
Please specify the location where cuDNN 7.0 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 
Please specify a list of comma-separated Cuda compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size.
[Default is: ""3.5,5.2""]: 
Setting up Cuda include
Setting up Cuda lib64
Setting up Cuda bin
Setting up Cuda nvvm
Setting up CUPTI include
Setting up CUPTI lib64
Configuration finished

I'm not familiar with bazel, is there any one who can help?
"
3406,How to debug tensorflow swig shared library,"I tired PyDev + CDT, and GDB, so Python file is easy to debugging . But swig generations *.so file can't debug into *.cc file side . 

Could anybody tell me HOW TO debug swig?
"
3404,"Can't create placeholder with partially defined shape e.g. (-1, 10)","I get `ValueError: Dimension -1 must be >= 0`
"
3403,A link in tensorflow's website is ineffective,"The link in **Download [the tutorial code](https://github.com/tensorflow/tensorflow/tree/r0.9/tensorflow/examples/learn/wide_n_deep_tutorial.py).**  from [TensorFlow Linear Model Tutorial](https://www.tensorflow.org/versions/master/tutorials/wide/index.html) failed.

Is the source code of the website not open? I didn't find it. 
"
3402,"Given one input tensor, why tf.nn.max_pool generate two tensors?","  with tf.name_scope('layer3'):
    conv3_weights = tf.Variable(tf.truncated_normal(
      [3, 3, 128, 256], stddev=0.1))
    variable_summaries(conv3_weights, 'layer3' + '/weights')
    conv3_biases = tf.Variable(tf.constant(0.1, shape=[256]))
    variable_summaries(conv3_biases, 'layer3' + '/biases')
    conv3 = tf.nn.conv2d(pool2,
      conv3_weights,
      strides=[1, 1, 1, 1],
      padding='SAME')
    tf.histogram_summary('layer3'+'/pre_activations', conv3)
    relu3 = tf.nn.relu(tf.nn.bias_add(conv3, conv3_biases))
    tf.histogram_summary('layer3'+'/activations', relu3)
    print relu3.get_shape()
    pool3 = tf.nn.max_pool(relu3,
      ksize=[1, 2, 2, 1],
      strides=[1, 2, 2, 1],
      padding='SAME')
    tf.histogram_summary('layer3'+'/pool', pool3)
    print pool3.get_shape()

When using TensorBoard to visualize the graph, I find the output of the layer3 are two tensors. I am puzzled why does it happen? Thank you very much! 
![1](https://cloud.githubusercontent.com/assets/20062851/16974093/b96aee78-4e6b-11e6-97c5-c266b4dc28d8.jpg)
"
3401,Run a TensorFlow demo model : IOError: CRC check failed,"### Environment info

Operating System:
(tensorflow) paddlescoot@paddlescoot-Satellite-P870:~$ cat /proc/version
Linux version 4.4.0-31-generic (buildd@lgw01-16) (gcc version 5.3.1 20160413 (Ubuntu 5.3.1-14ubuntu2.1) ) #50-Ubuntu SMP Wed Jul 13 00:07:12 UTC 2016

If installed from binary pip package, provide:
1. Which pip package you installed.
   Follow python 2.7 virtualenv installtion notes - https://www.tensorflow.org/versions/r0.9/get_started/os_setup.html#virtualenv-installation
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   0.9.0
### Steps to reproduce
1. Follow Test notes here - https://www.tensorflow.org/versions/r0.9/get_started/os_setup.html#test-the-tensorflow-installation
2. When you get to the last step, the following error appears : 
   (tensorflow) paddlescoot@paddlescoot-Satellite-P870:~$ python /home/paddlescoot/tensorflow/local/lib/python2.7/site-packages/tensorflow/models/image/mnist/convolutional.py
   Extracting data/train-images-idx3-ubyte.gz
   Traceback (most recent call last):
   File ""/home/paddlescoot/tensorflow/local/lib/python2.7/site-packages/tensorflow/models/image/mnist/convolutional.py"", line 316, in <module>
     tf.app.run()
   File ""/home/paddlescoot/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 30, in run
     sys.exit(main(sys.argv))
   File ""/home/paddlescoot/tensorflow/local/lib/python2.7/site-packages/tensorflow/models/image/mnist/convolutional.py"", line 128, in main
     train_data = extract_data(train_data_filename, 60000)
   File ""/home/paddlescoot/tensorflow/local/lib/python2.7/site-packages/tensorflow/models/image/mnist/convolutional.py"", line 75, in extract_data
     buf = bytestream.read(IMAGE_SIZE \* IMAGE_SIZE \* num_images)
   File ""/usr/lib/python2.7/gzip.py"", line 268, in read
     self._read(readsize)
   File ""/usr/lib/python2.7/gzip.py"", line 315, in _read
     self._read_eof()
   File ""/usr/lib/python2.7/gzip.py"", line 354, in _read_eof
     hex(self.crc)))
   IOError: CRC check failed 0xb3e5d2f6 != 0x255cc2beL
### What have you tried?
1. Searching similar issues.
"
3400,new stacks,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System:

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from sources, provide the commit hash:
### Steps to reproduce

1.
2.
3.
### What have you tried?

1.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
3397,Can't place tf.nn.moments() on GPU when first dimension is None,"At first this sounds like #2508, but this was closed and apparently fixed and the error message is also different. So it might be more related to #139, and possibly to the comment of @mrry on `tf.mean` on GPUs. The example below works with cpu device context (or no explicit device placement at all). Is this a missing feature or should one not expect that this is fixable?
### Environment info

Operating System:
Ubuntu 15.10

Installed version of CUDA and cuDNN: 
CUDA7.5/cuDNN4.0.4

(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```
-rw-r--r-- 1 root root 189170 Jan  1 23:25 /usr/local/cuda/lib/libcudadevrt.a
lrwxrwxrwx 1 root root     16 Jan  1 23:25 /usr/local/cuda/lib/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root     19 Jan  1 23:25 /usr/local/cuda/lib/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root 311596 Jan  1 23:25 /usr/local/cuda/lib/libcudart.so.7.5.18
-rw-r--r-- 1 root root 558020 Jan  1 23:25 /usr/local/cuda/lib/libcudart_static.a
```

If installed from sources, provide the commit hash: [fc91629](https://github.com/tensorflow/tensorflow/commit/fc9162975e52978d3af38549b570cc3cc5f0ab66)
### Steps to reproduce

```
import tensorflow as tf
import numpy as np

with tf.device(""/gpu:0""):
    x = tf.placeholder(tf.float32, shape=[None, 5])
    mean, var = tf.nn.moments(x, axes=[0])
sess = tf.Session()
sess.run([mean, var], feed_dict={x:np.random.randn(10, 5)})
```

results in

```
E tensorflow/core/client/tensor_c_api.cc:485] Cannot assign a device to node 'moments/sufficient_statistics/SparseToDense': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
     [[Node: moments/sufficient_statistics/SparseToDense = SparseToDense[T=DT_BOOL, Tindices=DT_INT32, validate_indices=true, _device=""/device:GPU:0""](moments/sufficient_statistics/SparseToDense/sparse_indices, moments/sufficient_statistics/Shape_1, moments/sufficient_statistics/SparseToDense/sparse_values, moments/sufficient_statistics/SparseToDense/default_value)]]
```
### What have you tried?
1. Setting `shape=[10, 5]` fixes the above problem (to be expected).
2. Setting device context to `with tf.device(""/cpu:0""):` works with `None` shape info, too.
"
3396,Numpy reshape and tf.reshape give different results in MNIST classification,"### Environment info

Operating System:

```
Linux anjum-Studio-XPS-1340 4.4.0-31-generic #50-Ubuntu SMP Wed Jul 13 00:07:12 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux
```

Installed version of CUDA and cuDNN: 
Using CPU only version

If installed from binary pip package, provide:
1. Which pip package you installed: https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.9.0-cp35-cp35m-linux_x86_64.whl
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.: 
   `0.9.0`
### Steps to reproduce
1. Use the example from http://terrytangyuan.github.io/2016/06/09/scikit-flow-v09/#customized-model but edit to use the MNIST dataset instead.
2. Flatten the MNIST images from 8x8 to 1x64 using `numpy.reshape` before passing the features to the model. This gives around 95% accuracy
3. Flatten the MNIST images from 8x8 to 1x64 using `tf.reshape` within the model. This gives around 93% accuracy
### What have you tried?

The feature tensors within the two models are the same shape:
Numpy.reshape: `Tensor(""input:0"", shape=(?, 64), dtype=float32)`
tf.reshape: `Tensor(""Reshape:0"", shape=(?, 64), dtype=float32)`
### Logs or other output that would be helpful

Gist recreating the issue is here: https://gist.github.com/Anjum48/ca0a1f597a70b6b50b37fed2032a91d5
"
3394,logdir not recognized as a keyword argument when fitting a DNNRegressor,"Hi,
I got the following error when trying to fit a DNNRegressor with this code:

```
reg=learn.DNNRegressor(hidden_units=[200,20],activation_fn=tf.tanh)
reg.fit(X_train,Y_train,steps=1000,logdir='/tmp/')
```

TypeError: fit() got an unexpected keyword argument 'logdir'

Was the option to monitor a regressor not implemented yet?
Thanks,
David
"
3393,build_pip_package failed to build without GPU option,"### Environment info

Operating System: Ubuntu 16.04 LTS
GCC Version: 5.4.0
python 3.5.2
Installed version of CUDA and cuDNN:  None

If installed from sources, provide the commit hash:
fc9162975e52978d3af38549b570cc3cc5f0ab66
### Steps to reproduce
1. build bazel from sources
2. git clone --recurse-submodules https://github.com/tensorflow/tensorflow
3. ./configure
4. bazel build -c opt //tensorflow/tools/pip_package:build_pip_package --verbose_failures
### What have you tried?
1. rebuild bazel and rebuild tensorflow
### Logs or other output that would be helpful

> INFO: Waiting for response from Bazel server (pid 17346)...
> WARNING: /home/jxypoi/Documents/tensorflow/util/python/BUILD:11:16: in includes attribute of cc_library rule //util/python:python_headers: 'python_include' resolves to 'util/python/python_include' not in 'third_party'. This will be an error in the future.
> WARNING: /home/jxypoi/.cache/bazel/_bazel_jxypoi/d296672d8345626b0b5383fe0f5b61e2/external/boringssl_git/WORKSPACE:1: Workspace name in /home/jxypoi/.cache/bazel/_bazel_jxypoi/d296672d8345626b0b5383fe0f5b61e2/external/boringssl_git/WORKSPACE (@boringssl) does not match the name given in the repository's definition (@boringssl_git); this will cause a build error in future versions.
> INFO: Found 1 target...
> ERROR: /home/jxypoi/Documents/tensorflow/tensorflow/core/kernels/BUILD:1080:1: C++ compilation of rule '//tensorflow/core/kernels:sparse_matmul_op' failed: gcc failed: error executing command 
>   (cd /home/jxypoi/.cache/bazel/_bazel_jxypoi/d296672d8345626b0b5383fe0f5b61e2/execroot/tensorflow && \
>   exec env - \
>     PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin \
>   /usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wl,-z,-relro,-z,now -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/local-py3-opt/bin/tensorflow/core/kernels/_objs/sparse_matmul_op/tensorflow/core/kernels/sparse_matmul_op.pic.d '-frandom-seed=bazel-out/local-py3-opt/bin/tensorflow/core/kernels/_objs/sparse_matmul_op/tensorflow/core/kernels/sparse_matmul_op.pic.o' -fPIC -DHAVE_CONFIG_H -iquote . -iquote bazel-out/local-py3-opt/genfiles -iquote external/protobuf -iquote bazel-out/local-py3-opt/genfiles/external/protobuf -iquote external/bazel_tools -iquote bazel-out/local-py3-opt/genfiles/external/bazel_tools -iquote external/farmhash_archive -iquote bazel-out/local-py3-opt/genfiles/external/farmhash_archive -iquote external/jpeg_archive -iquote bazel-out/local-py3-opt/genfiles/external/jpeg_archive -iquote external/png_archive -iquote bazel-out/local-py3-opt/genfiles/external/png_archive -iquote external/gif_archive -iquote bazel-out/local-py3-opt/genfiles/external/gif_archive -iquote external/highwayhash -iquote bazel-out/local-py3-opt/genfiles/external/highwayhash -iquote external/re2 -iquote bazel-out/local-py3-opt/genfiles/external/re2 -iquote external/eigen_archive -iquote bazel-out/local-py3-opt/genfiles/external/eigen_archive -iquote external/zlib_archive -iquote bazel-out/local-py3-opt/genfiles/external/zlib_archive -iquote external/boringssl_git -iquote bazel-out/local-py3-opt/genfiles/external/boringssl_git -iquote external/jsoncpp_git -iquote bazel-out/local-py3-opt/genfiles/external/jsoncpp_git -isystem external/protobuf/src -isystem bazel-out/local-py3-opt/genfiles/external/protobuf/src -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/farmhash_archive/farmhash-34c13ddfab0e35422f4c3979f360635a8c050260 -isystem bazel-out/local-py3-opt/genfiles/external/farmhash_archive/farmhash-34c13ddfab0e35422f4c3979f360635a8c050260 -isystem external/jpeg_archive/jpeg-9a -isystem bazel-out/local-py3-opt/genfiles/external/jpeg_archive/jpeg-9a -isystem external/png_archive/libpng-1.2.53 -isystem bazel-out/local-py3-opt/genfiles/external/png_archive/libpng-1.2.53 -isystem external/gif_archive/giflib-5.1.4/lib -isystem bazel-out/local-py3-opt/genfiles/external/gif_archive/giflib-5.1.4/lib -isystem external/highwayhash -isystem bazel-out/local-py3-opt/genfiles/external/highwayhash -isystem external/re2 -isystem bazel-out/local-py3-opt/genfiles/external/re2 -isystem third_party/eigen3 -isystem bazel-out/local-py3-opt/genfiles/third_party/eigen3 -isystem external/eigen_archive/eigen-eigen-b4fa9622b809 -isystem bazel-out/local-py3-opt/genfiles/external/eigen_archive/eigen-eigen-b4fa9622b809 -isystem external/zlib_archive/zlib-1.2.8 -isystem bazel-out/local-py3-opt/genfiles/external/zlib_archive/zlib-1.2.8 -isystem external/boringssl_git/src/include -isystem bazel-out/local-py3-opt/genfiles/external/boringssl_git/src/include -isystem external/jsoncpp_git/include -isystem bazel-out/local-py3-opt/genfiles/external/jsoncpp_git/include -fno-exceptions -DEIGEN_AVOID_STL_ARRAY -pthread -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c tensorflow/core/kernels/sparse_matmul_op.cc -o bazel-out/local-py3-opt/bin/tensorflow/core/kernels/_objs/sparse_matmul_op/tensorflow/core/kernels/sparse_matmul_op.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
> In file included from tensorflow/core/kernels/sparse_matmul_op.cc:20:0:
> ./tensorflow/core/kernels/sparse_matmul_op.h:46:26: error: 'Packet4f' does not name a type
>  EIGEN_DEVICE_FUNC inline Packet4f pexpand_bf16_l(const Packet4f& from) {
>                           ^
> ./tensorflow/core/kernels/sparse_matmul_op.h:59:26: error: 'Packet4f' does not name a type
>  EIGEN_DEVICE_FUNC inline Packet4f pexpand_bf16_u(const Packet4f& from) {
>                           ^
> ./tensorflow/core/kernels/sparse_matmul_op.h:117:21: error: 'Packet4f' does not name a type
>  EIGEN_STRONG_INLINE Packet4f pload4bf16<Packet4f>(const float\* from) {
>                      ^
> ./tensorflow/core/kernels/sparse_matmul_op.h:128:21: error: 'Packet4f' does not name a type
>  EIGEN_STRONG_INLINE Packet4f pload2bf16<Packet4f>(const float\* from) {
>                      ^
> ./tensorflow/core/kernels/sparse_matmul_op.h: In instantiation of 'Packet Eigen::internal::pexpand_bf16_l(const Packet&) [with Packet = float]':
> tensorflow/core/kernels/sparse_matmul_op.cc:375:3:   required from here
> ./tensorflow/core/kernels/sparse_matmul_op.h:31:44: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]
>    return reinterpret_cast<const float&>(tmp);
>                                             ^
> ./tensorflow/core/kernels/sparse_matmul_op.h: In instantiation of 'Packet Eigen::internal::pexpand_bf16_u(const Packet&) [with Packet = float]':
> tensorflow/core/kernels/sparse_matmul_op.cc:376:3:   required from here
> ./tensorflow/core/kernels/sparse_matmul_op.h:40:44: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]
>    return reinterpret_cast<const float&>(tmp);
>                                             ^
> Target //tensorflow/tools/pip_package:build_pip_package failed to build

**any problems with the src?**
"
3392,Remove unnecessary input-size requirement for convolutions with padding='SAME',"Right now there is conflicting behavior when `padding='SAME'`: If inputs have a defined height and width, then convolutions require that filters be no larger than input images (spatially). If inputs do not have a defined height and width, then it's okay for filters to be larger than images.

I think this conflicting behavior should be removed, especially since `padding='SAME'` is used for convenience and with the intention of allowing some border effects, and because this way we can continue to use this convenience even when filter size > input size.

TensorFlow 0.9 example with defined height and width:

```
inputs = tf.placeholder(tf.float32, shape=[None, 2, 2, 3])
weights = tf.get_variable('weights', [3, 3, 3, 10], tf.float32,
                          initializer=tf.random_normal_initializer())
t = tf.nn.conv2d(inputs, weights, [1, 1, 1, 1], 'SAME')

# ValueError: Filter must not be larger than the input: Filter: (3, 3) Input: (2, 2)
```

TensorFlow 0.9 example without defined height and width:

```
inputs = tf.placeholder(tf.float32, shape=[None, None, None, 3])
weights = tf.get_variable('weights', [3, 3, 3, 10], tf.float32,
                          initializer=tf.random_normal_initializer())
t = tf.nn.conv2d(inputs, weights, [1, 1, 1, 1], 'SAME')

with tf.Session() as sess:
    sess.run(tf.initialize_all_variables())
    print(sess.run(t, feed_dict={inputs: np.random.rand(1, 2, 2, 3)}).shape)

# Shape is what we expect: (1, 2, 2, 10)
```
"
3391,cudnn5  so slow,"I updated cudnn from 4 to 5, and reinstall tensorflow from source.
But I found that my code run almost 6 time slower than before.
"
3390,Index error in decoding,"When I tried  --decode  and gave a sentence, I got this error
Traceback (most recent call last):
  File ""translate.py"", line 279, in <module>
    tf.app.run()
  File ""/home/devadath/.local/lib/python3.5/site-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""translate.py"", line 274, in main
    decode()
  File ""translate.py"", line 244, in decode
    print("" "".join([tf.compat.as_str(rev_hi_vocab[output]) for output in outputs]))
  File ""translate.py"", line 244, in <listcomp>
    print("" "".join([tf.compat.as_str(rev_hi_vocab[output]) for output in outputs]))
IndexError: list index out of range

Any help is appreciated
"
3389,Why doesn't tensorflow support tensor as the feed_dict?,"**What I'm trying to do**

I am trying to extract CNN features for my own images with residual-net based on https://github.com/ry/tensorflow-resnet. I plan to input image data from JPG files before exploring how to convert the images into a single file.

**What I have done**

I have read https://www.tensorflow.org/versions/r0.9/how_tos/reading_data/index.html and some related materials about how to input data like feeding and placeholder. Here is my code:

```
import tensorflow as tf
from convert import print_prob, checkpoint_fn, meta_fn
from image_processing import image_preprocessing
tf.app.flags.DEFINE_integer('batch_size', 1, ""batch size"")
tf.app.flags.DEFINE_integer('input_size', 224, ""input image size"")
tf.app.flags.DEFINE_integer('min_after_dequeue', 224, ""min after dequeue"")
tf.app.flags.DEFINE_integer('layers', 152, ""The number of layers in the net"")
tf.app.flags.DEFINE_integer('image_number', 6951, ""number of images"")
FLAGS = tf.app.flags.FLAGS


def placeholder_inputs():
    images_placeholder = tf.placeholder(tf.float32, shape=(FLAGS.batch_size, FLAGS.input_size, FLAGS.input_size, 3))
    label_placeholder = tf.placeholder(tf.int32, shape=FLAGS.batch_size)
    return images_placeholder, label_placeholder


def fill_feed_dict(image_ba, label_ba, images_pl, labels_pl):
    feed_dict = {
        images_pl: image_ba,
    }
    return feed_dict

min_fraction_of_examples_in_queue = 0.4
min_queue_examples = int(FLAGS.image_number *
                     min_fraction_of_examples_in_queue)
dataset = tf.train.string_input_producer([""hollywood_test.txt""])
reader = tf.TextLineReader()
_, file_content = reader.read(dataset)
image_name, label, _ = tf.decode_csv(file_content, [[""""], [""""], [""""]], "" "")
label = tf.string_to_number(label)
num_preprocess_threads = 10
images_and_labels = []
with tf.Session() as sess:
    for thread_id in range(num_preprocess_threads):
        image_buffer = tf.read_file(image_name)
        bbox = []
        train = False
        image = image_preprocessing(image_buffer, bbox, train, thread_id)
        image = image_buffer
        images_and_labels.append([image, label])
    image_batch, label_batch = tf.train.batch_join(images_and_labels,
                                            batch_size=FLAGS.batch_size,
                                            capacity=min_queue_examples + 3 * FLAGS.batch_size)
    images_placeholder, labels_placeholder = placeholder_inputs()
    new_saver = tf.train.import_meta_graph(meta_fn(FLAGS.layers))
    new_saver.restore(sess, checkpoint_fn(FLAGS.layers))
    graph = tf.get_default_graph()
    prob_tensor = graph.get_tensor_by_name(""prob:0"")
    images = graph.get_tensor_by_name(""images:0"")
    feed_dict = fill_feed_dict(image_batch, label_batch, images, labels_placeholder)
    coord = tf.train.Coordinator()
    threads = tf.train.start_queue_runners(coord=coord)
    sess.run(tf.initialize_all_variables())
    prob = sess.run(prob_tensor, feed_dict=feed_dict)
    print_prob(prob[0])
    coord.request_stop()
    coord.join(threads)
```

**What my question is**

The code above got the error `TypeError: The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, or numpy ndarrays.` You can see I am trying to do all the work in the context of tensorflow. As far as I know, tensorflow is a framework where all the inputs and outputs of the nodes are tensors. However, I am quite confused why feed_dict doesn't support tensor as an input. But the batch_join function return a tensor and so do other ops. I found that in the mnist example of tensorflow there is even another function to produce a batch when tensorflow is providing methods for batching. So I wonder if there is an elegant way to do these things. If this is because of my lack of searching and careful reading I really apologize.
"
3388,Bug: Exception ignored in BaseSession.__del__,"Hello Everyone,

The following code produces an error in TensorFlow:

```
import tensorflow as tf

a = tf.constant(123)
b = tf.constant(456)
c = a * b

session = tf.Session()

# A slightly different error is produced if this is removed.
session.run(tf.initialize_all_variables())

result = session.run(c)

print(result)

session.close()    # The error is produced regardless of this.

#quit()            # This produces the error.

import sys
sys.exit()         # This also produces the error.
```

This is the contents of sandbox3.py which I run in PyCharm.

The output is:

```
/home/magnus/anaconda3/envs/tensorflow/bin/python /home/magnus/development/TensorFlow-Tutorials/sandbox3.py
56088
Exception ignored in: <bound method BaseSession.__del__ of <tensorflow.python.client.session.Session object at 0x7fb4ecd301d0>>
Traceback (most recent call last):
  File ""/home/magnus/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 171, in __del__
  File ""/home/magnus/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 167, in close
AttributeError: 'NoneType' object has no attribute 'raise_exception_on_not_ok_status'

Process finished with exit code 0
```

I'm using the following versions:
- TensorFlow 0.9.0 CPU installed from binary.
- Python 3.5.1
- Anaconda 2.5.0
- PyCharm 5.0.4
- Linux Mint 17.3
"
3387,mobile tensorflow,"About mobile tensorflow ( https://www.tensorflow.org/mobile.html ), I want to download the inception
(http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz), but it has been 
damaged.

Thank you!
"
3386,Ubuntu 16.04,"On Ubuntu 16.04 (gcc default is 5.3), 
apt-get install cuda-toolkit installs the library files in usr/lib/x86_64-linux-gnu
tensorflow prefers them in usr/local/cuda
.configure allows you to change the directory

cuDNN installs in /usr/local/cuda (more or less by default)
telling configure that cuDNN is in usr/local/cuda makes tf look for cuda in usr/local/cuda

Before you know it, you have cuda versions, nvidia versions, cuda folders etc. all over the place but tf not knowing any GPU!!
"
3385,Update probabilities for stratified_sampling,"The function `tf.contrib.framework.sampling_ops.stratified_sample` doesn't accept probability update. Is it a bug or a normal behaviour ?
Bellow is a sample code that produce the error. The idea is to resample a label sub set from large dataset with large number of label (and unbalanced) and update the target prob after each iteration : 

```
target_num_labels = 10
num_labels = 1000

p = [float(target_num_labels)/float(num_labels)]*num_labels
label_sampler = tf.contrib.distributions.Bernoulli(p=p, dtype=tf.float32)
label_samples = tf.squeeze(label_sampler.sample(1))
target_prob = tf.div(label_samples, tf.reduce_sum(label_samples))

images, labels = ....

init_prob = ... # unbalanced label distribution from the data set
[images], labels = tf.contrib.framework.stratified_sample([images], 
     labels, init_prob, target_prob, 256, enqueue_many=True)
```
"
3381,iOS Example Make Build Error,"I am following the iOS static TF build on the ""Building By Hand"" section [found here](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile#building-by-hand).  I am running the build command after downloading dependencies and compiling successfully.

When running `make -f tensorflow/contrib/makefile/Makefile  TARGET=IOS  IOS_ARCH=ARM64`, there is a generated error that stops the build.

```
error:statement expression not allowed at file scope
```

```
In file included from tensorflow/core/kernels/xent_op.cc:20:
In file included from ./tensorflow/core/kernels/xent_op.h:20:
In file included from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1:
In file included from /Users/michaellee/Code/ios/tensorflow/tensorflow/contrib/makefile/downloads/eigen-eigen-b4fa9622b809/unsupported/Eigen/CXX11/Tensor:14:
In file included from /Users/michaellee/Code/ios/tensorflow/tensorflow/contrib/makefile/downloads/eigen-eigen-b4fa9622b809/unsupported/Eigen/CXX11/../../../Eigen/Core:354:
/Users/michaellee/Code/ios/tensorflow/tensorflow/contrib/makefile/downloads/eigen-eigen-b4fa9622b809/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/NEON/Complex.h:286:35: error:
      statement expression not allowed at file scope
static uint64x2_t p2ul_CONJ_XOR = vld1q_u64( p2ul_conj_XOR_DATA );
                                  ^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../lib/clang/7.3.0/include/arm_neon.h:7624:39: note:
      expanded from macro 'vld1q_u64'
#define vld1q_u64(__p0) __extension__ ({ \
                                      ^
1 error generated.
make: *** [/Users/michaellee/Code/ios/tensorflow/tensorflow/contrib/makefile/gen/obj/tensorflow/core/kernels/xent_op.o] Error 1
```

I have recreated this problem on two different computers, and on a freshly pulled version

Xcode 7.3.1, OS X 10.11.5
"
3380,Multi-GPU Example only using a single GPU,"When running the CIFAR-10 example, it appears like TensorFlow is only utilizing one card - despite the fact that I have 4 cards installed in this machine (it is an NVIDIA DIGITS box). The script runs fine otherwise (can complete computation on a single card), but simply refuses to use more than one card. When attempting to use the script here: [https://github.com/aymericdamien/TensorFlow-Examples/blob/master/multigpu_basics.py](multigpu_basics.py) it appears as if Tensorflow allocates memory to one card, runs the computation, then allocates memory to a second card (in reverse numerical order, no less), and then runs the computation again, on that single card. Oddly, TensorFlow seems to see my cards in reverse order - when using ""/gpu:0"", it allocates work to the 4th card in the box. This is probably unrelated, but I mention it just in case. 

Operating System: Ubuntu 14.04
uname -a output: `Linux nvidia-1 3.16.0-34-generic #47~14.04.1-Ubuntu SMP Fri Apr 10 17:49:16 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux`
CIFAR example invocation: `cifar10_multi_gpu_train.py --num-gpus=2` - results are the same if I set that number between 2 and 4, inclusive.

nvidia-smi output, before running the CIFAR example:

``` +------------------------------------------------------+
| NVIDIA-SMI 352.93     Driver Version: 352.93         |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX TIT...  Off  | 0000:05:00.0      On |                  N/A |
| 22%   36C    P8    17W / 250W |    256MiB / 12284MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  GeForce GTX TIT...  Off  | 0000:06:00.0     Off |                  N/A |
| 22%   38C    P8    16W / 250W |     23MiB / 12287MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  GeForce GTX TIT...  Off  | 0000:09:00.0     Off |                  N/A |
| 22%   37C    P8    17W / 250W |     23MiB / 12287MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  GeForce GTX TIT...  Off  | 0000:0A:00.0     Off |                  N/A |
| 22%   35C    P8    15W / 250W |     23MiB / 12287MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0      1697    G   /usr/bin/X                                     174MiB |
|    0      2983    G   compiz                                          55MiB |
+-----------------------------------------------------------------------------+
```

NVIDIA-SMI under load:

```
+------------------------------------------------------+
| NVIDIA-SMI 352.93     Driver Version: 352.93         |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX TIT...  Off  | 0000:05:00.0      On |                  N/A |
| 22%   38C    P8    16W / 250W |    364MiB / 12284MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  GeForce GTX TIT...  Off  | 0000:06:00.0     Off |                  N/A |
| 22%   41C    P8    16W / 250W |    138MiB / 12287MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  GeForce GTX TIT...  Off  | 0000:09:00.0     Off |                  N/A |
| 22%   39C    P8    17W / 250W |    138MiB / 12287MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  GeForce GTX TIT...  Off  | 0000:0A:00.0     Off |                  N/A |
| 22%   45C    P2    88W / 250W |  11767MiB / 12287MiB |     90%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0      1697    G   /usr/bin/X                                     174MiB |
|    0      2983    G   compiz                                          49MiB |
|    0     11514    C   python                                         111MiB |
|    1     11514    C   python                                         111MiB |
|    2     11514    C   python                                         111MiB |
|    3     11514    C   python                                       11740MiB |
+-----------------------------------------------------------------------------+
```

I installed TensorFlow from source.
`
python -c ""import tensorflow; print(tensorflow.__version__)""
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so.7.5 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so.7.5 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so.7.5 locally
0.9.0
`

This is the Git commit hash that I got when pulling down TensorFlow:
`a3f61c1d5c76339e6c9655dac426bb3822659772`
"
3379,Tensorflow 0.9 HDF5,"The Tensorflow 0.9 changelog mentions HDF5 support but I can't find any further details. What is actually implemented, is it possible to stream HDF5 files using the Tensorflow pipelines?
"
3378,Why not feed placeholders by name?,"I couldn't find anything [in the documentation](https://www.tensorflow.org/versions/r0.9/how_tos/reading_data/index.html#feeding) on this. Is it possible to feed placeholders by name? If not, why? I think this would be useful to feed graphs after loading them from disk.

``` python
import tensorflow as tf
x = tf.placeholder(tf.float32, (None,), 'x')
y = tf.reduce_sum(x)
sess = tf.Session()

sess.run(y, {x: [1, 2, 3]}
# > 6.0

sess.run(y, {'x': [1, 2, 3]}
# > Cannot interpret feed_dict key as Tensor: The name 'x' refers to an operation,
# > not a Tensor. Tensor names must be of the form ""<op_name>:<output_index>"".

sess.run(y, {tf.get_default_graph().get_operation_by_name('x').outputs[0]: [1, 2, 3]})
# > 6.0
```
"
