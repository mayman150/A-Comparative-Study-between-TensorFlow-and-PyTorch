Issue Number,Issue Title,Issue Body
40408,Calling predict with a keras.Sequence on a keras.saved_model fail if no previous call on numpy,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Python 3.6.9 (default, Mar 13 2020, 17:02:25) 
[GCC 4.2.1 Compatible Apple LLVM 11.0.0 (clang-1100.0.33.17)] on darwin
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.1.1
- Python version: 3.6.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

Tensorflow raises an error when calling the loaded model onto a keras.Sequence. Calling model.build does not solve the issue

**Describe the expected behavior**

It should be possible to call the model onto a keras.Sequence as it works with tf.data.Dataset

**Standalone code to reproduce the issue**

```python
import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.utils import Sequence

#%% Create dummy Sequential
model = Sequential([Input((224, 224, 3)), GlobalAveragePooling2D(), Dense(1)])
model.summary()
assert model.built
model.input_shape
tf.saved_model.save(model, ""model"")

#%% Make prediction with loaded model and Sequence
tf_model = load_model(""model"")
class DataGen(Sequence):
    def __init__(self, data, batch_size):
        self.data = data
        self.batch_size = batch_size

    def __getitem__(self, index):
        return self.data[index * self.batch_size : (index + 1) * self.batch_size]

    def __len__(self):
        return len(self.data) // self.batch_size


X = np.random.rand(16, 224, 224, 3)
tf_model.predict(DataGen(X, batch_size=2))
# ValueError: Please provide model inputs as a list or tuple of 2 or 3 elements: (input, target) or (input, target, sample_weights) Received tf.Tensor(...)

#%% Manual build does not fix the issue
assert not tf_model.built
tf_model.build((None, 224, 224, 3))
assert tf_model.built
tf_model.predict(DataGen(X, batch_size=2))

#%% Try with tf.data.Dataset instead: OK
tf_model.predict(tf.data.Dataset.from_tensor_slices(X).batch(2))

#%% Call first on np.array does fix the issue
tf_model.predict(X[:2])
tf_model.predict(DataGen(X, batch_size=2))

#%% But model still does not have input_shape and has ""multiple"" in summary
tf_model.inputs
tf_model.input_shape
tf_model.summary()
```
"
40407,tensorboard --logdir=runs not working: Abort trap: 6,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Catalina
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.2.0
- Python version: 3.7.4
- Installed using virtualenv? pip? conda?: pip3
- CUDA/cuDNN version: -

I am trying to run tensorboard: `tensorboard --logdir=runs`.  
I have also tried: `tensorboard --logdir=runs --host=127.0.0.1`.  
I am running the command from the terminal from within the the directory, which contains the `runs` folder.

I get the following error:
```[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/descriptor_database.cc:393] Invalid file descriptor data passed to EncodedDescriptorDatabase::Add().
[libprotobuf FATAL external/com_google_protobuf/src/google/protobuf/descriptor.cc:1367] 
CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
libc++abi.dylib: terminating with uncaught exception of type google::protobuf::FatalException: 
CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
Abort trap: 6
```

My Python code contains the following lines:
```
tb_path = './runs/SimpleLSTM_MNIST'
if os.path.isdir(tb_path):
    shutil.rmtree(tb_path)

writer = tb.SummaryWriter(log_dir=tb_path)
```
My `runs` folder contains the folder `SimpleLSTM_MNIST`, which contains `events.out.tfevents.1591953948.computername.local.29440.0`.

I also tried installing `protobuf version 3.8.0`, as suggested [here](https://stackoverflow.com/questions/60028929/failing-to-launch-tensorboard-from-jupyter), but still get the same issue. "
40406,y shape and y_pred shape not same ,"why those two are different 

![tfp](https://user-images.githubusercontent.com/26671669/84497611-f3b32380-acd0-11ea-9538-6e1f60f32c19.png)
"
40404,Restore multiple (different) variables from the same checkpoint tensor.,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 1.15
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**
Currently, if I use the `init_from_checkpoint()` with an `assignment_map`, I can't map one checkpoint tensor to multiple separate graph variables. Using a list only works for multiple partitions of the same variable. For my research use-case, I want to restore `n` matrices of the same shape, from a single checkpoint(ed) matrix of the same shape as well. Once initialisation is done however, these `n` matrices have no co-relation with one another. They will be trained and updated completely independent of each other. Hence I don't want the same variable in the graph.

**Will this change the current api? How?**
It may change the semantics of assignment map, I am not sure.

**Who will benefit with this feature?**
Anyone who wants to re-use large pretrained deep learning models, but play around with architectural changes, say for pruning or model compression.

**Any Other info.**
I am wondering if as a workaround, I can have multiple calls to `init_from_checkpoint()`, one for each `i in n`? And restore them one by one basically. Will the `i'th` call ""overwrite"" the `i-1'th` call?"
40403,GPU-accelerated LSTMs/GRUs crash randomly with: [ InternalError: [_Derived_] Failed to call ThenRnnBackward with model config ],"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Pro, Build 19041
- TensorFlow installed from (source or binary): pip install tensorflow
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: 3.7.4
- CUDA/cuDNN version: CUDA 10.1, cuDNN 7.6.5
- GPU model and memory: NVidia Titan RTX, 24GB, RTX 2080 Ti, 11GB

- nvidia driver version: 450.99

**Describe the current behavior**
Both the Jupyter Notebook and extract Python script on the [Tensorflow Text Classification Tutorial ](https://www.tensorflow.org/tutorials/text/text_classification_rnn) crashes randomly when training locally on my GPU, with the following traceback:

```
tensorflow.python.framework.errors_impl.InternalError:  [_Derived_]  Failed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 64, 64, 1, 2537, 64, 64]
         [[{{node CudnnRNN}}]]
         [[sequential/bidirectional/forward_lstm/StatefulPartitionedCall]]
         [[gradient_tape/sequential/embedding/embedding_lookup/Reshape/_38]] [Op:__inference_train_function_6128]

Function call stack:
train_function -> train_function -> train_function
```
I found two similar issues [#37942](https://github.com/tensorflow/tensorflow/issues/37942) and [#35950 ](https://github.com/tensorflow/tensorflow/issues/35950)

Methods suggested in #37942 did not work and still crashes.

**Describe the expected behavior**
Example tutorial notebooks should run smoothly from top to bottom without random crashes.

**Standalone code to reproduce the issue**
[Github Gist here.](https://gist.github.com/leehanchung/8da991bf1264c19324920349171386bc)

Code:
```
import tensorflow_datasets as tfds
import tensorflow as tf

import matplotlib.pyplot as plt

def plot_graphs(history, metric):
    plt.plot(history.history[metric])
    plt.plot(history.history['val_'+metric], '')
    plt.xlabel(""Epochs"")
    plt.ylabel(metric)
    plt.legend([metric, 'val_'+metric])
    plt.show()


dataset, info = tfds.load('imdb_reviews/subwords8k', with_info=True,
                          as_supervised=True)
train_dataset, test_dataset = dataset['train'], dataset['test']

encoder = info.features['text'].encoder
print('Vocabulary size: {}'.format(encoder.vocab_size))

sample_string = 'Hello TensorFlow.'

encoded_string = encoder.encode(sample_string)
print('Encoded string is {}'.format(encoded_string))

original_string = encoder.decode(encoded_string)
print('The original string: ""{}""'.format(original_string))

assert original_string == sample_string

for index in encoded_string:
    print('{} ----> {}'.format(index, encoder.decode([index])))

BUFFER_SIZE = 10000
BATCH_SIZE = 64

train_dataset = train_dataset.shuffle(BUFFER_SIZE)
train_dataset = train_dataset.padded_batch(BATCH_SIZE)
test_dataset = test_dataset.padded_batch(BATCH_SIZE)

for example_batch, label_batch in train_dataset.take(20):
    print(""Batch shape:"", example_batch.shape)
    print(""label shape:"", label_batch.shape)

model = tf.keras.Sequential([
    tf.keras.layers.Embedding(encoder.vocab_size, 64),
    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(1)
])

model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
              optimizer=tf.keras.optimizers.Adam(1e-4),
              metrics=['accuracy'])

history = model.fit(train_dataset, epochs=10,
                    validation_data=test_dataset, 
                    validation_steps=30)
test_loss, test_acc = model.evaluate(test_dataset)

print('Test Loss: {}'.format(test_loss))
print('Test Accuracy: {}'.format(test_acc))
```

**Other info / logs** 
```
Epoch 1/10
2020-06-11 23:48:47.036226: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-06-11 23:48:47.417459: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
 39/391 [=>............................] - ETA: 33s - loss: 0.6931 - accuracy: 0.50282020-06-11 23:48:52.108366: E tensorflow/stream_executor/dnn.cc:613] CUDNN_STATUS_INTERNAL_ERROR
in tensorflow/stream_executor/cuda/cuda_dnn.cc(1986): 'cudnnRNNBackwardData( cudnn.handle(), rnn_desc.handle(), model_dims.max_seq_length, output_desc.handles(), output_data.opaque(), output_desc.handles(), output_backprop_data.opaque(), output_h_desc.handle(), output_h_backprop_data.opaque(), output_c_desc.handle(), output_c_backprop_data.opaque(), rnn_desc.params_handle(), params.opaque(), input_h_desc.handle(), input_h_data.opaque(), input_c_desc.handle(), input_c_data.opaque(), input_desc.handles(), input_backprop_data->opaque(), 
input_h_desc.handle(), input_h_backprop_data->opaque(), input_c_desc.handle(), input_c_backprop_data->opaque(), workspace.opaque(), workspace.size(), reserve_space_data->opaque(), 
reserve_space_data->size())'
2020-06-11 23:48:52.109818: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at cudnn_rnn_ops.cc:1922 : Internal: Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 64, 64, 1, 1615, 64, 64] 
Traceback (most recent call last):
  File "".\lesson1.py"", line 59, in <module>
    validation_steps=30)
  File ""C:\Users\Han\.virtualenvs\tensorflow-in-practice-9XcfUv0Y\lib\site-packages\tensorflow\python\keras\engine\training.py"", line 66, in _method_wrapper
    return method(self, *args, **kwargs)
  File ""C:\Users\Han\.virtualenvs\tensorflow-in-practice-9XcfUv0Y\lib\site-packages\tensorflow\python\keras\engine\training.py"", line 848, in fit
    tmp_logs = train_function(iterator)
  File ""C:\Users\Han\.virtualenvs\tensorflow-in-practice-9XcfUv0Y\lib\site-packages\tensorflow\python\eager\def_function.py"", line 580, in __call__
    result = self._call(*args, **kwds)
  File ""C:\Users\Han\.virtualenvs\tensorflow-in-practice-9XcfUv0Y\lib\site-packages\tensorflow\python\eager\def_function.py"", line 611, in _call
    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
  File ""C:\Users\Han\.virtualenvs\tensorflow-in-practice-9XcfUv0Y\lib\site-packages\tensorflow\python\eager\function.py"", line 2420, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access  File ""C:\Users\Han\.virtualenvs\tensorflow-in-practice-9XcfUv0Y\lib\site-packages\tensorflow\python\eager\function.py"", line 1665, in _filtered_call
    self.captured_inputs)
  File ""C:\Users\Han\.virtualenvs\tensorflow-in-practice-9XcfUv0Y\lib\site-packages\tensorflow\python\eager\function.py"", line 1746, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""C:\Users\Han\.virtualenvs\tensorflow-in-practice-9XcfUv0Y\lib\site-packages\tensorflow\python\eager\function.py"", line 598, in call
    ctx=ctx)
  File ""C:\Users\Han\.virtualenvs\tensorflow-in-practice-9XcfUv0Y\lib\site-packages\tensorflow\python\eager\execute.py"", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.InternalError:  [_Derived_]  Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 64, 64, 1, 1615, 64, 64]
         [[{{node gradients/CudnnRNN_grad/CudnnRNNBackprop}}]]
         [[StatefulPartitionedCall_1]]
         [[gradient_tape/sequential/embedding/embedding_lookup/Reshape/_38]] [Op:__inference_train_function_6172]

Function call stack:
train_function -> train_function -> train_function
```"
40402,Usage and signature of Model.train_step() is unclear,"## URL(s) with the issue:

[Colab link](https://colab.research.google.com/drive/1A6gugIKUl3GCsGFlvmghFHQy5CAOd0RC?usp=sharing)

## Description of issue (what needs changing):

There seems to be some kind of restriction on the signature of Model.train_step(), which is undocumented.

### Clear description

The issue comes up in TF 2.2.0, where the possibility to overwrite Model.train_step() was introduced.

The training is executed with Model.fit() with a generator as an input. The generator yields 4 tensors, which are combined in train_step() to produce a loss and gradients.

The logic fails, because tf.keras in the fit() function checks that the generator outputs at most 3 tensors (corresponding to x, y, and weights), so this mindset and the x, y, w signature is implicity forced onto the train_step() function.

This is not clear from the documentation, which only states, that train_step() has a single argument (data), which should be a 'A nested structure of Tensors.' [Link to documentation](https://www.tensorflow.org/api_docs/python/tf/keras/Model#train_step)

The also seems to be a lack of official examples using this new API, which would help determine the sequence of methods one needs to call in order to use the new API (calling Model.compile() for instance).

### Expected behaviour

According to both the documentation and the release notes on TF 2.2.0, I was expecting to be able to use an arbitrary list of tensors as parameter to Model.train_step().

I would expect that a restriction on Model.train_step()'s sole 'data' argument would be documented in the relevant documentation.

## Disclaimer

Please note if I get the usage of Model.train_step() wrong. Also if there is an example out there using this new and very convenient API, feel free to direct me towards it."
40401,Importing TensorFlow package in PyCharm,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.2.0
- Python version: 3.8
- Installed using virtualenv? pip? conda?: pip
- CUDA/cuDNN version: 11.0
- GPU model and memory: NVIDIA Geforce GTX 1050


**Describe the problem**

I installed tensorflow using `pip install tensorflow ` in cmd and tested in python its working or not using `import tensorflow as tf; print(tf.__version__)` successfully ran and got output 2.2.0. What means is I have installed tensorflow  correctly on my PC. But when I am trying to import tensorflow package in Pycharm using following Steps it doesn't work. 

**Provide the exact sequence of commands / steps that you executed before running into the problem**

Steps:
1.Opened project.
2. File -> Settings ->Project Interpreter (under Project: <Your project title>)
![image](https://user-images.githubusercontent.com/46365760/84466587-51c31500-ac97-11ea-9749-9a230b58e8c5.png)
3. Okay so there is no tensorflow package I need to add it now!
4.When I hit + button to add package I found Tensorflow but when I import it is says `conda.exceptions.UnsatisfiableError:`
![image](https://user-images.githubusercontent.com/46365760/84466734-b8e0c980-ac97-11ea-920d-af87263bafbc.png)
5. Error Screenshot
![image](https://user-images.githubusercontent.com/46365760/84466975-5b994800-ac98-11ea-8cbd-811f4d8999f8.png)


**Any other info / logs**

Tried Solutions:
1. Tensorflow works in Spyder too for me perfectly.
2. Tried creating new interpreter also but no luck!

Other Questions:
1. Why in second screenshot tensorflow version 2.1.0 is shown at bottom right side(Specific version) as I haven't installed any other versions previously and no option of 2.2.0?
2. Why tensorflow is located in Anaconda folder while I haven't installed tensorflow through Anaconda? 
3. Coping tensorflow package folder to pkgs folder i.e in my case from `C:\ProgramData\Anaconda3\Lib\site-packages\tensorflow` to `C:\ProgramData\Anaconda3\pkgs` Pycharm will able to access tensorflow ?
4. I referred a lot of your previous solved issues but why none have proper solution for 2.2.0?"
40400,Build failure with master: logging_op_resolver,"I am attempting to build the current development master and the built fails with fatal errors

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- TensorFlow installed from (source or binary): github master
- Python version: 3.8
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source): gpp-8
- CUDA/cuDNN version: 10.2/8.0
- GPU model and memory: RTX 2060 6gb

**Describe the problem**
After configuring and beginning the build, near the end I receive the following error:

```
ERROR: /home/user/Development/Software/TensorFlow/tensorflow/tensorflow/lite/tools/optimize/calibration/BUILD:84:1: C++ compilation of rule '//tensorflow/lite/tools/optimize/calibration:logging_op_resolver' failed (Exit 1)
tensorflow/lite/tools/optimize/calibration/logging_op_resolver.cc: In constructor 'tflite::optimize::calibration::LoggingOpResolver::LoggingOpResolver(const BuiltinOpsSet&, const CustomOpsSet&, const tflite::OpResolver&, tflite::optimize::calibration::KernelEvalFuncPtr)':
tensorflow/lite/tools/optimize/calibration/logging_op_resolver.cc:78:10: error: 'FATAL' was not declared in this scope
     DLOG(FATAL) << error_message;
          ^~~~~
tensorflow/lite/tools/optimize/calibration/logging_op_resolver.cc:78:10: note: suggested alternative:
In file included from ./tensorflow/core/platform/logging.h:27,
                 from tensorflow/lite/tools/optimize/calibration/logging_op_resolver.cc:20:
./tensorflow/core/platform/default/logging.h:39:11: note:   'tensorflow::FATAL'
 const int FATAL = 3;           // base_logging::FATAL;
           ^~~~~
tensorflow/lite/tools/optimize/calibration/logging_op_resolver.cc:78:5: error: 'DLOG' was not declared in this scope
     DLOG(FATAL) << error_message;
     ^~~~
tensorflow/lite/tools/optimize/calibration/logging_op_resolver.cc:78:5: note: suggested alternative: 'LOG'
     DLOG(FATAL) << error_message;
     ^~~~
     LOG
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
ERROR: /home/jeff/Development/Software/TensorFlow/tensorflow/tensorflow/python/tools/BUILD:99:1 C++ compilation of rule '//tensorflow/lite/tools/optimize/calibration:logging_op_resolver' failed (Exit 1)
INFO: Elapsed time: 151.066s, Critical Path: 34.40s
INFO: 3413 processes: 3413 local.
FAILED: Build did NOT complete successfully
```

**Provide the exact sequence of commands / steps that you executed before running into the problem**
configured to use Cuda 10.2, cuDNN 8.0, and compute capability 7.5


"
40398,miss the ruy/prepare_packed_matrices.h,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux raspberrypi os (May 2020)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
- TensorFlow installed from (source or binary): trying to build
- TensorFlow version: 2.2.0
- Python version: 2.7.0
- Installed using virtualenv? pip? conda?: no
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): (Raspbian 8.3.0-6+rpi1) 8.3.0
- CUDA/cuDNN version: no
- GPU model and memory: no


**Describe the problem**
Hi, I'm trying to natively compile the tensorflow lite in Raspberry Pi following the official guide.
In the lastest step `./tensorflow/lite/tools/make/build_rpi_lib.h`, I got error like this:
```
tensorflow/lite/tools/make/downloads/ruy/ruy/prepare_packed_matrices.cc:16:10: fatal error: ruy/prepare_packed_matrices.h: No such file or directory
 #include ""ruy/prepare_packed_matrices.h""
```
this file is not in path `downloads/ruy/ruy` after downloading the dependencies.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
See above.

**Any other info / logs**
I found the git commit log of download_dependencies.sh and got this file from the previous `RUY_URL` link. It compiled successfully. So I think it miss the prepare_packed_matrices.h.
"
40397,Mixed precision does not improve the speed,"I'm using TF 2.2 to write reinforcement learning algorithms. Because I use a relatively large model, I try to apply mixed precision to improve the training speed. My network consists of three ResNet blocks of depth `[16, 32, 32]`(features are downsampled using maxpooling layer with stride 2 before each block) following by 2 dense layers of size 512, and the input data is of shape `[512, 64, 64, 3]`. After applying the mixed_precision (following [this guide](https://www.tensorflow.org/guide/keras/mixed_precision)), I see the memory usage drops from 3787MB to 1229MB, but the training speed decreases from 20 training steps per second to 15 training steps per second. My code restrictly follows the [official guide](https://www.tensorflow.org/guide/keras/mixed_precision), but I cannot get the improvement on the speed. What might cause the problem?

By the way, my GPU is RTX 2080Ti."
40395,Saving/Loading Subclassed Models TF2+/keras,"**Update-template** I don't really see how to fill in this template.
This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.

Hello,

I am having a lot of difficulties saving a subclassed model and reloading it. I have uploaded the current files I'm working on (specifically, policy.py) to https://github.com/ryanmaxwell96/trpo_fractal5NN. Now, I know you are supposed to be able to save things under the SavedModel format so that is what I've been trying to follow. But I'm still getting the error seen here:

'''
Traceback (most recent call last):
  File ""train.py"", line 411, in <module>
    main(**vars(args))
  File ""train.py"", line 367, in main
    policy_model.save('policy_model')
  File ""/home/ryan/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py"", line 975, in save
    signatures, options)
  File ""/home/ryan/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py"", line 115, in save_model
    signatures, options)
  File ""/home/ryan/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save.py"", line 74, in save
    save_lib.save(model, filepath, signatures, options)
  File ""/home/ryan/.local/lib/python3.6/site-packages/tensorflow_core/python/saved_model/save.py"", line 883, in save
    _ = _SaveableView(checkpoint_graph_view)
  File ""/home/ryan/.local/lib/python3.6/site-packages/tensorflow_core/python/saved_model/save.py"", line 164, in __init__
    self.checkpoint_view.objects_ids_and_slot_variables())
  File ""/home/ryan/.local/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/graph_view.py"", line 418, in objects_ids_and_slot_variables
    object_names[obj] = _object_prefix_from_path(path)
  File ""/home/ryan/.local/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/graph_view.py"", line 64, in _object_prefix_from_path
    for trackable in path_to_root))
  File ""/home/ryan/.local/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/graph_view.py"", line 64, in <genexpr>
    for trackable in path_to_root))
  File ""/home/ryan/.local/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/graph_view.py"", line 57, in _escape_local_name
    return (name.replace(_ESCAPE_CHAR, _ESCAPE_CHAR + _ESCAPE_CHAR)
AttributeError: 'NoneType' object has no attribute 'replace'
'''

In line 90 of the policy.py file is where I'm trying to save the subclassed model ""self.trpo"" after having called train_on_batch and predict_on_batch. I have absolutely no idea what the error is telling me.

Any help would be greatly appreciated!

Thanks,

Ryan"
40394,"Save/load subclassed model TF+2, keras","This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.
"
40392,[TF2.2] Loading a Saved Model from tensorflow_hub failed with `AttributeError: '_UserObject' object has no attribute 'summary'`,"**System info:**
Python: 3.6.9
Tensorflow: 2.2.0 CPU package from _pip_

**The issue:**
I got https://tfhub.dev/google/imagenet/resnet_v2_50/classification/4?tf-hub-format=compressed from tf-hub and then uncompressed in a new directory.

with following code:

```
print(tf.__version__)

resnet50v2_save_path = os.path.join('.', ""test2/imagenet_resnet_v2_50_feature_vector_4/"")

loaded1 = tf.keras.models.load_model(resnet50v2_save_path)
print(loaded1.summary())
```

I get:
```
2.2.0
2020-06-11 21:51:49.413961: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 1995500000 Hz
2020-06-11 21:51:49.414437: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x57d3130 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-06-11 21:51:49.414460: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Traceback (most recent call last):
  File ""./test2.py"", line 43, in <module>
    print(loaded1.summary())
AttributeError: '_UserObject' object has no attribute 'summary'
```
However, if I create my own model and then save into .pb format and then load in the same way it works.

Why? Thx"
40391,Custom train loop inconsistent with Keras `fit` for vector variables,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Custom code
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab, MacOS 10.15.5
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Binary pip
- TensorFlow version (use command below):2.2.0
- Python version:3.7.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:None
- GPU model and memory:None

**Describe the current behavior**

Training a linear model using a custom train loop and `tf.GradientTape` is inconsistent with `tf.keras.Model.fit` and the variables are updated in the wrong way. Scalar variables are updated correctly, vector variables get the wrong gradient.

**Describe the expected behavior**

The final results should be close in both cases.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```python
import tensorflow as tf
import numpy as np

nn=40
_x= np.random.normal(size=(nn,3)).astype(np.float32)
_y= .4*_x[:,0] + 0.2*_x[:,1] -0.3*_x[:,2]+1.5 + np.random.normal(size=(nn), scale=.1).astype(np.float32)

_x = tf.convert_to_tensor(_x)
_y = tf.convert_to_tensor(_y)

modelx=tf.keras.Sequential([
    tf.keras.layers.Dense(1)
])

modelx(_x)

opt = tf.keras.optimizers.Adam(learning_rate=0.1)


for i in range(400):
    with tf.GradientTape() as tape:

        yhat = modelx(_x)
        loss = tf.reduce_sum(tf.math.squared_difference(yhat,_y ))
    grads = tape.gradient(loss, modelx.trainable_weights)

    opt.apply_gradients(zip(grads, modelx.trainable_weights))


modelx.variables
```

Colab to reproduce the bug:

https://colab.research.google.com/drive/12YlqtjsekXqhEZiTnlTnjxz2s0RJCV0r?usp=sharing

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40388,Protobuf not choosing the right libstdc++ while building with Bazel,"Hi everyone,

I'm having a bug which seems to be recurrent since 2016 and concerns the build of TensorFlow from the source using Bazel. Here are some system information and description of the problem.

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Scientific Linux 7
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.2.0
- Python version: 3.6.2
- Bazel version (if compiling from source): 3.2.0
- GCC/Compiler version (if compiling from source): 8.2.0
- CUDA/cuDNN version: 10.2/7
- GPU model and memory: V100/16GB

**Describe the current behavior**
I'm trying to build the last version of TensorFlow (2.20) using Bazel 3.2.0. Everything goes fine ignoring some warings until the protoc execution of protobuf. Please find the error snippet hereafter :

``
ERROR: /nobackup/anon/tensorflow/tensorflow/core/protobuf/BUILD:153:17: ProtoCompile tensorflow/core/protobuf/named_tensor.pb.h failed (Exit 1): protoc failed: error executing command 
  (cd /nobackup/anon/cache/bazel/_bazel_af261718/0773f41f5efd7b2afa75c2b5b53f9c82/execroot/org_tensorflow && \
  exec env - \
  bazel-out/host/bin/external/com_google_protobuf/protoc '--cpp_out=bazel-out/k8-opt-exec-50AE0418/bin' -I. -Iexternal/com_google_protobuf/src -Ibazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src tensorflow/core/protobuf/named_tensor.proto)
Execution platform: @local_execution_config_platform//:platform
bazel-out/host/bin/external/com_google_protobuf/protoc: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.20' not found (required by bazel-out/host/bin/external/com_google_protobuf/protoc)
bazel-out/host/bin/external/com_google_protobuf/protoc: /lib64/libstdc++.so.6: version `CXXABI_1.3.8' not found (required by bazel-out/host/bin/external/com_google_protobuf/protoc)
bazel-out/host/bin/external/com_google_protobuf/protoc: /lib64/libstdc++.so.6: version `CXXABI_1.3.9' not found (required by bazel-out/host/bin/external/com_google_protobuf/protoc)
bazel-out/host/bin/external/com_google_protobuf/protoc: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by bazel-out/host/bin/external/com_google_protobuf/protoc)
Target //tensorflow/tools/pip_package:build_pip_package failed to build
ERROR: /nobackup/anon/tensorflow/tensorflow/python/tools/BUILD:282:10 ProtoCompile tensorflow/core/framework/graph.pb.h failed (Exit 1): protoc failed: error executing command 
  (cd /nobackup/anon/cache/bazel/_bazel_af261718/0773f41f5efd7b2afa75c2b5b53f9c82/execroot/org_tensorflow && \
  exec env - \
  bazel-out/host/bin/external/com_google_protobuf/protoc '--cpp_out=bazel-out/k8-opt-exec-50AE0418/bin' -I. -Iexternal/com_google_protobuf/src -Ibazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src tensorflow/core/framework/graph.proto)
Execution platform: @local_execution_config_platform//:platform
``
As we can see, it refers to /lib64 instead of refering to the lib specified in LD_LIBRARY_PATH. Actually, the `exec env -` will erase all the env vars passed to command ... I've tried several workarounds by adding a `--linkopt=""-Wl, -rpath,/path/to/lib64""` or even in the following issues: https://github.com/bazelbuild/bazel/issues/1358#issuecomment-232019644 and https://github.com/bazelbuild/bazel/issues/649#issuecomment-166710509 but it seems that the CROSSTOOL file doesn't exist anymore... These workarounds don't work for me and I don't know what to do anymore.

**Describe the expected behavior**
Passing correct lib64 folder to LD_LIBRARY_PATH should overcome the problem but since `exec env -` is still active the variable is erased.

Do you have a solution for this problem?
Thanks"
40387,tf_upgrade_v2 needs explicit encodings on Windows to upgrade utf-8,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary x64
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: 3.8.2
- CUDA/cuDNN version: 10.1
- GPU model and memory: Tesla K80, 1080ti (11GB per gpu)

**Describe the current behavior**

Running tf_upgrade_v2 yields encoding errors on Windows, even with defaults set to utf-8 (though no explicit encodings in each file -- as this isn't required in Python 3). 

Adding explicit encoding to `tensorflow\tools\compatibility\ast_edits.py` as shown below resolved this for me -- if a default of utf-8 isn't desirable maybe a command line option?

```
    # Write to a temporary file, just in case we are doing an implace modify.
    # pylint: disable=g-backslash-continuation
    with open(in_filename, ""r"", encoding='utf-8') as in_file, \
        tempfile.NamedTemporaryFile(""w"", delete=False, encoding='utf-8') as temp_file:
      ret = self.process_opened_file(in_filename, in_file, out_filename,
                                     temp_file)
    # pylint: enable=g-backslash-continuation
```

"
40386,clarification with TF datasets: more efficient to vectorize with unbatching (batch -> map -> unbatch) or just map?,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

https://www.tensorflow.org/guide/data
https://www.tensorflow.org/guide/data_performance

## Description of issue (what needs changing):

The documentation for vectorizing code says that vectorizing transformations is more efficient, as with batch -> map. However, it doesn't say anything about the overhead of unbatch; as a result, I have seen the process batch -> map -> unbatch to vectorize transformations before adding more methods (like cache -> shuffle) that you don't want to perform on the batched dataset.

It's not clear which is better, or whether it depends on hardware, dataset, batch size, etc.:
1) Just performing dataset.map(my_transformation)
2) Performing dataset.batch(batch_size).map(my_transformation).unbatch()

When the whole dataset fits in memory, the map would be performed once (in front of cache), and so an inefficient implementation would only bear a one-time cost. However, if the dataset is large enough to require sharding (I haven't looked into this), wouldn't this extra cost be paid every time a new shard is loaded? 

I have seen (2) show up in numerous (non-official) tutorials, but at least in the few cases I have tested, it can cause a slowdown of up to 1.5x. It seems like a small change could clarify this, especially if the overhead in unbatch is probably always higher than the cost of non-vectorized transformations. I could also see it being that for certain cases, (2) is actually more efficient, but that's just a guess."
40385,ImportError: cannot import name 'naming' from 'tensorflow.python.autograph.core' for tf-agents,"Hey, not sure if this is for here, for I should move it to tf-agents. I figured since the deepest part of the traceback was in tensorflow, it should be here. Please let me know if I'm wrong and I'll move to tf-agents.
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No, using this example: https://www.tensorflow.org/agents/tutorials/1_dqn_tutorial
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux 5.6.15-arch1-1
- TensorFlow installed from (source or binary): built from source
- TensorFlow version (use command below): v1.12.1-33853-gc674577870 2.2.0
- Python version: 3.8
- Bazel version (if compiling from source): 2.0.0
- GCC/Compiler version (if compiling from source): 10.1.0
- CUDA/cuDNN version: 10.2 / 7.6.5
- GPU model and memory: GTX 1080 Ti  11GB

**Describe the current behavior**
Errors out when importing anything from tf-agents.
**Describe the expected behavior**
Should run without error.
**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
from tf_agents.agents.dqn import dqn_agent
**Other info / logs** Full traceback of error:
`  File ""/home/frodo/Desktop/gym_project/gym-open.py"", line 14, in <module>
    from tf_agents.agents.dqn import dqn_agent
  File ""/home/frodo/.local/lib/python3.8/site-packages/tf_agents/agents/__init__.py"", line 17, in <module>
    from tf_agents.agents import tf_agent
  File ""/home/frodo/.local/lib/python3.8/site-packages/tf_agents/agents/tf_agent.py"", line 26, in <module>
    from tf_agents.specs import tensor_spec
  File ""/home/frodo/.local/lib/python3.8/site-packages/tf_agents/specs/__init__.py"", line 20, in <module>
    from tf_agents.specs.distribution_spec import DistributionSpec
  File ""/home/frodo/.local/lib/python3.8/site-packages/tf_agents/specs/distribution_spec.py"", line 22, in <module>
    import tensorflow_probability as tfp
  File ""/home/frodo/.local/lib/python3.8/site-packages/tensorflow_probability/__init__.py"", line 76, in <module>
    from tensorflow_probability.python import *  # pylint: disable=wildcard-import
  File ""/home/frodo/.local/lib/python3.8/site-packages/tensorflow_probability/python/__init__.py"", line 24, in <module>
    from tensorflow_probability.python import experimental
  File ""/home/frodo/.local/lib/python3.8/site-packages/tensorflow_probability/python/experimental/__init__.py"", line 34, in <module>
    from tensorflow_probability.python.experimental import auto_batching
  File ""/home/frodo/.local/lib/python3.8/site-packages/tensorflow_probability/python/experimental/auto_batching/__init__.py"", line 24, in <module>
    from tensorflow_probability.python.experimental.auto_batching import frontend
  File ""/home/frodo/.local/lib/python3.8/site-packages/tensorflow_probability/python/experimental/auto_batching/frontend.py"", line 45, in <module>
    from tensorflow.python.autograph.core import naming
ImportError: cannot import name 'naming' from 'tensorflow.python.autograph.core' (/home/frodo/.local/lib/python3.8/site-packages/tensorflow/python/autograph/core/__init__.py)`
"
40384,"Tensorflow is blocking CUDAmemcpyAsyn, and high CPU usage","<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution: Linux Ubuntu 18.04):
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): c++ 2.2.0
- Bazel version (if compiling from source): 2.0.0
- GCC/Compiler version (if compiling from source):7.5.0
- CUDA/cuDNN version: 10.1
- GPU model and memory: NVIDIA TitanV 12GB

**Describe the current behavior**
Background:
Hi, I'm using tensorflow c++ to do offline inference. Since I want to do it in realtime, I dag in and found some optimisation tricks. Perhaps the most prominent thing is, if and do the inference by calling session->infer(). (if I understand this correctly) Tensorflow would do copy data from RAM to VRAM, GPU calculation, copy result back to RAM. I found that the GPU utilisation is low because the GPU is waiting the data being fed. So I'm trying to do async data tranfer and calculation. (This could double the performance of my model since the GPU is only used by 40%, without data transfer, it can take up to 90%)

I found an example of creating GPU resident tensor in the source code of Tensorflow and I used it:

TensorShape shape = TensorShape({this->batchSize, this->input_height, this->input_width, this->input_depth});
    PlatformGpuId platform_gpu_id(0);

    GPUMemAllocator *sub_allocatorA =
        new GPUMemAllocator(
            GpuIdUtil::ExecutorForPlatformGpuId(platform_gpu_id).ValueOrDie(),
            platform_gpu_id, false /*use_unified_memory*/, {}, {});
    GPUBFCAllocator *allocatorA = new GPUBFCAllocator(sub_allocatorA, shape.num_elements() * sizeof(uint8), ""GPU_0_bfc"");
    this->BufferA = new Tensor(allocatorA, tensorflow::DT_UINT8, shape);

and I feed data using:

cudaMemcpyAsync(dst, p, this->batchSize * this->input_depth * this->input_height * this->input_width, cudaMemcpyHostToDevice, *CUDAstream);

Issue 1:
I implemented three threads, one is for feeding data, one is for inference, and one is for data fetching.

For some reason, session->run() would block the cudaMemcpyAsync() in which the cudaMemcpyAsync() is pending until session->run() ends.
This does not happen all the time, but for the majority of the time.

Issue 2:
As I mentioned, I'm using GPU for inference, but tensorflow would occupy all my CPU (44 cores 100%) when it's inferring.
I tried the code below, but it still creates roughly 100 threads and eat all the CPU. This is not happening with your official python wheels. (with the same saved model, there are still lots of threads created, but it is basically not using CPU). I can make sure the calculation is done by GPU, (I opened both htop and nvtop at the same time)

    auto options = SessionOptions();
    options.config.mutable_gpu_options()->set_allow_growth(true);
    tensorflow::ConfigProto &config = options.config;
    config.set_inter_op_parallelism_threads(10);
    config.set_intra_op_parallelism_threads(10);
    config.set_use_per_session_threads(false);  


**Describe the expected behavior**

expected 1:

Async memory transfer without being blocked.

expected 2:

basically same CPU usage with python when running model on GPU.

**Standalone code to reproduce the issue**
If you need it, I can push them on to github

**Other info / logs**
No other important info/logs, I'm working remotely using VNP&SSH during this hard time.


"
40383,Feature Request: API to access peak memory usage of a function call that uses TF,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): TF 2.0, 2.1, 2.2
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**

In TF 1 it was possible to retrieve the peak memory usage via:
`tensorflow.contrib.memory_stats.python.ops.memory_stats_ops import MaxBytesInUse`

This does not seem to be possible anymore in TF 2.0+

**Will this change the current api? How?**

It should not change the current api, it should something like `tf.profiler.memory_stats_ops` to the API

**Who will benefit with this feature?**

Everybody, that wants to benchmark deep learning models in TF 2.0

**Any Other info.**

The function could behave similarly to the corresponding pytorch function: 
tensorflow.contrib.memory_stats.python.ops.memory_stats_ops import MaxBytesInUse
"
40382,tf.image.adjust_jpeg_quality/tf.rawOpsEncodeJpegVariableQuality returns negative/inverted RGB image,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **No** (only called low-level operators, like `EncodeJpegVariableQuality` from `tf.rawOps`)
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Google Colaboratory => Ubuntu 18.04**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **N/A**
- TensorFlow installed from (source or binary): **1.X version available in Google Colaboratory**
- TensorFlow version (use command below): **1.15.2**
- Python version: **3.6.9**
- Bazel version (if compiling from source): **N/A**
- GCC/Compiler version (if compiling from source): **7.5.0**
- CUDA/cuDNN version: **10.1 /10.1.243**
- GPU model and memory: **Tesla K80 (11441MiB available)**


**Describe the current behavior**
`tf.image.random_jpeg_quality` (using `tf.image.adjust_jpeg_quality`) returns an image with wrong RGB values (negative image of the one expected)

**Describe the expected behavior**
`tf.image.random_jpeg_quality` samples a different quality at runtime and returns properly formatted RGB image.

**Standalone code to reproduce the issue**
 [Colab Notebook](https://colab.research.google.com/drive/1H1vhKRDwy2E6qLX6XmCtbqW6iv6DiMDj?usp=sharing)

In the standalone code one can see the results of using the following 3 scenarios to emulate jpeg compression given an input **float32** image:
1. Directly call `tf.image.random_jpeg_quality` with two ints (max and min quality).
2. Using custom code to call `tf.image.adjust_jpeg_quality` with tensors not int(s)
3. Construct custom function based on `tf.image.adjust_jpeg_quality` but forcing the call to ""EncodeJpegVariableQuality"" operator (to ensure a different quality is obtained each run)

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

**Important notes**
I'm trying to use `tf.image.random_jpeg_quality` in my pipiline to emulate JPEG compression artifacts as another data augmentation transformation. This means that the input to the function is a float32 tensor which internally is converted to uint8, encoded, decoded again and converted back to float32.

However, `tf.image.convert_image_dtype` (in `tf.image.adjust_jpeg_quality`) re-scales the float32 to the (0.0, 1.0) range, reason why I manually re-scale it to (0.0, 255.0) as there are other data augmentations down the line that need standard RGB range (and mean-max normalisation is applied at the end of the pipeline). 
In scenario 3, I've also played around with the argument `saturate` of `tf.image.convert_image_dtype` hoping the problem was caused by an overflow while converting from float32 to uint8, but without success.

The ""normal"" and ""negative"" images (manually inverting them after seeing the RGB images outputted after re-scaling the output of the jpeg_quality functions).
The outputs in each case look as follows:
**'Normal' RGB images (without inverting their values)**
![image](https://user-images.githubusercontent.com/19503950/84380349-7d86c200-abe7-11ea-8bac-d0e6c09279f2.png)
(original left,  scenario 1)
![image](https://user-images.githubusercontent.com/19503950/84380718-203f4080-abe8-11ea-9dda-4f728adab232.png)
(Scenario 2, scenario 3)


**'Inverted/Negative' RGB images (after inverting their values)**
![image](https://user-images.githubusercontent.com/19503950/84381052-b4a9a300-abe8-11ea-96df-1d54764b1c91.png)
(original left,  scenario 1)
![image](https://user-images.githubusercontent.com/19503950/84380978-93e14d80-abe8-11ea-9000-2af1e1e09800.png)
(Scenario 2, scenario 3)

As you can see, inverting the RGB values gives a much more plausible image. However, after printing the normal + negative image(s) mean, I see that the average gray value is quite low at around 50 (after inversion). This is more likely the reason why the images look ""washed-out"".

Moreover, looking at the mean of the float32 image before inputting it to the JPEG functions and after re-scaling and clipping to range, differences are huge:
Input image has a mean (over 3 RGB channels) of ~100, output from jpeg functions is ~205.
Next, I'll try to convert the float32 to uint8 before calling the functions and let you known if anything changes.

Possibly related issues: #25882 (closed)

By all means, this could be an error on my end due to a bad usage of any of the aforementioned functions. I'm only reporting it here so no one else repeats such error or, we resolve the bug, if any.

Thanks in advance!

Regards,
Ferran."
40381,ValueError: tf.function-decorated function tried to create variables on non-first call.,"Standalone code to reproduce the issue
https://colab.research.google.com/drive/1gNzsl6mYg8_H2GRHpdxhk8VPGEOqREti?usp=sharing"
40380, keras.models.save_model does not respect include_optimizer option,"**System information**
Tensorflow: v2.2.0-0-g2b96f3662b 2.2.0

**Describe the current behavior**
When passing `include_optimizer=False` to ` keras.models.save_model` the optimizers weights are included.

**Describe the expected behavior**
When passing `include_optimizer=False` to ` keras.models.save_model` the optimizers weights are **NOT** included.

**Standalone code to reproduce the issue**
https://colab.research.google.com/drive/1JocUwWRNmGQzE4mbL85YO-DAaVilJmlD?usp=sharing

<img width=""1621"" alt=""Screenshot 2020-06-11 at 11 01 45"" src=""https://user-images.githubusercontent.com/8607233/84366389-07786000-abd3-11ea-838f-29efb095041b.png"">

"
40379,AttributeError: 'Sequential' object has no attribute '_get_save_spec',"**System information**
- OS Platform and Distribution Linux Ubuntu 18.04:
- TensorFlow version 2.2.0:


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab

converter = tf.lite.TFLiteConverter.from_keras_model(model).

``---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-36-3e84dbd4022a> in <module>()
      1 import tensorflow as tf
----> 2 converter = tf.lite.TFLiteConverter.from_keras_model(model)

1 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saving_utils.py in model_input_signature(model, keep_original_batch_size)
     75     TensorSpecs. This list does not contain the `training` argument.
     76   """"""
---> 77   input_specs = model._get_save_spec(dynamic_batch=not keep_original_batch_size)  # pylint: disable=protected-access
     78   if input_specs is None:
     79     return None

AttributeError: 'Sequential' object has no attribute '_get_save_spec'
```

**The output from the converter invocation**

```
# Copy and paste the output here.
```

**Also, please include a link to the saved model or GraphDef**

```
# Put link here or attach to the issue.
```

**Failure details**
If the conversion is successful, but the generated model is wrong,
state what is wrong:
- Producing wrong results and/or decrease in accuracy
- Producing correct results, but the model is slower than expected (model generated from old converter)


**RNN conversion support**
If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
40378,ValueError: You are trying to load a weight file containing 16 layers into a model with 0 layers.,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- TensorFlow version (or github SHA if from source):


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
# Copy and paste here the exact command
```

**The output from the converter invocation**

```
# Copy and paste the output here.
```

**Also, please include a link to the saved model or GraphDef**

```
# Put link here or attach to the issue.
```

**Failure details**
If the conversion is successful, but the generated model is wrong,
state what is wrong:
- Producing wrong results and/or decrease in accuracy
- Producing correct results, but the model is slower than expected (model generated from old converter)


**RNN conversion support**
If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
40375,ilsvrc:imagenet_accuracy_eval crossed compiled for Pixel4 fails on TF2.1.0's TFlite MobileNetV3 model,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): source
- Tensorflow version (commit SHA if source): 2.1.0
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.):
Pixel4

**Describe the problem**

**Please provide the exact sequence of commands/steps when you ran into the problem**
1. git clone https://github.com/tensorflow/tensorflow
2. git checkout remotes/origin/r2.1
3. conda install bazel==0.29.1
4. sudo snap install android-studio --classic
5. bazel build -c opt --config=android_arm64 //tensorflow/lite/tools/accuracy/ilsvrc:imagenet_accuracy_eval
6. Copy the imagenet_accuracy_eval to Pixel4
7. Download MobileNetV3 model and run TFLite converter with both TF1.5.0 and TF2.1.0. The two files obtained are attached.
[mbnv3_uint8q_tf150.tflite.txt](https://github.com/tensorflow/tensorflow/files/4763102/mbnv3_uint8q_tf150.tflite.txt)
[mbnv3_uint8q_tf210.tflite.txt](https://github.com/tensorflow/tensorflow/files/4763105/mbnv3_uint8q_tf210.tflite.txt)

8. Copy both tflite files to Pixel4 and run them with the following commands:
adb shell /data/local/tmp/yuan/imagenet_accuracy_eval --model_file=/data/local/tmp/yuan/mbnv3_uint8q_tf150.tflite --ground_truth_images_path=/data/local/tmp/ilsvrc_images --ground_truth_labels=/data/local/tmp/ilsvrc_validation_labels.txt --model_output_labels=/data/local/tmp/model_output_labels.txt --output_file_path=/data/local/tmp/mbv3_uint8q_tf150_output.txt --num_images=0

This will works for tf1.5 tflite model but it will crash for tf2.1.0 tflite model though I have used TF2.1 source code to compile imagenet_accuracy_eval:

Pixel4Host:~ yubei$ adb shell /data/local/tmp/yuan/imagenet_accuracy_eval_tf210 --model_file=/data/local/tmp/yuan/mbnv3_uint8q_tf210.tflite --ground_truth_images_path=/data/local/tmp/ilsvrc_images --ground_truth_labels=/data/local/tmp/yuan/ilsvrc_validation_labels.txt --model_output_labels=/data/local/tmp/model_output_labels.txt --output_file_path=/data/local/tmp/yuan/mbv3_uint8q_tf210_output.txt
native : imagenet_accuracy_eval.cc:213 Starting evaluation with: 4 threads.
native : imagenet_accuracy_eval.cc:117 Starting model evaluation: 100
INFO: Initialized TensorFlow Lite runtime.
Aborted 

It seems to me that this 2.1.0 executable doesn't support all functionalities in 2.1.0 TFLite models.
"
40374,Use keras `ModelCheckpoint` failed in multi-worker distribute training env,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, but the bug happens in official codes.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): No
- TensorFlow version (use command below): 2.2.0
- Python version: 3.7
- Bazel version (if compiling from source): No
- GCC/Compiler version (if compiling from source): No
- CUDA/cuDNN version: 10.1
- GPU model and memory: not relevant

**Describe the current behavior**
I'm writing some codes for training a keras model in multi-worker distribute strategy env. For some compatibility issues I don't use keras `model.fit` API to launch my training loop and write my customized training loop instead. In multi-gpu env with MirroredStrategy the keras `ModelCheckpoint` works fine, but when I switch to `MultiWorkerMirroredStrategy`, the `ModelCheckpoint` returns error at the beginning of the training job.

```
Traceback (most recent call last):
  File ""my_training_script.py"", line 720, in custom_training_loop
    callbacks._call_begin_hook(ModeKeys.TRAIN)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/callbacks.py"", line 253, in _call_begin_hook
    self.on_train_begin()
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/callbacks.py"", line 369, in on_train_begin
    callback.on_train_begin(logs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/callbacks.py"", line 931, in on_train_begin
    training_state.MultiWorkerTrainingState(self.model, self.filepath))
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/distribute/multi_worker_training_state.py"", line 90, in __init__
    if not multi_worker_util.should_save_checkpoint():
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/multi_worker_util.py"", line 243, in should_save_checkpoint
    return dc_context.get_current_worker_context().should_checkpoint
AttributeError: 'NoneType' object has no attribute 'should_checkpoint'
```

After a brief code search, I found the root cause of this error in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/distribute/distribute_coordinator_context.py#L26:

```
def get_current_worker_context():
  """"""Returns the current task context.""""""
  try:
    return _worker_context.current
  except AttributeError:
    return None
```
Which means the worker context is probably not set before the callback hooks launch. It returns a `None` object and `should_save_checkpoint` fails. I guess if other keras callbacks depend on the multi worker context, they will also fail if the multi-worker context is not correctly set before the training job starts.

So my question is that, is this behaviour a bug ? If not, how can I correctly setup the multi-worker training env without using `model.compile` or `model.fit`. According to the docs, the distribute training can be run by `strategy.run(step_function, args=args, kwargs=kwargs)` and `strategy.run` function handles the context settings. In this case, should I call the keras callbacks in `strategy.scope`, since my callbacks are not executed in `step_function` ?
"
40373,"Saving Keras model containing layer returning sparse tensor hits: ""ValueError: If specifying TensorSpec names for nested structures, either zero or all names have to be specified.""","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes (entirety included below)
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
  - macOS 10.14.5 (18F203)
  - current `tensorflow/tensorflow:latest` docker image (permanent reference: `tensorflow/tensorflow@sha256:08901711826b185136886c7b8271b9fdbe86b8ccb598669781a1f5cb340184eb`)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): pip on macOS, preinstalled in docker image
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: 3.6.9
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**

Suppose a Keras model that contains a layer that returns a sparse tensor, and that sparse tensor is used as input to a later layer. No `name`s are explicitly specified for any part of the model. Saving the model (with any of the `Model.save` method, `tf.saved_model.save` or `tf.keras.models.save_model`) hits an exception:

```
ValueError: If specifying TensorSpec names for nested structures, either zero or all names have to be specified.
```

If this is a problem in the user code, the exception doesn't make it clear:
- what the problem is
- where it is (e.g. which tensors/layers are effected) 
- how to fix it

For the second point, I ended up having to reduce (using a combination of creduce and manual editing) a much larger model to narrow down the problem from the original report in https://github.com/stellargraph/stellargraph/issues/1251.

(This may relate to #38465, in particular the ragged tensors mentioned in https://github.com/tensorflow/tensorflow/issues/38465#issuecomment-638542728.)

**Describe the expected behavior**

It would be good for at least one of:

- the exception message/metadata improved to answer the three points above, so it's easier to fix
- the code to work

**Standalone code to reproduce the issue**

```python
import tensorflow as tf

class SqueezedSparseConversion(tf.keras.layers.Layer):
    def call(self, inputs):
        return tf.SparseTensor([(0, 1)], [0.1], (3, 3))

class GraphConvolution(tf.keras.layers.Layer):
    def call(self, inputs):
        return inputs[0]

x_t = tf.keras.Input(0)
sp = SqueezedSparseConversion()(x_t)
out = GraphConvolution()([x_t, sp])

m = tf.keras.Model([x_t], out)
m.summary()
m.save("""")
```

This code is very simplified. In the real code, the `tf.SparseTensor` is constructed from data in `inputs`, and `GraphConvolution` does use the sparse tensor in `inputs[1]`, in addition to `inputs[0]`.

NB: if the sparse tensor is constructed purely within a layer, everything works:

```python
import tensorflow as tf

class GraphConvolution(tf.keras.layers.Layer):
    def call(self, inputs):
        sp = tf.SparseTensor([(0, 1)], [0.1], (3, 3))
        return inputs[0]

x_t = tf.keras.Input(0)
out = GraphConvolution()([x_t])

m = tf.keras.Model([x_t], out)
m.summary()
m.save("""")
```

**Other info / logs** 

```
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py"", line 1052, in save
    signatures, options)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py"", line 138, in save_model
    signatures, options)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save.py"", line 78, in save
    save_lib.save(model, filepath, signatures, options)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py"", line 951, in save
    obj, export_dir, signatures, options, meta_graph_def)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py"", line 1022, in _build_meta_graph
    _ = _SaveableView(checkpoint_graph_view)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py"", line 204, in __init__
    function._list_all_concrete_functions_for_serialization())  # pylint: disable=protected-access
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"", line 841, in _list_all_concrete_functions_for_serialization
    concrete_functions.append(self.get_concrete_function(*args, **kwargs))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 546, in get_concrete_function
    self.call_collection.add_trace(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 421, in add_trace
    fn.get_concrete_function(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 547, in get_concrete_function
    return super(LayerCall, self).get_concrete_function(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"", line 959, in get_concrete_function
    concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"", line 877, in _get_concrete_function_garbage_collected
    *args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 2496, in _get_concrete_function_garbage_collected
    graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 2777, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 2667, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py"", line 898, in func_graph_from_py_func
    args, arg_names, flat_shapes=arg_shapes)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py"", line 1132, in _get_defun_inputs_from_args
    args, names, structure=args, flat_shapes=flat_shapes)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py"", line 1196, in _get_defun_inputs
    raise ValueError(""If specifying TensorSpec names for nested structures, ""
ValueError: If specifying TensorSpec names for nested structures, either zero or all names have to be specified.
```"
40372,TPUStrategy does not export graph to TensorBoard while TPUEstimator does it,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Both Tested
- OS Platform and Distribution: Linux Ubuntu 18.04 on GCE
- TensorFlow installed from: PyPI, with `tensorflow==2.1.0`
- TensorFlow version: `v2.1.0-rc2-17-ge5bf8de 2.1.0`
- Python version: 3.6
- CUDA/cuDNN version: N/A (Issue from TPU environment)
- GPU model and memory: N/A (Same as above)
- (Additional) TensorBoard version: 2.1.0

**Describe the current behavior**

I've found [the official document from Google Cloud](https://cloud.google.com/tpu/docs/cloud-tpu-tools#xla_graphs) says that I can access to the graph by clicking `GRAPHS` tab inside TensorBoard without setting any other configuration to my code, so I constructed the graph and executed the training steps by using `TPUStrategy`. But I failed to find those informations on TensorBoard.

I additionally tested the official model by using `TPUEstimator` on V1 Compat API, and I could successfully obtain the graph data on TensorBoard. I assume this is a bug, but may need several help if not. Thank you!

**Describe the expected behavior**

The code below successfully export graph data on TensorBoard.

**Standalone code to reproduce the issue**

I've tested [the official tutorial using ResNet](https://github.com/tensorflow/tpu/blob/master/models/official/resnet/resnet_main.py), and saw it is successfully working.

Problem is at the code below:

> `Model` is very small toy model like `Linear-ReLU-Linear`, and was subclassed using `tf.keras`.

```python 
import tensorflow as tf
import os

from project.model import Model

def main():
    storage_name = ""google-cloud-storage-name""
    GRAPH_LOGDIR = f""{storage_name}/logs/""

    writer = tf.summary.create_file_writer(GRAPH_LOGDIR)

    resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=os.environ[""TPU_NAME""])
    tf.config.experimental_connect_to_cluster(resolver)
    tf.tpu.experimental.initialize_tpu_system(resolver)
    strategy = tf.distribute.experimental.TPUStrategy(resolver)

    with strategy.scope():
        model = Model()

        @tf.function
        def trace_model(model_input):
            return model(model_input)

        model_input = tf.ones((3, 48), tf.int64)

        tf.summary.trace_on(graph=True, profiler=True)
        trace_model(model_input)
        with writer.as_default():
            tf.summary.trace_export(name=""model_trace"", step=0, profiler_outdir=GRAPH_LOGDIR)

if __name__ == ""__main__"":
    main()
```

I estimated this code should work and export graph data to TensorBoard, but no any graph data was found.

**Other info / logs**

Every single examples were tested on Google Cloud, using Cloud TPU, Compute Engine, and Cloud Storage.
CC @ddehun"
40370,Image Encoding/Decoding and B64 Encoding/Decoding Not Working,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (or github SHA if from source): tf-nightly-gpu


**Provide the text output from tflite_convert**
```
2020-06-10 20:13:06.127888: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2020-06-10 20:13:08.090537: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library nvcuda.dll
2020-06-10 20:13:08.113383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1683] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce GTX 1060 computeCapability: 6.1
coreClock: 1.733GHz coreCount: 10 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 178.99GiB/s
2020-06-10 20:13:08.113524: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2020-06-10 20:13:08.116647: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
2020-06-10 20:13:08.119646: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2020-06-10 20:13:08.122447: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2020-06-10 20:13:08.126673: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2020-06-10 20:13:08.128467: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll
2020-06-10 20:13:08.135299: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2020-06-10 20:13:08.135697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1825] Adding visible gpu devices: 0
2020-06-10 20:13:08.136396: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-06-10 20:13:08.146065: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1eb4c32fa00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-06-10 20:13:08.146205: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-06-10 20:13:08.146679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1683] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce GTX 1060 computeCapability: 6.1
coreClock: 1.733GHz coreCount: 10 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 178.99GiB/s
2020-06-10 20:13:08.146785: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2020-06-10 20:13:08.146881: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
2020-06-10 20:13:08.146962: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2020-06-10 20:13:08.147058: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2020-06-10 20:13:08.147123: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2020-06-10 20:13:08.147222: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll
2020-06-10 20:13:08.147325: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2020-06-10 20:13:08.147829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1825] Adding visible gpu devices: 0
2020-06-10 20:13:08.640614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1224] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-06-10 20:13:08.640783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1230]      0
2020-06-10 20:13:08.640915: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1243] 0:   N
2020-06-10 20:13:08.641430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1369] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4826 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-06-10 20:13:08.644906: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1eb6d09aff0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-06-10 20:13:08.645004: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1060, Compute Capability 6.1
WARNING:tensorflow:From C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\keras\backend.py:467: set_learning_phase (from tensorflow.python.keras.backend) is deprecated and will be removed after 2020-10-11.
Instructions for updating:
Simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.
WARNING:tensorflow:From C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\training\tracking\tracking.py:105: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\training\tracking\tracking.py:105: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
2020-06-10 20:13:09.359436: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
2020-06-10 20:13:09.359812: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-06-10 20:13:09.361503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1683] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce GTX 1060 computeCapability: 6.1
coreClock: 1.733GHz coreCount: 10 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 178.99GiB/s
2020-06-10 20:13:09.361962: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2020-06-10 20:13:09.362238: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
2020-06-10 20:13:09.362494: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2020-06-10 20:13:09.362799: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2020-06-10 20:13:09.363040: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2020-06-10 20:13:09.363260: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll
2020-06-10 20:13:09.363492: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2020-06-10 20:13:09.363870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1825] Adding visible gpu devices: 0
2020-06-10 20:13:09.364116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1224] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-06-10 20:13:09.364323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1230]      0
2020-06-10 20:13:09.364533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1243] 0:   N
2020-06-10 20:13:09.364959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1369] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4826 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-06-10 20:13:09.390848: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:810] Optimization results for grappler item: graph_to_optimize
2020-06-10 20:13:09.391281: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812]   function_optimizer: Graph size after: 24 nodes (21), 27 edges (24), time = 1.991ms.
2020-06-10 20:13:09.391508: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812]   function_optimizer: Graph size after: 24 nodes (0), 27 edges (0), time = 0.906ms.
2020-06-10 20:13:09.391733: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:810] Optimization results for grappler item: decode_image_cond_jpeg_false_45
2020-06-10 20:13:09.391947: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812]   function_optimizer: Graph size after: 11 nodes (0), 12 edges (0), time = 0.673ms.
2020-06-10 20:13:09.392162: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812]   function_optimizer: Graph size after: 11 nodes (0), 12 edges (0), time = 0.593ms.
2020-06-10 20:13:09.392375: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:810] Optimization results for grappler item: decode_image_cond_jpeg_cond_png_cond_gif_false_75
2020-06-10 20:13:09.392602: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-06-10 20:13:09.392844: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-06-10 20:13:09.393065: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:810] Optimization results for grappler item: decode_image_cond_jpeg_cond_png_cond_gif_true_74
2020-06-10 20:13:09.393291: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-06-10 20:13:09.393513: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-06-10 20:13:09.393738: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:810] Optimization results for grappler item: decode_image_cond_jpeg_cond_png_false_64
2020-06-10 20:13:09.393958: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812]   function_optimizer: Graph size after: 8 nodes (0), 8 edges (0), time = 0.471ms.
2020-06-10 20:13:09.394159: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812]   function_optimizer: Graph size after: 8 nodes (0), 8 edges (0), time = 0.402ms.
2020-06-10 20:13:09.394365: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:810] Optimization results for grappler item: decode_image_cond_jpeg_cond_png_true_63
2020-06-10 20:13:09.394570: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-06-10 20:13:09.394760: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-06-10 20:13:09.394966: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:810] Optimization results for grappler item: decode_image_cond_jpeg_true_44
2020-06-10 20:13:09.395137: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-06-10 20:13:09.395308: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-06-10 20:13:09.497900: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:313] Ignored output_format.
2020-06-10 20:13:09.498161: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored drop_control_dependency.
2020-06-10 20:13:09.503781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1683] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce GTX 1060 computeCapability: 6.1
coreClock: 1.733GHz coreCount: 10 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 178.99GiB/s
2020-06-10 20:13:09.504393: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2020-06-10 20:13:09.504750: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
2020-06-10 20:13:09.504986: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2020-06-10 20:13:09.505255: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2020-06-10 20:13:09.505510: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2020-06-10 20:13:09.505846: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll
2020-06-10 20:13:09.506091: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2020-06-10 20:13:09.506647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1825] Adding visible gpu devices: 0
2020-06-10 20:13:09.506960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1224] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-06-10 20:13:09.507198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1230]      0
2020-06-10 20:13:09.507422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1243] 0:   N
2020-06-10 20:13:09.507869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1369] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4826 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1)
loc(fused[callsite(""decode_image/Substr@__inference_call_120""(""C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\ops\image_ops_impl.py"":2639:0) at callsite(""C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\util\dispatch.py"":201:0 at callsite(""dev.py"":30:0 at callsite(""C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\framework\func_graph.py"":955:0 at callsite(""C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\eager\function.py"":3722:0 at callsite(""C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\eager\def_function.py"":600:0 at callsite(""C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\framework\func_graph.py"":979:0 at callsite(""C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\eager\function.py"":3052:0 at callsite(""C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\eager\function.py"":3200:0 at ""C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\eager\function.py"":2842:0))))))))), ""image_byte_wrapper/StatefulPartitionedCall/decode_image/Substr""]): error: 'tf.Substr' op is neither a custom op nor a flex op
loc(fused[callsite(""decode_image/is_jpeg/Substr@__inference_call_120""(""C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\ops\image_ops_impl.py"":2707:0) at callsite(""C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\util\dispatch.py"":201:0 at callsite(""dev.py"":30:0 at callsite(""C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\framework\func_graph.py"":955:0 at callsite(""C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\eager\function.py"":3722:0 at callsite(""C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\eager\def_function.py"":600:0 at callsite(""C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\framework\func_graph.py"":979:0 at callsite(""C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\eager\function.py"":3052:0 at callsite(""C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\eager\function.py"":3200:0 at ""C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\eager\function.py"":2842:0))))))))), ""image_byte_wrapper/StatefulPartitionedCall/decode_image/is_jpeg/Substr""]): error: 'tf.Substr' op is neither a custom op nor a flex op
loc(""decode_image/cond_jpeg/is_png/Substr@decode_image_cond_jpeg_false_45""): error: 'tf.Substr' op is neither a custom op nor a flex op
loc(""decode_image/cond_jpeg/cond_png/cond_gif/Substr@decode_image_cond_jpeg_cond_png_cond_gif_false_75""): error: 'tf.Substr' op is neither a custom op nor a flex op
loc(""decode_image/cond_jpeg/cond_png/cond_gif/DecodeGif@decode_image_cond_jpeg_cond_png_cond_gif_true_74""): error: 'tf.DecodeGif' op is neither a custom op nor a flex op
loc(""decode_image/cond_jpeg/cond_png/DecodePng@decode_image_cond_jpeg_cond_png_true_63""): error: 'tf.DecodePng' op is neither a custom op nor a flex op
loc(""decode_image/cond_jpeg/DecodeJpeg@decode_image_cond_jpeg_true_44""): error: 'tf.DecodeJpeg' op is neither a custom op nor a flex op
error: failed while converting: 'main': Ops that need custom implementation (enabled via setting the -emit-custom-ops flag):
        tf.DecodeGif {device = """"}
        tf.DecodeJpeg {acceptable_fraction = 1.000000e+00 : f32, channels = 3 : i64, dct_method = """", device = """", fancy_upscaling = true, ratio = 1 : i64, try_recover_truncated = false}
        tf.DecodePng {channels = 3 : i64, device = """"}
        tf.Substr {T = i32, device = """", unit = ""BYTE""}
Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\lite\python\convert.py"", line 182, in toco_convert_protos
    model_str = wrap_toco.wrapped_toco_convert(model_flags_str,
  File ""C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\lite\python\wrap_toco.py"", line 32, in wrapped_toco_convert
    return _pywrap_toco_api.TocoConvert(
Exception: C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\ops\image_ops_impl.py:2639:1: error: 'tf.Substr' op is neither a custom op nor a flex op
    substr = string_ops.substr(contents, 0, 3)
^
C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\util\dispatch.py:201:1: note: called from
      return target(*args, **kwargs)
^
dev.py:30:1: note: called from
        image = tf.io.decode_image(inputs[0][0], channels=3)
^
C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\framework\func_graph.py:955:1: note: called from
            return autograph.converted_call(
^
C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\eager\function.py:3722:1: note: called from
    return wrapped_fn(*args, **kwargs)
^
C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\eager\def_function.py:600:1: note: called from
        return weak_wrapped_fn().__wrapped__(*args, **kwds)
^
C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\framework\func_graph.py:979:1: note: called from
      func_outputs = python_func(*func_args, **func_kwargs)
^
C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\eager\function.py:3052:1: note: called from
        func_graph_module.func_graph_from_py_func(
^
C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\eager\function.py:3200:1: note: called from
      graph_function = self._create_graph_function(args, kwargs)
^
C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\eager\function.py:2842:1: note: called from
      graph_function, _, _ = self._maybe_define_function(args, kwargs)
^
C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\ops\image_ops_impl.py:2639:1: note: see current operation: %2 = ""tf.Substr""(%1, %cst_1, %cst_0) {T = i32, device = """", unit = ""BYTE""} : (tensor<!tf.string>, tensor<i32>, tensor<i32>) -> tensor<!tf.string>
    substr = string_ops.substr(contents, 0, 3)
^
C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\ops\image_ops_impl.py:2707:1: error: 'tf.Substr' op is neither a custom op nor a flex op
        is_jpeg(contents), _jpeg, check_png, name='cond_jpeg')
^
C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\util\dispatch.py:201:1: note: called from
      return target(*args, **kwargs)
^
dev.py:30:1: note: called from
        image = tf.io.decode_image(inputs[0][0], channels=3)
^
C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\framework\func_graph.py:955:1: note: called from
            return autograph.converted_call(
^
C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\eager\function.py:3722:1: note: called from
    return wrapped_fn(*args, **kwargs)
^
C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\eager\def_function.py:600:1: note: called from
        return weak_wrapped_fn().__wrapped__(*args, **kwds)
^
C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\framework\func_graph.py:979:1: note: called from
      func_outputs = python_func(*func_args, **func_kwargs)
^
C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\eager\function.py:3052:1: note: called from
        func_graph_module.func_graph_from_py_func(
^
C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\eager\function.py:3200:1: note: called from
      graph_function = self._create_graph_function(args, kwargs)
^
C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\eager\function.py:2842:1: note: called from
      graph_function, _, _ = self._maybe_define_function(args, kwargs)
^
C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\ops\image_ops_impl.py:2707:1: note: see current operation: %3 = ""tf.Substr""(%1, %cst_1, %cst_0) {T = i32, device = """", unit = ""BYTE""} : (tensor<!tf.string>, tensor<i32>, tensor<i32>) -> tensor<!tf.string>
        is_jpeg(contents), _jpeg, check_png, name='cond_jpeg')
^
<unknown>:0: error: loc(""decode_image/cond_jpeg/is_png/Substr@decode_image_cond_jpeg_false_45""): 'tf.Substr' op is neither a custom op nor a flex op
<unknown>:0: note: loc(""decode_image/cond_jpeg/is_png/Substr@decode_image_cond_jpeg_false_45""): see current operation: %0 = ""tf.Substr""(%arg0, %cst_1, %cst_0) {T = i32, device = """", unit = ""BYTE""} : (tensor<!tf.string>, tensor<i32>, tensor<i32>) -> tensor<!tf.string>
<unknown>:0: error: loc(""decode_image/cond_jpeg/cond_png/cond_gif/Substr@decode_image_cond_jpeg_cond_png_cond_gif_false_75""): 'tf.Substr' op is neither a custom op nor a flex op
<unknown>:0: note: loc(""decode_image/cond_jpeg/cond_png/cond_gif/Substr@decode_image_cond_jpeg_cond_png_cond_gif_false_75""): see current operation: %0 = ""tf.Substr""(%arg0, %cst_0, %cst) {T = i32, device = """", unit = ""BYTE""} : (tensor<!tf.string>, tensor<i32>, tensor<i32>) -> tensor<!tf.string>
<unknown>:0: error: loc(""decode_image/cond_jpeg/cond_png/cond_gif/DecodeGif@decode_image_cond_jpeg_cond_png_cond_gif_true_74""): 'tf.DecodeGif' op is neither a custom op nor a flex op
<unknown>:0: note: loc(""decode_image/cond_jpeg/cond_png/cond_gif/DecodeGif@decode_image_cond_jpeg_cond_png_cond_gif_true_74""): see current operation: %0 = ""tf.DecodeGif""(%arg0) {device = """"} : (tensor<!tf.string>) -> tensor<?x?x?x3xui8>
<unknown>:0: error: loc(""decode_image/cond_jpeg/cond_png/DecodePng@decode_image_cond_jpeg_cond_png_true_63""): 'tf.DecodePng' op is neither a custom op nor a flex op
<unknown>:0: note: loc(""decode_image/cond_jpeg/cond_png/DecodePng@decode_image_cond_jpeg_cond_png_true_63""): see current operation: %0 = ""tf.DecodePng""(%arg0) {channels = 3 : i64, device = """"} : (tensor<!tf.string>) -> tensor<?x?x3xui8>
<unknown>:0: error: loc(""decode_image/cond_jpeg/DecodeJpeg@decode_image_cond_jpeg_true_44""): 'tf.DecodeJpeg' op is neither a custom op nor a flex op
<unknown>:0: note: loc(""decode_image/cond_jpeg/DecodeJpeg@decode_image_cond_jpeg_true_44""): see current operation: %0 = ""tf.DecodeJpeg""(%arg0) {acceptable_fraction = 1.000000e+00 : f32, channels = 3 : i64, dct_method = """", device = """", fancy_upscaling = true, ratio = 1 : i64, try_recover_truncated = false} : (tensor<!tf.string>) -> tensor<?x?x3xui8>
<unknown>:0: error: failed while converting: 'main': Ops that need custom implementation (enabled via setting the -emit-custom-ops flag):
        tf.DecodeGif {device = """"}
        tf.DecodeJpeg {acceptable_fraction = 1.000000e+00 : f32, channels = 3 : i64, dct_method = """", device = """", fancy_upscaling = true, ratio = 1 : i64, try_recover_truncated = false}
        tf.DecodePng {channels = 3 : i64, device = """"}
        tf.Substr {T = i32, device = """", unit = ""BYTE""}
<unknown>:0: note: see current operation: ""func""() ( {
^bb0(%arg0: tensor<?x1x!tf.string>):  // no predecessors
  %cst = ""std.constant""() {value = dense<""\FF\D8\FF""> : tensor<!tf.string>} : () -> tensor<!tf.string>
  %cst_0 = ""std.constant""() {value = dense<3> : tensor<i32>} : () -> tensor<i32>
  %cst_1 = ""std.constant""() {value = dense<0> : tensor<i32>} : () -> tensor<i32>
  %cst_2 = ""std.constant""() {value = dense<0> : tensor<1xi32>} : () -> tensor<1xi32>
  %cst_3 = ""std.constant""() {value = dense<1> : tensor<1xi32>} : () -> tensor<1xi32>
  %0 = ""tf.StridedSlice""(%arg0, %cst_2, %cst_3, %cst_3) {begin_mask = 0 : i64, device = """", ellipsis_mask = 0 : i64, end_mask = 0 : i64, new_axis_mask = 0 : i64, shrink_axis_mask = 1 : i64} : (tensor<?x1x!tf.string>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<1x!tf.string>
  %1 = ""tf.StridedSlice""(%0, %cst_2, %cst_3, %cst_3) {begin_mask = 0 : i64, device = """", ellipsis_mask = 0 : i64, end_mask = 0 : i64, new_axis_mask = 0 : i64, shrink_axis_mask = 1 : i64} : (tensor<1x!tf.string>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<!tf.string>
  %2 = ""tf.Substr""(%1, %cst_1, %cst_0) {T = i32, device = """", unit = ""BYTE""} : (tensor<!tf.string>, tensor<i32>, tensor<i32>) -> tensor<!tf.string>
  %3 = ""tf.Substr""(%1, %cst_1, %cst_0) {T = i32, device = """", unit = ""BYTE""} : (tensor<!tf.string>, tensor<i32>, tensor<i32>) -> tensor<!tf.string>
  %4 = ""tfl.equal""(%3, %cst) : (tensor<!tf.string>, tensor<!tf.string>) -> tensor<i1>
  %5 = ""tf.If""(%4, %1, %2) {_lower_using_switch_merge = false, _read_only_resource_inputs = [], device = """", else_branch = @decode_image_cond_jpeg_false_450, is_stateless = false, output_shapes = [#tf.shape<*>], then_branch = @decode_image_cond_jpeg_true_440} : (tensor<i1>, tensor<!tf.string>, tensor<!tf.string>) -> tensor<*xui8>
  ""std.return""(%5) : (tensor<*xui8>) -> ()
}) {sym_name = ""main"", tf.entry_function = {control_outputs = """", inputs = ""args_0"", outputs = ""Identity""}, type = (tensor<?x1x!tf.string>) -> tensor<*xui8>} : () -> ()


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""dev.py"", line 57, in <module>
    tflite = convert(model)
  File ""dev.py"", line 42, in convert
    tflite_model = converter.convert()
  File ""C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\lite\python\lite.py"", line 777, in convert
    return super(TFLiteKerasModelConverterV2,
  File ""C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\lite\python\lite.py"", line 591, in convert
    result = _toco_convert_impl(
  File ""C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\lite\python\convert.py"", line 555, in toco_convert_impl
    data = toco_convert_protos(
  File ""C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\lite\python\convert.py"", line 188, in toco_convert_protos
    raise ConverterError(str(e))
tensorflow.lite.python.convert.ConverterError: C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\ops\image_ops_impl.py:2639:1: error: 'tf.Substr' op is neither a custom op nor a flex op
    substr = string_ops.substr(contents, 0, 3)
^
C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\util\dispatch.py:201:1: note: called from
      return target(*args, **kwargs)
^
dev.py:30:1: note: called from
        image = tf.io.decode_image(inputs[0][0], channels=3)
^
C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\framework\func_graph.py:955:1: note: called from
            return autograph.converted_call(
^
C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\eager\function.py:3722:1: note: called from
    return wrapped_fn(*args, **kwargs)
^
C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\eager\def_function.py:600:1: note: called from
        return weak_wrapped_fn().__wrapped__(*args, **kwds)
^
C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\framework\func_graph.py:979:1: note: called from
      func_outputs = python_func(*func_args, **func_kwargs)
^
C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\eager\function.py:3052:1: note: called from
        func_graph_module.func_graph_from_py_func(
^
C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\eager\function.py:3200:1: note: called from
      graph_function = self._create_graph_function(args, kwargs)
^
C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\eager\function.py:2842:1: note: called from
      graph_function, _, _ = self._maybe_define_function(args, kwargs)
^
C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\ops\image_ops_impl.py:2639:1: note: see current operation: %2 = ""tf.Substr""(%1, %cst_1, %cst_0) {T = i32, device = """", unit = ""BYTE""} : (tensor<!tf.string>, tensor<i32>, tensor<i32>) -> tensor<!tf.string>
    substr = string_ops.substr(contents, 0, 3)
^
C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\ops\image_ops_impl.py:2707:1: error: 'tf.Substr' op is neither a custom op nor a flex op
        is_jpeg(contents), _jpeg, check_png, name='cond_jpeg')
^
C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\util\dispatch.py:201:1: note: called from
      return target(*args, **kwargs)
^
dev.py:30:1: note: called from
        image = tf.io.decode_image(inputs[0][0], channels=3)
^
C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\framework\func_graph.py:955:1: note: called from
            return autograph.converted_call(
^
C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\eager\function.py:3722:1: note: called from
    return wrapped_fn(*args, **kwargs)
^
C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\eager\def_function.py:600:1: note: called from
        return weak_wrapped_fn().__wrapped__(*args, **kwds)
^
C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\framework\func_graph.py:979:1: note: called from
      func_outputs = python_func(*func_args, **func_kwargs)
^
C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\eager\function.py:3052:1: note: called from
        func_graph_module.func_graph_from_py_func(
^
C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\eager\function.py:3200:1: note: called from
      graph_function = self._create_graph_function(args, kwargs)
^
C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\eager\function.py:2842:1: note: called from
      graph_function, _, _ = self._maybe_define_function(args, kwargs)
^
C:\ProgramData\Anaconda3\envs\deblurring-gpu\lib\site-packages\tensorflow\python\ops\image_ops_impl.py:2707:1: note: see current operation: %3 = ""tf.Substr""(%1, %cst_1, %cst_0) {T = i32, device = """", unit = ""BYTE""} : (tensor<!tf.string>, tensor<i32>, tensor<i32>) -> tensor<!tf.string>
        is_jpeg(contents), _jpeg, check_png, name='cond_jpeg')
^
<unknown>:0: error: loc(""decode_image/cond_jpeg/is_png/Substr@decode_image_cond_jpeg_false_45""): 'tf.Substr' op is neither a custom op nor a flex op
<unknown>:0: note: loc(""decode_image/cond_jpeg/is_png/Substr@decode_image_cond_jpeg_false_45""): see current operation: %0 = ""tf.Substr""(%arg0, %cst_1, %cst_0) {T = i32, device = """", unit = ""BYTE""} : (tensor<!tf.string>, tensor<i32>, tensor<i32>) -> tensor<!tf.string>
<unknown>:0: error: loc(""decode_image/cond_jpeg/cond_png/cond_gif/Substr@decode_image_cond_jpeg_cond_png_cond_gif_false_75""): 'tf.Substr' op is neither a custom op nor a flex op
<unknown>:0: note: loc(""decode_image/cond_jpeg/cond_png/cond_gif/Substr@decode_image_cond_jpeg_cond_png_cond_gif_false_75""): see current operation: %0 = ""tf.Substr""(%arg0, %cst_0, %cst) {T = i32, device = """", unit = ""BYTE""} : (tensor<!tf.string>, tensor<i32>, tensor<i32>) -> tensor<!tf.string>
<unknown>:0: error: loc(""decode_image/cond_jpeg/cond_png/cond_gif/DecodeGif@decode_image_cond_jpeg_cond_png_cond_gif_true_74""): 'tf.DecodeGif' op is neither a custom op nor a flex op
<unknown>:0: note: loc(""decode_image/cond_jpeg/cond_png/cond_gif/DecodeGif@decode_image_cond_jpeg_cond_png_cond_gif_true_74""): see current operation: %0 = ""tf.DecodeGif""(%arg0) {device = """"} : (tensor<!tf.string>) -> tensor<?x?x?x3xui8>
<unknown>:0: error: loc(""decode_image/cond_jpeg/cond_png/DecodePng@decode_image_cond_jpeg_cond_png_true_63""): 'tf.DecodePng' op is neither a custom op nor a flex op
<unknown>:0: note: loc(""decode_image/cond_jpeg/cond_png/DecodePng@decode_image_cond_jpeg_cond_png_true_63""): see current operation: %0 = ""tf.DecodePng""(%arg0) {channels = 3 : i64, device = """"} : (tensor<!tf.string>) -> tensor<?x?x3xui8>
<unknown>:0: error: loc(""decode_image/cond_jpeg/DecodeJpeg@decode_image_cond_jpeg_true_44""): 'tf.DecodeJpeg' op is neither a custom op nor a flex op
<unknown>:0: note: loc(""decode_image/cond_jpeg/DecodeJpeg@decode_image_cond_jpeg_true_44""): see current operation: %0 = ""tf.DecodeJpeg""(%arg0) {acceptable_fraction = 1.000000e+00 : f32, channels = 3 : i64, dct_method = """", device = """", fancy_upscaling = true, ratio = 1 : i64, try_recover_truncated = false} : (tensor<!tf.string>) -> tensor<?x?x3xui8>
<unknown>:0: error: failed while converting: 'main': Ops that need custom implementation (enabled via setting the -emit-custom-ops flag):
        tf.DecodeGif {device = """"}
        tf.DecodeJpeg {acceptable_fraction = 1.000000e+00 : f32, channels = 3 : i64, dct_method = """", device = """", fancy_upscaling = true, ratio = 1 : i64, try_recover_truncated = false}
        tf.DecodePng {channels = 3 : i64, device = """"}
        tf.Substr {T = i32, device = """", unit = ""BYTE""}
<unknown>:0: note: see current operation: ""func""() ( {
^bb0(%arg0: tensor<?x1x!tf.string>):  // no predecessors
  %cst = ""std.constant""() {value = dense<""\FF\D8\FF""> : tensor<!tf.string>} : () -> tensor<!tf.string>
  %cst_0 = ""std.constant""() {value = dense<3> : tensor<i32>} : () -> tensor<i32>
  %cst_1 = ""std.constant""() {value = dense<0> : tensor<i32>} : () -> tensor<i32>
  %cst_2 = ""std.constant""() {value = dense<0> : tensor<1xi32>} : () -> tensor<1xi32>
  %cst_3 = ""std.constant""() {value = dense<1> : tensor<1xi32>} : () -> tensor<1xi32>
  %0 = ""tf.StridedSlice""(%arg0, %cst_2, %cst_3, %cst_3) {begin_mask = 0 : i64, device = """", ellipsis_mask = 0 : i64, end_mask = 0 : i64, new_axis_mask = 0 : i64, shrink_axis_mask = 1 : i64} : (tensor<?x1x!tf.string>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<1x!tf.string>
  %1 = ""tf.StridedSlice""(%0, %cst_2, %cst_3, %cst_3) {begin_mask = 0 : i64, device = """", ellipsis_mask = 0 : i64, end_mask = 0 : i64, new_axis_mask = 0 : i64, shrink_axis_mask = 1 : i64} : (tensor<1x!tf.string>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<!tf.string>
  %2 = ""tf.Substr""(%1, %cst_1, %cst_0) {T = i32, device = """", unit = ""BYTE""} : (tensor<!tf.string>, tensor<i32>, tensor<i32>) -> tensor<!tf.string>
  %3 = ""tf.Substr""(%1, %cst_1, %cst_0) {T = i32, device = """", unit = ""BYTE""} : (tensor<!tf.string>, tensor<i32>, tensor<i32>) -> tensor<!tf.string>
  %4 = ""tfl.equal""(%3, %cst) : (tensor<!tf.string>, tensor<!tf.string>) -> tensor<i1>
  %5 = ""tf.If""(%4, %1, %2) {_lower_using_switch_merge = false, _read_only_resource_inputs = [], device = """", else_branch = @decode_image_cond_jpeg_false_450, is_stateless = false, output_shapes = [#tf.shape<*>], then_branch = @decode_image_cond_jpeg_true_440} : (tensor<i1>, tensor<!tf.string>, tensor<!tf.string>) -> tensor<*xui8>
  ""std.return""(%5) : (tensor<*xui8>) -> ()
}) {sym_name = ""main"", tf.entry_function = {control_outputs = """", inputs = ""args_0"", outputs = ""Identity""}, type = (tensor<?x1x!tf.string>) -> tensor<*xui8>} : () -> ()
```

**Standalone code to reproduce the issue** 
```
import tensorflow as tf

class ImageByteWrapper(tf.keras.Model):
    @tf.function(input_signature=[tf.TensorSpec(shape=[None, 1], dtype=tf.string)])
    def call(self, inputs):
        # Decode image into 4D tensor
        return tf.io.decode_image(inputs[0][0], channels=3)

def convert(model):
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]
    converter.target_spec.supported_ops = [
        tf.lite.OpsSet.TFLITE_BUILTINS,
        tf.lite.OpsSet.SELECT_TF_OPS,
    ]
    tflite_model = converter.convert()

    return tflite_model

model = ImageByteWrapper()

test_input = tf.random.uniform(shape=[64, 64, 3], minval=0, maxval=255, dtype=tf.int32)
test_input = tf.cast(test_input, dtype=tf.uint8)
test_input = tf.io.encode_jpeg(test_input)
test_input = tf.stack([test_input, test_input])
test_input = tf.reshape(test_input, [-1, 1])

with tf.device('/cpu:0'):
    test_output = model(test_input)

tflite = convert(model)
```

Most of the image encoding/decoding ops as well as Base64 encode/decode ops are not working. This is important because in production when deploying to some API is easier to transfer the data under b64 encoding or bytes encoding rather than actual tensors.

I just supplied the minimal example with tf.decode_image() for minimalism."
40369,model.load_weights fails to find matching files in gcs bucket,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux - colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
N/A
- TensorFlow installed from (source or binary):
default colab installation
- TensorFlow version (use command below):
- Python version:
3.6.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
model.load_weights from a gcs bucket fails to find matching files even though they exist

**Describe the expected behavior**
Find the files and load the weights

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

https://colab.research.google.com/drive/1PVXhopZg5RpKiJ6aUilO0oknsfNFX_Nr?usp=sharing


**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40366,Raise ValueError when saving a model created in mirroredstrategy,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Yes
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): tf-nightly
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
The model is created inside a mirroredstrategy. When I save the model using `model.save(save_path)` after training, it raises `ValueError: SyncOnReadVariable does not support `assign_add` in cross-replica context when aggregation is set to `tf.VariableAggregation.SUM`.` The error is triggered [here](https://github.com/tensorflow/models/blob/master/official/recommendation/ncf_keras_main.py#L85). The related error tracing is:

```python
  File ""ncf_keras_main.py"", line 85, in call
    self.add_metric(hr_sum, name=""hr_sum"", aggregation=""mean"")
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 1678, in add_metric
    metric_obj(value)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/metrics.py"", line 231, in __call__
    replica_local_fn, *args, **kwargs)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/distribute/distributed_training_utils.py"", line 1133, in call_replica_local_fn
    return fn(*args, **kwargs)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/metrics.py"", line 211, in replica_local_fn
    update_op = self.update_state(*args, **kwargs)  # pylint: disable=not-callable
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/utils/metrics_utils.py"", line 90, in decorated
    update_op = update_state_fn(*args, **kwargs)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/metrics.py"", line 176, in update_state_fn
    return ag_update_state(*args, **kwargs)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py"", line 302, in wrapper
    return func(*args, **kwargs)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/metrics.py"", line 373, in update_state
    update_total_op = self.total.assign_add(value_sum)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/distribute/values.py"", line 918, in assign_add
    ""SyncOnReadVariable does not support `assign_add` in ""
ValueError: SyncOnReadVariable does not support `assign_add` in cross-replica context when aggregation is set to `tf.VariableAggregation.SUM`.
```
I also attached a complete tracing for your reference.

**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
```python
Traceback (most recent call last):
  File ""ncf_keras_main.py"", line 568, in <module>
    app.run(main)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""ncf_keras_main.py"", line 563, in main
    logging.info(""Result is %s"", run_ncf(FLAGS))
  File ""ncf_keras_main.py"", line 351, in run_ncf
    keras_model.save(""save_model"")
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py"", line 1950, in save
    signatures, options)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py"", line 134, in save_model
    signatures, options)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/save.py"", line 78, in save
    save_lib.save(model, filepath, signatures, options)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py"", line 953, in save
    obj, export_dir, signatures, options, meta_graph_def)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py"", line 1015, in _build_meta_graph
    checkpoint_graph_view)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/saved_model/signature_serialization.py"", line 75, in find_function_to_export
    functions = saveable_view.list_functions(saveable_view.root)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py"", line 144, in list_functions
    self._serialization_cache)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py"", line 2543, in _list_functions_for_serialization
    Model, self)._list_functions_for_serialization(serialization_cache)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 3014, in _list_functions_for_serialization
    .list_functions_for_serialization(serialization_cache))
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/base_serialization.py"", line 87, in list_functions_for_serialization
    fns = self.functions_to_serialize(serialization_cache)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py"", line 77, in functions_to_serialize
    serialization_cache).functions_to_serialize)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py"", line 92, in _get_serialized_attributes
    serialization_cache)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/model_serialization.py"", line 51, in _get_serialized_attributes_internal
    default_signature = save_impl.default_save_signature(self.obj)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 205, in default_save_signature
    fn.get_concrete_function()
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 1168, in get_concrete_function
    concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 1074, in _get_concrete_function_garbage_collected
    self._initialize(args, kwargs, add_initializers_to=initializers)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 697, in _initialize
    *args, **kwds))
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 2842, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 3200, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 3062, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py"", line 979, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 600, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/saving/saving_utils.py"", line 132, in _wrapped_model
    outputs = model(inputs, training=False)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 961, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py"", line 385, in call
    inputs, training=training, mask=mask)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py"", line 507, in _run_internal_graph
    outputs = node.layer(*args, **kwargs)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 961, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py"", line 302, in wrapper
    return func(*args, **kwargs)
  File ""ncf_keras_main.py"", line 85, in call
    self.add_metric(hr_sum, name=""hr_sum"", aggregation=""mean"")
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 1678, in add_metric
    metric_obj(value)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/metrics.py"", line 231, in __call__
    replica_local_fn, *args, **kwargs)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/distribute/distributed_training_utils.py"", line 1133, in call_replica_local_fn
    return fn(*args, **kwargs)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/metrics.py"", line 211, in replica_local_fn
    update_op = self.update_state(*args, **kwargs)  # pylint: disable=not-callable
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/utils/metrics_utils.py"", line 90, in decorated
    update_op = update_state_fn(*args, **kwargs)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/metrics.py"", line 176, in update_state_fn
    return ag_update_state(*args, **kwargs)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py"", line 302, in wrapper
    return func(*args, **kwargs)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/metrics.py"", line 373, in update_state
    update_total_op = self.total.assign_add(value_sum)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/distribute/values.py"", line 918, in assign_add
    ""SyncOnReadVariable does not support `assign_add` in ""
ValueError: SyncOnReadVariable does not support `assign_add` in cross-replica context when aggregation is set to `tf.VariableAggregation.SUM`.
```"
40365,file_hash not validated after downloading in Keras.utils.data_utils.get_file().,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, but basically excerpted from keras.applications. 
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: 
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b
- Python version: 3.7.3
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:


**Describe the current behavior**
The `file_hash` is checked only when local pre-existing file is found, but not when the file is newly downloaded. 

**Describe the expected behavior**
The `file_hash` should also be checked once download is complete. 

**Standalone code to reproduce the issue**
As an example, I take code from `keras.applications` and deliberately have file path and file hash mismatch. In particular, I use the hash for no-top version but provide the path with the full model version. 
```
import tensorflow as tf
from tensorflow.python.keras.utils import data_utils

WEIGHTS_PATH_NO_TOP = (
    'https://storage.googleapis.com/tensorflow/keras-applications/'
    'inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels.h5')

weights_path = data_utils.get_file(
    'inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5',
    WEIGHTS_PATH_NO_TOP,
    cache_subdir='models',
    file_hash='bcbd6486424b2319ff4ef7d526e38f63')
```
It does not warn about file hash mismatch as it should, and blindly trust the newly downloaded file. 

"
40363,Convert .tflite file to human-readable format,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): source
- TensorFlow version (or github SHA if from source): 1.15

-------------------------------------------

Is there a recommended way to convert a .tflite file into a human-readable format?  I often encounter issues with .tflite models (e.g. poor prediction performance), even though there are no error messages in the TF-->TFL conversion process.  Being able to read the contents of the .tflite file would really help with the debug process.  Thanks."
40361,Bug with keras applications preprocess_input method,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, attached
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): pip installation
- TensorFlow version (use command below): 2.1.1. The bug that lead me to find this out also happened in 1.14.0, 1.15.3, so worth to check them out too.
- Python version: 3.7.7
- CUDA/cuDNN version: 10.1 / 7.6.5
- GPU model and memory: GeForce GTX 1050 Ti

**Describe the current behavior**
`tf.keras.applications.<model_name>.preprocess_input` behaves inconsistently between numpy arrays and tensorflow tensors, depending on `dtype`.
Also, there's a difference between working with CPU and GPU in case of tensorflow tensors with dtype `tf.uint8`.

For numpy arrays, the below code works for both `uint8` and `float32` dtypes.
However, for tensorflow tensors, the below doesn't behave correctly for `uint8` dtype, and behaves differently between GPU and CPU for this dtype.
Current output:
```
$ export CUDA_VISIBLE_DEVICES=; python test.py 2> /dev/null
CPU
numpy, uint8: [[[[ -1.939003 -15.778999 -23.68    ]]]]
numpy, float32: [[[[ -1.939003 -15.778999 -23.68    ]]]]
tensorflow, uint8: tf.Tensor([[[[255 241 233]]]], shape=(1, 1, 1, 3), dtype=uint8)
tensorflow, float32: tf.Tensor([[[[ -1.939003 -15.778999 -23.68    ]]]], shape=(1, 1, 1, 3), dtype=float32)

$ export CUDA_VISIBLE_DEVICES=0; python test.py 2> /dev/null
GPU
numpy, uint8: [[[[ -1.939003 -15.778999 -23.68    ]]]]
numpy, float32: [[[[ -1.939003 -15.778999 -23.68    ]]]]
tensorflow, uint8: tf.Tensor([[[[102 101 100]]]], shape=(1, 1, 1, 3), dtype=uint8)
tensorflow, float32: tf.Tensor([[[[ -1.939003 -15.778999 -23.68    ]]]], shape=(1, 1, 1, 3), dtype=float32)
```

This issue can be traced to `keras_applications.imagenet_utils`'s preprocess_input, which behaves differently for numpy arrays vs. tensorflow tensors, and in case of tensors - doesn't do casting of dtype, unlike in the case of numpy array.

**Describe the expected behavior**
Same result as numpy array with dtype `float32` for all of the outputs.

**Standalone code to reproduce the issue**
Run once with `CUDA_VISIBLE_DEVICES=` and once with `CUDA_VISIBLE_DEVICES=0`.
```
import numpy as np
import tensorflow as tf
from tensorflow.keras.applications.resnet50 import preprocess_input

print('GPU' if tf.config.list_physical_devices('GPU') else 'CPU')
arr = np.array([100, 101, 102], dtype=np.uint8).reshape((1, 1, 1, 3))
print('numpy, uint8:', preprocess_input(arr))
arr = np.array([100, 101, 102], dtype=np.float32).reshape((1, 1, 1, 3))
print('numpy, float32:', preprocess_input(arr))
arr = tf.reshape(tf.constant([100, 101, 102], dtype=tf.uint8), (1, 1, 1, 3))
print('tensorflow, uint8:', preprocess_input(arr))
arr = tf.reshape(tf.constant([100, 101, 102], dtype=tf.float32), (1, 1, 1, 3))
print('tensorflow, float32:', preprocess_input(arr))
```"
40360,same error using tflearn package ==0.3.2 and tenserflow ==1.14,"some error using tflearn package ==0.3.2 and tenserflow ==1.14 

error:'tensorflow.python.framework.op_def_registry' has no attribute 'register_op_list'

_Originally posted by @BV-SS in https://github.com/tensorflow/tensorflow/issues/34762#issuecomment-642140322_"
40359,Seg fault while post quantizing my model,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OS Linux 18.04.04 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): python wheel
- TensorFlow version (use command below): 2.2.0-rc4
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:10.1
- GPU model and memory: TitanV , 12 GB

I am trying to do post training quantization for the EfficientDet-D0 model pre-trained on COCO I got from his repo : https://github.com/google/automl  
Desired quantization is int8 because it needs to be running on a google coral.

Below is the code that I use:

`from PIL import Image
import numpy as np
export_dir = ""./savedmodeldir""

model = tf.saved_model.load(export_dir)

concrete_func = model.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]
concrete_func.inputs[0].set_shape([1, 512, 512, 3])
converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])

converter.optimizations = [tf.lite.Optimize.DEFAULT]
def representative_dataset_gen():
  num_calibration_steps=10
  path_to_img='./img/img.jpg'
  for _ in range(num_calibration_steps):
    # Get sample input data as a numpy array in a method of your choosing.
    im = np.asarray(Image.open(path_to_img).resize((512,512)),dtype=np.uint8)
    im=np.reshape(im, [1,512,512,3])
    with tf.device('/CPU:0'):
      image=tf.convert_to_tensor(im)
    yield [image]
converter.representative_dataset = representative_dataset_gen
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.int8  # or tf.uint8
converter.inference_output_type = tf.int8  # or tf.uint8

tflite_quant_model = converter.convert()`

Link to the savedmodeldir zip file:
https://drive.google.com/file/d/1Hsbox0LRm6z9FecnobMP7YK7ZJyFjknt/view?usp=sharing

The output I get while running the code:

WARNING:tensorflow:Importing a function (MetaGraph import) with ops with custom gradients. Will likely fail if a gradient is requested.
WARNING:tensorflow:Importing a function (MetaGraph import) with ops with custom gradients. Will likely fail if a gradient is requested.
WARNING:tensorflow:From /home/shrey/.local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
WARNING:tensorflow:Issue encountered when serializing global_step.
Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.
to_proto not supported in EAGER mode.
WARNING:tensorflow:Issue encountered when serializing moving_average_variables.
Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.
to_proto not supported in EAGER mode.
WARNING:tensorflow:Issue encountered when serializing variables.
Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.
to_proto not supported in EAGER mode.
WARNING:tensorflow:Issue encountered when serializing trainable_variables.
Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.
to_proto not supported in EAGER mode.
2020-06-10 11:40:38.281380: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
2020-06-10 11:40:38.281495: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-06-10 11:40:38.432064: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize
2020-06-10 11:40:38.432098: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 3786 nodes (0), 3573 edges (0), time = 21.187ms.
2020-06-10 11:40:38.432102: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 3786 nodes (0), 3573 edges (0), time = 26.002ms.
2020-06-10 11:40:38.432105: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: __inference_TensorArrayV2Write_cond_true_136_1822
2020-06-10 11:40:38.432109: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-06-10 11:40:38.432112: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-06-10 11:40:38.432115: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: __inference_cond_png_true_83_1595
2020-06-10 11:40:38.432118: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-06-10 11:40:38.432121: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-06-10 11:40:38.432124: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: __inference_while_body_23_4372
2020-06-10 11:40:38.432128: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 38 nodes (0), 41 edges (0), time = 0.721ms.
2020-06-10 11:40:38.432131: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 38 nodes (0), 41 edges (0), time = 0.751ms.
2020-06-10 11:40:38.432134: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: __inference_TensorArrayV2Write_cond_false_137_1473
2020-06-10 11:40:38.432137: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-06-10 11:40:38.432140: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-06-10 11:40:38.432143: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: __inference_cond_gif_true_93_2677
2020-06-10 11:40:38.432148: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-06-10 11:40:38.432151: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-06-10 11:40:38.432154: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: __inference_cond_gif_false_94_4320
2020-06-10 11:40:38.432158: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-06-10 11:40:38.432161: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-06-10 11:40:38.432185: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: __inference_decode_image_cond_jpeg_true_65_2555
2020-06-10 11:40:38.432190: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-06-10 11:40:38.432194: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-06-10 11:40:38.432198: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: __inference_decode_image_cond_jpeg_false_66_4339
2020-06-10 11:40:38.432202: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 10 nodes (0), 10 edges (0), time = 0.32ms.
2020-06-10 11:40:38.432210: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 10 nodes (0), 10 edges (0), time = 0.316ms.
2020-06-10 11:40:38.432213: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: __inference_while_cond_22_6546
2020-06-10 11:40:38.432219: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-06-10 11:40:38.432222: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-06-10 11:40:38.432227: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: __inference_cond_png_false_84_4328
2020-06-10 11:40:38.432230: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 7 nodes (0), 6 edges (0), time = 0.234ms.
2020-06-10 11:40:38.432234: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 7 nodes (0), 6 edges (0), time = 0.248ms.
2020-06-10 11:40:40.776624: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
2020-06-10 11:40:40.776752: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-06-10 11:40:41.366677: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize
2020-06-10 11:40:41.366709: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 2739 nodes (-1047), 2330 edges (-1243), time = 481.837ms.
2020-06-10 11:40:41.366713: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 2739 nodes (0), 2330 edges (0), time = 49.056ms.
Aborted (core dumped)


"
40358,"clang error: the clang compiler does not support '-march=native' [TF Lite, Android ARM]","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.14.6
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
- TensorFlow installed from (source or binary): trying to build
- TensorFlow version: 2.2.0
- Python version: 2.7
- Installed using virtualenv? pip? conda?: not installed
- Bazel version (if compiling from source): 2.0.0
- GCC/Compiler version (if compiling from source): not sure, I'm cross-compiling
- CUDA/cuDNN version: none
- GPU model and memory: none

**Describe the problem**

I'm trying to cross-compile TF Lite to Android. I want to create a cc_library that depends on //tensorflow/lite:framework, but it fails for ARM with the message:  

> clang: error: the clang compiler does not support '-march=native'

I can reproduce this in a clean TF repo with lite:framework itself,

```
bazel build -c opt --config=opt --config=android_arm64 --cxxopt=--std=c++11 --jobs=1 -s //tensorflow/lite:framework
```

It works fine for x86/x64 targets. It also works fine without --config=opt, which is adding the march=native flag. This `--config=opt` is advertised in many places of the source code, it's even configured in ./configure, so it's quite confusing to see that it does not work with common architectures.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

See above.

**Any other info / logs**

```
SUBCOMMAND: # //tensorflow/lite:framework [action 'Compiling tensorflow/lite/core/subgraph.cc', configuration: 45cc65458d2ef84231c73814ce4897ab5307bd5feffcfb2bfb3a1cf29f72c29c]
(cd /private/var/tmp/_bazel_natario/9e86fd2d24b8ec3357d15a3569d12c31/execroot/org_tensorflow && \
  exec env - \
    ANDROID_BUILD_TOOLS_VERSION=29.0.2 \
    ANDROID_NDK_API_LEVEL=18 \
    ANDROID_NDK_HOME=/Users/natario/Library/Android/sdk/ndk/20.1.5948944 \
    ANDROID_SDK_API_LEVEL=29 \
    ANDROID_SDK_HOME=/Users/natario/library/Android/Sdk \
    PATH=/Library/Frameworks/Python.framework/Versions/3.7/bin:/Users/natario/.rvm/gems/ruby-2.6.3/bin:/Users/natario/.rvm/gems/ruby-2.6.3@global/bin:/Users/natario/.rvm/rubies/ruby-2.6.3/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Users/natario/Library/Android/sdk/emulator:/Users/natario/Library/Android/sdk/tools:/Users/natario/Library/Android/sdk/tools/bin:/Users/natario/Library/Android/sdk/platform-tools:/Users/natario/bin:/Users/natario/.rvm/bin \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/usr/bin/python \
    PYTHON_LIB_PATH=/Library/Python/2.7/site-packages \
    TF2_BEHAVIOR=1 \
    TF_CONFIGURE_IOS=0 \
    TF_ENABLE_XLA=1 \
  external/androidndk/ndk/toolchains/llvm/prebuilt/darwin-x86_64/bin/clang -gcc-toolchain external/androidndk/ndk/toolchains/aarch64-linux-android-4.9/prebuilt/darwin-x86_64 -target aarch64-none-linux-android -fpic -isystemexternal/androidndk/ndk/sysroot/usr/include/aarch64-linux-android '-D__ANDROID_API__=18' -no-canonical-prefixes -Wno-invalid-command-line-argument -Wno-unused-command-line-argument -funwind-tables -fstack-protector-strong -fno-addrsig '-Werror=return-type' '-Werror=int-to-pointer-cast' '-Werror=pointer-to-int-cast' '-Werror=implicit-function-declaration' -O2 -g -DNDEBUG -MD -MF bazel-out/arm64-v8a-opt/bin/tensorflow/lite/_objs/framework/subgraph.pic.d '-frandom-seed=bazel-out/arm64-v8a-opt/bin/tensorflow/lite/_objs/framework/subgraph.pic.o' -fPIC -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/arm64-v8a-opt/bin -iquote external/flatbuffers -iquote bazel-out/arm64-v8a-opt/bin/external/flatbuffers -iquote external/com_google_absl -iquote bazel-out/arm64-v8a-opt/bin/external/com_google_absl -Ibazel-out/arm64-v8a-opt/bin/external/flatbuffers/_virtual_includes/runtime_cc -Ibazel-out/arm64-v8a-opt/bin/external/flatbuffers/_virtual_includes/flatbuffers -Ibazel-out/arm64-v8a-opt/bin/external/flatbuffers/src/_virtual_includes/flatbuffers -isystem tensorflow/lite/schema -isystem bazel-out/arm64-v8a-opt/bin/tensorflow/lite/schema -w '-march=native' -Wno-sign-compare '-std=c++14' '--std=c++11' -DFARMHASH_NO_CXX_STRING -Wno-sign-compare -O3 -ffunction-sections -fdata-sections -fno-exceptions -Wall -Wno-comment -Wno-extern-c-compat '--sysroot=external/androidndk/ndk/platforms/android-28/arch-arm64' -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++abi/include -isystem external/androidndk/ndk/sources/android/support/include -isystemexternal/androidndk/ndk/sysroot/usr/include -c tensorflow/lite/core/subgraph.cc -o bazel-out/arm64-v8a-opt/bin/tensorflow/lite/_objs/framework/subgraph.pic.o)
ERROR: /Users/natario/Projects/XXX/tensorflow/tensorflow/lite/BUILD:204:1: C++ compilation of rule '//tensorflow/lite:framework' failed (Exit 1)
clang: error: the clang compiler does not support '-march=native'
```
"
40357,[TF Lite] TfLiteGpuDelegate Init: CONV_2D: Unsupported data type for float32 tensor,"**System information**

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04
- TensorFlow installed from (source or binary): `pip install tensorflow`
- TensorFlow version (or github SHA if from source): 2.2.0
- TensorFlow Lite version: `org.tensorflow:tensorflow-lite:2.2.0`, `org.tensorflow:tensorflow-lite-gpu:2.2.0`

**Command used to run the converter or code if you’re using the Python API**
The code used to run the converter can be found in this notebook: https://github.com/franksacco/where-is-wally/blob/master/converter.ipynb.

In particular, the part of interest is:
```python
from tensorflow import lite

converter = lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [lite.Optimize.DEFAULT]
tflite_model = converter.convert()

with open('models/unet_v2.f1lo-b14-e60-lr0.001.44.optimized.tflite', 'wb') as f:
    f.write(tflite_model)
```

**The output from the converter invocation**

The optimized TFLite model is successfully generated.

**Also, please include a link to the saved model or GraphDef**

- Trained model: https://github.com/franksacco/where-is-wally/raw/master/models/unet_v2.f1lo-b14-e60-lr0.001.44.hdf5
- Optimized TFLite Model: https://github.com/franksacco/where-is-wally/raw/master/models/unet_v2.f1lo-b14-e60-lr0.001.44.optimized.tflite

The model uses [this implementation](https://www.depends-on-the-definition.com/unet-keras-segmenting-images/) of the [U-Net](https://arxiv.org/pdf/1505.04597.pdf) and takes a 256x256x3 image and outputs a 256x256x1 grayscale mask.

**Failure details**

The model without optimizations works perfectly.\
The model with optimizations works correctly when executed on the CPU.

However, when I try to initialize the TFLite interpreter with the GPU delegate using the following code, I get the error `java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: TfLiteGpuDelegate Init: CONV_2D: Unsupported data type for float32 tensor`.
```java
MappedByteBuffer model = FileUtil.loadMappedFile(
    activity, ""unet_v2.f1lo-b14-e60-lr0.001.44.optimized.tflite""
);

Interpreter.Options options = new Interpreter.Options();
options.addDelegate(new GpuDelegate());

Interpreter interpreter = new Interpreter(model, options);
```

**Any other info / logs**

Traceback of the exception:
```
I/tflite: Created TensorFlow Lite delegate for GPU.
I/tflite: Initialized TensorFlow Lite runtime.
W/System.err: java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: TfLiteGpuDelegate Init: CONV_2D: Unsupported data type for float32 tensor
W/System.err: TfLiteGpuDelegate Prepare: delegate is not initialized
    Node number 36 (TfLiteGpuDelegateV2) failed to prepare.
    Restored previous execution plan after delegate application failure.
W/System.err:     at org.tensorflow.lite.NativeInterpreterWrapper.applyDelegate(Native Method)
        at org.tensorflow.lite.NativeInterpreterWrapper.applyDelegates(NativeInterpreterWrapper.java:318)
W/System.err:     at org.tensorflow.lite.NativeInterpreterWrapper.init(NativeInterpreterWrapper.java:82)
        at org.tensorflow.lite.NativeInterpreterWrapper.<init>(NativeInterpreterWrapper.java:63)
        at org.tensorflow.lite.Interpreter.<init>(Interpreter.java:237)
        at it.unipr.advmobdev.whereiswally.ModelExecutor.loadInterpreter(ModelExecutor.java:245)
        at it.unipr.advmobdev.whereiswally.ModelExecutor.run(ModelExecutor.java:160)
```

---

I noticed that in [this commit](https://github.com/tensorflow/tensorflow/commit/062cf92d066771ab3cf2910f125b0209c305eb2b) was added the [`setQuantizedModelsAllowed()`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/gpu/java/src/main/java/org/tensorflow/lite/gpu/GpuDelegate.java#L66-L76) method in the `GpuDelegate.Options` class. This method is not available in my current version of the library.

Is it possible that the optimized / quantized model cannot be run with the GPU delegate? I was unable to find this information in the documentation."
40356,TensorFlow Lite Post-training Integer Quantization predicts identical value always,"**System information**
OS Linux 18.04.04 LTS
TensorFLow nightly 2.3.0-dev20200601
CPU Intel Core i7-855OU
ResNet-50 V2

Hi,

I have been experiencing issues converting ResNet-50 V2 from SavedModel to TensorFlow Lite Post-Training Integer Quantization. I have previously converted it to Tf Lite post-training dynamic range, post-training float16 quantization, and tf lite ""normal"". In all of those cases, it worked and performed as expected. Validation accuracy is 64.15%
I tried the float32 fallback option, the int8, and the uint8 option with identical issues. The conversion works fine but then when during test phase it predicts over and over again the same value.  Moreover, speed is 6s per inference whilst for the other versions is around 40 ms per inference. I also compiled the model for EdgeTPU. The conversion works but then again some issue, only one value is predicted for each image.

Please find below a link to a google folder with dataset, savedmodel, conversion code, and converted model. 


https://drive.google.com/drive/folders/11XruNeJzdIm9DTn7FnuIWYaSalqg2F0B?usp=sharing.


"
40355,//tensorflow/python/tpu:tpu_test and //tensorflow/python/tpu:datasets_test test case failure,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
**N/A**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
**N/A**
- TensorFlow installed from (source or binary): **both source and binary**
- TensorFlow version (use command below): **v2.2.0-0-g2b96f3662b 2.2.0**
- Python version: **3.6.9**
- Bazel version (if compiling from source): **2.0.0**
- GCC/Compiler version (if compiling from source): **7.5.0**
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
Test case failure for both test. 
For `//tensorflow/python/tpu:datasets_test`, it fails with:
- RuntimeError: /job:coordinator/replica:0/task:0/device:CPU:0 unknown device.
- See test log for datasets_test [test.log](https://github.com/tensorflow/tensorflow/files/4759420/test.log)

For `//tensorflow/python/tpu:tpu_test`, it fails with:
- RuntimeError: Attempting to capture an EagerTensor without building a function.
- See test log for tpu_test [test.log](https://github.com/tensorflow/tensorflow/files/4759392/test.log)


**Describe the expected behavior**
Both test cases should pass. 

**Standalone code to reproduce the issue**

For `tpu_test`, I copied the test case into [here](https://colab.research.google.com/drive/1aC8gfkgDfMCbS11JBGxuLFVVwkumSvka?usp=sharing)

For `datasets_test`, I copied a portion of the test (till the code section that triggers error as shown in the test log) [here](https://colab.research.google.com/drive/1V97nYdLkzxrJ2QI9g-OmzkIz-lA0fnoK?usp=sharing)

You can also run this via bazel test (with `no_oss` tag removed) if you build TensorFlow from source.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

The test logs have been attached to the `current behaviour` above.  I think there are also two things worth to note
- Both test cases can pass when eager execution is disabled (via `ops.disable_eager_execution()`), https://github.com/tensorflow/tensorflow/issues/33747 is a different error but could be related. I learned disabling eager execution from there. 
- When looking into `datasets_test`, the `unknown device` failure was due to a function call of `LookupDevice`, looks like the device for the context is not in `device_map_`. see below:
```
(gdb) p device_map_
$8 = std::unordered_map with 8 elements = {[{static npos = 18446744073709551615, static kMaxSize = 9223372036854775807, ptr_ = 0x36f3234 ""XLA_CPU:0"", length_ = 9}] = 0x374f740, [{
    static npos = 18446744073709551615, static kMaxSize = 9223372036854775807, ptr_ = 0x36f3223 ""/device:XLA_CPU:0XLA_CPU:0"", length_ = 17}] = 0x374f740, [{static npos = 18446744073709551615,
    static kMaxSize = 9223372036854775807, ptr_ = 0x36f31ec ""/job:localhost/replica:0/task:0/cpu:0/device:CPU:0CPU:0/device:XLA_CPU:0XLA_CPU:0"", length_ = 37}] = 0x1b88f10, [{
    static npos = 18446744073709551615, static kMaxSize = 9223372036854775807, ptr_ = 0x36f3211 ""/device:CPU:0CPU:0/device:XLA_CPU:0XLA_CPU:0"", length_ = 13}] = 0x1b88f10, [{
    static npos = 18446744073709551615, static kMaxSize = 9223372036854775807,
    ptr_ = 0x36f31c0 ""/job:localhost/replica:0/task:0/device:CPU:0/job:localhost/replica:0/task:0/cpu:0/device:CPU:0CPU:0/device:XLA_CPU:0XLA_CPU:0"", length_ = 44}] = 0x1b88f10, [{
    static npos = 18446744073709551615, static kMaxSize = 9223372036854775807, ptr_ = 0x36f321e ""CPU:0/device:XLA_CPU:0XLA_CPU:0"", length_ = 5}] = 0x1b88f10, [{static npos = 18446744073709551615,
    static kMaxSize = 9223372036854775807, ptr_ = 0x3754ad0 ""/job:localhost/replica:0/task:0/device:XLA_CPU:0"", length_ = 48}] = 0x374f740, [{static npos = 18446744073709551615,
    static kMaxSize = 9223372036854775807, ptr_ = 0x3754b10 ""/job:localhost/replica:0/task:0/xla_cpu:0"", length_ = 41}] = 0x374f740}

(gdb) p name
$9 = {static npos = 18446744073709551615, static kMaxSize = 9223372036854775807, ptr_ = 0x7fffc2f3e300 ""/job:coordinator/replica:0/task:0/device:CPU:0"", length_ = 46}

2       breakpoint     keep y   0x00007fffd0e10665 in tensorflow::StaticDeviceMgr::LookupDevice(absl::string_view, tensorflow::Device**) const at tensorflow/core/common_runtime/device_mgr.cc:112
        breakpoint already hit 1 time
```


Thanks,
Ruixin"
40354,Symbol file not loaded when I use C API,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64
- TensorFlow installed from (source or binary): source
- TensorFlow version: r1.15.0
- Python version: 3.7
- Bazel version (if compiling from source): 0.24.1
- GCC/Compiler version (if compiling from source): VS 2019 x64

Hello, here are two questions.
1. When I use C API downloaded from https://www.tensorflow.org/install/lang_c. When I run my project, VS 2019 shows ""Symbol file not loaded"". Later I user tensorflow_cc.dll, it shows the same error.
I use CMake x64-Release settings.
```
'TestTensorflow.exe' (Win32): Loaded 'D:\Visual Studio 2019\repos\TestTensorflow\out\build\x64-Release\TestTensorflow\tensorflow_cc.dll'. Module was built without symbols.
Exception thrown at 0x00007FFDDA4F3804 (tensorflow_cc.dll) in TestTensorflow.exe: 0xC0000005: Access violation reading location 0x0000000000000000.
```
2. When I use C++ API compiled from source, it shows ""cannot open source file 'google/protobuf/xxxx'""
Does it mean I need to install protobuf?
I compile it using
```
bazel build //tensorflow:tensorflow_cc.dll //tensorflow:tensorflow_cc_dll_import_lib //tensorflow:install_headers
```
Then I copy tensorflow_cc.dll, tensorflow_cc.lib, include/ dir in the bazel-out directory.

Thanks for your help."
40353,Windows 10 (No GPU): ImportError: DLL load failed: The specified module could not be found. ,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:N/A
- TensorFlow installed from (source or binary): pip install
- TensorFlow version: 2.2.0
- Python version: 3.7.7
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A



**Describe the problem**
I have had this error for quite a few times now. Initially I faced the same problem on python version 3.8.2 and after downgrading to python 3.7.7, the same problem persists.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
```bash
PS C:\Users\Dwij>python

Python 3.7.7 (tags/v3.7.7:d7c567b08f, Mar 10 2020, 10:41:24) [MSC v.1900 64 bit (AMD64)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
```


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

```bash
Traceback (most recent call last):
  File ""C:\Users\Dwij\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Dwij\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Dwij\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\Dwij\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\Dwij\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Users\Dwij\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\Dwij\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\__init__.py"", line 50, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\Dwij\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 69, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\Dwij\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Dwij\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Dwij\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\Dwij\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\Dwij\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors
```"
40352,"error with ""from tensorflow.keras.layers import Dense""","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Dell laptop
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.0
- Python version: 3.8
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: none
- GPU model and memory: Intel(R) HD Graphics 1696MB


I want to use keras in jupyterlab. The installation of tensorflow seemed to have worked fine, no error message occured using the anaconda powershell prompt and pip. When typing ""import tensorflow as tf"" in jupyter lab no error occurs. However, when I enter ""from tensorflow.keras.layers import Dense"" I get a long list of errors with repeated instances of ""dll not loading"" occuring, as shown in the error log below. I can't figure out how to fix this. My CPU is the Intel(R) Core(TM) i5 CPU M 540.

Sequence of commands: 
import tensorflow as tf
from tensorflow.keras.layers import Dense

Error log:
ERROR:root:Internal Python error in the inspect module.
Below is the traceback from this internal error.

Traceback (most recent call last):
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\kimal\anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\kimal\anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: Eine DLL-Initialisierungsroutine ist fehlgeschlagen.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\kimal\anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 3331, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-4-10b08cb426ec>"", line 2, in <module>
    from tensorflow.keras.layers import Dense
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\kimal\anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\__init__.py"", line 42, in <module>
    from . _api.v2 import audio
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\_api\v2\audio\__init__.py"", line 10, in <module>
    from tensorflow.python.ops.gen_audio_ops import decode_wav
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\ops\gen_audio_ops.py"", line 9, in <module>
    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\kimal\anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\kimal\anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\kimal\anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: Eine DLL-Initialisierungsroutine ist fehlgeschlagen.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\kimal\anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: 'ImportError' object has no attribute '_render_traceback_'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\kimal\anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\kimal\anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: Eine DLL-Initialisierungsroutine ist fehlgeschlagen.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\kimal\anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 1151, in get_records
    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)
  File ""C:\Users\kimal\anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 319, in wrapped
    return f(*args, **kwargs)
  File ""C:\Users\kimal\anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 353, in _fixed_getinnerframes
    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))
  File ""C:\Users\kimal\anaconda3\lib\inspect.py"", line 1502, in getinnerframes
    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)
  File ""C:\Users\kimal\anaconda3\lib\inspect.py"", line 1460, in getframeinfo
    filename = getsourcefile(frame) or getfile(frame)
  File ""C:\Users\kimal\anaconda3\lib\inspect.py"", line 696, in getsourcefile
    if getattr(getmodule(object, filename), '__loader__', None) is not None:
  File ""C:\Users\kimal\anaconda3\lib\inspect.py"", line 733, in getmodule
    if ismodule(module) and hasattr(module, '__file__'):
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\kimal\anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 1006, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 983, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 953, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
  File ""<frozen importlib._bootstrap>"", line 1006, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 983, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 967, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 677, in _load_unlocked
  File ""<frozen importlib._bootstrap_external>"", line 728, in exec_module
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\__init__.py"", line 42, in <module>
    from . _api.v2 import audio
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\_api\v2\audio\__init__.py"", line 10, in <module>
    from tensorflow.python.ops.gen_audio_ops import decode_wav
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\ops\gen_audio_ops.py"", line 9, in <module>
    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\kimal\anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\kimal\anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\kimal\anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: Eine DLL-Initialisierungsroutine ist fehlgeschlagen.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\kimal\anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 3331, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-4-10b08cb426ec>"", line 2, in <module>
    from tensorflow.keras.layers import Dense
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\kimal\anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\__init__.py"", line 42, in <module>
    from . _api.v2 import audio
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\_api\v2\audio\__init__.py"", line 10, in <module>
    from tensorflow.python.ops.gen_audio_ops import decode_wav
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\ops\gen_audio_ops.py"", line 9, in <module>
    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\kimal\anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\kimal\anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\kimal\anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: Eine DLL-Initialisierungsroutine ist fehlgeschlagen.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\kimal\anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: 'ImportError' object has no attribute '_render_traceback_'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\kimal\anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\kimal\anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: Eine DLL-Initialisierungsroutine ist fehlgeschlagen.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
ERROR:root:Internal Python error in the inspect module.
Below is the traceback from this internal error.

Traceback (most recent call last):
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\kimal\anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\kimal\anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: Eine DLL-Initialisierungsroutine ist fehlgeschlagen.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\kimal\anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 3331, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-4-10b08cb426ec>"", line 2, in <module>
    from tensorflow.keras.layers import Dense
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\kimal\anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\__init__.py"", line 42, in <module>
    from . _api.v2 import audio
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\_api\v2\audio\__init__.py"", line 10, in <module>
    from tensorflow.python.ops.gen_audio_ops import decode_wav
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\ops\gen_audio_ops.py"", line 9, in <module>
    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\kimal\anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\kimal\anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\kimal\anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: Eine DLL-Initialisierungsroutine ist fehlgeschlagen.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\kimal\anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: 'ImportError' object has no attribute '_render_traceback_'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\kimal\anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 3254, in run_ast_nodes
    if (await self.run_code(code, result,  async_=asy)):
  File ""C:\Users\kimal\anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 3348, in run_code
    self.showtraceback(running_compiled_code=True)
  File ""C:\Users\kimal\anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2047, in showtraceback
    value, tb, tb_offset=tb_offset)
  File ""C:\Users\kimal\anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 1418, in structured_traceback
    self, etype, value, tb, tb_offset, number_of_lines_of_context)
  File ""C:\Users\kimal\anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 1318, in structured_traceback
    self, etype, value, tb, tb_offset, number_of_lines_of_context
  File ""C:\Users\kimal\anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 1186, in structured_traceback
    formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)
TypeError: can only concatenate str (not ""list"") to str

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\kimal\anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: 'TypeError' object has no attribute '_render_traceback_'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\kimal\anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\kimal\anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: Eine DLL-Initialisierungsroutine ist fehlgeschlagen.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\kimal\anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 1151, in get_records
    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)
  File ""C:\Users\kimal\anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 319, in wrapped
    return f(*args, **kwargs)
  File ""C:\Users\kimal\anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 353, in _fixed_getinnerframes
    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))
  File ""C:\Users\kimal\anaconda3\lib\inspect.py"", line 1502, in getinnerframes
    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)
  File ""C:\Users\kimal\anaconda3\lib\inspect.py"", line 1460, in getframeinfo
    filename = getsourcefile(frame) or getfile(frame)
  File ""C:\Users\kimal\anaconda3\lib\inspect.py"", line 696, in getsourcefile
    if getattr(getmodule(object, filename), '__loader__', None) is not None:
  File ""C:\Users\kimal\anaconda3\lib\inspect.py"", line 733, in getmodule
    if ismodule(module) and hasattr(module, '__file__'):
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\kimal\anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 1006, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 983, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 953, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
  File ""<frozen importlib._bootstrap>"", line 1006, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 983, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 967, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 677, in _load_unlocked
  File ""<frozen importlib._bootstrap_external>"", line 728, in exec_module
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\__init__.py"", line 42, in <module>
    from . _api.v2 import audio
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\_api\v2\audio\__init__.py"", line 10, in <module>
    from tensorflow.python.ops.gen_audio_ops import decode_wav
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\ops\gen_audio_ops.py"", line 9, in <module>
    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\kimal\anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\kimal\anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\kimal\anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: Eine DLL-Initialisierungsroutine ist fehlgeschlagen.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\kimal\anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 3331, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-4-10b08cb426ec>"", line 2, in <module>
    from tensorflow.keras.layers import Dense
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\kimal\anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\__init__.py"", line 42, in <module>
    from . _api.v2 import audio
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\_api\v2\audio\__init__.py"", line 10, in <module>
    from tensorflow.python.ops.gen_audio_ops import decode_wav
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\ops\gen_audio_ops.py"", line 9, in <module>
    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\kimal\anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\kimal\anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\kimal\anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: Eine DLL-Initialisierungsroutine ist fehlgeschlagen.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\kimal\anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: 'ImportError' object has no attribute '_render_traceback_'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\kimal\anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 3254, in run_ast_nodes
    if (await self.run_code(code, result,  async_=asy)):
  File ""C:\Users\kimal\anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 3348, in run_code
    self.showtraceback(running_compiled_code=True)
  File ""C:\Users\kimal\anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2047, in showtraceback
    value, tb, tb_offset=tb_offset)
  File ""C:\Users\kimal\anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 1418, in structured_traceback
    self, etype, value, tb, tb_offset, number_of_lines_of_context)
  File ""C:\Users\kimal\anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 1318, in structured_traceback
    self, etype, value, tb, tb_offset, number_of_lines_of_context
  File ""C:\Users\kimal\anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 1186, in structured_traceback
    formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)
TypeError: can only concatenate str (not ""list"") to str

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\kimal\anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: 'TypeError' object has no attribute '_render_traceback_'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\kimal\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\kimal\anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\kimal\anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: Eine DLL-Initialisierungsroutine ist fehlgeschlagen.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
~\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py in <module>
     57 
---> 58   from tensorflow.python.pywrap_tensorflow_internal import *
     59   from tensorflow.python.pywrap_tensorflow_internal import __version__

~\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py in <module>
     27             return _mod
---> 28     _pywrap_tensorflow_internal = swig_import_helper()
     29     del swig_import_helper

~\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py in swig_import_helper()
     23             try:
---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
     25             finally:

~\anaconda3\lib\imp.py in load_module(name, file, filename, details)
    241         else:
--> 242             return load_dynamic(name, filename, file)
    243     elif type_ == PKG_DIRECTORY:

~\anaconda3\lib\imp.py in load_dynamic(name, path, file)
    341             name=name, loader=loader, origin=path)
--> 342         return _load(spec)
    343 

ImportError: DLL load failed: Eine DLL-Initialisierungsroutine ist fehlgeschlagen.

During handling of the above exception, another exception occurred:


During handling of the above exception, another exception occurred:

AttributeError                            Traceback (most recent call last)
~\anaconda3\lib\site-packages\IPython\core\interactiveshell.py in showtraceback(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)
   2043                         # in the engines. This should return a list of strings.
-> 2044                         stb = value._render_traceback_()
   2045                     except Exception:

AttributeError: 'ImportError' object has no attribute '_render_traceback_'

During handling of the above exception, another exception occurred:

TypeError                                 Traceback (most recent call last)
~\anaconda3\lib\site-packages\IPython\core\interactiveshell.py in run_code(self, code_obj, result, async_)
   3346             if result is not None:
   3347                 result.error_in_exec = sys.exc_info()[1]
-> 3348             self.showtraceback(running_compiled_code=True)
   3349         else:
   3350             outflag = False

~\anaconda3\lib\site-packages\IPython\core\interactiveshell.py in showtraceback(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)
   2045                     except Exception:
   2046                         stb = self.InteractiveTB.structured_traceback(etype,
-> 2047                                             value, tb, tb_offset=tb_offset)
   2048 
   2049                     self._showtraceback(etype, value, stb)

~\anaconda3\lib\site-packages\IPython\core\ultratb.py in structured_traceback(self, etype, value, tb, tb_offset, number_of_lines_of_context)
   1416             self.tb = tb
   1417         return FormattedTB.structured_traceback(
-> 1418             self, etype, value, tb, tb_offset, number_of_lines_of_context)
   1419 
   1420 

~\anaconda3\lib\site-packages\IPython\core\ultratb.py in structured_traceback(self, etype, value, tb, tb_offset, number_of_lines_of_context)
   1316             # Verbose modes need a full traceback
   1317             return VerboseTB.structured_traceback(
-> 1318                 self, etype, value, tb, tb_offset, number_of_lines_of_context
   1319             )
   1320         elif mode == 'Minimal':

~\anaconda3\lib\site-packages\IPython\core\ultratb.py in structured_traceback(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)
   1184         exception = self.get_parts_of_chained_exception(evalue)
   1185         if exception:
-> 1186             formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)
   1187             etype, evalue, etb = exception
   1188         else:

TypeError: can only concatenate str (not ""list"") to str
"
40350,build tensorflow 1.13 error,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux Ubuntu 16.04

- TensorFlow installed from (source or binary):
- TensorFlow version: 
1.13

- Python version:
3.7

- Installed using virtualenv? pip? conda?:
No

- Bazel version (if compiling from source):
0.19.2

- GCC/Compiler version (if compiling from source):
external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/bin/arm-linux-androideabi-gcc 

- CUDA/cuDNN version:
No

- GPU model and memory:

NDK version：
android-ndk-r12b 

configure
```
./configure 
WARNING: Running Bazel server needs to be killed, because the startup options are different.
WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"".
You have bazel 0.19.2 installed.
Please specify the location of python. [Default is /home/wushengqi/anaconda3/bin/python]: 


Found possible Python library paths:
  /home/wushengqi/anaconda3/lib/python3.7/site-packages
Please input the desired Python library path to use.  Default is [/home/wushengqi/anaconda3/lib/python3.7/site-packages]

Do you wish to build TensorFlow with XLA JIT support? [Y/n]: N
No XLA JIT support will be enabled for TensorFlow.

Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: N
No OpenCL SYCL support will be enabled for TensorFlow.

Do you wish to build TensorFlow with ROCm support? [y/N]: N
No ROCm support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: N
No CUDA support will be enabled for TensorFlow.

Do you wish to download a fresh release of clang? (Experimental) [y/N]: N
Clang will not be downloaded.

Do you wish to build TensorFlow with MPI support? [y/N]: N
No MPI support will be enabled for TensorFlow.

Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native -Wno-sign-compare]: 


Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Y
Searching for NDK and SDK installations.

Please specify the home path of the Android NDK to use. [Default is /home/wushengqi/Android/Sdk/ndk-bundle]: /home/wushengqi/android/android-ndk-r12b


Please specify the home path of the Android SDK to use. [Default is /home/wushengqi/Android/Sdk]: 


Please specify the Android SDK API level to use. [Available levels: ['19', '21', '23', '29']] [Default is 29]: 23


Please specify an Android build tools version to use. [Available versions: ['20.0.0', '25.0.2', '28.0.3', '29.0.3']] [Default is 29.0.3]: 25.0.2


Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details.
	--config=mkl         	# Build with MKL support.
	--config=monolithic  	# Config for mostly static monolithic build.
	--config=gdr         	# Build with GDR support.
	--config=verbs       	# Build with libverbs support.
	--config=ngraph      	# Build with Intel nGraph support.
	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects.
Preconfigured Bazel build configs to DISABLE default on features:
	--config=noaws       	# Disable AWS S3 filesystem support.
	--config=nogcp       	# Disable GCP support.
	--config=nohdfs      	# Disable HDFS support.
	--config=noignite    	# Disable Apacha Ignite support.
	--config=nokafka     	# Disable Apache Kafka support.
	--config=nonccl      	# Disable NVIDIA NCCL support.
```

```
ERROR: /home/wushengqi/.cache/bazel/_bazel_wushengqi/2840f8b2441253bda229f603c535fe4e/external/com_google_absl/absl/strings/BUILD.bazel:32:1: C++ compilation of rule '@com_google_absl//absl/strings:strings' failed (Exit 1): arm-linux-androideabi-gcc failed: error executing command 
  (cd /home/wushengqi/.cache/bazel/_bazel_wushengqi/2840f8b2441253bda229f603c535fe4e/execroot/org_tensorflow && \
  exec env - \
    ANDROID_BUILD_TOOLS_VERSION=25.0.2 \
    ANDROID_NDK_API_LEVEL=12 \
    ANDROID_NDK_HOME=/home/wushengqi/android/android-ndk-r12b \
    ANDROID_SDK_API_LEVEL=23 \
    ANDROID_SDK_HOME=/home/wushengqi/Android/Sdk \
    PATH=/home/wushengqi/anaconda3/bin:/home/wushengqi/bin:/home/wushengqi/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/wushengqi/wushengqi/bin:/home/wushengqi/android/android-ndk-r12b \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/home/wushengqi/anaconda3/bin/python \
    PYTHON_LIB_PATH=/home/wushengqi/anaconda3/lib/python3.7/site-packages \
    TF_DOWNLOAD_CLANG=0 \
    TF_NEED_CUDA=0 \
    TF_NEED_OPENCL_SYCL=0 \
    TF_NEED_ROCM=0 \
  external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/bin/arm-linux-androideabi-gcc -fstack-protector-strong -fpic -ffunction-sections -funwind-tables -no-canonical-prefixes -fno-canonical-system-headers '-march=armv7-a' '-mfpu=vfpv3-d16' '-mfloat-abi=softfp' -mthumb -Os -g -DNDEBUG -MD -MF bazel-out/armeabi-v7a-opt/bin/external/com_google_absl/absl/strings/_objs/strings/charconv.d '-frandom-seed=bazel-out/armeabi-v7a-opt/bin/external/com_google_absl/absl/strings/_objs/strings/charconv.o' -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote external/com_google_absl -iquote bazel-out/armeabi-v7a-opt/genfiles/external/com_google_absl -iquote bazel-out/armeabi-v7a-opt/bin/external/com_google_absl -iquote external/bazel_tools -iquote bazel-out/armeabi-v7a-opt/genfiles/external/bazel_tools -iquote bazel-out/armeabi-v7a-opt/bin/external/bazel_tools '-std=c++11' -Wall -Wextra -Wcast-qual -Wconversion-null -Wmissing-declarations -Woverlength-strings -Wpointer-arith -Wunused-local-typedefs -Wunused-result -Wvarargs -Wvla -Wwrite-strings -Wno-sign-compare '--sysroot=external/androidndk/ndk/platforms/android-12/arch-arm' -isystem external/androidndk/ndk/sources/cxx-stl/gnu-libstdc++/4.9/include -isystem external/androidndk/ndk/sources/cxx-stl/gnu-libstdc++/4.9/libs/armeabi-v7a/include -isystem external/androidndk/ndk/sources/cxx-stl/gnu-libstdc++/4.9/include/backward -c external/com_google_absl/absl/strings/charconv.cc -o bazel-out/armeabi-v7a-opt/bin/external/com_google_absl/absl/strings/_objs/strings/charconv.o)
external/com_google_absl/absl/strings/charconv.cc: In static member function 'static double absl::{anonymous}::FloatTraits<double>::MakeNan(const char*)':
external/com_google_absl/absl/strings/charconv.cc:89:20: error: 'nan' was not declared in this scope
     return nan(tagp);
                    ^
external/com_google_absl/absl/strings/charconv.cc: In static member function 'static float absl::{anonymous}::FloatTraits<float>::MakeNan(const char*)':
external/com_google_absl/absl/strings/charconv.cc:143:21: error: 'nanf' was not declared in this scope
     return nanf(tagp);
                     ^
external/com_google_absl/absl/strings/charconv.cc: In static member function 'static double absl::{anonymous}::FloatTraits<double>::MakeNan(const char*)':
external/com_google_absl/absl/strings/charconv.cc:90:3: warning: control reaches end of non-void function [-Wreturn-type]
   }
   ^
external/com_google_absl/absl/strings/charconv.cc: In static member function 'static float absl::{anonymous}::FloatTraits<float>::MakeNan(const char*)':
external/com_google_absl/absl/strings/charconv.cc:144:3: warning: control reaches end of non-void function [-Wreturn-type]
   }
   ^
Target //tensorflow/examples/TensorFlowService:libtensorflow-lib.so failed to build
INFO: Elapsed time: 6.811s, Critical Path: 2.51s, Remote (0.00% of the time): [queue: 0.00%, setup: 0.00%, process: 0.00%]
```
"
40349,Could not load dynamic library 'libcudnn.so.7',"**System information**
- OS Platform and Distribution: Ubuntu 20.04 LTS
- TensorFlow installed from (source or binary): Binary
- TensorFlow version: 2.2.0
- Python version: 3.8.2
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source): 8.4.0
- CUDA/cuDNN version: 10.1



When I run the program like:

`import tensorflow as tf`

it shows no problem but when i do:

`import tensorflow as tf

rank_0_tensor = tf.constant([2.0, 3.0, 4.0])
print(rank_0_tensor)`

i get the error showing:
![Screenshot from 2020-06-10 15-10-32](https://user-images.githubusercontent.com/63995679/84252815-ba41b300-ab2c-11ea-9dac-bd225364f492.png)

Can anybody help?
"
40348,tf.contrib module's alternative methods in Version 2 of Tensorflow ,"I'm following the documentation to migrate from V1 to V2 mentioned below which states that `tf.contrib` module is removed from the v2 and it can't be made to work even with this line of code: 
```
import tensorflow.compat.v1 as tf 
tf.disable_v2_behavior()
```
So, is the only option left is to remove them manually? If it is can we have a link mentioning the new methods for classes which are now not by supported in V2?
## URL(s) with the issue:
Guide to migration: https://www.tensorflow.org/guide/migrate
Old version's link to the tf.contrib module: https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/contrib

## Description of the issue (what needs changing):

The original documentation mentioned that the modules of `tf.contrib` are adjusted in other classes but no clear mention of where to find them. I can't find the alternative for many old methods like:
`tf.contrib.lookup.index_table_from_file`, `tf.contrib.crf.crf_decode`.
Can we have a link/mention to the new alternative methods for the removed `tf.contrib` classes in either the guide to migration or in the older version page, stating the new alternative, so that it is easier while migrating manually? 
"
40347,TF_SessionRunCallable in file session.py Crashes,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 7 32-bit
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 1.9.0
- Python version: 3.6.8
- Bazel version (if compiling from source): --------------------
- GCC/Compiler version (if compiling from source):  cmake 3.9.6
- CUDA/cuDNN version: ------------
- GPU model and memory: --------------

**Describe the current behavior**

I compiled tensorflow 1.9.0 for target os windows 7 32 bit, I used 
win 10 1709
git 2.14.1
cmake 3.9.6
anaconda3 5.1.0
visual studio 2017
swigwin-3.0.10

I installed the whl file on Virtualbox windows 7 32 bits and run a model, it works fine, but when I installed on the same condition on actual pc it raises an error, The ucrtbase.dll will crash.

The error that happens is :

Problem Event Name: APPCRASH
Application Name: python.exe
Application Version: 3.6.8150.1013
Application Timestamp: 5c201b63
Fault Module Name: ucrtbase.DLL
Fault Module Version: 10.0.14393.2990
Fault Module Timestamp: 5caeb859
Exception Code: 40000015
Exception Offset: 000884da
OS Version: 6.1.7601.2.1.0.256.48
Locale ID: 1033
Additional Information 1: f419
Additional Information 2: f419a63a49a2df57b723a80593a88e82
Additional Information 3: e2c1
Additional Information 4: e2c181b5a2bed9dd090d71f8ac7769de

However I debugged the code and I found that the error raises from this code :

### file :  

C:\Users\admin\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\tensorflow\python\client\session.py

### code : 
```
def call(self, *args):
#TODO(b/74355905): Support argument and return value nested structures,
#and tensor-like objects such as SparseTensors.
with errors.raise_exception_on_not_ok_status() as status:
if self._session._created_with_new_api:
**return tf_session.TF_SessionRunCallable(
self._session._session, self._handle, args, status, None)**
else:
return tf_session.TF_DeprecatedSessionRunCallable(
self._session._session, self._handle, args, status, None)
```

Line   causing the error: return tf_session.TF_SessionRunCallable(
self._session._session, self._handle, args, status, None)

I hope you can help me to fix this issue, Please give me the fixing instruction, because I could not install any fixing patches, I have to compile them for windows 32 bits and it is a painful work.

Thank you so much"
40346,Tensorflow dataset loading warning,"### System information


-   **OS Platform Windows 8.1
-   **TensorFlow version 2.0
-   **Python version 3.7.7

### Describe the problem
I tried to load the MNIST dataset from tensorflow datasets. It is giving me the following warning:
i installed gast 0.2.2 still the issue persists
System info:
OS: WIndows 8.1
Python 3.7.7
Tensorflow 2.0

Warning:
WARNING:tensorflow:Entity <function _get_dataset_from_filename at 0x00000075305C23A8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output. Cause: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <function _get_dataset_from_filename at 0x00000075305C23A8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output. Cause: module 'gast' has no attribute 'Num'
WARNING: Entity <function _get_dataset_from_filename at 0x00000075305C23A8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output. Cause: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method TopLevelFeature.decode_example of FeaturesDict({
'image': Image(shape=(28, 28, 1), dtype=tf.uint8),
'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),
})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method TopLevelFeature.decode_example of FeaturesDict({
'image': Image(shape=(28, 28, 1), dtype=tf.uint8),
'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),
})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4
WARNING: Entity <bound method TopLevelFeature.decode_example of FeaturesDict({
'image': Image(shape=(28, 28, 1), dtype=tf.uint8),
'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),
})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <function _get_dataset_from_filename at 0x00000075305C23A8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output. Cause: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <function _get_dataset_from_filename at 0x00000075305C23A8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output. Cause: module 'gast' has no attribute 'Num'
WARNING: Entity <function _get_dataset_from_filename at 0x00000075305C23A8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output. Cause: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method TopLevelFeature.decode_example of FeaturesDict({
'image': Image(shape=(28, 28, 1), dtype=tf.uint8),
'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),
})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method TopLevelFeature.decode_example of FeaturesDict({
'image': Image(shape=(28, 28, 1), dtype=tf.uint8),
'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),
})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4
WARNING: Entity <bound method TopLevelFeature.decode_example of FeaturesDict({
'image': Image(shape=(28, 28, 1), dtype=tf.uint8),
'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),
})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4


Tried after installing gast 0.2.2
still it is giving me the same error
"
40345,Backward LSTM behavior mismatch,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.2
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

v2.2.0-0-g2b96f3662b 2.2.0
**Describe the current behavior**
Say input is [a1 a2 a3] and running on GPU
In reverse LSTM, 
reversed_input_to_cudnn = [a3 a2 a1]
output_from_cudnn = [b3 b2 b1]
final output = [b1 b2 b3] 

This is based on the code and description mentioned here:
https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/keras/layers/recurrent_v2.py#L630
  
**Describe the expected behavior**
Expected final output is [b3 b2 b1] based on the description mentioned here:
https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/keras/layers/recurrent_v2.py#L1000

I'm not sure what internally is happening and what is the expected behavior?
Other inference engines like ONNXRuntime will give output [b1 b2 b3] and currently there is mismatch of outputs with ONNXRuntime and TF.

**Standalone code to reproduce the issue**
[simple_lstm.txt](https://github.com/tensorflow/tensorflow/files/4756947/simple_lstm.txt)
(rename to .h5) 
You can use this sample model to verify the results.


"
40344,We cannot duplicate the value since it's not constant. Failed to duplicate values for the stateful op.,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (or github SHA if from source): 2.3.0-dev20200609


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Bidirectional, LSTM, Dense

X = Input(shape=(None, 150), name='input')
Xc = Bidirectional(LSTM(20, return_sequences=True))(X)
Y = Dense(10, activation=tf.nn.softmax, name='output')(Xc)

model = Model(inputs=X, outputs=Y)
loss = tf.keras.losses.CategoricalCrossentropy()
model.compile(optimizer='adam',
              loss=loss,
              metrics=['accuracy'])
model.summary()

inputData = np.ones([100, 200, 150])
outputData = np.ones([100,200,10])

model.fit(x=inputData, y=outputData, epochs=2)

run_model = tf.function(lambda x: model(x))
BATCH_SIZE = 1
STEPS = None # 100
INPUT_SIZE = 150
concrete_func = run_model.get_concrete_function(
    tf.TensorSpec([BATCH_SIZE, STEPS, INPUT_SIZE], model.inputs[0].dtype))
MODEL_DIR = ""./saved_model""
model.save(MODEL_DIR, save_format=""tf"", signatures=concrete_func)

converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_DIR)
tflite_model = converter.convert() # Error!
```

**The output from the converter invocation**

```
---------------------------------------------------------------------------
Exception                                 Traceback (most recent call last)
~/VirtualEnv/ENV37-TF23NT/lib/python3.7/site-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
    184                                                  debug_info_str,
--> 185                                                  enable_mlir_converter)
    186       return model_str

~/VirtualEnv/ENV37-TF23NT/lib/python3.7/site-packages/tensorflow/lite/python/wrap_toco.py in wrapped_toco_convert(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
     37       debug_info_str,
---> 38       enable_mlir_converter)
     39 

Exception: <unknown>:0: error: loc(callsite(callsite(callsite(unknown at ""functional_1/bidirectional/backward_lstm/PartitionedCall@__inference_<lambda>_6523"") at ""StatefulPartitionedCall@__inference_signature_wrapper_6546"") at ""StatefulPartitionedCall"")): We cannot duplicate the value since it's not constant.

<unknown>:0: note: loc(""StatefulPartitionedCall""): called from
<unknown>:0: note: loc(callsite(callsite(callsite(unknown at ""functional_1/bidirectional/backward_lstm/PartitionedCall@__inference_<lambda>_6523"") at ""StatefulPartitionedCall@__inference_signature_wrapper_6546"") at ""StatefulPartitionedCall"")): see current operation: %5 = ""tfl.unidirectional_sequence_lstm""(%4, %cst_13, %cst_14, %cst_15, %cst_16, %cst_5, %cst_6, %cst_7, %cst_8, %cst_32, %cst_32, %cst_32, %cst_9, %cst_10, %cst_11, %cst_12, %cst_32, %cst_32, %3, %3, %cst_32, %cst_32, %cst_32, %cst_32) {cell_clip = 1.000000e+01 : f32, fused_activation_function = ""TANH"", proj_clip = 0.000000e+00 : f32, time_major = false} : (tensor<1x?x150xf32>, tensor<20x150xf32>, tensor<20x150xf32>, tensor<20x150xf32>, tensor<20x150xf32>, tensor<20x20xf32>, tensor<20x20xf32>, tensor<20x20xf32>, tensor<20x20xf32>, none, none, none, tensor<20xf32>, tensor<20xf32>, tensor<20xf32>, tensor<20xf32>, none, none, tensor<?x20xf32>, tensor<?x20xf32>, none, none, none, none) -> tensor<1x?x20xf32>
<unknown>:0: error: Failed to duplicate values for the stateful op

<unknown>:0: note: see current operation: ""func""() ( {
^bb0(%arg0: tensor<1x?x150xf32>):  // no predecessors
  %cst = ""std.constant""() {value = dense<[0.00800104905, 8.002180e-03, 0.00801025052, 0.00799552072, 0.00798829272, 0.00801645405, 0.00800046883, 0.00799199379, 0.00802111439, 0.00795717072]> : tensor<10xf32>} : () -> tensor<10xf32>
  %cst_0 = ""std.constant""() {value = dense<0.000000e+00> : tensor<f32>} : () -> tensor<f32>
  %cst_1 = ""std.constant""() {value = dense<20> : tensor<i32>} : () -> tensor<i32>
  %cst_2 = ""std.constant""() {value = dense<10> : tensor<1xi32>} : () -> tensor<1xi32>
  %cst_3 = ""std.constant""() {value = dense<2> : tensor<1xi32>} : () -> tensor<1xi32>
  %cst_4 = ""std.constant""() {value = dense<[0, 1]> : tensor<2xi32>} : () -> tensor<2xi32>
  %cst_5 = ""std.constant""() {value = dense<""0x43B055BE41EB30BC7CBC073ED64B033EBE556E3C656489BD3DF794BD644D33BDF3AF61BDC7E0DD3C41C3E53CB1A15F3D1102DABCA10234BC40563B3E12127F3D34B0CB3D39A77DBD0517453DDFE1F7BDDF83473CB66DFA3BF23B6BBED780F5BDD89FB43CFAA7FB3D7C449DBD80AB69BB42E56EBDF801553D664AA83C8219073E4759D13D1AA96A3E2B3580BDD08902BE2A3405BECFA8AC3D696411BE89C88ABDE13E093EE903043EC2340B3E6836BD3D623122BCC7B0B1BBDB32BCBD2A6CDABD6517CD3D713F913D2AEF9B3D40CAC93DF5E3D63D703676BECAF9A9BD1F9C1D3D9496273E52D2533CC6B00A3EC863933C6BB56BBEC922CCBD89AA5F3E89AEAEBD0B3A193E3626443E9B07443DA23B1C3C671945BD45112EBCCD87913EB31949BD3EB81D3E2182C43C4164B53D9C74F1BD1C88EEBCF59AD0BCBCBEE6BC9D43D33C4FF6913DF8B692BD271E663E1CC7E73DCC196E3C836EC03D3B91303E0AFA53BB7452F9BD2B8CF23D38CC613DA1F6B43DAEAA68BDD221863CA34B03BEDEFD6FBCA03C45BE6CA8633E4CACA53C0D6CACBC086D883DAC02753B878C99BEC33C14BC1090123BBD892D3EDCE4D43D64E2C7BC44BBC53CC9F8CA3D0670763EB46F24BB9B0B20BD94E4AF3D3CDE65BD8ECD503E9235D13D412F20BE2D648C3D39F6B73C6111323E4841CCBCA8EDB5BDC86956BBB2CA3BBD984065BD906B083EED91923DBF5CABBC9376F73CE42FA03D560D18BDF153CFBC4993A93D0755093EA4F544BEEF01823B8B56013E9D3DE23C3BA71D3EB2BC3CBEDADA243D2818773CF66D073E94D01E3EB463AB3DFC3227BEBC0E0DBE2EA1CFBBD458273DBCD92F3EA507993E47BAC2BDEEB640BD92CA673D254C253DEEA2883C177BC13C29AE1A3D0F6511BAF3D859BEE97216BEB7C9BF3BEAA9BEBD3C95AD3B23F37EBDD18329BD46EF113DDDF18C3EEA04543EC3B81C3EF10615BDCD10CD3CB6
...
...
EBDA94F863E437E6CBEB1F8C9BC29E166BE0A6C7EBEBB491B3E94C1363E308BBC3DE7969A3E3D763ABEC7248D3E30D3623E0F67E73D35859FBE522F913D78492CBE84823A3EBD52163DFA137F3EDC103B3E6D13A23E80CFAB3D1E78B4BD881468BEA37B553E50C436BECFC833BE3113403EC29BACBD2DEB62BCA9EB8A3D3F62AD3E5578843DA76FCE3D895EE5BB95318B3ED4D2F7BD209935BEA21190BE98DA9EBE1693A13E7067A73E3B8A813E813E363E6FBBA5BD5E5E54BECFF6A73EB52769BD9E95A53ED071973DC200E63DD239AFBD86A4A3BEA2E3CA3D1DDA04BE316DCA3D1F459F3D998431BE38311E3EE0D2A83E33F3543E39295D3D2FF682BE7AF0AC3EDA1AAABEFC26A3BEE20D66BEBD3D913E8267A13EEA65793E6ECE44BD951A10BE496502BE2E077FBE6F6AD0BD492369BE7B4E9DBDD86385BE552FB33E64C755BE8BA8B0BEF02B3CBE828D9BBEDE08ECBD53AF07BEF4FC093D44F7ADBDCE144C3EE2313ABD65A4AEBE81A0313E03F398BE305EBEBCAD4B763EE34F8BBE4B29A03CD167903E799B263E11073EBD21791DBD47585D3E102063BE11FA21BD32BA48BE7F3923BE88BD073E3A2F11BDCCA56DBE8FDA623EAD3D583DCA74B83DDE6A8FBCAC2A9CBE400576BD125E03BEEEAB59BC8FFF343E5E83773E""> : tensor<10x40xf32>} : () -> tensor<10x40xf32>
  %cst_30 = ""std.constant""() {value = dense<0> : tensor<1xi32>} : () -> tensor<1xi32>
  %cst_31 = ""std.constant""() {value = dense<1> : tensor<1xi32>} : () -> tensor<1xi32>
  %cst_32 = ""std.constant""() {value} : () -> none
  %0 = ""tfl.shape""(%arg0) : (tensor<1x?x150xf32>) -> tensor<3xi32>
  %1 = ""tfl.strided_slice""(%0, %cst_30, %cst_31, %cst_31) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<3xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>
  %2 = ""tfl.pack""(%1, %cst_1) {axis = 0 : i32, values_count = 2 : i32} : (tensor<i32>, tensor<i32>) -> tensor<2xi32>
  %3 = ""tfl.fill""(%2, %cst_0) : (tensor<2xi32>, tensor<f32>) -> tensor<?x20xf32>
  %4 = ""tfl.reverse_v2""(%arg0, %cst_31) : (tensor<1x?x150xf32>, tensor<1xi32>) -> tensor<1x?x150xf32>
  %5 = ""tfl.unidirectional_sequence_lstm""(%4, %cst_13, %cst_14, %cst_15, %cst_16, %cst_5, %cst_6, %cst_7, %cst_8, %cst_32, %cst_32, %cst_32, %cst_9, %cst_10, %cst_11, %cst_12, %cst_32, %cst_32, %3, %3, %cst_32, %cst_32, %cst_32, %cst_32) {cell_clip = 1.000000e+01 : f32, fused_activation_function = ""TANH"", proj_clip = 0.000000e+00 : f32, time_major = false} : (tensor<1x?x150xf32>, tensor<20x150xf32>, tensor<20x150xf32>, tensor<20x150xf32>, tensor<20x150xf32>, tensor<20x20xf32>, tensor<20x20xf32>, tensor<20x20xf32>, tensor<20x20xf32>, none, none, none, tensor<20xf32>, tensor<20xf32>, tensor<20xf32>, tensor<20xf32>, none, none, tensor<?x20xf32>, tensor<?x20xf32>, none, none, none, none) -> tensor<1x?x20xf32>
  %6 = ""tfl.reverse_v2""(%5, %cst_31) : (tensor<1x?x20xf32>, tensor<1xi32>) -> tensor<1x?x20xf32>
  %7 = ""tfl.unidirectional_sequence_lstm""(%arg0, %cst_25, %cst_26, %cst_27, %cst_28, %cst_17, %cst_18, %cst_19, %cst_20, %cst_32, %cst_32, %cst_32, %cst_21, %cst_22, %cst_23, %cst_24, %cst_32, %cst_32, %3, %3, %cst_32, %cst_32, %cst_32, %cst_32) {cell_clip = 1.000000e+01 : f32, fused_activation_function = ""TANH"", proj_clip = 0.000000e+00 : f32, time_major = false} : (tensor<1x?x150xf32>, tensor<20x150xf32>, tensor<20x150xf32>, tensor<20x150xf32>, tensor<20x150xf32>, tensor<20x20xf32>, tensor<20x20xf32>, tensor<20x20xf32>, tensor<20x20xf32>, none, none, none, tensor<20xf32>, tensor<20xf32>, tensor<20xf32>, tensor<20xf32>, none, none, tensor<?x20xf32>, tensor<?x20xf32>, none, none, none, none) -> tensor<1x?x20xf32>
  %8 = ""tfl.concatenation""(%7, %6) {axis = 2 : i32, fused_activation_function = ""NONE""} : (tensor<1x?x20xf32>, tensor<1x?x20xf32>) -> tensor<1x?x40xf32>
  %9 = ""tfl.shape""(%8) : (tensor<1x?x40xf32>) -> tensor<3xi32>
  %10 = ""tfl.gather""(%9, %cst_4) {axis = 0 : i32} : (tensor<3xi32>, tensor<2xi32>) -> tensor<2xi32>
  %11 = ""tfl.reduce_prod""(%10, %cst_30) {keep_dims = false} : (tensor<2xi32>, tensor<1xi32>) -> tensor<i32>
  %12 = ""tfl.concatenation""(%10, %cst_2) {axis = 0 : i32, fused_activation_function = ""NONE""} : (tensor<2xi32>, tensor<1xi32>) -> tensor<3xi32>
  %13 = ""tfl.gather""(%9, %cst_3) {axis = 0 : i32} : (tensor<3xi32>, tensor<1xi32>) -> tensor<1xi32>
  %14 = ""tfl.reduce_prod""(%13, %cst_30) {keep_dims = false} : (tensor<1xi32>, tensor<1xi32>) -> tensor<i32>
  %15 = ""tfl.pack""(%11, %14) {axis = 0 : i32, values_count = 2 : i32} : (tensor<i32>, tensor<i32>) -> tensor<2xi32>
  %16 = ""tfl.reshape""(%8, %15) : (tensor<1x?x40xf32>, tensor<2xi32>) -> tensor<?x?xf32>
  %17 = ""tfl.fully_connected""(%16, %cst_29, %cst_32) {fused_activation_function = ""NONE"", keep_num_dims = false, weights_format = ""DEFAULT""} : (tensor<?x?xf32>, tensor<10x40xf32>, none) -> tensor<?x10xf32>
  %18 = ""tfl.reshape""(%17, %12) : (tensor<?x10xf32>, tensor<3xi32>) -> tensor<?x?x?xf32>
  %19 = ""tfl.add""(%18, %cst) {fused_activation_function = ""NONE""} : (tensor<?x?x?xf32>, tensor<10xf32>) -> tensor<?x?x10xf32>
  %20 = ""tfl.softmax""(%19) {beta = 1.000000e+00 : f32} : (tensor<?x?x10xf32>) -> tensor<?x?x10xf32>
  ""std.return""(%20) : (tensor<?x?x10xf32>) -> ()
}) {arg0 = {tf_saved_model.index_path = [""x""]}, result0 = {tf_saved_model.index_path = [""output_0""]}, sym_name = ""serving_default"", tf.entry_function = {control_outputs = """", inputs = ""serving_default_x:0"", outputs = ""StatefulPartitionedCall:0""}, tf_saved_model.exported_names = [""serving_default""], type = (tensor<1x?x150xf32>) -> tensor<?x?x10xf32>} : () -> ()
```

**Failure details**
- Conversion succeeded If I set the STEPS to an integer value (e.g: 100).
- Conversion failed if I set the STEPS to None."
40343,timeseries_dataset_from_array wrong target output value,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 19.10 
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.3.0-dev20200609 - nightly-gpu
- Python version:Python 3.7.5
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: 10.0/7
- GPU model and memory: GeForce RTX 2060 8GB

**Describe the current behavior**
The output target (or y) start first with record of data (or sliding window), not with sequence_length+1 item 
**Describe the expected behavior**
Target (or y) should start from sequence_length+1
**Standalone code to reproduce the issue**
```python
import tensorflow as tf
from tensorflow.keras.preprocessing import timeseries_dataset_from_array
import numpy as np
tf.__version__

series = np.arange(1, 100)
print(series)
test_ds = timeseries_dataset_from_array(
        series, series, sequence_length=90, batch_size=1, shuffle=False, seed=7, sequence_stride=1, sampling_rate=1
    )
inputs, targets = tf.data.experimental.get_single_element(test_ds.take(1))
print(inputs.numpy())
print(targets.numpy())

""""""
output:
inputs [[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
  25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48
  49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72
  73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90]]
**targets [1]**
""""""
I was expecting target to start from 91. 
Is the expected behaviour to start from 1 or it should continue from end of ""sliding window""?

I changed the targets series as np.roll(series, -90) and remove last record of dataset and output looks ok. 

series = np.arange(1, 100)
#print(series)
print(np.roll(series, -90))
test_ds = timeseries_dataset_from_array(
        series, np.roll(series, -90), sequence_length=90, batch_size=1, shuffle=False, seed=7, sequence_stride=1, sampling_rate=1
    )
inputs, targets = tf.data.experimental.get_single_element(test_ds.take(1))
print(""inputs"", inputs.numpy())
print(""targets"", targets.numpy())

""""""
inputs [[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
  25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48
  49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72
  73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90]]
**targets [91]**
""""""

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40342,Cannot resume training using model.save and load_model(),"**System Information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes

- OS Platform and Distribution:
CentOS Linux 7.6.1810

- TensorFlow installed from : 
binary (pip)

- TensorFlow version :
2.2.0-rc3

- Python version:
3.6.4

- CUDA/cuDNN version:
CUDA 10.1 / cuDNN 7.6.0

- GPU model and memory:
2 x TitanX - 12GB

**Describe the current behavior**
I am using Tensorflow 2.2.0 on multi-gpu system. Having the need to train large networks for several days, I save the model weights with optimizer state using ```model.save()```. When I reload the model using ```tf.keras.models.load_model()```, the loss spikes sharply on TensorBoard and the accuracy also shows a sudden drop. Though the loss recovers within the epoch, it does not comply with the intended behavior of saving training state using ```model.save()```.

**Describe the expected behavior**
The API should be able to save and resume training from the very same point after loading a model from '.h5' file.

**Standalone code to reproduce the issue**
This code is a minimal reproducible example. It was tested on multi-gpu systems with 8 gpus. The re-run of the script is achieved by deleting the current model and distribute strategy and re-initializing them to simulate stop and restart of training process.
```
import os
import glob
import numpy as np
import tensorflow as tf
tf.__version__

gpus = tf.config.experimental.list_logical_devices('GPU')
print(gpus)

RESULT_DIR = os.path.join(os.getcwd(), 'Test', 'Results')
CHECKPOINT_FREQUENCY = 16
LOG_EVERY = 1

BATCH_SIZE_PER_GPU = 16
NUM_GPUS = len(gpus)
GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_GPU * NUM_GPUS

def get_model():
    
    model = tf.keras.Sequential([
        tf.keras.layers.Conv2D(filters=32, strides=1, kernel_size=(4,4), input_shape=(28,28,1)),
        tf.keras.layers.Activation('relu'),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(10)
    ])
    
    return model

class SparseCategoricalLoss(tf.keras.losses.Loss):
    
    def __init__(self, num_classes, name='SparseCategoricalLoss', from_logits=False, loss_weight=1.0, *args, **kwargs):
        
        super().__init__(*args, **kwargs)
        self.num_classes = num_classes
        self.name = name
        self.from_logits=from_logits
        self.loss_weight = loss_weight
        
    def loss_fn(self, y_true, y_pred):
        label = y_true[:,0:self.num_classes]
        logit = y_pred[:,0:self.num_classes]
        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=self.from_logits,
                                                             name=self.name,
                                                             reduction=tf.keras.losses.Reduction.NONE)(label, logit)
        loss *= self.loss_weight
        return loss
    
    
    def call(self, y_true, y_pred):
        total_loss = self.loss_fn(y_true, y_pred)
        return total_loss

    def get_config(self):
         
        config = super().get_config().copy()
        config.update({
            'num_classes' : self.num_classes,
            'name' : self.name,
            'loss_weight' : self.loss_weight
        })
        return config

loss = SparseCategoricalLoss(num_classes=10,
                             from_logits=True,
                             name='categorical_loss')

strategy = tf.distribute.MirroredStrategy()

with strategy.scope():
    
    model = get_model()
    
    optimizer = tf.keras.optimizers.RMSprop(
                                            learning_rate=0.001,
                                            epsilon=1.0,
                                            momentum=0.9,
                                            rho=0.9
                                           )
    
    model.compile(optimizer=optimizer, loss=loss, metrics=['acc'])

(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.mnist.load_data()
X_train = np.expand_dims(X_train, 3)
X_test = np.expand_dims(X_test, 3)

class LoggingCallback(tf.keras.callbacks.Callback):

    def __init__(self, result_dir, log_every, initial_step=0, checkpoint_frequency=None, **kwargs):
        
        super().__init__(**kwargs)
        
        # Create result directory
        self.result_dir = result_dir
        if not os.path.exists(result_dir):
            os.makedirs(result_dir)
        
        # create checkpoint directory
        checkpoint_dir = os.path.join(self.result_dir, 'checkpoint')
        if not os.path.exists(checkpoint_dir):
            os.makedirs(checkpoint_dir)
        
        # create tensorboard directory
        tensorboard_dir = os.path.join(self.result_dir, 'tensorboard')
        if not os.path.join(tensorboard_dir):
            os.makedirs(tensorboard_dir)
        
        self.log_every = log_every
        self.checkpoint_frequency = checkpoint_frequency
        self.train_writer = tf.summary.create_file_writer( os.path.join(tensorboard_dir, 'train') )
        self.step = initial_step
        
        
    # Write metrics to TensorBoard    
    def write_metrics_tensorboard(self, logs):
        with self.train_writer.as_default():
            for name, value in logs.items():
                if name in ['batch', 'size']:
                    continue
                tf.summary.scalar(name, value, step=self.step)
                
                
    def on_batch_end(self, batch, logs=None):
        
        self.step += 1
        
        # Write metrics to tensorboard
        if self.step % self.log_every == 0:
            self.write_metrics_tensorboard(logs)
            
        # Save model checkpoint (weights + optimizer state)
        if self.checkpoint_frequency and self.step % self.checkpoint_frequency == 0:
            name = 'model_step_%d.h5' % self.step
            path = os.path.join(self.result_dir, 'checkpoint', name)
            self.model.save( path )

callbacks = LoggingCallback(result_dir=RESULT_DIR, log_every=LOG_EVERY, checkpoint_frequency=CHECKPOINT_FREQUENCY)

model.fit(
          x = X_train, 
          y = Y_train, 
          batch_size=GLOBAL_BATCH_SIZE,
          epochs=7,
          validation_data = (X_test, Y_test),
          callbacks=callbacks,
          verbose=1 
         )

del model
del strategy

previous_checkpoints = glob.glob(os.path.join(RESULT_DIR, 'checkpoint', '*'))
previous_checkpoints.sort(key=lambda x : int(os.path.basename(x).split('_')[2].replace('.h5', '')) )
latest_checkpoint = previous_checkpoints[-1]
print('Found Latest Checkpoint : %s' % latest_checkpoint)
    
initial_step = int(os.path.basename(latest_checkpoint).split('_')[2].replace('.h5', ''))
print('Resuming training from step %d' % initial_step)
    
new_callback = LoggingCallback(result_dir=RESULT_DIR, log_every=LOG_EVERY, initial_step=initial_step, checkpoint_frequency=CHECKPOINT_FREQUENCY)

strategy = tf.distribute.MirroredStrategy()
with strategy.scope():
    model = tf.keras.models.load_model( latest_checkpoint, custom_objects={'SparseCategoricalLoss':SparseCategoricalLoss} )

model.fit(
          x = X_train, 
          y = Y_train, 
          batch_size=GLOBAL_BATCH_SIZE,
          epochs=10,
          validation_data = (X_test, Y_test),
          callbacks=new_callback,
          verbose=1 
         )

```

Here is a link to colab showing the output : https://colab.research.google.com/gist/suraj-maniyar/1a305d7249baee4393147cb479ea2933/restart_training.ipynb



**Other info / logs** 

The TensorBoard entry looks like this : 
![tensorboard](https://user-images.githubusercontent.com/16310456/84227046-66de4f00-aab1-11ea-86eb-9bcb6de2aa8d.PNG)


This was a toy example using mnist. After about 26k steps, when the training was restarted, the loss spiked up indicating that the last saved checkpoint did not save the training configuration correctly.
I am training an InceptionResNet network for several days and the spike in the loss is very concerning when I restart the training (shown below).
![tensorboard_inception](https://user-images.githubusercontent.com/16310456/84227678-04864e00-aab3-11ea-940d-85748d4823ec.PNG)

"
40341,How could I know my data is distributed in the right way?,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):

I am pretraining BERT in 1 machine with 4 GPU.

The input function code:
```
   def input_fn(params):
        batch_size = FLAGS.train_batch_size

        name_to_features = {
            ""input_ids"":
                tf.FixedLenFeature([max_seq_length], tf.int64),
            ""input_mask"":
                tf.FixedLenFeature([max_seq_length], tf.int64),
            ""segment_ids"":
                tf.FixedLenFeature([max_seq_length], tf.int64),
            ""masked_lm_positions"":
                tf.FixedLenFeature([max_predictions_per_seq], tf.int64),
            ""masked_lm_ids"":
                tf.FixedLenFeature([max_predictions_per_seq], tf.int64),
            ""masked_lm_weights"":
                tf.FixedLenFeature([max_predictions_per_seq], tf.float32),
            ""next_sentence_labels"":
                tf.FixedLenFeature([1], tf.int64),
        }

        if is_training:
            d = tf.data.Dataset.from_tensor_slices(tf.constant(input_files))
            d = d.repeat()
            d = d.shuffle(buffer_size=len(input_files))

            cycle_length = min(num_cpu_threads, len(input_files))

            d = d.apply(
                tf.contrib.data.parallel_interleave(
                    tf.data.TFRecordDataset,
                    sloppy=is_training,
                    cycle_length=cycle_length))
            d = d.shuffle(buffer_size=100)
        else:
            d = tf.data.TFRecordDataset(input_files)
            d = d.repeat()

        d = d.apply(
            tf.contrib.data.map_and_batch(
                lambda record: _decode_record(record, name_to_features),
                batch_size=batch_size,
                num_parallel_batches=num_cpu_threads,
                drop_remainder=True))
        d = d.prefetch(10)
        return d
```
The mirrow strategy code:
```
    distribution = tf.contrib.distribute.MirroredStrategy(
        devices=[""device:GPU:%d"" % i for i in range(FLAGS.n_gpus)],
        cross_tower_ops=tf.distribute.HierarchicalCopyAllReduce())

    run_config = RunConfig(
        train_distribute=distribution,
        log_step_count_steps=log_every_n_steps,
        model_dir=FLAGS.output_dir,
        save_checkpoints_steps=FLAGS.save_checkpoints_steps)

    model_fn = model_fn_builder(
        bert_config=bert_config,
        init_checkpoint=FLAGS.init_checkpoint,
        learning_rate=FLAGS.learning_rate,
        num_train_steps=FLAGS.num_train_steps,
        num_warmup_steps=FLAGS.num_warmup_steps,
        use_tpu=FLAGS.use_tpu,
        use_one_hot_embeddings=FLAGS.use_tpu)

    estimator = Estimator(
        model_fn=model_fn,
        params={},
        config=run_config)

```
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux 
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.15
- Python version: 3.6
- GPU model and memory: 22G


**Describe the current behavior**

I am pretraining BERT in 1 machine with 4 GPU. 

The problem is that I have 4 GPU. Each GPU could run 8 batchsize at most. 

I set `train_batch_size = 8` not 32. Is OK but I don't know each GPU get different data in one training step.

If I set `train_batch_size = 32`, it will out of memory (OOM).

Is my code right now? Will the data be distributed to 4 GPU and each GPU get different data?

**Describe the expected behavior**

I read the some doc that said `train_batch_size` could be 32.

Thank you very much.
"
40340,Problem while adding a custom metric,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):  tf-nightly-gpu 2.3.0.dev20200609
- Python version: 3.7.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1/7
- GPU model and memory: 

**Describe the current behavior**
Error when adding a custom metric.

**Describe the expected behavior**
Should accept a custom metric.

**Standalone code to reproduce the issue**
```
from tensorflow.keras import layers, Model
from tensorflow import keras
from tensorflow.keras import backend as K
import numpy as np


def custom_mse(y_true, y_pred):
    # calculating squared difference between target and predicted values
    loss = K.square(y_pred - y_true)  # (batch_size, 2)

    # summing both loss values along batch dimension
    loss = K.sum(loss, axis=1)  # (batch_size,)
    loss = K.mean(loss, axis=-1)
    return loss

np.random.seed(1)
x_train = np.random.random((10,2))
y1_train = np.random.random((10,1))
y2_train = np.random.random((10,3))

input1 = keras.Input(shape=(2))

# Build the network graph
a1 = layers.Dense(5)(input1)
a2 = layers.Dense(3)(a1)
a3 = layers.Dense(1)(a2)

# Building Keras model
myModel = Model([input1], [a3, a2])

# Creating custom loss
myCustomLoss = custom_mse(a1[:,0], a3)

# Adding custom loss to the model
myModel.add_loss(myCustomLoss)

# Compiling model with differente weights for the losses from the output
myModel.compile(optimizer='Adam',
                loss=['mse','mse'],
                loss_weights=[10.0, 5.0]
                )

# Creating a metric based on the myCustomLoss
myModel.add_metric(myCustomLoss, name='myMetric')

# Fit the model
myModel.fit(x=[x_train],
            y=[y1_train, y2_train],
                epochs=5,
                batch_size=5,
                shuffle=True,
                )
```
https://colab.research.google.com/drive/1RyuvG5l70MNG9wxEDw4biiyA_dG3sJBe?usp=sharing


**Other info / logs** 
```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-3-71ee0bb4652c> in <module>()
     42 
     43 # Creating a metric based on the myCustomLoss
---> 44 myModel.add_metric(myCustomLoss, name='myMetric')
     45 
     46 # Fit the model

3 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py in add_metric(self, value, name, **kwargs)
   1686       # Insert layers into the Keras Graph Network.
   1687       aggregation = None if from_metric_obj else 'mean'
-> 1688       self._graph_network_add_metric(value, aggregation, name)
   1689 
   1690   @deprecation.deprecated_args(None, '`inputs` is now automatically inferred',

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py in _graph_network_add_metric(self, value, aggregation, name)
    794     new_nodes.extend(add_metric_layer.inbound_nodes)
    795     new_layers.append(add_metric_layer)
--> 796     self._insert_layers(new_layers, new_nodes)
    797 
    798   @property

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py in _insert_layers(self, layers, relevant_nodes)
    728 
    729     # Insert layers and update other layer attrs.
--> 730     layer_set = set(self._layers)
    731     deferred_layers = []
    732     for layer in layers:

/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/data_structures.py in __hash__(self)
    607     # List wrappers need to compare like regular lists, and so like regular
    608     # lists they don't belong in hash tables.
--> 609     raise TypeError(""unhashable type: 'ListWrapper'"")
    610 
    611   def insert(self, index, obj):

TypeError: unhashable type: 'ListWrapper'
```
"
40339,Error in the tpu.ipynb notebook,"I'm trying to implement the code in this notebook https://github.com/tensorflow/docs/blob/master/site/en/guide/tpu.ipynb

The lines for updating the training loss and accuracy are incorrect:
```python
training_loss.update_state(loss * strategy.num_replicas_in_sync)
training_accuracy.update_state(labels, logits)
```
I don't understand the intent behind updating the loss with the product of the number of replicas and the batch loss but it gives the wrong result. Changing the line to
```python
training_loss.update_state(labels, logits)
```
appears to solve the bug.

I also changed the definition of `training_loss` from a `metrics.Mean` to a `metrics.SparseCategoricalCrossentropy`. "
40337,Op not registered 'LSTMBlockCell' in binary running on..,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: 1.13.1
- Python version: 3.6.7
- Installed using virtualenv? pip? conda?: virtualenv
- Bazel version (if compiling from source): 0.20.0
- GCC/Compiler version (if compiling from source): MSVC 2019
- CUDA/cuDNN version: none
- GPU model and memory: none



**Describe the problem**

I exported a .pb model from python. I managed to import this model into Tensorflow C++, but receive the following error message when I add the graph to my session:

""Not found: Op type not registered 'LSTMBlockCell' in binary running on MYDESKTOP. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.
Press any key to continue . . .""


**Provide the exact sequence of commands / steps that you executed before running into the problem**

#include ""stdafx.h""
#include <stdio.h>

#include ""tensorflow/core/public/session.h""
#include ""tensorflow/core/platform/env.h""

using namespace tensorflow;

int main(int argc, char* argv[]) {
  // Initialize a tensorflow session
  Session* session;
  Status status = NewSession(SessionOptions(), &session);
  if (!status.ok()) {
    std::cout << status.ToString() << ""\n"";
    return 1;
  }

  GraphDef graph_def;
  status = ReadBinaryProto(Env::Default(), ""C:\\Users\\workaccount\\Documents\\werk\\hexachord\\pycharm\\magenta\\frozen_test.pb"", &graph_def);
  if (status.ok()) {
    std::cout << status.ToString() << ""\n"";
  }

  // Add the graph to the session
  status = session->Create(graph_def);
  if (!status.ok()) {
    std::cout << status.ToString() << ""\n"";
	system(""pause"");
  }
}

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.



thank you kindly for your response"
40336,Eager Function Inputs cannot be Keras Symbolic Tensors error when using Intermediate layers in custom loss function,"I am using Colab with TF 2.2.

**Current behavior**
```
Inputs to eager execution function cannot be Keras symbolic tensors,
 but found [<tf.Tensor 'dense_3_1/Identity:0' shape=(100, 2) dtype=float32>
, <tf.Tensor 'dense_2_1/Identity:0' shape=(100, 2) dtype=float32>]
```
**Expected behavior**
Model trains successfully

**Standalone code to reproduce the issue**

1. Just copy the code from [here](https://github.com/keras-team/keras/blob/keras-2/examples/variational_autoencoder.py) to a colab cell,
2. Change keras to tensorflow.keras (using just keras works).
3. Code works with tf.config.experimental_run_functions_eagerly, but the problem is that it is very slow and sometimes causes OOM.
"
40332,gradient descent and performance issues with Tf 2.1 ,"I am using the latest builds of tensorflow and tensorflow probability respectively with the following code

```
x = x.astype(np.float64)#tf.dtypes.cast(x, tf.int32) #
#x = tf.cast(x, tf.float32)
#x = tensor_util.convert_nonref_to_tensor(x, dtype=x.dtype)

class RBFKernelFn(tf.keras.layers.Layer):
  def __init__(self, **kwargs):
    super(RBFKernelFn, self).__init__(**kwargs)
    dtype = kwargs.get('dtype', None)
    self.amplitude = tfp.util.TransformedVariable(
      1., tfb.Softplus(), dtype=dtype, name='amplitude')
    self.length_scale = tfp.util.TransformedVariable(
      1., tfb.Softplus(), dtype=dtype, name='length_scale')
    
    
  def call(self, x):
    # Never called -- this is just a layer so it can hold variables
    # in a way Keras understands.
    #print(dtype)
    return x

  @property
  def kernel(self):

    
    return tfk.ExponentiatedQuadratic(
      amplitude=self.amplitude,
      length_scale=self.length_scale)
    observation_noise_variance = tfp.util.TransformedVariable(
      1., tfb.Softplus(), dtype=dtype, name='observation_noise_variance')

dtype = np.float64
amplitude = tfp.util.TransformedVariable(
      1., tfb.Softplus(), dtype=dtype, name='amplitude')
length_scale = tfp.util.TransformedVariable(
      1., tfb.Softplus(), dtype=dtype, name='length_scale')
kernel = tfk.ExponentiatedQuadratic(
      amplitude=amplitude,
      length_scale=length_scale)
observation_noise_variance = tfp.util.TransformedVariable(
      1., tfb.Softplus(), dtype=dtype, name='observation_noise_variance')
```

and this is the code for the neural network itself
'
```
x_tst = x[189::]
x_range = 237
num_distributions_over_Functions = 1
tf.keras.backend.set_floatx('float64')
#kernel = Brownian #tfp.positive_semidefinite_kernels.ExponentiatedQuadratic#MaternOneHalf()

model = tf.keras.Sequential([
    tf.keras.Input(shape=(1,14), dtype=np.float64),
    tf.keras.layers.LSTM(25,kernel_initializer='ones',activation='tanh', dtype = x.dtype, use_bias=True),
    #tf.keras.layers.InputLayer(input_shape=(10),dtype=x.dtype),#put a 1 before the 9 later
    tf.keras.layers.Dense(50,kernel_initializer='ones', use_bias=False),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(75,kernel_initializer='ones', use_bias=False),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(100,kernel_initializer='ones', use_bias=False),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(125,kernel_initializer='ones', use_bias=False),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(150,kernel_initializer='ones',use_bias=False),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(175,kernel_initializer='ones',use_bias=False),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(200,kernel_initializer='ones',use_bias=False),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(225,kernel_initializer='ones',use_bias=False),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(250,kernel_initializer='ones',use_bias=False),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(225,kernel_initializer='ones',use_bias=False),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(200,kernel_initializer='ones',use_bias=False),
    #goal is to eventually replace the first dense layer with an LSTM layer
    #tf.keras.layers.LSTM
    #tf.keras.layers.TimeDistributed(Dense(vocabulary)))
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(150,kernel_initializer='ones',use_bias=False),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(125,kernel_initializer='ones', use_bias=False),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(100,kernel_initializer='ones',use_bias=False),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(75,kernel_initializer='ones', use_bias=False),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(50,kernel_initializer='ones',use_bias=False),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(25, kernel_initializer='ones',use_bias=False,),
    tfp.layers.VariationalGaussianProcess(
    num_inducing_points=num_inducing_points, kernel_provider=RBFKernelFn(dtype=x.dtype) , event_shape=(1,),
    inducing_index_points_initializer=tf.compat.v1.constant_initializer(
            np.linspace(0,x_range, num=1125,
                        dtype=x.dtype)[..., np.newaxis]), unconstrained_observation_noise_variance_initializer=(tf.compat.v1.constant_initializer(np.log(np.expm1(1.)).astype(x.dtype))),variational_inducing_observations_scale_initializer=(tf.compat.v1.constant_initializer(np.log(np.expm1(1.)).astype(np.float64))), mean_fn=None,
    jitter=1e-06, convert_to_tensor_fn=tfp.distributions.Distribution.sample)


])
```

I am getting the following warnings which seem to be impacting my performance further. Before the upgrade I could get near 0 loss with 270 epochs. Now it has stopped improving altogether after a few hundred epochs and gets permanently stuck at 34.

"
40331,ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type list).,"Im getting this valueError in colab gpu env with keras tensorflow ver 2.
ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type list). on running the following code :
 # ---- CTC ----
    # y_input layers (transcription data) for CTC loss

labels = Input(name='the_labels', shape=[None], dtype=dtype)       # transcription data (batch_size * y_seq_size)
input_length = Input(name='input_length', shape=X_train_length.shape, dtype=dtype)  # unpadded len of all x_sequences in batch
label_length = Input(name='label_length', shape=label_length.shape, dtype=dtype)  # unpadded len of all y_sequences in batch


# Lambda layer with ctc_loss function due to Keras not supporting CTC layers
loss_out = Lambda(function=ctc_lambda_func, name='ctc', output_shape=(1,))([y_pred, np.float32, Y_train, np.float32, X_train_length, np.float32, label_length, np.float32])
network_model = Model(inputs=[input_data, labels, input_length, label_length], outputs=y_pred)

PFA the screenshot for reference.
![code](https://user-images.githubusercontent.com/17008416/84185974-6e035e00-aaad-11ea-9959-c22d7e7b4624.png)




"
40328,Subclassed model with ConvLSTM2D layer can't be saved as a SavedModel in TF2.2 ,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): custom code, extended an example from TF guides 
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04/Mac OS 10.15
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.1 and 2.2
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1 
- GPU model and memory: 1080Ti 11Gb


**Describe the current behavior**

As a header states the model build with Subclassing API with ConvLSTM2D layer inside can't be saved as a SavedModel. Given that keras (.h5) model format doesn't support saving subclassed models I am left with no option to save the model architecture to file.

The issues appears in TF2.2 while there seems to be no bug in earlier version 2.1 

**Describe the expected behavior**

The code is to work without issues in both TF2.2 and TF2.1

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

https://colab.research.google.com/drive/1zfhnbz_dHfPloT9mzk0ei5F4aFaZGgnt?usp=sharing

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

```python
import numpy as np
import tensorflow as tf
print(tf.__version__)
from tensorflow import keras
from tensorflow.keras.layers import ConvLSTM2D, Bidirectional, LSTM

class CustomModel(keras.Model):
  def __init__(self, hidden_units):
    super(CustomModel, self).__init__()
    self.lstm = Bidirectional(ConvLSTM2D(filters=16, kernel_size=(1, 1), return_sequences=True, return_state=True))
    self.dense_layers = [keras.layers.Dense(u) for u in hidden_units]

  def call(self, inputs, training=None, mask=None):
    x = inputs
    x, _, _, _, _ = self.lstm(x)
    for layer in self.dense_layers:
      x = layer(x)
    return x

model = CustomModel([16, 16, 10])
# Build the model by calling it
input_arr = tf.random.uniform((1, 10, 10, 10, 5))
outputs=model.predict(input_arr)
model.save('my_model')

# Delete the custom-defined model class to ensure that the loader does not have
# access to it.
del CustomModel

loaded = keras.models.load_model('my_model')
```

Similar issue discussed on stackoverflow
https://stackoverflow.com/questions/61362953/keras-convlstm2d-valueerror-when-saving-model"
40326,TF2. How to set tf.OptimizerOptions.L0,"**System information**
- Have I written custom code NO:
- OS Platform and Distribution Linux (Ubuntu 20.04):
- TensorFlow installed from source:
- TensorFlow version (use command below):
- Python version: 3.8.2
- Bazel version 3.0.0:
- GCC/Compiler version gcc (Ubuntu 8.4.0-3ubuntu2) 8.4.0):

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
v1.12.1-32834-g3e842e5ffc 2.2.0

**Describe the current behavior**

Reference: https://github.com/yaroslavvb/stuff/blob/master/matmul_benchmark.py

Script from TF1.14
in my TF1 workload,  I was calling this to avoid optimizing away redundant nodes and it worked.
```
config = tf.ConfigProto(graph_options=tf.GraphOptions(optimizer_options=tf.OptimizerOptions(opt_level=tf.OptimizerOptions.L0)))
sess = tf.Session(config=config)
```

**Describe the expected behavior**
With TF2, I replaced above code with the following and it seems to be not working.  

`tf.compat.v1.OptimizerOptions(opt_level=-1)`

"
40325,[TF Lite] GPU delegates for windows,"Hi, I'm trying to run tf lite on windows with gpu support, so I can run inference on a windows desktop app as fast as possible without relying on CUDA (users may not have a nvidia graphics card or cuda installed)

Is there a way to compile/use the gpu delegates on windows?

This is related to #28830

**System information**
- OS Platform and Distribution: Windows 10 x64
- TensorFlow installed from: source
- TensorFlow version: v2.2.0
- Python version: 3.6
- Installed using conda
- Bazel version: 2.0.0
- GCC/Compiler version: Visual Studio 2019

**Describe the problem**

I cannot TF Lite with GPU support on windows. I compiled the tf lite c api, but it does not provide gpu delegates. I've tried to compile some sort of dll from //tensorflow/lite/delegates/gpu, but no luck.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
`bazel build //tensorflow/lite/c:tensorflowlite_c.dll -c opt`

Trying to compile the delegates:
`bazel build -c opt --copt -Os --copt -DTFLITE_GPU_BINARY_RELEASE --copt --linkopt -s --strip always //tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so`
`bazel build //tensorflow/lite/delegates/gpu:api -c opt`

**Any other info / logs**
```
bazel build -c opt --copt -Os --copt -DTFLITE_GPU_BINARY_RELEASE
 --copt --linkopt -s --strip always //tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so
...
ERROR: Z:/projects/tensorflow/tensorflow/lite/delegates/gpu/cl/BUILD:207:1: C++ compilation of rule '//tensorflow/lite/delegates/gpu/cl:egl_sync' failed (Exit 2)
cl : Command line warning D9002 : ignoring unknown option '--linkopt'
.\tensorflow/lite/delegates/gpu/cl/egl_sync.h(19): fatal error C1083: Cannot open include file: 'EGL/egl.h': No such file or directory
Target //tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so failed to build
INFO: Elapsed time: 4.166s, Critical Path: 3.91s
INFO: 31 processes: 31 local.
FAILED: Build did NOT complete successfully
```

```
bazel build //tensorflow/lite/delegates/gpu:api -c opt
...
ERROR: Z:/projects/tensorflow/tensorflow/lite/delegates/gpu/BUILD:196:1: C++ compilation of rule '//tensorflow/lite/delegates/gpu:api' failed (Exit 2)
cl_version.h: CL_TARGET_OPENCL_VERSION is not defined. Defaulting to 220 (OpenCL 2.2)
.\tensorflow/lite/delegates/gpu/gl/portable_gl31.h(21): fatal error C1083: Cannot open include file: 'EGL/egl.h': No such file or directory
Target //tensorflow/lite/delegates/gpu:api failed to build
INFO: Elapsed time: 0.552s, Critical Path: 0.33s
INFO: 0 processes.
FAILED: Build did NOT complete successfully
```
"
40323,Training using GradientTape not working ,"Tensorflow 2.2.0 
Mac OS Catalina
Built and Tested in Spyder 4

![Figure_1](https://user-images.githubusercontent.com/28906480/84167840-9f106e00-aa6e-11ea-94c0-ed9c1cd211fc.png)
Regression fits for each approach, the Keras fit is identical to the actual solution.


I have been trying to build a Neural Network based regressor that can model a nonlinear function. I am recreating the issue with a dummy case here. 

Initially I have established a function **u=f(x,t)=sin(x/2)+e^(-t)** and built up a dataset by doing a parameter scan along x and t.

    N = 5000
    x = np.linspace(-np.pi, np.pi, N)
    t = np.linspace(0, 2, N)

    lb = np.asarray([x.min(), t.min()])
    ub = np.asarray([x.max(), t.max()])

    def func_u(x, t): # Function that we are interested in modelling.
        return np.sin(x/2) + np.exp(-t)

    u_actual = func_u(x, t) 
 
    X = np.vstack((x, t)).T

After having built a labelled dataset that maps the function from input to output, tried fitting using a keras approach. 

```
def tf_model(): # Creating a two layer Neural Network. 
    act_func = 'relu'
    model_tf = keras.Sequential()
    model_tf.add(keras.layers.Input(shape=(2,)))
    model_tf.add(keras.layers.Dense(100, activation=act_func))
    model_tf.add(keras.layers.Dense(100, activation=act_func))
    model_tf.add(keras.layers.Dense(1, activation='linear'))
    
    return model_tf


model = tf_model()
model.compile(optimizer='adam', loss='mse')

model.fit(X, u_actual, # Fitting using the Keras API
          batch_size=500,
          epochs=1000,
          verbose=1)

u_model_fit = model(X).numpy()
```
Which does an amazing job of fitting to the data. 

However, when I try and do that with a custom training implementation using GradientTape, it all goes awfully wrong: 

```
def shuffle_and_batch(X, Y, num_batches=50): # Shuffle and group the input data inot various datasizes. 
    indices = tf.range(start=0, limit=tf.shape(X)[0], dtype=tf.int32) 
    shuffled_indices = tf.random.shuffle(indices)
    
    X = tf.gather(X, shuffled_indices)
    Y = tf.gather(Y, shuffled_indices)

    X = tf.split(X, num_batches)
    Y = tf.split(Y, num_batches)
    return X, Y


X_tf = tf.Variable(X, tf.float64) #Creating Tensors to treat as the inputs. 
Y_tf = tf.Variable(u_actual, tf.float64)

X_tf, Y_tf = shuffle_and_batch(X_tf, Y_tf)


def loss(model, X, Y): # mean squared reconstruction error 
    return tf.reduce_mean(tf.square(model(X, training=True) - Y))
                          
def loss_and_gradients(model, X, Y):
    with tf.GradientTape() as tape:
        loss_tf = loss(model, X, Y)
    grads_tf = tape.gradient(loss_tf, model.trainable_variables)  #Calculating the gradient of each of the loss with respect to the weights and biases. 
    return loss_tf, grads_tf
    

optimizer = tf.keras.optimizers.Adam()
nIter =1000
model = tf_model()

for it in range(nIter):
    for batch_num in range(50):
        loss_tf, grads_tf = loss_and_gradients(model, X_tf[batch_num], Y_tf[batch_num]) #Obtaining the loss and the gradients
        optimizer.apply_gradients(zip(grads_tf, model.trainable_variables)) #Applying the gradients for each step 

    tf.print('Iter : {}, loss : {}'.format(it, loss_tf))
    
u_tf = model(X).numpy()
```
I tried to do that with Pytorch and pretty much arrive at the same solution as that of using Gradient Tape 

```
model_torch = torch.nn.Sequential(
    torch.nn.Linear(2, 100),
    torch.nn.ReLU(),
    torch.nn.Linear(100, 100),
    torch.nn.ReLU(),
    torch.nn.Linear(100, 1)
    )

X_torch = torch.tensor(X, dtype=torch.float64).float()
Y_torch = torch.tensor(u_actual, dtype=torch.float64).float()

# X_torch, Y_torch = shuffle_and_batch_torch(X_torch, Y_torch)
X_torch, Y_torch = torch.autograd.Variable(X_torch, requires_grad=True), torch.autograd.Variable(Y_torch, requires_grad=True) #Ensuring that tracing occurs. 

traindata = torch.utils.data.TensorDataset(X_torch, Y_torch) #Loading, Shuffling and Batching the training data. 
dataloader = torch.utils.data.DataLoader(traindata, batch_size=50, shuffle=True)

def lossfunc_torch(model, X, Y): # Calculating the mean squared error, 
    y = model_torch(X)    
    loss = (y-Y).pow(2).mean()
    
    return loss

optimizer = torch.optim.Adam(model_torch.parameters(), 0.001)    
nIter = 1000


for it in range(nIter):
    for i, (x_torch, y_torch) in enumerate (dataloader):
        optimizer.zero_grad()
        
        loss_torch = lossfunc_torch(model_torch, x_torch, y_torch)
    
        loss_torch.backward()
        optimizer.step()
        
        
    print(""Iter : {}, Loss : {}"".format(it, loss_torch.item()))


u_torch = model_torch(X_torch).detach().numpy()

```
"
40322,"""The name 'num_detections:0' refers to a Tensor which does not exist. The operation, 'num_detections', does not exist in the graph.""","

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on a mobile device: No
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.13.1
- Python version: 3.6
- CUDA/cuDNN version:9/7.5
- GPU model and memory: Nvidia Geforce 840m



**Describe the current behaviour**
I have successfully trained and used a face mask detection model based on Keras Yolo project, the model predicts with good accuracy, I have converted the Keras model (.h5 ) to .pb model ( frozen model ) to export the model on the web with Flask.

I'm trying to test the model ( load the pb model ) and predict face mask and face no mask with an image.
 This code that I've used:
```python

import os
import numpy as np
import cv2
import matplotlib.pyplot as plt
import tensorflow as tf
# Provide path to an image for testing
img = cv2.imread(""D:\\keras_to_tensorflow\\test_images\\dss.jpg"")
img_height, img_width, _ = img.shape
img_cv2 = img[:, :, [2, 1, 0]]
# Load the Model
model_path = ""D:\\keras_to_tensorflow\\""
pb_file = os.path.join(model_path, 'face_detect.pb')
# Read the graph.
with tf.gfile.FastGFile(pb_file, 'rb') as f:
    graph_def = tf.GraphDef()
    graph_def.ParseFromString(f.read())
gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=1)
with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:
    sess.graph.as_default()
    tf.import_graph_def(graph_def, name='face_detect.pbtxt')

#Include this part with the tensorflow session
#Run the session using the tensors and feed the image to the session
#img_in = cv2.resize(img_cv2, (224, 224))
    img_in = img_cv2[:, :, [2, 1, 0]]  # BGR2RGB
    outputs = sess.run([sess.graph.get_tensor_by_name('num_detections:0'),
             sess.graph.get_tensor_by_name('detection_scores:0'),
             sess.graph.get_tensor_by_name('detection_boxes:0'),
             sess.graph.get_tensor_by_name('detection_classes:0')],
             feed_dict={
                       'input_1:0': img.reshape(1,
                        img.shape[0],
                        img.shape[1],3)})


# Visualize the results
    font = cv2.FONT_HERSHEY_SIMPLEX
    for i in range(num_detections):
        classId = int(outputs[3][0][i])
        print(classId)
        score = float(outputs[1][0][i])
        bbox = [float(v) for v in outputs[2][0][i]]
        if True:
            x = bbox[1] * img_width
            y = bbox[0] * img_height
            right = bbox[3] * img_width
            bottom = bbox[2] * img_height
            cv2.rectangle(img_cv2,
                          (int(x), int(y)),
                          (int(right), int(bottom)),
                          (225, 255, 0),
                          thickness=2)
            cv2.putText(img_cv2,str(class_list[classId-1]),(int(x),int(y)), font, 1, (200,0,0), 3, cv2.LINE_AA)
            print('SCORE:',score, ', Class:',class_list[classId-1], ', BBox:',int(x),int(y),int(right),int(bottom))

```

I got this error :

>KeyError: ""The name 'num_detections:0' refers to a Tensor which does not exist. The operation, 'num_detections', does not exist in the graph.""


+ Link of the project That I've used: https://github.com/experiencor/keras-yolo3
The problem that I did not have a tensor with this name, 

How can I make this code work perfectly? 



"
40321,Neural Structured Learning,"
Is neural structured learning is same as using graph neural network?"
40319,Options for tflite_convert,"Hello guys,

I'd like to find out all options available for `tflite_convert` and since I use `--help` I got

```
(tf-cpu):~$ tflite_convert --help
usage: tflite_convert [-h] --output_file OUTPUT_FILE
                      [--saved_model_dir SAVED_MODEL_DIR | --keras_model_file KERAS_MODEL_FILE]
                      [--enable_v1_converter]
                      [--experimental_new_converter [EXPERIMENTAL_NEW_CONVERTER]]

Command line tool to run TensorFlow Lite Converter.

optional arguments:
  -h, --help            show this help message and exit
  --output_file OUTPUT_FILE
                        Full filepath of the output file.
  --saved_model_dir SAVED_MODEL_DIR
                        Full path of the directory containing the SavedModel.
  --keras_model_file KERAS_MODEL_FILE
                        Full filepath of HDF5 file containing tf.Keras model.
  --enable_v1_converter
                        Enables the TensorFlow V1 converter in 2.0
  --experimental_new_converter [EXPERIMENTAL_NEW_CONVERTER]
                        Experimental flag, subject to change. Enables MLIR-
                        based conversion instead of TOCO conversion.

``` 

I see there are more options available such as ` --inference_type` `--std_dev_values` I'd like to know those and their respective parameters.
 "
40318,[TF Lite C API]  Zero outputs,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: SnapDragon 645, Android 10
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): v2.2.0
- Python version: 2.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: CUDA 10.2
- GPU model and memory: NA

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
I'm inferencing the same model in C++ API (using libtensorflowlite.so) and C API (using libtensorflowlite_c.so) on Android NDK r18b. While the C++ code works well and passed test cases, the C version output all zeros.

**Describe the expected behavior**

Output from C and C++ version should be exactly the same.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```
void forward(const float* real, const float* imag, float* pout) {
    TfLiteInterpreterAllocateTensors(interpreter);
    TfLiteTensor* tflite_real = TfLiteInterpreterGetInputTensor(interpreter, 0);
    TfLiteTensor* tflite_imag = TfLiteInterpreterGetInputTensor(interpreter, 1);
    TfLiteTensorCopyFromBuffer(tflite_real, real, N1 * sizeof(float));
    TfLiteTensorCopyFromBuffer(tflite_imag, imag, N2 * sizeof(float));

    TfLiteInterpreterInvoke(interpreter);
    const TfLiteTensor* out = TfLiteInterpreterGetOutputTensor(interpreter, 0);
    TfLiteTensorCopyToBuffer(out, pout, N_OUT * sizeof(float));
}
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40316,Cannot register 2 metrics with the same name Error,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): JetPack 4.3 (Ubuntu 18.04) 
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):source
- TensorFlow version (use command below):1.15.2
- Python version:3.6.9
- Bazel version (if compiling from source):0.26.1
- GCC/Compiler version (if compiling from source):7.5.0
- CUDA/cuDNN version:10.0/7.6.3
- GPU model and memory:Jetson AGX Xavier (GPU Volta)


**Describe the current behavior**
I'm trying to create an executable of my code (C++) which is using opencv and tensorflow. For this, I have to use autotools which is a tool used to create Makefiles. I'm successfully making my executable but I'm trying to use it I always have this error : 

`2020-06-09 14:02:25.158088: E tensorflow/core/lib/monitoring/collection_registry.cc:77] Cannot register 2 metrics with the same name: /tensorflow/cc/saved_model/load_attempt_count
2020-06-09 14:02:25.158383: E tensorflow/core/lib/monitoring/collection_registry.cc:77] Cannot register 2 metrics with the same name: /tensorflow/cc/saved_model/load_latency
2020-06-09 14:02:25.158467: E tensorflow/core/lib/monitoring/collection_registry.cc:77] Cannot register 2 metrics with the same name: /tensorflow/cc/saved_model/load_latency_by_stage
2020-06-09 14:02:25.159111: F tensorflow/core/framework/variant_op_registry.cc:53] Check failed: existing == nullptr (0x55a3931838 vs. nullptr)Unary VariantDecodeFn for type_name: tensorflow::data::WrappedDatasetVariant already registered
Aborted (core dumped)
`

I do not really understand why,because I have included the required tensorflow flags in my configuration as you can see below : 

AM_LDFLAGS = -lopencv_core -lopencv_imgproc -lopencv_highgui -lopencv_videoio -ltensorflow_cc -ltensorflow_framework -lprotobuf -lprotoc

Any help would be much appreciated, thanks !

"
40315,"Custom keras model  train success,but save error","SRGNNModel train sucess,but when I use tf.saved_model.save to save it, it crashed.
Is it cased by tf.compat.v1.nn.dynamic_rnn ? How can I change it？

-TensorFlow2.2

**Complete Code**

```
# coding=utf-8
""""""
 @date  :2020-06-05 17:31
""""""
from __future__ import absolute_import, division, print_function, unicode_literals
import tensorflow as tf
import argparse
import csv
import numpy as np
import time
from functools import partial
from tensorflow.keras.layers import Dense, Flatten, Conv2D
from tensorflow.keras import Model
import numpy as np
import csv
import math


class SRGNNModel(Model):
    def __init__(self, n_node, l2, step, lr, decay, lr_dc, batch_size=100, hidden_size=100, out_size=100):
        super(SRGNNModel, self).__init__()
        self.batch_size_num = batch_size
        self.hidden_size = hidden_size
        self.out_size = out_size
        self.n_node = n_node
        self.L2 = l2
        self.step = step
        self.stdv = 1.0 / math.sqrt(self.hidden_size)
        self.nasr_w1 = tf.Varnasr_w1 = tf.Variable(
            tf.random.uniform((self.out_size, self.out_size), -self.stdv, self.stdv), name='nasr_w1', dtype=tf.float32)
        self.nasr_w2 = tf.Variable(tf.random.uniform((self.out_size, self.out_size), -self.stdv, self.stdv),
                                   name='nasr_w2', dtype=tf.float32)
        self.nasr_v = tf.Variable(tf.random.uniform((1, self.out_size), -self.stdv, self.stdv), name='nasrv',
                                  dtype=tf.float32)
        self.nasr_b = tf.Variable(tf.zeros((self.out_size,)), name='nasr_b', dtype=tf.float32)

        self.embedding = tf.Variable(tf.random.uniform((self.n_node, self.hidden_size), -self.stdv, self.stdv),
                                     name='embedding', dtype=tf.float32)
        self.W_in = tf.Variable(tf.random.uniform((self.out_size, self.out_size), -self.stdv, self.stdv), name='W_in',
                                dtype=tf.float32)
        self.b_in = tf.Variable(tf.random.uniform((self.out_size,), -self.stdv, self.stdv), name='b_in',
                                dtype=tf.float32)
        self.W_out = tf.Variable(tf.random.uniform((self.out_size, self.out_size), -self.stdv, self.stdv), name='W_out',
                                 dtype=tf.float32)
        self.b_out = tf.Variable(tf.random.uniform((self.out_size,), -self.stdv, self.stdv), name='b_out',
                                 dtype=tf.float32)
        self.B = tf.Variable(tf.random.uniform((2 * self.out_size, self.out_size), -self.stdv, self.stdv), name='B',
                             dtype=tf.float32)
        self.learning_rate = tf.optimizers.schedules.ExponentialDecay(lr, decay, decay_rate=lr_dc, staircase=True)
        self.opt = tf.optimizers.Adam(self.learning_rate)

    def call(self, x):
        (adj_in, adj_out, alias, item, mask) = x
        self.batch_size = tf.shape(item)[0]
        fin_state = tf.nn.embedding_lookup(self.embedding, item)
        cell = tf.keras.layers.GRUCell(self.out_size)

        adj_in = tf.cast(adj_in, tf.float32)
        adj_out = tf.cast(adj_out, tf.float32)
        mask = tf.cast(mask, tf.float32)
        for i in range(self.step):
            fin_state = tf.reshape(fin_state, [self.batch_size, -1, self.out_size])
            fin_state_in = tf.reshape(tf.matmul(tf.reshape(fin_state, [-1, self.out_size]), self.W_in) + self.b_in,
                                      [self.batch_size, -1, self.out_size])
            fin_state_out = tf.reshape(tf.matmul(tf.reshape(fin_state, [-1, self.out_size]), self.W_out) + self.b_out,
                                       [self.batch_size, -1, self.out_size])

            av = tf.concat([tf.matmul(adj_in, fin_state_in), tf.matmul(adj_out, fin_state_out)], axis=-1)
            init_state = tf.reshape(fin_state, [-1, self.out_size])
            state_output, fin_state = tf.compat.v1.nn.dynamic_rnn(cell=cell,
                                                                  inputs=tf.expand_dims(
                                                                      tf.reshape(av, [-1, 2 * self.out_size]), axis=1),
                                                                  initial_state=init_state
                                                                  )
        re_embedding = tf.reshape(fin_state, [self.batch_size, -1, self.out_size])
        rm = tf.reduce_sum(mask, 1)
        last_id = tf.gather_nd(alias, tf.stack([tf.range(self.batch_size), tf.cast(rm, tf.int32) - 1], axis=1))

        last_h = tf.gather_nd(re_embedding, tf.stack([tf.range(self.batch_size), last_id], axis=1))

        seq_h = tf.stack([tf.nn.embedding_lookup(re_embedding[i], alias[i]) for i in range(self.batch_size_num)],
                         axis=0)
        last = tf.matmul(last_h, self.nasr_w1)
        seq = tf.matmul(tf.reshape(seq_h, [-1, self.out_size]), self.nasr_w2)
        last = tf.reshape(last, [self.batch_size, 1, -1])
        m = tf.nn.sigmoid(last + tf.reshape(seq, [self.batch_size, -1, self.out_size]) + self.nasr_b)
        coef = tf.matmul(tf.reshape(m, [-1, self.out_size]), self.nasr_v, transpose_b=True) * tf.reshape(mask, [-1, 1])
        b = self.embedding[1:]
        ma = tf.concat([tf.reduce_sum(tf.reshape(coef, [self.batch_size, -1, 1]) * seq_h, 1),
                        tf.reshape(last, [-1, self.out_size])], -1)
        y1 = tf.matmul(ma, self.B)
        logits = tf.matmul(y1, b, transpose_b=True)
        return logits


def data_generator(data):
    for example in data:
        yield example


def process_data(row):
    features = row[:-1]
    labels = row[-1]
    items, alias_inputs = tf.unique(features)  # value,index

    vector_length = tf.shape(features)[0]
    n_nodes = tf.shape(items)[0]
    indices = tf.gather(alias_inputs, tf.stack([tf.range(vector_length - 1), tf.range(vector_length - 1) + 1],
                                               axis=0))  # Stack and stagger values
    unique_indices, _ = tf.unique(indices[0] * (vector_length + 1) + indices[1])  # unique(a*x + b)
    unique_indices = tf.sort(unique_indices)  # Sort ascending
    unique_indices = tf.stack(
        [tf.math.floordiv(unique_indices, (vector_length + 1)), tf.math.floormod(unique_indices, (vector_length + 1))],
        axis=1)  # Ungroup and stack
    unique_indices = tf.cast(unique_indices, tf.int64)

    values = tf.ones(tf.shape(unique_indices, out_type=tf.int64)[0], dtype=tf.int64)
    dense_shape = tf.cast([n_nodes, n_nodes], tf.int64)

    adj = tf.SparseTensor(indices=unique_indices, values=values, dense_shape=dense_shape)
    adj = tf.sparse.to_dense(adj)

    u_sum_in_tf = tf.math.reduce_sum(adj, 0)
    u_sum_in_tf = tf.clip_by_value(u_sum_in_tf, 1, tf.reduce_max(u_sum_in_tf))
    A_in = tf.math.divide(adj, u_sum_in_tf)

    u_sum_out_tf = tf.math.reduce_sum(adj, 1)
    u_sum_out_tf = tf.clip_by_value(u_sum_out_tf, 1, tf.reduce_max(u_sum_out_tf))
    A_out = tf.math.divide(tf.transpose(adj), u_sum_out_tf)

    mask = tf.fill(tf.shape(features), 1)

    return A_in, A_out, alias_inputs, items, mask, labels


def input_fn(data, batch_size, max_seq, max_n_node):
    dataset = tf.data.Dataset.from_generator(partial(data_generator, data), output_types=(tf.int32))
    dataset = dataset.map(process_data, num_parallel_calls=tf.data.experimental.AUTOTUNE)
    dataset = dataset.padded_batch(batch_size=batch_size, padded_shapes=(
        [max_n_node, max_n_node],
        [max_n_node, max_n_node],
        [max_seq],
        [max_n_node],
        [max_seq],
        []))

    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
    return dataset


def loss_fn(logits, labels):
    softmax = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels - 1, logits=logits)
    loss = tf.reduce_mean(softmax)
    return loss


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--model_path', default='saved_model_test', help='model path')
    parser.add_argument('--method', type=str, default='ggnn', help='ggnn/gat/gcn')
    parser.add_argument('--validation', action='store_true', help='validation')
    parser.add_argument('--epoch', type=int, default=2, help='number of epochs to train for')
    parser.add_argument('--batch_size', type=int, default=10, help='input batch size')
    parser.add_argument('--hidden_size', type=int, default=100, help='hidden state size')
    parser.add_argument('--l2', type=float, default=1e-5, help='l2 penalty')
    parser.add_argument('--lr', type=float, default=0.001, help='learning rate')
    parser.add_argument('--step', type=int, default=1, help='gnn propogation steps')
    parser.add_argument('--nonhybrid', action='store_true', help='global preference')
    parser.add_argument('--lr_dc', type=float, default=0.1, help='learning rate decay rate')
    parser.add_argument('--lr_dc_step', type=int, default=3,
                        help='the number of steps after which the learning rate decay')
    opt = parser.parse_args()
    n_node = 0
    max_seq = 0
    max_n_node = 0
    origin_train_data = np.random.randint(1,50,size=[1000,10]).tolist()
    n_node = max(n_node, np.amax([np.amax(z) for z in origin_train_data]) + 1)
    max_seq = max(max_seq, len(max(origin_train_data, key=len)))
    max_n_node = max(max_n_node, len(max([np.unique(i) for i in origin_train_data], key=len)))
    train_dataset_size = len(origin_train_data)
    print(n_node, max_seq, max_n_node)

    origin_test_data = np.random.randint(1,50,size=[500,10]).tolist()
    n_node = max(n_node, np.amax([np.amax(z) for z in origin_test_data]) + 1)
    max_seq = max(max_seq, len(max(origin_test_data, key=len)))
    max_n_node = max(max_n_node, len(max([np.unique(i) for i in origin_test_data], key=len)))
    test_dataset_size = len(origin_test_data)

    print(""n_node:"", n_node)
    print(""max_seq:"", max_seq)
    print(""max_n_node:"", max_n_node)
    print(""train_dataset_size:"", train_dataset_size)
    print(""test_dataset_size:"", test_dataset_size)

    train_loss = tf.keras.metrics.Mean(name='train_loss')

    train_accuracy = tf.keras.metrics.SparseTopKCategoricalAccuracy(k=20)

    test_loss = tf.keras.metrics.Mean(name='test_loss')
    test_accuracy = tf.keras.metrics.SparseTopKCategoricalAccuracy(k=20)

    optimizer = tf.keras.optimizers.Adam()
    train_data = input_fn(origin_train_data, opt.batch_size, max_seq, max_n_node)
    test_data = input_fn(origin_test_data, opt.batch_size, max_seq, max_n_node)

    model = SRGNNModel(n_node=n_node,
                       l2=opt.l2,
                       step=opt.step,
                       lr=opt.lr,
                       decay=opt.lr_dc_step * train_dataset_size / opt.batch_size,
                       lr_dc=opt.lr_dc,
                       batch_size=opt.batch_size,
                       hidden_size=opt.hidden_size,
                       out_size=opt.hidden_size)


    def train_step(inputs, labels):
        with tf.GradientTape() as tape:
            predictions = model(inputs)
            loss = loss_fn(predictions, labels)
        gradients = tape.gradient(loss, model.trainable_variables)
        optimizer.apply_gradients(zip(gradients, model.trainable_variables))
        train_loss(loss)
        train_accuracy(labels - 1, predictions)


    def test_step(inputs, labels):
        predictions = model(inputs)
        loss = loss_fn(predictions, labels)
        test_loss(loss)
        test_accuracy(labels - 1, predictions)


    num = 0
    for epoch in range(opt.epoch):
        train_loss.reset_states()
        train_accuracy.reset_states()
        test_loss.reset_states()
        test_accuracy.reset_states()
        step_template = 'Epoch {},Global step {}, Loss: {}, Recall@20: {}'

        for A_in, A_out, alias_inputs, items, mask, labels in train_data:
            train_step((A_in, A_out, alias_inputs, items, mask), labels)
            num = num + 1

            if num % 10 == 0:
                print(time.strftime('%Y-%m-%d %H:%M:%S ', time.localtime(time.time())) +
                      step_template.format(epoch + 1, num * opt.batch_size, train_loss.result(),
                                           train_accuracy.result() * 100))

        for A_in, A_out, alias_inputs, items, mask, labels in test_data:
            test_step((A_in, A_out, alias_inputs, items, mask), labels)
        template = 'Epoch {}, Loss: {}, Recall@20: {}, Test Loss: {}, Test Recall@20: {}'
        print(time.strftime('%Y-%m-%d %H:%M:%S ', time.localtime(time.time())) +
              template.format(epoch + 1, train_loss.result(), train_accuracy.result() * 100, test_loss.result(),
                              test_accuracy.result() * 100))
    tf.saved_model.save(model, opt.model_path)
```

**Error Messgae**
```
Traceback (most recent call last):
  File ""ttt.py"", line 257, in <module>
    tf.saved_model.save(model, opt.model_path)
  File ""/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py"", line 951, in save
    obj, export_dir, signatures, options, meta_graph_def)
  File ""/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py"", line 1008, in _build_meta_graph
    checkpoint_graph_view)
  File ""/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/saved_model/signature_serialization.py"", line 75, in find_function_to_export
    functions = saveable_view.list_functions(saveable_view.root)
  File ""/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py"", line 143, in list_functions
    self._serialization_cache)
  File ""/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py"", line 1656, in _list_functions_for_serialization
    Model, self)._list_functions_for_serialization(serialization_cache)
  File ""/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 2750, in _list_functions_for_serialization
    .list_functions_for_serialization(serialization_cache))
  File ""/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/base_serialization.py"", line 87, in list_functions_for_serialization
    fns = self.functions_to_serialize(serialization_cache)
  File ""/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py"", line 77, in functions_to_serialize
    serialization_cache).functions_to_serialize)
  File ""/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py"", line 92, in _get_serialized_attributes
    serialization_cache)
  File ""/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/model_serialization.py"", line 47, in _get_serialized_attributes_internal
    default_signature = save_impl.default_save_signature(self.obj)
  File ""/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 203, in default_save_signature
    fn.get_concrete_function()
  File ""/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 959, in get_concrete_function
    concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)
  File ""/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 872, in _get_concrete_function_garbage_collected
    *args, **kwargs)
  File ""/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 2496, in _get_concrete_function_garbage_collected
    graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
  File ""/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 2777, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 2667, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py"", line 981, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 441, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/saving/saving_utils.py"", line 132, in _wrapped_model
    outputs = model(inputs, training=False)
  File ""/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 927, in __call__
    outputs = call_fn(cast_inputs, *args, **kwargs)
  File ""/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py"", line 309, in wrapper
    return func(*args, **kwargs)
  File ""ttt.py"", line 73, in call
    initial_state=init_state
  File ""/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py"", line 324, in new_func
    return func(*args, **kwargs)
  File ""/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py"", line 707, in dynamic_rnn
    dtype=dtype)
  File ""/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py"", line 916, in _dynamic_rnn_loop
    swap_memory=swap_memory)
  File ""/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2688, in while_loop
    back_prop=back_prop)
  File ""/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/while_v2.py"", line 196, in while_loop
    add_control_dependencies=add_control_dependencies)
  File ""/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py"", line 981, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/while_v2.py"", line 174, in wrapped_body
    outputs = body(*_pack_sequence_as(orig_loop_vars, args))
  File ""/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py"", line 884, in _time_step
    (output, new_state) = call_cell()
  File ""/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py"", line 870, in <lambda>
    call_cell = lambda: cell(input_t, state)
  File ""/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 897, in __call__
    self._maybe_build(inputs)
  File ""/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 2416, in _maybe_build
    self.build(input_shapes)  # pylint:disable=not-callable
  File ""/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py"", line 316, in wrapper
    output_shape = fn(instance, input_shape)
  File ""/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent.py"", line 1752, in build
    caching_device=default_caching_device)
  File ""/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 577, in add_weight
    caching_device=caching_device)
  File ""/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py"", line 743, in _add_variable_with_custom_getter
    **kwargs_for_getter)
  File ""/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_utils.py"", line 141, in make_variable
    shape=variable_shape if variable_shape else None)
  File ""/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variables.py"", line 259, in __call__
    return cls._variable_v1_call(*args, **kwargs)
  File ""/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variables.py"", line 220, in _variable_v1_call
    shape=shape)
  File ""/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variables.py"", line 66, in getter
    return captured_getter(captured_previous, **kwargs)
  File ""/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 511, in invalid_creator_scope
    ""tf.function-decorated function tried to create ""
ValueError: tf.function-decorated function tried to create variables on non-first call.
```"
40314,cant import tensorflow.contrib.tensorrt,"is there any way to import contrib.tensorrt in tensorflow 2.2.0?
"
40313,Can I inference models with XNNPACK backend through tensorflow lite Python APIs?,"One of my areas is model compression for deployment. Previously, I worked on QNNPACK and its performance was amazing. I knew that the main author of QNNPACK went to Google from FB, and he continues his work based on QNNPACK. A new library named XNNPACK was created. I am very excited to see the Sparse ConvNets feature of XNNPACK. XNNPACK suggests the TensorFlow lite in its readme. However, I did not find a specific doc or APIs for this feature. **So, can you provide some examples of the usage of XNNAPCK?**

**Specifically, I want to inference the models with XNNPACK backend on CPU no matter what platform I am. Like QNNPACK, I can do some experiments on x86, while I can run on Arm (such as NVIDIA Xavier, TX2, etc) when I want to deploy models.**

**For your reference**, you may learn something from PyTorch quantization feature, by which I can use same APIs to invoke QNNPACK backend on different platforms (x86 or Arm). "
40312,Using a FCN in a for loop,"Hello,
I have a question, if I want to create a Fully Connected Network and I would like to place it in a for loop, I want to tell Tensorflow that the weights of my FCN are shared between all iterations of this for loop, and prevent the creation of ""N"" instances of different FCNs.
What should I do in this case?"
40311,How to use BlockLSTM and BlockLSTMGrad to build a LSTM network in C++?,"Anyone have idea on how to use BlockLSTM and BlockLSTMGrad to build a LSTM network in C++? It take me quit a long on this problem, please give me a simple example, many thanks!"
40310,"Tried to export a function which references untracked object Tensor(""5486:0"", shape=(), dtype=resource).TensorFlow objects (e.g. tf.Variable) captured by functions must be tracked by assigning them to an attribute of a tracked object or assigned to an attribute of the main object directly.","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):MacOS 10.15.5
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):pip 
- TensorFlow version (use command below):2.2
- Python version:3.5/3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

1.  When I want to export saved model, I have met this crash ""Tried to export a function which references untracked object Tensor(""5486:0"", shape=(), dtype=resource).TensorFlow objects (e.g. tf.Variable) captured by functions must be tracked by assigning them to an attribute of a tracked object or assigned to an attribute of the main object directly.""

2. When I want to predict model manually, the log logs some warning :""
WARNING: Logging before flag parsing goes to stderr.
W0609 15:31:30.150616 140734750367168 util.py:144] Unresolved object in checkpoint: (root).optimizer.iter
W0609 15:31:30.150791 140734750367168 util.py:144] Unresolved object in checkpoint: (root).optimizer.beta_1
W0609 15:31:30.150847 140734750367168 util.py:144] Unresolved object in checkpoint: (root).optimizer.beta_2
W0609 15:31:30.150895 140734750367168 util.py:144] Unresolved object in checkpoint: (root).optimizer.decay
W0609 15:31:30.150939 140734750367168 util.py:144] Unresolved object in checkpoint: (root).optimizer.learning_rate
W0609 15:31:30.150986 140734750367168 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).embedding_layer.embeddings
W0609 15:31:30.151030 140734750367168 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).dense_layer.kernel
W0609 15:31:30.151072 140734750367168 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).dense_layer.bias
W0609 15:31:30.151117 140734750367168 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).bidirectional_layer.forward_layer.cell.kernel
W0609 15:31:30.151160 140734750367168 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).bidirectional_layer.forward_layer.cell.recurrent_kernel
W0609 15:31:30.151202 140734750367168 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).bidirectional_layer.forward_layer.cell.bias
W0609 15:31:30.151246 140734750367168 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).bidirectional_layer.backward_layer.cell.kernel
W0609 15:31:30.151288 140734750367168 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).bidirectional_layer.backward_layer.cell.recurrent_kernel
W0609 15:31:30.151330 140734750367168 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).bidirectional_layer.backward_layer.cell.bias
W0609 15:31:30.151374 140734750367168 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).embedding_layer.embeddings
W0609 15:31:30.151417 140734750367168 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).dense_layer.kernel
W0609 15:31:30.151458 140734750367168 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).dense_layer.bias
W0609 15:31:30.151500 140734750367168 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).bidirectional_layer.forward_layer.cell.kernel
W0609 15:31:30.151542 140734750367168 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).bidirectional_layer.forward_layer.cell.recurrent_kernel
W0609 15:31:30.151585 140734750367168 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).bidirectional_layer.forward_layer.cell.bias
W0609 15:31:30.151627 140734750367168 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).bidirectional_layer.backward_layer.cell.kernel
W0609 15:31:30.151669 140734750367168 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).bidirectional_layer.backward_layer.cell.recurrent_kernel
W0609 15:31:30.151710 140734750367168 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).bidirectional_layer.backward_layer.cell.bias
W0609 15:31:30.151752 140734750367168 util.py:152] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.
""
I don't know what's wrong on my customed model.
**Describe the expected behavior**
I want to predict from model and export saved model

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
Code can be download from baidu net drive by
link: https://pan.baidu.com/s/1ftizcVQsMXuAR91-X0Md4A 
key: 6rns
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40309,"how do you get the string out of  Tensor(""args_0:0"", shape=(), dtype=string) type?:","I tried to get the string out of 
type  tensor(""args_0:0"", shape=(), dtype=string). 

The reason I tried to do is that I want to get the original image size 

```

 dataset = tf.data.Dataset.from_tensor_slices((images,boxes,labels))
    run_train(dataset.map(resize_image_bbox, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(1).prefetch(tf.data.experimental.AUTOTUNE))

```

this images is the list of image_path 
then I passed it to the 


```
def resize_image_bbox(image,boxes,labels):

    print('image->',image)
    img = tf.io.read_file(image)
    img = tf.image.decode_jpeg(img, channels=3)
    img = tf.cast(img, tf.float32)
    newSize = (300, 300)

    new_img = tf.image.resize(img,newSize)
    return new_img,boxes,labels
```
I also need to resize my boxes with original image size
but I have no idea to get the original image size from it 

so I tried to read it from  the path then get the original image size 

If you have better idea let me know
=============================================================
<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 19.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source 
- TensorFlow version (use command below): 2.0 
- Python version: 2.0 
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1
- GPU model and memory: titan xp 

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.


"
40308,"TypeError: Expected int64, got 1e-07 of type 'float' instead : FasterRCNN tensorflow 2.x","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linus Ubuntu 18.04.4
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip install tensorflow==2.1.0
- TensorFlow version (use command below): 2.1.0
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory: GTX1650

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
Parsing annotation files
Training images per class:
{'Platelets': 234, 'RBC': 2606, 'WBC': 231, 'bg': 0}
Num classes (including bg) = 4
Config has been written to config.pickle, and can be loaded when testing to ensure correct results
Num train samples 193
Num val samples 31
loading weights from pretrain/vgg16_weights_tf_dim_ordering_tf_kernels.h5
Could not load pretrained model weights. Weights can be found in the keras application folder           https://github.com/fchollet/keras/tree/master/keras/applications
no previous model was loaded
Starting training
Epoch 1/50
Exception: in converted code:

/home/reighns/ObjectDetection/blood_cells_detection/keras-frcnn-ken/fasterrcnn/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_eager.py:305 train_on_batch  *
    outs, total_loss, output_losses, masks = (
/home/reighns/ObjectDetection/blood_cells_detection/keras-frcnn-ken/fasterrcnn/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_eager.py:253 _process_single_batch
    training=training))
/home/reighns/ObjectDetection/blood_cells_detection/keras-frcnn-ken/fasterrcnn/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_eager.py:167 _model_loss
    per_sample_losses = loss_fn.call(targets[i], outs[i])
/home/reighns/ObjectDetection/blood_cells_detection/keras-frcnn-ken/fasterrcnn/lib/python3.6/site-packages/tensorflow_core/python/keras/losses.py:221 call
    return self.fn(y_true, y_pred, **self._fn_kwargs)
/home/reighns/ObjectDetection/blood_cells_detection/keras-frcnn-ken/keras_frcnn/losses.py:42 rpn_loss_cls_fixed_num
    return lambda_rpn_class * K.sum(y_true[:, :, :, :num_anchors] * tf.keras.losses.binary_crossentropy(y_pred[:, :, :, :], y_true[:, :, :, num_anchors:])) / K.sum(epsilon + y_true[:, :, :, :num_anchors])
/home/reighns/ObjectDetection/blood_cells_detection/keras-frcnn-ken/fasterrcnn/lib/python3.6/site-packages/tensorflow_core/python/keras/losses.py:994 binary_crossentropy
    K.binary_crossentropy(y_true, y_pred, from_logits=from_logits), axis=-1)
/home/reighns/ObjectDetection/blood_cells_detection/keras-frcnn-ken/fasterrcnn/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py:4602 binary_crossentropy
    epsilon_ = _constant_to_tensor(epsilon(), output.dtype.base_dtype)
/home/reighns/ObjectDetection/blood_cells_detection/keras-frcnn-ken/fasterrcnn/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py:678 _constant_to_tensor
    return constant_op.constant(x, dtype=dtype)
/home/reighns/ObjectDetection/blood_cells_detection/keras-frcnn-ken/fasterrcnn/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py:258 constant
    allow_broadcast=True)
/home/reighns/ObjectDetection/blood_cells_detection/keras-frcnn-ken/fasterrcnn/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py:297 _constant_impl
    allow_broadcast=allow_broadcast))
/home/reighns/ObjectDetection/blood_cells_detection/keras-frcnn-ken/fasterrcnn/lib/python3.6/site-packages/tensorflow_core/python/framework/tensor_util.py:452 make_tensor_proto
    _AssertCompatible(values, dtype)
/home/reighns/ObjectDetection/blood_cells_detection/keras-frcnn-ken/fasterrcnn/lib/python3.6/site-packages/tensorflow_core/python/framework/tensor_util.py:332 _AssertCompatible
    (dtype.name, repr(mismatch), type(mismatch).__name__))

TypeError: Expected int64, got 1e-07 of type 'float' instead.

**Describe the expected behavior**
Expected to train a faster rcnn model using https://github.com/kentaroy47/frcnn-from-scratch-with-keras repo; I want to use the code in tf2.x version but encounter this error. The error might be related to the loss function py file.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40307,ImportError: DLL load failed: The specified module could not be found.,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 10 home
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip install tensorflow
- TensorFlow version: 2.2.0
- Python version: 3.6
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**
while doing import tensorflow as tf, I'm getting error


**Any other info / logs**
---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
A:\anaconda\lib\site-packages\tensorflow\python\pywrap_tensorflow.py in <module>
     57 
---> 58   from tensorflow.python.pywrap_tensorflow_internal import *
     59 

A:\anaconda\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py in <module>
     27             return _mod
---> 28     _pywrap_tensorflow_internal = swig_import_helper()
     29     del swig_import_helper

A:\anaconda\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py in swig_import_helper()
     23             try:
---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
     25             finally:

A:\anaconda\lib\imp.py in load_module(name, file, filename, details)
    241         else:
--> 242             return load_dynamic(name, filename, file)
    243     elif type_ == PKG_DIRECTORY:

A:\anaconda\lib\imp.py in load_dynamic(name, path, file)
    341             name=name, loader=loader, origin=path)
--> 342         return _load(spec)
    343 

ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

ImportError                               Traceback (most recent call last)
<ipython-input-1-64156d691fe5> in <module>
----> 1 import tensorflow as tf

A:\anaconda\lib\site-packages\tensorflow\__init__.py in <module>
     39 import sys as _sys
     40 
---> 41 from tensorflow.python.tools import module_util as _module_util
     42 from tensorflow.python.util.lazy_loader import LazyLoader as _LazyLoader
     43 

A:\anaconda\lib\site-packages\tensorflow\python\__init__.py in <module>
     48 import numpy as np
     49 
---> 50 from tensorflow.python import pywrap_tensorflow
     51 
     52 # Protocol buffers

A:\anaconda\lib\site-packages\tensorflow\python\pywrap_tensorflow.py in <module>
     67 for some common reasons and solutions.  Include the entire stack trace
     68 above this error message when asking for help."""""" % traceback.format_exc()
---> 69   raise ImportError(msg)
     70 
     71 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long

ImportError: Traceback (most recent call last):
  File ""A:\anaconda\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""A:\anaconda\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""A:\anaconda\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""A:\anaconda\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""A:\anaconda\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

"
40306,None Type not Supported,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): 
- TensorFlow version (or github SHA if from source): 1.14


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
# Copy and paste here the exact command
```

**The output from the converter invocation**

```
# Copy and paste the output here.
```

**Also, please include a link to the saved model or GraphDef**

```
# Put link here or attach to the issue.
```

**Failure details**
If the conversion is successful, but the generated model is wrong,
state what is wrong:
- Producing wrong results and/or decrease in accuracy
- Producing correct results, but the model is slower than expected (model generated from old converter)


**RNN conversion support**
If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.

**Any other info / logs*

Hi, when I trying to convert a .pb file to a .tflite model, my input tensor is of shape [None, None,None,4] . I am getting the None Type not supported error. 
How ever if I replace it with integer values like, [200,200,200,4] it works. 
How should I include the None Type support while convert .pb file to a .tflite file? "
40302,File system scheme 's3' not implemented,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: 3.6.5
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: NA
- GPU model and memory: NA

**Describe the current behavior**
tensorflow.python.framework.errors_impl.UnimplementedError: File system scheme 's3' not implemented

**Describe the expected behavior**
Should be able to connect the s3 filesystem.

**Standalone code to reproduce the issue**
from tensorflow.python.lib.io import file_io
print file_io.stat('s3://bucketname/path/')

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40301,AutoGraph could not transform,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.1.0
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1
- GPU model and memory: 2080TI 11gb

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
The following warning is printed
```
WARNING:tensorflow:AutoGraph could not transform <function parse_dataset.<locals>._parse at 0x7f3d8c126cb0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: Bad argument number for Name: 3, expecting 4
```
**Describe the expected behavior**
No warning

**Standalone code to reproduce the issue**

```
import tensorflow as tf


def bytes_feature(value):
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))


def float_tensor_to_bytes_feature(value):
    return bytes_feature(tf.io.serialize_tensor(tf.convert_to_tensor(value, dtype=tf.float32)).numpy())


def parse_dataset(dataset, feature_description, n_parallel_calls=None):
    def _parse(example_proto):
        deserialized_dict = tf.io.parse_single_example(example_proto, feature_description)
        return deserialized_dict

    parsed_dataset = dataset.map(_parse, num_parallel_calls=n_parallel_calls)
    return parsed_dataset


v = [1, 2, 3]

features = {
    'x': float_tensor_to_bytes_feature(v)
}

example_proto = tf.train.Example(features=tf.train.Features(feature=features))
example = example_proto.SerializeToString()
serialized_tensors = [example]

dataset = tf.data.Dataset.from_tensor_slices(serialized_tensors)

features_description = {
    'x': tf.io.FixedLenFeature([], tf.string),
}
parsed_dataset = parse_dataset(dataset, features_description)

print(next(iter(parsed_dataset)))

```"
40298,Decoding output of object detection mobile_ssd_v2_float_coco.tflite ,"The official documentation suggests mobile_ssd_v2_float_coco.tflite model for enabling GPU delegate, but after analyzing the Model with Netron, ( visualization tool to help identify how the output tensors differ.)
mobile_ssd_v2_float_coco.tflite
OUTPUT:
raw_outputs/box_encodings
id: raw_outputs/box_encodings
type: float32[1,2034,4]
raw_outputs/class_predictions
id: raw_outputs/class_predictions
type: float32[1,2034,91]

Whereas the default model detect.tflite used in the demo has 4 different parameters.
OUTPUT:
TFLite_Detection_PostProcess
id: TFLite_Detection_PostProcess
type: float32
TFLite_Detection_PostProcess:1
id: TFLite_Detection_PostProcess:1
type: float32
TFLite_Detection_PostProcess:2
id: TFLite_Detection_PostProcess:2
type: float32
TFLite_Detection_PostProcess:3
id: TFLite_Detection_PostProcess:3
type: float32
ie for Location, Classes, Scores, Number and detections

How can we use mobile_ssd_v2_float_coco.tfliteor any model to get enable GPU with Object Detection, Please suggest?"
40297,"Mask-RCNN conversion succeeds, but requires select-tf-ops despite selecting only TFLITE_BUILTINS","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux Ubuntu 18.04
- TensorFlow installed from (source or binary):
tensorflow:2.2.0-gpu-jupyter docker image, so... binary?
- TensorFlow version (or github SHA if from source):
2.2.0

**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
converter = lite.TFLiteConverter.from_keras_model(model.keras_model)
converter.target_spec.supported_ops = [lite.OpsSet.TFLITE_BUILTINS]
converter.experimental_new_converter = True
converter.allow_custom_ops = False
converter.representative_dataset = [(np.random.random((256,256,3))*255).astype(np.uint8)]
tflite_model = converter.convert()
open(""converted_model.tflite"", ""wb"").write(tflite_model)
```

**The output from the converter invocation**

```
256614676
```

**Also, please include a link to the saved model or GraphDef**

```
What is a good way to provide this?
Original model parameters from matterport repo here: https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5
```

**Failure details**
If the conversion is successful, but the generated model is wrong,
state what is wrong:
The produced tflite model works on my android device, but it requires the tf-select-ops library, and fails to accept the provided GpuDelegate.

**RNN conversion support**
If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
40295,"not tensorflow-GPU ""ImportError: DLL load failed: The specified module could not be found."" inside Conda / Win10","**System information**
- OS Platform and Distribution: Windows 10
- Mobile device : none
- TensorFlow installed from (source or binary): pip install tensorflow from conda terminal
- TensorFlow version: not known
- Python version: 3.7.6
- Installed using : pip install tensorflow from conda terminal
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

*not using tensorflow-gpu* 
executing:
import tensorflow

I get the following error:

Traceback (most recent call last):
  File ""D:\Programs\Anaconda3\envs\MLKeras\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""D:\Programs\Anaconda3\envs\MLKeras\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""D:\Programs\Anaconda3\envs\MLKeras\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""D:\Programs\Anaconda3\envs\MLKeras\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""D:\Programs\Anaconda3\envs\MLKeras\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""deep_versions.py"", line 5, in <module>
    import tensorflow
  File ""D:\Programs\Anaconda3\envs\MLKeras\lib\site-packages\tensorflow\__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""D:\Programs\Anaconda3\envs\MLKeras\lib\site-packages\tensorflow\python\__init__.py"", line 50, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""D:\Programs\Anaconda3\envs\MLKeras\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 69, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""D:\Programs\Anaconda3\envs\MLKeras\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""D:\Programs\Anaconda3\envs\MLKeras\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""D:\Programs\Anaconda3\envs\MLKeras\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""D:\Programs\Anaconda3\envs\MLKeras\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""D:\Programs\Anaconda3\envs\MLKeras\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help."
40288," metaclass conflict, ops.py, tensorflow.backend.py","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

Hello people, firstly...im new the last beginner and maybe the mess is big so...
Some days ago i trained YOLOv3 (TrainYourOwnYOLO) everything was fine, however, when i've tried to test the algorithm the things went wrong. Issue after issue. i was looking in forums and after one issue came another one.  The last change was here:

ops.py
core_tf_types.Tensor = tuple()
# Deprecated - do not use.
# This API to avoid breaking estimator and tensorflow-mesh which depend on this
# internal API. The stub should be safe to use after TF 2.3 is released.
def is_dense_tensor_like(t):
  return isinstance(t, core_tf_types.Tensor)

tensorflow_backend.py
from tensorflow.python.types import core as core_tf_types 

def is_tensor(x):
    return isinstance(x, tf_ops.core_tf_types) or tf_ops.is_dense_tensor_like(x)

When i try to run the detector -> Detector.py
Error is:
TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases

Could give me an advice what to do?!?!"
40287,Floating point exception occurred in tf.nn.fractional_max_pool,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04.3 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: 3.6.9
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
Floating point exception (arithmetic exception) occurs in c++ while executing `tf.nn.fractional_max_pool` when passing the first element of `pooling_ratio` > 2.0`. 

**Describe the expected behavior**
According to the document (https://www.tensorflow.org/api_docs/python/tf/nn/fractional_max_pool), the first and the last elements of `pooling_ratio` must be 1.0. However, in some cases,  even though these elements are not 1.0 no exception occurs.  I think the way `fractional_max_pool` handles invalid inputs should be consistent at least. 

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```python
import tensorflow as tf

tensor_4D = [[[[0, 1, 1], 
                      [2, 3, 3],
                      [1, 3, 2]],
                     [[1, 3, 2],
                      [2, 4, 2],
                      [0, 1, 1]]],
                      [[[0, 3, 1], 
                      [2, 4, 1],
                      [1, 3, 2]],
                     [[1, 1, 1],
                      [2, 3, 4],
                      [1, 3, 2]]],
                     [[[2, 2, 4], 
                      [2, 1, 3],
                      [0, 4, 2]],
                     [[2, 4, 1],
                      [2, 3, 0],
                      [1, 3, 3]]]]
pooling_ratio = [2.1]

tf.nn.fractional_max_pool(tensor_4D, pooling_ratio)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40286,List tf.function methods in tf.Module,"Hi all!

I use the dir(cls) build-in method to list member of a tf.Module but tf.function methods do not appear there. Is there a method that allow listing of tf.function in tf.Module?

Thanks
"
40285,Support for .next() on tf.data.Dataset,"**System information**
- TensorFlow version (you are using): 2.1.0
- Are you willing to contribute it (Yes/No): **Yes** (If approved)



**Describe the feature and the current behavior/state.**
Currently when working with https://www.tensorflow.org/api_docs/python/tf/data/Dataset
You can iterate a Dataset with a loop e.g. 
```python
for x,y in train:
   tf.print(x,y)
```

However if you want to get a single batch, the only option would be:

```python
train.__iter__().next()
```

Currently there is only support for creating a numpy iterator, Example
```python
train.as_numpy_iterator().next()
```
**and the output is not a tf object.** 

The closest to the expected behavior of `.next()` would be `train.take(1)` which still needs to be converted to an iterator. 

The current methods of getting a single batch are tedious and create bug prone code, multiple lines, and/or functions called. 

**Will this change the current api? How?**

It will create a .next() function for tf.data.Dataset e.g. 

https://www.tensorflow.org/api_docs/python/tf/data/Dataset#next

**Who will benefit with this feature?**
Hopefully the entire community 

**Any Other info.**

The feature could be implemented by using an existing iterator for the dataset object and when calling .next() simply picking an element from that iterator rather than creating an iterator every time for performance benefits. 
"
40283,Annoying Documentation for Tensorflow 2.2.0,"I saw the implementations of tf.reduce_mean, tf.reduce_sum but its not there in the documentation for tf 2.2.0. It is really annoying as it created a giant confusion in our code. Please keep documentation and implmentation in sync. "
40280,simple tf.vectorized_map raises error UnrecognizedFlagError: Unknown command line flag 'f',"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab
- TensorFlow installed from (source or binary): Default Colab
- TensorFlow version (use command below): 2.2.0
- Python version: 3.6.9
- CUDA/cuDNN version: N/A tested on CPU
- GPU model and memory: N/A tested on CPU

**Describe the current behavior**

```py
import tensorflow as tf

print(tf.vectorized_map(
    lambda seq: tf.reduce_min(tf.where(seq)),
    tf.constant([[False, True],
                 [True, False]])
))
```

Outputs the following error:

```
UnrecognizedFlagError: Unknown command line flag 'f'
```

I've seen this error quite often when using `tf.vectorized_map`, in very different settings. However, this is the simplest cast I've found so far. So I suspect the error is not limited to `tf.where()`.

**Describe the expected behavior**

I would expect the output to be:
```
tf.constant([1, 0], dtype=tf.dtypes.bool)
```

**Standalone code to reproduce the issue**

https://colab.research.google.com/gist/AndreasMadsen/9ee1fa1669aa7c656070ca5a850d7210/vectorized-map-bug.ipynb

**Other info / logs**

```
StagingError: in user code:

    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py:183 f  *
        return _pfor_impl(loop_fn, iters, parallel_iterations=parallel_iterations)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py:269 _pfor_impl  **
        outputs.append(converter.convert(loop_fn_output))
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/parallel_for/pfor.py:1284 convert
        output = self._convert_helper(y)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/parallel_for/pfor.py:1457 _convert_helper
        if flags.FLAGS.op_conversion_fallback_to_while_loop:
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/flags.py:85 __getattr__
        wrapped(_sys.argv)
    /usr/local/lib/python3.6/dist-packages/absl/flags/_flagvalues.py:633 __call__
        name, value, suggestions=suggestions)

    UnrecognizedFlagError: Unknown command line flag 'f'
```"
40278,Documentation instructions on installing tensorflow with CUDA support doesn't work,"OS: Ubuntu 18.04
Graphics card: Nvidia 1050Ti

**Problem**
Following the instructions under https://www.tensorflow.org/install/gpu#install_cuda_with_apt gives the following error: 

```ssh
...

Unpacking libcudnn7-dev (7.6.4.38-1+cuda10.1) ...
Errors were encountered while processing:
 /tmp/apt-dpkg-install-fjAi3S/55-libnvidia-compute-450_450.36.06-0ubuntu1_amd64.deb
E: Sub-process /usr/bin/dpkg returned an error code (1)
```
after executing this step
```ssh
sudo apt-get install --no-install-recommends \
>     cuda-10-1 \
>     libcudnn7=7.6.4.38-1+cuda10.1  \
>     libcudnn7-dev=7.6.4.38-1+cuda10.1
```

**Additional Info**
The complete message after running the above command is

```ssh
Reading package lists... Done
Building dependency tree       
Reading state information... Done
The following packages were automatically installed and are no longer required:
  libnvidia-common-440 libnvidia-extra-440
Use 'sudo apt autoremove' to remove them.
The following additional packages will be installed:
  cuda-command-line-tools-10-1 cuda-compiler-10-1 cuda-cudart-10-1
  cuda-cudart-dev-10-1 cuda-cufft-10-1 cuda-cufft-dev-10-1 cuda-cuobjdump-10-1
  cuda-cupti-10-1 cuda-curand-10-1 cuda-curand-dev-10-1 cuda-cusolver-10-1
  cuda-cusolver-dev-10-1 cuda-cusparse-10-1 cuda-cusparse-dev-10-1
  cuda-demo-suite-10-1 cuda-documentation-10-1 cuda-driver-dev-10-1
  cuda-drivers cuda-drivers-450 cuda-gdb-10-1 cuda-gpu-library-advisor-10-1
  cuda-libraries-10-1 cuda-libraries-dev-10-1 cuda-license-10-1
  cuda-license-10-2 cuda-memcheck-10-1 cuda-misc-headers-10-1 cuda-npp-10-1
  cuda-npp-dev-10-1 cuda-nsight-10-1 cuda-nsight-compute-10-1
  cuda-nsight-systems-10-1 cuda-nvcc-10-1 cuda-nvdisasm-10-1 cuda-nvgraph-10-1
  cuda-nvgraph-dev-10-1 cuda-nvjpeg-10-1 cuda-nvjpeg-dev-10-1
  cuda-nvml-dev-10-1 cuda-nvprof-10-1 cuda-nvprune-10-1 cuda-nvrtc-10-1
  cuda-nvrtc-dev-10-1 cuda-nvtx-10-1 cuda-nvvp-10-1 cuda-runtime-10-1
  cuda-samples-10-1 cuda-sanitizer-api-10-1 cuda-toolkit-10-1 cuda-tools-10-1
  cuda-visual-tools-10-1 default-jre default-jre-headless libcublas-dev
  libcublas10 libnvidia-cfg1-450 libnvidia-common-450 libnvidia-compute-450
  libnvidia-decode-450 libnvidia-encode-450 libnvidia-fbc1-450
  libnvidia-gl-450 libnvidia-ifr1-450 nsight-compute-2019.5.0
  nsight-systems-2019.5.2 nvidia-compute-utils-450 nvidia-dkms-450
  nvidia-driver-450 nvidia-kernel-common-450 nvidia-kernel-source-450
  nvidia-modprobe nvidia-settings nvidia-utils-450 openjdk-11-jre
  openjdk-11-jre-headless xserver-xorg-video-nvidia-450
Suggested packages:
  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei
  | fonts-wqy-zenhei
The following packages will be REMOVED:
  libnvidia-cfg1-440 libnvidia-compute-440 libnvidia-decode-440
  libnvidia-encode-440 libnvidia-fbc1-440 libnvidia-fbc1-440:i386
  libnvidia-gl-440 libnvidia-ifr1-440 nvidia-compute-utils-440 nvidia-dkms-440
  nvidia-driver-430 nvidia-driver-440 nvidia-kernel-common-440
  nvidia-kernel-source-440 nvidia-utils-440 xserver-xorg-video-nvidia-440
The following NEW packages will be installed:
  cuda-10-1 cuda-command-line-tools-10-1 cuda-compiler-10-1 cuda-cudart-10-1
  cuda-cudart-dev-10-1 cuda-cufft-10-1 cuda-cufft-dev-10-1 cuda-cuobjdump-10-1
  cuda-cupti-10-1 cuda-curand-10-1 cuda-curand-dev-10-1 cuda-cusolver-10-1
  cuda-cusolver-dev-10-1 cuda-cusparse-10-1 cuda-cusparse-dev-10-1
  cuda-demo-suite-10-1 cuda-documentation-10-1 cuda-driver-dev-10-1
  cuda-drivers cuda-drivers-450 cuda-gdb-10-1 cuda-gpu-library-advisor-10-1
  cuda-libraries-10-1 cuda-libraries-dev-10-1 cuda-license-10-1
  cuda-license-10-2 cuda-memcheck-10-1 cuda-misc-headers-10-1 cuda-npp-10-1
  cuda-npp-dev-10-1 cuda-nsight-10-1 cuda-nsight-compute-10-1
  cuda-nsight-systems-10-1 cuda-nvcc-10-1 cuda-nvdisasm-10-1 cuda-nvgraph-10-1
  cuda-nvgraph-dev-10-1 cuda-nvjpeg-10-1 cuda-nvjpeg-dev-10-1
  cuda-nvml-dev-10-1 cuda-nvprof-10-1 cuda-nvprune-10-1 cuda-nvrtc-10-1
  cuda-nvrtc-dev-10-1 cuda-nvtx-10-1 cuda-nvvp-10-1 cuda-runtime-10-1
  cuda-samples-10-1 cuda-sanitizer-api-10-1 cuda-toolkit-10-1 cuda-tools-10-1
  cuda-visual-tools-10-1 default-jre default-jre-headless libcublas-dev
  libcublas10 libcudnn7 libcudnn7-dev libnvidia-cfg1-450 libnvidia-common-450
  libnvidia-compute-450 libnvidia-decode-450 libnvidia-encode-450
  libnvidia-fbc1-450 libnvidia-gl-450 libnvidia-ifr1-450
  nsight-compute-2019.5.0 nsight-systems-2019.5.2 nvidia-compute-utils-450
  nvidia-dkms-450 nvidia-driver-450 nvidia-kernel-common-450
  nvidia-kernel-source-450 nvidia-modprobe nvidia-settings nvidia-utils-450
  openjdk-11-jre openjdk-11-jre-headless xserver-xorg-video-nvidia-450
0 upgraded, 79 newly installed, 16 to remove and 239 not upgraded.
Need to get 0 B/2,205 MB of archives.
After this operation, 4,855 MB of additional disk space will be used.
Do you want to continue? [Y/n] 
Extracting templates from packages: 100%
(Reading database ... 294935 files and directories currently installed.)
Removing nvidia-driver-430 (440.59-0ubuntu0.18.04.1) ...
Removing nvidia-driver-440 (440.82-0ubuntu0~0.18.04.2) ...
Removing xserver-xorg-video-nvidia-440 (440.82-0ubuntu0~0.18.04.2) ...
Removing libnvidia-cfg1-440:amd64 (440.82-0ubuntu0~0.18.04.2) ...
Removing libnvidia-encode-440:amd64 (440.82-0ubuntu0~0.18.04.2) ...
Removing libnvidia-decode-440:amd64 (440.82-0ubuntu0~0.18.04.2) ...
Removing nvidia-utils-440 (440.82-0ubuntu0~0.18.04.2) ...
Removing libnvidia-fbc1-440:i386 (440.82-0ubuntu0~0.18.04.2) ...
Removing libnvidia-fbc1-440:amd64 (440.82-0ubuntu0~0.18.04.2) ...
Removing libnvidia-ifr1-440:amd64 (440.82-0ubuntu0~0.18.04.2) ...
Removing libnvidia-gl-440:amd64 (440.82-0ubuntu0~0.18.04.2) ...
Removing nvidia-compute-utils-440 (440.82-0ubuntu0~0.18.04.2) ...
Removing nvidia-dkms-440 (440.82-0ubuntu0~0.18.04.2) ...
Removing all DKMS Modules
Done.
INFO:Disable nvidia
DEBUG:Parsing /usr/share/ubuntu-drivers-common/quirks/dell_latitude
DEBUG:Parsing /usr/share/ubuntu-drivers-common/quirks/put_your_quirks_here
DEBUG:Parsing /usr/share/ubuntu-drivers-common/quirks/lenovo_thinkpad
update-initramfs: deferring update (trigger activated)
Removing nvidia-kernel-common-440 (440.82-0ubuntu0~0.18.04.2) ...
update-initramfs: deferring update (trigger activated)
Removing nvidia-kernel-source-440 (440.82-0ubuntu0~0.18.04.2) ...
Removing libnvidia-compute-440:amd64 (440.82-0ubuntu0~0.18.04.2) ...
Selecting previously unselected package cuda-license-10-1.
(Reading database ... 294368 files and directories currently installed.)
Preparing to unpack .../00-cuda-license-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-license-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-misc-headers-10-1.
Preparing to unpack .../01-cuda-misc-headers-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-misc-headers-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-nvcc-10-1.
Preparing to unpack .../02-cuda-nvcc-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-nvcc-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-cuobjdump-10-1.
Preparing to unpack .../03-cuda-cuobjdump-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-cuobjdump-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-nvprune-10-1.
Preparing to unpack .../04-cuda-nvprune-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-nvprune-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-compiler-10-1.
Preparing to unpack .../05-cuda-compiler-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-compiler-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-nvdisasm-10-1.
Preparing to unpack .../06-cuda-nvdisasm-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-nvdisasm-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-gdb-10-1.
Preparing to unpack .../07-cuda-gdb-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-gdb-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-nvprof-10-1.
Preparing to unpack .../08-cuda-nvprof-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-nvprof-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-sanitizer-api-10-1.
Preparing to unpack .../09-cuda-sanitizer-api-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-sanitizer-api-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-memcheck-10-1.
Preparing to unpack .../10-cuda-memcheck-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-memcheck-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-cudart-10-1.
Preparing to unpack .../11-cuda-cudart-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-cudart-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-driver-dev-10-1.
Preparing to unpack .../12-cuda-driver-dev-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-driver-dev-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-cudart-dev-10-1.
Preparing to unpack .../13-cuda-cudart-dev-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-cudart-dev-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-cupti-10-1.
Preparing to unpack .../14-cuda-cupti-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-cupti-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-gpu-library-advisor-10-1.
Preparing to unpack .../15-cuda-gpu-library-advisor-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-gpu-library-advisor-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-nvtx-10-1.
Preparing to unpack .../16-cuda-nvtx-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-nvtx-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-command-line-tools-10-1.
Preparing to unpack .../17-cuda-command-line-tools-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-command-line-tools-10-1 (10.1.243-1) ...
Selecting previously unselected package openjdk-11-jre-headless:amd64.
Preparing to unpack .../18-openjdk-11-jre-headless_11.0.7+10-2ubuntu2~18.04_amd64.deb ...
Unpacking openjdk-11-jre-headless:amd64 (11.0.7+10-2ubuntu2~18.04) ...
Selecting previously unselected package default-jre-headless.
Preparing to unpack .../19-default-jre-headless_2%3a1.11-68ubuntu1~18.04.1_amd64.deb ...
Unpacking default-jre-headless (2:1.11-68ubuntu1~18.04.1) ...
Selecting previously unselected package openjdk-11-jre:amd64.
Preparing to unpack .../20-openjdk-11-jre_11.0.7+10-2ubuntu2~18.04_amd64.deb ...
Unpacking openjdk-11-jre:amd64 (11.0.7+10-2ubuntu2~18.04) ...
Selecting previously unselected package default-jre.
Preparing to unpack .../21-default-jre_2%3a1.11-68ubuntu1~18.04.1_amd64.deb ...
Unpacking default-jre (2:1.11-68ubuntu1~18.04.1) ...
Selecting previously unselected package cuda-nsight-10-1.
Preparing to unpack .../22-cuda-nsight-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-nsight-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-nvvp-10-1.
Preparing to unpack .../23-cuda-nvvp-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-nvvp-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-nvrtc-10-1.
Preparing to unpack .../24-cuda-nvrtc-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-nvrtc-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-nvrtc-dev-10-1.
Preparing to unpack .../25-cuda-nvrtc-dev-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-nvrtc-dev-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-cusolver-10-1.
Preparing to unpack .../26-cuda-cusolver-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-cusolver-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-cusolver-dev-10-1.
Preparing to unpack .../27-cuda-cusolver-dev-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-cusolver-dev-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-license-10-2.
Preparing to unpack .../28-cuda-license-10-2_10.2.89-1_amd64.deb ...
Unpacking cuda-license-10-2 (10.2.89-1) ...
Selecting previously unselected package libcublas10.
Preparing to unpack .../29-libcublas10_10.2.2.89-1_amd64.deb ...
Unpacking libcublas10 (10.2.2.89-1) ...
Selecting previously unselected package libcublas-dev.
Preparing to unpack .../30-libcublas-dev_10.2.2.89-1_amd64.deb ...
Unpacking libcublas-dev (10.2.2.89-1) ...
Selecting previously unselected package cuda-cufft-10-1.
Preparing to unpack .../31-cuda-cufft-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-cufft-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-cufft-dev-10-1.
Preparing to unpack .../32-cuda-cufft-dev-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-cufft-dev-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-curand-10-1.
Preparing to unpack .../33-cuda-curand-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-curand-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-curand-dev-10-1.
Preparing to unpack .../34-cuda-curand-dev-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-curand-dev-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-cusparse-10-1.
Preparing to unpack .../35-cuda-cusparse-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-cusparse-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-cusparse-dev-10-1.
Preparing to unpack .../36-cuda-cusparse-dev-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-cusparse-dev-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-npp-10-1.
Preparing to unpack .../37-cuda-npp-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-npp-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-npp-dev-10-1.
Preparing to unpack .../38-cuda-npp-dev-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-npp-dev-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-nvml-dev-10-1.
Preparing to unpack .../39-cuda-nvml-dev-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-nvml-dev-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-nvjpeg-10-1.
Preparing to unpack .../40-cuda-nvjpeg-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-nvjpeg-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-nvjpeg-dev-10-1.
Preparing to unpack .../41-cuda-nvjpeg-dev-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-nvjpeg-dev-10-1 (10.1.243-1) ...
Selecting previously unselected package nsight-compute-2019.5.0.
Preparing to unpack .../42-nsight-compute-2019.5.0_2019.5.0.14-1_amd64.deb ...
Unpacking nsight-compute-2019.5.0 (2019.5.0.14-1) ...
Selecting previously unselected package cuda-nsight-compute-10-1.
Preparing to unpack .../43-cuda-nsight-compute-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-nsight-compute-10-1 (10.1.243-1) ...
Selecting previously unselected package nsight-systems-2019.5.2.
Preparing to unpack .../44-nsight-systems-2019.5.2_2019.5.2.16-b54ef97_amd64.deb ...
Unpacking nsight-systems-2019.5.2 (2019.5.2.16-b54ef97) ...
Selecting previously unselected package cuda-nsight-systems-10-1.
Preparing to unpack .../45-cuda-nsight-systems-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-nsight-systems-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-nvgraph-10-1.
Preparing to unpack .../46-cuda-nvgraph-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-nvgraph-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-nvgraph-dev-10-1.
Preparing to unpack .../47-cuda-nvgraph-dev-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-nvgraph-dev-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-visual-tools-10-1.
Preparing to unpack .../48-cuda-visual-tools-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-visual-tools-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-tools-10-1.
Preparing to unpack .../49-cuda-tools-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-tools-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-samples-10-1.
Preparing to unpack .../50-cuda-samples-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-samples-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-documentation-10-1.
Preparing to unpack .../51-cuda-documentation-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-documentation-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-libraries-dev-10-1.
Preparing to unpack .../52-cuda-libraries-dev-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-libraries-dev-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-toolkit-10-1.
Preparing to unpack .../53-cuda-toolkit-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-toolkit-10-1 (10.1.243-1) ...
Selecting previously unselected package libnvidia-common-450.
Preparing to unpack .../54-libnvidia-common-450_450.36.06-0ubuntu1_all.deb ...
Checking for existing driver runfile install
/var/lib/dpkg/tmp.ci/preinst: 6: /var/lib/dpkg/tmp.ci/preinst: [[: not found
Unpacking libnvidia-common-450 (450.36.06-0ubuntu1) ...
Preparing to unpack .../55-libnvidia-compute-450_450.36.06-0ubuntu1_amd64.deb ...
Unpacking libnvidia-compute-450:amd64 (450.36.06-0ubuntu1) ...
dpkg: error processing archive /tmp/apt-dpkg-install-fjAi3S/55-libnvidia-compute-450_450.36.06-0ubuntu1_amd64.deb (--unpack):
 trying to overwrite '/usr/lib/x86_64-linux-gnu/libnvidia-allocator.so', which is also in package libnvidia-extra-440:amd64 440.82-0ubuntu0~0.18.04.2
Selecting previously unselected package libnvidia-decode-450:amd64.
Preparing to unpack .../56-libnvidia-decode-450_450.36.06-0ubuntu1_amd64.deb ...
Unpacking libnvidia-decode-450:amd64 (450.36.06-0ubuntu1) ...
Selecting previously unselected package libnvidia-encode-450:amd64.
Preparing to unpack .../57-libnvidia-encode-450_450.36.06-0ubuntu1_amd64.deb ...
Unpacking libnvidia-encode-450:amd64 (450.36.06-0ubuntu1) ...
Selecting previously unselected package libnvidia-fbc1-450:amd64.
Preparing to unpack .../58-libnvidia-fbc1-450_450.36.06-0ubuntu1_amd64.deb ...
Unpacking libnvidia-fbc1-450:amd64 (450.36.06-0ubuntu1) ...
Selecting previously unselected package libnvidia-gl-450:amd64.
Preparing to unpack .../59-libnvidia-gl-450_450.36.06-0ubuntu1_amd64.deb ...
Unpacking libnvidia-gl-450:amd64 (450.36.06-0ubuntu1) ...
Selecting previously unselected package libnvidia-ifr1-450:amd64.
Preparing to unpack .../60-libnvidia-ifr1-450_450.36.06-0ubuntu1_amd64.deb ...
Unpacking libnvidia-ifr1-450:amd64 (450.36.06-0ubuntu1) ...
Selecting previously unselected package nvidia-compute-utils-450.
Preparing to unpack .../61-nvidia-compute-utils-450_450.36.06-0ubuntu1_amd64.deb ...
Unpacking nvidia-compute-utils-450 (450.36.06-0ubuntu1) ...
Selecting previously unselected package nvidia-kernel-source-450.
Preparing to unpack .../62-nvidia-kernel-source-450_450.36.06-0ubuntu1_amd64.deb ...
Unpacking nvidia-kernel-source-450 (450.36.06-0ubuntu1) ...
Selecting previously unselected package nvidia-kernel-common-450.
Preparing to unpack .../63-nvidia-kernel-common-450_450.36.06-0ubuntu1_amd64.deb ...
Unpacking nvidia-kernel-common-450 (450.36.06-0ubuntu1) ...
Selecting previously unselected package nvidia-dkms-450.
Preparing to unpack .../64-nvidia-dkms-450_450.36.06-0ubuntu1_amd64.deb ...
Unpacking nvidia-dkms-450 (450.36.06-0ubuntu1) ...
Selecting previously unselected package nvidia-utils-450.
Preparing to unpack .../65-nvidia-utils-450_450.36.06-0ubuntu1_amd64.deb ...
Unpacking nvidia-utils-450 (450.36.06-0ubuntu1) ...
Selecting previously unselected package libnvidia-cfg1-450:amd64.
Preparing to unpack .../66-libnvidia-cfg1-450_450.36.06-0ubuntu1_amd64.deb ...
Unpacking libnvidia-cfg1-450:amd64 (450.36.06-0ubuntu1) ...
Selecting previously unselected package xserver-xorg-video-nvidia-450.
Preparing to unpack .../67-xserver-xorg-video-nvidia-450_450.36.06-0ubuntu1_amd64.deb ...
Unpacking xserver-xorg-video-nvidia-450 (450.36.06-0ubuntu1) ...
Selecting previously unselected package nvidia-driver-450.
Preparing to unpack .../68-nvidia-driver-450_450.36.06-0ubuntu1_amd64.deb ...
Unpacking nvidia-driver-450 (450.36.06-0ubuntu1) ...
Selecting previously unselected package nvidia-modprobe.
Preparing to unpack .../69-nvidia-modprobe_450.36.06-0ubuntu1_amd64.deb ...
Unpacking nvidia-modprobe (450.36.06-0ubuntu1) ...
Selecting previously unselected package nvidia-settings.
Preparing to unpack .../70-nvidia-settings_450.36.06-0ubuntu1_amd64.deb ...
Unpacking nvidia-settings (450.36.06-0ubuntu1) ...
Selecting previously unselected package cuda-drivers-450.
Preparing to unpack .../71-cuda-drivers-450_450.36.06-1_amd64.deb ...
Unpacking cuda-drivers-450 (450.36.06-1) ...
Selecting previously unselected package cuda-drivers.
Preparing to unpack .../72-cuda-drivers_450.36.06-1_amd64.deb ...
Unpacking cuda-drivers (450.36.06-1) ...
Selecting previously unselected package cuda-libraries-10-1.
Preparing to unpack .../73-cuda-libraries-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-libraries-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-runtime-10-1.
Preparing to unpack .../74-cuda-runtime-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-runtime-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-demo-suite-10-1.
Preparing to unpack .../75-cuda-demo-suite-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-demo-suite-10-1 (10.1.243-1) ...
Selecting previously unselected package cuda-10-1.
Preparing to unpack .../76-cuda-10-1_10.1.243-1_amd64.deb ...
Unpacking cuda-10-1 (10.1.243-1) ...
Selecting previously unselected package libcudnn7.
Preparing to unpack .../77-libcudnn7_7.6.4.38-1+cuda10.1_amd64.deb ...
Unpacking libcudnn7 (7.6.4.38-1+cuda10.1) ...
Selecting previously unselected package libcudnn7-dev.
Preparing to unpack .../78-libcudnn7-dev_7.6.4.38-1+cuda10.1_amd64.deb ...
Unpacking libcudnn7-dev (7.6.4.38-1+cuda10.1) ...
Errors were encountered while processing:
 /tmp/apt-dpkg-install-fjAi3S/55-libnvidia-compute-450_450.36.06-0ubuntu1_amd64.deb
E: Sub-process /usr/bin/dpkg returned an error code (1)
```"
40277,tf2.0 Multi-worker training with Keras  only utilizing one GPU,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
```
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):yes
- OS  : Ubuntu 16.04LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:No
- TensorFlow installed from (source or binary): Frome docker TF2.1.0-gpu-py3
- TensorFlow version (use command below): TF2.1.0-gpu-py3
- Python version: 3.6
- CUDA/cuDNN version:10.1 not sure cuDNN version
- docker18.09.7-3
- nvidia-container-runtime=2.0.0
- kubernetes 1.5.7
- kubeflow 1.01
- 1Master   IP:14X.XXX.XXX.1
- node1     IP:14X.XXX.XXX.8     GTX1060
- node2     IP:14X.XXX.XXX.9     GTX1060
- node3     IP:14X.XXX.XXX.10    GTX1070

```
**Describe the current behavior**
I use  Multi-worker training with Keras but it only use one Gpu
Error:
1.error: Internal: Complete shape not known for Adam/allreduce/CollectiveReduce_2
2.`eval_fn` is not passed in. The `worker_fn` will be used if an ""evaluator"" task exists in the cluster
3.Most import it only run one gpu
I run the code described below:

TEST 1: (3 machine)

![image](https://user-images.githubusercontent.com/50796022/84034018-556f4700-a9cc-11ea-8865-944bb5c13e51.png)


TEST 2 : (2 machine)
![image](https://user-images.githubusercontent.com/50796022/84033957-396ba580-a9cc-11ea-84ac-c9af37f06710.png)
**Describe the expected behavior**
Use Multi gpu
### My Docker File
```
FROM tensorflow/tensorflow:2.1.0-gpu-py3
RUN apt-get update
RUN apt-get install -y libsm6 libxext6 libxrender-dev
RUN pip install opencv-python
RUN pip install Pillow
RUN mkdir -p /app
ADD tp720_1.py /app/
COPY nspo /app/
```
### My yaml
```
apiVersion: kubeflow.org/v1
kind: TFJob
metadata:
  name: nspo-rice
spec:
  tfReplicaSpecs:
    Chief:
      replicas: 1
      template:
        metadata:
          annotations:
            sidecar.istio.io/inject: ""false""
          name: tensorflow
        spec:
          containers:
          - command:
            - python
            - tp720_1.py
            image: nsporice:270_7
            name: tensorflow
            env:
            - name: test_tmpdir
              value: /app/data
            resourceas:
              limits:
                cpu: '1'
            volumeMounts:
            - mountPath: /app/data
              name: nspo-rice-volume
            workingDir: /app
          restartPolicy: Never
          volumes:
          - name: nspo-rice-volume
            persistentVolumeClaim:
              claimName: nspo-rice-volume
    Worker:
      replicas: 2
      template:
        metadata:
          annotations:
            sidecar.istio.io/inject: ""false""
          name: tensorflow
        spec:
          containers:
          - command:
            - python
            - tp720_1.py
            image: nsporice:270_7
            name: tensorflow
            env:
            - name: test_tmpdir
              value: /app/data
            resourceas:
              limits:
                nvidia.com/gpu: 1
            volumeMounts:
            - mountPath: /app/data
              name: nspo-rice-volume
            workingDir: /app
          restartPolicy: Never
          volumes:
          - name: nspo-rice-volume
            persistentVolumeClaim:
              claimName: nspo-rice-volume

```
My code
```
from os import walk
from os.path import join
import numpy as np
import matplotlib.pyplot as plt
import cv2
import time
import random
from scipy import signal
import os
import json
import tensorflow as tf
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, GRU, LSTM, TimeDistributed, RepeatVector, Bidirectional
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.layers import LeakyReLU
from tensorflow.keras import losses
from tensorflow.keras import optimizers
from tensorflow.keras import metrics
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
import tensorflow.keras.backend as K
from tensorflow.keras.models import load_model
class TimeHistory(tf.keras.callbacks.Callback):
    def on_train_begin(self, logs={}):
        self.losses = {'batch':[], 'epoch':[]}
        self.accuracy = {'batch':[], 'epoch':[]}
        self.val_loss = {'batch':[], 'epoch':[]}
        self.val_acc = {'batch':[], 'epoch':[]}
        self.times = []
        self.totaltime = time.time()
        
    def on_train_end(self, logs={}):
        self.totaltime = time.time() - self.totaltime
    
    def on_batch_end(self, batch, logs={}):
        self.losses['batch'].append(logs.get('loss'))
        self.accuracy['batch'].append(logs.get('acc'))
        self.val_loss['batch'].append(logs.get('val_loss'))
        self.val_acc['batch'].append(logs.get('val_acc'))

    def on_epoch_begin(self, batch, logs={}):
        self.epoch_time_start = time.time()
        
    def on_epoch_end(self, batch, logs={}):
        self.losses['epoch'].append(logs.get('loss'))
        
        self.accuracy['epoch'].append(logs.get('acc'))
        self.val_loss['epoch'].append(logs.get('val_loss'))
        self.val_acc['epoch'].append(logs.get('val_acc'))
        self.times.append(time.time() - self.epoch_time_start)
   
    def loss_plot(self, loss_type):
        acc =[]
        loss = []
        val = []
        iters = range(len(self.losses[loss_type]))
        # acc
        acc.extend(self.accuracy[loss_type])
        # loss
        print(""loss = "",self.losses[loss_type])
        loss.extend(self.losses[loss_type])
        # val
        print(""val = "",self.losses[loss_type])
        val.extend(self.val_acc[loss_type])
        return(acc, loss,val)
time_callback = TimeHistory()
      
def buildManyToOneModel(shape):

    model = tf.keras.models.Sequential([
        GRU(32, input_dim = shape[2], input_length = shape[1], return_sequences = True),
        GRU(64, return_sequences = True),
        GRU(128, return_sequences = False),
        #LSTM(16, return_sequences = True),
        #LSTM(16, return_sequences = False),
        BatchNormalization(),
        Dense(1, activation='sigmoid')
    ])
    model.compile(loss='mse', optimizer = 'adam', metrics=['acc'])
    model.summary()
    return model

def slice_(data, node_num):
    total = float(data.shape[0])
    store = []
    if node_num == 1:
        store.append(data[0:int(total),:])
        store.append([0])
        store.append([0])
    elif node_num == 2:
        slice_index = int(total / 2)
        store.append(data[0:slice_index, :])
        store.append(data[slice_index:int(total), :])
        store.append([0])
    elif node_num == 3:
        slice_index = int(total / 3)
        store.append(data[0:slice_index, :])
        store.append(data[slice_index:2*slice_index, :])
        store.append(data[2*slice_index:int(total), :])
    return store

def train():
    print(""TensorFlow version: "", tf.__version__)
    tf_config = os.environ.get('TF_CONFIG', '{}')
    print(""TF_CONFIG %s"", tf_config)
    tf_config_json = json.loads(tf_config)
    cluster = tf_config_json.get('cluster')
    job_name = tf_config_json.get('task', {}).get('type')
    task_index = tf_config_json.get('task', {}).get('index')

    print(""cluster={} job_name={} task_index={}}"", cluster, job_name, task_index)
    
    gpus = tf.config.experimental.list_physical_devices('GPU')
    if gpus:
        try:
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
        except RuntimeError as e:
            print(e)
    strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy(communication=tf.distribute.experimental.CollectiveCommunication.RING)
    print ('Number of devices: {}'.format(strategy.num_replicas_in_sync))

    data0 = np.load('/app/data/2017_360w_data_0.npy')
    data1 = np.load('/app/data/2017_360w_data_1.npy')
    data0 = data0[:,:,0]
    data1 = data1[:,:,0]
    print(""data0:"",data0.shape)
    print(""data1:"",data1.shape)
    a1 = np.array(data0)[0 : int(data0.shape[0]*0.7), :]
    a2 = np.array(data1)[0 : int(data1.shape[0]*0.7), :]
    a3 = np.array(data0)[int(data0.shape[0]*0.7) : data0.shape[0], :]
    a4 = np.array(data1)[int(data1.shape[0]*0.7) : data1.shape[0], :]
    X_train = np.concatenate((a1, a2), axis=0) 
    X_val = np.concatenate((a3, a4), axis=0) 

    b1 = np.zeros((a1.shape[0], 1))
    b2 = np.ones((a2.shape[0], 1))

    b3 = np.zeros((a3.shape[0], 1))

    b4 = np.ones((a4.shape[0], 1))

    Y_train = np.concatenate((b1, b2), axis=0)
    Y_val = np.concatenate((b3, b4), axis=0)
    X_train = X_train.astype(np.float32)
    Y_train = Y_train.astype(np.float32)
    X_val = X_val.astype(np.float32)
    Y_val = Y_val.astype(np.float32)
    X_train = X_train[:,:,np.newaxis]

    X_val = X_val[:,:,np.newaxis]
    print(X_train.shape)
    print(Y_train.shape)
    print(X_val.shape)
    print(Y_val.shape)
    print(type(X_train)) 
    print(type(Y_train))    
    BUFFER_SIZE = X_train.shape[0]
 
    BATCH_SIZE_PER_REPLICA = 5000
    GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA  * (strategy.num_replicas_in_sync-1)
    
    #train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)
    #test_dist_dataset = strategy.experimental_distribute_dataset(test_dataset) 
   
    if BUFFER_SIZE % GLOBAL_BATCH_SIZE != 0:
        parallel_steps =  X_train.shape[0] // GLOBAL_BATCH_SIZE + 1
        a =  X_val.shape[0] // GLOBAL_BATCH_SIZE + 1
    else:
        parallel_steps =  X_train.shape[0] // GLOBAL_BATCH_SIZE
        a =  X_val.shape[0] // GLOBAL_BATCH_SIZE         
    print(parallel_steps) 
    t2 = time.time()
    with strategy.scope():
         train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train)).repeat().shuffle(buffer_size=5000000).batch(GLOBAL_BATCH_SIZE)
         #test_dataset = tf.data.Dataset.from_tensor_slices((X_val, Y_val)).batch(GLOBAL_BATCH_SIZE) 
         options = tf.data.Options()
         options.experimental_distribute.auto_shard_policy = \
                                        tf.data.experimental.AutoShardPolicy.DATA
         train_dataset = train_dataset.with_options(options)    
         #test_dataset = test_dataset.with_options(options)        
         multi_worker_model = buildManyToOneModel(X_train.shape)    

    #history = multi_worker_model.fit(train_dataset, epochs=30, validation_data=test_dataset,steps_per_epoch=parallel_steps,validation_steps=a,callbacks=[time_callback])
    history = multi_worker_model.fit(train_dataset, epochs=30,steps_per_epoch=parallel_steps,callbacks=[time_callback])
    t3 = time.time()    
    print (""It cost "", t3 - t2, "" seconds"")


    accuracy, loss,val = time_callback.loss_plot('epoch')
    print(""totaltime:%.4f""%time_callback.totaltime)
    for i in range(len(accuracy)):
        print(""acc: %.4f, loss: %.4f,val:%.4f -----epoch:%d"" %(accuracy[i], loss[i],val[i],i+1))
    totaltime='%.2f'%time_callback.totaltime
    ttime= t3 - t2
    traningtime='%.2f'%ttime
    maxval='%.2f'%max(val)
    save_dir = '/app/data'
    f = open(save_dir+""/720_1.txt"", ""a"")
    f.write(""\ntotaltime:{},traningtime:{},val:{}"".format(totaltime,traningtime,maxval))
    f.close()
if __name__ == '__main__':
    train()  
```



Pod logs
```
2020-06-08 12:52:04.146322: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6
2020-06-08 12:52:04.147962: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6
2020-06-08 12:52:04.788595: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-06-08 12:52:04.795356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:05:00.0 name: GeForce GTX 1070 computeCapability: 6.1
coreClock: 1.7715GHz coreCount: 15 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s
2020-06-08 12:52:04.795467: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-06-08 12:52:04.795550: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-06-08 12:52:04.798357: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-06-08 12:52:04.799032: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-06-08 12:52:04.802641: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-06-08 12:52:04.804156: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-06-08 12:52:04.804221: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-06-08 12:52:04.805601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-06-08 12:52:04.806525: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-06-08 12:52:04.814745: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2198720000 Hz
2020-06-08 12:52:04.815811: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5c54090 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-06-08 12:52:04.815832: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-06-08 12:52:04.933082: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5cb9890 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-06-08 12:52:04.933126: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1070, Compute Capability 6.1
2020-06-08 12:52:04.934468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:05:00.0 name: GeForce GTX 1070 computeCapability: 6.1
coreClock: 1.7715GHz coreCount: 15 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s
2020-06-08 12:52:04.934575: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-06-08 12:52:04.934620: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-06-08 12:52:04.934658: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-06-08 12:52:04.934694: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-06-08 12:52:04.934746: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-06-08 12:52:04.934794: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-06-08 12:52:04.934850: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-06-08 12:52:04.938735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-06-08 12:52:04.938852: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-06-08 12:52:05.301356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-06-08 12:52:05.301383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-06-08 12:52:05.301391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-06-08 12:52:05.302813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6927 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:05:00.0, compute capability: 6.1)
2020-06-08 12:52:05.305432: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:05:00.0 name: GeForce GTX 1070 computeCapability: 6.1
coreClock: 1.7715GHz coreCount: 15 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s
2020-06-08 12:52:05.305510: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-06-08 12:52:05.305552: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-06-08 12:52:05.305590: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-06-08 12:52:05.305617: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-06-08 12:52:05.305649: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-06-08 12:52:05.305686: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-06-08 12:52:05.305721: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-06-08 12:52:05.306950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-06-08 12:52:05.306975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-06-08 12:52:05.306983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-06-08 12:52:05.306988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-06-08 12:52:05.308211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:worker/replica:0/task:1/device:GPU:0 with 6927 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:05:00.0, compute capability: 6.1)
2020-06-08 12:52:05.314693: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job chief -> {0 -> nspo-rice-chief-0.kubeflow.svc:2222}
2020-06-08 12:52:05.314716: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job worker -> {0 -> nspo-rice-worker-0.kubeflow.svc:2222, 1 -> localhost:2222}
2020-06-08 12:52:05.315663: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:390] Started server with target: grpc://localhost:2222
WARNING:tensorflow:`eval_fn` is not passed in. The `worker_fn` will be used if an ""evaluator"" task exists in the cluster.
WARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.
WARNING:tensorflow:ModelCheckpoint callback is not provided. Workers will need to restart training if any fails.
2020-06-08 12:52:16.277123: W tensorflow/core/grappler/optimizers/scoped_allocator_optimizer.cc:440] error: Internal: Complete shape not known for Adam/allreduce/CollectiveReduce_2
2020-06-08 12:52:16.277150: W tensorflow/core/grappler/optimizers/scoped_allocator_optimizer.cc:1056] error: Internal: Complete shape not known for Adam/allreduce/CollectiveReduce_2
2020-06-08 12:52:16.277227: E tensorflow/core/grappler/optimizers/scoped_allocator_optimizer.cc:1073] ScopedAllocatorOptimizer: Internal: Complete shape not known for Adam/allreduce/CollectiveReduce_2
2020-06-08 12:52:16.277234: W tensorflow/core/grappler/optimizers/scoped_allocator_optimizer.cc:846] error: Internal: Complete shape not known for Adam/allreduce/CollectiveReduce_2
2020-06-08 12:52:16.277886: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] scoped_allocator_optimizer failed: Internal: Complete shape not known for Adam/allreduce/CollectiveReduce_2
2020-06-08 12:52:16.672402: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
TensorFlow version:  2.1.0
TF_CONFIG %s {""cluster"":{""chief"":[""nspo-rice-chief-0.kubeflow.svc:2222""],""worker"":[""nspo-rice-worker-0.kubeflow.svc:2222"",""nspo-rice-worker-1.kubeflow.svc:2222""]},""task"":{""type"":""worker"",""index"":1},""environment"":""cloud""}
cluster={} job_name={} task_index={}} {'chief': ['nspo-rice-chief-0.kubeflow.svc:2222'], 'worker': ['nspo-rice-worker-0.kubeflow.svc:2222', 'nspo-rice-worker-1.kubeflow.svc:2222']} worker 1
Number of devices: 3
data0: (1760157, 14)
data1: (1839843, 14)
(2519999, 14, 1)
(2519999, 1)
(1080001, 14, 1)
(1080001, 1)
<class 'numpy.ndarray'>
<class 'numpy.ndarray'>
252
Model: ""sequential""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru (GRU)                    (None, 14, 32)            3360      
_________________________________________________________________
gru_1 (GRU)                  (None, 14, 64)            18816     
_________________________________________________________________
gru_2 (GRU)                  (None, 128)               74496     
_________________________________________________________________
batch_normalization (BatchNo (None, 128)               512       
_________________________________________________________________
dense (Dense)                (None, 1)                 129       
=================================================================
Total params: 97,313
Trainable params: 97,057
Non-trainable params: 256
_________________________________________________________________
Train for 252 steps
Epoch 1/30
252/252 [==============================] - 53s 209ms/step - loss: 0.1431 - acc: 0.8200
Epoch 2/30
252/252 [==============================] - 38s 149ms/step - loss: 0.0953 - acc: 0.8733
Epoch 3/30
252/252 [==============================] - 38s 149ms/step - loss: 0.0890 - acc: 0.8798
````"
40276,TensorArray concat() throws _FallbackException,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.2.0
- Python version: 3.7.5
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1/ 7.6.5
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
- For a image classification challenge, i need to save the predictions with the corresponding filenames to a json-file. In this example this is simply replaced by an manual added index, because fashion_mnist doesn't contain filenames.
- As the dataset is batched, at the end of the prediction, it is necessary to flatten the TensorArray via the concat()-Function after all samples in the testset have been processed.  
- If i run this code without @tf.function by setting tf.config.experimental_run_functions_eagerly(True), the issue won't happen.
- If i run the code with the @tf.function annotator, the error below is thrown. 
- Error occurs with tf-gpu 2.1.0 as well as with tf-gpu 2.2.0

**Describe the expected behavior**
The concat-Function should work like without the @tf.function annotator.

**Standalone code to reproduce the issue**

[Link to colab notebook](https://github.com/MilimaBwana/Issues/blob/master/TFFunction_Issue.ipynb)

```python
import tensorflow as tf
from pathlib import Path
import json
import keras
import numpy as np
import os


class JSONLogger:

    def __init__(self, model, directory):
        self.model = model
        self.directory = directory
        Path(directory).mkdir(parents=True, exist_ok=True)

        self.idx_list = tf.TensorArray(tf.int32, size=0, dynamic_size=True, clear_after_read=False)
        self.predictions_list = tf.TensorArray(tf.int64, size=0, dynamic_size=True, clear_after_read=False)
        self.index = 0

    def on_batch_predict_end(self, indices, predictions):
        self.idx_list = self.idx_list.write(self.index, indices)
        self.predictions_list = self.predictions_list.write(self.index, predictions)
        self.index += 1

    def on_predict_end(self):
        indices = self.idx_list.concat() # Error gets thrown here
        predictions_list = self.predictions_list.concat()
        helper_list = []

        for index, prediction in zip(indices.numpy(),
                                     predictions_list.numpy()):
            tmp_dict = {'Index': str(index), 'Class': str(prediction)}
            helper_list.append(tmp_dict)
        
        with open(self.directory + '/predictions.json', 'w') as file:
            json.dump(helper_list, file)


class fashion_model(tf.keras.Model):
    def __init__(self):
        super(fashion_model, self).__init__()
        self.optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)
        self.flatten = tf.keras.layers.Flatten(data_format='channels_last')
        self.dense1 = tf.keras.layers.Dense(units=128, input_shape=(28 * 28,), activation='relu')
        self.out_layer = tf.keras.layers.Dense(units=10)

        self.loss_object = tf.keras.losses.SparseCategoricalCrossentropy(
            from_logits=True,
            reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE)

        self.train_loss = tf.keras.metrics.Mean('train_loss')

    def call(self, inputs, training=None, mask=None):
        x = self.flatten(inputs)
        x = self.dense1(x)
        x = self.out_layer(x)
        return x


@tf.function
def train_step(model, sample):
    images, labels, _ = sample

    with tf.GradientTape() as tape:
        logits = model(images, training=True)
        loss = model.loss_object(y_pred=logits, y_true=labels)

    gradients = tape.gradient(loss, model.trainable_variables)
    model.optimizer.apply_gradients(grads_and_vars=zip(gradients, model.trainable_variables))

    model.train_loss(loss)


@tf.function
def predict_step(model, sample, logger):
    images, labels, indices = sample
    logits = model(images, training=False)
    logger.on_batch_predict_end(indices, tf.argmax(logits, axis=-1))


def tf_run(run_eagerly=False):
    # pip install ..  only works on colab
    !pip install tensorflow-gpu==2.2.0
    print('TFVersion: ', tf.__version__)
    print('Run eagerly', run_eagerly)
    if run_eagerly:
        tf.config.experimental_run_functions_eagerly(True)

    fashion_mnist = keras.datasets.fashion_mnist

    (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()

    class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
                   'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']
    train_idx = np.arange(len(train_labels), dtype=np.int32)
    train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels, train_idx))
    train_dataset.shuffle(5000)
    train_dataset = train_dataset.batch(32, drop_remainder=True)

    test_idx = np.arange(len(test_labels), dtype=np.int32)
    test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels, test_idx))
    test_dataset = test_dataset.batch(32, drop_remainder=True)
    model = fashion_model()
    logger = JSONLogger(model, os.getcwd())
    print('Path', os.getcwd())

    for epoch in range(1, 3):

        for sample in train_dataset:
            train_step(model, sample)

        template = 'Epoch {}, Loss: {}'
        print(template.format(epoch,
                              model.train_loss.result()))

        model.train_loss.reset_states()

    for sample in test_dataset:
        predict_step(model, sample, logger)

    logger.on_predict_end()


if __name__ == ""__main__"":
    tf_run(False)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
```python
_FallbackException                        Traceback (most recent call last)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py in identity(input, name)
   3888         _ctx._context_handle, tld.device_name, ""Identity"", name,
-> 3889         tld.op_callbacks, input)
   3890       return _result

_FallbackException: This function does not handle the case of the path where all inputs are not already EagerTensors.


During handling of the above exception, another exception occurred:

TypeError                                 Traceback (most recent call last)

12 frames

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     58     ctx.ensure_initialized()
     59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
---> 60                                         inputs, attrs, num_outputs)
     61   except core._NotOkStatusException as e:
     62     if name is not None:

TypeError: An op outside of the function building code is being passed
a ""Graph"" tensor. It is possible to have Graph tensors
leak out of the function building context by including a
tf.init_scope in your function building code.
For example, the following function will fail:
  @tf.function
  def has_init_scope():
    my_constant = tf.constant(1.)
    with tf.init_scope():
      added = my_constant * 2
The graph tensor has name: sample_2:0
```

"
40275,Import error : dll load failed Tensorflow 2.0 version,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1.  It must be a bug, a feature request, or a significant problem with the
    documentation (for small docs fixes please send a PR instead).
2.  The form below must be filled out.
3.  It shouldn't be a TensorBoard issue. Those go
    [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**:
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**:
-   **TensorFlow installed from (source or binary)**:
-   **TensorFlow version (use command below)**:
-   **Python version**:
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**:
-   **GPU model and memory**:
-   **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
40273,Shuffle buffer filled,"I am getting the following logging:

```
2020-06-08 06:09:37.995077: I tensorflow/core/kernels/shuffle_dataset_op.cc:112] Filling up shuffle buffer (this may take a while): 59921 of 64000

2020-06-08 06:09:38.725673: I tensorflow/core/kernels/shuffle_dataset_op.cc:126] Shuffle buffer filled.
````

What does it mean?"
40272,"Bazel build option ""--config=v1"" does not build Tensorflow 1.x","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- Linux Ubuntu 18.04:
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.2.0
- Python version: 3.6.9
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source): 2.0.0
- GCC/Compiler version (if compiling from source): 7.5.0
- CUDA/cuDNN version: 10.2/7.6.5
- GPU model and memory: GeForce RTX 2080 SUPER 8GB


**Describe the problem**

When trying to build the v1.x form the v2.2.0, the actual version built is not 1.x, but 2.2.0.

Here are the steps I took:
```
$ ./configure
You have bazel 2.0.0 installed.
Please specify the location of python. [Default is /usr/bin/python]: /usr/bin/python3


Found possible Python library paths:
  /usr/lib/python3/dist-packages
  /usr/local/lib/python3.6/dist-packages
Please input the desired Python library path to use.  Default is [/usr/lib/python3/dist-packages]
 
Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: 
No OpenCL SYCL support will be enabled for TensorFlow.

Do you wish to build TensorFlow with ROCm support? [y/N]: 
No ROCm support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: y
CUDA support will be enabled for TensorFlow.

Do you wish to build TensorFlow with TensorRT support? [y/N]: 
No TensorRT support will be enabled for TensorFlow.

Found CUDA 10.2 in:
    /usr/local/cuda/lib64
    /usr/local/cuda/include
Found cuDNN 7 in:
    /usr/lib/x86_64-linux-gnu
    /usr/include


Please specify a list of comma-separated CUDA compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only supports compute capabilities >= 3.5 [Default is: 7.5]: 


Do you want to use clang as CUDA compiler? [y/N]: 
nvcc will be used as CUDA compiler.

Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: 


Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native -Wno-sign-compare]: 


Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: 
Not configuring the WORKSPACE for Android builds.

Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details.
	--config=mkl         	# Build with MKL support.
	--config=monolithic  	# Config for mostly static monolithic build.
	--config=ngraph      	# Build with Intel nGraph support.
	--config=numa        	# Build with NUMA support.
	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects.
	--config=v2          	# Build TensorFlow 2.x instead of 1.x.
Preconfigured Bazel build configs to DISABLE default on features:
	--config=noaws       	# Disable AWS S3 filesystem support.
	--config=nogcp       	# Disable GCP support.
	--config=nohdfs      	# Disable HDFS support.
	--config=nonccl      	# Disable NVIDIA NCCL support.
Configuration finished


$ bazel build --jobs 12 --config=opt --config=cuda --config=v1 //tensorflow/tools/pip_package:build_pip_package

$ ./bazel-bin/tensorflow/tools/pip_package/build_pip_package path-to-package/

$ pip3 install path-to-package/tensorflow-2.2.0-cp36-cp36m-linux_x86_64.whl

$ python3 -c ""import tensorflow as tf; print(tf.__version__)""
2.2.0
```

My expectation is that when I pass ""--config=v1"" I would get Tensorflow 1.x built, not 2.2.0."
40270,TfLite Sign Op Support,How long will the sign op be surpported? Or would you please provide some suggestions for implementing a tflite custom op using eigen lib as tf sign op.
40268,AutoGraph saved model with uint8 input will not convert to tflite,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Both Windows and Linux
- TensorFlow installed from (source or binary):
From binary with pip and preinstalled on colab

- TensorFlow version (or github SHA if from source):
'2.2.0'

**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.
https://colab.research.google.com/drive/1cnxZOljJUz_Z-q4MNvvm4nQaRQL5C6Pf#scrollTo=h_QP1TGd3sRa
```
class Net(tf.Module):
    @tf.function(input_signature=[tf.TensorSpec(shape=(1,1,3),dtype=tf.uint8)])
    def process(self,image):
        return image

test_exp=Net()

tf.saved_model.save(test_exp,""saved_model"")

converter_tlite=tf.lite.TFLiteConverter.from_saved_model(""saved_model"")

converter_tlite.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]

converter_tlite.inference_input_type=tf.uint8
converter_tlite.inference_output_type=tf.uint8

test_tflite=converter_tlite.convert()
```

**The output from the converter invocation**

```
ConverterError: See console for info.
2020-06-08 08:52:53.152754: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:89] Ignored output_format.
2020-06-08 08:52:53.152800: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:95] Ignored drop_control_dependency.
loc(""Func/PartitionedCall/input/_0""): error: requires all operands to be either same as or ref type of results
Traceback (most recent call last):
  File ""/usr/local/bin/toco_from_protos"", line 8, in <module>
    sys.exit(main())
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 93, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run
    _run_main(main, args)
  File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 56, in execute
    enable_mlir_converter)
Exception: <unknown>:0: error: loc(""Func/PartitionedCall/input/_0""): requires all operands to be either same as or ref type of results
```

**Failure details**
The graph will not convert to tflite. See error above


**Any other info / logs**

Reproducible in Colab. Graph with float32 input works fine"
40267,"Keras layer on TPU, Cannot assign a device for operation RandomUniform","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.2.0, v2.2.0-rc4-8-g2b96f3662b
- Python version: 3.6.9
- Bazel version (if compiling from source): None
- GCC/Compiler version (if compiling from source): None
- CUDA/cuDNN version: None
- GPU model and memory: TPU

**Describe the current behavior**

I'm trying to use the `tf.keras.layers.Dense` layer on TPU.
I get the exception `InvalidArgumentError: Cannot assign a device for operation encoder/kernel/Initializer/random_uniform/RandomUniform: Could not satisfy explicit device specification '' because the node {{colocation_node encoder/kernel/Initializer/random_uniform/RandomUniform}} was colocated with a group of nodes that required incompatible device '/device:TPU:0'. All available devices [/job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0].`.

**Describe the expected behavior**

I would expect that this works.

**Standalone code to reproduce the issue**

```
import os
import tensorflow as tf
import numpy

# https://www.tensorflow.org/guide/tpu
if os.environ.get('COLAB_TPU_ADDR', """"):
  resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])
  tf.config.experimental_connect_to_cluster(resolver)
  # This is the TPU initialization code that has to be at the beginning.
  tf.tpu.experimental.initialize_tpu_system(resolver)

tf.compat.v1.disable_v2_behavior()
tf.compat.v1.reset_default_graph()

with tf.device(""/TPU:0""):
  x = tf.compat.v1.placeholder(tf.float32, shape=(3, 4, 2), name=""x"")
  encoder = tf.keras.layers.Dense(units=5, activation=""tanh"", name=""encoder"")(x)

  vars_init_op = tf.compat.v1.global_variables_initializer()

rnd = numpy.random.RandomState(42)
x_np = rnd.normal(size=(3, 4, 2))

with tf.compat.v1.Session() as session:
  session.run(vars_init_op)
  session.run(encoder, feed_dict={x: x_np})

```

[Colab](https://colab.research.google.com/drive/1WTzn71tXYWeyyDxqFwXxblnDhZtxAbQX?usp=sharing).

**Other info / logs**

```
InvalidArgumentError: Cannot assign a device for operation encoder/kernel/Initializer/random_uniform/RandomUniform: Could not satisfy explicit device specification '' because the node {{colocation_node encoder/kernel/Initializer/random_uniform/RandomUniform}} was colocated with a group of nodes that required incompatible device '/device:TPU:0'. All available devices [/job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0]. 
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:TPU:0' assigned_device_name_='' resource_device_name_='/device:TPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]
AssignVariableOp: CPU XLA_CPU 
RandomUniform: CPU XLA_CPU 
VarIsInitializedOp: CPU XLA_CPU 
Const: CPU XLA_CPU 
Mul: CPU XLA_CPU 
ReadVariableOp: CPU XLA_CPU 
Sub: CPU XLA_CPU 
VarHandleOp: CPU XLA_CPU 
Add: CPU XLA_CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  encoder/kernel/Initializer/random_uniform/shape (Const) 
  encoder/kernel/Initializer/random_uniform/min (Const) 
  encoder/kernel/Initializer/random_uniform/max (Const) 
  encoder/kernel/Initializer/random_uniform/RandomUniform (RandomUniform) 
  encoder/kernel/Initializer/random_uniform/sub (Sub) 
  encoder/kernel/Initializer/random_uniform/mul (Mul) 
  encoder/kernel/Initializer/random_uniform (Add) 
  encoder/kernel (VarHandleOp) /device:TPU:0
  encoder/kernel/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:TPU:0
  encoder/kernel/Assign (AssignVariableOp) /device:TPU:0
  encoder/kernel/Read/ReadVariableOp (ReadVariableOp) /device:TPU:0
  encoder/Tensordot/ReadVariableOp (ReadVariableOp) 

	 [[{{node encoder/kernel/Initializer/random_uniform/RandomUniform}}]]
```

Maybe #31318 is related?
"
40266,Unexpected rise in inference time after quantization,"<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 and Colab
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 1.15.0 ,2.2.0, 2.2.0-dev20200508 for QAT
- Python version: 3.6.5
- GPU model and memory: using CPU

**Describe the current behavior**
The inference time of TF-Lite model becomes extremely high after the post training integer quantization and after Quantization Aware Training of model when using calibration dataset for static quantization.
Tried on various models and with different datasets on 1.15.0 and also on 2.2.0 and  2.2.0-dev20200508 for QAT

**Describe the expected behavior**
The inference time of TFlite model (with post-training static quantization and after QAT) should be less or at least equal to TFLite model without quantization. 

**Steps and code to reproduce the issue**

Links for notebook files: 
https://drive.google.com/file/d/1XFWXp-nXhEdBuikaW3q3uJ2EmPy8fbOZ/view?usp=sharing
https://drive.google.com/file/d/16kEu87nj-Q2gjgET6CcZUvKxJvpi6pMW/view?usp=sharing

Train keras model using the dataset.(Using california housing data)

input_size = 8 

model = keras.Sequential()
model.add(tf.keras.layers.Flatten())
for i in range(0,2):
    model.add(tf.keras.layers.Dense(1024,activation='relu'))
    
model.add(tf.keras.layers.Dense(1))

In TF 1.15.0:
----------------
Created ONNX model using h5 file of saved model using keras2onnx. (Also tried the same flow by generating ONNX model using pytorch with same model architecture)
Created '.pb' file from ONNX model. 
Using  'tf.lite.TFLiteConverter.from_frozen_graph' to create TFLite model. 

In TF 2.2.0:
----------------
Using  'tf.lite.TFLiteConverter.from_keras_model' to create TFLite model.


case-1
=======
converter = tf.lite.TFLiteConverter.from_frozen_graph(<path to .pb file>,['input_1'],['output_1'])    
converter.optimizations = [tf.lite.Optimize.DEFAULT]    
converter.representative_dataset = representative_data_gen
tflite_int_model = converter.convert()

case-2
=======
converter = tf.lite.TFLiteConverter.from_frozen_graph(<path to .pb file>,['input_1'],['output_1'])    
converter.optimizations = [tf.lite.Optimize.DEFAULT]    
converter.representative_dataset = representative_data_gen
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.uint8
converter.inference_output_type = tf.uint8

case-3(QAT):
=======
quantize_model = tfmot.quantization.keras.quantize_model
q_aware_model = quantize_model(model)
q_aware_model.compile(optimizer='rmsprop',loss='mean_squared_error')
q_aware_model.summary()

q_aware_model.fit(x, y, batch_size=128, epochs=2, validation_split=0.2)

converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()


Now loading the quantized TFLite models for inference. 

Without quantization, the average inference time of TFLite model is 100 microseconds in my PC and around 200 on google colab (avg for one record when run inference for 1000 input records)
In all the cases(case1,case2 and case3 mentioned above), After quantization, the average inference time of TFLite model is around 10000 microseconds in my PC and its around 500 on colab(avg for one record when run inference for 1000 input records)


"
40265,`from tensorflow import keras` errors if it's in a file named `code.py`,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu:18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0 
- Python version: Python 3.8.3
- Bazel version (if compiling from source): N+A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
If you have a single line with `from tensorflow import keras` in a file called `code.py` and run `python3 code.py` you get following error: 
```
Traceback (most recent call last):
  File ""code.py"", line 1, in <module>
    from tensorflow import keras
  File ""/usr/local/lib/python3.8/site-packages/tensorflow/__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/__init__.py"", line 64, in <module>
    from tensorflow.python.framework.framework_lib import *  # pylint: disable=redefined-builtin
  File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/framework/framework_lib.py"", line 25, in <module>
    from tensorflow.python.framework.ops import Graph
  File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py"", line 64, in <module>
    from tensorflow.python.platform import app
  File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/platform/app.py"", line 23, in <module>
    from absl.app import run as _run
  File ""/usr/local/lib/python3.8/site-packages/absl/app.py"", line 35, in <module>
    import pdb
  File ""/usr/local/lib/python3.8/pdb.py"", line 77, in <module>
    import code
  File ""/code.py"", line 1, in <module>
    from tensorflow import keras
  File ""/usr/local/lib/python3.8/site-packages/tensorflow/keras/__init__.py"", line 14, in <module>
    from . import activations
  File ""/usr/local/lib/python3.8/site-packages/tensorflow/keras/activations/__init__.py"", line 10, in <module>
    from tensorflow.python.keras.activations import deserialize
  File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/__init__.py"", line 27, in <module>
    from tensorflow.python.keras import models
  File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/models.py"", line 23, in <module>
    from tensorflow.python.keras import backend as K
  File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/backend.py"", line 36, in <module>
    from tensorflow.python.client import session as session_module
  File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/client/session.py"", line 38, in <module>
    from tensorflow.python.framework import sparse_tensor
  File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/framework/sparse_tensor.py"", line 29, in <module>
    from tensorflow.python.framework import constant_op
  File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py"", line 324, in <module>
    ops.register_tensor_conversion_function(
AttributeError: partially initialized module 'tensorflow.python.framework.ops' has no attribute 'register_tensor_conversion_function' (most likely due to a circular import)
```
This does *not* happen when the file is not called exactly `code.py`. 

**Describe the expected behavior**
You can just import the code, no error. 

**Standalone code to reproduce the issue**
`docker run -it --rm python:3 bash`
then 
```
python3 -m pip install -y tensorflow 
echo ""from tensorflow import keras"" > code.py
python3 code.py # ==> error happens
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
Linked Stackoverflow issue, proving at least 2 people had this issue: 
https://stackoverflow.com/questions/62165354/cannot-import-keras-from-tensorflow-depending-on-if-there-exists-a-file-in-the-c/62243098?noredirect=1#comment110099265_62243098"
40263,learned_unigram_candidate_sampler may enter infinite loop when range_max is a very large number,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0 & v2.1.0-rc2-17-ge5bf8de 2.1.0
- Python version: 3.7.6
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: NA
- GPU model and memory: NA

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
`tf.random.learned_unigram_candidate_sampler`/`tf.nn.learned_unigram_candidate_sampler` may enter infinite loop when `range_max` is a very large number.

When `range_max` is a large number, the execution may stuck in the while loop [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/lib/random/weighted_picker.cc#L32-L34). The `LevelSize` function returns `1 << level`, so when `level` is a large number, the left shift will have undefined behavior. So `LevelSize(num_levels_ - 1)` may never be `>= N`, causing infinite loop.

**Describe the expected behavior**
In `WeightedPicker::WeightedPicker(int N)`, there should be a boundary checking for `N` (same number as `range_max`). If input `N` is big enough to cause left shift to have undefined behavior, tensorflow should raise a warning to the user and perhaps an exception to stop the execution.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```python
import tensorflow as tf
import numpy as np

# this function call will not terminate
tf.random.learned_unigram_candidate_sampler(
    true_classes=np.random.rand(100, 10),
    num_true=10,
    num_sampled=100,
    unique=True,
    range_max=2000000000, # big enough to cause << to have undefined behavior & cause infinite loop
)
```
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40262,"Use the trained k-NN classifier model to classify new, previously unseen objects ","I am trying to run below following lines in Jupiter notebook using necessary libraries and packages but yet its not running for me:

fruit_prediction = knn.predict([[20, 4.3, 5.5]])
lookup_fruit_name[fruit_prediction[0]]

Moreover below is the following error I am getting:
ValueError                                Traceback (most recent call last)
<ipython-input-12-1d28f9746e24> in <module>
----> 1 fruit_prediction = knn.predict([[20, 4.3, 5.5]])
      2 lookup_fruit_name[fruit_prediction[0]]

~\AppData\Roaming\Python\Python37\site-packages\sklearn\neighbors\_classification.py in predict(self, X)
    171         X = check_array(X, accept_sparse='csr')
    172 
--> 173         neigh_dist, neigh_ind = self.kneighbors(X)
    174         classes_ = self.classes_
    175         _y = self._y

~\AppData\Roaming\Python\Python37\site-packages\sklearn\neighbors\_base.py in kneighbors(self, X, n_neighbors, return_distance)
    661                 delayed_query(
    662                     self._tree, X[s], n_neighbors, return_distance)
--> 663                 for s in gen_even_slices(X.shape[0], n_jobs)
    664             )
    665         else:

~\OneDrive\Documents\Python\lib\site-packages\joblib\parallel.py in __call__(self, iterable)
   1027             # remaining jobs.
   1028             self._iterating = False
-> 1029             if self.dispatch_one_batch(iterator):
   1030                 self._iterating = self._original_iterator is not None
   1031 

~\OneDrive\Documents\Python\lib\site-packages\joblib\parallel.py in dispatch_one_batch(self, iterator)
    845                 return False
    846             else:
--> 847                 self._dispatch(tasks)
    848                 return True
    849 

~\OneDrive\Documents\Python\lib\site-packages\joblib\parallel.py in _dispatch(self, batch)
    763         with self._lock:
    764             job_idx = len(self._jobs)
--> 765             job = self._backend.apply_async(batch, callback=cb)
    766             # A job can complete so quickly than its callback is
    767             # called before we get here, causing self._jobs to

~\OneDrive\Documents\Python\lib\site-packages\joblib\_parallel_backends.py in apply_async(self, func, callback)
    204     def apply_async(self, func, callback=None):
    205         """"""Schedule a func to be run""""""
--> 206         result = ImmediateResult(func)
    207         if callback:
    208             callback(result)

~\OneDrive\Documents\Python\lib\site-packages\joblib\_parallel_backends.py in __init__(self, batch)
    568         # Don't delay the application, to avoid keeping the input
    569         # arguments in memory
--> 570         self.results = batch()
    571 
    572     def get(self):

~\OneDrive\Documents\Python\lib\site-packages\joblib\parallel.py in __call__(self)
    251         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    252             return [func(*args, **kwargs)
--> 253                     for func, args, kwargs in self.items]
    254 
    255     def __reduce__(self):

~\OneDrive\Documents\Python\lib\site-packages\joblib\parallel.py in <listcomp>(.0)
    251         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    252             return [func(*args, **kwargs)
--> 253                     for func, args, kwargs in self.items]
    254 
    255     def __reduce__(self):

~\AppData\Roaming\Python\Python37\site-packages\sklearn\neighbors\_base.py in _tree_query_parallel_helper(tree, *args, **kwargs)
    488     under PyPy.
    489     """"""
--> 490     return tree.query(*args, **kwargs)
    491 
    492 

sklearn\neighbors\_binary_tree.pxi in sklearn.neighbors._kd_tree.BinaryTree.query()

ValueError: query data dimension must match training data dimension

Can someone please tell me what I should I do ?"
40261,model.predict is much slower on TF 2.1+,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): WIndows 10 and Ubuntu 18.04
- TensorFlow installed from (source or binary): Binary with pip3
- TensorFlow version (use command below): 2.1+ vs. 2.0
- Python version: 3.7
- CUDA/cuDNN version: Used with CPU
- CPU model: Intel i7 5930

**Describe the current behavior**
Starting from tensorflow-cpu 2.1, my program spends multiple fold of time on model.predict() compared to tensorflow 2.0. TF 2.2 get about the same result as 2.1.
My original program is fairly complicate. I wrote a simpliest example code below.
With TF 2.0, it takes 0.13 seconds to run.
With TF 2.2, it takes about 3 seconds.

**Describe the expected behavior**
It should have similar execution time with TF 2.1+

**Standalone code to reproduce the issue**
```
from tensorflow.keras import Input, Model
import time
import numpy as np

x = Input(shape=(1, 1))
model = Model(inputs=x, outputs=x)

t = time.time()
i = 0
while i<100:
    model.predict(np.zeros((1, 1, 1)))
    i += 1
print(time.time() - t)
```"
40260,Failed to build TF on macOS with CUDA 10.1 due to cusparse_10_1.inc,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution: macOS 10.13.6
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.2.0
- Python version: 3.7
- Bazel version (if compiling from source): 2.2.0
- GCC/Compiler version (if compiling from source): XCode 10.1
- CUDA/cuDNN version: 10.1.243/ 7.6.5
- GPU model and memory: Nvidia Titan V



**Describe the problem**


Building tensorflow from source encountered the following error:
```
ERROR: /Volumes/Data/github/tensorflow/tensorflow/stream_executor/cuda/BUILD:448:1: C++ compilation of rule '//tensorflow/stream_executor/cuda:cusparse_stub' failed (Exit 1)
In file included from tensorflow/stream_executor/cuda/cusparse_stub.cc:59:
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7786:21: error: unknown type name 'cusparseSpVecDescr_t'
cusparseCreateSpVec(cusparseSpVecDescr_t *spVecDescr, int64_t size, int64_t nnz,
                    ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7790:7: error: unknown type name 'cusparseSpVecDescr_t'; did you mean 'cusparseSpMatDescr_t'?
      cusparseSpVecDescr_t *, int64_t, int64_t, void *, void *,
      ^~~~~~~~~~~~~~~~~~~~
      cusparseSpMatDescr_t
bazel-out/host/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/cusparse.h:6964:36: note: 'cusparseSpMatDescr_t' declared here
typedef struct cusparseSpMatDescr* cusparseSpMatDescr_t;
                                   ^
In file included from tensorflow/stream_executor/cuda/cusparse_stub.cc:59:
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7799:22: error: unknown type name 'cusparseSpVecDescr_t'; did you mean 'cusparseSpMatDescr_t'?
cusparseDestroySpVec(cusparseSpVecDescr_t spVecDescr) {
                     ^~~~~~~~~~~~~~~~~~~~
                     cusparseSpMatDescr_t
bazel-out/host/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/cusparse.h:6964:36: note: 'cusparseSpMatDescr_t' declared here
typedef struct cusparseSpMatDescr* cusparseSpMatDescr_t;
                                   ^
In file included from tensorflow/stream_executor/cuda/cusparse_stub.cc:59:
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7800:51: error: unknown type name 'cusparseSpVecDescr_t'; did you mean 'cusparseSpMatDescr_t'?
  using FuncPtr = cusparseStatus_t(CUSPARSEAPI *)(cusparseSpVecDescr_t);
                                                  ^~~~~~~~~~~~~~~~~~~~
                                                  cusparseSpMatDescr_t
bazel-out/host/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/cusparse.h:6964:36: note: 'cusparseSpMatDescr_t' declared here
typedef struct cusparseSpMatDescr* cusparseSpMatDescr_t;
```

"
40259,How to convert tensorflow::tensorproto to tensorflow::tensor in C++,"My question is just like the title.

When using tfserving, you need to get the following：
```
tensorflow::SavedModelBundle bundle;
tensorflow::LoadSavedModel(...)
```
The model needs to be predicted after loading：
```
bundle.session.Run(...)
```
However, one input requirement of the run function is tensorflow::tensor type, and my a priori data is of tensorflow::tensorproto type, how do I convert it? In addition, where is the interface documentation for C++?"
40258,TFLiteConverter: failed to convert `tf.cast` (from `uint8` to `float32`),"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes (https://gist.github.com/kalaluthien/1cb86948d8f8e58260a1ee81ca6f8482)
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): `2.1.0`
- Python version: `3.6`
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**
Failed to convert tf model to tflite model when using `tf.cast` to convert `tf.uint8` to `tf.float32`.
Because MLIR-based converter refuses uint8 input. (But tflite's CAST ops support conversion of uint8 to float32!)

I need to convert input with uint8 to float32 in order to feed **integer input** to **float models** in order to exploit same interface with other **interger quantized models**.
(actually float models = post-training float models but this is not a concern)

**Describe the expected behavior**
Success to convert Input tensor with integer type to float type.

**Standalone code to reproduce the issue**
https://gist.github.com/kalaluthien/1cb86948d8f8e58260a1ee81ca6f8482

**Other info / logs** 
```
Traceback (most recent call last):
  File ""/usr/local/bin/toco_from_protos"", line 8, in <module>
    sys.exit(main())
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 93, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 56, in execute
    enable_mlir_converter)
Exception: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py:497:13: error: 'tfl.cast' op operand #0 must be tensor of 32-bit float or 1-bit integer or 32-bit integer or 64-bit integer values, but got 'tensor<1x14x14x3x!tf.quint8>'
            *args, **kwds))
            ^
```"
40257,Code for univariate_data() preprocessing function in LSTM Timeseries documentation example incorrect,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

https://www.tensorflow.org/tutorials/structured_data/time_series


## Description of issue (what needs changing):

The code for the univariate_data function in the example located at the above site creates a series of indexing and method not found errors. It can be resolved by the following code. 

def univariate_data(dataset, start_index, end_index, history_size, target_size):
  data = []
  labels = []

  start_index = start_index + history_size
  if end_index is None:
    end_index = len(dataset) - target_size

  for i in range(start_index, end_index):
    #indices = range(i-history_size, i)

    # Reshape data from (history_size,) to (history_size, 1)
    data.append(dataset[i-history_size:i].values.reshape(history_size, 1))
    labels.append(dataset[i+target_size])
  return np.array(data), np.array(labels)
"
40256,Can TensorFlow models be saved and restored with multiple optimizers using tf.train.Checkpoint?,"As per the [documentation](https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/train/Checkpoint), the recommendation for object-based checkpoints is to use `tf.train.Checkpoint` and one can simply use it as:

`    checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)`

But if there are multiple optimizers involved in the overall training process, how does one save and restore the model with all optimizers resuming from where they left off during training? I've attached a sample code below which uses two optimizers (i.e. L-BFGS and Adam). It can and save and restore the model using `tf.train.Saver` but this only saves the model without maintaining the optimizers from where they left off during training. Therefore any insights into adapting the below code to use `tf.train.Checkpoint` and save/restore it with multiple optimizers is sought, if possible at all. 

```
    import numpy as np 
    import tensorflow as tf
    
    path_save = '/home/mathewsa/stored_models/' #custom path to save network
    save_model = str(path_save)+""test_save.ckpt""
    end_it = 1000 #number of iterations
    frac_train = 1.0 #randomly sampled fraction of data to create training set
    frac_sample_train = 0.01 #randomly sampled fraction of data from training set to train in batches
    layers = [2, 20, 20, 20, 20, 20, 20, 20, 20, 1]
    
    #Generate training data
    len_data = 10000
    x_x = np.array([np.linspace(0.,1.,len_data)])
    x_y = np.array([np.linspace(0.,1.,len_data)]) 
    y_true = np.array([np.linspace(-1.,1.,len_data)])
    
    N_train = int(frac_train*len_data)
    idx = np.random.choice(len_data, N_train, replace=False)
    
    x_train = x_x.T[idx,:]
    y_train = x_y.T[idx,:] 
    v1_train = y_true.T[idx,:] 
    
    sample_batch_size = int(frac_sample_train*N_train)
    
    np.random.seed(1234)
    tf.set_random_seed(1234)
    import logging
    logging.getLogger('tensorflow').setLevel(logging.ERROR)
    tf.logging.set_verbosity(tf.logging.ERROR)
    
    class NeuralNet:
        def __init__(self, x, y, v1, layers):
            X = np.concatenate([x, y], 1)  
            self.lb = X.min(0)
            self.ub = X.max(0)
            self.X = X
            self.x = X[:,0:1]
            self.y = X[:,1:2] 
            self.v1 = v1 
            self.layers = layers 
            self.weights_v1, self.biases_v1 = self.initialize_NN(layers) 
            self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=False,
                                                         log_device_placement=False)) 
            self.x_tf = tf.placeholder(tf.float32, shape=[None, self.x.shape[1]])
            self.y_tf = tf.placeholder(tf.float32, shape=[None, self.y.shape[1]]) 
            self.v1_tf = tf.placeholder(tf.float32, shape=[None, self.v1.shape[1]])  
            self.v1_pred = self.net(self.x_tf, self.y_tf) 
            self.loss = tf.reduce_mean(tf.square(self.v1_tf - self.v1_pred)) 
            self.optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.loss,
                                                                    var_list=self.weights_v1+self.biases_v1,
                                                                    method = 'L-BFGS-B',
                                                                    options = {'maxiter': 50,
                                                                               'maxfun': 50000,
                                                                               'maxcor': 50,
                                                                               'maxls': 50,
                                                                               'ftol' : 1.0 * np.finfo(float).eps})
            self.optimizer_Adam = tf.train.AdamOptimizer()
            self.train_op_Adam_v1 = self.optimizer_Adam.minimize(self.loss, var_list=self.weights_v1+self.biases_v1) 
            self.saver = tf.train.Saver()
            init = tf.global_variables_initializer()  
            self.sess.run(init)
        def initialize_NN(self, layers):
            weights = []
            biases = []
            num_layers = len(layers)
            for l in range(0,num_layers-1):
                W = self.xavier_init(size=[layers[l], layers[l+1]])
                b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float32), dtype=tf.float32)
                weights.append(W)
                biases.append(b) 
            return weights, biases
        def xavier_init(self, size):
            in_dim = size[0]
            out_dim = size[1]
            xavier_stddev = np.sqrt(2/(in_dim + out_dim)) 
            return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), dtype=tf.float32)
        def neural_net(self, X, weights, biases):
            num_layers = len(weights) + 1
            H = 2.0*(X - self.lb)/(self.ub - self.lb) - 1.0
            for l in range(0,num_layers-2):
                W = weights[l]
                b = biases[l]
                H = tf.tanh(tf.add(tf.matmul(H, W), b))
            W = weights[-1]
            b = biases[-1]
            Y = tf.add(tf.matmul(H, W), b) 
            return Y
        def net(self, x, y): 
            v1_out = self.neural_net(tf.concat([x,y], 1), self.weights_v1, self.biases_v1)
            v1 = v1_out[:,0:1]
            return v1
        def callback(self, loss):
            global Nfeval
            print(str(Nfeval)+' - Loss in loop: %.3e' % (loss))
            Nfeval += 1
        def fetch_minibatch(self, x_in, y_in, v1_in, N_train_sample):  
            idx_batch = np.random.choice(len(x_in), N_train_sample, replace=False)
            x_batch = x_in[idx_batch,:]
            y_batch = y_in[idx_batch,:] 
            v1_batch = v1_in[idx_batch,:] 
            return x_batch, y_batch, v1_batch
        def train(self, end_it): 
            saver = tf.train.Saver()
            print('Stage 4.20')
            try:
                saver.restore(self.sess, save_model) 
                print('Using previous model')
            except:
                self.Nfeval = 1
                print('No previous model') 
            it = 0
            while it < end_it: 
                x_res_batch, y_res_batch, v1_res_batch = self.fetch_minibatch(self.x, self.y, self.v1, sample_batch_size) # Fetch residual mini-batch
                tf_dict = {self.x_tf: x_res_batch, self.y_tf: y_res_batch,
                           self.v1_tf: v1_res_batch}
                self.sess.run(self.train_op_Adam_v1, tf_dict)
                self.optimizer.minimize(self.sess,
                                        feed_dict = tf_dict,
                                        fetches = [self.loss],
                                        loss_callback = self.callback) 
                it = it + 1
            self.save_path = saver.save(self.sess, save_model)
            print('Finishing up training and saving as: ') 
            print(save_model) 
        def restore_model(self, path_full_saved):
            saver = tf.train.Saver()
            print('Stage 4.20')
            try:
                saver.restore(self.sess, str(path_full_saved))
                print('Using previous model')
            except:
                print('No previous model')
        def predict(self, x_star, y_star): 
            tf_dict = {self.x_tf: x_star, self.y_tf: y_star}
            v1_star = self.sess.run(self.v1_pred, tf_dict)  
            return v1_star
    
    model = NeuralNet(x_train, y_train, v1_train, layers)
     
    Nfeval = 1
    model.train(end_it)
```"
40255,Collect runtime information when using tf.function,"**System information**
- TensorFlow version (you are using): TF2.2
- Are you willing to contribute it (Yes/No):
Yes


**Describe the feature and the current behavior/state.**
In tf1.x, it is possible to use `RunOptions` and `RunMetadata` to get the runtime information for a single run. I wonder if it is possible to achieve the same functionality in tf2.x `tf.function`? I understand we have the beautiful profiling tool introduced in tf2.2, but it would be better if we can get the raw information besides viewing them through tensorboard. 
**Will this change the current api? How?**
It probably will. This may need to add a few more arguments to the function wrapped by `tf.function`.
**Who will benefit with this feature?**
The developer who may need the raw runtime information to tune the model and help make the inherent optimization in tensorflow better.
**Any Other info.**
Not yet."
40253,Difference of 0.5 factor compared to Research Paper in Soft NMS implementation,"Hi,

I believe the below lines are for Gaussian implementation of Soft-NMS, since the variable 'scale' is used in:
https://github.com/tensorflow/tensorflow/blob/7474d3c8345d663cea3f9132c47cd1bd342b0cec/tensorflow/core/kernels/non_max_suppression_op.cc#L189
https://github.com/tensorflow/tensorflow/blob/7474d3c8345d663cea3f9132c47cd1bd342b0cec/tensorflow/core/kernels/non_max_suppression_op.cc#L194

But in the research paper, no multiplier of 0.5 is mentioned. Please refer page number 4 of [https://arxiv.org/pdf/1704.04503.pdf](https://arxiv.org/pdf/1704.04503.pdf).

So if paper suggests ideal sigma value of 0.5, should I configure value of 0.25 instead?"
40252,Support including tensorflow directly in bazel WORKSPACEs,"We recently started including tensorflow in our bazel based iOS builds. Because of the currently required `./configure` step we cannot include it directly in our WORKSPACE and depend on targets as you can with some bazel dependencies, instead we have to pre-compile the targets we're interested in, and vendor them somehow into our build.

It would be great if the tensorflow build system provided a way to be able to depend on it directly from within other bazel workspaces.

Given the current job of the configure script this might be a very difficult request."
40251,`AttributeError due to '_TensorLike',"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NO
- TensorFlow installed from (source or binary):Binary
- TensorFlow version (use command below): tf-nightly-gpu latest
- Python version:3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:10.1
- GPU model and memory: gtx 1060

I'm getting the following error,

`AttributeError: module 'tensorflow.python.framework.ops' has no attribute '_TensorLike'
`
and this error points to the following line,

`    x = Conv2D(32, (3,3), strides=(1,1), padding='same', name='conv_1', use_bias=False)(input_image)
`
"
40250,tf.raw_ops.CollectivePermute bug caused by strange device numbering,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.2.0
- Python version: 3.6

**Describe the current behavior**
The 8 cores are numbered as 0,1,2,3,6,7,4,5 by CollectivePermute and  tensorflow.python.tpu.ops.tpu_ops.all_to_all.

**Describe the expected behavior**
They should be numbered as 0,1,2,3,4,5,6,7.

**Standalone code to reproduce the issue**
```
import tensorflow as tf

resolver = tf.distribute.cluster_resolver.TPUClusterResolver(
  tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])
tf.config.experimental_connect_to_cluster(resolver)
tf.tpu.experimental.initialize_tpu_system(resolver)
strategy = tf.distribute.experimental.TPUStrategy(resolver)

@tf.function
def step_fn():
  context = tf.distribute.get_replica_context()
  v = context.replica_id_in_sync_group
  v = tf.raw_ops.CollectivePermute(
      input=v,
      source_target_pairs=[[0,1],[1,2],[2,3],[3,4],[4,5],[5,6],[6,7],[7,0]])
  return v

ret = strategy.run(step_fn)
print(ret)
```

**Other info / logs** Include any logs or source code that would be helpful to
The following is the output. 
```
PerReplica:{
  0: tf.Tensor(5, shape=(), dtype=int32),
  1: tf.Tensor(0, shape=(), dtype=int32),
  2: tf.Tensor(1, shape=(), dtype=int32),
  3: tf.Tensor(2, shape=(), dtype=int32),
  4: tf.Tensor(7, shape=(), dtype=int32),
  5: tf.Tensor(4, shape=(), dtype=int32),
  6: tf.Tensor(3, shape=(), dtype=int32),
  7: tf.Tensor(6, shape=(), dtype=int32)
}
```
The correct output should be 7,0,1,2,3,4,5,6"
40249,The parameters for BatchNormalization are not updated,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Official Website
- TensorFlow version (use command below): 2.2.0
- Python version: 3.7.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: No
- GPU model and memory: No

**Describe the current behavior**

I am simply changing to codes from `tf.layers` to `tf.keras.layers`, based on the migration instructions on the official website. But it turned out the parameters for `tf.keras.layers.BatchNormalization` are not updated properly, while everything works fine for `tf.layers.BatchNormalization()`. I do not know the reasons.

**Describe the expected behavior**

The parameters for `tf.keras.layers.BatchNormalization` should be updated just like what have been done for `tf.layers.BatchNormalization`.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

Codes:
```
import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()
import numpy as np

def get_positive(batch_size):
    train_images = np.zeros((50, 28, 28, 1), dtype=np.float32) + 1.
    train_labels = np.int8(np.zeros((50, 1)) + 1)
    dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))
    dataset = dataset.repeat(1)
    dataset = dataset.batch(batch_size)
    dataset = dataset.prefetch(1)
    return dataset.make_one_shot_iterator().get_next()

def get_negative(batch_size):
    train_images = np.zeros((50, 28, 28, 1), dtype=np.float32)
    train_labels = np.int8(np.zeros((50, 1)))
    dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))
    dataset = dataset.repeat(1)
    dataset = dataset.batch(batch_size)
    dataset = dataset.prefetch(1)
    return dataset.make_one_shot_iterator().get_next()

def tf_model(feature, is_training):
    with tf.variable_scope(""tf_model"", reuse=tf.AUTO_REUSE):
        net = tf.layers.Conv2D(
            8, (3, 3), strides=(2, 2),
            activation=tf.nn.relu)(feature)  # 13x13x8
        net = tf.layers.BatchNormalization()(net, is_training)
        net = tf.layers.Conv2D(
            1, (3, 3), strides=(2, 2), activation=tf.nn.relu)(net)  # 6x6x1
        net = tf.layers.Flatten()(net)  # 36
        net = tf.layers.Dense(1)(net)
        return net

def tf_keras_model(feature, is_training):
    with tf.variable_scope(""tf_model"", reuse=tf.AUTO_REUSE):
        net = tf.keras.layers.Conv2D(
            8, (3, 3), strides=(2, 2),
            activation=tf.nn.relu)(feature)  # 13x13x8
        net = tf.keras.layers.BatchNormalization()(net, is_training)
        net = tf.keras.layers.Conv2D(
            1, (3, 3), strides=(2, 2), activation=tf.nn.relu)(net)  # 6x6x1
        net = tf.keras.layers.Flatten()(net)  # 36
        net = tf.keras.layers.Dense(1)(net)
        return net

def get_bn_vars(collection):
    moving_mean, moving_variance = None, None
    for var in collection:
        name = var.name.lower()
        if ""variance"" in name:
            moving_variance = var
        if ""mean"" in name:
            moving_mean = var

    if moving_mean is not None and moving_variance is not None:
        return moving_mean, moving_variance
    raise ValueError(""Unable to find moving mean and variance"")

def main_layers(case):
    positive, positive_labels = get_positive(10)
    negative, negative_labels = get_negative(10)

    model_true = tf_model(positive, True)

    loss = tf.losses.sigmoid_cross_entropy(positive_labels, model_true)
    if case == 2:
        model_false = tf_model(negative, True)
        loss += tf.losses.sigmoid_cross_entropy(negative_labels, model_false)

    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)
    with tf.control_dependencies(update_ops):
        train_op = tf.train.GradientDescentOptimizer(1e-3).minimize(loss)

    mean, variance = get_bn_vars(tf.global_variables())
    init = tf.global_variables_initializer()
    with tf.Session() as sess:
        sess.run(init)
        while True:
            try:
                loss_value, _ = sess.run([loss, train_op])
                print(""loss: "", loss_value)
            except tf.errors.OutOfRangeError:
                break
        print(sess.run([mean, variance]))

def main_tf_keras_layers(case):
    tf.keras.backend.set_learning_phase(True)
    positive, positive_labels = get_positive(10)
    negative, negative_labels = get_negative(10)

    model_true = tf_keras_model(positive, True)

    loss = tf.losses.sigmoid_cross_entropy(positive_labels, model_true)
    if case == 2:
        model_false = tf_model(negative, True)
        loss += tf.losses.sigmoid_cross_entropy(negative_labels, model_false)

    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)
    with tf.control_dependencies(update_ops):
        train_op = tf.train.GradientDescentOptimizer(1e-3).minimize(loss)

    mean, variance = get_bn_vars(tf.global_variables())
    init = tf.global_variables_initializer()
    with tf.Session() as sess:
        sess.run(init)
        while True:
            try:
                loss_value, _ = sess.run([loss, train_op])
                print(""loss: "", loss_value)
            except tf.errors.OutOfRangeError:
                break
        print(sess.run([mean, variance]))
```

If we run `main_layers(1)`, we would get:
```
loss:  0.69315034
loss:  0.6928972
loss:  0.69264734
loss:  0.6923976
loss:  0.6921481
[array([0.        , 0.        , 0.        , 0.01786391, 0.02162646,
       0.        , 0.00420831, 0.        ], dtype=float32), array([0.95099014, 0.95099014, 0.95099014, 0.95099014, 0.95099014,
       0.95099014, 0.95099014, 0.95099014], dtype=float32)]
```

However, if we run `main_tf_keras_layers(1)`, we would get:
```
loss:  0.6930456
loss:  0.69101626
loss:  0.688996
loss:  0.68698376
loss:  0.68497455
[array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)]
```

It turns out that parameters for `tf.keras.layers.BatchNormalization` are not updated properly. They should be expected to be similar to  `tf.layers.BatchNormalization`.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40248, Error while reading resource variable _AnonymousVar117 from Container while training with colab,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): colab
- TensorFlow version (use command below): 2.3
- Python version:3.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: colab
- GPU model and memory: gtx 1060


I'm getting the following error,
```

FailedPreconditionError                   Traceback (most recent call last)
<ipython-input-6-daf439831857> in <module>()
     89 
     90 if __name__ == '__main__':
---> 91     _main_()

11 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     58     ctx.ensure_initialized()
     59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
---> 60                                         inputs, attrs, num_outputs)
     61   except core._NotOkStatusException as e:
     62     if name is not None:

FailedPreconditionError:  Error while reading resource variable _AnonymousVar117 from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/_AnonymousVar117/N10tensorflow3VarE does not exist.
	 [[node loss/lambda_2_loss/custom_loss/Less_2/ReadVariableOp (defined at /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3009) ]] [Op:__inference_keras_scratch_graph_19741]

Function call stack:
keras_scratch_graph
```

The error log is pointless that it doesn't even tell me where the error could be in my code. "
40247,Functional Keras API not getting converted using TFLiteTransferConverter in Model Personalization,"**Working on Colab**
- TensorFlow version: 2.2.0

## Error
While reading about PR **RFC: On-Device Training with TensorFlow**([https://github.com/tensorflow/community/pull/124](https://github.com/tensorflow/community/pull/124)), and trying to include 'train' option in convert(I know tflite currently does not support on-device training, but was curious to check how operations would look like), I am facing the following error:

```
InvalidArgumentError                      Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/importer.py in _import_graph_def_internal(graph_def, input_map, return_elements, validate_colocation_constraints, name, producer_op_list)
    496         results = c_api.TF_GraphImportGraphDefWithResults(
--> 497             graph._c_graph, serialized, options)  # pylint: disable=protected-access
    498         results = c_api_util.ScopedTFImportGraphDefResults(results)

InvalidArgumentError: Input 0 of node SGD/SGD/update_11/ResourceApplyGradientDescent was passed float from sequential/dense_1/BiasAdd/ReadVariableOp/resource:0 incompatible with expected resource.

During handling of the above exception, another exception occurred:

ValueError                                Traceback (most recent call last)
12 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/importer.py in _import_graph_def_internal(graph_def, input_map, return_elements, validate_colocation_constraints, name, producer_op_list)
    499       except errors.InvalidArgumentError as e:
    500         # Convert to ValueError for backwards compatibility.
--> 501         raise ValueError(str(e))
    502 
    503     # Create _DefinedFunctions for any imported functions.

ValueError: Input 0 of node SGD/SGD/update_11/ResourceApplyGradientDescent was passed float from sequential/dense_1/BiasAdd/ReadVariableOp/resource:0 incompatible with expected resource.
```

### Command used to run the converter or code if you’re using the Python API
**Model Description**
```
model = tf.keras.Sequential([tf.keras.layers.Conv2D(32, kernel_size=3, padding='same', activation='relu', input_shape=(32,32,3)),
                             tf.keras.layers.Conv2D(32, kernel_size=3, activation='relu', padding='same'),
                             tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),
                             tf.keras.layers.Conv2D(64, kernel_size=3, activation='relu', padding='same'),
                             tf.keras.layers.Conv2D(64, kernel_size=3, activation='relu', padding='same'),
                             tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),
                             tf.keras.layers.Flatten(),
                             tf.keras.layers.Dense(128, activation='relu'),
                             tf.keras.layers.Dense(10)])

model.compile(optimizer='sgd', loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), metrics=['accuracy'])
```

 **Convert Code**
```
_LOSS_FN = tf.keras.losses.CategoricalCrossentropy()
_OPTIM = tf.optimizers.SGD()

@tf.function(input_signature=[
    tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype),
    tf.TensorSpec(model.outputs[0].shape, model.outputs[0].dtype),
])
def train(x, y):
  with tf.GradientTape() as tape:
    prediction = model(x)
    loss = _LOSS_FN(prediction, y)
  gradients = tape.gradient(loss, model.trainable_variables)
  _OPTIM.apply_gradients(zip(gradients, model.trainable_variables))

concrete_func = train.get_concrete_function()

# convert to tflite
converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])
converted_tflite_model = converter.convert()
```

Can anyone please help me out with the error? "
40246,(Embedding python into c) ImportError: numpy.core.multiarray failed to import,"I am working on a project which is related to object detection and ocr.  I am using Ubuntu 18.04 and python 2.7, yolov3 for object detection and tesseract 5.0.0-alpha-692-g62ea for ocr. I have to embed python code that is for ocr into the c code which is for object detection. I wrote this C code and compile at the terminal by ""  sudo gcc code.c -lpython2.7  ""

#include </usr/include/python2.7/Python.h>

int main() {
Py_Initialize();
PyRun_SimpleString(""import sys; sys.path.append('.')"");
PyRun_SimpleString(""import ocr3;"");
PyRun_SimpleString(""print ocr3.myabs(2.0)"");
Py_Finalize();

return 0;
}

but it gives an error while running a.out:

ImportError: numpy.core.multiarray failed to import
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""./ocr3.py"", line 1, in <module>
    import cv2
  File ""/home/asus/.local/lib/python2.7/site-packages/cv2/__init__.py"", line 3, in <module>
    from .cv2 import *
ImportError: numpy.core.multiarray failed to import
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
NameError: name 'ocr3' is not defined


so, I tried another C code:

#include <stdio.h>
#include <ncurses.h>
#include </usr/local/include/python2.7/Python.h>

int main()
{
	char filename[] = ""ocr3.py"";
	FILE* fp;

	Py_Initialize();

	fp = _Py_fopen(filename, ""r"");
	PyRun_SimpleFile(fp, filename);

	Py_Finalize();
	return 0;
}
but again I have an issue while running a.out: "" code.c:(.text+0x3e): undefined reference to `_Py_fopen'  ""

Unfortunately, I could not find any solution. Can anyone help about the fix one of the these problems?"
40245,Tensorflow v2.2 build fails with cuda 10.2 TensorRT 7.0.0.11-1,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source build
- TensorFlow version: master branch
- Python version: 3.7.7
- Installed using virtualenv? pip? conda?: virtualenv
- Bazel version (if compiling from source): 3.0.0
- GCC/Compiler version (if compiling from source): 8.4.0
- CUDA/cuDNN version: CUDA 10.2 / cuDNN: 7.6.5
- GPU model and memory: Nvidia TITAN Xp

**Describe the problem**
Building TensorFlow master branch with option ``` bazel build --verbose_failures --config=opt --config=nonccl //tensorflow/tools/pip_package:build_pip_package ``` fails with the message shown below. I would very much appreciate any help in building this.


**Provide the exact sequence of commands / steps that you executed before running into the problem**
within the tensorflow master branch source directory, after standard ./configure (CUDA support enabled), below is the configuration.

```
You have bazel 3.0.0 installed.
Please specify the location of python. [Default is /import/home/xxxxx/Desktop/tf/bin/python3]: 


Found possible Python library paths:
  /import/home/xxxxxx/Desktop/tf/lib/python3.7/site-packages
Please input the desired Python library path to use.  Default is [/import/home/xxxxx/Desktop/tf/lib/python3.7/site-packages]

Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: 
No OpenCL SYCL support will be enabled for TensorFlow.

Do you wish to build TensorFlow with ROCm support? [y/N]: 
No ROCm support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: y
CUDA support will be enabled for TensorFlow.

Do you wish to build TensorFlow with TensorRT support? [y/N]: y
TensorRT support will be enabled for TensorFlow.

Found CUDA 10.2 in:
    /usr/local/cuda-10.2/targets/x86_64-linux/lib
    /usr/local/cuda-10.2/targets/x86_64-linux/include
Found cuDNN 7 in:
    /usr/lib/x86_64-linux-gnu
    /usr/include
Found TensorRT 7 in:
    /usr/lib/x86_64-linux-gnu
    /usr/include/x86_64-linux-gnu


Please specify a list of comma-separated CUDA compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus. Each capability can be specified as ""x.y"" or ""compute_xy"" to include both virtual and binary GPU code, or as ""sm_xy"" to only include the binary code.
Please note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only supports compute capabilities >= 3.5 [Default is: 6.1,6.1]: 6.1


Do you want to use clang as CUDA compiler? [y/N]: 
nvcc will be used as CUDA compiler.

Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: /usr/bin/gcc-8


Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native -Wno-sign-compare]: 


Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: 
Not configuring the WORKSPACE for Android builds.

Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details.
	--config=mkl         	# Build with MKL support.
	--config=monolithic  	# Config for mostly static monolithic build.
	--config=ngraph      	# Build with Intel nGraph support.
	--config=numa        	# Build with NUMA support.
	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects.
	--config=v2          	# Build TensorFlow 2.x instead of 1.x.
Preconfigured Bazel build configs to DISABLE default on features:
	--config=noaws       	# Disable AWS S3 filesystem support.
	--config=nogcp       	# Disable GCP support.
	--config=nohdfs      	# Disable HDFS support.
	--config=nonccl      	# Disable NVIDIA NCCL support.
Configuration finished
```

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
```
INFO: From ProtoCompile tensorflow/core/framework/tensor.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/framework/types.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/example/example_parser_configuration.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/framework/reader_base.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/profiler/profiler_options.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/protobuf/named_tensor.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/framework/summary.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/util/event.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/framework/node_def.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/framework/tensor_slice.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/util/saved_tensor_slice.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/framework/versions.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/util/memmapped_file_system.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/protobuf/saver.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/protobuf/transport_options.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/protobuf/trackable_object_graph.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/protobuf/data/experimental/snapshot.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/framework/api_def.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/protobuf/control_flow.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/protobuf/debug.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/protobuf/cluster.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/protobuf/meta_graph.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/protobuf/tensor_bundle.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/protobuf/tensorflow_server.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/protobuf/struct.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/protobuf/saved_object_graph.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/protobuf/debug_event.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/protobuf/rewriter_config.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/protobuf/verifier_config.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/protobuf/remote_tensor_handle.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/protobuf/config.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/protobuf/queue_runner.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/protobuf/device_properties.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/protobuf/graph_debug_info.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/protobuf/device_filters.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/protobuf/saved_model.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/protobuf/bfc_memory_map.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/framework/allocation_description.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/lib/core/error_codes.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/framework/device_attributes.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/framework/attr_value.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/framework/function.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/framework/cost_graph.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/framework/graph_transfer_info.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/framework/log_memory.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/framework/variable.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/framework/op_def.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/framework/step_stats.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/framework/kernel_def.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/framework/graph.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/framework/remote_fused_graph_execute_info.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/framework/tensor_description.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/util/test_log.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/profiler/protobuf/xplane.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/stream_executor/dnn.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/core/grappler/costs/op_performance_data.pb.h [for host]:
bazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.
ERROR: /import/home/xxxxx/Desktop/tensorflow/tensorflow/core/util/proto/BUILD:64:1: C++ compilation of rule '//tensorflow/core/util/proto:proto_utils' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command 
  (cd /import/home/xxxxx/.cache/bazel/_bazel_xxxxx/b8f3678e231ee59114f75ff5566fbc57/execroot/org_tensorflow && \
  exec env - \
    LD_LIBRARY_PATH=:/usr/local/cuda/lib64:/usr/local/cuda/lib64 \
    PATH=/home/xxxxx/bin:/home/xxxxx/.local/bin:/import/home/xxxxx/Desktop/tf/bin:/opt/CD-adapco/13.04.011-R8/STAR-View+13.04.011/bin:/opt/CD-adapco/13.04.011-R8/STAR-CCM+13.04.011-R8/star/bin:/opt/CD-adapco/13.04.011-R8/STAR-View+13.04.011/bin:/opt/CD-adapco/13.04.011-R8/STAR-CCM+13.04.011-R8/star/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/usr/local/cuda/bin:/work/star/13.04.011-R8/STAR-CCM+13.04.011-R8/star/bin:/snap/bin:/home/xxxxx/bin \
    PWD=/proc/self/cwd \
  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -MD -MF bazel-out/host/bin/tensorflow/core/util/proto/_objs/proto_utils/proto_utils.pic.d '-frandom-seed=bazel-out/host/bin/tensorflow/core/util/proto/_objs/proto_utils/proto_utils.pic.o' -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/host/bin -iquote external/com_google_absl -iquote bazel-out/host/bin/external/com_google_absl -iquote external/eigen_archive -iquote bazel-out/host/bin/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/host/bin/external/local_config_sycl -iquote external/nsync -iquote bazel-out/host/bin/external/nsync -iquote external/gif -iquote bazel-out/host/bin/external/gif -iquote external/libjpeg_turbo -iquote bazel-out/host/bin/external/libjpeg_turbo -iquote external/com_google_protobuf -iquote bazel-out/host/bin/external/com_google_protobuf -iquote external/com_googlesource_code_re2 -iquote bazel-out/host/bin/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/host/bin/external/farmhash_archive -iquote external/fft2d -iquote bazel-out/host/bin/external/fft2d -iquote external/highwayhash -iquote bazel-out/host/bin/external/highwayhash -iquote external/zlib -iquote bazel-out/host/bin/external/zlib -iquote external/local_config_cuda -iquote bazel-out/host/bin/external/local_config_cuda -iquote external/local_config_tensorrt -iquote bazel-out/host/bin/external/local_config_tensorrt -Ibazel-out/host/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual -Ibazel-out/host/bin/external/local_config_tensorrt/_virtual_includes/tensorrt_headers -isystem external/eigen_archive -isystem bazel-out/host/bin/external/eigen_archive -isystem external/nsync/public -isystem bazel-out/host/bin/external/nsync/public -isystem external/gif -isystem bazel-out/host/bin/external/gif -isystem external/com_google_protobuf/src -isystem bazel-out/host/bin/external/com_google_protobuf/src -isystem external/farmhash_archive/src -isystem bazel-out/host/bin/external/farmhash_archive/src -isystem external/zlib -isystem bazel-out/host/bin/external/zlib -isystem external/local_config_cuda/cuda -isystem bazel-out/host/bin/external/local_config_cuda/cuda -isystem external/local_config_cuda/cuda/cuda/include -isystem bazel-out/host/bin/external/local_config_cuda/cuda/cuda/include -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -fPIC -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -fno-omit-frame-pointer -no-canonical-prefixes -fno-canonical-system-headers -g0 -O2 -ffunction-sections -fdata-sections -g0 '-march=native' -g0 '-std=c++14' -c tensorflow/core/util/proto/proto_utils.cc -o bazel-out/host/bin/tensorflow/core/util/proto/_objs/proto_utils/proto_utils.pic.o)
Execution platform: @local_execution_config_platform//:platform
In file included from /usr/include/c++/8/cmath:45,
                 from external/com_google_absl/absl/time/time.h:78,
                 from ./tensorflow/core/util/proto/proto_utils.h:21,
                 from tensorflow/core/util/proto/proto_utils.cc:16:
/usr/include/x86_64-linux-gnu/bits/mathcalls.h:289:1: internal compiler error: Segmentation fault
 __MATHCALL (rint,, (_Mdouble_ __x));
 ^~~~~~~~~~
Please submit a full bug report,
with preprocessed source if appropriate.
See <file:///usr/share/doc/gcc-8/README.Bugs> for instructions.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
ERROR: /import/home/xxxxx/Desktop/tensorflow/tensorflow/python/tools/BUILD:226:1 C++ compilation of rule '//tensorflow/core/util/proto:proto_utils' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command 
  (cd /import/home/xxxxx/.cache/bazel/_bazel_xxxxx/b8f3678e231ee59114f75ff5566fbc57/execroot/org_tensorflow && \
  exec env - \
    LD_LIBRARY_PATH=:/usr/local/cuda/lib64:/usr/local/cuda/lib64 \
    PATH=/home/xxxxx/bin:/home/xxxxx/.local/bin:/import/home/xxxxx/Desktop/tf/bin:/opt/CD-adapco/13.04.011-R8/STAR-View+13.04.011/bin:/opt/CD-adapco/13.04.011-R8/STAR-CCM+13.04.011-R8/star/bin:/opt/CD-adapco/13.04.011-R8/STAR-View+13.04.011/bin:/opt/CD-adapco/13.04.011-R8/STAR-CCM+13.04.011-R8/star/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/usr/local/cuda/bin:/work/star/13.04.011-R8/STAR-CCM+13.04.011-R8/star/bin:/snap/bin:/home/xxxxx/bin \
    PWD=/proc/self/cwd \
  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -MD -MF bazel-out/host/bin/tensorflow/core/util/proto/_objs/proto_utils/proto_utils.pic.d '-frandom-seed=bazel-out/host/bin/tensorflow/core/util/proto/_objs/proto_utils/proto_utils.pic.o' -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/host/bin -iquote external/com_google_absl -iquote bazel-out/host/bin/external/com_google_absl -iquote external/eigen_archive -iquote bazel-out/host/bin/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/host/bin/external/local_config_sycl -iquote external/nsync -iquote bazel-out/host/bin/external/nsync -iquote external/gif -iquote bazel-out/host/bin/external/gif -iquote external/libjpeg_turbo -iquote bazel-out/host/bin/external/libjpeg_turbo -iquote external/com_google_protobuf -iquote bazel-out/host/bin/external/com_google_protobuf -iquote external/com_googlesource_code_re2 -iquote bazel-out/host/bin/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/host/bin/external/farmhash_archive -iquote external/fft2d -iquote bazel-out/host/bin/external/fft2d -iquote external/highwayhash -iquote bazel-out/host/bin/external/highwayhash -iquote external/zlib -iquote bazel-out/host/bin/external/zlib -iquote external/local_config_cuda -iquote bazel-out/host/bin/external/local_config_cuda -iquote external/local_config_tensorrt -iquote bazel-out/host/bin/external/local_config_tensorrt -Ibazel-out/host/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual -Ibazel-out/host/bin/external/local_config_tensorrt/_virtual_includes/tensorrt_headers -isystem external/eigen_archive -isystem bazel-out/host/bin/external/eigen_archive -isystem external/nsync/public -isystem bazel-out/host/bin/external/nsync/public -isystem external/gif -isystem bazel-out/host/bin/external/gif -isystem external/com_google_protobuf/src -isystem bazel-out/host/bin/external/com_google_protobuf/src -isystem external/farmhash_archive/src -isystem bazel-out/host/bin/external/farmhash_archive/src -isystem external/zlib -isystem bazel-out/host/bin/external/zlib -isystem external/local_config_cuda/cuda -isystem bazel-out/host/bin/external/local_config_cuda/cuda -isystem external/local_config_cuda/cuda/cuda/include -isystem bazel-out/host/bin/external/local_config_cuda/cuda/cuda/include -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -fPIC -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -fno-omit-frame-pointer -no-canonical-prefixes -fno-canonical-system-headers -g0 -O2 -ffunction-sections -fdata-sections -g0 '-march=native' -g0 '-std=c++14' -c tensorflow/core/util/proto/proto_utils.cc -o bazel-out/host/bin/tensorflow/core/util/proto/_objs/proto_utils/proto_utils.pic.o)
Execution platform: @local_execution_config_platform//:platform
INFO: Elapsed time: 727.625s, Critical Path: 23.83s
INFO: 641 processes: 641 local.
FAILED: Build did NOT complete successfully
```"
40244,TF2.2: MultiWorkerMirroredStrategy doesn't assign workers correctly and training doesn't start,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):binary via PIP
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1/7.6.5
- GPU model and memory: 960M/4GB

**Describe the current behavior**
Have custom training script set up with strategy MultiWorkerMirroredStrategy, in this case trying on 2 separate workers using a docker image.
The script crashes on both workers:
worker 0:
```
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Identity: {{node Identity}} was explicitly assigned to /job:localhost/replica:0/task:0/device:CPU:0 but available devices are [ /job:worker/replica:0/task:0/device:CPU:0, /job:worker/replica:0/task:0/device:GPU:0, /job:worker/replica:0/task:0/device:XLA_CPU:0, /job:worker/replica:0/task:0/device:XLA_GPU:0 ]. Make sure the device specification refers to a valid device.
	 [[Identity]] [Op:__inference_distributed_train_step_14920]
2020-06-07 16:08:53.189763: W tensorflow/core/common_runtime/eager/context.cc:447] Unable to destroy server_ object, so releasing instead. Servers don't support clean shutdown.
```

worker 1:
```
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Identity: {{node Identity}} was explicitly assigned to /job:localhost/replica:0/task:0/device:CPU:0 but available devices are [ /job:worker/replica:0/task:1/device:CPU:0, /job:worker/replica:0/task:1/device:GPU:0, /job:worker/replica:0/task:1/device:XLA_CPU:0, /job:worker/replica:0/task:1/device:XLA_GPU:0 ]. Make sure the device specification refers to a valid device.
	 [[Identity]] [Op:__inference_distributed_train_step_14761]
2020-06-07 16:08:53.186955: W tensorflow/core/common_runtime/eager/context.cc:447] Unable to destroy server_ object, so releasing instead. Servers don't support clean shutdown.
```

**Describe the expected behavior**
The script starts training on all workers.

**Standalone code to reproduce the issue**
I don't have stand-alone code, but I've attached my training script. It was built following documentation and start command includes the TF_CONFIG environment set, for example on worker 0:
```
TF_CONFIG='{""cluster"": {""worker"": [""192.168.1.130:12345"", ""192.168.1.131:12345""]}, ""task"":{""index"": 0, ""type"": ""worker""}}' python3 multi_train.py --data_root /datasets --config configs/v53.cfg
```

**Other info / logs**
training script - [multi_train_py.txt](https://github.com/tensorflow/tensorflow/files/4742432/multi_train_py.txt)
complete log of worker 0 (similar to worker 1) - [complete_log.txt](https://github.com/tensorflow/tensorflow/files/4742437/complete_log.txt)

"
40242,Tensorflow 2.x and tf.compat issues,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NO
- TensorFlow installed from (source or binary):Binary
- TensorFlow version (use command below): 2.2
- Python version:3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:10.1
- GPU model and memory: gtx 1060


The Tensorflow's latest version is a complete tragedy. It just breaks each and every functions that has been written with the older version of tensorflow. The eager execution is the pain in the neck. It just throws the countless meaningless error. I got `tf.function-decorated Value error`. I fixed it and now I'm getting the following error,

```
tensorflow.python.eager.core._SymbolicException: Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'Conv2DBackpropInput_1:0' shape=(1, 13, 13, 1280) dtype=float32>]
2020-06-07 16:49:58.682705: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.
	 [[{{node PyFunc}}]]

```

```
Disabling eager execution throws the following error,

ValueError: Operation name: ""AssignAddVariableOp""
op: ""AssignAddVariableOp""
input: ""AssignAddVariableOp/Variable""
input: ""Const""
attr {
  key: ""dtype""
  value {
    type: DT_FLOAT
  }
}
 is not an element of this graph.
```

**Please regularize the code base before even trying to issue a vendor certificate aka TensorFlow certified developer certificate**
"
40239,Tensorflow Lite Converter Raise Issue,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): binary
- TensorFlow version (or github SHA if from source): 2.2.0

**Failure details**
I try to convert TF model to TFlite but converter raise ERROR
 Here is my code :

model = tf.keras.models.load_model(load_path, custom_objects={'loss_dice_coefficient_error': loss_dice_coefficient_error,
                                             'dice_coefficient': dice_coefficient,
                                             'jaccard_coef': jaccard_coef})
    
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    converter.experimental_new_converter = True
    converter.allow_custom_ops = True
    
    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
                                       tf.lite.OpsSet.SELECT_TF_OPS]
        
    tflite_model = converter.convert()



**Any other info / logs**
Traceback (most recent call last):
  File ""G:\AI_library_3\Create_Lite_Model.py"", line 89, in <module>
    load_all_models()
  File ""G:\AI_library_3\Create_Lite_Model.py"", line 81, in load_all_models
    load_model_from_path_convert_to_lite(models_root, ""LV_ED"", lite_models_root)
  File ""G:\AI_library_3\Create_Lite_Model.py"", line 73, in load_model_from_path_convert_to_lite
    tflite_model = converter.convert()
  File ""C:\Users\admin\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\lite\python\lite.py"", line 518, in convert
    **converter_kwargs)
  File ""C:\Users\admin\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\lite\python\convert.py"", line 496, in toco_convert_impl
    enable_mlir_converter=enable_mlir_converter)
  File ""C:\Users\admin\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\lite\python\convert.py"", line 227, in toco_convert_protos
    raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: See console for info.
2020-06-07 17:30:36.154029: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found
2020-06-07 17:30:36.154352: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2020-06-07 17:30:40.516629: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:144] Ignored output_format.
2020-06-07 17:30:40.516872: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:147] Ignored drop_control_dependency.
2020-06-07 17:30:40.566746: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2020-06-07 17:30:40.628297: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1b479ed4240 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-06-07 17:30:40.628652: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-06-07 17:30:40.642470: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-06-07 17:30:40.691199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GT 610 computeCapability: 2.1
coreClock: 1.62GHz coreCount: 1 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 9.94GiB/s
2020-06-07 17:30:40.692419: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found
2020-06-07 17:30:40.693284: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cublas64_10.dll'; dlerror: cublas64_10.dll not found
2020-06-07 17:30:40.694129: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cufft64_10.dll'; dlerror: cufft64_10.dll not found
2020-06-07 17:30:40.694962: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'curand64_10.dll'; dlerror: curand64_10.dll not found
2020-06-07 17:30:40.695842: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cusolver64_10.dll'; dlerror: cusolver64_10.dll not found
2020-06-07 17:30:40.696682: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cusparse64_10.dll'; dlerror: cusparse64_10.dll not found
2020-06-07 17:30:40.697563: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudnn64_7.dll'; dlerror: cudnn64_7.dll not found
2020-06-07 17:30:40.697849: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1598] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-06-07 17:30:40.744757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-06-07 17:30:40.745082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-06-07 17:30:40.745282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-06-07 17:30:40.756749: I tensorflow/compiler/xla/service/platform_util.cc:139] StreamExecutor cuda device (0) is of insufficient compute capability: 3.5 required, device is 2.1
2020-06-07 17:30:40.757309: I tensorflow/compiler/jit/xla_gpu_device.cc:161] Ignoring visible XLA_GPU_JIT device. Device number is 0, reason: Internal: no supported devices found for platform CUDA
loc(callsite(""model_1/conv2d_transpose_1/atrous_conv2d_transpose/Conv2DBackpropInput""(""C:\Users\admin\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\eager\def_function.py"":865:0) at callsite(""C:\Users\admin\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\eager\def_function.py"":959:0 at callsite(""C:\Users\admin\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\lite\python\lite.py"":435:0 at callsite(""G:\AI_library_3\Create_Lite_Model.py"":66:0 at callsite(""G:\AI_library_3\Create_Lite_Model.py"":81:0 at callsite(""G:\AI_library_3\Create_Lite_Model.py"":89:0 at callsite(""C:\Users\admin\AppData\Local\Programs\Python\Python36\lib\idlelib\run.py"":474:0 at callsite(""C:\Users\admin\AppData\Local\Programs\Python\Python36\lib\idlelib\run.py"":144:0 at ""<string>"":1:0))))))))): **error: 'tfl.transpose_conv' op expect output type tensor<9x29x38x64xf32>, got tensor<?x?x?x?xf32>**
Traceback (most recent call last):

  File ""c:\users\admin\appdata\local\programs\python\python36\lib\runpy.py"", line 193, in _run_module_as_main

    ""__main__"", mod_spec)

  File ""c:\users\admin\appdata\local\programs\python\python36\lib\runpy.py"", line 85, in _run_code

    exec(code, run_globals)

  File ""C:\Users\admin\AppData\Local\Programs\Python\Python36\Scripts\toco_from_protos.exe\__main__.py"", line 9, in <module>

  File ""c:\users\admin\appdata\local\programs\python\python36\lib\site-packages\tensorflow\lite\toco\python\toco_from_protos.py"", line 93, in main

    app.run(main=execute, argv=[sys.argv[0]] + unparsed)

  File ""c:\users\admin\appdata\local\programs\python\python36\lib\site-packages\tensorflow\python\platform\app.py"", line 40, in run

    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)

  File ""c:\users\admin\appdata\local\programs\python\python36\lib\site-packages\absl\app.py"", line 299, in run

    _run_main(main, args)

  File ""c:\users\admin\appdata\local\programs\python\python36\lib\site-packages\absl\app.py"", line 250, in _run_main

    sys.exit(main(argv))

  File ""c:\users\admin\appdata\local\programs\python\python36\lib\site-packages\tensorflow\lite\toco\python\toco_from_protos.py"", line 56, in execute

    enable_mlir_converter)

Exception: C:\Users\admin\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\eager\def_function.py:865:9: error: 'tfl.transpose_conv' op expect output type tensor<9x29x38x64xf32>, got tensor<?x?x?x?xf32>

        self._initialize(args, kwargs, add_initializers_to=initializers)

        ^

C:\Users\admin\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\eager\def_function.py:959:5: note: called from

    concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)

    ^

C:\Users\admin\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\lite\python\lite.py:435:5: note: called from

    concrete_func = func.get_concrete_function()

    ^

G:\AI_library_3\Create_Lite_Model.py:66:5: note: called from

    converter = tf.lite.TFLiteConverter.from_keras_model(model)

    ^

G:\AI_library_3\Create_Lite_Model.py:81:5: note: called from

    load_model_from_path_convert_to_lite(models_root, ""LV_ED"", lite_models_root)

    ^

G:\AI_library_3\Create_Lite_Model.py:89:1: note: called from

load_all_models()    

^

C:\Users\admin\AppData\Local\Programs\Python\Python36\lib\idlelib\run.py:474:17: note: called from

                exec(code, self.locals)

                ^

C:\Users\admin\AppData\Local\Programs\Python\Python36\lib\idlelib\run.py:144:17: note: called from

                ret = method(*args, **kwargs)

                ^

<string>: note: called from

"
40238,Unhandled Rejection (Error): No backend found in registry in a React App,"Hi, 

 System Specifications:
- Fedora 32
- React JS 
- npm
- Tensorflow-mobilenet

Behavior:

This basic React App using mobilenet from @tensorflow-models was working fine a few months ago. Now I am getting Unhandled Rejection error.

```
import * as mobilenet from '@tensorflow-models/mobilenet';
import photo from './assets/file.jpg';
import { loadImage } from 'canvas';
import React, { useState } from 'react';

const App = () => {
	const [res, handleRes] = useState([]);
	const myPhoto = () => {
		return <img src={photo} alt=""foto ""></img>;
	};
	const myPrediction = async () => {
		const loadModel = await mobilenet.load();
		const pic = await loadImage(photo);
		const pred = await loadModel.classify(pic);
		console.log(pred);
		handleRes(pred);
	};

	return (
		<div className=""App"">
			{myPhoto()}
			<button onClick={(e) => myPrediction(e)}>Predict</button>
			{res.map((e, k) => (
				<li key={k}>
					<h1>{e.className + ': ' + Math.round(e.probability * 100) + '%'}</h1>
				</li>
			))}
		</div>
	);
};

export default App;
```
This basic example should make a prediction on the uploaded image.

I made a post here https://programandoconro.wordpress.com/2019/12/30/react-app-para-clasificacion-de-imagenes-con-machine-learning/

Full App code is here https://github.com/programandoconro/Image-Classification-ML-App (not working either).
![file](https://user-images.githubusercontent.com/50117686/83968945-8f552600-a8c4-11ea-8928-131356e1637b.jpg)

Fortunately,  deployed App still working  https://programandoconro.github.io/Image-Classification-ML-App/

Sample image attached.

Thank you, "
40237,Machine translation using Seq2Seq with attention by using LSTM instead of GRU,"Hello,
I am using the template in tutorial 'Machine translation using Seq2Seq with attention'. However, seq2seq is built on GRU.(The link is https://www.tensorflow.org/tutorials/text/nmt_with_attention) 

Could you please provide a template that Machine translation using Seq2Seq with attention using LSTM instead of GRU?

"
40236,ModuleNotFoundError: No module named 'tensorflow.contrib',"I want to train from tensorflow, but I always get error on this bug.
from tensorflow.contrib import data as tf_data
ModuleNotFoundError: No module named 'tensorflow.contrib'
I have try install lower version of tensorflow, but still didn't work.
environment:macos python3.7 tensorflow2.2.0"
40234,error with tf.strings.to_number(),"This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.
"
40233,Encountered fatal Python error with TFLite Experimental Converter,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `tensorflow/tensorflow:latest-gpu` Docker image on Ubuntu 20.04 host on GCP Compute Engine VM
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: 3.6.9
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: 10.2 (Using Docker TensorFlow GPU image)
- GPU model and memory: Tesla V100-SXM2-16GB

**Describe the current behavior**
I'm using the new QAT API demonstrated in the docs [here](https://www.tensorflow.org/model_optimization/guide/quantization/training_example). Then I'm taking the resulting model and converting it to TFLite, again referencing the docs. Everything works as advertised until converting the model, where I encounter an error (see logs below).

**Describe the expected behavior**
I expected to get a converted model I could save as a `tflite` binary. I was only able to do this when explicitly disabling the experimental converter.

**Standalone code to reproduce the issue**
I don't have this available at the moment- I will try to provide this when able. In the meantime, this is the code snippet surrounding the problem. Let me know if this is insufficient.

```
model = tfmot.quantization.keras.quantize_model(model)
model.compile(optimizer=optimizer, loss=loss)
history = model.fit(train_dataset, epochs=FLAGS.epochs, callbacks=callbacks, validation_data=val_dataset)

converter = tf.lite.TFLiteConverter.from_keras_model(model)
# converter.experimental_new_converter = False # Must uncomment this line to convert successfully
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()

with open(""output.tflite"", 'wb') as f:
    f.write(tflite_model)
```

Our model is made up of the following Keras layers: Add, Concatenate, Conv2D, Input, Lambda, LeakyReLU, MaxPool2D, UpSampling2D, ZeroPadding2D, and BatchNormalization organized into several sub-models. Each submodel is quantized on its own because the `tfmot` API does not have native support for submodels. [This ](https://github.com/tensorflow/model-optimization/issues/377#issuecomment-623586866) was the recommended workaround until that is added.

**Other info / logs**
It's a long one, here is what was spit out. All lines following line 59 were output together at the end. From my point of view the console didn't update from line 59 for several minutes until it all appeared together. I checked `nvidia-smi` while I waited and noticed GPU VRAM usage was at 100% (almost 16GB was being used by the Python process running this script) but GPU utilization was at 0%. Checking `htop` showed RAM and CPU usage very low at the time.

https://pastebin.com/LMNefb3V
"
40232,Request to include tf.depth_to_space,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary):  
- TensorFlow version (or github SHA if from source): 1.14


**Provide the text output from tflite_convert**

```
ValueError: Didn't find custom op for name 'DEPTH_TO_SPACE' with version 1
Registration failed.
```

**Standalone code to reproduce the issue** 
import tensorflow as tf
graph_def_file = ""frozen_model.pb""
input_arrays = [""Placeholder""]
output_arrays = [""DepthToSpace""]

converter = tf.lite.TFLiteConverter.from_frozen_graph(
  graph_def_file, 
  input_arrays, 
  output_arrays, 
  input_shapes={'Placeholder':[200,200,200,4]}
  )
converter.allow_custom_ops = True
tflite_model = converter.convert()
open(""fix_shape.tflite"", ""wb"").write(tflite_model)

Link to the model : https://drive.google.com/file/d/1i9q1XtMVMe31KRGRhy1vbtiEL1hy0x_Z/view?usp=sharing

**Any other info / logs**
I tried testing with tensorflow versions >=2.0 and also tf.nightly 
It did not work out"
40231,tf.linalg.expm enters infinite loop when input may cause reduce_sum to have inf,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0 & v2.1.0-rc2-17-ge5bf8de 2.1.0
- Python version: 3.7.6
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source):NA
- CUDA/cuDNN version:NA
- GPU model and memory:NA

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
`tf.linalg.expm` may enter an infinite loop when certain input can cause `math_ops.reduce_sum` to return `inf`, so `l1_norm`, `squarings`, and `max_squarings` will all become `inf` and the `while_loop`'s condition will never be false.

Part of this behavior comes from how `reduce_sum` deals with overflow with certain dtype, because for example, if input is `float16`, it's very easy to have input to cause `reduce_sum` to have `inf` in the result. On the other hand, if input is `float32`, `inf` may not occur easily because it's more difficult for `reduce_sum` to have overflow with `float32`
**Describe the expected behavior**
Tensorflow should be able to detect this infinite loop and then throw an exception to warn the user and stop the execution.
**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```python
import tensorflow as tf
import numpy as np

# an input big enough to cause reduce_sum to return inf
in_tensor = (np.random.rand(1000, 1000) * 10000).astype('float16')

tf.linalg.expm(in_tensor) # will not terminate
```
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

The problem seems to be this call: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/linalg/linalg_impl.py#L274-L278
```python
    l1_norm = math_ops.reduce_max(
        math_ops.reduce_sum(
            math_ops.abs(matrix),
            axis=array_ops.size(array_ops.shape(matrix)) - 2),
        axis=-1)[..., array_ops.newaxis, array_ops.newaxis]
```
where `math_ops.reduce_sum` would have `inf` value in result, so `l1_norm` would also contain `inf`. Then, eventually `max_squarings` would just be `inf` due to error propagation, so the while_loop condition `c = lambda i, r: math_ops.less(i, max_squarings)` would never evaluate to be false, causing the infinite loop."
40230,the result of each execution is very different.,"https://colab.research.google.com/drive/1_YW_Afi0yZS5wJQxJbHXddezIppZFUL_

As you can see in colab, the result of each execution is very different.

I understand that the results of the run change because the weights change, but the difference is too great.

Reduced to reduce loss. Why does this happen and how can I reduce the difference in execution results to increase the accuracy and reliability of predictions?"
40229,tf.function-decorated  Value error,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:no
- TensorFlow installed from (source or binary):binary
- TensorFlow version (use command below):2.3
- Python version:3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:10.1
- GPU model and memory: GTX 1050

I'm using the following code to create a custom loss,

    
```
@tf.function
def custom_loss(self, y_true, y_pred):
        mask_shape = tf.shape(y_true)[:4]
        
        cell_x = tf.cast(tf.reshape(tf.tile(tf.range(self.grid_w), [self.grid_h]), (1, self.grid_h, self.grid_w, 1, 1)),dtype=tf.float32)
        cell_y = tf.transpose(cell_x, (0,2,1,3,4))

        cell_grid = tf.tile(tf.concat([cell_x,cell_y], -1), [self.batch_size, 1, 1, self.nb_box, 1])
        
        coord_mask = tf.zeros(mask_shape)
        conf_mask  = tf.zeros(mask_shape)
        class_mask = tf.zeros(mask_shape)
        
        seen = tf.Variable(0.)
        total_recall = tf.Variable(0.)
```


But it throws the following error,
    ValueError: tf.function-decorated function tried to create variables on non-first call.

"
40228,Tensor had Inf values (maybe from TensorArray),"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None
- TensorFlow installed from (source or binary): `pip3.7 install --user tensorflow-gpu`
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: 3.7.7 (installed via Linuxbrew)
- Bazel version (if compiling from source): None
- GCC/Compiler version (if compiling from source): Not relevant
- CUDA/cuDNN version: CUDA 10.1, cuDNN 7.6
- GPU model and memory: GTX 2070

**Describe the current behavior**

We observed strange unstable training behavior with some TF versions, mostly for attention-based LSTM-based encoder-decoder models (for speech recognition or translation). This results in getting inf or nan at some very early point in training (after 100-200 steps or so).
Normally this might just be due to too high learning rate or so. However, the setup runs totally fine up to (including) TF 1.14.0, and it occured only since 1.15.0. This might just be due to bad luck. However, this problem was reported by a couple of individual people, for individual different setups. It was always the same observation: The setup ran fine with TF <=1.14, and produced inf or nan with TF 1.15. And it was always an attention-based LSTM-based encoder-decoder model.
In all cases, this was with CUDA 10.1. (I saw #31166 which reported a problem with CUDA 10.0, but this seems to be fixed in CUDA 10.1, so it seems that we have some different problem here.)

This looked a bit too suspicious. The bug in our framework [RETURNN](https://github.com/rwth-i6/returnn/) is reported [here](https://github.com/rwth-i6/returnn/issues/297).

So I tried to reproduce the problem. This was not really so simple but I finally managed to come up with a standalone script (independent of our framework) (see below for the code). This script can run on TF 1.14, TF 1.15 and TF 2.2 (and probably other TF versions as well). And it always produces Inf at some point (sometimes earlier, sometimes later), on GPU, with CUDA 10.1.

**Describe the expected behavior**

The training setup of our framework should also run stable with TF 1.15.

The simple example script below should never ever produce Inf.

**Standalone code to reproduce the issue**

The following code reproduces the problem for me:
```
import numpy
import tensorflow as tf
import argparse


def add_check_numerics_ops(name=""add_check_numerics_ops""):
  """"""
  This is similar to :func:`tf.add_check_numerics_ops` and based on similar code.
  It adds some more logic and options.
  Copied from RETURNN, and simplified.
  :param str name: op-name for the final tf.group
  :return: operation which performs all the checks
  :rtype: tf.Operation
  """"""
  ops = tf.compat.v1.get_default_graph().get_operations()
  with tf.name_scope(name):
    check_op = []
    # This code relies on the ordering of ops in get_operations().
    # The producer of a tensor always comes before that tensor's consumer in
    # this list. This is true because get_operations() returns ops in the order
    # added, and an op can only be added after its inputs are added.
    for op in ops:
      assert isinstance(op, tf.Operation)
      # Frames from within a while-loop are partly broken.
      # https://github.com/tensorflow/tensorflow/issues/2211
      # noinspection PyProtectedMember
      if op._get_control_flow_context() != tf.compat.v1.get_default_graph()._get_control_flow_context():
        continue
      for output in op.outputs:
        if output.dtype not in [tf.float16, tf.float32, tf.float64]:
          continue
        message = op.name + "":"" + str(output.value_index)
        with tf.control_dependencies(check_op):
          print(""add check for:"", output, op.type)
          check_op = [tf.compat.v1.check_numerics(output, message=message, name=op.name + ""_check_numerics"")]
    return tf.group(*check_op)


def main():
  arg_parser = argparse.ArgumentParser()
  arg_parser.add_argument(""--nsteps"", type=int, default=-1)
  arg_parser.add_argument(""--reset_after_nsteps"", type=int, default=-1)
  args = arg_parser.parse_args()

  print(""TF version:"", tf.__version__)

  # tf.compat.v1.disable_eager_execution()
  tf.compat.v1.disable_v2_behavior()

  n_input_dim = 2
  n_classes_dim = 3
  x = tf.compat.v1.placeholder(tf.float32, shape=(None, None, n_input_dim), name=""x"")
  targets = tf.compat.v1.placeholder(tf.int32, shape=(None, None), name=""targets"")
  encoder = tf.keras.layers.Dense(units=5, activation=""tanh"", name=""encoder"")(x)
  batch = tf.shape(encoder)[0]
  size = tf.shape(encoder)[1]
  orth_embed = tf.keras.layers.Embedding(input_dim=n_classes_dim, output_dim=6)(targets)  # (B,T,D)
  orth_embed = tf.transpose(orth_embed, [1, 0, 2])  # (T,B,D)
  prev_orth_embed = tf.concat(
    [tf.zeros([1, batch, orth_embed.get_shape().as_list()[-1]]), orth_embed[:-1]], axis=0)  # (T,B,D)
  prev_orth_embed_ta = tf.TensorArray(
    tf.float32, name=""prev_orth_embed_ta"", dynamic_size=True, size=0,
    element_shape=(None, prev_orth_embed.get_shape().as_list()[-1]))
  prev_orth_embed_ta = prev_orth_embed_ta.unstack(prev_orth_embed)
  c_ta = tf.TensorArray(tf.float32, name=""c_ta"", dynamic_size=True, size=0)
  s_ta = tf.TensorArray(tf.float32, name=""s_ta"", dynamic_size=True, size=0)

  def loop_cond(t, *args):
    return tf.less(t, size)

  s_lstm = tf.keras.layers.LSTMCell(5, name=""s"")  # originally was LSTMBlockCell

  def loop_body(t, prev_c, prev_s_state, c_ta_, s_ta_):
    assert isinstance(prev_c, tf.Tensor)
    prev_c.set_shape((None, encoder.get_shape().as_list()[-1]))
    prev_orth_embed_t = prev_orth_embed_ta.read(t)  # (B,D)
    s_in_in = tf.concat([prev_c, prev_orth_embed_t], axis=-1)  # (B,D)
    s_in = tf.keras.layers.Dense(units=5, name=""s_in"", activation=""tanh"")(s_in_in)
    s, s_state = s_lstm(s_in, prev_s_state)
    c_in = s  # (B,D)

    # dot attention
    base = encoder  # (batch, base_time, n_out)
    base_ctx = encoder  # (batch, base_time, inner)
    source = tf.expand_dims(c_in, axis=2)  # (batch, inner, 1)
    energy = tf.matmul(base_ctx, source)  # (batch, base_time, 1)
    energy.set_shape(tf.TensorShape([None, None, 1]))
    energy = tf.squeeze(energy, axis=2)  # (batch, base_time)
    energy_mask = tf.sequence_mask(tf.fill([batch], size), maxlen=tf.shape(energy)[1])
    # NOTE: The following line seems to trigger it!
    energy = tf.where(energy_mask, energy, float(""-inf"") * tf.ones_like(energy))
    base_weights = tf.nn.softmax(energy)  # (batch, base_time)
    base_weights_bc = tf.expand_dims(base_weights, axis=1)  # (batch, 1, base_time)
    out = tf.matmul(base_weights_bc, base)  # (batch, 1, n_out)
    out.set_shape(tf.TensorShape([None, 1, base.get_shape().as_list()[-1]]))
    c = tf.squeeze(out, axis=1)  # (batch, n_out)

    assert isinstance(c_ta_, tf.TensorArray)
    assert isinstance(s_ta_, tf.TensorArray)
    c_ta_ = c_ta_.write(t, c)
    s_ta_ = s_ta_.write(t, s)

    return t + 1, c, s_state, c_ta_, s_ta_

  _, _, _, c_ta, s_ta = tf.while_loop(
    cond=loop_cond, body=loop_body,
    loop_vars=(
      0,  # t
      tf.zeros([batch, tf.shape(encoder)[-1]]),  # prev_c
      s_lstm.get_initial_state(batch_size=batch, dtype=tf.float32),  # prev_s_state
      c_ta, s_ta))

  assert isinstance(c_ta, tf.TensorArray)
  assert isinstance(s_ta, tf.TensorArray)
  c_ = c_ta.stack()  # (T,B,D)
  s_ = s_ta.stack()  # (T,B,D)
  cs = tf.concat([c_, s_], axis=-1)  # (T,B,D)
  cs = tf.transpose(cs, [1, 0, 2])  # (B,T,D)
  att = tf.keras.layers.Dense(units=6, name=""att"", activation=""tanh"")(cs)
  output_logits = tf.keras.layers.Dense(units=n_classes_dim, name=""output_prob"", activation=None)(att)
  loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=targets, logits=output_logits)  # (B,T)
  loss = tf.reduce_mean(loss)
  loss_eval = loss

  opt = tf.compat.v1.train.AdamOptimizer(learning_rate=0.01)  # originally was NadamOptimizer...
  minimize_op = opt.minimize(loss)

  check_op = add_check_numerics_ops()
  with tf.control_dependencies([check_op, minimize_op]):
    loss = tf.identity(loss)
  vars_init_op = tf.compat.v1.global_variables_initializer()

  rnd = numpy.random.RandomState(42)
  n_batch = 2
  n_time = 5
  x_np = rnd.normal(size=(n_batch, n_time, n_input_dim))
  targets_np = rnd.randint(0, n_classes_dim, size=(n_batch, n_time))

  with tf.compat.v1.Session() as session:
    session.run(vars_init_op)
    step = 0
    while True:
      print(""step %i, loss:"" % step, session.run(loss, feed_dict={x: x_np, targets: targets_np}))
      print(""step %i, loss (eval):"" % step, session.run(loss_eval, feed_dict={x: x_np, targets: targets_np}))
      step += 1
      if 0 <= args.nsteps <= step:
        print(""Stop after %i steps."" % args.nsteps)
        break
      if args.reset_after_nsteps >= 0 and step % args.reset_after_nsteps == 0:
        print(""Reset after %i steps."" % args.reset_after_nsteps)
        session.run(vars_init_op)


if __name__ == '__main__':
  main()
```
I use the option `--reset_after_nsteps 100`.

The current version of this test case can also be found [here](https://github.com/albertz/playground/blob/master/tf-test-tensorarray-bug.py).

**Other info / logs**

```
...
step 652, loss: 0.106880724                                                                                                 
step 652, loss (eval): 0.098194                                                                                             
step 653, loss: 0.098194                                                                                                    
step 653, loss (eval): 0.09007898                                                                                           
2020-06-07 00:05:42.224810: E tensorflow/core/kernels/check_numerics_op.cc:289] abnormal_detected_host @0x7f149dc07d00 = {0, 1} gradients/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3:1                                 
InvalidArgumentError: 2 root error(s) found.                                                                                
  (0) Invalid argument: gradients/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3:1 : Tensor had Inf values                                                                                                                 
         [[node add_check_numerics_ops/gradients/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3_check_numerics (defined at tf-test-tensorarray-bug.py:47) ]]                                                               
         [[Identity/_69]]                                                                                                   
  (1) Invalid argument: gradients/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3:1 : Tensor had Inf values                                                                                                                 
         [[node add_check_numerics_ops/gradients/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3_check_numerics (defined at tf-test-tensorarray-bug.py:47) ]]
0 successful operations.
0 derived errors ignored.

Errors may have originated from an input operation.
Input Source operations connected to node add_check_numerics_ops/gradients/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3_check_numerics:
 gradients/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3 (defined at tf-test-tensorarray-bug.py:138)

Input Source operations connected to node add_check_numerics_ops/gradients/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3_check_numerics:
 gradients/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3 (defined at tf-test-tensorarray-bug.py:138)
```
"
40227,CUDA Toolkit 11.0 RC,"NVIDIA released their `CUDA 11.0 RC Toolkit`, and was wondering if there is an existing tensorflow-nightly build that can pull it or do I have to build from source which takes around 7 hours?
"
40226,Eigen download can fail due to Gitlab captcha,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS Linux release 7.8.2003
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/
- TensorFlow installed from (source or binary): source
- TensorFlow version: n/a
- Python version: n/a
- Installed using virtualenv? pip? conda?: n/a
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source): GCC 4.8.5
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a



**Describe the problem**
Downloading eigen from the gitlab mirror sometimes fails due to captcha and doesn't have a helpful error message
**Provide the exact sequence of commands / steps that you executed before running into the problem**
```
[root@9a53b50ad80e tensorflow]# ./tensorflow/lite/tools/make/download_dependencies.sh
downloading https://gitlab.com/libeigen/eigen/-/archive/c2ab36f47a34e572f37e3dd556ac8a04ab769277/eigen-c2ab36f47a34e572f37e3dd556ac8a04ab769277.tar.gz
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100  5511    0  5511    0     0  41050      0 --:--:-- --:--:-- --:--:-- 40822
checking sha256 of tensorflow/lite/tools/make/downloads/eigen
/tmp/tmp.y8lTsk6u19/eigen-c2ab36f47a34e572f37e3dd556ac8a04ab769277.tar.gz: FAILED
sha256sum: WARNING: 1 computed checksum did NOT match
[root@9a53b50ad80e tensorflow]# head /tmp/tmp.uZlok4zSME/eigen-c2ab36f47a34e572f37e3dd556ac8a04ab769277.tar.gz
<!DOCTYPE html>
<html>
<head>
  <meta content=""width=device-width, initial-scale=1, maximum-scale=1"" name=""viewport"">
  <title>Captcha Challenge</title>
  <style>body{color:#666;text-align:center;font-family:Helvetica Neue,Helvetica,Arial,sans-serif;margin:auto;font-size:14px;display:flex;flex-direction:column;align-items:center;justify-content:center}hr{max-width:800px;margin:18px auto;border:0;border-top:1px solid #eee;border-bottom:1px solid #fff}img{max-width:40vw}.container{margin:auto 20px}.cferror_details{list-style-type:none}.cf-error-details h1{color:#456;font-size:20px;font-weight:400;line-height:28px}</style>
</head>

<body>
  <div class=""header"">
```
**Any other info / logs**
In https://github.com/tensorflow/tensorflow/pull/29017 , the tensorflow mirror was filtered out, but I'm not sure if this mirror is more stable now. Options to resolve include using or falling back to the tensorflow mirror or checking for the `403` status from Gitlab to present a more descriptive error message. I didn't get this error on my own computer but did when running inside centos7 docker on https://labs.play-with-docker.com/
"
40225,how could tf.image.extract_patches with dynamic kernel size?,"The `sizes` parameter in `tf.image.extract_patches` can only be integers. However, I want to let the `kernel_size = sentence_length` which is variable. The `sentence_length` comes from `tf.shape(input)[1]`, in which `input` is `tf.keras.Input()` of size `[None, None, embedding_size]`."
40224,'fused' argument of BatchNormalization is not saved in the model,"Batch normalization layer's `fused` argument is not part of the saved model h5/json.   

Tested with TF version: 2.1.0 (CPU), Python 3.7.7

```
from tensorflow.keras import layers
from tensorflow.keras.models import Model

x = layers.Input((32, 32))
m = Model(x, layers.BatchNormalization(fused=False)(x))
print('fused' in m.to_json())
```
Output: `False`.
Expected output is `True`.

I found this issue when trying to get equal predictions in different versions of tensorflow.

I made a model with batch normalization layers. I tested the model in TF 1.12 and TF 2.1.0 (both are CPU versions, if that matters) with the same input. I got almost same predictions but differing in 4 or 5th decimal. Difference may become larger if the model is deeper. Once I manually added `""fused"" : false` in the model json, the predictions became exactly same, at least after batch norm layer. 

Fixing this issue can help during sanity check of the model, for the developers like me who work with different TF versions simultaneously.
"
40222,remove training nodes from freeze_graph failure using TransformGraph.,"Getting TensorRT conversion failure due to ops not supported in TensorRT. Till now I have come to conclusion to optimize/prune the original tensorflow flow graph so that freeze graph should have only supported ops as per TensorRT and that should then convert easily to uff.

To do this, i want to remove training nodes (map/*) using TransformGraph. Option i used are below, other then Input shape change and “Identity” node no other node removed like : ‘switch’, ‘exit’, ‘add’.

1) what options to choose in TransformGraph() to remove ‘switch’, ‘exit’, ‘add’ nodes?
2) Used Optimize_for_inference() and remvoe_traing_nodes() without  success.

Saved_model:
https://drive.google.com/file/d/15VWWKp-F4LNcajbcG7a_awJayAjfM5r_/view?usp=sharing

Freeze_graph.pb:
https://drive.google.com/file/d/1OhWTui8Jdsh-ZBvBMYvMvyYrVh_t88cO/view?usp=sharing

TransformGraph notebook:
https://drive.google.com/file/d/1ePqNPHjcbf5IhrLAK1yRpHM9IOnhk7aG/view?usp=sharing

I want to remove thses nodes. (Graph Image)
https://drive.google.com/file/d/1SFKn-EHjP7hYrvUSNG8aaZ1p9ZYPbeG0/view?usp=sharing

Thanks
"
40221,Can not convert tf.map_fn during TFLite Conversion (With Minimum Example),"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 and Ubuntu 2004 over WSL2
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (or github SHA if from source): 2.2 Stable

**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]
converter.target_spec.supported_ops = [
    tf.lite.OpsSet.TFLITE_BUILTINS,
    tf.lite.OpsSet.SELECT_TF_OPS,
]
tflite_model = converter.convert()
```

**The output from the converter invocation**

```
2020-06-05 22:27:19.003670: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-06-05 22:27:19.003971: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-06-05 22:27:19.004272: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-06-05 22:27:19.004567: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-06-05 22:27:19.004842: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-06-05 22:27:19.005144: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-06-05 22:27:19.005465: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-06-05 22:27:19.006000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-06-05 22:27:19.006294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-06-05 22:27:19.006536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0
2020-06-05 22:27:19.006735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N
2020-06-05 22:27:19.007280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4831 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-06-05 22:27:19.301593: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize
2020-06-05 22:27:19.301969: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 1282 nodes (966), 1999 edges (1683), time = 33.269ms.
2020-06-05 22:27:19.302215: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 1282 nodes (0), 1999 edges (0), time = 15.255ms.
2020-06-05 22:27:19.302403: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: map_while_body_33337
2020-06-05 22:27:19.302750: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 39 nodes (0), 42 edges (0), time = 1.062ms.
2020-06-05 22:27:19.303076: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 39 nodes (0), 42 edges (0), time = 0.9ms.
2020-06-05 22:27:19.303388: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: cond_png_false_33387
2020-06-05 22:27:19.303619: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 8 nodes (0), 8 edges (0), time = 0.331ms.
2020-06-05 22:27:19.303812: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 8 nodes (0), 8 edges (0), time = 0.34ms.
2020-06-05 22:27:19.304065: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: cond_png_true_33386
2020-06-05 22:27:19.304353: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-06-05 22:27:19.304665: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-06-05 22:27:19.304962: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: map_1_while_cond_34702
2020-06-05 22:27:19.305318: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-06-05 22:27:19.305696: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-06-05 22:27:19.306091: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: decode_image_cond_jpeg_false_33368
2020-06-05 22:27:19.306474: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 11 nodes (0), 12 edges (0), time = 0.448ms.
2020-06-05 22:27:19.306808: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 11 nodes (0), 12 edges (0), time = 0.489ms.
2020-06-05 22:27:19.307104: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: cond_gif_false_33398
2020-06-05 22:27:19.307397: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-06-05 22:27:19.307741: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-06-05 22:27:19.308084: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: decode_image_cond_jpeg_true_33367
2020-06-05 22:27:19.308466: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-06-05 22:27:19.308762: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-06-05 22:27:19.309035: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: map_1_while_body_34703
2020-06-05 22:27:19.309325: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-06-05 22:27:19.309541: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-06-05 22:27:19.309842: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: map_while_cond_33336
2020-06-05 22:27:19.310108: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-06-05 22:27:19.310376: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-06-05 22:27:19.310642: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: cond_gif_true_33397
2020-06-05 22:27:19.310783: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-06-05 22:27:19.310998: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-06-05 22:27:21.532247: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
2020-06-05 22:27:21.532847: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-06-05 22:27:21.535655: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce GTX 1060 computeCapability: 6.1
coreClock: 1.733GHz coreCount: 10 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 178.99GiB/s
2020-06-05 22:27:21.536315: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-06-05 22:27:21.536688: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-06-05 22:27:21.537057: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-06-05 22:27:21.537401: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-06-05 22:27:21.537814: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-06-05 22:27:21.538133: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-06-05 22:27:21.538423: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-06-05 22:27:21.538987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-06-05 22:27:21.539329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-06-05 22:27:21.539617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0
2020-06-05 22:27:21.540042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N
2020-06-05 22:27:21.540561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4831 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-06-05 22:27:21.867862: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize
2020-06-05 22:27:21.868148: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 931 nodes (-351), 1333 edges (-666), time = 84.162ms.
2020-06-05 22:27:21.868426: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 931 nodes (0), 1333 edges (0), time = 20.041ms.
2020-06-05 22:27:21.868694: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: map_1_while_body_34703_frozen
2020-06-05 22:27:21.868934: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 30 nodes (0), 27 edges (0), time = 0.558ms.
2020-06-05 22:27:21.869323: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 30 nodes (0), 27 edges (0), time = 0.322ms.
2020-06-05 22:27:21.869599: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: map_while_cond_33336_frozen
2020-06-05 22:27:21.869891: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 11 nodes (0), 8 edges (0), time = 0.256ms.
2020-06-05 22:27:21.870168: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 11 nodes (0), 8 edges (0), time = 0.111ms.
2020-06-05 22:27:21.870434: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: decode_image_cond_jpeg_false_33368_frozen
2020-06-05 22:27:21.870756: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 11 nodes (0), 12 edges (0), time = 0.415ms.
2020-06-05 22:27:21.871043: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 11 nodes (0), 12 edges (0), time = 0.195ms.
2020-06-05 22:27:21.871326: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: cond_png_true_33386_frozen
2020-06-05 22:27:21.871605: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 6 nodes (0), 4 edges (0), time = 0.199ms.
2020-06-05 22:27:21.871895: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 6 nodes (0), 4 edges (0), time = 0.067ms.
2020-06-05 22:27:21.872182: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: cond_gif_true_33397_frozen
2020-06-05 22:27:21.872445: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 8 nodes (-7), 8 edges (-6), time = 0.434ms.
2020-06-05 22:27:21.872715: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 8 nodes (0), 8 edges (0), time = 0.093ms.
2020-06-05 22:27:21.872937: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: cond_gif_false_33398_frozen
2020-06-05 22:27:21.873215: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 15 nodes (-4), 18 edges (-2), time = 0.527ms.
2020-06-05 22:27:21.873520: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 15 nodes (0), 18 edges (0), time = 0.164ms.
2020-06-05 22:27:21.873774: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: cond_png_false_33387_frozen
2020-06-05 22:27:21.874025: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 8 nodes (0), 8 edges (0), time = 0.264ms.
2020-06-05 22:27:21.874282: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 8 nodes (0), 8 edges (0), time = 0.129ms.
2020-06-05 22:27:21.874542: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: decode_image_cond_jpeg_true_33367_frozen
2020-06-05 22:27:21.874782: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 9 nodes (-3), 8 edges (-2), time = 0.378ms.
2020-06-05 22:27:21.875115: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 9 nodes (0), 8 edges (0), time = 0.109ms.
2020-06-05 22:27:21.875358: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: map_1_while_cond_34702_frozen
2020-06-05 22:27:21.875596: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 11 nodes (0), 8 edges (0), time = 0.255ms.
2020-06-05 22:27:21.875888: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 11 nodes (0), 8 edges (0), time = 0.107ms.
2020-06-05 22:27:21.876138: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: map_while_body_33337_frozen
2020-06-05 22:27:21.876413: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 39 nodes (0), 42 edges (0), time = 1.324ms.
2020-06-05 22:27:21.876736: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 39 nodes (0), 42 edges (0), time = 0.491ms.
Traceback (most recent call last):
  File ""deploy.py"", line 122, in <module>
    generator = run(model.generator, tflite_path)
  File ""deploy.py"", line 88, in run
    tflite = convert(wrapped)
  File ""deploy.py"", line 63, in convert
    tflite_model = converter.convert()
  File ""C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\lite\python\lite.py"", line 514, in convert
    result = _toco_convert_impl(
  File ""C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\lite\python\convert.py"", line 491, in toco_convert_impl
    data = toco_convert_protos(
  File ""C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\lite\python\convert.py"", line 227, in toco_convert_protos
    raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: See console for info.
2020-06-05 22:27:28.323077: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-06-05 22:27:31.116166: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:144] Ignored output_format.
2020-06-05 22:27:31.116208: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:147] Ignored drop_control_dependency.
loc(fused[callsite(""map/TensorArrayV2_1@__inference_call_34750""(""C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\python\ops\map_fn.py"":417:0) at callsite(""C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\python\util\deprecation.py"":574:0 at callsite(""C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\deblurrer-1.0.0-py3.8.egg\deblurrer\model\wrapper.py"":42:0 at callsite(""C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\python\framework\func_graph.py"":957:0 at callsite(""C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\python\eager\function.py"":3299:0 at callsite(""C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\python\eager\def_function.py"":441:0 at callsite(""C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\python\framework\func_graph.py"":981:0 at callsite(""C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\python\eager\function.py"":2657:0 at callsite(""C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\python\eager\function.py"":2777:0 at ""C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\python\eager\function.py"":2446:0))))))))), ""image_byte_wrapper/StatefulPartitionedCall/map/TensorArrayV2_1""]): error: requires element_shape to be 1D tensor during TF Lite transformation pass
loc(fused[callsite(""map/TensorArrayV2_1@__inference_call_34750""(""C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\python\ops\map_fn.py"":417:0) at callsite(""C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\python\util\deprecation.py"":574:0 at callsite(""C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\deblurrer-1.0.0-py3.8.egg\deblurrer\model\wrapper.py"":42:0 at callsite(""C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\python\framework\func_graph.py"":957:0 at callsite(""C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\python\eager\function.py"":3299:0 at callsite(""C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\python\eager\def_function.py"":441:0 at callsite(""C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\python\framework\func_graph.py"":981:0 at callsite(""C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\python\eager\function.py"":2657:0 at callsite(""C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\python\eager\function.py"":2777:0 at ""C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\python\eager\function.py"":2446:0))))))))), ""image_byte_wrapper/StatefulPartitionedCall/map/TensorArrayV2_1""]): error: failed to legalize operation 'tf.TensorListReserve'
Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\envs\deblurring-model\Scripts\toco_from_protos-script.py"", line 11, in <module>
    load_entry_point('tensorflow==2.2.0', 'console_scripts', 'toco_from_protos')()
  File ""C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\lite\toco\python\toco_from_protos.py"", line 93, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\python\platform\app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\absl\app.py"", line 299, in run
    _run_main(main, args)
  File ""C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\absl\app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\lite\toco\python\toco_from_protos.py"", line 50, in execute
    output_str = _pywrap_toco_api.TocoConvert(
Exception: C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\python\ops\map_fn.py:417:3: error: requires element_shape to be 1D tensor during TF Lite transformation pass
  return map_fn(
  ^
C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\python\util\deprecation.py:574:7: note: called from
      return func(*args, **kwargs)
      ^
C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\deblurrer-1.0.0-py3.8.egg\deblurrer\model\wrapper.py:42:9: note: called from
        images = tf.map_fn(pre_input, inputs, dtype=tf.float32)
        ^
C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\python\framework\func_graph.py:957:13: note: called from
            return autograph.converted_call(
            ^
C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\python\eager\function.py:3299:5: note: called from
    return wrapped_fn(*args, **kwargs)
    ^
C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\python\eager\def_function.py:441:9: note: called from
        return weak_wrapped_fn().__wrapped__(*args, **kwds)
        ^
C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\python\framework\func_graph.py:981:7: note: called from
      func_outputs = python_func(*func_args, **func_kwargs)
      ^
C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\python\eager\function.py:2657:9: note: called from
        func_graph_module.func_graph_from_py_func(
        ^
C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\python\eager\function.py:2777:7: note: called from
      graph_function = self._create_graph_function(args, kwargs)
      ^
C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\python\eager\function.py:2446:7: note: called from
      graph_function, _, _ = self._maybe_define_function(args, kwargs)
      ^
C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\python\ops\map_fn.py:417:3: error: failed to legalize operation 'tf.TensorListReserve'
  return map_fn(
  ^
C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\python\util\deprecation.py:574:7: note: called from
      return func(*args, **kwargs)
      ^
C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\deblurrer-1.0.0-py3.8.egg\deblurrer\model\wrapper.py:42:9: note: called from
        images = tf.map_fn(pre_input, inputs, dtype=tf.float32)
        ^
C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\python\framework\func_graph.py:957:13: note: called from
            return autograph.converted_call(
            ^
C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\python\eager\function.py:3299:5: note: called from
    return wrapped_fn(*args, **kwargs)
    ^
C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\python\eager\def_function.py:441:9: note: called from
        return weak_wrapped_fn().__wrapped__(*args, **kwds)
        ^
C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\python\framework\func_graph.py:981:7: note: called from
      func_outputs = python_func(*func_args, **func_kwargs)
      ^
C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\python\eager\function.py:2657:9: note: called from
        func_graph_module.func_graph_from_py_func(
        ^
C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\python\eager\function.py:2777:7: note: called from
      graph_function = self._create_graph_function(args, kwargs)
      ^
C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\python\eager\function.py:2446:7: note: called from
      graph_function, _, _ = self._maybe_define_function(args, kwargs)
```

**Failure details**
When trying to convert tf.map_fn op tflite the above error trace arises. The function is the following:
```
def pre_input(image):
            image = tf.io.decode_image(image[0])
            image = tf.cast(image, dtype=tf.float32)
            image = (image - 127.0) / 128.0
            return image

images = tf.map_fn(pre_input, inputs, dtype=tf.float32)
```
With ```inputs``` on line 7 being a string tensor of shape [batch, 1], and outputs a float tensor with shape [batch, h, w, 3].

Special care to the line ```Exception: C:\ProgramData\Anaconda3\envs\deblurring-model\lib\site-packages\tensorflow\python\ops\map_fn.py:417:3: error: requires element_shape to be 1D tensor during TF Lite transformation pass```

I tried different shapes for inputs, like [batch, 1, 1] or [batch], this changes the fn input elements accordingly, but no luck, seems to be a problem with the shape of the inner TensorArray elements, but i dont know how i can have control over that.

Thanks in advance!
"
40220,"Windows Python 3.7, Pycharm and tensorflow problem on import tensorflow","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (Windows 10):
- TensorFlow installed from (source or binary):
- TensorFlow version: 1.12.0
- Python version: 3.7
- Installed using pip:

Im traying to run a script with tensorflow imported, it works when use spyder but with pycharm gives me this traceback:

`Traceback (most recent call last):
  File ""C:\Users\YOURDATA\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    fp, pathname, description = imp.find_module('_pywrap_tensorflow_internal', [dirname(__file__)])
  File ""C:\Users\YOURDATA\AppData\Local\Programs\Python\Python37-32\lib\imp.py"", line 296, in find_module
    raise ImportError(_ERR_MSG.format(name), name=name)
ImportError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\YOURDATA\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\YOURDATA\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\YOURDATA\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    import _pywrap_tensorflow_internal
ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:/Users/YOURDATA/Desktop/SamuelFernandes/ML/Object_detection_Ualg - pycharm/main.py"", line 3, in <module>
    import generate_tfrecord
  File ""C:\Users\YOURDATA\Desktop\SamuelFernandes\ML\Object_detection_Ualg - pycharm\generate_tfrecord.py"", line 25, in <module>
    import tensorflow as tf
  File ""C:\Users\YOURDATA\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""C:\Users\YOURDATA\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\YOURDATA\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\YOURDATA\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    fp, pathname, description = imp.find_module('_pywrap_tensorflow_internal', [dirname(__file__)])
  File ""C:\Users\YOURDATA\AppData\Local\Programs\Python\Python37-32\lib\imp.py"", line 296, in find_module
    raise ImportError(_ERR_MSG.format(name), name=name)
ImportError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\YOURDATA\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\YOURDATA\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\YOURDATA\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    import _pywrap_tensorflow_internal
ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'`

Im traying to run a script with tensorflow imported, it works when use spyder but with pycharm gives me this traceback:

    Traceback (most recent call last):
  File ""C:\Users\YOURDATA\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    fp, pathname, description = imp.find_module('_pywrap_tensorflow_internal', [dirname(__file__)])
  File ""C:\Users\YOURDATA\AppData\Local\Programs\Python\Python37-32\lib\imp.py"", line 296, in find_module
    raise ImportError(_ERR_MSG.format(name), name=name)
ImportError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\YOURDATA\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\YOURDATA\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\YOURDATA\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    import _pywrap_tensorflow_internal
ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:/Users/YOURDATA/Desktop/SamuelFernandes/ML/Object_detection_Ualg - pycharm/main.py"", line 3, in <module>
    import generate_tfrecord
  File ""C:\Users\YOURDATA\Desktop\SamuelFernandes\ML\Object_detection_Ualg - pycharm\generate_tfrecord.py"", line 25, in <module>
    import tensorflow as tf
  File ""C:\Users\YOURDATA\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""C:\Users\YOURDATA\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\YOURDATA\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\YOURDATA\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    fp, pathname, description = imp.find_module('_pywrap_tensorflow_internal', [dirname(__file__)])
  File ""C:\Users\YOURDATA\AppData\Local\Programs\Python\Python37-32\lib\imp.py"", line 296, in find_module
    raise ImportError(_ERR_MSG.format(name), name=name)
ImportError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\YOURDATA\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\YOURDATA\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\YOURDATA\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    import _pywrap_tensorflow_internal
ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'

I'm new to python and know it as a loot of compatibility issues, can someane help me see what is happening? Thanks"
40219,Import util issue,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1.  It must be a bug, a feature request, or a significant problem with the
    documentation (for small docs fixes please send a PR instead).
2.  The form below must be filled out.
3.  It shouldn't be a TensorBoard issue. Those go
    [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**:
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**:
-   **TensorFlow installed from (source or binary)**:
-   **TensorFlow version (use command below)**:
-   **Python version**:
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**:
-   **GPU model and memory**:
-   **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
40218,tensorflow/core/public/session.h Reset is not work?,"This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.
"
40217,MobileNetV3,"**System information**
- TensorFlow version (you are using): tf-nightly 2.2.0.dev20200508 
- Are you willing to contribute it (Yes/No): Would be willing to but I've never contributed code to an open sourced project.



**Describe the feature and the current behavior/state.**
I want to do transfer learning using MobileNetV3. I see on [here](https://github.com/keras-team/keras-applications/blob/master/keras_applications/mobilenet_v3.py) that MobileNetV3 is available, but I don't see it either in the [Keras website](https://keras.io/applications/) or on [TF.](https://www.tensorflow.org/api_docs/python/tf/keras/applications?version=nightly) Why is this? 

**Will this change the current api? How?**
No

**Who will benefit with this feature?**
Everyone"
40215,keras layers LSTM uses inconsistent dropout approach,"**System information**
- TensorFlow version (use command below): 2.2

**Describe the current behavior**
The input dropout mask is the same for the respective input, forget, update, and output computation. 

from the call method in the LSTM class in [recurrent_v2.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/recurrent_v2.py)
```python
    dropout_mask = self.get_dropout_mask_for_cell(inputs, training, count=4)
    if dropout_mask is not None:
        inputs = inputs * dropout_mask[0]
```

However, the recurrent dropout mask is unique for the input, forget, update, and output computation
```python
        h_tm1_i = h_tm1 * rec_dp_mask[0]
        h_tm1_f = h_tm1 * rec_dp_mask[1]
        h_tm1_c = h_tm1 * rec_dp_mask[2]
        h_tm1_o = h_tm1 * rec_dp_mask[3]
```

If the input dropout mask approach was the intended behavior can someone link me a reference paper that explains why and shouldn't we at least set the count=1. To me it seems like we are attempting to follow the approach from ""[A Theoretically Grounded Application of Dropout in Recurrent Neural Networks](http://papers.nips.cc/paper/6241-a-theoretically-grounded-application-of-dropout-in-recurrent-neural-networks.pdf)""

**Describe the expected behavior**
I'd have thought the input dropout mask would be unique to the input, forget, update, and output computation

"
40213,"""tensorflow.python.framework.errors_impl.InvalidArgumentError: Retval[0] does not have value"" on aarch64","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below):1.15.0
- Python version:2.7
- Bazel version (if compiling from source):0.26.0
- GCC/Compiler version (if compiling from source):7.4.0
- CUDA/cuDNN version: no
- GPU model and memory:no

**Describe the current behavior**

I used [tensorflow/benchmark](https://github.com/tensorflow/benchmarks) to train resnet50 by [tf_cnn_benchmarks.py](https://github.com/tensorflow/benchmarks/blob/master/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py) on my aarch64 platform.
command line:
python tf_cnn_benchmarks.py --device=cpu --data_format=NHWC --optimizer=sgd --distortions=false --variable_update=replicated --data_dir=/opt/imagenet/tf_train --data_name=imagenet --model=resnet50 --batch_size=32 --train_dir=/opt/data/resnet50_ckpt/cpu_v1/  --num_epochs=10--save_model_steps=20


**Describe the expected behavior**
After training thousands batchs raise ""tensorflow.python.framework.errors_impl.InvalidArgumentError: Retval[0] does not have value""

> INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, Retval[0] does not have value
I0605 18:58:49.349148 281473050139600 coordinator.py:224] Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, Retval[0] does not have value
Traceback (most recent call last):
  File ""tf_cnn_benchmarks.py"", line 73, in <module>
    app.run(main)  # Raises error on invalid flags, unlike tf.app.run()
  File ""/root/.env/tf2.0.0/lib/python2.7/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/root/.env/tf2.0.0/lib/python2.7/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""tf_cnn_benchmarks.py"", line 68, in main
    bench.run()
  File ""/home/tf/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 1880, in run
    return self._benchmark_train()
  File ""/home/tf/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 2085, in _benchmark_train
    return self._benchmark_graph(result_to_benchmark, eval_build_results)
  File ""/home/tf/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 2294, in _benchmark_graph
    is_chief, summary_writer, profiler)
  File ""/home/tf/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 2430, in benchmark_with_session
    collective_graph_key=collective_graph_key)
  File ""/home/tf/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 869, in benchmark_one_step
    results = sess.run(fetches, options=run_options, run_metadata=run_metadata)
  File ""/root/.env/tf2.0.0/lib/python2.7/site-packages/tensorflow_core/python/client/session.py"", line 956, in run
    run_metadata_ptr)
  File ""/root/.env/tf2.0.0/lib/python2.7/site-packages/tensorflow_core/python/client/session.py"", line 1180, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/root/.env/tf2.0.0/lib/python2.7/site-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run
    run_metadata)
  File ""/root/.env/tf2.0.0/lib/python2.7/site-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Retval[0] does not have value

"
40208,MKL does not work with tensorflow 2.2.0,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Centos 7
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.2.0
- Python version: N/A
- Installed using virtualenv? pip? conda?: N/A
- Bazel version (if compiling from source): 2.0.0
- GCC/Compiler version (if compiling from source): devtoolset-7 on centos 7
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A



**Describe the problem**
We have built tensorflow 2.2.0 framework and jni targets from source with `--config=mkl`. When we run models, logs show that MKL is not enabled even though there are few symbols of mkl.
[tensorflow log](https://github.com/tensorflow/tensorflow/blob/r2.2/tensorflow/core/platform/cpu_feature_guard.cc#L143)

```
nm -D libtensorflow_framework.so | grep -i mkl | wc -l
     173

```
**Provide the exact sequence of commands / steps that you executed before running into the problem**
```
BAZEL_LINKLIBS=-l%:libstdc++.a bazel build -c opt --cxxopt=-D_GLIBCXX_USE_CXX11_ABI=0 --copt=-O3 \
      --copt=-Wformat --copt=-Wformat-security --copt=-fstack-protector --copt=-fPIC --copt=-fpic --linkopt=-znoexecstack --linkopt=-zrelro --linkopt=-znow --linkopt=-fstack-protector \
      --copt=-msse4.2 --copt=-mavx \
      --config=mkl \
      --linkopt -ldl \
      --copt=-march=x86-64 \
      --config=v2 \
      //tensorflow/tools/lib_package:libtensorflow_jni \
      //tensorflow/tools/lib_package:libtensorflow \
```

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

We were using Docker to compile and build the targets.
We used the same commands without `--config=v2` to successfully build tensorflow 1.15 with MKL enabled. It has 15718 mkl related symbols."
40207,Model training ending after around 50 steps.,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version:1.14.0 (cpu version)
- Python version:3.7.7
- Installed using virtualenv? pip? conda?:conda
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: NA
- GPU model and memory: NA



**Describe the problem**
Im training a model using the ssd_inception_v2_coco mode.  I execute the command:  python model_main.py --alsologtostderr --model_dir=training/ --pipeline_config_path=training/ssd_inception_v2_coco.config
and it trains for about 50 steps before it runs through a couple hundred lines of tracebacks and a couple numpy type errors.  It does save the data so if I run the command again it continues from where it left off.
**Provide the exact sequence of commands / steps that you executed before running into the problem**
python model_main.py --alsologtostderr --model_dir=training/ --pipeline_config_path=training/ssd_inception_v2_coco.config

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

>python model_main.py --alsologtostderr --model_dir=training/ --pipeline_config_path=training/ssd_inception_v2_coco.config
C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\framework\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([(""qint8"", np.int8, 1)])
C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\framework\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([(""quint8"", np.uint8, 1)])
C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\framework\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([(""qint16"", np.int16, 1)])
C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\framework\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([(""quint16"", np.uint16, 1)])
C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\framework\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([(""qint32"", np.int32, 1)])
C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\framework\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([(""resource"", np.ubyte, 1)])
C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([(""qint8"", np.int8, 1)])
C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([(""quint8"", np.uint8, 1)])
C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([(""qint16"", np.int16, 1)])
C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([(""quint16"", np.uint16, 1)])
C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([(""qint32"", np.int32, 1)])
C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([(""resource"", np.ubyte, 1)])
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From C:\Users\gomezn\Documents\TensorFlow\models\research\slim\nets\inception_resnet_v2.py:373: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

WARNING:tensorflow:From C:\Users\gomezn\Documents\TensorFlow\models\research\slim\nets\mobilenet\mobilenet.py:389: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.

WARNING:tensorflow:From model_main.py:109: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

WARNING:tensorflow:From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\utils\config_util.py:96: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.

W0605 16:20:32.751548 21396 deprecation_wrapper.py:119] From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\utils\config_util.py:96: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.

WARNING:tensorflow:From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\model_lib.py:597: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.

W0605 16:20:32.762156 21396 deprecation_wrapper.py:119] From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\model_lib.py:597: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.

WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.
W0605 16:20:32.763155 21396 model_lib.py:598] Forced number of epochs for all eval validations to be 1.
WARNING:tensorflow:From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\utils\config_util.py:482: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

W0605 16:20:32.782005 21396 deprecation_wrapper.py:119] From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\utils\config_util.py:482: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

INFO:tensorflow:Maybe overwriting train_steps: None
I0605 16:20:32.783971 21396 config_util.py:482] Maybe overwriting train_steps: None
INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1
I0605 16:20:32.793966 21396 config_util.py:482] Maybe overwriting sample_1_of_n_eval_examples: 1
INFO:tensorflow:Maybe overwriting use_bfloat16: False
I0605 16:20:32.795971 21396 config_util.py:482] Maybe overwriting use_bfloat16: False
INFO:tensorflow:Maybe overwriting eval_num_epochs: 1
I0605 16:20:32.807742 21396 config_util.py:482] Maybe overwriting eval_num_epochs: 1
INFO:tensorflow:Maybe overwriting load_pretrained: True
I0605 16:20:32.817380 21396 config_util.py:482] Maybe overwriting load_pretrained: True
INFO:tensorflow:Ignoring config override key: load_pretrained
I0605 16:20:32.819402 21396 config_util.py:492] Ignoring config override key: load_pretrained
WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
W0605 16:20:32.827637 21396 model_lib.py:614] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False
I0605 16:20:32.829394 21396 model_lib.py:649] create_estimator_and_inputs: use_tpu False, export_to_tpu False
INFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001EA704252C8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0605 16:20:32.841974 21396 estimator.py:209] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001EA704252C8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x000001EA70433168>) includes params argument, but params are not passed to Estimator.
W0605 16:20:32.848480 21396 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x000001EA70433168>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:Not using Distribute Coordinator.
I0605 16:20:32.854470 21396 estimator_training.py:186] Not using Distribute Coordinator.
INFO:tensorflow:Running training and evaluation locally (non-distributed).
I0605 16:20:32.859618 21396 training.py:612] Running training and evaluation locally (non-distributed).
INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.
I0605 16:20:32.861163 21396 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.
WARNING:tensorflow:From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\training\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0605 16:20:32.887774 21396 deprecation.py:323] From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\training\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
WARNING:tensorflow:From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\data_decoders\tf_example_decoder.py:170: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.

W0605 16:20:32.902736 21396 deprecation_wrapper.py:119] From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\data_decoders\tf_example_decoder.py:170: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.

WARNING:tensorflow:From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\data_decoders\tf_example_decoder.py:185: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.

W0605 16:20:32.903731 21396 deprecation_wrapper.py:119] From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\data_decoders\tf_example_decoder.py:185: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.

WARNING:tensorflow:From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\builders\dataset_builder.py:61: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.

W0605 16:20:32.941629 21396 deprecation_wrapper.py:119] From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\builders\dataset_builder.py:61: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.

WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.
W0605 16:20:32.946616 21396 dataset_builder.py:66] num_readers has been reduced to 1 to match input file shards.
WARNING:tensorflow:From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\builders\dataset_builder.py:80: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.experimental.parallel_interleave(...)`.
W0605 16:20:32.953633 21396 deprecation.py:323] From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\builders\dataset_builder.py:80: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.experimental.parallel_interleave(...)`.
WARNING:tensorflow:From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\contrib\data\python\ops\interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0605 16:20:32.957589 21396 deprecation.py:323] From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\contrib\data\python\ops\interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
WARNING:tensorflow:From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\builders\dataset_builder.py:149: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map()
W0605 16:20:32.990371 21396 deprecation.py:323] From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\builders\dataset_builder.py:149: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map()
WARNING:tensorflow:From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\utils\ops.py:472: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.

W0605 16:20:33.112078 21396 deprecation_wrapper.py:119] From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\utils\ops.py:472: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.

WARNING:tensorflow:From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\utils\ops.py:472: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0605 16:20:33.115038 21396 deprecation.py:323] From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\utils\ops.py:472: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING:tensorflow:From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\utils\ops.py:474: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0605 16:20:33.126492 21396 deprecation.py:323] From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\utils\ops.py:474: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\inputs.py:320: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0605 16:20:33.167061 21396 deprecation.py:323] From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\inputs.py:320: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING:tensorflow:From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\core\preprocessor.py:512: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

W0605 16:20:33.171998 21396 deprecation_wrapper.py:119] From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\core\preprocessor.py:512: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\core\preprocessor.py:188: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.
Instructions for updating:
`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.
W0605 16:20:33.220893 21396 deprecation.py:323] From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\core\preprocessor.py:188: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.
Instructions for updating:
`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.
WARNING:tensorflow:From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\util\dispatch.py:180: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.
Instructions for updating:
Use the `axis` argument instead
W0605 16:20:33.224887 21396 deprecation.py:506] From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\util\dispatch.py:180: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.
Instructions for updating:
Use the `axis` argument instead
WARNING:tensorflow:From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\core\preprocessor.py:2421: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.

W0605 16:20:33.810291 21396 deprecation_wrapper.py:119] From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\core\preprocessor.py:2421: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.

WARNING:tensorflow:From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\builders\dataset_builder.py:152: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.batch(..., drop_remainder=True)`.
W0605 16:20:34.148696 21396 deprecation.py:323] From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\builders\dataset_builder.py:152: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.batch(..., drop_remainder=True)`.
INFO:tensorflow:Calling model_fn.
I0605 16:20:34.162653 21396 estimator.py:1145] Calling model_fn.
WARNING:tensorflow:From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\ops\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0605 16:20:34.387717 21396 deprecation.py:506] From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\ops\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
INFO:tensorflow:depth of additional conv before box predictor: 0
I0605 16:20:37.683687 21396 convolutional_box_predictor.py:150] depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
I0605 16:20:37.718561 21396 convolutional_box_predictor.py:150] depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
I0605 16:20:37.755499 21396 convolutional_box_predictor.py:150] depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
I0605 16:20:37.789371 21396 convolutional_box_predictor.py:150] depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
I0605 16:20:37.824299 21396 convolutional_box_predictor.py:150] depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
I0605 16:20:37.861396 21396 convolutional_box_predictor.py:150] depth of additional conv before box predictor: 0
WARNING:tensorflow:From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\utils\variables_helper.py:134: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.

W0605 16:20:37.901255 21396 deprecation_wrapper.py:119] From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\utils\variables_helper.py:134: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.

WARNING:tensorflow:From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\model_lib.py:332: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.

W0605 16:20:37.925952 21396 deprecation_wrapper.py:119] From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\model_lib.py:332: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.

WARNING:tensorflow:From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\meta_architectures\ssd_meta_arch.py:1028: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

W0605 16:20:40.277952 21396 deprecation_wrapper.py:119] From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\meta_architectures\ssd_meta_arch.py:1028: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\core\losses.py:174: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.

W0605 16:20:40.291881 21396 deprecation_wrapper.py:119] From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\core\losses.py:174: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.

WARNING:tensorflow:From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\core\losses.py:180: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.

W0605 16:20:40.293919 21396 deprecation_wrapper.py:119] From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\core\losses.py:180: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.

WARNING:tensorflow:From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\model_lib.py:356: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.

W0605 16:20:40.543186 21396 deprecation_wrapper.py:119] From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\model_lib.py:356: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.

WARNING:tensorflow:From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\utils\learning_schedules.py:54: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.

W0605 16:20:40.545150 21396 deprecation_wrapper.py:119] From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\utils\learning_schedules.py:54: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.

WARNING:tensorflow:From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\builders\optimizer_builder.py:44: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.

W0605 16:20:40.563030 21396 deprecation_wrapper.py:119] From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\builders\optimizer_builder.py:44: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.

WARNING:tensorflow:From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\training\rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0605 16:20:42.401734 21396 deprecation.py:506] From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\training\rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
INFO:tensorflow:Done calling model_fn.
I0605 16:20:48.850543 21396 estimator.py:1147] Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
I0605 16:20:48.853538 21396 basic_session_run_hooks.py:541] Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
I0605 16:20:52.710421 21396 monitored_session.py:240] Graph was finalized.
2020-06-05 16:20:52.713721: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
WARNING:tensorflow:From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\training\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
W0605 16:20:52.743332 21396 deprecation.py:323] From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\training\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
INFO:tensorflow:Restoring parameters from training/model.ckpt-1242
I0605 16:20:52.765274 21396 saver.py:1280] Restoring parameters from training/model.ckpt-1242
WARNING:tensorflow:From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\training\saver.py:1066: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
W0605 16:20:54.521835 21396 deprecation.py:323] From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\training\saver.py:1066: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
INFO:tensorflow:Running local_init_op.
I0605 16:20:55.466892 21396 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I0605 16:20:55.871834 21396 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 1242 into training/model.ckpt.
I0605 16:21:05.430812 21396 basic_session_run_hooks.py:606] Saving checkpoints for 1242 into training/model.ckpt.
INFO:tensorflow:loss = 4.2586923, step = 1243
I0605 16:21:24.690247 21396 basic_session_run_hooks.py:262] loss = 4.2586923, step = 1243
INFO:tensorflow:Saving checkpoints for 1304 into training/model.ckpt.
I0605 16:31:09.404349 21396 basic_session_run_hooks.py:606] Saving checkpoints for 1304 into training/model.ckpt.
WARNING:tensorflow:From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\training\saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W0605 16:31:09.901591 21396 deprecation.py:323] From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\training\saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
INFO:tensorflow:Calling model_fn.
I0605 16:31:12.018701 21396 estimator.py:1145] Calling model_fn.
INFO:tensorflow:depth of additional conv before box predictor: 0
I0605 16:31:15.044162 21396 convolutional_box_predictor.py:150] depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
I0605 16:31:15.074082 21396 convolutional_box_predictor.py:150] depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
I0605 16:31:15.102516 21396 convolutional_box_predictor.py:150] depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
I0605 16:31:15.129999 21396 convolutional_box_predictor.py:150] depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
I0605 16:31:15.158922 21396 convolutional_box_predictor.py:150] depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
I0605 16:31:15.185850 21396 convolutional_box_predictor.py:150] depth of additional conv before box predictor: 0
WARNING:tensorflow:From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\eval_util.py:785: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0605 16:31:15.971594 21396 deprecation.py:323] From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\eval_util.py:785: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING:tensorflow:From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\utils\visualization_utils.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.

W0605 16:31:16.161088 21396 deprecation.py:323] From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\utils\visualization_utils.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.

WARNING:tensorflow:From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\utils\visualization_utils.py:924: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.

W0605 16:31:16.337792 21396 deprecation_wrapper.py:119] From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\utils\visualization_utils.py:924: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.

WARNING:tensorflow:From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\model_lib.py:456: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.

W0605 16:31:16.428550 21396 deprecation_wrapper.py:119] From C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\model_lib.py:456: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.

INFO:tensorflow:Done calling model_fn.
I0605 16:31:16.751320 21396 estimator.py:1147] Done calling model_fn.
INFO:tensorflow:Starting evaluation at 2020-06-05T16:31:16Z
I0605 16:31:16.775298 21396 evaluation.py:255] Starting evaluation at 2020-06-05T16:31:16Z
INFO:tensorflow:Graph was finalized.
I0605 16:31:17.219084 21396 monitored_session.py:240] Graph was finalized.
INFO:tensorflow:Restoring parameters from training/model.ckpt-1304
I0605 16:31:17.229057 21396 saver.py:1280] Restoring parameters from training/model.ckpt-1304
INFO:tensorflow:Running local_init_op.
I0605 16:31:17.974575 21396 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I0605 16:31:18.098278 21396 session_manager.py:502] Done running local_init_op.
creating index...
index created!
INFO:tensorflow:Loading and preparing annotation results...
I0605 16:31:23.954166 13852 coco_tools.py:109] Loading and preparing annotation results...
INFO:tensorflow:DONE (t=0.00s)
I0605 16:31:23.962145 13852 coco_tools.py:131] DONE (t=0.00s)
creating index...
index created!
2020-06-05 16:31:23.992431: W tensorflow/core/framework/op_kernel.cc:1490] Invalid argument: TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.
Traceback (most recent call last):

  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\numpy\core\function_base.py"", line 117, in linspace
    num = operator.index(num)

TypeError: 'numpy.float64' object cannot be interpreted as an integer


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\ops\script_ops.py"", line 209, in __call__
    ret = func(*args)

  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\metrics\coco_evaluation.py"", line 358, in first_value_func
    self._metrics = self.evaluate()

  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\metrics\coco_evaluation.py"", line 209, in evaluate
    coco_wrapped_groundtruth, coco_wrapped_detections, agnostic_mode=False)

  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\metrics\coco_tools.py"", line 170, in __init__
    iouType=iou_type)

  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\pycocotools\cocoeval.py"", line 76, in __init__
    self.params = Params(iouType=iouType) # parameters

  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\pycocotools\cocoeval.py"", line 527, in __init__
    self.setDetParams()

  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\pycocotools\cocoeval.py"", line 507, in setDetParams
    self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05) + 1, endpoint=True)

  File ""<__array_function__ internals>"", line 6, in linspace

  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\numpy\core\function_base.py"", line 121, in linspace
    .format(type(num)))

TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.


Traceback (most recent call last):
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\client\session.py"", line 1356, in _do_call
    return fn(*args)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\client\session.py"", line 1341, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\client\session.py"", line 1429, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.OutOfRangeError: End of sequence
         [[{{node IteratorGetNext}}]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\training\evaluation.py"", line 272, in _evaluate_once
    session.run(eval_ops, feed_dict)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 754, in run
    run_metadata=run_metadata)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 1252, in run
    run_metadata=run_metadata)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 1353, in run
    raise six.reraise(*original_exc_info)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\six.py"", line 703, in reraise
    raise value
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 1338, in run
    return self._sess.run(*args, **kwargs)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 1411, in run
    run_metadata=run_metadata)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 1169, in run
    return self._sess.run(*args, **kwargs)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\client\session.py"", line 950, in run
    run_metadata_ptr)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\client\session.py"", line 1173, in _run
    feed_dict_tensor, options, run_metadata)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\client\session.py"", line 1350, in _do_run
    run_metadata)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\client\session.py"", line 1370, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.OutOfRangeError: End of sequence
         [[node IteratorGetNext (defined at model_main.py:105) ]]

Original stack trace for 'IteratorGetNext':
  File ""model_main.py"", line 109, in <module>
    tf.app.run()
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\platform\app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\absl\app.py"", line 299, in run
    _run_main(main, args)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\absl\app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""model_main.py"", line 105, in main
    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\training.py"", line 473, in train_and_evaluate
    return executor.run()
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\training.py"", line 613, in run
    return self.run_local()
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\training.py"", line 714, in run_local
    saving_listeners=saving_listeners)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 367, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1158, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1192, in _train_model_default
    saving_listeners)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1484, in _train_with_estimator_spec
    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 754, in run
    run_metadata=run_metadata)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 1252, in run
    run_metadata=run_metadata)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 1338, in run
    return self._sess.run(*args, **kwargs)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 1419, in run
    run_metadata=run_metadata))
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\training\basic_session_run_hooks.py"", line 594, in after_run
    if self._save(run_context.session, global_step):
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\training\basic_session_run_hooks.py"", line 619, in _save
    if l.after_save(session, step):
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\training.py"", line 519, in after_save
    self._evaluate(global_step_value)  # updates self.eval_result
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\training.py"", line 539, in _evaluate
    self._evaluator.evaluate_and_export())
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\training.py"", line 920, in evaluate_and_export
    hooks=self._eval_spec.hooks)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 477, in evaluate
    name=name)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 519, in _actual_eval
    return _evaluate()
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 501, in _evaluate
    self._evaluate_build_graph(input_fn, hooks, checkpoint_path))
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1501, in _evaluate_build_graph
    self._call_model_fn_eval(input_fn, self.config))
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1534, in _call_model_fn_eval
    input_fn, ModeKeys.EVAL)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1022, in _get_features_and_labels_from_input_fn
    self._call_input_fn(input_fn, mode))
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\util.py"", line 65, in parse_input_fn_result
    result = iterator.get_next()
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\data\ops\iterator_ops.py"", line 426, in get_next
    output_shapes=self._structure._flat_shapes, name=name)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\ops\gen_dataset_ops.py"", line 1973, in iterator_get_next
    output_shapes=output_shapes, name=name)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 788, in _apply_op_helper
    op_def=op_def)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\util\deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\framework\ops.py"", line 3616, in create_op
    op_def=op_def)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\framework\ops.py"", line 2005, in __init__
    self._traceback = tf_stack.extract_stack()


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\client\session.py"", line 1356, in _do_call
    return fn(*args)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\client\session.py"", line 1341, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\client\session.py"", line 1429, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.InvalidArgumentError: TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.
Traceback (most recent call last):

  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\numpy\core\function_base.py"", line 117, in linspace
    num = operator.index(num)

TypeError: 'numpy.float64' object cannot be interpreted as an integer


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\ops\script_ops.py"", line 209, in __call__
    ret = func(*args)

  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\metrics\coco_evaluation.py"", line 358, in first_value_func
    self._metrics = self.evaluate()

  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\metrics\coco_evaluation.py"", line 209, in evaluate
    coco_wrapped_groundtruth, coco_wrapped_detections, agnostic_mode=False)

  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\metrics\coco_tools.py"", line 170, in __init__
    iouType=iou_type)

  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\pycocotools\cocoeval.py"", line 76, in __init__
    self.params = Params(iouType=iouType) # parameters

  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\pycocotools\cocoeval.py"", line 527, in __init__
    self.setDetParams()

  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\pycocotools\cocoeval.py"", line 507, in setDetParams
    self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05) + 1, endpoint=True)

  File ""<__array_function__ internals>"", line 6, in linspace

  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\numpy\core\function_base.py"", line 121, in linspace
    .format(type(num)))

TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.


         [[{{node PyFunc_3}}]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""model_main.py"", line 109, in <module>
    tf.app.run()
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\platform\app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\absl\app.py"", line 299, in run
    _run_main(main, args)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\absl\app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""model_main.py"", line 105, in main
    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\training.py"", line 473, in train_and_evaluate
    return executor.run()
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\training.py"", line 613, in run
    return self.run_local()
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\training.py"", line 714, in run_local
    saving_listeners=saving_listeners)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 367, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1158, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1192, in _train_model_default
    saving_listeners)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1484, in _train_with_estimator_spec
    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 754, in run
    run_metadata=run_metadata)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 1252, in run
    run_metadata=run_metadata)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 1353, in run
    raise six.reraise(*original_exc_info)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\six.py"", line 703, in reraise
    raise value
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 1338, in run
    return self._sess.run(*args, **kwargs)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 1419, in run
    run_metadata=run_metadata))
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\training\basic_session_run_hooks.py"", line 594, in after_run
    if self._save(run_context.session, global_step):
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\training\basic_session_run_hooks.py"", line 619, in _save
    if l.after_save(session, step):
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\training.py"", line 519, in after_save
    self._evaluate(global_step_value)  # updates self.eval_result
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\training.py"", line 539, in _evaluate
    self._evaluator.evaluate_and_export())
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\training.py"", line 920, in evaluate_and_export
    hooks=self._eval_spec.hooks)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 477, in evaluate
    name=name)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 519, in _actual_eval
    return _evaluate()
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 508, in _evaluate
    output_dir=self.eval_dir(name))
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1609, in _evaluate_run
    config=self._session_config)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\training\evaluation.py"", line 272, in _evaluate_once
    session.run(eval_ops, feed_dict)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 854, in __exit__
    self._close_internal(exception_type)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 887, in _close_internal
    h.end(self._coordinated_creator.tf_sess)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\training\basic_session_run_hooks.py"", line 951, in end
    self._final_ops, feed_dict=self._final_ops_feed_dict)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\client\session.py"", line 950, in run
    run_metadata_ptr)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\client\session.py"", line 1173, in _run
    feed_dict_tensor, options, run_metadata)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\client\session.py"", line 1350, in _do_run
    run_metadata)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\client\session.py"", line 1370, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.
Traceback (most recent call last):

  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\numpy\core\function_base.py"", line 117, in linspace
    num = operator.index(num)

TypeError: 'numpy.float64' object cannot be interpreted as an integer


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\ops\script_ops.py"", line 209, in __call__
    ret = func(*args)

  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\metrics\coco_evaluation.py"", line 358, in first_value_func
    self._metrics = self.evaluate()

  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\metrics\coco_evaluation.py"", line 209, in evaluate
    coco_wrapped_groundtruth, coco_wrapped_detections, agnostic_mode=False)

  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\metrics\coco_tools.py"", line 170, in __init__
    iouType=iou_type)

  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\pycocotools\cocoeval.py"", line 76, in __init__
    self.params = Params(iouType=iouType) # parameters

  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\pycocotools\cocoeval.py"", line 527, in __init__
    self.setDetParams()

  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\pycocotools\cocoeval.py"", line 507, in setDetParams
    self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05) + 1, endpoint=True)

  File ""<__array_function__ internals>"", line 6, in linspace

  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\numpy\core\function_base.py"", line 121, in linspace
    .format(type(num)))

TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.


         [[node PyFunc_3 (defined at C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\metrics\coco_evaluation.py:368) ]]

Original stack trace for 'PyFunc_3':
  File ""model_main.py"", line 109, in <module>
    tf.app.run()
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\platform\app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\absl\app.py"", line 299, in run
    _run_main(main, args)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\absl\app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""model_main.py"", line 105, in main
    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\training.py"", line 473, in train_and_evaluate
    return executor.run()
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\training.py"", line 613, in run
    return self.run_local()
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\training.py"", line 714, in run_local
    saving_listeners=saving_listeners)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 367, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1158, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1192, in _train_model_default
    saving_listeners)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1484, in _train_with_estimator_spec
    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 754, in run
    run_metadata=run_metadata)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 1252, in run
    run_metadata=run_metadata)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 1338, in run
    return self._sess.run(*args, **kwargs)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 1419, in run
    run_metadata=run_metadata))
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\training\basic_session_run_hooks.py"", line 594, in after_run
    if self._save(run_context.session, global_step):
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\training\basic_session_run_hooks.py"", line 619, in _save
    if l.after_save(session, step):
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\training.py"", line 519, in after_save
    self._evaluate(global_step_value)  # updates self.eval_result
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\training.py"", line 539, in _evaluate
    self._evaluator.evaluate_and_export())
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\training.py"", line 920, in evaluate_and_export
    hooks=self._eval_spec.hooks)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 477, in evaluate
    name=name)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 519, in _actual_eval
    return _evaluate()
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 501, in _evaluate
    self._evaluate_build_graph(input_fn, hooks, checkpoint_path))
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1501, in _evaluate_build_graph
    self._call_model_fn_eval(input_fn, self.config))
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1537, in _call_model_fn_eval
    features, labels, ModeKeys.EVAL, config)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1146, in _call_model_fn
    model_fn_results = self._model_fn(features=features, **kwargs)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\model_lib.py"", line 454, in model_fn
    eval_config, list(category_index.values()), eval_dict)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\eval_util.py"", line 916, in get_eval_metric_ops_for_evaluators
    eval_dict))
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\object_detection\metrics\coco_evaluation.py"", line 368, in get_estimator_eval_metric_ops
    first_value_op = tf.py_func(first_value_func, [], tf.float32)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\util\deprecation.py"", line 324, in new_func
    return func(*args, **kwargs)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\ops\script_ops.py"", line 480, in py_func
    return py_func_common(func, inp, Tout, stateful, name=name)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\ops\script_ops.py"", line 462, in py_func_common
    func=func, inp=inp, Tout=Tout, stateful=stateful, eager=False, name=name)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\ops\script_ops.py"", line 285, in _internal_py_func
    input=inp, token=token, Tout=Tout, name=name)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\ops\gen_script_ops.py"", line 161, in py_func
    ""PyFunc"", input=input, token=token, Tout=Tout, name=name)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 788, in _apply_op_helper
    op_def=op_def)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\util\deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\framework\ops.py"", line 3616, in create_op
    op_def=op_def)
  File ""C:\Users\gomezn\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\framework\ops.py"", line 2005, in __init__
    self._traceback = tf_stack.extract_stack()"
40205,Unit test //tensorflow/python:session_clusterspec_prop_test fails because eager execution is incompatible with tf.placeholder(),"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): v2.2.0-0-g2b96f3662b 2.2.0
- Python version: 3.8.2
- Bazel version (if compiling from source): 2.0.0
- GCC/Compiler version (if compiling from source): gcc (Ubuntu 9.3.0-10ubuntu2) 9.3.0
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
The test case `//tensorflow/python:session_clusterspec_prop_test` fails with the following log (Partial log, see [test.log](https://github.com/tensorflow/tensorflow/files/4738058/test.log) for the full log):
```
[ RUN      ] SessionClusterSpecPropagationTest.testClusterSpecPropagationIsolation
2020-06-03 11:07:09.469162: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:46629}
2020-06-03 11:07:09.470895: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:390] Started server with target: grpc://localhost:46629
[  FAILED  ] SessionClusterSpecPropagationTest.testClusterSpecPropagationIsolation

======================================================================
ERROR: testClusterSpecPropagationIsolation (__main__.SessionClusterSpecPropagationTest)
testClusterSpecPropagationIsolation (__main__.SessionClusterSpecPropagationTest)
Test that two sessions using ClusterSpec propagation are isolated.
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/home/sidong/.cache/bazel/_bazel_sidong/9ef871a29c692fc6a18121463529e145/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/client/session_clusterspec_prop_test.py"", line 416, in testClusterSpecPropagationIsolation
    init_value = array_ops.placeholder(dtypes.int32, shape=[])
  File ""/home/sidong/.cache/bazel/_bazel_sidong/9ef871a29c692fc6a18121463529e145/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/ops/array_ops.py"", line 3023, in placeholder
    raise RuntimeError(""tf.placeholder() is not compatible with ""
RuntimeError: tf.placeholder() is not compatible with eager execution.
``` 

**Describe the expected behavior**
The test case should pass.

**Standalone code to reproduce the issue**
`bazel --host_jvm_args=""-Xms1024m"" --host_jvm_args=""-Xmx2048m"" test --host_javabase=""@local_jdk//:jdk"" -k --build_tests_only --test_output=errors -- //tensorflow/python:session_clusterspec_prop_test`

**Other info / logs** 
As the error message suggested, the error is caused by eager-execution. It seems to me that in this test case, eager execution should be disabled (as it is enabled by default in Tensorflow 2.x). Modifying the test file as following will knock down the error, and the test will pass.
```
diff --git a/tensorflow/python/client/session_clusterspec_prop_test.py b/tensorflow/python/client/session_clusterspec_prop_test.py
index f33b9129b8..7b0344d73e 100644
--- a/tensorflow/python/client/session_clusterspec_prop_test.py
+++ b/tensorflow/python/client/session_clusterspec_prop_test.py
@@ -563,4 +563,5 @@ class SessionClusterSpecPropagationTest(test_util.TensorFlowTestCase):
 
 
 if __name__ == '__main__':
+  ops.disable_eager_execution()
   googletest.main()
```
Please let me know if I should PR this fix, or if there is another way of disabling eager execution (or maybe do not use `tf.placeholder()`?). Thanks.

Sidong"
40204,Floating point exception while executing tf.unravel_index function,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04.3 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: 3.6.9
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
When passing 0 in argument `dims` in `tf.unravel_index` function, a floating point exception occurs because of divide by zero in  `mod_op` function at tensorflow/core/kernels/unravel_index_op.cc:29. 


**Describe the expected behavior**
No crash in the c++ level. I would expect an exception in python saying that `dims` argument should not be 0.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

`python -c ""import tensorflow as tf; tf.unravel_index(indices=[2, 5, 7], dims=[3, 0])""`

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40203,Provide compatibility with previous Keras-Preprocessing API.,"**System information**
- TensorFlow version (you are using): 2.2
- Are you willing to contribute it (Yes/No): Yes

In response to https://github.com/keras-team/keras-preprocessing/issues/299

**Describe the feature and the current behavior/state.**

Currently, matching image datasets iterations with real pathnames is not as trivial as it was in keras-preprocessing. It is also not explained clearly in the documentation.

```python
# Keras preprocessing

flow = ImageDataGenerator.flow_from_directory('a_path', ...)
filenames = flow.filenames

# TF Dataset 

dataset = `image_dataset_from_directory('a_path', ...)
image_paths, labels, class_names = keras.preprocessing.dataset_utils.index_directory('a_path')
```

**Suggestion**
Include a Dataset that will return filenames as an attribute of the returned Dataset.

This dataset would also be shuffled, batched so that if we zip both datasets, we can easily track what is the filename currently being used. This is useful when debugging models, tracking performance, etc.


**Will this change the current api? How?**

No, we add an attribute to the returned Dataset.

**Who will benefit with this feature?**

Every user using `flow_from_directory(...).filenames`.

**Any Other info.**

I can submit a PR, but I wanted to know if this is a good fit or should we suggest users use the example above.
"
40202,"""Inconsistent CUDA toolkit path: /usr vs /usr/lib"" when running ./configure","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): source
- TensorFlow version: v2.2.0 (2b96f3662bd776e277f86997659e61046b56c315)
- Python version: 3.7.3
- Installed using virtualenv? pip? conda?: No
- Bazel version (if compiling from source): 2.0.0
- GCC/Compiler version (if compiling from source): 8.3.0
- CUDA/cuDNN version: 10.1/7.6.5
- GPU model and memory: GeForce GTX 1070 and 8192 MB



**Describe the problem**

I receive the error ""Inconsistent CUDA toolkit path: /usr vs /usr/lib"" when running `./configure`. I believe I should not receive the error.

**Any other info / logs**

Console output:

```
~/tensorflow % ./configure
You have bazel 2.0.0 installed.
Please specify the location of python. [Default is /usr/bin/python]: /usr/bin/python3


Found possible Python library paths:
  /usr/local/lib/python3.7/dist-packages
  /usr/lib/python3.7/dist-packages
  /usr/lib/python3/dist-packages
Please input the desired Python library path to use.  Default is [/usr/local/lib/python3.7/dist-packages]

Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: 
No OpenCL SYCL support will be enabled for TensorFlow.

Do you wish to build TensorFlow with ROCm support? [y/N]: 
No ROCm support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: y
CUDA support will be enabled for TensorFlow.

Do you wish to build TensorFlow with TensorRT support? [y/N]: 
No TensorRT support will be enabled for TensorFlow.

Inconsistent CUDA toolkit path: /usr vs /usr/libAsking for detailed CUDA configuration... ^C
```

At the time of writing, the error comes from [`third_party/gpus/find_cuda_config.py:292`](https://github.com/tensorflow/tensorflow/blob/255f590ab64e637f49288883013d35efa0633b35/third_party/gpus/find_cuda_config.py#L292). The error occurs because, on my system, `cuda_binary_dir` evaluates to `/usr/bin`, while `nvvm_library_dir` evaluates to `/usr/lib/nvidia-cuda-toolkit/libdevice`. Although I'm using Debian 10, which isn't officially supported, this error can also occur in Ubuntu 20.04 if the user installed `nvcc` via the [`nvidia-cuda-toolkit`](https://packages.ubuntu.com/focal/amd64/nvidia-cuda-toolkit/filelist) package, which installs `nvcc` in two locations:

* `/usr/bin/nvcc`
* `/usr/lib/nvidia-cuda-toolkit/bin/nvcc`

~~The solution I tentatively suggest is to remove the consistency check from `find_cuda_config.py` because it's merely a heuristic. As a result, the check might cause `./configure` to proceed when it should exit early, or to exit early when it should proceed.~~

---
**Edit:** As pointed out by @tensorfoo and @ambertide, removing the consistency check doesn't work. A more reliable workaround is to install the cuda toolkit using Nvidia's .run file installer."
40200,Quantization of LeNET model using MNIST dataset breaks during model freeze,"I'm trying to train Lenet-net using the MNIST dataset from [here](http://yann.lecun.com/exdb/mnist/ ) and to quantize its float model. My steps are the following:

Firstly, I have applied MNIST dataset to train the classifier which works fines. 

```
python3 train_image_classifier.py --dataset_dir=tmp/mnist --dataset_name=mnist --train_dir=train/mnist --model_name=lenet --clone_on_cpu=true --max_number_of_steps=50000 --quantize_delay=40000
```

Secondly, I have exported the trained model to the pb format and it works well.

```
python3 export_inference_graph.py --dataset_dir=tmp/mnist --dataset_name=mnist --train_dir=train/mnist --model_name=lenet --checkpoint=train/mnist/model.ckpt-50000 --quantize --output_file=mnist.pb 
```

Finally, I try to freeze graph using 
```
freeze_graph --input_graph=mnist.pb --input_checkpoint=train/mnist/model.ckpt-50000 --output_graph=mnist_frozen.pb --input_binary=true --output_node_names=Predictions/Reshape_1 
``` 

but the following error occurred

```
InvalidArgumentError: Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:

Assign requires shapes of both tensors to match. lhs shape= [5,5,3,32] rhs shape= [5,5,1,32] 
```

Please can you advise how to freeze it correctly?


BTW, I have tried other models like CIFAR10 and all process works fine.
"
40199,Rolled RNN cannot be converted to INT8,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.4 LTS
- TensorFlow installed from (source or binary): tf-nightly
- TensorFlow version (use command below): 2.2.0.dev20200508 (also happens with 2.3.0.dev20200605)
- Python version: 3.7.4

**Describe the current behavior**
When converting a rolled RNN model to INT8, the conversion fails with the following error:

```
TypeError: pybind11::init(): factory function returned nullptr
During handling of the above exception, another exception occurred:
...
ValueError: Failed to parse the model: pybind11::init(): factory function returned nullptr.
```

**Describe the expected behavior**
The conversion should be successful.

**Standalone code to reproduce the issue**
Please find the gist [here](https://colab.research.google.com/gist/MatteoArm/02a4f032cab5b58a414d741b78107de1/untitled0.ipynb)

**Other info / logs** Include any logs or source code that would be helpful to
My traceback:

```
Traceback (most recent call last):
  File ""/opt/anaconda/3/envs/P3.7.4_TF2.2.0.dev20200508/lib/python3.7/site-packages/tensorflow/lite/python/optimize/calibrator.py"", line 51, in __init__
    _calibration_wrapper.CalibrationWrapper(model_content))
TypeError: pybind11::init(): factory function returned nullptr

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""rnn_rolled_issue.py"", line 83, in <module>
    tflite_model_INT8 = converter.convert()
  File ""/opt/anaconda/3/envs/P3.7.4_TF2.2.0.dev20200508/lib/python3.7/site-packages/tensorflow/lite/python/lite.py"", line 639, in convert
    output_tensors)
  File ""/opt/anaconda/3/envs/P3.7.4_TF2.2.0.dev20200508/lib/python3.7/site-packages/tensorflow/lite/python/lite.py"", line 505, in convert
    constants.FLOAT, True)
  File ""/opt/anaconda/3/envs/P3.7.4_TF2.2.0.dev20200508/lib/python3.7/site-packages/tensorflow/lite/python/lite.py"", line 337, in _calibrate_quantize_model
    calibrate_quantize = _calibrator.Calibrator(result)
  File ""/opt/anaconda/3/envs/P3.7.4_TF2.2.0.dev20200508/lib/python3.7/site-packages/tensorflow/lite/python/optimize/calibrator.py"", line 53, in __init__
    raise ValueError(""Failed to parse the model: %s."" % e)
ValueError: Failed to parse the model: pybind11::init(): factory function returned nullptr.
```
"
40196,2.3 Nightly build produces error when initializing system in TF documentation's Colab tutorial,"**System information**
- Have I written custom code: NO
- TensorFlow installed from: pip (tf-nightly)
- TensorFlow version: 2.3.0-dev20200605

**Describe the current behavior**
TPU won't initialize in colab using the nightly build.

**Describe the expected behavior**
Run the https://www.tensorflow.org/guide/tpu notebook successfully, as one would if using TF 2.2.

**Standalone code to reproduce the issue**
1. Load https://www.tensorflow.org/guide/tpu in colab.
2. Run `!pip install tf-nightly` in a new cell before running anything else.
3. Run the TPU initialization section of the notebook.
4. Observe the following error:

```InvalidArgumentError: NodeDef expected inputs 'string' do not match 0 inputs specified; Op<name=_Send; signature=tensor:T -> ; attr=T:type; attr=tensor_name:string; attr=send_device:string; attr=send_device_incarnation:int; attr=recv_device:string; attr=client_terminated:bool,default=false; is_stateful=true>; NodeDef: {{node _Send}}
```


"
40195,Allow overriding the build method for Metrics,"**System information**
- TensorFlow version (you are using): 2.2
- Are you willing to contribute it (Yes/No): yes



**Describe the feature and the current behavior/state.**
Most `tf.keras.metrics.Metric` subclasses today are accumulated as scalars and hence can have their accumulation tensors statically initialized in `__init__` before the Metric is used. There are exceptions to this where tensor shape is dependent values only accessible during runtime. An example of an exception is the `MeanTensor` metric (https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/keras/metrics.py#L2812-L2921), where the tensor shape is determined in a special `_build` method. That unfortunately uses protected parts of the API.

This was a problem for me when implementing/augmenting a custom RSquare metric for `tensorflow_addons` (https://www.tensorflow.org/addons/api_docs/python/tfa/metrics/RSquare). When performing multivariate regression, it is necessary to calculate the R2 metric for each variable separately, and hence I would really like to do something similar to what is done in `MeanTensor`, i.e. setting the shape of the accumulation tensors based on the de facto dimensionality of model outputs/labels during runtime. I shied away from this, however, due to the use of protected API components. The consequence is that the user of the Metric needs to specify the shape of the labels up front, which is error prone and annoying. Discussing this with one of the maintainers of `tensorflow_addons`, it was mentioned that there are reasons to expect `Metric` to properly support a `build` method in the future (https://github.com/tensorflow/addons/pull/1310#issuecomment-599143485). This feature request is partly to communicate this need, but with a focus on a specific use case rather than a specific implementation. I don't know if this has been covered in other issues. Perhaps you know, @gabrieldemarmiesse?

**Will this change the current api? How?**
I don't want to recommend any implementation over others as long as the use case is catered to: Dynamic shape metrics.

**Who will benefit with this feature?**
Developers and users of custom `tf.keras.metrics.Metric` subclasses.

**Any Other info.**
"
40194,How to feed multi tf.data.Dataset objects into a multi-input/output model in tensorflow,"I how to deal with multi input/output when the input is numpy arrays. However, my inputs are all tf.data.datasets objects. And I would like to feed the latter into a multi-input/output in tensorflow keras 2.1. 

    def prepare_dataset(...):
        X_train = tf.data.Dataset.from_tensor_slices(final_df_QS_normalized_train_val)
        X_train = X_train.window(train_window_length, shift=1, drop_remainder=True)
        X_train = X_train.flat_map(lambda window : window.batch(train_window_length))
        X_train = X_train.shuffle(100, seed=42)
        X_train = X_train.batch(batch_size)

        y_train = tf.data.Dataset.from_tensor_slices(final_df_DQ_normalized_train_val)
        y_train = y_train.window(train_window_length, shift=1, drop_remainder=True)
        y_train = y_train.flat_map(lambda window : window.batch(train_window_length))
        y_train = y_train.shuffle(100, seed=42)
        y_train = y_train.batch(batch_size)

        sample_weights_train = tf.data.Dataset.from_tensor_slices(sample_weights_df_train_val)
        sample_weights_train = sample_weights_train.window(train_window_length, shift=1, drop_remainder=True)
        sample_weights_train = sample_weights_train.flat_map(lambda window : window.batch(train_window_length))
        sample_weights_train = sample_weights_train.shuffle(100, seed=42)
        sample_weights_train = sample_weights_train.batch(batch_size)
        ..... # the same is applied to the validation data part....
        return X_train, y_train, sample_weights_train

Then I have a method that creates a model and return the input/output as follows:

    def build_uncomplied_model(hparams, CASE_UPC_CD):
        inputs = tf.keras.Input(shape=(None, 1), name=CASE_UPC_CD + ""_input"")
        x = inputs

        if hparams['model_uncertainty']:
                x = layers.Bidirectional(layers.LSTM(hparams[""cell_size_1""], return_sequences=True, 
                                                    dropout=hparams['dropout']), merge_mode=hparams['merge_mode'])(x, training=True)
        else:
                x = layers.Bidirectional(layers.LSTM(hparams[""cell_size_1""], return_sequences=True, 
                                                    dropout=hparams['dropout']))(x)

        outputs = layers.TimeDistributed(layers.Dense(1), name=CASE_UPC_CD + ""_output"")(x)

        return inputs, outputs

Then inside a for loop, I created a multiple of this model. All inputs/outputs are stored in a list to be used later in model creation. 

    c = 0
    for CASE_UPC_CD in tqdm(final_df_QS_normalized_train.columns.values):
        c += 1
        logdir = os.path.join(ROOT_DIR, ""logs_SeparateLSTMs"", time_now, CASE_UPC_CD)

        X_train, y_train, sample_weights_train, X_valid, y_valid, sample_weights_valid = \
                                                       prepare_dataset(final_df_QS_normalized_train[CASE_UPC_CD], 
                                                       final_df_DQ_normalized_train[CASE_UPC_CD], 
                                                       final_df_QS_normalized_valid[CASE_UPC_CD], 
                                                       final_df_DQ_normalized_valid[CASE_UPC_CD], 
                                                       sample_weights_df_train[CASE_UPC_CD], 
                                                       sample_weights_df_valid[CASE_UPC_CD], hparams)

        train_input[CASE_UPC_CD + ""_input""] = X_train
        train_output[CASE_UPC_CD + ""_output""] = y_train

        valid_input[CASE_UPC_CD + ""_input""] = X_valid
        valid_output[CASE_UPC_CD + ""_output""] = y_valid

        inputs, outputs = build_uncomplied_model(hparams, CASE_UPC_CD)

        inputs_all.append(inputs)
        outputs_all.append(outputs)

        if c == 10:
            break

    train_dataset = tf.data.Dataset.from_tensor_slices((train_input, train_output))
    valid_dataset = tf.data.Dataset.from_tensor_slices((valid_input, valid_output))

This last line is throwing an error:

    ValueError: Unbatching a dataset is only supported for rank >= 1

How to solve this issue? Any help is much appreciated
"
40193,Would be better to replace the signature of ReadNBytes to not have `size_t` as the type of the last argument.,"Would be better to replace the signature of ReadNBytes to not have `size_t` as the type of the last argument. Let's try to do this in another PR (as there would be multiple places to change)

_Originally posted by @mihaimaruseac in https://github.com/tensorflow/tensorflow/pull/40133/files_"
40192,'Function could not be transformed and will be executed as-is' while training RNN with Embedding in Keras,"I got the attached error saying that I should report to ""AutoGraph team"".

I was training a following toy-model:

```
model = keras.Sequential()

model.add(keras.layers.Embedding(vocab_size, 2, input_length = max_len))
model.add(keras.layers.Flatten())             
model.add(keras.layers.Dense(1, activation = 'sigmoid'))
```

with `tf.keras`, tensorflow version == '2.0.0'.

Operating system = Win10
Python = 3.6

```
Train on 14 samples
Epoch 1/300
WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000001F5E571F620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'
WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000001F5E571F620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'
Epoch 2/300
Epoch 3/300
Epoch 4/300
Epoch 5/300
Epoch 6/300
Epoch 7/300
Epoch 8/300
Epoch 9/300
Epoch 10/300
Epoch 11/300
Epoch 12/300
Epoch 13/300
Epoch 14/300
Epoch 15/300
Epoch 16/300
Epoch 17/300
Epoch 18/300
Epoch 19/300
Epoch 20/300
Epoch 21/300
Epoch 22/300
Epoch 23/300
Epoch 24/300
Epoch 25/300
Epoch 26/300
Epoch 27/300
Epoch 28/300
Epoch 29/300
Epoch 30/300
Epoch 31/300
Epoch 32/300
Epoch 33/300
Epoch 34/300
Epoch 35/300
Epoch 36/300
Epoch 37/300
Epoch 38/300
Epoch 39/300
Epoch 40/300
Epoch 41/300
Epoch 42/300
Epoch 43/300
Epoch 44/300
Epoch 45/300
Epoch 46/300
Epoch 47/300
Epoch 48/300
Epoch 49/300
Epoch 50/300
Epoch 51/300
Epoch 52/300
Epoch 53/300
Epoch 54/300
Epoch 55/300
Epoch 56/300
Epoch 57/300
Epoch 58/300
Epoch 59/300
Epoch 60/300
Epoch 61/300
Epoch 62/300
Epoch 63/300
Epoch 64/300
Epoch 65/300
Epoch 66/300
Epoch 67/300
Epoch 68/300
Epoch 69/300
Epoch 70/300
Epoch 71/300
Epoch 72/300
Epoch 73/300
Epoch 74/300
Epoch 75/300
Epoch 76/300
Epoch 77/300
Epoch 78/300
Epoch 79/300
Epoch 80/300
Epoch 81/300
Epoch 82/300
Epoch 83/300
Epoch 84/300
Epoch 85/300
Epoch 86/300
Epoch 87/300
Epoch 88/300
Epoch 89/300
Epoch 90/300
Epoch 91/300
Epoch 92/300
Epoch 93/300
Epoch 94/300
Epoch 95/300
Epoch 96/300
Epoch 97/300
Epoch 98/300
Epoch 99/300
Epoch 100/300
Epoch 101/300
Epoch 102/300
Epoch 103/300
Epoch 104/300
Epoch 105/300
Epoch 106/300
Epoch 107/300
Epoch 108/300
Epoch 109/300
Epoch 110/300
Epoch 111/300
Epoch 112/300
Epoch 113/300
Epoch 114/300
Epoch 115/300
Epoch 116/300
Epoch 117/300
Epoch 118/300
Epoch 119/300
Epoch 120/300
Epoch 121/300
Epoch 122/300
Epoch 123/300
Epoch 124/300
Epoch 125/300
Epoch 126/300
Epoch 127/300
Epoch 128/300
Epoch 129/300
Epoch 130/300
Epoch 131/300
Epoch 132/300
Epoch 133/300
Epoch 134/300
Epoch 135/300
Epoch 136/300
Epoch 137/300
Epoch 138/300
Epoch 139/300
Epoch 140/300
Epoch 141/300
Epoch 142/300
Epoch 143/300
Epoch 144/300
Epoch 145/300
Epoch 146/300
Epoch 147/300
Epoch 148/300
Epoch 149/300
Epoch 150/300
Epoch 151/300
Epoch 152/300
Epoch 153/300
Epoch 154/300
Epoch 155/300
Epoch 156/300
Epoch 157/300
Epoch 158/300
Epoch 159/300
Epoch 160/300
Epoch 161/300
Epoch 162/300
Epoch 163/300
Epoch 164/300
Epoch 165/300
Epoch 166/300
Epoch 167/300
Epoch 168/300
Epoch 169/300
Epoch 170/300
Epoch 171/300
Epoch 172/300
Epoch 173/300
Epoch 174/300
Epoch 175/300
Epoch 176/300
Epoch 177/300
Epoch 178/300
Epoch 179/300
Epoch 180/300
Epoch 181/300
Epoch 182/300
Epoch 183/300
Epoch 184/300
Epoch 185/300
Epoch 186/300
Epoch 187/300
Epoch 188/300
Epoch 189/300
Epoch 190/300
Epoch 191/300
Epoch 192/300
Epoch 193/300
Epoch 194/300
Epoch 195/300
Epoch 196/300
Epoch 197/300
Epoch 198/300
Epoch 199/300
Epoch 200/300
Epoch 201/300
Epoch 202/300
Epoch 203/300
Epoch 204/300
Epoch 205/300
Epoch 206/300
Epoch 207/300
Epoch 208/300
Epoch 209/300
Epoch 210/300
Epoch 211/300
Epoch 212/300
Epoch 213/300
Epoch 214/300
Epoch 215/300
Epoch 216/300
Epoch 217/300
Epoch 218/300
Epoch 219/300
Epoch 220/300
Epoch 221/300
Epoch 222/300
Epoch 223/300
Epoch 224/300
Epoch 225/300
Epoch 226/300
Epoch 227/300
Epoch 228/300
Epoch 229/300
Epoch 230/300
Epoch 231/300
Epoch 232/300
Epoch 233/300
Epoch 234/300
Epoch 235/300
Epoch 236/300
Epoch 237/300
Epoch 238/300
Epoch 239/300
Epoch 240/300
Epoch 241/300
Epoch 242/300
Epoch 243/300
Epoch 244/300
Epoch 245/300
Epoch 246/300
Epoch 247/300
Epoch 248/300
Epoch 249/300
Epoch 250/300
Epoch 251/300
Epoch 252/300
Epoch 253/300
Epoch 254/300
Epoch 255/300
Epoch 256/300
Epoch 257/300
Epoch 258/300
Epoch 259/300
Epoch 260/300
Epoch 261/300
Epoch 262/300
Epoch 263/300
Epoch 264/300
Epoch 265/300
Epoch 266/300
Epoch 267/300
Epoch 268/300
Epoch 269/300
Epoch 270/300
Epoch 271/300
Epoch 272/300
Epoch 273/300
Epoch 274/300
Epoch 275/300
Epoch 276/300
Epoch 277/300
Epoch 278/300
Epoch 279/300
Epoch 280/300
Epoch 281/300
Epoch 282/300
Epoch 283/300
Epoch 284/300
Epoch 285/300
Epoch 286/300
Epoch 287/300
Epoch 288/300
Epoch 289/300
Epoch 290/300
Epoch 291/300
Epoch 292/300
Epoch 293/300
Epoch 294/300
Epoch 295/300
Epoch 296/300
Epoch 297/300
Epoch 298/300
Epoch 299/300
Epoch 300/300

<tensorflow.python.keras.callbacks.History at 0x1f5ebf5b320>
```"
40188,No documentatio non how to manipulate a python.data.ops.dataset_oops.BatchDataset,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:
https://keras.io/api/preprocessing/image/

## Description of issue (what needs changing):
the documentation says that the object returned from the tf.keras.preprocessing.image_dataset_from_directory function is a tf.data.Dataset object.  However, there is no documentation on how to manipulate it or get details how to use it. I
### Clear description
I have a large dataset and i am trying to split it into testing and training, however while i can ""complete a validation split in the  function (as documented) this is no documentation on how I can address the training or validation subsets.  Should i convert the objects to np array or can it be manipulated within TF and if so how?


### Correct links

Is the link to the source code correct?

### Parameters defined

train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    wk_dir,
    labels=""inferred"",
    label_mode=""int"",
    class_names=None,
    color_mode=""grayscale"",
    batch_size=batches,
    image_size=image_dim,
    shuffle=True,
    seed=1968,
    validation_split=0.2,
    subset=""training"",
    interpolation=""bilinear"",
    follow_links=False,
)

### Returns defined

Found 127842 files belonging to 3 classes.
Using 102274 files for training.

print(type(train_ds))
<class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>

what are the attributes which can be used to , get details and possible split this object type?
AttributeError: 'BatchDataset' object has no attribute 'eval'

### Raises listed and defined




"
40187,"When using batch normalization layer in distributed training, saved model couldn't be used to predict or serve in tfserving","**System information**
- Have I written custom code: YES
- OS Platform and Distribution: WIN 10
- TensorFlow installed from: pip
- TensorFlow version: 2.2.0
- Python version:3.7.7
- CPU ONLY

**Describe the current behavior**

When using batch normalization layer (eithor `SyncBatchNormalization` or `BatchNormalization`)  in `MultiWorkerMirroredStrategy` distributed training, training process works well, and model could be saved as well.

But when I tried to load the model (`keras.models.load_model`) to predict, it would raise error. And when I tried to use `saved_model_cli run` or `tfserving` for predicting, it will hang and get no response.

**Standalone code to reproduce the issue**

Note that I don't know how to use `MultiWorkerMirroredStrategy` in `colab`, so I just give the reproduce steps here, and it's very easy.

1. Training Code (worker.py)

```python
import os
import json

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from absl import app, flags
import numpy as np

FLAGS = flags.FLAGS
flags.DEFINE_string(""logs"", ""logs"", ""logs dir"")
flags.DEFINE_integer(""index"", 0, ""worker index"")


class ThreeLayerMLP(keras.Model):
    def __init__(self, name=None):
        super().__init__(name=name)
        self.dense_1 = layers.Dense(32, activation='relu', name='dense_1')
        self.bn = layers.experimental.SyncBatchNormalization()
        self.dense_2 = layers.Dense(16, activation='relu', name='dense_2')
        self.pred_layer = layers.Dense(
            1,
            activation='sigmoid',
            name='predictions',
        )

    def call(self, inputs, training=None):
        print(inputs.shape)
        x = self.dense_1(inputs)
        x = self.bn(x)
        x = self.dense_2(x)
        return self.pred_layer(x)


def prepare_data():
    np.random.seed(0)
    x_train, y_train = (
        np.random.random((6000, 32)),
        np.random.randint(2, size=(6000, 1)),
    )

    x_val, y_val = (
        np.random.random((1000, 32)),
        np.random.randint(2, size=(1000, 1)),
    )

    return ((x_train, y_train), (x_val, y_val))


def main(argv):
    del argv  # Unused args
    tf_config = {
        ""cluster"": {
            ""worker"": [""localhost:12345"", ""localhost:12346""],
        },
        ""task"": {
            ""index"": FLAGS.index,
            ""type"": ""worker""
        }
    }
    os.environ[""TF_CONFIG""] = json.dumps(tf_config)
    print(json.loads(os.environ[""TF_CONFIG""]))

    # distributed strategy
    strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()
    BATCH_SIZE_PER_REPLICA = 64
    BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync
    print('Number of devices: %d' % strategy.num_replicas_in_sync)

    with strategy.scope():
        model = ThreeLayerMLP(name='3_layer_mlp')
        model.compile(
            loss=tf.keras.losses.BinaryCrossentropy(),
            optimizer=keras.optimizers.RMSprop(),
            metrics=[""AUC""],
        )

    tensorboard_callback = tf.keras.callbacks.TensorBoard(
        log_dir=FLAGS.logs,
        histogram_freq=1,
        update_freq='batch',
    )

    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
        filepath=os.path.join(FLAGS.logs, ""checkpoints"", ""ckpt""), )

    ((x_train, y_train), (x_val, y_val)) = prepare_data()

    model.fit(
        x_train,
        y_train,
        epochs=1,
        batch_size=BATCH_SIZE,
        validation_data=(x_val, y_val),
        callbacks=[tensorboard_callback, checkpoint_callback],
    )

    model_dir = os.path.join(FLAGS.logs, ""models"", str(FLAGS.index))
    model.save(model_dir)


if __name__ == '__main__':
    app.run(main)
```

2. Distributed training: open 2 terminal with tensorflow 2.2.0 installed, and execute the command below:

```shell
python worker.py --index=0
python worker.py --index=1
```

3. Model load and predict code:

```python
from tensorflow import keras
import numpy as np


def main():
    model = keras.models.load_model('logs/models/0')
    model.summary()
    x_test, y_test = prepare_test_data()
    print(model.predict(x_test))

def prepare_test_data():
    x_test, y_test = (
        np.random.random((10, 32)),
        np.random.randint(2, size=(10, 1)),
    )

    return x_test, y_test

if __name__ == '__main__':
    main()
```

execute the code above and will raise error:

```shell
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation 3_layer_mlp/StatefulPartitionedCall/StatefulPartitionedCall/sync_batch_normalization/Cast/allreduce/CollectiveReduce: {{node 3_layer_mlp/StatefulPartitionedCall/StatefulPartitionedCall/sync_batch_normalization/Cast/allreduce/CollectiveReduce}} was explicitly assigned to /job:worker/replica:0/task:0/device:CPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0 ]. Make sure the device specification refers to a valid device.
         [[3_layer_mlp/StatefulPartitionedCall/StatefulPartitionedCall/sync_batch_normalization/Cast/allreduce/CollectiveReduce]] [Op:__inference_predict_function_1439]
```

4. saved_model_cli:

```shell
saved_model_cli run --dir logs/models/0 --tag_set serve --signature_def serving_default --input_expr ""input_1=np.random.random((1,32))""
```

after execute the command above, the process will hang and get no response. The same behavior occur when sending http predict request to tfserving.

If I remove the `batchnormalization` layer, erverything will back to normal."
40186,Importing tensorflow using python -c causes segmentation fault on interpreter exit,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution: Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: 3.8.0b4
- CUDA/cuDNN version: 10.2
- GPU model and memory: Quadro P2000

**Describe the current behavior**:
Running  `python -c ""import tensorflow""` results in a segmentation fault:

`[1]    25266 segmentation fault (core dumped)  python -c ""import tensorflow""`

**Describe the expected behavior**
No segmentation fault happens, the program just exits.

**Standalone code to reproduce the issue**

Run `python -c ""import tensorflow""` using python 3.8.

I found the issue because I was running tensorflow in a subprocess like this:

```python
import subprocess


def call_subprocess_command(*command):
    with subprocess.Popen(args=command, text=True, shell=False,
                          stdout=subprocess.PIPE, stderr=subprocess.STDOUT) as process:
        assert process.stdout is not None
        for line in iter(process.stdout.readline, """"):
            line = line.strip()
            print(""(subprocess)"", line)

    if process.returncode != 0:
        raise RuntimeError(f""{command} failed with exit code {process.returncode}"")


call_subprocess_command(""python"", ""-X"", ""faulthandler"", ""-c"", ""import tensorflow;print(tensorflow.__version__)"")
```

This prints the version, thus indicating that the segmentation fault happens when the interpreter exits.
```
(subprocess) 2.2.0
(subprocess) Fatal Python error: Segmentation fault
(subprocess) 
(subprocess) Current thread 0x00007fe3c40f0080 (most recent call first):
Traceback (most recent call last):
  File ""/home/veith/.config/JetBrains/PyCharm2020.1/scratches/scratch.py"", line 16, in <module>
    call_subprocess_command(""python"", ""-X"", ""faulthandler"", ""-c"", ""import tensorflow;print(tensorflow.__version__)"")
  File ""/home/veith/.config/JetBrains/PyCharm2020.1/scratches/scratch.py"", line 13, in call_subprocess_command
    raise RuntimeError(f""{command} failed with exit code {process.returncode}"")
RuntimeError: ('python', '-X', 'faulthandler', '-c', 'import tensorflow;print(tensorflow.__version__)') failed with exit code -11

Process finished with exit code 1
```
"
40185,[RNN] dynamic input shape support,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.15.4
- TensorFlow installed from (source or binary): binary
- TensorFlow version (or github SHA if from source): tf-nightly (2.3.0.dev20200604)


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
https://colab.research.google.com/drive/1BtT2DkitM6PQKxOAsd-S0IU2Fwh2Reo1?usp=sharing
```

**Failure details**
I was heard about the support for unknown dimensions in TF Lite (https://github.com/tensorflow/tensorflow/issues/29590#issuecomment-580951882), then I tried to convert my model mainly followed by the instructions (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/examples/experimental_new_converter/Keras_LSTM_fusion_Codelab.ipynb), but with replacing specific dimensions in TensorSpec() to None, the model exported to SavedModel format successfully. However, the conversion of TF Lite converter didn't work fine (errors shown in Colab).

Before this, I've also tried fixed size in TenserSpec(), then called resize_tensor_input() & allocate_tensors() on the TF Lite interpreter's side, but it didn't work either :(

Are there any proper ways for model in TF Lite to accept variable shape data?"
40183,Very slow quantized tflite model,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (or github SHA if from source): 2.2.0


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.representative_dataset = representative_dataset_gen
converter.inference_input_type = tf.uint8
converter.inference_output_type = tf.uint8
tf_lite_model = converter.convert()

with open(""model.tflite"", ""wb"") as f:
    f.write(tf_lite_model)
```

**The output from the converter invocation**

```
2020-06-05 10:53:29.063149: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
2020-06-05 10:53:29.063233: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-06-05 10:53:29.080730: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize
2020-06-05 10:53:29.080748: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.006ms.
2020-06-05 10:53:29.080752: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-06-05 10:53:32.284115: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
2020-06-05 10:53:32.284242: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-06-05 10:53:33.407982: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize
2020-06-05 10:53:33.408011: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 1092 nodes (-568), 1139 edges (-568), time = 474.12ms.
2020-06-05 10:53:33.408016: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 1092 nodes (0), 1139 edges (0), time = 213.886ms.
```

**Also, please include a link to the saved model or GraphDef**

```
https://drive.google.com/file/d/1imjVvw8IqQ6tvQRYaKJi_ynxQUHBBSH_/view?usp=sharing
```

**Failure details**
Before conversion, running standard keras model on CPU took ~300ms per frame. After conversion it takes ~55s. 
Eventually I want to deploy the model on Coral Dev Board. Currently after compiling it for edge TPU inference takes ~4s using Coral.

Is it normal that it's so slow? I expect it to be at least not slower than before conversion. 

**Any other info / logs**
Logs from edge tpu compiler:
```
Edge TPU Compiler version 2.1.302470888
Input: model.tflite
Output: model_edgetpu.tflite

Operator                       Count      Status

ADD                            1          More than one subgraph is not supported
ADD                            71         Mapped to Edge TPU
MAX_POOL_2D                    1          Mapped to Edge TPU
PAD                            35         Mapped to Edge TPU
MUL                            35         Mapped to Edge TPU
CONCATENATION                  1          More than one subgraph is not supported
QUANTIZE                       1          Operation is otherwise supported, but not mapped due to some unspecified limitation
QUANTIZE                       3          Mapped to Edge TPU
CONV_2D                        115        Mapped to Edge TPU
CONV_2D                        4          More than one subgraph is not supported
DEQUANTIZE                     1          Operation is working on an unsupported data type
RESIZE_BILINEAR                2          Operation is otherwise supported, but not mapped due to some unspecified limitation
RESIZE_BILINEAR                6          Mapped to Edge TPU
SOFTMAX                        1          Max 16000 elements supported

```

"
40182,ImportError: cannot import name 'function_pb2',"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CENTOS 7.8
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source(Master)
- TensorFlow version: 2.2
- Python version: 3.6.8
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): Build label: 3.0.0
- GCC/Compiler version (if compiling from source): gcc version 7.3.1 20180303 (Red Hat 7.3.1-5) (GCC) 
- CUDA/cuDNN version: 10.2
- GPU model and memory: NVIDIA (TESLA M60)



**Describe the problem**

hittiing the following error after succesful bazel build.
INFO: 0 processes.
INFO: Build completed successfully
./bazel-bin/tensorflow/tools/pip_package/build_pip_package --nightly_flag /tmp/tensorflow_pkg

pip install /tmp/tensorflow_pkg/tensorflow-2.2.0-cp36-cp36m-linux_x86_64.whl 
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""tensorflow/python/__init__.py"", line 40, in <module>
    from tensorflow.python.eager import context
ImportError: No module named eager


 import tensorflow as tf
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/nobackup/tensorflow/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""/nobackup/tensorflow/tensorflow/python/__init__.py"", line 40, in <module>
    from tensorflow.python.eager import context
  File ""/nobackup/tensorflow/tensorflow/python/eager/context.py"", line 32, in <module>
    from tensorflow.core.framework import function_pb2
ImportError: cannot import name 'function_pb2'

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""tensorflow/python/__init__.py"", line 40, in <module>
    from tensorflow.python.eager import context
ImportError: No module named eager
"
40180,TFLite cross-compiling arm64 build error?,"As I am currently trying to Tensorflow lite for ARM64 architecture, I just try to follow the instructions from below: https://www.tensorflow.org/lite/guide/build_arm64#cross-compile_for_arm64

But I simply get a compilation error: tensorflow/lite/tools/make/downloads/ruy/ruy/cpuinfo.cc:9:21: fatal error: cpuinfo.h: No such file or directory

I am surprised this starting build not working out of the box.

Btw, I am trying to do the above in Ubuntu 16.04 VM.

------------------------

### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: No
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**:
-   **TensorFlow installed from (source or binary)**:From Git clone
-   **TensorFlow version (use command below)**:latest
-   **Python version**:
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**:
-   **GPU model and memory**:
-   **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
40178,Always exceeds 10% of free system memory.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
ubuntu 16.04 LTS
- TensorFlow installed from (source or binary):
conda 4.8.3
- TensorFlow version (use command below):
tensorflow-gpu v2.2.0
- Python version:
python 3.7.7
- GCC/Compiler version (if compiling from source):
gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
- CUDA/cuDNN version:
CUDA Version 10.1.168
- GPU model and memory:
2 * GeForce RTX 2080 Ti 11GB

**Describe the current behavior**
I can use the same input data and run the same model correctly on the tensorflow-gpu-v1.14, but it doesn't work when I use the tensorflow-gpu-v2.0 or tensorflow-gpu-v2.2.

After excute the fit function, it will raise an error:
tensorflow.python.framework.errors_impl.InternalError: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run GatherV2: Dst tensor is not initialized. [Op:GatherV2]

Also, when I change the enviroment to tensorflow-cpu-v2.0 or v2.2, it will work correctly but using CPU, that will be very slow.

**Describe the expected behavior**
It should run as well as when I used tensorflow-gpu-v1.14.
I'm sure the memory of GPU and CPU is enough. I tried many ways to solve it but not worked:
- `
gpus = tf.config.experimental.list_physical_devices('GPU')`
`tf.config.experimental.set_memory_growth(gpus[0], True)`
`tf.config.experimental.set_memory_growth(gpus[1], True)
`
- `os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'`
it will just hide the error message and not help.
- decrease the batch_size for fit, but it still invalid.
- reboot my computer, still not work.
- remove the enviroment and install again, still not work.

Is there anything wrong?

**Standalone code to reproduce the issue**
- x_train.shape: (1254521, 56, 40)
- y_train.shape: (1254521, 2)

My simple train function:
```
import numpy as np
import tensorflow as tf


def train(file_path):
    print('Loading data ...')
    x_train = np.float32(np.random.randint(-8, 8, size=[1254521, 56, 40]))
    y_train = [[1, 0] for _ in range(x_train.shape[0])]
    y_train = np.float32(y_train)

    print(x_train.shape, y_train.shape)

    print('Create model ...')
    data = tf.keras.Input(shape=[56, 40])
    x = tf.keras.layers.Reshape([56, 40, 1])(data)

    cnn_out = tf.keras.layers.Conv2D(8, (20, 5), strides=(1, 2))(x)
    cnn_output = tf.keras.layers.Reshape([37, 18 * 8])(cnn_out)

    gru_out = tf.keras.layers.GRU(20)(cnn_output)

    outputs = tf.keras.layers.Dense(2)(gru_out)

    my_model = tf.keras.Model(inputs=data, outputs=outputs)

    my_model.compile()

    print(my_model.summary())

    my_model.fit(x_train, y_train, epochs=100, batch_size=1024, validation_split=0.1)
    my_model.save(file_path)


if __name__ == '__main__':
    train(""test.h5"")

```

**Other info / logs** Include any logs or source code that would be helpful to
Full traceback of error:

```
Loading data ...
(1254521, 56, 40) (1254521, 2)
Create model ...
2020-06-05 16:26:08.953877: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-06-05 16:26:08.997184: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-05 16:26:08.997775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.635GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2020-06-05 16:26:08.997841: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-05 16:26:08.998395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.635GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2020-06-05 16:26:08.998559: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-06-05 16:26:08.999723: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-06-05 16:26:09.000912: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-06-05 16:26:09.001118: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-06-05 16:26:09.002557: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-06-05 16:26:09.003395: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-06-05 16:26:09.006865: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-06-05 16:26:09.007010: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-05 16:26:09.007707: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-05 16:26:09.008324: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-05 16:26:09.008891: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-05 16:26:09.009430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1
2020-06-05 16:26:09.009771: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-06-05 16:26:09.042664: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3192000000 Hz
2020-06-05 16:26:09.043165: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5615ceb22100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-06-05 16:26:09.043193: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-06-05 16:26:09.182570: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-05 16:26:09.182998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.635GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2020-06-05 16:26:09.183062: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-05 16:26:09.183455: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.635GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2020-06-05 16:26:09.183493: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-06-05 16:26:09.183504: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-06-05 16:26:09.183513: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-06-05 16:26:09.183523: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-06-05 16:26:09.183532: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-06-05 16:26:09.183541: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-06-05 16:26:09.183551: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-06-05 16:26:09.183586: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-05 16:26:09.184053: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-05 16:26:09.184672: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-05 16:26:09.185309: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-05 16:26:09.185863: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1
2020-06-05 16:26:09.185958: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-06-05 16:26:09.187361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-06-05 16:26:09.187379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 1 
2020-06-05 16:26:09.187385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N N 
2020-06-05 16:26:09.187389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 1:   N N 
2020-06-05 16:26:09.187506: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-05 16:26:09.187922: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-05 16:26:09.188338: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-05 16:26:09.188891: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-05 16:26:09.189454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9860 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
2020-06-05 16:26:09.189759: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-05 16:26:09.190357: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-05 16:26:09.190762: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10203 MB memory) -> physical GPU (device: 1, name: GeForce RTX 2080 Ti, pci bus id: 0000:08:00.0, compute capability: 7.5)
2020-06-05 16:26:09.192135: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5615cfe5f110 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-06-05 16:26:09.192150: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5
2020-06-05 16:26:09.192155: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): GeForce RTX 2080 Ti, Compute Capability 7.5
Model: ""model""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 56, 40)]          0         
_________________________________________________________________
reshape (Reshape)            (None, 56, 40, 1)         0         
_________________________________________________________________
conv2d (Conv2D)              (None, 37, 18, 8)         808       
_________________________________________________________________
reshape_1 (Reshape)          (None, 37, 144)           0         
_________________________________________________________________
gru (GRU)                    (None, 20)                9960      
_________________________________________________________________
dense (Dense)                (None, 2)                 42        
=================================================================
Total params: 10,810
Trainable params: 10,810
Non-trainable params: 0
_________________________________________________________________
None
2020-06-05 16:26:10.028753: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 11240508160 exceeds 10% of free system memory.
2020-06-05 16:26:24.748619: W tensorflow/core/common_runtime/bfc_allocator.cc:434] Allocator (GPU_0_bfc) ran out of memory trying to allocate 10.47GiB (rounded to 11240508160)
Current allocation summary follows.
2020-06-05 16:26:24.748646: I tensorflow/core/common_runtime/bfc_allocator.cc:934] BFCAllocator dump for GPU_0_bfc
2020-06-05 16:26:24.748653: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (256):   Total Chunks: 15, Chunks in use: 15. 3.8KiB allocated for chunks. 3.8KiB in use in bin. 248B client-requested in use in bin.
2020-06-05 16:26:24.748658: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (512):   Total Chunks: 1, Chunks in use: 1. 512B allocated for chunks. 512B in use in bin. 480B client-requested in use in bin.
2020-06-05 16:26:24.748663: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (1024):  Total Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.
2020-06-05 16:26:24.748668: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (2048):  Total Chunks: 2, Chunks in use: 1. 6.2KiB allocated for chunks. 3.2KiB in use in bin. 3.1KiB client-requested in use in bin.
2020-06-05 16:26:24.748675: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (4096):  Total Chunks: 2, Chunks in use: 1. 9.5KiB allocated for chunks. 4.8KiB in use in bin. 4.7KiB client-requested in use in bin.
2020-06-05 16:26:24.748680: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (8192):  Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-06-05 16:26:24.748685: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (16384):         Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-06-05 16:26:24.748691: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (32768):         Total Chunks: 2, Chunks in use: 1. 91.8KiB allocated for chunks. 33.8KiB in use in bin. 33.8KiB client-requested in use in bin.
2020-06-05 16:26:24.748695: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (65536):         Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-06-05 16:26:24.748700: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (131072):        Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-06-05 16:26:24.748705: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (262144):        Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-06-05 16:26:24.748710: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (524288):        Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-06-05 16:26:24.748716: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (1048576):       Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-06-05 16:26:24.748721: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (2097152):       Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-06-05 16:26:24.748726: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (4194304):       Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-06-05 16:26:24.748731: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (8388608):       Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-06-05 16:26:24.748736: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (16777216):      Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-06-05 16:26:24.748741: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (33554432):      Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-06-05 16:26:24.748746: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (67108864):      Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-06-05 16:26:24.748751: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (134217728):     Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-06-05 16:26:24.748756: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (268435456):     Total Chunks: 1, Chunks in use: 0. 9.63GiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-06-05 16:26:24.748761: I tensorflow/core/common_runtime/bfc_allocator.cc:957] Bin for 10.47GiB was 256.00MiB, Chunk State: 
2020-06-05 16:26:24.748768: I tensorflow/core/common_runtime/bfc_allocator.cc:963]   Size: 9.63GiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 33.8KiB | Requested Size: 33.8KiB | in_use: 1 | bin_num: -1
2020-06-05 16:26:24.748773: I tensorflow/core/common_runtime/bfc_allocator.cc:970] Next region of size 10339342080
2020-06-05 16:26:24.748780: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7f2a7e000000 of size 1280 next 1
2020-06-05 16:26:24.748784: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7f2a7e000500 of size 256 next 5
2020-06-05 16:26:24.748789: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7f2a7e000600 of size 256 next 8
2020-06-05 16:26:24.748793: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7f2a7e000700 of size 256 next 10
2020-06-05 16:26:24.748797: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7f2a7e000800 of size 256 next 11
2020-06-05 16:26:24.748802: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7f2a7e000900 of size 256 next 14
2020-06-05 16:26:24.748806: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7f2a7e000a00 of size 256 next 16
2020-06-05 16:26:24.748811: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7f2a7e000b00 of size 512 next 17
2020-06-05 16:26:24.748815: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7f2a7e000d00 of size 256 next 20
2020-06-05 16:26:24.748820: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7f2a7e000e00 of size 256 next 21
2020-06-05 16:26:24.748824: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7f2a7e000f00 of size 256 next 22
2020-06-05 16:26:24.748828: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7f2a7e001000 of size 256 next 23
2020-06-05 16:26:24.748833: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7f2a7e001100 of size 256 next 2
2020-06-05 16:26:24.748837: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7f2a7e001200 of size 256 next 3
2020-06-05 16:26:24.748841: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7f2a7e001300 of size 256 next 4
2020-06-05 16:26:24.748845: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7f2a7e001400 of size 256 next 9
2020-06-05 16:26:24.748850: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7f2a7e001500 of size 256 next 18
2020-06-05 16:26:24.748854: I tensorflow/core/common_runtime/bfc_allocator.cc:990] Free  at 7f2a7e001600 of size 3072 next 6
2020-06-05 16:26:24.748858: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7f2a7e002200 of size 3328 next 7
2020-06-05 16:26:24.748863: I tensorflow/core/common_runtime/bfc_allocator.cc:990] Free  at 7f2a7e002f00 of size 4864 next 19
2020-06-05 16:26:24.748867: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7f2a7e004200 of size 4864 next 15
2020-06-05 16:26:24.748872: I tensorflow/core/common_runtime/bfc_allocator.cc:990] Free  at 7f2a7e005500 of size 59392 next 13
2020-06-05 16:26:24.748876: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7f2a7e013d00 of size 34560 next 12
2020-06-05 16:26:24.748881: I tensorflow/core/common_runtime/bfc_allocator.cc:990] Free  at 7f2a7e01c400 of size 10339226368 next 18446744073709551615
2020-06-05 16:26:24.748885: I tensorflow/core/common_runtime/bfc_allocator.cc:995]      Summary of in-use Chunks by size: 
2020-06-05 16:26:24.748891: I tensorflow/core/common_runtime/bfc_allocator.cc:998] 15 Chunks of size 256 totalling 3.8KiB
2020-06-05 16:26:24.748895: I tensorflow/core/common_runtime/bfc_allocator.cc:998] 1 Chunks of size 512 totalling 512B
2020-06-05 16:26:24.748900: I tensorflow/core/common_runtime/bfc_allocator.cc:998] 1 Chunks of size 1280 totalling 1.2KiB
2020-06-05 16:26:24.748905: I tensorflow/core/common_runtime/bfc_allocator.cc:998] 1 Chunks of size 3328 totalling 3.2KiB
2020-06-05 16:26:24.748909: I tensorflow/core/common_runtime/bfc_allocator.cc:998] 1 Chunks of size 4864 totalling 4.8KiB
2020-06-05 16:26:24.748914: I tensorflow/core/common_runtime/bfc_allocator.cc:998] 1 Chunks of size 34560 totalling 33.8KiB
2020-06-05 16:26:24.748918: I tensorflow/core/common_runtime/bfc_allocator.cc:1002] Sum Total of in-use chunks: 47.2KiB
2020-06-05 16:26:24.748923: I tensorflow/core/common_runtime/bfc_allocator.cc:1004] total_region_allocated_bytes_: 10339342080 memory_limit_: 10339342080 available bytes: 0 curr_region_allocation_bytes_: 20678684160
2020-06-05 16:26:24.748929: I tensorflow/core/common_runtime/bfc_allocator.cc:1010] Stats: 
Limit:                 10339342080
InUse:                       48384
MaxInUse:                   109824
NumAllocs:                      56
MaxAllocSize:                34560

2020-06-05 16:26:24.748939: W tensorflow/core/common_runtime/bfc_allocator.cc:439] *___________________________________________________________________________________________________
Traceback (most recent call last):
  File ""question.py"", line 35, in <module>
    train(""test.h5"")
  File ""question.py"", line 30, in train
    my_model.fit(x_train, y_train, epochs=100, batch_size=1024, validation_split=0.1)
  File ""/home/fzy/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py"", line 66, in _method_wrapper
    return method(self, *args, **kwargs)
  File ""/home/fzy/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py"", line 797, in fit
    shuffle=False))
  File ""/home/fzy/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py"", line 1338, in train_validation_split
    functools.partial(_split, indices=train_indices), arrays)
  File ""/home/fzy/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/util/nest.py"", line 617, in map_structure
    structure[0], [func(*x) for x in entries],
  File ""/home/fzy/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/util/nest.py"", line 617, in <listcomp>
    structure[0], [func(*x) for x in entries],
  File ""/home/fzy/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py"", line 1335, in _split
    return array_ops.gather_v2(t, indices)
  File ""/home/fzy/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py"", line 180, in wrapper
    return target(*args, **kwargs)
  File ""/home/fzy/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py"", line 4541, in gather_v2
    batch_dims=batch_dims)
  File ""/home/fzy/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py"", line 180, in wrapper
    return target(*args, **kwargs)
  File ""/home/fzy/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py"", line 4524, in gather
    return gen_array_ops.gather_v2(params, indices, axis, name=name)
  File ""/home/fzy/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 3755, in gather_v2
    _ops.raise_from_not_ok_status(e, name)
  File ""/home/fzy/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 6653, in raise_from_not_ok_status
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InternalError: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run GatherV2: Dst tensor is not initialized. [Op:GatherV2]


```"
40176,tensorflow.python.framework.errors_impl.InvalidArgumentError: Retval[1] does not have value with aarch64,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
CentOS Linux release 7.6.1810 (AltArch)  4.14.0-115.el7a.0.1.aarch64
- TensorFlow installed from (source or binary):
compiled from source 
- TensorFlow version (use command below):
1.13.1
- Python version:
3.7.6
- Bazel version (if compiling from source):
0.20.0
- GCC/Compiler version (if compiling from source):
5.5.0
- CUDA/cuDNN version:
no
- GPU model and memory:
no

I use multilayers' lstm to generate texts. The network :
def buildModel(wordNum, gtX, hidden_units=128, layers=2, embedding=True):  
    """"""build rnn""""""
    with tf.variable_scope(""embedding""):  # embedding
        if embedding is True:
            embedding = tf.get_variable(""embedding"", [wordNum, hidden_units], dtype = tf.float32)
            inputbatch = tf.nn.embedding_lookup(embedding, gtX)

        else:
            inputbatch = tf.one_hot(gtX, wordNum)
        print('shape: ', inputbatch.shape)
    inputbatch = tf.layers.batch_normalization(inputbatch, 0)
    basicCell = tf.contrib.rnn.BasicLSTMCell(hidden_units, state_is_tuple = True)
    droped_cell = tf.contrib.rnn.DropoutWrapper(basicCell, output_keep_prob=0.5)
    stack_cells = []
    for _ in range(layers):
        stack_cells.append(droped_cell)
#     stackCell = tf.contrib.rnn.MultiRNNCell([basicCell] * layers)
    stackCell = tf.contrib.rnn.MultiRNNCell(stack_cells)
    initState = stackCell.zero_state(np.shape(gtX)[0], tf.float32)
    outputs, finalState = tf.nn.dynamic_rnn(stackCell, inputbatch, initial_state = initState)
    # outputs = tf.concat(outputs, 1)
    outputs = tf.reshape(outputs, [-1, hidden_units])
    print('outpus:', outputs.shape)
    with tf.variable_scope(""softmax""):
        w = tf.get_variable(""w"", initializer=tf.truncated_normal([hidden_units, wordNum], stddev=0.1))
        b = tf.get_variable(""b"", initializer=tf.zeros(wordNum))
        logits = tf.matmul(outputs, w) + b

    probs = tf.nn.softmax(logits)
    return logits, probs, stackCell, initState, finalState
And the loss function is tf.contrib.legacy_seq2seq.sequence_loss_by_example.
The following error appears  occasionally, sometimes in one epoch, sometimes in a few epochs. I am very confused about it. What is going on? I have  tried to add dropout , BN and fix the length of input, etc. But they are useless. Please help, tks a lot!
 All error log:
Traceback (most recent call last):
  File ""/ddhome/.pyenv/versions/anaconda3-5.3.1/envs/py3.7.6-tf1.13.1/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1334, in _do_call
    return fn(*args)
  File ""/ddhome/.pyenv/versions/anaconda3-5.3.1/envs/py3.7.6-tf1.13.1/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1319, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File ""/ddhome/.pyenv/versions/anaconda3-5.3.1/envs/py3.7.6-tf1.13.1/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1407, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Retval[1] does not have value

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/ddhome/src/lstm_debug/HCIA-IP/exp-lstm.py"", line 224, in <module>
    train()
  File ""/ddhome/src/lstm_debug/HCIA-IP/exp-lstm.py"", line 203, in train
    a, loss, gStep = sess.run([trainOP, cost, addGlobalStep], feed_dict={gtX: x, gtY: y})
  File ""/ddhome/.pyenv/versions/anaconda3-5.3.1/envs/py3.7.6-tf1.13.1/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 929, in run
    run_metadata_ptr)
  File ""/ddhome/.pyenv/versions/anaconda3-5.3.1/envs/py3.7.6-tf1.13.1/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1152, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/ddhome/.pyenv/versions/anaconda3-5.3.1/envs/py3.7.6-tf1.13.1/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1328, in _do_run
    run_metadata)
  File ""/ddhome/.pyenv/versions/anaconda3-5.3.1/envs/py3.7.6-tf1.13.1/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1348, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Retval[1] does not have value

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40175,tf.summary.flush segfaults when writer is not a valid tf.summary.SummaryWriter object,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:NA
- TensorFlow installed from (source or binary):binary
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0 & v2.1.0-rc2-17-ge5bf8de 2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):NA
- GCC/Compiler version (if compiling from source):NA
- CUDA/cuDNN version:NA
- GPU model and memory:NA

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
`tf.summary.flush` doesn't have input validity check to ensure `writer` is a `tf.summary.SummaryWriter`;
give it a ndarray as `writer` would make it segfault.
**Describe the expected behavior**
The function shouldn't segfault and should have a proper input checking.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```python
import tensorflow as tf
import numpy as np
tf.summary.flush(writer=np.random.rand(2,2)) # causes segfaults
```
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40172,ROCm build broken,"TensorFlow cannot build AMD GPUs using ROCm at head right now. The compilation error is:

```
tensorflow/core/kernels/scatter_nd_op_gpu.cu.cc:68:5: note: in instantiation of function template specialization 'tensorflow::GpuAtomicMin<long long, long long>' requested here
    GpuAtomicMin(out, val);
    ^
tensorflow/core/kernels/scatter_nd_op_gpu.cu.cc:118:9: note: in instantiation of member function 'tensorflow::(anonymous namespace)::LeftUpdate<long long, tensorflow::scatter_nd_op::UpdateOp::MIN>::operator()' requested here
        update(out + i + si, ldg(updates + (index * slice_size + si)));
        ^
tensorflow/core/kernels/scatter_nd_op_gpu.cu.cc:156:33: note: in instantiation of function template specialization 'tensorflow::ScatterNdOpKernel<long long, int, tensorflow::scatter_nd_op::UpdateOp::MIN, 1>' requested here
    TF_CHECK_OK(GpuLaunchKernel(ScatterNdOpKernel<T, Index, op, IXDIM>,
                                ^
/opt/rocm/hip/include/hip/hcc_detail/hip_atomic.h:141:5: note: candidate function not viable: no known conversion from 'long long *' to 'int *' for 1st argument
int atomicMin(int* address, int val)
    ^
/opt/rocm/hip/include/hip/hcc_detail/hip_atomic.h:147:14: note: candidate function not viable: no known conversion from 'long long *' to 'unsigned int *' for 1st argument
unsigned int atomicMin(unsigned int* address, unsigned int val)
             ^
/opt/rocm/hip/include/hip/hcc_detail/hip_atomic.h:153:20: note: candidate function not viable: no known conversion from 'long long *' to 'unsigned long long *' for 1st argument
unsigned long long atomicMin(
 
```

The problem seems to be in our code, our templates need gpuAtomicMin for also signed types, but they are not available for signed types in AMD code.

@chsigg FYI
@whchung could you take a look
"
40171,Memory leak when repeatedly loading and deleting keras models,"If a Keras model is saved using `tf.saved_model.save` and then repeatedly loaded with `tf.saved_model.load` and deleted with `del` it becomes apparent that there is a slow memory leak.  `keras.backend.clear_session` does not resolve this issue.  See attached gist for an example that reproduces this issue in TensorFlow 2.2 on Google Colab.

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
I have attached a custom repro case, but this appears to happen for various types of typical keras models.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Can reproduce in Google Colab and Docker RedHat images
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
not tested
- TensorFlow installed from (source or binary):
binary (from pip)
- TensorFlow version (use command below):
('2.2.0', 'v2.2.0-0-g2b96f3662b')
- Python version:
3.6.9 (google colab)
- Bazel version (if compiling from source):
N/A
- GCC/Compiler version (if compiling from source):
N/A
- CUDA/cuDNN version:
default in google colab
- GPU model and memory:
default in google colab

**Describe the current behavior**
When Keras models are saved / loaded repeatedly, memory usage gradually continues to grow over time.  For dynamic model servers that load and unload models over time, this may eventually lead to a crash due to memory exhaustion.

**Describe the expected behavior**
All memory should be recovered after a keras model instance is deleted with `del` and the garbage collector is run with `gc.collect()`.

**Standalone code to reproduce the issue**
The following GitHub gist demonstrates the issue (can also be run in Colab):
https://gist.github.com/idfah/dff83de8d2a6406c9b92221e6282a8d6"
40170,build failed on CentOS-7 @flatbuffers//:flatc' #1660 ,"## Bug Report
Getting the following error while building.

```
ERROR: /build/external/flatbuffers/BUILD.bazel:60:1: 
Linking of rule '@flatbuffers//:flatc' failed (Exit 1)

```

Re: #1563
this bug also reported the same issue but with building docker. Here, I am not building any docker.




### System information
- **OS Platform and Distribution (e.g., CentOS Linux 7)**:
- **TensorFlow repo (source v2.2.0)**:

### Describe the problem
Getting the above build error
### Exact Steps to Reproduce
clone and checkout the tag v2.2.0
./configure
<accept all defaults>
`bazel --output_base=$build_dir build --config=mkl //tensorflow/tools/pip_package:build_pip_package`

### Source code / logs
```
INFO: From Compiling external/snappy/snappy-stubs-internal.cc:
cc1plus: warning: command line option '-Wno-implicit-function-declaration' is valid for C/ObjC but not for C++
ERROR: /build/external/swig/BUILD.bazel:5:1: Linking of rule '@swig//:swig' failed (Exit 1)
bazel-out/host/bin/external/swig/_objs/swig/allocate.o:allocate.cxx:function Allocate::~Allocate(): error: undefined reference to 'operator delete(void*, unsigned long)'
bazel-out/host/bin/external/swig/_objs/swig/contract.o:contract.cxx:function Contracts::~Contracts(): error: undefined reference to 'operator delete(void*, unsigned long)'
bazel-out/host/bin/external/swig/_objs/swig/lang.o:lang.cxx:function Language::~Language(): error: undefined reference to 'operator delete(void*, unsigned long)'
bazel-out/host/bin/external/swig/_objs/swig/module.o:module.cxx:function Swig_register_module(char const*, Language* (*)()) [clone .cold.0]: error: undefined reference to 'operator delete(void*, unsigned long)'
collect2: error: ld returned 1 exit status
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 87.968s, Critical Path: 69.22s
INFO: 4631 processes: 4631 local.
FAILED: Build did NOT complete successfully
```
"
40168,linking error while building TensorFlow Lite C++ image classification demo for Android,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04

bazel build -c opt --config=android_arm64 //tensorflow/lite/examples/label_image:label_image
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=204
INFO: Reading rc options for 'build' from /home/ambuj/try/tensorflow/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /home/ambuj/try/tensorflow/.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=v2
INFO: Reading rc options for 'build' from /home/ambuj/try/tensorflow/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/home/ambuj/try/env/bin/python3 --action_env PYTHON_LIB_PATH=/home/ambuj/try/env/lib/python3.6/site-packages --python_path=/home/ambuj/try/env/bin/python3 --config=xla --action_env ANDROID_NDK_HOME=/opt/android-ndk --action_env ANDROID_NDK_API_LEVEL=27 --action_env ANDROID_BUILD_TOOLS_VERSION=29.0.2 --action_env ANDROID_SDK_API_LEVEL=28 --action_env ANDROID_SDK_HOME=/opt/android-sdk --action_env TF_CONFIGURE_IOS=0
INFO: Found applicable config definition build:v2 in file /home/ambuj/try/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:xla in file /home/ambuj/try/tensorflow/.bazelrc: --action_env=TF_ENABLE_XLA=1 --define=with_xla_support=true
INFO: Found applicable config definition build:android_arm64 in file /home/ambuj/try/tensorflow/.bazelrc: --config=android --cpu=arm64-v8a --fat_apk_cpu=arm64-v8a
INFO: Found applicable config definition build:android in file /home/ambuj/try/tensorflow/.bazelrc: --crosstool_top=//external:android/crosstool --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --noenable_platform_specific_config --copt=-w --cxxopt=-std=c++14 --host_cxxopt=-std=c++14
DEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = ""1556410077 -0400""
DEBUG: Call stack for the definition of repository 'io_bazel_rules_docker' which is a git_repository (rule definition at /home/ambuj/.cache/bazel/_bazel_ambuj/9eebf77bd6558b95e6f902cd1dc311ce/external/bazel_tools/tools/build_defs/repo/git.bzl:195:18):
 - <builtin>
 - /home/ambuj/.cache/bazel/_bazel_ambuj/9eebf77bd6558b95e6f902cd1dc311ce/external/bazel_toolchains/repositories/repositories.bzl:37:9
 - /home/ambuj/try/tensorflow/WORKSPACE:37:1
INFO: Analyzed target //tensorflow/lite/examples/label_image:label_image (0 packages loaded, 1926 targets configured).
INFO: Found 1 target...
ERROR: /home/ambuj/try/tensorflow/tensorflow/lite/examples/label_image/BUILD:15:1: Linking of rule '//tensorflow/lite/examples/label_image:label_image' failed (Exit 1)
bazel-out/arm64-v8a-opt/bin/tensorflow/lite/experimental/delegates/hexagon/builders/libop_builder.a(transpose_conv_2d_builder.o): In function `tflite::delegates::hexagon::TransposeConv2dOpBuilder::PopulateSubGraph(TfLiteIntArray const*, TfLiteIntArray const*, TfLiteContext*)':
/proc/self/cwd/tensorflow/lite/experimental/delegates/hexagon/builders/transpose_conv_2d_builder.cc:90: undefined reference to `tflite::delegates::hexagon::OpBuilder::kScalarShape'
/proc/self/cwd/tensorflow/lite/experimental/delegates/hexagon/builders/transpose_conv_2d_builder.cc:90: undefined reference to `tflite::delegates::hexagon::OpBuilder::kScalarShape'
/proc/self/cwd/tensorflow/lite/experimental/delegates/hexagon/builders/transpose_conv_2d_builder.cc:147: undefined reference to `tflite::delegates::hexagon::OpBuilder::kScalarShape'
/proc/self/cwd/tensorflow/lite/experimental/delegates/hexagon/builders/transpose_conv_2d_builder.cc:147: undefined reference to `tflite::delegates::hexagon::OpBuilder::kScalarShape'
/proc/self/cwd/tensorflow/lite/experimental/delegates/hexagon/builders/transpose_conv_2d_builder.cc:200: undefined reference to `tflite::delegates::hexagon::OpBuilder::kScalarShape'
bazel-out/arm64-v8a-opt/bin/tensorflow/lite/experimental/delegates/hexagon/builders/libop_builder.a(transpose_conv_2d_builder.o):/proc/self/cwd/tensorflow/lite/experimental/delegates/hexagon/builders/transpose_conv_2d_builder.cc:200: more undefined references to `tflite::delegates::hexagon::OpBuilder::kScalarShape' follow
bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/cl/libarguments.a(arguments.o): In function `char const* std::__ndk1::__search_substring<char, std::__ndk1::char_traits<char> >(char const*, char const*, char const*, char const*)':
/proc/self/cwd/external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include/__string:(.text+0x230c): undefined reference to `tflite::gpu::cl::Arguments::kArgsPrefix'
/proc/self/cwd/external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include/__string:(.text+0x2310): undefined reference to `tflite::gpu::cl::Arguments::kArgsPrefix'
bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/cl/libarguments.a(arguments.o): In function `std::__ndk1::char_traits<char>::compare(char const*, char const*, unsigned long)':
/proc/self/cwd/external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include/__string:250: undefined reference to `tflite::gpu::cl::Arguments::kArgsPrefix'
/proc/self/cwd/external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include/__string:250: undefined reference to `tflite::gpu::cl::Arguments::kArgsPrefix'
bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/cl/libarguments.a(arguments.o): In function `char const* std::__ndk1::__search_substring<char, std::__ndk1::char_traits<char> >(char const*, char const*, char const*, char const*)':
/proc/self/cwd/external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include/__string:(.text+0x2b40): undefined reference to `tflite::gpu::cl::Arguments::kArgsPrefix'
bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/cl/libarguments.a(arguments.o):/proc/self/cwd/external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include/__string:(.text+0x2b44): more undefined references to `tflite::gpu::cl::Arguments::kArgsPrefix' follow
bazel-out/arm64-v8a-opt/bin/tensorflow/lite/experimental/delegates/hexagon/builders/libop_builder.a(pack_builder.o): In function `tflite::delegates::hexagon::PackOpBuilder::PopulateSubGraph(TfLiteIntArray const*, TfLiteIntArray const*, TfLiteContext*)':
/proc/self/cwd/tensorflow/lite/experimental/delegates/hexagon/builders/pack_builder.cc:47: undefined reference to `tflite::delegates::hexagon::OpBuilder::kScalarShape'
/proc/self/cwd/tensorflow/lite/experimental/delegates/hexagon/builders/pack_builder.cc:47: undefined reference to `tflite::delegates::hexagon::OpBuilder::kScalarShape'
/proc/self/cwd/tensorflow/lite/experimental/delegates/hexagon/builders/pack_builder.cc:(.text+0x2d4): undefined reference to `tflite::delegates::hexagon::OpBuilder::kScalarShape'
/proc/self/cwd/tensorflow/lite/experimental/delegates/hexagon/builders/pack_builder.cc:(.text+0x2d8): undefined reference to `tflite::delegates::hexagon::OpBuilder::kScalarShape'
/proc/self/cwd/tensorflow/lite/experimental/delegates/hexagon/builders/pack_builder.cc:(.text+0x35c): undefined reference to `tflite::delegates::hexagon::OpBuilder::kScalarShape'
bazel-out/arm64-v8a-opt/bin/tensorflow/lite/experimental/delegates/hexagon/builders/libop_builder.a(pack_builder.o):/proc/self/cwd/tensorflow/lite/experimental/delegates/hexagon/builders/pack_builder.cc:(.text+0x360): more undefined references to `tflite::delegates::hexagon::OpBuilder::kScalarShape' follow
clang: error: linker command failed with exit code 1 (use -v to see invocation)
Target //tensorflow/lite/examples/label_image:label_image failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 0.811s, Critical Path: 0.31s
INFO: 0 processes.
FAILED: Build did NOT complete successfully
"
40167,GPU delegate not as accurate as NNAPI reference  on 16float models on Style Transfer example. tensorflow-lite,"I was comparing the output of the transfer style app (while using the floating point models).

And found the following results

I/Style: Difference on average between CPU and  CPU: 8.049963811796872E-7
I/Style: Difference on average between CPU and  GPU: 0.00804935239782874
I/Style: Difference on average between CPU and  NNAPIREFERENCE: 8.941092843719466E-7
I/Style: Difference on average between CPU and  NNAPIDEFAULT: 7.434606152762919E-7
I/Style: Difference on average between CPU and  NNAPIGPU: 8.056053260209931E-7
I/Style: Difference on average between CPU and  NNAPIDSP: 7.446350522072008E-7
I/Style: Difference on average between CPU and  NNAPIHTA: 7.532546634042985E-7


NNAPI Reference is much more accurate than GPU through gpu delegate. What exactly is the threshold or standard for correctness? 


**How to reproduce results.**

I run the same noise through each interpreter, accelerated as specified.

the model produces an output of float[1][384][384][3]. I, basically, just take the difference between each float value and average them (sum and divide). I use the results from the CPU as the baseline, and compare.

The models used are attached. 

[style_float_models.zip](https://github.com/tensorflow/tensorflow/files/4732809/style_float_models.zip)


"
40166,Make possible loading model with custom gradient,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): tf2.1
- Are you willing to contribute it (Yes/No): No



**Describe the feature and the current behavior/state.**
Currently when a saved model is loaded, a custom gradient is not loaded.
Warnings like 
""WARNING: Importing a function _function-name_ with ops with custom gradients. Will likely fail if a gradient is requested."" 
are shown and the model is failing during training with error 
""LookupError: No gradient defined for operation '_namespace_/IdentityN' (op type: IdentityN)""

Link to TODO in code:
https://github.com/tensorflow/tensorflow/blob/b794497e61fdb976448c562e9b87b09e24cbfabf/tensorflow/python/saved_model/function_deserialization.py#L351
It would be beneficial to have it working.

**Will this change the current api? How?**
No

**Who will benefit with this feature?*
People using custom gradient

**Any Other info.**
"
40165,AttributeError: 'PerReplica' object has no attribute 'begin',"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 1.14
- Python version: Python 2
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
I'm trying to distributed evaluation on 2 GPUs on my local dev server using Mirrored Strategy. But I'm getting errors as follows:
```
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 477, in evaluate
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 517, in _actual_eval
    return _evaluate()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 508, in _evaluate
    output_dir=self.eval_dir(name))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1609, in _evaluate_run
    config=self._session_config)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/evaluation.py"", line 269, in _evaluate_once
    session_creator=session_creator, hooks=hooks) as session:
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1007, in __init__
    stop_grace_period_secs=stop_grace_period_secs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 713, in __init__
    h.begin()
**AttributeError: 'PerReplica' object has no attribute 'begin'**
```

I also noticed I'm having ""not used by distribute strategy"" error in the log (which I don't have in distributed training using mirrored strategy):
```
2020-06-04 18:40:02.149347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/device:GPU:0 with 14006 MB memory) -> physical GPU (device: 0, name: Quadro RTX 5000, pci bus id: 0000:17:00.0, compute capability: 7.5)
2020-06-04 18:40:02.149933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/device:GPU:1 with 14039 MB memory) -> physical GPU (device: 1, name: Quadro RTX 5000, pci bus id: 0000:65:00.0, compute capability: 7.5)
**INFO: tensorflow: Device is available but not used by distribute strategy: /device:CPU:0**
```

My distributed model evaluation is as follows:
```
strategy = tf.compat.v1.distribute.MirroredStrategy()

 self.run_config = tf.estimator.RunConfig(
        model_dir=self.job_dir,
        save_summary_steps=self.save_summary_steps,
        session_config=session_config,
        eval_distribute=strategy,
)

estimator = tf.estimator.Estimator(
    model_fn=eval_model_fn,
    config=self.run_config
)

eval_result = estimator.evaluate(
    input_fn=input_tf_dataset,
    steps=eval_steps,
    name=self.eval_name,
    hooks=hooks,
    checkpoint_path=weights_path
)          
```


**Describe the expected behavior**
I expected distributed evaluation shall work, because I also have distributed training + evaluation working properly as follows:
```
self.run_config = tf.estimator.RunConfig(
    model_dir=self.job_dir,
    save_checkpoints_steps=self.save_checkpoints_steps,
    save_checkpoints_secs=self.save_checkpoints_secs,
    keep_checkpoint_max=self.keep_checkpoint_max,
    save_summary_steps=self.save_summary_steps,
    session_config=session_config,
    train_distribute=distributed_strategy,
)

train_spec = tf.estimator.TrainSpec(
    input_fn=train_input_tf_dataset
    max_steps=max_steps,
    hooks=train_hooks,
)
eval_spec = tf.estimator.EvalSpec(
    input_fn=eval_input_tf_dataset
    steps=eval_steps,
    name=self.eval_name,
    hooks=eval_hooks
)

tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)
```

**Standalone code to reproduce the issue**
I don't have standalone code to reproduce the issue right now.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

I also found this issue: https://github.com/tensorflow/tensorflow/issues/28018. But for my case, even if I remove hooks, I still get the similar error."
40163,Save and load custom optimizers for continued training,"My question is essentially the exact same as that specified [here](https://stackoverflow.com/questions/49503748/save-and-load-model-optimizer-state) but without using the Keras backend. Namely, how does one save and restore custom optimizers to their last state in TensorFlow (e.g. [`L-BFGS-B`](http://tensorflow.biotecan.com/python/Python_1.8/tensorflow.google.cn/api_docs/python/tf/contrib/opt/ScipyOptimizerInterface.html), Adam) when continuing training? Is this currently supported?

As per the solution [here](https://stackoverflow.com/questions/43243527/python-tensorflow-how-to-restart-training-with-optimizer-and-import-meta-graph) for the Adam optimizer specifically, it appears one approach is to use `tf.add_collection` and `tf.get_collection`, but that appears to not work if I need to restore the optimizer in a new session/shell. I have written a simple test code below where I am able to to save and restore the neural network itself after training, *but* the optimizers and global counter variable are not starting from where they last ended if I launch the script from a new session/shell. Therefore, insights into restoring optimizers when continuing training via this script are sought. The goal is to save the optimizers and properly continue training from where the optimizers last ended when the code is launched again.
```
import numpy as np 
import tensorflow as tf

path_save = '/home/mathewsa/stored_models/' #custom path to save network
save_model = str(path_save)+""test_save.ckpt""
end_it = 1000 #number of iterations
frac_train = 1.0 #randomly sampled fraction of data to create training set
frac_sample_train = 0.01 #randomly sampled fraction of data from training set to train in batches
layers = [2, 20, 20, 20, 20, 20, 20, 20, 20, 1]

#Generate training data
len_data = 10000
x_x = np.array([np.linspace(0.,1.,len_data)])
x_y = np.array([np.linspace(0.,1.,len_data)]) 
y_true = np.array([np.linspace(-1.,1.,len_data)])

N_train = int(frac_train*len_data)
idx = np.random.choice(len_data, N_train, replace=False)

x_train = x_x.T[idx,:]
y_train = x_y.T[idx,:] 
v1_train = y_true.T[idx,:] 

sample_batch_size = int(frac_sample_train*N_train)

np.random.seed(1234)
tf.set_random_seed(1234)
import logging
logging.getLogger('tensorflow').setLevel(logging.ERROR)
tf.logging.set_verbosity(tf.logging.ERROR)

class NeuralNet:
    def __init__(self, x, y, v1, layers):
        X = np.concatenate([x, y], 1)  
        self.lb = X.min(0)
        self.ub = X.max(0)
        self.X = X
        self.x = X[:,0:1]
        self.y = X[:,1:2] 
        self.v1 = v1 
        self.layers = layers 
        self.weights_v1, self.biases_v1 = self.initialize_NN(layers) 
        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=False,
                                                     log_device_placement=False)) 
        self.x_tf = tf.placeholder(tf.float32, shape=[None, self.x.shape[1]])
        self.y_tf = tf.placeholder(tf.float32, shape=[None, self.y.shape[1]]) 
        self.v1_tf = tf.placeholder(tf.float32, shape=[None, self.v1.shape[1]])  
        self.v1_pred = self.net(self.x_tf, self.y_tf) 
        self.loss = tf.reduce_mean(tf.square(self.v1_tf - self.v1_pred)) 
        self.optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.loss,
                                                                var_list=self.weights_v1+self.biases_v1,
                                                                method = 'L-BFGS-B',
                                                                options = {'maxiter': 50,
                                                                           'maxfun': 50000,
                                                                           'maxcor': 50,
                                                                           'maxls': 50,
                                                                           'ftol' : 1.0 * np.finfo(float).eps})
        self.optimizer_Adam = tf.train.AdamOptimizer()
        self.train_op_Adam_v1 = self.optimizer_Adam.minimize(self.loss, var_list=self.weights_v1+self.biases_v1) 
        self.saver = tf.train.Saver()
        init = tf.global_variables_initializer()  
        self.sess.run(init)
    def initialize_NN(self, layers):
        weights = []
        biases = []
        num_layers = len(layers)
        for l in range(0,num_layers-1):
            W = self.xavier_init(size=[layers[l], layers[l+1]])
            b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float32), dtype=tf.float32)
            weights.append(W)
            biases.append(b) 
        return weights, biases
    def xavier_init(self, size):
        in_dim = size[0]
        out_dim = size[1]
        xavier_stddev = np.sqrt(2/(in_dim + out_dim)) 
        return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), dtype=tf.float32)
    def neural_net(self, X, weights, biases):
        num_layers = len(weights) + 1
        H = 2.0*(X - self.lb)/(self.ub - self.lb) - 1.0
        for l in range(0,num_layers-2):
            W = weights[l]
            b = biases[l]
            H = tf.tanh(tf.add(tf.matmul(H, W), b))
        W = weights[-1]
        b = biases[-1]
        Y = tf.add(tf.matmul(H, W), b) 
        return Y
    def net(self, x, y): 
        v1_out = self.neural_net(tf.concat([x,y], 1), self.weights_v1, self.biases_v1)
        v1 = v1_out[:,0:1]
        return v1
    def callback(self, loss):
        global Nfeval
        print(str(Nfeval)+' - Loss in loop: %.3e' % (loss))
        Nfeval += 1
    def fetch_minibatch(self, x_in, y_in, v1_in, N_train_sample):  
        idx_batch = np.random.choice(len(x_in), N_train_sample, replace=False)
        x_batch = x_in[idx_batch,:]
        y_batch = y_in[idx_batch,:] 
        v1_batch = v1_in[idx_batch,:] 
        return x_batch, y_batch, v1_batch
    def train(self, end_it): 
        saver = tf.train.Saver()
        print('Stage 4.20')
        try:
            saver.restore(self.sess, save_model) 
            print('Using previous model')
        except:
            self.Nfeval = 1
            print('No previous model') 
        it = 0
        while it < end_it: 
            x_res_batch, y_res_batch, v1_res_batch = self.fetch_minibatch(self.x, self.y, self.v1, sample_batch_size) # Fetch residual mini-batch
            tf_dict = {self.x_tf: x_res_batch, self.y_tf: y_res_batch,
                       self.v1_tf: v1_res_batch}
            self.sess.run(self.train_op_Adam_v1, tf_dict)
            self.optimizer.minimize(self.sess,
                                    feed_dict = tf_dict,
                                    fetches = [self.loss],
                                    loss_callback = self.callback) 
            it = it + 1
        self.save_path = saver.save(self.sess, save_model)
        print('Finishing up training and saving as: ') 
        print(save_model) 
    def restore_model(self, path_full_saved):
        saver = tf.train.Saver()
        print('Stage 4.20')
        try:
            saver.restore(self.sess, str(path_full_saved))
            print('Using previous model')
        except:
            print('No previous model')
    def predict(self, x_star, y_star): 
        tf_dict = {self.x_tf: x_star, self.y_tf: y_star}
        v1_star = self.sess.run(self.v1_pred, tf_dict)  
        return v1_star

model = NeuralNet(x_train, y_train, v1_train, layers)
 
Nfeval = 1
model.train(end_it)
```"
40162,Can't build the binary for Sparkfun Edge Examples,"I'm new to this but after following the instructions to flash the SparkFun Edge with the hello world example it can't create the binary file. After entering 

make -f tensorflow/lite/micro/tools/make/Makefile TARGET=sparkfun_edge hello_world_bin

These errors appear after downloading the dependencies:

1: tensorflow/lite/micro/tools/make/downloads/gcc_embedded/bin//arm-none-eabi-g++: ELF: not found
tensorflow/lite/micro/tools/make/downloads/gcc_embedded/bin//arm-none-eabi-g++: 1: tensorflow/lite/micro/tools/make/downloads/gcc_embedded/bin//arm-none-eabi-g++: Syntax error: Unterminated quoted string
make: *** [tensorflow/lite/micro/tools/make/Makefile:300: tensorflow/lite/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/micro/examples/hello_world/main.o] Error 2

This has also happened with the other examples. The folders are created (/tensorflow/lite/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/micro/examples/hello_world) but not the hello_world.bin file. 

Thank you.

I'm using Rapbian on Pi4"
40161,"<tf.Variable 'Variable:0' shape=(1, 56, 56, 256) dtype=float32, numpy= array([[[[0.        , 3.6259902 , 3.3980963 , ...,        nan,                  nan,        nan],","Does anyone ever experience like this? Please give enlightenment, thank you

![image](https://user-images.githubusercontent.com/58981061/83787982-cce86200-a6be-11ea-86be-93c587a5e45a.png)
"
40160,"Unable to call ""image_dataset_from_directory""","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): conda install tensorflow 
- TensorFlow version:- version 2.1.0
- Python version: 3.7
- Installed using virtualenv? pip? conda?:conda
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:


**Describe the problem**
Am following the commands on the tensir.io site ( https://keras.io/api/preprocessing/image/#image_dataset_from_directory-function )
and when i try to do the imports of the required functions at the start of my program i get an error.  I have reviewed the directories and the image_dataset_from_directory is not in the folder so it didn't download as part of the package.  how can i get it or has it been discontinued?

Initial commands:
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import preprocessing
from tensorflow.keras.preprocessing.image import image_dataset_from_directory

Error: 

from tensorflow.keras.preprocessing.image import image_dataset_from_directory
Traceback (most recent call last):

  File ""<ipython-input-11-7fae7ea40691>"", line 1, in <module>
    from tensorflow.keras.preprocessing.image import image_dataset_from_directory

ImportError: cannot import name 'image_dataset_from_directory' from 'tensorflow.keras.preprocessing.image' (d:\anaconda3\envs\masters\lib\site-packages\tensorflow_core\python\keras\api\_v2\keras\preprocessing\image\__init__.py)
"
40159,tf.ragged.constant does not detect dense dimensions,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 2.2.0
- Python version: 3.7.6
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: NA
- GPU model and memory: NA

**Describe the current behavior**

Note: I am reporting this as a bug but I am not sure if it may actually be a feature request, as I am not entirely sure if the described behaviour is fully expected or not.

[`tf.ragged.constant`](https://www.tensorflow.org/api_docs/python/tf/ragged/constant) does not properly detect which dimensions should be ragged from the given Python list. By default, only the outermost dimension is considered as dense, even if other coherent dimensions exist in the data. One can use `ragged_rank` and/or `inner_shape` to mark a number of innermost dimensions as dense, but it does not seem to be possible to do the opposite, that is, marking some outermost dimensions after the first one as dense. And, in general, it does not detect nor allow to make a ragged tensor with an arbitrary combination of ragged and dense dimensions (even though it is possible to build such ragged tensors in other ways).

**Describe the expected behavior**

I would expect that all coherent dimensions of a Python nested list are detected as dense dimensions:

```python
import tensorflow as tf
print(tf.ragged.constant([[[1], [2, 3], [4]], [[5, 6], [], [7]]]).shape)
# (2, 3, None)
```

As a feature addition, having the possibility to specify which arbitrary dimensions are ragged or not would also be nice, although it would have to be with a different API. Maybe I could have for example:

```python
import tensorflow as tf
tf.ragged.constant([[[1], [2, 3], [4]], [[5, 6], [], [7]]], shape=[2, -1, None])
```

With `-1` meaning ""detect automatically from data"" and `None` meaning `ragged dimension`.

**Standalone code to reproduce the issue**

```python
import tensorflow as tf
# Dense inner dimensions are not detected
print(tf.ragged.constant([[[1], [2, 3], [4]], [[5, 6], [], [7]]]).shape)
# (2, None, None)
# The outermost dimension is always dense
print(tf.ragged.constant([[1], [2, 3], [4]]).shape)
# (3, None)
# But simply adding a couple of brackets makes the dimension ragged
print(tf.ragged.constant([[[1], [2, 3], [4]]]).shape)
# (1, None, None)
```

**Other info / logs**
NA
"
40157,"TFLite: Cannot run inference on TF Lite Model: ""Regular TensorFlow ops are not supported by this interpreter."" ","**System information**
- OSX
- TF 2.3.0-dev20200602


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

Conversion code:
```
    converter = tf.lite.TFLiteConverter.from_saved_model(curr_dir + ""saved_model"")
    tflite_model = converter.convert()

    # Save the TF Lite model.
    with tf.io.gfile.GFile(curr_dir + '/model.tflite', 'wb') as f:
        f.write(tflite_model)
```


Inference code:
```
    # Compare Inference
    import tensorflow as tf

    # Load the TFLite model and allocate tensors.
    interpreter = tf.lite.Interpreter(model_path=""./model.tflite"")
    interpreter.allocate_tensors()

    # Get input and output tensors.
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()
```
The model I'm trying to convert to tflite and run inference on is SSDLite_MobileNetV2, obtained rom the Model Zoo:

http://download.tensorflow.org/models/object_detection/ssdlite_mobilenet_v2_coco_2018_05_09.tar.gz

**Failure details**

Conversion is successful, however I cannot run inference: Here is the error that I run into:
```
RuntimeError: Regular TensorFlow ops are not supported by this interpreter. 
Make sure you apply/link the Flex delegate before inference.Node number 3 (FlexTensorArrayV3) failed to prepare.
```

I've been playing around with converter settings with no luck
i.e. combinations of: 
```    
    # converter.optimizations = [tf.lite.Optimize.DEFAULT]
    # converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
    #                                        tf.lite.OpsSet.SELECT_TF_OPS]
```

With none of the settings above set, or the supported_ops set, I can convert the model but cannot run inference, with a similar error as above.
With optimizations set to default, it gives me an error in conversion"
40156,Tensorflow 2.0 Object detection GPU fails,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None
- TensorFlow installed from (source or binary):  binary
- TensorFlow version: Tensorflow-gpu 2.0.2
- Python version: 3.6
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): None
- GCC/Compiler version (if compiling from source): None
- CUDA/cuDNN version: 10.0/7.6.0
- GPU model and memory: GeForce 930MX
**Describe the current behavior**
Hi.
I'm trying to do an object detection tutorial from [this](https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb), however I get the following output without success:
`(tfflask) C:\Users\DELL\Downloads\models-master\research\object_detection>python test_object.py
2020-06-04 21:02:11.627763: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2020-06-04 21:02:14.271146: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-06-04 21:02:14.688585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties:
name: GeForce 930MX major: 5 minor: 0 memoryClockRate(GHz): 1.0195
pciBusID: 0000:03:00.0
2020-06-04 21:02:14.694154: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.
2020-06-04 21:02:14.700750: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
2020-06-04 21:02:16.474139: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2020-06-04 21:02:16.555975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties:
name: GeForce 930MX major: 5 minor: 0 memoryClockRate(GHz): 1.0195
pciBusID: 0000:03:00.0
2020-06-04 21:02:16.567918: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.
2020-06-04 21:02:16.576144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-06-04 21:04:34.299345: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-06-04 21:04:34.303521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0
2020-06-04 21:04:34.305504: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N
2020-06-04 21:04:34.311931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1384 MB memory) -> physical GPU (device: 0, name: GeForce 930MX, pci bus id: 0000:03:00.0, compute capability: 5.0)
2020-06-04 21:04:41.840234: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-06-04 21:04:42.605329: W tensorflow/stream_executor/cuda/redzone_allocator.cc:312] Internal: Invoking ptxas not supported on Windows
Relying on driver to perform ptx compilation. This message will be only logged once.
2020-06-04 21:04:43.557938: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-06-04 21:04:43.829741: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.09GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-06-04 21:04:44.020239: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.15GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-06-04 21:04:44.422733: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
`


Is the memory overloading? I tried inserting:
`physical_devices = tf.compat.v1.config.experimental.list_physical_devices('GPU') 

tf.compat.v1.config.experimental.set_memory_growth(physical_devices[0], True)`
but to no avail."
40155,"TFLite: Cannot run inference on TF Lite Model: ""Regular TensorFlow ops are not supported by this interpreter. Make sure you apply/link the Flex delegate before inference.Node number 3","**System information**
- OSX Mojave
- TF 2.3.0-dev20200602
- Python 3.7.7
- TF installed using Conda



**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
    converter = tf.lite.TFLiteConverter.from_saved_model(curr_dir + ""saved_model"")
    tflite_model = converter.convert()

    # Save the TF Lite model.
    with tf.io.gfile.GFile(curr_dir + '/model.tflite', 'wb') as f:
        f.write(tflite_model)
```

**The output from the converter invocation**

```
# Copy and paste the output here.
```

**Also, please include a link to the saved model or GraphDef**

```
# Put link here or attach to the issue.
```

**Failure details**
If the conversion is successful, but the generated model is wrong,
state what is wrong:
- Producing wrong results and/or decrease in accuracy
- Producing correct results, but the model is slower than expected (model generated from old converter)


**RNN conversion support**
If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
40154,GPU delegate gives different result from CPU,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution:Linux Ubuntu 18.04
- Mobile device if the issue happens on mobile device: Pixel 3 XL
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): r2.2.0 and master
- Python version: 3.6
- Bazel version (if compiling from source): 3.0.0
- GCC/Compiler version (if compiling from source): default
- CUDA/cuDNN version: 10.0
- GPU model and memory: 

**Describe the current behavior**
GPU delegate gives very different result from CPU. 
I was able to hard-code the source (in tensorflow/lite/delegates/gpu/common/model_builder.cc) to allow some operations to be delegated to GPU. Out of 270+ operations: 
- Delegating just one Conv_2d will produce very similar result as the one by CPU only. 
- Delegating a few more operations seem to produce bigger difference. 
- Delegating just the first MUL operation will produce very different result. 

**Describe the expected behavior**
result should be close

**Standalone code to reproduce the issue**
I personally hijacked tflite tools/benchmark code and give an sample image as deterministic input, instead of random input. 
I would love to provide my code change if it helps. 


**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

The tflite model was converted from InsightFace/ArcFace MXNet model
https://github.com/deepinsight/insightface/wiki/Model-Zoo (3.2 model)
link to download the tflite
https://drive.google.com/file/d/1pJX2I8btskVy-QHiF-mcUF7HF6ZFaQuf/view?usp=sharing

Also attached the graph of above model:
[visualized_official_arcface_no_sub.zip](https://github.com/tensorflow/tensorflow/files/4731201/visualized_official_arcface_no_sub.zip)
"
40152,TFLite: ELU activation not supported on GPU delegate,"Models with ELU activation op cannot run on GPU delegate, getting the following error:

```
java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: Next operations are not supported by GPU delegate:
ELU: Operation is not supported.
```

Can support for this op be added to GPU delegate?

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Android
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (or github SHA if from source): 2.2.0

Here's a code to generate a minimal example model:

```
import tensorflow as tf
model = tf.keras.Sequential([
    tf.keras.Input(shape=(32,32)),
    tf.keras.layers.ELU()
])
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.experimental_new_converter=False
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]
tflite_model = converter.convert()
with open('elu.tflite', ""wb"") as f:
    f.write(tflite_model)
```
"
40151,Initiating inputs on functional model API doesn't work as expected,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):  Unknown (not installed)
- TensorFlow version (use command below): 2.1.0
- Python version: Python 3.7.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 440.33.01  CUDA Version: 10.2 
- GPU model and memory: RTX 2080 TI 11016MiB


**Describe the current behavior**
The current behavior creates two ""parallel"" models when provided with multiple outputs within the same model and if this model was defined with custom inputs as in my example below. 

**Describe the expected behavior**
You can run the same code with a pre-built model. 
```python
res=tf.keras.applications.ResNet50()
grad_model = tf.keras.models.Model(
    [res.inputs], [res.layers[-5].output, res.output]
)
grad_model.summary()
```
**Standalone code to reproduce the issue**
```python
class LeNet(tf.keras.Model):
    def __init__(self):
        super(LeNet, self).__init__()
        self.conv1 = Conv2D(32, 3, activation='relu')
        self.conv2 = Conv2D(64, 3, activation='relu')
        self.conv3 = Conv2D(128, 3, activation='relu')
        self.flatten = Flatten()
        self.d1 = Dense(128, activation='relu')
        self.d2 = Dense(64)
        self.out = Dense(10, activation='softmax')

    def call(self, x):
        if(len(x.shape)==3):
            x=tf.expand_dims(x,axis=0)
        
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        x = self.flatten(x)
        x = self.d1(x)
        x = self.d2(x)
        return self.out(x)
lenet=LeNet()
inputs=tf.keras.layers.Input((28,28,1))
lenet(inputs)
lenet.summary()
grad_model = tf.keras.models.Model(
    [lenet.inputs], [lenet.layers[-5].output, lenet.output]
)
grad_model.summary()
```
**Other info / logs** 

I think the issue is that the inputs to the model when lenet(inputs) is run, is not updating the inbound nodes for all layers or replacing the existing ones. 
"
40150,tf.TensorArray.stack() fails inside tf.function when dtype is tf.uint32 or tf.uint64,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: 3.7.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: none
- GPU model and memory: N/A

**Describe the current behavior**
When used in a tf.function, calling stack() in a tf.TensorArray object fails with the following error when the dtype is tf.uint32 or tf.uint64.

> tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument:  Unsupported type in DataTypeToPrimitiveType: 'variant'
	 [[node TensorArrayV2Stack/TensorListStack (defined at ta_error.py:21) ]]
  (1) Invalid argument:  Unsupported type in DataTypeToPrimitiveType: 'variant'
	 [[node TensorArrayV2Stack/TensorListStack (defined at ta_error.py:21) ]]
	 [[TensorArrayV2Stack/TensorListStack/_6]]
0 successful operations.
0 derived errors ignored. [Op:__inference_test_12]

**Describe the expected behavior**
Should not fail, but return a stacked tensor. Works correctly when the dtype is not tf.uint32 or tf.uint64. Also works correctly when executed in eager mode.

**Standalone code to reproduce the issue**
```python
@tf.function
def test():
  ta = tf.TensorArray(tf.uint64, 1)
  ta = ta.write(0, 123)
  return ta.stack()
```
"
40149,libtensorflowlite.so crash on Android (NDK r18b),"[<em>Please](url) make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Android Phone 
- TensorFlow installed from (source or binary): 2.1.1
- TensorFlow version:
- Python version: 2.7
- Installed using virtualenv? pip? conda?: None
- Bazel version (if compiling from source): 0.27.1
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: None
- GPU model and memory:



**Describe the problem**

I built the libtensorflowlite.so for both armeabi-v7a and arm64-v8a using the build command from doc file:

```
bazel build -c opt --config=android_arm //tensorflow/lite:libtensorflowlite.so
bazel build -c opt --config=android_arm64 //tensorflow/lite:libtensorflowlite.so
```

Here is the bazel configuration:
```
build --host_force_python=PY2
build --action_env PYTHON_BIN_PATH=""/usr/bin/python""
build --action_env PYTHON_LIB_PATH=""/usr/local/lib/python2.7/dist-packages""
build --python_path=""/usr/bin/python""
build:xla --define with_xla_support=true
build:opt --copt=-march=native
build:opt --copt=-Wno-sign-compare
build:opt --host_copt=-march=native
build:opt --define with_default_optimizations=true
build --action_env ANDROID_NDK_HOME=""/mnt/1tb-drive/software/Android/ndk/android-ndk-r18b""
build --action_env ANDROID_NDK_API_LEVEL=""21""
build --action_env ANDROID_BUILD_TOOLS_VERSION=""28.0.3""
build --action_env ANDROID_SDK_API_LEVEL=""28""
build --action_env ANDROID_SDK_HOME=""/mnt/1tb-drive/software/Android""
test --flaky_test_attempts=3
test --test_size_filters=small,medium
test --test_tag_filters=-benchmark-test,-no_oss,-oss_serial
test --build_tag_filters=-benchmark-test,-no_oss
test --test_tag_filters=-gpu
test --build_tag_filters=-gpu
build --action_env TF_CONFIGURE_IOS=""0""
```
However, when using this in a jnilibs (along with NDK r18b), the generated .so file has segmentation fault. How could I fix this problem?

```
A/libc: Fatal signal 11 (SIGSEGV), code 1 (SEGV_MAPERR), fault addr 0x0 in tid 20155 (Thread-3), pid 20112
```

To be clear, I was able to load model succesfully:

```
modelStftSpectrogram = tflite::FlatBufferModel::BuildFromFile(path.c_str());

    if(!model){
        exit(0);
    }
    
    tflite::ops::builtin::BuiltinOpResolver resolver;
    tflite::InterpreterBuilder(*model, resolver)(&interpreter);

    TFLITE_MINIMAL_CHECK(interpreter != nullptr);
    TFLITE_MINIMAL_CHECK(interpreter->AllocateTensors() == kTfLiteOk);
```

Then the segmentation fault happens exactly at this line:

```
    float *tflite_input = interpreter->typed_input_tensor<float>(0);

```

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
40148,adding_an_op compile fail Windows unistd.h,"Tensorflow r2.2 compile on Windows 10.  The example adding_an_op will fail with error message file not found unistd.h.  Error occurs on line 74 of external/eigen_archive/unsupported/Eigen/CXX11/Tensor.  

There is an #ifdef EIGEN_USE_GPU conditional #include <unistd.h> which will fail on Windows, as this is a unix file.  It is actually conditionally excluded from Windows previously in the file at line 51, so it is unclear why the include is not part of that conditional.  Commenting out the line 74 will enable successful compilation on Windows without any immediately apparent side effects.  This was not tested on *nix.

Thank you for looking at this."
40147,tf.sparse_tensor_to_dense get the wrong result,"Python 3.6.1
tensorflow = 1.15.0
```
ids_index = tf.sparse_tensor_to_dense(ids_sparse_tensor, default_value=0, validate_indices=True,name=None) 
with tf.Session() as session:
    session.run(tf.global_variables_initializer())
    session.run(tf.tables_initializer())
    print(""ids_sparse_tensor""+""*""*30)
    print(ids_sparse_tensor.indices.eval().shape)
    print(ids_sparse_tensor.values.eval().shape)
    print(ids_sparse_tensor.eval())
    print(""ids_index""+""*"" * 30)
    ids_index_value=ids_index.eval()
    print(ids_index_value.shape) #(1024, 91)
    print(ids_index_value)               
...
```
I got result below:
ids_sparse_tensor******************************
(93184, 2)
(93184,)
SparseTensorValue(indices=array([[   0,    0],
       [   0,    1],
       [   0,    2],
       ...,
       [1023,   88],
       [1023,   89],
       [1023,   90]], dtype=int64), values=array([7250, 1622, 2987, ...,    0,    0,    0], dtype=int64), dense_shape=array([1024,   91], dtype=int64))
ids_index******************************
(1024, 91)
[[1233 1144 7106 ...    0    0    0]
 [4758 6123 6134 ...    0    0    0]
 [2487 1965 4448 ...    0    0    0]
 ...
 [   0    0    0 ...    0    0    0]
 [  57 5203    0 ...    0    0    0]
 [5848 4164 2790 ...    0    0    0]]

My question is : Why ids_index[0,0]=1233 ? I think it should be 7250."
40146,Java API doc for TFLite,"As pointed out on the tflite@tensorflow.org list recently, there's no documentation for the use of Java against the TFLite API as yet. https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/api_docs/index.md

There is however API doc for Java for full TF.

Is there anyone assigned to work on this ? If not, I'm happy to have a go.

"
40145,[TF/MLIR] tf-mlir-translate crash with specific build config,"With the current TF HEAD (1421933a1d442bcc624f030d3be468620ce94164), tf-mlir-translate crashes on minimal input with this build config: 
```C=clang CXX=clang++  bazel --per_file_copt=mlir,llvm-project@-UNDEBUG --linkopt=""-fuse-ld=lld""     //tensorflow/compiler/mlir:tf-mlir-translate``` and ```bazel 3.0.0```.

(Removing --per_file_copt=mlir,llvm-project@-UNDEBUG from the build config makes it run fine. )

```
$ tf-mlir-translate -graphdef-to-mlir   model_graph_crash.pbtxt

PLEASE submit a bug report to  and include the crash backtrace.
Stack dump:
0.	Program arguments: bazel-bin/tensorflow/compiler/mlir/tf-mlir-translate -graphdef-to-mlir model_graph_crash.pbtxt 
 #0 0x00000000075575cd llvm::sys::PrintStackTrace(llvm::raw_ostream&) (bazel-bin/tensorflow/compiler/mlir/tf-mlir-translate+0x75575cd)
 #1 0x0000000007555665 llvm::sys::RunSignalHandlers() (bazel-bin/tensorflow/compiler/mlir/tf-mlir-translate+0x7555665)
 #2 0x00000000075578da SignalHandler(int) (bazel-bin/tensorflow/compiler/mlir/tf-mlir-translate+0x75578da)
 #3 0x00007faf5f479b20 __restore_rt (/lib64/libpthread.so.0+0x14b20)
 #4 0x0000000001a4b362 tensorflow::(anonymous namespace)::ImporterBase::InferOutputType(tensorflow::Node const&, int, mlir::Builder) (bazel-bin/tensorflow/compiler/mlir/tf-mlir-translate+0x1a4b362)
 #5 0x0000000001a52e4a tensorflow::(anonymous namespace)::ImporterBase::ConvertNode(tensorflow::Node const&) (bazel-bin/tensorflow/compiler/mlir/tf-mlir-translate+0x1a52e4a)
 #6 0x0000000001a40032 tensorflow::(anonymous namespace)::ImporterBase::Convert(llvm::StringRef, mlir::FunctionType, absl::lts_2020_02_25::InlinedVector<tensorflow::OutputTensor, 4ul, std::allocator<tensorflow::OutputTensor> > const&, absl::lts_2020_02_25::InlinedVector<tensorflow::OutputTensor, 4ul, std::allocator<tensorflow::OutputTensor> > const&, absl::lts_2020_02_25::InlinedVector<tensorflow::Node*, 4ul, std::allocator<tensorflow::Node*> > const&, llvm::ArrayRef<std::pair<mlir::Identifier, mlir::Attribute> >, bool) (bazel-bin/tensorflow/compiler/mlir/tf-mlir-translate+0x1a40032)
 #7 0x0000000001a382cc tensorflow::(anonymous namespace)::GraphDefImporter::Convert(mlir::MLIRContext*, tensorflow::Graph const&, tensorflow::GraphDebugInfo const&, tensorflow::FunctionLibraryDefinition const&, tensorflow::GraphImportConfig const&, llvm::StringRef) (bazel-bin/tensorflow/compiler/mlir/tf-mlir-translate+0x1a382cc)
 #8 0x0000000001a3635a tensorflow::ConvertGraphdefToMlir(tensorflow::GraphDef const&, tensorflow::GraphDebugInfo const&, tensorflow::GraphImportConfig const&, mlir::MLIRContext*, bool) (bazel-bin/tensorflow/compiler/mlir/tf-mlir-translate+0x1a3635a)
 #9 0x0000000001a22d1a tensorflow::GraphdefToMlirImport(llvm::StringRef, absl::lts_2020_02_25::string_view, absl::lts_2020_02_25::string_view, absl::lts_2020_02_25::string_view, absl::lts_2020_02_25::string_view, absl::lts_2020_02_25::string_view, absl::lts_2020_02_25::string_view, bool, bool, bool, bool, bool, mlir::MLIRContext*) (bazel-bin/tensorflow/compiler/mlir/tf-mlir-translate+0x1a22d1a)
#10 0x0000000001a22352 tensorflow::GraphdefToMlirTranslateFunction(llvm::StringRef, absl::lts_2020_02_25::string_view, absl::lts_2020_02_25::string_view, absl::lts_2020_02_25::string_view, absl::lts_2020_02_25::string_view, absl::lts_2020_02_25::string_view, absl::lts_2020_02_25::string_view, bool, bool, bool, bool, bool, mlir::MLIRContext*) (bazel-bin/tensorflow/compiler/mlir/tf-mlir-translate+0x1a22352)
#11 0x0000000001a203e5 mlir::GraphdefToMlirTranslateFunction(llvm::StringRef, mlir::MLIRContext*) (bazel-bin/tensorflow/compiler/mlir/tf-mlir-translate+0x1a203e5)
#12 0x0000000001a207a8 std::_Function_handler<mlir::OwningModuleRef (llvm::StringRef, mlir::MLIRContext*), mlir::OwningModuleRef (*)(llvm::StringRef, mlir::MLIRContext*)>::_M_invoke(std::_Any_data const&, llvm::StringRef&&, mlir::MLIRContext*&&) (bazel-bin/tensorflow/compiler/mlir/tf-mlir-translate+0x1a207a8)
#13 0x00000000073bb991 std::_Function_handler<mlir::OwningModuleRef (llvm::SourceMgr&, mlir::MLIRContext*), mlir::TranslateToMLIRRegistration::TranslateToMLIRRegistration(llvm::StringRef, std::function<mlir::OwningModuleRef (llvm::StringRef, mlir::MLIRContext*)> const&)::$_0>::_M_invoke(std::_Any_data const&, llvm::SourceMgr&, mlir::MLIRContext*&&) (bazel-bin/tensorflow/compiler/mlir/tf-mlir-translate+0x73bb991)
#14 0x00000000073bb6bd std::_Function_handler<mlir::LogicalResult (llvm::SourceMgr&, llvm::raw_ostream&, mlir::MLIRContext*), registerTranslateToMLIRFunction(llvm::StringRef, std::function<mlir::OwningModuleRef (llvm::SourceMgr&, mlir::MLIRContext*)> const&)::$_3>::_M_invoke(std::_Any_data const&, llvm::SourceMgr&, llvm::raw_ostream&, mlir::MLIRContext*&&) (bazel-bin/tensorflow/compiler/mlir/tf-mlir-translate+0x73bb6bd)
#15 0x0000000001901d88 main::$_0::operator()(std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer> >, llvm::raw_ostream&) const (bazel-bin/tensorflow/compiler/mlir/tf-mlir-translate+0x1901d88)
#16 0x0000000001901c5e main (bazel-bin/tensorflow/compiler/mlir/tf-mlir-translate+0x1901c5e)
#17 0x00007faf5f2a91a3 __libc_start_main (/lib64/libc.so.6+0x271a3)
#18 0x000000000190102e _start (bazel-bin/tensorflow/compiler/mlir/tf-mlir-translate+0x190102e)
Segmentation fault (core dumped)
```



Input file: model_graph_crash.pbtxt

```
node {
  name: ""Placeholder""
  op: ""Placeholder""
  attr {
    key: ""_output_shapes""
    value {
      list {
        shape {
          dim {
            size: 1
          }
          dim {
            size: 3
          }
          dim {
            size: 224
          }
          dim {
            size: 224
          }
        }
      }
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 1
        }
        dim {
          size: 3
        }
        dim {
          size: 224
        }
        dim {
          size: 224
        }
      }
    }
  }
}
```"
40144,GPU Delegate doesn't work for tflite model on Android device,"I was trying to increase the run speed of Posenet, these are the performances:

2020-06-04 08:41:21.143 I/InterpreterPosenet: Scaling to [-1,1] took 207.85 ms
2020-06-04 08:41:21.894 I/posenet: Interpreter took 743.94 ms
2020-06-04 08:41:22.559 I/InterpreterPosenet: Scaling to [-1,1] took 226.94 ms
2020-06-04 08:41:23.058 I/posenet: Interpreter took 498.60 ms
2020-06-04 08:41:23.497 I/InterpreterPosenet: Scaling to [-1,1] took 191.16 ms
2020-06-04 08:41:23.858 I/posenet: Interpreter took 360.01 ms
2020-06-04 08:41:24.324 I/InterpreterPosenet: Scaling to [-1,1] took 223.37 ms
2020-06-04 08:41:24.866 I/posenet: Interpreter took 541.24 ms

As you can see this aren't very good performances and I was trying to find a way to increase the speed, and then I found out the GPU Delegate from tensorflow in this link:
https://www.tensorflow.org/lite/performance/gpu

And also in this link you can see that the speed of PoseNet increased somewhere by 2x,

I followed the instructions and this is my init method of the class Posenet.kt:
  init {
    val gpuDelegate = GpuDelegate()
    val options = Interpreter.Options().addDelegate(gpuDelegate)
    interpreter = Interpreter(loadModelFile(""posenet_model.tflite"", context), options)
  }

Also the gradle dependencies: 
    implementation 'org.tensorflow:tensorflow-lite-gpu:2.0.0'
    implementation 'org.tensorflow:tensorflow-lite:2.1.0'
 
I also made some measurements for 40 frames and Posenet took: 550.2947368 ms on average and after GPU Delegate: 528.7305263 ms on average 

And also I don't get any errors from the method run() or from Interpreter, so what I am doing wrong ?

The device has the RK3399 processor: http://opensource.rock-chips.com/wiki_RK3399

**EDIT:** 
I Found out that this processor (RK3399) doesn't support GPU delegate, but I also tried on a device with Qualcomm 835 processor ( https://www.qualcomm.com/products/snapdragon-835-mobile-platform ) which supports GPU Delegate but still doesn't improve the performance."
40143,OperatorNotAllowedInGraphError: using a tf.Tensor as a Python bool is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.,"```
def unet(pretrained_weights = None,input_size = (256,256,1)):
    inputs = keras.Input(shape = input_size)
    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)
    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)
    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)
    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)
    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)
    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)
    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)
    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)
    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)
    drop4 = Dropout(0.5)(conv4)
    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)

    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)
    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)
    drop5 = Dropout(0.5)(conv5)

    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))
    merge6 = concatenate([drop4,up6], axis = 3)
    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)
    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)

    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))
    merge7 = concatenate([conv3,up7], axis = 3)
    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)
    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)

    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))
    merge8 = concatenate([conv2,up8], axis = 3)
    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)
    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)

    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))
    merge9 = concatenate([conv1,up9], axis = 3)
    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)
    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)
    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)
    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)

    model = Model(inputs = inputs, outputs = conv10)

    def iou(y_pred, y_true):
        y_pred = tf.cast((y_pred > 0), dtype=tf.float32)
        i = tf.reduce_sum(y_true * y_pred)
        u = tf.reduce_sum(y_true + y_pred)
        return (i / u).item()if u != 0 else u.item()
    
    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy',iou])
    
    model.summary()


    if(pretrained_weights):
    	model.load_weights(pretrained_weights)

    return `model`

model = unet()
```
When I run the code above, I encounter the following errors:

```
OperatorNotAllowedInGraphError Traceback (most recent call last)
in 
----> 1 model = unet()

in unet(pretrained_weights, input_size)
51 return (i / u).item()if u != 0 else u.item()
52
---> 53 model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy',iou])
54
55 model.summary()

~\Anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\training\tracking\base.py in _method_wrapper(self, *args, **kwargs)
455 self._self_setattr_tracking = False # pylint: disable=protected-access
456 try:
--> 457 result = method(self, *args, **kwargs)
458 finally:
459 self._self_setattr_tracking = previous_value # pylint: disable=protected-access

~\Anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\keras\engine\training.py in compile(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)
437 targets=self._targets,
438 skip_target_masks=self._prepare_skip_target_masks(),
--> 439 masks=self._prepare_output_masks())
440
441 # Prepare sample weight modes. List with the same length as model outputs.

~\Anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\keras\engine\training.py in _handle_metrics(self, outputs, targets, skip_target_masks, sample_weights, masks, return_weighted_metrics, return_weighted_and_unweighted_metrics)
2002 metric_results.extend(
2003 self._handle_per_output_metrics(self._per_output_metrics[i],
-> 2004 target, output, output_mask))
2005 if return_weighted_and_unweighted_metrics or return_weighted_metrics:
2006 metric_results.extend(

~\Anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\keras\engine\training.py in _handle_per_output_metrics(self, metrics_dict, y_true, y_pred, mask, weights)
1953 with K.name_scope(metric_name):
1954 metric_result = training_utils.call_metric_function(
-> 1955 metric_fn, y_true, y_pred, weights=weights, mask=mask)
1956 metric_results.append(metric_result)
1957 return metric_results

~\Anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\keras\engine\training_utils.py in call_metric_function(metric_fn, y_true, y_pred, weights, mask)
1153
1154 if y_pred is not None:
-> 1155 return metric_fn(y_true, y_pred, sample_weight=weights)
1156 # Mean metric only takes a single value.
1157 return metric_fn(y_true, sample_weight=weights)

~\Anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\keras\metrics.py in call(self, *args, **kwargs)
194 from tensorflow.python.keras.distribute import distributed_training_utils # pylint:disable=g-import-not-at-top
195 return distributed_training_utils.call_replica_local_fn(
--> 196 replica_local_fn, *args, **kwargs)
197
198 @Property

~\Anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\keras\distribute\distributed_training_utils.py in call_replica_local_fn(fn, *args, **kwargs)
1133 with strategy.scope():
1134 return strategy.extended.call_for_each_replica(fn, args, kwargs)
-> 1135 return fn(*args, **kwargs)
1136
1137

~\Anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\keras\metrics.py in replica_local_fn(*args, **kwargs)
177 def replica_local_fn(*args, **kwargs):
178 """"""Updates the state of the metric in a replica-local context.""""""
--> 179 update_op = self.update_state(*args, **kwargs) # pylint: disable=not-callable
180 with ops.control_dependencies([update_op]):
181 result_t = self.result() # pylint: disable=not-callable

~\Anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\keras\utils\metrics_utils.py in decorated(metric_obj, *args, **kwargs)
74
75 with tf_utils.graph_context_for_symbolic_tensors(*args, **kwargs):
---> 76 update_op = update_state_fn(*args, **kwargs)
77 if update_op is not None: # update_op will be None in eager execution.
78 metric_obj.add_update(update_op)

~\Anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\keras\metrics.py in update_state(self, y_true, y_pred, sample_weight)
585 y_pred, y_true)
586
--> 587 matches = self._fn(y_true, y_pred, **self._fn_kwargs)
588 return super(MeanMetricWrapper, self).update_state(
589 matches, sample_weight=sample_weight)

in iou(y_pred, y_true)
49 i = tf.reduce_sum(y_true * y_pred)
50 u = tf.reduce_sum(y_true + y_pred)
---> 51 return (i / u).item()if u != 0 else u.item()
52
53 model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy',iou])

~\Anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\framework\ops.py in bool(self)
755 TypeError.
756 """"""
--> 757 self._disallow_bool_casting()
758
759 def nonzero(self):

~\Anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\framework\ops.py in _disallow_bool_casting(self)
524 else:
525 # Default: V1-style Graph execution.
--> 526 self._disallow_in_graph_mode(""using a tf.Tensor as a Python bool"")
527
528 def _disallow_iteration(self):

~\Anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\framework\ops.py in _disallow_in_graph_mode(self, task)
513 raise errors.OperatorNotAllowedInGraphError(
514 ""{} is not allowed in Graph execution. Use Eager execution or decorate""
--> 515 "" this function with @tf.function."".format(task))
516
517 def _disallow_bool_casting(self):

OperatorNotAllowedInGraphError: using a tf.Tensor as a Python bool is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.
```

How can I correct my code so that I can run it successfully?"
40142,speech command related issue on custom dataset,"steps i followed for making dataset
1) collect 4 word (number,tollfree ,call,virtual) 
convert them into TTS and changed its pitch to make more data and achieved 
2500 data per sample
2) while training im getting an accuracy of 100% and validation is also 100% but when i test this on call data the result are all wrong.
99% is all wrong.
`I0604 07:34:51.632841 140415957108544 train.py:242] Step #1500: rate 0.000020, accuracy 100.00%, cross entropy 0.004794`


i dont know what im doing wrong"
40141,ERROR: /tensorflow_src/tensorflow/core/kernels/BUILD:4135:1: C++ compilation of rule '//tensorflow/core/kernels:cwise_op' failed (Exit 4),"
**System information**
- OS Platform: host: mac 14.10 
- docker image:  tensorflow/tensorflow:latest-devel
- TensorFlow version: 2.2
- Python version: 3.6.9
- building tensorflow from source using docker on mac with ubuntu in docker image
- Bazel version (if compiling from source): 3.0.0
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: NONE ( cpu only build)
- GPU model and memory: NONE 

**the problem**
```
ERROR: /tensorflow_src/tensorflow/core/kernels/BUILD:4135:1: C++ compilation of rule '//tensorflow/core/kernels:cwise_op' failed (Exit 4)
gcc: internal compiler error: Killed (program cc1plus)
Please submit a full bug report,
with preprocessed source if appropriate.
See <file:///usr/share/doc/gcc-7/README.Bugs> for instructions.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 1941.471s, Critical Path: 387.25s
INFO: 668 processes: 668 local.
FAILED: Build did NOT complete successfully

```
- I am trying to build tensorflow from source to enable the AVX and FMA instruction. i followed the exact set of instructions inorder to start building. As given [here](https://www.tensorflow.org/install/source#docker_linux_builds) i am building the cpu only version.
- Since i am building from the latest one, I should be building from master branch. so I initiated using the below command: 

` bazel build --config=opt --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --local_cpu_resources=1 --local_ram_resources=2048  //tensorflow/tools/pip_package:build_pip_package`

- after this the analysis phase was done. The error occurred during compilation.

unable to diagnose the error. Please help

"
40140,TF model convert to TFLite,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu18.04.3
- TensorFlow installed from (source or binary):
- TensorFlow version (or github SHA if from source):1.9.0


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.
import tensorflow as tf

graph_def_file = ""/home/pychen/MobileNetV2-SSD/MobileNetV2-SSD_600x300/frozen_inference_graph.pb""
input_arrays = [""image_tensor""]
output_arrays = [""detection_classes"", ""detection_boxes"", ""detection_scores""]

converter = tf.contrib.lite.TocoConverter.from_frozen_graph(
  graph_def_file=graph_def_file, input_arrays=input_arrays, output_arrays=output_arrays)
tflite_model = converter.convert()
open(""MobileNetV2_SSD.tflite"", ""wb"").write(tflite_model)
```
# Copy and paste here the exact command
```

**The output from the converter invocation**

```
# Copy and paste the output here.
```

**Also, please include a link to the saved model or GraphDef**

```
# Put link here or attach to the issue.
```

**Failure details**
If the conversion is successful, but the generated model is wrong,
state what is wrong:
- Producing wrong results and/or decrease in accuracy
- Producing correct results, but the model is slower than expected (model generated from old converter)


**RNN conversion support**
If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.

**Any other info / logs**
Traceback (most recent call last):
  File ""/home/pychen/.local/lib/python3.6/site-packages/tensorflow/python/framework/importer.py"", line 418, in import_graph_def
    graph._c_graph, serialized, options)  # pylint: disable=protected-access
tensorflow.python.framework.errors_impl.InvalidArgumentError: NodeDef mentions attr 'Truncate' not in Op<name=Cast; signature=x:SrcT -> y:DstT; attr=SrcT:type; attr=DstT:type>; NodeDef: ToFloat = Cast[DstT=DT_FLOAT, SrcT=DT_UINT8, Truncate=false](image_tensor). (Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""tf_to_tflite_graphdef.py"", line 8, in <module>
    graph_def_file=graph_def_file, input_arrays=input_arrays, output_arrays=output_arrays)
  File ""/home/pychen/.local/lib/python3.6/site-packages/tensorflow/contrib/lite/python/lite.py"", line 204, in from_frozen_graph
    import_graph_def(graph_def, name="""")
  File ""/home/pychen/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 432, in new_func
    return func(*args, **kwargs)
  File ""/home/pychen/.local/lib/python3.6/site-packages/tensorflow/python/framework/importer.py"", line 422, in import_graph_def
    raise ValueError(str(e))
ValueError: NodeDef mentions attr 'Truncate' not in Op<name=Cast; signature=x:SrcT -> y:DstT; attr=SrcT:type; attr=DstT:type>; NodeDef: ToFloat = Cast[DstT=DT_FLOAT, SrcT=DT_UINT8, Truncate=false](image_tensor). (Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).


Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
40139,Timeseries forecasting tutorial has bias issues,"
## URL(s) with the issue:

https://www.tensorflow.org/tutorials/structured_data/time_series
## Description of issue (what needs changing):

### Clear description

In the time-series forecasting tutorial, the normalization is done prior to obtaining time-series windows. 
Consider this:
`uni_data = (uni_data-uni_train_mean)/uni_train_std`
This is done before:
```
x_train_uni, y_train_uni = univariate_data(uni_data, 0, TRAIN_SPLIT,
                                           univariate_past_history,
                                           univariate_future_target)
```
This is causing the past_history samples using values of future targets as well during the normalization. This is a bias. In reality, we cannot use future values to normalize current values.
This, I think, is a bias and a bug.

### Correct links



### Parameters defined


### Returns defined


### Raises listed and defined


### Usage example

Normalization should be done after extraction of sequences and only using the LHS of the sequence. I still dont know if normalizing the RHS of the sequence is desired. but does not hurt as long as we denormalize

### Request visuals, if applicable


### Submit a pull request?

"
40138,tf.broadcast_to abort() and core dump when given shape value overflows int32,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:NA
- TensorFlow installed from (source or binary):binary
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0 & v2.1.0-rc2-17-ge5bf8de 2.1.0
- Python version: 3.7.6
- Bazel version (if compiling from source):NA
- GCC/Compiler version (if compiling from source):NA
- CUDA/cuDNN version:NA
- GPU model and memory:NA

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
`tf.broadcast_to` aborts and core dump if given `shape` could overflow `int32`. 
The `abort()` only seems to happen when `input` is in `uint32` or `uint64`.
If `input` is other dtype like `int32` or `float32`, tensorflow would not abort, but instead throw an exception to report the issue.
**Describe the expected behavior**
Tensorflow should not abort() and core dump.
Tensorflow should give a more meaningful message when overflow occurs and make the error handling behavior consistent.
**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

With `input` being `uint32` or `uint64` and a `shape` big enough to overflow `int32`:
```python
import tensorflow as tf
import numpy as np

in_tensor = np.array([1, 2]).astype('uint32')  # would later cause abort() and core dump
shape = np.array([1e18, 2]).astype('int64') # make shape big enough to overflow int32
tf.broadcast_to(in_tensor, shape)
```
would cause the following:
> ...
2020-06-04 06:16:17.434615: F tensorflow/core/framework/tensor_shape.cc:345] Check failed: size >= 0 (-1486618624 vs. 0)
Aborted (core dumped)

When `input` is not `uint32` nor `uint64` and a `shape` big enough to overflow `int32`:
```python
import tensorflow as tf
import numpy as np

in_tensor = np.array([1, 2]).astype('float32')  # would later cause exception
shape = np.array([1e18, 2]).astype('int64') # make shape big enough to overflow int32
tf.broadcast_to(in_tensor, shape)
```
would cause exception thrown instead of abort() and core dump:
>...
tensorflow.python.framework.errors_impl.InvalidArgumentError: Dimension -1486618624 must be >= 0 [Op:BroadcastTo]

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40137,Can't training model with multi GPU,"Hi, I try to train my model on Keras 2.3 and TF 2.2. I use tf.distribute.MirroredStrategy() and have issue #38500 and tf.keras.utils.multi_gpu_model but it was removed after 2020-04-01. I also face with OOM errors because i can't specify device to train. Please tell me how can i train model with multi-gpu and avoid OOM errors. Thank you so much!"
40136,Transfer segment_sum op from 2.2 to 1.15 version，Op type wrong。,"As the title, I try to transfer segment_sum op from 2.2 to 1.15 version. For some reason, we must use tensorflow 1.15. I diff the code between the two version. Finally, the  converted tflite model can compute correct, but the Op Type is wrong. 
<img width=""182"" alt=""TFLite Model"" src=""https://user-images.githubusercontent.com/41407473/83709781-cf60a280-a651-11ea-81dc-00b8798a3d05.png"">
<img width=""143"" alt=""TF Model"" src=""https://user-images.githubusercontent.com/41407473/83710045-5dd52400-a652-11ea-9a7e-cf9def6dcb9a.png"">
![image](https://user-images.githubusercontent.com/41407473/83710109-8c52ff00-a652-11ea-9b7a-3602347b046c.png)
I find 120 corresponds to NonMaxSuppressionV4 in tf 2.2.
Thanks for your help."
40135,Can contrib_audio.mfcc has gardient ?,"tensorflow version:1.14
python:3.6
I need to used operation(mfcc) in `tensorflow.python.ops import gen_audio_ops as contrib_audio` to extract mfcc feature from an audio, then compute the gradient for this audio. But I got error `LookupError: No gradient defined for operation 'mfcc' (op type: Mfcc)`. This operation can not via gradient? If not, how can I fix this error?
"
40131,DLL load failed,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): pip install 
- TensorFlow version: 1.14.0
- Python version: 3.7
- Installed using virtualenv? pip? conda?: pip
- GPU model and memory: 



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**

Cannot succesfully import keras

**Any other info / logs**

ImportError: Traceback (most recent call last):
  File ""C:\Users\u726\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\u726\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\u726\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\u726\Anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\u726\Anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.
"
40130,No Debug Symbols when using per_file_copt option,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): RHEL 8 (Linux 4.18.0-147)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.2.0
- Python version: 3.7
- Installed using virtualenv? pip? conda?:virtualenv
- Bazel version (if compiling from source): 2.0.0
- GCC/Compiler version (if compiling from source): 8.3.1
- CUDA/cuDNN version: Not used
- GPU model and memory: Not used


I've been building 2.2.0 from source (targets:build_pip_package and libtensorflow_cc.so) while  selectively including debug flags, using the per_file_copt option (per suggestion in issue #27495). 

 My build succeeds, but the debug symbols aren't there for either libtensorflow_cc.so.2.2.0 or the libtensorflow_framework.so.2.2.0.

 Below are some of the options I've tried. If I examine the .so files, with 'readelf -S libtensorflow_cc.so.2.2.0' they indicate that the debug symbols exist, but not so for libtensorflow_framework.so.2.2.0. TotalView debugger and gdb don't appear to find any of the debug symbols

**Provide the exact sequence of commands / steps that you executed before running into the problem**

I always build the build_pip_package target first. After it's complete I provide the exact same command (below), changing the build target to libtensorflow_cc.so


Variation 1 (This doesn't uses the per_file_copt option, but demonstrates that the --strip=never compile option gives an error when put after the '-c' flags):
 bazel build -c dbg --strip=never //tensorflow/tools/pip_package:build_pip_package

Variation 2: (moving the --strip=never flag in front of the -c options)
 bazel build --strip=never -c opt --config=opt --per_file_copt=//tensorflow/c/.*\.cc,//tensorflow/cc/.*/.*\.cc,//tensorflow/core/.*/.*\.cc@-g //tensorflow/tools/pip_package:build_pip_package

Variation 3 (try to prevent stripping by passing -O0 to the per_file_copt)
bazel build -c opt --config=opt --per_file_copt=//tensorflow/c/.*\.cc,//tensorflow/cc/.*/.*\.cc,//tensorflow/core/.*/.*\.cc@-g,O0  //tensorflow/tools/pip_package:build_pip_package

Please advise as to what I'm doing wrong and how to make sure that the debug symbols (which I believe are built), don't get stripped during linking.

Thanks

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
40129,TFLite Converter not quantizing supported op weights,"**System information**
-Mac OSX
-TF 2.3.0-dev20200602

**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
    # From Saved Model
    converter = tf.lite.TFLiteConverter.from_saved_model(curr_dir + ""saved_model"")
    # converter.optimizations = [tf.lite.Optimize.DEFAULT]
    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
                                           tf.lite.OpsSet.SELECT_TF_OPS]
    tflite_model = converter.convert()

    # Save the TF Lite model.
    with tf.io.gfile.GFile(curr_dir + '/model.tflite', 'wb') as f:
        f.write(tflite_model)
```


Model obtained from Model Zoo
http://download.tensorflow.org/models/object_detection/ssdlite_mobilenet_v2_coco_2018_05_09.tar.gz

Follow-up issue to : https://github.com/tensorflow/tensorflow/issues/40059

Running the above code to generate a tflite file from the pretrained ssdlite_mobilenet model. However I'm suspecting not a whole lot of optimization is happening. The file size for the frozen graph is 19911343 bytes and the optimized tflite model is 18905520 bytes. 

Dissecting the model (using Netron), I can also see that the [supported ops](https://www.tensorflow.org/lite/guide/ops_compatibility) are still using float32 type weights. 

I was hoping to see 2-4x size reduction as a good chunk of the model is conv2d with float32 weights. Any ideas why I'm not able to really optimize this particular model? 

Want to also add:

I modified my conversion code above to avoid use of the experimental flags:
```
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
```
replacing it with a stable-version documented configuration:
```
converter.optimizations = [tf.lite.Optimize.DEFAULT]
```

In this case the conversion fails:
```
error: 'tf.TensorArrayWriteV3' op is neither a custom op nor a flex op
error: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):
        tf.NonMaxSuppressionV2 {T = f32, T_threshold = f32, device = """"}
        tf.Size {device = """"}
        tf.TensorArrayGatherV3 {device = """", element_shape = #tf.shape<100>}
        tf.TensorArrayGatherV3 {device = """", element_shape = #tf.shape<100x4>}
        tf.TensorArrayGatherV3 {device = """", element_shape = #tf.shape<300x300x3>}
        tf.TensorArrayGatherV3 {device = """", element_shape = #tf.shape<3>}
        tf.TensorArrayGatherV3 {device = """", element_shape = #tf.shape<>}
        tf.TensorArrayReadV3 {device = """"}
        tf.TensorArrayScatterV3 {device = """"}
        tf.TensorArraySizeV3 {device = """"}
        tf.TensorArrayV3 {clear_after_read = true, device = """", dtype = f32, dynamic_size = false, element_shape = #tf.shape<*>, identical_element_shapes = false, tensor_array_name = """"}
        tf.TensorArrayV3 {clear_after_read = true, device = """", dtype = i32, dynamic_size = false, element_shape = #tf.shape<*>, identical_element_shapes = false, tensor_array_name = """"}
        tf.TensorArrayWriteV3 {device = """"}
```"
40127,Hierarchical display for TensorBoard,"**System information**
- TensorFlow version (you are using): 2.1
- Are you willing to contribute it (Yes/No): Not a frontend guy so I don't know if I can help.



**Describe the feature and the current behavior/state.**
I'm using TensorBoard to display an optimisation process with two stages, `lambda_sweep` and `counterfactual_search`, so I used the `name` argument to the summary ops to display the plots for the two stages separtely:

![image](https://user-images.githubusercontent.com/30216068/83668596-1e61f580-a5c8-11ea-9fb8-5199c97b3012.png)

I would like this behaviour to be hierarchical, that is, other drop-downs would appear when clicking one of the stages. Instead, I get the follwing:

![image](https://user-images.githubusercontent.com/30216068/83669076-df806f80-a5c8-11ea-9828-866bcb4d2071.png)

I was wondering if there is any way to extend the first level logic so that, for example, under `counterfactual_search` I get another page I can click on that is called `lambda`  and so on.





**Will this change the current api? How?**
I don't think so, it sounds more like a frontnend feature to me?
**Who will benefit with this feature?**
All tensorboard users.

**Any Other info.**
"
40126,Dynamic libtensorflow-lite for ARM64,"I followed [cross-compile for ARM64](https://www.tensorflow.org/lite/guide/build_arm64#cross-compile_for_arm64) and produced a static library `libtensorflow-lite.a`
Is it possible to cross-compile for ARM64 this library as dynamic (shared) *so* version for ARM64 as well? "
40125,tf.random.uniform unexpected behaviour for unknown shape,"Hi,

Using `tf.random.uniform` with a tensor of equal `minval` and `maxval` values and unknown shape does not generate the expected independent variates:
```
tf.random.uniform((), minval=[0, 0, 0], maxval=[4,4,4])
 <tf.Tensor: shape=(3,), dtype=float32, numpy=array([2.1699166, 2.1699166, 2.1699166], dtype=float32)>
```
If the shape is specified, however, independent random variates are returned:
```
tf.random.uniform([3], minval=[0, 0, 0], maxval=[4,4,4])
<tf.Tensor: shape=(3,), dtype=float32, numpy=array([1.3341255 , 0.45406246, 3.4779797 ], dtype=float32)>
```
Is this a bug or a known feature?  If the latter, should it be documented?

Thanks.

TF version 2.3.0-dev20200528 (tf-nightly)

"
40124,Cross-compile the label_image with ARM64 libtensorflow-lite.a,"I cross-compiled the TensorFlow Lite static library for ARM64-based computer and I'd like to build the label_image example for that target as well. To build label_image, it should run this command `bazel build tensorflow/examples/label_image/...` How should I set it to use that already built static library and cross-compile for ARM64-based target?

Thank you for your advice."
40123,sess.run() in tensorflow2.1,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 18.04):
- TensorFlow installed from (pip source form Tsinghua mirror):
- TensorFlow version (2.1):
- Python version:3.6.7
- GPU model and memory:without GPU


**Describe the current behavior**
when I used such code:
with tf.Graph().as_default() as graph:
    features = input_fn(input_fn_params)
    model_fn(features=features,
             labels=None,
             mode=tf.estimator.ModeKeys.PREDICT,
             params=model_fn_params)

    tf.train.Saver()
    graph_def = graph.as_graph_def(add_shapes=True)
    tf.train.write_graph(graph_def, directory, 'inference.pbtxt')
    meta_graph_name = os.path.join(directory, 'inference.meta')
    tf.train.export_meta_graph(filename=meta_graph_name)

How can I transform tensor to ndarray in  tf.Graph().as_default()


"
40122,Incorrect result of _MKLMaxPoolGrad,"**System information**
- OS Platform and Distribution: `Arch Linux 5.5.2-arch1-1  x86_64`
- TensorFlow installed from: `source`
- TensorFlow version: `v1.12.1-33097-g83eb4048ba 2.2.0` and `v2.2.0-0-g2b96f3662b 2.2.0`
- Python version: `Python 3.6.10`
- Bazel version: `3.0.0` for master, `2.0.0` for r2.2
- GCC/Compiler version: `GCC 9.3.0`

The package was built with the commands:
```bash
bazel build --config=mkl //tensorflow/tools/pip_package:build_pip_package
# For master (commit #83eb40)
./bazel-bin/tensorflow/tools/pip_package/build_pip_package --nightly_flag ./master-83eb40
# For r2.2
bazel build --config=mkl //tensorflow/tools/pip_package:build_pip_package
```

**Describe the current behavior**
The gradient of the max pooling 2D is wrong.

Code:
```python
import numpy as np
import tensorflow as tf
tf.compat.v1.disable_v2_behavior()

x = np.array([
    [3, 0, 0, 2, 3],
    [0, 0, 0, 0, 1],
    [0, 0, 0, 1, 3],
    [0, 0, 0, 0, 0],
    [1, 1, 3, 8, 6]
]).astype(np.float32).reshape([1, 5, 5, 1])

x_t = tf.compat.v1.placeholder(tf.float32, shape=[1, 5, 5, 1])
w = np.array([1]).reshape([1, 1, 1, 1]).astype(np.float32)
conv_t = tf.nn.conv2d(x_t, w, [1, 1, 1, 1], 'SAME')
pool_t = tf.nn.max_pool(conv_t, [1, 2, 2, 1], [1, 2, 2, 1], 'VALID')
grad_t = tf.gradients(ys=pool_t, xs=conv_t)

tensors = [conv_t, pool_t, grad_t]
tensors = [tf.squeeze(t, [-1]) for t in tensors]

with tf.compat.v1.Session() as sess:
    conv, pool, grad = sess.run(tensors, feed_dict={x_t: x})
    print('conv\n', conv, '\npool\n', pool, '\ngrad\n', grad)
```
Output:
```
conv
 [[[3. 0. 0. 2. 3.]
  [0. 0. 0. 0. 1.]
  [0. 0. 0. 1. 3.]
  [0. 0. 0. 0. 0.]
  [1. 1. 3. 8. 6.]]]
pool
 [[[3. 2.]
  [0. 1.]]]
grad
 [[[[1. 0. 1. 0. 0.]
   [0. 0. 0. 0. 0.]
   [1. 0. 1. 0. 0.]
   [0. 0. 0. 0. 0.]
   [0. 0. 0. 0. 0.]]]]
```

**Describe the expected behavior**
If we run the code with `TF_DISABLE_MKL=1`, the gradient will be
```
 [[[[1. 0. 0. 1. 0.]
   [0. 0. 0. 0. 0.]
   [1. 0. 0. 1. 0.]
   [0. 0. 0. 0. 0.]
   [0. 0. 0. 0. 0.]]]]
```
Note that the positions of the second `1`'s in the first and the third rows are different.

**Other info / logs**
If I directly feed the input to max pooling, the result is correct.
```python
import numpy as np
import tensorflow as tf
tf.compat.v1.disable_v2_behavior()


x = np.array([
    [3, 0, 0, 2, 3],
    [0, 0, 0, 0, 1],
    [0, 0, 0, 1, 3],
    [0, 0, 0, 0, 0],
    [1, 1, 3, 8, 6]
]).astype(np.float32).reshape([1, 5, 5, 1])

x_t = tf.compat.v1.placeholder(tf.float32, shape=[1, 5, 5, 1])
pool_t = tf.nn.max_pool(x_t, [1, 2, 2, 1], [1, 2, 2, 1], 'VALID')
grad_t = tf.gradients(ys=pool_t, xs=x_t)

tensors = [x_t, pool_t, grad_t]
tensors = [tf.squeeze(t, [-1]) for t in tensors]

with tf.compat.v1.Session() as sess:
    x, pool, grad = sess.run(tensors, feed_dict={x_t: x})
    print('x\n', x, '\npool\n', pool, '\ngrad\n', grad)
```
Output:
```
x
 [[[3. 0. 0. 2. 3.]
  [0. 0. 0. 0. 1.]
  [0. 0. 0. 1. 3.]
  [0. 0. 0. 0. 0.]
  [1. 1. 3. 8. 6.]]]
pool
 [[[3. 2.]
  [0. 1.]]]
grad
 [[[[1. 0. 0. 1. 0.]
   [0. 0. 0. 0. 0.]
   [1. 0. 0. 1. 0.]
   [0. 0. 0. 0. 0.]
   [0. 0. 0. 0. 0.]]]]
```
In addition, if the I replace the conv2d with relu, which will be also rewritten, the result is also correct.
```python
import numpy as np
import tensorflow as tf
tf.compat.v1.disable_v2_behavior()


x = np.array([
    [3, 0, 0, 2, 3],
    [0, 0, 0, 0, 1],
    [0, 0, 0, 1, 3],
    [0, 0, 0, 0, 0],
    [1, 1, 3, 8, 6]
]).astype(np.float32).reshape([1, 5, 5, 1])

x_t = tf.compat.v1.placeholder(tf.float32, shape=[1, 5, 5, 1])
relu_t = tf.nn.relu(x_t)
pool_t = tf.nn.max_pool(relu_t, [1, 2, 2, 1], [1, 2, 2, 1], 'VALID')
grad_t = tf.gradients(ys=pool_t, xs=relu_t)

tensors = [relu_t, pool_t, grad_t]
tensors = [tf.squeeze(t, [-1]) for t in tensors]

with tf.compat.v1.Session() as sess:
    relu, pool, grad = sess.run(tensors, feed_dict={x_t: x})
    print('relu\n', relu, '\npool\n', pool, '\ngrad\n', grad)
```
Output:
```
relu
 [[[3. 0. 0. 2. 3.]
  [0. 0. 0. 0. 1.]
  [0. 0. 0. 1. 3.]
  [0. 0. 0. 0. 0.]
  [1. 1. 3. 8. 6.]]]
pool
 [[[3. 2.]
  [0. 1.]]]
grad
 [[[[1. 0. 0. 1. 0.]
   [0. 0. 0. 0. 0.]
   [1. 0. 0. 1. 0.]
   [0. 0. 0. 0. 0.]
   [0. 0. 0. 0. 0.]]]]
```
I checked the log with `TF_CPP_MIN_VLOG_LEVEL=1` and confirmed that the OP was rewritten.

It seems that the result is affected by the convolution."
40121,TFlite Converter Error: from tensorflow.lite.toco.python.toco_from_protos import main ModuleNotFoundError: No module named 'tensorflow',"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.15.5
- TensorFlow installed from (source or binary):binary
- TensorFlow version (or github SHA if from source): tensorflow 2.2.0 
- Python 3.7.6


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]
tflite_quant_model = converter.convert()
open(""model/train/converted_model.tflite"", ""wb"").write(tflite_quant_model)
print('tflite convert finish')
```

**The output from the converter invocation**

```
Total params: 3,084,997
Trainable params: 3,084,997
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/10
25/25 [==============================] - 2s 79ms/step - loss: 0.6899 - accuracy: 0.6162
Epoch 2/10
25/25 [==============================] - 2s 77ms/step - loss: 0.5860 - accuracy: 0.6862
Epoch 3/10
25/25 [==============================] - 2s 75ms/step - loss: 0.4454 - accuracy: 0.8050
Epoch 4/10
25/25 [==============================] - 2s 76ms/step - loss: 0.2366 - accuracy: 0.9038
Epoch 5/10
25/25 [==============================] - 2s 76ms/step - loss: 0.1573 - accuracy: 0.9400
Epoch 6/10
25/25 [==============================] - 2s 76ms/step - loss: 0.0459 - accuracy: 0.9875
Epoch 7/10
25/25 [==============================] - 2s 76ms/step - loss: 0.0103 - accuracy: 0.9975
Epoch 8/10
25/25 [==============================] - 2s 75ms/step - loss: 0.0634 - accuracy: 0.9725
Epoch 9/10
25/25 [==============================] - 2s 76ms/step - loss: 0.0796 - accuracy: 0.9712
Epoch 10/10
25/25 [==============================] - 2s 75ms/step - loss: 0.0063 - accuracy: 0.9975
Saved trained model at ./model/train/sts_rmsprop_binary_crossentropy_epochs_10.h5 
2020-06-03 20:42:32.237929: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)
2020-06-03 20:42:32.238000: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-06-03 20:42:32.249905: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize
2020-06-03 20:42:32.249928: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.005ms.
2020-06-03 20:42:32.249932: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-06-03 20:42:32.472526: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)
2020-06-03 20:42:32.472630: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-06-03 20:42:32.594738: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize
2020-06-03 20:42:32.594761: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 66 nodes (-14), 66 edges (-16), time = 79.678ms.
2020-06-03 20:42:32.594766: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 66 nodes (0), 66 edges (0), time = 12.165ms.
Traceback (most recent call last):
  File ""sts_v2.py"", line 117, in <module>
    tflite_quant_model = converter.convert()
  File ""/Users/dingxirong/venv/lib/python3.7/site-packages/tensorflow/lite/python/lite.py"", line 518, in convert
    **converter_kwargs)
  File ""/Users/dingxirong/venv/lib/python3.7/site-packages/tensorflow/lite/python/convert.py"", line 496, in toco_convert_impl
    enable_mlir_converter=enable_mlir_converter)
  File ""/Users/dingxirong/venv/lib/python3.7/site-packages/tensorflow/lite/python/convert.py"", line 227, in toco_convert_protos
    raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: See console for info.
Traceback (most recent call last):
  File ""/Users/dingxirong/venv/bin/toco_from_protos"", line 5, in <module>
    from tensorflow.lite.toco.python.toco_from_protos import main
ModuleNotFoundError: No module named 'tensorflow'

```"
40119,RuntimeError: Encountered unresolved custom op: RandomStandardNormal.Node number 1 (RandomStandardNormal) failed to prepare,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (or github SHA if from source): 2.1.0

**Output from the converter and interpreter invocations**
```
2020-06-03 10:23:11.668039: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize
2020-06-03 10:23:11.668089: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.003ms.
2020-06-03 10:23:11.668114: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-06-03 10:23:11.850912: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
2020-06-03 10:23:11.851102: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-06-03 10:23:11.856571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:
pciBusID: 0000:09:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-06-03 10:23:11.856639: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-06-03 10:23:11.856672: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-06-03 10:23:11.856706: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-06-03 10:23:11.856737: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-06-03 10:23:11.856768: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-06-03 10:23:11.856808: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-06-03 10:23:11.856835: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-06-03 10:23:11.865046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-06-03 10:23:11.865092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-06-03 10:23:11.865108: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0
2020-06-03 10:23:11.865121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N
2020-06-03 10:23:11.916336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10770 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:09:00.0, compute capability: 3.7)
2020-06-03 10:23:11.936932: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize
2020-06-03 10:23:11.936982: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 70 nodes (-33), 73 edges (-37), time = 7.528ms.
2020-06-03 10:23:11.936998: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 70 nodes (0), 73 edges (0), time = 2.65ms.
Traceback (most recent call last):
  File ""train.py"", line 30, in <module>
    tflite_interpreter.allocate_tensors()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/interpreter.py"", line 247, in allocate_tensors
    return self._interpreter.AllocateTensors()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py"", line 110, in AllocateTensors
    return _tensorflow_wrap_interpreter_wrapper.InterpreterWrapper_AllocateTensors(self)
RuntimeError: Encountered unresolved custom op: RandomStandardNormal.Node number 1 (RandomStandardNormal) failed to prepare.
```

**Standalone code to reproduce the issue** 
```
import tensorflow as tf
import tensorflow_probability as tfp
from tensorflow_probability import distributions as tfd

(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

x_train = x_train.astype('float32')/255.
x_test = x_test.astype('float32')/255.

kl_divergence_function = (lambda q, p, _: tfd.kl_divergence(q, p) /
                          tf.cast(x_train.shape[0], dtype=tf.float32))

model = tf.keras.Sequential([
    tf.keras.layers.Flatten(),
    tfp.layers.DenseFlipout(
        10, kernel_divergence_fn=kl_divergence_function,
        activation=tf.nn.softmax
    ),
])

optimizer = tf.keras.optimizers.Adam(lr=0.001)
model.compile(optimizer, loss='sparse_categorical_crossentropy')
model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=3)

tflite_converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_converter.allow_custom_ops = True
tflite_model = tflite_converter.convert()

tflite_interpreter = tf.lite.Interpreter(model_content=tflite_model)
tflite_interpreter.allocate_tensors()
```

Also, please include a link to a GraphDef or the model if possible.
[model.zip](https://github.com/tensorflow/tensorflow/files/4722692/model.zip)

**Issue details**

I have been trying to convert a keras/saved_model into a tflite model. While the converter is not producing errors, suggesting that the conversion is succesful, when the interpreter is invoked I get the following:
`RuntimeError: Encountered unresolved custom op: RandomStandardNormal.Node number 1 (RandomStandardNormal) failed to prepare.`

I have attached a simple script to reproduce the error, as well as the saved_model files.

"
40117,'os' has no attribute 'errno' when using keras.utils.plot_model,"**System information**
- Tensorflow install via pip
- `pydot` version 1.2.3
- `tensorflow` version 2.2.0
- `python` 3.7.7

**Error Details**
When running `tf.keras.utils.plot_model` an error is raised:

```
~\Anaconda3\lib\site-packages\pydot.py in create(self, prog, format)
   1878                 stderr=subprocess.PIPE, stdout=subprocess.PIPE)
   1879         except OSError as e:
-> 1880             if e.errno == os.errno.ENOENT:
   1881                 raise Exception(
   1882                     '""{prog}"" not found in path.'.format(

AttributeError: module 'os' has no attribute 'errno'
```

I understand that this error is a problem with `pydot`, but perhaps a `pydot` version bump would fix this problem (most recent `pydot` version is 1.4.*).

**Code to Reproduce**
```python
import tensorflow as tf

model = tf.keras.models.Sequential([
    tf.keras.Input(shape=(512, 512, 1)),
    tf.keras.layers.Conv2D(3, 3),
    tf.keras.layers.MaxPool2D(),
])

tf.keras.utils.plot_model(model)
```"
42805,Tensorflowの「overfit and underfit」の不備,%tensorboard --logdir {logdir}/sizes　を実行すると　UsageError: Line magic function `%tensorboard` not found.　となる。
40115,Attempted to use a closed filewriter,"Hello, everyone, I am doing cosine_matrix_learning based on tensorflow_1.14.0. When I run the code, I got a warning like this:

/home/duyao/anaconda3/envs/cosine_metric_learning/lib/python3.7/site-packages/tensorflow/python/summary/writer/writer.py:386: UserWarning: Attempting to use a closed FileWriter. The operation will be a noop unless the FileWriter is explicitly reopened.
  warnings.warn(""Attempting to use a closed FileWriter. ""

However, I found there is the reopen function in the tensorflow_writer.py, but it seems not work.

 def reopen(self):
    """"""Reopens the EventFileWriter.

    Can be called after `close()` to add more events in the same directory.
    The events will go into a new events file.

    Does nothing if the EventFileWriter was not closed.
    """"""
    self.event_writer.reopen()
    self._closed = False


It seems that the problem is not caused by my project-related codes. I am confused about this, do I need to make some configuration about tensorflow when I train my model? I hope someone can give me some advice, thank you~






"
40114,[Feature Request] Logging of validation metrics when using validation_freq > 1,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.2.0
- Are you willing to contribute it (Yes/No): No



**Describe the feature and the current behavior/state.**
The `tf.keras.callbacks.CSVLogger` currently does not log metrics which are not computed every epoch during training. By this I mean that the columns in the produced .csv file do not contain certain metrics. This includes validation scores if they are (for performace reasons) only computed every validation_freq training epochs when using Model.fit.
Allowing the user to pass another (optional) parameter to the CSVLogger constructor called, say, 'missing_value_string' which is then used to fill the rows where no value is available for a metric.
I fear the reasons for why validation metrics are not being logged for me lie deeper, however, wherever the metrics to be logged are selected (which, I think, is not in CSVLogger).

**Will this change the current api? How?**
I can't quite tell. I would not expect significant changes of the API.

**Who will benefit with this feature?**
People who cannot, for some reason, change the number of steps in an epoch circumventing the need to set validation_freq!=1.

**Any Other info.**
"
40113,ERROR: /tensorflow_src/tensorflow/compiler/aot/BUILD:277:1: C++ compilation of rule '//tensorflow/compiler/aot:embedded_protocol_buffers' failed (Exit 1),"

**System information**
- OS Platform: host: mac 14.10 
- docker image:  tensorflow/tensorflow:latest-devel
- TensorFlow version: 2.2
- Python version: 3.6.9
- building tensorflow from source using docker on mac with ubuntu in docker image
- Bazel version (if compiling from source): 3.0.0
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: NONE ( cpu only build)
- GPU model and memory: NONE 

**the problem**
```
ERROR: /tensorflow_src/tensorflow/compiler/aot/BUILD:277:1: C++ compilation of rule '//tensorflow/compiler/aot:embedded_protocol_buffers' failed (Exit 1)
In file included from ./third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint:41:0,
                 from ./tensorflow/core/framework/numeric_types.h:24,
                 from ./tensorflow/compiler/xla/types.h:23,
                 from ./tensorflow/compiler/xla/array.h:34,
                 from ./tensorflow/compiler/xla/array2d.h:29,
                 from ./tensorflow/compiler/xla/literal.h:32,
                 from ./tensorflow/compiler/xla/service/llvm_ir/llvm_util.h:33,
                 from tensorflow/compiler/aot/embedded_protocol_buffers.cc:31:
./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:30:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]
 typedef eigen_packet_wrapper<__m256i, 20> Packet32q8i;
                                         ^
./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:31:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]
 typedef eigen_packet_wrapper<__m256i, 21> Packet16q16i;
                                         ^
./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:32:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]
 typedef eigen_packet_wrapper<__m256i, 22> Packet32q8u;
                                         ^
./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:33:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]
 typedef eigen_packet_wrapper<__m128i, 23> Packet16q8i;
                                         ^
./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:34:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]
 typedef eigen_packet_wrapper<__m128i, 25> Packet16q8u;
                                         ^
./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:35:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]
 typedef eigen_packet_wrapper<__m128i, 26> Packet8q16i;
                                         ^
./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:36:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]
 typedef eigen_packet_wrapper<__m256i, 27> Packet8q32i;
                                         ^
./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:37:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]
 typedef eigen_packet_wrapper<__m128i, 28> Packet4q32i;
                                         ^
In file included from ./tensorflow/compiler/xla/index_util.h:24:0,
                 from ./tensorflow/compiler/xla/literal.h:35,
                 from ./tensorflow/compiler/xla/service/llvm_ir/llvm_util.h:33,
                 from tensorflow/compiler/aot/embedded_protocol_buffers.cc:31:
./tensorflow/compiler/xla/shape.h: In member function 'void xla::Shape::clear_dynamic_dimensions()':
./tensorflow/compiler/xla/shape.h:139:27: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
       for (int64 i = 0; i < dynamic_dimensions_.size(); ++i) {
                         ~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~
In file included from ./tensorflow/compiler/xla/service/llvm_ir/llvm_util.h:34:0,
                 from tensorflow/compiler/aot/embedded_protocol_buffers.cc:31:
./tensorflow/compiler/xla/service/hlo_instruction.h: In member function 'void xla::HloInstruction::ReplaceCalledComputations(std::function<xla::HloComputation*(xla::HloComputation*)>)':
./tensorflow/compiler/xla/service/hlo_instruction.h:1431:25: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
     for (int64 i = 0; i < called_computations_.size(); ++i) {
                       ~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
In file included from ./tensorflow/core/platform/default/logging.h:29:0,
                 from ./tensorflow/core/platform/logging.h:27,
                 from ./tensorflow/core/platform/status.h:24,
                 from ./tensorflow/core/lib/core/status.h:19,
                 from ./tensorflow/compiler/xla/status.h:19,
                 from ./tensorflow/compiler/xla/statusor.h:18,
                 from ./tensorflow/compiler/aot/embedded_protocol_buffers.h:24,
                 from tensorflow/compiler/aot/embedded_protocol_buffers.cc:16:
./tensorflow/core/platform/default/logging.h: In instantiation of 'std::__cxx11::string* tensorflow::internal::Check_LEImpl(const T1&, const T2&, const char*) [with T1 = long long int; T2 = long unsigned int; std::__cxx11::string = std::__cxx11::basic_string<char>]':
./tensorflow/compiler/xla/shape_util.h:129:5:   required from here
./tensorflow/core/platform/default/logging.h:388:35: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
 TF_DEFINE_CHECK_OP_IMPL(Check_LE, <=)
./tensorflow/core/platform/macros.h:88:49: note: in definition of macro 'TF_PREDICT_TRUE'
 #define TF_PREDICT_TRUE(x) (__builtin_expect(!!(x), 1))
                                                 ^
./tensorflow/core/platform/default/logging.h:388:1: note: in expansion of macro 'TF_DEFINE_CHECK_OP_IMPL'
 TF_DEFINE_CHECK_OP_IMPL(Check_LE, <=)
 ^~~~~~~~~~~~~~~~~~~~~~~
In file included from ./tensorflow/compiler/xla/array2d.h:29:0,
                 from ./tensorflow/compiler/xla/literal.h:32,
                 from ./tensorflow/compiler/xla/service/llvm_ir/llvm_util.h:33,
                 from tensorflow/compiler/aot/embedded_protocol_buffers.cc:31:
./tensorflow/compiler/xla/array.h: In instantiation of 'bool xla::Array<T>::operator==(const xla::Array<T>&) const [with T = long long int]':
./tensorflow/compiler/xla/service/hlo_sharding.h:190:38:   required from here
./tensorflow/compiler/xla/array.h:430:25: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
     for (int64 i = 0; i < sizes_.size(); ++i) {
                       ~~^~~~~~~~~~~~~~~
In file included from ./tensorflow/core/platform/default/logging.h:29:0,
                 from ./tensorflow/core/platform/logging.h:27,
                 from ./tensorflow/core/platform/status.h:24,
                 from ./tensorflow/core/lib/core/status.h:19,
                 from ./tensorflow/compiler/xla/status.h:19,
                 from ./tensorflow/compiler/xla/statusor.h:18,
                 from ./tensorflow/compiler/aot/embedded_protocol_buffers.h:24,
                 from tensorflow/compiler/aot/embedded_protocol_buffers.cc:16:
./tensorflow/compiler/xla/array.h: In instantiation of 'tensorflow::int64 xla::Array<T>::dim(tensorflow::int64) const [with T = int; tensorflow::int64 = long long int]':
./tensorflow/compiler/xla/array2d.h:71:44:   required from 'tensorflow::int64 xla::Array2D<T>::height() const [with T = int; tensorflow::int64 = long long int]'
./tensorflow/compiler/xla/service/computation_placer.h:47:45:   required from here
./tensorflow/compiler/xla/array.h:406:13: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
     CHECK(n < sizes_.size());
./tensorflow/core/platform/macros.h:87:47: note: in definition of macro 'TF_PREDICT_FALSE'
 #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))
                                               ^
./tensorflow/compiler/xla/array.h:406:5: note: in expansion of macro 'CHECK'
     CHECK(n < sizes_.size());
     ^
tensorflow/compiler/aot/embedded_protocol_buffers.cc: At global scope:
tensorflow/compiler/aot/embedded_protocol_buffers.cc:152:1: fatal error: opening dependency file bazel-out/host/bin/tensorflow/compiler/aot/_objs/embedded_protocol_buffers/embedded_protocol_buffers.pic.d: Structure needs cleaning
 }  // namespace tensorflow
 ^
compilation terminated.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
ERROR: /tensorflow_src/tensorflow/python/tools/BUILD:82:1 C++ compilation of rule '//tensorflow/compiler/aot:embedded_protocol_buffers' failed (Exit 1)
INFO: Elapsed time: 82780.701s, Critical Path: 581.17s
INFO: 16036 processes: 16036 local.
FAILED: Build did NOT complete successfully

```
- I am trying to build tensorflow from source to enable the AVX and FMA instruction. i followed the exact set of instructions inorder to start building. As given [here](https://www.tensorflow.org/install/source#docker_linux_builds) i am building the cpu only version.
- Since i am building from the latest one, I should be building from master branch. so I initiated using the below command: 

` bazel build --config=opt --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --local_cpu_resources=1 --local_ram_resources=2048  //tensorflow/tools/pip_package:build_pip_package`

- after this the analysis phase was done. The error occurred during compilation.

unable to diagnose the error. Please help

EDIT: update: I tried to build again. but the error this arror occured: 
```ERROR: /tensorflow_src/tensorflow/compiler/aot/BUILD:295:1: failed to create output directory '/root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/compiler/aot/_objs/aot_only_var_handle_op': /root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/compiler/aot/_objs/aot_only_var_handle_op (Structure needs cleaning)
Target //tensorflow/tools/pip_package:build_pip_package failed to build
ERROR: /tensorflow_src/tensorflow/python/tools/BUILD:99:1 failed to create output directory '/root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/compiler/aot/_objs/aot_only_var_handle_op': /root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/compiler/aot/_objs/aot_only_var_handle_op (Structure needs cleaning)```"
40112,import tensorflow as tf not working on WIN10,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): WIN10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): tf2.2.0
- TensorFlow version (use command below):
- Python version: 3.7.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
~\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py in <module>
     57 
---> 58   from tensorflow.python.pywrap_tensorflow_internal import *
     59 

~\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py in <module>
     27             return _mod
---> 28     _pywrap_tensorflow_internal = swig_import_helper()
     29     del swig_import_helper

~\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py in swig_import_helper()
     23             try:
---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
     25             finally:

~\anaconda3\lib\imp.py in load_module(name, file, filename, details)
    241         else:
--> 242             return load_dynamic(name, filename, file)
    243     elif type_ == PKG_DIRECTORY:

~\anaconda3\lib\imp.py in load_dynamic(name, path, file)
    341             name=name, loader=loader, origin=path)
--> 342         return _load(spec)
    343 

ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

ImportError                               Traceback (most recent call last)
<ipython-input-14-ebece4447484> in <module>
      5 import re
      6 from bs4 import BeautifulSoup
----> 7 import tensorflow as tf
      8 # from keras.preprocessing.text import Tokenizer
      9 # from keras.preprocessing.sequence import pad_sequences

~\anaconda3\lib\site-packages\tensorflow\__init__.py in <module>
     39 import sys as _sys
     40 
---> 41 from tensorflow.python.tools import module_util as _module_util
     42 from tensorflow.python.util.lazy_loader import LazyLoader as _LazyLoader
     43 

~\anaconda3\lib\site-packages\tensorflow\python\__init__.py in <module>
     48 import numpy as np
     49 
---> 50 from tensorflow.python import pywrap_tensorflow
     51 
     52 # Protocol buffers

~\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py in <module>
     67 for some common reasons and solutions.  Include the entire stack trace
     68 above this error message when asking for help."""""" % traceback.format_exc()
---> 69   raise ImportError(msg)
     70 
     71 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long

ImportError: Traceback (most recent call last):
  File ""C:\Users\SHARATHWIN10\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\SHARATHWIN10\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\SHARATHWIN10\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\SHARATHWIN10\anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\SHARATHWIN10\anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
**Describe the expected behavior**
Should work without any errors

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
import tensorflow as tf
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40110,Dynamically added layers do not show up in custom model layers member,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Os X 10.15.4
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.2.0
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
I have a custom model https://gist.github.com/SandeepNaidu/d4d9482daa466fa21b22211693bbae82 which is used to create dynamically the architecture in terms of depth and breadth of the network. Even upon adding directly to self.layers it does not show up later when the layers are retrieved. The number of hidden layers and breadth can vary based on experiments. So need a better way to add them to self.layers. 

**Describe the expected behavior**
Ability to add layers dynamically to layers object of Model in custom model

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
https://gist.github.com/SandeepNaidu/d4d9482daa466fa21b22211693bbae82

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40108,TF reports cublas64_10.dll not found,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Version 1909
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.2
- Python version: 3.8.3
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1/7.6.5
- GPU model and memory: NVIDIA Quadro M1200 - 4 GB



**Describe the problem**
I am trying to get tensorflow to make use of the NVIDIA GPU in my laptop.  Tensorflow is able to find all CUDA-related libraries *except* cublas64_10.dll.  After installing CUDA 10.1 (I've tried 10.1 and 10.1 update 2, both without any success), I copied all the .dll files that got installed in ""C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\bin"" to C:\Windows\System32.  I included cublas64_10.dll when I copied these files.  (Before copying the .dll files, tensorflow could not find any of the CUDA-related libraries, even after adding ""C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\bin"" to my PATH and rebooting my computer a couple times.)  I confirmed that the cublas64_10.dll in C:\Windows\System32 was bit-for-bit identical to the one in ""C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\bin"", and that I had permission to read cublas64_10.dll.  (I copied this file from C:\Windows\System32 to a different directory to confirm this.)  I also downloaded just CUBLAS from CUDA 10.2, being very careful no other components got installed on my system, and then copied the cublas64_10.dll file from that version of CUDA to C:\Windows\System32.  None of my efforts were fruitful.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
python -c ""import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))""

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
>python -c ""import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))""
2020-06-02 21:13:03.752642: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-06-02 21:13:06.095237: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-06-02 21:13:06.576837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: Quadro M1200 computeCapability: 5.0
coreClock: 1.148GHz coreCount: 5 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 74.65GiB/s
2020-06-02 21:13:06.588734: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-06-02 21:13:06.594961: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cublas64_10.dll'; dlerror: cublas64_10.dll not found
2020-06-02 21:13:06.604653: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-06-02 21:13:06.615330: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-06-02 21:13:06.626644: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-06-02 21:13:06.635321: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-06-02 21:13:06.652175: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-06-02 21:13:06.658845: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1598] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
[]

>DIR ""C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\bin\cublas64_10.dll"" C:\Windows\System32\cublas64_10.dll
 Volume in drive C is OSDisk
 Volume Serial Number is E295-9E24

 Directory of C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\bin

07/28/2019  10:30 PM        58,830,848 cublas64_10.dll
               1 File(s)     58,830,848 bytes

 Directory of C:\Windows\System32

07/28/2019  10:30 PM        58,830,848 cublas64_10.dll
               1 File(s)     58,830,848 bytes
               0 Dir(s)  64,581,230,592 bytes free

>PATH
PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\libnvvp;;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0;C:\WINDOWS\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\WebEx\Productivity Tools;C:\Program Files\osquery;C:\Program Files\Intel\WiFi\bin;C:\Program Files\Common Files\Intel\WirelessCommon;C:\Program Files\nodejs;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Perforce;C:\Program Files\NVIDIA Corporation\Nsight Compute 2019.4.0\;C:\Users\figueroa\AppData\Local\Microsoft\WindowsApps;C:\Users\figueroa\AppData\Roaming\npm;C:\Users\figueroa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\Scripts;""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64"";""U:\Perforce\sw\main\apps\p4review"";""U:\Perforce\sw\tools\cygnus\bin"";""U:\Perforce\sw\tools\win64\ActivePerl\5.10.1.1006\bin""
"
40107,[tf.data] preserve_cardinality in map(),"I was wondering the reason of the `preserve_cardinality` argument in `MapDataset` and `ParallelMapDataset`. As far as I can see, the corresponding ops are both implemented with:
```c++
int64 Cardinality() const override { return input_->Cardinality(); }
```
However, in python, we have
```python
  @functools.wraps(DatasetV2.map)
  def map(self, map_func, num_parallel_calls=None, deterministic=None):
    if num_parallel_calls is None:
      return DatasetV1Adapter(
          MapDataset(self, map_func, preserve_cardinality=False))
    else:
      return DatasetV1Adapter(
          ParallelMapDataset(
              self,
              map_func,
              num_parallel_calls,
              deterministic,
              preserve_cardinality=False))
```
Could anyone tell me the purpose of `preserve_cardinality`? And if there are any modification need doing, I'd love to help. Thank you!"
40104,`tf.compat.v1.setdiff1d` documentation refers `out_idx` as an argument,"## URL(s) with the issue:

https://www.tensorflow.org/api_docs/python/tf/compat/v1/setdiff1d

## Description of issue (what needs changing):

### Clear description

In the ""Args"" section, there is an input `out_idx`, but it is not in the signature, and the function doesn't accept the argument.

Running code: 

~~~python
tf.compat.v1.setdiff1d([1],[1],out_idx=tf.dtypes.int32, name=None)
~~~

got exception:

~~~python
TypeError: setdiff1d() got an unexpected keyword argument 'out_idx'
~~~

### Parameters defined

Yes

### Returns defined

Yes

### Raises listed and defined

No


## System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS Mojave 10.14
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 2.2.0-rc3
- **Python version**: 3.8.2"
40103,Unclear type/dimension dependency of `filters` in  `conv1d/3d_transpose` documentation,"## URL(s) with the issue:

https://www.tensorflow.org/api_docs/python/tf/nn/conv1d_transpose

https://www.tensorflow.org/api_docs/python/tf/nn/conv3d_transpose

## Description of issue (what needs changing):

### Clear description

Unclear type and dimension dependency of input `filters`. According to the document, `filters` should have the same type as `value` and the `in_channel` dimension must match that of `value`, but it is unclear what `value` is.

### Parameters defined

Yes

### Returns defined

Yes

### Raises listed and defined

https://www.tensorflow.org/api_docs/python/tf/nn/conv1d_transpose: Yes

https://www.tensorflow.org/api_docs/python/tf/nn/conv3d_transpose:  No, the ""Raises"" list is not provided or defined


## System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS Mojave 10.14
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 2.2.0-rc3
- **Python version**: 3.8.2
  "
40102,Exception: could not rewrite use of immutable bound input,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (or github SHA if from source): 2.3.0-dev20200601


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
tf_converter = tf.lite.TFLiteConverter.from_saved_model(""./saved_model_v2.3"")
# tf_converter.allow_custom_ops = True
# tf_converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
# tf_converter.experimental_new_converter = True
tflite_model = tf_converter.convert()
```

**The output from the converter invocation**
- On 2.3.0-dev20200601
```
---------------------------------------------------------------------------
Exception                                 Traceback (most recent call last)
~/VirtualEnv/ENV37-TFNT/lib/python3.7/site-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
    179                                                  debug_info_str,
--> 180                                                  enable_mlir_converter)
    181       return model_str

~/VirtualEnv/ENV37-TFNT/lib/python3.7/site-packages/tensorflow/lite/python/wrap_toco.py in wrapped_toco_convert(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
     37       debug_info_str,
---> 38       enable_mlir_converter)
     39 

Exception: <unknown>:0: error: loc(callsite(callsite(""functional_1/crf__layer_v2/cond@__inference__wrapped_model_19200"" at ""StatefulPartitionedCall@__inference_signature_wrapper_34502"") at ""StatefulPartitionedCall"")): could not rewrite use of immutable bound input
<unknown>:0: note: loc(""StatefulPartitionedCall""): called from
<unknown>:0: note: loc(callsite(callsite(""functional_1/crf__layer_v2/cond@__inference__wrapped_model_19200"" at ""StatefulPartitionedCall@__inference_signature_wrapper_34502"") at ""StatefulPartitionedCall"")): see current operation: %96:2 = ""tf.If""(%94, %91, %95, %arg2) {_lower_using_switch_merge = true, _read_only_resource_inputs = [3], device = """", else_branch = @functional_1_crf__layer_v2_cond_false_189510, is_stateless = false, output_shapes = [#tf.shape<?x?>, #tf.shape<?>], then_branch = @functional_1_crf__layer_v2_cond_true_189500} : (tensor<i1>, tensor<?x?x15xf32>, tensor<?xi32>, tensor<!tf.resource<tensor<15x15xf32>>>) -> (tensor<?x?xi32>, tensor<?xf32>)


During handling of the above exception, another exception occurred:

ConverterError                            Traceback (most recent call last)
<ipython-input-6-23c7043d5029> in <module>
----> 1 tflite_model = tf_converter.convert()

~/VirtualEnv/ENV37-TFNT/lib/python3.7/site-packages/tensorflow/lite/python/lite.py in convert(self)
    575     return super(TFLiteSavedModelConverterV2,
    576                  self).convert(meta_graph.graph_def, input_tensors,
--> 577                                output_tensors)
    578 
    579 

~/VirtualEnv/ENV37-TFNT/lib/python3.7/site-packages/tensorflow/lite/python/lite.py in convert(self, graph_def, input_tensors, output_tensors)
    496         input_tensors=input_tensors,
    497         output_tensors=output_tensors,
--> 498         **converter_kwargs)
    499 
    500     if quant_mode.post_training_int8_no_float():

~/VirtualEnv/ENV37-TFNT/lib/python3.7/site-packages/tensorflow/lite/python/convert.py in toco_convert_impl(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)
    553       input_data.SerializeToString(),
    554       debug_info_str=debug_info_str,
--> 555       enable_mlir_converter=enable_mlir_converter)
    556   return data
    557 

~/VirtualEnv/ENV37-TFNT/lib/python3.7/site-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
    181       return model_str
    182     except Exception as e:
--> 183       raise ConverterError(str(e))
    184 
    185   if distutils.spawn.find_executable(_toco_from_proto_bin) is None:

ConverterError: <unknown>:0: error: loc(callsite(callsite(""functional_1/crf__layer_v2/cond@__inference__wrapped_model_19200"" at ""StatefulPartitionedCall@__inference_signature_wrapper_34502"") at ""StatefulPartitionedCall"")): could not rewrite use of immutable bound input
<unknown>:0: note: loc(""StatefulPartitionedCall""): called from
<unknown>:0: note: loc(callsite(callsite(""functional_1/crf__layer_v2/cond@__inference__wrapped_model_19200"" at ""StatefulPartitionedCall@__inference_signature_wrapper_34502"") at ""StatefulPartitionedCall"")): see current operation: %96:2 = ""tf.If""(%94, %91, %95, %arg2) {_lower_using_switch_merge = true, _read_only_resource_inputs = [3], device = """", else_branch = @functional_1_crf__layer_v2_cond_false_189510, is_stateless = false, output_shapes = [#tf.shape<?x?>, #tf.shape<?>], then_branch = @functional_1_crf__layer_v2_cond_true_189500} : (tensor<i1>, tensor<?x?x15xf32>, tensor<?xi32>, tensor<!tf.resource<tensor<15x15xf32>>>) -> (tensor<?x?xi32>, tensor<?xf32>)
```

- On v2.2.0
```
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
~/VirtualEnv/ENV37-TF22/lib/python3.7/site-packages/tensorflow/python/framework/importer.py in _import_graph_def_internal(graph_def, input_map, return_elements, validate_colocation_constraints, name, producer_op_list)
    496         results = c_api.TF_GraphImportGraphDefWithResults(
--> 497             graph._c_graph, serialized, options)  # pylint: disable=protected-access
    498         results = c_api_util.ScopedTFImportGraphDefResults(results)

InvalidArgumentError: Input 3 of node StatefulPartitionedCall/model/crf__layer_v2/cond was passed resource from Func/StatefulPartitionedCall/input/_18:0 incompatible with expected float.

During handling of the above exception, another exception occurred:

ValueError                                Traceback (most recent call last)
<ipython-input-6-23c7043d5029> in <module>
----> 1 tflite_model = tf_converter.convert()

~/VirtualEnv/ENV37-TF22/lib/python3.7/site-packages/tensorflow/lite/python/lite.py in convert(self)
    457     frozen_func, graph_def = (
    458         _convert_to_constants.convert_variables_to_constants_v2_as_graph(
--> 459             self._funcs[0], lower_control_flow=False))
    460     input_tensors = [
    461         tensor for tensor in frozen_func.inputs

~/VirtualEnv/ENV37-TF22/lib/python3.7/site-packages/tensorflow/python/framework/convert_to_constants.py in convert_variables_to_constants_v2_as_graph(func, lower_control_flow, aggressive_inlining)
    705   graph_def, converted_inputs = _convert_variables_to_constants_v2_impl(
    706       func, lower_control_flow, aggressive_inlining)
--> 707   frozen_func = _construct_concrete_function(func, graph_def, converted_inputs)
    708   return frozen_func, graph_def

~/VirtualEnv/ENV37-TF22/lib/python3.7/site-packages/tensorflow/python/framework/convert_to_constants.py in _construct_concrete_function(func, output_graph_def, converted_input_indices)
    404   new_func = wrap_function.function_from_graph_def(output_graph_def,
    405                                                    new_input_names,
--> 406                                                    new_output_names)
    407 
    408   # Manually propagate shape for input tensors where the shape is not correctly

~/VirtualEnv/ENV37-TF22/lib/python3.7/site-packages/tensorflow/python/eager/wrap_function.py in function_from_graph_def(graph_def, inputs, outputs)
    631     importer.import_graph_def(graph_def, name="""")
    632 
--> 633   wrapped_import = wrap_function(_imports_graph_def, [])
    634   import_graph = wrapped_import.graph
    635   return wrapped_import.prune(

~/VirtualEnv/ENV37-TF22/lib/python3.7/site-packages/tensorflow/python/eager/wrap_function.py in wrap_function(fn, signature, name)
    609           signature=signature,
    610           add_control_dependencies=False,
--> 611           collections={}),
    612       variable_holder=holder,
    613       signature=signature)

~/VirtualEnv/ENV37-TF22/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    979         _, original_func = tf_decorator.unwrap(python_func)
    980 
--> 981       func_outputs = python_func(*func_args, **func_kwargs)
    982 
    983       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

~/VirtualEnv/ENV37-TF22/lib/python3.7/site-packages/tensorflow/python/eager/wrap_function.py in __call__(self, *args, **kwargs)
     84 
     85   def __call__(self, *args, **kwargs):
---> 86     return self.call_with_variable_creator_scope(self._fn)(*args, **kwargs)
     87 
     88   def call_with_variable_creator_scope(self, fn):

~/VirtualEnv/ENV37-TF22/lib/python3.7/site-packages/tensorflow/python/eager/wrap_function.py in wrapped(*args, **kwargs)
     90     def wrapped(*args, **kwargs):
     91       with variable_scope.variable_creator_scope(self.variable_creator_scope):
---> 92         return fn(*args, **kwargs)
     93 
     94     return wrapped

~/VirtualEnv/ENV37-TF22/lib/python3.7/site-packages/tensorflow/python/eager/wrap_function.py in _imports_graph_def()
    629 
    630   def _imports_graph_def():
--> 631     importer.import_graph_def(graph_def, name="""")
    632 
    633   wrapped_import = wrap_function(_imports_graph_def, [])

~/VirtualEnv/ENV37-TF22/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)
    505                 'in a future version' if date is None else ('after %s' % date),
    506                 instructions)
--> 507       return func(*args, **kwargs)
    508 
    509     doc = _add_deprecated_arg_notice_to_docstring(

~/VirtualEnv/ENV37-TF22/lib/python3.7/site-packages/tensorflow/python/framework/importer.py in import_graph_def(***failed resolving arguments***)
    403       return_elements=return_elements,
    404       name=name,
--> 405       producer_op_list=producer_op_list)
    406 
    407 

~/VirtualEnv/ENV37-TF22/lib/python3.7/site-packages/tensorflow/python/framework/importer.py in _import_graph_def_internal(graph_def, input_map, return_elements, validate_colocation_constraints, name, producer_op_list)
    499       except errors.InvalidArgumentError as e:
    500         # Convert to ValueError for backwards compatibility.
--> 501         raise ValueError(str(e))
    502 
    503     # Create _DefinedFunctions for any imported functions.

ValueError: Input 3 of node StatefulPartitionedCall/model/crf__layer_v2/cond was passed resource from Func/StatefulPartitionedCall/input/_18:0 incompatible with expected float.
```

**Also, please include a link to the saved model or GraphDef**


[saved model generated on v2.2.0](http://www.invencodes.com/saved_model_v2.2.tar.gz)
[saved model generated on v2.3.0-dev20200601](http://www.invencodes.com/saved_model_v2.3.tar.gz)


**Failure details**
- Conversion failed both on 2.2.0 and 2.3.0-dev20200601.
- The model includes a custom layer (crf_layer_v2) that uses tfa.text.crf_decode and tfa.text.crf_log_likelihood.


**RNN conversion support**
If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
40100,Design a generic type Python API for the hparams plugin,"**System information**
- TensorFlow version (you are using): tf2.20
- Are you willing to contribute it (Yes/No): No



**Describe the feature and the current behavior/state.**
While I follow the following tutorial to do the hyperparameter tuning. I cannot choose from list type object.
https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams

```
HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([[256, 512, 256, 128,64],[256, 512, 1024, 512, 256, 128],[256, 512, 1024, 512, 256, 128, 64, 32]]))

ValueError: Unknown dtype: <class 'list'>

```

I am playing with the canned estimator and tune the 'dnn_hidden_units' hyperparameter with 'from tensorboard.plugins.hparams import api as hp'. But it seems that I cannot tune 'dnn_hidden_units' with this library. 

```
    estimator = tf.estimator.DNNLinearCombinedClassifier(
        # wide settings
        linear_feature_columns=feature_columns,
        linear_optimizer=FtrlwithParams,
        # deep settings
        dnn_feature_columns=feature_columns,
        dnn_hidden_units=[256, 512, 256, 128, 64],
#         dnn_hidden_units=[1000, 500,100],
        dnn_optimizer=AdamWithParams,
        batch_norm=True,
        dnn_dropout=0.5,
        n_classes=NUM_LABEL,
        config=RUN_CONFIG,
        # warm-start settings
        warm_start_from=MODEL_DIR
    )
```

**Will this change the current api? How?**
No. Maybe we can add a new API or a generic API.

**Who will benefit with this feature?**
Anyone need to do hyperparameter tuning.

I expect that people build models with list-like parameter. So I think this is a common feature.

"
40099,asking for dll that don't exist..,"<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): nope, I'm working in R
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): 
- TensorFlow version (use command below): gpu 2.0.0
- Python version: 3.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0 (but also 10.1 has the same issues)
- GPU model and memory: GTX 1070

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
The follow error pops up

 # Run if keras is installed on your machine
> library(keras)

Attaching package: �keras�

The following object is masked from �package:tuneR�:

    normalize

> # Build the training set
> Y_train <- to_categorical(as.integer(Train[,1]) - 1) # One hot encoding
2020-06-02 20:44:42.684525: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
> # X as matrix
> X_train <- as.matrix(Train[,-1])
> # Build the test set
> Y_test <- to_categorical(as.integer(Test[,1]) - 1)
> Y_test <- Y_test[,-1]
> X_test <- as.matrix(Test[,-1])
> # Build the sequential model
> mod0 <- keras_model_sequential()
> mod0 %>%
+   # Input shape layer = c(samples, rows, cols, channels)
+   layer_reshape(input_shape=ncol(X_train),target_shape=c(1,1,ncol(X_train))) %>% 
+   # First conv 2d layer with 128 neurons, kernel size of 8 x 8 and stride of 1 x 1
+   layer_conv_2d(128, c(8,8), c(1,1), padding='same') %>%
+   layer_batch_normalization() %>%
+   layer_activation(""relu"") %>%
+   layer_dropout(0.2) %>%
+   # Second conv 2d layer with 256 neurons, kernel size of 5 x 5 and stride of 1 x 1
+   layer_conv_2d(256, c(5,5), c(1,1), padding='same') %>%
+   layer_batch_normalization() %>%
+   layer_activation(""relu"") %>%
+   layer_dropout(0.2) %>%
+   # Third conv 2d layer with 128 neurons, kernel size of 3 x 3 and stride of 1 x 1
+   layer_conv_2d(128, c(3,3), c(1,1), padding='same') %>%
+   layer_batch_normalization() %>%
+   layer_activation(""relu"") %>%
+   layer_dropout(0.2) %>%
+   # Average pooling layer
+   layer_global_average_pooling_2d() %>%
+   # Activation output layer with 2 classes
+   layer_dense(units = ncol(Y_train),  activation='softmax')
2020-06-02 20:45:03.955606: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-06-02 20:45:03.976379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1070 with Max-Q Design computeCapability: 6.1
coreClock: 1.379GHz coreCount: 16 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 238.66GiB/s
2020-06-02 20:45:03.976741: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-06-02 20:45:03.978237: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cublas64_10.dll'; dlerror: cublas64_10.dll not found
2020-06-02 20:45:03.979542: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cufft64_10.dll'; dlerror: cufft64_10.dll not found
2020-06-02 20:45:03.980756: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'curand64_10.dll'; dlerror: curand64_10.dll not found
2020-06-02 20:45:03.982018: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cusolver64_10.dll'; dlerror: cusolver64_10.dll not found
2020-06-02 20:45:03.983263: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cusparse64_10.dll'; dlerror: cusparse64_10.dll not found
2020-06-02 20:45:03.998222: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-06-02 20:45:03.998400: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1598] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-06-02 20:45:03.999344: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2020-06-02 20:45:04.009529: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2126e31daa0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-06-02 20:45:04.009767: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-06-02 20:45:04.010010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-06-02 20:45:04.010176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      
> # Model compile
> mod0 %>% compile(loss = 'categorical_crossentropy',
+                  optimizer = ""adam"",
+                  metrics = ""categorical_accuracy"")
> # Add a callback to reduce the learning rate when reaching the plateau
> reduce_lr <- callback_reduce_lr_on_plateau(monitor = 'loss', factor = 0.5,
+                                            patience = 50, min_lr = 0.0001)
> # Start learning
> mod0 %>% fit(X_train, Y_train, batch_size = 32, epochs = 50,
+              validation_data = list(X_test, Y_test),
+              verbose = 1, callbacks = reduce_lr)
Epoch 1/50
7/7 [==============================] - 0s 50ms/step - loss: 0.4958 - categorical_accuracy: 0.7870
Error in py_call_impl(callable, dots$args, dots$keywords) : 
  ValueError: in user code:

    C:\Users\axeld\AppData\Local\r-miniconda\envs\r-reticulate\lib\site-packages\tensorflow\python\keras\engine\training.py:941 test_function  *
        outputs = self.distribute_strategy.run(
    C:\Users\axeld\AppData\Local\r-miniconda\envs\r-reticulate\lib\site-packages\tensorflow\python\distribute\distribute_lib.py:951 run  **
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    C:\Users\axeld\AppData\Local\r-miniconda\envs\r-reticulate\lib\site-packages\tensorflow\python\distribute\distribute_lib.py:2290 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    C:\Users\axeld\AppData\Local\r-miniconda\envs\r-reticulate\lib\site-packages\tensorflow\python\distribute\distribute_lib.py:2649 _call_for_each_replica
        return fn(*args, **kwargs)
    C:\Users\axeld\AppData\Local\r-miniconda\envs\r-reticulate\lib\site-packages\tensorflow\python\keras\engine\training.py:912 test_step  **
> 

**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40098,ValueError: `handle` is not available outside the replica context or a `tf.distribute.Strategy.update()` call,"Hello,

I am not able to train on multiple gpus using ` tf.distribute.MirroredStrategy`. The code works fine without this. 

following is the code snippet of training:-
```
mirrored_strategy = tf.distribute.MirroredStrategy(devices=['/gpu:5','/gpu:6'])
with mirrored_strategy.scope():
    train_X,frames_array = get_frames()
    train_Y,heatmap = get_grids()
    train_X, X_test, heatmap, y_test = train_test_split(train_X, heatmap, test_size=0.20, random_state=42)
    opt = SGD(lr=0.0005, momentum=0.9, decay=1e-2)
    model2 = fine_model()
    model2.compile(loss= KL_loss, optimizer=opt)
    model2.fit(train_X,heatmap,batch_size=2,epochs=100,validation_data=(X_test, y_test))
````

Also, I have explicitly specified tf to use gpu 5 and 6, however it uses gpu 0 as well.

below is the error,
```
Traceback (most recent call last):
  File ""gaze_model.py"", line 260, in <module>
    model2.fit(train_X,heatmap,batch_size=2,epochs=1,validation_data=(X_test, y_test))
  File ""/home/centos/Anaconda/envs/tensorflow2/lib/python3.7/site-packages/keras/engine/training.py"", line 1213, in fit
    self._make_train_function()
  File ""/home/centos/Anaconda/envs/tensorflow2/lib/python3.7/site-packages/keras/engine/training.py"", line 316, in _make_train_function
    loss=self.total_loss)
  File ""/home/centos/Anaconda/envs/tensorflow2/lib/python3.7/site-packages/keras/legacy/interfaces.py"", line 91, in wrapper
    return func(*args, **kwargs)
  File ""/home/centos/Anaconda/envs/tensorflow2/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py"", line 75, in symbolic_fn_wrapper
    return func(*args, **kwargs)
  File ""/home/centos/Anaconda/envs/tensorflow2/lib/python3.7/site-packages/keras/optimizers.py"", line 192, in get_updates
    grads = self.get_gradients(loss, params)
  File ""/home/centos/Anaconda/envs/tensorflow2/lib/python3.7/site-packages/keras/optimizers.py"", line 91, in get_gradients
    grads = K.gradients(loss, params)
  File ""/home/centos/Anaconda/envs/tensorflow2/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py"", line 75, in symbolic_fn_wrapper
    return func(*args, **kwargs)
  File ""/home/centos/Anaconda/envs/tensorflow2/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py"", line 3025, in gradients
    return tf.gradients(loss, variables)
  File ""/home/centos/Anaconda/envs/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/ops/gradients_impl.py"", line 274, in gradients_v2
    unconnected_gradients)
  File ""/home/centos/Anaconda/envs/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/ops/gradients_util.py"", line 530, in _GradientsHelper
    for x in xs
  File ""/home/centos/Anaconda/envs/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/ops/gradients_util.py"", line 530, in <listcomp>
    for x in xs
  File ""/home/centos/Anaconda/envs/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/distribute/values.py"", line 720, in handle
    raise ValueError(""`handle` is not available outside the replica context""
ValueError: `handle` is not available outside the replica context or a `tf.distribute.Strategy.update()` call.
```


**I am using tensorflow 2.1.0 and keras 2.3.1**
 "
40097,Please add additional check in TfLiteQuantizationFree,"Hi!
Please add additional check for *quantization->params* before using it in the [function](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/c/common.c#L89).
The bug  appears when default TfLiteConverterCalculator was used ([MediaPipe](https://github.com/google/mediapipe) framework).
Please look at [theirs source](https://github.com/google/mediapipe/blob/master/mediapipe/calculators/tflite/tflite_converter_calculator.cc#L317).
As you can see *quant.params* is set to *nullptr*.
Therefore add additional check for similar situations (on other frameworks).
For example:
```C
if (q_params != NULL) {
    if (q_params->scale) {
        TfLiteFloatArrayFree(q_params->scale);
        q_params->scale = NULL;
    }
    if (q_params->zero_point) {
        TfLiteIntArrayFree(q_params->zero_point);
        q_params->zero_point = NULL;
    }
    free(q_params);
}
````
Thanks."
40096,Prediction failed: Could not import PIL.Image. The use of `load_img` requires PIL.,"While using Custom Prediction Routine, I've received the following error according to Logs Viewer in console:

`Prediction failed: Could not import PIL.Image. The use of 'load_img' requires PIL.
`
- TensorFlow version: `1.15`
- Python version: `3.7`

setup.py:

```
from setuptools import setup

install_requires=['pillow', 'opencv-python', 'matplotlib']

setup(
name='my_custom_code',
version='0.1',
scripts=['predictor.py'],
install_requires=install_requires
)
```

predictor.py imports:
```
import os
import pandas as pd
import pickle
import cv2
import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf
from tensorflow.python.lib.io import file_io
from pandas.compat import StringIO
from datetime import datetime
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Model
from PIL import Image
```

I need to use this library because of ImageDataGenerator (part of the predictor.py above):
 ```
# Create ImageDataGenerator for test set
    test_img_gen = ImageDataGenerator(preprocessing_function=self.remove_text,
                                       samplewise_std_normalization=True, samplewise_center=True)
    test_generator = test_img_gen.flow_from_dataframe(dataframe=setup_dict['TEST_SET'],
                                                      directory=setup_dict['RAW_DATA_PATH'],
                                                      x_col=""filename"", y_col='label_str',
                                                      target_size=tuple(setup_dict['IMG_DIM']), batch_size=1,
                                                      class_mode='categorical', validate_filenames=False, shuffle=False)
```

Command being used to create new versions:
`gcloud beta ai-platform versions create v1   --model MyModel   --runtime-version 1.15   --python-version 3.7   --origin gs://custom-prediction/   --package-uris gs://custom-prediction/my_custom_code-0.1.tar.gz   --prediction-class predictor.MyPredictor`

Can someone help me?"
40095,Can't set weights for exactly the same model,"Hi there, 
I'm trying to save model based on its config and weights but it seems like some properties of config are missing when you initialize using model_from_json. 

This simple core reproduce the issue, its related (I think with embedding feature columns)

```
import tensorflow as tf
from tensorflow import keras
from tensorflow import feature_column
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split


def df_to_dataset(dataframe, shuffle=True, batch_size=32):
    dataframe = dataframe.copy()
    labels = dataframe.pop('target')
    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))
    if shuffle:
        ds = ds.shuffle(buffer_size=len(dataframe))
    ds = ds.batch(batch_size)
    return ds


URL = 'https://storage.googleapis.com/applied-dl/heart.csv'
df = pd.read_csv(URL)
df.head()

countries = ['afghanistan', 'aland islands', 'albania', 'algeria', 'american samoa', 'andorra', 'angola', 'anguilla', 'antarctica', 'antigua and barbuda', 'argentina', 'armenia', 'aruba', 'australia', 'austria', 'azerbaijan', 'bahamas (the)', 'bahrain', 'bangladesh', 'barbados', 'belarus', 'belgium', 'belize', 'benin', 'bermuda']

df['country'] = pd.DataFrame(np.random.choice(list(countries), len(df)))

feature_columns = []
for f in list(df.columns):
    if f!='target':
        if df[f].dtype.name in ['int64','float64']:
            num_feat = feature_column.numeric_column(f)
            bucket_feat = feature_column.bucketized_column(num_feat, boundaries=[25,50,75,90,95,99])
            feature_columns.append(bucket_feat)
        else:
            categ_feat = feature_column.categorical_column_with_vocabulary_list(f, df[f].unique())
            categ_feat_embedding = feature_column.embedding_column(categ_feat, dimension=8)
            feature_columns.append(categ_feat_embedding)

train_df, val_df = train_test_split(df, test_size=0.2)

batch_size = 128
train_ds = df_to_dataset(train_df, batch_size=batch_size)
val_ds = df_to_dataset(val_df, shuffle=False, batch_size=batch_size)

feature_layer = keras.layers.DenseFeatures(feature_columns)
model = keras.Sequential()
model.add(feature_layer)
model.add(keras.layers.Dense(128, activation='relu'))
model.add(keras.layers.Dense(1, activation='sigmoid'))
model.compile(optimizer=keras.optimizers.Adam(lr=1e-3),
              loss=keras.losses.BinaryCrossentropy())


history = model.fit(train_ds,
                    validation_data=val_ds,
                    epochs=2,
                    verbose=1)


model2 = tf.keras.models.model_from_json(model.to_json())
model2.set_weights(model.get_weights())
```

The error is:
`ValueError: Weights for model sequential_5 have not yet been created. Weights are created when the Model is first called on inputs or `build()` is called with an `input_shape`.`

When I compare the config of model (original) against model2 (replica) the only feature that differ are embeddings one:

`
'initializer': {'class_name': 'TruncatedNormal',
        'config': {'mean': 0.0,
         'stddev': 0.35355339059327373,
         'seed': None,
         'dtype': 'float32'}},
`
Specifically the last one dtype

"
40090,run this:python freeze_graph.py \ --input_graph C:/Users/Administrator.DESKTOP-5V6G6NA/tensorflowfiles/bird\data2/slim/tmp/inception_v3_inf_graph.pb \ --input_checkpoint .tmp/train_logs/model.ckpt-721 \ --input_binary true \ --output_node_names InceptionV3/Predictions/Reshape_1 \ --output_graph .tmp/frozen_graph.pb,"WARNING:tensorflow:From freeze_graph.py:124: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
W0602 23:33:08.629297 12556 deprecation.py:323] From freeze_graph.py:124: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
Fatal Python error: Segmentation fault

Current thread 0x0000310c (most recent call first):
  File ""D:\91UserData\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\lib\io\file_io.py"", line 384 in get_matching_files_v2
  File ""D:\91UserData\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\lib\io\file_io.py"", line 363 in get_matching_files
  File ""D:\91UserData\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\training\checkpoint_management.py"", line 372 in checkpoint_exists
  File ""D:\91UserData\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\util\deprecation.py"", line 324 in new_func
  File ""freeze_graph.py"", line 124 in freeze_graph_with_def_protos
  File ""freeze_graph.py"", line 357 in freeze_graph
  File ""freeze_graph.py"", line 374 in main
  File ""freeze_graph.py"", line 482 in <lambda>
  File ""D:\91UserData\Anaconda3\envs\tensorflow\lib\site-packages\absl\app.py"", line 250 in _run_main
  File ""D:\91UserData\Anaconda3\envs\tensorflow\lib\site-packages\absl\app.py"", line 299 in run
  File ""D:\91UserData\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\platform\app.py"", line 40 in run
  File ""freeze_graph.py"", line 483 in run_main
  File ""freeze_graph.py"", line 487 in <module>


get this error;
tf=1.14.0 cpu
"
40087,micro_speech train example broken,"@tensorflow/micro

**System information**
- Windows 10
- tensorflow 1.x
- Arduino Nano 33

The training portion of the micro_speech example appears to be broken.  The only modification I have made is to train for the words ""up,down,on,off"" instead of ""yes,no"".  I ran all of the code cells except for the code cell that skips the training.  The following code cell generates an error:

with tf.Session() as sess:
  float_converter = tf.lite.TFLiteConverter.from_saved_model(SAVED_MODEL)
  float_tflite_model = float_converter.convert()
  float_tflite_model_size = open(FLOAT_MODEL_TFLITE, ""wb"").write(float_tflite_model)
  print(""Float model is %d bytes"" % float_tflite_model_size)

  converter = tf.lite.TFLiteConverter.from_saved_model(SAVED_MODEL)
  converter.optimizations = [tf.lite.Optimize.DEFAULT]
  converter.inference_input_type = tf.lite.constants.INT8
  converter.inference_output_type = tf.lite.constants.INT8
  def representative_dataset_gen():
    for i in range(100):
      data, _ = audio_processor.get_data(1, i*1, model_settings,
                                         BACKGROUND_FREQUENCY, 
                                         BACKGROUND_VOLUME_RANGE,
                                         TIME_SHIFT_MS,
                                         'testing',
                                         sess)
      flattened_data = np.array(data.flatten(), dtype=np.float32).reshape(1, 1960)
      yield [flattened_data]
  converter.representative_dataset = representative_dataset_gen
  tflite_model = converter.convert()
  tflite_model_size = open(MODEL_TFLITE, ""wb"").write(tflite_model)
  print(""Quantized model is %d bytes"" % tflite_model_size)

Error generated below:

---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py in _do_call(self, fn, *args)
   1364     try:
-> 1365       return fn(*args)
   1366     except errors.OpError as e:

11 frames
InvalidArgumentError: You must feed a value for placeholder tensor 'data/background_data' with dtype float and shape [16000,1]
	 [[{{node data/background_data}}]]

During handling of the above exception, another exception occurred:

InvalidArgumentError                      Traceback (most recent call last)
/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py in _do_call(self, fn, *args)
   1382                     '\nsession_config.graph_options.rewrite_options.'
   1383                     'disable_meta_optimizer = True')
-> 1384       raise type(e)(node_def, op, message)
   1385 
   1386   def _extend_graph(self):

InvalidArgumentError: You must feed a value for placeholder tensor 'data/background_data' with dtype float and shape [16000,1]
	 [[node data/background_data (defined at /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py:1748) ]]

"
40086,layers.set_weights() not working with tf.keras.optimizers.Ftrl,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.13.2
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): ('v2.1.0-rc2-17-ge5bf8de410', '2.1.0')
- Python version: Python 2.7.14
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**
I create a model and manually initialize its weights to W0 using layers.set_weights().
Then I fit the model with tf.keras.optimizers.Ftrl and a tiny learning rate (1e-5).
The model weights became to small values around zero. It seems that model weights have been reinitialized to zeros.

**Describe the expected behavior**
Because the learning rate is very small, the model weights are expected to remain near to W0 (the manually initialized value) after training.
I tried other optimizers (SGD, Adam) from tf.keras.optimizers, the behavior is under expectation.

**Standalone code to reproduce the issue**
```python
import numpy as np
import tensorflow as tf

vocabulary = ['word1', 'word2']
categorical_column = tf.feature_column.categorical_column_with_vocabulary_list(
    'feat1', vocabulary)
embedding_column = tf.feature_column.embedding_column(
    categorical_column,
    dimension=1,
    initializer=tf.constant_initializer(0))
feature_columns = [embedding_column]

# In this model, only embeddings are trainable variables
model = tf.keras.Sequential([
    tf.keras.layers.DenseFeatures(feature_columns),
    tf.keras.layers.Dense(
        units=1,
        use_bias=False,
        trainable=False,
        kernel_initializer=tf.constant_initializer(1))
])

instances = {'feat1': np.array(['word1', 'word1', 'word2', 'word2'])}
labels = np.array([0, 0, 0, 0])

# Call the model to make variable initilized
model(instances)
print(model.trainable_variables)   # output weight [0, 0]

# Manually initialize mdoel weights to [-9, -7]
weights = [np.array([[-9], [-7]])]
model.layers[0].set_weights(weights)
print(model.trainable_variables)   # output weight [-9, -7]

# Fit the model using Ftrl optimizer with a small learning rate
optimizer = tf.keras.optimizers.Ftrl(learning_rate=1e-5)
model.compile(
    optimizer=optimizer,
    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True))
model.fit(instances, labels, epochs=1, verbose=2)
print(model.trainable_variables)  # output weight [-8.501399e-07, -7.271125e-06]
```
**Other info / logs** 
```
[<tf.Variable 'sequential_12/dense_features_12/feat1_embedding/embedding_weights:0' shape=(2, 1) dtype=float32, numpy=
array([[0.],
       [0.]], dtype=float32)>]
[<tf.Variable 'sequential_12/dense_features_12/feat1_embedding/embedding_weights:0' shape=(2, 1) dtype=float32, numpy=
array([[-9.],
       [-7.]], dtype=float32)>]
Train on 4 samples
4/4 - 0s - loss: 5.1743e-04
[<tf.Variable 'sequential_12/dense_features_12/feat1_embedding/embedding_weights:0' shape=(2, 1) dtype=float32, numpy=
array([[-8.501399e-07],
       [-7.271125e-06]], dtype=float32)>]
```"
40085,Lambda layer does not compute masked values properly,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Windows 10
- TensorFlow installed from (source or binary):
conda binary
- TensorFlow version (use command below):
'2.1.0'
- Python version:
3.7


**Describe the current behavior**

Output of the model with lambda subtracting 0.5 from input, and input as [1, -10], with -10 being masked value
```
<tf.Tensor: shape=(1, 2, 1), dtype=float32, numpy=
array([[[ 0.5],
        [-0.5]]], dtype=float32)
```


**Describe the expected behavior**

Output
```
<tf.Tensor: shape=(1, 2, 1), dtype=float32, numpy=
array([[[ 0.5],
        [ 0. ]]], dtype=float32)
```
or
```
<tf.Tensor: shape=(1, 2, 1), dtype=float32, numpy=
array([[[ 0.5],
        [ -10. ]]], dtype=float32)
```

**Standalone code to reproduce the issue**

```
import numpy as np
from tensorflow import keras
inputs_shape = (2, 1)
inputs = keras.layers.Input(shape=inputs_shape)
masked = keras.layers.Masking(mask_value=-10., input_shape=inputs_shape)(inputs)
output = keras.layers.Lambda(lambda x: x - 0.5)(masked)
model = keras.Model(inputs=inputs, outputs=output)
data = np.array([[1, -10]], dtype=np.float32).reshape(-1, 2, 1)
model(data)
```"
40084,"tflite accuracy tool what parameter ""--model_output_labels"" is?","i have a tflite accuracy test with tflite accuracy tool in https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/accuracy/ilsvrc, but i do not konw parameter ""--model_output_labels"" is, anyone would tell me, i will appreciate."
40083,"RNN unrolled, cannot be converted using from_keras_model","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): tf-nightly
- TensorFlow version (or github SHA if from source):
-  version is 2.2.0.dev20200508, git version is v1.12.1-31489-g6047d50555

**Describe the current behavior**
Conversion fails with the following:
```
ValueError: Cannot unroll a RNN if the time dimension is undefined.
- If using a Sequential model, specify the time dimension by passing an `input_shape` or `batch_input_shape` argument to your first layer. If your first layer is an Embedding, you can also use the `input_length` argument.
- If using the functional API, specify the time dimension by passing a `shape` or `batch_shape` argument to your Input layer.
```
This seems to be due to the following addition to the from_keras_model conversion: 
```
self._keras_model.save(temp_dir, save_format=""tf"")
```

**Describe the expected behavior**
Conversion should succeed as it did before in previous versions.

**Standalone code to reproduce the issue**
```
import numpy as np
import tensorflow as tf

from tensorflow.keras.models import Model

class SimpleModel(Model):
    def __init__(self):
        super().__init__()
        self.model_name = ""mnist""
        self.train_data = None
        self.test_data = None
        self.calib_data = None
        self.num_calib = 1000
        # (data preprocessing) Normalize the input image so that
        # each pixel value is between 0 to 1.
        self.pre_process = lambda x: x / 255.0

        self._load_data()

    def _load_data(self):
        # Load MNIST dataset
        mnist = tf.keras.datasets.mnist

        # _data: (images, labels)
        self.train_data, self.test_data = mnist.load_data()
        self.calib_data = self.pre_process(
            self.train_data[0][0 : self.num_calib].astype(np.float32)
        )

    def train(self):
        cell = tf.keras.layers.GRUCell(3)

        model = tf.keras.models.Sequential([
            tf.keras.layers.Input(shape=(28, 28), name='input'),
            #tf.keras.layers.LSTM(32),
            tf.keras.layers.RNN(cell, unroll=True),
            tf.keras.layers.Flatten(),
            tf.keras.layers.Dense(10, activation=tf.nn.softmax, name='output')
        ])
        model.summary()

        train_images = self.pre_process(self.train_data[0])
        train_labels = self.train_data[1]
        test_images = self.pre_process(self.test_data[0])
        test_labels = self.test_data[1]
        # Train the digit classification model
        model.compile(
            optimizer=""adam"",
            loss=""sparse_categorical_crossentropy"",
            metrics=[""accuracy""],
        )
        model.fit(
            train_images,
            train_labels,
            epochs=1,
            validation_data=(test_images, test_labels),
        )
        # dump SavedModel - ANOTHER BUG HERE!
        #model.save(str(self.savedModel_dir))

        return model

    def eval(self, tflite_model_path: str):
        interpreter = tf.lite.Interpreter(model_path=str(tflite_model_path))
        interpreter.allocate_tensors()

        input_index = interpreter.get_input_details()[0][""index""]
        output_index = interpreter.get_output_details()[0][""index""]

        # (data preprocessing) Normalize the input image so that
        # each pixel value is between 0 to 1.
        test_images = self.pre_process(self.test_data[0])
        test_labels = self.test_data[1]
        # Run predictions on every image in the ""test"" dataset.
        prediction_digits = []
        for test_image in test_images:
            # Pre-processing: add batch dimension and convert to float32 to match with
            # the model's input data format.
            test_image = np.expand_dims(test_image, axis=0).astype(np.float32)
            interpreter.set_tensor(input_index, test_image)

            # Run inference.
            interpreter.invoke()

            # Post-processing: remove batch dimension and find the digit with highest
            # probability.
            output = interpreter.tensor(output_index)
            digit = np.argmax(output()[0])
            prediction_digits.append(digit)

        # Compare prediction results with ground truth labels to calculate accuracy.
        accurate_count = 0
        for index, _ in enumerate(prediction_digits):
            if prediction_digits[index] == test_labels[index]:
                accurate_count += 1
        accuracy = accurate_count * 1.0 / len(prediction_digits)

        return accuracy

    def _get_calib_data_func(self):
        def representative_data_gen():
            for input_value in self.calib_data:
                input_value = np.expand_dims(input_value, axis=0).astype(np.float32)
                yield [input_value]

        return representative_data_gen


if __name__ == ""__main__"":
    temp = SimpleModel()
    model = temp.train()

    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    converter.representative_dataset = temp._get_calib_data_func()

    # save INT8 tflite
    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8,
        tf.lite.OpsSet.SELECT_TF_OPS]
    converter.experimental_new_converter = True
    tflite_model_INT8 = converter.convert()
    open(""lstm_unrolled_int8.tflite"", ""wb"").write(tflite_model_INT8)

```


"
40081,Cannot save RNN-based model as a saved model format,"**System information**

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04.3 LTS
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b (GIT_VERSION), 2.2.0 (VERSION)
- Python version: 3.7.5
- CUDA/cuDNN version: 10.1
- GPU model and memory: Titan RTX, ~25GB

**Describe the current behavior**

I wrote a simple code that builds RNN using GRUCells and save with signature function.

```python
import tensorflow as tf

gru_encoder = tf.keras.layers.RNN([tf.keras.layers.GRUCell(200) for _ in range(4)], return_sequences=True)


gru_encoder(tf.keras.Input((32, 200)))


@tf.function(
    input_signature=[tf.TensorSpec(shape=[None, None, None], dtype=tf.float32)]  # batch, sequence length, hidden size
)
def _signature_fn(input_embedding):
    return gru_encoder(input_embedding)


tf.saved_model.save(gru_encoder, ""./test-model/1"", signatures=_signature_fn)
```

And the result of above script is

```sh
$ python test.py
2020-06-02 18:42:20.388075: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-06-02 18:42:20.525918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:19:00.0 name: TITAN RTX computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.65GiB deviceMemoryBandwidth: 625.94GiB/s
2020-06-02 18:42:20.527134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties: 
pciBusID: 0000:1a:00.0 name: TITAN RTX computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.65GiB deviceMemoryBandwidth: 625.94GiB/s
2020-06-02 18:42:20.528153: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 2 with properties: 
pciBusID: 0000:67:00.0 name: TITAN RTX computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.65GiB deviceMemoryBandwidth: 625.94GiB/s
2020-06-02 18:42:20.529164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 3 with properties: 
pciBusID: 0000:68:00.0 name: TITAN RTX computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.65GiB deviceMemoryBandwidth: 625.94GiB/s
2020-06-02 18:42:20.536014: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-06-02 18:42:20.537691: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-06-02 18:42:20.539509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-06-02 18:42:20.539851: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-06-02 18:42:20.541872: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-06-02 18:42:20.542990: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-06-02 18:42:20.547193: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-06-02 18:42:20.556527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1, 2, 3
2020-06-02 18:42:20.556829: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2020-06-02 18:42:20.590996: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3500000000 Hz
2020-06-02 18:42:20.593061: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f254c000b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-06-02 18:42:20.593123: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-06-02 18:42:21.337111: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f0e31589f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-06-02 18:42:21.337154: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): TITAN RTX, Compute Capability 7.5
2020-06-02 18:42:21.337163: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): TITAN RTX, Compute Capability 7.5
2020-06-02 18:42:21.337171: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): TITAN RTX, Compute Capability 7.5
2020-06-02 18:42:21.337179: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): TITAN RTX, Compute Capability 7.5
2020-06-02 18:42:21.339651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:19:00.0 name: TITAN RTX computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.65GiB deviceMemoryBandwidth: 625.94GiB/s
2020-06-02 18:42:21.341408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties: 
pciBusID: 0000:1a:00.0 name: TITAN RTX computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.65GiB deviceMemoryBandwidth: 625.94GiB/s
2020-06-02 18:42:21.343151: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 2 with properties: 
pciBusID: 0000:67:00.0 name: TITAN RTX computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.65GiB deviceMemoryBandwidth: 625.94GiB/s
2020-06-02 18:42:21.344891: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 3 with properties: 
pciBusID: 0000:68:00.0 name: TITAN RTX computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.65GiB deviceMemoryBandwidth: 625.94GiB/s
2020-06-02 18:42:21.344938: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-06-02 18:42:21.344955: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-06-02 18:42:21.344969: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-06-02 18:42:21.344984: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-06-02 18:42:21.345001: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-06-02 18:42:21.345016: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-06-02 18:42:21.345031: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-06-02 18:42:21.356549: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1, 2, 3
2020-06-02 18:42:21.356628: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-06-02 18:42:21.367494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-06-02 18:42:21.367544: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 1 2 3 
2020-06-02 18:42:21.367553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N N N N 
2020-06-02 18:42:21.367559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 1:   N N N N 
2020-06-02 18:42:21.367565: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 2:   N N N N 
2020-06-02 18:42:21.367570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 3:   N N N N 
2020-06-02 18:42:21.374361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22604 MB memory) -> physical GPU (device: 0, name: TITAN RTX, pci bus id: 0000:19:00.0, compute capability: 7.5)
2020-06-02 18:42:21.376397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 22604 MB memory) -> physical GPU (device: 1, name: TITAN RTX, pci bus id: 0000:1a:00.0, compute capability: 7.5)
2020-06-02 18:42:21.377956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 22604 MB memory) -> physical GPU (device: 2, name: TITAN RTX, pci bus id: 0000:67:00.0, compute capability: 7.5)
2020-06-02 18:42:21.379349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 22581 MB memory) -> physical GPU (device: 3, name: TITAN RTX, pci bus id: 0000:68:00.0, compute capability: 7.5)
Traceback (most recent call last):
  File ""test.py"", line 16, in <module>
    tf.saved_model.save(gru_encoder, ""./test-model/1"", signatures=_signature_fn)
  File ""{PROJECT_DIRECTORY}/env/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py"", line 951, in save
    obj, export_dir, signatures, options, meta_graph_def)
  File ""{PROJECT_DIRECTORY}/env/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py"", line 1012, in _build_meta_graph
    signature_serialization.validate_saveable_view(checkpoint_graph_view)
  File ""{PROJECT_DIRECTORY}/env/lib/python3.7/site-packages/tensorflow/python/saved_model/signature_serialization.py"", line 268, in validate_saveable_view
    saveable_view.root):
  File ""{PROJECT_DIRECTORY}/env/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py"", line 108, in list_dependencies
    extra_dependencies = self.list_extra_dependencies(obj)
  File ""{PROJECT_DIRECTORY}/env/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py"", line 137, in list_extra_dependencies
    self._serialization_cache)
  File ""{PROJECT_DIRECTORY}/env/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 2746, in _list_extra_dependencies_for_serialization
    .list_extra_dependencies_for_serialization(serialization_cache))
  File ""{PROJECT_DIRECTORY}/env/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/base_serialization.py"", line 74, in list_extra_dependencies_for_serialization
    return self.objects_to_serialize(serialization_cache)
  File ""{PROJECT_DIRECTORY}/env/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py"", line 73, in objects_to_serialize
    serialization_cache).objects_to_serialize)
  File ""{PROJECT_DIRECTORY}/env/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py"", line 94, in _get_serialized_attributes
    serialized_attr.set_and_validate_objects(object_dict)
  File ""{PROJECT_DIRECTORY}/env/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/serialized_attributes.py"", line 212, in set_and_validate_objects
    ' {})'.format(object_dict[key], key))
ValueError: Object dictionary contained a non-trackable object: (None, None, None, None) (for key states)
```

**Describe the expected behavior**

I think this script should run without any exception and actually it works fine in `tensorflow==2.1.0`.
"
40078,tensorflow.python.framework.errors_impl.InvalidArgumentError: input depth must be evenly divisible by filter depth: 544 vs 96 [Op:Conv2D],"Does anyone ever experience like this? Please give enlightenment, thank you
""tensorflow.python.framework.errors_impl.InvalidArgumentError: input depth must be evenly divisible by filter depth: 544 vs 96 [Op:Conv2D]""
![1](https://user-images.githubusercontent.com/58981061/83502393-b211c400-a4eb-11ea-8b0c-891c664ac43d.PNG)
"
40076,Concatenate ReLU and Batch Norm error,"**System information**
- Have I written custom code that uses Tensorflow's cReLU function:

```
...
x = tf.keras.layers.Conv2D(32, (3, 3), padding=""same"")(inputs)
x = tf.keras.layers.Activation(""relu"")(x)
x = tf.keras.layers.BatchNormalization(axis=chanDim)(x)
x = tf.keras.layers.Conv2D(32, (3, 3), padding=""same"")(x)
x = tf.keras.layers.Lambda(lambda t: tf.nn.crelu(x))(x)
x = tf.keras.layers.BatchNormalization(axis=chanDim)(x)
x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)
x = tf.keras.layers.Dropout(0.25)(x)
...
```
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.2.0
- Python version: 3.6.9
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: 10.1 / 7.6.5
- GPU model and memory: RTX 2070 Super (8 GB)


**Describe the current behavior**

I get the following error:

```
...
ValueError: Input 0 of layer batch_normalization_1 is incompatible with the layer: expected ndim=4, found ndim=2. Full shape received: [None, 20]
```

**Describe the expected behavior**

There was no error in Tensorflow 1.X.

**Standalone code to reproduce the issue**

`zip` containing the source code: https://www.dropbox.com/s/65q937qqqqa8x8d/keras-vs-tensorflow.zip?dl=0

**Question**

It seems there is difference in either cReLU or Batch Norm implementation in Tensorflow 2.X compared to Tensorflow 1.X. Can someone point out what the change is so I can modify my code?
"
40075,Tensorflow Lite GPU delegate using C++ thread detach on Galaxy Tab S6 is 2.5x slower than without a thread detach,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS 10.15 / Android 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Samsung Galaxy Tab S6
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.2
- Python version:
- Bazel version (if compiling from source): 2.0.0
- GCC/Compiler version (if compiling from source): Apple clang version 11.0.3 (clang-1103.0.32.59)
- CUDA/cuDNN version:
- GPU model and memory: Adreno 640 / 128GB 6GB RAM, 256GB 8GB RAM



**Describe the current behavior**
I'm running a Tensorflow Lite model with C++ in Android devices.
But when I run a model with GPU delegate with C++ std::thread(s) in Galaxy Tab S6, it becomes 
slower than without using std::thread.
It happens when just using a thread, even if it's number is just 1.
But without a thread, everything works fine.

With the very same code, no such behavior is happening in other devices, such as Galaxy Tab S5, Galaxy Fold, Oppo FindX, and other Android devices.
But only in Galaxy Tab S6, using std::thread with GPU delegate is slower than without using a thread(13ms -> 30ms).
Creating a model and running a model is called from the same thread.
Tensorflow Lite libraries, C++ native codes, Java code is same in all devices.

**Describe the expected behavior**
Same inference time when with or without thread(s).

**Standalone code to reproduce the issue**
Since the model I'm using is the company's model, I can't provide the model's data. 
So I created a simple test app repository at here(it's not working since the model is absent): https://github.com/lackhole/hellovmex

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.


### C/C++ Function call profiling
![No thread](https://user-images.githubusercontent.com/35574936/83500301-8a295d00-a4f9-11ea-83ee-3206b0ab7885.png)
 * Without using std::thread and run on main thread.


![Thread](https://user-images.githubusercontent.com/35574936/83500318-8f86a780-a4f9-11ea-83bd-498e92a200fd.png)
 * With using 2 detached std::thread


If any additional information is needed, please let me know."
40074,[Feature Request] Multiple primals and tangents for tf.autodiff.ForwardAccumulator,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.2
- Are you willing to contribute it (Yes/No): Not Sure



**Describe the feature and the current behavior/state.**
`tf.autodiiff.ForwardAccumulator` only supports Tensors or Variables as primals and tangents. To take JVP of a Neural Network in forward mode, each and every variable is needed to be treated seperately. So, that would mean, number of of iterations needed for the JVP would be equal to the total number of variables. That's completely infeasible.

**Will this change the current api? How?**
Yes, instead of one primal and one tangent in `tf.autodiff.ForwardAccumulator` it would have the capability to take multiple primals and tangents and when .jvp() is called it should return a list of all the JVPs.
**Who will benefit with this feature?**

Anyone who is need forward mode JVPs / HVPs of multiple variables in their code.

**Any Other info.**
Here's a sample of how that should work:
```python3
x = tf.eye(2)
layer = tf.keras.layers.Dense(1)
layer.build([None, 2])
tangents = [tf.eye(*variable.shape) for variable in layer.trainable_variables]
with tf.autodiff.ForwardAccumulator(layer.trainable_variables, tangents) as acc:
  output = layer(x)
  jvps = acc.jvp(output)
```
where `jvps` should be a list of the jvp of the variables and tangents.

CC: @allenlavoie"
40072,tf.nn.relu on nan inputs returns zeros on GPU,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, see below.
- OS Platform and Distribution: Ubuntu 16.04, Google Colab
- TensorFlow installed from: binary
- TensorFlow version: 2.2
- Python version: 3.6.9
- CUDA/cuDNN version: 10.1, 7.6.5
- GPU model and memory: GeForce GTX 1080 (8GB) (and Google Colab)

**Describe the current behavior**

The behavior of `tf.nn.relu` when fed with `nan`-valued inputs is inconsistent between GPU and CPU:

- The CPU returns `nan` (as expected).
- The GPU returns `0`, obfuscating `nan` in the computation.

Similar (but not quite identical) behavior has been described for `TF1.14` in #32730 and subsequently fixed in `TF1.15.3`, but remains in `TF2.2`

**Describe the expected behavior**

All devices should show consistent behavior like the CPU, returning `nan`.

**Standalone code to reproduce the issue**
The following snippet can also be found in [this Colab notebook](https://colab.research.google.com/drive/1LtUP4TySBPd7Ng80qdQtB2UIl3mtF3cX?usp=sharing).

The first three assertions do not fail. The last three assertions all fail. This is a bit different from #32730, where the `x1` assertion worked.
```python
x1 = tf.nn.relu(np.nan)
x2 = tf.nn.relu(np.nan * tf.random.normal(shape=[]))
x3 = tf.nn.relu(tf.Variable(np.nan))
with tf.device(""/cpu:0""):
    x1_cpu = tf.nn.relu(np.nan)
    x2_cpu = tf.nn.relu(np.nan * tf.random.normal(shape=[]))
    x3_cpu = tf.nn.relu(tf.Variable(np.nan))

assert np.all(np.isnan(x1_cpu.numpy()))
assert np.all(np.isnan(x2_cpu.numpy()))
assert np.all(np.isnan(x3_cpu.numpy()))

assert np.all(np.isnan(x1.numpy()))
assert np.all(np.isnan(x2.numpy()))
assert np.all(np.isnan(x3.numpy()))
```"
40070,Class Weights InvalidArgumentError,"Hi, I am using class weights for my unbalanced dataset, and i am getting this error 

```
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-38-797b60fa6b57> in <module>
      6     steps_per_epoch=STEPS_PER_EPOCH,
      7     validation_data=get_validation_dataset(),
----> 8     class_weight=class_weigths
      9 )

/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    817         max_queue_size=max_queue_size,
    818         workers=workers,
--> 819         use_multiprocessing=use_multiprocessing)
    820 
    821   def evaluate(self,

/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    340                 mode=ModeKeys.TRAIN,
    341                 training_context=training_context,
--> 342                 total_epochs=epochs)
    343             cbks.make_logs(model, epoch_logs, training_result, ModeKeys.TRAIN)
    344 

/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)
    126         step=step, mode=mode, size=current_batch_size) as batch_logs:
    127       try:
--> 128         batch_outs = execution_function(iterator)
    129       except (StopIteration, errors.OutOfRangeError):
    130         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?

/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in execution_function(input_fn)
     96     # `numpy` translates Tensors to values in Eager mode.
     97     return nest.map_structure(_non_none_constant_value,
---> 98                               distributed_function(input_fn))
     99 
    100   return execution_function

/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py in map_structure(func, *structure, **kwargs)
    566 
    567   return pack_sequence_as(
--> 568       structure[0], [func(*x) for x in entries],
    569       expand_composites=expand_composites)
    570 

/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py in <listcomp>(.0)
    566 
    567   return pack_sequence_as(
--> 568       structure[0], [func(*x) for x in entries],
    569       expand_composites=expand_composites)
    570 

/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in _non_none_constant_value(v)
    128 
    129 def _non_none_constant_value(v):
--> 130   constant_value = tensor_util.constant_value(v)
    131   return constant_value if constant_value is not None else v
    132 

/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_util.py in constant_value(tensor, partial)
    820   """"""
    821   if isinstance(tensor, ops.EagerTensor):
--> 822     return tensor.numpy()
    823   if not is_tensor(tensor):
    824     return tensor

/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py in numpy(self)
    940     """"""
    941     # TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.
--> 942     maybe_arr = self._numpy()  # pylint: disable=protected-access
    943     return maybe_arr.copy() if isinstance(maybe_arr, np.ndarray) else maybe_arr
    944 

/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py in _numpy(self)
    908       return self._numpy_internal()
    909     except core._NotOkStatusException as e:
--> 910       six.raise_from(core._status_to_exception(e.code, e.message), None)
    911 
    912   @property

/opt/conda/lib/python3.7/site-packages/six.py in raise_from(value, from_value)

InvalidArgumentError: {{function_node __inference_distributed_function_431665}} Compilation failure: Detected unsupported operations when trying to compile graph has_valid_nonscalar_shape_true_402714_const_0[] on XLA_TPU_JIT: DenseToDenseSetOperation (No registered 'DenseToDenseSetOperation' OpKernel for XLA_TPU_JIT devices compatible with node {{node has_invalid_dims/DenseToDenseSetOperation}}
	.  Registered:  device='CPU'; T in [DT_INT8]
  device='CPU'; T in [DT_INT16]
  device='CPU'; T in [DT_INT32]
  device='CPU'; T in [DT_INT64]
  device='CPU'; T in [DT_UINT8]
  device='CPU'; T in [DT_UINT16]
  device='CPU'; T in [DT_STRING]
){{node has_invalid_dims/DenseToDenseSetOperation}}
	 [[has_valid_nonscalar_shape]]
	 [[loss/dense_4_loss/weighted_loss/broadcast_weights/assert_broadcastable/is_valid_shape]]
	TPU compilation failed
	 [[tpu_compile_succeeded_assert/_2606253191027783421/_10]]
```

I am using Kaggle Notebook with TPU. And Tensorflow version is `2.1.0` and Keras version is `2.2.4-tf`. Here's the [kaggle notebook](https://www.kaggle.com/shubhamai/melanoma-classification?scriptVersionId=35284218) to reproduce the error. Thanks."
40068,Model fit incredibly slow ,"Hi, I've been trying to fit the following model for the last 3 hours and the the only output displayed by the model is 'Epoch 1/5'. I noticed when others fitted their models, the output would also display 'Train on X samples, Validate on X samples' and thought maybe the lack of seeing that display and the model hanging are related 
```
#Creating the first layer 
model = Sequential()
model.add(Conv1D(2,0, activation = 'relu', input_shape = X_train[0].shape  ))
model.add(BatchNormalization())
model.add(MaxPool1D())
model.add(Dropout(0.4))

#Adding second layer
model.add(Conv1D(4, 0, activation = 'relu'))
model.add(BatchNormalization())
model.add(MaxPool1D())
model.add(Dropout(0.4))

#Adding third layer
model.add(Conv1D(8, 0, activation = 'relu'))
model.add(BatchNormalization())
model.add(MaxPool1D())
model.add(Dropout(0.4))

#Adding fourth layer
model.add(Conv1D(16, 0, activation = 'relu'))
model.add(BatchNormalization())
model.add(MaxPool1D())
model.add(Dropout(0.5))

model.add(Flatten())

model.add(Dense(16, activation = 'relu'))
model.add(BatchNormalization())
model.add(Dropout(0.5)) 
model.add(Dense(16, activation = 'relu'))
model.add(BatchNormalization())
model.add(Dropout(0.5))

model.add(Dense(4, activation = 'softmax'))

model.summary() 

model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])
history = model.fit(X_train, y_train, epochs = 5, batch_size = 5, validation_data = (X_test, y_test), verbose = 1)
```

Below is the result of model.summary():
```
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d (Conv1D)              (None, 2, 2)              2         
_________________________________________________________________
batch_normalization (BatchNo (None, 2, 2)              8         
_________________________________________________________________
max_pooling1d (MaxPooling1D) (None, 1, 2)              0         
_________________________________________________________________
dropout (Dropout)            (None, 1, 2)              0         
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 2, 4)              4         
_________________________________________________________________
batch_normalization_1 (Batch (None, 2, 4)              16        
_________________________________________________________________
max_pooling1d_1 (MaxPooling1 (None, 1, 4)              0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 1, 4)              0         
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 2, 8)              8         
_________________________________________________________________
batch_normalization_2 (Batch (None, 2, 8)              32        
_________________________________________________________________
max_pooling1d_2 (MaxPooling1 (None, 1, 8)              0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 1, 8)              0         
_________________________________________________________________
conv1d_3 (Conv1D)            (None, 2, 16)             16        
_________________________________________________________________
batch_normalization_3 (Batch (None, 2, 16)             64        
_________________________________________________________________
max_pooling1d_3 (MaxPooling1 (None, 1, 16)             0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 1, 16)             0         
_________________________________________________________________
flatten (Flatten)            (None, 16)                0         
_________________________________________________________________
dense (Dense)                (None, 16)                272       
_________________________________________________________________
batch_normalization_4 (Batch (None, 16)                64        
_________________________________________________________________
dropout_4 (Dropout)          (None, 16)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 16)                272       
_________________________________________________________________
batch_normalization_5 (Batch (None, 16)                64        
_________________________________________________________________
dropout_5 (Dropout)          (None, 16)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 4)                 68        
=================================================================
Total params: 890
Trainable params: 766
Non-trainable params: 124
_________________________________________________________________
```

Given the size of the model, I find it hard to believe that it would take over 3 hours for anything to happen. Any insight is appreciated and happy to provide any additional information. "
42804,bn - Add support for Bengali Language,"Requesting a new feature. Bengali language translation.
I am willing to contribute."
40067,Doc recommends stateful training but the batches are shuffled?,"I'm reading this tutorial page from the documentation: https://www.tensorflow.org/tutorials/text/text_generation

The GRU layer is stateful so it remembers its state between batches. But the batches are shuffled. Therefore I think the stateful parameter should be `False`. "
40066,Tensorflow S3 read performance improvement,"Hello TF community,

I have a well-tuned input pipeline build using tf.data API. The data is loaded from S3 in TFRecord format. Running one pipeline gives me 7GB/min IO throughput on a p2.8xlarge EC2 instance. If I created two input pipeline instances in two separate processes, the IO throughput is almost doubled. I am thinking if it is possible to create two input pipelines in two processes and feed into one model training process. This will increase the IO throughput significantly.

Is it possible to share TF dataset between processes?

Thanks, Weiqi"
40065,tf.io.gfile / GCS fails to work on OpenSUSE,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux OpenSUSE Tumbleweed
- TensorFlow installed from (source or binary): Binary (conda)
- TensorFlow version (use command below): unknown 2.1.0
- Python version: 3.7.5
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
```python
import tensorflow as tf
tf.io.gfile.listdir(""gs://some-bucket"") # replace w/ bucket of your choice
```

This code gives an error:
```
2020-06-01 15:43:56.684531: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Unavailable: Error executing an HTTP request: libcurl code 77 meaning 'Problem with the SSL CA cert (path? access rights?)', error details: error setting certificate verify locations:
  CAfile: /etc/ssl/certs/ca-certificates.crt
  CApath: none"". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"".
```

After that it hangs for a while, and then raises a `NotFoundError`.

I believe this is because the libcurl packaged with tensorflow doesn't know where to find the ca-certificates bundle file on OpenSUSE, which is at `/etc/ssl/ca-bundle.pem` rather than `/etc/ssl/certs/ca-certificates.crt`. Also, I installed through miniconda so there's another equivalent file at `$CONDA_PREFIX/ssl/cacert.pem`. Neither of these seems to be found by tensorflow.

[This code](https://github.com/tensorflow/tensorflow/blob/5597c17b6a677be5264ebda7cc31404f0ae8a434/tensorflow/core/platform/cloud/curl_http_request.cc#L129-L132) suggests that the bundle file's location can be customized with the `CURL_CA_BUNDLE` env variable. However, this doesn't change the behavior as far as i can tell; the error is still raised.

**Describe the expected behavior**
It should list the contents of the bucket."
40063,tf.estimator.BoostedTreesClassifier does support multi-classes: AttributeError: 'NoneType' object has no attribute 'is_compatible_with',"System information
I am using colab to reproduce the issue and the ipynb is attached below.

You can collect some of this information using our environment capture
tf.version.GIT_VERSION: v2.2.0-0-g2b96f3662b 
tf.version.VERSION:  2.2.0

Describe the current behavior
cannot train tf.estimator.BoostedTreesClassifier on multi-classes data

Describe the expected behavior
Change the last 100 samples' label to a third class in following tutorial:
https://www.tensorflow.org/tutorials/estimator/boosted_trees#train_and_evaluate_the_model

Standalone code to reproduce the issue
https://colab.research.google.com/drive/13vl2mV7C_62HxKCw7-uuMp5WMm_OxYGL?usp=sharing

Other info / logs Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

error is show in the last cell of the colab notebook.

```
INFO:tensorflow:Using default config.
WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpf3g1hc6c
INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpf3g1hc6c', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/canned/boosted_trees.py:398: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
INFO:tensorflow:Calling model_fn.
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-35-828fa5064808> in <module>()
      8 # The model will stop training once the specified number of trees is built, not
      9 # based on the number of steps.
---> 10 est.train(train_input_fn, max_steps=100)
     11 
     12 # Eval.

13 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/parallel_for/gradients.py in batch_jacobian(output, inp, use_pfor, parallel_iterations)
    111   """"""
    112   output_shape = output.shape
--> 113   if not output_shape[0].is_compatible_with(inp.shape[0]):
    114     raise ValueError(""Need first dimension of output shape (%s) and inp shape ""
    115                      ""(%s) to match."" % (output.shape, inp.shape))

AttributeError: 'NoneType' object has no attribute 'is_compatible_with'
```"
40061,from_dlpack leaking memory,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux Ubuntu 18.04
- TensorFlow installed from (source or binary):
binary
- TensorFlow version (use command below):
2.2.0
- Python version:
3.6
- CUDA/cuDNN version:
10.1
- GPU model and memory:
V100 32GB

TensorFlow `from_dlpack` causes permanent decreases in available GPU memory, leading to OOM issues when called iteratively (e.g. for feeding Keras models, see [this example](https://github.com/NVIDIA/NVTabular/blob/master/nvtabular/tf_dataloader.py)). Since the tensor returned by `from_dlpack` points to the original capsule, I would expect the memory to be freed as soon as the capsule (and any of its pointers) are destroyed.

I've reproduced the issue, as well as provided comparisons with PyTorch behavior, in [this repo](https://github.com/alecgunny/tf-dlpack-repro). A basic example, run in the environment defined by the Dockerfile in the linked repo, would be
```
import tensorflow as tf
tf.config.set_logical_device_configuration(
  tf.config.list_physical_devices('GPU')[0],
  [tf.config.LogicalDeviceConfiguration(memory_limit=8192)]
)
from tensorflow.experimental.dlpack import from_dlpack

import numpy as np
import numba
import cudf


def get_free_mem():
  return numba.cuda.current_context().get_memory_info().free


def make_data(to_tf=False):
  df = cudf.DataFrame({'a': np.random.randn(1000000), 'b': np.random.randn(1000000)})
  if to_tf:
    x = {col: from_dlpack(df[col].to_dlpack()) for col in df.columns}

# initialize tf gpu
x = tf.random.normal((1,))

mem_before = get_free_mem()
make_data()
print('CuDF memory delta: {} B'.format(mem_before - get_free_mem()))

mem_before = get_free_mem()
make_data(to_tf=True)
print('CuDF to TensorFlow memory delta: {} B'.format(mem_before - get_free_mem()))
```
The output of which will look something like
```
CuDF memory delta: 0 B
CuDF to TensorFlow memory delta: 16777216 B
```"
40059,TFLiteConverter: Exception: Merge of two inputs that differ on more than one predicate,"**System information**
Mac OSX
TF 2.1.0rc1

**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
    model = tf.saved_model.load(curr_dir + ""saved_model"")
    concrete_func = model.signatures[
    tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]
    concrete_func.inputs[0].set_shape([1, 256, 256, 3])

    converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])
    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]

    tflite_model = converter.convert()

```

**The output from the converter invocation**

```
2020-06-01 14:47:13.833020: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-06-01 14:47:13.844343: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9c3ef017f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-06-01 14:47:13.844362: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-06-01 14:47:17.869419: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)
2020-06-01 14:47:17.869495: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-06-01 14:47:18.085471: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize
2020-06-01 14:47:18.085496: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-06-01 14:47:18.085502: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-06-01 14:47:24.250143: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)
2020-06-01 14:47:24.250232: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-06-01 14:47:25.306823: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize
2020-06-01 14:47:25.306844: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 6392 nodes (-2001), 10177 edges (-2235), time = 673.165ms.
2020-06-01 14:47:25.306853: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 6392 nodes (0), 10177 edges (0), time = 172.856ms.
Traceback (most recent call last):
  File ""/Users/me/object_detection/ssdlite_mobilenetv2/ssdlite_mobilenet_v2_coco_2018_05_09/convert.py"", line 33, in <module>
    main()
  File ""/Users/me/object_detection/ssdlite_mobilenetv2/ssdlite_mobilenet_v2_coco_2018_05_09/convert.py"", line 26, in main
    tflite_model = converter.convert()
  File ""/Users/me/miniconda3/envs/tf_lite/lib/python3.7/site-packages/tensorflow/lite/python/lite.py"", line 518, in convert
    **converter_kwargs)
  File ""/Users/me/miniconda3/envs/tf_lite/lib/python3.7/site-packages/tensorflow/lite/python/convert.py"", line 496, in toco_convert_impl
    enable_mlir_converter=enable_mlir_converter)
  File ""/Users/me/miniconda3/envs/tf_lite/lib/python3.7/site-packages/tensorflow/lite/python/convert.py"", line 227, in toco_convert_protos
    raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: See console for info.
2020-06-01 14:47:29.716790: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:144] Ignored output_format.
2020-06-01 14:47:29.716811: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:147] Ignored drop_control_dependency.
Traceback (most recent call last):
  File ""/Users/me/miniconda3/envs/tf_lite/bin/toco_from_protos"", line 8, in <module>
    sys.exit(main())
  File ""/Users/me/miniconda3/envs/tf_lite/lib/python3.7/site-packages/tensorflow/lite/toco/python/toco_from_protos.py"", line 93, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""/Users/me/miniconda3/envs/tf_lite/lib/python3.7/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/Users/me/miniconda3/envs/tf_lite/lib/python3.7/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/Users/me/miniconda3/envs/tf_lite/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/Users/me/miniconda3/envs/tf_lite/lib/python3.7/site-packages/tensorflow/lite/toco/python/toco_from_protos.py"", line 56, in execute
    enable_mlir_converter)
**Exception: Merge of two inputs that differ on more than one predicate** {s(Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater:0,else), s(Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/cond/cond/pred_id:0,then)} and {s(Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater:0,else), s(Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/cond/cond/pred_id:0,else), s(Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/cond/Greater:0,else)}
        for node {{node Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/cond/cond/Merge}}

```

Model obtained from Model Zoo
http://download.tensorflow.org/models/object_detection/ssdlite_mobilenet_v2_coco_2018_05_09.tar.gz


**Any other info / logs**

I'm trying to convert the `ssdlite_mobilenet_v2_coco` pre-trained model from the TF Model Zoo to TFLite. I understand that those models were made on TF1.2, so I was using the saved_model to generate a concrete function (because TFLite doesn't like dynamic input shapes), and from there convert to TFLite. 

Running into conversion errors on a Merge (please see output log above)

I came across this page https://www.tensorflow.org/lite/guide/ops_select outlining that control ops (such as merge) are unsupported, to specify to use TF ops whenever required. But still no luck.

Is there anything strikingly wrong with my process?"
40058,TF can't access GPU,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 10
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.1.0
- Python version: 3.6
- CUDA/cuDNN version: 10
- GPU model and memory: RTX 2060

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
![image](https://user-images.githubusercontent.com/31595943/83438657-69acc480-a45f-11ea-80a1-5cb3efb584d3.png)

**Describe the expected behavior**
Tensorflow should be able to use GPU, but in the current case it is not able to while pytorch is able in the same scenario 



"
40056,org.tensorflow:tensorflow-lite-gpu nightly build error vs 2.2.0,"Im not even sure how reportable this bug is, since it is occurring on a nightly build (6/1/2020), Code was working on friday. 


However when I change from nightly build to 2.2.0, works just fine:
`fliteOptions.addDelegate(GpuDelegate()) 
`
but on nightly:
E/TestRunner: java.lang.UnsatisfiedLinkError: dlopen failed: cannot locate symbol ""_ZN6tflite3gpu2cl9Arguments11kArgsPrefixE"" referenced by ""/data/app/~~KImLgowMRYSuuZbqgdRMgw==/com.qualcomm.style-LOBlofHPnlpjAMuiEJPKFQ==/lib/arm64/libtensorflowlite_gpu_jni.so""...
        at java.lang.Runtime.loadLibrary0(Runtime.java:1087)

trips it when it is loading the library 

The models used are the same models found in the style transfer android sample project, and I will link them in this post. 

Also, if there is a special procedure or contact for nightly build bugs, let me know. 

The models are quantized, which means it should fallback to the cpu, I think this is just a general linking build issue, rather than a gpu delegate problem. I will include the models for reproduce ability 

models:
[quantized_models.zip](https://github.com/tensorflow/tensorflow/files/4712477/quantized_models.zip)


"
40055,DefaultQuantParamsPass doesn't work correctly if bias constant has multiple users,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.3.0.dev20200601 
- Python version: 3.7.7
- Bazel version (if compiling from source): 3.0.0

**Describe the current behavior**

[`DefaultQuantParamsPass`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/mlir/lite/transforms/default_quant_params.cc) doesn't correctly handle quantization if a  `bias` constant has multiple users. This issue can be seen in the following toy model:
```python
img = tf.keras.layers.Input((32, 32, 3))
x = tf.keras.layers.Conv2D(64, 3, activation=""relu"", use_bias=True)(img)
x = tf.keras.layers.BatchNormalization()(x)
model = tf.keras.models.Model(img, x)
```
Since the `bias` of the `Conv2D` and `beta` from the `BatchNormalization` are both zero at initialization and have the same shape these tensors are shared by MLIR and don't convert correctly since `DefaultQuantParamsPass` doesn't duplicate the tensor to satisfy the differet quantization constraints by `tfl.conv_2d` and `tfl.mul`.

**Describe the expected behavior**
The `bias` of the `Conv2D` layer should be quantized to `int32` as required by `tfl.conv_2d`  and `beta` used by `tfl.mul` from the `BatchNormalization` layer should be quantized to `int8` as required my `tfl.mul`.

**Standalone code to reproduce the issue**
The issue can be reproduced by the following MLIR test:
```mlir
// RUN: tf-opt %s --tfl-default-quant --tfl-quantize --tfl-post-quantize | FileCheck %s  --dump-input-on-failure

// CHECK-LABEL: test_quantize_shared_bias
func @test_quantize_shared_bias(%arg0: tensor<1x112x112x32xf32>, %arg1: tensor<32x3x3x3xf32>) -> tensor<1x56x56x32xf32> {
  %cst = constant dense<0.0> : tensor<32xf32>
  %conv = ""tfl.conv_2d""(%arg0, %arg1, %cst) {dilation_h_factor = 2 : i32, dilation_w_factor = 3 : i32, fused_activation_function = ""RELU"", padding = ""SAME"", stride_h = 4 : i32, stride_w = 5 : i32} : (tensor<1x112x112x32xf32>, tensor<32x3x3x3xf32>, tensor<32xf32>) -> tensor<1x56x56x32xf32>
  %add = ""tfl.add""(%conv, %cst) {fused_activation_function = ""NONE""} : (tensor<1x56x56x32xf32>, tensor<32xf32>) -> tensor<1x56x56x32xf32>
  return %add : tensor<1x56x56x32xf32>

  // CHECK: %0 = ""tfl.pseudo_qconst""() {qtype = tensor<32x!quant.uniform<i32:f32, 6.1514801999231058E-5>>, value = dense<0> : tensor<32xi32>} : () -> tensor<32x!quant.uniform<i32:f32, 6.1514801999231058E-5>>
  // CHECK: %1 = ""tfl.pseudo_qconst""() {qtype = tensor<32x!quant.uniform<u8:f32, 0.0078431372549019607:128>>, value = dense<-128> : tensor<32xi8>} : () -> tensor<32x!quant.uniform<u8:f32, 0.0078431372549019607:128>>
  // CHECK: %2 = ""tfl.conv_2d""(%arg0, %arg1, %0) {dilation_h_factor = 2 : i32, dilation_w_factor = 3 : i32, fused_activation_function = ""RELU"", padding = ""SAME"", stride_h = 4 : i32, stride_w = 5 : i32} : (tensor<1x112x112x32x!quant.uniform<u8:f32, 0.0078431372549019607:128>>, tensor<32x3x3x3x!quant.uniform<u8:f32, 0.0078431372549019607:128>>, tensor<32x!quant.uniform<i32:f32, 6.1514801999231058E-5>>) -> tensor<1x56x56x32x!quant.uniform<u8:f32, 0.0078431372549019607:128>>
  // CHECK: %3 = ""tfl.add""(%2, %1) {fused_activation_function = ""NONE""} : (tensor<1x56x56x32x!quant.uniform<u8:f32, 0.0078431372549019607:128>>, tensor<32x!quant.uniform<u8:f32, 0.0078431372549019607:128>>) -> tensor<1x56x56x32x!quant.uniform<u8:f32, 0.0078431372549019607:128>>
  // CHECK: return %3 : tensor<1x56x56x32x!quant.uniform<u8:f32, 0.0078431372549019607:128>>
}
```

The current implementation outputs the following graph which fails to quantize the convolution:
```mlir
func @test_quantize_shared_bias(%arg0: tensor<1x112x112x32x!quant.uniform<u8:f32, 0.0078431372549019607:128>>, %arg1: tensor<32x3x3x3x!quant.uniform<u8:f32, 0.0078431372549019607:128>>) -> tensor<1x56x56x32x!quant.uniform<u8:f32, 0.0078431372549019607:128>> {
  %cst = constant dense<0.000000e+00> : tensor<32xf32>
  %0 = ""tfl.dequantize""(%arg1) : (tensor<32x3x3x3x!quant.uniform<u8:f32, 0.0078431372549019607:128>>) -> tensor<32x3x3x3xf32>
  %1 = ""tfl.dequantize""(%arg0) : (tensor<1x112x112x32x!quant.uniform<u8:f32, 0.0078431372549019607:128>>) -> tensor<1x112x112x32xf32>
  %2 = ""tfl.conv_2d""(%1, %0, %cst) {dilation_h_factor = 2 : i32, dilation_w_factor = 3 : i32, fused_activation_function = ""RELU"", padding = ""SAME"", stride_h = 4 : i32, stride_w = 5 : i32} : (tensor<1x112x112x32xf32>, tensor<32x3x3x3xf32>, tensor<32xf32>) -> tensor<1x56x56x32xf32>
  %3 = ""tfl.quantize""(%2) {qtype = tensor<1x56x56x32x!quant.uniform<u8:f32, 0.0078431372549019607:128>>} : (tensor<1x56x56x32xf32>) -> tensor<1x56x56x32x!quant.uniform<u8:f32, 0.0078431372549019607:128>>
  %4 = ""tfl.dequantize""(%3) : (tensor<1x56x56x32x!quant.uniform<u8:f32, 0.0078431372549019607:128>>) -> tensor<1x56x56x32xf32>
  %5 = ""tfl.add""(%4, %cst) {fused_activation_function = ""NONE""} : (tensor<1x56x56x32xf32>, tensor<32xf32>) -> tensor<1x56x56x32xf32>
  %6 = ""tfl.quantize""(%5) {qtype = tensor<1x56x56x32x!quant.uniform<u8:f32, 0.0078431372549019607:128>>} : (tensor<1x56x56x32xf32>) -> tensor<1x56x56x32x!quant.uniform<u8:f32, 0.0078431372549019607:128>>
  return %6 : tensor<1x56x56x32x!quant.uniform<u8:f32, 0.0078431372549019607:128>>
}
```

When allowing hybrid operands the issue becomes clearer and it generates a graph that will fail to execute in TFLite due to a floating point bias being used in the quantized convolution:
https://github.com/tensorflow/tensorflow/blob/de32c75f2f0b9c298d858180fc19fa8881bfab41/tensorflow/compiler/mlir/lite/transforms/quantize.cc#L72
```mlir
func @test_quantize_shared_bias(%arg0: tensor<1x112x112x32x!quant.uniform<u8:f32, 0.0078431372549019607:128>>, %arg1: tensor<32x3x3x3x!quant.uniform<u8:f32, 0.0078431372549019607:128>>) -> tensor<1x56x56x32x!quant.uniform<u8:f32, 0.0078431372549019607:128>> {
  %cst = constant dense<0.000000e+00> : tensor<32xf32>
  %0 = ""tfl.conv_2d""(%arg0, %arg1, %cst) {dilation_h_factor = 2 : i32, dilation_w_factor = 3 : i32, fused_activation_function = ""RELU"", padding = ""SAME"", stride_h = 4 : i32, stride_w = 5 : i32} : (tensor<1x112x112x32x!quant.uniform<u8:f32, 0.0078431372549019607:128>>, tensor<32x3x3x3x!quant.uniform<u8:f32, 0.0078431372549019607:128>>, tensor<32xf32>) -> tensor<1x56x56x32x!quant.uniform<u8:f32, 0.0078431372549019607:128>>
  %1 = ""tfl.add""(%0, %cst) {fused_activation_function = ""NONE""} : (tensor<1x56x56x32x!quant.uniform<u8:f32, 0.0078431372549019607:128>>, tensor<32xf32>) -> tensor<1x56x56x32x!quant.uniform<u8:f32, 0.0078431372549019607:128>>
  return %1 : tensor<1x56x56x32x!quant.uniform<u8:f32, 0.0078431372549019607:128>>
}
```

**Other info / logs**

@liufengdb fixed a very similar issue in the quantization driver with https://github.com/tensorflow/tensorflow/commit/4a17afaf6e5d891a3e21561fa20ca093fe09b4e2 and https://github.com/tensorflow/tensorflow/commit/2f01bf6606ee6f10c7e57b98d16a3926d2087fd5 so it would be great to integrate the fixes in the `DefaultQuantParamsPass` as well. This pass is very useful for benchmarking quantized models without the need to correctly include fake quant ops in the graph. I tried using the post-training quantization workflow, but in my testing it failed when used together with custom ops."
40053,AttributeError: module 'tensorflow.python.framework.ops' has no attribute '_set_call_cpp_shape_fn',"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Installed using anaconda and though conda install -c anaconda keras
- TensorFlow version: 1.14.0
- Python version:
- Installed using virtualenv? pip? conda?: condo AND tried using pip with a fresh install
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source): Not sure
- CUDA/cuDNN version: Not using gpu
- GPU model and memory:



**Describe the problem**
I am trying to run a .py program from the anaconda prompt. The program is using tensorflow and keras. I have set up a new condo environment and tried to install tensorflow and keras using both pip and conda. Once in this environment I try to run the code and it produces the error message:
AttributeError: module 'tensorflow.python.framework.ops' has no attribute '_set_call_cpp_shape_fn'

**Provide the exact sequence of commands / steps that you executed before running into the problem**
I activate my new environment, change to the directory of my code, the call python vad.py.

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
(PythonCPU) C:\Users\User\Documents\SpeechRecognition\task4>python vad.py
C:\Users\User\anaconda3\envs\PythonCPU\lib\site-packages\tensorflow\python\framework\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([(""qint8"", np.int8, 1)])
C:\Users\User\anaconda3\envs\PythonCPU\lib\site-packages\tensorflow\python\framework\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([(""quint8"", np.uint8, 1)])
C:\Users\User\anaconda3\envs\PythonCPU\lib\site-packages\tensorflow\python\framework\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([(""qint16"", np.int16, 1)])
C:\Users\User\anaconda3\envs\PythonCPU\lib\site-packages\tensorflow\python\framework\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([(""quint16"", np.uint16, 1)])
C:\Users\User\anaconda3\envs\PythonCPU\lib\site-packages\tensorflow\python\framework\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([(""qint32"", np.int32, 1)])
C:\Users\User\anaconda3\envs\PythonCPU\lib\site-packages\tensorflow\python\framework\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([(""resource"", np.ubyte, 1)])
Using TensorFlow backend.
Traceback (most recent call last):
  File ""vad.py"", line 3, in <module>
    import tensorflow as tf
  File ""C:\Users\User\anaconda3\envs\PythonCPU\lib\site-packages\tensorflow\__init__.py"", line 28, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""C:\Users\User\anaconda3\envs\PythonCPU\lib\site-packages\tensorflow\python\__init__.py"", line 63, in <module>
    from tensorflow.python.framework.framework_lib import *  # pylint: disable=redefined-builtin
  File ""C:\Users\User\anaconda3\envs\PythonCPU\lib\site-packages\tensorflow\python\framework\framework_lib.py"", line 25, in <module>
    from tensorflow.python.framework.ops import Graph
  File ""C:\Users\User\anaconda3\envs\PythonCPU\lib\site-packages\tensorflow\python\framework\ops.py"", line 54, in <module>
    from tensorflow.python.platform import app
  File ""C:\Users\User\anaconda3\envs\PythonCPU\lib\site-packages\tensorflow\python\platform\app.py"", line 23, in <module>
    from absl.app import run as _run
  File ""C:\Users\User\anaconda3\envs\PythonCPU\lib\site-packages\absl\app.py"", line 35, in <module>
    import pdb
  File ""C:\Users\User\anaconda3\envs\PythonCPU\lib\pdb.py"", line 76, in <module>
    import code
  File ""C:\Users\User\Documents\SpeechRecognition\task4\code.py"", line 4, in <module>
    import keras
  File ""C:\Users\User\anaconda3\envs\PythonCPU\lib\site-packages\keras\__init__.py"", line 3, in <module>
    from . import utils
  File ""C:\Users\User\anaconda3\envs\PythonCPU\lib\site-packages\keras\utils\__init__.py"", line 6, in <module>
    from . import conv_utils
  File ""C:\Users\User\anaconda3\envs\PythonCPU\lib\site-packages\keras\utils\conv_utils.py"", line 9, in <module>
    from .. import backend as K
  File ""C:\Users\User\anaconda3\envs\PythonCPU\lib\site-packages\keras\backend\__init__.py"", line 1, in <module>
    from .load_backend import epsilon
  File ""C:\Users\User\anaconda3\envs\PythonCPU\lib\site-packages\keras\backend\load_backend.py"", line 90, in <module>
    from .tensorflow_backend import *
  File ""C:\Users\User\anaconda3\envs\PythonCPU\lib\site-packages\keras\backend\tensorflow_backend.py"", line 9, in <module>
    from tensorflow.python.ops import image_ops as tf_image_ops
  File ""C:\Users\User\anaconda3\envs\PythonCPU\lib\site-packages\tensorflow\python\ops\image_ops.py"", line 28, in <module>
    from tensorflow.python.ops.gen_image_ops import *
  File ""C:\Users\User\anaconda3\envs\PythonCPU\lib\site-packages\tensorflow\python\ops\gen_image_ops.py"", line 19, in <module>
    from tensorflow.python.framework import common_shapes as _common_shapes
  File ""C:\Users\User\anaconda3\envs\PythonCPU\lib\site-packages\tensorflow\python\framework\common_shapes.py"", line 729, in <module>
    ops._set_call_cpp_shape_fn(call_cpp_shape_fn)
AttributeError: module 'tensorflow.python.framework.ops' has no attribute '_set_call_cpp_shape_fn'"
40052,Format issue in `tf.ragged.constant` documentation,"## URL(s) with the issue:

https://www.tensorflow.org/api_docs/python/tf/ragged/constant

## Description of issue (what needs changing):

### Clear description

Format issue. In the ""Args"" section, format of description of `ragged_rank` is problematic. The default value should be `max(0, K-1-len(inner_shape))`

### Parameters defined

Yes

### Returns defined

Yes

### Raises listed and defined

Yes
"
40051,`tf.hessians` documentation refers `colocate_gradients_with_ops` as an argument,"## URL(s) with the issue:

https://www.tensorflow.org/api_docs/python/tf/hessians

## Description of issue (what needs changing):

### Clear description

In the ""Args"" section, there is an input `colocate_gradients_with_ops`, but it is not in the signature, and the function doesn't accept the argument.

Running code:

~~~python
tf.hessians(1,1,colocate_gradients_with_ops=None)
~~~

got exception:

~~~python
TypeError: HessiansV2() got an unexpected keyword argument 'colocate_gradients_with_ops'
~~~

### Parameters defined

Yes

### Returns defined

Yes

### Raises listed and defined

Yes

## System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS Mojave 10.14
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 2.2.0-rc3
- **Python version**: 3.8.2
"
40050,Unclear shape dependency of `value` in  `tf.keras.backend.moving_average_update` documentation,"## URL(s) with the issue:

https://www.tensorflow.org/api_docs/python/tf/keras/backend/moving_average_update

## Description of issue (what needs changing):

### Clear description

Unclear shape dependency of input `value`. According to the document, `value` should have the same shape as `variable`, but it is unclear what is `variable`.

### Parameters defined

Yes

### Returns defined

Yes

### Raises listed and defined

No"
40049,Usage of secure grpc functions breaks builds using unsecure grpc,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Ubuntu 16.04 on s390x
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
N/A
- TensorFlow installed from (source or binary):
Source
- TensorFlow version:
Master
- Python version:
3.7.6
- Installed using virtualenv? pip? conda?:
Building from source
- Bazel version (if compiling from source):
2.0.0
- GCC/Compiler version (if compiling from source):
gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
- CUDA/cuDNN version:
N/A disabled in configure
- GPU model and memory:
N/A not using GPU for tensorflow


**Describe the problem**
On s390x grpc_unsecure build is used:

```
cc_library(
    name = ""grpc"",
    visibility = [""//visibility:public""],
    deps = select({
        "":linux_s390x"": [""@com_github_grpc_grpc//:grpc_unsecure""],
        ""//conditions:default"": [""@com_github_grpc_grpc//:grpc""],
    }),
)

cc_library(
    name = ""grpc++"",
    visibility = [""//visibility:public""],
    deps = select({
        "":linux_s390x"": [""@com_github_grpc_grpc//:grpc++_unsecure""],
        ""//conditions:default"": [""@com_github_grpc_grpc//:grpc++""],
    }),
)
```

When building tensorflow master on s390x the following error occurs:
```
Traceback (most recent call last):
  File ""/home/alfred/jenkins/workspace/TensorFlow_IBMZ_CI/Tensorflow_tmp/_bazel_jenkins/f9a4b527679ac8529256cd6c97867507/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v2.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py"", line 64, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: /home/alfred/jenkins/workspace/TensorFlow_IBMZ_CI/Tensorflow_tmp/_bazel_jenkins/f9a4b527679ac8529256cd6c97867507/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v2.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZN9grpc_impl12experimental22LocalServerCredentialsE23grpc_local_connect_type

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/alfred/jenkins/workspace/TensorFlow_IBMZ_CI/Tensorflow_tmp/_bazel_jenkins/f9a4b527679ac8529256cd6c97867507/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v2.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py"", line 27, in <module>
    from tensorflow.python.tools.api.generator import doc_srcs
  File ""/home/alfred/jenkins/workspace/TensorFlow_IBMZ_CI/Tensorflow_tmp/_bazel_jenkins/f9a4b527679ac8529256cd6c97867507/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v2.runfiles/org_tensorflow/tensorflow/python/__init__.py"", line 50, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/home/alfred/jenkins/workspace/TensorFlow_IBMZ_CI/Tensorflow_tmp/_bazel_jenkins/f9a4b527679ac8529256cd6c97867507/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v2.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py"", line 83, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/home/alfred/jenkins/workspace/TensorFlow_IBMZ_CI/Tensorflow_tmp/_bazel_jenkins/f9a4b527679ac8529256cd6c97867507/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v2.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py"", line 64, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: /home/alfred/jenkins/workspace/TensorFlow_IBMZ_CI/Tensorflow_tmp/_bazel_jenkins/f9a4b527679ac8529256cd6c97867507/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v2.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZN9grpc_impl12experimental22LocalServerCredentialsE23grpc_local_connect_type


Failed to load the native TensorFlow runtime.
```

The issue is caused because the built pywrap internal shared library is missing a few grpc secure symbols. The reason is tensorflow master has started to use secure grpc functions which breaks the build.

Is this perhaps a mistake in the code? Should unsecure grpc functions be used instead?


**Provide the exact sequence of commands / steps that you executed before running into the problem**
Build tensorflow on s390x from source. 

```
bazel --host_jvm_args=""-Xms1024m"" --host_jvm_args=""-Xmx2048m"" build  --define=tensorflow_mkldnn_contraction_kernel=0 //tensorflow/tools/pip_package:build_pip_package
```




**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

A possible solution is to replace the use of secure grpc functions with unsecure grpc functions, which can be fixed by the below patch:

```diff --git a/tensorflow/compiler/xla/python/tpu_driver/grpc_tpu_driver.cc b/tensorflow/compiler/xla/python/tpu_driver/grpc_tpu_driver.cc
index 7632f21..db91ea2 100644
--- a/tensorflow/compiler/xla/python/tpu_driver/grpc_tpu_driver.cc
+++ b/tensorflow/compiler/xla/python/tpu_driver/grpc_tpu_driver.cc
@@ -1083,14 +1083,8 @@ REGISTER_TPU_DRIVER(
     ""grpc://"",
     [](const TpuDriverConfig& config)
         -> xla::StatusOr<std::unique_ptr<TpuDriver>> {
-      if (absl::StartsWith(config.worker(), ""grpc://localhost"")) {
-        LOG(INFO) << ""Using local credentials for localhost: connection."";
-        return CreateGrpcTpuDriver(
-            config, ::grpc::experimental::LocalCredentials(LOCAL_TCP));
-      } else {
-        return CreateGrpcTpuDriver(config,
-                                   ::grpc::InsecureChannelCredentials());
-      }
+      return CreateGrpcTpuDriver(config,
+                                 ::grpc::InsecureChannelCredentials());
     });
 }  // namespace tpu_driver
diff --git a/tensorflow/core/data/service/local_credentials_factory.cc b/tensorflow/core/data/service/local_credentials_factory.cc
index 136bf49..2fd9202 100644
--- a/tensorflow/core/data/service/local_credentials_factory.cc
+++ b/tensorflow/core/data/service/local_credentials_factory.cc
@@ -24,13 +24,13 @@ class LocalCredentialsFactory : public CredentialsFactory {
   Status CreateServerCredentials(
       std::shared_ptr<::grpc::ServerCredentials>* out) override {
-    *out = grpc::experimental::LocalServerCredentials(LOCAL_TCP);
+    *out = grpc::InsecureServerCredentials();
     return Status::OK();
   }
   Status CreateClientCredentials(
       std::shared_ptr<::grpc::ChannelCredentials>* out) override {
-    *out = grpc::experimental::LocalCredentials(LOCAL_TCP);
+    *out = grpc::InsecureChannelCredentials();
     return Status::OK();
   }
 };```"
40048,Test case //tensorflow/python/eager:def_function_test_cpu_only fails on TF2.2 due to inconsistent XLA flag.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): N/A
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.2.0
- Python version: 3.8.2
- Bazel version (if compiling from source): 2.0.0
- GCC/Compiler version (if compiling from source): gcc (Ubuntu 9.3.0-10ubuntu2) 9.3.0
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
The test case `//tensorflow/python/eager:def_function_test_cpu_only` fails with the following error log:
```
======================================================================
ERROR: testExperimentalCompileRaisesExceptionWhenXlaIsUnsupported (__main__.DefFunctionCpuOnlyTest)
testExperimentalCompileRaisesExceptionWhenXlaIsUnsupported (__main__.DefFunctionCpuOnlyTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/home/sidong/.cache/bazel/_bazel_sidong/9ef871a29c692fc6a18121463529e145/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/eager/def_function_test_cpu_only.runfiles/org_tensorflow/tensorflow/python/eager/def_function_test_cpu_only.py"", line 46, in testExperimentalCompileRaisesExceptionWhenXlaIsUnsupported
    fn([1, 1, 2, 3])
  File ""/home/sidong/.cache/bazel/_bazel_sidong/9ef871a29c692fc6a18121463529e145/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/eager/def_function_test_cpu_only.runfiles/org_tensorflow/tensorflow/python/eager/def_function.py"", line 576, in __call__
    result = self._call(*args, **kwds)
  File ""/home/sidong/.cache/bazel/_bazel_sidong/9ef871a29c692fc6a18121463529e145/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/eager/def_function_test_cpu_only.runfiles/org_tensorflow/tensorflow/python/eager/def_function.py"", line 650, in _call
    return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access
  File ""/home/sidong/.cache/bazel/_bazel_sidong/9ef871a29c692fc6a18121463529e145/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/eager/def_function_test_cpu_only.runfiles/org_tensorflow/tensorflow/python/eager/function.py"", line 1661, in _filtered_call
    return self._call_flat(
  File ""/home/sidong/.cache/bazel/_bazel_sidong/9ef871a29c692fc6a18121463529e145/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/eager/def_function_test_cpu_only.runfiles/org_tensorflow/tensorflow/python/eager/function.py"", line 1745, in _call_flat
    return self._build_call_outputs(self._inference_function.call(
  File ""/home/sidong/.cache/bazel/_bazel_sidong/9ef871a29c692fc6a18121463529e145/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/eager/def_function_test_cpu_only.runfiles/org_tensorflow/tensorflow/python/eager/function.py"", line 593, in call
    outputs = execute.execute(
  File ""/home/sidong/.cache/bazel/_bazel_sidong/9ef871a29c692fc6a18121463529e145/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/eager/def_function_test_cpu_only.runfiles/org_tensorflow/tensorflow/python/eager/execute.py"", line 59, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.InvalidArgumentError: Function invoked by the following node is not compilable: {{node __inference_fn_7}} = __inference_fn_7[_XlaMustCompile=true, config_proto=""\n\007\n\003CPU\020\001\n\007\n\003GPU\020\0002\002J\0008\001"", executor_type=""""]().
Uncompilable nodes:
Unique: unsupported op: No registered 'Unique' OpKernel for XLA_CPU_JIT devices compatible with node {{node Unique}}
        Stacktrace:
                Node: __inference_fn_7, function:
                Node: Unique, function: __inference_fn_7
 [Op:__inference_fn_7]

----------------------------------------------------------------------
Ran 2 tests in 0.318s

FAILED (errors=1, skipped=1)
```
**Describe the expected behavior**
The test case should raise a ValueError ""Attempting to use experimental_compile, but XLA support is not linked in. Rebuild with --define=with_xla_support=true."", and captured by `self.assertRaisesRegexp()`
The test case should pass.

**Standalone code to reproduce the issue**
I modified the test case a little bit, and it could be reproduced from this [gist](https://colab.research.google.com/drive/1qweKRl1ZxEPWtN-qlz6DsNCVR0J8M8fg?usp=sharing)


**Other info / logs** 
I looked into this issue, it seems that it is caused by inconsistent internal APIs. When debugging this test file, I get the following results:
```
> /home/sidong/.cache/bazel/_bazel_sidong/338a466d2403fbfe3413e7ca6003e4cf/execroot/org_tensorflow/bazel-out/s390x-opt/bin/tensorflow/python/eager/def_function_test_cpu_only.runfiles/org_tensorflow/tensorflow/python/eager/def_function_test_cpu_only.py(47)testExperimentalCompileRaisesExceptionWhenXlaIsUnsupported()
-> fn([1, 1, 2, 3])
(Pdb) p test_util.is_xla_enabled()
False
(Pdb) p pywrap_tfe.TF_IsXlaEnabled()
True
```
Basically, the test proceeds if `test_util.is_xla_enabled()` is false, and it will raise the exception as intended when `pywrap_tfe.TF_IsXlaEnabled()` is false. The inconsistency caused the exception not correctly raised.
One way to fix it is to discard `test_util.is_xla_enabled()` and only use `pywrap_tfe.TF_IsXlaEnabled()`, but I think maybe it's better to solve this inconsistency issue. I noticed that the `pywrap_tfe.TF_IsXlaEnabled()` API and this test case was added from the same [commit](https://github.com/tensorflow/tensorflow/commit/96e0b87d1e23ac1dd7a7aa984e3f479647267b32), and I assume the cause of inconsistency is that the function `SetXlaIsEnabled()` was called incorrectly. Could you look into this issue and check why the function was called when xla was not enabled? Thanks.

Sidong"
40047,"InvalidArgumentError:  Incompatible shapes: [200,10] vs. [200,5] [[node LogicalAnd_3 (defined at <ipython-input-11-ea6e7bc7fc28>:1) ]]","Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes, I have written custom code. 

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
I am running into this problem on Google Colab, which has Tensorflow 2.2.0

- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:
NA

- **TensorFlow installed from (source or binary)**:
Google Colab setup, Tensorflow version 2.2.0

- **TensorFlow version (use command below)**:
TensorFlow 2.2.0

- **Python version**: Python 3.6.9
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

While the model is getting trained, it randomly fails in any of the iteration of epoch with an Incompatible shape Error for **LogicalAnd** node, with the shapes differing as [200, 10] and [200, 5].
The difference in axis 1 here is actually : 2*Batch_size and Batch_size. So, if I change Batch_Size, the shapes change accordingly. Also, I'm not seeing this error on my local machine if I'm running this same code, Tensorflow version 2.2.0_rc1on a CPU. But, on Google Colab, I tried it both on CPU and GPU, and I face this error.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

Deep Network containing Pretrained Bert and  ResNet50V2 networks. The final layer outputs of both networks are concatenated and connected to a final Softmax layer of 2 neurons. There are 4 Input layers for complete network : 3 for BERT and 1 for ResNet50V2.

**Here's the architecture code for network** : 
`
    def complete_model():
    input_word_ids = tf.keras.layers.Input(
        (MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_word_ids')
    input_masks = tf.keras.layers.Input(
        (MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_masks')
    input_segments = tf.keras.layers.Input(
        (MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_segments')
    
    img_input = tf.keras.layers.Input((256, 256, 3))
    
    bert_layer = hub.KerasLayer(BERT_PATH, trainable=True)
    
    _, sequence_output = bert_layer([input_word_ids, input_masks, input_segments])
    bert_out = tf.keras.layers.GlobalAveragePooling1D()(sequence_output)
    
    resnet_model = tf.keras.applications.ResNet50V2(include_top=False, weights='imagenet', input_tensor=img_input, pooling='avg')
    resnet_out = resnet_model.output
    
    x = tf.keras.layers.Concatenate()([bert_out, resnet_out])
    x = tf.keras.layers.Dropout(0.4)(x)
    out = tf.keras.layers.Dense(2, activation='softmax')(x)
    
    model = tf.keras.models.Model(inputs=[img_input, input_word_ids, input_masks, input_segments], outputs=out)
    return model
`

The model is created and then compiled and trained with the tf.keras.fit API. I created a tf.keras.Sequence object for generating inputs in batches in format :
**<batch of images for ResNet50V2 of shape (256, 256, 3)>, <batch for Input IDs for BERT of shape (512)>, <batch for Attention Masks for BERT of shape (512)>, <batch for Segment IDs for BERT of shape (512)> and output <batch of class labels (batch_size, 2)>**

**Below is the Error Trace which I get** :

Epoch 1/5
  18/1700 [..............................] - ETA: 1:31:14 - loss: 1.6233 - accuracy: 0.5889 - auc: 0.5584
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-14-ea6e7bc7fc28> in <module>()
----> 1 hist = model.fit(train_dataseq, epochs=5, verbose=1, steps_per_epoch=8500//5, validation_data=valid_dataseq, validation_steps=500//5)

8 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)
     64   def _method_wrapper(self, *args, **kwargs):
     65     if not self._in_multi_worker_mode():  # pylint: disable=protected-access
---> 66       return method(self, *args, **kwargs)
     67 
     68     # Running inside `run_distribute_coordinator` already.

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
    846                 batch_size=batch_size):
    847               callbacks.on_train_batch_begin(step)
--> 848               tmp_logs = train_function(iterator)
    849               # Catch OutOfRangeError for Datasets of unknown size.
    850               # This blocks until the batch has finished executing.

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
    578         xla_context.Exit()
    579     else:
--> 580       result = self._call(*args, **kwds)
    581 
    582     if tracing_count == self._get_tracing_count():

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
    609       # In this case we have created variables on the first call, so we run the
    610       # defunned version which is guaranteed to never create variables.
--> 611       return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
    612     elif self._stateful_fn is not None:
    613       # Release the lock early so that multiple threads can perform the call

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs)
   2418     with self._lock:
   2419       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
-> 2420     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
   2421 
   2422   @property

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _filtered_call(self, args, kwargs)
   1663          if isinstance(t, (ops.Tensor,
   1664                            resource_variable_ops.BaseResourceVariable))),
-> 1665         self.captured_inputs)
   1666 
   1667   def _call_flat(self, args, captured_inputs, cancellation_manager=None):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1744       # No tape is watching; skip to running the function.
   1745       return self._build_call_outputs(self._inference_function.call(
-> 1746           ctx, args, cancellation_manager=cancellation_manager))
   1747     forward_backward = self._select_forward_and_backward_functions(
   1748         args,

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in call(self, ctx, args, cancellation_manager)
    596               inputs=args,
    597               attrs=attrs,
--> 598               ctx=ctx)
    599         else:
    600           outputs = execute.execute_with_cancellation(

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     58     ctx.ensure_initialized()
     59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
---> 60                                         inputs, attrs, num_outputs)
     61   except core._NotOkStatusException as e:
     62     if name is not None:

InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument:  Incompatible shapes: [200,10] vs. [200,5]
	 [[node LogicalAnd (defined at <ipython-input-14-ea6e7bc7fc28>:1) ]]
	 [[assert_less_equal/Assert/AssertGuard/pivot_f/_2738/_167]]
  (1) Invalid argument:  Incompatible shapes: [200,10] vs. [200,5]
	 [[node LogicalAnd (defined at <ipython-input-14-ea6e7bc7fc28>:1) ]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_64050]

Function call stack:
train_function -> train_function
"
40046,TypeError: '_TupleWrapper' object is not callable,"```
def run_train(dataset, num_epochs=2):
    start_time = time.perf_counter()

    model = VGGBase()

    for _ in tf.data.Dataset.range(num_epochs):
        for image,target in dataset: # (batch_size (N), 300, 300, 3)
            image = np.array(image)
            target = np.array(target)
            print(target)
            print(type(image), type(target),image.shape,target.shape)
            predicted_locs, predicted_socres = model(image)# (N, 8732, 4), (N, 8732, n_classes)
            print(predicted_locs,predicted_socres)
            pass
            break
        pass

def train():
    if isprint:print(tf.__version__)
    batch_size= 256

    #dataset test0
    images,boxes,labels,difficulties= PascalVOCDataset()
    boxes = tf.ragged.constant(boxes)
    dataset = tf.data.Dataset.from_tensor_slices((images,boxes))
    run_train(dataset.map(resize_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(1).prefetch(tf.data.experimental.AUTOTUNE))
```

I got an error of 

```
 File ""/home/jake/Gits/ssd_tensorflow/model.py"", line 56, in call
    x = self.conv1_1(x)# (N, 64, 300, 300)
TypeError: '_TupleWrapper' object is not callable
```

my model looks like 
```
class  VGGBase(Model):
    def __init__(self):
        super(VGGBase,self).__init__()
        self.padding_1 = tf.keras.layers.ZeroPadding2D(padding=(1, 1))  # put this before your conv layer
        self.conv1_1 = tf.keras.layers.Conv2D(3, kernel_size=3,padding='same',strides=1, activation='relu'),
        self.conv1_2 = tf.keras.layers.Conv2D(64, kernel_size=3, padding='same',strides=1,activation='relu'),
        self.pool1 = tf.keras.layers.MaxPool2D(2,2),

        self.conv2_1  =  tf.keras.layers.Conv2D(128, kernel_size=3, padding='same',strides= 1,activation='relu'),
        self.conv2_2 = tf.keras.layers.Conv2D(128, kernel_size=3,padding='same',strides= 1,activation='relu'),
        self.pool2 = tf.keras.layers.MaxPool2D(2,2),

        self.conv3_1 =  tf.keras.layers.Conv2D(256, kernel_size=3, padding='same',strides= 1,activation='relu'),
        self.conv3_2 =  tf.keras.layers.Conv2D(256, kernel_size=3, padding='same',strides= 1,activation='relu'),
        self.conv3_3 =  tf.keras.layers.Conv2D(256, kernel_size=3, padding='same',strides= 1,activation='relu'),
        self.pool3 = tf.keras.layers.MaxPool2D(2,2),

        self.conv4_1 = tf.keras.layers.Conv2D(512, kernel_size=3, padding='same', strides=1,activation='relu'),
        self.conv4_2 = tf.keras.layers.Conv2D(512, kernel_size=3, padding='same', strides=1,activation='relu'),
        self.conv4_3 = tf.keras.layers.Conv2D(512, kernel_size=3, padding='same', strides=1,activation='relu'),
        self.pool4 = tf.keras.layers.MaxPool2D(2, 2),

        self.conv5_1 = tf.keras.layers.Conv2D(512, kernel_size=3, padding='same', strides=1,activation='relu'),
        self.conv5_2 = tf.keras.layers.Conv2D(512, kernel_size=3, padding='same', strides=1,activation='relu'),
        self.conv5_3 = tf.keras.layers.Conv2D(512, kernel_size=3, padding='same', strides=1,activation='relu'),
        self.pool5 = tf.keras.layers.MaxPool2D(2, 2),

        self.padding6 = tf.keras.layers.ZeroPadding2D(padding=(6, 6))  # put this before your conv layer
        self.conv6 = tf.keras.layers.Conv2D(1024, kernel_size=3, padding='same',dilation_rate=6,activation='relu') # atrous convolution
        self.conv7 = tf.keras.layers.Conv2D(1024, kernel_size=1,activation='relu')
        #self.load_weights()
    def call(self,x):
        x = self.padding_1(x)
        x = self.conv1_1(x)# (N, 64, 300, 300)
        x = self.conv1_2(x)# (N, 64, 300, 300)
        x = self.pool1(x) # (N, 64, 150, 150)

        x = self.conv2_1(x) # (N, 128, 150, 150)
        x = self.conv2_2(x) # (N, 128, 150, 150)
        x = self.pool2(x)# (N, 128, 75, 75)

        x = self.conv3_1(x) # (N, 256, 75, 75)
        x = self.conv3_2(x)# (N, 256, 75, 75)
        x = self.conv3_3(x)# (N, 256, 75, 75)
        x = self.pool3(x) #(N, 256, 38, 38), it would have been 37 if not for ceil_mode = True

        x = self.conv4_1(x)# (N, 512, 38, 38)
        x = self.conv4_2(x)# (N, 512, 38, 38)
        x = self.conv4_3(x)# (N, 512, 38, 38)
        conv4_3_feats = x# (N, 512, 38, 38)
        x = self.pool4(x)# (N, 512, 19, 19)

        x = self.conv5_1(x) # (N, 512, 19, 19)
        x = self.conv5_2(x) # (N, 512, 19, 19)
        x = self.conv5_3(x) # (N, 512, 19, 19)
        x = self.pool5(x) # (N, 512, 19, 19), pool5 does not reduce dimensions

        x = self.padding6(x)
        x = self.conv6(x) # (N, 1024, 19, 19)
        x = self.conv7(x) # (N, 1024, 19, 19)
        conv7_feats = x

        return conv4_3_feats, conv7_feats

```
"
40045,[MLIR/XLA] Invalid IR passes verification,"With TensorFlow HEAD at 3ffb4ad2d43311f41155b6e00fd105e50df685da (May 31), the following snippet should fail verification with `tf-opt` but it doesn't:

```
  func @main(%arg0: memref<4x64x128x3xf32>) -> tuple<tensor<4x64x128x3xf32>> {
    ""xla_lhlo.copy""(%arg0, %arg0) : (memref<4x64x128x3xf32>, memref<4x64x128x3xf32>) -> ()
    ""xla_lhlo.terminator""() : () -> ()
  }
```

To reproduce: `$ bazel-bin/tensorflow/compiler/mlir/tf-opt  verify.mlir`.

@joker-eph @pifon2a @sherhut 
"
40044,TFLite: Support grouped convolutions,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab
- TensorFlow installed from (source or binary): binary
- TensorFlow version (or github SHA if from source): tf-nightly==2.3.0.dev20200531

**Motivation**
#25818 added support for native grouped convolutions a year ago. This feature is now also available via Keras layers in the latest nightly release (#36773, #39516).
Converting a model using grouped convolutions to TFLite works fine, though the TFLite runtime currently doesn't support this feature and will throw an error when trying to allocate the Tensors.

It would be great to have this feature available in TFLite in order to have consistent behaviour accross TensorFlow and TFLite. The PRs linked above provide more detail about why this feature something that people would want to use.

**Standalone code to reproduce the issue** 
The issue can be reproduced using [this colab notebook](https://colab.research.google.com/drive/1ngxLfGs0lrGZV1Y8zwTP5X6WAEEEGp1P?usp=sharing).

**Any other info / logs**

I guess adding a reference implementation and implementing optimized kernels in the XNNPack delegate would be pretty straight forward as it already has native support for grouped convolutions:
https://github.com/tensorflow/tensorflow/blob/add80cd47acfa2335b260b8ab877e4dc5cff499b/tensorflow/lite/delegates/xnnpack/xnnpack_delegate.cc#L1072

Though, I am not sure how much effort it would be to support it in the other optimized code paths with Ruy.

If there is a fundamental reason why support for grouped convolutions cannot be added to TFLite it would be great to handle this in the MLIR based converter and translate native TF grouped convolutions to a naive loop based implementation using `tfl.split` and `tfl.concat` which would allow people to use TF group convolutions and and fall back to a loop based implementation in TFLite for now."
40043,gcc: internal compiler error: Killed (program cc1plus),"**System information**
- OS Platform: host: mac 14.10 
- docker image:  tensorflow/tensorflow:latest-devel
- TensorFlow version: 2.2
- Python version: 3.6.9
- building tensorflow from source using docker on mac with ubuntu in docker image
- Bazel version (if compiling from source): 3.0.0
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: NONE ( cpu only build)
- GPU model and memory: NONE 

**the problem**
```
ERROR: /tensorflow_src/tensorflow/core/BUILD:2193:1: C++ compilation of rule '//tensorflow/core:framework_internal_impl' failed (Exit 4): gcc failed: error executing command 
  (cd /root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/execroot/org_tensorflow && \
  exec env - \
    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \
    PWD=/proc/self/cwd \

  /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/_objs/framework_internal_impl/batch_util.pic.d '-frandom-seed=bazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/_objs/framework_internal_impl/batch_util.pic.o' -fPIC -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DHAVE_SYS_UIO_H -DTF_USE_SNAPPY -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/k8-opt-exec-50AE0418/bin -iquote external/com_google_protobuf -iquote bazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf -iquote external/com_google_absl -iquote bazel-out/k8-opt-exec-50AE0418/bin/external/com_google_absl -iquote external/nsync -iquote bazel-out/k8-opt-exec-50AE0418/bin/external/nsync -iquote external/eigen_archive -iquote bazel-out/k8-opt-exec-50AE0418/bin/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/k8-opt-exec-50AE0418/bin/external/local_config_sycl -iquote external/gif -iquote bazel-out/k8-opt-exec-50AE0418/bin/external/gif -iquote external/libjpeg_turbo -iquote bazel-out/k8-opt-exec-50AE0418/bin/external/libjpeg_turbo -iquote external/com_googlesource_code_re2 -iquote bazel-out/k8-opt-exec-50AE0418/bin/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/k8-opt-exec-50AE0418/bin/external/farmhash_archive -iquote external/fft2d -iquote bazel-out/k8-opt-exec-50AE0418/bin/external/fft2d -iquote external/highwayhash -iquote bazel-out/k8-opt-exec-50AE0418/bin/external/highwayhash -iquote external/zlib -iquote bazel-out/k8-opt-exec-50AE0418/bin/external/zlib -iquote external/double_conversion -iquote bazel-out/k8-opt-exec-50AE0418/bin/external/double_conversion -iquote external/snappy -iquote bazel-out/k8-opt-exec-50AE0418/bin/external/snappy -isystem external/com_google_protobuf/src -isystem bazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src -isystem external/nsync/public -isystem bazel-out/k8-opt-exec-50AE0418/bin/external/nsync/public -isystem external/eigen_archive -isystem bazel-out/k8-opt-exec-50AE0418/bin/external/eigen_archive -isystem external/gif -isystem bazel-out/k8-opt-exec-50AE0418/bin/external/gif -isystem external/farmhash_archive/src -isystem bazel-out/k8-opt-exec-50AE0418/bin/external/farmhash_archive/src -isystem external/zlib -isystem bazel-out/k8-opt-exec-50AE0418/bin/external/zlib -isystem external/double_conversion -isystem bazel-out/k8-opt-exec-50AE0418/bin/external/double_conversion -g0 '-march=native' -g0 '-std=c++14' -DEIGEN_AVOID_STL_ARRAY -Iexternal/gemmlowp -Wno-sign-compare '-ftemplate-depth=900' -fno-exceptions '-DTENSORFLOW_USE_XLA=1' -msse3 -pthread '-DTENSORFLOW_USE_XLA=1' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c tensorflow/core/util/batch_util.cc -o bazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/_objs/framework_internal_impl/batch_util.pic.o)
Execution platform: @local_execution_config_platform//:platform
In file included from ./third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint:41:0,
                 from ./tensorflow/core/framework/numeric_types.h:24,
                 from ./tensorflow/core/framework/allocator.h:26,
                 from ./tensorflow/core/framework/tensor.h:23,
                 from ./tensorflow/core/util/batch_util.h:18,
                 from tensorflow/core/util/batch_util.cc:16:

./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:30:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]
 typedef eigen_packet_wrapper<__m256i, 20> Packet32q8i;
                                         ^
./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:31:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]
 typedef eigen_packet_wrapper<__m256i, 21> Packet16q16i;
                                         ^
./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:32:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]
 typedef eigen_packet_wrapper<__m256i, 22> Packet32q8u;
                                         ^
./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:33:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]
 typedef eigen_packet_wrapper<__m128i, 23> Packet16q8i;
                                         ^
./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:34:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]
 typedef eigen_packet_wrapper<__m128i, 25> Packet16q8u;
                                         ^
./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:35:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]
 typedef eigen_packet_wrapper<__m128i, 26> Packet8q16i;
                                         ^
./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:36:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]
 typedef eigen_packet_wrapper<__m256i, 27> Packet8q32i;
                                         ^
./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:37:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]
 typedef eigen_packet_wrapper<__m128i, 28> Packet4q32i;
                                         ^
gcc: internal compiler error: Killed (program cc1plus)
Please submit a full bug report,
with preprocessed source if appropriate.
See <file:///usr/share/doc/gcc-7/README.Bugs> for instructions.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 1314.325s, Critical Path: 521.70s
INFO: 469 processes: 469 local.
FAILED: Build did NOT complete successfully
```
- I am trying to build tensorflow from source to enable the AVX and FMA instruction. i followed the exact set of instructions inorder to start building. As given [here](https://www.tensorflow.org/install/source#docker_linux_builds) i am building the cpu only version.
- Since i am building from the latest one, I should be building from master branch. so I initiated using the below command: 

`bazel build --config=opt --local_ram_resources=4096  --verbose_failures //tensorflow/tools/pip_package:build_pip_packag`

- after this the analysis phase was done. The error occurred during compilation.

unable to diagnose the error. Please help
"
40042,Tensorflow getting slower and slower,"I am benchmarking tensorflow with the cifar10_train.py script from https://github.com/tensorflow/models (v.1.13.0)

Running for 100000 steps, in the first  190 steps
```
2020-06-01 03:26:25.877249: step 0, loss = 4.68 (387.6 examples/sec; 0.330 sec/batch)
2020-06-01 03:26:26.113249: step 10, loss = 4.60 (5423.4 examples/sec; 0.024 sec/batch)
2020-06-01 03:26:26.251981: step 20, loss = 4.53 (9227.0 examples/sec; 0.014 sec/batch)
2020-06-01 03:26:26.391191: step 30, loss = 4.36 (9194.3 examples/sec; 0.014 sec/batch)
2020-06-01 03:26:26.532910: step 40, loss = 4.52 (9032.0 examples/sec; 0.014 sec/batch)
2020-06-01 03:26:26.671122: step 50, loss = 4.30 (9261.1 examples/sec; 0.014 sec/batch)
2020-06-01 03:26:26.810607: step 60, loss = 4.22 (9176.7 examples/sec; 0.014 sec/batch)
2020-06-01 03:26:26.948641: step 70, loss = 4.18 (9273.1 examples/sec; 0.014 sec/batch)
2020-06-01 03:26:27.084231: step 80, loss = 4.16 (9440.1 examples/sec; 0.014 sec/batch)
2020-06-01 03:26:27.221754: step 90, loss = 4.20 (9307.6 examples/sec; 0.014 sec/batch)
INFO:tensorflow:global_step/sec: 59.5952
I0601 03:26:27.554355 140231070107392 basic_session_run_hooks.py:692] global_step/sec: 59.5952
2020-06-01 03:26:27.555495: step 100, loss = 4.20 (3835.3 examples/sec; 0.033 sec/batch)
2020-06-01 03:26:27.698553: step 110, loss = 4.02 (8947.4 examples/sec; 0.014 sec/batch)
2020-06-01 03:26:27.838008: step 120, loss = 3.89 (9178.6 examples/sec; 0.014 sec/batch)
2020-06-01 03:26:27.980759: step 130, loss = 4.19 (8966.7 examples/sec; 0.014 sec/batch)
2020-06-01 03:26:28.117689: step 140, loss = 3.95 (9347.8 examples/sec; 0.014 sec/batch)
2020-06-01 03:26:28.253787: step 150, loss = 3.97 (9405.1 examples/sec; 0.014 sec/batch)
2020-06-01 03:26:28.394747: step 160, loss = 3.93 (9080.5 examples/sec; 0.014 sec/batch)
2020-06-01 03:26:28.536241: step 170, loss = 3.99 (9046.3 examples/sec; 0.014 sec/batch)
2020-06-01 03:26:28.675036: step 180, loss = 3.81 (9222.2 examples/sec; 0.014 sec/batch)
2020-06-01 03:26:28.812280: step 190, loss = 3.95 (9326.5 examples/sec; 0.014 sec/batch)
```
then it progressively goes downhill.

in the last 200 steps;
```2020-06-01 04:39:15.068430: step 99800, loss = 0.61 (1638.6 examples/sec; 0.078 sec/batch)
2020-06-01 04:39:15.610507: step 99810, loss = 0.69 (2361.4 examples/sec; 0.054 sec/batch)
2020-06-01 04:39:16.214997: step 99820, loss = 0.60 (2117.5 examples/sec; 0.060 sec/batch)
2020-06-01 04:39:16.808370: step 99830, loss = 0.58 (2157.2 examples/sec; 0.059 sec/batch)
2020-06-01 04:39:17.416628: step 99840, loss = 0.74 (2104.4 examples/sec; 0.061 sec/batch)
2020-06-01 04:39:18.010663: step 99850, loss = 0.79 (2154.8 examples/sec; 0.059 sec/batch)
2020-06-01 04:39:18.617192: step 99860, loss = 0.67 (2110.4 examples/sec; 0.061 sec/batch)
2020-06-01 04:39:19.218318: step 99870, loss = 0.58 (2129.3 examples/sec; 0.060 sec/batch)
2020-06-01 04:39:19.815205: step 99880, loss = 0.57 (2144.5 examples/sec; 0.060 sec/batch)
2020-06-01 04:39:20.411179: step 99890, loss = 0.79 (2147.7 examples/sec; 0.060 sec/batch)
INFO:tensorflow:global_step/sec: 16.3652
I0601 04:39:21.177534 139750045267712 basic_session_run_hooks.py:692] global_step/sec: 16.3652
2020-06-01 04:39:21.178711: step 99900, loss = 0.71 (1667.6 examples/sec; 0.077 sec/batch)
2020-06-01 04:39:21.718429: step 99910, loss = 0.72 (2371.8 examples/sec; 0.054 sec/batch)
2020-06-01 04:39:22.323965: step 99920, loss = 0.77 (2113.8 examples/sec; 0.061 sec/batch)
2020-06-01 04:39:22.923835: step 99930, loss = 0.66 (2133.8 examples/sec; 0.060 sec/batch)
2020-06-01 04:39:23.516449: step 99940, loss = 0.59 (2159.9 examples/sec; 0.059 sec/batch)
2020-06-01 04:39:24.106146: step 99950, loss = 0.73 (2170.6 examples/sec; 0.059 sec/batch)
2020-06-01 04:39:24.705905: step 99960, loss = 0.54 (2134.2 examples/sec; 0.060 sec/batch)
2020-06-01 04:39:25.302246: step 99970, loss = 0.71 (2146.4 examples/sec; 0.060 sec/batch)
2020-06-01 04:39:25.897399: step 99980, loss = 0.63 (2150.7 examples/sec; 0.060 sec/batch)
2020-06-01 04:39:26.500119: step 99990, loss = 0.66 (2123.7 examples/sec; 0.060 sec/batch)
```
There is a steady drop in examples/sec
is this normal?

OS Ubuntu-16.04
Tensorflow 1.15.3 compiled from  source
python-3.7.6
tested for both cuda-10.0 and 10.1
Nvidia 418.56 driver

Not sure if  these warnings are relevant
```
WARNING:tensorflow:From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10_train.py:130: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

WARNING:tensorflow:From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10_train.py:123: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.

W0601 03:30:25.042990 139750045267712 module_wrapper.py:139] From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10_train.py:123: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.

WARNING:tensorflow:From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10_train.py:124: The name tf.gfile.DeleteRecursively is deprecated. Please use tf.io.gfile.rmtree instead.

W0601 03:30:25.043155 139750045267712 module_wrapper.py:139] From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10_train.py:124: The name tf.gfile.DeleteRecursively is deprecated. Please use tf.io.gfile.rmtree instead.

WARNING:tensorflow:From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10_train.py:125: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.

W0601 03:30:25.045882 139750045267712 module_wrapper.py:139] From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10_train.py:125: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.

WARNING:tensorflow:From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10_train.py:65: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.

W0601 03:30:25.046512 139750045267712 module_wrapper.py:139] From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10_train.py:65: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.

WARNING:tensorflow:From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10_input.py:158: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.
W0601 03:30:25.050264 139750045267712 deprecation.py:323] From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10_input.py:158: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.
WARNING:tensorflow:From /home/bernard/opt/cuda-10.1/lib/python3.7/site-packages/tensorflow_core/python/training/input.py:277: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.
W0601 03:30:25.053800 139750045267712 deprecation.py:323] From /home/bernard/opt/cuda-10.1/lib/python3.7/site-packages/tensorflow_core/python/training/input.py:277: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.
WARNING:tensorflow:From /home/bernard/opt/cuda-10.1/lib/python3.7/site-packages/tensorflow_core/python/training/input.py:189: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.
W0601 03:30:25.054384 139750045267712 deprecation.py:323] From /home/bernard/opt/cuda-10.1/lib/python3.7/site-packages/tensorflow_core/python/training/input.py:189: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.
WARNING:tensorflow:From /home/bernard/opt/cuda-10.1/lib/python3.7/site-packages/tensorflow_core/python/training/input.py:198: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
W0601 03:30:25.055722 139750045267712 deprecation.py:323] From /home/bernard/opt/cuda-10.1/lib/python3.7/site-packages/tensorflow_core/python/training/input.py:198: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
WARNING:tensorflow:From /home/bernard/opt/cuda-10.1/lib/python3.7/site-packages/tensorflow_core/python/training/input.py:198: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
W0601 03:30:25.056567 139750045267712 deprecation.py:323] From /home/bernard/opt/cuda-10.1/lib/python3.7/site-packages/tensorflow_core/python/training/input.py:198: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
WARNING:tensorflow:From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10_input.py:79: FixedLengthRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.FixedLengthRecordDataset`.
W0601 03:30:25.060451 139750045267712 deprecation.py:323] From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10_input.py:79: FixedLengthRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.FixedLengthRecordDataset`.
WARNING:tensorflow:From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10_input.py:172: The name tf.random_crop is deprecated. Please use tf.image.random_crop instead.

W0601 03:30:25.071967 139750045267712 module_wrapper.py:139] From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10_input.py:172: The name tf.random_crop is deprecated. Please use tf.image.random_crop instead.

WARNING:tensorflow:From /home/bernard/opt/cuda-10.1/lib/python3.7/site-packages/tensorflow_core/python/ops/image_ops_impl.py:1518: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
W0601 03:30:25.104054 139750045267712 deprecation.py:323] From /home/bernard/opt/cuda-10.1/lib/python3.7/site-packages/tensorflow_core/python/ops/image_ops_impl.py:1518: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
WARNING:tensorflow:From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10_input.py:126: shuffle_batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.shuffle(min_after_dequeue).batch(batch_size)`.
W0601 03:30:25.105133 139750045267712 deprecation.py:323] From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10_input.py:126: shuffle_batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.shuffle(min_after_dequeue).batch(batch_size)`.
WARNING:tensorflow:From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10_input.py:135: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.

W0601 03:30:25.113710 139750045267712 module_wrapper.py:139] From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10_input.py:135: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.

WARNING:tensorflow:From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10.py:203: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0601 03:30:25.115518 139750045267712 module_wrapper.py:139] From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10.py:203: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10.py:135: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0601 03:30:25.115780 139750045267712 deprecation.py:506] From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10.py:135: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10.py:111: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W0601 03:30:25.115960 139750045267712 module_wrapper.py:139] From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10.py:111: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10.py:93: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

W0601 03:30:25.125622 139750045267712 module_wrapper.py:139] From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10.py:93: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

WARNING:tensorflow:From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10.py:94: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

W0601 03:30:25.126545 139750045267712 module_wrapper.py:139] From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10.py:94: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10.py:215: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

W0601 03:30:25.138711 139750045267712 module_wrapper.py:139] From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10.py:215: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10.py:138: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.

W0601 03:30:25.170348 139750045267712 module_wrapper.py:139] From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10.py:138: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.

WARNING:tensorflow:From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10.py:295: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

W0601 03:30:25.234809 139750045267712 module_wrapper.py:139] From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10.py:295: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

WARNING:tensorflow:From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10.py:343: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.

W0601 03:30:25.235462 139750045267712 module_wrapper.py:139] From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10.py:343: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.

INFO:tensorflow:Summary name local3/weight_loss (raw) is illegal; using local3/weight_loss__raw_ instead.
I0601 03:30:25.261295 139750045267712 summary_op_util.py:66] Summary name local3/weight_loss (raw) is illegal; using local3/weight_loss__raw_ instead.
INFO:tensorflow:Summary name local4/weight_loss (raw) is illegal; using local4/weight_loss__raw_ instead.
I0601 03:30:25.262904 139750045267712 summary_op_util.py:66] Summary name local4/weight_loss (raw) is illegal; using local4/weight_loss__raw_ instead.
INFO:tensorflow:Summary name cross_entropy (raw) is illegal; using cross_entropy__raw_ instead.
I0601 03:30:25.264466 139750045267712 summary_op_util.py:66] Summary name cross_entropy (raw) is illegal; using cross_entropy__raw_ instead.
INFO:tensorflow:Summary name total_loss (raw) is illegal; using total_loss__raw_ instead.
I0601 03:30:25.266004 139750045267712 summary_op_util.py:66] Summary name total_loss (raw) is illegal; using total_loss__raw_ instead.
WARNING:tensorflow:From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10.py:355: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.

W0601 03:30:25.267595 139750045267712 module_wrapper.py:139] From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10.py:355: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.

WARNING:tensorflow:From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10.py:362: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W0601 03:30:25.333956 139750045267712 module_wrapper.py:139] From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10.py:362: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

WARNING:tensorflow:From /home/bernard/opt/cuda-10.1/lib/python3.7/site-packages/tensorflow_core/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0601 03:30:25.350221 139750045267712 deprecation.py:323] From /home/bernard/opt/cuda-10.1/lib/python3.7/site-packages/tensorflow_core/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
WARNING:tensorflow:From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10_train.py:84: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.

W0601 03:30:25.504043 139750045267712 module_wrapper.py:139] From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10_train.py:84: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.

WARNING:tensorflow:From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10_train.py:110: The name tf.train.MonitoredTrainingSession is deprecated. Please use tf.compat.v1.train.MonitoredTrainingSession instead.

W0601 03:30:25.504228 139750045267712 module_wrapper.py:139] From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10_train.py:110: The name tf.train.MonitoredTrainingSession is deprecated. Please use tf.compat.v1.train.MonitoredTrainingSession instead.

WARNING:tensorflow:From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10_train.py:112: The name tf.train.StopAtStepHook is deprecated. Please use tf.estimator.StopAtStepHook instead.

W0601 03:30:25.504341 139750045267712 module_wrapper.py:139] From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10_train.py:112: The name tf.train.StopAtStepHook is deprecated. Please use tf.estimator.StopAtStepHook instead.

WARNING:tensorflow:From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10_train.py:113: The name tf.train.NanTensorHook is deprecated. Please use tf.estimator.NanTensorHook instead.

W0601 03:30:25.504446 139750045267712 module_wrapper.py:139] From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10_train.py:113: The name tf.train.NanTensorHook is deprecated. Please use tf.estimator.NanTensorHook instead.

WARNING:tensorflow:From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10_train.py:115: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

W0601 03:30:25.504545 139750045267712 module_wrapper.py:139] From /home/bernard/python-dev/test/models-master/tutorials/image/cifar10/cifar10_train.py:115: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

INFO:tensorflow:Create CheckpointSaverHook.
I0601 03:30:25.504671 139750045267712 basic_session_run_hooks.py:541] Create CheckpointSaverHook.
WARNING:tensorflow:From /home/bernard/opt/cuda-10.1/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0601 03:30:25.617982 139750045267712 deprecation.py:323] From /home/bernard/opt/cuda-10.1/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
```
"
40041,Customizing what happens in fit(),"I read the guide document of keras, and run codes of 'Customizing what happens in fit() -> Going lower-level', just copy code on the guide and run it, but I get this error message:

""ValueError: The model cannot be compiled because it has no loss to optimize.""

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): manjaro
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0 cpu
- Python version: 3.7

**Describe the current behavior**
I run code copied from here ""https://keras.io/guides/customizing_what_happens_in_fit/#going-lowerlevel""


**Describe the expected behavior**
According to the doc, I can just skip passing loss function when I call model.compile, but it does not work, It seems like when I call model.fit, the overrided method ""train_step"" is not called.
"
40038,Warnings in tf.autodiff.ForwardAccumulator,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: 3.7.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1/7.6.5
- GPU model and memory: GTX 2080TI/11GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

I run the first example in [doc for ForwardAccumulator](https://www.tensorflow.org/api_docs/python/tf/autodiff/ForwardAccumulator). It gives the following warning message:

```
WARNING:tensorflow:5 out of the last 5 calls to <function _jvp_helper at 0x00000152FA90A288> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
WARNING:tensorflow:6 out of the last 6 calls to <function _jvp_helper at 0x00000152FA90A288> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
```

**Describe the expected behavior**

No warning.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```
import tensorflow as tf

x = tf.constant([[2.0, 3.0], [1.0, 4.0]])
dense = tf.keras.layers.Dense(1)
dense.build([None, 2])
with tf.autodiff.ForwardAccumulator(
   primals=dense.kernel,
   tangents=tf.constant([[1.], [0.]])) as acc:
  loss = tf.reduce_sum((dense(x) - tf.constant([1., -1.])) ** 2.)
acc.jvp(loss)
```


**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40037,How am I supposed to debug an error with this complexity? - Shapes mismatch YoloV4 - tensorflow 2.2,"I recently added a new feature to my [yolo implementation in tensorflow 2.2](https://github.com/emadboctorx/yolov3-keras-tf2) is models are currently loaded directly from [DarkNet](https://github.com/AlexeyAB/darknet) cfg files for convenience, I tested the code with yolov3 configuration as well as yolov4 configuration they both work just fine except for v4 training. Shortly after I start training I get a shapes mismatch error and I'll be very grateful if someone can help me get rid of the error and get to finally complete my project. Please let me know in the comments and I will provide you with any resources you need to help me with fixing the problem and thank you in advance...

This is what you would want to do in order to reproduce:

* clone the repo above
* download the files necessary for the code to run below
* run the following in train.py

```
if __name__ == '__main__':
    tr = Trainer((608, 608, 3),
                 '../Config/yolo4.cfg',
                 '../Config/beverly_hills.txt',
                 1344, 756, score_threshold=0.1,
                 train_tf_record='../Data/TFRecords/beverly_hills_train.tfrecord',
                 valid_tf_record='../Data/TFRecords/beverly_hills_test.tfrecord')

    tr.train(
        100,
        8,
        1e-3,
        dataset_name='beverly_hills',
        merge_evaluation=False,
        n_epoch_eval=10,
        clear_outputs=True
    )
```

links to files you need:

[bh_labels.csv](https://drive.google.com/file/d/13WHpo6qBB4LsFvr4jydDcxEmyQYROEI8/view?usp=sharing)
[beverly_hills.txt](https://drive.google.com/file/d/1-WWwrDa-QoqK0GqjANMqX3tcwsuVH7Bd/view?usp=sharing)
[beverly_hills_train.tfrecord](https://drive.google.com/file/d/13uJWnOqMdbvwWv6EttLN8U6G8F6eL7bB/view?usp=sharing)
[beverly_hills_test.tfrecord](https://drive.google.com/file/d/13nesAJRryuzE09i0FxBQsmixM51QRjIL/view?usp=sharing)

The error:

```
Traceback (most recent call last):
  File ""trainer.py"", line 629, in <module>
    clear_outputs=True
  File ""../Helpers/utils.py"", line 62, in wrapper
    result = func(*args, **kwargs)
  File ""trainer.py"", line 490, in train
    validation_data=valid_dataset,
  File ""/root/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 108, in _method_wrapper
    return method(self, *args, **kwargs)
  File ""/root/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 1090, in fit
    tmp_logs = train_function(iterator)
  File ""/root/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 766, in __call__
    result = self._call(*args, **kwds)
  File ""/root/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 826, in _call
    return self._stateless_fn(*args, **kwds)
  File ""/root/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 2811, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File ""/root/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 1838, in _filtered_call
    cancellation_manager=cancellation_manager)
  File ""/root/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 1914, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""/root/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 549, in call
    ctx=ctx)
  File ""/root/.local/lib/python3.6/site-packages/tensorflow/python/eager/execute.py"", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.InvalidArgumentError:  Incompatible shapes: [4,76,76,3,1] vs. [4,19,19,3,1]
     [[node yolo_loss/logistic_loss/mul (defined at ../Helpers/utils.py:260) ]] [Op:__inference_train_function_38735]

Errors may have originated from an input operation.
Input Source operations connected to node yolo_loss/logistic_loss/mul:
 yolo_loss/split_1 (defined at ../Helpers/utils.py:222) 
 yolo_loss/split (defined at ../Helpers/utils.py:196)

Function call stack:
train_function
```
And when I change the batch_size to 8 instead of 4, the error mutates into the following(the source of the error changes)

```
Traceback (most recent call last):
  File ""/Users/emadboctor/Desktop/Code/yolov3-keras-tf2/Main/trainer.py"", line 693, in <module>
    clear_outputs=True,
  File ""/Users/emadboctor/Desktop/Code/yolov3-keras-tf2/Helpers/utils.py"", line 62, in wrapper
    result = func(*args, **kwargs)
  File ""/Users/emadboctor/Desktop/Code/yolov3-keras-tf2/Main/trainer.py"", line 526, in train
    validation_data=valid_dataset,
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py"", line 66, in _method_wrapper
    return method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py"", line 848, in fit
    tmp_logs = train_function(iterator)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 580, in __call__
    result = self._call(*args, **kwds)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 644, in _call
    return self._stateless_fn(*args, **kwds)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 2420, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 1665, in _filtered_call
    self.captured_inputs)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 1746, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 598, in call
    ctx=ctx)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/execute.py"", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.InvalidArgumentError:  Incompatible shapes: [8,13,13,3,2] vs. [8,52,52,3,2]
	 [[node gradient_tape/yolo_loss/sub_5/BroadcastGradientArgs (defined at Users/emadboctor/Desktop/Code/yolov3-keras-tf2/Main/trainer.py:526) ]] [Op:__inference_train_function_42744]

Function call stack:
train_function
```"
40036,"Tensorflow 2.2 takes much more time than 2.1/2.0 to start training with ""keras.fit""","**System information**
- OS Platform and Distribution:Ubuntu 18.04
- TensorFlow installed from (source or binary):conda (I trided pip, same)
- TensorFlow version:2.2
- Python version:3.7
- CUDA/cuDNN version: 10.1
- GPU model and memory:  Titan RTX * 2  = 48GB

Tensorflow 2.2 takes much more time than 2.1/2.0 to start training, after called ""keras.fit"".

```
2020-06-01 10:16:44.991459: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-06-01 10:16:46.235945: W tensorflow/stream_executor/gpu/asm_compiler.cc:81] Running ptxas --version returned 256
2020-06-01 10:16:46.328871: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
2020-06-01 10:16:48.148004: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-06-01 10:23:36.473814: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session started.
```

It stucks about 7 mins to start training.

However, in 2.1

```
INFO:tensorflow:batch_all_reduce: 436 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10
I0531 20:55:03.956965 139684401002304 cross_device_ops.py:760] batch_all_reduce: 436 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10
INFO:tensorflow:batch_all_reduce: 436 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10
I0531 20:55:14.695299 139684401002304 cross_device_ops.py:760] batch_all_reduce: 436 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10
2020-05-31 20:55:39.932592: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-31 20:55:41.811100: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-05-31 20:55:48.718710: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
```
"
40035,Training error on Cloud TPUs,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian OS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.2.0
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
I am using a custom-modified code which works well on CPUs to train on TPUs and I am getting the error below
```
2020-05-31 22:06:00.162510: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2020-05-31 22:06:00.169480: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2000179999 Hz
2020-05-31 22:06:00.170574: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x41a8240 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-05-31 22:06:00.170610: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-05-31 22:06:00.180728: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.240.1.2:8470}
2020-05-31 22:06:00.180770: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:56139}
2020-05-31 22:06:00.195639: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.240.1.2:8470}
2020-05-31 22:06:00.195683: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:56139}
2020-05-31 22:06:00.196179: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:390] Started server with target: grpc://localhost:56139
All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU')]
2020/05/31 22:06:05 Network Started
Number of devices: 8
Traceback (most recent call last):
  File ""check_tpu_distribute_strategy_trainer.py"", line 166, in <module>
    for x in train_dist_dataset:
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/input_lib.py"", line 296, in __next__
    return self.get_next()
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/input_lib.py"", line 328, in get_next
    global_has_value, replicas = _get_next_as_optional(self, self._strategy)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/input_lib.py"", line 192, in _get_next_as_optional
    iterator._iterators[i].get_next_as_list(new_name))  # pylint: disable=protected-access
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/input_lib.py"", line 1150, in get_next_as_list
    strict=True,
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 1204, in cond
    if pred:
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py"", line 884, in __bool__
    return bool(self._numpy())
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py"", line 929, in _numpy
    six.raise_from(core._status_to_exception(e.code, e.message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.UnavailableError: failed to connect to all addresses
Additional GRPC error information:
{""created"":""@1590962770.862373470"",""description"":""Failed to pick subchannel"",""file"":""third_party/grpc/src/core/ext/filters/client_channel/client_channel.cc"",""file_line"":3959,""referenced_errors"":[{""created"":""@1590962770.862371521"",""description"":""failed to connect to all addresses"",""file"":""third_party/grpc/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc"",""file_line"":394,""grpc_status"":14}]}
	 [[{{node MultiDeviceIteratorGetNextFromShard}}]]
	 [[RemoteCall]]
2020-05-31 22:06:10.972287: W tensorflow/core/distributed_runtime/eager/remote_tensor_handle_data.cc:76] Unable to destroy remote tensor handles. If you are running a tf.function, it usually indicates some op in the graph gets an error: failed to connect to all addresses
Additional GRPC error information:
{""created"":""@1590962770.862373470"",""description"":""Failed to pick subchannel"",""file"":""third_party/grpc/src/core/ext/filters/client_channel/client_channel.cc"",""file_line"":3959,""referenced_errors"":[{""created"":""@1590962770.862371521"",""description"":""failed to connect to all addresses"",""file"":""third_party/grpc/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc"",""file_line"":394,""grpc_status"":14}]}
	 [[{{node MultiDeviceIteratorGetNextFromShard}}]]
	 [[RemoteCall]]
```
**Describe the expected behavior**
The code works without any problem with CPUs. The data is stored on the VM not on the GCS bucket.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40032,Regression on tf-nightly when using Cloud TPU and writing to GCS,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 4.19.118-2
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): tf-nightly==2.3.0.dev20200531
- Python version: 3.7.3
- GPU model and memory: v3-8 TPU on Google Cloud

**Describe the current behavior**
Following the [MNIST with TPUs tutorial](https://cloud.google.com/tpu/docs/quickstart) using tf-nightly + tf-models-nightly I get the following exception when training the model with a TPU (see full log at end of issue):
`tensorflow.python.framework.errors_impl.InternalError: Unexpected response from GCS when writing to gs://bert-data-for-grover-daniel-191017/mnist/: 'Location' header not returned.`

- *Using a CPU/GPU the above code works fine.*
- *Using TF=2.2.0 and its respective TF-Models' tag works fine as well.*

I should stress that I'm linking to the tutorial because it's a simple script that reproduces the issue. This also affects my own project, and I have spent the last 24 hours going through my own code before thinking that it might be a bug in tensorflow / TPU drivers. I would also like to add that it might still be a misconfiguration on my part related to my Google Cloud setup (though I've already went through the basics of setting the correct permissions), but even if that's the case I believe TF's exceptions should be more relevant than the cryptic ""Location header not returned"" string, which seems too low-level.

Looking through other issues, the only one in the past that seems relevant is #29304, though there the exception is always thrown when trying to write to the bucket, while here it's only when using TPUs (as mentioned above, it works fine with CPU/GPU).

**Standalone code to reproduce the issue**
See above tutorial for reproducing error while using the latest tf-nightly and tf-models-nightly.

**Other info / logs** Include any logs or source code that would be helpful to
Full log when running mnist_main.py (replacing my actual bucket name with <bucket name>):
```
(venv) or@instance-6-tf-nightly:~/models/official/vision/image_classification$ python3 mnist_main.py \
>   --tpu=$TPU_NAME \
>   --model_dir=$MODEL_DIR \
>   --data_dir=$DATA_DIR \
>   --train_epochs=10 \
>   --distribution_strategy=tpu \
>   --download
2020-05-31 18:12:25.684123: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-05-31 18:12:25.684174: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
I0531 18:12:27.662264 139671896655680 transport.py:157] Attempting refresh to obtain initial access_token
I0531 18:12:27.766179 139671896655680 transport.py:157] Attempting refresh to obtain initial access_token
2020-05-31 18:12:27.836011: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-05-31 18:12:27.836062: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)
2020-05-31 18:12:27.836083: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-6-tf-nightly): /proc/driver/nvidia/version does not exist
I0531 18:12:27.865279 139671896655680 transport.py:157] Attempting refresh to obtain initial access_token
I0531 18:12:27.951599 139671896655680 transport.py:157] Attempting refresh to obtain initial access_token
I0531 18:12:28.011914 139671896655680 remote.py:218] Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0
2020-05-31 18:12:28.012461: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-05-31 18:12:28.020191: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300000000 Hz
2020-05-31 18:12:28.020458: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x59b9fe0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-05-31 18:12:28.020490: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-05-31 18:12:28.030120: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.149.197.2:8470}
2020-05-31 18:12:28.030185: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:34872}
2020-05-31 18:12:48.223171: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.149.197.2:8470}
2020-05-31 18:12:48.223227: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:34872}
2020-05-31 18:12:48.223761: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:422] Started server with target: grpc://localhost:34872
INFO:tensorflow:Initializing the TPU system: node-2-test
I0531 18:12:48.225129 139671896655680 tpu_strategy_util.py:72] Initializing the TPU system: node-2-test
INFO:tensorflow:Clearing out eager caches
I0531 18:12:48.369003 139671896655680 tpu_strategy_util.py:100] Clearing out eager caches
INFO:tensorflow:Finished initializing TPU system.
I0531 18:12:54.483889 139671896655680 tpu_strategy_util.py:123] Finished initializing TPU system.
I0531 18:12:54.511550 139671896655680 transport.py:157] Attempting refresh to obtain initial access_token
I0531 18:12:54.605852 139671896655680 transport.py:157] Attempting refresh to obtain initial access_token
INFO:tensorflow:Found TPU system:
I0531 18:12:54.659763 139671896655680 tpu_system_metadata.py:159] Found TPU system:
INFO:tensorflow:*** Num TPU Cores: 8
I0531 18:12:54.659997 139671896655680 tpu_system_metadata.py:160] *** Num TPU Cores: 8
INFO:tensorflow:*** Num TPU Workers: 1
I0531 18:12:54.660263 139671896655680 tpu_system_metadata.py:161] *** Num TPU Workers: 1
INFO:tensorflow:*** Num TPU Cores Per Worker: 8
I0531 18:12:54.660351 139671896655680 tpu_system_metadata.py:163] *** Num TPU Cores Per Worker: 8
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)
I0531 18:12:54.660465 139671896655680 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)
I0531 18:12:54.660613 139671896655680 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)
I0531 18:12:54.660671 139671896655680 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)
I0531 18:12:54.660733 139671896655680 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)
I0531 18:12:54.660809 139671896655680 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)
I0531 18:12:54.660887 139671896655680 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)
I0531 18:12:54.660967 139671896655680 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)
I0531 18:12:54.661044 139671896655680 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)
I0531 18:12:54.661120 139671896655680 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)
I0531 18:12:54.661195 139671896655680 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)
I0531 18:12:54.661268 139671896655680 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)
I0531 18:12:54.661341 139671896655680 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)
I0531 18:12:54.661427 139671896655680 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)
I0531 18:12:54.974422 139671896655680 dataset_info.py:430] Load pre-computed DatasetInfo (eg: splits, num examples,...) from GCS: mnist/3.0.1
I0531 18:12:55.118813 139671896655680 dataset_info.py:361] Load dataset info from /tmp/tmpq933cjqntfds
I0531 18:12:55.120393 139671896655680 dataset_info.py:401] Field info.citation from disk and from code do not match. Keeping the one from code.
I0531 18:12:55.181865 139671896655680 dataset_builder.py:333] Generating dataset mnist (gs://<bucket name>/data/mnist/3.0.1)
Downloading and preparing dataset mnist/3.0.1 (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to gs://<bucket name>/data/mnist/3.0.1...
W0531 18:12:56.779903 139671896655680 dataset_builder.py:357] Dataset mnist is hosted on GCS. It will automatically be downloaded to your
local data directory. If you'd instead prefer to read directly from our public
GCS bucket (recommended if you're running on GCP), you can instead pass
`try_gcs=True` to `tfds.load` or set `data_dir=gs://tfds-data/datasets`.

Dl Completed...: 100%|██████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  4.35 file/s]
Dl Completed...: 100%|██████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  5.19 file/s]
I0531 18:12:57.596850 139671896655680 dataset_info.py:361] Load dataset info from gs://<bucket name>/data/mnist/3.0.1.incompleteIAR91Z
I0531 18:12:57.898775 139671896655680 dataset_info.py:401] Field info.citation from disk and from code do not match. Keeping the one from code.
Dataset mnist downloaded and prepared to gs://<bucket name>/data/mnist/3.0.1. Subsequent calls will reuse this data.
I0531 18:12:58.717931 139671896655680 dataset_builder.py:478] Constructing tf.data.Dataset for split ['train', 'test'], from gs://<bucket name>/data/mnist/3.0.1
2020-05-31 18:12:59.741571: I tensorflow/core/profiler/lib/profiler_session.cc:163] Profiler session started.
Traceback (most recent call last):
  File ""mnist_main.py"", line 171, in <module>
    app.run(main)
  File ""/home/or/models/venv/lib/python3.7/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/or/models/venv/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""mnist_main.py"", line 164, in main
    stats = run(flags.FLAGS)
  File ""mnist_main.py"", line 135, in run
    validation_freq=flags_obj.epochs_between_evals)
  File ""/home/or/models/venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py"", line 108, in _method_wrapper
    return method(self, *args, **kwargs)
  File ""/home/or/models/venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py"", line 1066, in fit
    steps=data_handler.inferred_steps)
  File ""/home/or/models/venv/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py"", line 226, in __init__
    self.set_model(model)
  File ""/home/or/models/venv/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py"", line 277, in set_model
    callback.set_model(model)
  File ""/home/or/models/venv/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py"", line 1951, in set_model
    self._write_keras_model_graph()
  File ""/home/or/models/venv/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py"", line 1989, in _write_keras_model_graph
    summary_ops_v2.keras_model('keras', self.model, step=0)
  File ""/home/or/models/venv/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py"", line 1155, in keras_model
    metadata=summary_metadata)
  File ""/home/or/models/venv/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py"", line 681, in write
    _should_record_summaries_v2(), record, _nothing, name=""summary_cond"")
  File ""/home/or/models/venv/lib/python3.7/site-packages/tensorflow/python/framework/smart_cond.py"", line 51, in smart_cond
    pred_value = smart_constant_value(pred)
  File ""/home/or/models/venv/lib/python3.7/site-packages/tensorflow/python/framework/smart_cond.py"", line 75, in smart_constant_value
    pred_value = tensor_util.constant_value(pred)
  File ""/home/or/models/venv/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py"", line 829, in constant_value
    return tensor.numpy()
  File ""/home/or/models/venv/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 1071, in numpy
    maybe_arr = self._numpy()  # pylint: disable=protected-access
  File ""/home/or/models/venv/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 1039, in _numpy
    six.raise_from(core._status_to_exception(e.code, e.message), None)  # pylint: disable=protected-access
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InternalError: Unexpected response from GCS when writing to gs://<bucket name>/mnist/: 'Location' header not returned.
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File ""/home/or/models/venv/lib/python3.7/site-packages/tensorflow/python/eager/context.py"", line 2270, in async_wait
    context().sync_executors()
  File ""/home/or/models/venv/lib/python3.7/site-packages/tensorflow/python/eager/context.py"", line 652, in sync_executors
    pywrap_tfe.TFE_ContextSyncExecutors(self._context_handle)
tensorflow.python.framework.errors_impl.InternalError: Unexpected response from GCS when writing to gs://<bucket name>/mnist/: 'Location' header not returned.
```
"
40031,Unexpected failure when preparing tensor allocations: tensorflow/lite/kernels/transpose.cc:,"I have trained an audio classification model using Keras & Tensorflow and converted it to Tensorflow lite, it is converted fine but when I run on Android I get this error:

```
 Process: org.tensorflow.lite.examples.speech, PID: 15170
    java.lang.IllegalStateException: Internal error: Unexpected failure when preparing tensor allocations: tensorflow/lite/kernels/transpose.cc:56 op_context->perm->dims->data[0] != dims (3 != 2)
    Node number 1 (TRANSPOSE) failed to prepare.
    
        at org.tensorflow.lite.NativeInterpreterWrapper.allocateTensors(Native Method)
        at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:145)
        at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:314)
```

**Usage:**

```
tfLite = try {
    tfliteOptions.setNumThreads(4)

    Interpreter(loadModelFile(assets, actualModelFilename), tfliteOptions)
} catch (e: Exception) {
    throw RuntimeException(e)
}

for (i in 0 until RECORDING_LENGTH) {
    floatInputBuffer[i][0] = inputBuffer[i] / 32767.0f
}

val inputArray = arrayOf<Any>(floatInputBuffer)
val outputMap: MutableMap<Int, Any> = HashMap()
outputMap[0] = outputScores

// Run the model.
tfLite?.runForMultipleInputsOutputs(inputArray, outputMap)
```


**Android Dependency:**

` implementation 'org.tensorflow:tensorflow-lite:2.2.0'`
       
**Python Requirements:**

```
tensorboard==2.1.1
tensorflow==2.1.0
tensorflow-estimator==2.1.0
```

**Model Conversion:**

    # Create a converter
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    converter.allow_custom_ops = True
    converter.experimental_new_converter = True

    # Convert the model
    tflite_model = converter.convert()

    # Create the tflite model file
    tflite_model_name = ""android/app/src/main/assets/converted_model.tflite""
    open(tflite_model_name, ""wb"").write(tflite_model)


**Model Summary:**

Model: ""long_short_term_memory""

|Layer (type)|Output Shape|Param #| Connected to|

|input (InputLayer) |             [(None, 1, 16000)]|   0    |                                        
melbands (Melspectrogram)       (None, 128, 100, 1)  296064      input[0][0]                      
batch_norm (Normalization2D)    (None, 128, 100, 1)  0           melbands[0][0]                   
permute (Permute)               (None, 100, 128, 1)  0           batch_norm[0][0]                 
reshape (TimeDistributed)       (None, 100, 128)     0           permute[0][0]                    
d_dense_tanh (TimeDistributed) (None, 100, 64)      8256        reshape[0][0]                    
bidirectional_lstm (Bidirection (None, 100, 64)      24832       td_dense_tanh[0][0]              
skip_connection (Concatenate)   (None, 100, 128)     0           td_dense_tanh[0][0]              
                                                                 bidirectional_lstm[0][0]         
dense_1_relu (Dense)            (None, 100, 64)      8256        skip_connection[0][0]            
max_pool_1d (MaxPooling1D)      (None, 50, 64)       0           dense_1_relu[0][0]               
dense_2_relu (Dense)            (None, 50, 32)       2080        max_pool_1d[0][0]                
flatten (Flatten)               (None, 1600)         0           dense_2_relu[0][0]               
dropout (Dropout)               (None, 1600)         0           flatten[0][0]                    
dense_3_relu (Dense)            (None, 32)           51232       dropout[0][0]                    
softmax (Dense)                 (None, 2)            66          dense_3_relu[0][0]               

Total params: 390,786
Trainable params: 390,786
Non-trainable params: 0

**Complete Python & Android Code can be found here:**
[TensorFlow Lite Audio Classification](https://github.com/umair13adil/Audio-Classification)"
40030,models.metrics,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.2.0
- Python version: 3.7.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1/ V10.1.105
- GPU model and memory: Geforce MX110 2GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
I created a simple model using tf.keras Sequential API and printed its metrics but it is outputting an empty list. No matter what I try, It returns an empty list.
```
[]
```
**Describe the expected behavior**
It should return 
```
[<tensorflow.python.keras.metrics.BinaryAccuracy at 0x7f3e5e218320>,
 <tensorflow.python.keras.metrics.MeanAbsoluteError at 0x7f3e5c063a20>]
```
**Standalone code to reproduce the issue**
```python3
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, MaxPool2D
model = Sequential([
    Conv2D(16,(3,3),padding='same', input_shape=(1,28,28),data_format='channels_first'),
    MaxPooling2D((3,3), data_format='channels_first')
])
opt = tf.keras.optimizers.Adam(learning_rate=0.005)
model.compile(optimizer=opt,
              loss=tf.keras.losses.BinaryCrossentropy(),
              metrics=[tf.keras.metrics.BinaryAccuracy(),
              tf.keras.metrics.MeanAbsoluteError()]
              )
print(model.metrics)
```
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40028,Tensorflow after built from source in High Sierra won't import in Jupyter notebook,"Hello and i would to apologise if this is not the right place to ask the question i have but it is my first time writing to ask for help.

Getting to my question, i built tensorflow from source in my macbook pro (mid 10) which is running on High Sierra 10.13.6. After installing tensorflow it imports without problems in python from terminal but when i open jupyter notebook and i try to import it from there it does not recognise tensorflow giving the impression as it was never installed. I looked it up before asking here and with sys.executable notebook and python use the same executables. 

An odd but interesting thing is that when i create a jupyter .ipynb file in the ""/Users/mac"" directory where tensorflow directory lies after source installation it loads tensorflow without problems.Elsewhere when creating a .ipynb in my laptop, tensorflow does not import.

Finally the ""tf.__ version __ "" won't show me my tensorflow version nowhere not even when i import it througth the terminal.

Thank you in advance for your answers."
40027,TF2.2 HALT TRAINING ON 2 2080TI+NVLINK BRIDGE,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):NO 
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): LINUX UBUNTU 20.04LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NO
- TensorFlow installed from (source or binary): pip3 install tensorflow
- TensorFlow version (use command below): 2.2
- Python version: 3.8 
- Bazel version (if compiling from source): NO 
- GCC/Compiler version (if compiling from source): GCC7
- CUDA/cuDNN version: 10.1/7.6.5/  NCCL  2.6.4
- GPU model and memory: 2 X 2080ti 11GB + NVLINK BRIDGE



**Describe the current behavior**
the training halt at ""model.fit()"", and then the Linux halt, no response to my mouse, keyboard, I have to reboot.
**Describe the expected behavior**
Training should be running.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

CODE is TF2.2 official example :
https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/distribute/keras.ipynb
With TF2.2, CUDA 10.1, CUDNN NEWEST WITH CUDA 10.1 ,7.6.5 
NCCL  2.6.4 
 Linux Ubuntu 20.04 LTS.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

If I remove NVLINK, reboot , the above code runs fine, and 2 GPU have load.

and I tested NVLINK bridge with CUDA's utility code for NVLINK speed , I think NVLINK is functional and the 2 GPU's peer to peer speed is fast.

the LOG can't be obtained ,because I have to reboot my computer ,the whole Linux system halt ,and had no response ."
40026,Cannot build TensorFlow Lite iOS framework for benchmark tool due to '@XNNPACK//:neonv8_ukernels' rule compilation failure,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS 10.14.6
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: none
- TensorFlow installed from (source or binary): source
- TensorFlow version: master (edbe5e189c1ec14d3a3386aa29e6118d807d9379)
- Python version: 3.7.7 (also fails in the same way with 2.7.16)
- Installed using virtualenv? pip? conda?: not installed
- Bazel version (if compiling from source): 3.0.0
- GCC/Compiler version (if compiling from source): Apple clang version 11.0.0 (clang-1100.0.33.17)
- CUDA/cuDNN version: none
- GPU model and memory: AMD Radeon R9 M370X 2 GB



**Describe the problem**
Building the benchmark framework for the TFLite iOS benchmark app (https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/benchmark/ios) fails with 'C++ compilation of rule '@XNNPACK//:neonv8_ukernels' failed'. XNNPack has been upgraded in April to fix an AArch64 compilation issue (#38400 #38436), perhaps this is the cause?

**Provide the exact sequence of commands / steps that you executed before running into the problem**

`./tensorflow/lite/tools/benchmark/ios/build_benchmark_framework.sh`

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

```
$ ./configure 

You have bazel 3.0.0 installed.
Please specify the location of python. [Default is /usr/local/opt/python/bin/python3.7]: 


Found possible Python library paths:
  /usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages
Please input the desired Python library path to use.  Default is [/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages]

Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: 
No OpenCL SYCL support will be enabled for TensorFlow.

Do you wish to build TensorFlow with ROCm support? [y/N]: 
No ROCm support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: 
No CUDA support will be enabled for TensorFlow.

Do you wish to download a fresh release of clang? (Experimental) [y/N]: 
Clang will not be downloaded.

Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native -Wno-sign-compare]: 


Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: N
Not configuring the WORKSPACE for Android builds.

Do you wish to build TensorFlow with iOS support? [y/N]: y
iOS support will be enabled for TensorFlow.

Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details.
	--config=mkl         	# Build with MKL support.
	--config=monolithic  	# Config for mostly static monolithic build.
	--config=ngraph      	# Build with Intel nGraph support.
	--config=numa        	# Build with NUMA support.
	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects.
	--config=v2          	# Build TensorFlow 2.x instead of 1.x.
Preconfigured Bazel build configs to DISABLE default on features:
	--config=noaws       	# Disable AWS S3 filesystem support.
	--config=nogcp       	# Disable GCP support.
	--config=nohdfs      	# Disable HDFS support.
	--config=nonccl      	# Disable NVIDIA NCCL support.
Configuration finished

$ ./tensorflow/lite/tools/benchmark/ios/build_benchmark_framework.sh

++ bazel info workspace
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=0 --terminal_columns=80
INFO: Reading rc options for 'info' from /Users/valentinmiu/2019/tensorflow/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'info' from /Users/valentinmiu/2019/tensorflow/.bazelrc:
  Inherited 'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=v2
INFO: Reading rc options for 'info' from /Users/valentinmiu/2019/tensorflow/.tf_configure.bazelrc:
  Inherited 'build' options: --action_env PYTHON_BIN_PATH=/usr/local/opt/python/bin/python3.7 --action_env PYTHON_LIB_PATH=/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages --python_path=/usr/local/opt/python/bin/python3.7 --config=xla --action_env TF_CONFIGURE_IOS=1
INFO: Found applicable config definition build:v2 in file /Users/valentinmiu/2019/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:xla in file /Users/valentinmiu/2019/tensorflow/.bazelrc: --action_env=TF_ENABLE_XLA=1 --define=with_xla_support=true
INFO: Found applicable config definition build:macos in file /Users/valentinmiu/2019/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14
+ WORKSPACE_ROOT=/Users/valentinmiu/2019/tensorflow
+ BENCHMARK_DIR=tensorflow/lite/tools/benchmark
+ DEST_DIR=tensorflow/lite/tools/benchmark/ios/TFLiteBenchmark/TFLiteBenchmark/Frameworks
+ FRAMEWORK_TARGET=TensorFlowLiteBenchmarkC_framework
+ PROFILING_ARGS=
+ getopts p opt_name
+ shift 0
+ pushd /Users/valentinmiu/2019/tensorflow
~/2019/tensorflow ~/2019/tensorflow
+ bazel build --config=ios_fat -c opt //tensorflow/lite/tools/benchmark/experimental/ios:TensorFlowLiteBenchmarkC_framework
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=272
INFO: Reading rc options for 'build' from /Users/valentinmiu/2019/tensorflow/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /Users/valentinmiu/2019/tensorflow/.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=v2
INFO: Reading rc options for 'build' from /Users/valentinmiu/2019/tensorflow/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/usr/local/opt/python/bin/python3.7 --action_env PYTHON_LIB_PATH=/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages --python_path=/usr/local/opt/python/bin/python3.7 --config=xla --action_env TF_CONFIGURE_IOS=1
INFO: Found applicable config definition build:v2 in file /Users/valentinmiu/2019/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:xla in file /Users/valentinmiu/2019/tensorflow/.bazelrc: --action_env=TF_ENABLE_XLA=1 --define=with_xla_support=true
INFO: Found applicable config definition build:ios_fat in file /Users/valentinmiu/2019/tensorflow/.bazelrc: --config=ios --ios_multi_cpus=armv7,arm64,i386,x86_64
INFO: Found applicable config definition build:ios in file /Users/valentinmiu/2019/tensorflow/.bazelrc: --apple_platform_type=ios --apple_bitcode=embedded --copt=-fembed-bitcode --copt=-Wno-c++11-narrowing --noenable_platform_specific_config --copt=-w --cxxopt=-std=c++14 --host_cxxopt=-std=c++14
INFO: Build option --action_env has changed, discarding analysis cache.
INFO: Analyzed target //tensorflow/lite/tools/benchmark/experimental/ios:TensorFlowLiteBenchmarkC_framework (115 packages loaded, 9402 targets configured).
INFO: Found 1 target...
ERROR: /private/var/tmp/_bazel_valentinmiu/94cd6c8db58787268db4435bda1fd58c/external/XNNPACK/BUILD.bazel:2048:1: C++ compilation of rule '@XNNPACK//:neonv8_ukernels' failed (Exit 1)
external/XNNPACK/src/math/roundne-neonv8.c:24:23: error: initializing 'const float32x4_t' (vector of 4 'float32_t' values) with an expression of incompatible type 'int'
    const float32x4_t vy = vrndnq_f32(vx);
                      ^    ~~~~~~~~~~~~~~
1 error generated.
Target //tensorflow/lite/tools/benchmark/experimental/ios:TensorFlowLiteBenchmarkC_framework failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 1327.686s, Critical Path: 96.87s
INFO: 5060 processes: 5060 local.
FAILED: Build did NOT complete successfully```
"
40025,"Same labels and predictions, non-zero loss","```python
import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Input, Dense, Flatten
from tensorflow.keras.models import Model

#%%#######################################################
ipt = Input(batch_shape=(128, 28, 28, 1))
x   = Flatten()(ipt)
out = Dense(10, activation='softmax')(x)
model = Model(ipt, out)
model.compile('adam', 'categorical_crossentropy')

#%%#######################################################
x = np.random.uniform(0, 1, model.input_shape)
pred = model(x, training=True)  # =False also works
loss = model.compiled_loss(pred, pred)

print(tf.__version__)
print(loss)
```

```python
2.3.0-dev20200531  # Colab; also reproduced in 2.2.0, Win-10
tf.Tensor(1.9904033, shape=(), dtype=float32)
```

What's the deal?"
40024,"How to set batch_bize best. I get leakage in old Cuda versions, allocated memory consumption error in new  Cuda versions.","Cuda :10.0.0
Tensorflow :  1.14.0
Keras :  2.3.1
Python=3.6.4
Nvidia GeForce GTX 970

Keras Model InceptionV3, Epoch 10, BatchSize=80, ImageSize=(170,170,3), Activation softplus, Optimizer Adam, Loss Function Categorical_crossentropy, Learning_rate=0.0001,

...
2020-05-31 15:32:23.841070: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 9 Chunks of size 12582912 totalling 108.00MiB
2020-05-31 15:32:23.843941: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 14826240 totalling 14.14MiB
2020-05-31 15:32:23.846970: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 18137088 totalling 17.30MiB
2020-05-31 15:32:23.852014: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 18393856 totalling 17.54MiB
2020-05-31 15:32:23.855604: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 21233664 totalling 20.25MiB
2020-05-31 15:32:23.858570: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 3 Chunks of size 23887872 totalling 68.34MiB
2020-05-31 15:32:23.862554: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 24526848 totalling 23.39MiB
2020-05-31 15:32:23.865774: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 28164096 totalling 26.86MiB
2020-05-31 15:32:23.871765: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 32768000 totalling 62.50MiB
2020-05-31 15:32:23.874621: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 33293824 totalling 31.75MiB
2020-05-31 15:32:23.879541: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 55083008 totalling 105.06MiB
2020-05-31 15:32:23.886215: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 57802752 totalling 110.25MiB
2020-05-31 15:32:23.891302: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 70975488 totalling 135.38MiB
2020-05-31 15:32:23.894429: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 71203584 totalling 67.90MiB
2020-05-31 15:32:23.897584: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 83172096 totalling 79.32MiB
2020-05-31 15:32:23.902251: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 98283008 totalling 93.73MiB
2020-05-31 15:32:23.906031: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 105160704 totalling 100.29MiB
2020-05-31 15:32:23.909807: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 110166016 totalling 105.06MiB
2020-05-31 15:32:23.912743: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 206682368 totalling 197.11MiB
2020-05-31 15:32:23.915783: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 220082688 totalling 209.89MiB
2020-05-31 15:32:23.922903: I tensorflow/core/common_runtime/bfc_allocator.cc:816] Sum Total of in-use chunks: 2.93GiB
2020-05-31 15:32:23.925769: I tensorflow/core/common_runtime/bfc_allocator.cc:818] total_region_allocated_bytes_: 3150400512 memory_limit_: 3150400716 available bytes: 204 curr_region_allocation_bytes_: 6300801536
2020-05-31 15:32:23.931420: I tensorflow/core/common_runtime/bfc_allocator.cc:824] Stats:
Limit:                  3150400716
InUse:                  3148202496
MaxInUse:               3150392320
NumAllocs:                  545033
MaxAllocSize:           2255688704

2020-05-31 15:32:23.944922: W tensorflow/core/common_runtime/bfc_allocator.cc:319] **********************************xx*********xx**********x******************************************
2020-05-31 15:32:23.951512: W tensorflow/core/framework/op_kernel.cc:1502] OP_REQUIRES failed at concat_op.cc:153 : Resource exhausted: OOM when allocating tensor with shape[64,2048,3,3] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
**************************************************************************
**************************************************************************
Cuda :10.1.0
Tensorflow :  2.1.0
The others parameters same.

2020-05-30 14:14:25.050571: I tensorflow/core/common_runtime/bfc_allocator.cc:958] 1 Chunks of size 166842368 totalling 159.11MiB
2020-05-30 14:14:25.054540: I tensorflow/core/common_runtime/bfc_allocator.cc:958] 1 Chunks of size 177561600 totalling 169.34MiB
2020-05-30 14:14:25.058475: I tensorflow/core/common_runtime/bfc_allocator.cc:958] 1 Chunks of size 194433024 totalling 185.43MiB
2020-05-30 14:14:25.063757: I tensorflow/core/common_runtime/bfc_allocator.cc:962] Sum Total of in-use chunks: 2.60GiB
2020-05-30 14:14:25.068505: I tensorflow/core/common_runtime/bfc_allocator.cc:964] total_region_allocated_bytes_: 3138866176 memory_limit_: 3138866380 available bytes: 204 curr_region_allocation_bytes_: 6277732864
2020-05-30 14:14:25.074911: I tensorflow/core/common_runtime/bfc_allocator.cc:970] Stats:
Limit:                  3138866380
InUse:                  2792979456
MaxInUse:               3138865664
NumAllocs:                  790450
MaxAllocSize:           2361825536

2020-05-30 14:14:25.081733: W tensorflow/core/common_runtime/bfc_allocator.cc:429] **************************************************************__*****x*************x*_********xx*___
2020-05-30 14:14:25.087205: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at conv_grad_input_ops.cc:1108 : Resource exhausted: OOM when allocating tensor with shape[16,64,170,170] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
2020-05-30 14:14:25.096432: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Resource exhausted: OOM when allocating tensor with shape[16,64,170,170] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
         [[{{node gradients_13/block1_conv2_13/convolution_grad/Conv2DBackpropInput}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.




"
40023,OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed,"**code below**
```
@tf.function
  def train_step(self, batch):
    with tf.GradientTape() as disc_tape, tf.GradientTape() as infe_tape, tf.GradientTape() as gener_tape:
      loss_encoder, loss_decoder, loss_disc = self.compute_loss(batch)

      grad_encoder = gener_tape.gradient(loss_encoder, self.model.inference_net.trainable_variables)
      grad_decoder = infe_tape.gradient(loss_decoder, self.model.generative_net.trainable_variables)
      grad_disc = disc_tape.gradient(loss_disc, self.model.discriminator.trainable_variables)

      self.infe_optimizer.apply_gradients(zip(grad_encoder, self.model.inference_net.trainable_variables))
      self.genr_optimizer.apply_gradients(zip(grad_decoder, self.model.generative_net.trainable_variables))
      self.disc_optimizer.apply_gradients(zip(grad_disc, self.model.discriminator.trainable_variables))

      return loss_encoder, loss_decoder, loss_disc

  @tf.function
  def train(self, epoch):
    loss_history = tf.zeros([3,0])
    for batch in self.train_dataset:
      loss_encoder, loss_decoder, loss_disc = self.train_step(batch)
      loss_each = tf.expand_dims(tf.stack([loss_encoder, loss_decoder, loss_disc], axis=0), 1)
      loss_history = tf.concat([loss_history, loss_each], axis=1)

    mean_loss_encoder, mean_loss_decoder, mean_loss_disc = tf.reduce_mean(loss_history, axis=1)
    tf.summary.scalar('encoder loss', data=mean_loss_encoder, step=epoch, description='train_loss')
    tf.summary.scalar('decoder loss', data=mean_loss_decoder, step=epoch, description='train_loss')
    tf.summary.scalar('discriminator loss', data=mean_loss_disc, step=epoch, description='train_loss')
    print('encoder training loss %.5f' % mean_loss_encoder, 'decoder training loss %.5f' % mean_loss_decoder, 'discriminator training loss %.5f' % mean_loss_disc)

  @tf.function
  def validation_step(self, batch):
     return self.compute_loss(batch, training=tf.constant(False, tf.bool))

  @tf.function
  def validation(self, epoch):
    '''produce mean loss for epoch and append to self.val_loss_monior'''

    loss_history = tf.zeros([3,0])
    for batch in self.validation_dataset:
        loss_encoder, loss_decoder, loss_disc = self.validation_step(batch)
        loss_each = tf.expand_dims(tf.concat([loss_encoder, loss_decoder, loss_disc], axis=0), 1)
        loss_history = tf.concat([loss_history, loss_each], axis=1) 
    mean_loss_each = tf.reduce_mean(loss_history, axis=1)
    print('encoder validation loss %.5f' % mean_loss_each[0], 'decoder validation loss %.5f' % mean_loss_each[1], 'discriminator validation loss %.5f' % mean_loss_each[2])

    tf.summary.scalar('encoder loss', data=mean_loss_each[0], step=epoch, description='val_loss')
    tf.summary.scalar('decoder loss', data=mean_loss_each[1], step=epoch, description='val_loss')
    tf.summary.scalar('discriminator loss', data=mean_loss_each[2], step=epoch, description='val_loss')

    # self.val_loss_monior: (3, self.patience), each row store history loss for each network
    loss_each = tf.expand_dims(mean_loss_each, 1)
    if epoch + 1 > self.patience:
      is_less =  self.val_loss_monior < loss_each
      is_less_encoder, is_less_decoder, is_less_discriminator = list(map(lambda x: tf.raw_ops.Any(input=tf.cast(tf.squeeze(x), tf.bool), axis=0), tf.split(is_less, 3, axis=0)))

      if not is_less_encoder:
         self.infe_optimizer.learning_rate *= self.decay_rate
      if not is_less_decoder:
         self.genr_optimizer.learning_rate *= self.decay_rate
      if not is_less_discriminator:
         self.disc_optimizer.learning_rate *= self.decay_rate
    
    self.val_loss_monior = tf.slice(self.val_loss_monior, [0, 1], [3, self.patience - 1])
    self.val_loss_monior = tf.concat([self.val_loss_monior, loss_each], axis=1)

    tf.summary.scalar('encoder learning rate', data=self.infe_optimizer.learning_rate, step=epoch)
    tf.summary.scalar('decoder learning rate', data=self.genr_optimizer.learning_rate, step=epoch)
    tf.summary.scalar('discriminator learning rate', data=self.disc_optimizer.learning_rate, step=epoch)

  def generate_images(self, epoch):
    predictions = self.model.sample(16, training=False)
    fig = plt.figure(figsize=(4,4))
    for i in range(predictions.shape[0]):
        plt.subplot(4, 4, i+1)
        plt.imshow(predictions[i])
        plt.axis('off')
    plt.savefig('image_at_epoch_{:03d}.png'.format(epoch))
    plt.show()

  @tf.function
  def fit(self):
    self.val_loss_monitor = tf.zeros([3, self.patience])
    for epoch in range(self.epochs):
      start = time.time()
      epoch = tf.cast(epoch, tf.int64)
      self.train(epoch)
      self.validation(epoch)

      print ('Time for epoch {} is {} sec'.format(epoch, time.time()-start))
      display.clear_output(wait=True)
      if (epoch + 1) % 5 == 0:
        self.generate_images(epoch)
```
**error massage below**
```


OperatorNotAllowedInGraphError: in user code:

    <ipython-input-5-8af39e045349>:152 fit  *
        self.train(epoch)
    <ipython-input-5-8af39e045349>:90 train  *
        mean_loss_encoder, mean_loss_decoder, mean_loss_disc = tf.reduce_mean(loss_history, axis=1)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:561 __iter__
        self._disallow_iteration()
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:554 _disallow_iteration
        self._disallow_when_autograph_enabled(""iterating over `tf.Tensor`"")
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:532 _disallow_when_autograph_enabled
        "" decorating it directly with @tf.function."".format(task))

    OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed: AutoGraph did not convert this function. Try decorating it directly with @tf.function.
```
The problem should be 
```
mean_loss_encoder, mean_loss_decoder, mean_loss_disc = tf.reduce_mean(loss_history, axis=1)
```
Error is about iterating over `tf.Tensor` is not allowed.
Is reduce_mean not working in tf.function?"
40022,"why pd  converted to cpkt, pd model detection effect is poor, nothing can be detected","
"
40020,TypeError: 'tuple' object is not callable,"tensorflow 2.0
pycharm 
python 3.7 


```
def run_train(dataset, num_epochs=2):
    start_time = time.perf_counter()
    model = VGGBase()
    for _ in tf.data.Dataset.range(num_epochs):
        for image,target in dataset: # (batch_size (N), 300, 300, 3)
            predicted_locs, predicted_socres = model(image) <============error here 
            print(predicted_locs,predicted_socres)
            pass
            break
        pass
    tf.print(""실행 시간:"", time.perf_counter() - start_time)

vgg16
class  VGGBase(Model):
    def __init__(self):
        super(VGGBase,self).__init__()
        self.conv1_1 = tf.keras.layers.Conv2D(3, kernel_size=3,padding='same',strides=1, activation='relu'),
        self.conv1_2 = tf.keras.layers.Conv2D(64, kernel_size=3, padding='same',strides=1,activation='relu'),
        self.pool1 = tf.keras.layers.MaxPool2D(2,2),

        self.conv2_1  =  tf.keras.layers.Conv2D(128, kernel_size=3, padding='same',strides= 1),
        self.conv2_2 = tf.keras.layers.Conv2D(128, kernel_size=3,padding='same',strides= 1),
        self.pool2 = tf.keras.layers.MaxPool2D(2,2),

        self.conv3_1 =  tf.keras.layers.Conv2D(256, kernel_size=3, padding='same',strides= 1),
        self.conv3_2 =  tf.keras.layers.Conv2D(256, kernel_size=3, padding='same',strides= 1),
        self.conv3_3 =  tf.keras.layers.Conv2D(256, kernel_size=3, padding='same',strides= 1),
        self.pool3 = tf.keras.layers.MaxPool2D(2,2),

        self.conv4_1 = tf.keras.layers.Conv2D(512, kernel_size=3, padding='same', strides=1),
        self.conv4_2 = tf.keras.layers.Conv2D(512, kernel_size=3, padding='same', strides=1),
        self.conv4_3 = tf.keras.layers.Conv2D(512, kernel_size=3, padding='same', strides=1),
        self.pool4 = tf.keras.layers.MaxPool2D(2, 2),

        self.conv5_1 = tf.keras.layers.Conv2D(512, kernel_size=3, padding='same', strides=1),
        self.conv5_2 = tf.keras.layers.Conv2D(512, kernel_size=3, padding='same', strides=1),
        self.conv5_3 = tf.keras.layers.Conv2D(512, kernel_size=3, padding='same', strides=1),
        self.pool5 = tf.keras.layers.MaxPool2D(2, 2),

        self.conv6 = tf.keras.layers.Conv2D(1024, kernel_size=3, padding='same',dilation_rate=6) # atrous convolution
        self.conv7 = tf.keras.layers.Conv2D(1024, kernel_size=1)

        #self.load_weights()
    def call(self,x):
        x = self.conv1_1(x)
        x = self.conv1_2(x)
        x = self.pool1(x)

        x = relu(self.conv2_1(x))
        x = relu(self.conv2_2(x))
        x = relu(self.pool2(x))

        x = relu(self.conv3_1(x))
        x = relu(self.conv3_2(x))
        x = relu(self.pool3(x))

        x = relu(self.conv4_1(x))
        x = relu(self.conv4_2(x))
        conv4_3_feats = x
        x = relu(self.pool4(x))

        x = relu(self.conv5_1(x))
        x = relu(self.conv5_2(x))
        x = relu(self.pool5(x))

        x = relu(self.conv6(x))
        x = relu(self.conv7(x))
        conv7_feats = x

        return conv4_3_feats, conv7_feats
```

File ""/home/jake/Gits/ssd_tensorflow/train.py"", line 36, in train
    run_train(dataset.map(resize_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(64).prefetch(tf.data.experimental.AUTOTUNE))
  File ""/home/jake/Gits/ssd_tensorflow/train.py"", line 22, in run_train
    predicted_locs, predicted_socres = model(image)# (N, 8732, 4), (N, 8732, n_classes)
  File ""/home/jake/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 891, in __call__
    outputs = self.call(cast_inputs, *args, **kwargs)
  File ""/home/jake/Gits/ssd_tensorflow/model.py"", line 38, in call
    x = self.conv1_1(x)
TypeError: 'tuple' object is not callable
"
40019,"When subclassing the `Model` class, you should implement a `call` method.","tf version: tf 2.1.0

```python
import tensorflow as tf

def sub_test_model():
    x = inputs = tf.keras.Input((5,), name='input')
    x = tf.keras.layers.Dense(8)(x)
    x = tf.keras.layers.Softmax()(x)
    
    return tf.keras.Model(inputs, x)  

def test_create_model():
    x = inputs = tf.keras.Input((3,), name='input')
    x = tf.keras.layers.Dense(5)(x)
    x = tf.keras.layers.Softmax()(x)
    
    x = sub_test_model()(x)
    
    return tf.keras.Model(inputs, x)


test_model = test_create_model()
test_model.save(""checkpoints/test_model"")
test_model_restore = tf.keras.models.load_model(""checkpoints/test_model"")
```

without sub_test_model, the model save/load will work fine. with the sub model, it will occur the following error.
![image](https://user-images.githubusercontent.com/731496/83344067-e3945f00-a334-11ea-813d-7819e99a7db9.png)
"
40017,Image recognition with TensorFlow Lite for Andorid,"0


I am new to Android Studio and TensorFlow lite, I have used google teachable machines to train some model an create my tflite files I started working form this git code that tensorflow provides for image-classification:

https://github.com/tensorflow/examples/tree/master/lite/examples/image_classification/android

And after following this tutorial:

https://codelabs.developers.google.com/codelabs/recognize-flowers-with-tensorflow-on-android/index.html?index=..%2F..index#0

My android phone can now recognise objects using the camera, I would like to add a feature so that the app would read the name on the Object Label using the ""text to speech"" function, I need this to help a blind person recognising object using this app, but the code is too complex and I don't know how to implement this, can anyone help me? this video show more ore less what the app is supposed to do: https://www.youtube.com/watch?v=sa4qGxQAlqs I only miss the text to speech feature"
40016,Overflow in tf.keras.layers.experimental.preprocessing.Normalization,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes (see below for code to reproduce).
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Windows 10 10.0.18363.836
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
N/A
- TensorFlow installed from (source or binary):
Binary ([conda](https://anaconda.org/anaconda/tensorflow-gpu))
- TensorFlow version (use command below):
unknown 2.1.0
- Python version:
3.6.10
- Bazel version (if compiling from source):
N/A
- GCC/Compiler version (if compiling from source):
N/A
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**

Using for a `tf.keras.layers.experimental.preprocessing.Normalization` layer `norm`, `norm.adapt(dataset)` encounters overflow warnings.

**Describe the expected behavior**

Calculate norm and standard deviation correctly.

**Standalone code to reproduce the issue**

```python
import numpy as np
import tensorflow as tf


def gen():
    for i in range(2 ** 13):
        array = np.random.random_sample(1024*1024*4).reshape(
            (1024, 1024, 4)).astype(np.float32)
        yield array * 1024 # Exacerbate the issue.

dataset = tf.data.Dataset.from_generator(
    gen, tf.float32, tf.TensorShape([1024, 1024, 4]))

dataset = dataset.batch(4)

norm = tf.keras.layers.experimental.preprocessing.Normalization()

norm.adapt(dataset)             # This ends up with RuntimeWarnings.

print(norm.mean)                  # Result is all 'inf'.
print(norm.variance)              # Result is 0.
```


**Other info / logs**

```
d:\local\envs\tf_2_1\lib\site-packages\tensorflow_core\python\keras\layers\preprocessing\normalization.py:181: RuntimeWarning: divide by zero encountered in true_divide
  ]) / combined_count
d:\local\envs\tf_2_1\lib\site-packages\tensorflow_core\python\keras\layers\preprocessing\normalization.py:190: RuntimeWarning: invalid value encountered in reduce
  variance_contribution(accumulator) for accumulator in accumulators
d:\local\envs\tf_2_1\lib\site-packages\tensorflow_core\python\keras\layers\preprocessing\normalization.py:187: RuntimeWarning: overflow encountered in square
  accumulator.variance + np.square(accumulator.mean - combined_mean))
d:\local\envs\tf_2_1\lib\site-packages\tensorflow_core\python\keras\layers\preprocessing\normalization.py:187: RuntimeWarning: invalid value encountered in multiply
  accumulator.variance + np.square(accumulator.mean - combined_mean))
<tf.Variable 'mean:0' shape=(4,) dtype=float32, numpy=array([inf, inf, inf, inf], dtype=float32)>
<tf.Variable 'variance:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>
```

The count overflow problem could potentially be mitigated by changing the dtype [here](https://github.com/tensorflow/tensorflow/blob/2b96f3662bd776e277f86997659e61046b56c315/tensorflow/python/keras/layers/preprocessing/normalization.py#L158) to int64,
"
40015,Error ImageDataGenerator in multiple GPU,"I have the following error when running code using multiple GPUs. I am using ImageDataGenerator to classify images that are separated by directories.
The error is:

Traceback (most recent call last):
  File ""new_train_alg_CNN.py"", line 113, in <module>
    train = model.fit_generator(generator=train_generator,steps_per_epoch = trai              n_generator.samples/BATCH_SIZE,validation_data=validation_generator,validation_s              teps=validation_generator.samples/BATCH_SIZE,epochs= 100,callbacks=[checkpoint,               early_stop],use_multiprocessing=True)
  File ""/root/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/pytho              n/util/deprecation.py"", line 324, in new_func
    return func(*args, **kwargs)
  File ""/root/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/pytho              n/keras/engine/training_v1.py"", line 1217, in fit_generator
    return self.fit(
  File ""/root/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/pytho              n/keras/engine/training_v1.py"", line 766, in fit
    return func.fit(
  File ""/root/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/pytho              n/keras/engine/training_distributed.py"", line 612, in fit
    dataset = model._distribution_standardize_user_data(
  File ""/root/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/pytho              n/keras/engine/training_v1.py"", line 2167, in _distribution_standardize_user_dat              a
    assert isinstance(x, dataset_ops.DatasetV2)
AssertionError
"
40014,DNNLinearCombinedClassifier serving input format,"I used the code below to train and export a DNNLinearCombinedClassifier model, but the input format is not what I want, **is there a way to export DNNLinearCombinedClassifier model to support serving input format like below?
'{""signature_name"":""xxx"", ""instances"":[{""feature1"": [1.0, 1.0, 1.0, 1.0..........], ""feature2"": [1.0, 1.0, 1.0, 1.0..........], ""feature3"": [1.0, 1.0, 1.0, 1.0..........]...........}]}'**
The idea is, we may post K records to server, but we don't need to repeat feature names for K times, we just need to post K feature values.
For exmple, we post data below to tf serving
'{""signature_name"":""xxx"", ""instances"":[{""feature1"": [1.0, 1.0, 1.0, 1.0], ""feature2"": [1.0, 1.0, 1.0, 1.0], ""feature3"": [1.0, 1.0, 1.0, 1.0]}]}'
We can get prediction result:
[0.1, 0.1, 0.1, 0.1]
My training and exporting code:
```
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
import sys
import os
import tensorflow as tf


tf.logging.set_verbosity(tf.logging.INFO)

ROOT_PATH = './Data/adult/'
TRAIN_PATH = ROOT_PATH + 'train.csv'
EVAL_PATH = ROOT_PATH + 'test.csv'
PREDICT_PATH = ROOT_PATH + 'predict.csv'
MODEL_PATH = '/tmp/adult_model'
EXPORT_PATH = '/tmp/adult_export_model'
_CSV_COLUMNS = [
    'age', 'workclass', 'fnlwgt', 'education', 'education_num',
    'marital_status', 'occupation', 'relationship', 'race', 'gender',
    'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',
    'income_bracket'
]

_CSV_COLUMN_DEFAULTS = [[0], [''], [0], [''], [0], [''], [''], [''], [''], [''],
                        [0], [0], [0], [''], [0]]

_HASH_BUCKET_SIZE = 1000

_NUM_EXAMPLES = {
    'train': 32561,
    'validation': 16281,
}


def build_model_columns():
    age = tf.feature_column.numeric_column('age')
    education_num = tf.feature_column.numeric_column('education_num')
    capital_gain = tf.feature_column.numeric_column('capital_gain')
    capital_loss = tf.feature_column.numeric_column('capital_loss')
    hours_per_week = tf.feature_column.numeric_column('hours_per_week')

    education = tf.feature_column.categorical_column_with_vocabulary_list(
        'education', [
            'Bachelors', 'HS-grad', '11th', 'Masters', '9th', 'Some-college',
            'Assoc-acdm', 'Assoc-voc', '7th-8th', 'Doctorate', 'Prof-school',
            '5th-6th', '10th', '1st-4th', 'Preschool', '12th'])

    marital_status = tf.feature_column.categorical_column_with_vocabulary_list(
        'marital_status', [
            'Married-civ-spouse', 'Divorced', 'Married-spouse-absent',
            'Never-married', 'Separated', 'Married-AF-spouse', 'Widowed'])

    relationship = tf.feature_column.categorical_column_with_vocabulary_list(
        'relationship', [
            'Husband', 'Not-in-family', 'Wife', 'Own-child', 'Unmarried',
            'Other-relative'])

    workclass = tf.feature_column.categorical_column_with_vocabulary_list(
        'workclass', [
            'Self-emp-not-inc', 'Private', 'State-gov', 'Federal-gov',
            'Local-gov', '?', 'Self-emp-inc', 'Without-pay', 'Never-worked'])

    occupation = tf.feature_column.categorical_column_with_hash_bucket(
        'occupation', hash_bucket_size=_HASH_BUCKET_SIZE)

    age_buckets = tf.feature_column.bucketized_column(
        age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])

    base_columns = [
        education, marital_status, relationship, workclass, occupation,
        age_buckets,
    ]

    crossed_columns = [
        tf.feature_column.crossed_column(
            ['education', 'occupation'], hash_bucket_size=_HASH_BUCKET_SIZE),
        tf.feature_column.crossed_column(
            [age_buckets, 'education', 'occupation'],
            hash_bucket_size=_HASH_BUCKET_SIZE),
    ]

    wide_columns = base_columns + crossed_columns

    deep_columns = [
        age,
        education_num,
        capital_gain,
        capital_loss,
        hours_per_week,
        tf.feature_column.indicator_column(workclass),
        tf.feature_column.indicator_column(education),
        tf.feature_column.indicator_column(marital_status),
        tf.feature_column.indicator_column(relationship),
        # To show an example of embedding
        tf.feature_column.embedding_column(occupation, dimension=8),
    ]

    return wide_columns, deep_columns


def input_fn(data_path, shuffle, num_epochs, batch_size):
    def parse_csv(value):
        columns = tf.decode_csv(value, record_defaults=_CSV_COLUMN_DEFAULTS)
        features = dict(zip(_CSV_COLUMNS, columns))
        labels = features.pop('income_bracket')
        # classes = tf.equal(labels, '>50K')  # binary classification
        return features, labels

    # Extract lines from input files using the Dataset API.
    dataset = tf.data.TextLineDataset(data_path)

    if shuffle:
        dataset = dataset.shuffle(buffer_size=_NUM_EXAMPLES['train'])

    dataset = dataset.map(parse_csv, num_parallel_calls=5)

    # We call repeat after shuffling, rather than before, to prevent separate
    # epochs from blending together.
    dataset = dataset.repeat(num_epochs)
    dataset = dataset.batch(batch_size)
    return dataset


def run():
    wide_columns, deep_columns = build_model_columns()

    config = tf.estimator.RunConfig(save_checkpoints_steps=100)
    estimator = tf.estimator.DNNLinearCombinedClassifier(model_dir=MODEL_PATH,
                                                         linear_feature_columns=wide_columns,
                                                         linear_optimizer=tf.train.FtrlOptimizer(learning_rate=0.01),
                                                         dnn_feature_columns=deep_columns,
                                                         dnn_hidden_units=[256, 64, 32, 16],
                                                         dnn_optimizer=tf.train.AdamOptimizer(learning_rate=0.001),
                                                         config=config)
    estimator.train(
        input_fn=lambda: input_fn(data_path=TRAIN_PATH, shuffle=True, num_epochs=40, batch_size=100), steps=2000)
    # Evaluate the model.
    eval_result = estimator.evaluate(
        input_fn=lambda: input_fn(data_path=EVAL_PATH, shuffle=False, num_epochs=1, batch_size=40))

    print('Test set accuracy:', eval_result)
    
    # Predict.
    pred_dict = estimator.predict(
        input_fn=lambda: input_fn(data_path=PREDICT_PATH, shuffle=False, num_epochs=1, batch_size=40))
    for pred_res in pred_dict:
        print(pred_res['probabilities'][1])

    columns = wide_columns + deep_columns
    feature_spec = tf.feature_column.make_parse_example_spec(feature_columns=columns)
    serving_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)
    estimator.export_savedmodel(EXPORT_PATH, serving_input_fn)


if __name__ == '__main__':
    run()
```"
40008,convert error,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- TensorFlow version (or github SHA if from source):


**Provide the text output from tflite_convert**

```
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CONV_2D, DEPTHWISE_CONV_2D, DIV, FLOOR, FULLY_CONNECTED, MAX_POOL_2D, MUL, RESHAPE, SUB. Here is a list of operators for which you will need custom implementations: RandomUniform.
```

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

Also, please include a link to a GraphDef or the model if possible.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem.
If including tracebacks, please include the full traceback. Large logs and files
should be attached.
"
40007,Is there a way to train large amount of variable size data in TF,"Hi, I am working on a model (structure shown below). I have 9 inputs, 8 is images whose size is (224,224,3) and the other is audio whose size is (1, 96, 1366). I use tf.keras to construct model following: `model = Model([image_1...image_8, audio_input], output)`
![image](https://user-images.githubusercontent.com/14579257/83305598-ed438880-a1b5-11ea-81ec-626acff96b11.png)

Since my data is too large, I use the `fit_generator` to train it (I know it is `fit` now, I use the old name for distinguishing from each other). 

Firstly I tried tensorflow dataset following below:
```
class BasicDatasetLight(object):
    def __init__(self, run_data, batch_size):
        """"""
        :param run_data: a dictionary storing the data info
        :param batch_size:
        """"""
        from os.path import splitext
        data_array = np.load(run_data[""data_file""], allow_pickle=True)
        self.run_info = run_data
        self.x, self.y = data_array[:,:-1], data_array[:,-1].astype(dtype=int)
        self.img_num = len(data_array[0][0])        # input image number
        _, self.image_type = splitext(data_array[0][0][0])      # input image type
        self.model_input_num = run_data[""input_num""]
        self.gen_out_type = self.__gen_out_type_shape()[0]     # get output type tuple
        self.gen_out_shape = self.__gen_out_type_shape()[1]     # get output shape tuple
        self.batch_size = batch_size

    def __len__(self):
        """"""
        generate batch number
        :return:
        """"""
        return len(self.x) // self.batch_size

    def __gen_out_type_shape(self):
        """"""
        generate output type tuple according the input
        :return:
        """"""
        peep_file = self.x[:,0][0][0]
        peep_shape = self.run_info[""image_shape""]
        peep_image = _tf_load_img(peep_file, peep_shape[0], decode_image=self.image_type)
        out_type = peep_image.dtype
        # type list [type] * image_input_num + [audio type]
        type_list = [out_type] * (len(peep_shape)*self.img_num) + [out_type]
        # shape list [shape] * image_input_num + [audio shape]
        shape_list = [peep_shape[0]]*(len(peep_shape)*self.img_num) + [self.run_info[""audio_shape""]]
        gen_out_shape = fake_gen_shape(shape_list)
        assert len(type_list)==self.model_input_num,""wrong input number""
        return (tuple(type_list),tf.int8), (gen_out_shape, tf.TensorShape(1,))

    def give_dataset(self):
        """"""
        serve the dataset to model
        :return:
        """"""
        ds = tf.data.Dataset.from_generator(
            lambda: _get_generator_light(self.x, self.y, self.run_info,self.image_type),
             output_types=self.gen_out_type,
             output_shapes=self.gen_out_shape)
        ds = ds.repeat()
        ds = ds.batch(self.batch_size, drop_remainder=True)
        ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
        return ds
```
The the methods starting with ""__"" are all internal functions. The `give_dataset` is the method serving dataset. It calls the `_get_generator_light` to form dataset from generator. The function is listed below:
```
def _tf_load_img(img_file, target_shape, decode_image="".jpg""):
    """"""
    tensorflow load image
    :param img_file:
    :param target_shape: (H x W x C) channel last
    :param decode_image: image extension for decoding mode
    :return:
    """"""
    image = tf.io.read_file(img_file)
    # image shape channel last
    if ""png"" in decode_image: image = tf.image.decode_png(image, channels=target_shape[-1])
    else: image = tf.image.decode_jpeg(image, channels=target_shape[-1])
    image = tf.cast(image, tf.float32)
    image = (image/127.5) - 1
    image = tf.image.resize(image, (target_shape[0], target_shape[1]))
    return image


def _get_generator_light(x, y, run_info, image_type="".jpg""):
    """"""
    a generator function for tensorflow dataset
    :param x:   input data
    :param y:   label
    :param run_info:    run information dictionary
    :param image_type:  image type for identifying decoding mode
    :return: ([input list], output)
    """"""
    # images number x copies (models may need different inputs) + audio input
    image_in,audio_in,y = x[:,0],x[:,1],y
    image_shape = run_info[""image_shape""]
    image_num = len(image_in[0])
    decode_image = image_type
    buff_size = len(image_shape)*image_num + 1
    for data_read_index in range(len(x)):
        # data_buff = np.empty(buff_size, dtype=object)
        data_buff = [None] * buff_size
        buff_index = 0
        for ii in range(image_num):
            for neti in range(len(image_shape)):
                image = _tf_load_img(image_in[data_read_index][ii],
                                     image_shape[neti],
                                     decode_image=decode_image)
                data_buff[buff_index] = image
                buff_index += 1
        data_buff[buff_index] = np.expand_dims(audio_in[data_read_index],axis=0)
        label = y[data_read_index]
        assert buff_index==buff_size-1, ""wrong data buff size""
        yield data_buff, label
```
NOTICE: `_get_generator_light` calls `_tf_load_img`, which is also listed. 
However, it shows the error:
```
Traceback (most recent call last):

  File ""/opt/anaconda3/envs/mau/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 795, in generator_py_func
    flattened_values = nest.flatten_up_to(output_types, values)

  File ""/opt/anaconda3/envs/mau/lib/python3.7/site-packages/tensorflow_core/python/data/util/nest.py"", line 396, in flatten_up_to
    assert_shallow_structure(shallow_tree, input_tree)

  File ""/opt/anaconda3/envs/mau/lib/python3.7/site-packages/tensorflow_core/python/data/util/nest.py"", line 324, in assert_shallow_structure
    check_types=check_types)

  File ""/opt/anaconda3/envs/mau/lib/python3.7/site-packages/tensorflow_core/python/data/util/nest.py"", line 299, in assert_shallow_structure
    ""Input has type: %s."" % type(input_tree))

TypeError: If shallow structure is a sequence, input must also be a sequence. Input has type: <class 'list'>.
```

Then I tried to use python generator:
```
class BasicGeneratorLight(tf.keras.utils.Sequence):
    def __init__(self, run_data, batch_size):
        """"""
        :param run_data: a dictionary storing the data info
        :param batch_size:
        """"""
        from os.path import splitext
        data_array = np.load(run_data[""data_file""], allow_pickle=True)
        self.run_info = run_data
        self.x, self.y = data_array[:,:-1], data_array[:,-1].astype(dtype=int)
        self.img_num = len(data_array[0][0])        # input image number
        _, self.image_type = splitext(data_array[0][0][0])      # input image type
        self.model_input_num = run_data[""input_num""]
        self.batch_size = batch_size

    def __len__(self):
        return len(self.x) // self.batch_size

    def __getitem__(self, idx):
        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]
        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]
        img_num = self.img_num    # check how many images we have
        imagenet_shapes = self.run_info[""image_shape""]      #  input shape for each image net (ORDER MATTERS!)
        imgnet_num = len(imagenet_shapes)
        input_num = img_num*imgnet_num+1
        model_data = np.empty(input_num,dtype=object)     # data buffer
        model_data_index = 0
        audio_buff = np.empty([self.batch_size] + list(self.run_info[""audio_shape""]), dtype=float)
        audio_read = True
        for ii in range(img_num):   # read every image
            for neti in range(imgnet_num):  # prepare for each image model
                image_buff = np.empty([self.batch_size] + list(imagenet_shapes[neti]), dtype=float)
                # load data per img
                for di in range(self.batch_size):
                    curr_imgfile = batch_x[di, 0][ii]
                    #image_buff[di, :, :, :] = _tf_load_img(curr_imgfile,
                    #                                       imagenet_shapes[neti], self.image_type)
                    image_buff[di, :, :, :] = _keras_load_img(curr_imgfile,
                                                              imagenet_shapes[neti],'vgg')  # use 'vgg' for all
                    if audio_read:
                        aud_len = batch_x[di, 1].shape[-1]
                        audio_buff[di, 0, :, :aud_len] = batch_x[di, 1]  # set channle axis to 0 as only mono channel
                audio_read = False  # disable audio_read after reading audio one time
                model_data[model_data_index] = image_buff
                model_data_index += 1
        model_data[model_data_index] = audio_buff  # append audio data to the end
        assert model_data_index==input_num-1, ""input number wrong""
        return list(model_data), batch_y
```
It finally can run the experiment, however, it gives the error:
```
2020-05-30 04:14:00.228692: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled
2020-05-30 04:14:00.232101: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled
2020-05-30 04:14:00.235563: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled
2020-05-30 04:14:00.238860: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled
```
I use 32 workers and max_queue_size 32. Though the experiment is running without stop, the error seems something wrong to me.

Without the generator way and tf.data way, how can I train my model?"
40006,custom operators by reference in tf2.2.0,"**System information**
- TensorFlow version (you are using): 2.2.0
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**

Following the [custom operator guide](https://www.tensorflow.org/guide/create_op) we learn how to build a custom operator.

However, the guide does not explain how to build custom operators when the input and output are passed by reference. In fact, following the [AssignOp](https://github.com/tensorflow/tensorflow/blob/7817237d5852c7778d3ba03c40f139e6f2c37a76/tensorflow/core/kernels/assign_op.h) as a naive example, we get errors concerning the impossibility to run it on eager mode and when using `@tf.function` / disabling eager that the input tensors must be mutable, even if the object we are passing is already a `tf.Variable`.

Searching for the `tf.Variable.assign` function in v2.2.0 we realize that its c++ operator is [AssignVariableOp](https://github.com/tensorflow/tensorflow/blob/7769f52b9f6433c4e97ae42ba2060034e357a071/tensorflow/core/kernels/resource_variable_ops.cc) which is interfaced in `gen_resource_variable_ops` (generated during compilation) and it performs the `tf.Variable` updates through a resource object mechanism.

As far as I understand, there is no simple side load mechanism for custom operators by reference without modifying the `gen_resource_variable_ops` / `resource_variable_ops.py`, thus I am wondering if there are less intrusive alternatives to this approach and the respective documentation.

**Will this change the current api? How?**

Probably yes.

**Who will benefit with this feature?**

Projects that require custom operators based on mutable objects.
"
40005,"Conflict python between Tensorflow, Spyder and Octave","Hello,
I am very new of python environment.
After some time spent learning python through Anaconda on Windows PC (in particular with Spyder), I also decided to learn Tensorflow, always in Spyder. So, I created a new dedicated environment for TF with the v3.6.9 and v1.17.2, respectively, for python and numpy.

I have never had problems running codes that require TF import with this configuration.
However, after some time, to use the Octave symbolic library I had to download Python from Microsoft Store. The downloaded version were 3.8.3 and I also installed the pip package from cmd. The symbolic package in Octave works, but from that moment when I run a code in Spyder that requires the import of tensorflow, I get the following error:

```
IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!

Importing the numpy C-extensions failed. This error can happen for
many reasons, often due to issues with your setup or how NumPy was
installed.

We have compiled some common reasons and troubleshooting tips at:

    https://numpy.org/devd_ocs/user/trou_bleshooting-importerror.html

Please note and check the following:

  * The Python version is: Python3.6 from ""C:\Users\ivang\.conda\envs\tensorflow_cpu\python.exe""
  * The NumPy version is: ""1.18.4""

and make sure that they are the versions you expect.
Please carefully study the documentation linked above for further help.

Original error was: No module named `'numpy.core._multiarray_umath_'
```

As suggested, checking my PATH and PYTHONPATH environment variables I obtained the paths in the attached picture. 
![PATHS](https://user-images.githubusercontent.com/47055464/83290215-999d6300-a1e6-11ea-92c7-b71af5a9f7a7.png)
These environment variables were not created by me, but by Python at the time of its stand-alone installation.

I understand that the problem is related to the different versions of python installed, but why this conflict happens if I created a dedicated environment in Anaconda, as explained at the beginning of the post? How can I solve this conflict using both TF in Spyder and the library in Octave on the same PC?

I tried to uninstall Python 3.8 but the environment variables remain and also the directory in C:\Program Files\Python38\ where site packages are installed.

Thank you so much for the help,
IG"
40004,Link error for libtensorflow_cc.so when using LoadSavedModel,"The version scripts don't export any symbols from protobuf. This is fine as long as basic functionality doesn't use symbols from protobuf, but LoadSavedModel seems to me to be a part of the basic functionality of tensorflow. Adding `*google*protobuf*` to the version scripts fixes the issue, as would hiding the protobuf data from the interface

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.2.0
- Python version: n/a
- Bazel version (if compiling from source): 2.0.0
- GCC/Compiler version (if compiling from source): GCC 7.5.0
- CUDA/cuDNN version: CUDA 10.1, cuDNN 7.6.3
- GPU model and memory: n/a

**Describe the current behavior**
When using the LoadSavedModel function from c++ and linking against tensorflow_cc.so, a link error appears saying `undefined reference to 'google::protobuf::internal::MapFieldBase::SyncMapWithRepeatedField() const'`

**Describe the expected behavior**
The program links and runs without issues

**Standalone code to reproduce the issue**
Any c++ program using LoadSavedModel and linking libtensorflow_cc.so will do"
40003,About the official document variable name introduced by Profiler is inconsistent！,"About the official document variable name introduced by Profiler is inconsistent！

Please see the URL：
[https://tensorflow.google.cn/guide/profiler?hl=en](https://tensorflow.google.cn/guide/profiler?hl=en)

![WechatIMG6](https://user-images.githubusercontent.com/61530230/83288790-8c986800-a216-11ea-94aa-0b6ddc2d4e51.png)

You can find problems with two variables：“tb_callback” and “tensorboard_callback” ！"
40002,The tf.keras.Model.compile metrics do not respect masking since TF 2.2,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **Yes**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Linux Debian Stable**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: --
- TensorFlow installed from (source or binary): **binary**
- TensorFlow version (use command below): **TF 2.2, TF-nightly 2.3.0-dev20200529**
- Python version: **3.7**

**Describe the current behavior**
The metrics passed to `tf.keras.Model.compile` as `metrics` do not respect model masks.

**Describe the expected behavior**
Until TF 2.1, these metrics did respect model masks.

**Standalone code to reproduce the issue**
Consider the following code which masks the input element.
```python
import numpy as np
import tensorflow as tf
print(tf.__version__)

model = tf.keras.Sequential([
    tf.keras.layers.Masking(1.),
    tf.keras.layers.Dense(1)
])
model.compile(optimizer=tf.optimizers.Adam(),
              loss=tf.losses.MeanSquaredError(),
              metrics=[tf.metrics.MeanSquaredError()],
              weighted_metrics=[tf.metrics.MeanSquaredError()])

print(model.train_on_batch(np.ones([1, 1]), np.ones([1, 1])))
```

TensorFlow until 2.1 masks also the metric in `metrics`, while TensorFlow 2.2 and later do not.
- TensorFlow 2.1 [(colab)](https://colab.research.google.com/drive/1q_CgkAh-wMdXy93ENXUBqU6JKWSPraBi?usp=sharing) prints `[0.0, 0.0, 0.0]`
- TensorFlow 2.2 [(colab)](https://colab.research.google.com/drive/1_iEw5yPbJInfjWAjmgYZijUjvqrzpjTZ?usp=sharing) prints `[0.0, 1.0, 0.0]`
- TensorFlow-Nightly 2.3.0-dev20200529 [(colab)](https://colab.research.google.com/drive/1d4_B_rxfRcPdJcCAFPNw2fV1_VG2kcVv?usp=sharing) prints `[0.0, 1.0, 0.0]`

**Other info / logs**
The logic of applying the mask in `master` is here:
https://github.com/tensorflow/tensorflow/blob/a1ae008076e14f7e445abf2605759779d2a1fb8b/tensorflow/python/keras/engine/compile_utils.py#L404-L414
The `metrics` do not get called with `sample_weight`, but that is the place where the masks are applied (in `apply_mask`).

On the other hand, in TF 2.1
https://github.com/tensorflow/tensorflow/blob/3ffdb91f122f556a74a6e1efd2469bfe1063cb5c/tensorflow/python/keras/engine/training.py#L2000-L2012
the `output_mask` was passed even for the unweighted metrics."
40001,cannot import name 'compiler',"Hello,

**System information**
I try to run a code on Google Colab. I'm using Tensorflow 2.2.0

When I try to run my code to import tensorflow_probability as tfp.

`import tensorflow_probability as tfp
import tensorflow as tf`

And then when I execute I get : 
`ImportError: cannot import name 'compiler' `



"
40000,"TFLite, 2.2.0, accuracy drops significantly when tf.lite.Optimize.DEFAULT option is used","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu
- TensorFlow installed from (source or binary):
- TensorFlow version (or github SHA if from source):


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

Colab:
https://colab.research.google.com/drive/1Z2Xvh2dufYR8y9U-9735KgBOGYYd9NtN#scrollTo=X-vMKEjgTIp0

```
import tensorflow as tf
print(tf.__version__)

from tensorflow.keras.applications import MobileNet
from tensorflow.keras.layers import *
from tensorflow.keras.models import *
import numpy as np
import random
import tensorflow_datasets as tfds

np.random.seed(42)
tf.random.set_seed(42)

train_ds, validation_ds = tfds.load(
    ""tf_flowers"",
    split=[""train[:90%]"", ""train[90%:]""],
    as_supervised=True
)

size = (224, 224)
train_ds = train_ds.map(lambda x, y: (tf.image.resize(x, size), y))
validation_ds = validation_ds.map(lambda x, y: (tf.image.resize(x, size), y))

def normalize_img(img, label):
    img = tf.cast(img, tf.float32) / 255.
    return (img, label)

train_ds = train_ds.map(normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE).\
    shuffle(1024).\
    batch(32).\
    prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
validation_ds = validation_ds.map(normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE).\
    batch(32).\
    prefetch(buffer_size=tf.data.experimental.AUTOTUNE)

base = MobileNet(weights=""imagenet"", include_top=False,
                    input_shape=(224, 224, 3))

def get_training_model():
    base.trainable = False
    class_head = base.output
    class_head = GlobalAveragePooling2D()(class_head)
    class_head = Dense(512, activation=""relu"")(class_head)
    class_head = Dropout(0.5)(class_head)
    class_head = Dense(5, activation=""softmax"")(class_head)

    classifier = Model(inputs=base.input, outputs=class_head)

    classifier.compile(loss=""sparse_categorical_crossentropy"", 
                          optimizer=""adam"",
                          metrics=[""accuracy""])

    return classifier

test_model = get_training_model()
history = test_model.fit(train_ds,
              validation_data=validation_ds,
              epochs=5)

test_model_dir = ""./test_model""
test_model.save(test_model_dir)

converter = tf.lite.TFLiteConverter.from_saved_model(test_model_dir)
converter.optimizations = [tf.lite.Optimize.DEFAULT]

quantized_tflite_model = converter.convert()
f = open(""test_model.tflite"", ""wb"")
f.write(quantized_tflite_model)
f.close()

# Referred from: https://www.tensorflow.org/lite/performance/post_training_integer_quant
def evaluate_model(interpreter):
    accurate_count = 0

    input_index = interpreter.get_input_details()[0][""index""]
    output_index = interpreter.get_output_details()[0][""index""]

    # Run predictions on every image in the ""test"" dataset.
    predictions = []
    for (val_images, val_labels) in validation_ds:
        for val_image, val_label in zip(val_images, val_labels):
            val_image = tf.expand_dims(val_image, 0)
            interpreter.set_tensor(input_index, val_image)

            # Run inference.
            interpreter.invoke()

            # Post-processing: remove batch dimension and find the digit with highest
            # probability.
            probability = interpreter.get_tensor(output_index)
            flower_id = np.argmax(probability[0])
            predictions.append(flower_id)

            # Compare prediction results with ground truth labels to calculate accuracy.
            if flower_id == val_label:
                accurate_count += 1
    
    accuracy = accurate_count * 1.0 / len(predictions)

    return accuracy

interpreter_test = tf.lite.Interpreter(model_path=""test_model.tflite"")
interpreter_test.allocate_tensors()

accuracy = evaluate_model(interpreter_test)
print(""accuracy is {}"".format(accuracy))

```

**The output from the converter invocation**

```
accuracy is 0.4332425068119891
```

**Failure details**
If I remove the line:
**converter.optimizations = [tf.lite.Optimize.DEFAULT]**
from the script, then 
accuracy is 0.9264305177111717

The converted model with this settings is wrong."
39999,Wrong output shape with ellipsis in tflite from keras models,"I'm working on converting a model using tflite, starting from a keras model, and I noticed that if I use ellipsis to slice up tensors something weird happens: once I loaded the tflite model inside the interpreter, before allocating tensors (through `interpreter.allocate_tensors`) calling the function `interpreter.get_output_details()` gives as output shape the same one that I got with my keras model, but after the tensor allocations `interpreter.get_output_details()` gives an output shape different from the one of the keras model. This does not happen if I use normal slicing instead of ellipsis.
I create a toy example for replicating this behavior:
```
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers
from tensorflow import keras

input_layer = keras.Input(shape=(3, 4))
X = layers.Dense(10)(input_layer)
X = layers.Dense(1)(X)[..., 0]      #      <-----------  with ellipsis
model = keras.Model(input_layer, X)
loss = keras.losses.MeanSquaredError()
optimizer = keras.optimizers.Adam()
model.compile(optimizer, loss=loss)
model.fit(
    np.random.random((10, 3, 4)).astype(np.float32),
    np.ones((10, 3)).astype(np.float32),
    epochs=10,
    batch_size=5,
)
tflite_model_multi = tf.lite.TFLiteConverter.from_keras_model(
    model
)
tflite_model_multi = tflite_model_multi.convert()

with open('my_model.tflite', 'wb') as fin:
    fin.write(tflite_model_multi)
interpreter = tf.lite.Interpreter(model_path='my_model.tflite')
print(interpreter.get_output_details())
interpreter.allocate_tensors()
print(interpreter.get_output_details())
```
outputs:
```
[{'name': 'Identity', 'index': 14, 'shape': array([1, 3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}}]
[{'name': 'Identity', 'index': 14, 'shape': array([1, 1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}}]
```
 Instead if in the same chunk of code I use slices:
```
...
X = layers.Dense(1)(X)[:, :, 0]      #      <-----------  without ellipsis
...
```
it outputs
```
[{'name': 'Identity', 'index': 14, 'shape': array([1, 3], dtype=int32), 'shape_signature': array([1, 3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]
[{'name': 'Identity', 'index': 14, 'shape': array([1, 3], dtype=int32), 'shape_signature': array([1, 3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]
```

I don't know if this behavior is wanted, but likely one can spend easily a couple of hours debugging around in order to find it."
39998,STOP UPDATING,"More updations, more pains!!!
"
39996,tf.Module break gradient registration,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab default

**Describe the current behavior**
When using operations within a tf.Module init, the gradient is broken

**Describe the expected behavior**
The gradient should still be registered properly

**Standalone code to reproduce the issue**
https://colab.research.google.com/drive/1X3DTc5-E-WadufSHUbVfBnVFEPQ0iOSR?usp=sharing
"
39995,broadcasting behavior in tensorflow keras layers vs base tensorflow operators,"ubuntu : 20.04
Tensorflow : 2.2.0

Tensorflow keras layers have different broadcasting semantics than numpy broadcasting (same as tensorflow core). Briefly speaking, AFAIK, broadcasting should keep adding a dimension on left hand side to the point where ndim of two arrays being operated on become equal and then the operation is carried out by required number of replications along all the axis of size 1. for example (5,10) + (2,5,10) would be changed to (1,5,10) + (2,5,10) and then (1,5,10) would be added to (2,5,10) by replicating itself along axis 2. But keras does not seem to follow this. Below is the code to reproduce the issue
```
from tensorflow import keras as k
from tensorflow.keras import layers as l
import tensorflow as tf
import numpy as np

inp = k.Input(shape=(10),dtype=tf.float32)
vec1 = tf.constant(np.arange(start=1000,stop=1010,dtype=np.float32).reshape(10,))
vec2 = tf.constant(np.arange(start=100,stop=110,dtype=np.float32).reshape(1,10))
ou1 = inp+vec1
ou2 = l.Add()([inp,vec1])
ou3 = inp+vec2
ou4 = l.Add()([inp,vec2])
out5 = vec1+vec2
print(ou1,'\n',ou2,'\n',ou3,'\n',ou4,'\n',ou5)
out6 = l.Add()([vec1,vec2])


```
output:
```
Tensor(""AddV2_55:0"", shape=(None, 10), dtype=float32) 
Tensor(""AddV2_56:0"", shape=(10, 10), dtype=float32) 
Tensor(""AddV2_57:0"", shape=(None, 10), dtype=float32) 
Tensor(""AddV2_58:0"", shape=(None, 10), dtype=float32) 
Tensor(""Add_1:0"", shape=(None, 10), dtype=float32)
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-49-0cd687be06bc> in <module>
     13 out5 = vec1+vec2
     14 print(ou1,'\n',ou2,'\n',ou3,'\n',ou4,'\n',ou5)
---> 15 out6 = l.Add()([vec1,vec2])
     16 

~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, *args, **kwargs)
    962         # Eager execution on data tensors.
    963         with backend.name_scope(self._name_scope()):
--> 964           self._maybe_build(inputs)
    965           cast_inputs = self._maybe_cast_inputs(inputs)
    966           with base_layer_utils.autocast_context_manager(

~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py in _maybe_build(self, inputs)
   2414         # operations.
   2415         with tf_utils.maybe_init_scope(self):
-> 2416           self.build(input_shapes)  # pylint:disable=not-callable
   2417       # We must set also ensure that the layer is marked as built, and the build
   2418       # shape is stored since user defined build functions may not be calling

~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py in wrapper(instance, input_shape)
    314     if input_shape is not None:
    315       input_shape = convert_shapes(input_shape, to_tuples=True)
--> 316     output_shape = fn(instance, input_shape)
    317     # Return shapes from `fn` as TensorShapes.
    318     if output_shape is not None:

~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/layers/merge.py in build(self, input_shape)
    100       raise ValueError(
    101           'Can not merge tensors with different '
--> 102           'batch sizes. Got tensors with shapes : ' + str(input_shape))
    103     if input_shape[0] is None:
    104       output_shape = None

ValueError: Can not merge tensors with different batch sizes. Got tensors with shapes : [(10,), (1, 10)]
```
"
39993,"TensorFlow 2.2.0 - Can't create layer of type ""Max"" in function 'getLayerInstance' OpenCV","**System information**
https://pastebin.com/QVAkgHib
- Tensorflow-GPU => 2.2.0
- OpenCV => 4.3.0-dev
- Operating System / Platform => Ubuntu 20.04
- Compiler => GCC 8.4.0

I have created a Triplet Model based on a ResNet50: 
```
    base_model = ResNet50(weights='imagenet', include_top=False, pooling='max')
    for layer in base_model.layers:
        layer.trainable = False
    x = base_model.output
    x = Dropout(0.6)(x)
    x = Dense(embedding_dim)(x)
    out = Lambda(lambda x: K.l2_normalize(x, axis=1))(x)
    embedding_model = Model(base_model.input, out, name=""embedding"")
```
After training this model, I froze all the layers and then saved it like this:
```
    for layer in embedding_model.layers:
        layer.trainable = False
    embedding_model.save('triplet_embedding_model')
```
which results in a folder containing a pb file and assets and variables folder.

Then I am using the following script to generate a frozen graph based on the model saved earlier: 
```
import tensorflow as tf
from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2
import os
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'


loaded = tf.saved_model.load('triplet_embedding_model')
infer = loaded.signatures['serving_default']

f = tf.function(infer).get_concrete_function(input_1=tf.TensorSpec(shape=[None, 224, 224, 3], dtype=tf.float32))
f2 = convert_variables_to_constants_v2(f)
graph_def = f2.graph.as_graph_def()

# Export frozen graph
with tf.io.gfile.GFile('frozen_graph.pb', 'wb') as f:
   f.write(graph_def.SerializeToString())
```
When I try to load the model in OpenCV using: 
```
net = cv2.dnn.readNet('frozen_graphs/frozen_graph.pb')
```
I get the following error: 
```
cv2.error: OpenCV(4.3.0-dev) /home/andreilica/OpenCV/opencv/modules/dnn/src/dnn.cpp:610: error: (-2:Unspecified error) Can't create layer ""StatefulPartitionedCall/StatefulPartitionedCall/embedding/max_pool/Max"" of type ""Max"" in function 'getLayerInstance'
```
What am I doing wrong here? "
39992,Suboptimal execution order of parallel map calls for tf.data,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 and Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.2
- Python version: 3.6.7
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
When using a num_parallel_calls larger than the number of worker threads in the threadpool in a Dataset.map call, the order of execution is more or less random, causing a busty output behavior.

If the dataset map transform has a list of 20 elements to process, it typically processes them in a order that looks something like this:
5, 4, 7, 6, 1, 0, 2, 3, 18, 15, 10, 9, 13, 19, 14, 8, 17, 10, 12, 11

This is problematic since the output has to be contiguous, so no output will be available until a large portion of the calls in the threadpool have been processed.

I have attached a file with a self contained example which reproduces this behavior.

There are workarounds, such as allowing non-deterministic output, but in the long run, we want our trainings to be as deterministic as possible to aid debugging, so fixing this behavior would be very helpful for us.


**Describe the expected behavior**
I expect the map call to start processing the next unprocessed element in the dataset whenever it has a free worker thread, so the results can be made available as soon as possible.

**Standalone code to reproduce the issue**
See attached file.
[parallel_map_test.zip](https://github.com/tensorflow/tensorflow/files/4702027/parallel_map_test.zip)


**Other info / logs**
Example output from the code is also available in the attached file.
"
39991,Correct way of using tf.keras.layers.experimental.preprocessing layers under strategy scope,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Yes
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): nightly
- Python version: 3.7
- Bazel version (if compiling from source): 
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

How should I use the preprocessing layers together with distribute strategy? Since strategy requires something like this:

```python
with strategy.scope():
    model = build_model()
    model.fit(...)
```

But when I use the preprocessing layers, I got the following errors:

```python
Traceback (most recent call last):
  File ""make_image_classifier.py"", line 307, in <module>
    run_main()
  File ""make_image_classifier.py"", line 303, in run_main
    app.run(main)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""make_image_classifier.py"", line 260, in main
    FLAGS.summaries_dir)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow_hub/tools/make_image_classifier/make_image_classifier_lib.py"", line 380, in make_image_classifier
    hparams.do_data_augmentation, augment_params)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow_hub/tools/make_image_classifier/make_image_classifier_lib.py"", line 261, in build_model
    preprocessing.RandomRotation(factor=augment_params['rotation_range']),
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py"", line 787, in __init__
    self._rng = make_generator(self.seed)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py"", line 1289, in make_generator
    return stateful_random_ops.Generator.from_non_deterministic_state()
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/ops/stateful_random_ops.py"", line 471, in from_non_deterministic_state
    return cls(state=state, alg=alg)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/ops/stateful_random_ops.py"", line 384, in __init__
    trainable=False)
  File ""/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/ops/stateful_random_ops.py"", line 270, in _create_variable
    ""Creating a generator within a strategy scope is disallowed, because ""
ValueError: Creating a generator within a strategy scope is disallowed, because there is ambiguity on how to replicate a generator (e.g. should it be copied so that each replica gets the same random numbers, or 'split' so that each replica gets different random numbers).
```

The error message is reasonable to me, but how should I use them correctly? As a reference, my model was built like:

```python
def build_model(...):
  model = tf.keras.Sequential([
      tf.keras.Input(shape=(image_size[0], image_size[1], 3)),])

  aug_preprocessor = None
  if do_data_augmentation:
    preprocessing = tf.keras.layers.experimental.preprocessing
    aug_preprocessor = tf.keras.Sequential(
      preprocessing.RandomRotation(factor=augment_params['rotation_range']),
      preprocessing.RandomWidth(factor=augment_params['width_shift_range']),
      preprocessing.RandomHeight(factor=augment_params['height_shift_range']),
      preprocessing.RandomZoom(factor=augment_params['zoom_range']),
      preprocessing.RandomFlip(mode='horizontal')
    )
    model.add(aug_preprocessor)

  model.add(module_layer)
  model.add(tf.keras.layers.Dropout(rate=hparams.dropout_rate))
  model.add(tf.keras.layers.Dense(
      num_classes,
      activation=""softmax"",
      kernel_regularizer=tf.keras.regularizers.l1_l2(l1=hparams.l1_regularizer,
                                                     l2=hparams.l2_regularizer)))

  print(model.summary())
  return model

with strategy.scope():
    model = build_model(model)
    summ = train_model(model,...)
```


**Describe the expected behavior**


**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
39989,Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10  
- TensorFlow version (use command below): 2.1.0  
- Python version: 3.6.9  
- CUDA/cuDNN version: 10.1.105/ 7.6.5
- GPU model and memory: GTX 1660 ti 6GB and 32GB memory


**Describe the current behavior**
![1](https://user-images.githubusercontent.com/44919399/83260746-ef1e4380-a1d7-11ea-82fd-3191e31daae0.jpg)

**Describe the expected behavior**
![2](https://user-images.githubusercontent.com/44919399/83261174-91d6c200-a1d8-11ea-86fc-aded91194419.jpg)

**Standalone code to reproduce the issue**
    _import tensorflow as tf
    inp = tf.random.normal([32, 10, 8])
    lstm = tf.keras.layers.LSTM(4)
    out = lstm(inp)_

**Other info / logs**
As you can in expected behavior it worked but I always have to set gpu memory growth. Which is not the permanent solution. I used to get no issue before cause I upgraded tensorflow to 2.2.0 and this started. I also downgraded to previous version still getting this error. Can someone please help me? Thank You in advance.
"
39986,Custom dataset op encounters refcount error,"I'm trying to implement a customize dataset op so that developing extention of tf.data may not need to recompile the whole tensorflow codebase. And as a start, I'm implementing an identity dataset op that would do nothing but pass the data of its input.

After compiled according to the custom op tutorial, the dataset can successfully output data, but it will raise error on destruction. The error message is:
```bash
% python3 identity_dataset_op.py 
2020-05-29 19:09:04.290680: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-05-29 19:09:04.304126: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd634565fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-05-29 19:09:04.304140: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
tf.Tensor(1, shape=(), dtype=int32)
2020-05-29 19:09:04.308089: F /usr/local/lib/python3.7/site-packages/tensorflow_core/include/tensorflow/core/lib/core/refcount.h:90] Check failed: ref_.load() == 0 (1 vs. 0)
zsh: abort      python3 identity_dataset_op.py
```
The problem is that the refcount has not been set to 0 when the program enters the destructor and this cause the destructor of `RefCounted` (which is the base class of all Dataset) panic.

However, I believe the destructor of a dataset will only be called when its refcount is set to 0. I wonder if this error is connected to some functionality that a custom op cannot use. Also, it will be really nice if you tell me whether it is possible to make a customize dataset op.

BTW, during debugging, I noticed that the `MakeDataset` function would be called twice. Is there any reason for this?

Thank you so much for your time on this issue.
  
The code for the op is in this zip file. 
[custom_dataset_op.zip](https://github.com/tensorflow/tensorflow/files/4701471/custom_dataset_op.zip)

To run the test, simple compile the .cc file to `identity_dataset_op.zip` and run `python identity_dataset.py`."
39985,Conv3D operations are not using tensor cores with mixed float16 policy,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **No**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **CentOS 7**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **N/A**
- TensorFlow installed from (source or binary): **pip package**
- TensorFlow version (use command below): **v2.2.0-rc4-8-g2b96f3662b 2.2.0**
- Python version: **3.7.4**
- Bazel version (if compiling from source): **N/A**
- GCC/Compiler version (if compiling from source): **N/A**
- CUDA/cuDNN version: **10.1/7.6.4**
- GPU model and memory: **RTX2080TI**

**Describe the current behavior**

When using Conv3D layers and a mixed float16 policy the Conv3D layers do not use tensor cores.
Using the same settings for a Conv2D layer does result in the Conv2D layers using the tensor cores.
The [description here](https://www.tensorflow.org/guide/keras/mixed_precision#ensuring_gpu_tensor_cores_are_used) also suggests that Conv3D layers should work with tensor cores

**Describe the expected behavior**

For Conv3D layers to use tensor cores

**Standalone code to reproduce the issue**

Google colab [available here](https://colab.research.google.com/drive/1PKMPvKNe-dk79BjyPK_7N0F_JBoYM9x1?usp=sharing)

**Other info / logs** 

Perhaps related to  #33672, but following the instructions given there (setting the environment variables) does not solve the problem."
39983,"""/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/"" Number of warnings generated during project build","**System information**
Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): tensorflow-gpu version 2.2
Python version: 3.6
Bazel version (if compiling from source): NA
GCC/Compiler version (if compiling from source): 8.4
CUDA/cuDNN version: 10.1
GPU model and memory: Tesla P100 (Google Colab)
Exact command to reproduce: !sh make.sh
**Describe the problem**
I am trying to reproduce the results from this repo: https://github.com/bostondiditeam/MV3D. While building the project, I get a host of warnings which I can ignore but I think these warnings are causing the succeeding error. 
I have tried updating gcc version from 7.x to 8.4 because CUDA 10.1 is compatible with gcc8 but that didn't resolve the problem. 
I would really like to know how I can compile the file psroi_pooling_op.cu.o properly!
**Source code / logs**

This is what my make file looks like:

#!/usr/bin/env bash
TF_INC=$(python -c 'import tensorflow as tf; print(tf.sysconfig.get_include())')
echo $TF_INC

CUDA_PATH=/usr/local/cuda/

cd roi_pooling_layer

nvcc -std=c++11 -c -o roi_pooling_op.cu.o roi_pooling_op_gpu.cu.cc \
	-I $TF_INC -D GOOGLE_CUDA=1 -x cu -Xcompiler -fPIC -arch=sm_75

## if you install tf using already-built binary, or gcc version 4.x, uncomment the two lines below
#g++ -std=c++11 -shared -D_GLIBCXX_USE_CXX11_ABI=0 -o roi_pooling.so roi_pooling_op.cc \
#	roi_pooling_op.cu.o -I $TF_INC -fPIC $CXXFLAGS -lcudart -L $CUDA_PATH/lib64

# for gcc5-built tf
g++ -std=c++11 -shared -D_GLIBCXX_USE_CXX11_ABI=1 -o roi_pooling.so roi_pooling_op.cc \
	roi_pooling_op.cu.o -I $TF_INC -fPIC -lcudart -L $CUDA_PATH/lib64
cd ..


# add building psroi_pooling layer
cd psroi_pooling_layer

nvcc -std=c++11 -c -o psroi_pooling_op.cu.o psroi_pooling_op_gpu.cu.cc \
	-I $TF_INC -D GOOGLE_CUDA=1 -x cu -Xcompiler -fPIC -arch=sm_75

g++ -std=c++11 -shared -D_GLIBCXX_USE_CXX11_ABI=1 -o psroi_pooling.so psroi_pooling_op.cc \
	psroi_pooling_op.cu.o -I $TF_INC -fPIC -lcudart -L $CUDA_PATH/lib64

## if you install tf using already-built binary, or gcc version 4.x, uncomment the two lines below
#g++ -std=c++11 -shared -D_GLIBCXX_USE_CXX11_ABI=0 -o psroi_pooling.so psroi_pooling_op.cc \
#	psroi_pooling_op.cu.o -I $TF_INC -fPIC $CXXFLAGS -lcudart -L $CUDA_PATH/lib64

cd ..

This is the output:
2020-05-29 09:59:27.073245: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
/usr/local/lib/python3.6/dist-packages/tensorflow/include
/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/XprHelper.h(114): warning: __host__ annotation is ignored on a function(""no_assignment_operator"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/XprHelper.h(114): warning: __device__ annotation is ignored on a function(""no_assignment_operator"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/XprHelper.h(115): warning: __host__ annotation is ignored on a function(""no_assignment_operator"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/XprHelper.h(115): warning: __device__ annotation is ignored on a function(""no_assignment_operator"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/XprHelper.h(115): warning: __host__ annotation is ignored on a function(""~no_assignment_operator"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/XprHelper.h(115): warning: __device__ annotation is ignored on a function(""~no_assignment_operator"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(1386): warning: calling a constexpr __host__ function(""real"") from a __host__ __device__ function(""abs"") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(1386): warning: calling a constexpr __host__ function(""imag"") from a __host__ __device__ function(""abs"") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(1386): warning: calling a constexpr __host__ function from a __host__ __device__ function is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(1386): warning: calling a constexpr __host__ function from a __host__ __device__ function is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(1391): warning: calling a constexpr __host__ function(""real"") from a __host__ __device__ function(""abs"") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(1391): warning: calling a constexpr __host__ function(""imag"") from a __host__ __device__ function(""abs"") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(1391): warning: calling a constexpr __host__ function from a __host__ __device__ function is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(1391): warning: calling a constexpr __host__ function from a __host__ __device__ function is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(1415): warning: calling a constexpr __host__ function(""real"") from a __host__ __device__ function(""exp"") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(1416): warning: calling a constexpr __host__ function(""imag"") from a __host__ __device__ function(""exp"") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(1417): warning: calling a constexpr __host__ function(""imag"") from a __host__ __device__ function(""exp"") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(1415): warning: calling a constexpr __host__ function from a __host__ __device__ function is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(1416): warning: calling a constexpr __host__ function from a __host__ __device__ function is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(1417): warning: calling a constexpr __host__ function from a __host__ __device__ function is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(1418): warning: calling a constexpr __host__ function from a __host__ __device__ function is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(1423): warning: calling a constexpr __host__ function(""real"") from a __host__ __device__ function(""exp"") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(1424): warning: calling a constexpr __host__ function(""imag"") from a __host__ __device__ function(""exp"") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.


/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(1423): warning: calling a constexpr __host__ function from a __host__ __device__ function is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(1424): warning: calling a constexpr __host__ function from a __host__ __device__ function is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(1425): warning: calling a constexpr __host__ function from a __host__ __device__ function is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(1426): warning: calling a constexpr __host__ function from a __host__ __device__ function is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/DenseBase.h(639): warning: __host__ annotation is ignored on a function(""DenseBase"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/DenseBase.h(639): warning: __device__ annotation is ignored on a function(""DenseBase"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MatrixBase.h(484): warning: __host__ annotation is ignored on a function(""MatrixBase"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MatrixBase.h(484): warning: __device__ annotation is ignored on a function(""MatrixBase"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MatrixBase.h(485): warning: __host__ annotation is ignored on a function(""MatrixBase"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MatrixBase.h(485): warning: __device__ annotation is ignored on a function(""MatrixBase"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MatrixBase.h(485): warning: __host__ annotation is ignored on a function(""~MatrixBase"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MatrixBase.h(485): warning: __device__ annotation is ignored on a function(""~MatrixBase"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/ArrayBase.h(156): warning: __host__ annotation is ignored on a function(""ArrayBase"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/ArrayBase.h(156): warning: __device__ annotation is ignored on a function(""ArrayBase"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/ArrayBase.h(157): warning: __host__ annotation is ignored on a function(""ArrayBase"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/ArrayBase.h(157): warning: __device__ annotation is ignored on a function(""ArrayBase"") that is explicitly defaulted on its first declaration


/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/ArrayBase.h(157): warning: __device__ annotation is ignored on a function(""~ArrayBase"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/CwiseUnaryView.h(70): warning: __host__ annotation is ignored on a function(""CwiseUnaryView"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/CwiseUnaryView.h(70): warning: __device__ annotation is ignored on a function(""CwiseUnaryView"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/CwiseUnaryView.h(110): warning: __host__ annotation is ignored on a function(""CwiseUnaryViewImpl"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/CwiseUnaryView.h(110): warning: __device__ annotation is ignored on a function(""CwiseUnaryViewImpl"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/CwiseUnaryView.h(125): warning: __host__ annotation is ignored on a function(""CwiseUnaryViewImpl"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/CwiseUnaryView.h(125): warning: __device__ annotation is ignored on a function(""CwiseUnaryViewImpl"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/CwiseUnaryView.h(125): warning: __host__ annotation is ignored on a function(""~CwiseUnaryViewImpl"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/CwiseUnaryView.h(125): warning: __device__ annotation is ignored on a function(""~CwiseUnaryViewImpl"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MapBase.h(185): warning: __host__ annotation is ignored on a function(""MapBase"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MapBase.h(185): warning: __device__ annotation is ignored on a function(""MapBase"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MapBase.h(186): warning: __host__ annotation is ignored on a function(""MapBase"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MapBase.h(186): warning: __device__ annotation is ignored on a function(""MapBase"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MapBase.h(186): warning: __host__ annotation is ignored on a function(""~MapBase"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MapBase.h(186): warning: __device__ annotation is ignored on a function(""~MapBase"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MapBase.h(300): warning: __host__ annotation is ignored on a function(""MapBase"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MapBase.h(300): warning: __device__ annotation is ignored on a function(""MapBase"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MapBase.h(301): warning: __host__ annotation is ignored on a function(""MapBase"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MapBase.h(301): warning: __device__ annotation is ignored on a function(""MapBase"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MapBase.h(301): warning: __host__ annotation is ignored on a function(""~MapBase"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MapBase.h(301): warning: __device__ annotation is ignored on a function(""~MapBase"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Map.h(162): warning: __host__ annotation is ignored on a function(""Map"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MapBase.h(186): warning: __device__ annotation is ignored on a function(""~MapBase"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MapBase.h(300): warning: __host__ annotation is ignored on a function(""MapBase"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MapBase.h(300): warning: __device__ annotation is ignored on a function(""MapBase"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MapBase.h(301): warning: __host__ annotation is ignored on a function(""MapBase"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MapBase.h(301): warning: __device__ annotation is ignored on a function(""MapBase"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MapBase.h(301): warning: __host__ annotation is ignored on a function(""~MapBase"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MapBase.h(301): warning: __device__ annotation is ignored on a function(""~MapBase"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Map.h(162): warning: __host__ annotation is ignored on a function(""Map"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Map.h(162): warning: __device__ annotation is ignored on a function(""Map"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Ref.h(90): warning: __host__ annotation is ignored on a function(""RefBase"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Ref.h(90): warning: __device__ annotation is ignored on a function(""RefBase"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Ref.h(232): warning: __host__ annotation is ignored on a function(""Ref"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Ref.h(232): warning: __device__ annotation is ignored on a function(""Ref"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Block.h(111): warning: __host__ annotation is ignored on a function(""Block"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Block.h(111): warning: __device__ annotation is ignored on a function(""Block"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Block.h(161): warning: __host__ annotation is ignored on a function(""BlockImpl"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Block.h(161): warning: __device__ annotation is ignored on a function(""BlockImpl"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Block.h(181): warning: __host__ annotation is ignored on a function(""BlockImpl_dense"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Block.h(181): warning: __device__ annotation is ignored on a function(""BlockImpl_dense"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Block.h(341): warning: __host__ annotation is ignored on a function(""BlockImpl_dense"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Block.h(341): warning: __device__ annotation is ignored on a function(""BlockImpl_dense"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/IndexedView.h(113): warning: __host__ annotation is ignored on a function(""IndexedView"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/IndexedView.h(113): warning: __device__ annotation is ignored on a function(""IndexedView"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Reshaped.h(103): warning: __host__ annotation is ignored on a function(""Reshaped"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Reshaped.h(103): warning: __device__ annotation is ignored on a function(""Reshaped"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Reshaped.h(137): warning: __host__ annotation is ignored on a function(""ReshapedImpl"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Reshaped.h(137): warning: __device__ annotation is ignored on a function(""ReshapedImpl"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Reshaped.h(155): warning: __host__ annotation is ignored on a function(""ReshapedImpl_dense"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Reshaped.h(155): warning: __device__ annotation is ignored on a function(""ReshapedImpl_dense"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Reshaped.h(215): warning: __host__ annotation is ignored on a function(""ReshapedImpl_dense"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Reshaped.h(215): warning: __device__ annotation is ignored on a function(""ReshapedImpl_dense"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Transpose.h(66): warning: __host__ annotation is ignored on a function(""Transpose"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Transpose.h(66): warning: __device__ annotation is ignored on a function(""Transpose"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Transpose.h(126): warning: __host__ annotation is ignored on a function(""TransposeImpl"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Transpose.h(126): warning: __device__ annotation is ignored on a function(""TransposeImpl"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Transpose.h(157): warning: __host__ annotation is ignored on a function(""TransposeImpl"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Transpose.h(157): warning: __device__ annotation is ignored on a function(""TransposeImpl"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Transpose.h(157): warning: __host__ annotation is ignored on a function(""~TransposeImpl"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Transpose.h(157): warning: __device__ annotation is ignored on a function(""~TransposeImpl"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Diagonal.h(78): warning: __host__ annotation is ignored on a function(""Diagonal"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Diagonal.h(78): warning: __device__ annotation is ignored on a function(""Diagonal"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/TriangularMatrix.h(222): warning: __host__ annotation is ignored on a function(""TriangularView"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/TriangularMatrix.h(222): warning: __device__ annotation is ignored on a function(""TriangularView"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/TriangularMatrix.h(559): warning: __host__ annotation is ignored on a function(""TriangularViewImpl"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/TriangularMatrix.h(559): warning: __device__ annotation is ignored on a function(""TriangularViewImpl"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/TriangularMatrix.h(560): warning: __host__ annotation is ignored on a function(""TriangularViewImpl"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/TriangularMatrix.h(560): warning: __device__ annotation is ignored on a function(""TriangularViewImpl"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/TriangularMatrix.h(560): warning: __host__ annotation is ignored on a function(""~TriangularViewImpl"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/TriangularMatrix.h(560): warning: __device__ annotation is ignored on a function(""~TriangularViewImpl"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Reverse.h(90): warning: __host__ annotation is ignored on a function(""Reverse"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Reverse.h(90): warning: __device__ annotation is ignored on a function(""Reverse"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/ArrayWrapper.h(47): warning: __host__ annotation is ignored on a function(""ArrayWrapper"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/ArrayWrapper.h(47): warning: __device__ annotation is ignored on a function(""ArrayWrapper"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/ArrayWrapper.h(145): warning: __host__ annotation is ignored on a function(""MatrixWrapper"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/ArrayWrapper.h(145): warning: __device__ annotation is ignored on a function(""MatrixWrapper"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/XprHelper.h(114): warning: __host__ annotation is ignored on a function(""no_assignment_operator"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/XprHelper.h(114): warning: __device__ annotation is ignored on a function(""no_assignment_operator"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/XprHelper.h(115): warning: __host__ annotation is ignored on a function(""no_assignment_operator"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/XprHelper.h(115): warning: __device__ annotation is ignored on a function(""no_assignment_operator"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/XprHelper.h(115): warning: __host__ annotation is ignored on a function(""~no_assignment_operator"") that is explicitly defaulted on its first declaration

/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/XprHelper.h(115): warning: __device__ annotation is ignored on a function(""~no_assignment_operator"") that is explicitly defaulted on its first declaration
cuda_kernel_helper.h(49): error: class ""Eigen::GpuDevice"" has no member ""getNumCudaMultiProcessors""

cuda_kernel_helper.h(49): error: class ""Eigen::GpuDevice"" has no member ""maxCudaThreadsPerMultiProcessor""

cuda_kernel_helper.h(48): error: no instance of overloaded function ""std::min"" matches the argument list
            argument types are: (<error-type>, const int)

cuda_kernel_helper.h(51): error: class ""Eigen::GpuDevice"" has no member ""maxCudaThreadsPerBlock""

cuda_kernel_helper.h(51): error: no instance of overloaded function ""std::min"" matches the argument list
            argument types are: (int, <error-type>)

cuda_kernel_helper.h(54): error: class ""Eigen::GpuDevice"" has no member ""getNumCudaMultiProcessors""

cuda_kernel_helper.h(81): error: class ""Eigen::GpuDevice"" has no member ""getNumCudaMultiProcessors""

cuda_kernel_helper.h(81): error: class ""Eigen::GpuDevice"" has no member ""maxCudaThreadsPerMultiProcessor""

cuda_kernel_helper.h(83): error: no instance of overloaded function ""std::max"" matches the argument list
            argument types are: (<error-type>, int)

cuda_kernel_helper.h(90): error: no instance of overloaded function ""std::min"" matches the argument list
            argument types are: (<error-type>, const int)

10 errors detected in the compilation of ""/tmp/tmpxft_000008ff_00000000-6_psroi_pooling_op_gpu.cu.cpp1.ii"".
g++: error: psroi_pooling_op.cu.o: No such file or directory
make: 'LidarTopPreprocess.so' is up to date."
39982,For tf.keras.losses.categorical_hinge maximum op dtype missmatch using mixed_precision with float16,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

***Issue:***
     return math_ops.maximum(0., neg - pos + 1.)
    lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py:5740 maximum
        ""Maximum"", x=x, y=y, name=name)
    lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:506 _apply_op_helper
        inferred_from[input_arg.type_attr]))

    TypeError: Input 'y' of 'Maximum' Op has type float16 that does not match type float32 of argument 'x'.

***Plausible solution:***
   return math_ops.maximum( neg - pos + 1., 0.)
So that dtype is matched with calculated entity rather than other way."
39981,tf.math.maximum example is written incorrectly.,"## URL(s) with the issue:

https://www.tensorflow.org/api_docs/python/tf/math/maximum#returns


## Description of issue (what needs changing):

The example of tf.math.maximum is not written correctly.
It's written in this manner,
Example: 
``` x = tf.constant([0., 0., 0., 0.]) y = tf.constant([-2., 0., 2., 5.]) tf.math.maximum(x, y) ```
Instead of this it should've written in this manner,
``` 
    x = tf.constant([0., 0., 0., 0.])
    y = tf.constant([-2., 0., 2., 5.])
    tf.math.maximum(x, y)
    -> tf.Tensor([0. 0. 2. 5.], shape=(4,), dtype=float32)
```    





### Submit a pull request?
no"
39980,tf.keras.layers.Multiply fails on Variables,"tensorflow 2.2.0

ubuntu 20.04


I am trying a simple code:
```
import tensorflow as tf
v1 = tf.Variable(np.array([[1.,2.],[2.,3.]]))
v2 = tf.Variable(np.array([[1.,2.],[2.,3.]]))
v3=tf.keras.layers.Multiply()([v1,v2])
```
I am getting:
```
RuntimeError                              Traceback (most recent call last)
<ipython-input-15-70cdbcdc638c> in <module>
      2 v1 = tf.Variable(np.array([[1.,2.],[2.,3.]]))
      3 v2 = tf.Variable(np.array([[1.,2.],[2.,3.]]))
----> 4 v3=tf.keras.layers.Multiply()([v1,v2])

~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, *args, **kwargs)
    966           with base_layer_utils.autocast_context_manager(
    967               self._compute_dtype):
--> 968             outputs = self.call(cast_inputs, *args, **kwargs)
    969           self._handle_activity_regularization(inputs, outputs)
    970           self._set_mask_metadata(inputs, outputs, input_masks)

~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/layers/merge.py in call(self, inputs)
    181         return y
    182     else:
--> 183       return self._merge_function(inputs)
    184 
    185   @tf_utils.shape_type_conversion

~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/layers/merge.py in _merge_function(self, inputs)
    320     output = inputs[0]
    321     for i in range(1, len(inputs)):
--> 322       output *= inputs[i]
    323     return output
    324 

~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py in __imul__(self, unused_other)
   1255 
   1256   def __imul__(self, unused_other):
-> 1257     raise RuntimeError(""Variable *= value not supported. Use ""
   1258                        ""`var.assign(var * value)` to modify the variable or ""
   1259                        ""`var = var * value` to get a new Tensor object."")

RuntimeError: Variable *= value not supported. Use `var.assign(var * value)` to modify the variable or `var = var * value` to get a new Tensor object.
```
What am i doing wrong? please help me understand the issue"
39979,micro_speech example broken,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Embedded device: Arduino Nano 33 BLE Sense (IDE 1.8.12)
- TensorFlow installed from (source or binary): Source (latest version)

**Describe the current behavior**
This issue is regarding TensorFlow Lite for Microcontrollers. The micro_speech example is not working (it doesn't detect any words) or even ""unknown"" tags.

**Standalone code to reproduce the issue**
The only thing I am using is the example as given in the GitHub (with the pretrained model)

**Other info / logs** 
Tried debugging a bit, but didn't get too far. It seems to be some problem with the RecognizeCommands file."
39978,Missing positional argument error when deepcopy a LSTMCell,"**System information**
- Have I written custom code: Yes
- OS Platform and Distribution: Ubuntu 16.04
- TensorFlow installed from: binary
- TensorFlow version: 2.2.0
- Python version: 3.5 & 3.6

**Describe the current behavior**

An exception is raised when calling `copy.deepcopy` on a `tf.keras.layers.LSTMCell`.

**Describe the expected behavior**

Keras layers should support `copy.deepcopy` without error since https://github.com/tensorflow/tensorflow/commit/4fd10c487c7e287f99b9a1831316add453dcba04. The same code worked in TensorFlow 2.1.

**Standalone code to reproduce the issue**

```python
import copy
import tensorflow as tf

cell = tf.keras.layers.LSTMCell(512)
cell = copy.deepcopy(cell)
```

**Other info / logs**

```text
Traceback (most recent call last):
  File ""test/deepcopy.py"", line 5, in <module>
    cell = copy.deepcopy(cell)
  File ""<env_dir>/lib/python3.6/copy.py"", line 180, in deepcopy
    y = _reconstruct(x, memo, *rv)
  File ""<env_dir>/lib/python3.6/copy.py"", line 280, in _reconstruct
    state = deepcopy(state, memo)
  File ""<env_dir>/lib/python3.6/copy.py"", line 150, in deepcopy
    y = copier(x, memo)
  File ""<env_dir>/lib/python3.6/copy.py"", line 240, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File ""<env_dir>/lib/python3.6/copy.py"", line 180, in deepcopy
    y = _reconstruct(x, memo, *rv)
  File ""<env_dir>/lib/python3.6/copy.py"", line 280, in _reconstruct
    state = deepcopy(state, memo)
  File ""<env_dir>/lib/python3.6/copy.py"", line 150, in deepcopy
    y = copier(x, memo)
  File ""<env_dir>/lib/python3.6/copy.py"", line 240, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File ""<env_dir>/lib/python3.6/copy.py"", line 150, in deepcopy
    y = copier(x, memo)
  File ""<env_dir>/lib/python3.6/copy.py"", line 240, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File ""<env_dir>/lib/python3.6/copy.py"", line 180, in deepcopy
    y = _reconstruct(x, memo, *rv)
  File ""<env_dir>/lib/python3.6/copy.py"", line 280, in _reconstruct
    state = deepcopy(state, memo)
  File ""<env_dir>/lib/python3.6/copy.py"", line 150, in deepcopy
    y = copier(x, memo)
  File ""<env_dir>/lib/python3.6/copy.py"", line 220, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
  File ""<env_dir>/lib/python3.6/copy.py"", line 220, in <listcomp>
    y = [deepcopy(a, memo) for a in x]
  File ""<env_dir>/lib/python3.6/copy.py"", line 150, in deepcopy
    y = copier(x, memo)
  File ""<env_dir>/lib/python3.6/copy.py"", line 240, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File ""<env_dir>/lib/python3.6/copy.py"", line 161, in deepcopy
    y = copier(memo)
  File ""<env_dir>/lib/python3.6/weakref.py"", line 421, in __deepcopy__
    new = self.__class__()
TypeError: __init__() missing 1 required positional argument: 'default_factory'
```"
39977,map the input image path dataset. ,"```
 images,boxes,labels,difficulties= PascalVOCDataset()
 dataset = tf.data.Dataset.from_tensor_slices((images)).shuffle(100).batch(2)

tf.Tensor(b'/media/jake/mark-4tb3/input/datasets/pascal/VOCtrainval_11-May-2012/VOCdevkit/VOC2012/JPEGImages/2008_000199.jpg', shape=(), dtype=string) tf.Tensor(b'/media/jake/mark-4tb3/input/datasets/pascal/VOCtrainval_11-May-2012/VOCdevkit/VOC2012/JPEGImages/2008_000187.jpg', shape=(), dtype=string)

```
This will return the images, boxes with


I want to map this file path to the real image path 


```
def func2(image,bbox):
    print('func2')
    print('dataset->',image)
    images = np.array(image)
    newSize = [300, 300]
    if isprint: print('image_A->', images[0].decode(""utf-8""))
    image = cv2.imread(images[0].decode(""utf-8""))
    if isprint: print(image.shape)
    image = np.array(image)
    scale_x = newSize[0] / image.shape[1]
    scale_y = newSize[1] / image.shape[0]
    image = cv2.resize(image, (newSize[0], newSize[1]))
    return tf.convert_to_tensor(image, dtype=tf.uint8), bbox
def fast_benchmark(dataset, num_epochs=2):
    start_time = time.perf_counter()
    for _ in tf.data.Dataset.range(num_epochs):
        for _ in dataset:
            pass
    tf.print(""실행 시간:"", time.perf_counter() - start_time)

fast_benchmark(dataset.map(func2).batch(1).prefetch(tf.data.experimental.AUTOTUNE))
```


**NotImplementedError: in converted code:
    relative to /home/jake:

    Gits/ssd_tensorflow/train.py:46 func2  *
        images = np.array(image)
    venv/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py:396 converted_call
        return py_builtins.overload_of(f)(*args)
    venv/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:736 __array__
        "" array."".format(self.name))

    NotImplementedError: Cannot convert a symbolic Tensor (args_0:0) to a numpy array.

func2
dataset-> Tensor(""args_0:0"", shape=(), dtype=string)

Process finished with exit code 1**
"
39976,RandomContrast Layer - confusing __init__ error message,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab
- TensorFlow installed from (source or binary): Colab
- TensorFlow version (use command below): 2.2.0
- Python version: 3.6.9

**Describe the current behavior**
When instantiating a RandomContrast layer object with a value > 1. (e.g. 2) for the `Factor` parameter, a `ValueError` is raised with the following error message which is somewhat confusing in this scenario: 'Factor cannot have negative values, got 2'


**Describe the expected behavior**
A `ValueError` should be raised with a more appropriate error message, something like: 'Factor cannot be greater than 1, got 2'

**Standalone code to reproduce the issue**
```python
random_contrast_layer = tf.keras.layers.experimental.preprocessing.RandomContrast(2)
```
"
39974,Setuptools 40.0.0 is incompatible,"Does this error affect  tensorflow while executing it as import tensorflow as tf?

![Screenshot (5)](https://user-images.githubusercontent.com/25500477/83214482-67f3b000-a184-11ea-89ce-41725b15b702.png)

"
39973,dataset.from_generator error with multiple inputs,"
**System information**
- no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): tensorflow-2.1.0 (cpu)
- Python version: 3.7

**Describe the current behavior**
I use tf.keras.Model to build up a model. It has multiple inputs, say input is like `[i_1, i_2, i_3, a_1]`, output is only one, say `y`.
I have a generator function
```
def gen():
    for i in range(data_length):
        ...
        yield [i_1, i_2, i_3, a_1], y
```
Notice that the inputs have variable sizes. Then I have the dataset built as:
`ds = tf.data.dataset.from_generator(gen, output_type=(tf.float32,tf.float32, tf.float32, tf.float32, tf.int8))`
when I send the ds to model.fit, it shows the error `map_fn() takes from 1 to 3 positional arguments but 5 were given`

Then I tried 
`ds = tf.data.dataset.from_generator(gen, output_type=([tf.float32,tf.float32, tf.float32, tf.float32], tf.int8))`
and 
`ds = tf.data.dataset.from_generator(gen, output_type=((tf.float32,tf.float32, tf.float32, tf.float32), tf.int8))`
Both of them show errors. How should make the from_generator take multiple inputs?

Thank you!"
39972,Can't use Keras with GPU (Tensorflow-gpu==1.15),"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.4 LTS
- TensorFlow installed from (source or binary): source
- TensorFlow version: tensorflow-gpu==1.15
- Python version: 3.7
- Installed using virtualenv? pip? conda?: pip
- CUDA/cuDNN version: CUDA Version: 10.1 
- GPU model and memory: GeForce RTX 2080 Ti/PCIe/SSE2

Hi guys, I'm installed tensorflow-gpu 1.15 and Keras 2.1.4. 
When i run: 

sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))

Return:
Device mapping:
/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device
/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device
/job:localhost/replica:0/task:0/device:XLA_GPU:1 -> device: XLA_GPU device

But when i run:

K.tensorflow_backend._get_available_gpus()

Return []

And when i train model it don't use gpu. But if i install tensorflow-gpu 2.2, model was trained by GPU on keras.

How can i use GPU on Keras with tensorflow-gpu 1.15? Thank you so much !"
39970,"Unable to use tfp.optimizer.lbfgs_minimize, error after 2 iterations","Hi I am unable to use tfp.optimizer.lbfgs_minimize, following the tutorial on https://www.tensorflow.org/probability/examples/Optimizers_in_TensorFlow_Probability.

Similar to https://github.com/tensorflow/probability/issues/398,

I am facing error ""Inputs to operation Select of type Select must have the same size and shape.  Input 0: [110] != input 1: [1] [Op:Select]""

I noticed that when my cost function if of shape (1,) and my gradient of shape (x,1) it says x!=1
But what I don't understand is why does my cost function need to be of shape(x,1)? When I add a placeholder return which returns shape (x,1) for cost value as well, it runs.  

![image](https://user-images.githubusercontent.com/7682371/83195374-09054b00-a132-11ea-8b56-f353f89b54a7.png)
"
39969,"Simple keras model ""predict"" call fails inside py_function","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes. Created a simple example for reproducibility. 
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.3 LTS
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: Python 3.7.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source): 
- CUDA/cuDNN version: CUDA 10.2 / cuDNN 7.6.5
- GPU model and memory: GeForce GTX 980 Ti / 6GB

**Describe the current behavior**

Using the 'predict' api for a keras model inside a py_function throws the following error:
`LookupError: No gradient defined for operation 'IteratorGetNext' (op type: IteratorGetNext)`

**Standalone code to reproduce the issue**


```
import numpy as np
import tensorflow as tf

inp = tf.keras.Input(shape=(5,))
out = tf.keras.layers.Dense(1)(inp)
model = tf.keras.Model(inp, out)

def outer_func(arr):
    def _func(x):
        res = model.predict(x)
        return res

    out = tf.py_function(
        _func,
        (arr,),
        tf.float32
    )
    return out

outer_func(np.random.rand(10, 5))
```"
39968,"TensorFlow ""steals"" stdout when using output redirection","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Example code provided.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04 and Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pypi
- TensorFlow version (use command below): 2.1.0 and 2.2.0
- Python version: 3.7.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**

When using TensorFlow with output redirection or pipelining under linux, stdout is buffered for a very long time/indefinitely. In my example script, Python's print is outputed when the script exits. This only happens when you redirect script output. Test on zsh and bash. This is really annoying for longer scripts, that train real models.

There is one more thing you can notice in my example script, print version happens before TensorFlow is initialized, so it should output before warnings.

Correct:

```
Tensorflow version: 2.2.0
2020-05-28 22:05:10.001027: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-05-28 22:05:10.001046: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)
2020-05-28 22:05:10.001058: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (lain): /proc/driver/nvidia/version does not exist
2020-05-28 22:05:10.001249: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-05-28 22:05:10.024089: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3699850000 Hz
2020-05-28 22:05:10.024353: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f6e5c000b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-05-28 22:05:10.024385: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
tf.Tensor(1, shape=(), dtype=int32)
tf.Tensor(2, shape=(), dtype=int32)
tf.Tensor(3, shape=(), dtype=int32)
```

Incorrect order because stdout is cached:

```
2020-05-28 22:02:34.064521: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-05-28 22:02:34.064545: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)
2020-05-28 22:02:34.064562: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (lain): /proc/driver/nvidia/version does not exist
2020-05-28 22:02:34.064822: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-05-28 22:02:34.088105: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3699850000 Hz
2020-05-28 22:02:34.088365: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7bcc000b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-05-28 22:02:34.088379: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Tensorflow version: 2.2.0
tf.Tensor(1, shape=(), dtype=int32)
tf.Tensor(2, shape=(), dtype=int32)
tf.Tensor(3, shape=(), dtype=int32)
```

I don't think it applies to stderr. If I would speculate, I would say that someone is trying to detect terminal and something goes wrong when you redirect output.

**Describe the expected behavior**

TensorFlow should not be ""stealing"" or changing default stdout behavior.



**Standalone code to reproduce the issue**
```
import time

import tensorflow as tf

print('Tensorflow version:', tf.version.VERSION)


def run():
    dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])
    for element in dataset:
        print(element)
    time.sleep(60)


if __name__ == '__main__':
    run()
```

How to run it:

Correct output:

```
python stdout-bug.py
```

Broken:

```
python stdout-bug.py | tee foo.log 2>&1
python stdout-bug.py | tee foo.log
python stdout-bug.py > foo.log 2>&1
python stdout-bug.py > foo.log
```

"
39965,Use of unresolved identifier 'CoreMLDelegate',"![Screenshot 2020-05-29 at 12 50 56 AM](https://user-images.githubusercontent.com/44207274/83184096-918de680-a146-11ea-836f-1cf6c895c7fb.png)

pod version TensorFlowLiteSwift 0.0.1-nightly.20200527

Facing this issue even after running 

> pod cache clean TensorFlowLiteSwift
"
39963,Error when using Class_Weight in Keras for binary classification,"Here is the model summary: 
```
Model: ""sequential""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d (Conv1D)              (None, 35, 32)            96        
_________________________________________________________________
batch_normalization (BatchNo (None, 35, 32)            128       
_________________________________________________________________
dropout (Dropout)            (None, 35, 32)            0         
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 34, 64)            4160      
_________________________________________________________________
batch_normalization_1 (Batch (None, 34, 64)            256       
_________________________________________________________________
dropout_1 (Dropout)          (None, 34, 64)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2176)              0         
_________________________________________________________________
dense (Dense)                (None, 64)                139328    
_________________________________________________________________
dropout_2 (Dropout)          (None, 64)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 65        
=================================================================
Total params: 144,033
Trainable params: 143,841
Non-trainable params: 192
```
Here is the error message:

```
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-14-09a8a255f317> in <module>()
----> 1 history = model.fit(X_Train,Y_Train, epochs = epochs, validation_data =(X_Test,Y_Test), verbose=1,class_weight=class_weights1)

8 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     58     ctx.ensure_initialized()
     59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
---> 60                                         inputs, attrs, num_outputs)
     61   except core._NotOkStatusException as e:
     62     if name is not None:

InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument:  indices[31] = -9223372036854775808 is not in [0, 2)
     [[{{node GatherV2}}]]
     [[IteratorGetNext]]
     [[IteratorGetNext/_2]]
  (1) Invalid argument:  indices[31] = -9223372036854775808 is not in [0, 2)
     [[{{node GatherV2}}]]
     [[IteratorGetNext]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_6381]

Function call stack:
train_function -> train_function
```
Somehow I'm getting a massive negative number? My dataset is all percentile data so numbers between 0 and 1.

Also here is the code to set up the model:
```
class_weights1 = {0: 1., 1: 50.}

epochs = 1
model = Sequential()
model.add(Conv1D(filters = 32, kernel_size = 2, activation='relu',input_shape=(36,1)))
model.add(BatchNormalization())
model.add(Dropout(0.2))

model.add(Conv1D(filters = 64, kernel_size = 2, activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(0.5))

model.add(Flatten())
model.add(Dense(64,activation='relu'))
model.add(Dropout(0.5))

model.add(Dense(1,activation='sigmoid'))
```
And then the code to compile and run it:
```
model.compile(optimizer=Adam(lr=0.005),loss='binary_crossentropy',metrics=['accuracy'])

history = model.fit(X_Train,Y_Train, epochs = epochs, validation_data =(X_Test,Y_Test), verbose=1,class_weight=class_weights1)
```
I know this is a problem with my class_weight because when I remove it, everything works (but the model is terrible because the data is imbalanced and I need to increase the weight of the minority class to adjust for this)."
39962,TFLite Convert Python API Has Bad Code,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue: https://www.tensorflow.org/lite/convert/python_api

## Description of issue (what needs changing):
Under 'Converting a Keras model' it has the code `tf.gfile.GFile` and that code has moved to `tf.io.gfile.GFile`

### Clear description
This change should be made so that the code runs.

### Correct links

Is the link to the source code correct? Yes

### Parameters defined

Are all parameters defined and formatted correctly? Yes

### Returns defined

Are return values defined? Yes

### Raises listed and defined

Are the errors defined? No errors

### Usage example

Is there a usage example? No

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content? N/A

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
39960,windows 8.1 : import error: DLL load failed,"windows 8.1
pip install tensorflow_cpu
import tensorflow as tf

ImportError                               Traceback (most recent call last)
~\anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\pywrap_tensorflow.py in <module>
     57 
---> 58   from tensorflow.python.pywrap_tensorflow_internal import *
     59 

~\anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py in <module>
     27             return _mod
---> 28     _pywrap_tensorflow_internal = swig_import_helper()
     29     del swig_import_helper

~\anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py in swig_import_helper()
     23             try:
---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
     25             finally:

~\anaconda3\envs\tensorflow_cpu\lib\imp.py in load_module(name, file, filename, details)
    241         else:
--> 242             return load_dynamic(name, filename, file)
    243     elif type_ == PKG_DIRECTORY:

~\anaconda3\envs\tensorflow_cpu\lib\imp.py in load_dynamic(name, path, file)
    341             name=name, loader=loader, origin=path)
--> 342         return _load(spec)
    343 

ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

ImportError                               Traceback (most recent call last)
<ipython-input-1-64156d691fe5> in <module>
----> 1 import tensorflow as tf

~\anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\__init__.py in <module>
     39 import sys as _sys
     40 
---> 41 from tensorflow.python.tools import module_util as _module_util
     42 from tensorflow.python.util.lazy_loader import LazyLoader as _LazyLoader
     43 

~\anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\__init__.py in <module>
     48 import numpy as np
     49 
---> 50 from tensorflow.python import pywrap_tensorflow
     51 
     52 # Protocol buffers

~\anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\pywrap_tensorflow.py in <module>
     67 for some common reasons and solutions.  Include the entire stack trace
     68 above this error message when asking for help."""""" % traceback.format_exc()
---> 69   raise ImportError(msg)
     70 
     71 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long

ImportError: Traceback (most recent call last):
  File ""C:\Users\Pratik\anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Pratik\anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Pratik\anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\Pratik\anaconda3\envs\tensorflow_cpu\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\Pratik\anaconda3\envs\tensorflow_cpu\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**:
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
39959,how to check quantization method applied,"how do I check what quantization specification has been applied to model (TensorFlow quantized format)?
I'd like to know what
- Dynamic range quantization, Full integer quantization, Float16 quantization,etc...
- Symmetric vs asymmetric
- Per-axis vs per-tensor
- Signed integer vs unsigned integer
- etc..

Thank you
"
39958,"Training fails with ""CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure"" on Windows 10","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **yes**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Windows 10**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **No**
- TensorFlow installed from (source or binary): **binary (via pip install)**
- TensorFlow version (use command below): **v2.2.0-rc4-8-g2b96f3662b 2.2.0**
- Python version: **3.6.8**
- Bazel version (if compiling from source): Not applicable
- GCC/Compiler version (if compiling from source): Not applicable
- CUDA/cuDNN version: **cuda 10.1.243_426.00_win10 (CUDA Toolkit 10.1 update2 Archive ) / cuDNN v7.6.5 (November 5th, 2019), for CUDA 10.1**
- GPU model and memory: **GeForce GTX 1070, Compute Capability 6.1, 8Gb; 
also on GeForce GTX 1050 Ti 4Gb on another Win 10 machine with the same cuda version installed**

**Describe the current behavior**
I use TF Keras API to define the model and the training process.

The training stops with the error:
```
2020-05-28 18:52:43.846256: E tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2020-05-28 18:52:43.846616: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:273] Unexpected Event status: 1

exit code -1073740791
```

after several training epochs.

It happens in a reproducible way (the same python file execution fails after the same number of epochs).
When I change the random seed (thus the dataset is shuffled differently) the process fails after different number of epochs!
Changing batch size also effects the number of epochs until the training fail (randomly)!
I use batch size of 1 or 2 as I have rather large model.

**Describe the expected behaviour**
Training runs without the error requested number of epochs."
39957,TF Lite wheel is not supported on platform including ARMv7 and python 3.6.5,"@tensorflow/micro

**System information**
- Hardware : Freescale i.MX6 Quad/DualLite
- Processor: ARMv7 Processor rev 10 (v71)
- OS Platform and Distribution: Yocto built Linux distribution (kernel 4.9.4+)
- TensorFlow Lite interpreter installed: wheel https://dl.google.com/coral/python/tflite_runtime-2.1.0.post1-cp36-cp36m-linux_armv7l.whl (https://www.tensorflow.org/lite/guide/python#learn_more) 
- Installed python version: 3.6.5
- Installed pip3 version: 9.0.3

I downloaded the wheel described above from Tensorflow's website and followed the guidelines doing so because the processor is of the ARMv7 type and because the installed python version is 3.6.5. 
I transferred the wheel from my local computer to the hardware over SSH. Now running `pip3 install tflite_runtime-2.1.0.post1-cp36-cp36m-linux_armv71.whl` gives me the following error message: `tflite_runtime-2.1.0.post1-cp36-cp36m-linux_armv71.wh is not a supported wheel on this platform`.

Why is that? As far as I know, the hardware and software answers to all requirements set out to be able to install this particular wheel.


"
39955,AttributeError: module 'tensorflow.python.keras.api._v2.keras.preprocessing.text' has no attribute 'text_dataset_from_directory',"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Using example code from tensorflow
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: On computer
- TensorFlow installed from (source or binary): Source
- TensorFlow version (use command below): 2.2
- Python version:3.8.2
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:Not installed
- GPU model and memory:No GPU

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

GIT Version:
v2.2.0-rc4-8-g2b96f3662b 2.2.0

**Describe the current behavior**
Unable Unable to load the function text_dataset_from_directory. I have installed tensorflow 2.2 and keras. I am not sure if any api is called from the installed package.
I installed tf - nightly as well, but still unable to resolve the issue. I am not sure if am missing anything. Please help me on this.

**Describe the expected behavior**
All functions has to work.
**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
![image](https://user-images.githubusercontent.com/7239271/83170984-00614480-a133-11ea-964e-021faa011e9d.png)
"
39954,Convert keras model to quantized tflite lost precision,"I'm trying to convert my keras model into tflite quantized model so that I can run my model on coral TPU, but the output of my keras model and tflite model are significantly different.

The red points are quantized tflite model output, and blue points are original keras model output.

[img is here](https://i.stack.imgur.com/AdFyR.png)

Here is my code to convert keras model to quantized tflite model :

```
quant = True
gc.collect()
import tensorflow as tf
import numpy as np
import pathlib
print(tf.__version__)
converter = tf.lite.TFLiteConverter.from_keras_model(model)
if quant:
    print(""Converting quant...."")
    sample_size = 200
    rdm_idx = np.random.choice(range(len(X_test)),sample_size)
    rep_data = tf.cast(X_train[rdm_idx], tf.float32) / 255.0
    dataset = tf.data.Dataset.from_tensor_slices(rep_data).batch(1)

    def representative_data_gen():
        for input_value in dataset.take(sample_size):
            yield [input_value]

    converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]
    converter.representative_dataset = representative_data_gen
    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
    converter.inference_input_type = tf.uint8
    converter.inference_output_type = tf.uint8
    tflite_model_quant = converter.convert()
    open(""MaskedLandMarkDetction_MobileNetV2_quant_fromKeras_v5.tflite"", ""wb"").write(tflite_model_quant)

    print(""Write quantization tflite done."")
else:
    print(""Converting normal...."")
    tflite_model = converter.convert()
    open(""MaskedLandMarkDetction_MobileNetV2_fromKeras.tflite"", ""wb"").write(tflite_model)
    print(""Write tflite done."") 
```

`X_train `is my training data, and I will scale input images value from 0 to 1 by divided `255.`, so I do the same in `representative_data_gen `functions.

Any assistance you can provide would be greatly appreciated."
39953,The problem of using the function “SetDefaultDevice” to set the gpu,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:no
- TensorFlow installed from (source or binary):source C++
- TensorFlow version (use command below):2.1
- Python version:3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:10.0 , 7.6.5
- GPU model and memory:4G


**Describe the current behavior**

Use the following code to set the gpu, but it has no effect：
```
status = LoadSavedModel(sessionOptions, runOptions, model_path, { ""serve"" }, &bundle);
std::unique_ptr<tensorflow::Session>& session = bundle.session;
GraphDef graphdef;
session->Create(graphdef);
graph::SetDefaultDevice(""/gpu:2"", &graphdef);
```

No matter how many parameters I set, it shows that gpu is found: 0"
39949,Tflite convertor generates 2 graphs ,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 18.04):
- TensorFlow installed from (source):
- TensorFlow version (tf-nightly.2.3.0-dev20200527):

I have used the latest version of TF-nightly and used it for the quantization of a model.
The model consists of LSTM layers, when I tried to convert to tflite version it generates main and subgraph.  

The subgraph consists of LSTM while loop. How can I combine this multiple graph into a single graph.

Following is the code used for conversion 

`converter = tf.lite.TFLiteConverter.from_keras_model(model)`
`converter.optimizations = \[tf.lite.Optimize.DEFAULT\]`
`converter.experimental_new_converter = True`
`tflite_model = converter.convert()`
`open(""converted_model.tflite"", ""wb"").write(tflite_model)`"
39948,ERROR: Unrecognized option: --experimental_repo_remote_exec,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: 1.8.0
- Python version: 3.5.2
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source):0.10.0
- GCC/Compiler version (if compiling from source):6.5.0
- CUDA/cuDNN version:9.0/7.1
- GPU model and memory:1050 , 2G



**Describe the problem**
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=114
INFO: Reading rc options for 'build' from /home/why/Downloads/NVIDIA_driver&CUDA&Tensorflow/tensorflow/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
WARNING: while reading option defaults file '/home/why/Downloads/NVIDIA_driver&CUDA&Tensorflow/tensorflow/.bazelrc':
  invalid command name 'try-import'.
WARNING: while reading option defaults file '/home/why/Downloads/NVIDIA_driver&CUDA&Tensorflow/tensorflow/.bazelrc':
  invalid command name 'try-import'.
ERROR: Unrecognized option: --experimental_repo_remote_exec

**Provide the exact sequence of commands / steps that you executed before running into the problem**
bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
39947,Can't build tensorflow from source with docker image,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: 
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Mint 19.3
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: 
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: 2.2.0
- **Python version**: 3.6.9
- **Bazel version (if compiling from source)**: 3.0.0
- **GCC/Compiler version (if compiling from source)**: 7.5.0
- **CUDA/cuDNN version**:
- **GPU model and memory**: Nvidia RTX 2060 (Laptop), 6GB
-**Driver Version**: 440.59
- **Exact command to reproduce**: 
Docker version: 19.03.09
Nvidia Container Toolkit: installed and tested
Commands:
docker pull tensorflow/tensorflow:devel-py3
docker run -it -w /tensorflow_src -v $PWD:/mnt -e HOST_PERMS=""$(id -u):$(id -g)"" \
    tensorflow/tensorflow:devel-py3 bash
Within the container: 
git pull
./configure 
bazel build --config=opt --verbose_failures //tensorflow/tools pip_package:build_pip_package



### Describe the problem
I tried to build tensorflow from source with docker. 
I strictly followed the instructions from the tensorflow website, but the build is never successfull and i get an internal compiler error.
I tried it with and without Cuda support, always fails.

### Source code / logs
[tf_build_errors.txt](https://github.com/tensorflow/tensorflow/files/4695738/tf_build_errors.txt)

"
39944,per-channel quantization,"Hello,

It seem the tool by default uses ""per-channel-quantization"" is this possible to turn-off during quantization? I need that support to switch-off (switch-off per-channel quantization) since my device does not support it and is an integer only hardware accelerator.

I am looking for a way to quantize it all uniformly, so all input channels are quantized equally (in the same range) and fully. is there some special setting or the way to do it so?

Thank you for your help and advice."
39943,EagerTensor without building a function,"Hi there,

I want to create a simple pipeline to predict Survival in the Titanic dataset.
My goal to load data butch by butch from disk (I don't want to load all CSV into the memory) and made a prediction with DNNLinearCombinedClassifier.

During the testing I got  #RuntimeError: Attempting to capture an EagerTensor without building a function.#  error message. 

The script work well with this estimator:
```
preprocessing_layer = tf.keras.layers.DenseFeatures(categorical_columns+numeric_columns)

model = tf.keras.Sequential([
  preprocessing_layer,
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dense(1),
])

# compile the model
model.compile(
    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
    optimizer='adam',
    metrics=['accuracy'])

model.fit(train_data, epochs=20)
```

Here is my code:

```

import numpy as np
import tensorflow as tf

####################################################################################################
####################### helper functions ###########################################################
####################################################################################################

# load dataset from disk in to the memory batch by batch
def get_dataset(params, file_path):
  dataset = tf.data.experimental.make_csv_dataset(
      file_path,
      batch_size=1, # Artificially small to make examples easier to show.
      label_name=params['label'],
      na_value=""?"",
      num_epochs=1,
      ignore_errors=True)
  return dataset

# create feature columns for model
def generat_feature_coulumns(NUMERIC_FEATURES,CATEGORIES):
    numeric_columns = []
    for feature in NUMERIC_FEATURES:
      num_col = tf.feature_column.numeric_column(key=feature)
      numeric_columns.append(num_col)
    
    categorical_columns = []
    for feature, vocab in CATEGORIES.items():
      cat_col = tf.feature_column.categorical_column_with_vocabulary_list(
            key=feature, vocabulary_list=vocab)
      categorical_columns.append(tf.feature_column.indicator_column(cat_col))
    return   numeric_columns,categorical_columns

# helper function
def pack_row(batch, label):
    return batch, label

####################################################################################################
####################### set parameters   ###########################################################
####################################################################################################
    
# set params
params = {
        'label' : 'survived',
        'labels': [0,1],
        'train' : 'dataset/train.csv',
        'test' : 'dataset/eval.csv'  ,
        'model_dir' : 'results/'
        }

# set the numeric and categorical feature,values
NUMERIC_FEATURES = ['age','n_siblings_spouses','parch', 'fare']
CATEGORIES = {
    'sex': ['male', 'female'],
    'class' : ['First', 'Second', 'Third'],
    'deck' : ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'],
    'embark_town' : ['Cherbourg', 'Southhampton', 'Queenstown'],
    'alone' : ['y', 'n']
    }


####################################################################################################
##################################### create model #################################################
####################################################################################################
# generate numeric and categorical feature columns
numeric_columns,categorical_columns =  generat_feature_coulumns(NUMERIC_FEATURES,CATEGORIES)
# make mixed feature layer

model = tf.estimator.DNNLinearCombinedClassifier(
    model_dir=params['model_dir'],
    linear_feature_columns=[categorical_columns],
    dnn_feature_columns=[numeric_columns],
    dnn_hidden_units=[100, 50],
    n_classes = 2)

####################################################################################################
####################### train the model   ##########################################################
####################################################################################################

test_dataset = get_dataset(params,params['test'])
train_dataset = get_dataset(params,params['train'])

train_data =  train_dataset.map(pack_row).shuffle(500)
test_data = test_dataset.map(pack_row)
  
model.train(lambda: test_data, steps=100)
```"
39942,Incorrect Layer Normalization description,"Hi,
I see a [description of LayerNormalization](https://www.tensorflow.org/addons/tutorials/layers_normalizations).
According to this image:
![image](https://user-images.githubusercontent.com/1153259/83129373-64f5b280-a0e5-11ea-9f66-8f4ae4e3fbb2.png)
LayerNorm should compute mean and var across dimensions (C, H, W), thus I expect them to be 1D tensors of length N.
But the code of [tf.keras.layers.LayerNormalization](https://github.com/tensorflow/tensorflow/blob/2b96f3662bd776e277f86997659e61046b56c315/tensorflow/python/keras/layers/normalization.py#L1131) computes mean and var on 3rd dimension (which is C) and generates tensors of shape (N,H,W,1)

That seems incorrect, am I missing something? "
39941,Building libtensorflow.so 1.10.1 on Linux with GCC 4.8 and -std=c++11 doesn't export CXX11 symbols,"**System information**
- OS: CentOS 7.6
- TensorFlow installed from: source
- TensorFlow version: 1.10.1
- Python version: 2.7
- Bazel version: 0.15.0
- GCC version: 4.8.5

**Describe the problem**
When I try to build a shared TensorFlow library on CentOS 7 with the GCC 4.8 compiler the compiled library doesn't used C++11 for their exported symbols. However, when I try to use the library in a standalone program and include the TensorFlow headers it fails during linking because it expects C++11 symbols whereas they are not present in the libtensorflow.so shared library, e.g.
```undefined reference to `tensorflow::Status::ToString[abi:cxx11]() const```
where as libtensorflow_framework.so has
```T tensorflow::Status::ToString() const```.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
Priory to building I have altered `.tf_configuration.bazelrc` (imported in .bazlerc) by including
`build --cxxopt='-std=c++11'`.
Furthermore, I have added to the tensorflow/BUILD file
`linkopts = [""-std=c++11""]`
`copts = [""-std=c++11""]`
to the libtensorflow_framework.so and libtensorflow.so targets.
Finally I invoke the build with
`bazel build --cxxopt='-std=c++11' tensorflow::libtensorflow.so`
but the resulting libtensorflow.so doesn't export C++11 symbols.

When I tried building libtensorflow.so with GCC 5 on a Linux Mint machine it exported the symbols as C++11; furthermore I can compile tensorflow 2 on my Debian machine and the symbols also use C++11. For my particular purpose, though, I need to use GCC 4.8 and that's where it fails.

Is it, bychance, possible to statically link the standard C++ libraries in the tensorflow library?"
39940,Segmentation fault (core dumped),"tensorflow2.1.0 
Linux mctech 2.6.32-431.el6.x86_64
centos7
"
39939,Segmentation fault (core dumped),
39938,micro_speech example breaks when feeding it trained model on Arduino,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- TensorFlow version (use command below):
1.15
- Microcontroller used:
Arduino Nano 33 BLE Sense (Arduino 1.8.12 IDE)

**Describe the current behavior**
micro_speech example works on pretrained model, but whenever I try to train a model and run it on the device it breaks (even with ""yes"" and ""no"" words). The serial port receives the following message:

Feature generation failed
Requested feature_data_ size 536907080 doesn't match 1960.

When running test_micro_speech_test with the same model it also crashes the program (it never stops running).

The model trains fine and achieves a good accuracy on colab and it doesn't give any errors when converting either.

**Describe the expected behavior**

It should run inference just like the pretrained model.

**Standalone code to reproduce the issue**
Trained with the following notebook (didn't alter anything):
https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/micro_speech/train/train_micro_speech_model.ipynb

Using the Arduino TFLite library version 1.15
"
39937,No module named 'tensorflow.contrib',"I'm using tensorflow with python3.8, but when I run the code, the output shows: `No module named 'tensorflow.contrib'`
Detailed:
`Traceback (most recent call last):
  File ""/Users/brandonli/PycharmProjects/untitled/main.py"", line 7, in <module>
    import tflearn
  File ""/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tflearn/__init__.py"", line 4, in <module>
    from . import config
  File ""/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tflearn/config.py"", line 5, in <module>
    from .variables import variable
  File ""/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tflearn/variables.py"", line 7, in <module>
    from tensorflow.contrib.framework.python.ops import add_arg_scope as contrib_add_arg_scope
ModuleNotFoundError: No module named 'tensorflow.contrib'`
I'm running tensorflow 2.2.0
Some people say that running 1.14 could solve the problem, so I run 
`sudo pip3 install tensorflow==1.14.0` in the Terminal
but I found out that I could only install 2.2.0
Any way to solve this problem?
Running macOS Catalina
Python3.8
also working with tflearn in my code"
39936,"lstm_cell.get_initial_state(batch_size, dtype) caught 'Duplicate node name' error if batch_size is unknown","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
<ins>Yes</ins>
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
<ins>macOS Catalina version 10.15.5</ins>
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
<ins>No</ins>
- TensorFlow installed from (source or binary):
<ins>binary</ins>
- TensorFlow version (use command below):
<ins>2.1.0</ins>
- Python version:
<ins>3.7.7</ins>
- Bazel version (if compiling from source):
<ins>N/A</ins>
- GCC/Compiler version (if compiling from source):
<ins>N/A</ins>
- CUDA/cuDNN version:
<ins>N/A</ins>
- GPU model and memory:
<ins>N/A</ins>

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
Calling `get_initial_state(batch_size, dtype)` from LSTMCell caught `ValueError: Duplicate node name in graph: 'zeros/packed'` error if batch_size is unknown or inferred from `tf.shape(input)[0]`

**Describe the expected behavior**
`get_initial_state(batch_size, dtype)` returns the expected states even if batch_size is a Tensor, because often times the batch_size is unknown beforehand and could be varied from each run

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

This code works:
```
import tensorflow as tf
cell = tf.keras.layers.LSTMCell(units=32, name=""controller"")
state = cell.get_initial_state(batch_size=2, dtype=tf.float32)
print(state)
```

The following doesn't work:
```
import tensorflow as tf
cell = tf.keras.layers.LSTMCell(units=32, name=""controller"")
i = tf.keras.Input(shape=[2, 3])
state = cell.get_initial_state(batch_size=tf.shape(i)[0], dtype=tf.float32)
print(state)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
The functionality is required in a [DNC model](https://github.com/carusyte/tf-DNC/blob/2ca0f2bf7e9b2dcf45e776db0f733d434246628f/dnc/dnc.py#L148) I'm experimenting with recently."
39935,[TF 2.3.0] [Intel MKL] Eigen Threadpool Support with Intel oneDNN,"> <em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>

**PR to be submitted to replace OpenMP with Eigen Threadpool.**
Attn: @penpornk 

1. https://github.com/tensorflow/tensorflow/pull/39893 **( Merged)**
2. https://github.com/tensorflow/tensorflow/pull/39915 **(Merged)**
3. #40128 **(Merged)**
4. #40254 **(Merged)**
5.  #40488 **(Merged)**
6.  #40489 **(Merged)**

Edited by penpornk@ to update the PR list."
39934,[TF 2.3.0] [Intel MKL] BFloat16 Support for Intel CPUs,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>

**Adding support for Bfloat16 datatype for running models on Intel CPUs.**
Attn: @penpornk 
**The following PRs have been submitted for inclusion in TF2.3.0**
1. #34504 **(Closed)**; Replaced by #40596 **(Merged)**
2. #39597 **(Merged)**
3. #40212 **(Merged)**
4. #40211 **(Merged)**
5. #40455 **(Merged)** 
6. #40330 **(Merged)**
7. #40598 **(Merged)**

TF2.3.0 performance of Resnet-50-v1.5 depends on Eigen PR: 

8. [Eigen MR #84](https://gitlab.com/libeigen/eigen/-/merge_requests/84) **(Merged)**
9. #40684 **(Merged as https://github.com/tensorflow/tensorflow/commit/8cf97846290cf7d8b95256fe3123abaaa8c8e553)**

**Postponed to 2.4**
* [Change the type `tensorflow::bfloat16` to `Eigen::bfloat16`](https://gitlab.com/libeigen/eigen/-/merge_requests/84#note_365322477).
* Vectorize RandomUniform: https://github.com/tensorflow/tensorflow/pull/39747 **(Test failure)** "
39931,model = keras.models.Sequential() # I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 72.19M (75694080 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):pip
- TensorFlow version (use command below):2.1.0
- Python version:3.7.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:10.1.0
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
# building an image classifier
n_rows = 4
n_cols = 10
plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))
for row in range(n_rows):
    for col in range(n_cols):
        index = n_cols * row + col
        plt.subplot(n_rows, n_cols, index + 1)
        plt.imshow(X_train[index], cmap=""binary"", interpolation=""nearest"")
        plt.axis('off')
        plt.title(class_names[y_train[index]], fontsize=12)
plt.subplots_adjust(wspace=0.2, hspace=0.5)
save_fig('fashion_mnist_plot', tight_layout=False)
plt.show()

model = keras.models.Sequential()
model.add(keras.layers.Flatten(input_shape=[28, 28]))
model.add(keras.layers.Dense(300, activation=""relu""))
model.add(keras.layers.Dense(100, activation=""relu""))
model.add(keras.layers.Dense(10, activation=""softmax""))

**Describe the expected behavior**
model.layers

<tensorflow.python.keras.layers.core.Flatten at 0x7ff370af5780>,
 <tensorflow.python.keras.layers.core.Dense at 0x7ff370af5c88>,
 <tensorflow.python.keras.layers.core.Dense at 0x7ff330ab36d8>,
 <tensorflow.python.keras.layers.core.Dense at 0x7ff330ab3828>]

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. 
If possible, please share a link to Colab/Jupyter/any notebook.

https://colab.research.google.com/github/ageron/handson-ml2/blob/master/10_neural_nets_with_keras.ipynb#scrollTo=KQiHD3LwTRDF

**Other info / logs** 

2020-05-28 13:40:44.785958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 72 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:29:00.0, compute capability: 7.5)
2020-05-28 13:40:44.787561: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ed4ff1eab0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-05-28 13:40:44.787571: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2060 SUPER, Compute Capability 7.5
2020-05-28 13:40:44.789256: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 72.19M (75694080 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-05-28 13:40:44.796521: F ./tensorflow/core/kernels/random_op_gpu.h:232] Non-OK-status: GpuLaunchKernel(FillPhiloxRandomKernelLaunch<Distribution>, num_blocks, block_size, 0, d.stream(), gen, data, size, dist) status: Internal: out of memory
Aborted (core dumped)
"
39926,ICPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA,"```
2020-05-28 11:16:19.791171: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-05-28 11:16:19.819834: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3599930000 Hz
2020-05-28 11:16:19.820503: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x467ba80 executing computations on platform Host. Devices:
2020-05-28 11:16:19.820524: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
tf.Tensor(736.5775, shape=(), dtype=float32)
```

_Originally posted by @SarahLynnePu in https://github.com/tensorflow/tensorflow/issues/24814#issuecomment-635035003_"
39925,Missing pre-processing for Mobilenet V2 model training,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://colab.research.google.com/github/tensorflow/examples/blob/master/community/en/flowers_tf_lite.ipynb

https://github.com/tensorflow/examples/blob/master/lite/codelabs/flower_classification/android/finish/app/src/main/java/org/tensorflow/lite/examples/classification/tflite/Classifier.java#L292

## Description of issue (what needs changing):
In the above codelabs tutorial, we see image has been rescaled to [0-1] by dividing by 255. Since pre-trained weights (imagenet) are trained by feed [-1 1] normalized image. Ideally tutorial should add that step to correctly leverage transfer learning. 

### Clear description
So what is happening is we create a tflite model trained with [0-1] based preprocessing. On android client we are doing [-1 1] based preprocessing before feeding to tflite model.
Can someone please clarify?
### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

See the API guide: https://www.tensorflow.org/community/contribute/docs_ref
on how to write testable usage examples.

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
39924,DynamicPaddedBatchDatasetOp for tf.data,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): tf-nightly
- Are you willing to contribute it (Yes/No): Yes. If this feature is agreed, I'm happy to implement it.



**Describe the feature and the current behavior/state.**

`tf.data` provides a `padded_batch` transformation, but it only supports a fixed batch size. In some use cases (e.g. model inference), `dynamic_padded_batch` will bring some extra performance benefits. 

For example, for the named entity recognition model (e.g. BiLSTM-based, BERT-based), the input sentences/tokens will be required to be padded and then batched before feed into the model inference. If we use the fixed batch size, the short sentences and the long sentences may be combined together in a batch, which will add many unnecessary padding elements to the short sentences. For this kind of cases, `dynamic_padded_batch` transformation will be more efficient. It enables users to input a customized `dynamic_batch_function` to control how to split the batches. In this case, the sentences with similar lengths may be put together as a batch; If the next sentence is too long, it will be placed into the next batch; With this, the number of padding elements in each batch can be as small as possible. 

In summary,  `DynamicPaddedBatchDatasetOp` will provide users with more flexibility to control how to split the batch.


**Will this change the current api? How?**

It will not change the current api; another new operation `DynamicPaddedBatchDatasetOp` will be added; 

**Who will benefit with this feature?**

The users who use `tf.data` to build the data pipeline.

**Any Other info.**

cc: @jsimsa @aaudiber 
"
39923,NNAPI Reference does not output the same result as CPU for style transfer app on android for tensorflow lite,"I have altered this app significantly such that ""StyleTransferModelExecutor"" could configure the interpreter with more fine granularity:
For example: 
`StyleExecutor(appContext, quant = true, device = Device.NNAPI, NNAcc = ""nnapi-reference"")`

I am more than willing to share all that code, however the main point is:
running inference with: 
style_predict_quantized_256.tflite""
style_transfer_quantized_384.tflite

On CPU is different than NNAPI reference.

This is how I set the options for nnapi reference:
```
val tfliteOptions = Interpreter.Options()
var opts = NnApiDelegate.Options()
opts.setAcceleratorName(""nnapi-reference"")
tfliteOptions.addDelegate(NnApiDelegate(opts))
Interpreter(loadModelFile(context, modelName), tfliteOptions)
```

I have an instrumented test that essentially runs noise through the models, and compares the results, and the results are significantly different. 

I believe this is a bigger issue than just transfer style, and really relates to quantized models on nnapi not agreeing with cpu. I just use this app as a basis for re reproducibility

Feeding in noise:
![content](https://user-images.githubusercontent.com/16094320/83071496-10d5ca00-a022-11ea-8a42-98d64db06e93.png)
![style](https://user-images.githubusercontent.com/16094320/83071511-13d0ba80-a022-11ea-81da-79234966b65a.png)

CPU and GPU inference agree:
![cpuInference](https://user-images.githubusercontent.com/16094320/83071501-1206f700-a022-11ea-87fd-46bda36dceee.png)
![gpuInference](https://user-images.githubusercontent.com/16094320/83071504-129f8d80-a022-11ea-97ee-a0c37960ea1d.png)

NNAPI Reference differs:
![nnInference](https://user-images.githubusercontent.com/16094320/83071508-13382400-a022-11ea-9a1f-b26f9d849aac.png)
"
39922,MultiWorker Mirrored strategy fails to start with TF_CONFIG,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes. A few imports, no fundamental changes. 
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.2.0
- Python version: 3.6.9 
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
Script is getting stuck at: 
2020-05-27 12:45:54.403718: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:390] Started server with target: grpc://localhost:12345

No further further output beyond this point

**Describe the expected behavior**
The training should proceed as in tutorial.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```
import tensorflow as tf
import numpy as np
import os
import json

os.environ['TF_CONFIG'] = json.dumps({
    'cluster': {
        'worker': [""localhost:12345"", ""localhost:23456""]
    },
    'task': {'type': 'worker', 'index': 0}
})


def mnist_dataset(batch_size):
  (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()
  # The `x` arrays are in uint8 and have values in the range [0, 255].
  # We need to convert them to float32 with values in the range [0, 1]
  x_train = x_train / np.float32(255)
  y_train = y_train.astype(np.int64)
  train_dataset = tf.data.Dataset.from_tensor_slices(
      (x_train, y_train)).shuffle(60000).repeat().batch(batch_size)
  return train_dataset

def build_and_compile_cnn_model():
  model = tf.keras.Sequential([
      tf.keras.Input(shape=(28, 28)),
      tf.keras.layers.Reshape(target_shape=(28, 28, 1)),
      tf.keras.layers.Conv2D(32, 3, activation='relu'),
      tf.keras.layers.Flatten(),
      tf.keras.layers.Dense(128, activation='relu'),
      tf.keras.layers.Dense(10)
  ])
  model.compile(
      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
      optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),
      metrics=['accuracy'])
  return model

strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()

# Worker related variables
num_workers = 4
per_worker_batch_size = 64
global_batch_size = per_worker_batch_size * num_workers
multi_worker_dataset = mnist_dataset(global_batch_size)

with strategy.scope():
  # Model building/compiling need to be within `strategy.scope()`.
  multi_worker_model = build_and_compile_cnn_model()

multi_worker_model.fit(multi_worker_dataset, epochs=3, steps_per_epoch=70)
```




**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

Complete output of the script on execution:
2020-05-27 20:36:51.353890: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-05-27 20:36:51.353922: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)
2020-05-27 20:36:51.353941: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (dell3): /proc/driver/nvidia/version does not exist
2020-05-27 20:36:51.380090: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3392065000 Hz
2020-05-27 20:36:51.381000: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa764000b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-05-27 20:36:51.381033: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-05-27 20:36:51.396045: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12345, 1 -> localhost:23456}
2020-05-27 20:36:51.396385: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:390] Started server with target: grpc://localhost:12345

The code is tested on a fresh virtual environment with tensorflow. The same error is reproduced with the tensorflow/tensorflow docker container. It was also reproduced with Python 3.8.3. 

The script proceeds with execution if the code that sets the TF_CONFIG environment variable is removed. However, execution on multiple machines is not possible without setting TF_CONFIG.
"
39921,Cannot save keras model in tf format,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): tensorflow-gpu==2.0.0
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
Keras model throws an error when I'm trying to save it in .tf format
**Describe the expected behavior**
Model saved without error
**Standalone code to reproduce the issue**
```
from tensorflow.keras.layers import Input
from tensorflow.keras.layers import Conv2DTranspose
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Concatenate
import tensorflow.keras.backend as K
import tensorflow.keras as keras
class MyConcat(keras.layers.Layer):
    def __init__(self):
        super(MyConcat, self).__init__()
    def call(self, inputs):
        x, emb = inputs
        return Concatenate(axis=1)([x, emb])
    
    def compute_output_shape(self, input_shape):
        shape = (None, input_shape[0][1] + input_shape[1][1],
                input_shape[0][2], input_shape[0][3])
        return shape

```
```
inputs = Input(shape=(5,1,14))
emb = Input(shape=(512,6,18))

upconv1 = Conv2DTranspose(filters=16, 
                          kernel_size=(6,5), 
                          strides=(6,1),
                          data_format=""channels_first"")(inputs)

x = MyConcat()([upconv1, emb])

decoder = Model(inputs=[inputs, emb], outputs=x)      
decoder.save(""decoder.tf"", save_format=""tf"")
```

Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-10-1bd6aa1b259b> in <module>
     10 
     11 decoder = Model(inputs=[inputs, emb], outputs=x)
---> 12 decoder.save(""decoder.tf"", save_format=""tf"")

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py in save(self, filepath, overwrite, include_optimizer, save_format, signatures, options)
    973     """"""
    974     saving.save_model(self, filepath, overwrite, include_optimizer, save_format,
--> 975                       signatures, options)
    976 
    977   def save_weights(self, filepath, overwrite=True, save_format=None):

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py in save_model(model, filepath, overwrite, include_optimizer, save_format, signatures, options)
    113   else:
    114     saved_model_save.save(model, filepath, overwrite, include_optimizer,
--> 115                           signatures, options)
    116 
    117 

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/save.py in save(model, filepath, overwrite, include_optimizer, signatures, options)
     72   # default learning phase placeholder.
     73   with K.learning_phase_scope(0):
---> 74     save_lib.save(model, filepath, signatures, options)
     75 
     76   if not include_optimizer:

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py in save(obj, export_dir, signatures, options)
    868   if signatures is None:
    869     signatures = signature_serialization.find_function_to_export(
--> 870         checkpoint_graph_view)
    871 
    872   signatures = signature_serialization.canonicalize_signatures(signatures)

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/saved_model/signature_serialization.py in find_function_to_export(saveable_view)
     62   # If the user did not specify signatures, check the root object for a function
     63   # that can be made into a signature.
---> 64   functions = saveable_view.list_functions(saveable_view.root)
     65   signature = functions.get(DEFAULT_SIGNATURE_ATTR, None)
     66   if signature is not None:

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py in list_functions(self, obj)
    139     if obj_functions is None:
    140       obj_functions = obj._list_functions_for_serialization(  # pylint: disable=protected-access
--> 141           self._serialization_cache)
    142       self._functions[obj] = obj_functions
    143     return obj_functions

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py in _list_functions_for_serialization(self, serialization_cache)
   2420   def _list_functions_for_serialization(self, serialization_cache):
   2421     return (self._trackable_saved_model_saver
-> 2422             .list_functions_for_serialization(serialization_cache))
   2423 
   2424 

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/base_serialization.py in list_functions_for_serialization(self, serialization_cache)
     89         `ConcreteFunction`.
     90     """"""
---> 91     fns = self.functions_to_serialize(serialization_cache)
     92 
     93     # The parent AutoTrackable class saves all user-defined tf.functions, and

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/layer_serialization.py in functions_to_serialize(self, serialization_cache)
     77   def functions_to_serialize(self, serialization_cache):
     78     return (self._get_serialized_attributes(
---> 79         serialization_cache).functions_to_serialize)
     80 
     81   def _get_serialized_attributes(self, serialization_cache):

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/layer_serialization.py in _get_serialized_attributes(self, serialization_cache)
     92 
     93     object_dict, function_dict = self._get_serialized_attributes_internal(
---> 94         serialization_cache)
     95 
     96     serialized_attr.set_and_validate_objects(object_dict)

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/model_serialization.py in _get_serialized_attributes_internal(self, serialization_cache)
     51     objects, functions = (
     52         super(ModelSavedModelSaver, self)._get_serialized_attributes_internal(
---> 53             serialization_cache))
     54     functions['_default_save_signature'] = default_signature
     55     return objects, functions

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/layer_serialization.py in _get_serialized_attributes_internal(self, serialization_cache)
    101     """"""Returns dictionary of serialized attributes.""""""
    102     objects = save_impl.wrap_layer_objects(self.obj, serialization_cache)
--> 103     functions = save_impl.wrap_layer_functions(self.obj, serialization_cache)
    104     # Attribute validator requires that the default save signature is added to
    105     # function dict, even if the value is None.

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py in wrap_layer_functions(layer, serialization_cache)
    164   call_fn_with_losses = call_collection.add_function(
    165       _wrap_call_and_conditional_losses(layer),
--> 166       '{}_layer_call_and_return_conditional_losses'.format(layer.name))
    167   call_fn = call_collection.add_function(
    168       _extract_outputs_from_fn(layer, call_fn_with_losses),

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py in add_function(self, call_fn, name)
    492       # Manually add traces for layers that have keyword arguments and have
    493       # a fully defined input signature.
--> 494       self.add_trace(*self._input_signature)
    495     return fn
    496 

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py in add_trace(self, *args, **kwargs)
    411             fn.get_concrete_function(*args, **kwargs)
    412 
--> 413         trace_with_training(True)
    414         trace_with_training(False)
    415       else:

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py in trace_with_training(value, fn)
    409           utils.set_training_arg(value, self._training_arg_index, args, kwargs)
    410           with K.learning_phase_scope(value):
--> 411             fn.get_concrete_function(*args, **kwargs)
    412 
    413         trace_with_training(True)

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py in get_concrete_function(self, *args, **kwargs)
    536     if not self.call_collection.tracing:
    537       self.call_collection.add_trace(*args, **kwargs)
--> 538     return super(LayerCall, self).get_concrete_function(*args, **kwargs)
    539 
    540 

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in get_concrete_function(self, *args, **kwargs)
    774       if self._stateful_fn is None:
    775         initializer_map = object_identity.ObjectIdentityDictionary()
--> 776         self._initialize(args, kwargs, add_initializers_to=initializer_map)
    777         self._initialize_uninitialized_variables(initializer_map)
    778 

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)
    406     self._concrete_stateful_fn = (
    407         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
--> 408             *args, **kwds))
    409 
    410     def invalid_creator_scope(*unused_args, **unused_kwds):

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)
   1846     if self.input_signature:
   1847       args, kwargs = None, None
-> 1848     graph_function, _, _ = self._maybe_define_function(args, kwargs)
   1849     return graph_function
   1850 

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _maybe_define_function(self, args, kwargs)
   2148         graph_function = self._function_cache.primary.get(cache_key, None)
   2149         if graph_function is None:
-> 2150           graph_function = self._create_graph_function(args, kwargs)
   2151           self._function_cache.primary[cache_key] = graph_function
   2152         return graph_function, args, kwargs

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   2039             arg_names=arg_names,
   2040             override_flat_arg_shapes=override_flat_arg_shapes,
-> 2041             capture_by_value=self._capture_by_value),
   2042         self._function_attributes,
   2043         # Tell the ConcreteFunction to clean up its graph once it goes out of

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    913                                           converted_func)
    914 
--> 915       func_outputs = python_func(*func_args, **func_kwargs)
    916 
    917       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in wrapped_fn(*args, **kwds)
    356         # __wrapped__ allows AutoGraph to swap in a converted function. We give
    357         # the function a weak reference to itself to avoid a reference cycle.
--> 358         return weak_wrapped_fn().__wrapped__(*args, **kwds)
    359     weak_wrapped_fn = weakref.ref(wrapped_fn)
    360 

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py in wrapper(*args, **kwargs)
    513         layer, inputs=inputs, build_graph=False, training=training,
    514         saving=True):
--> 515       ret = method(*args, **kwargs)
    516     _restore_layer_losses(original_losses)
    517     return ret

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/utils.py in wrap_with_training_arg(*args, **kwargs)
    109         training,
    110         lambda: replace_training_and_call(True),
--> 111         lambda: replace_training_and_call(False))
    112 
    113   # Create arg spec for decorated function. If 'training' is not defined in the

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/tf_utils.py in smart_cond(pred, true_fn, false_fn, name)
     57         pred, true_fn=true_fn, false_fn=false_fn, name=name)
     58   return smart_module.smart_cond(
---> 59       pred, true_fn=true_fn, false_fn=false_fn, name=name)
     60 
     61 

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/framework/smart_cond.py in smart_cond(pred, true_fn, false_fn, name)
     52   if pred_value is not None:
     53     if pred_value:
---> 54       return true_fn()
     55     else:
     56       return false_fn()

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/utils.py in <lambda>()
    108     return tf_utils.smart_cond(
    109         training,
--> 110         lambda: replace_training_and_call(True),
    111         lambda: replace_training_and_call(False))
    112 

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/utils.py in replace_training_and_call(training)
    104     def replace_training_and_call(training):
    105       set_training_arg(training, training_arg_index, args, kwargs)
--> 106       return wrapped_call(*args, **kwargs)
    107 
    108     return tf_utils.smart_cond(

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py in call_and_return_conditional_losses(inputs, *args, **kwargs)
    555   layer_call = _get_layer_call_method(layer)
    556   def call_and_return_conditional_losses(inputs, *args, **kwargs):
--> 557     return layer_call(inputs, *args, **kwargs), layer.get_losses_for(inputs)
    558   return _create_call_fn_decorator(layer, call_and_return_conditional_losses)
    559 

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py in call(self, inputs, training, mask)
    706     return self._run_internal_graph(
    707         inputs, training=training, mask=mask,
--> 708         convert_kwargs_to_constants=base_layer_utils.call_context().saving)
    709 
    710   def compute_output_shape(self, input_shape):

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py in _run_internal_graph(self, inputs, training, mask, convert_kwargs_to_constants)
    858 
    859           # Compute outputs.
--> 860           output_tensors = layer(computed_tensors, **kwargs)
    861 
    862           # Update tensor_dict.

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)
    845                     outputs = base_layer_utils.mark_as_return(outputs, acd)
    846                 else:
--> 847                   outputs = call_fn(cast_inputs, *args, **kwargs)
    848 
    849             except errors.OperatorNotAllowedInGraphError as e:

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/utils.py in return_outputs_and_add_losses(*args, **kwargs)
     55     inputs = args[inputs_arg_index]
     56     args = args[inputs_arg_index + 1:]
---> 57     outputs, losses = fn(inputs, *args, **kwargs)
     58     layer.add_loss(losses, inputs)
     59     return outputs

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py in __call__(self, *args, **kwargs)
    530   def __call__(self, *args, **kwargs):
    531     if not self.call_collection.tracing:
--> 532       self.call_collection.add_trace(*args, **kwargs)
    533     return super(LayerCall, self).__call__(*args, **kwargs)
    534 

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py in add_trace(self, *args, **kwargs)
    414         trace_with_training(False)
    415       else:
--> 416         fn.get_concrete_function(*args, **kwargs)
    417     self.tracing = False
    418 

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py in get_concrete_function(self, *args, **kwargs)
    536     if not self.call_collection.tracing:
    537       self.call_collection.add_trace(*args, **kwargs)
--> 538     return super(LayerCall, self).get_concrete_function(*args, **kwargs)
    539 
    540 

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in get_concrete_function(self, *args, **kwargs)
    774       if self._stateful_fn is None:
    775         initializer_map = object_identity.ObjectIdentityDictionary()
--> 776         self._initialize(args, kwargs, add_initializers_to=initializer_map)
    777         self._initialize_uninitialized_variables(initializer_map)
    778 

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)
    406     self._concrete_stateful_fn = (
    407         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
--> 408             *args, **kwds))
    409 
    410     def invalid_creator_scope(*unused_args, **unused_kwds):

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)
   1846     if self.input_signature:
   1847       args, kwargs = None, None
-> 1848     graph_function, _, _ = self._maybe_define_function(args, kwargs)
   1849     return graph_function
   1850 

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _maybe_define_function(self, args, kwargs)
   2148         graph_function = self._function_cache.primary.get(cache_key, None)
   2149         if graph_function is None:
-> 2150           graph_function = self._create_graph_function(args, kwargs)
   2151           self._function_cache.primary[cache_key] = graph_function
   2152         return graph_function, args, kwargs

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   2039             arg_names=arg_names,
   2040             override_flat_arg_shapes=override_flat_arg_shapes,
-> 2041             capture_by_value=self._capture_by_value),
   2042         self._function_attributes,
   2043         # Tell the ConcreteFunction to clean up its graph once it goes out of

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    913                                           converted_func)
    914 
--> 915       func_outputs = python_func(*func_args, **func_kwargs)
    916 
    917       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in wrapped_fn(*args, **kwds)
    356         # __wrapped__ allows AutoGraph to swap in a converted function. We give
    357         # the function a weak reference to itself to avoid a reference cycle.
--> 358         return weak_wrapped_fn().__wrapped__(*args, **kwds)
    359     weak_wrapped_fn = weakref.ref(wrapped_fn)
    360 

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py in wrapper(*args, **kwargs)
    513         layer, inputs=inputs, build_graph=False, training=training,
    514         saving=True):
--> 515       ret = method(*args, **kwargs)
    516     _restore_layer_losses(original_losses)
    517     return ret

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py in call_and_return_conditional_losses(inputs, *args, **kwargs)
    555   layer_call = _get_layer_call_method(layer)
    556   def call_and_return_conditional_losses(inputs, *args, **kwargs):
--> 557     return layer_call(inputs, *args, **kwargs), layer.get_losses_for(inputs)
    558   return _create_call_fn_decorator(layer, call_and_return_conditional_losses)
    559 

<ipython-input-5-d4972c5cbebe> in call(self, inputs)
      4     def call(self, inputs):
      5         x, emb = inputs
----> 6         return Concatenate(axis=1)([x, emb])
      7 
      8     def compute_output_shape(self, input_shape):

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)
    815           # Build layer if applicable (if the `build` method has been
    816           # overridden).
--> 817           self._maybe_build(inputs)
    818           cast_inputs = self._maybe_cast_inputs(inputs)
    819 

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py in _maybe_build(self, inputs)
   2139         # operations.
   2140         with tf_utils.maybe_init_scope(self):
-> 2141           self.build(input_shapes)
   2142       # We must set self.built since user defined build functions are not
   2143       # constrained to set self.built.

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/tf_utils.py in wrapper(instance, input_shape)
    304     if input_shape is not None:
    305       input_shape = convert_shapes(input_shape, to_tuples=True)
--> 306     output_shape = fn(instance, input_shape)
    307     # Return shapes from `fn` as TensorShapes.
    308     if output_shape is not None:

~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/merge.py in build(self, input_shape)
    389                        'inputs with matching shapes '
    390                        'except for the concat axis. '
--> 391                        'Got inputs shapes: %s' % (input_shape))
    392 
    393   def _merge_function(self, inputs):

ValueError: A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 16, None, None), (None, 512, 6, 18)]"
39920,"    TfLiteGpuDelegate Init: Tensor ""model/tf_op_layer_Reshape/Reshape"" has bad input dims size: 5.","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Android**
- TensorFlow version (use command below): **org.tensorflow:tensorflow-lite:0.0.0-nightly / org.tensorflow:tensorflow-lite-gpu:0.0.0-nightly**
- GPU model and memory: **Hawaii Nova3 built in GPU** 

I am Trying to the run this example https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android with Yolov4 converted model (.weight -> .tflite). It worked fine on the CPU, however when enabling the **GPU** and the following error happens:

     **Caused by: java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: Following operations are not supported by GPU delegate:
    EXP: Operation is not supported.
    SPLIT_V: Operation is not supported.
    88 operations will run on the GPU, and the remaining 477 operations will run on the CPU.
    TfLiteGpuDelegate Init: Tensor ""model/tf_op_layer_Reshape/Reshape"" has bad input dims size: 5.
    TfLiteGpuDelegate Prepare: delegate is not initialized
    Node number 565 (TfLiteGpuDelegateV2) failed to prepare.
    
    Restored original execution plan after delegat
        at org.tensorflow.lite.NativeInterpreterWrapper.applyDelegate(Native Method)
        at org.tensorflow.lite.NativeInterpreterWrapper.applyDelegates(NativeInterpreterWrapper.java:347)
        at org.tensorflow.lite.NativeInterpreterWrapper.init(NativeInterpreterWrapper.java:82)
        at org.tensorflow.lite.NativeInterpreterWrapper.<init>(NativeInterpreterWrapper.java:63)
        at org.tensorflow.lite.Interpreter.<init>(Interpreter.java:237)
        at org.tensorflow.lite.examples.detection.tflite.YoloV4Classifier.create(YoloV4Classifier.java:115)
        	... 17 more**

I think this is the model part causeing this error
![image](https://user-images.githubusercontent.com/4397109/83063715-3fc35e80-a069-11ea-9965-d948804a98ea.png)

Any idea how i can overcome this issue? 
"
39918,Tflite.tensorflow  Cannot convert a Tensor of dtype resource to a NumPy array. after multi mirrored strategy training,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.3 LTS
- TensorFlow installed from (source or binary): Tnsorflow 2.2-gpu docker
- TensorFlow version (or github SHA if from source): tensorflow/tensorflow:2.2.0-gpu


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
https://github.com/uidchet/tflite-issue

```

**The output from the converter invocation**

  ```
  File ""tflite.py"", line 22, in convert_model
    tflite_model = converter.convert()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py"", line 459, in convert
    self._funcs[0], lower_control_flow=False))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/convert_to_constants.py"", line 706, in convert_variables_to_constants_v2_as_graph
    func, lower_control_flow, aggressive_inlining)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/convert_to_constants.py"", line 457, in _convert_variables_to_constants_v2_impl
    tensor_data = _get_tensor_data(func)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/convert_to_constants.py"", line 217, in _get_tensor_data
    data = val_tensor.numpy()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 961, in numpy
    maybe_arr = self._numpy()  # pylint: disable=protected-access
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 929, in _numpy
    six.raise_from(core._status_to_exception(e.code, e.message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot convert a Tensor of dtype resource to a NumPy array.

```

**Also, please include a link to the saved model or GraphDef**

```
https://github.com/uidchet/tflite-issue/blob/master/sav_model.zip
```

"
39916,segment only person,"resized_im, seg_map = MODEL.run(orignal_im)

seg_map has multiple categories,Including person.
I want get only person.What should i do？"
39913,"[TF 2.2.0/TPU]: tf.data.Dataset segmentation fault with ""the Encode() method is not implemented for DatasetVariantWrapper objects"" after calling TPUCusterResolver() ","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS 10.14.6
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): binary 
- TensorFlow version (use command below):
- Python version: v2.2.0-0-g2b96f3662b 2.2.0
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: NA
- GPU model and memory: NA
- TPU on Colab

**Describe the current behavior**
Code is crasing wgen using TPU (working fine with CPU and GPU). Exact same crashes on GCP AI Training and Colab (using TPU). After I use in my code: `tf.distribute.cluster_resolver.TPUClusterResolver()` any action of my tf.data.Dataset (from TFRecord file) like `valid_dataset.take(5)` will cash with the following error message:

```
INFO:tensorflow:Finished initializing TPU system.
INFO:tensorflow:Found TPU system:
INFO:tensorflow:*** Num TPU Cores: 8
INFO:tensorflow:*** Num TPU Workers: 1
INFO:tensorflow:*** Num TPU Cores Per Worker: 8
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)
 here start the issues!
2020-05-27 16:27:47.913455: I tensorflow/core/common_runtime/eager/execute.cc:966] Executing op TakeDataset on task /job:worker/replica:0/task:0/device:CPU:0
2020-05-27 16:27:47.913542: E tensorflow/core/framework/dataset.cc:88] The Encode() method is not implemented for DatasetVariantWrapper objects.
Fatal Python error: Segmentation fault

Current thread 0x00007f67f1a67780 (most recent call first):
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 6007 in take_dataset
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py"", line 3640 in __init__
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py"", line 1267 in take
  File ""test.py"", line 70 in main
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250 in _run_main
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299 in run
  File ""test.py"", line 78 in <module>
```

Before using `TPUCusterResolver()` I can access my data without any issue like `valid_dataset.take(5)`

Some information:
- On GCP it is always crashing
- On Colab, if I copy the full code in one cell, it working most of the time 
- On Colab, running the `!python test.py` from a cell is always cashing

**Describe the expected behavior**
Should run without crashing as before calling `TPUCusterResolver()` and the output should like that:
```
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)
 here start the issues!
Executing op TakeDataset on task /job:worker/replica:0/task:0/device:CPU:0
 take(5) not ok 1 <TakeDataset shapes: ({input_ids: (None, None), attention_mask: (None, None), token_type_ids: (None, None)}, (None,)), types: ({input_ids: tf.int32, attention_mask: tf.int32, token_type_ids: tf.int32}, tf.int64)>
Executing op TakeDataset on task /job:worker/replica:0/task:0/device:CPU:0
 take(5) not ok 2 <TakeDataset shapes: ({input_ids: (None, None), attention_mask: (None, None), token_type_ids: (None, None)}, (None,)), types: ({input_ids: tf.int32, attention_mask: tf.int32, token_type_ids: tf.int32}, tf.int64)>
```

**Standalone code to reproduce the issue**
- Go on Colab
- Choose select TPU in the runtime
- check that TF 2.2.0 is installed (is the default right now)
- normally no other packages are needed and the data are on a public GCP bucket
- In Colab create a python file called test.py and copy the full code below
- In a Colab cell run `!python test.py` --> this will seg fault
- In another Colab cell, copy the code below. It should run without any error.


```python
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'
os.environ['TF_CPP_MIN_VLOG_LEVEL'] = '0'
import tensorflow as tf
tf.get_logger().propagate = False
tf.debugging.set_log_device_placement(True)
tf.autograph.set_verbosity(5, alsologtostdout=False)
import model.tf_bert_classification.model as tf_bert
from absl import flags
from absl import app
import sys

use_tpu=True
print(""Tensorflow version"", tf.__version__)

#FLAGS = flags.FLAGS
#flags.DEFINE_string('f', '', 'kernel') # just for jupyter notebook and avoid : ""UnrecognizedFlagError: Unknown command line flag 'f'""

def main(argv):
#def main():
  def parse_tfrecord_glue_files(record):
      print("" ---> parse_tfrecord_glue_files"")
      features_spec = {
          'input_ids': tf.io.FixedLenFeature([], tf.string, default_value=''),
          'attention_mask': tf.io.FixedLenFeature([], tf.string, default_value=''),
          'token_type_ids': tf.io.FixedLenFeature([], tf.string, default_value=''),
          'label': tf.io.FixedLenFeature([], tf.int64, default_value=0)
      }
      example = tf.io.parse_single_example(record, features_spec)
      f0 = tf.ensure_shape(tf.io.parse_tensor(example['input_ids'], out_type=tf.int32), (None,))
      f1 = tf.ensure_shape(tf.io.parse_tensor(example['attention_mask'], out_type=tf.int32), (None,))
      f2 = tf.ensure_shape(tf.io.parse_tensor(example['token_type_ids'], out_type=tf.int32), (None,))
      return {'input_ids': f0, 'attention_mask': f1, 'token_type_ids': f2}, example['label']

  def build_dataset(input_tfrecords, batch_size, shuffle_buffer=2048):
      print("" ---> build_dataset"")
      file_pattern = input_tfrecords+'/*.tfrecord'
      dataset = tf.data.Dataset.list_files(file_pattern,
                                          shuffle=True,
                                          seed=None
                                          )
      dataset = dataset.interleave(tf.data.TFRecordDataset,
                                  cycle_length=tf.data.experimental.AUTOTUNE,
                                  num_parallel_calls=tf.data.experimental.AUTOTUNE,
                                  deterministic=False)
      dataset = dataset.shuffle(shuffle_buffer)
      dataset = dataset.map(parse_tfrecord_glue_files, num_parallel_calls=tf.data.experimental.AUTOTUNE)
      dataset = dataset.batch(batch_size)
      dataset = dataset.cache()
      dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)
      return dataset

  valid_dataset = build_dataset('gs://public-test-data-gs/valid', 64, 2048)
  valid_dataset = valid_dataset.repeat(2)

  print("" take(5)ok"", valid_dataset.take(5))

  if use_tpu:
    print('setting up TPU: cluster resolver')
    tpu_cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver()
    print('setting up TPU: \n {}'.format(tpu_cluster_resolver))
    print('running on TPU: \n {}'.format(tpu_cluster_resolver.cluster_spec().as_dict()['worker'])) 
    tf.config.experimental_connect_to_cluster(tpu_cluster_resolver)
    tf.tpu.experimental.initialize_tpu_system(tpu_cluster_resolver)
    strategy = tf.distribute.experimental.TPUStrategy(tpu_cluster_resolver)
  else:
     strategy = tf.distribute.MirroredStrategy()
  
  print("" here start the issues!"")
  print("" take(5) not ok 1"", valid_dataset.take(5))

  with strategy.scope():
    print("" take(5) not ok 2"", valid_dataset.take(5))

#main()
#main(sys.argv)
if __name__ == '__main__':
  app.run(main)
```

**Other info / logs** Include any logs or source code that would be helpful to

"
39912,//tensorflow/python/compiler/xla:jit_test fails on s390x and need to add support for llvm,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): N/A
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): v2.2.0
- Python version: 3.8.2
- Bazel version (if compiling from source):2.0.0
- GCC/Compiler version (if compiling from source):gcc (Ubuntu 9.3.0-10ubuntu2) 9.3.0
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
I'm building Tensorflow v2.2.0 on s390x (ibm z architecture). When running the test case //tensorflow/python/compiler/xla:jit_test, I got the following error message:

Running tests under Python 3.8.2: /usr/bin/python
[ RUN      ] CompilationEnabledInGradientTest.testCompilationGradientScopeNames_function
2020-05-20 20:23:54.560838: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 1555500000 Hz
2020-05-20 20:23:54.561101: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1fce270 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-05-20 20:23:54.561105: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
/home/sidong/.cache/bazel/_bazel_sidong/338a466d2403fbfe3413e7ca6003e4cf/execroot/org_tensorflow/bazel-out/s390x-opt/bin/tensorflow/python/compiler/xla/jit_test.runfiles/org_tensorflow/tensorflow/python/framework/indexed_slices.py:349: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working
  if not isinstance(values, collections.Sequence):
[       OK ] CompilationEnabledInGradientTest.testCompilationGradientScopeNames_function
[ RUN      ] CompilationEnabledInGradientTest.testCompilationGradientScopeNames_v1_graph
[       OK ] CompilationEnabledInGradientTest.testCompilationGradientScopeNames_v1_graph
[ RUN      ] CompilationEnabledInGradientTest.testCompilationInGradient_function
'z14' is not a recognized processor for this target (ignoring processor)
'z14' is not a recognized processor for this target (ignoring processor)
'z14' is not a recognized processor for this target (ignoring processor)
'z14' is not a recognized processor for this target (ignoring processor)
2020-05-20 20:23:54.964299: F tensorflow/compiler/xla/service/llvm_ir/llvm_util.cc:252] Check failed: module->getDataLayout().isLittleEndian() == tensorflow::port::kLittleEndian (1 vs. 0)
Fatal Python error: Aborted

Also, similar error messages were also observed in other xla related test cases. Please check below for the code to reproduce the error.

**Describe the expected behavior**
module->getDataLayout().isLittleEndian() should return 0.
test case should pass.

**Standalone code to reproduce the issue**
```
import numpy as np
import tensorflow as tf
from tensorflow.python.framework.ops import disable_eager_execution

disable_eager_execution()
sess = tf.compat.v1.Session()
with sess.as_default():
  jit_scope = tf.python.compiler.xla.jit.experimental_jit_scope
  x = tf.constant(3)
  print(x.eval())
  with jit_scope():
    y = tf.constant(5)
  print(x.eval())
  print(y.eval())
```
The first two evaluation will return 3 and the third evaluation will fail and throws the error on s390x.

**Other info / logs** 

I dug into this issue and notice that the bug may be caused by llvm configuration. I checked the file `third_party/llvm/llvm.autogenerated.BUILD` and noticed that ""SystemZ"", a target that is supported by llvm, is not listed as a target in this BUILD file. I think this could cause llvm not supporting s390x architecture correctly. Since this is an auto-generated file, I wonder how should I modify it and add support for s390x properly?
"
39909,Max and min for dynamic tensors should be recorded during calibration: Failed for tensor Shape,"**System information**
- OS Platform and Distribution: Linux Ubuntu 18.04
- TensorFlow installed using pip, it's actually tf-nightly-gpu
- TensorFlow version: tf-nightly-gpu==2.3.0.dev20200527


**Command used to run the converter or code if you’re using the Python API**

```
import numpy
import tensorflow as tf


def data_reader(size=900):
    return numpy.ones((size, 32, 86, 1), numpy.uint8) * 255


data = data_reader()
data = tf.cast(data, tf.float32)
repr_ds = tf.data.Dataset.from_tensor_slices((data)).batch(1)


def representative_data_gen():
    for input_value in repr_ds.take(100):
        yield [input_value]


converter = tf.lite.TFLiteConverter.from_saved_model(""./exported"")
converter.experimental_new_converter = True

converter.optimizations = [tf.lite.Optimize.DEFAULT]

converter.representative_dataset = representative_data_gen
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.uint8
converter.inference_output_type = tf.uint8

tflite_model = converter.convert()

open(""exported.tflite"", ""wb"").write(tflite_model)
```

```
**The output from the converter invocation**
```
Traceback (most recent call last):
  File ""..."", line 29, in <module>
    tflite_model = converter.convert()
  File ""venv/lib/python3.6/site-packages/tensorflow/lite/python/lite.py"", line 920, in convert
    return super(TFLiteConverterV2, self).convert()
  File ""venv/lib/python3.6/site-packages/tensorflow/lite/python/lite.py"", line 752, in convert
    self).convert(graph_def, input_tensors, output_tensors)
  File ""venv/lib/python3.6/site-packages/tensorflow/lite/python/lite.py"", line 502, in convert
    constants.FLOAT, False)
  File venv/lib/python3.6/site-packages/tensorflow/lite/python/lite.py"", line 349, in _calibrate_quantize_model
    inference_output_type, allow_float)
  File ""venv/lib/python3.6/site-packages/tensorflow/lite/python/optimize/calibrator.py"", line 93, in calibrate_and_quantize
    np.dtype(output_type.as_numpy_dtype()).num, allow_float)
RuntimeError: Max and min for dynamic tensors should be recorded during calibration: Failed for tensor Shape
Empty min/max for tensor Shape
```

**Also, please include a link to the saved model or GraphDef**

```
https://drive.google.com/file/d/1dSDVWjM2fJbT71r-EiUqkwygtYr0a5aE/view?usp=sharing
```

**Failure details**
I am trying to convert this model by performing full integer quantization described [here](https://www.tensorflow.org/lite/performance/post_training_quantization#full_integer_quantization_of_weights_and_activations), but it fails as described above. If I attempt to convert it without a representative dataset it works ok, but the input/output tensors remain float32 and I need int8. Maybe I am missing something, but I'd like to know if this is solvable. Thanks in advance.
"
39908,Connecting to invalid output 163 of source node GRU_1/while which has 163 outputs..,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): VERSION: 2.2.0; GIT_VERSION: v2.2.0-rc4-8-g2b96f3662b
- Python version: 3.7
- CUDA/cuDNN version: CUDA 10.1, cuDNN 7.6.5
- GPU model and memory: GTX 1080 8Gb; 16 Gb RAM

**Describe the current behavior**
My code works great on 2.1.1 but not works at 2.2.0. (**Error log №1 below**)
Empirically found that the problem appears if a dropout or recurrent_dropout is used in GRU layers.
Tried to change GRU to LSTM also, - same problem.
I tried to use tf.compat.v1.experimental.output_all_intermediates() True and False - has no effect.
At 2.2.0 it works ONLY if I remove dropout and reccurent_dropout options from GRU layers AND disable eager_execution with tf.compat.v1.disable_eager_execution() command.
But if I remove dropouts and eager is enabled - I have another error (**Error log №2 below**)

**Standalone code to reproduce the issue**  
Test case with this problem:
https://colab.research.google.com/drive/1HUayaLsHNZ30JaBlxvLyQz7Evf1FnsD5?usp=sharing

**Other info / logs** 
**Error log №1:**
```
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
   1364     try:
-> 1365       return fn(*args)
   1366     except errors.OpError as e:

14 frames
InvalidArgumentError: Node 'training/SGD/gradients/gradients/GRU_1/while_grad/GRU_1/while_grad': Connecting to invalid output 163 of source node GRU_1/while which has 163 outputs. Try using tf.compat.v1.experimental.output_all_intermediates(True).

During handling of the above exception, another exception occurred:

InvalidArgumentError                      Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
   1382                     '\nsession_config.graph_options.rewrite_options.'
   1383                     'disable_meta_optimizer = True')
-> 1384       raise type(e)(node_def, op, message)
   1385 
   1386   def _extend_graph(self):

InvalidArgumentError: Node 'training/SGD/gradients/gradients/GRU_1/while_grad/GRU_1/while_grad': Connecting to invalid output 163 of source node GRU_1/while which has 163 outputs. Try using tf.compat.v1.experimental.output_all_intermediates(True).

```

**Error log №2:**

```
tf.keras.utils.plot_model(model)

---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-14-8c47125ededc> in <module>()
----> 1 tf.keras.utils.plot_model(model)

1 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/vis_utils.py in model_to_dot(model, show_shapes, show_layer_names, rankdir, expand_nested, dpi, subgraph)
    141 
    142     # Append a wrapped layer's label to node's label, if it exists.
--> 143     layer_name = layer.name
    144     class_name = layer.__class__.__name__
    145 

AttributeError: 'dict' object has no attribute 'name'
```

```
model.fit(parsed_alldata_dataset, steps_per_epoch=1000, epochs=100)
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-15-1d2f84f55c4b> in <module>()
----> 1 model.fit(parsed_alldata_dataset, steps_per_epoch=1000, epochs=100)

10 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
    966           except Exception as e:  # pylint:disable=broad-except
    967             if hasattr(e, ""ag_error_metadata""):
--> 968               raise e.ag_error_metadata.to_exception(e)
    969             else:
    970               raise

AttributeError: in user code:

    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:571 train_function  *
        outputs = self.distribute_strategy.run(
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica
        return fn(*args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:543 train_step  **
        self.compiled_metrics.update_state(y, y_pred, sample_weight)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:391 update_state
        self._build(y_pred, y_true)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:322 _build
        self._metrics, y_true, y_pred)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py:1118 map_structure_up_to
        **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py:1214 map_structure_with_tuple_paths_up_to
        *flat_value_lists)]
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py:1213 <listcomp>
        results = [func(*args, **kwargs) for args in zip(flat_path_list,
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py:1116 <lambda>
        lambda _, *values: func(*values),  # Discards the path arg.
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:421 _get_metric_objects
        return [self._get_metric_object(m, y_t, y_p) for m in metrics]
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:421 <listcomp>
        return [self._get_metric_object(m, y_t, y_p) for m in metrics]
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:442 _get_metric_object
        y_t_rank = len(y_t.shape.as_list())

    AttributeError: 'NoneType' object has no attribute 'shape'

```
"
39907,TFlite with hexagon delegate returns wrong result. ,"**System information**
- I have written custom code
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Snapdragon 855 running Android 9
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.2.0
- Python version: python 3.8
- Bazel version (if compiling from source): 2.0.0
- GCC/Compiler version (if compiling from source): 7.5.0
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**

I'm using TFlite on a mobile device to execute a quantized NN network. Without use of delegates, 
I get the expected output image. When using the hexagon delegate, I get a white square image instead of the expected output. The dimensions and types remain the same. 

**Describe the expected behavior**

I expect to have the same output image compared to running TFlite on the same device without delegates. 


**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.


    {
       
        std::unique_ptr<tflite::FlatBufferModel> model =
                 tflite::FlatBufferModel::BuildFromFile(filename);
        TFLITE_MINIMAL_CHECK(model != nullptr);

    // Build the interpreter
    tflite::ops::builtin::BuiltinOpResolver resolver;
    InterpreterBuilder builder(*model, resolver);
    std::unique_ptr<Interpreter> interpreter;
    builder(&interpreter);
    TFLITE_MINIMAL_CHECK(interpreter != nullptr);

    // Allocate tensor buffers.
    TFLITE_MINIMAL_CHECK(interpreter->AllocateTensors() == kTfLiteOk);
    printf(""=== Pre-invoke Interpreter State ===\n"");
    tflite::PrintInterpreterState(interpreter.get());

    // input tensor type is float32
    int input = interpreter->inputs()[0];
    TfLiteIntArray* tensor_dims = interpreter->tensor(input)->dims;
    int wanted_height = tensor_dims->data[1];
    int wanted_width = tensor_dims->data[2];
    int wanted_channels = tensor_dims->data[3];

    int numberOfPixels = wanted_width*wanted_height*wanted_channels;
    if (numberOfPixels != 224*224*3) // expected input size
    {
        std::cout << ""input tensor is of wrong size"";
        exit(-1);
    }
    float * img_ptr = (float *)processedInput->getHostPtr();
    for (int k = 0; k < numberOfPixels; ++k)
    {
        interpreter->typed_tensor<float>(input)[k] = img_ptr[k];
    }


    /// setup hexagon delegate now
    const char * library_directory_path = ""/data/local/"";
    TfLiteHexagonInitWithPath(library_directory_path);  // Needed once at startup.
    TfLiteHexagonDelegateOptions params = {0};

    auto* delegate_ptr = TfLiteHexagonDelegateCreate(&params);
    Interpreter::TfLiteDelegatePtr delegate(delegate_ptr,
                                            [](TfLiteDelegate* delegate) {
                                                TfLiteHexagonDelegateDelete(delegate);
                                            });
    interpreter->ModifyGraphWithDelegate(delegate.get());



    // Run inference
    TFLITE_MINIMAL_CHECK(interpreter->Invoke() == kTfLiteOk);
    printf(""\n\n=== Post-invoke Interpreter State ===\n"");
    tflite::PrintInterpreterState(interpreter.get());

    int output = interpreter->outputs()[0];
    TfLiteIntArray* output_dims = interpreter->tensor(output)->dims;

    int output_w = output_dims->data[1]; // as expected, this 224 by 224 pixels
    int output_h = output_dims->data[2];
    numberOfPixels = output_h * output_w;

    // output tensor type is float32

    float * output_buffer = new float[numberOfPixels];
    for (int k=0; k < numberOfPixels;++k)
        output_buffer[k] = interpreter->typed_tensor<float>(output)[k];

    std::ofstream file;
    file.open(""/data/local/rgbImage_out.bin"", std::ios::binary|std::ofstream::out);
    if (file.is_open())
    {
        file.write((char *)output_buffer, 224*224*sizeof(float)); // assumed the out buffer is a vector
        file.close();

    }else{
        std::cout << ""couldn't open file"" << std::endl;
    }

    delete []  output_buffer;

    // After usage of delegate.
    TfLiteHexagonTearDown();  // Needed once at end of app/DSP usage.

     }


**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

See attached two log files which contain interpreter state prints before and after calling invoke()
for both cases - with and without a hexagon delegate
[no_delegate_log.txt](https://github.com/tensorflow/tensorflow/files/4689474/no_delegate_log.txt)
[delegate_log.txt](https://github.com/tensorflow/tensorflow/files/4689475/delegate_log.txt)


"
39906,Model cannot be saved because the input shapes have not been set.,"Hello, I'm following [save_and_serialize subclass model](https://www.tensorflow.org/guide/keras/save_and_serialize#whole-model_saving_loading) . When I run the following code,
```python
class CustomModel(tf.keras.Model):
    def __init__(self, hidden_units):
        super(CustomModel, self).__init__()
        self.dense_layers = [
            tf.keras.layers.Dense(u) for u in hidden_units]
    def call(self, inputs):
        x = inputs
        for layer in self.dense_layers:
            x = layer(x)
        return x

model = CustomModel([16, 16, 10])
# Build the model by calling it
input_arr = tf.random.uniform((1, 5))
outputs = model(input_arr)
model.save('my_custom_model')
```
I get the this error, `ValueError: Model <__main__.CustomModel object at 0x7f96797a2c10> cannot be saved because the input shapes have not been set. Usually, input shapes are automatically determined from calling .fit() or .predict(). To manually set the shapes, call model._set_inputs(inputs).`

But when I change code as following, 
```python
model = CustomModel([16, 16, 10])
input_arr = tf.random.uniform((1, 5))
outputs = model(input_arr)
model._set_inputs(input_arr) # add this line
model.save('my_custom_model')
```
It runs without any error. What could be the possible cause. Do I need to add `model._set_inputs(input_arr) ` explicitly ?

I'm using, 
`Ubuntu 20.04 LTS`
`conda environment`
`TensorFlow 2.1.1 `

Thanks
"
39905,"tensorflow.dll build with GPU support fails on Windows with ""( was unexpected at this time""","**System information**
- OS Platform and Distribution: Windows 10 Enterprise 1809
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.2.0
- Python version: 3.5.6 (via Anaconda)
- Bazel version (if compiling from source): 2.0.0
- GCC/Compiler version (if compiling from source): MS VisualStudio 2019 14.25.28610
- CUDA/cuDNN version: 10.1/7.6.5.32
- GPU model and memory: NVIDIA TITAN Xp 12GB



**Describe the problem**

Building a TF2 for GPU on Windows craches with a (likely cmd-related) error:
```( was unexpected at this time.```

This happens when building //tensorflow:tensorflow.dll, but in particular for any *_gpu target (i.e. can build a smaller target from the very beginning, will lead to the same error - alternative ""short"" command provided below as well)

**Provide the exact sequence of commands / steps that you executed before running into the problem**

Step 0: Setting up & activating a clean virtual environment as per instructions at https://www.tensorflow.org/install/source_windows, installing & upgrading MSYS2, placing [Bazel 2.0.0](https://github.com/bazelbuild/bazel/releases/download/2.0.0/bazel-2.0.0-windows-x86_64.exe) into the appropriate folder.

Step 1: Executing the following in cmd:

```
cd C:\source
git clone https://github.com/tensorflow/tensorflow.git
cd tensorflow
git checkout v2.2.0

:: setting up paths
SET PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\bin;%PATH%
SET PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\include;%PATH%
SET PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\extras\CUPTI\lib64;%PATH%
:: (CUDA_PATH points to the same v10.1 folder)
:: (cuDNN files already copied into the respective cuda folder)
SET PATH=C:\Program Files (x86)\Bazel;%PATH%
SET PATH=C:\msys64\usr\bin;%PATH%

:: setting up Bazel-related environment variables
set BAZEL_VS=C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional
set BAZEL_VC=C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\VC
set BAZEL_VC_FULL_VERSION=14.25.28610
:: (not setting BAZEL_SH since added msys64 into path, but setting it also does not help)
```

Configuration script output:
```
(TF2Build) C:\source\tensorflow>configure.cmd
You have bazel 2.0.0 installed.
Please specify the location of python. [Default is C:\Users\mikhail.startsev\Venvs\TF2Build\Scripts\python.exe]:


Found possible Python library paths:
  C:\Users\mikhail.startsev\Venvs\TF2Build\lib\site-packages
Please input the desired Python library path to use.  Default is [C:\Users\mikhail.startsev\Venvs\TF2Build\lib\site-packages]

Do you wish to build TensorFlow with ROCm support? [y/N]: n
No ROCm support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: y
CUDA support will be enabled for TensorFlow.

Found CUDA 10.1 in:
    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1/lib/x64
    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1/include
Found cuDNN 7 in:
    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1/lib/x64
    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1/include


Please specify a list of comma-separated CUDA compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only supports compute capabilities >= 3.5 [Default is: 3.5,7.0]:


Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is /arch:AVX]:


Would you like to override eigen strong inline for some C++ compilation to reduce the compilation time? [Y/n]: y
Eigen strong inline overridden.

Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: n
Not configuring the WORKSPACE for Android builds.
```

What I want to build in the end:
```
bazel build --define=no_tensorflow_py_deps=true -c opt //tensorflow/tensorflow.dll
```

What give the same errors but potentially faster (any other *_gpu target will do as well):
```
bazel build --define=no_tensorflow_py_deps=true -c opt tensorflow/core/kernels/debug_ops_gpu
```

Both result in the following lines at the end of the output (for //tensorflow/tensorflow.dll, the sub-target varies with each run, but always *_gpu):

```ERROR: C:/source/tensorflow/tensorflow/core/kernels/BUILD:2046:1: C++ compilation of rule '//tensorflow/core/kernels:gather_functor_gpu' failed (Exit 255)
( was unexpected at this time.
Target //tensorflow/core/kernels:debug_ops_gpu failed to build
```

**Any other info / logs**

For a more explicit output I ran the build with these extra options: `-s --verbose_failures --jobs=1`. The terminal output of the last subcommand is below:

``` 
INFO: Analyzed target //tensorflow/core/kernels:debug_ops_gpu (0 packages loaded, 0 targets configured).
INFO: Found 1 target...
SUBCOMMAND: # //tensorflow/core/kernels:debug_ops_gpu [action 'Compiling tensorflow/core/kernels/debug_ops_gpu.cu.cc', configuration: 0da6e0533905602ae3b4151f84e97ac897aad4120d80febd63f279c70317ba99]
cd C:/users/mikhail.startsev/_bazel_mikhail.startsev/3watukzj/execroot/org_tensorflow
  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1
    SET INCLUDE=C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\VC\Tools\MSVC\14.25.28610\ATLMFC\include;C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\VC\Tools\MSVC\14.25.28610\include;C:\Program Files (x86)\Windows Kits\NETFXSDK\4.8\include\um;C:\Program Files (x86)\Windows Kits\10\include\10.0.18362.0\ucrt;C:\Program Files (x86)\Windows Kits\10\include\10.0.18362.0\shared;C:\Program Files (x86)\Windows Kits\10\include\10.0.18362.0\um;C:\Program Files (x86)\Windows Kits\10\include\10.0.18362.0\winrt;C:\Program Files (x86)\Windows Kits\10\include\10.0.18362.0\cppwinrt
    SET LIB=C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\VC\Tools\MSVC\14.25.28610\ATLMFC\lib\x64;C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\VC\Tools\MSVC\14.25.28610\lib\x64;C:\Program Files (x86)\Windows Kits\NETFXSDK\4.8\lib\um\x64;C:\Program Files (x86)\Windows Kits\10\lib\10.0.18362.0\ucrt\x64;C:\Program Files (x86)\Windows Kits\10\lib\10.0.18362.0\um\x64;
    SET PATH=C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\VC\Tools\MSVC\14.25.28610\bin\HostX64\x64;C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\Common7\IDE\VC\VCPackages;C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\Common7\IDE\CommonExtensions\Microsoft\TestWindow;C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\Common7\IDE\CommonExtensions\Microsoft\TeamFoundation\Team Explorer;C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\MSBuild\Current\bin\Roslyn;C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\Team Tools\Performance Tools\x64;C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\Team Tools\Performance Tools;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Common\VSPerfCollectionTools\vs2019\\x64;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Common\VSPerfCollectionTools\vs2019\;C:\Program Files (x86)\Microsoft SDKs\Windows\v10.0A\bin\NETFX 4.8 Tools\x64\;C:\Program Files (x86)\Windows Kits\10\bin\10.0.18362.0\x64;C:\Program Files (x86)\Windows Kits\10\bin\x64;C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\\MSBuild\Current\Bin;C:\Windows\Microsoft.NET\Framework64\v4.0.30319;C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\Common7\IDE\;C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\Common7\Tools\;;C:\Windows\system32
    SET PWD=/proc/self/cwd
    SET PYTHON_BIN_PATH=C:/Users/mikhail.startsev/Venvs/TF2Build/Scripts/python.exe
    SET PYTHON_LIB_PATH=C:/Users/mikhail.startsev/Venvs/TF2Build/lib/site-packages
    SET RUNFILES_MANIFEST_ONLY=1
    SET TEMP=C:\Users\MIKHAI~1.STA\AppData\Local\Temp
    SET TF2_BEHAVIOR=1
    SET TF_CONFIGURE_IOS=0
    SET TF_CUDA_COMPUTE_CAPABILITIES=3.5,7.0
    SET TF_ENABLE_XLA=1
    SET TF_NEED_CUDA=1
    SET TMP=C:\Users\MIKHAI~1.STA\AppData\Local\Temp
  C:/Users/mikhail.startsev/Venvs/TF2Build/Scripts/python.exe -B external/local_config_cuda/crosstool/windows/msvc_wrapper_for_nvcc.py /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0600 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /D_SILENCE_STDEXT_HASH_DEPRECATION_WARNINGS /bigobj /Zm500 /J /Gy /GF /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /I. /Ibazel-out/x64_windows-opt/bin /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/local_config_sycl /Ibazel-out/x64_windows-opt/bin/external/local_config_sycl /Iexternal/com_google_absl /Ibazel-out/x64_windows-opt/bin/external/com_google_absl /Iexternal/nsync /Ibazel-out/x64_windows-opt/bin/external/nsync /Iexternal/gif /Ibazel-out/x64_windows-opt/bin/external/gif /Iexternal/libjpeg_turbo /Ibazel-out/x64_windows-opt/bin/external/libjpeg_turbo /Iexternal/com_google_protobuf /Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf /Iexternal/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/bin/external/com_googlesource_code_re2 /Iexternal/farmhash_archive /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive /Iexternal/fft2d /Ibazel-out/x64_windows-opt/bin/external/fft2d /Iexternal/highwayhash /Ibazel-out/x64_windows-opt/bin/external/highwayhash /Iexternal/zlib /Ibazel-out/x64_windows-opt/bin/external/zlib /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/snappy /Ibazel-out/x64_windows-opt/bin/external/snappy /Iexternal/local_config_cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda /Iexternal/local_config_tensorrt /Ibazel-out/x64_windows-opt/bin/external/local_config_tensorrt /Iexternal/mkl_dnn /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn /Iexternal/curl /Ibazel-out/x64_windows-opt/bin/external/curl /Iexternal/boringssl /Ibazel-out/x64_windows-opt/bin/external/boringssl /Iexternal/jsoncpp_git /Ibazel-out/x64_windows-opt/bin/external/jsoncpp_git /Iexternal/aws /Ibazel-out/x64_windows-opt/bin/external/aws /Iexternal/aws-c-common /Ibazel-out/x64_windows-opt/bin/external/aws-c-common /Iexternal/aws-c-event-stream /Ibazel-out/x64_windows-opt/bin/external/aws-c-event-stream /Iexternal/aws-checksums /Ibazel-out/x64_windows-opt/bin/external/aws-checksums /Iexternal/com_github_grpc_grpc /Ibazel-out/x64_windows-opt/bin/external/com_github_grpc_grpc /Iexternal/upb /Ibazel-out/x64_windows-opt/bin/external/upb /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual /Ibazel-out/x64_windows-opt/bin/external/local_config_tensorrt/_virtual_includes/tensorrt_headers /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cublas_headers_virtual /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cudnn_header /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/nsync/public /Ibazel-out/x64_windows-opt/bin/external/nsync/public /Iexternal/gif /Ibazel-out/x64_windows-opt/bin/external/gif /Iexternal/gif/windows /Ibazel-out/x64_windows-opt/bin/external/gif/windows /Iexternal/com_google_protobuf/src /Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf/src /Iexternal/farmhash_archive/src /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive/src /Iexternal/zlib /Ibazel-out/x64_windows-opt/bin/external/zlib /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/local_config_cuda/cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda /Iexternal/local_config_cuda/cuda/cuda/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cuda/include /Iexternal/local_config_cuda/cuda/cublas/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cublas/include /Iexternal/mkl_dnn/include /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/include /Iexternal/mkl_dnn/src /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src /Iexternal/mkl_dnn/src/common /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/common /Iexternal/mkl_dnn/src/cpu /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/cpu /Iexternal/mkl_dnn/src/cpu/gemm /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/cpu/gemm /Iexternal/mkl_dnn/src/cpu/xbyak /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/cpu/xbyak /Iexternal/curl/include /Ibazel-out/x64_windows-opt/bin/external/curl/include /Iexternal/boringssl/src/include /Ibazel-out/x64_windows-opt/bin/external/boringssl/src/include /Iexternal/jsoncpp_git/include /Ibazel-out/x64_windows-opt/bin/external/jsoncpp_git/include /Iexternal/aws/aws-cpp-sdk-core/include /Ibazel-out/x64_windows-opt/bin/external/aws/aws-cpp-sdk-core/include /Iexternal/aws/aws-cpp-sdk-s3/include /Ibazel-out/x64_windows-opt/bin/external/aws/aws-cpp-sdk-s3/include /Iexternal/aws/aws-cpp-sdk-transfer/include /Ibazel-out/x64_windows-opt/bin/external/aws/aws-cpp-sdk-transfer/include /Iexternal/aws-c-common/include /Ibazel-out/x64_windows-opt/bin/external/aws-c-common/include /Iexternal/aws-c-event-stream/include /Ibazel-out/x64_windows-opt/bin/external/aws-c-event-stream/include /Iexternal/aws-checksums/include /Ibazel-out/x64_windows-opt/bin/external/aws-checksums/include /Iexternal/com_github_grpc_grpc/include /Ibazel-out/x64_windows-opt/bin/external/com_github_grpc_grpc/include /Iexternal/com_github_grpc_grpc/src/core/ext/upb-generated /Ibazel-out/x64_windows-opt/bin/external/com_github_grpc_grpc/src/core/ext/upb-generated /Iexternal/com_github_grpc_grpc/third_party/address_sorting/include /Ibazel-out/x64_windows-opt/bin/external/com_github_grpc_grpc/third_party/address_sorting/include /DEIGEN_MPL2_ONLY /DEIGEN_MAX_ALIGN_BYTES=64 /DEIGEN_HAS_TYPE_TRAITS=0 /D__CLANG_SUPPORT_DYN_ANNOTATION__ /DTF_USE_SNAPPY /DTENSORFLOW_USE_CUSTOM_CONTRACTION_KERNEL /DTENSORFLOW_USE_MKLDNN_CONTRACTION_KERNEL /DCURL_STATICLIB /DPLATFORM_WINDOWS /DENABLE_CURL_CLIENT /DOPENSSL_IS_BORINGSSL /DGRPC_ARES=0 /showIncludes /MD /O2 /DNDEBUG /w /D_USE_MATH_DEFINES -DWIN32_LEAN_AND_MEAN -DNOGDI /std:c++14 -x cuda -DGOOGLE_CUDA=1 --no-cuda-include-ptx=all --cuda-include-ptx=sm_35 --cuda-gpu-arch=sm_35 --cuda-include-ptx=sm_70 --cuda-gpu-arch=sm_70 -DGOOGLE_CUDA=1 -DTENSORFLOW_USE_NVCC=1 -DTENSORFLOW_USE_XLA=1 -DTENSORFLOW_MONOLITHIC_BUILD /DPLATFORM_WINDOWS /DEIGEN_HAS_C99_MATH /DTENSORFLOW_USE_EIGEN_THREADPOOL /DEIGEN_AVOID_STL_ARRAY /Iexternal/gemmlowp /wd4018 /wd4577 /DNOGDI /DTF_COMPILE_LIBRARY -nvcc_options=relaxed-constexpr -nvcc_options=ftz=true /Fobazel-out/x64_windows-opt/bin/tensorflow/core/kernels/_objs/debug_ops_gpu/debug_ops_gpu.cu.o /c tensorflow/core/kernels/debug_ops_gpu.cu.cc
ERROR: C:/source/tensorflow/tensorflow/core/kernels/BUILD:1013:1: C++ compilation of rule '//tensorflow/core/kernels:debug_ops_gpu' failed (Exit 255)
**( was unexpected at this time.**
Target //tensorflow/core/kernels:debug_ops_gpu failed to build
INFO: Elapsed time: 1110.066s, Critical Path: 114.51s
INFO: 2748 processes: 2748 local.
FAILED: Build did NOT complete successfully
```

It is not the error of the msvc_wrapper_for_nvcc.py, since running it separately (with all the commands listed here) did not result in an error.

It seems that this type of errors (""XXX was unexpected at this time"") are cmd-specific, but the generic solution of `setlocal enableextensions enabledelayedexpansion` did not help or anyhow change anything.

**Other attempts with the same results**
* Also tried [building from the MSYS shell](https://www.tensorflow.org/install/source_windows#build_using_the_msys_shell)
* Tried using cygwin sh as BAZEL_SH
* TF2.1.0 (as well as TF2.1.1) and the master branch from the TF repo, with respective Bazel versions - 0.29.1 and 3.0.0

What _did_ work was building the tensorflow.dll without GPU support requested in configure.cmd, but that is not what I wanted to have in the end...


Overall, it seems that some batch command/script generated/used during building is malformatted, maybe because some environment variable is not set (and is expanded into and empty string) or something else, but I don't have a way to know which one, or which command exactly fails. The `-s` option to `bazel build` does not output the precise command that results into the error I am experiencing (and setting --logging to the highest value does not help either)."
39904,XLA compilation requires that operator arguments that represent shapes or dimensions be evaluated to concrete values at compile time,"Hi,

I am compiling a custom RNN with XLA (colab link to reproduce with tf-nightly https://colab.research.google.com/drive/1ehh6kklHmXSmcDs6mCdM-6y59v01dXKF?usp=sharing#scrollTo=MpeMlEwGje0n).

What I get is:
    XLA compilation requires that operator arguments that represent shapes or dimensions be evaluated to concrete values at compile time

 It could be as well that I am doing something completely wrong, though.
    
    "
39903,Can't import tensorflow ( tf-nightly-gpu),"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Window10
- TensorFlow installed from (source or binary): Anaconda
- TensorFlow version: tf-nightly-gpu    2.3.0.dev20200526
- Python version: Python 3.7.4
- Installed using virtualenv? pip? conda?: Yes
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1
- GPU model and memory:  NVIDIA GeForce RTX 2070 with Max-Q design (8GB)



**Describe the problem**
I updated my driver to the latest version, installed Visual Studio 2019 and CUDA/cuDNN version 10.1. I installed tensorflow through Anaconda prompt: pip install tf-nightly-gpu


**Provide the exact sequence of commands / steps that you executed before running into the problem**
from tensorflow.keras.applications.efficientnet import EfficientNetB0
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.efficientnet import preprocess_input


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
~\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py in <module>
     63   try:
---> 64     from tensorflow.python._pywrap_tensorflow_internal import *
     65   # This try catch logic is because there is no bazel equivalent for py_extension.

ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

ImportError                               Traceback (most recent call last)
<ipython-input-1-4eb6aa7ec913> in <module>
----> 1 from tensorflow.keras.applications.efficientnet import EfficientNetB0
      2 from tensorflow.keras.preprocessing import image
      3 from tensorflow.keras.applications.efficientnet import preprocess_input

~\Anaconda3\lib\site-packages\tensorflow\__init__.py in <module>
     39 import sys as _sys
     40 
---> 41 from tensorflow.python.tools import module_util as _module_util
     42 from tensorflow.python.util.lazy_loader import LazyLoader as _LazyLoader
     43 

~\Anaconda3\lib\site-packages\tensorflow\python\__init__.py in <module>
     48 import numpy as np
     49 
---> 50 from tensorflow.python import pywrap_tensorflow
     51 
     52 # Protocol buffers

~\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py in <module>
     81 for some common reasons and solutions.  Include the entire stack trace
     82 above this error message when asking for help."""""" % traceback.format_exc()
---> 83   raise ImportError(msg)
     84 
     85 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long

ImportError: Traceback (most recent call last):
  File ""C:\Users\G7\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 64, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

---------------------------------------------------------------------------

The installation works for my colleagues but it doesn't work for my notebook and we could not solve the problem. 

Thank you in advance!
Voravich"
39900,Keras: Regularizer not saved for Lambda layers,"**System information**
- Have I written custom code: Yes
- OS Platform and Distribution: Ubuntu 16.04.6 LTS
- TensorFlow installed from: binary, using pip
- TensorFlow version: v2.1.0-rc2-17-ge5bf8de 2.1.0
- Python version: 3.6.6
- CUDA version: 10.2

**Describe the current behavior**

Using the keras API, I can add regularizers to all layers. However, if I add a regularizer to a Lambda layer, after saving and reloading, the regularizer is not existent anymore...

**Describe the expected behavior**

I would expect that all regularizers exist after saving and reloading.

**Standalone code to reproduce the issue**

Code example:
```python
from tensorflow.keras.layers import Input, Dense, Lambda
from tensorflow.keras import regularizers
from tensorflow.keras.models import Model, load_model


layer_input = Input(shape=(None, 10), name='input')
layer_dense = Dense(12, activity_regularizer=regularizers.l2(), name='dense')(layer_input)
layer_lambda = Lambda(lambda batch: batch, activity_regularizer=regularizers.l2(), name='lambda')(layer_dense)

model = Model(inputs=layer_input, outputs=layer_lambda)
model.compile(loss='mean_squared_error')

print('* Original model *')
print('regularizer losses', model.losses)
print('regularizer dense', model.get_layer('dense').activity_regularizer)
print('regularizer lambda', model.get_layer('lambda').activity_regularizer)
print()

model.save('test.h5')
model_reloaded = load_model('test.h5')

print('* Reloaded model *')
print('regularizer losses', model_reloaded.losses)
print('regularizer dense', model_reloaded.get_layer('dense').activity_regularizer)
print('regularizer lambda', model_reloaded.get_layer('lambda').activity_regularizer)
```

Output
```
* Original model *
regularizer losses [<tf.Tensor 'dense/ActivityRegularizer/truediv:0' shape=() dtype=float32>, <tf.Tensor 'lambda/ActivityRegularizer/truediv:0' shape=() dtype=float32>]
regularizer dense <tensorflow.python.keras.regularizers.L1L2 object at 0x7f2b61e3c320>
regularizer lambda <tensorflow.python.keras.regularizers.L1L2 object at 0x7f2aeae19048>

* Reloaded model *
regularizer losses [<tf.Tensor 'dense_1/ActivityRegularizer/truediv:0' shape=() dtype=float32>]
regularizer dense <tensorflow.python.keras.regularizers.L1L2 object at 0x7f2aeaf85470>
regularizer lambda None
```"
39899,"Batch, shuffle, and unbatch","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux, TF 1.14
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 1.14
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: CPU
- GPU model and memory: CPU

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
100 elements, that are batched with a batch size of 5, shuffled, and then unbatched. The returned elements are not shuffled.

0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
**Describe the expected behavior**
100 elements, that are batched with a batch size of 5, shuffled, and then unbatched. The returned elements should be shuffled, but each 5 (batch size) consecutive elements should be unshuffled.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

`
import tensorflow as tf

dataset = tf.data.TFRecordDataset.range(100)
def dataset_fn(ds):
    ds_ = ds.batch(5).shuffle(buffer_size=100).unbatch()
    return ds_

dataset = dataset.apply(dataset_fn)

iterator = dataset.make_one_shot_iterator()
next_element = iterator.get_next()

#Actually run in a session
with tf.Session() as sess:
    for i in range(100):
        print(sess.run(next_element))
`
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
39895,[MLIR] xla hlo -> lhlo conversion issue when operand is a constant tensor,"With master branch as of 831a55584749593400807e0baa7478476b5dbc70 (May 26):
The xla hlo to lhlo lowering doesn't convert completely when the operand of an op (in this example below, that of broadcast_in_dim) is a constant tensor. To reproduce, please use:

```
func @main(%arg0: tensor<4x64x128x3xf32>, %arg1: tensor<5x3x3x10xf32>) {
  %cst = constant  dense<0.000000e+00> : tensor<f32>
  %0 = ""xla_hlo.broadcast_in_dim""(%cst) {broadcast_dimensions = dense<[]> : tensor<0xi64>, name = ""broadcast.6""} : (tensor<f32>) -> tensor<4x30x42x10xf32>
  return
}
```

and

```
$ tf-opt -hlo-legalize-to-lhlo constant-tensor-lowering.mlir 
constant-tensor-lowering.mlir:3:8: error: 'xla_lhlo.broadcast_in_dim' op operand #0 must be memref of floating-point or signless integer or complex-type values, but got 'tensor<f32>'
  %0 = ""xla_hlo.broadcast_in_dim""(%cst) {broadcast_dimensions = dense<[]> : tensor<0xi64>, name = ""broadcast.6""} : (tensor<f32>) -> tensor<4x30x42x10xf32>
       ^
constant-tensor-lowering.mlir:3:8: note: see current operation: ""xla_lhlo.broadcast_in_dim""(%cst, %0) {broadcast_dimensions = dense<[]> : tensor<0xi64>, name = ""broadcast.6""} : (tensor<f32>, memref<4x30x42x10xf32>) -> ()
```
Using `-print-ir-after-all` reveals the operand for the lhlo broadcast_in_dim op wasn't converted to a memref:


```
tuple.mlir:4:10: error: 'xla_lhlo.broadcast_in_dim' op operand #0 must be memref of floating-point or signless integer or complex-type values, but got 'tensor<f32>'
    %0 = ""xla_hlo.broadcast_in_dim""(%cst) {broadcast_dimensions = dense<[]> : tensor<0xi64>, name = ""broadcast.6""} : (tensor<f32>) -> tensor<4x30x42x10xf32>
         ^
tuple.mlir:4:10: note: see current operation: ""xla_lhlo.broadcast_in_dim""(%cst, %0) {broadcast_dimensions = dense<[]> : tensor<0xi64>, name = ""broadcast.6""} : (tensor<f32>, memref<4x30x42x10xf32>) -> ()
// *** IR Dump After mlir::detail::VerifierPass Failed ***


""module""() ( {
  ""func""() ( {
  ^bb0(%arg0: memref<4x64x128x3xf32>, %arg1: memref<5x3x3x10xf32>):  // no predecessors
    %cst = ""std.constant""() {name = ""constant.5"", value = dense<0.000000e+00> : tensor<f32>} : () -> tensor<f32>
    %0 = ""std.alloc""() : () -> memref<4x30x42x10xf32>
    ""xla_lhlo.broadcast_in_dim""(%cst, %0) {broadcast_dimensions = dense<[]> : tensor<0xi64>, name = ""broadcast.6""} : (tensor<f32>, memref<4x30x42x10xf32>) -> ()
    %1 = ""std.alloc""() : () -> memref<4x30x42x10xf32>
    ""xla_lhlo.convolution""(%arg0, %arg1, %1) {batch_group_count = 1 : i64, dimension_numbers = {input_batch_dimension = 0 : i64, input_feature_dimension = 3 : i64, input_spatial_dimensions = dense<[1, 2]> : tensor<2xi64>, kernel_input_feature_dimension = 2 : i64, kernel_output_feature_dimension = 3 : i64, kernel_spatial_dimensions = dense<[0, 1]> : tensor<2xi64>, output_batch_dimension = 0 : i64, output_feature_dimension = 3 : i64, output_spatial_dimensions = dense<[1, 2]> : tensor<2xi64>}, feature_group_count = 1 : i64, lhs_dilations = dense<1> : tensor<2xi64>, name = ""convolution.4"", padding = dense<0> : tensor<2x2xi64>, precision_config = [""DEFAULT"", ""DEFAULT""], rhs_dilations = dense<1> : tensor<2xi64>, window_strides = dense<[2, 3]> : tensor<2xi64>} : (memref<4x64x128x3xf32>, memref<5x3x3x10xf32>, memref<4x30x42x10xf32>) -> ()
    %2 = ""std.alloc""() : () -> memref<4x30x42x10xf32>
    ""xla_lhlo.maximum""(%0, %1, %2) {name = ""maximum.7""} : (memref<4x30x42x10xf32>, memref<4x30x42x10xf32>, memref<4x30x42x10xf32>) -> ()
    ""xla_lhlo.terminator""() : () -> ()
  }) {sym_name = ""main"", type = (memref<4x64x128x3xf32>, memref<5x3x3x10xf32>) -> ()} : () -> ()
  ""module_terminator""() : () -> ()
}) : () -> ()
```
This is nothing specific to broadcast_in_dim (happens with say xla_hlo.add as well). This is likely a missing conversion for std.constant that needs to be completed?"
39894,Keras Mixed Precision Policy and Horovod are incompatible.,"CC: @reedwm @nluehr @tgaddair @cliffwoolley @pkanwar23

It seems that Mixed Precision Keras policy is currently in broken state when used combined with Horovod. If you use the test repository, you can reproduce the issue (you will need 2+ GPUs) https://github.com/DEKHTIARJonathan/TF_HVD_Stability_Test.

The issues comes by the sequence of operations:
1. set_visible_devices()
2. define Keras Policy

**Reproducible Test Case:**

```bash
#!/usr/bin/env bash

export HOROVOD_GPU_ALLREDUCE=NCCL
export HOROVOD_GPU_BROADCAST=NCCL
export HOROVOD_NCCL_INCLUDE=/usr/include
export HOROVOD_NCCL_LIB=/usr/lib/x86_64-linux-gnu
export HOROVOD_NCCL_LINK=SHARED
export HOROVOD_WITHOUT_PYTORCH=1
export HOROVOD_WITHOUT_MXNET=1
export HOROVOD_WITH_TENSORFLOW=1
export HOROVOD_WITH_MPI=1
export HOROVOD_BUILD_ARCH_FLAGS=""-march=sandybridge -mtune=broadwell""
pip uninstall horovod -y
pip install --no-cache --no-cache-dir horovod==0.19.3

git clone https://github.com/DEKHTIARJonathan/TF_HVD_Stability_Test.git
cd TF_HVD_Stability_Test 

pip install -r requirements.txt
pytest
```

**Will give the following result:**

```bash
platform linux -- Python 3.6.9, pytest-5.4.2, py-1.8.1, pluggy-0.13.1 -- /usr/bin/python
cachedir: .pytest_cache
rootdir: /workspace, inifile: pytest.ini
plugins: typeguard-2.7.1
collected 18 items                                                                                                                                                                                           
test.py::HorovodTest::test_example_00_RN50_Gradient_Tape_HVD_1GPU PASSED                                                         [  5%]
test.py::HorovodTest::test_example_01_RN50_Gradient_Tape_HVD_AMP_1GPU PASSED                                                     [ 11%]
test.py::HorovodTest::test_example_02_RN50_Gradient_Tape_HVD_AMP_FP16_All_Reduce_1GPU PASSED                                     [ 16%]
test.py::HorovodTest::test_example_03_RN50_Gradient_Tape_HVD_2GPUs PASSED                                                        [ 22%]
test.py::HorovodTest::test_example_04_RN50_Gradient_Tape_HVD_AMP_2GPUs FAILED                                                    [ 27%]        # ======> FAILS
test.py::HorovodTest::test_example_05_RN50_Gradient_Tape_HVD_AMP_FP16_All_Reduce_2GPUs FAILED                                    [ 33%]        # ======> FAILS
test.py::HorovodTest::test_example_06_keras_Sequential_CTL_Gradient_Tape_HVD_1GPU PASSED                                         [ 38%]
test.py::HorovodTest::test_example_07_keras_Sequential_CTL_Gradient_Tape_HVD_AMP_1GPU PASSED                                     [ 44%]
test.py::HorovodTest::test_example_08_keras_Sequential_CTL_Gradient_Tape_HVD_AMP_FP16_All_Reduce_1GPU PASSED                     [ 50%]
test.py::HorovodTest::test_example_09_keras_Sequential_CTL_Gradient_Tape_HVD_2GPUs PASSED                                        [ 55%]
test.py::HorovodTest::test_example_10_keras_Sequential_CTL_Gradient_Tape_HVD_AMP_2GPUs FAILED                                    [ 61%]        # ======> FAILS
test.py::HorovodTest::test_example_11_keras_Sequential_CTL_Gradient_Tape_HVD_AMP_FP16_All_Reduce_2GPUs FAILED                    [ 66%]        # ======> FAILS
test.py::HorovodTest::test_example_12_keras_fit_compile_Gradient_Tape_HVD_1GPU PASSED                                            [ 72%]
test.py::HorovodTest::test_example_13_keras_fit_compile_Gradient_Tape_HVD_AMP_1GPU PASSED                                        [ 77%]
test.py::HorovodTest::test_example_14_keras_fit_compile_Gradient_Tape_HVD_AMP_FP16_All_Reduce_1GPU PASSED                        [ 83%]
test.py::HorovodTest::test_example_15_keras_fit_compile_Gradient_Tape_HVD_2GPUs PASSED                                           [ 88%]
test.py::HorovodTest::test_example_16_keras_fit_compile_Gradient_Tape_HVD_AMP_2GPUs FAILED                                       [ 94%]        # ======> FAILS
test.py::HorovodTest::test_example_17_keras_fit_compile_Gradient_Tape_HVD_AMP_FP16_All_Reduce_2GPUs FAILED                       [100%]        # ======> FAILS
```

**If we look at the traceback, the error is quite explicit:**

```python
[1,1]<stderr>:Traceback (most recent call last):
[1,1]<stderr>:  File ""examples/tf2_FitCompile_GradientTape.py"", line 49, in <module>
[1,1]<stderr>:    policy = mixed_precision.Policy('mixed_float16')
[1,1]<stderr>:  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/mixed_precision/experimental/policy.py"", line 349, in __init__
[1,1]<stderr>:    skip_local=True)
[1,1]<stderr>:  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/mixed_precision/experimental/device_compatibility_check.py"", line 157, in log_device_compatibility_check
[1,1]<stderr>:    device_attr_list = device_lib.list_local_devices()
[1,1]<stderr>:  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/device_lib.py"", line 43, in list_local_devices
[1,1]<stderr>:    _convert(s) for s in _pywrap_device_lib.list_devices(serialized_config)
[1,1]<stderr>:RuntimeError: TensorFlow device (GPU:0) is being mapped to multiple CUDA devices (0 now, and 1 previously), which is not supported. This may be the result of providing different GPU configurations (ConfigProto.gpu_options, for example different visible_device_list) when creating multiple Sessions in the same process. This is not  currently supported, see https://github.com/tensorflow/tensorflow/issues/19083
```

@reedwm so far I can see that you found a somehow linked issue: https://github.com/tensorflow/tensorflow/commit/f748283ee01059be52da5dada6e2157d9f6732ba
Unfortunately, this is not solve and is something really limiting.

To ""hot fix"" the issue, you can just comment these lines: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/mixed_precision/experimental/policy.py#L339-L341

However, I suppose that you may want to fix the issue more ""cleanly"".

@pkanwar23: one more example why we need the horovod unittests."
39892,TF 2.0 using tf.keras - Custom Loss w/ Multiple Output Model - AttributeError: 'Tensor' object has no attribute 'numpy' raised during training,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Catalina 10.15.4
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.3.0-dev20200526
- Python version: 3.6.9
- (in Google Colab - my available devices are: '/physical_device:CPU:0', '/physical_device:XLA_CPU:0', '/physical_device:XLA_GPU:0', '/physical_device:GPU:0')

**Describe the current behavior**

I'm implementing a model for source separation. It requires: 
- Two outputs (the time-frequency representation of each source)
- Custom loss function

The current behavior is: `AttributeError: 'Tensor' object has no attribute 'numpy'.`
As suggested in similar #38038, I tried converting my x, y's into tensors, ensuring eager execution, executing the code on tf nightly, but no avail.
Dummy code that replicates this and the full log is shown below.

**Describe the expected behavior**

My goal is to implement this loss function (described in this [paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6853860&tag=1)):
<img width=""344"" alt=""po-sen_loss_func"" src=""https://user-images.githubusercontent.com/25238854/82953031-4ec1e800-9f67-11ea-8506-4918e4a6ca8c.png"">

The tricky part is that for an output, along with accessing the other output's predictions, I also need to access the other's targets in the loss function. I do this by passing the targets into both x and y params of model.fit() This may not be the problem's cause but I mention it just in case 🤷‍♂️

Does anyone know how to solve this? I super appreciate it!

**Standalone code to reproduce the issue**
```
!pip install tf_nightly

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import backend as K
from tensorflow.keras.layers import Input, SimpleRNN, Dense, Lambda, TimeDistributed
from tensorflow.keras.models import Model
import numpy as np


print('Tensorflow version:', tf.__version__)
tf.config.run_functions_eagerly(True)
print('Eager execution enabled?', tf.executing_eagerly())

def make_model(input_data, features, loss_const, batch_size):

    input_layer = Input(batch_shape=(batch_size, 
                                     input_data.shape[-2], 
                                     input_data.shape[-1]),
                        dtype='float32', name='piano_noise_mixed')
    x = SimpleRNN(features // 2, 
                  activation='relu', 
                  return_sequences=True) (input_layer)
    x = SimpleRNN(features // 2, 
                  activation='relu',
                  return_sequences=True) (x)

    piano_hat = TimeDistributed(Dense(features)) (x)  # source 1 branch
    noise_hat = TimeDistributed(Dense(features)) (x)  # source 2 branch

    piano_pred = Lambda(lambda y: soft_mask(y, noise_hat, input_layer, 
                                            piano_flag=True), 
                        name='piano_pred') (piano_hat)
    noise_pred = Lambda(lambda y: soft_mask(y, piano_hat, input_layer,
                                            piano_flag=False), 
                        name='noise_pred') (noise_hat)

    # Two additional 'keras funtional API inputs' for the labels
    piano_label_layer = Input(batch_shape=(batch_size, 
                                     input_data.shape[-2], 
                                     input_data.shape[-1]),
                              dtype='float32', name='piano_true')
    noise_label_layer = Input(batch_shape=(batch_size, 
                                     input_data.shape[-2], 
                                     input_data.shape[-1]),
                              dtype='float32', name='noise_true')
    
    print('X shape (inside NN):', input_layer.shape, 
          'y1 shape (inside NN):', piano_label_layer.shape, 
          'y2 shape (inside NN):', noise_label_layer.shape)

    model = Model(inputs=[input_layer, piano_label_layer, noise_label_layer],
                  outputs=[piano_pred, noise_pred])

    model.compile(optimizer='rmsprop',
                  loss={'piano_pred': source_sep_loss(other_pred=noise_pred, 
                                           other_true=noise_label_layer,
                                           loss_const=loss_const,
                                           piano_flag=True),
                        'noise_pred': source_sep_loss(other_pred=piano_pred,
                                           other_true=piano_label_layer,
                                           loss_const=loss_const,
                                           piano_flag=False)},
                  run_eagerly=True)

    return model

def source_sep_loss(other_pred, other_true, loss_const, piano_flag=False):
    def loss_func(y_true, y_pred):
        last_dim = y_pred.shape[1] * y_pred.shape[2]
        if piano_flag:  # y_true = piano labels, y_pred = piano pred
            loss = (                
                K.sum(K.reshape(y_pred - y_true, shape=(-1, last_dim)) ** 2, axis=-1) -
                (loss_const * K.sum(K.reshape(y_pred - other_true, shape=(-1, last_dim)) ** 2, axis=-1)) +
                K.sum(K.reshape(other_pred - other_true, shape=(-1, last_dim)) ** 2, axis=-1) -
                (loss_const * K.sum(K.reshape(other_pred - y_true, shape=(-1, last_dim)) ** 2, axis=-1)))
        else:           # y_true = noise labels, y_pred = noise pred
            loss = (
                K.sum(K.reshape(other_pred - other_true, shape=(-1, last_dim)) ** 2, axis=-1) -
                (loss_const * K.sum(K.reshape(other_pred - y_true, shape=(-1, last_dim)) ** 2, axis=-1)) +
                K.sum(K.reshape(y_pred - y_true, shape=(-1, last_dim)) ** 2, axis=-1) -
                (loss_const * K.sum(K.reshape(y_pred - other_true, shape=(-1, last_dim)) ** 2, axis=-1)))
        return loss
    return loss_func

def soft_mask(y_hat_self, y_hat_other, x_mixed, piano_flag):
    mask = y_hat_self / (y_hat_self + y_hat_other)
    ones = tf.convert_to_tensor(np.ones(mask.shape).astype('float32'))
    y_tilde_self = mask * x_mixed if (piano_flag) else (ones - mask) * x_mixed

    return y_tilde_self


total_samples = 6
batch_size = 2
time_steps = 3
features = 4
loss_const = 2
epochs = 10
val_split = 0.25

X = tf.convert_to_tensor(np.random.rand(total_samples, time_steps, features))
y1 = tf.convert_to_tensor(np.random.rand(total_samples, time_steps, features))
y2 = tf.convert_to_tensor(np.random.rand(total_samples, time_steps, features))
print('X shape:', X.shape, 'y1 shape:', y1.shape, 'y2 shape:', y2.shape)

model = make_model(X, features, loss_const, batch_size)
print(model.summary())

model.fit({'piano_noise_mixed': X, 'piano_true': y1, 'noise_true': y2},
          {'piano_pred': y1, 'noise_pred': y2},
          validation_split=val_split,
          epochs=epochs, batch_size=batch_size)
```

**Other info / logs**
```
Requirement already satisfied: tf_nightly in /usr/local/lib/python3.6/dist-packages (2.3.0.dev20200526)
Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (1.1.2)
Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (3.2.1)
Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (2.10.0)
Requirement already satisfied: tb-nightly<2.4.0a0,>=2.3.0a0 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (2.3.0a20200526)
Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (0.2.0)
Requirement already satisfied: tf-estimator-nightly in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (2.3.0.dev2020052101)
Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (1.12.1)
Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (1.4.1)
Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (1.1.0)
Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (1.6.3)
Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (0.9.0)
Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (1.12.0)
Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (3.10.0)
Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (1.29.0)
Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (0.34.2)
Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (1.18.4)
Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (0.3.3)
Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf_nightly) (2.23.0)
Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf_nightly) (1.6.0.post3)
Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf_nightly) (3.2.2)
Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf_nightly) (46.3.0)
Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf_nightly) (1.7.2)
Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf_nightly) (1.0.1)
Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf_nightly) (0.4.1)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf_nightly) (1.24.3)
Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf_nightly) (3.0.4)
Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf_nightly) (2.9)
Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf_nightly) (2020.4.5.1)
Requirement already satisfied: importlib-metadata; python_version < ""3.8"" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tb-nightly<2.4.0a0,>=2.3.0a0->tf_nightly) (1.6.0)
Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf_nightly) (3.1.1)
Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf_nightly) (4.0)
Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf_nightly) (0.2.8)
Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.4.0a0,>=2.3.0a0->tf_nightly) (1.3.0)
Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < ""3.8""->markdown>=2.6.8->tb-nightly<2.4.0a0,>=2.3.0a0->tf_nightly) (3.1.0)
Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf_nightly) (0.4.8)
Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.4.0a0,>=2.3.0a0->tf_nightly) (3.1.0)
Tensorflow version: 2.3.0-dev20200526
Eager execution enabled? True
X shape: (6, 3, 4) y1 shape: (6, 3, 4) y2 shape: (6, 3, 4)
X shape (inside NN): (2, 3, 4) y1 shape (inside NN): (2, 3, 4) y2 shape (inside NN): (2, 3, 4)
Model: ""functional_1""
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
piano_noise_mixed (InputLayer)  [(2, 3, 4)]          0                                            
__________________________________________________________________________________________________
simple_rnn (SimpleRNN)          (2, 3, 2)            14          piano_noise_mixed[0][0]          
__________________________________________________________________________________________________
simple_rnn_1 (SimpleRNN)        (2, 3, 2)            10          simple_rnn[0][0]                 
__________________________________________________________________________________________________
time_distributed (TimeDistribut (2, 3, 4)            12          simple_rnn_1[0][0]               
__________________________________________________________________________________________________
time_distributed_1 (TimeDistrib (2, 3, 4)            12          simple_rnn_1[0][0]               
__________________________________________________________________________________________________
piano_true (InputLayer)         [(2, 3, 4)]          0                                            
__________________________________________________________________________________________________
noise_true (InputLayer)         [(2, 3, 4)]          0                                            
__________________________________________________________________________________________________
piano_pred (Lambda)             (2, 3, 4)            0           time_distributed[0][0]           
__________________________________________________________________________________________________
noise_pred (Lambda)             (2, 3, 4)            0           time_distributed_1[0][0]         
==================================================================================================
Total params: 48
Trainable params: 48
Non-trainable params: 0
__________________________________________________________________________________________________
None
Epoch 1/10
/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3274: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.
  ""Even though the tf.config.experimental_run_functions_eagerly ""
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-1-36baddb059fc> in <module>()
    114           {'piano_pred': y1, 'noise_pred': y2},
    115           validation_split=val_split,
--> 116           epochs=epochs, batch_size=batch_size)

15 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)
    106   def _method_wrapper(self, *args, **kwargs):
    107     if not self._in_multi_worker_mode():  # pylint: disable=protected-access
--> 108       return method(self, *args, **kwargs)
    109 
    110     # Running inside `run_distribute_coordinator` already.

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
   1088                 batch_size=batch_size):
   1089               callbacks.on_train_batch_begin(step)
-> 1090               tmp_logs = train_function(iterator)
   1091               if data_handler.should_sync:
   1092                 context.async_wait()

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in train_function(iterator)
    801       def train_function(iterator):
    802         """"""Runs a training execution with one step.""""""
--> 803         return step_function(self, iterator)
    804 
    805     else:

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in step_function(model, iterator)
    791 
    792       data = next(iterator)
--> 793       outputs = model.distribute_strategy.run(run_step, args=(data,))
    794       outputs = reduce_per_replica(
    795           outputs, self.distribute_strategy, reduction='first')

/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py in run(***failed resolving arguments***)
    967       fn = autograph.tf_convert(
    968           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)
--> 969       return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    970 
    971   # TODO(b/151224785): Remove deprecated alias.

/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py in call_for_each_replica(self, fn, args, kwargs)
   2350       kwargs = {}
   2351     with self._container_strategy().scope():
-> 2352       return self._call_for_each_replica(fn, args, kwargs)
   2353 
   2354   def _call_for_each_replica(self, fn, args, kwargs):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py in _call_for_each_replica(self, fn, args, kwargs)
   2709         self._container_strategy(),
   2710         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):
-> 2711       return fn(*args, **kwargs)
   2712 
   2713   def _reduce_to(self, reduce_op, value, destinations, experimental_hints):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py in wrapper(*args, **kwargs)
    273   def wrapper(*args, **kwargs):
    274     with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.UNSPECIFIED):
--> 275       return func(*args, **kwargs)
    276 
    277   if inspect.isfunction(func) or inspect.ismethod(func):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in run_step(data)
    784 
    785       def run_step(data):
--> 786         outputs = model.train_step(data)
    787         # Ensure counter is updated only if `train_step` succeeds.
    788         with ops.control_dependencies(_minimum_control_deps(outputs)):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in train_step(self, data)
    752     # such as loss scaling and gradient clipping.
    753     _minimize(self.distribute_strategy, tape, self.optimizer, loss,
--> 754               self.trainable_variables)
    755 
    756     self.compiled_metrics.update_state(y, y_pred, sample_weight)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in _minimize(strategy, tape, optimizer, loss, trainable_variables)
   2672       loss = optimizer.get_scaled_loss(loss)
   2673 
-> 2674   gradients = tape.gradient(loss, trainable_variables)
   2675 
   2676   # Whether to aggregate gradients outside of optimizer. This requires support

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/backprop.py in gradient(self, target, sources, output_gradients, unconnected_gradients)
   1057         output_gradients=output_gradients,
   1058         sources_raw=flat_sources_raw,
-> 1059         unconnected_gradients=unconnected_gradients)
   1060 
   1061     if not self._persistent:

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/imperative_grad.py in imperative_grad(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)
     75       output_gradients,
     76       sources_raw,
---> 77       compat.as_str(unconnected_gradients.value))

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/backprop.py in _gradient_function(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)
    154       gradient_name_scope += forward_pass_name_scope + ""/""
    155     with ops.name_scope(gradient_name_scope):
--> 156       return grad_fn(mock_op, *out_grads)
    157   else:
    158     return grad_fn(mock_op, *out_grads)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py in _SumGrad(op, grad)
    209       # more sense.
    210       output_shape_kept_dims = math_ops.reduced_shape(input_shape,
--> 211                                                       op.inputs[1])
    212     grad = array_ops.reshape(grad, output_shape_kept_dims)
    213   return [array_ops.broadcast_to(grad, input_shape), None]

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py in reduced_shape(input_shape, axes)
   3807   """"""
   3808   if context.executing_eagerly():
-> 3809     input_shape = input_shape.numpy()
   3810     axes = axes.numpy()
   3811     input_shape[axes] = 1

AttributeError: 'Tensor' object has no attribute 'numpy'
```"
39891,TF2.2 ImportError: cannot import name 'dense_features',"When importing hooks_helper from official, see the following issue pop up.

Traceback (most recent call last):
  File ""inference/fp32/wide_deep_inference.py"", line 46, in <module>
    from official.utils.logs import hooks_helper
  File ""/nfs/site/home/jojimonv/CIMonitor/Models/new/models/official/utils/logs/hooks_helper.py"", line 29, in <module>
    from official.utils.logs import hooks
  File ""/nfs/site/home/jojimonv/CIMonitor/Models/new/models/official/utils/logs/hooks.py"", line 26, in <module>
    class ExamplesPerSecondHook(tf.estimator.SessionRunHook):
  File ""/ec/pdx/disks/aipg_lab_home_pool_02/jojimonv/tfv2_new/lib/python3.6/site-packages/tensorflow/python/util/lazy_loader.py"", line 62, in __getattr__
    module = self._load()
  File ""/ec/pdx/disks/aipg_lab_home_pool_02/jojimonv/tfv2_new/lib/python3.6/site-packages/tensorflow/python/util/lazy_loader.py"", line 45, in _load
    module = importlib.import_module(self.__name__)
  File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""/ec/pdx/disks/aipg_lab_home_pool_02/jojimonv/tfv2_new/lib/python3.6/site-packages/tensorflow_estimator/__init__.py"", line 10, in <module>
    from tensorflow_estimator._api.v1 import estimator
  File ""/ec/pdx/disks/aipg_lab_home_pool_02/jojimonv/tfv2_new/lib/python3.6/site-packages/tensorflow_estimator/_api/v1/estimator/__init__.py"", line 10, in <module>
    from tensorflow_estimator._api.v1.estimator import experimental
  File ""/ec/pdx/disks/aipg_lab_home_pool_02/jojimonv/tfv2_new/lib/python3.6/site-packages/tensorflow_estimator/_api/v1/estimator/experimental/__init__.py"", line 10, in <module>
    from tensorflow_estimator.python.estimator.canned.dnn import dnn_logit_fn_builder
  File ""/ec/pdx/disks/aipg_lab_home_pool_02/jojimonv/tfv2_new/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/canned/dnn.py"", line 23, in <module>
    from tensorflow.python.feature_column import dense_features
ImportError: cannot import name 'dense_features'
Running Wide_Deep model Inference in Latency mode
"
39890,pip install Eigen:AVX512 build,"Is it possible to pip install TF-Eigen-build with AVX512 support?

I would like to install TF2 on my server and it seems like packages `tensorflow `and `tensorflow`-cpu are not built with AVX512 enabled because I get the following warning.

`Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA`

ref: [stakoverflow
](https://stackoverflow.com/questions/62015863/how-to-install-tensorflow-2-x-with-eigen-avx512-support)"
39888,Incompatible shapes using `sample_weight` in Graph execution,"Works fine in Eager. Code + error below; pasted outputs are from a Colab instance with `tf.__version__ == 2.3.0-dev20200526`, also reproduced in 2.2.0 and on Windows 10. No error in TF 1.14.0 Graph.

<hr>

**Attempted debug**: Placing below [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/utils/losses_utils.py#L111) (in local install)

```python
print(sample_weight)
try: print(""sample_weight ="", K.eval(sample_weight))
except: pass
print(loss, '\n')
```

yields:

```python
# EAGER
Tensor(""ExpandDims:0"", shape=(32, 1), dtype=float32)
Tensor(""mean_squared_error/weighted_loss/value:0"", shape=(), dtype=float32)

Tensor(""ExpandDims:0"", shape=(32, 1), dtype=float32)
Tensor(""mean_squared_error/weighted_loss/value:0"", shape=(), dtype=float32)

# GRAPH
1.0
sample_weight = 1.0
Tensor(""loss/conv2d_loss/weighted_loss/Mul:0"", shape=(32, 28, 28), dtype=float32)

Tensor(""conv2d_sample_weights:0"", shape=(None,), dtype=float32)
sample_weight = [1.]
Tensor(""loss_1/conv2d_loss/weighted_loss/Mul:0"", shape=(32, 28, 28), dtype=float32)
```
Graph handles `sample_weight` tensor differently; also see example at bottom.

<hr>

**Reproducible code + Error**:

```python
import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Input, Conv2D
from tensorflow.keras.models import Model
tf.compat.v1.disable_eager_execution()

batch_shape = (32, 28, 28, 1)

ipt = Input(batch_shape=batch_shape)
out = Conv2D(filters=1, kernel_size=(1, 1))(ipt)
model = Model(ipt, out)
model.compile('adam', 'mse')

x = y = np.random.randn(*batch_shape)
sw = np.ones(len(x))

model.train_on_batch(x, y, sw)
```

```python
/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in __call__(self, *args, **kwargs)
   1470         ret = tf_session.TF_SessionRunCallable(self._session._session,
   1471                                                self._handle, args,
-> 1472                                                run_metadata_ptr)
   1473         if run_metadata:
   1474           proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)
InvalidArgumentError: Incompatible shapes: [32] vs. [32,28,28]
	 [[{{node training/Adam/gradients/gradients/loss_1/conv2d_loss/weighted_loss/Mul_grad/Mul}}]]
```

<hr>

**No error case**: both Graph and Eager work fine if output shape is instead 2D.

<details>
   <summary><b>Example code</b></summary>

```python
import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten
from tensorflow.keras.models import Model

tf.compat.v1.disable_eager_execution()

batch_shape = (32, 28, 28, 1)

ipt = Input(batch_shape=batch_shape)
x   = Conv2D(filters=1, kernel_size=(1, 1))(ipt)
x   = Flatten()(x)
out = Dense(10, activation='softmax')(x)
model = Model(ipt, out)
model.compile('adam', 'categorical_crossentropy')

x = np.random.randn(*batch_shape)
n_classes, batch_size = 10, 32
class_labels = np.random.randint(0, n_classes, batch_size)
y = np.eye(n_classes)[class_labels]
sw = np.random.uniform(0, 2, (len(x),))

model.train_on_batch(x, y, sw)
```
```
sample_weight = 1.0
Tensor(""loss/dense_loss/weighted_loss/Mul:0"", shape=(32,), dtype=float32)
Tensor(""dense_sample_weights:0"", shape=(None,), dtype=float32)
sample_weight = [1.]
Tensor(""loss_1/dense_loss/weighted_loss/Mul:0"", shape=(32,), dtype=float32)
```
</details>

_However_, `sample_weight` still prints `[1.]`, even though we passed in `np.random.uniform(0, 2, ...)`."
39886,Unexpected behaviour of tf.image.convert_image_dtype,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): tf-nightly
- Python version: 3.6.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
Convert a `tf.int32` tensor to `tf.float32` seems underflow. As shown in the below code, I think `c` should be the right result, correct me if I am wrong.

**Describe the expected behavior**
The `tf.int32` tensorf should be scaled to `[0, 1]`, as documented.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```python
a = tf.reshape(tf.range(0, 12), shape=(3, 4))
print(a)
print(tf.reduce_mean(a), '\n')

b = tf.image.convert_image_dtype(a, dtype=tf.float32)
print(b)
print(tf.reduce_mean(b), '\n')

c = a / tf.reduce_max(a)
print(c)
print(tf.reduce_mean(c))

# output
tf.Tensor(
[[ 0  1  2  3]
 [ 4  5  6  7]
 [ 8  9 10 11]], shape=(3, 4), dtype=int32)
tf.Tensor(5, shape=(), dtype=int32) 

tf.Tensor(
[[0.0000000e+00 4.6566129e-10 9.3132257e-10 1.3969839e-09]
 [1.8626451e-09 2.3283064e-09 2.7939677e-09 3.2596290e-09]
 [3.7252903e-09 4.1909516e-09 4.6566129e-09 5.1222742e-09]], shape=(3, 4), dtype=float32)
tf.Tensor(2.561137e-09, shape=(), dtype=float32) 

tf.Tensor(
[[0.         0.09090909 0.18181818 0.27272727]
 [0.36363636 0.45454545 0.54545455 0.63636364]
 [0.72727273 0.81818182 0.90909091 1.        ]], shape=(3, 4), dtype=float64)
tf.Tensor(0.5, shape=(), dtype=float64)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
39885,object of type <class 'numpy.float64'> cannot be safely interpreted as an integer,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution : Linux Ubuntu 18.04

- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.15.0
- Python version: 3.7.4 

- CUDA/cuDNN version: 10.2 
- GPU model and memory: GeForce GTX 1050



**Describe the current behavior**
hey guys, i'm trying to train an object detection 3 classes model using resnet101 faster rcnn using model_main.py from object detection api,
label map : 

```
item {
  id: 1
  name: 'ooredoo'
  id: 2
  name: 'tt'
  id: 3
  name: 'orange'
}
```

config file  : 

```
# Faster R-CNN with Resnet-101 (v1), configuration for MSCOCO Dataset.
# Users should configure the fine_tune_checkpoint field in the train config as
# well as the label_map_path and input_path fields in the train_input_reader and
# eval_input_reader. Search for ""PATH_TO_BE_CONFIGURED"" to find the fields that
# should be configured.

model {
  faster_rcnn {
    num_classes: 3
    image_resizer {
      keep_aspect_ratio_resizer {
        min_dimension: 600
        max_dimension: 1024
      }
    }
    feature_extractor {
      type: 'faster_rcnn_resnet101'
      first_stage_features_stride: 16
    }
    first_stage_anchor_generator {
      grid_anchor_generator {
        scales: [0.25, 0.5, 1.0, 2.0]
        aspect_ratios: [0.5, 1.0, 2.0]
        height_stride: 16
        width_stride: 16
      }
    }
    first_stage_box_predictor_conv_hyperparams {
      op: CONV
      regularizer {
        l2_regularizer {
          weight: 0.0
        }
      }
      initializer {
        truncated_normal_initializer {
          stddev: 0.01
        }
      }
    }
    first_stage_nms_score_threshold: 0.0
    first_stage_nms_iou_threshold: 0.7
    first_stage_max_proposals: 300
    first_stage_localization_loss_weight: 2.0
    first_stage_objectness_loss_weight: 1.0
    initial_crop_size: 14
    maxpool_kernel_size: 2
    maxpool_stride: 2
    second_stage_box_predictor {
      mask_rcnn_box_predictor {
        use_dropout: false
        dropout_keep_probability: 1.0
        fc_hyperparams {
          op: FC
          regularizer {
            l2_regularizer {
              weight: 0.0
            }
          }
          initializer {
            variance_scaling_initializer {
              factor: 1.0
              uniform: true
              mode: FAN_AVG
            }
          }
        }
      }
    }
    second_stage_post_processing {
      batch_non_max_suppression {
        score_threshold: 0.0
        iou_threshold: 0.6
        max_detections_per_class: 100
        max_total_detections: 300
      }
      score_converter: SOFTMAX
    }
    second_stage_localization_loss_weight: 2.0
    second_stage_classification_loss_weight: 1.0
  }
}

train_config: {
  batch_size: 1
  optimizer {
    momentum_optimizer: {
      learning_rate: {
        manual_step_learning_rate {
          initial_learning_rate: 0.0003
          schedule {
            step: 300
            learning_rate: .00003
          }
          schedule {
            step: 600
            learning_rate: .000003
          }
        }
      }
      momentum_optimizer_value: 0.9
    }
    use_moving_average: false
  }
  gradient_clipping_by_norm: 10.0
  fine_tune_checkpoint: ""faster_rcnn_resnet101_coco_2018_01_28/model.ckpt""
  from_detection_checkpoint: true
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
}

train_input_reader: {
  tf_record_input_reader {
    input_path: ""data/train.record""
  }
  label_map_path: ""data/comm.pbtxt""
}

eval_config: {
  num_examples: 22
  # Note: The below line limits the evaluation process to 10 evaluations.
  # Remove the below line to evaluate indefinitely.
  max_evals: 10
}

eval_input_reader: {
  tf_record_input_reader {
    input_path: ""data/test.record""
  }
  label_map_path: ""data/comm.pbtxt""
  shuffle: false
  num_readers: 1
}

```
20-05-26 21:46:32.527504: W tensorflow/core/framework/op_kernel.cc:1639] Invalid argument: TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.
Traceback (most recent call last):

  File ""/home/milos/anaconda3/lib/python3.7/site-packages/numpy/core/function_base.py"", line 117, in linspace
    num = operator.index(num)

TypeError: 'numpy.float64' object cannot be interpreted as an integer


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py"", line 235, in __call__
    ret = func(*args)

  File ""/home/milos/Documents/research/object_detection/object_detection/metrics/coco_evaluation.py"", line 415, in first_value_func
    self._metrics = self.evaluate()

  File ""/home/milos/Documents/research/object_detection/object_detection/metrics/coco_evaluation.py"", line 246, in evaluate
    coco_wrapped_groundtruth, coco_wrapped_detections, agnostic_mode=False)

  File ""/home/milos/Documents/research/object_detection/object_detection/metrics/coco_tools.py"", line 177, in __init__
    cocoeval.COCOeval.__init__(self, groundtruth, detections, iouType=iou_type)

  File ""/home/milos/.local/lib/python3.7/site-packages/pycocotools/cocoeval.py"", line 76, in __init__
    self.params = Params(iouType=iouType) # parameters

  File ""/home/milos/.local/lib/python3.7/site-packages/pycocotools/cocoeval.py"", line 527, in __init__
    self.setDetParams()

  File ""/home/milos/.local/lib/python3.7/site-packages/pycocotools/cocoeval.py"", line 507, in setDetParams
    self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05) + 1, endpoint=True)

  File ""<__array_function__ internals>"", line 6, in linspace

  File ""/home/milos/anaconda3/lib/python3.7/site-packages/numpy/core/function_base.py"", line 121, in linspace
    .format(type(num)))

TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.


Traceback (most recent call last):
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call
    return fn(*args)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn
    target_list, run_metadata)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.OutOfRangeError: End of sequence
	 [[{{node IteratorGetNext}}]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/evaluation.py"", line 272, in _evaluate_once
    session.run(eval_ops, feed_dict)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py"", line 754, in run
    run_metadata=run_metadata)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py"", line 1259, in run
    run_metadata=run_metadata)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py"", line 1360, in run
    raise six.reraise(*original_exc_info)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/six.py"", line 703, in reraise
    raise value
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py"", line 1345, in run
    return self._sess.run(*args, **kwargs)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py"", line 1418, in run
    run_metadata=run_metadata)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py"", line 1176, in run
    return self._sess.run(*args, **kwargs)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 956, in run
    run_metadata_ptr)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 1180, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run
    run_metadata)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.OutOfRangeError: End of sequence
	 [[node IteratorGetNext (defined at /home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]

Original stack trace for 'IteratorGetNext':
  File ""model_main.py"", line 111, in <module>
    tf.app.run()
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""model_main.py"", line 107, in main
    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py"", line 473, in train_and_evaluate
    return executor.run()
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py"", line 613, in run
    return self.run_local()
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py"", line 714, in run_local
    saving_listeners=saving_listeners)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 370, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1161, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1195, in _train_model_default
    saving_listeners)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1494, in _train_with_estimator_spec
    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py"", line 754, in run
    run_metadata=run_metadata)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py"", line 1259, in run
    run_metadata=run_metadata)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py"", line 1345, in run
    return self._sess.run(*args, **kwargs)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py"", line 1426, in run
    run_metadata=run_metadata))
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/basic_session_run_hooks.py"", line 594, in after_run
    if self._save(run_context.session, global_step):
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/basic_session_run_hooks.py"", line 619, in _save
    if l.after_save(session, step):
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py"", line 519, in after_save
    self._evaluate(global_step_value)  # updates self.eval_result
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py"", line 539, in _evaluate
    self._evaluator.evaluate_and_export())
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py"", line 920, in evaluate_and_export
    hooks=self._eval_spec.hooks)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 480, in evaluate
    name=name)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 522, in _actual_eval
    return _evaluate()
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 504, in _evaluate
    self._evaluate_build_graph(input_fn, hooks, checkpoint_path))
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1511, in _evaluate_build_graph
    self._call_model_fn_eval(input_fn, self.config))
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1544, in _call_model_fn_eval
    input_fn, ModeKeys.EVAL)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1025, in _get_features_and_labels_from_input_fn
    self._call_input_fn(input_fn, mode))
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/util.py"", line 65, in parse_input_fn_result
    result = iterator.get_next()
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/iterator_ops.py"", line 426, in get_next
    name=name)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_dataset_ops.py"", line 2518, in iterator_get_next
    output_shapes=output_shapes, name=name)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py"", line 794, in _apply_op_helper
    op_def=op_def)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 3357, in create_op
    attrs, op_def, compute_device)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 3426, in _create_op_internal
    op_def=op_def)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 1748, in __init__
    self._traceback = tf_stack.extract_stack()


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call
    return fn(*args)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn
    target_list, run_metadata)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.InvalidArgumentError: TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.
Traceback (most recent call last):

  File ""/home/milos/anaconda3/lib/python3.7/site-packages/numpy/core/function_base.py"", line 117, in linspace
    num = operator.index(num)

TypeError: 'numpy.float64' object cannot be interpreted as an integer


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py"", line 235, in __call__
    ret = func(*args)

  File ""/home/milos/Documents/research/object_detection/object_detection/metrics/coco_evaluation.py"", line 415, in first_value_func
    self._metrics = self.evaluate()

  File ""/home/milos/Documents/research/object_detection/object_detection/metrics/coco_evaluation.py"", line 246, in evaluate
    coco_wrapped_groundtruth, coco_wrapped_detections, agnostic_mode=False)

  File ""/home/milos/Documents/research/object_detection/object_detection/metrics/coco_tools.py"", line 177, in __init__
    cocoeval.COCOeval.__init__(self, groundtruth, detections, iouType=iou_type)

  File ""/home/milos/.local/lib/python3.7/site-packages/pycocotools/cocoeval.py"", line 76, in __init__
    self.params = Params(iouType=iouType) # parameters

  File ""/home/milos/.local/lib/python3.7/site-packages/pycocotools/cocoeval.py"", line 527, in __init__
    self.setDetParams()

  File ""/home/milos/.local/lib/python3.7/site-packages/pycocotools/cocoeval.py"", line 507, in setDetParams
    self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05) + 1, endpoint=True)

  File ""<__array_function__ internals>"", line 6, in linspace

  File ""/home/milos/anaconda3/lib/python3.7/site-packages/numpy/core/function_base.py"", line 121, in linspace
    .format(type(num)))

TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.


	 [[{{node PyFunc_3}}]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""model_main.py"", line 111, in <module>
    tf.app.run()
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""model_main.py"", line 107, in main
    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py"", line 473, in train_and_evaluate
    return executor.run()
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py"", line 613, in run
    return self.run_local()
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py"", line 714, in run_local
    saving_listeners=saving_listeners)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 370, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1161, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1195, in _train_model_default
    saving_listeners)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1494, in _train_with_estimator_spec
    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py"", line 754, in run
    run_metadata=run_metadata)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py"", line 1259, in run
    run_metadata=run_metadata)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py"", line 1360, in run
    raise six.reraise(*original_exc_info)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/six.py"", line 703, in reraise
    raise value
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py"", line 1345, in run
    return self._sess.run(*args, **kwargs)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py"", line 1426, in run
    run_metadata=run_metadata))
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/basic_session_run_hooks.py"", line 594, in after_run
    if self._save(run_context.session, global_step):
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/basic_session_run_hooks.py"", line 619, in _save
    if l.after_save(session, step):
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py"", line 519, in after_save
    self._evaluate(global_step_value)  # updates self.eval_result
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py"", line 539, in _evaluate
    self._evaluator.evaluate_and_export())
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py"", line 920, in evaluate_and_export
    hooks=self._eval_spec.hooks)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 480, in evaluate
    name=name)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 522, in _actual_eval
    return _evaluate()
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 511, in _evaluate
    output_dir=self.eval_dir(name))
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1619, in _evaluate_run
    config=self._session_config)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/evaluation.py"", line 272, in _evaluate_once
    session.run(eval_ops, feed_dict)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py"", line 861, in __exit__
    self._close_internal(exception_type)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py"", line 894, in _close_internal
    h.end(self._coordinated_creator.tf_sess)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/basic_session_run_hooks.py"", line 951, in end
    self._final_ops, feed_dict=self._final_ops_feed_dict)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 956, in run
    run_metadata_ptr)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 1180, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run
    run_metadata)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.
Traceback (most recent call last):

  File ""/home/milos/anaconda3/lib/python3.7/site-packages/numpy/core/function_base.py"", line 117, in linspace
    num = operator.index(num)

TypeError: 'numpy.float64' object cannot be interpreted as an integer


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py"", line 235, in __call__
    ret = func(*args)

  File ""/home/milos/Documents/research/object_detection/object_detection/metrics/coco_evaluation.py"", line 415, in first_value_func
    self._metrics = self.evaluate()

  File ""/home/milos/Documents/research/object_detection/object_detection/metrics/coco_evaluation.py"", line 246, in evaluate
    coco_wrapped_groundtruth, coco_wrapped_detections, agnostic_mode=False)

  File ""/home/milos/Documents/research/object_detection/object_detection/metrics/coco_tools.py"", line 177, in __init__
    cocoeval.COCOeval.__init__(self, groundtruth, detections, iouType=iou_type)

  File ""/home/milos/.local/lib/python3.7/site-packages/pycocotools/cocoeval.py"", line 76, in __init__
    self.params = Params(iouType=iouType) # parameters

  File ""/home/milos/.local/lib/python3.7/site-packages/pycocotools/cocoeval.py"", line 527, in __init__
    self.setDetParams()

  File ""/home/milos/.local/lib/python3.7/site-packages/pycocotools/cocoeval.py"", line 507, in setDetParams
    self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05) + 1, endpoint=True)

  File ""<__array_function__ internals>"", line 6, in linspace

  File ""/home/milos/anaconda3/lib/python3.7/site-packages/numpy/core/function_base.py"", line 121, in linspace
    .format(type(num)))

TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.


	 [[node PyFunc_3 (defined at /home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]

Original stack trace for 'PyFunc_3':
  File ""model_main.py"", line 111, in <module>
    tf.app.run()
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""model_main.py"", line 107, in main
    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py"", line 473, in train_and_evaluate
    return executor.run()
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py"", line 613, in run
    return self.run_local()
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py"", line 714, in run_local
    saving_listeners=saving_listeners)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 370, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1161, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1195, in _train_model_default
    saving_listeners)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1494, in _train_with_estimator_spec
    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py"", line 754, in run
    run_metadata=run_metadata)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py"", line 1259, in run
    run_metadata=run_metadata)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py"", line 1345, in run
    return self._sess.run(*args, **kwargs)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py"", line 1426, in run
    run_metadata=run_metadata))
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/basic_session_run_hooks.py"", line 594, in after_run
    if self._save(run_context.session, global_step):
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/basic_session_run_hooks.py"", line 619, in _save
    if l.after_save(session, step):
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py"", line 519, in after_save
    self._evaluate(global_step_value)  # updates self.eval_result
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py"", line 539, in _evaluate
    self._evaluator.evaluate_and_export())
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py"", line 920, in evaluate_and_export
    hooks=self._eval_spec.hooks)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 480, in evaluate
    name=name)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 522, in _actual_eval
    return _evaluate()
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 504, in _evaluate
    self._evaluate_build_graph(input_fn, hooks, checkpoint_path))
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1511, in _evaluate_build_graph
    self._call_model_fn_eval(input_fn, self.config))
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1547, in _call_model_fn_eval
    features, labels, ModeKeys.EVAL, config)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1149, in _call_model_fn
    model_fn_results = self._model_fn(features=features, **kwargs)
  File ""/home/milos/Documents/research/object_detection/object_detection/model_lib.py"", line 539, in model_fn
    eval_config, list(category_index.values()), eval_dict)
  File ""/home/milos/Documents/research/object_detection/object_detection/eval_util.py"", line 1034, in get_eval_metric_ops_for_evaluators
    eval_dict))
  File ""/home/milos/Documents/research/object_detection/object_detection/metrics/coco_evaluation.py"", line 425, in get_estimator_eval_metric_ops
    first_value_op = tf.py_func(first_value_func, [], tf.float32)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func
    return func(*args, **kwargs)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py"", line 513, in py_func
    return py_func_common(func, inp, Tout, stateful, name=name)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py"", line 495, in py_func_common
    func=func, inp=inp, Tout=Tout, stateful=stateful, eager=False, name=name)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py"", line 318, in _internal_py_func
    input=inp, token=token, Tout=Tout, name=name)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_script_ops.py"", line 170, in py_func
    ""PyFunc"", input=input, token=token, Tout=Tout, name=name)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py"", line 794, in _apply_op_helper
    op_def=op_def)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 3357, in create_op
    attrs, op_def, compute_device)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 3426, in _create_op_internal
    op_def=op_def)
  File ""/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 1748, in __init__
    self._traceback = tf_stack.extract_stack()

ps : using labelImg to csv then to tf records

this is the code i'm using for to_csv : 
```
import os
import glob
import pandas as pd
import xml.etree.ElementTree as ET


def xml_to_csv(path):
    xml_list = []
    for xml_file in glob.glob(path + '/*.xml'):
        tree = ET.parse(xml_file)
        root = tree.getroot()
        for member in root.findall('object'):
            value = (root.find('filename').text,
                     int(root.find('size')[0].text),
                     int(root.find('size')[1].text),
                     member[0].text,
                     int(member[4][0].text),
                     int(member[4][1].text),
                     int(member[4][2].text),
                     int(member[4][3].text)
                     )
            xml_list.append(value)
    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']
    xml_df = pd.DataFrame(xml_list, columns=column_name)
    return xml_df


def main():
  for directory in ['train','test'] :
    image_path = os.path.join(os.getcwd(), 'images/{}'.format(directory))
    xml_df = xml_to_csv(image_path)
    xml_df.to_csv('data/{}_labels.csv'.format(directory), index=None)
    print('Successfully converted xml to csv.')


main()
```


code to generate tfrecords:
```

""""""
Usage:
  # From tensorflow/models/
  # Create train data:
  python generate_tfrecord.py --csv_input=data/train_labels.csv  --output_path=train.record

  # Create test data:
  python generate_tfrecord.py --csv_input=data/test_labels.csv  --output_path=test.record
""""""
from __future__ import division
from __future__ import print_function
from __future__ import absolute_import

import os
import io
import pandas as pd
import tensorflow as tf

from PIL import Image
from object_detection.utils import dataset_util
from collections import namedtuple, OrderedDict

flags = tf.app.flags
flags.DEFINE_string('csv_input', '', 'Path to the CSV input')
flags.DEFINE_string('output_path', '', 'Path to output TFRecord')
flags.DEFINE_string('image_dir', '', 'Path to images')
FLAGS = flags.FLAGS


# TO-DO replace this with label map
def class_text_to_int(row_label):
    if row_label == 'ooredoo':
        return 1
    elif row_label == 'tt' :
        return 2
    elif row_label == 'orange' :
        return 3
    else:
        None


def split(df, group):
    data = namedtuple('data', ['filename', 'object'])
    gb = df.groupby(group)
    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]


def create_tf_example(group, path):
    with tf.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:
        encoded_jpg = fid.read()
    encoded_jpg_io = io.BytesIO(encoded_jpg)
    image = Image.open(encoded_jpg_io)
    width, height = image.size

    filename = group.filename.encode('utf8')
    image_format = b'jpg'
    xmins = []
    xmaxs = []
    ymins = []
    ymaxs = []
    classes_text = []
    classes = []

    for index, row in group.object.iterrows():
        xmins.append(row['xmin'] / width)
        xmaxs.append(row['xmax'] / width)
        ymins.append(row['ymin'] / height)
        ymaxs.append(row['ymax'] / height)
        classes_text.append(row['class'].encode('utf8'))
        classes.append(class_text_to_int(row['class']))

    tf_example = tf.train.Example(features=tf.train.Features(feature={
        'image/height': dataset_util.int64_feature(height),
        'image/width': dataset_util.int64_feature(width),
        'image/filename': dataset_util.bytes_feature(filename),
        'image/source_id': dataset_util.bytes_feature(filename),
        'image/encoded': dataset_util.bytes_feature(encoded_jpg),
        'image/format': dataset_util.bytes_feature(image_format),
        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),
        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),
        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),
        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),
        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),
        'image/object/class/label': dataset_util.int64_list_feature(classes),
    }))
    return tf_example


def main(_):
    writer = tf.python_io.TFRecordWriter(FLAGS.output_path)
    path = os.path.join(FLAGS.image_dir)
    examples = pd.read_csv(FLAGS.csv_input)
    grouped = split(examples, 'filename')
    for group in grouped:
        tf_example = create_tf_example(group, path)
        writer.write(tf_example.SerializeToString())

    writer.close()
    output_path = os.path.join(os.getcwd(), FLAGS.output_path)
    print('Successfully created the TFRecords: {}'.format(output_path))


if __name__ == '__main__':
    tf.app.run()

```

i know it's index related and i can't figure out a way to solve it"
39884,Be able to specifiy the row split dtypes in a keras Ragged Input layer ,"**System information**
- TensorFlow version (you are using): Nightlies
- Are you willing to contribute it (Yes/No): depends


**Describe the feature and the current behavior/state.**
Currently to create a ragged input we use:
````
q = tf.keras.layers.Input(ragged=True, dtype=tf.int32, shape=(None,), )
````
we can specify the dtype of the values array but not the one from the row_split array.

**Will this change the current api? How?**
We should be able to provide the dtype we want to use for the row_split array as well:

````
q = tf.keras.layers.Input(ragged=True, dtype=tf.int32, shape=(None,),  row_split_dtype=tf.int32)
````
instead of the default int64.

**Who will benefit with this feature?**
Users with small array with no need for an offset array of 64;

**Any Other info.**
"
39883,test_fit_with_ModelCheckpoint_with_dir_as_h5_filepath test failure in //tensorflow/python/keras:callbacks_test,"Hello,

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **N/A**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Linux Ubuntu 18.04 x86_64**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): **source** 
- TensorFlow version (use command below):  **v2.2.0**
- Python version: **3.6.9**
- Bazel version (if compiling from source): **2.0.0**
- GCC/Compiler version (if compiling from source):  **gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0**
- CUDA/cuDNN version: **N/A**
- GPU model and memory: **N/A**

**Describe the current behavior**
When running the test cases on 2.2.0, I encountered an error in `//tensorflow/python/keras:callbacks_test`

The failed test log snippet is:
```
FAIL: test_fit_with_ModelCheckpoint_with_dir_as_h5_filepath (__main__.KerasCallbacksTest)
test_fit_with_ModelCheckpoint_with_dir_as_h5_filepath (__main__.KerasCallbacksTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/home/peterbao/.cache/bazel/_bazel_peterbao/c55b467aea9f5b6a0b36d1bc596dae4f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/keras/callbacks_test.runfiles/org_tensorflow/tensorflow/python/keras/callbacks_test.py"", line 821, in test_fit_with_ModelCheckpoint_with_dir_as_h5_filepath
    model.fit(train_ds, epochs=1, callbacks=[callback])
AssertionError: OSError not raised
``` 

**Describe the expected behavior**
`test_fit_with_ModelCheckpoint_with_dir_as_h5_filepath `  and `//tensorflow/python/keras:callbacks_test` to pass


**Standalone code to reproduce the issue**

The test case `test_fit_with_ModelCheckpoint_with_dir_as_h5_filepath` appears to be introduced in https://github.com/tensorflow/tensorflow/commit/50256e69b727e49025020e80ab98d5d05d4c7dcc and seems not changed after that. So I am thinking the test case would still fail on the master. To reproduce the failure, you can run `//tensorflow/python/keras:callbacks_test`.

**Other info / logs** 

I spent some time looking into the test case , and this is what I noticed,
```
(Pdb) list
1225                self.model.save(filepath, overwrite=True)
1226
1227            self._maybe_remove_file()
1228          except IOError as e:
1229            # `e.errno` appears to be `None` so checking the content of `e.args[0]`.
1230 ->         if 'is a directory' in six.ensure_str(e.args[0]):
1231              raise IOError('Please specify a non-directory filepath for '
1232                            'ModelCheckpoint. Filepath used is an existing '
1233                            'directory: {}'.format(filepath))
1234
1235      def _get_file_path(self, epoch, logs):
(Pdb) p e.args[0]
""Unable to create file (unable to open file: name = '/tmp/tem49izq6ff/tmplrdc03ul/temp.h5', errno = 21, error message = 'Is a directory', flags = 13, o_flags = 242)""
```
It looks like the code above wants an error message to be `is a directory` but the OSError actually has `Is a directory` as the error message. As a result, the more detailed error message is not outputted here and that results `test_fit_with_ModelCheckpoint_with_dir_as_h5_filepath` to be failing.

Based on this information, I think the following can fix the problem:
```
diff --git a/tensorflow/python/keras/callbacks.py b/tensorflow/python/keras/callbacks.py
index bb9e61d01a..bfad1112d7 100644
--- a/tensorflow/python/keras/callbacks.py
+++ b/tensorflow/python/keras/callbacks.py
@@ -1227,7 +1227,7 @@ class ModelCheckpoint(Callback):
         self._maybe_remove_file()
       except IOError as e:
         # `e.errno` appears to be `None` so checking the content of `e.args[0]`.
-        if 'is a directory' in six.ensure_str(e.args[0]):
+        if 'Is a directory' in six.ensure_str(e.args[0]):
           raise IOError('Please specify a non-directory filepath for '
                         'ModelCheckpoint. Filepath used is an existing '
                         'directory: {}'.format(filepath))
```

Let me know if more information is needed.

Thanks,
Peter"
39882,Add n-dimensional tensor support for tf.unique and tf.unique_with_counts,"Feature request for tf.unique and tf.unique_with_counts:
1. can apply to n-D tensor
2. can select which axis to apply it

**System information**
- TensorFlow version : 2.2.0
- Python version : 3.6.9

"
39880,KeyError: 'acc' in multi_worker_fault_tolerance_test,"In TF 2.2.0, it appears that `Key` name has been changed to `accuracy` from `acc` recently which is causing this testcase to fail.

```
======================================================================
ERROR: testFaultToleranceInSyncStrategy_test_fileformat_h5_loadweightsonrestart_False_mode_graph_preemptioncallback_classmainKerasMultiWorkerFaultToleranceTestPreemptionAtBatchBoundarySimulatingCallback_requiredgpus_0_saveweightsonly_False_strategycls_classtensorflowpythondistributecollectiveallreducestrategyCollectiveAllReduceStrategy (__main__.KerasMultiWorkerFaultToleranceTest)
testFaultToleranceInSyncStrategy_test_fileformat_h5_loadweightsonrestart_False_mode_graph_preemptioncallback_classmainKerasMultiWorkerFaultToleranceTestPreemptionAtBatchBoundarySimulatingCallback_requiredgpus_0_saveweightsonly_False_strategycls_classtensorflowpythondistributecollectiveallreducestrategyCollectiveAllReduceStrategy (__main__.KerasMultiWorkerFaultToleranceTest)
testFaultToleranceInSyncStrategy_test_fileformat_h5_loadweightsonrestart_False_mode_graph_preemptioncallback_classmainKerasMultiWorkerFaultToleranceTestPreemptionAtBatchBoundarySimulatingCallback_requiredgpus_0_saveweightsonly_False_strategycls_classtensorflowpythondistributecollectiveallreducestrategyCollectiveAllReduceStrategy(file_format='h5', load_weights_on_restart=False, mode='graph', preemption_callback=<class '__main__.KerasMultiWorkerFaultToleranceTest.PreemptionAtBatchBoundarySimulatingCallback'>, required_gpus=0, save_weights_only=False, strategy_cls=<class 'tensorflow.python.distribute.collective_all_reduce_strategy.CollectiveAllReduceStrategy'>)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/dist-packages/absl/testing/parameterized.py"", line 263, in bound_param_test
    test_method(self, **testcase_params)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/test_combinations.py"", line 314, in decorated
    execute_test_method()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/test_combinations.py"", line 297, in execute_test_method
    test_method(**kwargs_to_pass)
  File ""tensorflow/python/keras/distribute/multi_worker_fault_tolerance_test.py"", line 331, in testFaultToleranceInSyncStrategy
    [history['acc'][-1] for history in self._histories])
  File ""tensorflow/python/keras/distribute/multi_worker_fault_tolerance_test.py"", line 331, in <listcomp>
    [history['acc'][-1] for history in self._histories])
KeyError: 'acc'

```
https://github.com/tensorflow/tensorflow/blob/509325e1b12df34e5d06117ac58242de58bd7798/tensorflow/python/keras/distribute/multi_worker_fault_tolerance_test.py#L331

On my system here are the `self._histories` contains:
```
-> [history['acc'][-1] for history in self._histories])
(Pdb) pp self._histories
[{'accuracy': [1.0, 1.0, 1.0],
  'loss': [2.2476557890574136, 2.1090187231699624, 1.9728290637334187]},
 {'accuracy': [1.0, 1.0, 1.0],
  'loss': [2.2476557890574136, 2.1090187231699624, 1.9728290637334187]},
 {'accuracy': [1.0, 1.0], 'loss': [2.1090187231699624, 1.9728290637334187]},
 {'accuracy': [1.0, 1.0], 'loss': [2.1090187231699624, 1.9728290637334187]}]
(Pdb)
```
Following change fixes this error:

```
diff --git a/tensorflow/python/keras/distribute/multi_worker_fault_tolerance_test.py b/tensorflow/python/keras/distribute/multi_worker_fault_tolerance_test.py
index fa58d2479a..f026ed1cae 100644
--- a/tensorflow/python/keras/distribute/multi_worker_fault_tolerance_test.py
+++ b/tensorflow/python/keras/distribute/multi_worker_fault_tolerance_test.py
@@ -328,17 +328,17 @@ class KerasMultiWorkerFaultToleranceTest(test_base.IndependentWorkerTestBase,
     # Important: the results from preemption interrupted and non-interrupted
     # cases should give the same final results.
     assert_all_elements_are_identical(
-        [history['acc'][-1] for history in self._histories])
+        [history['accuracy'][-1] for history in self._histories])
     assert_all_elements_are_identical(
         [history['loss'][-1] for history in self._histories])
     # The length of `self._histories` would be num_workers * num_runs (3).
     self.assertLen(self._histories, 4)

     # Results from case 1 should have 3 full epochs.
-    self.assertLen(self._histories[0]['acc'], 3)
+    self.assertLen(self._histories[0]['accuracy'], 3)
     # Results from case 2 should only have 2 full epochs because it restarted at
     # epoch 1.
-    self.assertLen(self._histories[-1]['acc'], 2)
+    self.assertLen(self._histories[-1]['accuracy'], 2)


 if __name__ == '__main__':
```
Please let me know if this is an acceptable fix.

Thanks."
39879,The following classes have no ground truth,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution : Linux Ubuntu 18.04

- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.15.0
- Python version: 3.7.4 

- CUDA/cuDNN version: 10.2 
- GPU model and memory: GeForce GTX 1050



**Describe the current behavior**
hey guys, i'm trying to train an object detection 3 classes model using resnet101 faster rcnn using train.py from legacy folder from object detection api,
the losses looks very good but when running eval.py i get a very low mAP of the 3rd one only
with this warning : 
object_detection_evaluation.py:1279] The following classes have no ground truth examples: [1 2]

label map : 

```
item {
  id: 1
  name: 'ooredoo'
  id: 2
  name: 'tt'
  id: 3
  name: 'orange'
}
```


config file  : 

```
# Faster R-CNN with Resnet-101 (v1), configuration for MSCOCO Dataset.
# Users should configure the fine_tune_checkpoint field in the train config as
# well as the label_map_path and input_path fields in the train_input_reader and
# eval_input_reader. Search for ""PATH_TO_BE_CONFIGURED"" to find the fields that
# should be configured.

model {
  faster_rcnn {
    num_classes: 3
    image_resizer {
      keep_aspect_ratio_resizer {
        min_dimension: 600
        max_dimension: 1024
      }
    }
    feature_extractor {
      type: 'faster_rcnn_resnet101'
      first_stage_features_stride: 16
    }
    first_stage_anchor_generator {
      grid_anchor_generator {
        scales: [0.25, 0.5, 1.0, 2.0]
        aspect_ratios: [0.5, 1.0, 2.0]
        height_stride: 16
        width_stride: 16
      }
    }
    first_stage_box_predictor_conv_hyperparams {
      op: CONV
      regularizer {
        l2_regularizer {
          weight: 0.0
        }
      }
      initializer {
        truncated_normal_initializer {
          stddev: 0.01
        }
      }
    }
    first_stage_nms_score_threshold: 0.0
    first_stage_nms_iou_threshold: 0.7
    first_stage_max_proposals: 300
    first_stage_localization_loss_weight: 2.0
    first_stage_objectness_loss_weight: 1.0
    initial_crop_size: 14
    maxpool_kernel_size: 2
    maxpool_stride: 2
    second_stage_box_predictor {
      mask_rcnn_box_predictor {
        use_dropout: false
        dropout_keep_probability: 1.0
        fc_hyperparams {
          op: FC
          regularizer {
            l2_regularizer {
              weight: 0.0
            }
          }
          initializer {
            variance_scaling_initializer {
              factor: 1.0
              uniform: true
              mode: FAN_AVG
            }
          }
        }
      }
    }
    second_stage_post_processing {
      batch_non_max_suppression {
        score_threshold: 0.0
        iou_threshold: 0.6
        max_detections_per_class: 100
        max_total_detections: 300
      }
      score_converter: SOFTMAX
    }
    second_stage_localization_loss_weight: 2.0
    second_stage_classification_loss_weight: 1.0
  }
}

train_config: {
  batch_size: 1
  optimizer {
    momentum_optimizer: {
      learning_rate: {
        manual_step_learning_rate {
          initial_learning_rate: 0.0003
          schedule {
            step: 300
            learning_rate: .00003
          }
          schedule {
            step: 600
            learning_rate: .000003
          }
        }
      }
      momentum_optimizer_value: 0.9
    }
    use_moving_average: false
  }
  gradient_clipping_by_norm: 10.0
  fine_tune_checkpoint: ""faster_rcnn_resnet101_coco_2018_01_28/model.ckpt""
  from_detection_checkpoint: true
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
}

train_input_reader: {
  tf_record_input_reader {
    input_path: ""data/train.record""
  }
  label_map_path: ""data/comm.pbtxt""
}

eval_config: {
  num_examples: 22
  # Note: The below line limits the evaluation process to 10 evaluations.
  # Remove the below line to evaluate indefinitely.
  max_evals: 10
}

eval_input_reader: {
  tf_record_input_reader {
    input_path: ""data/test.record""
  }
  label_map_path: ""data/comm.pbtxt""
  shuffle: false
  num_readers: 1
}

```

already checked https://github.com/tensorflow/models/issues/1936 and https://github.com/tensorflow/models/issues/1696 
 
ps : using labelImg to csv then to tf records

this is the code i'm using for to_csv : 
```
import os
import glob
import pandas as pd
import xml.etree.ElementTree as ET


def xml_to_csv(path):
    xml_list = []
    for xml_file in glob.glob(path + '/*.xml'):
        tree = ET.parse(xml_file)
        root = tree.getroot()
        for member in root.findall('object'):
            value = (root.find('filename').text,
                     int(root.find('size')[0].text),
                     int(root.find('size')[1].text),
                     member[0].text,
                     int(member[4][0].text),
                     int(member[4][1].text),
                     int(member[4][2].text),
                     int(member[4][3].text)
                     )
            xml_list.append(value)
    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']
    xml_df = pd.DataFrame(xml_list, columns=column_name)
    return xml_df


def main():
  for directory in ['train','test'] :
    image_path = os.path.join(os.getcwd(), 'images/{}'.format(directory))
    xml_df = xml_to_csv(image_path)
    xml_df.to_csv('data/{}_labels.csv'.format(directory), index=None)
    print('Successfully converted xml to csv.')


main()
```"
39878,MeanSquaredError truncated to 32-bit precision when using 64-bit,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Mint 19.2
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.3.0-dev20200526
- Python version: 3.8.3
- GPU model and memory: RTX 2080 Ti - 11GB


**Current Behavior**
 When computing the loss using `keras.losses.MeanSquaredError` with data being of `dtype=tf.float64,` the results are consistent with casting to float32 then back to float64. The result of calling the loss function is of `dtype=tf.float64,` but there is an error of about 1e-8. I have observed this behavior in versions 2.1, 2.2, and the nightly build indicated above. I have not tested this with other loss functions, although this may be an issue for them as well. 

**Expected Behavior** 
Calling the loss function should return the same results as computing the loss manually in 64-bits when the data is 64-bit. 

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. 
```
import tensorflow as tf
from tensorflow import keras

# some sample data 
x = tf.convert_to_tensor([[2.1]], dtype=tf.float64)
y_true = tf.square(x)

# sample output of NN - something not the same as y_true
y_pred = tf.convert_to_tensor([[3.68]], dtype=tf.float64)

# TF loss
loss = keras.losses.MeanSquaredError()
tf_loss = loss(y_pred, y_true)

# manually computed loss in 64-bit
man_loss64 = tf.square(y_pred - y_true)

# manually computed loss, cast to 32 bit, then back to 64
man_loss32 = tf.cast(tf.cast(tf.square(y_pred - y_true), dtype=tf.float32), dtype=tf.float64)

# difference between loss computations
diff64 = abs(man_loss64 - tf_loss)
diff32 = abs(man_loss32 - tf_loss)
print(f'Difference in 64 bit: {diff64}')
print(f'Difference in 32 bit: {diff32}')
```


**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
39876,tensorflow-lite as shared(dynamic) lib for C/C++ & linux/ubuntu,"Hello

is there a way to build shared (dynamic) lib for TensorFlow-lite? If so, please share the steps to do so and possibly some simple example with it.

Thank you."
39875,autograph for bool logic control incorrect,"tf version: 2.1.0
HW: one gpu

```python
import tensorflow as tf

@tf.function
def check_zero(data):
    tf.print(data)
    if data == 0:
        tf.print(""check zero yes"")
        return True
    else:
        tf.print(""check zero no"")
        return False

@tf.function
def test_arg(a):
    is_zero = check_zero(a)
    
    if is_zero is True:
        tf.print(""zero"")
    else:
        tf.print(""not zero"")

for i in range(3):
    test_arg(i)
```
![image](https://user-images.githubusercontent.com/731496/82915054-d711ae80-9fa2-11ea-9f0b-3187d95b7ce8.png)
"
39874,asserterror when using tf.cond,"Assert error when using tf.cond, 
Here is the code stucture, it works fine when I run it eagerly, but get errors when build graph.

```python
    def kf():
     # some compute
        for t in range(N):
            a, p, pinf = tf.cond(tf.reduce_max(pinf) > tf.constant(1e-8, tf.float64),
                                 lambda: self.kf_init_step(self.data[t], a, p, pinf, self.H[t], self.Q[t]),
                                 lambda: self.kf_step(self.data[t], a, p, pinf, self.H[t], self.Q[t]))
            a_list.append(a)
            p_list.append(p)
            pinf_list.append(pinf)


    def kf_init_step(self, y, a, p, pinf, H, Q):
        # some compute
        return a_new, p_new, pinf_new

    def kf_step(self, y, a, p, pinf, H, Q):
        # some compute
        return a_new, p_new, pinf
```
Trackback:

```python
Traceback (most recent call last):
  File ""/Users/mac/Documents/bishe/DeepStateCount/DCSSM/run.py"", line 50, in <module>
    dssm.fit(train_ds, epochs=10, callbacks=[checkpoint])
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py"", line 819, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 235, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 593, in _process_training_inputs
    use_multiprocessing=use_multiprocessing)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 706, in _process_inputs
    use_multiprocessing=use_multiprocessing)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/data_adapter.py"", line 702, in __init__
    x = standardize_function(x)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 660, in standardize_function
    standardize(dataset, extract_tensors_from_dataset=False)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py"", line 2346, in _standardize_user_data
    all_inputs, y_input, dict_inputs = self._build_model_with_inputs(x, y)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py"", line 2572, in _build_model_with_inputs
    self._set_inputs(cast_inputs)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py"", line 2659, in _set_inputs
    outputs = self(inputs, **kwargs)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 773, in __call__
    outputs = call_fn(cast_inputs, *args, **kwargs)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/api.py"", line 237, in wrapper
    raise e.ag_error_metadata.to_exception(e)
AssertionError: in converted code:

    /Users/mac/Documents/bishe/DeepStateCount/DCSSM/DSSM.py:85 call  *
        loglikes = tf.map_fn(lambda x: self.linearloglike(x[0], x[1], x[2]),
    /Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/map_fn.py:268 map_fn
        maximum_iterations=n)
    /Users/mac/Documents/bishe/DeepStateCount/DCSSM/DSSM.py:127 linearloglike  *
        return linearssm.loglikelihood()
    /Users/mac/Documents/bishe/DeepStateCount/DCSSM/LinearSSM.py:92 loglikelihood  *
        filtered = self.kalman_filter()
    /Users/mac/Documents/bishe/DeepStateCount/DCSSM/LinearSSM.py:48 kalman_filter  *
        res = tf.cond(tf.reduce_max(pinf) > tf.constant(1e-8, dtype=tf.float64),
    /Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/control_flow_ops.py:1389 cond_for_tf_v2
        return cond(pred, true_fn=true_fn, false_fn=false_fn, strict=True, name=name)
    /Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py:507 new_func
        return func(*args, **kwargs)
    /Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/control_flow_ops.py:1174 cond
        return cond_v2.cond_v2(pred, true_fn, false_fn, name)
    /Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/cond_v2.py:100 cond_v2
        name=scope)
    /Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/cond_v2.py:219 _build_cond
        _make_indexed_slices_indices_types_match(_COND, [true_graph, false_graph])
    /Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/cond_v2.py:627 _make_indexed_slices_indices_types_match
        assert len(set(outs_per_branch)) == 1, outs_per_branch

    AssertionError: [1, 3]
```"
39873,Tensorflow see's GPU but only uses xla_cpu and crashes when told to use xla_gpu,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): True (I'm not using a code example but I have not written custom code within Tensorflow)
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ms Windows 10 Home - 10.0.18363
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): TensorFlow 2.2.0 installed using: pip install --upgrade tensorflow

- TensorFlow version (use command below):
Code: 
import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)
Output:
2020-05-26 09:27:35.360714: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)]
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: 
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Fri_Feb__8_19:08:26_Pacific_Standard_Time_2019
Cuda compilation tools, release 10.1, V10.1.105

- GPU model and memory:
incarnation: 17283739609840781326
physical_device_desc: ""device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1""
, name: ""/device:XLA_GPU:0""
device_type: ""XLA_GPU""
memory_limit: 17179869184
locality {
}
incarnation: 2207722455070197847
physical_device_desc: ""device: XLA_GPU device""
You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
I was training my models when it felt like they were running very slowly. After some digging I noticed that device GPU 0 is type xla_cpu and is not going through my gpu. device xla_gpu is listed but when forcing tensforflow to use it just crashes saying it can't find ptaxs.

**Describe the expected behavior**
I was hoping that TensorFlow would be able to use my gpu by default.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

I don't think this would be very useful but the error happens on the line with tf.device('/...
if I remove 'with tf.device('/device:XLA_GPU:0'):' everything works but tensorflow use my cpu with xla_cpu

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

I've posted more information here (I think it would be more readable than if I were to just copy and paste it here):
https://stackoverflow.com/questions/62009497/tensorflow-sees-gpu-but-only-uses-xla-cpu-and-crashes-when-told-to-use-xla-gpu"
39872,Mixing XLA and non XLA autograph triggers retracing,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): True
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux (Colab, I'm not sure what the os is)
- TensorFlow installed from (source or binary): Colab
- TensorFlow version (use command below): 2.2.0



**Describe the current behavior**
Mixing XLA (experimental_compile) and non XLA functions results in constant retracing

**Describe the expected behavior**
Functions inside an XLA function should inherit the option, XLA functions inside non XLA ones shouldn't retrace.

This is particularly important when relying on third-party libraries making use of the functionality.

**Standalone code to reproduce the issue**
https://colab.research.google.com/drive/1PrKsKSiKyGjjmX8Itub_BKe-SEihuWMM?usp=sharing


"
39871,"""ImportError: cannot import name tf2"" when doing Object Detection Model Training in Google Cloud","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:-
- TensorFlow installed from (source or binary):pip install
- TensorFlow version (use command below):('v1.15.0-rc3-22-g590d6ee', '1.15.0')
- Python version:2.7.12
- Bazel version (if compiling from source):-
- GCC/Compiler version (if compiling from source):gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
- CUDA/cuDNN version:
- GPU model and memory:


Starting a training job on google cloud for my object detection dataset. Job stops after ~7 minutes giving this error:
`Traceback (most recent call last):
  File ""/usr/lib/python2.7/runpy.py"", line 174, in _run_module_as_main
    ""__main__"", fname, loader, pkg_name)
  File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code
    exec code in run_globals
  File ""/root/.local/lib/python2.7/site-packages/object_detection/model_main.py"", line 26, in <module>
    from object_detection import model_lib
  File ""/root/.local/lib/python2.7/site-packages/object_detection/model_lib.py"", line 28, in <module>
    from object_detection import exporter as exporter_lib
  File ""/root/.local/lib/python2.7/site-packages/object_detection/exporter.py"", line 23, in <module>
    from object_detection.builders import model_builder
  File ""/root/.local/lib/python2.7/site-packages/object_detection/builders/model_builder.py"", line 39, in <module>
    from object_detection.utils import tf_version
  File ""/root/.local/lib/python2.7/site-packages/object_detection/utils/tf_version.py"", line 17, in <module>
    from tensorflow.python import tf2  # pylint: disable=import-outside-toplevel
ImportError: cannot import name tf2`
Local training however works fine, but is really slow and will take at least a week.


As I'm using tensorflow 1.15 this error should'nt occur...?


Install Tensorflow 1.15 with pip, all other libraries for the API, model repository, pycocotools, protobuf 3.11.4 -> testing the API installation works fine.
Create dataset including tfrecord files, training pipeline, googlecloud yaml file, ...
Run google cloud training job with:
# in tensorflow/models/research
    gcloud ai-platform jobs submit training balls200_training_260520a     --runtime-version 1.12     --job-dir=gs://200balls_model/train     --packages dist/object_detection-0.1.tar.gz,slim/dist/slim-0.1.tar.gz,tmp/pycocotools/pycocotools-2.0.tar.gz     --module-name object_detection.model_main     --region us-central1     --config /home/ubuntu/Documents/200balls_modeltraining/cloud.yml     --     --model_dir=gs://200balls_model/train     --pipeline_config_path=gs://200balls_model/pipeline.config  
"
39870,Issue with fetching of Output Tensor sizes in Model,"Output Size in tfLite Model for few networks are obtained only after the allocation of Tensorflow lite tensors. Could you please explain why it is special with the models like above . When I fetch the output dimensions of each output in the Model before allocation of tensors , I was getting the dimensions as zero.

Example : - http://storage.googleapis.com/download.tensorflow.org/models/tflite/coco_ssd_mobilenet_v1_1.0_quant_2018_06_29.zip

Output Size in tfLite Model for few other networks are obtained only independent of the allocation of Tensorflow lite tensors.  When I fetch the output dimensions of each output in the Model before allocation of tensors , I was getting the proper dimensions. 

Example : -
https://storage.googleapis.com/download.tensorflow.org/models/mobilenet_v1_2018_08_02/mobilenet_v1_1.0_224.tgz

Please explain the reason of this behaviour based on model
"
39869,'too many indices for array' exception depending on tensor length when masking a tensor,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows10
- TensorFlow installed from (source or binary): via pip
- TensorFlow version (use command below): tensorflow 2.2.0
- Python version: 3.7.7
- CUDA/cuDNN version: 10.1
- GPU model and memory: Nvidia GTX 970

**Describe the current behavior**
I want to select possible indices based on the value of a tensor. In this case I want to get all possible indices of the tensor, where the entry of the tensor is smaller than some value.

Though depending solely on the length of a sequence it throws unexpected 'too many indices for array' exceptions.

Here is the minimal problem, that reproduces the error on my machine

```
# failing example
import numpy as np
import tensorflow as tf

sentence = tf.constant([2, 92, 79, 378, 12, 2, 1396, 596, 11, 142, 7, 1901, 6, 11, 9, 1263, 21394, 346, 5, 2, 3086, 4])
target_vocab_size = 1000
possible_indices = np.arange(len(sentence))[(sentence < target_vocab_size)]
```

If I now do nothing but enlarging the tensor, by simply copy pasting its values twice it works.

```
# working example
import numpy as np
import tensorflow as tf

sentence = tf.constant([2, 92, 79, 378, 12, 2, 1396, 596, 11, 142, 7, 1901, 6, 11, 9, 1263, 21394, 346, 5, 2, 3086, 4,
                        2, 92, 79, 378, 12, 2, 1396, 596, 11, 142, 7, 1901, 6, 11, 9, 1263, 21394, 346, 5, 2, 3086, 4])
target_vocab_size = 1000
possible_indices = np.arange(len(sentence))[(sentence < target_vocab_size)]
```

When explicitly calling .numpy() on the mask it also works with the shorter tensor

```import numpy as np
import tensorflow as tf

sentence = tf.constant([2, 92, 79, 378, 12, 2, 1396, 596, 11, 142, 7, 1901, 6, 11, 9, 1263, 21394, 346, 5, 2, 3086, 4])

target_vocab_size = 1000
possible_indices = np.arange(len(sentence))[(sentence < target_vocab_size).numpy()]
```

When replacing tensorflow with numpy all the way it works just fine as well

```import numpy as np

sentence = np.array([2, 92, 79, 378, 12, 2, 1396, 596, 11, 142, 7, 1901, 6, 11, 9, 1263, 21394, 346, 5, 2, 3086, 4])
target_vocab_size = 1000
possible_indices = np.arange(len(sentence))[(sentence < target_vocab_size)]
```


"
39867,MAPELoss description is wrong,"https://github.com/tensorflow/tensorflow/blob/2b96f3662bd776e277f86997659e61046b56c315/tensorflow/python/keras/losses.py#L1242

MAPELoss description is wrong, it's not 
loss = 100 * mean(abs(y_true - y_pred) / y_true, axis=-1)
but may be this:
loss = 100*mean(abs((y_true - y_pred)/y_true, axis=-1))"
39865,"Loading tf saved model throws error in Keras, but works in tf","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): Binary
- Python version: 2.1
- CUDA/cuDNN version: Unsure
- GPU model and memory:  Unsure

TF: v2.1.0-rc2-17-ge5bf8de410 2.1.0


**Describe the current behavior**
When loading a model with sub/nested models in Keras it throws an error saying the Model must contain a call method. However, when loading the model directly through TensorFlow it still works.

**Describe the expected behavior**
The model should successfully load.

**Standalone code to reproduce the issue**
```python
# assuming a model with submodels called ""saved_model"" exists
import tensorflow as tf
model = tf.saved_model.load('saved_model') # works
model = keras.models.load_model('saved_model') # doesnt work
```

**Other info / logs**
```
NotImplementedError                       Traceback (most recent call last)
 in 
      3 import tensorflow as tf
      4 model = tf.saved_model.load('saved_model')
----> 5 tf.keras.models.load_model('saved_model')

~/.local/share/virtualenvs/model-TBy5gsp1/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py in load_model(filepath, custom_objects, compile)
    148   if isinstance(filepath, six.string_types):
    149     loader_impl.parse_saved_model(filepath)
--> 150     return saved_model_load.load(filepath, compile)
    151 
    152   raise IOError(

~/.local/share/virtualenvs/model-TBy5gsp1/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py in load(path, compile)
     87   # TODO(kathywu): Add saving/loading of optimizer, compiled losses and metrics.
     88   # TODO(kathywu): Add code to load from objects that contain all endpoints
---> 89   model = tf_load.load_internal(path, loader_cls=KerasObjectLoader)
     90 
     91   # pylint: disable=protected-access

~/.local/share/virtualenvs/model-TBy5gsp1/lib/python3.7/site-packages/tensorflow_core/python/saved_model/load.py in load_internal(export_dir, tags, loader_cls)
    550       loader = loader_cls(object_graph_proto,
    551                           saved_model_proto,
--> 552                           export_dir)
    553       root = loader.get(0)
    554     root.tensorflow_version = meta_graph_def.meta_info_def.tensorflow_version

~/.local/share/virtualenvs/model-TBy5gsp1/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py in __init__(self, *args, **kwargs)
    117   def __init__(self, *args, **kwargs):
    118     super(KerasObjectLoader, self).__init__(*args, **kwargs)
--> 119     self._finalize()
    120 
    121   def _finalize(self):

~/.local/share/virtualenvs/model-TBy5gsp1/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py in _finalize(self)
    155           inputs, outputs, _ = network_lib.reconstruct_from_config(
    156               node.get_config(),
--> 157               created_layers={layer.name: layer for layer in node.layers})
    158           node._init_graph_network(
    159               inputs, outputs,

~/.local/share/virtualenvs/model-TBy5gsp1/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py in reconstruct_from_config(config, custom_objects, created_layers)
   1901       if layer in unprocessed_nodes:
   1902         for node_data in unprocessed_nodes.pop(layer):
-> 1903           process_node(layer, node_data)
   1904 
   1905   input_tensors = []

~/.local/share/virtualenvs/model-TBy5gsp1/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py in process_node(layer, node_data)
   1849       if not isinstance(input_tensors, dict) and len(flat_input_tensors) == 1:
   1850         input_tensors = flat_input_tensors[0]
-> 1851       output_tensors = layer(input_tensors, **kwargs)
   1852 
   1853       # Update node index map.

~/.local/share/virtualenvs/model-TBy5gsp1/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)
    771                     not base_layer_utils.is_in_eager_or_tf_function()):
    772                   with auto_control_deps.AutomaticControlDependencies() as acd:
--> 773                     outputs = call_fn(cast_inputs, *args, **kwargs)
    774                     # Wrap Tensors in `outputs` in `tf.identity` to avoid
    775                     # circular dependencies.

~/.local/share/virtualenvs/model-TBy5gsp1/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py in call(self, inputs, training, mask)
    710     """"""
    711     if not self._is_graph_network:
--> 712       raise NotImplementedError('When subclassing the `Model` class, you should'
    713                                 ' implement a `call` method.')
    714 

NotImplementedError: When subclassing the `Model` class, you should implement a `call` method.
```
"
39864,Recreate Variables in tf.function,"I'll preface this issue with the following:
- I've thought about this for a really long time (I've watched the talks and read the docs), and I can't find any solutions, which is why I'm creating this issue
- I know this is a pretty big change to the fundamental concept of ""don't create `Variable`s in `tf.function`s"" (see https://youtu.be/Up9CvRLIIIw?t=478 and https://www.tensorflow.org/guide/function#variables)

**System information**
- TensorFlow version (you are using): 2.2.0
- Are you willing to contribute it (Yes/No): no—this seems like it'll take a lot of time—I might be able to work on this in 2 years, when I'm in college :) 


**Describe the feature and the current behavior/state.**
Currently, creating a `tf.Variable` in a `tf.function` raises a `ValueError`, for good reason: https://youtu.be/Up9CvRLIIIw?t=431. 

Suppose I want to run a function multiple times for benchmarking purposes (I know `tf.test` exists). If this function creates Variables, I can't run it multiple times. Instead, I need to create the variables outside of `tf.function`, and pass them to the `tf.function`. This makes for unclear and illogical code. 

What I want is to be able to **create/delete/recreate Variables in a `tf.function`**. 

**Will this change the current API? How?**
I don't think so; I don't expect any new functions or classes to be added to the external API. 

**Who will benefit with this feature?**
People who wants to run a function (with new state) multiple times—e.g., benchmarking, hyperparameter optimization, etc. I realize that ""with new state"" isn't the best word choice; what I mean is I want each run to be independent, and create new `Variables`.

**Any Other info.**
For the use-cases I have in mind, I think being able to delete Variables is what we need. I have no problem deleting `tf.Variable`s at the end of the `tf.function`. The reason I mention being able to create `tf.Variable`s in `tf.function`s is because I might be missing a use-case. 

I'm also unsure if this will help: `tf.variable_creator_scope`"
39862,sys.exc_info() can't put to queue in MultiProcessRunner,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):none
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:none
- TensorFlow installed from (source or binary):none
- TensorFlow version (use command below): master branch https://github.com/tensorflow/tensorflow/commit/498e5b4f6db80df13b54c44cbd657a2750067564
- Python version:nan
- Bazel version (if compiling from source):none
- GCC/Compiler version (if compiling from source):none
- CUDA/cuDNN version:none
- GPU model and memory:none

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
code line see [multi_process_runner.py:594](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/distribute/multi_process_runner.py#L594)

sys.exc_info() can't put to queue in MultiProcessRunner, because the traceback object can't be pickle, see [stackoverflow](https://stackoverflow.com/a/6132584).

when a subprocess raise an error, the line 497 of multi_process_runner.py will throw an error
`TypeError: can't pickle traceback objects`

**Describe the expected behavior**

Pls use other way to implement this. one way is using traceback.print_exc() or format_exc() functions. Don't put traceback objects in queue.


**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

none

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

none"
39861,close it please,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
39858,Unable to calculate gradient -> AttributeError: 'Tensor' object has no attribute 'numpy',"**System information**
- OS Platform and Distribution: macOS Catalina
- TensorFlow installed from (source or binary): Google Colab
- TensorFlow version: >=2.0
- Python version: 3.6

** I want to compute the gradient for KL Divergence ( between two distributions aka logits) with respect to noise (kind of input and not wrt weights). It was possible with Tensorflow 1.0 but using GradientTape seems to return me a None for ""grads"" which I am unable to comprehend**

Code:

import tensorflow as tf
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.layers import Input, Embedding, Dense, LSTM, Bidirectional

MAX_VOCAB_SIZE = 10000 # maximum no of unique words
MAX_DOC_LENGTH = 500 # maximum no of words in each sentence
EMBEDDING_DIM = 300 # Embeddings dimension from Glove directory
def compute_kld(p_logit, q_logit): # computes difference between two distributions
  p = tf.nn.softmax(p_logit)
  q = tf.nn.softmax(q_logit)
  kl_score = tf.reduce_sum( p * (tf.math.log(p+1e-16) - tf.math.log(q+1e-16)), axis = 1)
  return kl_score # Scalar -> lower kl means closer the distributions are closer

# Create Embeddings
inputs2d = Input(shape=(MAX_DOC_LENGTH,)) # takes a sequence of words
clean_embd= Embedding(input_dim=MAX_VOCAB_SIZE + 1, output_dim=EMBEDDING_DIM,
                      input_length=MAX_DOC_LENGTH)(inputs2d) # converts each input to embedding matrix
r_embd = tf.random.uniform(shape=tf.shape(clean_embd)) # random noise to be added to clean_embd

# Create Model
inputs3d = Input(shape=(MAX_DOC_LENGTH, EMBEDDING_DIM,)) # Embedding shall be my input to the model
network = Sequential()
network.add(LSTM(units=128,))
network.add(Dense(units=16, activation='relu'))
output = network(inputs3d)
model = Model(inputs3d, output)
model.summary()

# Calculate gradient
with tf.GradientTape(watch_accessed_variables=False) as tape:
    tape.watch(r_embd)
    r_embd_ = tf.math.add(clean_embd, r_embd) # Noised input
    # Compute logits
    p_logit = model(clean_embd) # True logit distribution
    p_logit_r = model(r_embd_) # Perturbed logits distribution
    # Find the Kl Score
    kl_score = tf.reduce_mean(compute_kld(p_logit, p_logit_r))
    kl_score = tf.convert_to_tensor(kl_score, dtype=tf.float32)
**grads = tape.gradient(kl_score, r_embd) # I wish to differentiate kl_score wrt r_embd. So the Jacobian matrix should be of shape (None, 500, 300) similar to (clean_embd | r_embd_).**

**# Error is that grads is returned as None; which I can't understand.**

# Future implementation
r_vadv_embd = tf.math.add(clean_embd, g)
**q_logits = model(r_vadv_embd) # End goal is to be able to calculate q_logit**

**Any other info / logs**
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-10-f19b613537c7> in <module>()
     15     kl_score = tf.reduce_mean(compute_kld(p_logit, p_logit_r))
     16     kl_score = tf.convert_to_tensor(kl_score, dtype=tf.float32)
---> 17 grads = tape.gradient(kl_score, r_embd)
     18 
     19 # g = [grad if grad is not None else tf.zeros_like(var)for var, grad in zip(r_embd, grads)]

4 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/backprop.py in gradient(self, target, sources, output_gradients, unconnected_gradients)
   1046         output_gradients=output_gradients,
   1047         sources_raw=flat_sources_raw,
-> 1048         unconnected_gradients=unconnected_gradients)
   1049 
   1050     if not self._persistent:

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/imperative_grad.py in imperative_grad(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)
     75       output_gradients,
     76       sources_raw,
---> 77       compat.as_str(unconnected_gradients.value))

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/backprop.py in _gradient_function(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)
    155       gradient_name_scope = ""gradient_tape/""
    156     with ops.name_scope(gradient_name_scope):
--> 157       return grad_fn(mock_op, *out_grads)
    158   else:
    159     return grad_fn(mock_op, *out_grads)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py in _SumGrad(op, grad)
    210       # more sense.
    211       output_shape_kept_dims = math_ops.reduced_shape(input_shape,
--> 212                                                       op.inputs[1])
    213     grad = array_ops.reshape(grad, output_shape_kept_dims)
    214   return [array_ops.broadcast_to(grad, input_shape), None]

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py in reduced_shape(input_shape, axes)
   3733   """"""
   3734   if context.executing_eagerly():
-> 3735     input_shape = input_shape.numpy()
   3736     axes = axes.numpy()
   3737     input_shape[axes] = 1

AttributeError: 'Tensor' object has no attribute 'numpy'
"
39857,device_spec from_string method not accepting some inputs,"The method `from_string` of `tensorflow.python.framework.device_spec` does not accept device names reported by `tf` itself:

`tf.config.list_physical_devices()` returns device names of the form `'/physical_device:GPU:0'`, However `from_string` does not accept this as input. Only works when `'/physical_device:'` is cut out.

**Expected behaviour:**
```python
tensorflow.python.framework.device_spec.DeviceSpecV2().from_string('/physical_device:GPU:0')
<tensorflow.python.framework.device_spec.DeviceSpecV2 at 0x7f7ec46fe8a0>
```

**Actual behaviour:**
```python
tensorflow.python.framework.device_spec.DeviceSpecV2().from_string('/physical_device:GPU:0')
ValueError: Unknown attribute: 'physical_device' in '/physical_device:GPU:0'
```"
39856,`tf.keras.models.clone_model` does not support custom model,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **Yes**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Ubuntu 18.04**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **N/A**
- TensorFlow installed from (source or binary): **pip**
- TensorFlow version (use command below): **2.2.0**
- Python version: **Python 3.6.10 :: Anaconda, Inc.**
- Bazel version (if compiling from source): **N/A**
- GCC/Compiler version (if compiling from source): **N/A**
- CUDA/cuDNN version: **CUDA 10.1**
- GPU model and memory: **GeForce RTX 2080 Ti**

**Describe the current behavior**

In TF2.2.0 release notes, it said 
> * You can now use custom training logic with `Model.fit` by overriding `Model.train_step`
> * Easily write state-of-the-art training loops without worrying about all of the features `Model.fit` handles for you (distribution strategies, callbacks, data formats, looping logic, etc)

I have implemented my own custom model whose `train_step` is overwrited, And I want to create an identical model by API `tf.keras.models.clone_model`.

But, the problem there is that my custom `train_step` is gone.

**Describe the expected behavior**

`tf.keras.models.clone_model` should copy not only model's layers but also `train_step`.

**Standalone code to reproduce the issue**
```python
#%%
import numpy as np
import tensorflow as tf
print(tf.__version__)

#%% 
class Composite(tf.keras.Model):
    def __init__(self, *args, **kwargs):

        super(Composite, self).__init__(*args, **kwargs)

    def train_step(self, data):

        data_adapter = tf.python.keras.engine.data_adapter
        data = data_adapter.expand_1d(data)
        x, y, sample_weight = data_adapter.unpack_x_y_sample_weight(data)

        tf.print(""HIHI! I'm in function train_step!"")

        with tf.GradientTape() as tape:
            y_pred = self(x, training=True)
            loss = self.compiled_loss(
                y, y_pred, sample_weight, regularization_losses=self.losses)

        _minimize = tf.python.keras.engine.training._minimize
        _minimize(self.distribute_strategy, tape, self.optimizer, loss,
                self.trainable_variables)

        self.compiled_metrics.update_state(y, y_pred, sample_weight)
        return {m.name: m.result() for m in self.metrics}

in_ = tf.keras.layers.Input(shape=(10, ) )
x = tf.keras.layers.Dense(1)(in_)
model = Composite(inputs=in_, outputs=x)
model.compile(loss='binary_crossentropy',optimizer='SGD', metrics=['accuracy'])

X = np.zeros((10,10))
Y = np.zeros((10,1))
model.fit(X,Y,verbose=2)

# %%
new_model = tf.keras.models.clone_model(model)
new_model.compile(loss='binary_crossentropy',optimizer='SGD', metrics=['accuracy'])
new_model.fit(X,Y,verbose=2)
```

**Other info / logs** 
```
there is the original model
HIHI! I'm in function train_step!
1/1 - 0s - loss: 0.0000e+00 - accuracy: 1.0000
<tensorflow.python.keras.callbacks.History at 0x7fa9603dd6a0>
there is the NEW model
1/1 - 0s - loss: 0.0000e+00 - accuracy: 1.0000
<tensorflow.python.keras.callbacks.History at 0x7fa96023bbe0>
```

From the console, you will see the output `HIHI! I'm in function train_step!` is gone when I run `new_model.fit(X,Y,verbose=2)`"
39855,DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.,"-windows 10
-python 3.8.3
-tensorflow 2.2.0

i have installed it using
`pip install tensorflow` 

i run this code
`import tensorflow as tf`

i got error
```
Traceback (most recent call last):
  File ""C:\Users\pratibha\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\pratibha\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\pratibha\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\pratibha\AppData\Local\Programs\Python\Python38\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\pratibha\AppData\Local\Programs\Python\Python38\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:/Users/pratibha/AppData/Roaming/JetBrains/PyCharmCE2020.1/scratches/textblob.py"", line 1, in <module>
    import tensorflow as tf
  File ""C:\Users\pratibha\AppData\Roaming\Python\Python38\site-packages\tensorflow\__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\pratibha\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\__init__.py"", line 50, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\pratibha\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 69, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\pratibha\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\pratibha\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\pratibha\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\pratibha\AppData\Local\Programs\Python\Python38\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\pratibha\AppData\Local\Programs\Python\Python38\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

Process finished with exit code 1
```
"
39854,XLA compilation not working in Windows 10 Pro,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Pro
- TensorFlow installed from (source or binary): pip install tensorflow-gpu
- TensorFlow version (use command below): 2.2.0
- Python version: 3.7
- CUDA/cuDNN version: 7.6.5
- GPU model and memory: RTX 2080 8GB

**Describe the current behavior**
XLA compilation in Windows doesn't seem to work even if in the changelog of TF 2.2.0 says XLA is now possible with Windows systems. Here is the output of the error:
`2020-05-25 17:03:22.775625: W tensorflow/compiler/xla/service/gpu/buffer_comparator.cc:592] Internal: Invoking GPU asm compilation is supported on Cuda non-Windows platforms only
Relying on driver to perform ptx compilation. 
Setting XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda  or modifying $PATH can be used to set the location of ptxas
This message will only be logged once.
2020-05-25 17:03:23.131452: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:70] Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice. This may result in compilation or runtime failures, if the program we try to run uses routines from libdevice.
2020-05-25 17:03:23.131584: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:71] Searched for CUDA in the following directories:
2020-05-25 17:03:23.131652: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   ./cuda_sdk_lib
2020-05-25 17:03:23.131702: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1
2020-05-25 17:03:23.131769: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   .
2020-05-25 17:03:23.131814: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:76] You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.
2020-05-25 17:03:23.132862: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:305] libdevice is required by this HLO module but was not found at ./libdevice.10.bc
2020-05-25 17:03:23.139801: I tensorflow/compiler/jit/xla_compilation_cache.cc:241] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2020-05-25 17:03:23.141241: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at xla_ops.cc:520 : Internal: libdevice not found at ./libdevice.10.bc
Traceback (most recent call last):
  File ""D:/Users/Alvaro/Documents/TFM/Project/eyesrgan/Resnet_MSE.py"", line 142, in <module>
    callbacks=callbacks)
  File ""D:\Development\Anaconda3\envs\TFM\lib\site-packages\tensorflow\python\keras\engine\training.py"", line 66, in _method_wrapper
    return method(self, *args, **kwargs)
  File ""D:\Development\Anaconda3\envs\TFM\lib\site-packages\tensorflow\python\keras\engine\training.py"", line 848, in fit
    tmp_logs = train_function(iterator)
  File ""D:\Development\Anaconda3\envs\TFM\lib\site-packages\tensorflow\python\eager\def_function.py"", line 580, in __call__
    result = self._call(*args, **kwds)
  File ""D:\Development\Anaconda3\envs\TFM\lib\site-packages\tensorflow\python\eager\def_function.py"", line 644, in _call
    return self._stateless_fn(*args, **kwds)
  File ""D:\Development\Anaconda3\envs\TFM\lib\site-packages\tensorflow\python\eager\function.py"", line 2420, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File ""D:\Development\Anaconda3\envs\TFM\lib\site-packages\tensorflow\python\eager\function.py"", line 1665, in _filtered_call
    self.captured_inputs)
  File ""D:\Development\Anaconda3\envs\TFM\lib\site-packages\tensorflow\python\eager\function.py"", line 1746, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""D:\Development\Anaconda3\envs\TFM\lib\site-packages\tensorflow\python\eager\function.py"", line 598, in call
    ctx=ctx)
  File ""D:\Development\Anaconda3\envs\TFM\lib\site-packages\tensorflow\python\eager\execute.py"", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.InternalError:  libdevice not found at ./libdevice.10.bc
	 [[{{node cluster_4_1/xla_compile}}]] [Op:__inference_train_function_12671]

Function call stack:
train_function


Process finished with exit code 1`


I already tried to add the XLA_FLAGS environment variable, as well as CUDA_DIR environ, both with any success.

**Describe the expected behavior**
XLA should work with its implicit gain in performance.

**Standalone code to reproduce the issue**
The source code can be found in this [colab](https://drive.google.com/open?id=12sx2GQN5kwRke7fPkj5TkgtugN5y1X44).

"
39853,"2 errors while building NodeDef 'tf_op_layer_Maximum_2/Maximum_2' using Op<name=Maximum; signature=x:T, y:T -> z:T ...Inconsistent values for attr 'T' DT_INT32 vs. DT_INT64","System information
I am using colab to reproduce the issue and the ipynb is attached below.

You can collect some of this information using our environment capture
tf.version.GIT_VERSION: v1.12.1-32511-g2cc80a74f2
tf.version.VERSION:  2.3.0-dev20200525

Describe the current behavior
cannot load the saved tf model

Describe the expected behavior
successifully save the model and serve it like this example: https://github.com/tensorflow/transform/blob/master/examples/census_example_v2_test.py

Standalone code to reproduce the issue
https://colab.research.google.com/drive/1h2QIX_QZetIzSuG0J6lNWkHoSa2nnIyS?usp=sharing

Other info / logs Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

error is show in the last cell of the colab notebook.

```
WARNING:tensorflow:Layer LSTM_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU
WARNING:tensorflow:Layer LSTM_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU
WARNING:tensorflow:Layer LSTM_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU
WARNING:tensorflow:Layer LSTM_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU
WARNING:tensorflow:Layer LSTM_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU
WARNING:tensorflow:Layer LSTM_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU
WARNING:tensorflow:Layer LSTM_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU
WARNING:tensorflow:Layer LSTM_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU
WARNING:tensorflow:Layer LSTM_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU
WARNING:tensorflow:Layer LSTM_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU
WARNING:tensorflow:Layer LSTM_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU
WARNING:tensorflow:Layer LSTM_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in _create_c_op(graph, node_def, inputs, control_inputs, op_def)
   1819   try:
-> 1820     c_op = pywrap_tf_session.TF_FinishOperation(op_desc)
   1821   except errors.InvalidArgumentError as e:

InvalidArgumentError: 2 errors while building NodeDef 'tf_op_layer_Maximum_2/Maximum_2' using Op<name=Maximum; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_INT16, DT_INT32, DT_INT64]>:
Inconsistent values for attr 'T' DT_INT32 vs. DT_INT64
Inconsistent values for attr 'T' DT_INT32 vs. DT_INT64

During handling of the above exception, another exception occurred:

ValueError                                Traceback (most recent call last)
15 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in _create_c_op(graph, node_def, inputs, control_inputs, op_def)
   1821   except errors.InvalidArgumentError as e:
   1822     # Convert to ValueError for backwards compatibility.
-> 1823     raise ValueError(str(e))
   1824 
   1825   return c_op

ValueError: 2 errors while building NodeDef 'tf_op_layer_Maximum_2/Maximum_2' using Op<name=Maximum; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_INT16, DT_INT32, DT_INT64]>:
Inconsistent values for attr 'T' DT_INT32 vs. DT_INT64
Inconsistent values for attr 'T' DT_INT32 vs. DT_INT64
```"
39852,tf.guarantee_const does not work with XLA compilation,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.15.5 Beta
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.2.0
- Python version: 3.8.2
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

**Describe the current behavior**
I am unable to use `tf.guarantee_const` in functions decorated with `tf.function(experimental_compile=True)`.

**Describe the expected behavior**
The method, with XLA, should run the same as the method without XLA, with no errors.

**Standalone code to reproduce the issue**
```python
import tensorflow as tf


@tf.function(experimental_compile=False)
def test_xla(x):
    x = tf.guarantee_const(x)
    return x**2

test_xla(3)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
```
2020-05-25 10:14:47.561576: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-05-25 10:14:47.621911: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fed5077ddc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-05-25 10:14:47.621943: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Traceback (most recent call last):
  File ""tfxla.py"", line 10, in <module>
    test_xla(3)
  File ""/private/tmp/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 576, in __call__
    result = self._call(*args, **kwds)
  File ""/private/tmp/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 650, in _call
    return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access
  File ""/private/tmp/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 1661, in _filtered_call
    return self._call_flat(
  File ""/private/tmp/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 1745, in _call_flat
    return self._build_call_outputs(self._inference_function.call(
  File ""/private/tmp/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 593, in call
    outputs = execute.execute(
  File ""/private/tmp/venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py"", line 59, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.InvalidArgumentError: Function invoked by the following node is not compilable: {{node __inference_test_xla_8}} = __inference_test_xla_8[_XlaMustCompile=true, config_proto=""\n\007\n\003CPU\020\001\n\007\n\003GPU\020\0002\002J\0008\001"", executor_type=""""]().
Uncompilable nodes:
GuaranteeConst: unsupported op: No registered 'GuaranteeConst' OpKernel for XLA_CPU_JIT devices compatible with node {{node GuaranteeConst}}
	Stacktrace:
		Node: __inference_test_xla_8, function: 
		Node: GuaranteeConst, function: __inference_test_xla_8
 [Op:__inference_test_xla_8]
```
"
39851,Cannot Read From Google Storage with tf.io.gfile.GFile under intel-tensorflow==1.14.0,"Support for Google Storage (`gs` protocol) seems to be missing from `intel-tensorflow==1.14.0`, which is unexpected. I'm aware that this is no core tensorflow issue but I've seen that some engineers from Intel are active in this repository.

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): docker image `intelaipg/intel-optimized-tensorflow:1.14.0-mkl-py3` (Ubuntu 18.04.2 LTS)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): No
- TensorFlow version (use command below): 1.14.0
- Python version: 3.6.8
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

Output: `v1.14.0-1-hardened-0-g340d16ee58 1.14.0`

**Describe the current behavior**

Google storage doesn't seem to be supported for some reason:

```
> python
Python 3.6.8 (default, Jan 14 2019, 11:02:34)
[GCC 8.0.1 20180414 (experimental) [trunk revision 259383]] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf; tf.io.gfile.GFile(""gs://some_bucket/test.txt"").read()
[deprecation warning redacted]
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 122, in read
    self._preread_check()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 84, in _preread_check
    compat.as_bytes(self.__name), 1024 * 512)
tensorflow.python.framework.errors_impl.UnimplementedError: File system scheme 'gs' not implemented (file: 'gs://some_bucket/test.txt')
```

**Describe the expected behavior**

Verified to work with 1.13.2:

```
> python
Python 3.6.8 (default, Jan 14 2019, 11:02:34)
[GCC 8.0.1 20180414 (experimental) [trunk revision 259383]] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf; tf.io.gfile.GFile(""gs://some_bucket/test.txt"").read()
[deprecation warning redacted]
'test\n'
```

**Standalone code to reproduce the issue**

See above.

**Other info / logs**
n/a
"
39850,array slice on tf.function is about 23 times slower than non tf function,"tf version: 2.1.0
HW: one gpu

```python code
import time
import tensorflow as tf

@tf.function
def test_tf_fun(inputs):
    for i in range(16):
        for j in range(128):
            t = inputs[i, j, :]

inputs = tf.random.uniform((16, 128, 4))

t1 = time.time()
test_tf_fun(inputs)
print(""duration for tf.fun: "", time.time() - t1)
```
![image](https://user-images.githubusercontent.com/731496/82810012-03a0ca00-9ec0-11ea-8ed5-778b3ed4ab66.png)

"
39847,tflite lstm,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- TensorFlow version (or github SHA if from source):


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
# Copy and paste here the exact command
```

**The output from the converter invocation**

```
# Copy and paste the output here.
```

**Also, please include a link to the saved model or GraphDef**

```
# Put link here or attach to the issue.
```

**Failure details**
If the conversion is successful, but the generated model is wrong,
state what is wrong:
- Producing wrong results and/or decrease in accuracy
- Producing correct results, but the model is slower than expected (model generated from old converter)


**RNN conversion support**
If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
39846,the gpu memory seem doesn't load well with crontab in centos7,"I use crontab to start a timed task, in the task, it has a DL model service, which was write with tensorflow.
but when crontab to start this service, the model memory didn't load well on GPU, it should load with 1.5G, but in practice, it loaded 0.3G, and the compute speed is so low, is there something wrong with tensorflow in crontab."
42133,"Graph visualization failed, in Graph mode [TF 2.2, TB 2.2.1]","Eager works, though partially - Graph doesn't work at all. [Suggested thread](https://github.com/tensorflow/tensorboard/issues/1961) doesn't reveal much.

![image](https://user-images.githubusercontent.com/16495490/82794515-a5ee8c80-9e83-11ea-9a48-932c5eda13eb.png)


```python
import shutil
import tempfile
import numpy as np
import tensorflow as tf
tf.compat.v1.disable_eager_execution()

from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import TensorBoard

#%%############################################
ipt = Input(shape=(16,))
out = Dense(16)(ipt)
model = Model(ipt, out)
model.compile('adam', 'mse')

logdir = tempfile.mkdtemp()
print('tensorboard --logdir=""%s""' % logdir)
tb = TensorBoard(logdir, write_graph=True)

#%%############################################
x = y = np.random.randn(160, 16)
model.fit(x, y, batch_size=32, callbacks=[tb])

# shutil.rmtree(logdir)
```

<hr>

**Environment info**:

  - _Browser_: Google Chrome v83.0.4103.61 x64 [also tried Firefox Developer Edition]
  - _System_: Windows 10 x64, GTX 1070, i7-7700HQ 2.8 GHz"
39845,DLL issue,"C:\Users\Admin\Desktop\nd\Project>python
Python 3.6.2 (v3.6.2:5fd33b5, Jul  8 2017, 04:57:36) [MSC v.1900 64 bit (AMD64)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
Traceback (most recent call last):
  File ""C:\Users\Admin\.virtualenvs\Project-Ldxc-xwW\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Admin\.virtualenvs\Project-Ldxc-xwW\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Admin\.virtualenvs\Project-Ldxc-xwW\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""c:\users\admin\appdata\local\programs\python\python36\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""c:\users\admin\appdata\local\programs\python\python36\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Users\Admin\.virtualenvs\Project-Ldxc-xwW\lib\site-packages\tensorflow\__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\Admin\.virtualenvs\Project-Ldxc-xwW\lib\site-packages\tensorflow\python\__init__.py"", line 50, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\Admin\.virtualenvs\Project-Ldxc-xwW\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 69, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\Admin\.virtualenvs\Project-Ldxc-xwW\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Admin\.virtualenvs\Project-Ldxc-xwW\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Admin\.virtualenvs\Project-Ldxc-xwW\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""c:\users\admin\appdata\local\programs\python\python36\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""c:\users\admin\appdata\local\programs\python\python36\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
>>>"
39843,Differences between model.load_weights and checkpoint.restore,"I can checkpoint.restore(ckfile) without any questions, but raise `Nothing except the root object matched a checkpointed value. Typically this means that the checkpoint does not match the Python program.` by model.load_weights(ckfile). I want to know what's the differences between these two api.

Thank you."
39842,"Loaded runtime CuDNN library: 7.5.0 but source was compiled with: 7.6.5.  CuDNN library major and minor version needs to match or have higher minor version in case of CuDNN 7.0 or later version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.","

**System information**
- WIN10:
- TensorFlow installed from (binary):
- TensorFlow version (2.2.0):
```
tensorboard               2.2.1                    pypi_0    pypi
tensorboard-plugin-wit    1.6.0.post3              pypi_0    pypi
tensorflow                2.2.0                    pypi_0    pypi
tensorflow-estimator      2.2.0                    pypi_0    pypi
tensorflow-gpu            2.2.0                    pypi_0    pypi
tensorflow-gpu-estimator  2.2.0                    pypi_0    pypi
```
- Python    3.7.3   :
- CUDA 10.1/cuDNN 7.6.5:
- GPU model and memory:NVIDIA 1070Ti 8G 

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
`v2.2.0-rc4-8-g2b96f3662b 2.2.0`

**Describe the current behavior**
when i use [keras_ocr](https://github.com/faustomorales/keras-ocr) project , cmd print `Loaded runtime CuDNN library: 7.5.0 but source was compiled with: 7.6.5.  CuDNN library major and minor version needs to match or have higher minor version in case of CuDNN 7.0 or later version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.` however the version of cuda and cudnn is good.
**Describe the expected behavior**

**Standalone code to reproduce the issue**
```
import matplotlib.pyplot as plt

import keras_ocr
import cv2
# keras-ocr will automatically download pretrained
# weights for the detector and recognizer.
pipeline = keras_ocr.pipeline.Pipeline()

# Get a set of three example images
images = [
    keras_ocr.tools.read(url) for url in [
        '.\debug\Army_Reserves_Recruitment_Banner_MOD_45156284.jpg',
        '.\debug\EUBanana-500x112.jpg',
        '.\debug\FseeG2QeLXo.jpg'
    ]
]
for image in images:
    image = cv2.resize(image,(480 ,640))

# Each list of predictions in prediction_groups is a list of
# (word, box) tuples.
prediction_groups = pipeline.recognize(images)

# Plot the predictions
#fig, axs = plt.subplots(nrows=len(images), figsize=(20, 20))
#for ax, image, predictions in zip(axs, images, prediction_groups):
#    keras_ocr.tools.drawAnnotations(image=image, predictions=predictions, ax=ax)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
```
C:\Users\有对象真好\Desktop>python lal.python
2020-05-25 10:54:31.190482: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
Looking for C:\Users\有对象真好\.keras-ocr\craft_mlt_25k.h5
2020-05-25 10:54:34.541182: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-05-25 10:54:34.572573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:
pciBusID: 0000:09:00.0 name: GeForce GTX 1070 Ti computeCapability: 6.1
coreClock: 1.683GHz coreCount: 19 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 238.66GiB/s
2020-05-25 10:54:34.583784: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-05-25 10:54:34.598399: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-05-25 10:54:34.617941: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-05-25 10:54:34.630153: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-05-25 10:54:34.653711: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-05-25 10:54:34.670926: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-05-25 10:54:34.710546: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-05-25 10:54:34.718154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-05-25 10:54:34.726651: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2020-05-25 10:54:34.747053: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1427ab75710 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-05-25 10:54:34.754351: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-05-25 10:54:34.767358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:
pciBusID: 0000:09:00.0 name: GeForce GTX 1070 Ti computeCapability: 6.1
coreClock: 1.683GHz coreCount: 19 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 238.66GiB/s
2020-05-25 10:54:34.785846: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-05-25 10:54:34.796338: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-05-25 10:54:34.805291: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-05-25 10:54:34.817470: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-05-25 10:54:34.827060: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-05-25 10:54:34.836200: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-05-25 10:54:34.845863: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-05-25 10:54:34.856443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-05-25 10:54:35.395109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-05-25 10:54:35.401033: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0
2020-05-25 10:54:35.412130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N
2020-05-25 10:54:35.421922: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6285 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070 Ti, pci bus id: 0000:09:00.0, compute capability: 6.1)
2020-05-25 10:54:35.445885: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1421e063660 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-05-25 10:54:35.454505: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1070 Ti, Compute Capability 6.1
2020-05-25 10:54:56.938514: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-05-25 10:54:57.626411: E tensorflow/stream_executor/cuda/cuda_dnn.cc:319] Loaded runtime CuDNN library: 7.5.0 but source was compiled with: 7.6.5.  CuDNN library major and minor version needs to match or have higher minor version in case of CuDNN 7.0 or later version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.
2020-05-25 10:54:57.662951: E tensorflow/stream_executor/cuda/cuda_dnn.cc:319] Loaded runtime CuDNN library: 7.5.0 but source was compiled with: 7.6.5.  CuDNN library major and minor version needs to match or have higher minor version in case of CuDNN 7.0 or later version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.
Traceback (most recent call last):
  File ""lal.python"", line 8, in <module>
    boxes = detector.detect(images=[image])[0]
  File ""C:\ProgramData\Anaconda3\lib\site-packages\keras_ocr\detection.py"", line 679, in detect
    boxes = getBoxes(self.model.predict(np.array(images), **kwargs),
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\keras\engine\training.py"", line 88, in _method_wrapper
    return method(self, *args, **kwargs)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\keras\engine\training.py"", line 1268, in predict
    tmp_batch_outputs = predict_function(iterator)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\eager\def_function.py"", line 580, in __call__
    result = self._call(*args, **kwds)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\eager\def_function.py"", line 650, in _call
    return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\eager\function.py"", line 1665, in _filtered_call
    self.captured_inputs)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\eager\function.py"", line 1746, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\eager\function.py"", line 598, in call
    ctx=ctx)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\eager\execute.py"", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
         [[node model_1/basenet.slice1.0/Conv2D (defined at C:\ProgramData\Anaconda3\lib\site-packages\keras_ocr\detection.py:679) ]] [Op:__inference_predict_function_3683]

Function call stack:
predict_function
```"
39841,Build tensorflow from source errors,"**System information**
Platform: IBM power8 ppc64le machine
OS: Red Hat Enterprise Linux Server 7.4 (Maipo)
TensorFlow build from source:
    Tensorflow source: v2.2.0 , commit: 2b96f36 - 05/05/2020
     Bazel version: 2.0.0:
    GCC/Compiler version: 7.3.0
    CUDA/cuDNN version:  cuda -10.1.105/libcudnn.so.7.5.0
   GPU: Tesla P100-SXM2-16GB

This is the command I used to build tensorflow from source:

      bazel build --jobs 10 //tensorflow/tools/pip_package:build_pip_package

The following is the errors:

    ERROR: /home/users/apps/ppc64le/tensorflow/tensorflow/lite/python/optimize/BUILD:50:1: SWIGing tensorflow/lite/python/optimize/calibration_wrapper.i failed (Exit 1)
    bazel-out/host/bin/external/swig/swig: /lib64/libstdc++.so.6: version `CXXABI_1.3.9' not found (required by bazel-out/host/bin/external/swig/swig)
    Target //tensorflow/tools/pip_package:build_pip_package failed to build
    Use --verbose_failures to see the command lines of failed build steps.
    ERROR: /home/users/apps/ppc64le/tensorflow/tensorflow/python/tools/BUILD:142:1 SWIGing tensorflow/lite/python/optimize/calibration_wrapper.i failed (Exit 1)

The system library /lib/libstdc++.so.6 points to libstdc++.so.6.0.19,  but gcc/7.3.0 has the version of libstdc++.so.6.0.25 which covers CXXABI_1.3.9. How to have the build link to libstdc++.so.6 of gcc/7.3.0  instead of system /lib64/libstdc++.so.6? Using LD_LIBRARY_PATH seems doesn't work.

Thanks in advance!

Best,
Shelton
    
"
39839,Passing initial_epoch parameter to callbacks' self.params in tf.keras.model.fit,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.x
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**

TensorFlow Addons are developing a progress bar (TQDM Progress bar) and we receive and issue where when user specify `initialEpoch > 0` during `model.fit` and when using `tfa.callbacks.TQDMProgressBar` the progress bar will never reach 100% because in `TQDMProgressBar` code we never consider the case when user set `initialEpoch`

`
model.fit(x=X, y=y, class_weight=None, batch_size=batchSize, verbose=0, callbacks=tfa.callbacks.TQDMProgressBar(), validation_split=0.2, shuffle=True, epochs=epochCount, initial_epoch=initialEpoch)
`

https://github.com/tensorflow/addons/issues/1748 

While searching for a solution, I noticed that `initial_epoch` is never passed to Callback's `self.params` dictionary and thus making it hard to implement the feature where users set an initial epoch, thus I am asking if it would make sense for TensorFlow to pass `initial_epoch` to Callback's `self.params` for us to implement that feature. The other way around would be to ask user to specify `initial_epoch` again in the progress bar but that would not be ideal. Thank you so much for your time!

**Will this change the current api? How?**

No, but this will add another key into Callbacks' `self.params` dictionary.

**Who will benefit with this feature?**

Users of TensorFlow Addons TQDM Progress Bar and thus that may need `initial_epoch` in their custom callbacks. 

**Any Other info.**

TensorFlow Addons TQDM Progress Bar Source code: 
https://github.com/tensorflow/addons/blob/master/tensorflow_addons/callbacks/tqdm_progress_bar.py
"
39838,ValueError thrown in trivial Keras model using tf.split,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes, pasted below
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
Anaconda, ""tensorflow-gpu""
- TensorFlow version (use command below):
2.1.0
- Python version:
3.7.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**
Keras model using tf.split (or tf.tile, or tf.zeros) hits the following exception, via ""assert_shallow_structure"" in nest.py, because one of the TensorSpecs is deeper in a sequence than the other (e.g. [[[TensorSpec]]] vs. [TensorSpec]). The actual trigger is tf.keras.models.load_model.

ValueError
Could not find matching function to call loaded from the SavedModel. Got:
  Positional arguments (1 total):
    * Tensor(""inputs:0"", shape=(None, 256, 8, 8), dtype=float32)
  Keyword arguments: {}

Expected these arguments to match one of the following 1 option(s):

Option 1:
  Positional arguments (1 total):
    * [TensorSpec(shape=(None, 256, 8, 8), dtype=tf.float32, name='inputs/0')]
  Keyword arguments: {}

**Describe the expected behavior**
Loading the SavedModel in Keras succeeds without an exception.

**Standalone code to reproduce the issue**
import tensorflow as tf
input = tf.keras.layers.Input(shape=(256, 8, 8), dtype=""float32"")
output, y = **tf.split(input, 2, axis=1)**
model = tf.keras.Model(input, output)
model.save(""C:\\Users\\Public\\repro"", save_format=""tf"")
tf.keras.models.load_model(""C:\\Users\\Public\\repro"")

**Workaround**
Wrapping the tf.split or other tf operation in a Keras Lambda layer works around the bug. Example code:
import tensorflow as tf
input = tf.keras.layers.Input(shape=(256, 8, 8), dtype=""float32"")
output, y = **tf.keras.layers.Lambda(lambda tensor : tf.split(tensor, 2, axis=1))(input)**
model = tf.keras.Model(input, output)
model.save(""C:\\Users\\Public\\repro"", save_format=""tf"")
tf.keras.models.load_model(""C:\\Users\\Public\\repro"")

**Other info / logs**
"
39837,Import Issue ,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:
- Python version:
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
39836,Recall and Precision of binary classifciation not the same as manual calculated,"i have a Keras Sequential Network and use the validation_data attribute to get an idea of the validation straight away. 

However when the model is trained and I predict on the validation set I dont get as high scores as keras is telling me through training.

This is the model and training:

```
def getKerasModel(ndim):

    model = Sequential()
    model.add(Dense(100, activation='relu', input_shape=(ndim,)))
    model.add(Dense(40, activation='relu'))
    model.add(Dense(1, activation='sigmoid'))
    model.compile(optimizer=""adam"", loss=""binary_crossentropy"", metrics=[keras.metrics.Precision(), keras.metrics.Recall()])
    return model
```
Then I train it:
```
from keras.wrappers.scikit_learn import KerasClassifier
from keras.utils import to_categorical

# pipeline is doing scales and one hot encoding
X_train2 = full_pipeline.fit_transform(X_train)
X_val2 = full_pipeline.transform(X_val)

model = getKerasModel(ndim=X_train2.shape[1])
model.fit(X_train2, y_train,epochs=5, batch_size=32, verbose=True, validation_data = (X_val2, y_val))
```
Now this is the result:
```
Train on 265815 samples, validate on 38247 samples
Epoch 1/5
265815/265815 [==============================] - 12s 45us/step - loss: 0.2715 - precision: 0.6690 - recall: 0.4065 - val_loss: 0.2965 - val_precision: 0.6875 - val_recall: 0.4654
Epoch 2/5
265815/265815 [==============================] - 13s 50us/step - loss: 0.2300 - precision: 0.6956 - recall: 0.4959 - val_loss: 0.3735 - val_precision: 0.7000 - val_recall: 0.5192
Epoch 3/5
265815/265815 [==============================] - 13s 47us/step - loss: 0.2111 - precision: 0.7020 - recall: 0.5376 - val_loss: 0.4003 - val_precision: 0.7071 - val_recall: 0.5509
Epoch 4/5
265815/265815 [==============================] - 17s 63us/step - loss: 0.1988 - precision: 0.7113 - recall: 0.5627 - val_loss: 0.4695 - val_precision: 0.7113 - val_recall: 0.5735
Epoch 5/5
265815/265815 [==============================] - 16s 61us/step - loss: 0.1900 - precision: 0.7120 - recall: 0.5831 - val_loss: 0.4893 - val_precision: 0.7134 - val_recall: 0.5908
```
So it definetly says after the last epoch :
```
val_precision: 0.7134 - val_recall: 0.5908
```
When I now use the model, do prediction and evaluate precision and recall seperatly it is much lower:
```
pr = model.predict(X_val2)

binary_result = [1 if i[0] > 0.5 else 0 for i in pr]
print(precision_score(y_val,binary_result))
print(recall_score(y_val,binary_result))

>> 0.23
>> 0.38
```
I don't get why keras is doing much better in its evaluation"
39835,Help Changing Tensor Value,"How can I change a particular tensor value? It seems eagertensors cannot be changed at all in either keras or tensorflow, but it seems to me that this should be a relatively straightforward task.


**System information**
- TensorFlow version 2+:
- Are you willing to contribute it (No): I don't know how



**Describe the feature and the current behavior/state.**
Cannot change tensor values

**Will this change the current api? How?**
Give more flexibility to users

**Who will benefit with this feature?**
All TF users
"
39834,Flops calculation in tensorflow 2.x version.,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using):
tensorflow 2.2
- Are you willing to contribute it (Yes/No):
No


**Describe the feature and the current behavior/state.**
Flops calculation in tf1.x usually use  tf.compat.v1.profiler.ProfileOptionBuilder,but it doesn't work success in tf2.x,So,anyone can show me the official example to calculate flop in tf2.x version?
**Will this change the current api? How?**
No
**Who will benefit with this feature?**
People who care about model efficiency.
**Any Other info.**
"
39833,Hashing functions for tf.string,"**System information**
- TensorFlow version (you are using): 2.2.0
- Are you willing to contribute it (Yes/No): depending on the time commitment

**Describe the feature and the current behavior/state.**
I want to apply SHA-512 to a `tf.string`, so this is what I'm doing
```python
def convert_to_hex_dig(input, length):
  return hashlib.sha512(
      input.numpy().decode('utf-8').encode('utf-8')
  ).hexdigest()[0:length]

current_key = tf.py_function(
  convert_to_hex_dig,
  [mystr, int(mystr_len)],
  Tout=tf.string
)
```

**Will this change the current API? How?**
A new method (or methods) will be added to `tf.strings` for SHA-512 hashing. Other methods may include other types of hashing. Alternatively, a TF addon could be created for hashing/encrypting `tf.string`s. 

**Who will benefit with this feature?**
Users who use TensorFlow for research relating to encryption systems.

**Any Other info.**
Python's `hashlib.sha512` source is here: https://github.com/python/cpython/blob/1ae035b7e847064d09df01ca62b8a761e9b5aae3/Modules/sha512module.c"
39832,Wrong result when calling 'multi-line' lambda inside @tf.function,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux, Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: 3.7.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

When decorating a function using `tf.function` that uses a lambda that extends to multiple lines,
only the first line is considered. When not decorating the function using `tf.function` the result is correct.

**Describe the expected behavior**

`tf.function` should not alter the function behaviour. In the example below, it prints `1` instead of `0`. Removing the `tf.function` decorator gives the correct result. Moving the lambda into a single line gives again a correct result.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```
import tensorflow as tf

a = (
     lambda y: lambda x: x*y 
     - y
    )(1)

@tf.function
def test_lambda():
    tf.print(a(1))
    
test_lambda()
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

The issue was noticed after applying black formatting changed the code output."
39831,Tensorflow keras fit - accuracy and loss both increasing drastically,"ubuntu - 20.04

tensorflow 2.2

dataset used = MNIST

I am testing tensorflow and i notice that validation `sparse_categorical_accuracy` (accuracy) and validation `SparseCategoricalCrossentropy` (loss) both are increasing together which, does not make sense to me. **This is not a case of overfitting**. I think the validation loss should be going down and validation accuracy increasing as the training progresses or, in case of overfitting, validation accuracy going down and validation loss going up. But, validation loss and validation accuracy both are increasing as the training progresses. The training schedule however, is progressing according to expectation i.e training loss going down and training accuracy going up

Here is the code and the output:

```
#testing without preprocess monsoon
import tensorflow as tf
from tensorflow import keras as k
from tensorflow.keras import layers as l
import tensorflow_addons as tfa

mnist = tf.keras.datasets.mnist
(x_t,y_t),(x_te,y_te) = mnist.load_data()
x_t = x_t.reshape(60000,-1)
x_te = x_te.reshape(10000,-1)

d_x_t = tf.data.Dataset.from_tensor_slices(x_t)
d_y_t = tf.data.Dataset.from_tensor_slices(y_t)
dataset = tf.data.Dataset.zip((d_x_t,d_y_t)).shuffle(1000).batch(32)

d_x_te = tf.data.Dataset.from_tensor_slices(x_te)
d_y_te = tf.data.Dataset.from_tensor_slices(y_te)
dataset_test = tf.data.Dataset.zip((d_x_te,d_y_te)).shuffle(1000,seed=42).batch(32)

inp = k.Input((784,))
x = l.BatchNormalization()(inp)
x1 = l.Dense(1024,activation='relu',name='dense_1')(x)
x1=l.Dropout(0.5)(x1)
x1 = l.BatchNormalization()(x1)
x2 = l.Dense(512,activation='relu',name='dense_2')(x1)
x3 = l.Dense(512,activation='relu',name='dense_3')(x)
x = x3+x2

x=l.Dropout(0.5)(x)
x = l.BatchNormalization()(x)
x = l.Dense(10,activation='relu',name='dense_4')(x)
predictions = l.Dense(10,activation=None,name='preds')(x)
model = k.Model(inputs=inp,outputs=predictions)

opt=tfa.optimizers.MovingAverage(
    k.optimizers.Adam(),
    True,
    0.99,
    None,
    'MovingAverage',
    clipnorm=5
)

model.compile(optimizer=opt,
              loss=k.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['sparse_categorical_accuracy'])
print('# Fit model on training data')
history = model.fit(dataset,
                    epochs=30,
                    steps_per_epoch=1875,
                    validation_data = dataset_test,
                    validation_steps = 313)

print('\nhistory dict:', history.history)
model.evaluate(dataset_test,batch_size=32,steps=331)

```

The learning evolution that i am getting is:

```
# Fit model on training data
Epoch 1/30
WARNING:tensorflow:From /home/nitin/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
1875/1875 [==============================] - 49s 26ms/step - loss: 0.3614 - sparse_categorical_accuracy: 0.8913 - val_loss: 0.3355 - val_sparse_categorical_accuracy: 0.9548
Epoch 2/30
1875/1875 [==============================] - 49s 26ms/step - loss: 0.1899 - sparse_categorical_accuracy: 0.9427 - val_loss: 1.2028 - val_sparse_categorical_accuracy: 0.9641
Epoch 3/30
1875/1875 [==============================] - 51s 27ms/step - loss: 0.1546 - sparse_categorical_accuracy: 0.9521 - val_loss: 1.6385 - val_sparse_categorical_accuracy: 0.9673
Epoch 4/30
1875/1875 [==============================] - 38s 20ms/step - loss: 0.1357 - sparse_categorical_accuracy: 0.9585 - val_loss: 2.8285 - val_sparse_categorical_accuracy: 0.9697
Epoch 5/30
1875/1875 [==============================] - 38s 20ms/step - loss: 0.1253 - sparse_categorical_accuracy: 0.9608 - val_loss: 3.8489 - val_sparse_categorical_accuracy: 0.9697
Epoch 6/30
1875/1875 [==============================] - 29s 16ms/step - loss: 0.1149 - sparse_categorical_accuracy: 0.9646 - val_loss: 2.1872 - val_sparse_categorical_accuracy: 0.9699
Epoch 7/30
1875/1875 [==============================] - 29s 16ms/step - loss: 0.1094 - sparse_categorical_accuracy: 0.9646 - val_loss: 2.9429 - val_sparse_categorical_accuracy: 0.9695
Epoch 8/30
1875/1875 [==============================] - 29s 16ms/step - loss: 0.1066 - sparse_categorical_accuracy: 0.9667 - val_loss: 5.6166 - val_sparse_categorical_accuracy: 0.9710
Epoch 9/30
1875/1875 [==============================] - 30s 16ms/step - loss: 0.0991 - sparse_categorical_accuracy: 0.9688 - val_loss: 3.9547 - val_sparse_categorical_accuracy: 0.9710
Epoch 10/30
1875/1875 [==============================] - 29s 16ms/step - loss: 0.0948 - sparse_categorical_accuracy: 0.9701 - val_loss: 4.8149 - val_sparse_categorical_accuracy: 0.9713
Epoch 11/30
1875/1875 [==============================] - 29s 16ms/step - loss: 0.0850 - sparse_categorical_accuracy: 0.9727 - val_loss: 7.4974 - val_sparse_categorical_accuracy: 0.9712
Epoch 12/30
1875/1875 [==============================] - 29s 16ms/step - loss: 0.0879 - sparse_categorical_accuracy: 0.9719 - val_loss: 4.3669 - val_sparse_categorical_accuracy: 0.9714
Epoch 13/30
1875/1875 [==============================] - 30s 16ms/step - loss: 0.0817 - sparse_categorical_accuracy: 0.9743 - val_loss: 9.2499 - val_sparse_categorical_accuracy: 0.9725
Epoch 14/30
1875/1875 [==============================] - 30s 16ms/step - loss: 0.0805 - sparse_categorical_accuracy: 0.9737 - val_loss: 7.5436 - val_sparse_categorical_accuracy: 0.9716
Epoch 15/30
1875/1875 [==============================] - 30s 16ms/step - loss: 0.0798 - sparse_categorical_accuracy: 0.9751 - val_loss: 14.2331 - val_sparse_categorical_accuracy: 0.9712
Epoch 16/30
1875/1875 [==============================] - 29s 16ms/step - loss: 0.0745 - sparse_categorical_accuracy: 0.9757 - val_loss: 7.9517 - val_sparse_categorical_accuracy: 0.9715
Epoch 17/30
1875/1875 [==============================] - 30s 16ms/step - loss: 0.0745 - sparse_categorical_accuracy: 0.9761 - val_loss: 7.9719 - val_sparse_categorical_accuracy: 0.9702
Epoch 18/30
1875/1875 [==============================] - 30s 16ms/step - loss: 0.0741 - sparse_categorical_accuracy: 0.9763 - val_loss: 13.8696 - val_sparse_categorical_accuracy: 0.9665
Epoch 19/30
1875/1875 [==============================] - 30s 16ms/step - loss: 0.0728 - sparse_categorical_accuracy: 0.9760 - val_loss: 20.2949 - val_sparse_categorical_accuracy: 0.9688
Epoch 20/30
1875/1875 [==============================] - 45s 24ms/step - loss: 0.0699 - sparse_categorical_accuracy: 0.9775 - val_loss: 8.8696 - val_sparse_categorical_accuracy: 0.9713
Epoch 21/30
1875/1875 [==============================] - 29s 16ms/step - loss: 0.0699 - sparse_categorical_accuracy: 0.9777 - val_loss: 12.9682 - val_sparse_categorical_accuracy: 0.9723
Epoch 22/30
1875/1875 [==============================] - 30s 16ms/step - loss: 0.0674 - sparse_categorical_accuracy: 0.9781 - val_loss: 61.1677 - val_sparse_categorical_accuracy: 0.9692
Epoch 23/30
1875/1875 [==============================] - 30s 16ms/step - loss: 0.0651 - sparse_categorical_accuracy: 0.9798 - val_loss: 21.3270 - val_sparse_categorical_accuracy: 0.9697
Epoch 24/30
1875/1875 [==============================] - 31s 16ms/step - loss: 0.0624 - sparse_categorical_accuracy: 0.9800 - val_loss: 62.2778 - val_sparse_categorical_accuracy: 0.9685
Epoch 25/30
1875/1875 [==============================] - 30s 16ms/step - loss: 0.0665 - sparse_categorical_accuracy: 0.9792 - val_loss: 24.9327 - val_sparse_categorical_accuracy: 0.9687
Epoch 26/30
1875/1875 [==============================] - 46s 24ms/step - loss: 0.0605 - sparse_categorical_accuracy: 0.9805 - val_loss: 42.0141 - val_sparse_categorical_accuracy: 0.9700
Epoch 27/30
1875/1875 [==============================] - 29s 16ms/step - loss: 0.0601 - sparse_categorical_accuracy: 0.9806 - val_loss: 54.8586 - val_sparse_categorical_accuracy: 0.9695
Epoch 28/30
1875/1875 [==============================] - 30s 16ms/step - loss: 0.0583 - sparse_categorical_accuracy: 0.9811 - val_loss: 25.3613 - val_sparse_categorical_accuracy: 0.9680
Epoch 29/30
1875/1875 [==============================] - 29s 16ms/step - loss: 0.0576 - sparse_categorical_accuracy: 0.9811 - val_loss: 23.2299 - val_sparse_categorical_accuracy: 0.9710
Epoch 30/30
1875/1875 [==============================] - 30s 16ms/step - loss: 0.0566 - sparse_categorical_accuracy: 0.9817 - val_loss: 16.5671 - val_sparse_categorical_accuracy: 0.9728

history dict: {'loss': [0.36135926842689514, 0.1898646354675293, 0.15456895530223846, 0.13569727540016174, 0.12525275349617004, 0.1148592159152031, 0.10943067818880081, 0.1066298857331276, 0.09912335127592087, 0.09476170688867569, 0.08501157909631729, 0.0879492461681366, 0.08170024305582047, 0.08047273010015488, 0.07976552098989487, 0.07453753799200058, 0.07450901716947556, 0.07413797080516815, 0.07278618961572647, 0.0698995441198349, 0.06988336145877838, 0.06740442663431168, 0.06507138162851334, 0.06242847815155983, 0.0665266141295433, 0.06050613150000572, 0.06005210056900978, 0.05830719694495201, 0.05763527378439903, 0.05664650723338127], 'sparse_categorical_accuracy': [0.8913000226020813, 0.9427499771118164, 0.9521499872207642, 0.9585333466529846, 0.9607999920845032, 0.9645500183105469, 0.9645666480064392, 0.9666833281517029, 0.9687666893005371, 0.9701166749000549, 0.9726999998092651, 0.9719499945640564, 0.9742666482925415, 0.9736999869346619, 0.9750999808311462, 0.9757000207901001, 0.9760833382606506, 0.9763166904449463, 0.9759833216667175, 0.977483332157135, 0.9777166843414307, 0.9780833125114441, 0.9798333048820496, 0.9800000190734863, 0.9792333245277405, 0.9805499911308289, 0.9805999994277954, 0.9810666441917419, 0.9810666441917419, 0.9816833138465881], 'val_loss': [0.33551061153411865, 1.2028071880340576, 1.6384732723236084, 2.828489065170288, 3.8488738536834717, 2.187160015106201, 2.9428975582122803, 5.6166462898254395, 3.954725503921509, 4.814915657043457, 7.4974141120910645, 4.366909503936768, 9.24986457824707, 7.543578147888184, 14.233136177062988, 7.951717853546143, 7.971870422363281, 13.869564056396484, 20.29490089416504, 8.869643211364746, 12.968180656433105, 61.167701721191406, 21.327049255371094, 62.27778625488281, 24.932708740234375, 42.01411437988281, 54.85857009887695, 25.361297607421875, 23.229896545410156, 16.56712532043457], 'val_sparse_categorical_accuracy': [0.954800009727478, 0.9641000032424927, 0.9672999978065491, 0.9696999788284302, 0.9696999788284302, 0.9699000120162964, 0.9695000052452087, 0.9710000157356262, 0.9710000157356262, 0.9713000059127808, 0.9711999893188477, 0.9714000225067139, 0.9725000262260437, 0.9715999960899353, 0.9711999893188477, 0.9714999794960022, 0.9702000021934509, 0.9664999842643738, 0.9688000082969666, 0.9713000059127808, 0.9722999930381775, 0.9692000150680542, 0.9696999788284302, 0.968500018119812, 0.9686999917030334, 0.9700000286102295, 0.9695000052452087, 0.9679999947547913, 0.9710000157356262, 0.9728000164031982]}
302/331 [==========================>...] - ETA: 0s - loss: 17.1192 - sparse_categorical_accuracy: 0.9725WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 331 batches). You may need to use the repeat() function when building your dataset.
313/331 [===========================>..] - 1s 3ms/step - loss: 16.5671 - sparse_categorical_accuracy: 0.9728
[16.567113876342773, 0.9728000164031982]
```"
39830,Stop .flow_from_dataframe from printing,"Can you please add a 'verbose' parameter to flow_from_dataframe to prevent printing?

I've implemented a custom generator that calls ```ImageDataGenerator```'s method ```flow_from_dataframe``` for each batch, to create a randomly sampled batch, which has one instance of each class:
```lang-python
  def __getitem__(self, idx):

        batch_df = pd.DataFrame()

        # create a dataframe with one random sample for each class
        for class_name in batch_class_names:
            rand_row = self.df_dict[class_name].sample(n = 1)
            batch_df = batch_df.append(rand_row, ignore_index=True)
            
        # create generator
        batch_gen = self.generator.flow_from_dataframe(
            dataframe=batch_df, directory=self.directory, x_col=""filename"",
            y_col=""brand"", classes=self.class_names,
            class_mode=""categorical"",
            target_size=self.image_dims, color_mode=""rgb"", batch_size=batch_df.shape[0], shuffle=self.shuffle)

        # return batch
        return next(batch_gen)
```

This causes ```flow_from_dataframe to``` print **a new line for each batch**, which ruins the epochs outputs.
Instead of printing a new line after each epoch (which has 100 batches), a new line is printed after each batch:

```lang-python
  1/100 [..............................] - ETA: 20:05 - loss: 3.4795 - tpr_metric: 0.0000e+00Found 9 validated image filenames belonging to 28 classes.
  2/100 [..............................] - ETA: 11:11 - loss: 3.4328 - tpr_metric: 0.0000e+00Found 9 validated image filenames belonging to 28 classes.
  3/100 [..............................] - ETA: 8:10 - loss: 3.4140 - tpr_metric: 0.0000e+00Found 9 validated image filenames belonging to 28 classes.
  4/100 [>.............................] - ETA: 6:39 - loss: 3.4309 - tpr_metric: 0.0000e+00Found 9 validated image filenames belonging to 28 classes.
  5/100 [>.............................] - ETA: 5:45 - loss: 3.4323 - tpr_metric: 0.0000e+00Found 9 validated image filenames belonging to 28 classes.
  6/100 [>.............................] - ETA: 5:08 - loss: 3.4221 - tpr_metric: 0.0000e+00Found 9 validated image filenames belonging to 28 classes.
  7/100 [=>............................] - ETA: 4:41 - loss: 3.4188 - tpr_metric: 0.0000e+00Found 9 validated image filenames belonging to 28 classes.
```

I've tried placing ```sys.stdout = open(os.devnull, 'w')``` before I call ```flow_from_dataframe``` and ```sys.stdout = sys.__stdout__``` right after, but this stopped all printing (epoch printing as well).


"
39829,CUDA compiling include file path failure inside tensorflow python installation directory in Windows 10,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: 3.6
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: 10.1
- GPU model and memory: (not related with this issue)

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

Create a CUDA source file, e.g. named *test.cu*, with content:

```
#define EIGEN_USE_GPU
#define __CUDA_INCLUDE_COMPILER_INTERNAL_HEADERS__
#include ""tensorflow/core/framework/op_kernel.h""
```

Then run command:
 `nvcc ./test.cu --include-path ""C:\Users\xxx\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\include""`

Then you will got error like this:

> C:/Users/xxx/AppData/Local/Programs/Python/Python36/lib/site-packages/tensorflow/include\unsupported/Eigen/CXX11/Tensor(74): fatal error C1083: Cannot open include file: 'unistd.h': No such file or directory 

**Describe the expected behavior**

Compiling succeed.

**My Research**

The error occurred in an Eigen C++ file named `Tensor`:

```
#ifdef EIGEN_USE_GPU
  #include <iostream>
  #if defined(EIGEN_USE_HIP)
    #include <hip/hip_runtime.h>
  #else
    #include <cuda_runtime.h>
  #endif
  #include <atomic>
  #include <unistd.h>
#endif
```

You can see that `unistd.h` including is not excluded by some conditional compiling branch of *_WIN32*.

It seems a bug within *Eigen*, but I found the original source [here](https://github.com/PX4/eigen/blob/master/unsupported/Eigen/CXX11/Tensor#L85):

```
#ifdef EIGEN_USE_GPU
#include <iostream>
#include <cuda_runtime.h>
#if __cplusplus >= 201103L
#include <atomic>
#include <unistd.h>
#endif
#endif
```

This is different, and I haven't found any uniform record in their committing history. So this seems modified by Tensorflow team or someone else already.

And I solved this issue just by commenting out the line of `#include <unistd.h>` in the tensorflow python installation directory. Expecting the official fix."
39828,Python project bug,"Hi I'm new to python and I start my first project but when I type ""minus"" it execute addition part of program and I try and try but I fail to fix it

x = int(input(""X Value: ""))
y = int(input(""Y Value: ""))
i = 0

while i == 0:
    print("" "")
    print(f""({x}, {y})"")
    cmd = input(""> "")
    cmd = cmd.lower()

    # plus
    if cmd == ""plus"" or ""Addition"":
        i = 1
        while i == 1:
            sub_cmd_pos = input(""(x) + y  or  (y) + x "")
            sub_cmd_pos = sub_cmd_pos.lower()
            if sub_cmd_pos == 'x':
                print(x + y)
                i = 1
            elif sub_cmd_pos == 'y':
                print(y + x)
                i = 1
            else:
                print(""Invalid Command, For help type 'help' "")

    # minus
    elif cmd == ""minus"" or ""subtraction"":
        i = 2
        while i == 2:
            sub_cmd_neg = input(""(x) - y  or  (y) - x "")
            sub_cmd_neg = sub_cmd_neg.lower()
            if sub_cmd_neg == 'x':
                print(x - y)
                i = 0
            elif sub_cmd_neg == 'y':
                print(y - x)
                i = 0
            else:
                print(""Invalid Command, For help type 'help' "")
"
39827,InvalidArgumentError while using GRU layer in custom training loop,"**System information**
- TensorFlow version `2.1.0`
- Python version: `3`
- GPU model and memory: `NVIDIA Tesla P100`
- CUDA Version: `10.1`
- Environment: This happens both on Kaggle and Colab

**Describe the current behavior**
I'm trying to train a Hugging face transformer model (roBERTa base) with a custom training loop, and got the error below:

```
InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument:  InstantiateOptions.input_devices must have the same length as the number of arguments: input_devices length = 23 number of arguments = 24
	 [[{{node while/body/_1/StatefulPartitionedCall}}]]
  (1) Invalid argument:  InstantiateOptions.input_devices must have the same length as the number of arguments: input_devices length = 23 number of arguments = 24
	 [[{{node while/body/_1/StatefulPartitionedCall}}]]
	 [[while/body/_1/Adam/Cast_6/ReadVariableOp/_30]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_step_35635]

Function call stack:
train_step -> train_step
```
The thing is I can run the same model using `model.fit()` API, and this error only happens when I use a LSTM or GRU layer on top of the transformer

**Describe the expected behavior**
Training should go normal"
39824, C++ compilation of rule '//tensorflow/core/kernels:mkl_softmax_op' failed - Win 10 / VS2019,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): Source
- TensorFlow version: Master Branch
- Python version: 3.7
- Bazel version (if compiling from source): 2.0.1
- GCC/Compiler version (if compiling from source):  VS2019
- CUDA/cuDNN version: 10.1
- GPU model and memory: 2070 Max-Q

**Describe the problem**

Build of mkl version of TF fails to build from source, errors with the following

ERROR: C:/sdks/tensorflow-dev/tensorflow/core/kernels/BUILD:8207:1: C++ compilation of rule '//tensorflow/core/kernels:mkl_softmax_op' failed (Exit 2)
.\tensorflow/core/util/mkl_util.h(1285): error C2131: expression did not evaluate to a constant
.\tensorflow/core/util/mkl_util.h(1284): note: failure was caused by a read of a variable outside its lifetime
.\tensorflow/core/util/mkl_util.h(1284): note: see usage of 'dim'
.\tensorflow/core/util/mkl_util.h(1286): error C2131: expression did not evaluate to a constant
.\tensorflow/core/util/mkl_util.h(1284): note: failure was caused by a read of a variable outside its lifetime
.\tensorflow/core/util/mkl_util.h(1284): note: see usage of 'dim'
.\tensorflow/core/util/mkl_util.h(1288): error C3863: array type 'dnnl_dim_t [kNumDims]' is not assignable
.\tensorflow/core/util/mkl_util.h(1289): error C3863: array type 'dnnl_dim_t [kNumDims]' is not assignable
Target //tensorflow/tools/pip_package:build_pip_package failed to build

**Provide the exact sequence of commands / steps that you executed before running into the problem**

bazel build --config=mkl //tensorflow/tools/pip_package:build_pip_package

"
39823,TFLite conversion of Conv1D layer with dilation_rate>1,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.2.0
- Python version: 3.7

**Describe the current behavior**
After converting a TF ```Conv1D``` op with ```dilation_rate>1``` to TFLite op, the interpreter cannot allocate tensors:

```
RuntimeError: tensorflow/lite/kernels/space_to_batch_nd.cc:98 NumDimensions(op_context.input) != kInputDimensionNum (3 != 4)Node number 0 (SPACE_TO_BATCH_ND) failed to prepare.
```

**Describe the expected behavior**
TFLite model should be able to load and execute by the interpreter.

**Standalone code to reproduce the issue**
```
import tensorflow as tf

from tensorflow.keras.models import Model
from tensorflow.keras.layers import *


def get_model():
  input = tf.keras.Input(shape=(10, 40))

  # No error when dilation rate == 1
  layer = Conv1D(32, (3), dilation_rate=2, padding='same', use_bias=False)(input)
  layer = GlobalMaxPooling1D()(layer)
  output = Dense(2)(layer)

  model = Model(inputs=[input], outputs=[output])
  return model


model = get_model()

converter = tf.lite.TFLiteConverter.from_keras_model(model)

tflite_model = converter.convert()
open(""./trained_model.tflite"", ""wb"").write(tflite_model)

interpreter = tf.lite.Interpreter(model_path=""./trained_model.tflite"")

interpreter.allocate_tensors()
```

**Other info / logs** 
The problem does not occur when ```dilation_rate==1```
"
39822,Translation from frozen graph to lite model is incorrect when quantization is enabled.,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (or github SHA if from source): 2.1.0


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

From a correct frozen graph, I try to use quantized tflite conversion which fails to give a correct prediction while unquantized version DOES give correct prediction. I attach all the code to generate these conversion as follows.

```
import tensorflow as tf
import tensorflow.compat.v1 as tf1

def tf2lite(model_file, input_img_size, quantized=False):
    # We only run this function with CPU
    my_devices = tf.config.list_physical_devices(device_type='CPU')
    tf.config.set_visible_devices(devices=my_devices, device_type='CPU')

    assert os.path.isfile(model_file), 'File {} does not exist'.format(model_file)
    assert os.path.splitext(model_file)[1] == '.pb', 'File {} is not TF model'.format(model_file)

    converter  = tf1.lite.TFLiteConverter.from_frozen_graph(
                    model_file,
                    input_arrays=['input_images'],
                    output_arrays=['classification_result'],
                    input_shapes={""input_images"": [1, input_img_size, input_img_size, 3]})
    if quantized: # enable quantization
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        rep = Representative_data(input_img_size)
        converter.representative_dataset = rep.data_gen
    tflite_net = converter.convert()
    return tflite_net

def tf2lite_save(model_file, input_img_size, save_file, quantized=False):
    net = tf2lite(model_file, input_img_size, quantized)
    with open(save_file, 'wb') as f:
        f.write(net)

frozen_file = './frozen_imgsize_{}.pb'.format(224)
tflite_file = './converted_imgsize_{}.tflite'.format(224)
tf2lite_save(frozen_file, 224, tflite_file, quantized=True)

# Verify TFLite model vs TF model
lite_model = tf.lite.Interpreter(model_path=tflite_file)
lite_model.allocate_tensors()
input_details = lite_model.get_input_details()
output_details = lite_model.get_output_details()
lite_model.set_tensor(input_details[0]['index'], tf_input)
lite_model.invoke()
lite_classify = lite_model.get_tensor(output_details[0]['index'])
print('TFLite: prediction={}'.format(np.argmax(lite_classify)))
print(lite_classify)
assert np.argmax(lite_classify) == 20
```

I miss out two things:
1. tf_input is No.1000 picture in ImageNet validation dataset whose correct classification index should be 20. I did the following picture transformation.
- resize picture size to 256
- center crop 224
- normalize with   mean=[0.485, 0.456, 0.406],
                            std=[0.229, 0.224, 0.225]

2. Representative_data class has too much code to upload. It is a ImageNet data loader which read val data and give 100 samples randomly for quantization to use. the image preprocessing is the same as above.

If we modify the above code to 
tf2lite_save(frozen_file, 224, tflite_file, quantized=False)

It will pass with correct result (see converted_imgsize_224_unquantized.tflite and log.txt). Otherwise, it will produce almost all 0 with incorrect classification (see converted_imgsize_224_quantized.tflite and log.txt).

Please help me to figure out what I did wrong. Many thanks.




**The output from the converter invocation**

```
[frozen_imgsize_224.pb.txt](https://github.com/tensorflow/tensorflow/files/4672384/frozen_imgsize_224.pb.txt)
[converted_imgsize_224_unquantized.tflite.txt](https://github.com/tensorflow/tensorflow/files/4672386/converted_imgsize_224_unquantized.tflite.txt)
[converted_imgsize_224_quantized.tflite.txt](https://github.com/tensorflow/tensorflow/files/4672387/converted_imgsize_224_quantized.tflite.txt)
[log.txt](https://github.com/tensorflow/tensorflow/files/4672396/log.txt)


```

**Also, please include a link to the saved model or GraphDef**

```
# Put link here or attach to the issue.
```

**Failure details**
If the conversion is successful, but the generated model is wrong,
state what is wrong:
- Producing wrong results and/or decrease in accuracy
- Producing correct results, but the model is slower than expected (model generated from old converter)


**RNN conversion support**
If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
39820,tf.queue.FIFOQueue throws NotFoundError on enqueue / dequeue if created in graph mode,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution: Windows 7 and Ubuntu 18.04.3 LTS (colab)
- TensorFlow installed from (source or binary): pip install tf-nightly-gpu
- TensorFlow version (use command below):    v1.12.1-32502-g2544e4e277 2.3.0-dev20200523 (Windows and colab)
- Python version: 3.6.6 (Windows), 3.6.9 (colab)
- CUDA/cuDNN version: 10.1/7.6.3.30 (Windows), unknown (colab)
- GPU model and memory: NVidia 1080Ti ~11GB (Windows), unknown (colab)

**Describe the current behavior**

When creating a tf.FIFOQueue inside a tf.function decorated function, enqueueing / dequeueing tensors from the queue fails with a NotFoundError mentioning a non-existing resource of name ""localhost/{Some number}/{C++ mangled name of class tensorflow::QueueInterface}""

All operations work fine if the queue is created in eager mode.

**Describe the expected behavior**

Either the graph mode execution should succeed just like in eager mode, or the unsuitability of queue creation for graph mode should be documented as API.

**Standalone code to reproduce the issue**

Linux case:

https://colab.research.google.com/drive/1OQ68ibI-9u-6f4nslwIzDuMzdztxVGwX?usp=sharing


Windows case:

```
import tensorflow as tf

@tf.function
def foo():	
	queue = tf.queue.FIFOQueue(-1, [tf.string], tf.TensorShape([]))
	queue.enqueue('Hello')
	s = queue.dequeue()
	tf.print(s)

foo()
```

Log is attached

[log.txt](https://github.com/tensorflow/tensorflow/files/4672215/log.txt)"
39819,not able to run %tensorboard --logdir logs\fit,"TypeError                                 Traceback (most recent call last)
~\Anaconda3\lib\site-packages\IPython\core\formatters.py in __call__(self, obj)
    691                 type_pprinters=self.type_printers,
    692                 deferred_pprinters=self.deferred_printers)
--> 693             printer.pretty(obj)
    694             printer.flush()
    695             return stream.getvalue()

~\Anaconda3\lib\site-packages\IPython\lib\pretty.py in pretty(self, obj)
    377                             meth = cls._repr_pretty_
    378                             if callable(meth):
--> 379                                 return meth(obj, self, cycle)
    380             return _default_pprint(obj, self, cycle)
    381         finally:

TypeError: _repr_pretty_() takes 1 positional argument but 3 were given

---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
~\Anaconda3\lib\site-packages\IPython\core\formatters.py in __call__(self, obj)
    691                 type_pprinters=self.type_printers,
    692                 deferred_pprinters=self.deferred_printers)
--> 693             printer.pretty(obj)
    694             printer.flush()
    695             return stream.getvalue()

~\Anaconda3\lib\site-packages\IPython\lib\pretty.py in pretty(self, obj)
    377                             meth = cls._repr_pretty_
    378                             if callable(meth):
--> 379                                 return meth(obj, self, cycle)
    380             return _default_pprint(obj, self, cycle)
    381         finally:

TypeError: _repr_pretty_() takes 1 positional argument but 3 were given
"
39818,tensorflow cannot use feature columns to keras model,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:
https://tensorflow.google.cn/versions/r2.1/api_docs/python/tf/feature_column/numeric_column



## Description of issue (what needs changing):

I tried to input a feature column to the keras model, but it was not available and the error was as follows:

```
    input_wide2 = keras.layers.Dense(300, activation=dnn_activation, )(input_lstm)
  File ""/home/zy/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 818, in __call__
    self._maybe_build(inputs)
  File ""/home/zy/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 2098, in _maybe_build
    self.input_spec, inputs, self.name)
  File ""/home/zy/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/input_spec.py"", line 163, in assert_input_compatibility
    if x.shape.ndims is None:
AttributeError: 'DenseFeatures' object has no attribute 'shape'
```

I tried to search the solution of the problem through google, and the answer I got was to use tf.keras.Sequential () to solve the problem, but my model cannot use tf.keras.Sequential (), because I need to make a multi-input and more complex model . Sequential () cannot meet my requirements. Is this error a bug? Or am I using the wrong method? My case
[text.txt](https://github.com/tensorflow/tensorflow/files/4672214/text.txt)
 code is as follows



```
from tensorflow import keras
from tensorflow import feature_column
from tensorflow.keras.layers import Dense
from tensorflow.keras import Input, Model
from tensorflow.keras import regularizers
import tensorflow as tf


def read_tfrecord_input( tf_dir, batch_size, df_columns_list, which_labels, output_size):
    raw_dataset = tf.data.TFRecordDataset(tf_dir)
    feature_description = {}

    def _parse_function(record):
        for n in df_columns_list:

            # if n =='KDJ_gold':                            
[text.txt](https://github.com/tensorflow/tensorflow/files/4672218/text.txt)

            #     feature_description['%s'%n]=tf.io.FixedLenFeature([], tf.string, default_value='')
            if 'pred' in n:
                pass
            else:
                feature_description['%s' % n] = tf.io.FixedLenFeature([], tf.float32, default_value=0.0)
            feature_description['pred'] = tf.io.FixedLenFeature([output_size], tf.float32)

        parsed = tf.io.parse_single_example(serialized=record, features=feature_description)

        labels = parsed['pred']
        # kdj_gold = tf.cast(parsed['KDJ_gold'], tf.string)
        input_dict = {}
        for n in df_columns_list:
            if 'pred' in n:
                print(n, 'pass')
                pass
            # elif n=='KDJ_gold':
            #     input_dict['%s'%n]=kdj_gold                
            else:
                input_dict['%s' % n] = parsed['%s' % n]
        return input_dict, labels

    parsed_dataset = raw_dataset.map(_parse_function, num_parallel_calls=24)  
    parsed_dataset = parsed_dataset.batch(batch_size, drop_remainder=True)
    parsed_dataset = parsed_dataset.repeat()

    return parsed_dataset
dropout_rate=0.5
dnn_activation='relu'
volume = tf.feature_column.numeric_column('volume', shape=(1,))
lstm_list=[volume]

input_deep = keras.layers.DenseFeatures(lstm_list)
input_lstm = keras.layers.DenseFeatures(lstm_list)
input_wide2 = keras.layers.Dense(300, activation=dnn_activation, )(input_lstm)
input_wide2 = keras.layers.Dropout(0.5)(input_wide2)
lstm = keras.layers.LSTM(units=300, return_sequences=True, return_state=True, activation='tanh')
whole_seq_output, final_memory_state, final_carry_state = lstm(input_wide2)
lstm_drop_layer = keras.layers.Dropout(0.5)(whole_seq_output)

dnn1 = keras.layers.Dense(units=800, activation=dnn_activation)(input_deep)
dnn1 = keras.layers.BatchNormalization(axis=1)(dnn1)
dnn1 = keras.layers.SpatialDropout1D(dropout_rate)(dnn1)
dnn2 = keras.layers.Dense(units=600, activation=dnn_activation)(dnn1)

cancat_all = keras.layers.concatenate([dnn2, lstm_drop_layer])
output = keras.layers.Dense(1, activation='tanh')(cancat_all)
model = Model(inputs=[input_lstm, input_deep], outputs=[output])

model.compile(loss=""mae"", optimizer=""Adam"")
estimatoer = keras.estimator.model_to_estimator(keras_model=model, model_dir='model/ld')
estimatoer.train(input_fn=lambda: read_tfrecord_input(
    tf_dir='data/train.tfrecord', batch_size=9600, df_columns_list=lstm_list,
    which_labels='pred_d', output_size=1), max_steps=500)
```

please help me ,thank you!!


### Clear description

For example, why should someone use this method? How is it useful?

### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

See the API guide: https://www.tensorflow.org/community/contribute/docs_ref
on how to write testable usage examples.

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
39817,AttributeError: 'Tensor' object has no attribute 'numpy',"I use tensorflow with Google Colaboratory
I have TensorFlow 2.x selected.

I wrote a small error metrics but could not succeed to transform the result to numpy array.
I got AttributeError: 'Tensor' object has no attribute 'numpy'

I thought I could transform my tensor to numpy array with a .numpy() call

```
def custom__error(y_true, y_pred):
  # ---- y_pred
  yp = tf.nn.softmax( y_pred)
  bp = tf.argsort(yp,axis=-1,direction='DESCENDING',stable=False,name=None)
  #cp = bp.numpy()
  xcp = bp[None,:10]
  # ---- y_true
  yt = tf.nn.softmax( y_true )
  bt = tf.argsort(yt,axis=-1,direction='DESCENDING',stable=False,name=None)
  #ct = bt.numpy()
  xct = bt[None,:10]
  # ---- common
  count =  tf.sets.intersection(xcp,xct)
  dcount = tf.sparse.to_dense(count)
  return dcount.numpy()
```
```
<ipython-input-46-10646c4f8b46> in custom__error(y_true, y_pred)
     15   count =  tf.sets.intersection(xcp,xct)
     16   dcount = tf.sparse.to_dense(count)
---> 17   return dcount.numpy()
     18 
     19 

AttributeError: 'Tensor' object has no attribute 'numpy'
```

"
39816,no specification for blank index for ctc_batch_cost,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod

https://tensorflow.google.cn/api_docs/python/tf/keras/backend/ctc_batch_cost

## Description of issue (what needs changing):

there is no specification for blank index. I can see default blank index for tf.nn.ctc_loss from [here](https://tensorflow.google.cn/api_docs/python/tf/nn/ctc_loss). is tf.keras.backend.ctc_batch_cost uses the same token for blank index? the old keras interface use a different default blank index. so, I am not sure about tf.keras's ctc_batch_cost's behavior.

### Clear description

For example, why should someone use this method? How is it useful?

the specification is important for people building recurrent neural network with tf.keras interfaces.

### Correct links

Is the link to the source code correct?

yes.

### Parameters defined

Are all parameters defined and formatted correctly?

yes.

### Returns defined

Are return values defined?

yes.

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

no.

### Usage example

Is there a usage example?

See the API guide: https://www.tensorflow.org/community/contribute/docs_ref
on how to write testable usage examples.

no.

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

no.

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style

no."
39815,tf.debugging.assert_near raises InvalidArgumentError for complex tensors,"**System information**
- Linux (different setups), other OS not tested
- tensorflow-cpu installed from pip
- TensorFlow version 2.2.0
- Python version 3.8.3

**Describe the current behavior**
`tf.debugging.assert_near` raises `InvalidArgumentError` for `complex64` or `complex128` inputs, although the documentation says complex inputs are allowed.

**Standalone code to reproduce the issue**
```python
import tensorflow as tf  
a = tf.constant([1j], dtype=tf.complex64) 
b = tf.constant([1j], dtype=tf.complex64) 
tf.debugging.assert_near(a, b)  
```

**Output** 
```
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-7-ddb632344d16> in <module>
----> 1 tf.debugging.assert_near(a, b)

/usr/lib/python3.8/site-packages/tensorflow/python/ops/check_ops.py in assert_near_v2(x, y, rtol, atol, message, summarize, name)
    756   @end_compatibility
    757   """"""
--> 758   return assert_near(x=x, y=y, rtol=rtol, atol=atol, summarize=summarize,
    759                      message=message, name=name)
    760 

/usr/lib/python3.8/site-packages/tensorflow/python/ops/check_ops.py in assert_near(x, y, rtol, atol, data, summarize, message, name)
    833           'x (%s) = ' % x_name, x, 'y (%s) = ' % y_name, y
    834       ]
--> 835     tol = atol + rtol * math_ops.abs(y)
    836     diff = math_ops.abs(x - y)
    837     condition = math_ops.reduce_all(math_ops.less(diff, tol))

/usr/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py in binary_op_wrapper(x, y)
    982     with ops.name_scope(None, op_name, [x, y]) as name:
    983       if isinstance(x, ops.Tensor) and isinstance(y, ops.Tensor):
--> 984         return func(x, y, name=name)
    985       elif not isinstance(y, sparse_tensor.SparseTensor):
    986         try:

/usr/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py in _mul_dispatch(x, y, name)
   1281   is_tensor_y = isinstance(y, ops.Tensor)
   1282   if is_tensor_y:
-> 1283     return gen_math_ops.mul(x, y, name=name)
   1284   else:
   1285     assert isinstance(y, sparse_tensor.SparseTensor)  # Case: Dense * Sparse.

/usr/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py in mul(x, y, name)
   6087         pass  # Add nodes to the TensorFlow graph.
   6088     except _core._NotOkStatusException as e:
-> 6089       _ops.raise_from_not_ok_status(e, name)
   6090   # Add nodes to the TensorFlow graph.
   6091   _, _, _op, _outputs = _op_def_library._apply_op_helper(

/usr/lib/python3.8/site-packages/tensorflow/python/framework/ops.py in raise_from_not_ok_status(e, name)
   6651   message = e.message + ("" name: "" + name if name is not None else """")
   6652   # pylint: disable=protected-access
-> 6653   six.raise_from(core._status_to_exception(e.code, message), None)
   6654   # pylint: enable=protected-access
   6655 

/usr/lib/python3.8/site-packages/six.py in raise_from(value, from_value)

InvalidArgumentError: cannot compute Mul as input #1(zero-based) was expected to be a complex64 tensor but is a float tensor [Op:Mul]

```"
39814,tf.random.uniform array minval/maxval with dtype=tf.int*,"Hi,

The current implementation of `tf.random.uniform` allows for non-scalar `minval` and `maxval` if `dtype=tf.float32` (or `tf.float64`).  However, this is not the case for `dtype=tf.int32` (or `tf.int64`).

e.g.
```python
tf.random.uniform(shape=(), minval=[0, 0], maxval=[10, 10], dtype=tf.int32)
ValueError: minval must be a scalar; got a tensor of shape [2] ....
```
generates a `ValueError` whereas
```python
tf.random.uniform(shape=(), minval=[0., 0.], maxval=[10., 10.], dtype=tf.float32)
tf.Tensor([5.918947 5.918947], shape=(2,), dtype=float32)
```
works as expected.

The documentation doesn't indicate that the integer version of `tf.random.uniform` has this restriction.  Is it expected behaviour, and if so what is the workaround?

Thanks,

Chris

----
TF version 2.3.0-dev20200521 (tf-nightly)
Python 3.7.6 (Anaconda 3)
"
39813,can't convert a string tensor to  python string when using Dataset.list_files(PATH).map(fun),"![image](https://user-images.githubusercontent.com/63587875/82728893-e59f6200-9d25-11ea-9f30-297c82594922.png)

as showed in the image. the wavPath is Tensor(""args_0:0"", shape=(), dtype=string). and then librosa.load(wavPath) raise error. there is noway to convert Tensor(""args_0:0"", shape=(), dtype=string) to the correct python string path
"
39812,ruy optimized library enabling for tf-lite,"Per blog [What’s new in TensorFlow Lite](https://blog.tensorflow.org/2020/04/whats-new-in-tensorflow-lite-from-devsummit-2020.html) there's supposed to be developed an optimized matrix multiplication library  [(ruy).](https://github.com/google/ruy)

How to check if this ([ruy](https://github.com/google/ruy)) optimized library is enabled during a build (compilation) from the source or how to check or make sure it's either enabled or disabled?
"
39811,ResourceExhaustedError with a RNN compiled with XLA,"Hi,

I experimented with a custom RNN compilation with XLA and I hit OOM with only a single layer RNN (used LayerNormLSTMCell cell).

Repro in collab (tested on tf-nightly)  https://colab.research.google.com/drive/1YWfuRX72A-819S_YqFZ0A0BNBAR5cTFv?usp=sharing
I understand that XLA maybe more memory hungry than cuDNN LSTM implementation, but its relatively small model to not fit to one GPU (single-layer layernorm LSTM with 1536 units)"
39810,Introduce a groundtruths argument in the call method of tf.keras.layer,"**System information**: Ubuntu 16.04
- TensorFlow version (you are using): 2.2.0
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**

Today, the API only support three arguments (inputs, training, masks):

```python
class MyNetwork(tf.keras.layers.Layer):

  def call(self, inputs, training=None):  
     # Do somestuff
      return stuff
```

I propose to introduce a fourth one (groundtruths or other):

```python
class MyNetwork(tf.keras.layers.Layer):

  def call(self, inputs, training=None, groundtruths=None):  
     # Do somestuff
      return stuff
```

You could tell: why don't you put your groundtruths inside the inputs? It leads to issue with the SavedModel format. My inputs in training and inference won't be the same which leads to errors.

Example:

```python
training_inputs = {'image': tf.zeros((1, 800, 800, 3)), 'gt_bbox':  tf.constant([[0, 0, 1, 1]], tf.float32)}
inference_inputs = {'image': tf.zeros((1, 800, 800, 3))}
```
**Will this change the current api? How?**

It will change the interface of the `call` method from `tf.keras.layers.Layer`.

**Who will benefit with this feature?**

People working on algorithms like FasterRCNN need to pass during the training the groundtruths 
to perform sampling on it. Currently you need to perform lot of hacks to be able to export your model.

**Any Other info.**

Maybe adding new arguments to the call method isn't the right way. Allowing saved_model to understand that you have two types of signatures, when training is True or False, for your model would be great.  It would make the following behavior compatible to saved_model.

Example:

```python
class MyNetwork(tf.keras.Model):

  def call(self, inputs, training=None):  
     if training:
          groundtruths = inputs['groundtruths']
          # Do somestuff with the groundtruths
      return stuff

    def train_step(self, data):
        data = data_adapter.expand_1d(data)
        x, y, _ = data_adapter.unpack_x_y_sample_weight(data)

        with tf.GradientTape() as tape:
            x['ground_truths'] = y
            y_pred = self(x, training=True)
            loss = self.compiled_loss(None, y_pred, None, regularization_losses=self.losses)
        training._minimize(self.distribute_strategy, tape, self.optimizer, loss,
                           self.trainable_variables)
        return {m.name: m.result() for m in self.metrics}

```
"
39809,Upgrading Tensorflow,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 'Windows-10-10.0.18362-SP0'
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): 
- TensorFlow version: 1.12.0
- Python version: Python 3.6.8 :: Acaconda, : lnc
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): No Bazel
- GCC/Compiler version (if compiling from source): I have no GCC/compiler
- CUDA/cuDNN version: I have no CUDA
- GPU model and memory: I have no GPU

**Describe the problem**
Hi, I'm a beginner of tensorflow. I want to upgrade tensorflow version from 1.12.0 to 2.2.0 using Anaconda prompt, but it didn't work at all. How can I solve this problem? 

**Provide the exact sequence of commands / steps that you executed before running into the problem**

![cpature](https://user-images.githubusercontent.com/60909846/82727392-32366d80-9d25-11ea-80e6-7a83346304c0.JPG)




**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
39808,ValueError: Could not find matching function to call loaded from the SavedModel,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No, it's an example code
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): from binary, using `pip install tensorflow-gpu==2.2.0-rc0` 
- TensorFlow version (use command below): 2.2.0
- Python version: 3.7
- Bazel version (if compiling from source): -
- GCC/Compiler version (if compiling from source): -
- CUDA/cuDNN version: 9.1
- GPU model and memory: Nvidia 1050Ti

(Full tensorflow version: `v2.2.0-rc1-34-ge6e5d6df2a 2.2.0-rc2`)

**Describe the current behavior**

Following the example code described [here](https://github.com/tensorflow/community/blob/master/rfcs/20181116-saved-model.md#python-objects-and-nests-in-function-signatures):

```python
@tf.function
def f(x, training):
  return x if training else 2.
f(-1., training=True)
f(-1., training=False)
obj = tf.train.Checkpoint(f=f)  # save() exports objects, so we wrap f
tf.saved_model.save(obj, ""/tmp/f"")
```

**Describe the expected behavior**

After loading the model again, when calling the exported function:

```python
imported = tf.saved_model.load(""/tmp/f"")
imported.f(10., training=True)  # 10 -> expected value.
```
10 should be the output

**Actual behavior** 

It yields an error: 

```python
ValueError: Could not find matching function to call loaded from the SavedModel. Got:
  Positional arguments (2 total):
    * 10
    * True
  Keyword arguments: {}

Expected these arguments to match one of the following 2 option(s):

Option 1:
  Positional arguments (2 total):
    * -1.0
    * False
  Keyword arguments: {}

Option 2:
  Positional arguments (2 total):
    * -1.0
    * True
  Keyword arguments: {}
```

**Standalone code to reproduce the issue**

Example code given.

**Other info / logs** 

It works if I put a value used before in the function, before saving the model: 

```python
# Code
imported.f(-1., training=False) # I HAVE called the function with these exact arguments before saving the model

# Result
<tf.Tensor: shape=(), dtype=float32, numpy=-1.0>
```
This could be the desired behavior of the library (to only work with previously evaluated inputs), however:
- I don't see the point of using such tool if it's just a lookup table
- Conflicts with the example given
"
39807,XLA Interpreter is not being compiled in Tensorflow 2.2,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): N/A
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): from source
- TensorFlow version (use command below): 2.2
- Python version: 3.6
- Bazel version (if compiling from source): 2.0.0
- GCC/Compiler version (if compiling from source): 7.5.0
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

Interpreter jit and services does not compile in Tensorflow 2.2.

The configuration was the default values displayed.

Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: 
No OpenCL SYCL support will be enabled for TensorFlow.

Do you wish to build TensorFlow with ROCm support? [y/N]: 
No ROCm support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: 
No CUDA support will be enabled for TensorFlow.

Do you wish to download a fresh release of clang? (Experimental) [y/N]: 
Clang will not be downloaded.

Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native -Wno-sign-compare]: 

Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: 
Not configuring the WORKSPACE for Android builds.

Steps to reproduce:
1) git clone -b r1.15 https://github.com/tensorflow/tensorflow.git
2) cd tensorflow
3) Add random character (e.g. ""dfgfsdg"") in the code area of xla_interpreter_device.cc (located in tensorflow/compiler/jit/).
4) bazel build -c dbg //tensorflow/tools/pip_package:build_pip_package

The compilation should fail. However it does not.

Note: my objective is to insert a custom backend. I was successful in TF version 1.15. However, when I reproduce those steps, the backend is not detected."
39806,"Error after run category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)","
![Capture](https://user-images.githubusercontent.com/63918976/82724724-56cd1e00-9d02-11ea-91e8-34f99eb57dec.PNG)
This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.
"
39805,Error after run,"This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.
"
39804,error,"![Capture](https://user-images.githubusercontent.com/63918976/82724698-18376380-9d02-11ea-955d-a37c6e2c9278.PNG)
<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:
- Python version:
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**
Error after run category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
39803,Invalid output Tensor index: 1 when trying to run a tiny-yolov3 model on TFLite,"Following @jvishnuvardhan suggestion in https://github.com/tensorflow/tensorflow/issues/39157#issuecomment-632788236_, I'm creating a new issue

I'm facing an error when trying to run a tiny-yolov3 model on TensorFlow Lite's Object Detection Android Demo. 
When I try to run the app on mobile phone, the app crashed with the following error 
```
E/AndroidRuntime: FATAL EXCEPTION: inference
    Process: org.tensorflow.lite.examples.detection, PID: 5535
    java.lang.IllegalArgumentException: Invalid output Tensor index: 1
        at org.tensorflow.lite.NativeInterpreterWrapper.getOutputTensor(NativeInterpreterWrapper.java:292)
        at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:166)
        at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:314)
        at org.tensorflow.lite.examples.detection.tflite.TFLiteObjectDetectionAPIModel.recognizeImage(TFLiteObjectDetectionAPIModel.java:204)
        at org.tensorflow.lite.examples.detection.DetectorActivity$2.run(DetectorActivity.java:181)
        at android.os.Handler.handleCallback(Handler.java:873)
        at android.os.Handler.dispatchMessage(Handler.java:99)
        at android.os.Looper.loop(Looper.java:214)
        at android.os.HandlerThread.run(HandlerThread.java:65)
```

I'm using yolov3-tiny that was trained (using transfer learning) with [Alexey](https://github.com/AlexeyAB/darknet)'s implementation to detect 2 custom objects (knife and machete).

[mystic's](https://github.com/mystic123/tensorflow-yolo-v3) implementation was then used  to convert the .weight file to a .pb

Then I used the following code to convert the .pb file to .tflite

```
import tensorflow as tf

graph_def_file = ""frozen_darknet_yolov3_model.pb""
input_arrays = [""inputs""]
output_arrays = [""output_boxes""]

converter = tf.lite.TFLiteConverter.from_frozen_graph(
        graph_def_file, input_arrays, output_arrays)
tflite_model = converter.convert()
open(""converted_model.tflite"", ""wb"").write(tflite_model)
```
(I'm using tensorflow 1.15 to run this code)

The .tflite that was created is then moved to the assets folder of the object_detection example of tflite https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android

The tflite and labelfile that I used can be found here https://drive.google.com/file/d/1Av7Q1mjLdOIEE81oNnt8cLENlXykxnEu/view?usp=sharing

I changed the following on DetectorActivity.java
```
TF_OD_API_INPUT_SIZE from 300 to 416
TF_OD_API_IS_QUANTIZED from true to false
```
Then I changed the following on TFLiteObjectDetectionAPIModel.java
```
NUM_DETECTIONS from 10 to 2535
d.outputLocations = new float[1][NUM_DETECTIONS][4] to d.outputLocations = new float[1][NUM_DETECTIONS][7];
```
Here's the DetectorActivity.java and TFLiteObjectDetectionAPIModel.java that I use [here](https://drive.google.com/file/d/1Zf0i2Y_Tjyh7Li3UcxteKRB_k5Bwhhgt/view?usp=sharing)


Any assistance would be appreciated"
39802,ImportError: DLL load failed: The specified module could not be found.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Pro
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip install
- TensorFlow version (use command below):  tensorflow_cpu-2.2.0-cp37-cp37m-win_amd64
- Python version: Python 3.7.6
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: NA
- GPU model and memory: NA

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
pip install tensorflow-cpu
import tensorflow
I went through all these github issue links [1](https://github.com/tensorflow/tensorflow/issues/22794), [2](https://github.com/tensorflow/tensorflow/issues/22794) and [3](https://www.tensorflow.org/install/errors) but I am unable to find any solution. I have installed Microsoft Visual C++ 2015 Redistributable Update 3 mentioned in one of the solutions, still no help.
---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
~\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py in <module>
     57 
---> 58   from tensorflow.python.pywrap_tensorflow_internal import *
     59 

~\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py in <module>
     27             return _mod
---> 28     _pywrap_tensorflow_internal = swig_import_helper()
     29     del swig_import_helper

~\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py in swig_import_helper()
     23             try:
---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
     25             finally:

~\anaconda3\lib\imp.py in load_module(name, file, filename, details)
    241         else:
--> 242             return load_dynamic(name, filename, file)
    243     elif type_ == PKG_DIRECTORY:

~\anaconda3\lib\imp.py in load_dynamic(name, path, file)
    341             name=name, loader=loader, origin=path)
--> 342         return _load(spec)
    343 

ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

ImportError                               Traceback (most recent call last)
<ipython-input-1-d6579f534729> in <module>
----> 1 import tensorflow

~\anaconda3\lib\site-packages\tensorflow\__init__.py in <module>
     39 import sys as _sys
     40 
---> 41 from tensorflow.python.tools import module_util as _module_util
     42 from tensorflow.python.util.lazy_loader import LazyLoader as _LazyLoader
     43 

~\anaconda3\lib\site-packages\tensorflow\python\__init__.py in <module>
     48 import numpy as np
     49 
---> 50 from tensorflow.python import pywrap_tensorflow
     51 
     52 # Protocol buffers

~\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py in <module>
     67 for some common reasons and solutions.  Include the entire stack trace
     68 above this error message when asking for help."""""" % traceback.format_exc()
---> 69   raise ImportError(msg)
     70 
     71 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long

ImportError: Traceback (most recent call last):
  File ""C:\Users\shivam\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\shivam\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\shivam\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\shivam\anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\shivam\anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
"
39801,Sparse Categorical CrossEntropy in Google Collab,"https://pastebin.com/efb18WPB
I've been in trouble when configure the model.compile and model.fit in Google Collaboratory.
I want my model in
- Divided into train set and validation set
- Implement image augmentation
- Use Image Data Generator
- Sequential Model and using more than 1 hidden layer
- Training the model in max 30 minutes
- Accuracy min 85%
- Could predict picture if we upload it.

I've been new in this ML. Please help me ASAP. Thankyou for your participation."
39800,how to multi scale train using tf.data.dataset,"This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.
"
39798,Unable to log scalar summaries in XLA,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.15.5 Beta
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.2.0
- Python version: 3.8.2
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

**Describe the current behavior**
Forcing XLA compilation via `experimental_compile=True` in a `tf.function` raises `tensorflow.python.framework.errors_impl.InvalidArgumentError` when the function contains `tf.summary.scalar` (I haven't tried other summaries). 

**Describe the expected behavior**
Passing `experimental_compile=True` should log the scalar without raising any errors. 

**Standalone code to reproduce the issue**
```python
import tensorflow as tf


@tf.function(
    experimental_compile=True,
)
def test_summaries():
    tf.summary.scalar('testing', 12.3)

with tf.summary.create_file_writer('./logs').as_default():
    tf.summary.experimental.set_step(0)
    test_summaries()
```

**Other info / logs**
```
2020-05-22 22:30:57.072264: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-05-22 22:30:57.091548: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f99eef80060 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-05-22 22:30:57.091590: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Traceback (most recent call last):
  File ""testsum.py"", line 12, in <module>
    test_summaries()
  File ""/private/tmp/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 576, in __call__
    result = self._call(*args, **kwds)
  File ""/private/tmp/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 650, in _call
    return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access
  File ""/private/tmp/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 1661, in _filtered_call
    return self._call_flat(
  File ""/private/tmp/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 1745, in _call_flat
    return self._build_call_outputs(self._inference_function.call(
  File ""/private/tmp/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 593, in call
    outputs = execute.execute(
  File ""/private/tmp/venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py"", line 59, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.InvalidArgumentError: Function invoked by the following node is not compilable: {{node __inference_test_summaries_22}} = __inference_test_summaries_22[_XlaMustCompile=true, config_proto=""\n\007\n\003GPU\020\000\n\007\n\003CPU\020\0012\002J\0008\001"", executor_type=""""](dummy_input).
Uncompilable nodes:
testing/write_summary/tag: unsupported op: Const op with type DT_STRING is not supported by XLA.
	Stacktrace:
		Node: __inference_test_summaries_22, function: 
		Node: testing/write_summary/tag, function: __inference_test_summaries_22

testing/write_summary/summary_metadata: unsupported op: Const op with type DT_STRING is not supported by XLA.
	Stacktrace:
		Node: __inference_test_summaries_22, function: 
		Node: testing/write_summary/summary_metadata, function: __inference_test_summaries_22

testing/write_summary: unsupported op: No registered 'WriteSummary' OpKernel for XLA_CPU_JIT devices compatible with node {{node testing/write_summary}}
	Stacktrace:
		Node: __inference_test_summaries_22, function: 
		Node: testing/write_summary, function: __inference_test_summaries_22
 [Op:__inference_test_summaries_22]
```
"
39797,Using Sequence as validation data in Model.fit,"According to the documentation, Model.fit_generator is deprecated now in favor of Model.fit, which now supports Sequence and generators. However, the doc also states that Sequence object cannot be used for the validation set. Is there any plan to add support to enable the use of Sequence or other custom generators in the future?
"
39796,Spleeter error,"Hey, this is the error i get (at the bottom) it seems like everything runs smoothly until you see a dll error pop up in the lines, then a few more times further down..if anyone knows what to do, let me know. thanks

Starting processing of all songs
Processing E:\Hoodie chasing forever\y2mate.com - Hoodie Allen - King To Me_HKYBI6ybN8s.mp3
Traceback (most recent call last):
  File ""C:\Users\mgood\AppData\Roaming\SpleeterGUI\python\Lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\mgood\AppData\Roaming\SpleeterGUI\python\Lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\mgood\AppData\Roaming\SpleeterGUI\python\Lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""D:\obj\windows-release\37amd64_Release\msi_python\zip_amd64\imp.py"", line 242, in load_module
  File ""D:\obj\windows-release\37amd64_Release\msi_python\zip_amd64\imp.py"", line 342, in load_dynamic
ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File ""D:\obj\windows-release\37amd64_Release\msi_python\zip_amd64\runpy.py"", line 193, in _run_module_as_main
  File ""D:\obj\windows-release\37amd64_Release\msi_python\zip_amd64\runpy.py"", line 85, in _run_code
  File ""C:\Users\mgood\AppData\Roaming\SpleeterGUI\python\Lib\site-packages\spleeter\__main__.py"", line 58, in <module>
    entrypoint()
  File ""C:\Users\mgood\AppData\Roaming\SpleeterGUI\python\Lib\site-packages\spleeter\__main__.py"", line 54, in entrypoint
    main(sys.argv)
  File ""C:\Users\mgood\AppData\Roaming\SpleeterGUI\python\Lib\site-packages\spleeter\__main__.py"", line 36, in main
    enable_logging()
  File ""C:\Users\mgood\AppData\Roaming\SpleeterGUI\python\Lib\site-packages\spleeter\utils\logging.py"", line 60, in enable_logging
    tf_logger = get_tensorflow_logger()
  File ""C:\Users\mgood\AppData\Roaming\SpleeterGUI\python\Lib\site-packages\spleeter\utils\logging.py"", line 27, in get_tensorflow_logger
    from tensorflow.compat.v1 import logging
  File ""C:\Users\mgood\AppData\Roaming\SpleeterGUI\python\Lib\site-packages\tensorflow\__init__.py"", line 99, in <module>
    from tensorflow_core import *
  File ""C:\Users\mgood\AppData\Roaming\SpleeterGUI\python\Lib\site-packages\tensorflow_core\__init__.py"", line 28, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""C:\Users\mgood\AppData\Roaming\SpleeterGUI\python\Lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\mgood\AppData\Roaming\SpleeterGUI\python\Lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""D:\obj\windows-release\37amd64_Release\msi_python\zip_amd64\__init__.py"", line 127, in import_module
  File ""C:\Users\mgood\AppData\Roaming\SpleeterGUI\python\Lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\mgood\AppData\Roaming\SpleeterGUI\python\Lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\mgood\AppData\Roaming\SpleeterGUI\python\Lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\mgood\AppData\Roaming\SpleeterGUI\python\Lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\mgood\AppData\Roaming\SpleeterGUI\python\Lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""D:\obj\windows-release\37amd64_Release\msi_python\zip_amd64\imp.py"", line 242, in load_module
  File ""D:\obj\windows-release\37amd64_Release\msi_python\zip_amd64\imp.py"", line 342, in load_dynamic
ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.
Failed to load the native TensorFlow runtime.
See https://www.tensorflow.org/install/errors
for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
Finished processing all songs

Run complete
"
39795,add tf.version.version_info similar to sys.version_info,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: 
*NA*
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 
*CentOS 7*
- **TensorFlow installed from (source or binary)**:
*binary: pip*
- **TensorFlow version (use command below)**:
*2.3.0-dev20200522*
- **Python version**:
*3.7.6*

- **Exact command to reproduce**:
*Feature request*

### Describe the problem
It is inconvenient to parse `tf.version.VERSION` to do version-specific logic.  The request is to provide a function more like `sys.version_info` so that the consumer doesn't need to parse a string.

### Source code / logs
Consider the output of `tf.version.VERSION`:
```
tf.version.VERSION
'2.3.0-dev20200522'
```
Contrast that output with `sys.version_info`:
```
>>> import sys
>>> sys.version_info
sys.version_info(major=3, minor=7, micro=6, releaselevel='final', serial=0)
```

The request is to add a function that will return a object similar to `sys.version_info`'s output.  Parsing that string is harder than first imagined.  Notice that not only are the ""fields"" concatenated together, depending on the build, the fields are different.  For instance, an older release gives `2.1.0`.

to be consistent with the other names in tf.version, I propose `tf.version.VERSION_INFO`.  What fields? major, minor, and micro are a must.  However since it is dictionary-like, it wouldn't hurt to have all versions (such as git and compiler) also included.

No workaround is requested.
"
39794,Failed installing tensorflow 2.1.0 into Cloud Functions runtime Python 3.7,"Hi all,

I'm trying to create a cloud function with the following config:

Runtime:
`Python 3.7`

Memory:
`256 MiB`

requirements.txt:
`tensorflow==2.1.0`

When I deploy, I got the following error:
`Build failed: {""cacheStats"": [{""status"": ""MISS"", ""hash"": ""54f4df7672bd136f86b67fd4d2390e30c509db5"", ""type"": ""docker_layer_cache"", ""level"": ""global""}, {""status"": ""MISS"", ""hash"": ""54f4df7672bd136f86b6730c509db5"", ""type"": ""docker_layer_cache"", ""level"": ""project""}]}`

This version is the one in which my model has been trained.

How to fix it?"
39793,"In tensorflow, for custom layers that need arguments at instantialion, does the get_config method need overriding?","Ubuntu - 20.04,
Tensorflow - 2.2.0,
Tensorboard - 2.2.1

I have [read](https://www.tensorflow.org/guide/keras/custom_layers_and_models#you_can_optionally_enable_serialization_on_your_layers) that one needs to reimplement the `get_config` method in order for a custom layer to be serializable.

I have a custom layer that accepts arguments in its `__init__`. It uses another custom layer and that consumes arguments in its `__init__` as well. I can:

Without Tensorboard callbacks:

1. Use them in a model both in eager model and graph form
2. Run `tf.saved_model.save` and it executes without a glich
3. Load the thus saved model using `tf.saved_model.load` and it loads the model saved in 2. above
4. I can call `model(input)` the loaded model. I can also call 'call_and_return_all_conditional_losses(input)` and they run right as well

With Tensorboard callbacks:

All of the above (can .fit, save, load, predict from loaded etc) except.. While running fit i get 
```WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer PREPROCESS_MONSOON has arguments in `__init__` and therefore must override `get_config`.```

Pasting the entire code here that can be run end to end. You just need to have tensorflow 2 installed. Please delete/add the callbacks (only tensorboard callbacks is there) to `.fit` to see the two behaviors mentioned above

```
import pandas as pd
import tensorflow as tf
from tensorflow.keras import layers as l
from tensorflow import keras as k
import numpy as np

##making empty directories
import os
os.makedirs('r_data',exist_ok=True)
os.makedirs('r_savedir',exist_ok=True)

#Preparing the dataset
mnist = tf.keras.datasets.mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train_ = pd.DataFrame(x_train.reshape(60000,-1),columns = ['col_'+str(i) for i in range(28*28)])
x_test_ = pd.DataFrame(x_test.reshape(10000,-1),columns = ['col_'+str(i) for i in range(28*28)])
x_train_['col_cat1'] = [np.random.choice(['a','b','c','d','e','f','g','h','i']) for i in range(x_train_.shape[0])]
x_test_['col_cat1'] = [np.random.choice(['a','b','c','d','e','f','g','h','i','j']) for i in range(x_test_.shape[0])]
x_train_['col_cat2'] = [np.random.choice(['a','b','c','d','e','f','g','h','i']) for i in range(x_train_.shape[0])]
x_test_['col_cat2'] = [np.random.choice(['a','b','c','d','e','f','g','h','i','j']) for i in range(x_test_.shape[0])]
x_train_[np.random.choice([True,False],size = x_train_.shape,p=[0.05,0.95]).reshape(x_train_.shape)] = np.nan
x_test_[np.random.choice([True,False],size = x_test_.shape,p=[0.05,0.95]).reshape(x_test_.shape)] = np.nan
x_train_.to_csv('r_data/x_train.csv',index=False)
x_test_.to_csv('r_data/x_test.csv',index=False)
pd.DataFrame(y_train).to_csv('r_data/y_train.csv',index=False)
pd.DataFrame(y_test).to_csv('r_data/y_test.csv',index=False)

#**THE MAIN LAYER THAT WE ARE TALKING ABOUT**
import tensorflow as tf
from tensorflow.keras import layers
from tensorflow import feature_column
import os

class NUM_TO_DENSE(layers.Layer):
    def __init__(self,num_cols):
        super().__init__()
        self.keys = num_cols
        self.keys_all = self.keys+[str(i)+'__nullcol' for i in self.keys]
#     def get_config(self):

#         config = super().get_config().copy()
#         config.update({
#             'keys': self.keys,
#             'keys_all': self.keys_all,
#         })
#         return config
    def build(self,input_shape):
        def create_moving_mean_vars():
            return tf.Variable(initial_value=0.,shape=(),dtype=tf.float32,trainable=False)
        self.moving_means_total = {t:create_moving_mean_vars() for t in self.keys}
        self.layer_global_counter = tf.Variable(initial_value=0.,shape=(),dtype=tf.float32,trainable=False)

    def call(self,inputs, training = True):
        null_cols = {k:tf.math.is_finite(inputs[k]) for k in self.keys}
        current_means = {}
        def compute_update_current_means(t):
            current_mean = tf.math.divide_no_nan(tf.reduce_sum(tf.where(null_cols[t],inputs[t],0.),axis=0),\
                                  tf.reduce_sum(tf.cast(tf.math.is_finite(inputs[t]),tf.float32),axis=0))
            self.moving_means_total[t].assign_add(current_mean)
            return current_mean
        
        if training:
            current_means = {t:compute_update_current_means(t) for t in self.keys}
            outputs = {t:tf.where(null_cols[t],inputs[t],current_means[t]) for t in self.keys}
            outputs.update({str(k)+'__nullcol':tf.cast(null_cols[k],tf.float32) for k in self.keys})
            self.layer_global_counter.assign_add(1.)
        else:
            outputs = {t:tf.where(null_cols[t],inputs[t],(self.moving_means_total[t]/self.layer_global_counter))\
                       for t in self.keys}
            outputs.update({str(k)+'__nullcol':tf.cast(null_cols[k],tf.float32) for k in self.keys})
        return outputs


class PREPROCESS_MONSOON(layers.Layer):
    def __init__(self,cat_cols_with_unique_values,num_cols):
        '''cat_cols_with_unqiue_values: (dict) {'col_cat':[unique_values_list]}
        num_cols: (list) [num_cols_name_list]'''
        super().__init__()
        self.cat_cols = cat_cols_with_unique_values
        self.num_cols = num_cols
#     def get_config(self):

#         config = super().get_config().copy()
#         config.update({
#             'cat_cols': self.cat_cols,
#             'num_cols': self.num_cols,
#         })
#         return config
    def build(self,input_shape):
        self.ntd = NUM_TO_DENSE(self.num_cols)
        self.num_colnames = self.ntd.keys_all
        self.ctd = {k:layers.DenseFeatures\
                    (feature_column.embedding_column\
                     (feature_column.categorical_column_with_vocabulary_list\
                      (k,v),tf.cast(tf.math.ceil(tf.math.log(tf.cast(len(self.cat_cols[k]),tf.float32))),tf.int32).numpy()))\
                   for k,v in self.cat_cols.items()}
        self.cat_colnames = [i for i in self.cat_cols]
        self.dense_colnames = self.num_colnames+self.cat_colnames
    def call(self,inputs,training=True):
        dense_num_d = self.ntd(inputs,training=training)
        dense_cat_d = {k:self.ctd[k](inputs) for k in self.cat_colnames}
        
        dense_num = tf.stack([dense_num_d[k] for k in self.num_colnames],axis=1)
        dense_cat = tf.concat([dense_cat_d[k] for k in self.cat_colnames],axis=1)
        dense_all = tf.concat([dense_num,dense_cat],axis=1)
        return dense_all

##Inputs
label_path = 'r_data/y_train.csv'
data_path = 'r_data/x_train.csv'
max_epochs = 100
batch_size = 32
shuffle_seed = 42

##Creating layer inputs
dfs = pd.read_csv(data_path,nrows=1)
cdtypes_x = dfs.dtypes
nc = list(dfs.select_dtypes(include=[int,float]).columns)
oc = list(dfs.select_dtypes(exclude=[int,float]).columns)
cdtypes_y = pd.read_csv(label_path,nrows=1).dtypes
dfc = pd.read_csv(data_path,usecols=oc)
ccwuv = {i:list(pd.Series(dfc[i].unique()).dropna()) for i in dfc.columns}
preds_name = pd.read_csv(label_path,nrows=1).columns

##creating datasets
dataset = tf.data.experimental.make_csv_dataset(
    'r_data/x_train.csv',batch_size, column_names=cdtypes_x.index,prefetch_buffer_size=1,
shuffle=True,shuffle_buffer_size=10000,shuffle_seed=shuffle_seed)
labels = tf.data.experimental.make_csv_dataset(
    'r_data/y_train.csv',batch_size, column_names=cdtypes_y.index,prefetch_buffer_size=1,
shuffle=True,shuffle_buffer_size=10000,shuffle_seed=shuffle_seed)
dataset = tf.data.Dataset.zip((dataset,labels))

##CREATING NETWORK
p = PREPROCESS_MONSOON(cat_cols_with_unique_values=ccwuv,num_cols=nc)

indict = {}
for i in nc:
    indict[i] = k.Input(shape = (), name=i,dtype=tf.float32)
for i in ccwuv:
    indict[i] = k.Input(shape=(), name=i,dtype=tf.string)
x = p(indict)
x = l.BatchNormalization()(x)
x = l.Dense(10,activation='relu',name='dense_1')(x)
predictions = l.Dense(10,activation=None,name=preds_name[0])(x)
model = k.Model(inputs=indict,outputs=predictions)

##Compiling model
model.compile(optimizer=k.optimizers.Adam(),
              loss=k.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['sparse_categorical_accuracy'])

##callbacks
log_dir = './tensorboard_dir/no_config'
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)

## Fit model on training data
history = model.fit(dataset,
                    batch_size=64,
                    epochs=30,
                    steps_per_epoch=5,
                    validation_split=0.,
                   callbacks = [tensorboard_callback])

#saving the model
tf.saved_model.save(model,'r_savedir')
#loading the model
model = tf.saved_model.load('r_savedir')

##Predicting on loaded model
for i in dataset:
    print(model(i[0],training=False))
    break

```  

I have commented out the part from the code where i override the config files in my custom layers and you can comment them in and the Warning about the layers not being serializable would go away.

Question:
Do i or do i not need to override the `config` method in order to make a custom layer that accepts arguments in `__init__` serializable?

Thank you in advance for help"
39792,Failed to legalize operation 'xla_hlo.return',"I am using TensorFlow installed from source and running on Google-Cloud. My git commit id is b52f058cb7fe2aee523fb2f0ae8ba712d2339b3a .

I am trying to test Reduce Op. I generated a frozen graph of .pbtxt format using a very simple program by using reduce_sum on 4*3*2 tensor. I generated graph def from it given below:

```
module attributes {tf.versions = {bad_consumers = [], min_consumer = 0 : i32, producer = 175 : i32}} {
  func @main(%arg0: tensor<4x3x2xf32>) -> tensor<f32> attributes {tf.entry_function = {control_outputs = """", inputs = ""Placeholder"", outputs = ""Sum""}} {
    %0 = tf_executor.graph {
      %outputs, %control = tf_executor.island wraps ""tf.Const""() {device = """", value = dense<[0, 1, 2]> : tensor<3xi32>} : () -> tensor<3xi32>
      %outputs_0, %control_1 = tf_executor.island wraps ""tf.Sum""(%arg0, %outputs) {device = """", keep_dims = false} : (tensor<4x3x2xf32>, tensor<3xi32>) -> tensor<f32>
      tf_executor.fetch %outputs_0 : tensor<f32>
    }
    return %0 : tensor<f32>
  }
```

Above is graphdef file. I converted it into Xla hlo using `./tf-opt --tf-executor-island-coarsening -canonicalize --xla-legalize-tf.` Which give the output as:

```
module attributes {tf.versions = {bad_consumers = [], min_consumer = 0 : i32, producer = 175 : i32}} {
  func @main(%arg0: tensor<4x3x2xf32>) -> tensor<f32> attributes {tf.entry_function = {control_outputs = """", inputs = ""Placeholder"", outputs = ""Sum""}} {
    %0 = xla_hlo.constant dense<[0, 1, 2]> : tensor<3xi32>
    %1 = tensor_cast %0 : tensor<3xi32> to tensor<3xi32>
    %2 = ""xla_hlo.convert""(%arg0) : (tensor<4x3x2xf32>) -> tensor<4x3x2xf32>
    %3 = xla_hlo.constant dense<0.000000e+00> : tensor<f32>
    %4 = ""xla_hlo.reduce""(%2, %3) ( {
    ^bb0(%arg1: tensor<f32>, %arg2: tensor<f32>):  // no predecessors
      %6 = xla_hlo.add %arg1, %arg2 : tensor<f32>
      ""xla_hlo.return""(%6) : (tensor<f32>) -> ()
    }) {dimensions = dense<[0, 1, 2]> : tensor<3xi64>} : (tensor<4x3x2xf32>, tensor<f32>) -> tensor<f32>
    %5 = ""xla_hlo.convert""(%4) : (tensor<f32>) -> tensor<f32>
    return %5 : tensor<f32>
  }
}

```
Now I am trying to convert above hlo file to lhlo using command ./tf-opt  --hlo-legalize-to-lhlo
But an segmentation fault came.
```
b.txt:12:7: error: failed to legalize operation 'xla_hlo.return' that was explicitly marked illegal
      ""xla_hlo.return""(%6) : (tensor<f32>) -> ()
      ^
b.txt:12:7: note: see current operation: ""xla_hlo.return""(%10) : (tensor<f32>) -> ()
PLEASE submit a bug report to  and include the crash backtrace.
Stack dump:
0.	Program arguments: ./tf-opt --hlo-legalize-to-lhlo b.txt 
./tf-opt[0x7fdd05d]
./tf-opt[0x7fdb1ad]
./tf-opt[0x7fdb6fd]
/lib64/libpthread.so.0(+0x12dc0)[0x7fac3735fdc0]
./tf-opt[0x7f7ba86]
./tf-opt[0x7f7eb0e]
./tf-opt[0x7f7deca]
./tf-opt[0x7f7e3e6]
./tf-opt[0x7f834b6]
./tf-opt[0x7f2e932]
./tf-opt[0x7f2f7ca]
./tf-opt[0x7f345dd]
./tf-opt[0x7d322dc]
./tf-opt[0x7f1890b]
./tf-opt[0x7f18c0c]
./tf-opt[0x7f18c0c]
./tf-opt[0x7f18c0c]
./tf-opt[0x7f1995f]
./tf-opt[0x7e0ebc9]
./tf-opt[0x7e13c89]
./tf-opt[0x7e13cfa]
./tf-opt[0x7e1ae85]
./tf-opt[0x5964480]
./tf-opt[0x59648c5]
./tf-opt[0x5964a80]
./tf-opt[0x930390]
/lib64/libc.so.6(__libc_start_main+0xf3)[0x7fac36d95873]
./tf-opt[0xa38cce]
Segmentation fault (core dumped)
```
This is the whole output. 
So is something still missing currently in the repo?
"
39790,RuntimeError: Inputs and outputs not all float|uint8|int16 types.Node number 4 (ADD) failed to invoke.,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04
- TensorFlow installed from (source or binary): binary 
- TensorFlow version (or github SHA if from source):TF 2.2.0 from anaconda 


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
import tensorflow as tf
# Path to the frozen graph file
graph_def_file = 'savedModel.pb'
# A list of the names of the model's input tensors
input_arrays = ['input.1']
# A list of the names of the model's output tensors
output_arrays = ['4358']
# Load and convert the frozen graph
converter = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph(
  graph_def_file, input_arrays, output_arrays)


converter.target_spec.supported_ops = [
    tf.lite.OpsSet.TFLITE_BUILTINS,
    tf.lite.OpsSet.SELECT_TF_OPS,
]
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_types = [tf.float16]
tflite_fp16_model = converter.convert()
tflite_model_fp16_file = ""tf_model.tflite""
open(tflite_model_fp16_file , ""wb"").write(tflite_fp16_model)

```

**The output from the converter invocation**

```
2020-05-22 20:38:17.870933: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-05-22 20:38:17.872070: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2020-05-22 20:38:17.872351: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-7CPMA5J): /proc/driver/nvidia/version does not exist
2020-05-22 20:38:17.872996: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-05-22 20:38:17.880532: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3192000000 Hz
2020-05-22 20:38:17.882702: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f5b64000b60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-05-22 20:38:17.882997: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
```

**Also, please include a link to the saved model or GraphDef**

```
https://drive.google.com/file/d/17d8lFYY-4Z7iExnLNdYbjOt6EQpVbDdI/view?usp=sharing
```

**Failure details**
If the conversion is successful, but the generated model is wrong,
state what is wrong:
- Producing wrong results and/or decrease in accuracy
- Producing correct results, but the model is slower than expected (model generated from old converter)

Model not running gives error  as below.


**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

> [{'name': 'input.1', 'index': 0, 'shape': array([  1,   3, 256, 256], dtype=int32), 'shape_signature': array([  1,   3, 256, 256], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]
> [{'name': '4358', 'index': 4138, 'shape': array([ 1, 17,  3], dtype=int32), 'shape_signature': array([ 1, 17,  3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]
> Traceback (most recent call last):
>   File ""test_graph.py"", line 20, in <module>
>     interpreter.invoke()
>   File ""/home/shreyas/.local/lib/python3.8/site-packages/tensorflow/lite/python/interpreter.py"", line 511, in invoke
>     self._interpreter.Invoke()
>   File ""/home/shreyas/.local/lib/python3.8/site-packages/tensorflow/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py"", line 113, in Invoke
>     return _tensorflow_wrap_interpreter_wrapper.InterpreterWrapper_Invoke(self)
> RuntimeError: Inputs and outputs not all float|uint8|int16 types.Node number 4 (ADD) failed to invoke.
"
39789,Keras List index is out of range!,"Hey all!
I am getting this obscure error for which I could find no solution online. I am trying to make this piece of code that finds the relation between two numbers. For testing purposes, I am using simple data where the relation is to simply add 5. Here is how my training data looks like:-
`0,5`
`1,6`
`2,7`
`3,8`
`4,9`
`...`
Now, I am trying to sketch out a simple model that accomplishes what I want to do. However, It does not even get to the training part of the code and simply _terminates_ with this obscure error:-

```
2020-05-22 20:00:25.521151: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-05-22 20:00:25.523749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-05-22 20:00:25.523805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      
Traceback (most recent call last):
  File ""main.py"", line 34, in <module>
    history = model.fit(train_data, epochs=100, verbose=1)
  File ""/home/awesome_ruler/.local/lib/python3.7/site-packages/keras/engine/training.py"", line 1239, in fit
    validation_freq=validation_freq)
  File ""/home/awesome_ruler/.local/lib/python3.7/site-packages/keras/engine/training_arrays.py"", line 141, in fit_loop
    if issparse(fit_inputs[i]) and not K.is_sparse(feed[i]):
IndexError: list index out of range

```
I am not understanding the source of this error as the iterator that `model.fit` is using was not written by me but is being used from the libraries themselves. For reference, here is my code:-
```
# -*- coding: utf-8 -*-
# @author = Neel Gupta

import numpy as np
import tensorflow as tf
from keras.models import Sequential
from keras.layers import Dense
from keras.optimizers import SGD
import matplotlib.pyplot as pyplot
import csv

def csv_arr(csv_f):
    results = []
    # the loop..
    with open(csv_f) as csvfile:
        reader = csv.reader(csvfile, quoting=csv.QUOTE_NONNUMERIC)  # change contents to floats
        for row in reader:  # each row is a list
            results.append(row)
    # returning the output
    return np.asarray(results)

train_data = np.reshape(csv_arr(""train.csv""), (15,2))
test_data = csv_arr(""test.csv"")

x_data = tf.keras.Input(shape=(15,2))

model = Sequential()
model.add(Dense(4, input_dim=2, activation='relu', kernel_initializer='glorot_uniform'))
model.add(Dense(1, activation='linear'))
opt = SGD(lr=0.01, momentum=0.9)
model.compile(loss='mean_squared_error', optimizer=opt, )

# fit model
history = model.fit(train_data, epochs=100, verbose=1)

# getting model's summary
model.summary()

# plot loss during training
pyplot.title('Loss / Mean Squared Error')
pyplot.plot(history.history['loss'], label='train')
pyplot.plot(history.history['val_loss'], label='test')
pyplot.legend()
pyplot.show()

```
I am using Tensorflow GPU, which is right now not using the acceleration due to some missing/broken libs. I am using TensorFlow version `2.2.0` and keras version `2.3`. Additionally, I am trying to use CUDA `10.1`. I do not know what other cause there is to my error. Can someone shed any light on this"
39788,Formula error display in RMSprop,"
## URL(s) with the issue: https://www.tensorflow.org/versions/r2.1/api_docs/python/tf/keras/optimizers/RMSprop

## Description of issue (what needs changing): the sub-indexes in the formula are not displayed correctly.

### Clear description
As an example, meansquared_{t} appears like mean_{s}quaredt and so on.
"
39787,Keras: list index is out of range!,"This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.
"
39786,Convert to tflite issue,"**System information**
- OS Platform and Distribution: elementary OS 5.1.3 Hera (based on Ubuntu 18.04 LTS)
- TensorFlow installed from (source or binary): binary , pip installed 
- TensorFlow version (or github SHA if from source): 1.14.0

**Provide the text output from tflite_convert**
```
Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONV_2D, ELU, FULLY_CONNECTED, L2_NORMALIZATION, LESS, MAX_POOL_2D, MUL, RANGE, RESHAPE, SHAPE, STRIDED_SLICE. Here is a list of operators for which you will need custom implementations: Enter, Exit, LoopCond, Merge, Switch, TensorArrayGatherV3, TensorArrayReadV3, TensorArrayScatterV3, TensorArraySizeV3, TensorArrayV3, TensorArrayWriteV3.
```



**Standalone code to reproduce the issue** 
 toco --graph_def_file=/out/saved_model.pb --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --output_file=/out/saved_model.tflite --inference_input_type=QUANTIZED_UINT8 --input_arrays=images --output_arrays=features --input_shapes=1,128,64,3 --std_dev_values=127 --mean_values=128 --enable_select_tf_opsA

**Environment capture script result**
```
== check python ===================================================
python version: 2.7.17
python branch: 
python build version: ('default', 'Apr 15 2020 17:20:14')
python compiler version: GCC 7.5.0
python implementation: CPython


== check os platform ===============================================
os: Linux
os kernel version: #38~18.04.1-Ubuntu SMP Tue Mar 31 04:17:56 UTC 2020
os release version: 5.3.0-46-generic
os platform: Linux-5.3.0-46-generic-x86_64-with-elementary-5.1.3-hera
linux distribution: ('elementary', '5.1.3', 'hera')
linux os distribution: ('elementary', '5.1.3', 'hera')
mac version: ('', ('', '', ''), '')
uname: ('Linux', 'asuspro', '5.3.0-46-generic', '#38~18.04.1-Ubuntu SMP Tue Mar 31 04:17:56 UTC 2020', 'x86_64', 'x86_64')
architecture: ('64bit', '')
machine: x86_64


== are we in docker =============================================
No

== compiler =====================================================
c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
Copyright (C) 2017 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== check pips ===================================================
numpy (1.16.6)
protobuf (3.11.3)
tensorflow (1.14.0)
tensorflow-estimator (1.14.0)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.version.VERSION = 1.14.0
tf.version.GIT_VERSION = v1.14.0-rc1-22-gaf24dc91b5
tf.version.COMPILER_VERSION = 4.8.5
Sanity check: array([1], dtype=int32)
      9322:	find library=libc.so.6 [0]; searching
      9322:	 search cache=/etc/ld.so.cache
      9322:	  trying file=/lib/x86_64-linux-gnu/libc.so.6
      9322:	
      9322:	find library=libpthread.so.0 [0]; searching
      9322:	 search cache=/etc/ld.so.cache
      9322:	  trying file=/lib/x86_64-linux-gnu/libpthread.so.0
      9322:	
      9322:	find library=libdl.so.2 [0]; searching
      9322:	 search cache=/etc/ld.so.cache
      9322:	  trying file=/lib/x86_64-linux-gnu/libdl.so.2
      9322:	
      9322:	find library=libutil.so.1 [0]; searching
      9322:	 search cache=/etc/ld.so.cache
      9322:	  trying file=/lib/x86_64-linux-gnu/libutil.so.1
      9322:	
      9322:	find library=libz.so.1 [0]; searching
      9322:	 search cache=/etc/ld.so.cache
      9322:	  trying file=/lib/x86_64-linux-gnu/libz.so.1
      9322:	
      9322:	find library=libm.so.6 [0]; searching
      9322:	 search cache=/etc/ld.so.cache
      9322:	  trying file=/lib/x86_64-linux-gnu/libm.so.6
      9322:	
      9322:	
      9322:	calling init: /lib/x86_64-linux-gnu/libpthread.so.0
      9322:	
      9322:	
      9322:	calling init: /lib/x86_64-linux-gnu/libc.so.6
      9322:	
      9322:	
      9322:	calling init: /lib/x86_64-linux-gnu/libm.so.6
      9322:	
      9322:	
      9322:	calling init: /lib/x86_64-linux-gnu/libz.so.1
      9322:	
      9322:	
      9322:	calling init: /lib/x86_64-linux-gnu/libutil.so.1
      9322:	
      9322:	
      9322:	calling init: /lib/x86_64-linux-gnu/libdl.so.2
      9322:	
      9322:	
      9322:	initialize program: /usr/bin/python
      9322:	
      9322:	
      9322:	transferring control: /usr/bin/python
      9322:	
      9322:	find library=libffi.so.6 [0]; searching
      9322:	 search cache=/etc/ld.so.cache
      9322:	  trying file=/usr/lib/x86_64-linux-gnu/libffi.so.6
      9322:	
      9322:	
      9322:	calling init: /usr/lib/x86_64-linux-gnu/libffi.so.6
      9322:	
      9322:	
      9322:	calling init: /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so
      9322:	
      9322:	find library=libopenblasp-r0-34a18dc3.3.7.so [0]; searching
      9322:	 search path=/home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs/tls/haswell/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs/tls/haswell:/home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs/tls/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs/tls:/home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs/haswell/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs/haswell:/home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs		(RPATH from file /home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/_multiarray_umath.so)
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs/tls/haswell/x86_64/libopenblasp-r0-34a18dc3.3.7.so
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs/tls/haswell/libopenblasp-r0-34a18dc3.3.7.so
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs/tls/x86_64/libopenblasp-r0-34a18dc3.3.7.so
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs/tls/libopenblasp-r0-34a18dc3.3.7.so
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs/haswell/x86_64/libopenblasp-r0-34a18dc3.3.7.so
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs/haswell/libopenblasp-r0-34a18dc3.3.7.so
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs/x86_64/libopenblasp-r0-34a18dc3.3.7.so
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs/libopenblasp-r0-34a18dc3.3.7.so
      9322:	
      9322:	find library=libgfortran-ed201abd.so.3.0.0 [0]; searching
      9322:	 search path=/home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs		(RPATH from file /home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/_multiarray_umath.so)
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs/libgfortran-ed201abd.so.3.0.0
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs/libgfortran-ed201abd.so.3.0.0
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs/libopenblasp-r0-34a18dc3.3.7.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/_multiarray_umath.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/_multiarray_tests.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/linalg/lapack_lite.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/linalg/_umath_linalg.so
      9322:	
      9322:	find library=libbz2.so.1.0 [0]; searching
      9322:	 search cache=/etc/ld.so.cache
      9322:	  trying file=/lib/x86_64-linux-gnu/libbz2.so.1.0
      9322:	
      9322:	
      9322:	calling init: /lib/x86_64-linux-gnu/libbz2.so.1.0
      9322:	
      9322:	
      9322:	calling init: /usr/lib/python2.7/lib-dynload/bz2.x86_64-linux-gnu.so
      9322:	
      9322:	
      9322:	calling init: /usr/lib/python2.7/lib-dynload/future_builtins.x86_64-linux-gnu.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/fft/fftpack_lite.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/random/mtrand.so
      9322:	
      9322:	find library=libcrypto.so.1.1 [0]; searching
      9322:	 search cache=/etc/ld.so.cache
      9322:	  trying file=/usr/lib/x86_64-linux-gnu/libcrypto.so.1.1
      9322:	
      9322:	
      9322:	calling init: /usr/lib/x86_64-linux-gnu/libcrypto.so.1.1
      9322:	
      9322:	
      9322:	calling init: /usr/lib/python2.7/lib-dynload/_hashlib.x86_64-linux-gnu.so
      9322:	
      9322:	find library=libtensorflow_framework.so.1 [0]; searching
      9322:	 search path=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../../_solib_k8/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/tls/haswell/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../../_solib_k8/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/tls/haswell:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../../_solib_k8/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/tls/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../../_solib_k8/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/tls:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../../_solib_k8/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/haswell/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../../_solib_k8/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/haswell:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../../_solib_k8/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../../_solib_k8/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/tls/haswell/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/tls/haswell:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/tls/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/tls:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/haswell/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/haswell:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../tls/haswell/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../tls/haswell:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../tls/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../tls:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../haswell/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../haswell:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/..		(RUNPATH from file /home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../../_solib_k8/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/tls/haswell/x86_64/libtensorflow_framework.so.1
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../../_solib_k8/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/tls/haswell/libtensorflow_framework.so.1
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../../_solib_k8/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/tls/x86_64/libtensorflow_framework.so.1
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../../_solib_k8/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/tls/libtensorflow_framework.so.1
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../../_solib_k8/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/haswell/x86_64/libtensorflow_framework.so.1
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../../_solib_k8/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/haswell/libtensorflow_framework.so.1
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../../_solib_k8/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/x86_64/libtensorflow_framework.so.1
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../../_solib_k8/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/libtensorflow_framework.so.1
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/tls/haswell/x86_64/libtensorflow_framework.so.1
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/tls/haswell/libtensorflow_framework.so.1
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/tls/x86_64/libtensorflow_framework.so.1
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/tls/libtensorflow_framework.so.1
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/haswell/x86_64/libtensorflow_framework.so.1
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/haswell/libtensorflow_framework.so.1
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/x86_64/libtensorflow_framework.so.1
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/libtensorflow_framework.so.1
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../tls/haswell/x86_64/libtensorflow_framework.so.1
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../tls/haswell/libtensorflow_framework.so.1
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../tls/x86_64/libtensorflow_framework.so.1
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../tls/libtensorflow_framework.so.1
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../haswell/x86_64/libtensorflow_framework.so.1
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../haswell/libtensorflow_framework.so.1
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../x86_64/libtensorflow_framework.so.1
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../libtensorflow_framework.so.1
      9322:	
      9322:	find library=librt.so.1 [0]; searching
      9322:	 search path=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/..		(RUNPATH from file /home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/librt.so.1
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../librt.so.1
      9322:	 search cache=/etc/ld.so.cache
      9322:	  trying file=/lib/x86_64-linux-gnu/librt.so.1
      9322:	
      9322:	find library=libstdc++.so.6 [0]; searching
      9322:	 search path=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/..		(RUNPATH from file /home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/libstdc++.so.6
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../libstdc++.so.6
      9322:	 search cache=/etc/ld.so.cache
      9322:	  trying file=/usr/lib/x86_64-linux-gnu/libstdc++.so.6
      9322:	
      9322:	find library=libgcc_s.so.1 [0]; searching
      9322:	 search path=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/..		(RUNPATH from file /home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/libgcc_s.so.1
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../libgcc_s.so.1
      9322:	 search cache=/etc/ld.so.cache
      9322:	  trying file=/lib/x86_64-linux-gnu/libgcc_s.so.1
      9322:	
      9322:	
      9322:	calling init: /lib/x86_64-linux-gnu/libgcc_s.so.1
      9322:	
      9322:	
      9322:	calling init: /usr/lib/x86_64-linux-gnu/libstdc++.so.6
      9322:	
      9322:	
      9322:	calling init: /lib/x86_64-linux-gnu/librt.so.1
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../libtensorflow_framework.so.1
      9322:	
      9322:	find library=libhdfs.so [0]; searching
      9322:	 search path=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/..		(RUNPATH from file /home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../libhdfs.so
      9322:	 search cache=/etc/ld.so.cache
      9322:	 search path=/lib/x86_64-linux-gnu/tls/haswell/x86_64:/lib/x86_64-linux-gnu/tls/haswell:/lib/x86_64-linux-gnu/tls/x86_64:/lib/x86_64-linux-gnu/tls:/lib/x86_64-linux-gnu/haswell/x86_64:/lib/x86_64-linux-gnu/haswell:/lib/x86_64-linux-gnu/x86_64:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu/tls/haswell/x86_64:/usr/lib/x86_64-linux-gnu/tls/haswell:/usr/lib/x86_64-linux-gnu/tls/x86_64:/usr/lib/x86_64-linux-gnu/tls:/usr/lib/x86_64-linux-gnu/haswell/x86_64:/usr/lib/x86_64-linux-gnu/haswell:/usr/lib/x86_64-linux-gnu/x86_64:/usr/lib/x86_64-linux-gnu:/lib/tls/haswell/x86_64:/lib/tls/haswell:/lib/tls/x86_64:/lib/tls:/lib/haswell/x86_64:/lib/haswell:/lib/x86_64:/lib:/usr/lib/tls/haswell/x86_64:/usr/lib/tls/haswell:/usr/lib/tls/x86_64:/usr/lib/tls:/usr/lib/haswell/x86_64:/usr/lib/haswell:/usr/lib/x86_64:/usr/lib		(system search path)
      9322:	  trying file=/lib/x86_64-linux-gnu/tls/haswell/x86_64/libhdfs.so
      9322:	  trying file=/lib/x86_64-linux-gnu/tls/haswell/libhdfs.so
      9322:	  trying file=/lib/x86_64-linux-gnu/tls/x86_64/libhdfs.so
      9322:	  trying file=/lib/x86_64-linux-gnu/tls/libhdfs.so
      9322:	  trying file=/lib/x86_64-linux-gnu/haswell/x86_64/libhdfs.so
      9322:	  trying file=/lib/x86_64-linux-gnu/haswell/libhdfs.so
      9322:	  trying file=/lib/x86_64-linux-gnu/x86_64/libhdfs.so
      9322:	  trying file=/lib/x86_64-linux-gnu/libhdfs.so
      9322:	  trying file=/usr/lib/x86_64-linux-gnu/tls/haswell/x86_64/libhdfs.so
      9322:	  trying file=/usr/lib/x86_64-linux-gnu/tls/haswell/libhdfs.so
      9322:	  trying file=/usr/lib/x86_64-linux-gnu/tls/x86_64/libhdfs.so
      9322:	  trying file=/usr/lib/x86_64-linux-gnu/tls/libhdfs.so
      9322:	  trying file=/usr/lib/x86_64-linux-gnu/haswell/x86_64/libhdfs.so
      9322:	  trying file=/usr/lib/x86_64-linux-gnu/haswell/libhdfs.so
      9322:	  trying file=/usr/lib/x86_64-linux-gnu/x86_64/libhdfs.so
      9322:	  trying file=/usr/lib/x86_64-linux-gnu/libhdfs.so
      9322:	  trying file=/lib/tls/haswell/x86_64/libhdfs.so
      9322:	  trying file=/lib/tls/haswell/libhdfs.so
      9322:	  trying file=/lib/tls/x86_64/libhdfs.so
      9322:	  trying file=/lib/tls/libhdfs.so
      9322:	  trying file=/lib/haswell/x86_64/libhdfs.so
      9322:	  trying file=/lib/haswell/libhdfs.so
      9322:	  trying file=/lib/x86_64/libhdfs.so
      9322:	  trying file=/lib/libhdfs.so
      9322:	  trying file=/usr/lib/tls/haswell/x86_64/libhdfs.so
      9322:	  trying file=/usr/lib/tls/haswell/libhdfs.so
      9322:	  trying file=/usr/lib/tls/x86_64/libhdfs.so
      9322:	  trying file=/usr/lib/tls/libhdfs.so
      9322:	  trying file=/usr/lib/haswell/x86_64/libhdfs.so
      9322:	  trying file=/usr/lib/haswell/libhdfs.so
      9322:	  trying file=/usr/lib/x86_64/libhdfs.so
      9322:	  trying file=/usr/lib/libhdfs.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
      9322:	
      9322:	find library=libssl.so.1.1 [0]; searching
      9322:	 search cache=/etc/ld.so.cache
      9322:	  trying file=/usr/lib/x86_64-linux-gnu/libssl.so.1.1
      9322:	
      9322:	
      9322:	calling init: /usr/lib/x86_64-linux-gnu/libssl.so.1.1
      9322:	
      9322:	
      9322:	calling init: /usr/lib/python2.7/lib-dynload/_ssl.x86_64-linux-gnu.so
      9322:	
      9322:	
      9322:	
      9322:	
      9322:	
      9322:	
      9322:	calling init: /usr/lib/python2.7/lib-dynload/_csv.x86_64-linux-gnu.so
      9322:	
      9322:	
      9322:	calling init: /usr/lib/python2.7/lib-dynload/termios.x86_64-linux-gnu.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/framework/fast_tensor_util.so
      9322:	
      9322:	find library=libuuid.so.1 [0]; searching
      9322:	 search cache=/etc/ld.so.cache
      9322:	  trying file=/lib/x86_64-linux-gnu/libuuid.so.1
      9322:	
      9322:	
      9322:	calling init: /lib/x86_64-linux-gnu/libuuid.so.1
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/wrapt/_wrappers.so
      9322:	
      9322:	
      9322:	calling init: /usr/lib/python2.7/lib-dynload/_json.x86_64-linux-gnu.so
      9322:	
      9322:	
      9322:	calling init: /usr/lib/python2.7/lib-dynload/_multiprocessing.x86_64-linux-gnu.so
      9322:	
      9322:	find library=libhdf5-9028dcc4.so.103.0.0 [0]; searching
      9322:	 search path=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/tls/haswell/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/tls/haswell:/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/tls/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/tls:/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/haswell/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/haswell:/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs		(RPATH from file /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/_errors.so)
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/tls/haswell/x86_64/libhdf5-9028dcc4.so.103.0.0
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/tls/haswell/libhdf5-9028dcc4.so.103.0.0
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/tls/x86_64/libhdf5-9028dcc4.so.103.0.0
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/tls/libhdf5-9028dcc4.so.103.0.0
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/haswell/x86_64/libhdf5-9028dcc4.so.103.0.0
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/haswell/libhdf5-9028dcc4.so.103.0.0
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/x86_64/libhdf5-9028dcc4.so.103.0.0
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/libhdf5-9028dcc4.so.103.0.0
      9322:	
      9322:	find library=libhdf5_hl-db841637.so.100.1.1 [0]; searching
      9322:	 search path=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs		(RPATH from file /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/_errors.so)
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/libhdf5_hl-db841637.so.100.1.1
      9322:	
      9322:	find library=libsz-1c7dd0cf.so.2.0.1 [0]; searching
      9322:	 search path=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./tls/haswell/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./tls/haswell:/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./tls/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./tls:/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./haswell/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./haswell:/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/.		(RPATH from file /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/libhdf5-9028dcc4.so.103.0.0)
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./tls/haswell/x86_64/libsz-1c7dd0cf.so.2.0.1
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./tls/haswell/libsz-1c7dd0cf.so.2.0.1
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./tls/x86_64/libsz-1c7dd0cf.so.2.0.1
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./tls/libsz-1c7dd0cf.so.2.0.1
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./haswell/x86_64/libsz-1c7dd0cf.so.2.0.1
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./haswell/libsz-1c7dd0cf.so.2.0.1
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./x86_64/libsz-1c7dd0cf.so.2.0.1
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./libsz-1c7dd0cf.so.2.0.1
      9322:	
      9322:	find library=libaec-2147abcd.so.0.0.4 [0]; searching
      9322:	 search path=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/.		(RPATH from file /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/libhdf5-9028dcc4.so.103.0.0)
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./libaec-2147abcd.so.0.0.4
      9322:	
      9322:	find library=libz-a147dcb0.so.1.2.3 [0]; searching
      9322:	 search path=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/.		(RPATH from file /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/libhdf5-9028dcc4.so.103.0.0)
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./libz-a147dcb0.so.1.2.3
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./libz-a147dcb0.so.1.2.3
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./libaec-2147abcd.so.0.0.4
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./libsz-1c7dd0cf.so.2.0.1
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/libhdf5-9028dcc4.so.103.0.0
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/libhdf5_hl-db841637.so.100.1.1
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/_errors.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/defs.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/_objects.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/_conv.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5r.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5t.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/utils.so
      9322:	
      9327:	find library=libc.so.6 [0]; searching
      9327:	 search cache=/etc/ld.so.cache
      9327:	  trying file=/lib/x86_64-linux-gnu/libc.so.6
      9327:	
      9327:	
      9327:	calling init: /lib/x86_64-linux-gnu/libc.so.6
      9327:	
      9327:	
      9327:	initialize program: sh
      9327:	
      9327:	
      9327:	transferring control: sh
      9327:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5z.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5a.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5s.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5p.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5ac.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/_proxy.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5d.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5ds.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5f.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5g.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5i.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5fd.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5pl.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5o.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5l.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/_lib/_ccallback_c.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/sparse/_sparsetools.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/sparse/_csparsetools.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/sparse/csgraph/_shortest_path.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/sparse/csgraph/_tools.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/sparse/csgraph/_traversal.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/sparse/csgraph/_min_spanning_tree.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/sparse/csgraph/_reordering.so
      9322:	
      9322:	find library=libjpeg-3b10b538.so.9.3.0 [0]; searching
      9322:	 search path=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/tls/haswell/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/tls/haswell:/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/tls/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/tls:/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/haswell/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/haswell:/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs		(RPATH from file /home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/_imaging.so)
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/tls/haswell/x86_64/libjpeg-3b10b538.so.9.3.0
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/tls/haswell/libjpeg-3b10b538.so.9.3.0
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/tls/x86_64/libjpeg-3b10b538.so.9.3.0
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/tls/libjpeg-3b10b538.so.9.3.0
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/haswell/x86_64/libjpeg-3b10b538.so.9.3.0
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/haswell/libjpeg-3b10b538.so.9.3.0
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/x86_64/libjpeg-3b10b538.so.9.3.0
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/libjpeg-3b10b538.so.9.3.0
      9322:	
      9322:	find library=libopenjp2-b3d7668a.so.2.3.1 [0]; searching
      9322:	 search path=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs		(RPATH from file /home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/_imaging.so)
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/libopenjp2-b3d7668a.so.2.3.1
      9322:	
      9322:	find library=libtiff-bd1961ca.so.5.5.0 [0]; searching
      9322:	 search path=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs		(RPATH from file /home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/_imaging.so)
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/libtiff-bd1961ca.so.5.5.0
      9322:	
      9322:	find library=liblzma-6cd627ed.so.5.2.4 [0]; searching
      9322:	 search path=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/./tls/haswell/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/./tls/haswell:/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/./tls/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/./tls:/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/./haswell/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/./haswell:/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/./x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/.		(RPATH from file /home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/libtiff-bd1961ca.so.5.5.0)
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/./tls/haswell/x86_64/liblzma-6cd627ed.so.5.2.4
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/./tls/haswell/liblzma-6cd627ed.so.5.2.4
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/./tls/x86_64/liblzma-6cd627ed.so.5.2.4
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/./tls/liblzma-6cd627ed.so.5.2.4
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/./haswell/x86_64/liblzma-6cd627ed.so.5.2.4
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/./haswell/liblzma-6cd627ed.so.5.2.4
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/./x86_64/liblzma-6cd627ed.so.5.2.4
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/./liblzma-6cd627ed.so.5.2.4
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/./liblzma-6cd627ed.so.5.2.4
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/libjpeg-3b10b538.so.9.3.0
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/libtiff-bd1961ca.so.5.5.0
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/libopenjp2-b3d7668a.so.2.3.1
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/_imaging.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/_scandir.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/ndimage/_nd_image.so
      9322:	
      9322:	find library=libopenblasp-r0-2ecf47d5.3.7.dev.so [0]; searching
      9322:	 search path=/home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/../.libs/tls/haswell/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/../.libs/tls/haswell:/home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/../.libs/tls/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/../.libs/tls:/home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/../.libs/haswell/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/../.libs/haswell:/home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/../.libs/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/../.libs		(RPATH from file /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/_fblas.so)
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/../.libs/tls/haswell/x86_64/libopenblasp-r0-2ecf47d5.3.7.dev.so
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/../.libs/tls/haswell/libopenblasp-r0-2ecf47d5.3.7.dev.so
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/../.libs/tls/x86_64/libopenblasp-r0-2ecf47d5.3.7.dev.so
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/../.libs/tls/libopenblasp-r0-2ecf47d5.3.7.dev.so
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/../.libs/haswell/x86_64/libopenblasp-r0-2ecf47d5.3.7.dev.so
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/../.libs/haswell/libopenblasp-r0-2ecf47d5.3.7.dev.so
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/../.libs/x86_64/libopenblasp-r0-2ecf47d5.3.7.dev.so
      9322:	  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/../.libs/libopenblasp-r0-2ecf47d5.3.7.dev.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/../.libs/libopenblasp-r0-2ecf47d5.3.7.dev.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/_fblas.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/_flapack.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/_flinalg.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/_solve_toeplitz.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/_decomp_update.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/cython_blas.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/cython_lapack.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/special/_ufuncs.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/special/_ufuncs_cxx.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/special/specfun.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/special/_comb.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/special/_ellip_harm_2.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/interpolate/_fitpack.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/interpolate/dfitpack.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/interpolate/_bspl.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/interpolate/_ppoly.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/interpolate/interpnd.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/spatial/ckdtree.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/spatial/qhull.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/_lib/messagestream.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/spatial/_voronoi.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/spatial/_distance_wrap.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/spatial/_hausdorff.so
      9322:	
      9322:	
      9322:	calling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/ndimage/_ni_label.so
      9322:	
      9322:	
      9322:	calling fini: /usr/bin/python [0]
      9322:	
      9322:	
      9322:	calling fini: /lib/x86_64-linux-gnu/libutil.so.1 [0]
      9322:	
      9322:	
      9322:	calling fini: /lib/x86_64-linux-gnu/libz.so.1 [0]
      9322:	
      9322:	
      9322:	calling fini: /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so [0]
      9322:	
      9322:	
      9322:	calling fini: /usr/lib/x86_64-linux-gnu/libffi.so.6 [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/_multiarray_umath.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/_multiarray_tests.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/linalg/lapack_lite.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/linalg/_umath_linalg.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs/libopenblasp-r0-34a18dc3.3.7.so [0]
      9322:	
      9322:	
      9322:	calling fini: /usr/lib/python2.7/lib-dynload/bz2.x86_64-linux-gnu.so [0]
      9322:	
      9322:	
      9322:	calling fini: /lib/x86_64-linux-gnu/libbz2.so.1.0 [0]
      9322:	
      9322:	
      9322:	calling fini: /usr/lib/python2.7/lib-dynload/future_builtins.x86_64-linux-gnu.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/fft/fftpack_lite.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/random/mtrand.so [0]
      9322:	
      9322:	
      9322:	calling fini: /usr/lib/python2.7/lib-dynload/_hashlib.x86_64-linux-gnu.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../libtensorflow_framework.so.1 [0]
      9322:	
      9322:	
      9322:	calling fini: /usr/lib/python2.7/lib-dynload/_ssl.x86_64-linux-gnu.so [0]
      9322:	
      9322:	
      9322:	calling fini: /usr/lib/x86_64-linux-gnu/libssl.so.1.1 [0]
      9322:	
      9322:	
      9322:	calling fini: /usr/lib/x86_64-linux-gnu/libcrypto.so.1.1 [0]
      9322:	
      9322:	
      9322:	
      9322:	
      9322:	
      9322:	
      9322:	calling fini: /usr/lib/python2.7/lib-dynload/_csv.x86_64-linux-gnu.so [0]
      9322:	
      9322:	
      9322:	calling fini: /usr/lib/python2.7/lib-dynload/termios.x86_64-linux-gnu.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/framework/fast_tensor_util.so [0]
      9322:	
      9322:	
      9322:	calling fini: /lib/x86_64-linux-gnu/libuuid.so.1 [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/wrapt/_wrappers.so [0]
      9322:	
      9322:	
      9322:	calling fini: /usr/lib/python2.7/lib-dynload/_json.x86_64-linux-gnu.so [0]
      9322:	
      9322:	
      9322:	calling fini: /usr/lib/python2.7/lib-dynload/_multiprocessing.x86_64-linux-gnu.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/_errors.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/defs.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/_objects.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/_conv.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5r.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5t.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/utils.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5z.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5a.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5s.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5p.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5ac.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/_proxy.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5d.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5ds.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5f.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5g.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5i.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5fd.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5pl.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5o.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5l.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/libhdf5_hl-db841637.so.100.1.1 [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/libhdf5-9028dcc4.so.103.0.0 [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./libsz-1c7dd0cf.so.2.0.1 [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./libaec-2147abcd.so.0.0.4 [0]
      9322:	
      9322:	
      9322:	calling fini: /lib/x86_64-linux-gnu/libdl.so.2 [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/_lib/_ccallback_c.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/sparse/_sparsetools.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/sparse/_csparsetools.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/sparse/csgraph/_shortest_path.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/sparse/csgraph/_tools.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/sparse/csgraph/_traversal.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/sparse/csgraph/_min_spanning_tree.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/sparse/csgraph/_reordering.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/_imaging.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/libopenjp2-b3d7668a.so.2.3.1 [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/libtiff-bd1961ca.so.5.5.0 [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/libjpeg-3b10b538.so.9.3.0 [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./libz-a147dcb0.so.1.2.3 [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/./liblzma-6cd627ed.so.5.2.4 [0]
      9322:	
      9322:	
      9322:	calling fini: /lib/x86_64-linux-gnu/librt.so.1 [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/_scandir.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/ndimage/_nd_image.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/_fblas.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/_flapack.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/_flinalg.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/_solve_toeplitz.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/_decomp_update.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/cython_blas.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/cython_lapack.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/special/_ufuncs.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/special/_ufuncs_cxx.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/special/specfun.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/special/_comb.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/special/_ellip_harm_2.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/interpolate/_fitpack.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/interpolate/dfitpack.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/interpolate/_bspl.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/interpolate/_ppoly.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/interpolate/interpnd.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/spatial/ckdtree.so [0]
      9322:	
      9322:	
      9322:	calling fini: /usr/lib/x86_64-linux-gnu/libstdc++.so.6 [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/spatial/qhull.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/../.libs/libopenblasp-r0-2ecf47d5.3.7.dev.so [0]
      9322:	
      9322:	
      9322:	calling fini: /lib/x86_64-linux-gnu/libgcc_s.so.1 [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs/libgfortran-ed201abd.so.3.0.0 [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/_lib/messagestream.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/spatial/_voronoi.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/spatial/_distance_wrap.so [0]
      9322:	
      9322:	
      9322:	calling fini: /lib/x86_64-linux-gnu/libm.so.6 [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/spatial/_hausdorff.so [0]
      9322:	
      9322:	
      9322:	calling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/ndimage/_ni_label.so [0]
      9322:	
      9322:	
      9322:	calling fini: /lib/x86_64-linux-gnu/libpthread.so.0 [0]
      9322:	

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
./tf_env_collect.sh: line 147: nvidia-smi: command not found

== cuda libs  ===================================================

== tensorflow installed from info ==================
Name: tensorflow
Version: 1.14.0
Summary: TensorFlow is an open source machine learning framework for everyone.
Home-page: https://www.tensorflow.org/
Author-email: packages@tensorflow.org
License: Apache 2.0
Location: /home/andreiungureanu/.local/lib/python2.7/site-packages

== python version  ==============================================
(major, minor, micro, releaselevel, serial)
(2, 7, 17, 'final', 0)

== bazel version  ===============================================
```"
39784,Tf.shape() does not support RaggedTensor,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):

Yes

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):

Ubuntu 16.04

- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:

No

- TensorFlow installed from (source or binary):

binary

- TensorFlow version (use command below):

v2.1.0-rc2-17-ge5bf8de 2.1.0

- Python version:

3.6.8

- Bazel version (if compiling from source):

No

- GCC/Compiler version (if compiling from source):

No

- CUDA/cuDNN version:

CPU only

- GPU model and memory:

CPU only

**Describe the current behavior**
Calling `tf.shape()` on a RaggedTensor results in an error:
`TypeError: object of type 'RaggedTensor' has no len `


**Describe the expected behavior**
It should return the shape of the tensor, similar to calling `RaggedTensor.shape`

**Standalone code to reproduce the issue**
https://colab.research.google.com/drive/1aN0DJwRbjDrt9-xu3tWmoNvth24a1wm0?usp=sharing

```
import tensorflow as tf
ragged = tf.ragged.constant([[0.1, 0.3, 0.5],
                                           [0.1],
                                            [0.4,0.5]])
print(ragged)
print(ragged.shape)
tf.shape(ragged)
```


**Other info / logs** Include any logs or source code that would be helpful to**
-"
39783,how to get the shared library containing the TfLite Delegate.of tf.lite.experimental.load delegate,"I am doing a real-time palm detection, using opencv to get the camera screen and input it into the tiflite model, to get the palm position and other information, and finally using opencv to frame the palm.The system I use is ubuntu18.04 and the language is python3.7.If I only use the CPU, I have done it. Because the delay is too large, I want to use the GPU to accelerate the model prediction.But I didn't find any example of GPU acceleration of tflite model on linux, both android and ios. I only saw the delegate GPU on the python api.
Like,follow:
> tf.lite.Interpreter(
>     model_path=None, model_content=None, experimental_delegates=None
> )


> tf.lite.experimental.load_delegate(
>     library, options=None
> )

library | Name of shared library containing the TfLiteDelegate.

options | Dictionary of options that are required to load the delegate. All keys and values in the dictionary should be convertible to str. Consult the documentation of the specific delegate for required and legal options. (default None)

But I don't know how to generate the library which containing the TfLiteDelegate.
Can anyone give me some advice？Thanks very much.



"
39782,How to get the learning rate in optimizer during training?,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): TF 2.0
- Are you willing to contribute it (Yes/No): No



**Describe the feature and the current behavior/state.**
When I am training the model with `tf.keras.optimizers.Adam` optimizer, I want to extract the learning rate during training to add it into the tensorboard. I did not find any API for this function. And the only result I found on Google is https://stackoverflow.com/questions/55622400/can-you-extract-the-current-learning-rate-from-tf-keras-adam, which suggested to calculate it by myself. I wonder if such API exists or will be added in the future.

**Will this change the current api? How?**
No. May add new features.

**Who will benefit with this feature?**
Potentially everyone.

**Any Other info.**
"
39781,[TF.Distribute] ctx.all_reduce is failed in the codition depends on layer-intenal variable.,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab GPU
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:  No
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.2.0
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.2
- GPU model and memory: I don't know (Google Colab served  one.)

**Describe the current behavior**

```python
class DataDepInitInternal(DataDepInit):
  """"""
  initialized is internal variable as Bool
  w is internal variable as Tensor
  """"""
  def initialize(self, x):
    ctx = tf.distribute.get_replica_context()
    if ctx:
      n = ctx.num_replicas_in_sync * 1.0
      mean,*_ = ctx.all_reduce(tf.distribute.ReduceOp.SUM, [tf.reduce_mean(x, axis=[0, 1, 2], keepdims=True) / n])
    return mean

  def call(self, x, first=True):
    if self.initialized: # <- this condition and below assignment cause error.
      self.initialized.assign(True)
      self.w.assign(self.initialize(x))
    return x - self.w
```
**Describe the expected behavior**
like this. (this layer use argument for condition, but I don't want to use it.
```python
class DataDepInitInternal(DataDepInit):
  """"""
  initialized is internal variable as Bool
  w is internal variable as Tensor
  """"""
  def initialize(self, x):
    ctx = tf.distribute.get_replica_context()
    if ctx:
      n = ctx.num_replicas_in_sync * 1.0
      mean,*_ = ctx.all_reduce(tf.distribute.ReduceOp.SUM, [tf.reduce_mean(x, axis=[0, 1, 2], keepdims=True) / n])
    return mean

  def call(self, x, first=True):
    if first:
      self.initialized.assign(True)
      self.w.assign(self.initialize(x))
    return x - self.w
```

**Standalone code to reproduce the issue**
All reproducal code is here. https://colab.research.google.com/gist/MokkeMeguru/dbe76b1da29366f9e52fef849c449e7e/data-dep-iinitialization.ipynb

**Other info / logs** Include any logs or source code that would be helpful to
see. colab, please.

Thanks!"
39780,`tf.Module` saves in an invalid state when `tf.function` references a variable defined in another scope,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux, Fedora 32 x86_64
- TensorFlow installed from (source or binary): `pip install tensorflow`, 
- TensorFlow version (use command below): 2.2.0
- Python version: 3.8.2
- CUDA/cuDNN version: 10.2.89 / 7.6.5.32
- GPU model and memory: NVIDIA GeForce GTX 960M

**Describe the current behavior**
I am wrapping a Keras model within a `tf.Module` which has a `tf.function` that runs a training step. As part of that I calculate a loss. If the loss function references a variable defined in a different scope, the model seems to serialize successfully, but `saved_model_cli show --dir $DIR --all` crashes with a `KeyError` related to the `tf.function` when run on the model that was saved. This suggests that the model saved was in some way invalid---something that should have been caught prior to saving.

```
josh@achebe:~/Projects/Umpire$ ./venv/bin/saved_model_cli show --dir ai/umpire_regressor --all

MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:

signature_def['__saved_model_init_op']:
  The given SavedModel SignatureDef contains the following input(s):
  The given SavedModel SignatureDef contains the following output(s):
    outputs['__saved_model_init_op'] tensor_info:
        dtype: DT_INVALID
        shape: unknown_rank
        name: NoOp
  Method name is: 
WARNING:tensorflow:From /home/josh/Projects/Umpire/venv/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:1813: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
Traceback (most recent call last):
  File ""./venv/bin/saved_model_cli"", line 8, in <module>
    sys.exit(main())
  File ""/home/josh/Projects/Umpire/venv/lib/python3.8/site-packages/tensorflow/python/tools/saved_model_cli.py"", line 1153, in main
    args.func(args)
  File ""/home/josh/Projects/Umpire/venv/lib/python3.8/site-packages/tensorflow/python/tools/saved_model_cli.py"", line 714, in show
    _show_all(args.dir)
  File ""/home/josh/Projects/Umpire/venv/lib/python3.8/site-packages/tensorflow/python/tools/saved_model_cli.py"", line 306, in _show_all
    _show_defined_functions(saved_model_dir)
  File ""/home/josh/Projects/Umpire/venv/lib/python3.8/site-packages/tensorflow/python/tools/saved_model_cli.py"", line 186, in _show_defined_functions
    trackable_object = load.load(saved_model_dir)
  File ""/home/josh/Projects/Umpire/venv/lib/python3.8/site-packages/tensorflow/python/saved_model/load.py"", line 578, in load
    return load_internal(export_dir, tags)
  File ""/home/josh/Projects/Umpire/venv/lib/python3.8/site-packages/tensorflow/python/saved_model/load.py"", line 602, in load_internal
    loader = loader_cls(object_graph_proto,
  File ""/home/josh/Projects/Umpire/venv/lib/python3.8/site-packages/tensorflow/python/saved_model/load.py"", line 123, in __init__
    self._load_all()
  File ""/home/josh/Projects/Umpire/venv/lib/python3.8/site-packages/tensorflow/python/saved_model/load.py"", line 134, in _load_all
    self._load_nodes()
  File ""/home/josh/Projects/Umpire/venv/lib/python3.8/site-packages/tensorflow/python/saved_model/load.py"", line 264, in _load_nodes
    node, setter = self._recreate(proto, node_id)
  File ""/home/josh/Projects/Umpire/venv/lib/python3.8/site-packages/tensorflow/python/saved_model/load.py"", line 370, in _recreate
    return factory[kind]()
  File ""/home/josh/Projects/Umpire/venv/lib/python3.8/site-packages/tensorflow/python/saved_model/load.py"", line 359, in <lambda>
    ""function"": lambda: self._recreate_function(proto.function),
  File ""/home/josh/Projects/Umpire/venv/lib/python3.8/site-packages/tensorflow/python/saved_model/load.py"", line 397, in _recreate_function
    return function_deserialization.recreate_function(
  File ""/home/josh/Projects/Umpire/venv/lib/python3.8/site-packages/tensorflow/python/saved_model/function_deserialization.py"", line 265, in recreate_function
    concrete_function_objects.append(concrete_functions[concrete_function_name])
KeyError: '__inference_fit_action_1159'
```

**Describe the expected behavior**
When I try to serialize a model, it should either serialize in a form that can be read by `saved_model_cli` or an error should be emitted.

**Standalone code to reproduce the issue**

```
import tensorflow as tf
from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Dense

fX = tf.float32

class TrainableAI(tf.Module):
    def __init__(self, keras_model, *args, **kwargs):
        self.model = keras_model
        super().__init__(*args, **kwargs)

    @tf.function(input_signature=[
        tf.TensorSpec(shape=(1,14,), dtype=fX),#1d_features
        tf.TensorSpec(shape=(1,19,), dtype=fX),# true_action_values
    ])
    def fit_action(self, _1d_features, true_action_values):
        estimated_action_values = self.model(_1d_features)
        mse = tf.keras.losses.MeanSquaredError()
        loss = mse(estimated_action_values, true_action_value)


input = Input(shape=(14,), name='1d_features', dtype=fX)
dense = Dense(64, activation='relu', name=""dense0"")(input)
action_value_estimate = Dense(1, activation='linear', name='estimate')(dense)
true_action_value = Input([1], dtype=fX, name='true_action_values')

model = Model(inputs=input, outputs=action_value_estimate, name='umpire_regressor')
trainable_ai = TrainableAI(model)

tf.saved_model.save(trainable_ai, 'umpire_regressor')
```

Then `saved_model_cli show --dir umpire_regressor --all`

Note that there is a typo where `action_value_estimate` is referenced instead of `action_value_estimates`. `action_value_estimate` without the trailing `s` is defined in the `if __name__==""__main__""` block. Resolving this typo resolves the error; however, the bug is that this was saved in an invalid state instead of an exception being thrown.

I tried running this in a Kaggle container running TF 2.1.0 and it caught the problem, so this may be a regression post-2.1.0."
39779,tfa ReduceLROnPlateau callback from Tf keras is not recognizing cohen kappa metrics direction in 'Auto' mode,
39778,cuda 10.2 issue,"Can tensorflow provide alternative CUDA prebuilt version as pytorch does?

this is really behind pytorch official site say supports cuda 10.1 only:

![image](https://user-images.githubusercontent.com/21303438/82635669-44d07a00-9c33-11ea-9bad-d407999f4331.png)

You can see pytorch is so user-friendly it provides every CUDA version prebuilt binarys.... I mean every not literally every but at least the decent on of CUDA 10.2.. (since cuda 11 out, 10.2 is not the newest)

But 10.2 is really common used in pytorch now..."
39777,AttributeError: module 'tensorflow.keras.layers.experimental' has no attribute 'EinsumDense',"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  mac os 
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binany (pip)
- TensorFlow version:  2.2.0
- Python version: 3.6.0
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:
**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
39776,'Model' object has no attribute 'total_loss' [2.2 Eager],"Below works in TF 2.1 and 2.0 Eager & Graph, and 2.2 Graph, but not 2.2 Eager; how, then, are we to get gradients in 2.2 Eager?

<hr>

```python
import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.models import Model
from tensorflow.keras import backend as K

ipt = Input((16,))
out = Dense(16)(ipt)
model = Model(ipt, out)
model.compile('adam', 'mse')

x = y = np.random.randn(32, 16)
model.train_on_batch(x, y)

outputs = model.optimizer.get_gradients(model.total_loss, model.trainable_weights)
inputs  = [model.inputs[0], model._feed_targets[0]]

grads_fn = K.function(inputs, outputs)
grads    = grads_fn([x, y])
_ = [print(g.shape) for g in grads]
```

"
39775,Broken in v2.2.0: set_visible_devices() is used with tf.keras.mixed_precision,"If you use set_visible_devices with tf.keras.mixed_precision, you get a crash in v2.2.0.

This was fixed in this commit: https://github.com/tensorflow/tensorflow/commit/f748283ee01059be52da5dada6e2157d9f6732ba

However, for some reason, in v2.2.0 the fix is applied in a way that is very broken and ineffective. On `master` this seems like this commit was applied correctly.

Specifically, on tag v2.2.0:
```python
  device_attr_list = device_lib.list_local_devices()
  if not skip_local:
    _log_device_compatibility_check(policy_name, device_attr_list)
    return
```
On master: 
```python
  if not skip_local:
    device_attr_list = device_lib.list_local_devices()
    _log_device_compatibility_check(policy_name, device_attr_list)
    return
```
The whole point of `skip_local` is to avoid calling that function so moving this line renders that fix ineffective.

I'm a little confused how this happened, maybe a cherry pick gone wrong, but I thought I would put this issue here in case anyone hits this issue. I don't know if v2.2.0 can be fixed or we just have to wait for v2.3.0 (since master has the fix)."
39774,Custom Keras model adds extra dimension to scalar inputs,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04.6
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 2.2.0
- Python version: 3.7.3
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1
- GPU model and memory: TITAN V (12036MiB)

**Describe the current behavior**

I am creating a custom Keras model that takes scalar inputs (i.e. inputs have shape [batch_size]). When I compile the model and pass in a tf.data.Dataset to model.fit(), the shape of the input data is changed to [batch_size, 1]. 

However, when I train in a training loop using an iterator, the shape of the input data is [batch_size]. 

This happens both locally and on Colab.

**Describe the expected behavior**
The current behavior adds a side effect of changing the data input shape when using model.fit(). This behavior is inconsistent, since an extra dimension is not added to scalar inputs when training iteratively. The expected behavior would not add an extra dimension to scalar inputs, or at least be consistent between model.fit() and iterative training.

**Standalone code to reproduce the issue**
Colab Notebook: https://colab.research.google.com/drive/14RyEYCRtYCwryJhkd4koYnK04RlUoqrI?usp=sharing

```python
import numpy as np
import tensorflow as tf

class ToyModel(tf.keras.Model):
  def call(self, inputs):
    # Inputs are scalar, so we should only have a batch dimesion.
    print(""Input shape is {}"".format(inputs.shape))
    return tf.reduce_sum(inputs)

toy_model = ToyModel()
optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)
loss = tf.keras.losses.MeanSquaredError()

data_size = 10
data_inputs = np.float32(np.random.randn(data_size))
data_outputs = np.float32(np.random.randn(data_size))
dataset = tf.data.Dataset.from_tensor_slices(
    (data_inputs, data_outputs)).batch(data_size)

# Train iteratively
iterator = iter(dataset)
inputs, outputs = iterator.next()
with tf.GradientTape() as tape:
  predictions = toy_model(inputs)
  loss_value = loss(outputs, predictions)
grads = tape.gradient(loss_value, toy_model.trainable_weights)
optimizer.apply_gradients(zip(grads, toy_model.trainable_weights))
# Input shape is [batch_size]

# Now, try training with fit() instead
toy_model.compile(optimizer=optimizer, loss=loss)
toy_model.fit(dataset, epochs=1)  
# Input shape is [batch_size, 1]

```

"
39772,Example of using SavedModel,"This issue regards TensorFlow 2.2.0

## URL(s) with the issue:

https://www.tensorflow.org/guide/saved_model
https://www.tensorflow.org/api_docs/python/tf/saved_model/save

## Description of issue:

_TL;DR:I went through the links posted and still I don't understand how to properly use SavedModel format while defining tags, input and output tensor names, etc._ 

For instance, say I have this very simple model: 

```python
import tensorflow as tf

inputs = tf.keras.Input(shape=(3,))
x = tf.keras.layers.Dense(4, activation=tf.nn.relu)(inputs)
outputs = tf.keras.layers.Dense(5, activation=tf.nn.softmax)(x)
model = tf.keras.Model(inputs=inputs, outputs=outputs)
```
Calling `model.save(folder)` will easily save the model on SavedModel format. However, if I want to load it and use it somewhere else in a production environment I need to know how to define and name the SignatureDefs, input/output tensors of the sub-graph, tags etc. 

But after reading and studying thoroughly the extensive documentation for hours, I didn't see any concrete example of how to do so. "
39770,could not find the module,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.2.0
- Python version: 3.7.4
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.2/7.6.5
- GPU model and memory: Geforce gtx 1650 4gb

(tfpose) C:\Users\mysel\algo_od\git\tf-pose-estimation>pip install --ignore installed --upgrade tensorflow-gpu

Usage:
  pip install [options] <requirement specifier> [package-index-options] ...
  pip install [options] -r <requirements file> [package-index-options] ...
  pip install [options] [-e] <vcs project url> ...
  pip install [options] [-e] <local project path> ...
  pip install [options] <archive url/path> ...

ambiguous option: --ignore (--ignore-installed, --ignore-requires-python?)

(tfpose) C:\Users\mysel\algo_od\git\tf-pose-estimation>pip install --ignore-installed --upgrade tensorflow-gpu
Collecting tensorflow-gpu
  Using cached tensorflow_gpu-2.2.0-cp37-cp37m-win_amd64.whl (460.4 MB)
Collecting wheel>=0.26; python_version >= ""3""
  Downloading wheel-0.34.2-py2.py3-none-any.whl (26 kB)
Collecting numpy<2.0,>=1.16.0
  Using cached numpy-1.18.4-cp37-cp37m-win_amd64.whl (12.8 MB)
Collecting tensorboard<2.3.0,>=2.2.0
  Using cached tensorboard-2.2.1-py3-none-any.whl (3.0 MB)
Collecting keras-preprocessing>=1.1.0
  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)
     |████████████████████████████████| 42 kB 271 kB/s
Collecting grpcio>=1.8.6
  Downloading grpcio-1.29.0-cp37-cp37m-win_amd64.whl (2.3 MB)
     |████████████████████████████████| 2.3 MB 1.3 MB/s
Processing c:\users\mysel\appdata\local\pip\cache\wheels\7c\06\54\bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\termcolor-1.1.0-cp37-none-any.whl
Collecting tensorflow-gpu-estimator<2.3.0,>=2.2.0
  Using cached tensorflow_gpu_estimator-2.2.0-py2.py3-none-any.whl (470 kB)
Collecting six>=1.12.0
  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)
Processing c:\users\mysel\appdata\local\pip\cache\wheels\cc\af\1a\498a24d0730ef484019e007bb9e8cef3ac00311a672c049a3e\absl_py-0.9.0-py3-none-any.whl
Collecting opt-einsum>=2.3.2
  Using cached opt_einsum-3.2.1-py3-none-any.whl (63 kB)
Collecting gast==0.3.3
  Using cached gast-0.3.3-py2.py3-none-any.whl (9.7 kB)
Collecting google-pasta>=0.1.8
  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)
Collecting h5py<2.11.0,>=2.10.0
  Using cached h5py-2.10.0-cp37-cp37m-win_amd64.whl (2.5 MB)
Collecting protobuf>=3.8.0
  Downloading protobuf-3.12.1-cp37-cp37m-win_amd64.whl (1.0 MB)
     |████████████████████████████████| 1.0 MB 1.6 MB/s
Collecting astunparse==1.6.3
  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)
Collecting scipy==1.4.1; python_version >= ""3""
  Using cached scipy-1.4.1-cp37-cp37m-win_amd64.whl (30.9 MB)
Collecting wrapt>=1.11.1
  Downloading wrapt-1.12.1.tar.gz (27 kB)
Collecting google-auth<2,>=1.6.3
  Downloading google_auth-1.15.0-py2.py3-none-any.whl (89 kB)
     |████████████████████████████████| 89 kB 1.8 MB/s
Collecting tensorboard-plugin-wit>=1.6.0
  Using cached tensorboard_plugin_wit-1.6.0.post3-py3-none-any.whl (777 kB)
Collecting werkzeug>=0.11.15
  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)
     |████████████████████████████████| 298 kB 1.7 MB/s
Collecting google-auth-oauthlib<0.5,>=0.4.1
  Using cached google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)
Collecting markdown>=2.6.8
  Downloading Markdown-3.2.2-py3-none-any.whl (88 kB)
     |████████████████████████████████| 88 kB 2.0 MB/s
Collecting requests<3,>=2.21.0
  Downloading requests-2.23.0-py2.py3-none-any.whl (58 kB)
     |████████████████████████████████| 58 kB 1.1 MB/s
Collecting setuptools>=41.0.0
  Downloading setuptools-46.4.0-py3-none-any.whl (583 kB)
     |████████████████████████████████| 583 kB 1.7 MB/s
Collecting rsa<4.1,>=3.1.4
  Downloading rsa-4.0-py2.py3-none-any.whl (38 kB)
Collecting pyasn1-modules>=0.2.1
  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)
Collecting cachetools<5.0,>=2.0.0
  Using cached cachetools-4.1.0-py3-none-any.whl (10 kB)
Collecting requests-oauthlib>=0.7.0
  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)
Collecting importlib-metadata; python_version < ""3.8""
  Downloading importlib_metadata-1.6.0-py2.py3-none-any.whl (30 kB)
Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1
  Using cached urllib3-1.25.9-py2.py3-none-any.whl (126 kB)
Collecting idna<3,>=2.5
  Downloading idna-2.9-py2.py3-none-any.whl (58 kB)
     |████████████████████████████████| 58 kB 787 kB/s
Collecting chardet<4,>=3.0.2
  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)
     |████████████████████████████████| 133 kB 1.3 MB/s
Collecting certifi>=2017.4.17
  Downloading certifi-2020.4.5.1-py2.py3-none-any.whl (157 kB)
     |████████████████████████████████| 157 kB 939 kB/s
Collecting pyasn1>=0.1.3
  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)
Collecting oauthlib>=3.0.0
  Using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)
Collecting zipp>=0.5
  Downloading zipp-3.1.0-py3-none-any.whl (4.9 kB)
Building wheels for collected packages: wrapt
  Building wheel for wrapt (setup.py) ... done
  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-win_amd64.whl size=33377 sha256=8f9b6e9ff0ab7c409644869dfbd50a922c41dda7f4e6768b3159bdf551be6be5
  Stored in directory: c:\users\mysel\appdata\local\pip\cache\wheels\62\76\4c\aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6
Successfully built wrapt
ERROR: awscli 1.18.41 requires botocore==1.15.41, which is not installed.
ERROR: awscli 1.18.41 requires colorama<0.4.4,>=0.2.5; python_version != ""3.4"", which is not installed.
ERROR: awscli 1.18.41 requires docutils<0.16,>=0.10, which is not installed.
ERROR: awscli 1.18.41 requires PyYAML<5.4,>=3.10; python_version != ""3.4"", which is not installed.
ERROR: awscli 1.18.41 has requirement rsa<=3.5.0,>=3.1.2, but you'll have rsa 4.0 which is incompatible.
Installing collected packages: wheel, numpy, pyasn1, rsa, setuptools, pyasn1-modules, six, cachetools, google-auth, protobuf, tensorboard-plugin-wit, werkzeug, oauthlib, urllib3, idna, chardet, certifi, requests, requests-oauthlib, google-auth-oauthlib, absl-py, zipp, importlib-metadata, markdown, grpcio, tensorboard, keras-preprocessing, termcolor, tensorflow-gpu-estimator, opt-einsum, gast, google-pasta, h5py, astunparse, scipy, wrapt, tensorflow-gpu
Successfully installed absl-py-0.9.0 astunparse-1.6.3 cachetools-4.1.0 certifi-2020.4.5.1 chardet-3.0.4 gast-0.3.3 google-auth-1.15.0 google-auth-oauthlib-0.4.1 google-pasta-0.2.0 grpcio-1.29.0 h5py-2.10.0 idna-2.9 importlib-metadata-1.6.0 keras-preprocessing-1.1.2 markdown-3.2.2 numpy-1.18.4 oauthlib-3.1.0 opt-einsum-3.2.1 protobuf-3.12.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.23.0 requests-oauthlib-1.3.0 rsa-4.0 scipy-1.4.1 setuptools-46.4.0.post20200518 six-1.15.0 tensorboard-2.2.1 tensorboard-plugin-wit-1.6.0.post3 tensorflow-gpu-2.2.0 tensorflow-gpu-estimator-2.2.0 termcolor-1.1.0 urllib3-1.25.9 werkzeug-1.0.1 wheel-0.34.2 wrapt-1.12.1 zipp-3.1.0

(tfpose) C:\Users\mysel\algo_od\git\tf-pose-estimation>python
Python 3.7.7 (default, May  6 2020, 11:45:54) [MSC v.1916 64 bit (AMD64)] :: Anaconda, Inc. on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow
Traceback (most recent call last):
  File ""D:\Anaconda\envs\tfpose\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""D:\Anaconda\envs\tfpose\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""D:\Anaconda\envs\tfpose\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""D:\Anaconda\envs\tfpose\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""D:\Anaconda\envs\tfpose\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""D:\Anaconda\envs\tfpose\lib\site-packages\tensorflow\__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""D:\Anaconda\envs\tfpose\lib\site-packages\tensorflow\python\__init__.py"", line 50, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""D:\Anaconda\envs\tfpose\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 69, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""D:\Anaconda\envs\tfpose\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""D:\Anaconda\envs\tfpose\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""D:\Anaconda\envs\tfpose\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""D:\Anaconda\envs\tfpose\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""D:\Anaconda\envs\tfpose\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
39769,RPi Zero Build instructions not working,"## URL(s) with the issue:
https://www.tensorflow.org/lite/guide/build_rpi#compile_natively_on_raspberry_pi

## Description of issue (what needs changing):
Guide on natively compiling says ""tested on Raspberry Pi Zero"", but following the instructions on a Raspberry Pi Zero leads to a build for armv7l, not armv6 as specified.
Adding TARGET_ARCH=armv6 to the command would likely work, as has been done in the cross-compile section to separate newer models from the RPi 1 / Zero. However, since me following these cross-compiling instructions resulted in a armv7l target as well (hard-float VFP ABI linking errors on Zero), I directly followed the tips from #30181 to be on the safe side."
39768,Tensorflow 1.x not available for python 3.8,"
**System information**
- OS Platform and Distribution Ubuntu 20.04 (LTS)
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 1.15
- Python version: 3.8.2
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A



**Describe the problem**
It seems that tensorflow 1.15.2 binaries are not available for Python 3.8 at this time.  This is at odds with the directions at https://www.tensorflow.org/install/pip state the system requirements for `tensorflow==1.15` are:

> * Python 3.5–3.8
> * pip 19.0 or later (requires manylinux2010 support)
> * Ubuntu 16.04 or later (64-bit)

Given that Ubuntu 20.04 is now the current LTS release and it has Python 3.8, it would be great if we could still run Tensorflow 1.x on that platform for as long as Tensorflow 1.x isn't deprecated.  

**Provide the exact sequence of commands / steps that you executed before running into the problem**

Just follow the exact instructions on https://www.tensorflow.org/install/pip for current Ubuntu release. Thanks!  "
39766,"Build Error fedora 32, gcc -10.xx","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- Linux Fedora 32
- TensorFlow installed from (source or binary):
- TensorFlow version:
- Python version:
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):


ERROR: /home/prashantkumar/.cache/bazel/_bazel_prashantkumar/bf7a6276eada3a0737ce3d01ac04c833/external/llvm-project/mlir/test/BUILD:146:1: C++ compilation of rule '@llvm-project//mlir/test:TestTransforms' failed (Exit 1)
In file included from /usr/lib/gcc/x86_64-redhat-linux/10/../../../../include/c++/10/bits/move.h:57,
                 from /usr/lib/gcc/x86_64-redhat-linux/10/../../../../include/c++/10/bits/nested_exception.h:40,
                 from /usr/lib/gcc/x86_64-redhat-linux/10/../../../../include/c++/10/exception:148,
                 from /usr/lib/gcc/x86_64-redhat-linux/10/../../../../include/c++/10/new:41,
                 from external/llvm-project/llvm/include/llvm/Support/Compiler.h:21,
                 from external/llvm-project/llvm/include/llvm/Support/Casting.h:17,
                 from external/llvm-project/mlir/include/mlir/Support/LLVM.h:24,
                 from external/llvm-project/mlir/include/mlir/IR/MLIRContext.h:12,
                 from external/llvm-project/mlir/include/mlir/IR/TypeSupport.h:16,
                 from external/llvm-project/mlir/include/mlir/IR/Types.h:12,
                 from external/llvm-project/mlir/include/mlir/IR/Value.h:16,
                 from external/llvm-project/mlir/include/mlir/IR/BlockSupport.h:16,
                 from external/llvm-project/mlir/include/mlir/IR/Block.h:16,
                 from external/llvm-project/mlir/include/mlir/IR/Operation.h:16,
                 from external/llvm-project/mlir/include/mlir/IR/OpDefinition.h:22,
                 from external/llvm-project/mlir/include/mlir/Dialect/Traits.h:17,
                 from external/llvm-project/mlir/test/lib/Dialect/Test/TestDialect.h:17,
                 from external/llvm-project/mlir/test/lib/Transforms/TestInlining.cpp:15:
/usr/lib/gcc/x86_64-redhat-linux/10/../../../../include/c++/10/type_traits: In instantiation of 'struct std::is_constructible<mlir::BlockAndValueMapping, llvm::iterator_range<llvm::detail::indexed_accessor_range_base<mlir::OperandRange, mlir::OpOperand*, mlir::Value, mlir::Value, mlir::Value>::iterator> >':
external/llvm-project/llvm/include/llvm/ADT/STLExtras.h:1171:30:   required by substitution of 'template<class RangeT, class> llvm::detail::indexed_accessor_range_base<mlir::OperandRange, mlir::OpOperand*, mlir::Value, mlir::Value, mlir::Value>::operator RangeT<RangeT, <template-parameter-1-2> >() const [with RangeT = mlir::BlockAndValueMapping; <template-parameter-1-2> = <missing>]'
external/llvm-project/mlir/test/lib/Transforms/TestInlining.cpp:49:75:   required from here
/usr/lib/gcc/x86_64-redhat-linux/10/../../../../include/c++/10/type_traits:909:52: error: static assertion failed: template argument must be a complete class or an unbounded array
  909 |       static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),




**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
39763,Ubuntu 18.04.4 LTS crashes while training with Tensorflow,"#System information

OS Platform and Distribution: Linux Ubuntu 18.04.4 LTS
TensorFlow installed from (container): tensorflow/tensorflow:nightly-gpu
TensorFlow version (use command below): Tensorflow: 2.3.0-dev20200514
Python version: 3.6.9
CUDA/cuDNN version: V10.1.243 / CUDNN=7.6.4.38-1
GPU model and memory: RTX 2080 8GB

### Describe the problem
Ubuntu gnome crashes or/and freezes while training any model with tensorflow. It is completely unable of finishing any training session...

### Source code / logs
Taken from /var/log/syslog:


May 14 20:44:09 APC-L gnome-shell[10844]: Some code accessed the property 'WindowPreviewMenu' on the module 'windowPreview'. That property was defined with 'let' or 'const' inside the module. This was previously supported, but is not correct according to the ES6 standard. Any symbols to be exported from a module must be defined with 'var'. The property access will work as previously for the time being, but please fix your code anyway.
May 14 20:45:08 APC-L gnome-session-binary[2276]: WARNING: Application 'org.gnome.Shell.desktop' killed by signal 11
May 14 20:45:08 APC-L gnome-session[2276]: gnome-session-binary[2276]: WARNING: Application 'org.gnome.Shell.desktop' killed by signal 11
May 14 20:45:17 APC-L /usr/lib/gdm3/gdm-x-session[2262]: (--) NVIDIA(GPU-0): DFP-0: disconnected
May 14 20:45:17 APC-L /usr/lib/gdm3/gdm-x-session[2262]: (--) NVIDIA(GPU-0): DFP-0: Internal DisplayPort
May 14 20:45:17 APC-L /usr/lib/gdm3/gdm-x-session[2262]: (--) NVIDIA(GPU-0): DFP-0: 2660.0 MHz maximum pixel clock
May 14 20:45:17 APC-L /usr/lib/gdm3/gdm-x-session[2262]: (--) NVIDIA(GPU-0):
May 14 20:45:17 APC-L /usr/lib/gdm3/gdm-x-session[2262]: (--) NVIDIA(GPU-0): DFP-1: disconnected
May 14 20:45:17 APC-L /usr/lib/gdm3/gdm-x-session[2262]: (--) NVIDIA(GPU-0): DFP-1: Internal TMDS
May 14 20:45:17 APC-L /usr/lib/gdm3/gdm-x-session[2262]: (--) NVIDIA(GPU-0): DFP-1: 165.0 MHz maximum pixel clock
May 14 20:45:17 APC-L /usr/lib/gdm3/gdm-x-session[2262]: (--) NVIDIA(GPU-0):
May 14 20:45:17 APC-L /usr/lib/gdm3/gdm-x-session[2262]: (--) NVIDIA(GPU-0): DFP-2: disconnected
May 14 20:45:17 APC-L /usr/lib/gdm3/gdm-x-session[2262]: (--) NVIDIA(GPU-0): DFP-2: Internal TMDS
May 14 20:45:17 APC-L /usr/lib/gdm3/gdm-x-session[2262]: (--) NVIDIA(GPU-0): DFP-2: 165.0 MHz maximum pixel clock
May 14 20:45:17 APC-L /usr/lib/gdm3/gdm-x-session[2262]: (--) NVIDIA(GPU-0):
May 14 20:45:17 APC-L /usr/lib/gdm3/gdm-x-session[2262]: (--) NVIDIA(GPU-0): DFP-3: disconnected
May 14 20:45:17 APC-L /usr/lib/gdm3/gdm-x-session[2262]: (--) NVIDIA(GPU-0): DFP-3: Internal DisplayPort
May 14 20:45:17 APC-L /usr/lib/gdm3/gdm-x-session[2262]: (--) NVIDIA(GPU-0): DFP-3: 2660.0 MHz maximum pixel clock
May 14 20:45:17 APC-L /usr/lib/gdm3/gdm-x-session[2262]: (--) NVIDIA(GPU-0):
May 14 20:45:17 APC-L /usr/lib/gdm3/gdm-x-session[2262]: (--) NVIDIA(GPU-0): DFP-4: disconnected
May 14 20:45:17 APC-L /usr/lib/gdm3/gdm-x-session[2262]: (--) NVIDIA(GPU-0): DFP-4: Internal TMDS
May 14 20:45:17 APC-L /usr/lib/gdm3/gdm-x-session[2262]: (--) NVIDIA(GPU-0): DFP-4: 165.0 MHz maximum pixel clock
May 14 20:45:17 APC-L /usr/lib/gdm3/gdm-x-session[2262]: (--) NVIDIA(GPU-0):
May 14 20:45:17 APC-L /usr/lib/gdm3/gdm-x-session[2262]: (--) NVIDIA(GPU-0): GBT AORUS AD27QD (DFP-5): connected
May 14 20:45:17 APC-L /usr/lib/gdm3/gdm-x-session[2262]: (--) NVIDIA(GPU-0): GBT AORUS AD27QD (DFP-5): Internal DisplayPort
May 14 20:45:17 APC-L /usr/lib/gdm3/gdm-x-session[2262]: (--) NVIDIA(GPU-0): GBT AORUS AD27QD (DFP-5): 2660.0 MHz maximum pixel clock
May 14 20:45:17 APC-L /usr/lib/gdm3/gdm-x-session[2262]: (--) NVIDIA(GPU-0):
May 14 20:45:17 APC-L /usr/lib/gdm3/gdm-x-session[2262]: (--) NVIDIA(GPU-0): DFP-6: disconnected
May 14 20:45:17 APC-L /usr/lib/gdm3/gdm-x-session[2262]: (--) NVIDIA(GPU-0): DFP-6: Internal TMDS
May 14 20:45:17 APC-L /usr/lib/gdm3/gdm-x-session[2262]: (--) NVIDIA(GPU-0): DFP-6: 165.0 MHz maximum pixel clock
May 14 20:45:17 APC-L /usr/lib/gdm3/gdm-x-session[2262]: (--) NVIDIA(GPU-0):
May 14 20:45:17 APC-L /usr/lib/gdm3/gdm-x-session[2262]: (--) NVIDIA(GPU-0): DFP-7: disconnected
May 14 20:45:17 APC-L /usr/lib/gdm3/gdm-x-session[2262]: (--) NVIDIA(GPU-0): DFP-7: Internal DisplayPort
May 14 20:45:17 APC-L /usr/lib/gdm3/gdm-x-session[2262]: (--) NVIDIA(GPU-0): DFP-7: 2660.0 MHz maximum pixel clock
May 14 20:45:17 APC-L /usr/lib/gdm3/gdm-x-session[2262]: (--) NVIDIA(GPU-0):
May 14 20:45:17 APC-L gsd-media-keys[2588]: g_variant_get_va: assertion 'value != NULL' failed
May 14 20:45:17 APC-L gsd-media-keys[2588]: g_variant_unref: assertion 'value != NULL' failed
May 14 20:45:17 APC-L org.gnome.Shell.desktop[12786]: current session already has an ibus-daemon.
May 14 20:45:17 APC-L dbus-daemon[1011]: [system] Activating via systemd: service name='org.freedesktop.GeoClue2' unit='geoclue.service' requested by ':1.155' (uid=1000 pid=12786 comm=""/usr/bin/gnome-shell "" label=""unconfined"")
May 14 20:45:17 APC-L systemd[1]: Starting Location Lookup Service...
May 14 20:45:17 APC-L dbus-daemon[1011]: [system] Successfully activated service 'org.freedesktop.GeoClue2'
May 14 20:45:17 APC-L systemd[1]: Started Location Lookup Service.
May 14 20:45:17 APC-L gnome-shell[12786]: Telepathy is not available, chat integration will be disabled.
May 14 20:45:18 APC-L gnome-shell[12786]: JS WARNING: [/usr/share/gnome-shell/extensions/ubuntu-dock@ubuntu.com/appIcons.js 1028]: unreachable code after return statement
May 14 20:45:18 APC-L gnome-shell[12786]: [AppIndicatorSupport-DEBUG] Registering StatusNotifierItem :1.96/org/ayatana/NotificationItem/software_update_available
May 14 20:45:18 APC-L gnome-shell[12786]: [AppIndicatorSupport-DEBUG] Registering StatusNotifierItem :1.96/org/ayatana/NotificationItem/livepatch
May 14 20:45:18 APC-L gnome-shell[12786]: Error looking up permission: GDBus.Error:org.freedesktop.portal.Error.NotFound: No entry for geolocation


I think it might be a NVIDIA driver issue... I have installed the latest propietary driver from NVIDIA 440.82 in several ways (nvidia web page run file, ubuntu software&update or ppa package). I also tried with a previous version driver (435.21), with the same result...

Thanks in advance."
39761,choosing bitrate when encoding audio,"**In tf1.15 there was the support of  choosing bitrate when encoding audio**
https://github.com/tensorflow/tensorflow/blob/r1.15/tensorflow/contrib/ffmpeg/ffmpeg_ops.py#L101

**Now the possibility is cut out**

It is very important feature in speech recognition tasks. So It will be great when you return back this option."
39759,Failed to bazel build //third_party/gpus/cuda/...,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- Ubuntu Linux 18.04, x86_64
-  CUDA-10.2/CUDNN-7.6.5/TensorRT-7 installed
- NVidia GeForce GTX 1070 GPU card, `nvidia-smi` works fine.
- TensorFlow installed from (source or binary): Not installed yet
- TensorFlow version:  tensorflow git repo on GitHub,  the latest master branch(CommitId: 880ea5d)
- Python version: system-provided Python3 (3.6.9)
- Bazel version (if compiling from source):  Bazel  `3.1.0` from bazel's official apt repo.
- GCC/Compiler version (if compiling from source): `gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0`

- CUDA/cuDNN version: CUDA-10.2.89-1, CUDNN-7.6.5.32-1+cuda10.2, TensorRT-7.0.0-1+cuda10.2
- GPU model and memory: GeForce GTX 1070,  8114MiB

**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**
```
git clone https://github.com/tensorflow/tensorflow.git  tensorflow.git
cd tensorflow.git
echo ""3.1.0"" > ./.bazelversion
./configure # Step by step following the instructions, with only CUDA and TensorRT support enabled
bazel build //third_party/gpus/cuda/...
```

Expected: Everything works fine.
Actual: Bazel build error, as can be seen from the following console log.
```
INFO: Found applicable config definition build:tensorrt in file /work/studio/github.com/tensorflow/tensorflow.git/.bazelrc: --action_env TF_NEED_TENSORRT=1
INFO: Found applicable config definition build:cuda in file /work/studio/github.com/tensorflow/tensorflow.git/.bazelrc: --config=using_cuda --define=using_cuda_nvcc=true
INFO: Found applicable config definition build:using_cuda in file /work/studio/github.com/tensorflow/tensorflow.git/.bazelrc: --define=using_cuda=true --action_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain
INFO: Found applicable config definition build:linux in file /work/studio/github.com/tensorflow/tensorflow.git/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels
INFO: Found applicable config definition build:dynamic_kernels in file /work/studio/github.com/tensorflow/tensorflow.git/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS
INFO: Analyzed target //third_party/gpus/cuda:build_defs_bzl (0 packages loaded, 0 targets configured).
INFO: Found 1 target...
ERROR: missing input file 'third_party/gpus/cuda/build_defs.bzl', owner: '//third_party/gpus/cuda:build_defs.bzl'
ERROR: /work/studio/github.com/tensorflow/tensorflow.git/third_party/gpus/cuda/BUILD:3:1: //third_party/gpus/cuda:build_defs_bzl: missing input file 'LabelCause{label=//third_party/gpus/cuda:build_defs.bzl, msg=missing input file 'third_party/gpus/cuda/build_defs.bzl', owner: '//third_party/gpus/cuda:build_defs.bzl'}'
Target //third_party/gpus/cuda:build_defs_bzl failed to build
Use --verbose_failures to see the command lines of failed build steps.
ERROR: /work/studio/github.com/tensorflow/tensorflow.git/third_party/gpus/cuda/BUILD:3:1 1 input file(s) do not exist
INFO: Elapsed time: 0.112s, Critical Path: 0.00s
INFO: 0 processes.
FAILED: Build did NOT complete successfully
```

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

```
$ lsb_release -a
No LSB modules are available.
Distributor ID:	Ubuntu
Description:	Ubuntu 18.04.4 LTS
Release:	18.04
Codename:	bionic

$ nvidia-smi
Thu May 21 22:35:58 2020       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 1070    On   | 00000000:01:00.0  On |                  N/A |
| 26%   45C    P0    35W / 151W |   1665MiB /  8114MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0      1276      G   /usr/lib/xorg/Xorg                            40MiB |
|    0      2459      G   /usr/lib/xorg/Xorg                           789MiB |
|    0      2615      G   /usr/bin/gnome-shell                         390MiB |
|    0     17079      G   ...quest-channel-token=9704712962697071887   184MiB |
|    0     21665      G   ...AAAAAAAAAAAACAAAAAAAAAA= --shared-files   242MiB |
+-----------------------------------------------------------------------------+
```"
39757,TfLite Micro - Conv2D layer not running on ESP32 board,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution: 
Compiling for ESP32: PlattformIO w/ ESP-IDF
Creating TfLite: Windows 10 w/ Anaconda and Python 3.7, 
- TensorFlow installed from (source or binary): 
Compiling C++: tflite/micro from hello-world example
TtLite creation: Python pip in a Anaconda environment with Python 3.7
- Tensorflow version (commit SHA if source): Tensorflow 2.2
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): ESP32CAM (ESP-IDF Compiler)

**Describe the problem**
Using a tflite-Model with a `Conv2D `layer results in a crash of the c++ code running on an ESP32 system. Just exchanging the layer to a `MaxPool2D `layer let the model run smoothly. This gave me the idea, that the problem is in using the Conv2D layer rather than the c++ code or model training.
The model structure looks like following:
```
model = Sequential()
model.add(InputLayer(input_shape=(32,20,3)))
model.add(Conv2D(8, (3, 3)))
# model.add(MaxPool2D(pool_size=(2,2)))
model.add(Flatten())
model.add(Dense(11, activation = ""softmax""))
```

The error on the ESP32 monitoring is the following
```
Input loaded.
Guru Meditation Error: Core  0 panic'ed (LoadProhibited). Exception was unhandled.
Core 0 register dump:
PC      : 0x40089191  PS      : 0x00060033  A0      : 0x80089913  A1      : 0x3ffb2f90
A2      : 0x3ffb3094  A3      : 0x00000000  A4      : 0x00060021  A5      : 0x000000fe
A6      : 0x00000001  A7      : 0x00000000  A8      : 0x00000000  A9      : 0x3ffb34f8
A10     : 0x00000003  A11     : 0x00060023  A12     : 0x00060021  A13     : 0x000000fe
A14     : 0x0000002a  A15     : 0x3ffb5370  SAR     : 0x0000001f  EXCCAUSE: 0x0000001c
EXCVADDR: 0x00000050  LBEG    : 0x4008e610  LEND    : 0x4008e63e  LCOUNT  : 0x00000000
Core 0 was running in ISR context:
EPC1    : 0x40089191  EPC2    : 0x00000000  EPC3    : 0x00000000  EPC4    : 0x00000000
```

The model training is done in a Jypiter Notebook on a Windows 10 system and the tflite file is created with the following conversion sequence:
```
name = ""conv2d""
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()
open(name + "".tfl"", ""wb"").write(tflite_model)
```

The coding for the ESP32 is done in C++ in ESP-IDF. The tflite micro library is copied from the hello-world example with the ESP-IDF compiler running on PlattformIO.
The simplified c++ code is:
```
...  INCLUDES ...

extern ""C"" void app_main() {
    static tflite::ErrorReporter* error_reporter = nullptr;
    const tflite::Model* model = nullptr;
    static tflite::MicroInterpreter* interpreter = nullptr;
    TfLiteTensor* output = nullptr;     
    static tflite::ops::micro::AllOpsResolver *resolver; 
    static tflite::MicroOpResolver<5> micro_op_resolver;
    int kTensorArenaSize = 128 * 1024;
    uint8_t *tensor_arena = new uint8_t[kTensorArenaSize];
    TfLiteStatus allocate_status;
    error_reporter = new tflite::MicroErrorReporter;

    CAccessSDClass accessSD;    
//    model = tflite::GetModel(accessSD.ReadFileToCharArray(""/sdcard/maxpool.tfl""));
    model = tflite::GetModel(accessSD.ReadFileToCharArray(""/sdcard/conv2d.tfl""));    
    printf(""Model loaded.\n"");       

    micro_op_resolver.AddBuiltin(tflite::BuiltinOperator_RESHAPE,
                                 tflite::ops::micro::Register_RESHAPE());
    micro_op_resolver.AddBuiltin(tflite::BuiltinOperator_CONV_2D,
                                 tflite::ops::micro::Register_CONV_2D());
    micro_op_resolver.AddBuiltin(tflite::BuiltinOperator_FULLY_CONNECTED,
                                 tflite::ops::micro::Register_FULLY_CONNECTED());
    micro_op_resolver.AddBuiltin(tflite::BuiltinOperator_SOFTMAX,
                                 tflite::ops::micro::Register_SOFTMAX());
    micro_op_resolver.AddBuiltin(tflite::BuiltinOperator_MAX_POOL_2D,
                                 tflite::ops::micro::Register_MAX_POOL_2D());
    interpreter = new tflite::MicroInterpreter(model, micro_op_resolver, tensor_arena, kTensorArenaSize, error_reporter);

    allocate_status = interpreter->AllocateTensors();

    CImageBasis cib(""/sdcard/zif0.jpg"");
    float* input_data_ptr = interpreter->typed_tensor<float>(0);
    for (int x = 0; x < cib.width; ++x)
        for (int y = 0; y < cib.height; ++y)
            for (int ch = 0; ch < cib.channels; ++ch)
            {
                *(input_data_ptr) = (float) cib.GetPixelColor(x, y, ch);
                input_data_ptr++;
            }
    printf(""Input loaded.\n"");

    interpreter->Invoke();
    printf(""Invoke Done.\n"");    

    output = interpreter->output(0);
    for (int i = 0; i < 11; ++i)
    {
        printf(""Result %d: %f\n"", i, output->data.f[i]);  
    }    
}
```


If the Conv2D layer is exchanged by a MaxPooling layer the model is running technically smoothl on exactly the same c++ code. The only change in the model is commenting the `Conv2D` layer and activation the `MaxPool2D` layer:
```
model.add(InputLayer(input_shape=(32,20,3)))
# model.add(Conv2D(8, (3, 3)))
model.add(MaxPool2D(pool_size=(2,2)))
model.add(Flatten())
model.add(Dense(11, activation = ""softmax""))
```

Then the result is as expected w/o any error:
```
Input loaded.
Invoke Done.
Result 0: 0.000000
Result 1: 0.000000
Result 2: 0.000000
Result 3: 0.000000
Result 4: 0.000000
Result 5: 0.000000
Result 6: 0.000000
Result 7: 0.000000
Result 8: 0.000000
Result 9: 0.000000
Result 10: 1.000000
```



**Any idea or hint where the problem is?**

**Remark**
This model is not doing any usefull anymore. I have reduced the model and the c++ code to a minimum for reproducing the problem. Final target is a image classification on a ESP32 with the inbuild camera. For the problem I need a dedicated CNN with several Conv2D layers.
"
39756,problem running visualize.py at import flatbuffersn,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **No**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  **Mac OS 10.15.3**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **n/a**
- TensorFlow installed from (source or binary): **from source**
- TensorFlow version (use command below): v1.12.1-32248-g8670c85844 **2.2.0**
- Python version: **3.7.4**
- Bazel version (if compiling from source): **3.0.0**
- GCC/Compiler version (if compiling from source): **Apple clang version 11.0.3 (clang-1103.0.32.59) (from gcc --version)**
- CUDA/cuDNN version: **n/a**
- GPU model and memory: **n/a**

**Describe the current behavior**
visualize.py script fails with this error:
`ImportError: cannot import name 'flatbuffersn' from 'flatbuffers.python' (/private/var/tmp/_bazel_jeremy/95159cfd4782ce915016562181875cd6/execroot/org_tensorflow/bazel-out/darwin-opt/bin/tensorflow/lite/tools/visualize.runfiles/flatbuffers/python/__init__.py)`

I am running it with the command 
`bazel run //tensorflow/lite/tools:visualize ~/dev/tfl_dev/mobilenet_v1_0.25_128_quant/mobilenet_v1_0.25_128_quant.tflite ~/tmp/mobnet.html
`
from the top of my tensorflow source directory.  The build phase seems to work fine, then the import error seems to happen on running visualize.py.  Full output in attached file.
[vis_dump.txt](https://github.com/tensorflow/tensorflow/files/4662612/vis_dump.txt)
The target tflite file can be downloaded [here]( http://download.tensorflow.org/models/mobilenet_v1_2018_08_02/mobilenet_v1_0.25_128_quant.tgz), but I don't think the tflite file ever gets loaded, so I doubt that the specific file is relevant.

The directory where it is trying to import from is listed here.  There is no flatbuffersn file or directory and the __init__.py file is empty.
```
ls -l /private/var/tmp/_bazel_jeremy/95159cfd4782ce915016562181875cd6/execroot/org_tensorflow/bazel-out/darwin-opt/bin/tensorflow/lite/tools/visualize.runfiles/flatbuffers/python/
total 0
-r-xr-xr-x   1 jeremy  wheel    0 May 20 16:15 __init__.py*
drwxr-xr-x   3 jeremy  wheel   96 May 21 09:39 __pycache__/
drwxr-xr-x  10 jeremy  wheel  320 May 20 16:15 flatbuffers/
```

**Describe the expected behavior**
I would expect it to dump an html file to ~/tmp/mobnet.html containing a visualization of the mobilenet model in the target tflite file.

**Standalone code to reproduce the issue**
The command line above.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
39755,tf.keras/Tensorboard callback does not implement activation histogram (and says it does),"**System information**
- TensorFlow version (you are using): r2.2

**Describe the feature and the current behavior/state.**

The callback v2 does advertise that it can record activations (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/callbacks.py#L1722), but the code clearly shows it doesn't : the following only saves weights histograms.
```
    if self.histogram_freq and epoch % self.histogram_freq == 0:
      self._log_weights(epoch)

```

The callback in callbacks_v1 did implement activation summary writing. However, there is one limitation where you cannot use it with eager execution enabled.

We should :
- either remove the comment saying that Tensorboard callback logs activation histogram (or at least add a note that it should be implemented in a future version)
- or, preferably of course, implement the feature..."
39754,applications_load_weight_test testcases fail on s390x architecture,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution: Ubuntu 18.04 on s390x architecture
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): v2.2.0-0-g2b96f3662b 2.2.0
- Python version: Python 3.6.9
- Bazel version (if compiling from source): bazel 2.0.0- (@non-git)
- GCC/Compiler version (if compiling from source):  gcc version 7.5.0 (Ubuntu 7.5.0-3ubuntu1~18.04)
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
`applications_load_weight_test` testcases fail on s390x architecture due to incompatible Keras applications models.  It appears that `h5py` fails to find `Conversion function` for `CSET H5T_CSET_ASCII` data types.  Error in the logs take the form of:
```
[  SKIPPED ] ApplicationsLoadWeightTest.test_session
======================================================================
ERROR: test_application_pretrained_weights_loading (__main__.ApplicationsLoadWeightTest)
test_application_pretrained_weights_loading (__main__.ApplicationsLoadWeightTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/334416e3a0381b53511e68de49f4ac07/execroot/org_tensorflow/bazel-out/s390x-opt/bin/tensorflow/python/keras/applications/applications_load_weight_test_resnet_v2.runfiles/org_tensorflow/tensorflow/python/keras/applications/applications_load_weight_test.py"", line 104, in test_application_pretrained_weights_loading
    model = app(weights='imagenet')
  File ""/root/.cache/bazel/_bazel_root/334416e3a0381b53511e68de49f4ac07/execroot/org_tensorflow/bazel-out/s390x-opt/bin/tensorflow/python/keras/applications/applications_load_weight_test_resnet_v2.runfiles/org_tensorflow/tensorflow/python/keras/applications/resnet_v2.py"", line 55, in ResNet50V2
    classifier_activation=classifier_activation,
  File ""/root/.cache/bazel/_bazel_root/334416e3a0381b53511e68de49f4ac07/execroot/org_tensorflow/bazel-out/s390x-opt/bin/tensorflow/python/keras/applications/applications_load_weight_test_resnet_v2.runfiles/org_tensorflow/tensorflow/python/keras/applications/resnet.py"", line 210, in ResNet
    model.load_weights(weights_path)
  File ""/root/.cache/bazel/_bazel_root/334416e3a0381b53511e68de49f4ac07/execroot/org_tensorflow/bazel-out/s390x-opt/bin/tensorflow/python/keras/applications/applications_load_weight_test_resnet_v2.runfiles/org_tensorflow/tensorflow/python/keras/engine/training.py"", line 250, in load_weights
    return super(Model, self).load_weights(filepath, by_name, skip_mismatch)
  File ""/root/.cache/bazel/_bazel_root/334416e3a0381b53511e68de49f4ac07/execroot/org_tensorflow/bazel-out/s390x-opt/bin/tensorflow/python/keras/applications/applications_load_weight_test_resnet_v2.runfiles/org_tensorflow/tensorflow/python/keras/engine/network.py"", line 1266, in load_weights
    hdf5_format.load_weights_from_hdf5_group(f, self.layers)
  File ""/root/.cache/bazel/_bazel_root/334416e3a0381b53511e68de49f4ac07/execroot/org_tensorflow/bazel-out/s390x-opt/bin/tensorflow/python/keras/applications/applications_load_weight_test_resnet_v2.runfiles/org_tensorflow/tensorflow/python/keras/saving/hdf5_format.py"", line 659, in load_weights_from_hdf5_group
    original_keras_version = f.attrs['keras_version'].decode('utf8')
  File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper
  File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper
  File ""/usr/local/lib/python3.6/dist-packages/h5py/_hl/attrs.py"", line 81, in __getitem__
    attr.read(arr, mtype=htype)
  File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper
  File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper
  File ""h5py/h5a.pyx"", line 355, in h5py.h5a.AttrID.read
  File ""h5py/_proxy.pyx"", line 50, in h5py._proxy.attr_rw
  File ""h5py/_proxy.pyx"", line 319, in h5py._proxy.needs_bkg_buffer
  File ""h5py/_proxy.pyx"", line 316, in h5py._proxy.needs_bkg_buffer
KeyError: 'Conversion function not found (no appropriate function for conversion path)'

----------------------------------------------------------------------
Ran 2 tests in 1.612s

FAILED (errors=1, skipped=1)
Failed to find converter for 8 -> b'PYTHON:OBJECT'

```

**Describe the expected behavior**

These testcases should pass on s390x architecture.

**Standalone code to reproduce the issue**
```
bazel --host_jvm_args=""-Xms1024m"" --host_jvm_args=""-Xmx2048m"" test  //tensorflow/python/keras/applications:applications_load_weight_test_resnet_v2
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

The problem appears when `h5py` tries to process keras application models downloaded to `~.keras/models/resnet50v2_weights_tf_dim_ordering_tf_kernels.h5`.  These models seem to be generated on x86 architecture and they fail to get past `h5py` process.  In particular, `original_keras_version = h5_file.file.attrs['keras_version'].decode('utf8')` [line ](https://github.com/tensorflow/tensorflow/blob/52fd23939e65699f8c7d53850a17daab7cc83177/tensorflow/python/keras/saving/hdf5_format.py#L659)fails with the following error:
```
  File ""/root/.cache/bazel/_bazel_root/334416e3a0381b53511e68de49f4ac07/execroot/org_tensorflow/bazel-out/s390x-opt/bin/tensorflow/python/keras/applications/applications_load_weight_test_resnet_v2.runfiles/org_tensorflow/tensorflow/python/keras/saving/hdf5_format.py"", line 659, in load_weights_from_hdf5_group
    original_keras_version = f.attrs['keras_version'].decode('utf8')
  File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper
  File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper
  File ""/usr/local/lib/python3.6/dist-packages/h5py/_hl/attrs.py"", line 81, in __getitem__
    attr.read(arr, mtype=htype)
  File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper
  File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper
  File ""h5py/h5a.pyx"", line 355, in h5py.h5a.AttrID.read
  File ""h5py/_proxy.pyx"", line 50, in h5py._proxy.attr_rw
  File ""h5py/_proxy.pyx"", line 319, in h5py._proxy.needs_bkg_buffer
  File ""h5py/_proxy.pyx"", line 316, in h5py._proxy.needs_bkg_buffer
KeyError: 'Conversion function not found (no appropriate function for conversion path)'
```
I suspect `keras_version` attribute has `CSET H5T_CSET_ASCII;` which `h5py` fails to convert to `UTF8` when architectures are different.

If  `h5py` is indeed the cause of these failures (which I suspect), then these testcases can be disabled on non-x86 archs or compatible Keras application models be used."
39753,MultiWorkerMirroredStrategy assign a wrong device,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  CentOS Linux release 7
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: nan
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de 2.1.0
- Python version: 3.6.10
- Bazel version (if compiling from source): nan
- GCC/Compiler version (if compiling from source): nan
- CUDA/cuDNN version: 10.1
- GPU model and memory: nan

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

Use distribution strategy MultiWorkerMirroredStrategy in graph mode, throw an error
`tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation metrics/auc/Identity: {{node metrics/auc/Identity}} was explicitly assigned to /replica:0/task:0/device:CPU:0 but available devices are [ /job:worker/replica:0/task:1/device:CPU:0, /job:worker/replica:0/task:1/device:GPU:0, /job:worker/replica:0/task:1/device:XLA_CPU:0, /job:worker/replica:0/task:1/device:XLA_GPU:0 ]. Make sure the device specification refers to a valid device.`

assign a wrong device which is `/replica:0/task:0/device:CPU:0` on task1

**Describe the expected behavior**

train normly

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```python
# file demo.py
import sys
import numpy as np
import tensorflow as tf

strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()
graph_context = tf.Graph().as_default()
strategy_context = strategy.scope()

with graph_context:
    with strategy_context:
        ip = tf.keras.layers.Input([2])
        h = tf.keras.layers.Dense(10, activation='relu', input_dim=2)(ip)
        out = tf.keras.layers.Dense(2, activation='softmax')(h)
        model = tf.keras.models.Model(inputs=[ip], outputs=[out])

        model.compile(optimizer='Adam',
                loss='categorical_crossentropy',
                metrics=[tf.keras.metrics.AUC(num_thresholds=100)])

    x = np.random.randn(100, 2)
    y = (x[:, 0] * x[:, 1]) > 0
    model.fit(x, tf.keras.utils.to_categorical(y), epochs=1)
```

run above script command:
```
TF_CONFIG='{""cluster"":{""worker"":[""localhost:2222"",""localhost:2223""]},""task"":{""type"":""worker"",""index"":0}}' CUDA_VISIBLE_DEVICES=0 python demo.py
TF_CONFIG='{""cluster"":{""worker"":[""localhost:2222"",""localhost:2223""]},""task"":{""type"":""worker"",""index"":1}}' CUDA_VISIBLE_DEVICES=1 python demo.py
```
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

```
Traceback (most recent call last):
  File ""/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/client/session.py"", line 1367, in _do_call
    return fn(*args)
  File ""/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn
    self._extend_graph()
  File ""/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/client/session.py"", line 1390, in _extend_graph
    tf_session.ExtendSession(self._session)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation metrics/auc/Identity: {{node metrics/auc/Identity}} was explicitly assigned to /replica:0/task:0/device:CPU:0 but available devices are [ /job:worker/replica:0/task:1/device:CPU:0, /job:worker/replica:0/task:1/device:GPU:0, /job:worker/replica:0/task:1/device:XLA_CPU:0, /job:worker/replica:0/task:1/device:XLA_GPU:0 ]. Make sure the device specification refers to a valid device.
         [[metrics/auc/Identity]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""../x.py"", line 22, in <module>
    model.fit(x, tf.keras.utils.to_categorical(y), epochs=1)
  File ""/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py"", line 819, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_distributed.py"", line 790, in fit
    *args, **kwargs)
  File ""/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_distributed.py"", line 777, in wrapper
    mode=dc.CoordinatorMode.INDEPENDENT_WORKER)
  File ""/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_coordinator.py"", line 853, in run_distribute_coordinator
    task_id, session_config, rpc_layer)
  File ""/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_coordinator.py"", line 360, in _run_single_worker
    return worker_fn(strategy)
  File ""/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_distributed.py"", line 772, in _worker_fn
    return method(model, **kwargs)
  File ""/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_distributed.py"", line 619, in fit
    epochs=epochs)
  File ""/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py"", line 2200, in _distribution_standardize_user_data
    session = K.get_session()
  File ""/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py"", line 496, in get_session
    _initialize_variables(session)
  File ""/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py"", line 911, in _initialize_variables
    [variables_module.is_variable_initialized(v) for v in candidate_vars])
  File ""/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/client/session.py"", line 960, in run
    run_metadata_ptr)
  File ""/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/client/session.py"", line 1183, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/client/session.py"", line 1361, in _do_run
    run_metadata)
  File ""/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/client/session.py"", line 1386, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation metrics/auc/Identity: node metrics/auc/Identity (defined at ../x.py:18)  was explicitly assigned to /replica:0/task:0/device:CPU:0 but available devices are [ /job:worker/replica:0/task:1/device:CPU:0, /job:worker/replica:0/task:1/device:GPU:0, /job:worker/replica:0/task:1/device:XLA_CPU:0, /job:worker/replica:0/task:1/device:XLA_GPU:0 ]. Make sure the device specification refers to a valid device.
         [[metrics/auc/Identity]]
```"
39752,unable to load model with custom objects on a Fresh Python Environment!,"Hi all, i have an issue in loading a model with custom loss function in a fresh-separate IPython Environment. Following is a sample code i used.

```
import tensorflow as tf
import tensorflow.keras.backend as K
import numpy as np


# creating the model
x = tf.keras.Input(shape = 10, name = ""Input"")

dense1 = tf.keras.layers.Dense(units = 10, activation = None)(x)
dense2 = tf.keras.layers.Dense(units = 10, activation = None)(dense1)
dense3 = tf.keras.layers.Dense(units = 10, activation = None)(dense2)
output = tf.keras.layers.Dense(units = 10, activation = None)(dense3)

model = tf.keras.Model(inputs = x, outputs = output)

# custom loss function
def custom_loss_func(y_true, y_pred):
    return K.mean(K.square(y_true - y_pred))

# compiling the model
model.compile(loss = custom_loss_func, optimizer = ""sgd"")

# sample fit
X = np.linspace(0,1,10).reshape(1,10)
Y = X**2

model.fit(X,Y,epochs = 10, batch_size = 1)

model.save(""custom_model.h5"")

# test code to load along with the model. and it works
#  new_model = tf.keras.models.load_model(""custom_model.h5"", custom_objects = {""custom_loss_func"":custom_loss_func})
```
in the last line, if i uncomment and run the script means, it works fine as the function is already defined on top. 
```
# test code to load along with the model. and it works
new_model = tf.keras.models.load_model(""custom_model.h5"", custom_objects = {""custom_loss_func"":custom_loss_func})
```

But if i run above line on a separate fresh IPython environment which hasn't seen this code yet, it throws error as below.

```
In [34]: new_model = tf.keras.models.load_model(""custom_model.h5"", custom_objects = {""custom_loss_func"":custom_loss_func})
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
<ipython-input-34-77825814faa4> in <module>
----> 1 new_model = tf.keras.models.load_model(""custom_model.h5"", custom_objects = {""custom_loss_func"":custom_loss_func})

NameError: name 'custom_loss_func' is not defined
```
Its correct, because that function object isn't defined in the new environment. 
I tried by defining a dummy function in the same name and try to load model, it didn't work as well, the errors are about mismatched input parameters, then mismatched return object etc.. 

Is there any working way to load the model with custom objects back on a fresh environment?"
39751,Non-deterministic behaviour: tf.math.unsorted_segment_sum uses CUDA Atomic Operations,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04.3
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):v2.1.0-rc2-17-ge5bf8de and v2.2.0-rc4-8-g2b96f3662b
- Python version: 3.7.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1.105 and 7.6.5.32
- GPU model and memory: RTX6000 24GB

**Describe the current behavior**
Currently, tf.math.unsorted_segment_sum uses non-deterministic GPU kernels which lead significant failings in the TensorFlow determinism venture. Other TensorFlow functions make use of tf.math.unsorted_segment_sum such as tf.gather (on backprop).

Some functions affected that I've discovered:
 - tfa.image.dense_image_warp (on backprop)
 - tf.gather (on backprop)

**Describe the expected behavior**

When TF_DETERMINISTIC_OPS=1,  tf.math.unsorted_segment_sum should use deterministic GPU kernels leading to reproducibility.

**Who will benefit from this bug fix correction?**
Determinism is an extremely important part of our venture into deep learning as a community. Without determinism, it is hard to reliably tune hyperparameters and conduct other types of investigations such ablation studies. Whilst many TensorFlow operations have a deterministic alternative upon setting the OS Environment variable TF_DETERMINISTIC_OPS=1, tf.math.unsorted_segment_sum seems to have fallen under the radar, perhaps because other operations took priority (such as tf.reduce_sum). 

Introducing this level of determinism to TensorFlow will allow it to be a better candidate for deep learning deployments in more sensitive environments such as medical. I.e. it doesn't make sense that a radiologist will look at result during one scan and then conduct the same scan and get a different result. It also affects the public's trust in AI venture altogether. ~~As far as I'm aware, PyTorch offers full deterministic capabilities (perhaps due to the benefit of hindsight with TensorFlow not having it).~~ 

**Standalone code to reproduce the issue**
Code to reproduce the issue:
(Edit: Please see the code here instead: https://github.com/tensorflow/tensorflow/issues/39751#issuecomment-632590302

I've added seed settings, TF_DETERMINISTIC_OPS, etc... and the issue still reproduces)

```
import tensorflow as tf
import numpy as np

num_segments = 4
data = tf.random.normal([30, 256, 256])
data = tf.constant(data)
segments = np.random.randint(low=0, high=num_segments, size=data.shape)

for i in range(5):
    reduced_summed = tf.math.unsorted_segment_sum(data, segments, num_segments)
    print(reduced_summed)
```
Output:

tf.Tensor([-273.92117  380.23163 1279.9718  -839.6437 ], shape=(4,), dtype=float32)
tf.Tensor([-273.92395  380.22168 1279.9834  -839.62573], shape=(4,), dtype=float32)
tf.Tensor([-273.91425  380.22177 1279.9773  -839.62976], shape=(4,), dtype=float32)
tf.Tensor([-273.9177  380.2243 1279.9733 -839.6427], shape=(4,), dtype=float32)
tf.Tensor([-273.91568  380.2217  1279.9747  -839.64166], shape=(4,), dtype=float32)

# Note: all printed results are different but in reality, they should be the same

Colab notebook with this code can be found at : https://colab.research.google.com/drive/1HNHSfERQ_IDDDM7bgabii9TQPufpsutp?usp=sharing

** Unit Tests **
Essentially, the code above will produce the same result, rather than a different result every time it is executed in the for loop.

Coming soon.


**Other info / logs**

More information about the GPU operation can be found at https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/segment_reduction_ops_gpu.cu.cc

More information coming soon"
39750,`Tensor` slicing is ~300x slower than `numpy` slicing,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution: macOS 10.14.5
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.1.0, 2.2.0-dev20200405
- Python version: 3.6

**Describe the current behavior**

Slicing a 1D `Tensor` is approximately 2 orders of magnitude slower than slicing a `numpy` `array`. Looking at the source code I'm not entirely sure whether this is a problem with `tensorflow` or `Eigen` so sorry if this in the wrong place!

**Describe the expected behavior**

I guess the expected behaviour is that tensorflow's slicing op has a competive performance to numpy. I'd be keen to implement a fix if its appropriate 

**Standalone code to reproduce the issue**

Here's a colab link with the below code snippet: https://colab.research.google.com/drive/1XeAgdhBwzxAuy613myIGttKrQ8W_UNCK?usp=sharing

```python
import numpy as np
import tensorflow as tf

arr = np.random.random(10_000_000).astype(np.float32)
tnsr = tf.constant(arr)

%timeit _ = tnsr[:100]
%timeit _ = arr[:100]
```

This outputs:

```
50.7 µs ± 668 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)
163 ns ± 2.52 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)
```

"
39749,PReLU operation throws error on tflite android benchmark tool with gpu,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Redmi Note 8 pro
- TensorFlow installed from (source or binary): Google Colab Tensorflow Binary
- TensorFlow version (use command below): tf  1.15 and tf 2.2
- Python version: 3.6.9


**Describe the current behavior**
I converted a tf.keras model with PReLU operation into **tflite** format. The **android tflite benchmark tool** throws an error on the model with the **default PReLU settings of shared_axes=Null**


```
adb shell /data/local/tmp/benchmark_model_tf15 --graph=/data/local/tmp/prelu_model1.tflite --enable_op_profiling=true --use_gpu=true
adb: /opt/intel/intelpython27/lib/libcrypto.so.1.0.0: no version information available (required by adb)
STARTING!
Min num runs: [50]
Min runs duration (seconds): [1]
Max runs duration (seconds): [150]
Inter-run delay (seconds): [-1]
Num threads: [1]
Benchmark name: []
Output prefix: []
Min warmup runs: [1]
Min warmup runs duration (seconds): [0.5]
Graph: [/data/local/tmp/prelu_mod3.tflite]
Input layers: []
Input shapes: []
Input value ranges: []
Use legacy nnapi : [0]
Allow fp16 : [0]
Require full delegation : [0]
Enable op profiling: [1]
Max profiling buffer entries: [1024]
CSV File to export profiling data to: []
Use gpu : [1]
Allow lower precision in gpu : [1]
Use Hexagon : [0]
Hexagon lib path : [/data/local/tmp]
Hexagon Profiling : [0]
Use nnapi : [0]
Use xnnpack : [0]
Loaded model /data/local/tmp/prelu_mod3.tflite
INFO: Initialized TensorFlow Lite runtime.
INFO: Created TensorFlow Lite delegate for GPU.
**ERROR: TfLiteGpuDelegate Init: PRELU: Dimensions are not HWC**
ERROR: TfLiteGpuDelegate Prepare: delegate is not initialized
ERROR: Node number 2 (TfLiteGpuDelegateV2) failed to prepare.

ERROR: Restored previous execution plan after delegate application failure.
Failed to apply GPU delegate.
Benchmarking failed.
```

Now, with option **shared_axes=[1,2]**, it runs the model without any error on gpu.
Also, the model runs **without any error on CPU**  in both settings.

**Describe the expected behavior**

The tflite model with default PReLU settings (i.e no shared axes ), should run without any errors on gpu delegate in android.

**Standalone code to reproduce the issue**

Colab Notebook: https://colab.research.google.com/drive/1pZRaeUB7Gj1HU1BR9DcSI6SxHfdsWbD_#scrollTo=_63mXS3A1m0r

**Other info / logs** 

* **prelu_model1.tflite**: No shared axes and **does not run on gpu**
* **prelu_model2.tflite**: Has shared_axes=[1,2] and runs on gpu
[prelu_models.zip](https://github.com/tensorflow/tensorflow/files/4662049/prelu_models.zip)

The behaviour seems to be same for tf 2.2 models and corresponding android benchmark tools.
How can we make it run on gpu with default settings ie. no shared _axes?"
39748,ERROR: Encountered unresolved custom op: Dilation2D.,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Ubuntu 20.04
- TensorFlow installed from (source or binary): source
- TensorFlow version : 2.1.0

**Error Output**

```
ERROR: Encountered unresolved custom op: Dilation2D.
ERROR: Node number 2 (Dilation2D) failed to prepare.
```

**Standalone code to reproduce the issue** 
link to code: [code](https://github.com/pranv12/tflite_example_cc)
link to model: [model](https://drive.google.com/file/d/1a7HeTnzP9J2H5z6JQZAsoOLnVOsZiZt_/view?usp=sharing)

a command to reproduce error: `g++ *.cc  -ltensorflow -ltensorflowLite`

**Any other info/logs**
there is no traceback in output."
39746,"Support ""depth_to_pace"" for tflite GPU delegate","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): source
- TensorFlow version (or github SHA if from source): a8001b9e8db92620603c3c0588d251192d327bae



**Provide the text output from tflite_convert**

```
# Copy and paste here
```

**Standalone code to reproduce the issue** 
Could you please add ""depth_to_pace"" support for tflite GPU delegate ?


**Any other info / logs**

INFO: Initialized TensorFlow Lite runtime.
INFO: Created TensorFlow Lite delegate for GPU.
ERROR: Following operations are not supported by GPU delegate:
DEPTH_TO_SPACE: Operation is not supported.
"
39745,Handling Unbalanced dataset : ImageAugmentation using tf.keras.preprocessing.image.ImageDataGenerator and tf.datasets: model.fit(),"## URL(s) with the issue:
https://www.tensorflow.org/guide/keras/train_and_evaluate#using_sample_weighting_and_class_weighting

https://www.tensorflow.org/tutorials/images/classification#data_augmentation

## Description of the issue (what needs changing):
According to the TensorFlow documentation we are not supposed to use class_weights parameter when training the models (model.fit()) using tf.datasets. So the suggested way is to use sample_weights. I was able to use sample_weights and create a dataset using sample_weights and passed it to the model.fit() method without using ImageDatGenerators.

a) But how can we do the same while using ImageDataGenerator class and flow_from_dataframe() data generator and using tf.datasets? 

b) Is there any option to pass sample_weights in tf.keras.preprocessing.image.ImageDataGenerator class's flow()/flow_from_dataframe() methods?

c) The second URL which I have shared above also does not mention whether the ImageDataGenerator class has a way of balancing the unbalanced datasets.

### Usage example
Can you provide a usage example?
"
39744,tensorflow for go install failed,"MacOS version(10.15.4)

1. I followed the instruction of  https://www.tensorflow.org/install/lang_c  ,I installed the c Library .but it doesn't word.the error is > hello_tf.c:2:10: fatal error: 'tensorflow/c/c_api.h' file not found

2. github.com/tensorflow/tensorflow/tensorflow/go/saved_model.go:25:2: cannot find package ""github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto"" in any of:
/usr/local/go/src/github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto (from $GOROOT)
/Users/moses/workspace/godemo/src/github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto (from $GOPATH)

how to solve this problem
"
39742,Warning while running teaching sample,"While running folloing sipmle code
```python
from tensorflow import data
dataset = data.Dataset.from_tensor_slices([8, 3, 0, 8, 2, 1])
for elem in dataset:
    print(elem.numpy())
it = iter(dataset)
print(next(it).numpy())
print(dataset.reduce(0, lambda state, value: state + value).numpy())
```
I have this warning
```python
WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000001B252F02AF0> and \
will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on \
Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: Unable to locate the source code of <function <lambda> at 0x000001B252F02AF0>. Note that\
functions defined in certain environments, like the interactive Python shell do not expose\
their source code. If that is the case, you should to define them in a .py source file. If you \
are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert.\
Original error: could not get source code
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
```
I knaw about https://github.com/tensorflow/tensorflow/issues/38691 issue, but warning repited on new TensorFlow  version
**System information**
Windows 10 64bit (no GPU machine)
Python 3.8.2
TensorFlow 2.2.0 (standard GPU version)
running on venv environment, in PyCharm Python console"
39741,Cd Tiger not opening,"
![Screenshot_2020-05-21-11-34-45-27](https://user-images.githubusercontent.com/65701344/82530632-49ab0600-9b2d-11ea-8892-3e0cee5f445b.png)
<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:
- Python version:
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
39740,cd Tiger build installation isssue when I'm using command cd Tiger it's retrun such a no file directory ,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:
- Python version:
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
39739,tf.keras.layers.Embedding convert error,"**System information**
- Linux Ubuntu 16.04):
- tf-nightly

Hello, 
I have problem when converting ""tf.keras.layers.Embedding"".
""from_keras_model"" works well but   ""from_saved_model"" doesn't. 

**Code**
```
embed_model = tf.keras.models.Sequential([ 
    tf.keras.layers.Embedding(10, 10)
])
dinput1 = np.random.randint([1],10)
out=embed_model(dinput1)

MODEL_DIR = ""embed_model""
embed_model.save(MODEL_DIR, save_format=""tf"" )
converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_DIR) 
#converter = tf.lite.TFLiteConverter.from_keras_model(embed_model)

converter.experimental_new_converter = True
tflite_embed_model = converter.convert()

open(""dec_model.tflite"", ""wb"").write(tflite_embed_model)
```

**Error Log**
Traceback (most recent call last):
  File ""/local1/sshwang/virtual_envs/pytorch_1/lib/python3.5/site-packages/tensorflow/lite/python/convert.py"", line 180, in toco_convert_protos
    enable_mlir_converter)
  File ""/local1/sshwang/virtual_envs/pytorch_1/lib/python3.5/site-packages/tensorflow/lite/python/wrap_toco.py"", line 38, in wrapped_toco_convert
    enable_mlir_converter)
Exception: Failed to find function '__inference__wrapped_model_251'. The imported TensorFlow GraphDef is ill-formed.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""embedding_model.py"", line 21, in <module>
    tflite_embed_model = converter.convert()
  File ""/local1/sshwang/virtual_envs/pytorch_1/lib/python3.5/site-packages/tensorflow/lite/python/lite.py"", line 920, in convert
    return super(TFLiteConverterV2, self).convert()
  File ""/local1/sshwang/virtual_envs/pytorch_1/lib/python3.5/site-packages/tensorflow/lite/python/lite.py"", line 752, in convert
    self).convert(graph_def, input_tensors, output_tensors)
  File ""/local1/sshwang/virtual_envs/pytorch_1/lib/python3.5/site-packages/tensorflow/lite/python/lite.py"", line 498, in convert
    **converter_kwargs)
  File ""/local1/sshwang/virtual_envs/pytorch_1/lib/python3.5/site-packages/tensorflow/lite/python/convert.py"", line 555, in toco_convert_impl
    enable_mlir_converter=enable_mlir_converter)
  File ""/local1/sshwang/virtual_envs/pytorch_1/lib/python3.5/site-packages/tensorflow/lite/python/convert.py"", line 183, in toco_convert_protos
    raise ConverterError(str(e))
tensorflow.lite.python.convert.ConverterError: Failed to find function '__inference__wrapped_model_251'. The imported TensorFlow GraphDef is ill-formed.

 "
39738,Subclassed layers not automatically saved to checkpoint in TF2.2,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): `Yes`
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `Linux Ubuntu 18.04`
- TensorFlow installed from (source or binary): `binary`
- TensorFlow version (use command below): `2.1 and 2.2`
- Python version: `3.6 and 3.8`
- CUDA/cuDNN version: `10.2 / 7.6.5`
- GPU model and memory: `TITAN X (Pascal) 12 GB`


**Describe the current behavior**
With TF 2.1, I was able to subclass the `tf.keras.Sequential` class as part of a model and checkpoints would save fine as far as I knew. 
With TF 2.2, I saw that `tf.keras.Sequential` layers are not tracked in the checkpoint unless the layers are also set as attribute of the subclass.

**Describe the expected behavior**
I'm curious to know if the behavior in TF 2.2 is the intended behavior. 
There are workarounds like manually setting the attributes or instantiating a `tf.keras.Sequential`.

**Standalone code to reproduce the issue**
```python
from pprint import pprint

import tensorflow as tf

class CustomSequential(tf.keras.Sequential):
    def __init__(self, set_attributes=False, name='CustomSequential', **kwargs):
        super().__init__([
            tf.keras.layers.Conv2D(2, 3, 2, name='conv2'),
            tf.keras.layers.Conv2D(4, 3, 2, name='conv3'),
            tf.keras.layers.Flatten(),
            tf.keras.layers.Dense(10)
        ], name=name, **kwargs)

        if set_attributes:
            self.conv1 = self.layers[0]
            self.conv2 = self.layers[1]
            self.dense = self.layers[3]


class CustomModel(tf.keras.Model):
    def __init__(self, set_attributes, name='CustomModel', **kwargs):
        super().__init__(name=name, **kwargs)
        self.convolution = tf.keras.layers.Conv2D(8, 3, name='conv1')
        self.sequential = CustomSequential(set_attributes, name='MySequential')

    def call(self, inputs):
        net = self.convolution(inputs)

        return self.sequential(net)


print('TensorFlow version')
print(tf.version.GIT_VERSION, tf.version.VERSION)
for set_attributes in [True, False]:
    print(f'Set sequential layer attributes: {set_attributes}')
    inputs = tf.random.uniform([5, 16, 16, 3])
    model = CustomModel(set_attributes)
    outputs = model(inputs)

    checkpoint = tf.train.Checkpoint(step=tf.Variable(1), model=model)
    manager = tf.train.CheckpointManager(checkpoint, f'./custom_model_{set_attributes}', max_to_keep=3)
    manager.save()

    pprint(tf.train.list_variables(manager.latest_checkpoint))
    print('------------------')
```

***TF 2.1 Result***
```
TensorFlow version
v2.1.0-rc2-17-ge5bf8de 2.1.0
Set sequential layer attributes: True
[('_CHECKPOINTABLE_OBJECT_GRAPH', []),
 ('model/convolution/bias/.ATTRIBUTES/VARIABLE_VALUE', [8]),
 ('model/convolution/kernel/.ATTRIBUTES/VARIABLE_VALUE', [3, 3, 3, 8]),
 ('model/sequential/layer-0/bias/.ATTRIBUTES/VARIABLE_VALUE', [2]),
 ('model/sequential/layer-0/kernel/.ATTRIBUTES/VARIABLE_VALUE', [3, 3, 8, 2]),
 ('model/sequential/layer-1/bias/.ATTRIBUTES/VARIABLE_VALUE', [4]),
 ('model/sequential/layer-1/kernel/.ATTRIBUTES/VARIABLE_VALUE', [3, 3, 2, 4]),
 ('model/sequential/layer-3/bias/.ATTRIBUTES/VARIABLE_VALUE', [10]),
 ('model/sequential/layer-3/kernel/.ATTRIBUTES/VARIABLE_VALUE', [16, 10]),
 ('save_counter/.ATTRIBUTES/VARIABLE_VALUE', []),
 ('step/.ATTRIBUTES/VARIABLE_VALUE', [])]
------------------
Set sequential layer attributes: False
[('_CHECKPOINTABLE_OBJECT_GRAPH', []),
 ('model/convolution/bias/.ATTRIBUTES/VARIABLE_VALUE', [8]),
 ('model/convolution/kernel/.ATTRIBUTES/VARIABLE_VALUE', [3, 3, 3, 8]),
 ('model/sequential/layer-0/bias/.ATTRIBUTES/VARIABLE_VALUE', [2]),
 ('model/sequential/layer-0/kernel/.ATTRIBUTES/VARIABLE_VALUE', [3, 3, 8, 2]),
 ('model/sequential/layer-1/bias/.ATTRIBUTES/VARIABLE_VALUE', [4]),
 ('model/sequential/layer-1/kernel/.ATTRIBUTES/VARIABLE_VALUE', [3, 3, 2, 4]),
 ('model/sequential/layer-3/bias/.ATTRIBUTES/VARIABLE_VALUE', [10]),
 ('model/sequential/layer-3/kernel/.ATTRIBUTES/VARIABLE_VALUE', [16, 10]),
 ('save_counter/.ATTRIBUTES/VARIABLE_VALUE', []),
 ('step/.ATTRIBUTES/VARIABLE_VALUE', [])]
------------------
```

***TF 2.2 Result***
```
TensorFlow version
v2.2.0-rc4-8-g2b96f3662b 2.2.0
Set sequential layer attributes: True
[('_CHECKPOINTABLE_OBJECT_GRAPH', []),
 ('model/convolution/bias/.ATTRIBUTES/VARIABLE_VALUE', [8]),
 ('model/convolution/kernel/.ATTRIBUTES/VARIABLE_VALUE', [3, 3, 3, 8]),
 ('model/sequential/conv1/bias/.ATTRIBUTES/VARIABLE_VALUE', [2]),
 ('model/sequential/conv1/kernel/.ATTRIBUTES/VARIABLE_VALUE', [3, 3, 8, 2]),
 ('model/sequential/conv2/bias/.ATTRIBUTES/VARIABLE_VALUE', [4]),
 ('model/sequential/conv2/kernel/.ATTRIBUTES/VARIABLE_VALUE', [3, 3, 2, 4]),
 ('model/sequential/dense/bias/.ATTRIBUTES/VARIABLE_VALUE', [10]),
 ('model/sequential/dense/kernel/.ATTRIBUTES/VARIABLE_VALUE', [16, 10]),
 ('save_counter/.ATTRIBUTES/VARIABLE_VALUE', []),
 ('step/.ATTRIBUTES/VARIABLE_VALUE', [])]
------------------
Set sequential layer attributes: False
[('_CHECKPOINTABLE_OBJECT_GRAPH', []),
 ('model/convolution/bias/.ATTRIBUTES/VARIABLE_VALUE', [8]),
 ('model/convolution/kernel/.ATTRIBUTES/VARIABLE_VALUE', [3, 3, 3, 8]),
 ('save_counter/.ATTRIBUTES/VARIABLE_VALUE', []),
 ('step/.ATTRIBUTES/VARIABLE_VALUE', [])]
------------------
```

This may be related to #37839."
39737,Provide way to exclude CoreML delegate from bazel build,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>

**System information**
- TensorFlow version (you are using): master
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**

Currently when you build for iOS (specifically Swift in our case) you end up with the `coreml_delegate` target whether or not you consume it. As described in this comment, this may be something we want to support optionally excluding:

https://github.com/tensorflow/tensorflow/blob/d53c999feb2751b6a3ec9bace5be6f0b4620e4b4/tensorflow/lite/experimental/swift/BUILD.apple#L13-L24

**Will this change the current api? How?**

I think we could maintain the current behavior, and have a [`config_setting`](https://docs.bazel.build/versions/master/be/general.html#config_setting) that could be used with a `--define` such as `--define=EXCLUDE_COREML=1` that we could [`select`](https://docs.bazel.build/versions/master/be/functions.html#select) on to opt these out. This is done extensively in the [envoy build system](https://github.com/envoyproxy/envoy/blob/2b0633a09ce2ebf7ff4ba19ac470c013b1f2d35b/bazel/BUILD#L114) for similar reasons.

**Who will benefit with this feature?**

Anyone who doesn't need the CoreML specific logic and wants to potentially reduce their app size (in some cases this may have very little app size effect because of dead stripping)

**Any Other info.**

More discussion on https://github.com/tensorflow/tensorflow/pull/38956"
39736,libhexagon_interface.so for non Android - Openwrt platform,"@tensorflow/tflite

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Openwrt 15.05
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: ipq6018
- TensorFlow installed from (source or binary): Source
- TensorFlow version: r2.2
- GCC/Compiler version (if compiling from source): musl arch64 gcc 5.3+ (https://musl.libc.org/)

**Describe the problem**
I'm trying to get hexagon delegate to work with QC's IPQ6018 SoC which contains a hexagon DSP. The currently available libhexagon_interface.so doesn't work as it has Android Dependencies. Is it possible to get a libhexagon_interface.so cross-compiled for openwrt without Android dependencies? 

Arch: armv8-64
One can build musl arch64 compiler using this project https://github.com/richfelker/musl-cross-make
After this step, using the binary generated you can cross-compile libhexagon_interface.so

I can help with testing if there is no access to Hardware. Thanks!
"
39735,ValueError when attempting to use adapt method from TextVectorization layer ,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab
- TensorFlow installed from (source or binary): pip install tf-nightly
- TensorFlow version (use command below): v1.12.1-32169-gf7d038cc3b 2.3.0-dev20200519
- Python version: 3.6.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the current behavior**
I've tried running the following two text classification guides:
- https://keras.io/examples/nlp/text_classification_from_scratch/
- https://keras.io/examples/nlp/pretrained_word_embeddings/

In each case, when I reach the call to the `adapt`  method, e.g. `vectorizer.adapt(text_ds)`, the following error is raised:

> /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/preprocessing/index_lookup.py in set_vocabulary(self, vocab)
    282           ""Attempted to set a vocabulary larger than the maximum vocab size. ""
    283           ""Passed vocab size is %s, max vocab size is %s."" %
--> 284           (total_vocab_size, self.max_tokens))
    285 
    286     start_index = num_special_tokens
>
> ValueError: Attempted to set a vocabulary larger than the maximum vocab size. Passed vocab size is 20001, max vocab size is 20000

**Describe the expected behavior**
The error should not be raised.

**Standalone code to reproduce the issue**
```
from tensorflow.keras.layers.experimental.preprocessing import TextVectorization
import numpy as np

#define a set of docs as per https://machinelearningmastery.com/ example
docs = np.array(['Well done!',
		'Good work',
		'Great effort',
		'nice work',
		'Excellent!',
		'Weak',
		'Poor effort!',
		'not good',
		'poor work',
		'Could have done better.'])

vectorizer = TextVectorization(max_tokens=5, output_sequence_length=4)
text_ds = tf.data.Dataset.from_tensor_slices(docs)
vectorizer.adapt(text_ds)

```
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-71-6ce2d6cd5e1a> in <module>()
      3 vectorizer = TextVectorization(max_tokens=5, output_sequence_length=4)
      4 text_ds = tf.data.Dataset.from_tensor_slices(docs)
----> 5 vectorizer.adapt(text_ds)

4 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/preprocessing/text_vectorization.py in adapt(self, data, reset_state)
    408           ""adapt() requires a Dataset or an array as input, got {}"".format(
    409               type(data)))
--> 410     super(TextVectorization, self).adapt(preprocessed_inputs, reset_state)
    411 
    412   def get_vocabulary(self):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_preprocessing_layer.py in adapt(self, data, reset_state)
    203 
    204     updates = self._combiner.extract(accumulator)
--> 205     self._set_state_variables(updates)
    206 
    207   def _set_state_variables(self, updates):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/preprocessing/text_vectorization.py in _set_state_variables(self, updates)
    521           updates[_OOV_IDF_NAME])
    522     else:
--> 523       self.set_vocabulary(updates[_VOCAB_NAME])
    524 
    525   def _preprocess(self, inputs):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/preprocessing/text_vectorization.py in set_vocabulary(self, vocab, df_data, oov_df_value)
    471                           ""called."").format(mode=self._output_mode))
    472 
--> 473     self._index_lookup_layer.set_vocabulary(vocab)
    474 
    475     # When doing raw or integer output, we don't have a Vectorize layer to

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/preprocessing/index_lookup.py in set_vocabulary(self, vocab)
    282           ""Attempted to set a vocabulary larger than the maximum vocab size. ""
    283           ""Passed vocab size is %s, max vocab size is %s."" %
--> 284           (total_vocab_size, self.max_tokens))
    285 
    286     start_index = num_special_tokens

ValueError: Attempted to set a vocabulary larger than the maximum vocab size. Passed vocab size is 6, max vocab size is 5.
"
39733,Documentation of accepted datatypes for `validation_data` in keras.Model.fit is incorrect. ,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit

## Description of issue (what needs changing):

The description of the keras `Model.fit` function is either ambiguous, or incorrect, regarding the accepted datatypes for the parameter `validation_data`. Specifically, some data types *are* accepted, even when the documentation states that they are not. For example, the datatype `keras.utils.Sequence` *is* accepted as a possible datatype, and (as far as I can tell) behaves as one would expect. 

As far as I can tell, this is primarily true when the user passes a generator/Sequence as `x`. In this case, the function `Model.fit` dispatches to the (deprecated) function `Model.fit_generator`, which *does* accept a generator or Sequence for the `validation_data` parameter.

This documentation should be corrected to unambiguously state one of the following: 

- *exactly* the list of datatypes that are accepted (e.g. numpy arrays, lists, pandas dataframes, etc). Note, this may require more work in order to fully test this set of datatypes. 
- *an approximation* of the list of datatypes that are accepted, with a cavaeat that some may be untested/only sometimes valid

If the types accepted are dependent on the type of `x`, then this should also be documented. 

### Submit a pull request?

If necessary, I am happy to open a PR, however I think that given this is clear user-facing code, and the primary interface for most tensorflow users it woudl be best to have this fix spearheaded by an internal developer."
39732,ImportError: cannot import name 'export_saved_model' from 'tensorflow.python.keras.saving.saved_model' (F:\New folder\New folder\lib\site-packages\tensorflow\python\keras\saving\saved_model\__init__.py),"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:
- Python version:
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
39730,Keras Tensorboard Callback conflicts with Lambda Callback writing summaries,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, but will test stock examples to verify issue
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): Docker tensorflow/tensorflow:2.2.0-gpu
- TensorFlow version (use command below):  Docker tensorflow/tensorflow:2.2.0-gpu
- Python version: 3.6.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1/7.6.4 (what'ts in the docker container)
- GPU model and memory: RTX 2080, 8GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

v2.2.0-rc4-8-g2b96f3662b 2.2.0

**Describe the current behavior**

Specify callbacks for Keras:
- TensorboardCallback, with a non-default batch interval
- LambdaCallback, which uses a created summary writer to write images a >1 batch interval which differs from the above

In the below script, the following settings produce expected results only when the `update_freq` is set to 1. 

**Describe the expected behavior**

Image writer should log and the status should be 1 (true)

Both summaries are written correctly at the correct batch intervals

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```
''' 
Modified from tensorboard tutorial
https://www.tensorflow.org/tensorboard/image_summaries
'''
import io
import itertools
from datetime import datetime

import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf
import tensorflow.keras as keras

# Define callback batch intervals
tb_callback_interval = 2
lambda_callback_interval = 10


fashion_mnist = keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = \
    fashion_mnist.load_data()

logdir = ""runs/bug_test/"" + datetime.now().strftime(""%Y%m%d-%H%M%S"")
tensorboard_callback = keras.callbacks.TensorBoard(
    log_dir=logdir, update_freq=tb_callback_interval)
file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')


def log_image(batch, logs):
    tf.print(""Batch: "", batch)
    if batch % lambda_callback_interval == 0:
        with file_writer_cm.as_default():
            status = tf.summary.image(
                ""Confusion Matrix"", tf.expand_dims(test_images[0:5, :, :], -1), step=batch)
            tf.print(""File write status (should be 1): "", status)


cm_callback = keras.callbacks.LambdaCallback(on_batch_end=log_image)

model = keras.models.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)),
    keras.layers.Dense(32, activation='relu'),
    keras.layers.Dense(10, activation='softmax')
])

model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# Train the classifier.
model.fit(
    train_images,
    train_labels,
    epochs=5,
    verbose=1,  # Suppress chatty output
    callbacks=[tensorboard_callback, cm_callback],
    validation_data=(test_images, test_labels),
)
```


**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
