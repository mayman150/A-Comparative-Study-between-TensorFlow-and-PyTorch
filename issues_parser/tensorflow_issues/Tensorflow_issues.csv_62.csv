Issue Number,Issue Title,Issue Body
11401,cuDNN version issues,"I am trying to train a ConvNet on my Windows laptop and I got this error.

Loaded runtime CuDNN library: 5005 (compatibility version 5000) but source was compiled with 5105 (compatibility version 5100).  If using a binary install, upgrade your CuDNN library to match.  If building from sources, make sure the library loaded at runtime matches a compatible version specified during compile configuration.

I am already using cudnn v5.1, so I have no clue why this is happening"
11399,Let string_split support splitting utf-8 characters,"### Describe the problem

Type of issue: feature request

The [string_split](https://www.tensorflow.org/versions/r0.12/api_docs/python/string_ops/splitting) function has (mostly) good behavior when splitting utf-8 strings by single-character delimiter, but fails to do it properly on null-width delimiter because of its documented behavior:

> If delimiter is an empty string, each element of the source is split into individual strings, each containing one byte. (This includes splitting multibyte sequences of UTF-8.)

For models like seq2seq one needs a split function that can split utf-8 strings into individual characters that can be processed by model as units, also embeddings having properly of being easily joined as utf-8 strings.

Could tensorflow provide alternative implementation of string_split that is utf-8 - aware?"
11398,slow cifar10_multi_gpu_train.py stock example and 'Ignoring device specification /device:GPU' warning,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no, using stock example scripts from cifar10
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04.2 LTS inside singularity container using docker image tensorflow:latest-gpu
- **TensorFlow installed from (source or binary)**: docker://tensorflow/tensorflow:latest-gpu (unmodified)
- **TensorFlow version (use command below)**: 

```
Singularity tensorflow.img:~> python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""
('v1.2.0-5-g435cdfc', '1.2.1')
```
- **Python version**: Python 2.7.12
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: cuda 8
- **GPU model and memory**: 2 x K80, 12GB each
- **Exact command to reproduce**:

```
$ python $CIFAR10_DIR/cifar10_multi_gpu_train.py --num_gpus=2 \
                                                 --batch_size=64 \
                                                 --log_device_placement=false \
                                                 --max_steps=10000
```

As a comparison, this one is faster:
```
$ python $CIFAR10_DIR/cifar10_train.py --batch_size=128 \
                                       --log_device_placement=false \
                                       --max_steps=10000
```

### Describe the problem

We have multiGPU systems (8 GPUs with P2P capability) and would like to take advantage of this for faster training but using the stock example cifar10, TensorFlow is even slower when using 2 GPUs than when using a single GPU (`cifar10_train.py`). I tried several batch sizes with no luck. The python process seems CPU bound when using 2 GPUs, so the GPU SMs are far from being busy (~20% usage).

Also, I can see the following warnings:
```
2017-07-09 18:44:15.097496: I tensorflow/core/common_runtime/simple_placer.cc:675] Ignoring device specification /device:GPU:1 for node 'tower_1/fifo_queue_Dequeue' because the input edge from 'prefetch_queue/fifo_queue' is a reference connection and already has a device field set to /device:CPU:0
2017-07-09 18:44:15.097562: I tensorflow/core/common_runtime/simple_placer.cc:675] Ignoring device specification /device:GPU:0 for node 'tower_0/fifo_queue_Dequeue' because the input edge from 'prefetch_queue/fifo_queue' is a reference connection and already has a device field set to /device:CPU:0
```


### Source code / logs

Trace from run:
```
2017-07-09 18:44:13.905522: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-09 18:44:13.905565: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-09 18:44:13.905573: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-07-09 18:44:14.479331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties:
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:06:00.0
Total memory: 11.17GiB
Free memory: 11.11GiB
2017-07-09 18:44:14.821091: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x48f93a0 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-07-09 18:44:14.823728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 1 with properties:
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:07:00.0
Total memory: 11.17GiB
Free memory: 11.11GiB
2017-07-09 18:44:14.827006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 1
2017-07-09 18:44:14.827019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y Y
2017-07-09 18:44:14.827039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 1:   Y Y
2017-07-09 18:44:14.827053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:06:00.0)
2017-07-09 18:44:14.827061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K80, pci bus id: 0000:07:00.0)
2017-07-09 18:44:15.097496: I tensorflow/core/common_runtime/simple_placer.cc:675] Ignoring device specification /device:GPU:1 for node 'tower_1/fifo_queue_Dequeue' because the input edge from 'prefetch_queue/fifo_queue' is a reference connection and already has a device field set to /device:CPU:0
2017-07-09 18:44:15.097562: I tensorflow/core/common_runtime/simple_placer.cc:675] Ignoring device specification /device:GPU:0 for node 'tower_0/fifo_queue_Dequeue' because the input edge from 'prefetch_queue/fifo_queue' is a reference connection and already has a device field set to /device:CPU:0
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-07-09 18:44:20.249834: step 0, loss = 4.68 (53.2 examples/sec; 2.407 sec/batch)
2017-07-09 18:44:21.645904: step 10, loss = 4.62 (4843.2 examples/sec; 0.026 sec/batch)
2017-07-09 18:44:22.487916: step 20, loss = 4.49 (2954.3 examples/sec; 0.043 sec/batch)
2017-07-09 18:44:23.351235: step 30, loss = 4.30 (2900.9 examples/sec; 0.044 sec/batch)
2017-07-09 18:44:24.264403: step 40, loss = 4.39 (2565.3 examples/sec; 0.050 sec/batch)
```"
11396,RecordInput blocks if buffer_size is larger than the amount of files in tfrecords.,"If the `buffer_size` keyword argument in `data_flow_ops.RecordInput(file_pattern, .. buffer_size=buffer_size)` is larger than the amount of files inside of `file_pattern`, the op will block forever.

This is slightly related to #11372, another case where `RecordInput` blocks forever.

Not sure how difficult/possible it would be to check for this or throw an error when this occurs. Feel free to mark this as closed if this is intended behaviour."
11395,Gradients are not registered,"(System information probably is not relevant to the issue, so I moved it below)

## The Problem

It seems that the code, generated by macros `REGISTER_GRADIENT_OP` in [math_grad.cc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/cc/gradients/math_grad.cc) is never executed:
`static bool unused_ret_val_123 = ::tensorflow::ops::GradOpRegistry::Global()->Register(name, fn);`

My `BUILD` file:
```
cc_binary(
    name = ""bitwise_operations"",
    srcs = [
       ""main.cpp""
    ],
    deps = [
        ""//tensorflow/cc:grad_ops"",
        ""//tensorflow/cc:cc_ops"",
        ""//tensorflow/cc:client_session"",
        ""//tensorflow/core:tensorflow"",
        ""//tensorflow/cc/DimanNe/tensorflow_utils:tensorflow_utils"",
    ],
)
```

## The cause

`Bazel` generates such `tensorflow/bazel-out/local-dbg/bin/tensorflow/cc/DimanNe/bitwise_operations/bitwise_operations-2.params` that instructs linker to put `math_grad.pic.o` in separate static library, here is how it looks in the params file containing linking instructions:
```
--start-lib
bazel-out/local-dbg/bin/tensorflow/cc/_objs/real_math_grad/tensorflow/cc/gradients/real_math_grad.pic.o
--end-lib
```
And [here1](https://www.google.ru/search?q=global+symbols+in+static+libraries&oq=global+symbols+in+static+libraries&aqs=chrome..69i57.7343j0j7&client=ubuntu&sourceid=chrome&ie=UTF-8#newwindow=1&q=global+initializer+in+static+libraries)/[here2](https://stackoverflow.com/questions/9459980/c-global-variable-not-initialized-when-linked-through-static-libraries-but-ok) you can find a lot of complaints about static global variables not being initialized, being linked as static libraries.


## The solution
Add `alwayslink = 1,` to `math_grad` library in `tensorflow/cc/BUILD` (and actually any *_grad library, since all of them use the same mechanism of registration of gradients).
Exactly the same has already been done here - `tensorflow/core/BUILD`.

It the solution is OK, I can make a pull-request.

## System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Kubuntu 17.04
- **TensorFlow installed from (source or binary)**:
Compiled from sources
- **TensorFlow version (use command below)**:
`remotes/origin/r1.2`
- **Python version**: 
Do not use it
- **Bazel version (if compiling from source)**:
$ bazel version
Build label: 0.5.1
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Tue Jun 6 10:34:11 2017 (1496745251)
Build timestamp: 1496745251
Build timestamp as int: 1496745251
- **CUDA/cuDNN version**:
no cude
- **GPU model and memory**:
01:00.0 VGA compatible controller: NVIDIA Corporation GK106 [GeForce GTX 650 Ti Boost] (rev a1)
- **Exact command to reproduce**:"
11391,""" argument unused '-mcpu=native' "" makes logs 3 times larger","### System information

- macOS 10.12.4
- Building from source according to the docs
- 'v1.2.0-1874-g75f56f0bd' 1.2.1
- Python 3.6.1 :: Anaconda 4.4.0 (x86_64)
- bazel: stable 0.5.2
- no cuda
- clang: Apple LLVM version 8.1.0 (clang-802.0.42)

### Description

When building TF on macOS I get lots of these warnings:
```
clang: warning: argument unused during compilation: '-mcpu=native' [-Wunused-command-line-argument]
```
It makes the log three times larger
Is it clang only issue? How to fix it? Is it enough just to check [here](https://github.com/tensorflow/tensorflow/blob/master/configure#L301-L306) if compiler is clang?

"
11390,"I used TensorFlow to build a deep learning training network and test network, and I was going to use the weights in the training network to use as the weight of the test network, where the training network and the test network were not the same, how should I solve?","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
11389,CUDA_ERROR_LAUNCH_FAILED,"I'm useing CNN like Tutorials
tensorflow-gpu 1.2.1
CUDA Toolkit 8.0
cuDNN 5.1
python 3.5.2
windows10
![image](https://user-images.githubusercontent.com/15059661/27991248-2b1ca360-64a3-11e7-802e-d50dd64acc64.png)
when it run :
> 2017-07-09 11:51:59.107178: W c:\tf_jenkins\home\workspace\release-win\m\windows-gpu\py\35\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE instructions, but these are available on your machine and could speed up CPU computations.
2017-07-09 11:51:59.107569: W c:\tf_jenkins\home\workspace\release-win\m\windows-gpu\py\35\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE2 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-09 11:51:59.107982: W c:\tf_jenkins\home\workspace\release-win\m\windows-gpu\py\35\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-09 11:51:59.108244: W c:\tf_jenkins\home\workspace\release-win\m\windows-gpu\py\35\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-09 11:51:59.108549: W c:\tf_jenkins\home\workspace\release-win\m\windows-gpu\py\35\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-09 11:51:59.109679: W c:\tf_jenkins\home\workspace\release-win\m\windows-gpu\py\35\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-07-09 11:51:59.408255: I c:\tf_jenkins\home\workspace\release-win\m\windows-gpu\py\35\tensorflow\core\common_runtime\gpu\gpu_device.cc:940] Found device 0 with properties: 
name: GeForce GTX 1080 Ti
major: 6 minor: 1 memoryClockRate (GHz) 1.721
pciBusID 0000:01:00.0
Total memory: 11.00GiB
Free memory: 9.12GiB
2017-07-09 11:51:59.408712: I c:\tf_jenkins\home\workspace\release-win\m\windows-gpu\py\35\tensorflow\core\common_runtime\gpu\gpu_device.cc:961] DMA: 0 
2017-07-09 11:51:59.408892: I c:\tf_jenkins\home\workspace\release-win\m\windows-gpu\py\35\tensorflow\core\common_runtime\gpu\gpu_device.cc:971] 0:   Y 
2017-07-09 11:51:59.409056: I c:\tf_jenkins\home\workspace\release-win\m\windows-gpu\py\35\tensorflow\core\common_runtime\gpu\gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0)
3153
2017-07-09 11:52:04.245057: E c:\tf_jenkins\home\workspace\release-win\m\windows-gpu\py\35\tensorflow\stream_executor\cuda\cuda_driver.cc:1068] failed to synchronize the stop event: CUDA_ERROR_LAUNCH_FAILED
2017-07-09 11:52:04.245474: E c:\tf_jenkins\home\workspace\release-win\m\windows-gpu\py\35\tensorflow\stream_executor\cuda\cuda_timer.cc:54] Internal: error destroying CUDA event in context 000001A873C64B60: CUDA_ERROR_LAUNCH_FAILED
2017-07-09 11:52:04.245791: E c:\tf_jenkins\home\workspace\release-win\m\windows-gpu\py\35\tensorflow\stream_executor\cuda\cuda_timer.cc:59] Internal: error destroying CUDA event in context 000001A873C64B60: CUDA_ERROR_LAUNCH_FAILED
2017-07-09 11:52:04.246154: F c:\tf_jenkins\home\workspace\release-win\m\windows-gpu\py\35\tensorflow\stream_executor\cuda\cuda_dnn.cc:1961] failed to enqueue convolution on stream: CUDNN_STATUS_MAPPING_ERROR
[Finished in 19.7s]

if i use tensorflow without gpu, it's ok
"
11388,[Feature Request] Tensor::DebugString for GPU backed tensors,Currently it crashes when calling ``Tensor::SummarizeValue`` and ``Tensor::DebugString`` in GPU backed tensors. I am wondering if there is a better way to debug when writing GPU code.
11387,Unable to install Tensorflow on Windows - Anaconda error trace,"I posted this issue on Stack Overflow, I seem to always have problems related to Anaconda dependencies, even related to my Mac. I'm on Python 3.6 which came with an auto-install when I installed Visual Studio. Do I just need to downgrade to get this to work? I'm also on the latest version of CUDA/cuDNN and have a TitanX. 

I'm on a new PC deep learning rig now, and installed CUDA, afterward I ran some of the pip install commands. I received the error below. 

`python -m pip install --upgrade pip`

Then this printed out:

`Successfully built protobuf markdown html5lib
Installing collected packages: protobuf, backports.weakref, html5lib, bleach, ma                               rkdown, tensorflow
Exception:
Traceback (most recent call last):
  File ""C:\Program Files\Anaconda3\lib\site-packages\pip\basecommand.py"", line 2                               15, in main
    status = self.run(options, args)
  File ""C:\Program Files\Anaconda3\lib\site-packages\pip\commands\install.py"", l                               ine 342, in run
    prefix=options.prefix_path,
  File ""C:\Program Files\Anaconda3\lib\site-packages\pip\req\req_set.py"", line 7                               84, in install
    **kwargs
  File ""C:\Program Files\Anaconda3\lib\site-packages\pip\req\req_install.py"", li                               ne 851, in install
    self.move_wheel_files(self.source_dir, root=root, prefix=prefix)
  File ""C:\Program Files\Anaconda3\lib\site-packages\pip\req\req_install.py"", li                               ne 1064, in move_wheel_files
    isolated=self.isolated,
  File ""C:\Program Files\Anaconda3\lib\site-packages\pip\wheel.py"", line 345, in                                move_wheel_files
    clobber(source, lib_dir, True)
  File ""C:\Program Files\Anaconda3\lib\site-packages\pip\wheel.py"", line 323, in                                clobber
    shutil.copyfile(srcfile, destfile)
  File ""C:\Program Files\Anaconda3\lib\shutil.py"", line 115, in copyfile
    with open(dst, 'wb') as fdst:
PermissionError: [Errno 13] Permission denied: 'C:\\Program Files\\Anaconda3\\Li                               b\\site-packages\\protobuf-3.3.0-py3.6-nspkg.pth'
`
"
11384,Upgrading to 1.2 Causes Issue with CUDA,"I don't know how to describe my problem any better than that, unfortunately. Previously, I was running TensorFlow 1.0, and I could successfully use CUDA:

```
ubuntu@ip-10-0-2-117:~$ /usr/bin/python2.7 /home/ubuntu/src/tensorflow/tensorflow/examples/tutorials/mnist/fully_connected_feed.py
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.7.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.7.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.7.5 locally
Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.
Extracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz
Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.
Extracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz
Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.
Extracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz
Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.
Extracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:1e.0
Total memory: 11.17GiB
Free memory: 11.11GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0)
Step 0: loss = 2.32 (0.463 sec)
```

etc. However, my new code relies on TensorFlow 1.2, so I upgraded. However, this seems to have somehow disconnected TensorFlow from CUDA:

```
ubuntu@ip-10-0-2-117:~/deep-basecaller$ /usr/bin/python2.7 /home/ubuntu/src/tensorflow/tensorflow/examples/tutorials/mnist/fully_connected_feed.py
Extracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz
Extracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz
Extracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz
Extracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz
2017-07-08 18:27:35.208170: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-08 18:27:35.208209: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-08 18:27:35.208218: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-07-08 18:27:35.208225: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-08 18:27:35.208234: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
Step 0: loss = 2.31 (0.098 sec)
```

What can I do to fix this problem?"
11383,Feeding TensorArray when running a session using feed_dict,"Currently there is no way to define a placeholder for a `tf.TensorArray`. A solution is to zero-pad a `tf.Tensor` and then unstack and slice it into a `tf.TensorArray`. However, this adds unpadding overhead which would have to be done for every batch.

A possible change would be to add a new placeholder type for feeding a `tf.TensorArray` to the graph, for example called `tf.tensor_array_placeholder`.

This could work as follows:
```python
# Define an input TensorArray with three elements
ta_input = tf.tensor_array_placeholder(dtype=tf.float32, size=3)
# Take the second element from the TensorArray
ta_second = ta.read(1)
# Sum its values
result = tf.reduce_sum(ta_second)

with tf.Session() as sess:
    run_result = sess.run(
        [result],
        # Feed raw values into ta_input. These could also be NumPy arrays
        { ta_input: [[1, 2, 3], [4, 5], [6, 7, 8, 9]] })

   print(run_result)  # Should print 9
```"
11380,Error while slicing with int64,"This is similar to #11318 but with a slice instead of an individual index. I upgraded to the latest version using `pip3 install --user --upgrade tensorflow-gpu`.

```
>>> import tensorflow as tf
>>> tf.__version__
'1.2.1'
>>> i = tf.constant(1, dtype=tf.int64)
>>> a[i:i+1]
<long stack trace>
TypeError: Input 'strides' of 'StridedSlice' Op has type int32 that does not match type int64 of argument 'begin'.
```"
11379,TFrecord reading time very high ,"#I have divided a dataset into 10 tfrecords files and I want to read 100 data points from each to create a batch of 10 sequence of 100 data points. I use the following function to do that. The data loading time from the tfrecords start off slow and then reaches to around 0.65s and after 100-200 sess.run calls it increases to around 10s. Can you please point out any mistake or suggestion which might help to reduce the read time ? Also, the behaviour I mentioned becomes more erratic sometimes.

    def get_data(mini_batch_size):
      data = []
      for i in range(mini_batch_size):
        filename_queue = tf.train.string_input_producer([data_path + 'Features' + str(i) + '.tfrecords'])
        reader = tf.TFRecordReader()
        _, serialized_example = reader.read(filename_queue)
        batch_serialized_example = tf.train.batch([serialized_example], batch_size=step_size, num_threads=8, capacity=step_size)
        features = tf.parse_example(batch_serialized_example,features={'feature_raw': tf.VarLenFeature(dtype=tf.float32)})
        feature = features['feature_raw'].values
        feature = tf.reshape(feature,[step_size, ConvLSTM.H, ConvLSTM.W, ConvLSTM.Di])
        data.append(feature)
      return tf.stack(data)
"
11376,py_func does not properly,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 14.04
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
1.2
- **Python version**: 
3.6
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
Cudnn v5.1
- **GPU model and memory**:
Pascal Titan X
- **Exact command to reproduce**:
```
import tensorflow as tf
import numpy as np

def fun(x):
    return np.ones([5]), np.ones([5])


aa, b = tf.py_func(fun, [1], tf.uint8)
```

### Describe the problem
The `py_func` does work properly

### Source code / logs
```
Traceback (most recent call last):
  File ""test.py"", line 9, in <module>
    a, b = ab
  File ""/home/jrmei/lib/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 541, in __iter__
    raise TypeError(""'Tensor' object is not iterable."")
TypeError: 'Tensor' object is not iterable.
```
"
11375,"tensorflow-""ValueError: Operation 'init' has been marked as not fetchable"" Plz Help","I started working with LSTMs for conversation modelling. I have got a sample piece of code with a persistent error. The code is given below.

'''
A Dynamic Recurrent Neural Network (LSTM) implementation example using
TensorFlow library. This example is using a toy dataset to classify linear
sequences. The generated sequences have variable length.
Long Short Term Memory paper: http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf
Author: Aymeric Damien
Project: https://github.com/aymericdamien/TensorFlow-Examples/
'''

from __future__ import print_function

import tensorflow as tf
import random
data_path=""C:/Users/AnacondaProjects/Convmodels/CleanedData/embeddings/""


# ====================
#  TOY DATA GENERATOR
# ====================
class ToySequenceData(object):
    def __init__(self, n_samples=100, max_seq_len=10, min_seq_len=2):
        self.data = []
        self.labels = []
        self.seqlen = []
        dummy_vector=[float(0.0) for i in range(300)]
        for i in range(n_samples):
            with open(data_path+str(i)+"".txt"",""r"",encoding=""utf-8"") as inp:
                input_line=[[float(i) for i in line.split()] for line in inp]
                current_input=[]
                for j in range(min(10,len(input_line)-1)):
                    current_input.append(input_line[j])
                    temp_data=current_input[:]
                    temp_data=temp_data+[dummy_vector[:] for k in range(max_seq_len-j-1)]
                    current_input=temp_data[:]
                    self.data.append(temp_data)
                    self.labels.append(input_line[j+1])
                    self.seqlen.append(j+1)
                i=i+(min(10,len(input_line)-1)-1)
        self.batch_id = 0

    def next(self, batch_size):
        """""" Return a batch of data. When dataset end is reached, start over.
        """"""
        if self.batch_id == len(self.data):
            self.batch_id = 0
        batch_data = (self.data[self.batch_id:min(self.batch_id +
                                                  batch_size, len(self.data))])
        batch_labels = (self.labels[self.batch_id:min(self.batch_id +
                                                  batch_size, len(self.data))])
        batch_seqlen = (self.seqlen[self.batch_id:min(self.batch_id +
                                                  batch_size, len(self.data))])
        self.batch_id = min(self.batch_id + batch_size, len(self.data))
        return batch_data, batch_labels, batch_seqlen


# ==========
#   MODEL
# ==========

# Parameters
learning_rate = 0.01
training_iters = 1000
batch_size = 128
display_step = 10

# Network Parameters
seq_max_len = 10 # Sequence max length
n_hidden = 64 # hidden layer num of features
n_classes = 300 # linear sequence or not

trainset = ToySequenceData(n_samples=100, max_seq_len=seq_max_len)
testset = ToySequenceData(n_samples=20, max_seq_len=seq_max_len)

# tf Graph input
x = tf.placeholder(""float"", [None, seq_max_len, n_classes])
y = tf.placeholder(""float"", [None, n_classes])
# A placeholder for indicating each sequence length
seqlen = tf.placeholder(tf.int32, [None])

# Define weights
Weights = {
    'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))
}
Biases = {
    'out': tf.Variable(tf.random_normal([n_classes]))
}


def dynamicRNN(x, seqlen, Weights, Biases):

    # Prepare data shape to match `rnn` function requirements
    # Current data input shape: (batch_size, n_steps, n_input)
    # Required shape: 'n_steps' tensors list of shape (batch_size, n_input)
    
    # Unstack to get a list of 'n_steps' tensors of shape (batch_size, n_input)
    x = tf.unstack(x, seq_max_len, 1)
    
    # Define a lstm cell with tensorflow
    with tf.variable_scope('lstm_cell_def'):
        lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden)

    # Get lstm cell output, providing 'sequence_length' will perform dynamic
    # calculation.
    with tf.variable_scope('rnn_cell_def',reuse=True): 
        outputs, states = tf.contrib.rnn.static_rnn(lstm_cell, x, dtype=tf.float32,
                            sequence_length=seqlen)

    # When performing dynamic calculation, we must retrieve the last
    # dynamically computed output, i.e., if a sequence length is 10, we need
    # to retrieve the 10th output.
    # However TensorFlow doesn't support advanced indexing yet, so we build
    # a custom op that for each sample in batch size, get its length and
    # get the corresponding relevant output.

    # 'outputs' is a list of output at every timestep, we pack them in a Tensor
    # and change back dimension to [batch_size, n_step, n_input]
    outputs = tf.stack(outputs)
    outputs = tf.transpose(outputs, [1, 0, 2])

    # Hack to build the indexing and retrieve the right output.
    batch_size = tf.shape(outputs)[0]
    # Start indices for each sample
    index = tf.range(0, batch_size) * seq_max_len + (seqlen - 1)
    # Indexing
    outputs = tf.gather(tf.reshape(outputs, [-1, n_hidden]), index)

    # Linear activation, using outputs computed above
    return tf.matmul(outputs, Weights['out']) + Biases['out']

pred = dynamicRNN(x, seqlen, Weights, Biases)

# Define loss and optimizer
cos_dist=tf.losses.cosine_distance(predictions=pred,labels=y,dim=1)
#cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))
optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cos_dist)

# Evaluate model
#correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))
normalize_pred = tf.nn.l2_normalize(pred,1)        
normalize_y = tf.nn.l2_normalize(y,1)
correct_pred=(1+tf.reduce_sum(tf.multiply(normalize_pred,normalize_y)))/2
accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))

# Initializing the variables
init = tf.global_variables_initializer()

# Launch the graph
with tf.Session() as sess:
    sess.run(init)
    step = 1
    # Keep training until reach max iterations
    while step * batch_size < training_iters:
        batch_x, batch_y, batch_seqlen = trainset.next(batch_size)
        # Run optimization op (backprop)
        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y,
                                       seqlen: batch_seqlen})
        if step % display_step == 0:
            # Calculate batch accuracy
            acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y,
                                                seqlen: batch_seqlen})
            # Calculate batch loss
            loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y,
                                             seqlen: batch_seqlen})
            print(""Iter "" + str(step*batch_size) + "", Minibatch Loss= "" + \
                  ""{:.6f}"".format(loss) + "", Training Accuracy= "" + \
                  ""{:.5f}"".format(acc))
        step += 1
    print(""Optimization Finished!"")

    # Calculate accuracy
    test_data = testset.data
    test_label = testset.labels
    test_seqlen = testset.seqlen
    print(""Testing Accuracy:"", \
        sess.run(accuracy, feed_dict={x: test_data, y: test_label,
                                      seqlen: test_seqlen}))

When I run this, it get "" ValueError: Operation 'init' has been marked as not fetchable "" and pointing to line: "" sess.run(init) "" Please kindly help! Thanks in advance."
11374,bazel build //tensorflow/examples/android:tensorflow_demo,"when i run  bazel build //tensorflow/examples/android:tensorflow_demo.i get the result as follow:

INFO: Found 1 target...
ERROR: missing input file '@androidsdk//:build-tools/24.0.3/lib/dx.jar'.
ERROR: /home/zhu/tensorflow/tensorflow/examples/android/BUILD:63:1: //tensorflow/examples/android:tensorflow_demo: missing input file '@androidsdk//:build-tools/24.0.3/lib/dx.jar'.
Target //tensorflow/examples/android:tensorflow_demo failed to build
Use --verbose_failures to see the command lines of failed build steps.
ERROR: /home/zhu/tensorflow/tensorflow/examples/android/BUILD:63:1 1 input file(s) do not exist.
INFO: Elapsed time: 18.794s, Critical Path: 0.60s
"
11373,[Slim] Training accuracy is increasing very slowly,"Hi,

I feel something odd is happening with my Inception_Resnet_v2 training. I am what I'm seeing is correct but it seems the training will take forever at the current rate. 

I am training slim against the full Imagenet dataset approx 14M images. The training is running on 8GPUs and the batch size is the default 32. If my calculations are correct this means that each epoch should consist of approximately (54,000 steps):

14,000,000 / (8 * 32) 

The training has been running for 800,000 steps so far (approx 15 epochs) yet the accuracy just reached 22%.

I have been evaluating the model after each 100,000 steps and at the start, the accuracy used to increase by 5% after each 100,000 step up until 500,000 steps, yet now it seems to be rapidly slowing down as now I am getting in approximate 0.8% increase every 100,000 steps after reaching the 500,000 steps mark.

I am not sure if this is expected as I do not have any data to compare it with but at this rate it can take several months, maybe even years to reach a viable accuracy rate. I am trying to reach somewhere above 70% at least.

Now is this expected? Are there any ways to speed up training beside adding GPUs? And if the latter is my only option, is it possible to continue training on the same checkpoints once the number of GPUs has increased?

"
11372,RecordInput blocks if file_pattern returns no files.,"The `tensorflow.python.ops.data_flow_ops.RecordInput()` blocks forever if the first input argument with keyword `file_pattern` is a pattern that does not point to (an) existing file(s).

It does not seem to be waiting for that file to appear either, because if I make it appear after the launch it's still blocked, leading me to believe this is a bug.

Reproduce:
```python
sess = tf.Session()
record_input = data_flow_ops.RecordInput(file_pattern=""foo"")
yield_op = record_input.get_yield_op()
sess.run(tf.global_variables_initializer())
sess.run(yield_op)
```"
11371,"Placeholder with shape=(None, 1024) gives an error when used with tf.cond","I'm using TensorFlow v1.2.0. Here is a simple example that shows the problem.
If a dimension of a placeholder is None I get the following error:

```
InvalidArgumentError (see above for traceback): Shape [-1,1024] has negative dimensions
	 [[Node: cond/Placeholder = Placeholder[dtype=DT_FLOAT, shape=[?,1024], _device=""/job:localhost/replica:0/task:0/cpu:0""](^cond/switch_t)]]
```

If I set the shape to None or to (1024, 1024) it gives no error. 

```
import numpy as np
import tensorflow as tf

rand_array = np.random.rand(1024, 1024)

x_c = tf.constant(rand_array, dtype=tf.float32)

py_flag = False
flag = tf.constant(py_flag, tf.bool)

def pl():
    return tf.placeholder(dtype=tf.float32, shape=(None, 1024))

x = tf.cond(flag, pl, lambda: x_c)

y = tf.matmul(x, x)

with tf.Session() as sess:
    if py_flag:
        print(sess.run(y, feed_dict={x: rand_array}))
    else:
        print(sess.run(y))
```"
11370,Feature Request: Include Depthwise Convolution in graph_transforms fold_batch_norms,"Hi!

Currently, the graph_transforms tool includes only `Conv2D` and `MatMul` ops when folding batch normalization scaling/multiplication into its weights, as in `fold_batch_norms.cc`. Google's Mobilenet example uses depthwise convolution extensively, so it would be nice to include this feature for the `DepthwiseConv2dNative` operation. The problem here is that weights are ordered differently for this operation and contain the `channel_muliplier` which would need to be checked when trying to bake subsequent multiplications. 
"
11369,TFRecord parse multiple times using parse_example,"In order to parse a sequence of example, I am using the following code in tensorflow.
    
    sequence_len = 10
    filename_queue = tf.train.string_input_producer(['foo.tfrecords'])
    reader = tf.TFRecordReader()
    _, seralized_example = reader.read_up_to(filename_queue,sequence_len)
    features = tf.parse_example(seralized_example,features={'feature_raw': tf.VarLenFeature(dtype=tf.float32)})
    feature = features['feature_raw'].values

This will give me a sequence of 10 examples. But I want to read the first 10 example sequence in on gpu the next one in the next gpu and so on. However, when I do that using tf.device() as follows, I get the same data in all the gpus. 
    
    sequence_len = 10
    data = []
    filename_queue = tf.train.string_input_producer(['foo.tfrecords'])
    reader = tf.TFRecordReader()
    for g in range(num_gpus):
      with tf.device('/gpu:%d' % g):
        _, seralized_example = reader.read_up_to(filename_queue,sequence_len)
        features = tf.parse_example(seralized_example,features={'feature_raw': tf.VarLenFeature(dtype=tf.float32)})
        feature = features['feature_raw'].values
        data.append(feature)

How to deal with this ?


"
11368,Feature : Tensorflow works on ubuntu12.04,"Hi,all:
I have a computing cluster,with a master and some slaves. 
I want to tran the AI model on master, and then send to slaves for calculation。
But，for some reason, part of slaves works on ubuntu12.04, and i can not update them to 14.04. 
so, how can i get a lite tensorflow or a saved model lib, than can be restored on ubuntu12.04 slaves.
Many thanks!"
11367,"saver will cause crash,error message:""InvalidArgumentError: Shape [xx] has negative dimensions""","### It should be a bug of tensorflow
add the saver will cause the procedure crash. error message is strange, as following:
_### InvalidArgumentError (see above for traceback): Shape [-1,32,32,3] has negative dimensions
	 [[Node: x = Placeholder[dtype=DT_FLOAT, shape=[?,32,32,3], _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]_

the added part is:
            if (i % 1000 == 0) or (i == num_iterations - 1):
                # Save all variables of the TensorFlow graph to a
                # checkpoint. Append the global_step counter
                # to the filename so we save the last several checkpoints.
                saver.save(sess,
                           save_path=save_dir,
                           global_step=train_step)

### System information
== cat /etc/issue ===============================================
Darwin zhangdeMacBook-Pro.local 16.6.0 Darwin Kernel Version 16.6.0: Fri Apr 14 16:21:16 PDT 2017; root:xnu-3789.60.24~6/RELEASE_X86_64 x86_64
Mac OS X 10.12.5

== are we in docker =============================================
No

== compiler =====================================================
Apple LLVM version 8.1.0 (clang-802.0.42)
Target: x86_64-apple-darwin16.6.0
Thread model: posix
InstalledDir: /Library/Developer/CommandLineTools/usr/bin

== uname -a =====================================================
Darwin zhangdeMacBook-Pro.local 16.6.0 Darwin Kernel Version 16.6.0: Fri Apr 14 16:21:16 PDT 2017; root:xnu-3789.60.24~6/RELEASE_X86_64 x86_64

== check pips ===================================================
numpy (1.13.0)
protobuf (3.3.0)
tensorflow (1.2.1)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.2.1
tf.GIT_VERSION = v1.2.0-5-g435cdfc
tf.COMPILER_VERSION = v1.2.0-5-g435cdfc
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================

== cuda libs  ===================================================

Tensorflow version:
v1.2.0-5-g435cdfc 1.2.1




### Source code / logs
source code:
```python
#coding=utf-8
import tensorflow as tf
import numpy as np
import cifar10
import preprocess
from six.moves import xrange
import os

img_size = 32
img_height = img_size
img_width = img_size
img_channel = 3

first_conv_feamap = 16
filter_size = 5
pool_size = 4

second_conv_feamap = 32

fcn1_size = 1024

epoch = 60
batch_size = 50


def weight_variable(shape):
    """"""weight_variable generates a weight variable of a given shape.""""""
    initial = tf.truncated_normal(shape, stddev=0.1)
    return tf.Variable(initial)

def bias_variable(shape):
    initial = tf.constant(0.1,shape=shape)
    return tf.Variable(initial)

def conv2d(x, W):
  """"""conv2d returns a 2d convolution layer with full stride.""""""
  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')

def max_pool_2x2(x):
  """"""max_pool_2x2 downsamples a feature map by 2X.""""""
  #ksize是窗口大小，stride是步长，4->1步长正好是2
  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],
                        strides=[1, 2, 2, 1], padding='SAME')


def sequence_batch(images, labels, idx,_batch_size):

    # Use the random index to select random images and labels.
    x_batch = images[idx:idx+_batch_size, :, :, :]
    y_batch = labels[idx:idx+_batch_size, :]

    return x_batch, y_batch

#Procedure start now!

images,training_class,labels = cifar10.load_training_data()

test_images,test_class,test_labels = cifar10.load_test_data()


log_dir = os.getcwd() + '/log'
print('log_dir is ' + log_dir)
if not os.path.exists(log_dir):
    os.makedirs(log_dir)


save_dir = os.getcwd() + '/checkpoints'
print('save_dir is ' + save_dir)
if not os.path.exists(save_dir):
    os.makedirs(save_dir)


x = tf.placeholder(tf.float32, shape=[None,img_height,img_width,img_channel], name='x')
y_ = tf.placeholder(tf.float32, shape=[None, 10], name='y_')
y_cls = tf.argmax(y_, dimension=1)

x = tf.reshape(x, shape=[-1, img_height, img_width, img_channel])

with tf.name_scope('conv1'):
    w_conv1 = weight_variable([filter_size, filter_size, img_channel, first_conv_feamap])
    b_conv1 = bias_variable([first_conv_feamap])

    h_conv1 = tf.nn.relu(conv2d(x, w_conv1) + b_conv1)
    h_pool1 = max_pool_2x2(h_conv1)

with tf.name_scope('conv2'):
    w_conv2 = weight_variable([filter_size, filter_size, first_conv_feamap, second_conv_feamap])
    b_conv2 = bias_variable([second_conv_feamap])

    h_conv2 = tf.nn.relu(conv2d(h_pool1, w_conv2) + b_conv2)
    h_pool2 = max_pool_2x2(h_conv2)

conv2_size = 8

with tf.name_scope('fcn1'):
    w_fcn1 = weight_variable([conv2_size * conv2_size * second_conv_feamap, fcn1_size])
    b_fcn1 = bias_variable([fcn1_size])

    # change with the image size and convlo
    h_pool2_flat = tf.reshape(h_pool2, [-1, conv2_size * conv2_size * second_conv_feamap])
    h_fcn1 = tf.nn.relu(tf.matmul(h_pool2_flat, w_fcn1) + b_fcn1)

    keep_prob = tf.placeholder(tf.float32)
    h_fcn1_drop = tf.nn.dropout(h_fcn1, keep_prob)

with tf.name_scope('fcn2'):
    w_fcn2 = weight_variable([fcn1_size, 10])
    b_fcn2 = bias_variable([10])

    y_cnn = tf.matmul(h_fcn1_drop, w_fcn2) + b_fcn2



cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_,logits=y_cnn))

train_step = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cross_entropy)

correct_prediction = tf.equal(tf.arg_max(y_cnn,1),tf.arg_max(y_,1))

accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))



saver = tf.train.Saver()



with tf.Session() as sess:
    init = tf.global_variables_initializer()
    sess.run(init)


    num_iterations = int(len(images)/batch_size)

    idx = 0

    for j in xrange(60):
        for i in xrange(num_iterations):


            x_batch,y_batch = sequence_batch(images,labels,idx,batch_size)

            print(""x_batch shape: "" + str(x_batch.shape))
            print(""y_batch shape: "" + str(y_batch.shape))

            train_step.run(
                feed_dict={
                    x: x_batch,
                    y_: y_batch,
                    keep_prob: 0.5
                }
            )

            idx = idx + batch_size

            if i%100 == 0:
                training_feed_dict = {
                    x: images,
                    y_: labels,
                    keep_prob: 1.0
                }

                test_feed_dict = {
                    x: test_images,
                    y_: test_labels,
                    keep_prob: 1.0
                }



                train_accuracy = accuracy.eval(
                    feed_dict=training_feed_dict
                )
                print('step %d, training accuracy %g' % (i, train_accuracy))

                test_accuracy = accuracy.eval(
                    feed_dict=test_feed_dict
                )
                print('step %d, test accuracy %g' % (i, test_accuracy))

            if (i % 1000 == 0) or (i == num_iterations - 1):
                # Save all variables of the TensorFlow graph to a
                # checkpoint. Append the global_step counter
                # to the filename so we save the last several checkpoints.
                saver.save(sess,
                           save_path=save_dir,
                           global_step=train_step)

                print(""Saved checkpoint."")


    print('test accuracy in every epoch %g' % accuracy.eval(
        feed_dict={
            x: test_images,
            y_: test_labels,
            keep_prob: 1.0
        }
        )
    )

```




"
11366,Problems with AOT-Compiled Inception V3 model (runtime crash / nonsense output),"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS X 10.12.5
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: ('v1.2.0-rc2-21-g12f033d', '1.2.0')
- **Python version**: 2.7.13
- **Bazel version (if compiling from source)**: bazel release 0.5.1-homebrew
- **CUDA/cuDNN version**: n/a (CPU only build)
- **GPU model and memory**: n/a
- **Exact command to reproduce**: See description below.

### Describe the problem
I've successfully built the AOT compiler and all its tests pass fine. I'm trying to do the analogous thing as in the matmul example to build an AOT-compiled library for a frozen Inception V3 graph: specifically, `inception_v3_2016_08_28_frozen.pb`, which I hope to incorporate into my larger C++ project.

The bazel build goes fine, and I get a (large) library and header file. I can successfully compile and link that into my larger project. When I `Run()` it, however, I get a `EXC_BAD_ACCESS` on this line of disassembly:
```
0x10143f55f <+143>: movq   (%rax), %rax
```
with this stack trace from a call to `Run()`:
```
#0	0x000000010143f55f in Eigen::TensorEvaluator<Eigen::TensorContractionOp<Eigen::array<Eigen::IndexPair<long long>, 1ul> const, Eigen::TensorReshapingOp<Eigen::DSizes<long long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorReshapingOp<Eigen::DSizes<long long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>::Context<Eigen::internal::gemm_pack_lhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 4, true, false, 0, Eigen::MakePointer>, 8, 4, 0, false, false>, Eigen::internal::gemm_pack_rhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 4, true, false, 0, Eigen::MakePointer>, 4, 0, false, false>, Eigen::internal::gebp_kernel<float, float, long, Eigen::internal::blas_data_mapper<float, long, 0, 0>, 8, 4, false, false>, Eigen::internal::TensorContractionInputMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 4, true, false, 0, Eigen::MakePointer>, Eigen::internal::TensorContractionInputMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 4, true, false, 0, Eigen::MakePointer>, Eigen::internal::blas_data_mapper<float, long, 0, 0> >::enqueue_packing_helper(long, long, long, bool) ()
#7	0x00000001012ff70b in __tensorflow_aot_test__aot_test ()
```

Furthermore, when I write my own simple binary, separate from my larger project, along the lines of the matmul test example for AOT, I can build and run it without the above crash, but no matter what input I feed in, I get the same output: the 1001-element results vector is all zeros except entry 429, which is exactly 1.0. My guess was that the image data I'm feeding in was somehow garbage, but I've verified (?) that I can read in the same binary blob of pre-processed image data in Matlab and it looks reasonable. (Pre-processing here includes resizing the image to the required size (299x299), dividing each element by 255, and storing as floats.)

Is something going wrong in AOT-compiling the graph here, or am I doing something wrong or missing something totally stupid? Is there something used in the Inception architecture that's not supported? Should I be trying with another frozen graph? Note that I'm on the `r1.2` branch, but may try switching to master next to see if it's something that's been changed/fixed since `r1.2`. See below for source. 

### Source code / logs

`BUILD` file for my `aot_test` library and a simple binary to run it:
```
load(""//tensorflow/compiler/aot:tfcompile.bzl"", ""tf_library"")

tf_library(
    name = ""aot_test"",
    cpp_class = ""TF_TestAOT"",
    graph = ""inception_v3_2016_08_28_frozen.pb"",
    config = ""aot_test.config.pbtxt"",
)

cc_binary(
    name = ""my_binary"",
    srcs = [
        ""my_binary.cc"", 
    ],
    deps = [
        "":aot_test"",  
        ""//third_party/eigen3"",
    ],
    # I've tried with or without this
    #linkopts = [
    #      ""-lpthread"",
    #]
)
```

Contents of `aot_test.config.pbtxt` referenced above:
```
feed {
  id { node_name: ""input"" }
  shape {
    dim { size: 1   }
    dim { size: 299 }
    dim { size: 299 }
    dim { size: 3   }
  }
}

fetch {
  id { node_name: ""InceptionV3/Predictions/Reshape_1"" }
}
```

Contents of `my_binary.cc` referenced above:
```
#define EIGEN_USE_THREADS
#define EIGEN_USE_CUSTOM_THREAD_POOL

#include <cstdlib>
#include <iostream>
#include ""third_party/eigen3/unsupported/Eigen/CXX11/Tensor""
#include ""tensorflow/aot_test/aot_test.h"" // generated

int main(int argc, char** argv) {
  Eigen::ThreadPool tp(1);  // Size the thread pool as appropriate. (I've tried various options here)
  Eigen::ThreadPoolDevice device(&tp, tp.NumThreads());

  TF_TestAOT test;
  test.set_thread_pool(&device);

  // Set up args and run the computation. 
  // Printing out the data shows it is valid. I've also tried random input data and multiple images.
  FILE* file = fopen(""/tmp/img_norm.bin"", ""rb"");
  const size_t n = fread(test.arg0_data(), sizeof(float), 299*299*3, file); 
  fclose(file);
  std::cout << ""Read "" << n << "" floats"" << std::endl;
  
  test.Run();

  std::cout << ""Status: "" << test.error_msg() << std::endl;
  
  // Check result
  const float* output_data = test.result0_data();
  float maxScore = -1.f;
  int maxIndex = -1;
  for(int i=0; i<1001; ++i)
  {
     // If I print this, i'll see all zeros except entry 429, which is one
    //std::cout << ""Score["" << i << ""]="" << output_data[i] << std::endl;
    if(output_data[i] > maxScore)
    {
      maxScore = output_data[i];
      maxIndex = i;
    }
  }

  std::cout << ""Max score = "" << maxScore << "" at index "" << maxIndex << std::endl;

  return 0;
}
```

"
11365,seq2seq.AttentionWrapper cannot implement Bahdanau model (RNNsearch),"
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, but there is no stock example script
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: OSX 10.12.5
- **TensorFlow installed from (source or binary)**: source (via virtualenv/pip3)
- **TensorFlow version (use command below)**:v1.2.0-5-g435cdfc 1.2.1
- **Python version**: 3.6.1
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**:  N/A

### Describe the problem
[RNNsearch](https://arxiv.org/pdf/1409.0473.pdf) has two different RNN cells in it (the encoder and decoder). At a given time step, the inputs to the attention mechanism are all the encoder's outputs (the ""annotations"" in the Bahdanau paper, aka the `memory` of the `BahdanauAttention` constructor) and the decoder's previous state.

Crucially, `AttentionWrapper.call` is running its input through the passed in `cell` before applying `AttentionMechanism` to the cell's output. ([Docstring](https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/AttentionWrapper#call); source confirms this.)

This precludes the encoder cell from being passed to AttentionWrapper, because AttentionWrapper depends on BahdanauAttention, whose `memory` depends on the encoder cell's output. (So you would need to run the encoder once to get the `memory` and `AttentionWrapper` would run it again.)

But the decoder cell can also not be the cell passed in, because in the Bahdanau paper, the decoder's output is not used by the attention mechanism at all. Moreover, neither cell takes the previous step's attention (in Bahdanau).

I'm hoping I've misunderstood, but currently the API doesn't seem like it can be made to align with the paper, which would be sort of curious – but perhaps intentional!

### Source code / logs
    bahdanau = tf.contrib.seq2seq.BahdanauAttention(
        num_units=params['ATTENTION_SIZE'],
        memory=annotations,  # annotations, _ = tf.nn.static_rnn(encoder, time_major_input)
        normalize=False,
        name='BahdanauAttention')
    decoder = tf.nn.rnn_cell.BasicLSTMCell(
        params['DECODER_SIZE'],
        forget_bias=1.0)
    attn_cell = tf.contrib.seq2seq.AttentionWrapper(
        cell=decoder,
        attention_mechanism=bahdanau,
        output_attention=False,
        name=""AttentionWrappedDecoder"")
"
11364,Error on tf.contrib.training.stratified_sample,"I made a small example to illustrate, which makes some synthetic data with unbalanced classes and tries to take balanced samples from it:
```
import tensorflow as tf
from tensorflow.python.framework import ops
from tensorflow.python.framework import dtypes

batch_size = 10
data = ['a']*9990+['b']*10
labels = [1]*9990+[0]*10
data_tensor = ops.convert_to_tensor(data, dtype=dtypes.string)
label_tensor = ops.convert_to_tensor(labels)
target_probs = [0.5,0.5]
data_batch, label_batch = tf.contrib.training.stratified_sample(
    data_tensor, label_tensor, target_probs, batch_size,
    queue_capacity=2*batch_size)

with tf.Session() as sess:
    d,l = sess.run(data_batch,label_batch)
print('percentage ""a"" = %.3f' % (np.sum(l)/len(l)))
```

This gives the error:
```
Traceback (most recent call last):
  File ""/home/jason/code/scrap.py"", line 59, in <module>
    test_stratified_sample()
  File ""/home/jason/code/scrap.py"", line 50, in test_stratified_sample
    label_tensor, target_probs, batch_size, queue_capacity=2*batch_size)
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/contrib/training/python/training/sampling_ops.py"", line 191, in stratified_sample
    with ops.name_scope(name, 'stratified_sample', tensors + [labels]):
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/math_ops.py"", line 829, in binary_op_wrapper
    y = ops.convert_to_tensor(y, dtype=x.dtype.base_dtype, name=""y"")
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py"", line 676, in convert_to_tensor
    as_ref=False)
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py"", line 741, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/constant_op.py"", line 113, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/constant_op.py"", line 102, in constant
    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/tensor_util.py"", line 374, in make_tensor_proto
    _AssertCompatible(values, dtype)
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/tensor_util.py"", line 302, in _AssertCompatible
    (dtype.name, repr(mismatch), type(mismatch).__name__))
TypeError: Expected string, got list containing Tensors of type '_Message' instead.
```

All the searching I did on this TypeError message returned legitimate bugs, not user errors, so I'm putting this here. For completeness:
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` gives ('v1.2.0-0-g12f033d', '1.2.0')"
11363,tf.parse_single_example parses labels incorrectly,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, but only slightly--I'm using the Inception v3 framework but made some minor modifications to the inception_eval.py code (none around the image processing script)
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux 16.04
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: 1.1.0
- **Python version**: 3.5
- **Bazel version (if compiling from source)**: 0.5.1
- **CUDA/cuDNN version**: 8.0.61
- **GPU model and memory**: Cirrus Logic GD 5446, 16GB
- **Exact command to reproduce**: bazel-bin/inception/imagenet_eval --checkpoint_dir=$HOME/train --eval_dir=$HOME/eval

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem

The parse_single_example function in parsing_ops.py seems to be incorrectly parsing encoded protobufs written into a TFRecord. Specifically, I have been trying to classify images into categories labelled ""1"", ""2"", ""3"", and ""4"". Up until the point in my neural network where the images and associated label are turned into a protobuf serialized image, the labels associated with the images are correct--tf.train.Feature successfully turns each label into an associated integer consistently matching the label. However, after being serialized and then written to a TFRecord and compressed, and then decoded through tf.parse_single_example, the label for each image becomes some random integer between 1 and 9 and no longer matches the label number, with no discernable pattern.

I've traced the issue through the Inception code, and this problem is not happening in Inception--the bug is somewhere between my images are converted from a jpeg with labels to a serialized protobuf through tf.train.Example(features=tf.train.Features(features)) and when the protobuf is decoded through tf.parse_single_example. The label in outputs created by outputs = _parse_single_example_raw within tf.parse_single_example is already incorrect, and the int64 object for each label, created by passing label values into tf.train.Feature(int64_list=tf.train.Int64List(value=label)), that is passed into tf.train.Example(features=tf.train.Features(features)) to create the serialized protobuf that is parsed by tf.parse_single_example still correctly matches the original labels. Therefore, the problem must be happening somewhere between the serialization and the parsing, both of which occur within tensorflow.

EDIT/UPDATE: Upon further examination, the bug seems to occur in some combination of when the image is serialized and when it is written to a TFRecord. I used protoc to manually compile example.proto and used that to manually parse parse the protobufs created by calling tf.train.Example on a Features tensor and encoding them with the SerializeToString method of the example.proto, and while the image/class/text and filename seemed to be correct, the label was missing. After the encoded protobufs are written to a TFRecord, compressed, and then parsed from the TFRecord through, tf.parse_single_example, and they are incorrect--the image/class/label seems to be missing, the image/class/text is no longer correct either, even though it was correct before being passed in, and the beginning of the protobuf has some really wonky encoding going on that example.proto's ParseFromString doesn't seem to be able to read and convert into a string. Additionally, I tried decoding the protobufs parsed from the TFRecord with tf.parse_single_example from latin1 manually, and the labels were still incorrect and matched the incorrect labels from using example.proto's ParseFromString, indicating that the problem isn't happening in the decoding. The parsed protobufs created by image_processing.py have been attached below. 

FURTHER EDIT: Issue has been updated to reflect new information

### Source code / logs

The relevant inception code that calls the aformentioned tensorflow functions is shown below:

**For serializing images+labels into a protobuf**:

```
def _convert_to_example(filename, image_buffer, label, text, height, width):
  """"""Build an Example proto for an example.

  Args:
    filename: string, path to an image file, e.g., '/path/to/example.JPG'
    image_buffer: string, JPEG encoding of RGB image
    label: integer, identifier for the ground truth for the network
    text: string, unique human-readable, e.g. 'dog'
    height: integer, image height in pixels
    width: integer, image width in pixels
  Returns:
    Example proto
  """"""

  colorspace = 'RGB'
  channels = 3
  image_format = 'JPEG'

  example = tf.train.Example(features=tf.train.Features(feature={
      'image/height': _int64_feature(height),
      'image/width': _int64_feature(width),
      'image/colorspace': _bytes_feature(tf.compat.as_bytes(colorspace)),
      'image/channels': _int64_feature(channels),
      'image/class/label': _int64_feature(label),
      'image/class/text': _bytes_feature(tf.compat.as_bytes(text)),
      'image/format': _bytes_feature(tf.compat.as_bytes(image_format)),
      'image/filename': _bytes_feature(tf.compat.as_bytes(os.path.basename(filename))),
      'image/encoded': _bytes_feature(tf.compat.as_bytes(image_buffer))}))
  return example
```

```
def _int64_feature(value):
  """"""Wrapper for inserting int64 features into Example proto.""""""
  if not isinstance(value, list):
    value = [value]
  return tf.train.Feature(int64_list=tf.train.Int64List(value=value))
```

**For parsing a protobuf**
```

def parse_example_proto(example_serialized):
  """"""Parses an Example proto containing a training example of an image.

  The output of the build_image_data.py image preprocessing script is a dataset
  containing serialized Example protocol buffers. Each Example proto contains
  the following fields:

    image/height: 462
    image/width: 581
    image/colorspace: 'RGB'
    image/channels: 3
    image/class/label: 615
    image/class/synset: 'n03623198'
    image/class/text: 'knee pad'
    image/object/bbox/xmin: 0.1
    image/object/bbox/xmax: 0.9
    image/object/bbox/ymin: 0.2
    image/object/bbox/ymax: 0.6
    image/object/bbox/label: 615
    image/format: 'JPEG'
    image/filename: 'ILSVRC2012_val_00041207.JPEG'
    image/encoded: <JPEG encoded string>

   Args:
     example_serialized: scalar Tensor tf.string containing a serialized
       Example protocol buffer.

   Returns:
     image_buffer: Tensor tf.string containing the contents of a JPEG file.
     label: Tensor tf.int32 containing the label.
     bbox: 3-D float Tensor of bounding boxes arranged [1, num_boxes, coords]
       where each coordinate is [0, 1) and the coordinates are arranged as
       [ymin, xmin, ymax, xmax].
     text: Tensor tf.string containing the human-readable label.
   """"""
   # Dense features in Example proto.
   feature_map = {
       'image/encoded': tf.FixedLenFeature([], dtype=tf.string,
                                           default_value=''),
       'image/class/label': tf.FixedLenFeature([1], dtype=tf.int64,
                                               default_value=-1),
       'image/class/text': tf.FixedLenFeature([], dtype=tf.string,
                                              default_value=''),
   }
   sparse_float32 = tf.VarLenFeature(dtype=tf.float32)
  # Sparse features in Example proto.
   feature_map.update(
       {k: sparse_float32 for k in ['image/object/bbox/xmin',
                                    'image/object/bbox/ymin',
                                    'image/object/bbox/xmax',
                                    'image/object/bbox/ymax']})

   features = tf.parse_single_example(example_serialized, feature_map)
   label = tf.cast(features['image/class/label'], dtype=tf.int32)

   xmin = tf.expand_dims(features['image/object/bbox/xmin'].values, 0)
   ymin = tf.expand_dims(features['image/object/bbox/ymin'].values, 0)
   xmax = tf.expand_dims(features['image/object/bbox/xmax'].values, 0)
   ymax = tf.expand_dims(features['image/object/bbox/ymax'].values, 0)

   # Note that we impose an ordering of (y, x) just to make life difficult.
   bbox = tf.concat(axis=0, values=[ymin, xmin, ymax, xmax])

   # Force the variable number of bounding boxes into the shape
   # [1, num_boxes, coords].
   bbox = tf.expand_dims(bbox, 0)
   bbox = tf.transpose(bbox, [0, 2, 1])

   return features['image/encoded'], label, bbox, features['image/class/text']
```

**Protobufs created by parsing from byte-encoded protobufs compressed and written to a TFRecord and then uncompressed and read with tf.parse_single_example, and decoded with example.proto's ParseFromString**:
```
�
�	
image/encoded�	
�	
�	�����JFIF�,,�����C����C�����""��������������	
�������}�!1AQa""q2��#B��R��$3br�	
%&'()*456789:CDEFGHIJSTUVWXYZcdefghijstuvwxyz�����������������������������������������������������������������������������������	
������w�!1AQaq""2B����	#3R�br�
�%������n_����ߋ�~;|�
<g����!�_����W�Zo���o
�[x�����)�����>)|I�-�k~)��[_�^(�m����/����b���F���uۛ�}4Y�]k�k٭M����P��

image/height


image/class/label


image/class/text

6

image/channels


image/width


image/filename
	
368.png

image/format

JPEG

image/colorspace

RGB

�
�

image/encoded�

�	
�	�����JFIF�,,�����C����C�����""��������������	
�������}�!1AQa""q2��#B��R��$3br�	
%&'()*456789:CDEFGHIJSTUVWXYZcdefghijstuvwxyz�����������������������������������������������������������������������������������	
������w�!1AQaq""2B����	#3R�br�
#�2��?��,���,���N�����%|��S'���;ƿ�j/�~�n�ڏōF��W^�ׂ���wDգ��⏌-u�𶫫�6�h^��R��r��E�?��(���

image/colorspace

RGB

image/channels


image/width


image/height


image/class/label


image/filename



5852.png

image/format

JPEG

image/class/text

5

�
�

image/encoded�

�

�
�����JFIF�,,�����C����C�����""��������������	
�������}�!1AQa""q2��#B��R��$3br�	
%&'()*456789:CDEFGHIJSTUVWXYZcdefghijstuvwxyz�����������������������������������������������������������������������������������	
������w�!1AQaq""2B����	#3R�br�
]�CkKq��;�����n�d��!����m_R{}J(��kv��?��(�S�
]oP�������

image/colorspace

RGB

image/channels


image/width


image/height


image/class/label


image/filename



7602.png

image/format

JPEG

image/class/text

5

�	
�
image/encoded�
�
������JFIF�,,�����C����C�����""��������������	
�������}�!1AQa""q2��#B��R��$3br�	
%&'()*456789:CDEFGHIJSTUVWXYZcdefghijstuvwxyz�����������������������������������������������������������������������������������	
������w�!1AQaq""2B����	#3R�br�
$4�%�&'()*56789:CDEFGHIJSTUVWXYZcdefghijstuvwxyz�����������������������������������������������������������������������������?���?��O�	��x��
�^|��<	�j~Ծ(��z��l|�������^j:���G���L��(��Ū��Y��L&����.~,������_�Q���w���>��<tK{r�To|R�I{n��[Aht�\{�0��\�O�������>+�O�5�T���_	>!��ᗋc�n��NO�Ě��u䰽EE��]WJ�[[�E[�s*�p�Ws�?�z��/��&�,��_���z�""C�x�_�<A}��ȱ�j��[[��`�H�xj�+�����A�C�h?�S�+�kv5����s��jZ����Տ�~k2A��(�t�WUx�I%��a�_0Kk[�c�Wh��(���

image/colorspace

RGB

image/channels


image/width


image/height


image/class/label


image/filename
	
663.png

image/format

JPEG

image/class/text

1

�
�
image/encoded�
�
�
�����JFIF�,,�����C����C�����""��������������	
�������}�!1AQa""q2��#B��R��$3br�	
%&'()*456789:CDEFGHIJSTUVWXYZcdefghijstuvwxyz�����������������������������������������������������������������������������������	
������w�!1AQaq""2B����	#3R�br�
$4�%�&'()*56789:CDEFGHIJSTUVWXYZcdefghijstuvwxyz�����������������������������������������������������������������������������?���?���a�6#�
�վ�+7�M��&����[��[���[��?�G��cP�K��)i�����qk�j��ϭM࿆:u�� ����>'�i�[���u�\��{���_�N_�{�	������M���~+ռ'a�	�������Oj:���A��X��=gA����#�F��-#������*����:��F?�:��O��m?�3����������7���:�4=3�ď��%^Z����#����>![��Mk������j���߇�Y�m�������P����	���
������vVW�����u�h��6�P2K���b����?���jW��_��?�Y������?e�����rXx{�O�u���bXɨ�k���kC��h��;+Y4���:мK��O{w�����u[+I����=��Íhx���<Y�/�Y�F����օ�ь�Y�SC����&(���&cfDm�������C~�W�j�<|f�ݩ[I�ڏ��7��}o,}���]��\֮""�*��L��Z=>�����4���?��/�-���ۿ¿��a��kÚ����bo���K��U�tk�
�����tMC����~�ڞk���uï��|W�i�)�����^��u��-P��

image/class/text

3

image/height


image/class/label


image/colorspace

RGB

image/filename



7763.png

image/format

JPEG

image/channels


image/width

```"
11361,Feature Request: Change REGISTER_OP macro to facilitate customization on static initialization sequence,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: iOS
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: 1.0
- **Python version**: N/A
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: iPhone series
- **Exact command to reproduce**: N/A

### `REGISTER_OP` current syntax is not friendly for customization

`REGISTER_OP` in its current implementation, which leverages C++ macro trick to do method-chaining is not friendly for customization. For example, a typical `REGISTER_OP` macro call looks like this:

```
REGISTER_OP(""DynamicPartition"")
    .Input(""data: T"")
    .Input(""partitions: int32"")
    .Output(""outputs: num_partitions * T"")
    .Attr(""num_partitions: int"")
    .Attr(""T: type"")
    ....;
```

When implementing lazy initialization, this macro, comparing with others from TensorFlow (`REGISTER_KERNEL_BUILDER` for example) is more difficult to customize. The reason is that the macro doesn't capture subsequent method calls, therefore, cannot scope these method calls into a function unit. But, this is easy to solve if we change the `REGISTER_OP` syntax a bit:

```
REGISTER_OP(Op(""DynamicPartition"")
    .Input(""data: T"")
    .Input(""partitions: int32"")
    .Output(""outputs: num_partitions * T"")
    .Attr(""num_partitions: int"")
    .Attr(""T: type"")
    ....);
```
The above example is very close to how `REGISTER_KERNEL_BUILDER` works:
```
REGISTER_KERNEL_BUILDER(Name(""NoOp"").Device(DEVICE_CPU), NoOp);
```
so we have some consistencies there.

A hypothetic change to the `REGISTER_OP` macro could look like this:
```
static inline OpDefBuilderWrapper<true> Op(const char name[]) {
    return OpDefBuilderWrapper<true>(name);
}
}  // namespace register_op

#define REGISTER_OP(op) REGISTER_OP_UNIQ_HELPER(__COUNTER__, op)
#define REGISTER_OP_UNIQ_HELPER(ctr, op) REGISTER_OP_UNIQ(ctr, op)
#define REGISTER_OP_UNIQ(ctr, op)                                            \
  static ::tensorflow::register_op::OpDefBuilderReceiver register_op##ctr    \
      TF_ATTRIBUTE_UNUSED =                                                  \
          ::tensorflow::register_op::op;
```

More importantly, this small change enabled some lazy initialization opportunities regarding ops registration, you can imagine a platform-specific change (not likely to get upstreamed) to this macro:

```
#define REGISTER_OP_UNIQ(ctr, op)                                            \
__attribute__((used)) static void register_op_init##ctr(void) {              \
  static ::tensorflow::register_op::OpDefBuilderReceiver register_op##ctr    \
      TF_ATTRIBUTE_UNUSED =                                                  \
          ::tensorflow::register_op::op;                                     \
}                                                                            \
__attribute__((used)) __attribute__((section (""__DATA,tf_reg_op""))) static void *register_op_func##ctr = (void *)&register_op_init##ctr
```

Which put the static initializers into a function and a lazy initializer can call op registrations by scanning the data section and invoke these functions one by one.

Please let me know if this will violate some core assumptions TensorFlow is making and your concerns."
11359,Feature : Multi-dimensional input in LSTM,"Current input format for RNN Cell (ie LSTM) is
```
        (batch_size, Sequence_length)

        cell_fn = gr iid_rnn.Grid2LSTMCell
        additional_cell_args.update({'use_peepholes': True, 'forget_bias': 1.0})
        cell = cell_fn(args.rnn_size, **additional_cell_args)
        self.cell = cell = rnn_cell.MultiRNNCell([cell] * args.num_layers)
        self.input_data =    tf.placeholder(tf.int32, [args.batch_size, args.seq_length])
```
it would be useful to have multi-dimensionnal input as below : 

`        (batch_size, Sequence_length, extra_dim1)`


"
11356,Cannot run example in tensorflow docker due to missing dependency,"- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 14.04
- **TensorFlow installed from (source or binary)**: running in official docker container
- **TensorFlow version (use command below)**: 1.1.0
- **Python version**: 2.7
- **CUDA/cuDNN version**: CUDA 8.0
- **GPU model and memory**: Titan X
- **Exact command to reproduce**:
`docker run -it -p 8888:8888 gcr.io/tensorflow/tensorflow`

### Describe the problem
The official tensorflow docker container does not include h5py. This might be intentional?

However, this breaks an example:
- tensorflow/tensorflow/examples/learn/hdf5_classification.py

This also causes a number of contrib methods to raise exceptions:
- tensorflow/tensorflow/contrib/learn/python/learn/learn_io/data_feeder_test.py
- a numbert of keras.contrib files
"
11355,Use pretrained model VGG16 for android app (demo example),"I download demo example which uses tensorflow_inception_graph.pb from the google tensorflow download page.

What I want to do is to replace it with vgg_16.pb. (The same demo app, only difference is the model')

But I need a help for replacing those with new ones.

In ClassifierActivity.java (https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android)

  ```
private static final int **INPUT_SIZE** = 224; ==> 224
  private static final int **IMAGE_MEAN** = 117; ==> ?
  private static final float **IMAGE_STD** = 1; ==> ?
  private static final String **INPUT_NAME** = ""input"";
  private static final String **OUTPUT_NAME** = ""output"";

  private static final String MODEL_FILE = ""file:///android_asset/tensorflow_inception_graph.pb""; ==>changing the file 
  private static final String **LABEL_FILE** =
      ""file:///android_asset/imagenet_comp_graph_label_strings.txt"";  ==> reusing it. Is it ok? (vgg16 is also trained with imagenet data)
```

I want to replace ""tensorflow_inception_graph.pb"" with ""vgg_16.pb""

For that, I followed those step
1. converting ckpt to pbtxt

```
import tensorflow as tf
import tensorflow.contrib.slim as slim
from nets.vgg import vgg_16, vgg_arg_scope
import numpy as np

height = 224
width = 224
channels = 3

# Create graph
X = tf.placeholder(tf.float32, shape=[None, height, width, channels])
with slim.arg_scope(vgg_arg_scope()):
        logits, end_points = vgg_16(X, num_classes=1000, is_training=False)
predictions = end_points[""vgg_16/fc8""]
saver = tf.train.Saver()

X_test = np.ones((1,224,224,3))

with tf.Session() as sess:
        saver.restore(sess,""./vgg_16.ckpt"")
        predictions_val = predictions.eval(feed_dict={X: X_test})
        tf.train.write_graph(sess.graph_def, './', 'vgg_16.pbtxt')
```
2. creating pb file 
`python [../../../../]tensorflow/tensorflow/python/tools/freeze_graph.py --input_graph=./vgg_16.pbtxt --input_checkpoint=./vgg_16.ckpt --output_graph=./vgg_16.pb --output_node_names=vgg_16/fc8/squeezed`

3. Finding input, output 
```

import tensorflow as tf
import os
import numpy as np
from tensorflow.python.platform import gfile

with gfile.FastGFile(""./vgg_16.pb"",'rb') as f:
    graph_def = tf.GraphDef()
    graph_def.ParseFromString(f.read())
    tf.import_graph_def(graph_def, name='')

[n.name + '=>' +  n.op for n in graph_def.node if n.op in ( 'Softmax','Placeholder', 'Squeeze')]
```
`[u'Placeholder=>Placeholder', u'vgg_16/fc8/squeezed=>Squeeze']`

```
with tf.Session() as sess:
    input_x = sess.graph.get_tensor_by_name(""Placeholder:0"")
    print input_x
    input_x = sess.graph.get_operation_by_name(""Placeholder"")
    print input_x
    out = sess.graph.get_tensor_by_name(""vgg_16/fc8/squeezed:0"")
    print out
    output = sess.graph.get_operation_by_name(""vgg_16/fc8/squeezed"")
    print output
```
```
Tensor(""Placeholder:0"", dtype=float32)
name: ""Placeholder""
op: ""Placeholder""
attr {
  key: ""dtype""
  value {
    type: DT_FLOAT
  }
}
attr {
  key: ""shape""
  value {
    shape {
    }
  }
}

Tensor(""vgg_16/fc8/squeezed:0"", shape=(?, 1000), dtype=float32)
name: ""vgg_16/fc8/squeezed""
op: ""Squeeze""
input: ""vgg_16/fc8/BiasAdd""
attr {
  key: ""T""
  value {
    type: DT_FLOAT
  }
}
attr {
  key: ""squeeze_dims""
  value {
    list {
      i: 1
      i: 2
    }
  }
}
```

But why input and output is not kind of demo codes. Do I change it to 
```
  private static final String **INPUT_NAME** = ""input""; ==> ""Policeholde""
  private static final String **OUTPUT_NAME** = ""output""; ==> ""vgg_16/fc8/squeezed""
```

4. Last one. the size of 
  eventhough I run the script. the size is not changed much.. Still big 553MB
`python ../../../../tensorflow/tensorflow/python/tools/optimize_for_inference.py --input=./inception_v3.pb --output=./vgg_16.pb --input_names= ? --output_names=vgg_16/fc8/squeezed`

```
553440161 Jul  7 16:06 optimized_graph_vgg_16.pb
553444585 Jul  7 09:46 vgg_16.pb
```"
11352, Ran out of memory when running ROLO on tensorflow,"Hello,

Environment : ubuntu 14.04, Nvidia 740M 2Gb, 8Gb RAM, Cuda 7.5, TF 0.8.0

`I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
ROLO init
Utils init
self.cfgPath=
Default: running ROLO test.
Building ROLO graph...
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:900] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: GeForce GT 740M
major: 3 minor: 5 memoryClockRate (GHz) 1.0325
pciBusID 0000:0a:00.0
Total memory: 1.96GiB
Free memory: 1.81GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GT 740M, pci bus id: 0000:0a:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GT 740M, pci bus id: 0000:0a:00.0)
E tensorflow/stream_executor/cuda/cuda_driver.cc:932] failed to allocate 1.00G (1073741824 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
E tensorflow/stream_executor/cuda/cuda_driver.cc:932] failed to allocate 921.60M (966367744 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
E tensorflow/stream_executor/cuda/cuda_driver.cc:932] failed to allocate 829.44M (869731072 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
Loading complete!

('TESTING ROLO on video sequence: ', 'Human2')
I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GT 740M, pci bus id: 0000:0a:00.0)
I tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (256): 	Total Chunks: 1, Chunks in use: 0 256B allocated for chunks. 24B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (512): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (1024): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (2048): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (4096): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (8192): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (16384): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (32768): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (65536): 	Total Chunks: 1, Chunks in use: 0 96.2KiB allocated for chunks. 96.1KiB client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (131072): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (262144): 	Total Chunks: 1, Chunks in use: 0 442.5KiB allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (524288): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (1048576): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:652] Bin for 513.50MiB was 256.00MiB, Chunk State: 
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015c0000 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015c0100 of size 65792
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015d0200 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015d0300 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015d0400 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015d0500 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015d0600 of size 98560
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015e8700 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015e8800 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015e8900 of size 65792
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015f8a00 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015f8b00 of size 98560
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501610c00 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501610d00 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501610e00 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501610f00 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501611100 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501629300 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501629400 of size 65792
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501639500 of size 98560
I tensorflow/core/common_runtime/bfc_allocator.cc:679] Free at 0x501611000 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:679] Free at 0x501611200 of size 98560
I tensorflow/core/common_runtime/bfc_allocator.cc:679] Free at 0x501651600 of size 453120
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501dc0000 of size 1073741824
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x541dc0000 of size 704482304
I tensorflow/core/common_runtime/bfc_allocator.cc:685]      Summary of in-use Chunks by size: 
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 14 Chunks of size 256 totalling 3.5KiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 3 Chunks of size 65792 totalling 192.8KiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 3 Chunks of size 98560 totalling 288.8KiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 1 Chunks of size 704482304 totalling 671.85MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 1 Chunks of size 1073741824 totalling 1.00GiB
I tensorflow/core/common_runtime/bfc_allocator.cc:692] Sum Total of in-use chunks: 1.66GiB
I tensorflow/core/common_runtime/bfc_allocator.cc:694] Stats: 
Limit:                  1739522048
InUse:                  1778720768
MaxInUse:               1778819584
NumAllocs:                      37
MaxAllocSize:           1073741824

W tensorflow/core/common_runtime/bfc_allocator.cc:270] *******************************xxxxxxxxxxxxxxxxxxxxxxxxxxxxx*******************************xxxxxxxxx
W tensorflow/core/common_runtime/bfc_allocator.cc:271] Ran out of memory trying to allocate 513.50MiB.  See logs for memory state.
W tensorflow/core/framework/op_kernel.cc:900] Resource exhausted: OOM when allocating tensor with shape[8204,16408]
Traceback (most recent call last):
  File ""./experiments/testing/ROLO_network_test_all.py"", line 276, in <module>
    main(' ')
  File ""./experiments/testing/ROLO_network_test_all.py"", line 272, in main
    ROLO_TF(argvs)
  File ""./experiments/testing/ROLO_network_test_all.py"", line 93, in __init__
    self.ROLO(argvs)
  File ""./experiments/testing/ROLO_network_test_all.py"", line 267, in ROLO
    self.testing(x_path, y_path)
  File ""./experiments/testing/ROLO_network_test_all.py"", line 157, in testing
    sess.run(init)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 340, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 564, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 637, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 659, in _do_call
    e.code)
tensorflow.python.framework.errors.ResourceExhaustedError: OOM when allocating tensor with shape[8204,16408]
	 [[Node: RNN/LSTMCell/W_0/Initializer/random_uniform/mul = Mul[T=DT_FLOAT, _class=[""loc:@RNN/LSTMCell/W_0""], _device=""/job:localhost/replica:0/task:0/gpu:0""](RNN/LSTMCell/W_0/Initializer/random_uniform/RandomUniform, RNN/LSTMCell/W_0/Initializer/random_uniform/sub)]]
Caused by op u'RNN/LSTMCell/W_0/Initializer/random_uniform/mul', defined at:
  File ""./experiments/testing/ROLO_network_test_all.py"", line 276, in <module>
    main(' ')
  File ""./experiments/testing/ROLO_network_test_all.py"", line 272, in main
    ROLO_TF(argvs)
  File ""./experiments/testing/ROLO_network_test_all.py"", line 93, in __init__
    self.ROLO(argvs)
  File ""./experiments/testing/ROLO_network_test_all.py"", line 236, in ROLO
    self.build_networks()
  File ""./experiments/testing/ROLO_network_test_all.py"", line 125, in build_networks
    self.lstm_module = self.LSTM_single('lstm_test', self.x, self.istate, self.weights, self.biases)
  File ""./experiments/testing/ROLO_network_test_all.py"", line 108, in LSTM_single
    outputs, state = tf.nn.rnn(cell, [_X[step]], state)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py"", line 143, in rnn
    (output, state) = call_cell()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py"", line 136, in <lambda>
    call_cell = lambda: cell(input_, state)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell.py"", line 352, in __call__
    dtype, self._num_unit_shards)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell.py"", line 216, in _get_concat_variable
    sharded_variable = _get_sharded_variable(name, shape, dtype, num_shards)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell.py"", line 246, in _get_sharded_variable
    dtype=dtype))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py"", line 339, in get_variable
    collections=collections)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py"", line 262, in get_variable
    collections=collections, caching_device=caching_device)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py"", line 158, in get_variable
    dtype=variable_dtype)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py"", line 209, in __init__
    dtype=dtype)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py"", line 275, in _init_from_args
    self._initial_value = ops.convert_to_tensor(initial_value(),
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py"", line 149, in <lambda>
    init_val = lambda: initializer(shape.as_list(), dtype=dtype)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/init_ops.py"", line 200, in _initializer
    dtype, seed=seed)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/random_ops.py"", line 183, in random_uniform
    return math_ops.add(rnd * (maxval - minval), minval, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py"", line 518, in binary_op_wrapper
    return func(x, y, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py"", line 1039, in mul
    return _op_def_lib.apply_op(""Mul"", x=x, y=y, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py"", line 655, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2154, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1154, in __init__
    self._traceback = _extract_stack()`"
11351,transform_graph quantize_weights doesn't compile on windows,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:

I'm executing a command from documentation, and I don't think that my custom model is part of the issue.

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:

Windows Server 2012 R2 64-bit

- **TensorFlow installed from (source or binary)**:

Latest master (7/7/2017) compiled with bazel and msvc

- **TensorFlow version (use command below)**:

commit 1e037850f1a (July 6 21:55:34 2017 -0400)

- **Python version**: 

3.5.3 Anaconda 64-bit

- **Bazel version (if compiling from source)**:

0.5.1

- **CUDA/cuDNN version**:

CPU Only

- **GPU model and memory**:

CPU Only (CPU is dual socket Xeon E5-2687W v2)

- **Exact command to reproduce**:
```
$ bazel-bin/tensorflow/tools/graph_transforms/transform_graph --in_graph=/c/Users/name/git-repos/project/input/file.pb --out_graph=/c/Users/name/git-repos/project/input/file_q.pb --inputs='image_tensor' --outputs='detection_boxes,detection_scores,detection_classes' --transforms='fold_constants(ignore_error=true)
fold_batch_norms
fold_old_batch_norms
quantize_weights'
```

### Describe the problem

I originally asked this question on StackOverflow and I was recommended to file a bug report:

https://stackoverflow.com/questions/44955491/tensorflow-transform-graph-doesnt-have-quantize-weights

The `transform_graph` program in tensorflow does not include the `quantize_weights` transform. If I execute the command above without the `quantize_weights` transform it works correctly.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

```
$ bazel-bin/tensorflow/tools/graph_transforms/transform_graph --in_graph=/c/Users/name/git-repos/project/input/file.pb --out_graph=/c/Users/name/git-repos/project/input/file_q.pb --inputs='image_tensor' --outputs='detection_boxes,detection_scores,detection_classes' --transforms='fold_constants(ignore_error=true)
fold_batch_norms
fold_old_batch_norms
quantize_weights'
```
```
2017-07-06 13:21:10.361492: I C:\tools\msys64\tmp\_bazel_name\avtc4yfu\execroot\tensorflow\tensorflow\tools\graph_transforms\transform_graph.cc:263] Applying fold_constants
2017-07-06 13:21:10.476001: W C:\tools\msys64\tmp\_bazel_name\avtc4yfu\execroot\tensorflow\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-07-06 13:21:13.241688: I C:\tools\msys64\tmp\_bazel_name\avtc4yfu\execroot\tensorflow\tensorflow\tools\graph_transforms\transform_graph.cc:263] Applying fold_batch_norms
2017-07-06 13:21:16.088969: I C:\tools\msys64\tmp\_bazel_name\avtc4yfu\execroot\tensorflow\tensorflow\tools\graph_transforms\transform_graph.cc:263] Applying fold_old_batch_norms
2017-07-06 13:21:16.650913: E C:\tools\msys64\tmp\_bazel_name\avtc4yfu\execroot\tensorflow\tensorflow\tools\graph_transforms\transform_graph.cc:209] Transform 'quantize_weights' not recognized.
2017-07-06 13:21:16.650934: E C:\tools\msys64\tmp\_bazel_name\avtc4yfu\execroot\tensorflow\tensorflow\tools\graph_transforms\transform_graph.cc:210] usage: C:\Users\name\git-repos\tensorflow\bazel-bin\tensorflow\tools\graph_transforms\transform_graph.exe
Flags:
        --in_graph=""""                           string  input graph file name
        --out_graph=""""                          string  output graph file name
        --inputs=""""                             string  inputs
        --outputs=""""                            string  outputs
        --transforms=""""                         string  list of transforms
        --output_as_text=false                  bool    whether to write the graph in text protobuf format

Transforms are:
add_default_attributes
backport_concatv2
backport_tensor_array_v3
fold_batch_norms
fold_constants
fold_old_batch_norms
freeze_requantization_ranges
fuse_pad_and_conv
fuse_resize_and_conv
fuse_resize_pad_and_conv
insert_logging
obfuscate_names
remove_attribute
remove_device
remove_nodes
rename_attribute
rename_op
set_device
sort_by_execution_order
sparsify_gather
strip_unused_nodes
```
"
11350,MonitoredTrainingSession to have accessible summary writer.,"**Tensorflow version: 1.2.1**

I am using `MonitoredTrainingSession` extensively to train models, and for the most part does exactly what I want it to do. However, I would like to be able to extract (or pass in) a `FileWriter` object so I can report other summaries from inside my evaluation routines. This is because only one` FileWriter` can write to the events log:

At the moment, this is the best workaround I can do:

```python
sess = tf.train.MonitoredTrainingSession(
       ...
    )

# HACK: this is so we use the same summary writer obj for both summaries, only way to do it.
summary_writer = sess._hooks[1]._summary_writer
```

Then I can use the `summary_writer` to manually report summaries in the evaluation part of my code:

```python
mean_test_loss = ...
summary = tf.Summary(value=[
    tf.Summary.Value(tag='mean_test_loss', simple_value=mean_test_loss)
])
summary_writer.add_summary(summary, current_step)

```

It would be nice to have a non-hacky way to get the `summary_writer` from the session so only one `FileWriter` writes to the events file.

One thought I had is to have a `FileWriter` object as part of the `Scaffold` that is used to build the session. That way anyone can get hold of the scaffold and use the one `summary_writer` designated to write to the events log.

I would be happy to help implementing this if other people are interested.

"
11348,The order in which tensorflow libraries are loaded leads to segmentation fault,"I have a simple java code below.Running this code produces a core dump.
i am running this on debian/8 jessie system. I use tensorflow 1.2.1.
The same code works fine in mac osx but has problems when we run the same  in Linux.
When the code is changed to load tensorflow libraries before rocksdb library it works fine on all platforms.

package com.test.tensorflow;

import org.rocksdb.RocksDB;
import org.rocksdb.RocksDBException;
import org.tensorflow.SavedModelBundle;
import org.tensorflow.Session;
import org.tensorflow.Tensor;

public class TestTensorFlow {

	public static void main(String[] args){
		
		 System.out.println(""before loading.."" + System.getProperty(""java.io.tmpdir""));
		
		
		 RocksDB.loadLibrary();
		 try {
			RocksDB db =RocksDB.open(""/tmp/rocksdelete"");
			db.close();
		} catch (RocksDBException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		}
		 
		 SavedModelBundle smb = SavedModelBundle.load(""test-model"", ""serve"");
		 Session tfSession = smb.session();
		 System.out.println(""loaded"");

	}
}
"
11347,[Doc] tf.abs + complex numbers,"TF 1.2.0

`tf.abs` already supports complex numbers but this is not documented.

https://www.tensorflow.org/api_docs/python/tf/abs"
11345,//tensorflow/python:nn_test is failing on Windows,"https://ci.tensorflow.org/job/tf-master-win-bzl/1218/consoleFull
```
18:54:32 INFO: From Testing //py_test_dir/tensorflow/python:nn_test:
18:54:32 ==================== Test output for //py_test_dir/tensorflow/python:nn_test:
18:54:32 ......................................F...........
18:54:32 ======================================================================
18:54:32 FAIL: testOutput4DInput123 (__main__.MomentsTest)
18:54:32 ----------------------------------------------------------------------
18:54:32 Traceback (most recent call last):
18:54:32   File ""\\?\c:\temp\Bazel.runfiles_nwtmklpc\runfiles\org_tensorflow\py_test_dir\tensorflow\python\ops\nn_test.py"", line 878, in testOutput4DInput123
18:54:32     self.doOutputTest((10, 10, 10, 30), (1, 2, 3))
18:54:32   File ""\\?\c:\temp\Bazel.runfiles_nwtmklpc\runfiles\org_tensorflow\py_test_dir\tensorflow\python\ops\nn_test.py"", line 854, in doOutputTest
18:54:32     self.assertAllClose(variance, expected_var, rtol=tol, atol=tol)
18:54:32   File ""C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\framework\test_util.py"", line 660, in assertAllClose
18:54:32     self._assertArrayLikeAllClose(a, b, rtol=rtol, atol=atol)
18:54:32   File ""C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\framework\test_util.py"", line 630, in _assertArrayLikeAllClose
18:54:32     np.testing.assert_allclose(b, a, rtol=rtol, atol=atol, err_msg=msg)
18:54:32   File ""C:\Program Files\Anaconda3\lib\site-packages\numpy\testing\utils.py"", line 1411, in assert_allclose
18:54:32     verbose=verbose, header=header, equal_nan=equal_nan)
18:54:32   File ""C:\Program Files\Anaconda3\lib\site-packages\numpy\testing\utils.py"", line 796, in assert_array_compare
18:54:32     raise AssertionError(msg)
18:54:32 AssertionError: 
18:54:32 Not equal to tolerance rtol=0.0001, atol=0.0001
18:54:32 None
18:54:32 (mismatch 100.0%)
18:54:32  x: array([[[[ 0.000834]]],
18:54:32 
18:54:32 ...
18:54:32  y: array([[[[ 0.001117]]],
18:54:32 
18:54:32 ...
```"
11344,"can't find some header files when i'm using c/c++ API, eg: tensorflow/core/example/example.pb.h","TF version 1.1.0      ubuntu 14.04 ,    install by pip 
In many examples about c or c++ API in tensorflow, i can find some codes like:

#include ""tensorflow/core/example/example.pb.h""
#include ""tensorflow/core/example/feature.pb.h""
#include ""tensorflow/core/framework/graph.pb_text.h""

but in the folder where tensorflow is intalled, i can't find these file, someone knows why?"
11343,Does tensorflow support mfcc now?,"Is mfcc support in tensorflow now? I found this https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/mfcc.h

but I can't find this op in Python API in tensorflow. 

So is that not open yet? Or it's wrapped in some other Python api?"
11341,"Feature request: Add float16 support for Conv3D, MaxPool3D and AvgPool3D ops","Support for `tf.float16 dtype` was added ([#1300](https://github.com/tensorflow/tensorflow/issues/1300)) to a bunch of ops. Can we add it for conv3d too, please?

conv3d is important to development of videos and medical images systems. Since both consumes a lot of memory, it would be good to have fp16 support to allow deeper models."
11339,Implement Audio Ops for Python Client,"### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS X 10.10.5
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.2.1
- **Python version**: 3.5.2

There are some very useful audio operations defined in tensorflow/core/ops/audio_ops.cc. It would be great if python client users could access these by default. "
11337,get error in tensorflow 1.2 but the code works on tensorflow 1.0,"Hi,

I have the following code. I can run it successfully in tf v1.0 but it failed in tf v1.2. The error is from the (inputs, state) in the GRUCell. Can you help me understand why the errors come from?

Thank you.


```python
import tensorflow as tf
from  tensorflow.contrib.learn.python.learn.estimators.dnn  import DNNClassifier
from tensorflow.contrib.layers import real_valued_column
from tensorflow.contrib.layers.python.layers.initializers import xavier_initializer

dropout=0.2
hidden_1_size = 1000
hidden_2_size = 250
NUM_EPOCHS=100
BATCH_SIZE=50
lr=0.0001

num_features = 2328
RNN_HIDDEN_SIZE=100
FIRST_LAYER_SIZE=1000
SECOND_LAYER_SIZE=250
NUM_LAYERS=2
BATCH_SIZE=50
NUM_EPOCHS=200
lr=0.0003
ATTN_LENGTH=30
beta=0


class RNNModel():
    def __init__(self):
        global_step = tf.contrib.framework.get_or_create_global_step()
        self.input_data = tf.placeholder(dtype=tf.float32,shape=[BATCH_SIZE,num_features])
        self.target_data = tf.placeholder(dtype=tf.int32,shape=[BATCH_SIZE])
        self.dropout_prob = tf.placeholder(dtype=tf.float32,shape=[])
        
        def makeGRUCells():
            base_cell = tf.contrib.rnn.GRUCell(num_units=RNN_HIDDEN_SIZE,) 
            layered_cell = tf.contrib.rnn.MultiRNNCell([base_cell] * NUM_LAYERS,state_is_tuple=False) 
            attn_cell =tf.contrib.rnn.AttentionCellWrapper(cell=layered_cell,attn_length=ATTN_LENGTH,state_is_tuple=False)
            return attn_cell
        
        self.gru_cell = makeGRUCells()
        self.zero_state = self.gru_cell.zero_state(1, tf.float32)
        
        self.start_state = tf.placeholder(dtype=tf.float32,shape=[1,self.gru_cell.state_size])
        print((self.start_state))
        
        

        with tf.variable_scope(""fff"",initializer=xavier_initializer(uniform=False), reuse = None):
            droped_input = tf.nn.dropout(self.input_data,keep_prob=self.dropout_prob)
            
            layer_1 = tf.contrib.layers.fully_connected(
                num_outputs=FIRST_LAYER_SIZE,
                inputs=droped_input,
            )
            layer_2 = tf.contrib.layers.fully_connected(
                num_outputs=RNN_HIDDEN_SIZE,
                inputs=layer_1,
            )
            
        
        split_inputs = tf.reshape(droped_input,shape=[1,BATCH_SIZE,num_features],name=""reshape_l1"") # Each item in the batch is a time step, iterate through them
        #print(split_inputs.shape)
        split_inputs = tf.unstack(split_inputs,axis=1,name=""unpack_l1"")
        #print(""lentgh is "" + str(len(split_inputs)))
        states =[]
        outputs =[]
        with tf.variable_scope(""rnn"",initializer=xavier_initializer(uniform=False), reuse = None) as scope:
            state = self.start_state
            for i, inp in enumerate(split_inputs):
                if i >0:
                    scope.reuse_variables()
                print((state))
                print((inp))
                print(""this is for "" + str(i))
                output, state = self.gru_cell(inputs = inp, state = state)
                states.append(state)
                outputs.append(output)
        self.end_state = states[-1]
        outputs = tf.stack(outputs,axis=1) # Pack them back into a single tensor
        outputs = tf.reshape(outputs,shape=[BATCH_SIZE,RNN_HIDDEN_SIZE])
        self.logits = tf.contrib.layers.fully_connected(
            num_outputs=num_classes,
            inputs=outputs,
            activation_fn=None
        )

            
        with tf.variable_scope(""loss"", reuse = None):
            self.penalties =    tf.reduce_sum([beta*tf.nn.l2_loss(var) for var in tf.trainable_variables()])

            
            self.losses = tf.nn.sparse_softmax_cross_entropy_with_logits(logits = self.logits,labels = self.target_data)
            self.loss = tf.reduce_sum(self.losses + beta*self.penalties)
        
        with tf.name_scope(""train_step""):
            opt = tf.train.AdamOptimizer(lr)
            gvs = opt.compute_gradients(self.loss)
            self.train_op = opt.apply_gradients(gvs, global_step=global_step)
        
        with tf.name_scope(""predictions""):
            probs = tf.nn.softmax(self.logits)
            self.predictions = tf.argmax(probs, 1)
            correct_pred = tf.cast(tf.equal(self.predictions, tf.cast(self.target_data,tf.int64)),tf.float64)
            self.accuracy = tf.reduce_mean(correct_pred)

         
with tf.Graph().as_default():
    model = RNNModel()
```


```python

WARNING:tensorflow:<tensorflow.contrib.rnn.python.ops.rnn_cell.AttentionCellWrapper object at 0x0000000038EB4CC0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
Tensor(""Placeholder_3:0"", shape=(1, 3300), dtype=float32)
Tensor(""Placeholder_3:0"", shape=(1, 3300), dtype=float32)
Tensor(""unpack_l1:0"", shape=(1, 2328), dtype=float32)
this is for 0




---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-20-2249079aecbe> in <module>()
      1 with tf.Graph().as_default():
----> 2     model = RNNModel()

<ipython-input-19-58646adfd4d3> in __init__(self)
     48                 print((inp))
     49                 print(""this is for "" + str(i))
---> 50                 output, state = self.gru_cell(inputs = inp, state = state)
     51                 states.append(state)
     52                 outputs.append(output)

C:\Users\hsong01\AppData\Local\Continuum\Anaconda\lib\site-packages\tensorflow\python\ops\rnn_cell_impl.py in __call__(self, inputs, state, scope)
    178       with vs.variable_scope(vs.get_variable_scope(),
    179                              custom_getter=self._rnn_get_variable):
--> 180         return super(RNNCell, self).__call__(inputs, state)
    181 
    182   def _rnn_get_variable(self, getter, *args, **kwargs):

C:\Users\hsong01\AppData\Local\Continuum\Anaconda\lib\site-packages\tensorflow\python\layers\base.py in __call__(self, inputs, *args, **kwargs)
    439         # Check input assumptions set after layer building, e.g. input shape.
    440         self._assert_input_compatibility(inputs)
--> 441         outputs = self.call(inputs, *args, **kwargs)
    442 
    443         # Apply activity regularization.

C:\Users\hsong01\AppData\Local\Continuum\Anaconda\lib\site-packages\tensorflow\contrib\rnn\python\ops\rnn_cell.py in call(self, inputs, state)
   1111       input_size = inputs.get_shape().as_list()[1]
   1112     inputs = _linear([inputs, attns], input_size, True)
-> 1113     lstm_output, new_state = self._cell(inputs, state)
   1114     if self._state_is_tuple:
   1115       new_state_cat = array_ops.concat(nest.flatten(new_state), 1)

C:\Users\hsong01\AppData\Local\Continuum\Anaconda\lib\site-packages\tensorflow\python\ops\rnn_cell_impl.py in __call__(self, inputs, state, scope)
    178       with vs.variable_scope(vs.get_variable_scope(),
    179                              custom_getter=self._rnn_get_variable):
--> 180         return super(RNNCell, self).__call__(inputs, state)
    181 
    182   def _rnn_get_variable(self, getter, *args, **kwargs):

C:\Users\hsong01\AppData\Local\Continuum\Anaconda\lib\site-packages\tensorflow\python\layers\base.py in __call__(self, inputs, *args, **kwargs)
    439         # Check input assumptions set after layer building, e.g. input shape.
    440         self._assert_input_compatibility(inputs)
--> 441         outputs = self.call(inputs, *args, **kwargs)
    442 
    443         # Apply activity regularization.

C:\Users\hsong01\AppData\Local\Continuum\Anaconda\lib\site-packages\tensorflow\python\ops\rnn_cell_impl.py in call(self, inputs, state)
    914                                       [-1, cell.state_size])
    915           cur_state_pos += cell.state_size
--> 916         cur_inp, new_state = cell(cur_inp, cur_state)
    917         new_states.append(new_state)
    918 

C:\Users\hsong01\AppData\Local\Continuum\Anaconda\lib\site-packages\tensorflow\python\ops\rnn_cell_impl.py in __call__(self, inputs, state, scope)
    178       with vs.variable_scope(vs.get_variable_scope(),
    179                              custom_getter=self._rnn_get_variable):
--> 180         return super(RNNCell, self).__call__(inputs, state)
    181 
    182   def _rnn_get_variable(self, getter, *args, **kwargs):

C:\Users\hsong01\AppData\Local\Continuum\Anaconda\lib\site-packages\tensorflow\python\layers\base.py in __call__(self, inputs, *args, **kwargs)
    439         # Check input assumptions set after layer building, e.g. input shape.
    440         self._assert_input_compatibility(inputs)
--> 441         outputs = self.call(inputs, *args, **kwargs)
    442 
    443         # Apply activity regularization.

C:\Users\hsong01\AppData\Local\Continuum\Anaconda\lib\site-packages\tensorflow\python\ops\rnn_cell_impl.py in call(self, inputs, state)
    293       value = math_ops.sigmoid(
    294           _linear([inputs, state], 2 * self._num_units, True, bias_ones,
--> 295                   self._kernel_initializer))
    296       r, u = array_ops.split(value=value, num_or_size_splits=2, axis=1)
    297     with vs.variable_scope(""candidate""):

C:\Users\hsong01\AppData\Local\Continuum\Anaconda\lib\site-packages\tensorflow\python\ops\rnn_cell_impl.py in _linear(args, output_size, bias, bias_initializer, kernel_initializer)
   1015         _WEIGHTS_VARIABLE_NAME, [total_arg_size, output_size],
   1016         dtype=dtype,
-> 1017         initializer=kernel_initializer)
   1018     if len(args) == 1:
   1019       res = math_ops.matmul(args[0], weights)

C:\Users\hsong01\AppData\Local\Continuum\Anaconda\lib\site-packages\tensorflow\python\ops\variable_scope.py in get_variable(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)
   1063       collections=collections, caching_device=caching_device,
   1064       partitioner=partitioner, validate_shape=validate_shape,
-> 1065       use_resource=use_resource, custom_getter=custom_getter)
   1066 get_variable_or_local_docstring = (
   1067     """"""%s

C:\Users\hsong01\AppData\Local\Continuum\Anaconda\lib\site-packages\tensorflow\python\ops\variable_scope.py in get_variable(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)
    960           collections=collections, caching_device=caching_device,
    961           partitioner=partitioner, validate_shape=validate_shape,
--> 962           use_resource=use_resource, custom_getter=custom_getter)
    963 
    964   def _get_partitioned_variable(self,

C:\Users\hsong01\AppData\Local\Continuum\Anaconda\lib\site-packages\tensorflow\python\ops\variable_scope.py in get_variable(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)
    358           reuse=reuse, trainable=trainable, collections=collections,
    359           caching_device=caching_device, partitioner=partitioner,
--> 360           validate_shape=validate_shape, use_resource=use_resource)
    361     else:
    362       return _true_getter(

C:\Users\hsong01\AppData\Local\Continuum\Anaconda\lib\site-packages\tensorflow\python\ops\variable_scope.py in wrapped_custom_getter(getter, *args, **kwargs)
   1403     return custom_getter(
   1404         functools.partial(old_getter, getter),
-> 1405         *args, **kwargs)
   1406   return wrapped_custom_getter
   1407 

C:\Users\hsong01\AppData\Local\Continuum\Anaconda\lib\site-packages\tensorflow\python\ops\rnn_cell_impl.py in _rnn_get_variable(self, getter, *args, **kwargs)
    181 
    182   def _rnn_get_variable(self, getter, *args, **kwargs):
--> 183     variable = getter(*args, **kwargs)
    184     trainable = (variable in tf_variables.trainable_variables() or
    185                  (isinstance(variable, tf_variables.PartitionedVariable) and

C:\Users\hsong01\AppData\Local\Continuum\Anaconda\lib\site-packages\tensorflow\python\ops\variable_scope.py in wrapped_custom_getter(getter, *args, **kwargs)
   1403     return custom_getter(
   1404         functools.partial(old_getter, getter),
-> 1405         *args, **kwargs)
   1406   return wrapped_custom_getter
   1407 

C:\Users\hsong01\AppData\Local\Continuum\Anaconda\lib\site-packages\tensorflow\python\ops\rnn_cell_impl.py in _rnn_get_variable(self, getter, *args, **kwargs)
    181 
    182   def _rnn_get_variable(self, getter, *args, **kwargs):
--> 183     variable = getter(*args, **kwargs)
    184     trainable = (variable in tf_variables.trainable_variables() or
    185                  (isinstance(variable, tf_variables.PartitionedVariable) and

C:\Users\hsong01\AppData\Local\Continuum\Anaconda\lib\site-packages\tensorflow\python\ops\rnn_cell_impl.py in _rnn_get_variable(self, getter, *args, **kwargs)
    181 
    182   def _rnn_get_variable(self, getter, *args, **kwargs):
--> 183     variable = getter(*args, **kwargs)
    184     trainable = (variable in tf_variables.trainable_variables() or
    185                  (isinstance(variable, tf_variables.PartitionedVariable) and

C:\Users\hsong01\AppData\Local\Continuum\Anaconda\lib\site-packages\tensorflow\python\ops\variable_scope.py in _true_getter(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource)
    350           trainable=trainable, collections=collections,
    351           caching_device=caching_device, validate_shape=validate_shape,
--> 352           use_resource=use_resource)
    353 
    354     if custom_getter is not None:

C:\Users\hsong01\AppData\Local\Continuum\Anaconda\lib\site-packages\tensorflow\python\ops\variable_scope.py in _get_single_variable(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource)
    667         raise ValueError(""Trying to share variable %s, but specified shape %s""
    668                          "" and found shape %s."" % (name, shape,
--> 669                                                    found_var.get_shape()))
    670       if not dtype.is_compatible_with(found_var.dtype):
    671         dtype_str = dtype.name

ValueError: Trying to share variable rnn/attention_cell_wrapper/multi_rnn_cell/cell_0/gru_cell/gates/kernel, but specified shape (200, 200) and found shape (2428, 200).
```
"
11336,TF 1.2 vs 1.1: Keras K.set_learning_phase(False) not working in 1.2 but works in 1.1,"Hi all,

Works fine in 1.1 but in 1.2: 
```
from tensorflow.contrib.keras.python.keras import backend as K
from tensorflow.contrib.keras.python.keras.models import load_model
K.set_learning_phase(False)
model = load_model(MODEL_PATH)
```
```
model.uses_learning_phase <-- returns TRUE
```

This does not happen in 1.1. What may have changed that cause this in 1.2? 

Thank you in advance.
Best regards,
Dylan Randle

"
11334,Memory Overhead/Leak in Android lib,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Nexus 6p, Android v7.1.2
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**:  1.2.0-rc2
- **Python version**: 2.7.10
- **Bazel version (if compiling from source)**: 0.4.5-homebrew
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**:
- **Exact command to reproduce**: 
-- Selective Headers: ` bazel build -c opt --copt=""-DSELECTIVE_REGISTRATION"" --copt=""-DSUPPORT_SELECTIVE_REGISTRATION"" //tensorflow/contrib/android:libtensorflow_inference.so --crosstool_top=//external:android/crosstool --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --cpu=armeabi-v7a `
-- Added `tensorflow/core/kernels/random_shuffle_queue_op.cc` and `tensorflow/core/kernels/random_shuffle_op.cc` to `tf_op_files.txt` file
-- Removed unused nodes: `bazel build tensorflow/tools/graph_transforms:transform_graph
bazel-bin/tensorflow/tools/graph_transforms/transform_graph \
--in_graph=model.pb \
--out_graph=optimized_model.pb \
--inputs='input' \
--outputs='output' \
--transforms='
  strip_unused_nodes(type=float, shape=""1,299,299,3"")'`

### Describe the problem
The Tensorflow Android library is using a lot more memory than I expected. It almost seems like it's maintaining a reference to all input arrays, as memory usage balloons the longer the model is used. 
Here is an example of the memory usage with feed/run/fetch commented out (source code below):

![no_tensorflow](https://user-images.githubusercontent.com/4616968/27930636-3342a548-624c-11e7-91ed-3f4f56b7cf5f.png)

Here is the same timeframe, with the only difference being that feed/run/fetch is enabled:

![tensorflow](https://user-images.githubusercontent.com/4616968/27930738-954e125e-624c-11e7-82f2-cc21e67bc5d3.png)

Memory usage is over three times worse. The longer I leave the model running, the more memory usage increases (it eventually gets to 110 mb).

The below method is being called at a rate of 4.419011933 per sec (i.e. it's processing 4.412 input arrays per second), where each input array is of size 96\*96\*3 (27648).

This is being run on a Nexus 6p, running stock 7.1.2. The model is a conv net with inception, batch norm and dropout, trained using tensorflow slim. 

### Source code / logs
Commented out:
```java
public float[] runInference(float[] pixels) {
        assertRightSize(pixels);
        final float[] outputArray = new float[128];
        // Simulate some sort of output
        Arrays.fill(outputArray, new Random().nextInt(1000)/new Random().nextFloat());
//     inferenceInterface.feed(""phase_train"", new bool[]{false});
//     inferenceInterface.feed(""input"", pixels, 1, 96, 96, 3);
//     inferenceInterface.run(new String[]{""output""});
        // Copy the output Tensor back into the output array.
//     inferenceInterface.fetch(""output"", outputArray);

        return outputArray;
    }
```
Enabled:

```java
public float[] runInference(float[] pixels) {
        assertRightSize(pixels);
        final float[] outputArray = new float[128];
        inferenceInterface.feed(""phase_train"", new bool[]{false});
        inferenceInterface.feed(""input"", pixels, 1, 96, 96, 3);
        inferenceInterface.run(new String[]{""output""});
        // Copy the output Tensor back into the output array.
        inferenceInterface.fetch(""output"", outputArray);

        return outputArray;
    }
```

where `float[] pixels` is a float array of size `27648`, denoting the pixels in an image of size 96x96.

The custom code is an update to the InferenceInterface to accept boolean types during feeding: 

```java
public void feed(String inputName, boolean[] src, long... dims) {
        byte[] b = new byte[src.length];
        for (int i = 0; i < src.length; ++i) {
            b[i] = (byte) (src[i] ? 1 : 0);
        }
        addFeed(inputName, Tensor.create(DataType.BOOL, dims, ByteBuffer.wrap(b)));
    }
```

Please let me know if there's any other information I can provide."
11333,"ValueError: Variable vgg_16/conv1/conv1_1/weights already exists, disallowed","I got this kind of error message when trying use existing weight.

```
ValueError: Variable vgg_16/conv1/conv1_1/weights already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:

  File ""/usr/local/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/variables.py"", line 217, in variable
    use_resource=use_resource)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py"", line 181, in func_with_args
    return func(*args, **current_args)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/variables.py"", line 262, in model_variable
    use_resource=use_resource)
```

Code: https://github.com/datomnurdin/tensorflow-image-segmentation/blob/master/index.ipynb

Please advice. Thank you."
11332,[feature request] Inconsistency of new Decoder api and Dense layer,"TF 1.1 has released new seq2seq API (`tf.contrib.seq2seq.BasicDecoder` etc.) and Decoders have `output_layer` parameter, which must be subclass of `tf.layers.Layer`.

If one wants to use dense projection, it has to do `from tensorflow.python.layers.core import Dense` which seems a bit inconvenient. 

Maybe the better way is to include `Dense` and `Dropout` classes into `tf.layers`? After that, one could write just `tf.layers.Dense` or `tf.layers.Dropout`."
11329, tf.image.rgb_to_grayscale Bug?,"Hi,
I have the same problem with this one with the current version of tensorflow under python 3.5. It seems that tf.image.rgb_to_grayscale cannot accept RGB input. Wonder if anyone could check this. Many thanks.

https://stackoverflow.com/questions/40924184/error-while-feeding-images-to-tensorflow-graph"
11328,wide_n_deep AttributeError (master) and ValueError (r1.2),"I'm using TensorFlow 1.2.1. When I run `python wide_n_deep_tutorial.py --model_type=wide` from the [Linear Model tutorial](https://www.tensorflow.org/tutorials/wide), I get the following AttributeError:

```
  File ""wide_n_deep_tutorial.py"", line 139, in build_estimator
    m = tf.estimator.LinearClassifier(
AttributeError: 'module' object has no attribute 'LinearClassifier'
```

I tried switching to r1.2, as suggested in #11256, but got this ValueError on r1.2:

```
Traceback (most recent call last):
  File ""wide_n_deep_tutorial.py"", line 234, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/home/usr/tensorflow/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""wide_n_deep_tutorial.py"", line 197, in main
    FLAGS.train_data, FLAGS.test_data)
  File ""wide_n_deep_tutorial.py"", line 186, in train_and_eval
    m.fit(input_fn=lambda: input_fn(df_train), steps=train_steps)
  File ""/home/usr/tensorflow/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py"", line 289, in new_func
    return func(*args, **kwargs)
  File ""/home/usr/tensorflow/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 455, in fit
    loss = self._train_model(input_fn=input_fn, hooks=hooks)
  File ""/home/usr/tensorflow/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 953, in _train_model
    features, labels = input_fn()
  File ""wide_n_deep_tutorial.py"", line 186, in <lambda>
    m.fit(input_fn=lambda: input_fn(df_train), steps=train_steps)
  File ""wide_n_deep_tutorial.py"", line 148, in input_fn
    for k in CATEGORICAL_COLUMNS}
  File ""wide_n_deep_tutorial.py"", line 148, in <dictcomp>
    for k in CATEGORICAL_COLUMNS}
  File ""/home/usr/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/sparse_tensor.py"", line 132, in __init__
    indices_shape = indices.get_shape().with_rank(2)
  File ""/home/usr/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/tensor_shape.py"", line 632, in with_rank
    raise ValueError(""Shape %s must have rank %d"" % (self, rank))
ValueError: Shape (0,) must have rank 2
```
"
11327,Backprop through conv2d with large tensors fails,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
source
- **TensorFlow version (use command below)**:
1.1.0
- **Python version**: 
3.5.2
- **Bazel version (if compiling from source)**:
0.4.5
- **CUDA/cuDNN version**:
CUDA Version 8.0.61
- **GPU model and memory**:
GeForce GTX 1080, 8GB
- **Exact command to reproduce**:
```
import tensorflow as tf

proj = tf.Variable( tf.random_normal([720,1,400,600], stddev = 2) )
kernel = tf.Variable( tf.random_normal([1, 401, 1, 1], stddev = .5), trainable = True )
proj = tf.nn.conv2d(
    input = proj,
    filter = kernel,
    strides = [ 1, 1, 1, 1 ],
    padding = 'SAME',
    data_format = 'NCHW',
    name = 'ramlak-filter'
)
grad = tf.gradients( proj, kernel, proj )

with tf.Session() as sess:
    sess.run( tf.global_variables_initializer() )
    print( sess.run( grad ) )
```

### Describe the problem
Backpropagation through `conv2d` for large tensors produces an error for me (see log below). This is true for the code above. Lowering the batch size in `proj` from 720 to 100 eliminates the error. The issue has been confirmed by another user at [stackoverflow](https://stackoverflow.com/questions/44901742/tensorflow-error-while-backpropagating-through-conv2d).

### Source code / logs
```
NotFoundError (see above for traceback): No algorithm without scratch worked!
	 [[Node: gradients/ramlak-filter_grad/Conv2DBackpropFilter = Conv2DBackpropFilter[T=DT_FLOAT, data_format=""NCHW"", padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/gpu:0""](Variable/read, gradients/ramlak-filter_grad/Shape_1, ramlak-filter)]]
[log.txt](https://github.com/tensorflow/tensorflow/files/1128268/log.txt)

```

Please find the full log attached.

"
11326,ModuleNotFoundError: No module named '_pywrap_tensorflow_internal',"Windows 10 Home
Python 3.6
CUDA 8.0 & 7.5 
cuDNN 5.1 (for both 8.0 and 7.5)
CUDA path variables set (to 8.0)
GeForce GTX 970
tensorflow installed from:
https://github.com/tensorflow/tensorflow/tree/r1.2
http://i.imgur.com/tqTp5LA.png

I also have Theano and CNTK installed and they both work

the error happens when importing tensorflow
`import tensorflow as tf`

```
>>> import tensorflow as tf
Traceback (most recent call last):
  File ""D:\Programs\Anaconda3.6\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    return importlib.import_module(mname)
  File ""D:\Programs\Anaconda3.6\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 978, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 961, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 950, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 648, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 560, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 922, in create_module
  File ""<frozen importlib._bootstrap>"", line 205, in _call_with_frames_removed
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""D:\Programs\Anaconda3.6\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""D:\Programs\Anaconda3.6\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 21, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""D:\Programs\Anaconda3.6\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""D:\Programs\Anaconda3.6\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""D:\Programs\Anaconda3.6\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""D:\Programs\Anaconda3.6\lib\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""D:\Programs\Anaconda3.6\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 52, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""D:\Programs\Anaconda3.6\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    return importlib.import_module(mname)
  File ""D:\Programs\Anaconda3.6\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 978, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 961, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 950, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 648, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 560, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 922, in create_module
  File ""<frozen importlib._bootstrap>"", line 205, in _call_with_frames_removed
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""D:\Programs\Anaconda3.6\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""D:\Programs\Anaconda3.6\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 21, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""D:\Programs\Anaconda3.6\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""D:\Programs\Anaconda3.6\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
```"
11325,[contribution] 3d geometric transformations?,"Hi!
I wonder if you see purpose in adding 3d geometric transformations to contrib? (such as those available in [transforms3d library](https://github.com/matthew-brett/transforms3d))
I've written a few of those in tensorflow for one of my projects and I wonder if it would be worth doing some refactoring and documentation to make it contribution-worthy?
I've implemented them using tf python functions, I haven't done any lower level performance optimisation, is that fine?"
11324,TypeError: concat() got an unexpected keyword argument 'concat_dim',"I got this error message regarding to tf.concat

```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-3-bf534f0e5e9f> in <module>()
     42 
     43 combined_mask = tf.concat(concat_dim=2, values=[bit_mask_class,
---> 44                                                 bit_mask_background])
     45 
     46 # Lets reshape our input so that it becomes suitable for

TypeError: concat() got an unexpected keyword argument 'concat_dim'
```

Code: https://github.com/datomnurdin/tensorflow-image-segmentation/blob/master/index.ipynb

Please advice. Thank you."
11321,Is 'tf.concat' 's API is wrong?,"According 'tf.concat' 's API (0.12):

`t1 = [[1, 2, 3], [4, 5, 6]]`
`t2 = [[7, 8, 9], [10, 11, 12]]`
`tf.concat(0, [t1, t2])`

while console returns:

`tf.concat(0, [t1, t2])
Traceback (most recent call last):`
`File ""<ipython-input-65-5990b998f0fa>"", line 1, in <module>
    tf.concat(0, [t1, t2])`
`File ""E:\SDK\Anaconda2\envs\py3\lib\site-packages\tensorflow\python\ops\array_ops.py"", line 1044, in concat
    ).assert_is_compatible_with(tensor_shape.scalar())`
`File ""E:\SDK\Anaconda2\envs\py3\lib\site-packages\tensorflow\python\framework\tensor_shape.py"", line 732, in assert_is_compatible_with
    raise ValueError(""Shapes %s and %s are incompatible"" % (self, other))`
`ValueError: Shapes (2, 2, 3) and () are incompatible`

**BUT I try to swap the params' position, it is well.**

`t1 = [[1, 2, 3], [4, 5, 6]]`
`t2 = [[7, 8, 9], [10, 11, 12]]`
`tf.concat([t1, t2], 0)`"
11320,BeamSearchDecoder Bug on beam_width,"### System information
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 14.04
- TensorFlow installed from (source or binary): Pip Binary
- TensorFlow version (use command below): 1.2.1
- Python version: 3.4
### My coustom code
```python
class Model():
'''
A seq2seq model
placeholder: 
    encoder_input, a int32 tensor shaped [None, max_encoder_len]
    encoder_length, a int32 tensor shaped [None]
    decoder_input, a int32 tensor shaped [None, max_decoder_len]
cell:
    LSTMCell. cell.output_size = 128
'''

    # some irrespective code

    @property
    def _prediction(self):
        with self._graph.as_default():
            GO_SYMBOL = [500]
            END_SYMBOL = 501

            initial_state = self.encoder['final_state']

            decoder = tf.contrib.seq2seq.BeamSearchDecoder(
                cell=self.cell,
                embedding=lambda tokens:tf.nn.embedding_lookup(self._decoder_embedding, tokens),
                start_tokens=GO_SYMBOL,
                end_token=END_SYMBOL,
                initial_state=initial_state,
                beam_width=self._beam_size, # self._beam_size = 1 is ok 
                                            # but self._beam_size = 2 runs wrong
                output_layer=self._output_projection_layer
            )

            outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(
                decoder=decoder,
                maximum_iterations=self._max_decoder_len
            )

            return outputs.predicted_ids[:, :, 0]

    # some irrespective code

    def predict(self, word_list):
        '''
        Args:
            word_list: [word0, word1...]. 1-dimentional array
        return:
            outputs: [o0, o1...]. 1-dimentional array
                     where oi is word_index
        '''
        length = len(word_list)
        word_index_list = preprocess.words_to_indices(word_list) # turn words to numbers
        if len(word_index_list) < self._max_encoder_len:
            word_index_list.extend([0] * (self._max_encoder_len - len(word_index_list)))

        feed_dict = {
            self.input_length['encoder_input']: [word_index_list],
            self.input_length['encoder_length']: [length]
        }

        (
            output
        ) = self._session.run([
            self._prediction
        ],
            feed_dict = feed_dict
        )

        return output
```
### Error Desciption
It is ok to build tfGraph. But I get into trouble when calling Model.predict().
If the beam_width is set as 1, the program can normally run. And it raise the following error when the beam_width is set as 2.
```
  File ""/home/runke/lxtest/algorithm/algorithm/estimation/get_earnings.py"", line 347, in _prediction
    output_layer=self._output_projection_layer
  File ""/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py"", line 193, in __init__
    initial_state, self._cell.state_size)
  File ""/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/python/util/nest.py"", line 325, in map_structure
    structure[0], [func(*x) for x in entries])
  File ""/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/python/util/nest.py"", line 325, in <listcomp>
    structure[0], [func(*x) for x in entries])
  File ""/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py"", line 374, in _maybe_split_batch_beams
    return self._split_batch_beams(t, s)
  File ""/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py"", line 339, in _split_batch_beams
    ([self._batch_size, self._beam_width], t_shape[1:]), 0))
  File ""/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 2451, in reshape
    name=name)
  File ""/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py"", line 767, in apply_op
    op_def=op_def)
  File ""/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/python/framework/ops.py"", line 2506, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/python/framework/ops.py"", line 1269, in __init__
    self._traceback = _extract_stack()

InvalidArgumentError (see above for traceback): Input to reshape is a tensor with 128 values, but the requested shape has 256
         [[Node: Reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/cpu:0""](encoder/rnn/while/Exit_2, concat)]]
```"
11318,TypeError: Input 'strides' of 'StridedSlice' Op has type int32 that does not match type int64 of argument 'begin'.,"I just want to get a slice of a tensor. It works for int32 but not for int64:

```
In [35]: import tensorflow as tf
    ...: a=tf.Variable([0,1,2], dtype=tf.int64)
    ...: i = tf.constant(1, dtype=tf.int64)
    ...: a[i]
    ...:
<long stack trace>
TypeError: Input 'strides' of 'StridedSlice' Op has type int32 that does not match type int64 of argument 'begin'.
In [36]: import tensorflow as tf
    ...: a=tf.Variable([0,1,2], dtype=tf.int32)
    ...: i = tf.constant(1, dtype=tf.int32)
    ...: a[i]
    ...:
Out[36]: <tf.Tensor 'strided_slice_22:0' shape=() dtype=int32>
```"
11316,order of execution of functions in cond statement is inconsistent,"### Inconsistency and/or feature request.

Tensorflows control flow method
`tf.cond(condition, fn1, fn2)`
executes both functions fn1 and fn2 and returns only one depending on the evaluation of condition. In addition, the order in which the two functions are evaluated varies or is undefined as the following code shows:
```
var1 = tf.Variable(tf.zeros(1), trainable=False, name='var1')
var2 = tf.Variable(tf.zeros(1), trainable=False, name='var2')
update_var1 = tf.assign(var1,var1 +1)
update_var2 = tf.assign(var2,var2 +1)
training = tf.placeholder(tf.bool)
def f1():
  with tf.control_dependencies([update_var1]):
    return var1 + 10*var2
def f2():
  with tf.control_dependencies([update_var2]):
    return var1 + 10*var2

final = tf.cond(training, f1, f2)
sess = tf.Session()
sess.run(tf.global_variables_initializer())
for i in range(10):
  print(sess.run(final, feed_dict={training: False}))
```
The output of this varies from run to run, but a typical example is:
```
[ 10.] 
[ 22.] 
[ 33.]
[ 44.]
[ 55.]
[ 66.]
[ 77.]
[ 87.]
[ 98.]
[ 110.]
```
For the lines with 10, 87 and 98 the order of execution apparently was:
1. update var1
2. evaluate and return var1 * 10*var2
3. **update var2**

while for the lines with 22, 33, 44, 55, 66, 77 and 110 the order of execution must have been:
1. update var1
2. **update var2**
3. evaluate and return var1 * 10*var2 


------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
See code in description
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux
- **TensorFlow installed from (source or binary)**:
from binary
- **TensorFlow version (use command below)**:
('v1.2.0-rc2-21-g12f033d', '1.2.0')
- **Python version**: 
Python 2.7.13 |Anaconda 4.3.1 (64-bit)
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

"
11315,"tf.assert_equal throws ""object was never used"" error in v1.2.x","The following code is copied from some tensorflow repository outside.

`tf.assert_equal( tf.size( x ), tf.constant( 1 ) )`

While running in tensorflow v1.2.0 or v1.2.1, it throws the following log.

`ERROR:tensorflow:==================================
Object was never used (type <class 'tensorflow.python.framework.ops.Operation'>):
<tf.Operation 'update_hyper/cond/assert_equal/Assert/Assert' type=Assert>
If you want to mark it as used call its ""mark_used()"" method.
It was originally created here:
['File ""/usr/lib64/python3.5/runpy.py"", line 193, in _run_module_as_main\n    ""__main__"", mod_spec)', 'File ""/usr/lib64/python3.5/runpy.py"", line 85, in _run_code\n    exec(code, run_globals)', 'File ""/usr/lib/python3.5/site-packages/ipykernel_launcher.py"", line 16, in <module>\n    app.launch_new_instance()', 'File ""/usr/lib/python3.5/site-packages/traitlets/config/application.py"", line 658, in launch_instance\n    app.start()', 'File ""/usr/lib/python3.5/site-packages/ipykernel/kernelapp.py"", line 477, in start\n    ioloop.IOLoop.instance().start()', 'File ""/usr/lib64/python3.5/site-packages/zmq/eventloop/ioloop.py"", line 177, in start\n    super(ZMQIOLoop, self).start()', 'File ""/usr/lib64/python3.5/site-packages/tornado/ioloop.py"", line 888, in start\n    handler_func(fd_obj, events)', 'File ""/usr/lib64/python3.5/site-packages/tornado/stack_context.py"", line 277, in null_wrapper\n    return fn(*args, **kwargs)', 'File ""/usr/lib64/python3.5/site-packages/zmq/eventloop/zmqstream.py"", line 440, in _handle_events\n    self._handle_recv()', 'File ""/usr/lib64/python3.5/site-packages/zmq/eventloop/zmqstream.py"", line 472, in _handle_recv\n    self._run_callback(callback, msg)', 'File ""/usr/lib64/python3.5/site-packages/zmq/eventloop/zmqstream.py"", line 414, in _run_callback\n    callback(*args, **kwargs)', 'File ""/usr/lib64/python3.5/site-packages/tornado/stack_context.py"", line 277, in null_wrapper\n    return fn(*args, **kwargs)', 'File ""/usr/lib/python3.5/site-packages/ipykernel/kernelbase.py"", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)', 'File ""/usr/lib/python3.5/site-packages/ipykernel/kernelbase.py"", line 235, in dispatch_shell\n    handler(stream, idents, msg)', 'File ""/usr/lib/python3.5/site-packages/ipykernel/kernelbase.py"", line 399, in execute_request\n    user_expressions, allow_stdin)', 'File ""/usr/lib/python3.5/site-packages/ipykernel/ipkernel.py"", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)', 'File ""/usr/lib/python3.5/site-packages/ipykernel/zmqshell.py"", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)', 'File ""/usr/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)', 'File ""/usr/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2802, in run_ast_nodes\n    if self.run_code(code, result):', 'File ""/usr/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)', 'File ""<ipython-input-13-85a15e405d64>"", line 1, in <module>\n    h1 = m1.fit( nn_train_x, nn_train_y, epochs=epochs, batch_size=batch_size, verbose=0 )', 'File ""/usr/lib/python3.5/site-packages/keras/models.py"", line 870, in fit\n    initial_epoch=initial_epoch)', 'File ""/usr/lib/python3.5/site-packages/keras/engine/training.py"", line 1490, in fit\n    self._make_train_function()', 'File ""/usr/lib/python3.5/site-packages/keras/engine/training.py"", line 1014, in _make_train_function\n    self.total_loss)', 'File ""<ipython-input-5-1252bd787625>"", line 7, in get_updates\n    opt_update = self.optimizer.apply_gradients( grads )', 'File ""/data/jupyter/yellowfin/yellowfin.py"", line 223, in apply_gradients\n    update_hyper_op = self.update_hyper_param()', 'File ""/data/jupyter/yellowfin/yellowfin.py"", line 191, in update_hyper_param\n    lambda: self._mu_var) )', 'File ""/usr/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py"", line 289, in new_func\n    return func(*args, **kwargs)', 'File ""/usr/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 1814, in cond\n    orig_res_t, res_t = context_t.BuildCondBranch(true_fn)', 'File ""/usr/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 1689, in BuildCondBranch\n    original_result = fn()', 'File ""/data/jupyter/yellowfin/yellowfin.py"", line 190, in <lambda>\n    self._mu = tf.identity(tf.cond(self._do_tune, lambda: self.get_mu_tensor(),', 'File ""/data/jupyter/yellowfin/yellowfin.py"", line 180, in get_mu_tensor\n    tf.assert_equal(tf.size(root), tf.constant(1) )', 'File ""/usr/lib/python3.5/site-packages/tensorflow/python/ops/check_ops.py"", line 318, in assert_equal\n    return control_flow_ops.Assert(condition, data, summarize=summarize)', 'File ""/usr/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py"", line 170, in wrapped\n    return _add_should_use_warning(fn(*args, **kwargs))', 'File ""/usr/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py"", line 139, in _add_should_use_warning\n    wrapped = TFShouldUseWarningWrapper(x)', 'File ""/usr/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py"", line 96, in __init__\n    stack = [s.strip() for s in traceback.format_stack()]']
==================================`

What I expect would be an exception thrown only when the assertion evaluates to false.

Why is it a must to use object returned from assert statement?"
11314,There is no work_sharder file in tensorflow/core/framework,"I am reading the `Add a new op` section in official website. There is a link [https://www.github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/core/framework/work_sharder.h](work_sharder.h), and this link is 404 not found. Then i tried to find the work_shader.h in tensorflow/tensorlfow/core/framework, and i failed. where can i find work_sharder.h file and detailed documentation of it ?
Thx.
"
11313,tf.nn.embedding_lookup_sparse behaves not as expected,"Simple repeated code:

```python
import tensorflow as tf
import numpy as np


a = tf.constant([[2,3], [3,0]])
b = tf.constant([0, 3])

s = tf.SparseTensor(tf.cast(a, tf.int64), b, dense_shape=(4,5))

n = np.random.rand(5,3)
nn = tf.Variable(n, name='aha')

r = tf.nn.embedding_lookup_sparse(nn, s, None,combiner='sum')

sess = tf.Session()
sess.run(tf.global_variables_initializer())

print sess.run(r)
```

**expected results**: 2*3

```python
[[ 0.45522392  0.67905994  0.79126569]
 [ 0.62346977  0.42459864  0.03796264]]
```

but **actual results**: 4\*3

```python
[[ 0.          0.          0.        ]
 [ 0.          0.          0.        ]
 [ 0.45522392  0.67905994  0.79126569]
 [ 0.62346977  0.42459864  0.03796264]]
```

I do not get it. Can anyone help to clarify the result?

Tensorflow version: 1.2.1, installed with pip.
OS: mac os 10.12.5 

[tf.nn.embedding_lookup_sparse](https://www.tensorflow.org/api_docs/python/tf/nn/embedding_lookup_sparse)

Another problem: I am using a partitioned variable to lookup. Pseudo code:

```python
a = tf.getVariable(...) # it is a partitioned variable, pass partitioner to it
b = list(a)

result = []
for p in b:
    result.append( tf.nn.embedding_lookup_sparse(p, sparseTensor, None, combiner='sum'))

final_result = tf.concat(result, 0)

sess.run(final_result)
```

if I remove the `tf.concat`, and replace it with:

```python
for ff in final_result:
    sess.run(ff)
```

The part of code behaves as expected. But when I do concat, it crashes and the error message is:

```python
InvalidArgumentError (see above for traceback): segment ids are not increasing
	 [[Node: embedding_lookup_sparse = SparseSegmentSum[T=DT_DOUBLE, Tidx=DT_INT32, _device=""/job:localhost/replica:0/task:0/cpu:0""](embedding_lookup_sparse/embedding_lookup, embedding_lookup_sparse/Unique:1, embedding_lookup_sparse/Cast)]]
```

After a serious investigation, I understand **segment ids are not increasing**. It means that:

```python
sparse_ids = [[1,0],[0,1]] # invalid
sparse_ids = [[0,1],[1,0]] # valid
```
This is documented in the previous link I provided. But I have printed all the sparse indices and values using `tf.Print`. Everything seems fine. 

So my question is : does `tf.concat` apply any special rules？

"
11312,"tf.gfile.FastGFile(filename, 'r').read()  error: 'utf-8' codec can't decode byte 0xff","
### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
TensorFlow 1.2.0

image_data = tf.gfile.FastGFile(filename, 'r').read()   
python2.7 is good，but Python3.5 error ：  'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

why???"
11311,AttributeError: 'Tensor' object has no attribute 'assign_add',"I'm trying to use ""assign_add"" : 
https://www.tensorflow.org/api_docs/python/tf/assign_add

my code : 
accum_ops = tf.assign_add(accum_grad, grad, name=name)

Output ; 
AttributeError: 'Tensor' object has no attribute 'assign_add'

Has the name changed ?
"
11310,"My problem---tensor-flow connect with Windows IIS?Hello,i just ask a question three days ago, but no response,can you spend some time to reply me?","I set up a tensorflow system, use flask grammar to set up . And in local computer, all run ok, no error.
But when I mount it in IIS, as Web API to use, It always show FASTCGI error. Does tensorflow incompatiable with IIS?"
11309,Mixture of multivariate distributions,"Consider a mixture of 2-dimensional Gaussians in TensorFlow:
```python
ds = tf.contrib.distributions

cat = ds.Categorical(probs=[0.3, 0.2, 0.5])
comps = [ds.MultivariateNormalDiag(loc=[-5.0, -5.0], scale_diag=tf.ones(2)),
         ds.MultivariateNormalDiag(loc=[0.0, 0.0], scale_diag=tf.ones(2)),
         ds.MultivariateNormalDiag(loc=[5.0, 5.0], scale_diag=tf.ones(2))]

mix = ds.Mixture(cat=cat, components=comps)
```
This works because each `MultivariateNormalDiag` distribution has a batch shape of `()`. It is compatible with the `Categorical`'s batch shape.

Now consider a mixture of 2-dimensional Bernoulli's, or Gamma's, or Laplace, or StudentT's. We need an equivalent `MultivariateBernoulli`, `MultivariateGamma`, etc. distribution which allows us to fix the batch shape and increase the event shape.

Are there plans to make such distributions available? 

What about edge cases such as a matrixvariate (k-variate) Bernoulli, where additional parameter dimensions determine the batch shape and the event shape is fixed at 2 (k)?

@ebrevdo , @jvdillon. Issue motivated by https://github.com/blei-lab/edward/issues/686."
11308,"Reading data from GCS, processing hangs indefinitely","
### System information
- Using the ml engine example here: https://github.com/GoogleCloudPlatform/cloudml-samples/tree/master/census/estimator/trainer
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OSX 10.11.5
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.1.0
- **Python version**: 2.7.12

### Describe the problem
This code runs fine if I point it to local data. It also runs fine if I point it to the public dataset gs://cloudml-public/census/data/adult.data.csv in the instructions. However, when I make a copy of that public dataset and store it in my own GCS bucket the code just hangs after listing these common warnings:
```
2017-07-05 16:14:50.392729: W tensorflow/core/platform/cpu_feature_guard.cc:45] The 
TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your 
machine and could speed up CPU computations.
2017-07-05 16:14:50.392761: W tensorflow/core/platform/cpu_feature_guard.cc:45] The 
TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-05 16:14:50.392767: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-07-05 16:14:50.392772: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-05 16:14:50.392776: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
```
I am assuming the issue is permissions related or that the file can't be found but rather than failing or giving an error it just runs indefinitely. I'm not entirely sure if this is happening during the string_input_producer step, the read_up_to step or even as part of the shuffle_batch. It seems like a bug that nothing is causing the code to fail.

    files = tf.concat([
      tf.train.match_filenames_once(filename)
      for filename in filenames
    ], axis=0)

    filename_queue = tf.train.string_input_producer(
        files, num_epochs=num_epochs, shuffle=shuffle)
    reader = tf.TextLineReader(skip_header_lines=skip_header_lines)

    _, rows = reader.read_up_to(filename_queue, num_records=batch_size)
    # DNNLinearCombinedClassifier expects rank 2 tensors.
    row_columns = tf.expand_dims(rows, -1)
    columns = tf.decode_csv(row_columns, record_defaults=CSV_COLUMN_DEFAULTS)
    features = dict(zip(CSV_COLUMNS, columns))

    # Remove unused columns
    for col in UNUSED_COLUMNS:
      features.pop(col)

    if shuffle:
      # This operation maintains a buffer of Tensors so that inputs are
      # well shuffled even between batches.
      features = tf.train.shuffle_batch(
          features,
          batch_size,
          capacity=batch_size * 10,
          min_after_dequeue=batch_size*2 + 1,
          num_threads=multiprocessing.cpu_count(),
          enqueue_many=True,
          allow_smaller_final_batch=True
      )

"
11307,Feature are incompatible with given information in evaluate() using contrib.learn.SVM,"Code is as follows:
```
def svm_tf(file):
	X,Y,training_size, index = process_data(file)
	def input_fn():
		return {
              'example_id': tf.constant(index[:training_size]),
              'multi_dim_feature': tf.constant(X[:training_size].values.tolist()),
        }, tf.constant(Y[:training_size])

	feature_columns = [tf.contrib.layers.real_valued_column(""multi_dim_feature"",dimension=4)]
	svm = learn.SVM(feature_columns=feature_columns,
					l1_regularization=0.0,
					l2_regularization=1.0,
					example_id_column='example_id')	
	svm.fit(input_fn=input_fn,steps=50)

        def test_input():
		return{
		'example_id': tf.constant(index[training_size:]),
		'features': tf.constant(X[training_size:].values.tolist())
		}, tf.constant(Y[training_size:])
	 

	accuracy = svm.evaluate(input_fn=test_input,steps=1)['accuracy']
	print('\nAccuracy :{0:f}\n'.format(accuracy))
```

	
	


However, when I run the program, it runs into error as follows:
```
Traceback (most recent call last):
  File ""subscriber.py"", line 84, in <module>
    svm_tf(file)
  File ""subscriber.py"", line 75, in svm_tf
    accuracy = svm.evaluate(input_fn=test_input,steps=1)['accuracy']
  File ""/home/annie/.local/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py"", line 289, in new_func
    return func(*args, **kwargs)
  File ""/home/annie/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 543, in evaluate
    log_progress=log_progress)
  File ""/home/annie/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 827, in _evaluate_model
    self._check_inputs(features, labels)
  File ""/home/annie/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 757, in _check_inputs
    (str(features), str(self._features_info)))
ValueError: Features are incompatible with given information. Given features: {'example_id': <tf.Tensor 'Const:0' shape=(1000,) dtype=string>, 'features': <tf.Tensor 'Const_1:0' shape=(1000, 4) dtype=float32>}, required signatures: {'example_id': TensorSignature(dtype=tf.string, shape=TensorShape([Dimension(4000)]), is_sparse=False), 'multi_dim_feature': TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(4000), Dimension(4)]), is_sparse=False)}.
```

I cannot find any relevant questions online and therefore is very lost
Please help! Thanks in advance
"
11304,TensorFlow on Kieler Open Source und Linux Tage?,"Hi,

I didn't find any contact information for the TensorFlow project, so I try it here :-)

We are organising our 15th ""Kieler Open Source und Linux Tage"" (northern of Germany, www.kielux.de), a conference with 4 parallel tracks with talks and workshops and a smal exhibition for open source community projects and companies.

Is there anybody who would like to hold a talk and/or give a TensorFlow workshop and/or make a booth on our event (14th - 16th September)?

Please answer by eMail to kontakt @ kilux.de .

Cu Hauke"
11303,Catch keyboard interrupt in session run,"Right now, Ctrl+c does not abort a long session run."
11301,Blas SGEMM launch failed,"- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: I am using Resnet code from tensorflow models with some modifications.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Fedora 24
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: ('v1.2.0-rc2-21-g12f033d', '1.2.0')
- **Python version**: 2.7
- **CUDA/cuDNN version**: cuda_8.0.61-cudnnv5
- **GPU model and memory**: Nvidia Titan X, 12 GB

I am training a Resnet model on my own data from scratch. After successfully running for 65700 steps, it crashed with the following error:

2017-06-30 16:27:50.302438: E tensorflow/stream_executor/cuda/cuda_blas.cc:543] failed to run cuBLAS routine cublasSgemm_v2: CUBLAS_STATUS_EXECUTION_FAILED
Traceback (most recent call last):
  File ""resnet_main.py"", line 178, in <module>
    if z%100 == 0:
  File ""/s/chopin/l/grad/prady/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""resnet_main.py"", line 171, in main
    tf.logging.info('Loading checkpoint %s', ckpt_state.model_checkpoint_path)
  File ""resnet_main.py"", line 90, in train
    mon_sess.run(model.train_op)
  File ""/s/chopin/l/grad/prady/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 505, in run
    run_metadata=run_metadata)
  File ""/s/chopin/l/grad/prady/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 842, in run
    run_metadata=run_metadata)
  File ""/s/chopin/l/grad/prady/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 798, in run
    return self._sess.run(*args, **kwargs)
  File ""/s/chopin/l/grad/prady/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 952, in run
    run_metadata=run_metadata)
  File ""/s/chopin/l/grad/prady/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 798, in run
    return self._sess.run(*args, **kwargs)
  File ""/s/chopin/l/grad/prady/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 789, in run
    run_metadata_ptr)
  File ""/s/chopin/l/grad/prady/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 997, in _run
    feed_dict_string, options, run_metadata)
  File ""/s/chopin/l/grad/prady/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1132, in _do_run
    target_list, options, run_metadata)
  File ""/s/chopin/l/grad/prady/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1152, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InternalError: Blas SGEMM launch failed : m=12544, n=1024, k=256
	 [[Node: unit_3_2/sub3/conv3/Conv2D = Conv2D[T=DT_FLOAT, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/gpu:0""](unit_3_2/sub3/leaky_relu, unit_3_2/sub3/conv3/DW/read)]]
	 [[Node: train_step/update/_6858 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_15509_train_step/update"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

Caused by op u'unit_3_2/sub3/conv3/Conv2D', defined at:
  File ""resnet_main.py"", line 178, in <module>
    if z%100 == 0:
  File ""/s/chopin/l/grad/prady/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""resnet_main.py"", line 171, in main
    tf.logging.info('Loading checkpoint %s', ckpt_state.model_checkpoint_path)
  File ""resnet_main.py"", line 31, in train
    model.build_graph()
  File ""/s/chopin/l/grad/prady/PycharmProjects/GestureRecognition/frame/resnet_model.py"", line 42, in build_graph
    self._build_model()
  File ""/s/chopin/l/grad/prady/PycharmProjects/GestureRecognition/frame/resnet_model.py"", line 95, in _build_model
    x = res_func(x, filters[3], filters[3], self._stride_arr(1), False)
  File ""/s/chopin/l/grad/prady/PycharmProjects/GestureRecognition/frame/resnet_model.py"", line 245, in _bottleneck_residual
    x = self._conv('conv3', x, 1, out_filter / 4, out_filter, [1, 1, 1, 1])
  File ""/s/chopin/l/grad/prady/PycharmProjects/GestureRecognition/frame/resnet_model.py"", line 273, in _conv
    return tf.nn.conv2d(x, kernel, strides, padding='SAME')
  File ""/s/chopin/l/grad/prady/.local/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 399, in conv2d
    data_format=data_format, name=name)
  File ""/s/chopin/l/grad/prady/.local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 767, in apply_op
    op_def=op_def)
  File ""/s/chopin/l/grad/prady/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2506, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/s/chopin/l/grad/prady/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1269, in __init__
    self._traceback = _extract_stack()

InternalError (see above for traceback): Blas SGEMM launch failed : m=12544, n=1024, k=256
	 [[Node: unit_3_2/sub3/conv3/Conv2D = Conv2D[T=DT_FLOAT, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/gpu:0""](unit_3_2/sub3/leaky_relu, unit_3_2/sub3/conv3/DW/read)]]
	 [[Node: train_step/update/_6858 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_15509_train_step/update"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

2017-06-30 16:27:55.680213: E tensorflow/stream_executor/event.cc:33] error destroying CUDA event in context 0x564291240800: CUDA_ERROR_MISALIGNED_ADDRESS

On another machine with exact configuration, it is still running successfully (425,000 steps as of now). I don't understand why it crashed on one machine after running for 65,700 steps."
11300,State of GPU support for commercial Android devices,"Question has been asked in  [this thread](https://github.com/tensorflow/tensorflow/issues/663) but got no answer. Just curious what's the plans of TF team to support Android GPUs (or no plan at all) for commercial devices such as Nexus. I understand OpenCL is not included in Android now, but we still have RenderScript. And [some work](https://github.com/nesl/RSTensorFlow/tree/matmul_and_conv/tensorflow/contrib/android_renderscript_ops) has already been put to this end.

It would be great to know it from TF developers."
11299,undefined reference to 'soc_interface_AllocateInOutNodeBuffers'  Hexagon build failed with latest commit,"OS: Ubuntu 16.04 64bits
 Android Version: 7.1 (Nougat)
 NDK Version: android-ndk-r12b
 HEXAGON SDK: 3.1
 nnlib source: https://source.codeaurora.org/quic/hexagon_nn/nnlib

I have cloned to git commit id - 43a819e1386195f7010f8ca9c74ed96ab81913d8

when I try to build executable for hexagon,
`CC_PREFIX=${CC_PREFIX} NDK_ROOT=${NDK_ROOT} ""${BUILD_ALL_ANDROID_PATH}"" -x ""${GEN_LIBS_DIR}"" -s ""${TF_ROOT_DIR}/tensorflow/contrib/makefile/sub_makefiles/hexagon_graph_execution/Makefile.in"" -t hexagon_graph_execution`

I am getting build error,
```
tensorflow/tensorflow/contrib/makefile/gen/lib/libtensorflow-core.a(hexagon_control_wrapper.o):hexagon_control_wrapper.cc:function tensorflow::HexagonControlWrapper::Init(tensorflow::RemoteFusedGraphExecuteInfo const&): error: undefined reference to 'soc_interface_AllocateInOutNodeBuffers'
collect2: error: ld returned 1 exit status
```

build changes are moved partially out of `tensorflow/contrib/makefile/sub_makefiles/hexagon_graph_execution/Makefile.in`

is this the possible cause for error.

I am not sure I can pull out latest commit and build over that, but right now I am stuck at build fail.
Help me with a fix ."
11297,Matrix Inverse in TensorFlow,"I have a problem related to calculating matrix inverse in TensorFlow python interface version 1.1.0 on Linux. What I'm now trying to do is that, I have an input vector as `tensorflow.float64`, say `S` and a value `V`. I augment the vector `S` to be polynomial fashion in the form ![A=[ 1, S, S^2, S^3 ]](https://latex.codecogs.com/gif.download?A%3D%5B%201%2C%20S%2C%20S%5E2%2C%20S%5E3%20%5D) and want to do a regression on `V`. I choose to compute the linear regression myself instead of using the infrastructure from tensorflow, where the regression is conducted as ![\beta=(A^TA)^{-1}A^T\times V](https://latex.codecogs.com/gif.download?%5Cbeta%3D%28A%5ETA%29%5E%7B-1%7DA%5ET%5Ctimes%20V). The problem occurs at the ![(A^TA)^{-1}](https://latex.codecogs.com/gif.download?%28A%5ETA%29%5E%7B-1%7D) step, where the inverse multiply the original matrix does not give an identity. However, if I feed the ![A^TA](https://latex.codecogs.com/gif.download?A%5ETA) as a constant matrix containing the same value as the preprocessed input, the result is really the inverse of itself.

The code below is a runnable version with parameter `control=True` turns on the constant input matrix version where the inverse behaves correctly. Three matrices are output by running the program, the original matrix, the ""inverse"" by `tf.matrix_inverse`, and the multiplication of the ""inverse"" with the original matrix aiming to recover an identify. `control=False` gives the same original matrix as `control=True` run, however, the recovered ""identity"" is not correct with `control=False`. I suspect something wrong with the data flow during preprocessing. However, limited by my experience with TensorFlow, I cannot spot it. Would you mind a help why the `tf.matrix_inverse` does not work as expected?


    import tensorflow as tf
    import pprint
    
    def matrixInverse( control=False ):
        '''Compute inverse of a matrix.
    
    Parameters
    ----------
    control : bool
        whether to use control group or not.
        '''
        X = tf.constant( [ [100. , 100., 100., 100.],
             [ 101.75497118 ,  92.84824314 ,  95.09528336 , 103.24955959],
             [ 92.33287485 ,  95.86868862 ,  84.70664178 , 107.9505686 ],
             [ 85.86109085 ,  99.05621029 ,  94.24396596 , 119.60257907] ], dtype=tf.float64 )
    
        # extract input X
        s = tf.slice( X, [ 2, 0 ], [ 1, 4 ])
        s = tf.squeeze(s)
        s1 = tf.multiply( tf.ones( 4, dtype=tf.float64 ), s )
        s2 = tf.multiply( s, s )
        s3 = tf.multiply( tf.multiply( s, s ), s )
    
        A = tf.concat( [ tf.ones( 4, dtype=tf.float64 ), s1, s2, s3 ], 0 )
        A = tf.reshape( A, [ 4, 4 ] )
    
        # filter only the first element in the selected row
        itm = tf.constant( [ True, False, False, False ], dtype=tf.bool )
    
        A = tf.boolean_mask( tf.transpose(A), itm )
    
        if control:
            ATA = tf.constant([[  1.00000000e+00,   9.23328748e+01,   8.52535978e+03,   7.87170977e+05],
                         [  9.23328748e+01,   8.52535978e+03,   7.87170977e+05,   7.26817593e+07],
                         [  8.52535978e+03,   7.87170977e+05,   7.26817593e+07,   6.71091579e+09],
                         [  7.87170977e+05,   7.26817593e+07,   6.71091579e+09,   6.19638148e+11]], dtype = tf.float64)
        else:
            ATA = tf.matmul( tf.transpose( A ), A )
    
        inverseATA = tf.matrix_inverse( ATA )
    
        sess = tf.Session()
        pprint.pprint( sess.run( [ ATA, inverseATA, tf.matmul( ATA, inverseATA ) ] ) )"
11296,No OpKernel was registered to support Op 'LesseEqual' with these attrs on Android,"On Android I am trying to load a tensorflow graph which I have frozen by using convert_variables_to_constants however I am getting:

com.example.trio.tensordemo E/TensorflowDebug: 
java.lang.IllegalArgumentException: No OpKernel was registered to support Op 'LessEqual' with these attrs.  Registered devices: [CPU], 
Registered kernels:
<no registered kernels>
[[Node: bidirectional_rnn/fw/fw/LessEqual = LessEqual[T=DT_INT32, _device=""/device:GPU:0""](bidirectional_rnn/fw/fw/Max, bidirectional_rnn/fw/fw/LessEqual/y)]]
This is what the node looks like:

name: ""bidirectional_rnn/fw/fw/LessEqual_1""
op: ""LessEqual""
input: ""bidirectional_rnn/fw/fw/Max""
input: ""bidirectional_rnn/fw/fw/LessEqual_1/y""
device: ""/device:CPU:0""
attr {
  key: ""T""
  value {
    type: DT_INT32
  }
}
The tensorflow version I trained and loaded in Android are both r1.2.

"
11295,Different batch size different result with inception_v2,"I user inception_v2 as a base network for classification. During training, the batchsize=128. During testing, if the batchsize=128, everything is ok. However, if the batchsize is smaller than 128 the results are different. And the precision declines as the batchsize drops. If the batchsize=1, the network will failed. I also used inception_v3 and inception_v1, the same problems appered. However, if the base network is replaced with Alex network (tensorflow), everything goes well. 
I also replace the inception_v2 with vgg (slim), and everything goes well. 
The bug is associated with inception_v1~v3.  I think I have not used inception_v2 properly. Did anyone encounter similar problems?"
11293,tf.reverse doesn't support tensor with unknown shape,"### System information
   ubuntu 14.04
   tensorflow installed from binary
   tensorflow version: tensorflow-gpu  1.2.1
   python version: python 2.7
   CUDA/CuDNN version: cuda 8.0/ CUDNN 5.1
   GPU model
   
You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

### Describe the problem
Hey tensorflow community. I want to feed an unknown shape tensor into tf.placeholder. Then it is reversed. But it reports errors
a = tf.placeholder(dtype = tf.int64,shape = [None])
b = tf.reverse(a,axis = 0)

### Source code / logs
![1](https://user-images.githubusercontent.com/15981416/27864587-c449c5d4-61c1-11e7-852d-fa8911f9e429.png)
![2](https://user-images.githubusercontent.com/15981416/27864596-ca4d3790-61c1-11e7-9568-bc822a9917bb.png)


"
11290,Restoring SavedModel in //tensorflow/c:c_api_test fails ,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04 
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version**: 'v1.2.1-0-gb4957ff', '1.2.1'
- **Python version**: 2.7.12
- **Bazel version**: 0.4.5
- **CUDA/cuDNN version**: No GPU
- **GPU model and memory**: No GPU
- **Exact command to reproduce**: bazel test //tensorflow/c:c_api_test

### The problem:
While executing c_api_test from c module on a big endian machine, it fails while restoring SavedModel(tensorflow/cc/saved_model/testdata/half_plus_two/00000123). There is a warning displayed `Reading a bundle with different endianness from the reader`. 

Similarly, other tests from cc, java module which read this SavedModel from testdata also fail due to endianness mismatch.

What would be appropriate way to handle this failure on big endian?
Is there a way to convert the above SavedModel to Big Endian while reading it in the tests?

### Test Logs:
```
[ RUN      ] CAPI.SavedModel
2017-06-29 09:04:33.999662: I tensorflow/cc/saved_model/loader.cc:226] Loading SavedModel from: <HOME>/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/tensorflow/bazel-out/local-opt/bin/tensorflow/c/c_api_test.runfiles/org_tensorflow/tensorflow/cc/saved_model/testdata/half_plus_two/00000123
2017-06-29 09:04:34.039733: I tensorflow/cc/saved_model/loader.cc:145] Restoring SavedModel bundle.
2017-06-29 09:04:34.079006: W tensorflow/core/framework/op_kernel.cc:1158] Unimplemented: Reading a bundle with different endianness from the reader
2017-06-29 09:04:34.079311: W tensorflow/core/framework/op_kernel.cc:1158] Unimplemented: Reading a bundle with different endianness from the reader
2017-06-29 09:04:34.079363: W tensorflow/core/framework/op_kernel.cc:1158] Unimplemented: Reading a bundle with different endianness from the reader
2017-06-29 09:04:34.079708: I tensorflow/cc/saved_model/loader.cc:274] Loading SavedModel: fail. Took 136931 microseconds.
tensorflow/c/c_api_test.cc:1198: Failure
      Expected: TF_OK
      Which is: 0
To be equal to: TF_GetCode(s)
      Which is: 12
Reading a bundle with different endianness from the reader
         [[Node: save/RestoreV2 = RestoreV2[_output_shapes=[[]], dtypes=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/cpu:0""](_arg_save/Const_0_1, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]
```"
11289,argument --learning_rate: conflicting option string: --learning_rate,"Hi everyone,

I'm currently learning how to user Tensorflow, but when I'm running the fully_connected_feed.py file from tensorflow website. It returns the following error: 
argument --learning_rate: conflicting option string: --learning_rate

Does someone know how to fix the issue?

This is the entire Error message: 


  File ""<ipython-input-8-db6c9214eb7b>"", line 1, in <module>
    debugfile('C:/Users/X188068/Desktop/Merck/Vevey Deviation/fully connected feed__Mechanics 101.py', wdir='C:/Users/X188068/Desktop/Merck/Vevey Deviation')

  File ""C:\Users\X188068\AppData\Local\Continuum\Anaconda3\lib\site-packages\spyder\utils\site\sitecustomize.py"", line 888, in debugfile
    debugger.run(""runfile(%r, args=%r, wdir=%r)"" % (filename, args, wdir))

  File ""C:\Users\X188068\AppData\Local\Continuum\Anaconda3\lib\bdb.py"", line 431, in run
    exec(cmd, globals, locals)

  File ""<string>"", line 1, in <module>

  File ""C:\Users\X188068\AppData\Local\Continuum\Anaconda3\lib\site-packages\spyder\utils\site\sitecustomize.py"", line 866, in runfile
    execfile(filename, namespace)

  File ""C:\Users\X188068\AppData\Local\Continuum\Anaconda3\lib\site-packages\spyder\utils\site\sitecustomize.py"", line 102, in execfile
    exec(compile(f.read(), filename, 'exec'), namespace)

  File ""c:/users/x188068/desktop/merck/vevey deviation/fully connected feed__mechanics 101.py"", line 25, in <module>
    flags.DEFINE_float('learning_rate', 0.01, 'Initial learning rate.')

  File ""C:\Users\X188068\AppData\Local\Continuum\Anaconda3\lib\site-packages\tensorflow\python\platform\flags.py"", line 132, in DEFINE_float
    _define_helper(flag_name, default_value, docstring, float)

  File ""C:\Users\X188068\AppData\Local\Continuum\Anaconda3\lib\site-packages\tensorflow\python\platform\flags.py"", line 65, in _define_helper
    type=flagtype)

  File ""C:\Users\X188068\AppData\Local\Continuum\Anaconda3\lib\argparse.py"", line 1348, in add_argument
    return self._add_action(action)

  File ""C:\Users\X188068\AppData\Local\Continuum\Anaconda3\lib\argparse.py"", line 1711, in _add_action
    self._optionals._add_action(action)

  File ""C:\Users\X188068\AppData\Local\Continuum\Anaconda3\lib\argparse.py"", line 1552, in _add_action
    action = super(_ArgumentGroup, self)._add_action(action)

  File ""C:\Users\X188068\AppData\Local\Continuum\Anaconda3\lib\argparse.py"", line 1362, in _add_action
    self._check_conflict(action)

  File ""C:\Users\X188068\AppData\Local\Continuum\Anaconda3\lib\argparse.py"", line 1501, in _check_conflict
    conflict_handler(action, confl_optionals)

  File ""C:\Users\X188068\AppData\Local\Continuum\Anaconda3\lib\argparse.py"", line 1510, in _handle_conflict_error
    raise ArgumentError(action, message % conflict_string)

ArgumentError: argument --learning_rate: conflicting option string: --learning_rate
"
11287,Missing definition in Getting Started With TensorFlow guide,"
### System information
- macOS 10.12.5
- installed from binary
- Tensorflow v1.2.0-1751-g43a819e13 1.2.1
- Python 3.6.1
- Bazel 0.5.2-homebrew

### Describe the problem
The custom model section of the [""Getting Started With TensorFlow"" guide](https://www.tensorflow.org/get_started/get_started) doesn't define ""eval_input_fn"".

I ran across the error when I copied the code line by line and ran it on my machine. I fixed it by adding the following definition after ""input_fn"" is defined:

```
eval_input_fn = tf.contrib.learn.io.numpy_input_fn({""x"":x_eval}, y_eval,
                                                   4, num_epochs = 1000);
```

### Source code / logs
Code in Guide:
```
import numpy as np
import tensorflow as tf
# Declare list of features, we only have one real-valued feature
def model(features, labels, mode):
  # Build a linear model and predict values
  W = tf.get_variable(""W"", [1], dtype=tf.float64)
  b = tf.get_variable(""b"", [1], dtype=tf.float64)
  y = W*features['x'] + b
  # Loss sub-graph
  loss = tf.reduce_sum(tf.square(y - labels))
  # Training sub-graph
  global_step = tf.train.get_global_step()
  optimizer = tf.train.GradientDescentOptimizer(0.01)
  train = tf.group(optimizer.minimize(loss),
                   tf.assign_add(global_step, 1))
  # ModelFnOps connects subgraphs we built to the
  # appropriate functionality.
  return tf.contrib.learn.ModelFnOps(
      mode=mode, predictions=y,
      loss=loss,
      train_op=train)

estimator = tf.contrib.learn.Estimator(model_fn=model)
# define our data sets
x_train = np.array([1., 2., 3., 4.])
y_train = np.array([0., -1., -2., -3.])
x_eval = np.array([2., 5., 8., 1.])
y_eval = np.array([-1.01, -4.1, -7, 0.])
input_fn = tf.contrib.learn.io.numpy_input_fn({""x"": x_train}, y_train, 4, num_epochs=1000)

# WHERE I ADDED THE DEFINITION

# train
estimator.fit(input_fn=input_fn, steps=1000)
# Here we evaluate how well our model did. 
train_loss = estimator.evaluate(input_fn=input_fn)
eval_loss = estimator.evaluate(input_fn=eval_input_fn)
print(""train loss: %r""% train_loss)
print(""eval loss: %r""% eval_loss)
```

Error:
```
Traceback (most recent call last):
  File ""custom_model.py"", line 37, in <module>
    eval_loss = estimator.evaluate(input_fn=eval_input_fn);
NameError: name 'eval_input_fn' is not defined
```"
11286,tensorboard fetching sprite image... parsing metadata takes forever,"When i study tensorboard embedding, My code refers #6322 @danielgordon10. Whatever my datasets size is(I modify `batch_size` , `epoches` and `embedding data_szie`, but it doesn't works ), `localhost:6006#embedding` takes forever and the browser  shows always `fetching sprite image... parsing metadata`. What should i do? Could someone give me any ideas?
"
11284,"Error when build tfprof, bazel version 0.5.2","Hi, I want to try with tfprof, but failed to build the tool. The error information is as follow. 

### System information
- **OS Platform and Distribution**:  Linux Ubuntu 14.04
- **Bazel version (if compiling from source)**: 0.5.2
- **Exact command to reproduce**: ```bazel build --config opt tensorflow/tools/tfprof/...```

```
~/tensorflow-src$ ~/bin/bazel build --config opt tensorflow/tools/tfprof/...
Extracting Bazel installation...
...........
WARNING: Config values are not defined in any .rc file: opt
ERROR: /home/feigao/tensorflow-src/tensorflow/core/BUILD:1415:1: no such target '//tensorflow/tools/git:gen/spec.json': target 'gen/spec.json' not declared in package 'tensorflow/tools/git' defined by /home/feigao/tensorflow-src/tensorflow/tools/git/BUILD and referenced by '//tensorflow/core:version_info_gen'.
ERROR: /home/feigao/tensorflow-src/tensorflow/core/BUILD:1415:1: no such target '//tensorflow/tools/git:gen/head': target 'gen/head' not declared in package 'tensorflow/tools/git' defined by /home/feigao/tensorflow-src/tensorflow/tools/git/BUILD and referenced by '//tensorflow/core:version_info_gen'.
ERROR: /home/feigao/tensorflow-src/tensorflow/core/BUILD:1415:1: no such target '//tensorflow/tools/git:gen/branch_ref': target 'gen/branch_ref' not declared in package 'tensorflow/tools/git' defined by /home/feigao/tensorflow-src/tensorflow/tools/git/BUILD and referenced by '//tensorflow/core:version_info_gen'.
ERROR: Analysis of target '//tensorflow/tools/tfprof/internal:tfprof_tensor_test' failed; build aborted.
```"
11281,Failed to load the native TensorFlow runtime.,"### Describe the problem
I'm not sure what I did incorrectly. I opened up the anaconda prompts and followed the steps here: https://gist.github.com/jeffgreenca/28e0fe58644b8af48f97a3e18fe08302

### Source code / logs
Traceback (most recent call last):

  File ""<ipython-input-2-41389fad42b5>"", line 1, in <module>
    import tensorflow as tf

  File ""/sscc/home/s/snu8359/.conda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *

  File ""/sscc/home/s/snu8359/.conda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow

  File ""/sscc/home/s/snu8359/.conda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 52, in <module>
    raise ImportError(msg)

ImportError: Traceback (most recent call last):
  File ""/sscc/home/s/snu8359/.conda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/sscc/home/s/snu8359/.conda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/sscc/home/s/snu8359/.conda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/sscc/home/s/snu8359/.conda/envs/tensorflow/lib/python3.5/imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""/sscc/home/s/snu8359/.conda/envs/tensorflow/lib/python3.5/imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: /lib64/libc.so.6: version `GLIBC_2.14' not found (required by /sscc/home/s/snu8359/.conda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

"
11280,Can't access gs:// logfiles using tensorboard,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 
Ubuntu 14.04
- **TensorFlow installed from (source or binary)**: 
pip install
- **TensorFlow version (use command below)**:
1.2.1
- **Python version**:  
3.6
- **Exact command to reproduce**:
`tensorboard --logdir=gs://mybucket
`

### Describe the problem
When trying to run tensorboard from a google cloud storage bucket the following error occurs:

`tensorflow.python.framework.errors_impl.UnimplementedError: File system scheme gs not implemented
`

Even after running gs authentication
`gcloud auth application-default login`


### Source code / logs

I was following [this guide](https://github.com/tensorflow/models/blob/master/object_detection/g3doc/running_pets.md) on training a pet object detector"
11279,Want to build tensorflow for android but stuck at this problem.,"OS Platform and Distribution : Windows 10
Bazel version :0.5.2

C:\Users\dulam\tensorflow>bazel build -c opt //tensorflow/contrib/android:libtensorflow_inference.so
ERROR: C:/users/dulam/tensorflow/tensorflow/core/BUILD:1415:1: no such target '//tensorflow/tools/git:gen/spec.json': target 'gen/spec.json' not declared in package 'tensorflow/tools/git' defined by C:/users/dulam/tensorflow/tensorflow/tools/git/BUILD and referenced by '//tensorflow/core:version_info_gen'.
ERROR: C:/users/dulam/tensorflow/tensorflow/core/BUILD:1415:1: no such target '//tensorflow/tools/git:gen/head': target 'gen/head' not declared in package 'tensorflow/tools/git' defined by C:/users/dulam/tensorflow/tensorflow/tools/git/BUILD and referenced by '//tensorflow/core:version_info_gen'.
ERROR: C:/users/dulam/tensorflow/tensorflow/core/BUILD:1415:1: no such target '//tensorflow/tools/git:gen/branch_ref': target 'gen/branch_ref' not declared in package 'tensorflow/tools/git' defined by C:/users/dulam/tensorflow/tensorflow/tools/git/BUILD and referenced by '//tensorflow/core:version_info_gen'.
ERROR: Analysis of target '//tensorflow/contrib/android:libtensorflow_inference.so' failed; build aborted."
11278,Examples in 'Getting started with tensor flow' use deprecated methods,"https://www.tensorflow.org/get_started/get_started 
Basic Usage example output:

WARNING:tensorflow:Using temporary folder as model directory: C:\Users\pocherka\AppData\Local\Temp\tmpaq48b_3u
WARNING:tensorflow:From C:\Users\pocherka\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\contrib\learn\python\learn\estimators\head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
WARNING:tensorflow:From C:\Users\pocherka\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\contrib\learn\python\learn\estimators\head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
WARNING:tensorflow:From C:\Users\pocherka\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\contrib\learn\python\learn\estimators\head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
train loss: {'global_step': 1000, 'loss': 2.3828899e-11}
eval loss: {'global_step': 1000, 'loss': 0.0025255322}sic usage

"
11277,Tensorflow Windows Bug with BeamSearchDecoder,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, 
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: Pip Binary 
- **TensorFlow version (use command below)**: 1.2.1
- **Python version**: 3.5
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: 5.1
- **GPU model and memory**: Nvidia Gtx 1080 (8 GB)

### Describe the problem

Tensorflow on Windows gives an error (""Multiple OpKernel registrations match NodeDef"") when I try to use BeamSearchDecoder in the seq2seq module. The same code works well on Ubuntu. Someone else on stackoverflow also had the [same issue](https://stackoverflow.com/questions/44535111/error-when-restoring-model-multiple-opkernel-registrations-match-nodedef). I have attached a snippet of code that generates the same error on my computer (original code is much bigger).


### Source code to reproduce the problem
```
import tensorflow as tf
import numpy as np
sess = tf.Session()
cell1 = tf.contrib.rnn.BasicLSTMCell(90)
word_embedding = tf.convert_to_tensor(np.eye(1,1),dtype=tf.float32)
decoder = tf.contrib.seq2seq.BeamSearchDecoder(
                                                        cell=cell1,
                                                        embedding=lambda inputs : tf.nn.embedding_lookup(word_embedding, inputs),
                                                        start_tokens=[1],
                                                        end_token=2,
                                                        initial_state=cell1.zero_state(batch_size=3,dtype=tf.float32),
                                                        beam_width=3
)
outputs_decoding, last_state_decoding, _ = tf.contrib.seq2seq.dynamic_decode(
                        decoder, maximum_iterations=1)
sess.run(outputs_decoding)
```
### Error Message
```
Traceback (most recent call last):
  File ""C:\Program Files\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 1139, in _do_call
    return fn(*args)
  File ""C:\Program Files\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 1117, in _run_fn
    self._extend_graph()
  File ""C:\Program Files\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 1166, in _extend_graph
    self._session, graph_def.SerializeToString(), status)
  File ""C:\Program Files\Python35\lib\contextlib.py"", line 66, in __exit__
    next(self.gen)
  File ""C:\Program Files\Python35\lib\site-packages\tensorflow\python\framework\errors_impl.py"", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: Multiple OpKernel registrations match NodeDef 'decoder/GatherTree = GatherTree[T=DT_INT32](decoder/TensorArrayStack_1/TensorArrayGatherV3, decoder/TensorArrayStack_2/TensorArrayGatherV3, decoder/while/Exit_11)': 'op: ""GatherTree"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }' and 'op: ""GatherTree"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }'
         [[Node: decoder/GatherTree = GatherTree[T=DT_INT32](decoder/TensorArrayStack_1/TensorArrayGatherV3, decoder/TensorArrayStack_2/TensorArrayGatherV3, decoder/while/Exit_11)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""a.py"", line 16, in <module>
    sess.run(outputs_decoding)
  File ""C:\Program Files\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 789, in run
    run_metadata_ptr)
  File ""C:\Program Files\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 997, in _run
    feed_dict_string, options, run_metadata)
  File ""C:\Program Files\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 1132, in _do_run
    target_list, options, run_metadata)
  File ""C:\Program Files\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 1152, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Multiple OpKernel registrations match NodeDef 'decoder/GatherTree = GatherTree[T=DT_INT32](decoder/TensorArrayStack_1/TensorArrayGatherV3, decoder/TensorArrayStack_2/TensorArrayGatherV3, decoder/while/Exit_11)': 'op: ""GatherTree"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }' and 'op: ""GatherTree"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }'
         [[Node: decoder/GatherTree = GatherTree[T=DT_INT32](decoder/TensorArrayStack_1/TensorArrayGatherV3, decoder/TensorArrayStack_2/TensorArrayGatherV3, decoder/while/Exit_11)]]

Caused by op 'decoder/GatherTree', defined at:
  File ""a.py"", line 15, in <module>
    decoder, maximum_iterations=1)
  File ""C:\Program Files\Python35\lib\site-packages\tensorflow\contrib\seq2seq\python\ops\decoder.py"", line 296, in dynamic_decode
    final_outputs, final_state, final_sequence_lengths)
  File ""C:\Program Files\Python35\lib\site-packages\tensorflow\contrib\seq2seq\python\ops\beam_search_decoder.py"", line 280, in finalize
    sequence_length=sequence_lengths)
  File ""C:\Program Files\Python35\lib\site-packages\tensorflow\contrib\seq2seq\ops\gen_beam_search_ops.py"", line 43, in gather_tree
    sequence_length=sequence_length, name=name)
  File ""C:\Program Files\Python35\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 767, in apply_op
    op_def=op_def)
  File ""C:\Program Files\Python35\lib\site-packages\tensorflow\python\framework\ops.py"", line 2506, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""C:\Program Files\Python35\lib\site-packages\tensorflow\python\framework\ops.py"", line 1269, in __init__
    self._traceback = _extract_stack()

InvalidArgumentError (see above for traceback): Multiple OpKernel registrations match NodeDef 'decoder/GatherTree = GatherTree[T=DT_INT32](decoder/TensorArrayStack_1/TensorArrayGatherV3, decoder/TensorArrayStack_2/TensorArrayGatherV3, decoder/while/Exit_11)': 'op: ""GatherTree"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }' and 'op: ""GatherTree"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }'
         [[Node: decoder/GatherTree = GatherTree[T=DT_INT32](decoder/TensorArrayStack_1/TensorArrayGatherV3, decoder/TensorArrayStack_2/TensorArrayGatherV3, decoder/while/Exit_11)]]
```"
11275,tfcompile with tf.nn.dynamic_rnn crashes,"Trying to build a C++ binary with tfcompile crashes with `INVALID ARGUMENTS: Mising Exit successor to rnn/while/Switch` if the graph contains `tf.nn.dynamic_rnn`, but it works with `tf.nn.static_rnn`. Why is this?"
11273,Memory leak when using `tf.layers`,"### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.2.1
- **Python version**: 3.5
- **Exact command to reproduce**:

``` python
import os

import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
import psutil


def memory():
    pid = os.getpid()
    py = psutil.Process(pid)
    memory_use = py.memory_info()[0] / 2. ** 30
    return memory_use


memory_usage = []
for i in range(1000):
    memory_usage.append(memory())
    print(""iter"", i, memory_usage[-1])

    with tf.Graph().as_default():
        x = tf.constant(np.ones((100, 1000), dtype=np.float32))

        # memory leak
        x = tf.layers.dense(x, units=1000)

        # no memory leak
        # with tf.variable_scope(""layer"", reuse=False):
        #     x = tf.matmul(x, tf.get_variable(
        #         ""w"", shape=(1000, 1000), dtype=tf.float32,
        #         initializer=tf.ones_initializer()))

plt.figure()
plt.plot(memory_usage)
plt.xlabel(""iterations"")
plt.ylabel(""memory usage"")
plt.show()
```

### Describe the problem
There is some kind of memory leak when repeatedly building graphs containing `tf.layers` elements.  The example above shows the memory usage comparing what I think should be roughly equivalent implementations, one using `tf.layers.dense` and the other using manually created kernels/matmul ops.  When using `tf.layers.dense` the memory usage continually increases, whereas the manual approach shows memory being periodically cleaned up by garbage collection.  So my guess would be that there is some internal reference to the `tf.layers` elements that is preventing them from being garbage collected.

not using `tf.layers.dense`:
![non_layer](https://user-images.githubusercontent.com/1952220/27835565-78f5628c-60a9-11e7-9134-971b5caba784.png)


using `tf.layers.dense`:
![with_layer](https://user-images.githubusercontent.com/1952220/27835536-570a2bda-60a9-11e7-8936-1631f67be3b0.png)



"
11272,error in tensorflow/tensorflow/examples/tutorials/word2vec/word2vec_basic.py,"### System information
== cat /etc/issue ===============================================
Linux ai 2.6.32-642.11.1.el6.x86_64 #1 SMP Fri Nov 18 19:25:05 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux
LSB_VERSION=base-4.0-amd64:base-4.0-noarch:core-4.0-amd64:core-4.0-noarch:graphics-4.0-amd64:graphics-4.0-noarch:printing-4.0-amd64:printing-4.0-noarch

== are we in docker =============================================
No

== compiler =====================================================
c++ (GCC) 4.9.3
Copyright © 2015 Free Software Foundation, Inc.

== uname -a =====================================================
Linux ai 2.6.32-642.11.1.el6.x86_64 #1 SMP Fri Nov 18 19:25:05 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy (1.13.0)
protobuf (3.3.0)
tensorflow (1.1.0)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.2.1
tf.GIT_VERSION = v1.2.0-5-g435cdfc
tf.COMPILER_VERSION = v1.2.0-5-g435cdfc
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH /usr/local/lib64:/usr/local/lib:
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
./newfile.sh: line 85: nvidia-smi: command not found

== cuda libs  ===================================================

### Describe the problem
I change the data set and encounter error which is ""TypeError: sequence index must be integer, not 'slice'"" in line 117. 

### Source code / logs
The code what i have changed is as below
![image](https://user-images.githubusercontent.com/524093/27833171-297c04ee-6104-11e7-88c6-90e963fc7f9c.png)

### What I Do
Change buffer[:] = data[:span] To buffer.extend(data[:span]) in line 117 and work well. Please check the code.  
Thank you for your attention."
11271,tensorflow.python.framework.errors.NotFoundError: No algorithm worked!,"I install the TensorFlow 0.10.0 on Ubuntu 14.0.4 with cuda 7.5 and cudnn 5.1.The GPU is GTX980 
when I run a softmax example on minst dataset the TensorFlow can work but when i build CNN with TensorFlow it will cause error.
```
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
Extracting MNIST_data/train-images-idx3-ubyte.gz
Extracting MNIST_data/train-labels-idx1-ubyte.gz
Extracting MNIST_data/t10k-images-idx3-ubyte.gz
Extracting MNIST_data/t10k-labels-idx1-ubyte.gz
Start to train the convolutional neural network......
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: GeForce GTX 980
major: 5 minor: 2 memoryClockRate (GHz) 1.2155
pciBusID 0000:02:00.0
Total memory: 3.94GiB
Free memory: 3.82GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x27e67f0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties: 
name: GeForce GTX 980
major: 5 minor: 2 memoryClockRate (GHz) 1.2155
pciBusID 0000:03:00.0
Total memory: 3.94GiB
Free memory: 3.87GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 1 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y Y 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 1:   Y Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980, pci bus id: 0000:02:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX 980, pci bus id: 0000:03:00.0)
E tensorflow/stream_executor/cuda/cuda_driver.cc:1115] failed to get elapsed time between events: CUDA_ERROR_NOT_READY
E tensorflow/stream_executor/cuda/cuda_driver.cc:1115] failed to get elapsed time between events: CUDA_ERROR_NOT_READY
E tensorflow/stream_executor/cuda/cuda_driver.cc:1115] failed to get elapsed time between events: CUDA_ERROR_NOT_READY
E tensorflow/stream_executor/cuda/cuda_driver.cc:1115] failed to get elapsed time between events: CUDA_ERROR_NOT_READY
E tensorflow/stream_executor/cuda/cuda_driver.cc:1115] failed to get elapsed time between events: CUDA_ERROR_NOT_READY
Traceback (most recent call last):
  File ""test.py"", line 69, in <module>
    test_cnn()  
  File ""test.py"", line 59, in test_cnn
    sess.run(fetches=Step_train, feed_dict={x:batch[0], y:batch[1], dropout_prob:0.5})  
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 710, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 908, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 958, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 978, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.NotFoundError: No algorithm worked!
	 [[Node: Conv2D_1 = Conv2D[T=DT_FLOAT, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/gpu:0""](MaxPool, weight_1/read)]]
Caused by op u'Conv2D_1', defined at:
  File ""test.py"", line 69, in <module>
    test_cnn()
  File ""test.py"", line 35, in test_cnn
    conv2_out = tf.nn.relu(conv_2d(pool1_out, w_conv2)+b_conv2)
  File ""test.py"", line 12, in conv_2d
    return tf.nn.conv2d(input=x, filter=w, strides=[1, 1, 1, 1], padding=""SAME"")
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py"", line 394, in conv2d
    data_format=data_format, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 703, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2317, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1239, in __init__
    self._traceback = _extract_stack()

E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:643] Deallocating stream with pending work
^CWrite failed: Broken pipe
```
if you can help me solve the problem or give some advice, it will be great"
11269,Build failure for r1.2  & master (r1.1 builds fine),"### System information
== cat /etc/issue ===============================================
Linux Lounge 4.11.8-200.fc25.x86_64 #1 SMP Thu Jun 29 16:13:56 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""25 (Workstation Edition)""
VERSION_ID=25
REDHAT_BUGZILLA_PRODUCT_VERSION=25
REDHAT_SUPPORT_PRODUCT_VERSION=25

== are we in docker =============================================
No

== compiler =====================================================
c++ (GCC) 6.3.1 20161221 (Red Hat 6.3.1-1)
Copyright (C) 2016 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux Lounge 4.11.8-200.fc25.x86_64 #1 SMP Thu Jun 29 16:13:56 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy (1.13.0)
protobuf (3.3.0)
tensorflow (1.2.1)
tensorflow-tensorboard (0.1.2)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.2.1
tf.GIT_VERSION = v1.2.0-1709-g679bb02
tf.COMPILER_VERSION = v1.2.0-1709-g679bb02
Sanity check: array([1], dtype=int32)
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""tensorflow/python/pywrap_tensorflow.py"", line 52, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""tensorflow/python/pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
ImportError: No module named pywrap_tensorflow_internal


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

== env ==========================================================
LD_LIBRARY_PATH /usr/local/cuda::/usr/local/cuda-7.5/lib64
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
Tue Jul  4 21:42:35 2017       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 375.66                 Driver Version: 375.66                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 750 Ti  Off  | 0000:01:00.0      On |                  N/A |
|  6%   36C    P8     1W /  38W |    243MiB /  2000MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0      1490    G   /usr/bin/gnome-shell                           118MiB |
+-----------------------------------------------------------------------------+

== cuda libs  ===================================================
/usr/local/cuda-8.0/lib64/libcudart.so.8.0.61
/usr/local/cuda-8.0/lib64/libcudart_static.a

### Describe the problem
I've managed to compile tf r1.1 with CUDA support with no problems. Howwever r1.2 and master throw an error at the final link stage (I think). I call the build process from a script (below).

The error is pasted below the calling script. The error message says to recompile with -fPIC, so I added that to the --copt and --cxxopt bazel command, but it makes no difference.

And issue  #9149 is affecting me as well, although it doesn't affect build success.

Thanks to all the wonderful TF hackers! You're making the world a better place.

## Script used to build TF
#! /bin/sh
cd ~/Downloads/Software/tensorflow
export CUDA_TOOLKIT_PATH=/usr/local/cuda
export CUDNN_INSTALL_PATH=/lib64
export GCC_HOST_COMPILER_PATH=/usr/bin/gcc53
export LD_LIBRARY_PATH=/lib64:/usr/lib64:/usr/local/cuda/lib64:/usr/local/cuda-8.0/lib64
export PATH=/home/john/bin:/usr/local/cuda/bin:/usr/local/bin:/usr/local/sbin:/usr/bin
export PYTHON_BIN_PATH=/usr/bin/python
export PYTHON_LIB_PATH=/usr/lib64/python2.7/site-packages
export TF_CUDA_CLANG=0
export TF_CUDA_COMPUTE_CAPABILITIES=5.2
export TF_CUDA_VERSION='8' 
export TF_CUDNN_VERSION='6'
export TF_NEED_CUDA=1
export TF_NEED_OPENCL=0 
export CC=/usr/bin/gcc53
export CXX=/usr/bin/g++-53

rm -fr ~/.cache/bazel/_bazel_john/189563267da147eb81f91b14c734315c/
bazel clean
\#git checkout r1.1
./configure
bazel build --config=opt --copt=-O2 ---copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --cxxopt=-O2 --copt=-w --config=cuda //tensorflow/tools/pip_package:build_pip_package --verbose_failures 

## Error at final (?) linking
2017-07-04 22:01:21.178045: W tensorflow/core/framework/op_gen_lib.cc:194] Squeeze can't find input squeeze_dims to rename
ERROR: /home/john/Downloads/Software/tensorflow/tensorflow/python/BUILD:2638:1: Linking of rule '//tensorflow/python:_pywrap_tensorflow_internal.so' failed: link_dynamic_library.sh failed: error executing command 
  (cd /home/john/.cache/bazel/_bazel_john/189563267da147eb81f91b14c734315c/execroot/org_tensorflow && \
  exec env - \
    CUDA_TOOLKIT_PATH=/usr/local/cuda \
    CUDNN_INSTALL_PATH=/lib64 \
    GCC_HOST_COMPILER_PATH=/usr/bin/gcc53 \
    LD_LIBRARY_PATH=/lib64:/usr/lib64:/usr/local/cuda/lib64:/usr/local/cuda-8.0/lib64 \
    PATH=/home/john/bin:/usr/local/cuda/bin:/usr/local/bin:/usr/local/sbin:/usr/bin \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/bin/python \
    PYTHON_LIB_PATH=/usr/lib/python2.7/site-packages \
    TF_CUDA_CLANG=0 \
    TF_CUDA_COMPUTE_CAPABILITIES=3.5,5.2 \
    TF_CUDA_VERSION='' \
    TF_CUDNN_VERSION='' \
    TF_NEED_CUDA=1 \
    TF_NEED_OPENCL=0 \
  external/bazel_tools/tools/cpp/link_dynamic_library.sh no ignored ignored ignored external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -shared -o bazel-out/local_linux-opt/bin/tensorflow/python/_pywrap_tensorflow_internal.so '-Wl,-rpath,$ORIGIN/../../_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccusolver___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib' '-Wl,-rpath,$ORIGIN/../../_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccublas___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib' '-Wl,-rpath,$ORIGIN/../../_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccuda_Udriver___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib' '-Wl,-rpath,$ORIGIN/../../_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccudnn___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib' '-Wl,-rpath,$ORIGIN/../../_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccufft___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib' '-Wl,-rpath,$ORIGIN/../../_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccurand___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib' '-Wl,-rpath,$ORIGIN/../../_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccudart___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib' -Lbazel-out/local_linux-opt/bin/_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccusolver___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib -Lbazel-out/local_linux-opt/bin/_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccublas___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib -Lbazel-out/local_linux-opt/bin/_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccuda_Udriver___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib -Lbazel-out/local_linux-opt/bin/_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccudnn___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib -Lbazel-out/local_linux-opt/bin/_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccufft___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib -Lbazel-out/local_linux-opt/bin/_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccurand___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib -Lbazel-out/local_linux-opt/bin/_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccudart___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib -Wl,--version-script tensorflow/tf_version_script.lds -Wl,-z,muldefs -Wl,-z,muldefs -Wl,-rpath,../local_config_cuda/cuda/lib64 -Wl,-rpath,../local_config_cuda/cuda/extras/CUPTI/lib64 -pthread -Wl,-no-as-needed -B/usr/bin/ -Wl,-z,relro,-z,now -no-canonical-prefixes -pass-exit-codes '-Wl,--build-id=md5' '-Wl,--hash-style=gnu' -Wl,--gc-sections -Wl,@bazel-out/local_linux-opt/bin/tensorflow/python/_pywrap_tensorflow_internal.so-2.params): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
/usr/bin/ld: /usr/lib/gcc/x86_64-redhat-linux/5.3.1/libgomp.a(critical.o): relocation R_X86_64_32 against `.bss' can not be used when making a shared object; recompile with -fPIC
/usr/lib/gcc/x86_64-redhat-linux/5.3.1/libgomp.a: error adding symbols: Bad value
collect2: error: ld returned 1 exit status
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 1865.691s, Critical Path: 223.61s

"
11268,ImportError: No module named google.protobuf ,"hello ,there! when i use C++ to call python program that use tensorflow，report this error


Traceback (most recent call last):
  
File ""<string>"", line 1, in <module>
 
File ""/root/anaconda2/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>

    from tensorflow.python import *
  
File ""/root/anaconda2/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 54, in <module>

    from tensorflow.core.framework.graph_pb2 import *
File ""/root/anaconda2/lib/python2.7/site-packages/tensorflow/core/framework/graph_pb2.py"", line 6, in <module>

    from google.protobuf import descriptor as _descriptor

ImportError: No module named google.protobuf

code is here ：
PyRun_SimpleString(""sys.path.append('/root/anaconda2/lib/python2.7/site-packages')"");
PyRun_SimpleString(""sys.path.append('/root/pythoncode/vgg')"");
PyRun_SimpleString(""import tensorflow as tf"");
PyRun_SimpleString(""print sys.path"");

have anyone meet this question？please，help! thank you very much!

 "
11267,Inconsistent default value,"In this doc:

> https://www.tensorflow.org/api_docs/python/tf/assign

the default value for `validate_shape` and `use_locking` is different between the method signature and the explanation below it.

```
assign(
    ref,
    value,
    validate_shape=None,
    use_locking=None,
    name=None
)
```

vs. 

```
validate_shape: An optional bool. Defaults to True. ...
use_locking: An optional bool. Defaults to True. ...
```"
11266,how to trace the training time of the layers,"I am training the CNN, I have embedding layer, conv layer, fc layer and etc. I can get the training time per batch, but how can I get the training time of each layer per batch?"
11265,faster-rcnn incompatible shapes randomly during training custom dataset,"I'm trying to train faster-rcnn with resnet101 on a custom dataset, which I have formatted appropriately for tf. When I run training, it can run anywhere from 30-1000 steps before it gives me an error like this:

 ```
File ""train.py"", line 195, in main
    worker_job_name, is_chief, FLAGS.train_dir)
  File ""/home/chris/tensorflow/models/object_detection/trainer.py"", line 192, in train
    clones = model_deploy.create_clones(deploy_config, model_fn, [input_queue])
  File ""/home/chris/tensorflow/models/slim/deployment/model_deploy.py"", line 193, in create_clones
    outputs = model_fn(*args, **kwargs)
  File ""/home/chris/tensorflow/models/object_detection/trainer.py"", line 133, in _create_losses
    losses_dict = detection_model.loss(prediction_dict)
  File ""/home/chris/tensorflow/models/object_detection/meta_architectures/faster_rcnn_meta_arch.py"", line 1173, in loss
    groundtruth_classes_with_background_list))
  File ""/home/chris/tensorflow/models/object_detection/meta_architectures/faster_rcnn_meta_arch.py"", line 1329, in _loss_box_classifier
    batch_reg_targets, weights=batch_reg_weights) / normalizer
  File ""/home/chris/tensorflow/models/object_detection/core/losses.py"", line 71, in __call__
    return self._compute_loss(prediction_tensor, target_tensor, **params)
  File ""/home/chris/tensorflow/models/object_detection/core/losses.py"", line 158, in _compute_loss
    diff = prediction_tensor - target_tensor
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py"", line 846, in binary_op_wrapper
    return func(x, y, name=name)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_math_ops.py"", line 2582, in _sub
    result = _op_def_lib.apply_op(""Sub"", x=x, y=y, name=name)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py"", line 767, in apply_op
    op_def=op_def)

InvalidArgumentError (see above for traceback): Incompatible shapes: [1,61,4] vs. [1,64,4]
	 [[Node: gradients/Loss/BoxClassifierLoss/Loss/sub_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _device=""/job:localhost/replica:0/task:0/gpu:0""](gradients/Loss/BoxClassifierLoss/Loss/sub_grad/Shape, gradients/Loss/BoxClassifierLoss/Loss/sub_grad/Shape_1)]]
	 [[Node: gradients/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm/batchnorm/mul_grad/tuple/control_dependency_1/_3949 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_22091_gradients/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm/batchnorm/mul_grad/tuple/control_dependency_1"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
```


The dimension mismatch is from what I can tell from from looking in losses.py the number of anchors, but I really don't know how to try debug this. FWIW, the training on ssd runs without issue so far.

A bit of info about the dataset, the images all contain multiple (likely crowded) of the same object."
11263,Image Retrain Inception only check the own specific category not tensor dataset,"
I have retrained the inception model from my data set of traffic sign.Its working fine but when I am trying to check other image e.g panda it's resulting with the name of traffic sign with some probabilities.I don't understand why its doing it.I need both tensor-flow data-set and my own category too. My steps:

-I have installed the python 3.5.2 in windows 7

-I installed tensor-flow with pip --install tensorflow

-I download these two files retrain.py to train my data and label_image.py to check image.

files downloaded from: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/image_retraining"
11257,building gexagon_graph_execution for hexagon_DSP failed,"I have followed the build and run script for HVX here, after installing the protobuf and downloading the pre-built libraries the code has failed at :

`error: undefined reference to 'soc_interface_AllocateInOutNodeBuffers'
`here is the related file:

```
/home/amir/Documents/tensorflow/tensorflow/contrib/makefile/gen/lib/libtensorflow-core.a(hexagon_control_wrapper.o):hexagon_control_wrapper.cc:function tensorflow::HexagonControlWrapper::Init(tensorflow::RemoteFusedGraphExecuteInfo const&): error: undefined reference to 'soc_interface_AllocateInOutNodeBuffers'
collect2: error: ld returned 1 exit status
/home/amir/Documents/tensorflow/tensorflow/contrib/makefile/sub_makefiles/hexagon_graph_execution/Makefile.in:64: recipe for target '/home/amir/Documents/tensorflow/tensorflow/contrib/makefile/gen/bin/hexagon_graph_execution' failed
make: *** [/home/amir/Documents/tensorflow/tensorflow/contrib/makefile/gen/bin/hexagon_graph_execution] Error 1
```
@satok16 could you help me out here about the linking problem? Running on Ubuntu 16.04.02"
11256,wide_n_deep  tutorial not work,"Run the wide_n_deep_tutorial.py,  I got the msg like that:

  **## File ""wide_n_deep_tutorial.py"", line 147, in build_estimator
    m = tf.estimator.DNNLinearCombinedClassifier(
AttributeError: 'module' object has no attribute 'DNNLinearCombinedClassifier'**


**## it shows that DNNLinearCombinedClassifier not in estimator, In the previous version, it seems in tf.contrib.learn** 

**## is it a bug ?**"
11255,Feature request:  do not reload latest checkpoint on each DNNRegressor.predict() call,"### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

Each DNNRegressor.predict (or predict_scores) call reloads model parameters from the latest saved model checkpoint, even if the checkpoint hasn't changed between predict() calls.  This slows down generation of predictions.  It will be helpful to be able to disable reloading of model parameters after the initial loading, and/or to be able to reload the latest checkpoint manually via a separate function call.

"
11254,"Import tensorflow with error information""KeyError: ""Couldn't find field google.protobuf.FileOptions.php_class_prefix""""","here is the error information:
>>> import tensorflow
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/shaoyn/anaconda2/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/home/shaoyn/anaconda2/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 52, in <module>
    from tensorflow.core.framework.graph_pb2 import *
  File ""/home/shaoyn/anaconda2/lib/python2.7/site-packages/tensorflow/core/framework/graph_pb2.py"", line 10, in <module>
    from google.protobuf import descriptor_pb2
  File ""/home/shaoyn/anaconda2/lib/python2.7/site-packages/google/protobuf/descriptor_pb2.py"", line 1003, in <module>
    options=None),
  File ""/home/shaoyn/anaconda2/lib/python2.7/site-packages/google/protobuf/descriptor.py"", line 498, in __new__
    return _message.default_pool.FindFieldByName(full_name)
KeyError: ""Couldn't find field google.protobuf.FileOptions.php_class_prefix"""
11253,pip or package issues,"Over the past few hours I have tried to run pip install --upgrade tensorflow_gpu  roughly 20 times, and keep getting read time out from pypi.python.org.  I finally added the --verbose and -- timeout 10000 to troubleshoot. Now I get this:

  Using version 1.2.1 (newest of versions: 1.2.0, 1.2.1)
  Looking up ""https://pypi.python.org/packages/47/81/2b8020393615b06af06e0d7c32d74b9a844ebebf4385f9eb00cfdfdbdd92/tensorflow_gpu-1.2.1-cp36-cp36m-win_amd64.whl"" in the cache
  No cache entry available
  Starting new HTTPS connection (1): pypi.python.org
  ""GET /packages/47/81/2b8020393615b06af06e0d7c32d74b9a844ebebf4385f9eb00cfdfdbdd92/tensorflow_gpu-1.2.1-cp36-cp36m-win_amd64.whl HTTP/1.1"" 200 51299687
  Downloading tensorflow_gpu-1.2.1-cp36-cp36m-win_amd64.whl (51.3MB)
  Downloading from URL https://pypi.python.org/packages/47/81/2b8020393615b06af06e0d7c32d74b9a844ebebf4385f9eb00cfdfdbdd92/tensorflow_gpu-1.2.1-cp36-cp36m-win_amd64.whl#md5=46bb283df033c7fb7c233346eb26d40f (from https://pypi.python.org/simple/tensorflow-gpu/)
    12% |████                            | 6.3MB 6.4kB/s eta 1:57:37
Cleaning up...
**THESE PACKAGES DO NOT MATCH THE HASHES FROM THE REQUIREMENTS FILE. If you have updated the package versions, please update the hashes. Otherwise, examine the package contents carefully; someone may have tampered with them.
    tensorflow_gpu from https://pypi.python.org/packages/47/81/2b8020393615b06af06e0d7c32d74b9a844ebebf4385f9eb00cfdfdbdd92/tensorflow_gpu-1.2.1-cp36-cp36m-win_amd64.whl#md5=46bb283df033c7fb7c233346eb26d40f:
        Expected md5 46bb283df033c7fb7c233346eb26d40f
             Got        7ba60530da51fdc733b89f9dd3b660fc**

Exception information:
Traceback (most recent call last):
  File ""c:\users\roger\envs\tensorflow_attention_ocr\lib\site-packages\pip\basecommand.py"", line 215, in main
    status = self.run(options, args)
  File ""c:\users\roger\envs\tensorflow_attention_ocr\lib\site-packages\pip\commands\install.py"", line 335, in run
    wb.build(autobuilding=True)
  File ""c:\users\roger\envs\tensorflow_attention_ocr\lib\site-packages\pip\wheel.py"", line 749, in build
    self.requirement_set.prepare_files(self.finder)
  File ""c:\users\roger\envs\tensorflow_attention_ocr\lib\site-packages\pip\req\req_set.py"", line 386, in prepare_files
    raise hash_errors
pip.exceptions.HashErrors: THESE PACKAGES DO NOT MATCH THE HASHES FROM THE REQUIREMENTS FILE. If you have updated the package versions, please update the hashes. Otherwise, examine the package contents carefully; someone may have tampered with them.
    tensorflow_gpu from https://pypi.python.org/packages/47/81/2b8020393615b06af06e0d7c32d74b9a844ebebf4385f9eb00cfdfdbdd92/tensorflow_gpu-1.2.1-cp36-cp36m-win_amd64.whl#md5=46bb283df033c7fb7c233346eb26d40f:
        Expected md5 46bb283df033c7fb7c233346eb26d40f
             Got        7ba60530da51fdc733b89f9dd3b660fc"
11252,AttributeError when calling train in tf.estimator.DNNClassifier,"### System information
- I wrote a custom script, using the tf.estimator.DNNclassifier. Source code below.
- **OS Platform and Distribution**: MacOS 10.12.5
- **TensorFlow installed from**: source
- **TensorFlow version**:  v1.2.0-1741-g88633a8eb 1.2.1
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: 0.5.2
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**:
- **Additional libraries**: numpy (1.13.0), protobuf (3.3.0), tensorflow-tensorboard (0.1.2)

### Describe the problem
When using tf.estimator.DNNClassifier train function, I get the an AttributeError listed below in the logs, relate to the definition of `values=tuple(six.itervalues(features))` in `_dnn_model_fn`.
Note: when using `tensorflow.contrib.learn.DNNClassifier` instead (with `fit`, instead of `train`) no error occurs.

### Source code

```
import tensorflow.contrib.learn as skflow
feature_columns = skflow.infer_real_valued_columns_from_input(totA.astype(np.float32))
clf = tf.estimator.DNNClassifier(feature_columns=feature_columns,hidden_units=dnntfDef.hidden_layers,
                               optimizer=dnntfDef.optimizer, n_classes=numTotClasses,
                               activation_fn=dnntfDef.activationFn, model_dir=model_directory)

clf.train(input_fn=lambda: input_fn(A, Cl2), steps=2000
```

### logs

`    
clf.train(input_fn=lambda: input_fn(A, Cl2), steps=dnntfDef.trainingSteps)
  File ""/opt/local/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 241, in train
    loss = self._train_model(input_fn=input_fn, hooks=hooks)
  File ""/opt/local/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 616, in _train_model
    model_fn_lib.ModeKeys.TRAIN)
  File ""/opt/local/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 601, in _call_model_fn
    features=features, labels=labels, **kwargs)
  File ""/opt/local/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/estimator/canned/dnn.py"", line 265, in _model_fn
    config=config)
  File ""/opt/local/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/estimator/canned/dnn.py"", line 84, in _dnn_model_fn
    values=tuple(six.itervalues(features)),
  File ""/opt/local/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/six.py"", line 578, in itervalues
    return iter(d.values(**kw))
AttributeError: 'Tensor' object has no attribute 'values'
`

"
11250,label_image example does not work with Mobilenetv1 (224),"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Mac OS X 10.12.5
- **TensorFlow installed from (source or binary)**:
Source
- **TensorFlow version (use command below)**:
Github tag 1.2 release
- **Python version**: 
2.7 (Mac OS X System install)
- **Bazel version (if compiling from source)**:
Homebrew 0.4.5
- **CUDA/cuDNN version**:
NA
- **GPU model and memory**:
NA

- **Exact command to reproduce**:
`bazel-bin/tensorflow/examples/label_image/label_image --image=/Path/to/image.jpg --input_layer=input --output_layer=MobilenetV1/Predictions/Reshape_1  --graph=/Path/To/my/trained/mobilenet.pb --labels=/Path/To/My/labels.txt --input_mean=0  --input_std=255`

### Describe the problem
Ive retrained MobileNetV1 (224) via the TF Slim readme.md and have produced a graph.pb trained against a data set with 5 labels to classify. I am attempting to validate my training by running the exported graph on some validation and training data myself, and have build label_image and specified the above flags  to run.

Its unclear if label image is expected  able to run MobileNet , but it does not: it errors with:

` E tensorflow/examples/label_image/main.cc:312] Running model failed: Invalid argument: Tried to explicitly squeeze dimension 1 but dimension was not 1: 2
	 [[Node: MobilenetV1/Logits/SpatialSqueeze = Squeeze[T=DT_FLOAT, squeeze_dims=[1, 2], _device=""/job:localhost/replica:0/task:0/cpu:0""](MobilenetV1/Logits/Conv2d_1c_1x1/BiasAdd)]]`

### Source code / logs
Full execution command and output:

`Mayalls-Object:tensorflow vade$ bazel-bin/tensorflow/examples/label_image/label_image --image=/Volumes/MediaArchive/datasets/SynopsisCinemaNet/data/Framing/original_photos/Extreme\ Close\ Up/images_12\ copy.jpg --input_layer=input --output_layer=MobilenetV1/Predictions/Reshape_1  --graph=/Volumes/MediaArchive/datasets/SynopsisCinemaNet/model/FramingWeekend/CinemaNetFraming.pb --labels=/Volumes/MediaArchive/datasets/SynopsisCinemaNet/datasets/Framing/labels.txt --input_mean=0  --input_std=255
2017-07-03 14:44:05.971869: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-03 14:44:05.972224: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-07-03 14:44:05.972228: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-03 14:44:05.972231: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-07-03 14:44:06.123365: E tensorflow/examples/label_image/main.cc:312] Running model failed: Invalid argument: Tried to explicitly squeeze dimension 1 but dimension was not 1: 2
	 [[Node: MobilenetV1/Logits/SpatialSqueeze = Squeeze[T=DT_FLOAT, squeeze_dims=[1, 2], _device=""/job:localhost/replica:0/task:0/cpu:0""](MobilenetV1/Logits/Conv2d_1c_1x1/BiasAdd)]]
Mayalls-Object:tensorflow vade$ bazel-bin/tensorflow/examples/label_image/label_image --image=/Volumes/MediaArchive/datasets/SynopsisCinemaNet/data/Framing/converted_photos/Extreme\ Close\ Up/images_12\ copy.jpg --input_layer=input --output_layer=MobilenetV1/Predictions/Reshape_1  --graph=/Volumes/MediaArchive/datasets/SynopsisCinemaNet/model/FramingWeekend/CinemaNetFraming.pb --labels=/Volumes/MediaArchive/datasets/SynopsisCinemaNet/datasets/Framing/labels.txt --input_mean=0  --input_std=255
2017-07-03 14:44:47.201141: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-03 14:44:47.201530: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-07-03 14:44:47.201534: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-03 14:44:47.201538: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-07-03 14:44:47.365892: E tensorflow/examples/label_image/main.cc:312] Running model failed: Invalid argument: Tried to explicitly squeeze dimension 1 but dimension was not 1: 2
	 [[Node: MobilenetV1/Logits/SpatialSqueeze = Squeeze[T=DT_FLOAT, squeeze_dims=[1, 2], _device=""/job:localhost/replica:0/task:0/cpu:0""](MobilenetV1/Logits/Conv2d_1c_1x1/BiasAdd)]]
Mayalls-Object:tensorflow vade$ `"
11248,error in freeze_graph.py,"### System information
Ubuntu 16.04
Python 2.7.12
Tensorflow 1.2.1 installed using pip
GPU: Nvidia Quadro M2000M 4GB
CUDA V 8.0.4

### Issue
I am trying to recreate the frozen graph using freeze_graph.py from the ssd_mobilenet pretrained model available here:

https://github.com/tensorflow/models/blob/master/object_detection/g3doc/detection_model_zoo.md

I printed the output nodes using the following command:

`for n in detection_graph.as_graph_def().node:`
`    print(n.name)`

I tried running freeze_graph with different output_nodes such as add_6, Postprocessor/BatchMultiClassNonMaxSuppression/stack with following command:

freeze_graph.py --input_graph=ssd_mobilenet_v1_coco/graph.pbtxt --input_checkpoint=ssd_mobilenet_v1_coco/model.ckpt --output_graph=./frozen_graph.pb --output_node_names=add_6

This is the error that I get:

Traceback (most recent call last):
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/tools/freeze_graph.py"", line 202, in <module>
    app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/home/adminloc/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/tools/freeze_graph.py"", line 134, in main
    FLAGS.variable_names_blacklist)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/tools/freeze_graph.py"", line 99, in freeze_graph
    _ = importer.import_graph_def(input_graph_def, name="""")
  File ""/home/adminloc/.local/lib/python2.7/site-packages/tensorflow/python/framework/importer.py"", line 283, in import_graph_def
    raise ValueError('No op named %s in defined operations.' % node.op)
ValueError: No op named SSTableReaderV2 in defined operations.

When I try feeding the old frozen_graph (.pb file) as --input_graph with --input_binary=true to freeze_graph, I get the following error:

Traceback (most recent call last):
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/tools/freeze_graph.py"", line 202, in <module>
    app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/home/adminloc/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/tools/freeze_graph.py"", line 134, in main
    FLAGS.variable_names_blacklist)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/tools/freeze_graph.py"", line 112, in freeze_graph
    sess.run([restore_op_name], {filename_tensor_name: input_checkpoint})
  File ""/home/adminloc/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 789, in run
    run_metadata_ptr)
  File ""/home/adminloc/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 945, in _run
    + e.args[0])
TypeError: Cannot interpret feed_dict key as Tensor: The name 'save/Const:0' refers to a Tensor which does not exist. The operation, 'save/Const', does not exist in the graph.

I don't know if this is a bug or lack of documentation, but it would be nice to add some documentation such as the output nodes.

P.S: I am trying to recreate the frozen graph to be able to create a new frozen graph after fine tuning the model."
11247,Standalone Embedding Projector does not load bookmarks,"The standalone[ Embedding Projector](http://projector.tensorflow.org/) does not open the _Load bookmarks_ window for me all of a sudden. _Save bookmarks_ and everything else still works though. 

I am on Windows 7 (Enterprise) using Chrome (Google Chrome	59.0.3071.115 (Official Build) (64-bit) (cohort: Stable)).

"
11245,The data type conversion between int32 and float32,"My project require convert the data type of tensor (dtype=float32) to int32, and then I need turn the dtype back (from int32 to float32) after some operations.
 The code is

>  y = tf.to_int32(x)
>  bitwiseXor = tf.bitwise.bitwise_xor(y, key)
>  z = tf.to_float(bitwiseXor)

But following errors appears, how to solve it?

> Traceback (most recent call last):
>   File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/op_def_library.py"", line 490, in apply_op
>     preferred_dtype=default_dtype)
>   File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py"", line 675, in internal_convert_to_tensor
>     ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
>   File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/constant_op.py"", line 121, in _constant_tensor_conversion_function
>     return constant(v, dtype=dtype, name=name)
>   File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/constant_op.py"", line 102, in constant
>     tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))
>   File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/tensor_util.py"", line 364, in make_tensor_proto
>     raise ValueError(""None values not supported."")
> ValueError: None values not supported.
> 
> During handling of the above exception, another exception occurred:
> 
> Traceback (most recent call last):
>   File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/op_def_library.py"", line 504, in apply_op
>     values, as_ref=input_arg.is_ref).dtype.name
>   File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py"", line 675, in internal_convert_to_tensor
>     ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
>   File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/constant_op.py"", line 121, in _constant_tensor_conversion_function
>     return constant(v, dtype=dtype, name=name)
>   File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/constant_op.py"", line 102, in constant
>     tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))
>   File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/tensor_util.py"", line 364, in make_tensor_proto
>     raise ValueError(""None values not supported."")
> ValueError: None values not supported.
> 
> During handling of the above exception, another exception occurred:
> 
> Traceback (most recent call last):
>   File ""/win1/Ubuntu_App/RemotePython/EncNN/My_EncML.py"", line 134, in <module>
>     model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))
>   File ""/usr/local/lib/python3.4/dist-packages/keras/engine/training.py"", line 1458, in fit
>     self._make_train_function()
>   File ""/usr/local/lib/python3.4/dist-packages/keras/engine/training.py"", line 1002, in _make_train_function
>     self.total_loss)
>   File ""/usr/local/lib/python3.4/dist-packages/keras/optimizers.py"", line 326, in get_updates
>     new_a = self.rho * a + (1. - self.rho) * K.square(g)
>   File ""/usr/local/lib/python3.4/dist-packages/keras/backend/tensorflow_backend.py"", line 1225, in square
>     return tf.square(x)
>   File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/math_ops.py"", line 428, in square
>     return gen_math_ops.square(x, name=name)
>   File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/gen_math_ops.py"", line 2544, in square
>     result = _op_def_lib.apply_op(""Square"", x=x, name=name)
>   File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/op_def_library.py"", line 508, in apply_op
>     (input_name, err))
> ValueError: Tried to convert 'x' to a tensor and failed. Error: None values not supported.
> 
> Process finished with exit code 1"
11241,[Feature request] add checkpoint_convert.py script to pip package,"In the TensorFlow 1.2.0 pip package (at least for Linux), [checkpoint_convert.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/python/tools/checkpoint_convert.py) is not included. Because of #11168, 92da8abfd35b93488ed7a55308b8f589ee23b622, 157370e5916b85c65958ed8383ae31d727228ed7, it might be useful. Esp., in our framework, I would like to add some automatic handling at runtime when a checkpoint file is loaded and some variables are not found, to automatically try to load variables under different names according to `_RNN_NAME_REPLACEMENTS`. Thus, extending to adding `checkpoint_convert.py` to the pip package, it would also be nice to make `_RNN_NAME_REPLACEMENTS` public (remove the leading underscore).
"
11240,tf.control_dependencies does not work with variable initializer for read_value?,"Consider this code:

```
def test_var_init():
  v = tf.Variable(initial_value=2, trainable=False, name=""test_var_init"")
  with tf.control_dependencies([v.initializer]):
    x = v.read_value()
  assert x.eval() == 2
```

It should always succeed. However, it stochastically fails (maybe in about 75% of the runs or so), with the error:
```
FailedPreconditionError: Attempting to use uninitialized value test_var_init
         [[Node: test_var_init/_0 = _Send[T=DT_INT32, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_5_test_var_init"", _device=""/job:localhost/replica:0/task:0/cpu:0""](test_var_init)]]
```

TensorFlow v1.2.0-rc2-21-g12f033d, 1.2.0, installed via pip, on Ubuntu 16.04 Linux.
It only seems to happen with GPU.

I think on TF 1.1 and earlier this worked, although maybe for some reason the probability to fail was much lower there and I didn't notice it.
"
11239,Variables in Dataset functions not (always) initialized,"### System information
- **OS**: MacOS 10.12.4
- **TensorFlow**: stock cpu tensorflow 1.2 from pip
- **Python**: Python 2.7.13

### Describe the problem
When using a Dataset function containing tf.Variables needing initialization it succeeds sometimes, but fails other times. I haven't managed to pin point it further using `sleep`s or `tf.control_dependencies`.

### Source code / logs
```
import tensorflow as tf

def fn(x):
    v = tf.Variable(5, dtype=tf.int64)
    return x + v

dataset = (tf.contrib.data.Dataset.range(10)
    .map(fn)
)

iterator = dataset.make_initializable_iterator()
next = iterator.get_next()

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    sess.run(iterator.initializer)

    for i in range(3):
        res = sess.run(next)
        print(res)
```

Moving the `v` variable out of the `fn` scope seems to resolve the issue.

Error log when variable fails to initialize:
```
(tf) no00023794:distributed-cluster olanymoe$ python set_test.py 
<MapDataset shapes: (), types: tf.int64>
2017-07-03 10:33:55.377579: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-03 10:33:55.377593: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-07-03 10:33:55.377597: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-03 10:33:55.377601: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-07-03 10:34:05.404642: W tensorflow/core/framework/op_kernel.cc:1158] Failed precondition: Attempting to use uninitialized value Variable
	 [[Node: Variable/read = Identity[T=DT_INT64, _class=[""loc:@Variable""]](Variable)]]
Traceback (most recent call last):
  File ""set_test.py"", line 49, in <module>
    res = sess.run(next)
  File ""/Users/olanymoe/anaconda2/envs/tf/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 789, in run
    run_metadata_ptr)
  File ""/Users/olanymoe/anaconda2/envs/tf/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 997, in _run
    feed_dict_string, options, run_metadata)
  File ""/Users/olanymoe/anaconda2/envs/tf/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1132, in _do_run
    target_list, options, run_metadata)
  File ""/Users/olanymoe/anaconda2/envs/tf/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1152, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value Variable
	 [[Node: Variable/read = Identity[T=DT_INT64, _class=[""loc:@Variable""]](Variable)]]
	 [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[]], output_types=[DT_INT64], _device=""/job:localhost/replica:0/task:0/cpu:0""](Iterator)]]
```"
11236,Cannot use AdamOptimizer in C++ when running graph defined from Python,"Running Ubuntu 14.04, with r1.2 Tensorflow

I have defined a graph in Python
```
features = 784
output_dim = 10
graph_name = ""graph.pb""
graph_folder = ""/home/fran/Repositories/tensorflow/bazel-bin/tensorflow/test""
input_node_name = ""input""
output_node_name = ""output""

with tf.Session() as session:
    x = tf.placeholder(tf.float32, [None, features], name=""input"")
    W = tf.Variable(tf.zeros([features, output_dim]), dtype=tf.float32, name=""Weight"")
    b = tf.Variable(tf.zeros([output_dim]), dtype=tf.float32, name=""bias"")
    y_pred = tf.nn.softmax(tf.matmul(x, W)+b, name=output_node_name)

    y_true = tf.placeholder(tf.float32, [None, 10], name=""y_true"")
    cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_true * tf.log(y_pred), reduction_indices=[1]), name=""loss"")
    optimizer = tf.train.AdamOptimizer(0.00001)
    train_step = optimizer.minimize(cross_entropy, name=""train"")
    init = tf.variables_initializer(tf.global_variables(), name='init_all_vars_op')
    saver = tf.train.Saver()
    tf.train.write_graph(session.graph_def, graph_folder, graph_name, as_text=False)
```

If I run this graph in a C++ program, where I load the graph, initialize the variables and feed X and Y tensors to ""train"", I get the following error (works fine with other optimizers like GradientDescent or RMSPropOptimizer):
```
Training.
Step: 0; Loss: 9.25913
2017-07-03 09:54:43.264264: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Invalid argument: NodeDef mentions attr 'use_nesterov' not in Op<name=ApplyAdam; signature=var:Ref(T), m:Ref(T), v:Ref(T), beta1_power:T, beta2_power:T, lr:T, beta1:T, beta2:T, epsilon:T, grad:T -> out:Ref(T); attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT64, DT_INT32, DT_UINT8, DT_UINT16, DT_INT16, DT_INT8, DT_COMPLEX64, DT_COMPLEX128, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF]; attr=use_locking:bool,default=false>; NodeDef: train/update_Weight/ApplyAdam = ApplyAdam[T=DT_FLOAT, _class=[""loc:@Weight""], use_locking=false, use_nesterov=false, _device=""/job:localhost/replica:0/task:0/cpu:0""](Weight, Weight/Adam, Weight/Adam_1, beta1_power/read, beta2_power/read, train/learning_rate, train/beta1, train/beta2, train/epsilon, gradients/MatMul_grad/tuple/control_dependency_1). (Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).
	 [[Node: train/update_Weight/ApplyAdam = ApplyAdam[T=DT_FLOAT, _class=[""loc:@Weight""], use_locking=false, use_nesterov=false, _device=""/job:localhost/replica:0/task:0/cpu:0""](Weight, Weight/Adam, Weight/Adam_1, beta1_power/read, beta2_power/read, train/learning_rate, train/beta1, train/beta2, train/epsilon, gradients/MatMul_grad/tuple/control_dependency_1)]]
2017-07-03 09:54:43.264468: F tensorflow/driving_school/training.cc:102] Non-OK-status: session->Run(inputs, {}, {""train""}, nullptr) status: Invalid argument: NodeDef mentions attr 'use_nesterov' not in Op<name=ApplyAdam; signature=var:Ref(T), m:Ref(T), v:Ref(T), beta1_power:T, beta2_power:T, lr:T, beta1:T, beta2:T, epsilon:T, grad:T -> out:Ref(T); attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT64, DT_INT32, DT_UINT8, DT_UINT16, DT_INT16, DT_INT8, DT_COMPLEX64, DT_COMPLEX128, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF]; attr=use_locking:bool,default=false>; NodeDef: train/update_Weight/ApplyAdam = ApplyAdam[T=DT_FLOAT, _class=[""loc:@Weight""], use_locking=false, use_nesterov=false, _device=""/job:localhost/replica:0/task:0/cpu:0""](Weight, Weight/Adam, Weight/Adam_1, beta1_power/read, beta2_power/read, train/learning_rate, train/beta1, train/beta2, train/epsilon, gradients/MatMul_grad/tuple/control_dependency_1). (Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).
	 [[Node: train/update_Weight/ApplyAdam = ApplyAdam[T=DT_FLOAT, _class=[""loc:@Weight""], use_locking=false, use_nesterov=false, _device=""/job:localhost/replica:0/task:0/cpu:0""](Weight, Weight/Adam, Weight/Adam_1, beta1_power/read, beta2_power/read, train/learning_rate, train/beta1, train/beta2, train/epsilon, gradients/MatMul_grad/tuple/control_dependency_1)]]
Aborted (core dumped)
```
Is this a bug?

For reference, the code I use to load the graph definition and train is the following:
```
#include ""tensorflow/core/public/session.h""
#include ""tensorflow/core/platform/env.h""

using namespace tensorflow;

int main(int argc, char* argv[]) {

    Session* session;
    std::cout << ""Initializing Tensorflow session."" << std::endl;
    TF_CHECK_OK(NewSession(SessionOptions(), &session));

    // Read in the protobuf graph we previously exported
    // (The path is relative to the cwd. Keep this in mind
    // when using `bazel run` since the cwd isn't where you call
    // `bazel run` but from inside a temp folder.)
    GraphDef graph_def;
    std::cout << ""Reading protobuf graph."" << std::endl;
    TF_CHECK_OK(ReadBinaryProto(Env::Default(), ""graph.pb"", &graph_def));

    std::cout << ""Loading graph in Tensorflow session."" << std::endl;
    TF_CHECK_OK(session->Create(graph_def));

    int batch_size = 64;
    int input_feature_len = 784;
    int output_feature_len = 10;
    int training_steps = 1000;
    int save_interval = 100;
    std::string save_path = ""/home/fran/Repositories/tensorflow/tensorflow/test/"";

    std::cout << ""Initializing Tensorflow I/O tensors."" << std::endl;
    Tensor X(DT_FLOAT, TensorShape({batch_size, input_feature_len}));
    Tensor Y(DT_FLOAT, TensorShape({batch_size, output_feature_len}));

    // Initialize our variables for training
    std::cout << ""Initializing Tensorflow variables."" << std::endl;
    TF_CHECK_OK(session->Run({}, {}, {""init_all_vars_op""}, nullptr));

    auto _XTensor = X.matrix<float>();
    auto _YTensor = Y.matrix<float>();
    _XTensor.setRandom();
    _YTensor.setRandom();

    // Assuming graph contains single input X, with node name ""input""
    // and single ground truth placeholder, with node name ""y_true""
    std::vector<std::pair<string, Tensor>> inputs = {
            { ""input"", X },
            { ""y_true"", Y }
    };

    // for checkpoint generation
    Tensor model_string(DT_STRING, TensorShape( { 1, 1 } ) );

    // Initialize output pointer for loss metric.
    // Assuming graph contains single loss, with node name ""loss""
    // and single training node, with node name ""train""
    std::cout << ""Training."" << std::endl;
    std::vector<Tensor> output;
    for (int i=0; i<training_steps; ++i) {
        TF_CHECK_OK(session->Run(inputs, {""loss""}, {}, &output)); // Get loss (for monitoring)
        float loss = output[0].scalar<float>()(0);
        std::cout << ""Step: "" << i << ""; Loss: "" << loss << std::endl;
        TF_CHECK_OK(session->Run(inputs, {}, {""train""}, nullptr)); // Train
        output.clear();

        // to save checkpoint feed name of checkpoint file as saver_def.filename_tensor_name
        // and fetch the value of saver_def.save_tensor_name, as per graph definition script.
        if (i % save_interval == 0){
            model_string.matrix< std::string >()( 0, 0 ) = save_path + ""model_checkpoint_step"" + std::to_string(i) + "".ckpt"";
            TF_CHECK_OK(session->Run({{""save/Const:0"", model_string}}, {}, {""save/control_dependency""}, nullptr));
        };
    };
    std::cout << ""Training complete."" << std::endl;
    
    std::cout << ""Closing Tensorflow session."" << std::endl;
    session->Close();
    delete session;
    return 0;
}
```
"
11235,quantify the mobilenet,"I try to quantify the mobilenet(in the https://github.com/tensorflow/models/blob/master/object_detection/g3doc/detection_model_zoo.md ssd_mobilenet_v1_coco), the tensorflow I use is v1.2,
bazel build tensorflow/tools/quantization:quantize_graph \
&& bazel-bin/tensorflow/tools/quantization/quantize_graph \
--input=bazel build tensorflow/tools/quantization:quantize_graph \
&& bazel-bin/tensorflow/tools/quantization/quantize_graph \
--input=ssd_mobilenet_v1_coco_11_06_2017/frozen_inference_graph.pb
--output_node_names=""  "" --print_nodes --output=/tmp/quantized_graph.pb \
--mode=eightbit --logtostderr
but I don't decide the out_node_names ."
11233,"About if tensorflow can use flask to mount in IIS, use like as an web API to use? ","I set up a tensorflow system, use flask grammar to set up . And in local computer, all run ok, no error.
But when I mount it in IIS, as Web API to use, It always show FASTCGI error. Does tensorflow  incompatiable with IIS?

"
11232,Enable MKL Support in TensorFlow for Java,"# Description

I'm trying to use TensorFlow for Java in a Dataflow pipeline. Currently everything appears to be working but since Dataflow only supports CPU instances, inference time seems to be quite slow. In my previous experiments I've seen that building TensorFlow from source with MKL support usually provides a very significant speed gain.

Since I'm currently using TensorFlow for Java directly from Maven repository, I won't be able to get MKL support. Would it be possible to enable MKL support for TensorFlow in Java?"
11231,"[solved, solution is on the bottom] link libtensorflow-core.a to c++ cross comple project","Hi ~ all~

   i followed:
      https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/makefile/README.md
  and successfully got ios, android, linux lib files in contrib\makefile\gen\lib.

  i'm developing a cross platform sdk lib which is written by c++.  my plan is using my sdk c++ code to call tensorflow lib. 

   here is my question: where are the h files according to the tensorflow lib file ? 

   commenly, a lib project's out put is not only a binary file , but also h files .
"
11229,32-bit build failure in tensorflow/contrib/tensor_forest/kernels/stats_ops.cc,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 14.04.5 i386
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: Git revision 744120fd8a0c3be0a90cca5a971459894c90b859
- **Python version**: 2.7.6
- **Bazel version (if compiling from source)**: 0.4.5
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: See log below

### Describe the problem
Building //tensorflow/contrib/tensor_forest:stats_ops_lib for a 32-bit architecture fails,

### Source code / logs
git checkout 744120fd8a0c3be0a90cca5a971459894c90b859
export PYTHON_BIN_PATH=/usr/bin/python
export USE_DEFAULT_PYTHON_LIB_PATH=1
export CC_OPT_FLAGS=""-march=native""
export TF_NEED_MKL=0
export TF_NEED_JEMALLOC=1
export TF_NEED_GCP=0
export TF_NEED_HDFS=0
export TF_ENABLE_XLA=0
export TF_NEED_OPENCL=0
export TF_NEED_CUDA=0
export TF_NEED_VERBS=0
export TF_NEED_MPI=0
export COMPUTE=:0
./configure
bazel build -c opt --verbose_failures //tensorflow/contrib/tensor_forest:stats_ops_lib

(removed unimportant log output)

ERROR: /home/codeplay/tensorflow/tensorflow/contrib/tensor_forest/BUILD:277:1: C++ compilation of rule '//tensorflow/contrib/tensor_forest:stats_ops_lib' failed: gcc failed: error executing command 
  (cd /home/codeplay/.cache/bazel/_bazel_codeplay/552bd1ca300856cf615cf243a9219401/execroot/tensorflow && \
  exec env - \
    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games \
    PYTHON_BIN_PATH=/usr/bin/python \
    PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \
    TF_NEED_CUDA=0 \
    TF_NEED_OPENCL=0 \
  /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/local-opt/bin/tensorflow/contrib/tensor_forest/_objs/stats_ops_lib/tensorflow/contrib/tensor_forest/kernels/stats_ops.pic.d '-frandom-seed=bazel-out/local-opt/bin/tensorflow/contrib/tensor_forest/_objs/stats_ops_lib/tensorflow/contrib/tensor_forest/kernels/stats_ops.pic.o' -fPIC -DEIGEN_MPL2_ONLY -iquote . -iquote bazel-out/local-opt/genfiles -iquote external/bazel_tools -iquote bazel-out/local-opt/genfiles/external/bazel_tools -iquote external/eigen_archive -iquote bazel-out/local-opt/genfiles/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/local-opt/genfiles/external/local_config_sycl -iquote external/protobuf -iquote bazel-out/local-opt/genfiles/external/protobuf -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/eigen_archive -isystem bazel-out/local-opt/genfiles/external/eigen_archive -isystem external/protobuf/src -isystem bazel-out/local-opt/genfiles/external/protobuf/src -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c tensorflow/contrib/tensor_forest/kernels/stats_ops.cc -o bazel-out/local-opt/bin/tensorflow/contrib/tensor_forest/_objs/stats_ops_lib/tensorflow/contrib/tensor_forest/kernels/stats_ops.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
In file included from ./tensorflow/contrib/tensor_forest/kernels/v4/leaf_model_operators.h:19:0,
                 from ./tensorflow/contrib/tensor_forest/kernels/v4/decision-tree-resource.h:21,
                 from tensorflow/contrib/tensor_forest/kernels/stats_ops.cc:18:
./tensorflow/contrib/tensor_forest/kernels/v4/input_target.h: In member function 'virtual float tensorflow::tensorforest::TensorInputTarget::GetTargetWeight(int) const':
./tensorflow/contrib/tensor_forest/kernels/v4/input_target.h:70:47: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
     return num_weights > 0 && example_index < num_weights
                                               ^
In file included from ./tensorflow/contrib/tensor_forest/kernels/v4/split_collection_operators.h:20:0,
                 from ./tensorflow/contrib/tensor_forest/kernels/v4/fertile-stats-resource.h:24,
                 from tensorflow/contrib/tensor_forest/kernels/stats_ops.cc:19:
./tensorflow/contrib/tensor_forest/kernels/v4/grow_stats.h: In member function 'bool tensorflow::tensorforest::GrowStats::IsInitialized() const':
./tensorflow/contrib/tensor_forest/kernels/v4/grow_stats.h:80:49: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
     return weight_sum_ > 0 || splits_.size() == num_splits_to_consider_;
                                                 ^
tensorflow/contrib/tensor_forest/kernels/stats_ops.cc: In function 'void tensorflow::tensorforest::UpdateStats(tensorflow::tensorforest::FertileStatsResource*, const std::unique_ptr<tensorflow::tensorforest::TensorDataSet>&, const tensorflow::Tensor&, const tensorflow::Tensor&, int, const std::vector<int>&, const std::vector<int>&, std::unordered_map<int, std::unique_ptr<tensorflow::mutex> >*, tensorflow::mutex*, tensorflow::int32, tensorflow::int32, std::unordered_set<int>*)':
tensorflow/contrib/tensor_forest/kernels/stats_ops.cc:176:72: error: no matching function for call to 'tensorflow::tensorforest::TensorInputTarget::TensorInputTarget(const Eigen::TensorMap<Eigen::Tensor<const float, 1, 1, int>, 0, Eigen::MakePointer>*, const Eigen::TensorMap<Eigen::Tensor<const float, 1, 1, int>, 0, Eigen::MakePointer>*, const tensorflow::Tensor&, int&)'
   TensorInputTarget target(&labels, &weights, input_labels, num_targets);
                                                                        ^
tensorflow/contrib/tensor_forest/kernels/stats_ops.cc:176:72: note: candidates are:
In file included from ./tensorflow/contrib/tensor_forest/kernels/v4/leaf_model_operators.h:19:0,
                 from ./tensorflow/contrib/tensor_forest/kernels/v4/decision-tree-resource.h:21,
                 from tensorflow/contrib/tensor_forest/kernels/stats_ops.cc:18:
./tensorflow/contrib/tensor_forest/kernels/v4/input_target.h:57:3: note: tensorflow::tensorforest::TensorInputTarget::TensorInputTarget(const SingleDimStorageType*, const SingleDimStorageType*, const tensorflow::Tensor&, int)
   TensorInputTarget(const SingleDimStorageType* t,
   ^
./tensorflow/contrib/tensor_forest/kernels/v4/input_target.h:57:3: note:   no known conversion for argument 1 from 'const Eigen::TensorMap<Eigen::Tensor<const float, 1, 1, int>, 0, Eigen::MakePointer>*' to 'const SingleDimStorageType* {aka const Eigen::TensorMap<Eigen::Tensor<const float, 1, 1, long int>, 0>*}'
./tensorflow/contrib/tensor_forest/kernels/v4/input_target.h:55:7: note: tensorflow::tensorforest::TensorInputTarget::TensorInputTarget(const tensorflow::tensorforest::TensorInputTarget&)
 class TensorInputTarget : public StoredInputTarget<SingleDimStorageType> {
       ^
./tensorflow/contrib/tensor_forest/kernels/v4/input_target.h:55:7: note:   candidate expects 1 argument, 4 provided
./tensorflow/contrib/tensor_forest/kernels/v4/input_target.h:55:7: note: tensorflow::tensorforest::TensorInputTarget::TensorInputTarget(tensorflow::tensorforest::TensorInputTarget&&)
./tensorflow/contrib/tensor_forest/kernels/v4/input_target.h:55:7: note:   candidate expects 1 argument, 4 provided
tensorflow/contrib/tensor_forest/kernels/stats_ops.cc: In function 'void tensorflow::tensorforest::UpdateStatsCollated(tensorflow::tensorforest::FertileStatsResource*, tensorflow::tensorforest::DecisionTreeResource*, const std::unique_ptr<tensorflow::tensorforest::TensorDataSet>&, const tensorflow::Tensor&, const tensorflow::Tensor&, int, const std::unordered_map<int, std::vector<int> >&, const std::vector<int>&, tensorflow::mutex*, tensorflow::int32, tensorflow::int32, std::unordered_set<int>*)':
tensorflow/contrib/tensor_forest/kernels/stats_ops.cc:226:72: error: no matching function for call to 'tensorflow::tensorforest::TensorInputTarget::TensorInputTarget(const Eigen::TensorMap<Eigen::Tensor<const float, 1, 1, int>, 0, Eigen::MakePointer>*, const Eigen::TensorMap<Eigen::Tensor<const float, 1, 1, int>, 0, Eigen::MakePointer>*, const tensorflow::Tensor&, int&)'
   TensorInputTarget target(&labels, &weights, input_labels, num_targets);
                                                                        ^
tensorflow/contrib/tensor_forest/kernels/stats_ops.cc:226:72: note: candidates are:
In file included from ./tensorflow/contrib/tensor_forest/kernels/v4/leaf_model_operators.h:19:0,
                 from ./tensorflow/contrib/tensor_forest/kernels/v4/decision-tree-resource.h:21,
                 from tensorflow/contrib/tensor_forest/kernels/stats_ops.cc:18:
./tensorflow/contrib/tensor_forest/kernels/v4/input_target.h:57:3: note: tensorflow::tensorforest::TensorInputTarget::TensorInputTarget(const SingleDimStorageType*, const SingleDimStorageType*, const tensorflow::Tensor&, int)
   TensorInputTarget(const SingleDimStorageType* t,
   ^
./tensorflow/contrib/tensor_forest/kernels/v4/input_target.h:57:3: note:   no known conversion for argument 1 from 'const Eigen::TensorMap<Eigen::Tensor<const float, 1, 1, int>, 0, Eigen::MakePointer>*' to 'const SingleDimStorageType* {aka const Eigen::TensorMap<Eigen::Tensor<const float, 1, 1, long int>, 0>*}'
./tensorflow/contrib/tensor_forest/kernels/v4/input_target.h:55:7: note: tensorflow::tensorforest::TensorInputTarget::TensorInputTarget(const tensorflow::tensorforest::TensorInputTarget&)
 class TensorInputTarget : public StoredInputTarget<SingleDimStorageType> {
       ^
./tensorflow/contrib/tensor_forest/kernels/v4/input_target.h:55:7: note:   candidate expects 1 argument, 4 provided
./tensorflow/contrib/tensor_forest/kernels/v4/input_target.h:55:7: note: tensorflow::tensorforest::TensorInputTarget::TensorInputTarget(tensorflow::tensorforest::TensorInputTarget&&)
./tensorflow/contrib/tensor_forest/kernels/v4/input_target.h:55:7: note:   candidate expects 1 argument, 4 provided
Target //tensorflow/contrib/tensor_forest:stats_ops_lib failed to build"
11228,GPU kernel for segment_sum?,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: ('v1.2.0-5-g435cdfc', '1.2.1')
- **Python version**: 2.7.12
- **CUDA/cuDNN version**: 6.0
- **GPU model and memory**: GTK1070/ 8105MB

^^ I don't think system information is hugely relevant in this case, but writing them down anyways.

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

This is a feature request. I was running *tf.unsorted_segment_sum* on an unsorted list of segments, and thought that I might be able to get a performance gain if the segment ids are sorted (as that is usually the case).
However, to my surprise, I discovered that there are no supported GPU kernels for vanilla segment_sum, forcing tensorflow to copy memory over to the CPU and thereby slowing down the operation greatly.
Would it be possible to support an optimized GPU version of segment_sum that takes advantage of the fact that the segments are sorted?

### Source code / logs

(Device Placement)
UnsortedSegmentSum: (UnsortedSegmentSum)/job:localhost/replica:0/task:0/gpu:0
softmax/ops/SegmentSum: (SegmentSum)/job:localhost/replica:0/task:0/cpu:0

(Profiling)
[Unsorted Segment Sum] : Took 1.979 Seconds
[Segment Sum] : Took 2.704 Seconds"
11223,tf.gather axis argument,"It'd be nice to have an `axis` argument to `tf.gather`. This would bring it closer to the numpy equivalent, [np.take](https://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.take.html). 

This would also pave the way to supporting Numpy [array indexing](https://docs.scipy.org/doc/numpy/user/basics.indexing.html#index-arrays), e.g. `t[:, [0, 2, 3], ::2]`.

Based on discussion in #9236 and all the remedies provided on [this StackOverflow thread](https://stackoverflow.com/questions/36764791/in-tensorflow-how-to-use-tf-gather-for-the-last-dimension), there would be a lot of use for it.

The most common workaround of `tf.transpose(tf.gather(tf.transpose(...), ...), ...)` is super inefficient.
 "
11219,gridlstm,"Hello,
 
1- where can find an example for GRIDLSTM(2D) or multi_diagonal . i search in net but not found.
2- known that tensorflow support from keras . how can insert a tensorflow layer in keras .

THANKS"
11218,"ValueError: Shape (1, 5) must have rank at least 3","CODE I AM TRYING TO RUN : 

from __future__ import print_function, division
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt

num_epochs = 100
total_series_length = 50000
truncated_backprop_length = 15
state_size = 4
num_classes = 2
echo_step = 3
batch_size = 5
num_batches = total_series_length//batch_size//truncated_backprop_length

def generateData():
    x = np.array(np.random.choice(2, total_series_length, p=[0.5, 0.5]))
    y = np.roll(x, echo_step)
    y[0:echo_step] = 0

    x = x.reshape((batch_size, -1))  # The first index changing slowest, subseries as rows
    y = y.reshape((batch_size, -1))

    return (x, y)

batchX_placeholder = tf.placeholder(tf.float32, [batch_size, truncated_backprop_length])
batchY_placeholder = tf.placeholder(tf.int32, [batch_size, truncated_backprop_length])

cell_state = tf.placeholder(tf.float32, [batch_size, state_size])
hidden_state = tf.placeholder(tf.float32, [batch_size, state_size])
init_state = tf.nn.rnn_cell.LSTMStateTuple(cell_state, hidden_state)

W2 = tf.Variable(np.random.rand(state_size, num_classes),dtype=tf.float32)
b2 = tf.Variable(np.zeros((1,num_classes)), dtype=tf.float32)

# unstack columns
inputs_series = tf.split(batchX_placeholder, truncated_backprop_length, 1)
labels_series = tf.unstack(batchY_placeholder, axis=1)

# Forward passes
cell = tf.contrib.rnn.BasicLSTMCell(state_size, state_is_tuple=True)
states_series, current_state = tf.nn.dynamic_rnn(cell, inputs_series, initial_state = init_state)

logits_series = [tf.matmul(state, W2) + b2 for state in states_series] #Broadcasted addition
predictions_series = [tf.nn.softmax(logits) for logits in logits_series]

losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(logits, labels) for logits, labels in zip(logits_series,labels_series)]
total_loss = tf.reduce_mean(losses)

train_step = tf.train.AdagradOptimizer(0.3).minimize(total_loss)

def plot(loss_list, predictions_series, batchX, batchY):
    plt.subplot(2, 3, 1)
    plt.cla()
    plt.plot(loss_list)

    for batch_series_idx in range(5):
        one_hot_output_series = np.array(predictions_series)[:, batch_series_idx, :]
        single_output_series = np.array([(1 if out[0] < 0.5 else 0) for out in one_hot_output_series])

        plt.subplot(2, 3, batch_series_idx + 2)
        plt.cla()
        plt.axis([0, truncated_backprop_length, 0, 2])
        left_offset = range(truncated_backprop_length)
        plt.bar(left_offset, batchX[batch_series_idx, :], width=1, color=""blue"")
        plt.bar(left_offset, batchY[batch_series_idx, :] * 0.5, width=1, color=""red"")
        plt.bar(left_offset, single_output_series * 0.3, width=1, color=""green"")

    plt.draw()
    plt.pause(0.0001)


with tf.Session() as sess:
    sess.run(tf.initialize_all_variables())
    plt.ion()
    plt.figure()
    plt.show()
    loss_list = []

    for epoch_idx in range(num_epochs):
        x,y = generateData()
        _current_cell_state = np.zeros((batch_size, state_size))
        _current_hidden_state = np.zeros((batch_size, state_size))

        print(""New data, epoch"", epoch_idx)

        for batch_idx in range(num_batches):
            start_idx = batch_idx * truncated_backprop_length
            end_idx = start_idx + truncated_backprop_length

            batchX = x[:,start_idx:end_idx]
            batchY = y[:,start_idx:end_idx]

            _total_loss, _train_step, _current_state, _predictions_series = sess.run(
                [total_loss, train_step, current_state, predictions_series],
                feed_dict={
                    batchX_placeholder: batchX,
                    batchY_placeholder: batchY,
                    cell_state: _current_cell_state,
                    hidden_state: _current_hidden_state

                })

            _current_cell_state, _current_hidden_state = _current_state

            loss_list.append(_total_loss)

            if batch_idx%100 == 0:
                print(""Step"",batch_idx, ""Batch loss"", _total_loss)
                plot(loss_list, _predictions_series, batchX, batchY)

plt.ioff()
plt.show()



But I have the following error 
ValueError: Shape (1, 5) must have rank at least 3
"
11217,tools.compatibility module is missing or not installed properly through pip,"Running tf_upgrade.py gets ImportError:

```
$ python tf_upgrade.py 
Traceback (most recent call last):
  File ""tf_upgrade.py"", line 23, in <module>
    from tensorflow.tools.compatibility import ast_edits
ImportError: No module named compatibility

```
There's no subdir named compatibility under tools in python packages dir. Those were taken from:

```
>>> import site; site.getsitepackages()
['/usr/local/lib/python2.7/dist-packages', '/usr/lib/python2.7/dist-packages'] 
```

### System information
Ubuntu 16.04
Tensorflow 1.2.1, upgraded 'natively' via pip from a pre 1.0 version:
$ sudo -H pip install --upgrade tensorflow-gpu
Python version 2.7.12

"
11214,"Downloading and building imagenet from scratch says ""wget: command not found""","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Using scripts provided with tensorflow to download and build imagenet from scratch.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: ('v1.2.0-5-g435cdfc', '1.2.1')
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**: NA
- **CUDA/cuDNN version**: 8.0
- **GPU model and memory**: Nvidia GRID M6-8Q(8GB)
- **Exact command to reproduce**: bazel-bin/inception/download_and_preprocess_imagenet ""${DATA_DIR}""

### Describe the problem
I am trying to train inception v3 net for imagenet dataset using instructions at-
[](https://github.com/tensorflow/models/tree/master/slim)
[](https://github.com/tensorflow/models/blob/master/inception/README.md#getting-started)

After setting the download path using following command - 
```
# location of where to place the ImageNet data
DATA_DIR=$HOME/imagenet-data
```
I ran the bazel command to build preprocessing script-
```
# build the preprocessing script.
cd tensorflow-models/inception
bazel build //inception:download_and_preprocess_imagenet
```
And then run it-
```
# run it
bazel-bin/inception/download_and_preprocess_imagenet ""${DATA_DIR}""
```
Running above command fails saying it cannot find `wget` - 

> root@docker_container:/data/workspace/models/inception# bazel-bin/inception/download_and_preprocess_imagenet ""${DATA_DIR}""
> In order to download the imagenet data, you have to create an account with
> image-net.org. This will get you a username and an access key. You can set the
> IMAGENET_USERNAME and IMAGENET_ACCESS_KEY environment variables, or you can
> enter the credentials here.
> Username: <my username>
> Access key: <my password>
> Saving downloaded files to /data/imagenet-data/raw-data/
> Downloading bounding box annotations.
> bazel-bin/inception/download_and_preprocess_imagenet.runfiles/inception/inception/data/download_imagenet.sh: line 58: wget: command not found
> bazel-bin/inception/download_and_preprocess_imagenet.runfiles/inception/inception/data/download_imagenet.sh: line 64: wget: command not found

"
11210,Tensorflow execution with HVX failed on Qualcomm 820 Board,"@satok16 could you have a look at this error? 

I have built the libs and am using Intrinsys 820 Qualcomm board. Tried your troubleshooting procedure to sign as well and put the .so file in `/system/lib/rfsa/adsp/`. Running hexagon graph gives me the same error : 

```
WARNING: linker: Warning: unable to normalize """"
Running main() from test_main.cc
Note: Google Test filter = GraphTransferer.RunInceptionV3OnHexagonExampleWithTfRuntime
[==========] Running 1 test from 1 test case.
[----------] Global test environment set-up.
[----------] 1 test from GraphTransferer
[ RUN      ] GraphTransferer.RunInceptionV3OnHexagonExampleWithTfRuntime
native : hexagon_graph_execution_test.cc:445 Fuse and run inception v3 on hexagon with tf runtime
tensorflow/core/kernels/hexagon/hexagon_graph_execution_test.cc:72: Failure
Expected: (version) >= (1), actual: 0 vs 1
native : hexagon_graph_execution_test.cc:123 Read /data/local/tmp/img_299x299.bmp, size = 269156bytes
native : hexagon_graph_execution_test.cc:129 header size = 54
native : hexagon_graph_execution_test.cc:131 image size = 40
native : hexagon_graph_execution_test.cc:133 width = 299
native : hexagon_graph_execution_test.cc:135 height = -299
native : hexagon_graph_execution_test.cc:457 Ioading image finished.
native : hexagon_graph_execution_test.cc:464 Build fused graph
can't determine number of CPU cores: assuming 4
can't determine number of CPU cores: assuming 4
native : hexagon_graph_execution_test.cc:123 Read /data/local/tmp/img_299x299.bmp, size = 269156bytes
native : hexagon_graph_execution_test.cc:129 header size = 54
native : hexagon_graph_execution_test.cc:131 image size = 40
native : hexagon_graph_execution_test.cc:133 width = 299
native : hexagon_graph_execution_test.cc:135 height = -299
native : hexagon_graph_execution_test.cc:263 Ioading image finished.
native : hexagon_graph_execution_test.cc:171 Ioading image finished.
native : hexagon_graph_execution_test.cc:175 Copy data to tensor.
native : hexagon_graph_execution_test.cc:284 Run graph
Init hexagon with max attributes (Controller version = 92)
Failed to disable DSP DCVS: ffffffff

Failed to append const node 65538
Failed to append const node 65538
Failed to append const node 65539
Failed to append const node 65539

```
`...
`
```
Failed to append const node 66640
native : hexagon_control_wrapper.cc:252 Setup graph completed
Prepare failed! returned 0xffffffff

DUMP HEXAGON LOG: 
Execute graph!
Execution failed!
execute got err: -1

Execution failed
native : hexagon_control_wrapper.cc:312 Check failed: output_tensor->TotalBytes() >= std::get<1>(output) 4032, 2152910848
Aborted 

```
I have attached my adblogcat output as well here. Thanks.
[logcat.txt](https://github.com/tensorflow/tensorflow/files/1117450/logcat.txt)

"
11205,How to create our own dataset,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
11203,L-Op and R-Op in Tensorflow?,"Are there currently equivalents of [theano.gradient.Lop](http://deeplearning.net/software/theano/tutorial/gradients.html#l-operator) and [theano.gradient.Rop](http://deeplearning.net/software/theano/tutorial/gradients.html#r-operator) implemented in Tensorflow? If not, is this a feature that is in the pipeline? I'm trying to port some code over but can't seem to find a way to do this yet. Thank you!"
11202,quantify the mobilenet,"I try to quantify the mobilenet, but I don't decide the out_node ."
11201,bazel build causes Kernel Panic on clean Ubuntu 16.04,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Trying for source
- **TensorFlow version (use command below)**: 1.2
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**: 0.5.2
- **CUDA/cuDNN version**: 5.1
- **GPU model and memory**: Nvidia GTX 750 Ti
- **Exact command to reproduce**: bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package 

### Describe the problem
I get through a fair chunk of the build process then I get hit with: 

Kernel panic - not syncing: Timeout: Not all cpus entered broadcast exception handler

The computer then reboots after about 30 seconds.  This is on a fresh install of Ubuntu.

### Source code / logs

~/Development/tensorflow$ ./configure
.........
You have bazel 0.5.2 installed.
Please specify the location of python. [Default is /usr/bin/python]: 
Found possible Python library paths:
  /usr/local/lib/python2.7/dist-packages
  /usr/lib/python2.7/dist-packages
Please input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/dist-packages]

Using python library path: /usr/local/lib/python2.7/dist-packages
Do you wish to build TensorFlow with MKL support? [y/N] 
No MKL support will be enabled for TensorFlow
Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native]: 
Do you wish to use jemalloc as the malloc implementation? [Y/n] 
jemalloc enabled
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N] Y
Google Cloud Platform support will be enabled for TensorFlow
Do you wish to build TensorFlow with Hadoop File System support? [y/N] y
Hadoop File System support will be enabled for TensorFlow
Do you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N] 
No XLA support will be enabled for TensorFlow
Do you wish to build TensorFlow with VERBS support? [y/N] y
VERBS support will be enabled for TensorFlow
Do you wish to build TensorFlow with OpenCL support? [y/N] 
No OpenCL support will be enabled for TensorFlow
Do you wish to build TensorFlow with CUDA support? [y/N] y
CUDA support will be enabled for TensorFlow
Do you want to use clang as CUDA compiler? [y/N] 
nvcc will be used as CUDA compiler
Please specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 8.0]: 
Please specify the location where CUDA  toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 
Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: 
Please specify the cuDNN version you want to use. [Leave empty to default to cuDNN 6.0]: 5
Please specify the location where cuDNN 5 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 
Please specify a list of comma-separated Cuda compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size.
[Default is: ""5.0""]: ""5.0,6.1""
Do you wish to build TensorFlow with MPI support? [y/N] 
MPI support will not be enabled for TensorFlow
Configuration finished


"
11200,How can I cmpile the Tensorflow library to use CPU Instructions,"My CPU is AMD Ryzen 5 1400
Here is my Instructions sets given by CPU-Z
	MMX (+), SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2, SSE4A, x86-64, AMD-V, AES, AVX, AVX2, FMA3, SHA"
11199,AttributeError: 'module' object has no attribute 'prepare_attention',"**Tensorflow Version**:
```
('v1.1.0-rc0-61-g1ec6ed5', '1.1.0')
```
**Issue**:
```
$ python
Python 2.7.10 (default, Feb  7 2017, 00:08:15) 
[GCC 4.2.1 Compatible Apple LLVM 8.0.0 (clang-800.0.34)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
>>> tf.contrib.seq2seq.prepare_attention()
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
AttributeError: 'module' object has no attribute 'prepare_attention'
```
I'm not sure what why the tf.contrib.seq2seq cannot find [`prepare_attention`](https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/contrib/seq2seq/prepare_attention), any clue to why that is would be appreciated."
11196,[Feature Request] Distributed Tensorflow with Data Parallelism and DMA,"Hi, I have a machine with multiple GPUs and deployed a distributed Tensorflow exploiting data parallelism. I use ClusterConfig to configure the cluster's topology and pass this to Experiment to run the distributed training. I wanted to make one of the GPUs as the parameter server and use the rest for the workers, each of which uses one GPU. I did this through launching multiple processes for parameter server and workers while setting up the env variable (CUDA_VISIBLE_DEVICES) to one of the GPUs. 

In this case, I noticed that the GPUs don't communicate to each other via DMA and I guess this is because the DMA is only available between visible devices to Tensorflow.  

I also tried ""device_count={""GPU"": 1}"" to make Tensorflow see all the GPUs while using only one GPU, but this still seems to occupy the whole resource of all visible GPUs, preventing another Tensorflow process to be launched over the idle GPU. 

It would be great if there is a way to use only one GPU for a Tensorflow process but still enable DMA with the other GPUs sitting in the system. Am I missing such feature even though it exists? 

Thank you!"
11195,No error reported when a wrong argument name is inputted to tf.app.flags,"The default behavior of `tf.app.flags` is: when the user inputs a wrong/undefined argument name, the program just keeps running without throwing out any error about it. For example, 
```
flags.DEFINE_string(""weight_path"", None, ""the path of saved model to restore from"")
```
But when the user inputs 
```
python your_prog.py --weights_path ${MODEL_PATH}
```
The program just keeps running with `weight_path=None` and does not report the wrong argument of `weights_path` which has a **s** appended.
Should we change this kind of default behavior? In this case, users may think they input the correct arguments to finetune the model but unfortunately it just trains from scratch. "
11194,Android TF Classify Multi-label output example?,"What would you have to change to the existing tensorflow android TFClassify app demo to output multiple labels?  

For instance I have a multi output model trained in keras with multiple softmax output nodes. The current TFClassify example has one output node so would the solution be to merely add additional output nodes in the java files?"
11193,Document building tensorflow-gpu from source?,"I have built Tensorflow 1.2 from source with GPU support. However the Python package name is ""tensorflow"" and not ""tensorflow-gpu"" as is common. We also have machines that don't have GPUs in them so I'd like to have them both. However I could not find any documentation on how to do this when building from source."
11192,"why use ""x_is_dict"" to check y?","In tensorflow/contrib/learn/python/learn/learn_io/data_feeder.py
On L325:
`self._y = None if y is None else \
      dict([(k, check_array(v, v.dtype)) for k, v in list(y.items())]) if x_is_dict else check_array(y, y.dtype)
`
   
I happened to have a implementation where x is a dict but y is a numpy array, so I got an error. I wonder why we do not use y_is_dict here? "
11189,"On Network with Shared Weights, Optimizer.minimize has no effect","I have a simple siamese network--a network with two branches that share weights--and a script to train it on some very simple data. The loss and gradients are both non-zero, but executing an optimizer.minimize(loss) operation has no effect on the weights. Executing it in two steps with compute_gradients and apply_gradients also has no effect.

I have tried multiple optimizers and settings, and explored StackOverflow without finding relevant information.

I have included both scripts (they are small) with the relevant debug statements so that you can easily inspect the weights and gradients as well. You will see that the accuracy/weights/gradients do not change (loss changes because new batches are being computed each iteration).

------------------------

### System information
- Windows 10, up to date
- Tensorflow 1.2.0, CPU-only mode
- Python 3.5
- Executing from Windows terminal

Network constructor:

```
import tensorflow as tf

class SameDiffNet:
	# a siamese FC network for classifying vectors as same/different
	
	def __init__(self,inputLen):
		# settings
		self.NUM_BRANCHES = 2
		self.LAYER_SIZES = [20,20]
		self.DATA_TYPE = tf.float32
		self.NORM_CONSTANT = 0.0001
		
		# input
		self.inputs = []
		for branch in range(self.NUM_BRANCHES):
			self.inputs.append(tf.placeholder(self.DATA_TYPE,[None,inputLen]))

		# network branches
		self.branches = []
		self.branchWeights = self.branch_weights(inputLen)
		for branch in range(self.NUM_BRANCHES):
			self.branches.append(self.network_branch(branch))
				
		# combination layer and loss
		self.out = self.distance_layer_euclidean()
		self.target = tf.placeholder(self.DATA_TYPE,[None, 1])
		self.loss = self.contrastive_loss()
		self.accuracy = self.my_accuracy()
		
	def branch_weights(self,inputLen):
		# weights are shared, so they are computed once and re-used to make multiple graphs
		# They are stored as a dictionary of arrays for flexible layer shapes and sizes
		netWeights = {""weights"": [], ""bias"": []}
		netWeights[""weights""].append(tf.Variable(tf.random_normal([inputLen,self.LAYER_SIZES[0]]), name=""weights0""))
		netWeights[""bias""].append(tf.Variable(tf.zeros([self.LAYER_SIZES[0]]),name=""bias0""))
		
		for layer in range(1,len(self.LAYER_SIZES)):
			netWeights[""weights""].append(tf.Variable(tf.random_normal([self.LAYER_SIZES[layer-1],self.LAYER_SIZES[layer]]), name=""weights"" + str(layer)))
			netWeights[""bias""].append(tf.Variable(tf.zeros([self.LAYER_SIZES[layer]]), name=""bias"" + str(layer)))
		
		return netWeights
		
	def network_branch(self,branch):
		fc = self.inputs[branch]
		for layer in range(len(self.LAYER_SIZES)):
			fc = tf.nn.relu(tf.nn.bias_add(tf.matmul(fc,self.branchWeights[""weights""][layer]), self.branchWeights[""bias""][layer]))
		return fc
			
	def distance_layer_euclidean(self):
		assert self.NUM_BRANCHES == 2
		dist = tf.subtract(1.0,tf.sigmoid(tf.sqrt(tf.reduce_sum(tf.pow(tf.subtract(self.branches[0],self.branches[1]),2),1)+self.NORM_CONSTANT)))
		return dist
		
	def cross_entropy_loss(self):
		loss = tf.reduce_sum(tf.multiply(-1.0,tf.add(tf.multiply(self.target,tf.log(self.out+self.NORM_CONSTANT)),tf.multiply(1-self.target,tf.log(1-self.out+self.NORM_CONSTANT)))))
		return loss
		
	def contrastive_loss(self):
		loss = tf.reduce_sum(tf.pow(tf.subtract(self.out,self.target),2))
		return loss 
		
         #Does not work either, so I wrote a simple replacement
	def tf_accuracy(self):
		return tf.metrics.accuracy(tf.round(self.out),self.target)
		
	def my_accuracy(self):
		return tf.reduce_mean(tf.cast(tf.equal(tf.round(self.out), self.target),tf.float32))
```


Run script:

```
''' A simple test where we train our siamese network on toy examples
Our training data consists of a pair of 0's and 1's, and our truth output will
simply be the XOR of these two values'''

import time
import numpy as np
import tensorflow as tf
from sameDiffNet import SameDiffNet

numTraining = 1000
numTest = 500
numIter = 10000

sess = tf.InteractiveSession()
network = SameDiffNet(2)
optimizer = tf.train.GradientDescentOptimizer(0.1)
train = optimizer.minimize(network.loss)
gradients = optimizer.compute_gradients(network.loss) #,tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES))
applyGrad = optimizer.apply_gradients(gradients)

data = np.random.randint(0,2,(numTraining+numTest,2))
truth = data[:,0] == data[:,1]
truth = [float(not truth[b]) for b in range(numTraining+numTest)]
data = data.astype(float)

trainData = data[:numTraining,:]
testData = data[numTraining:,:]
trainTruth = truth[:numTraining]
testTruth = truth[numTraining:]

#Create test data once
testPermutationL = np.random.permutation(numTest)
testPermutationR = np.random.permutation(numTest)
testTarget = [[float(testTruth[testPermutationL[i]] == testTruth[testPermutationR[i]])] for i in range(numTest)]

tf.global_variables_initializer().run()

#debugging
print(""Trainable Variables:"")
print(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES))

for iter in range(numIter):
	permutationL = np.random.permutation(numTraining)
	permutationR = np.random.permutation(numTraining)
	target = [[float(trainTruth[permutationL[i]] == trainTruth[permutationR[i]])] for i in range(numTraining)]
	
	# all large debug output is included in triple-quotes
	
	'''
	print(data[permutationL[1:5],:])
	print(data[permutationR[1:5],:])
	print(target[1:5])
	'''
	
	# you can run the optimization in two steps or one
	'''
	grad = sess.run([gradients], feed_dict={
					network.inputs[0]:trainData[permutationL,:],
					network.inputs[1]:trainData[permutationR,:],
					network.target: target})
	
	sess.run([applyGrad])
	'''
	
	_, loss = sess.run([train,network.loss], feed_dict={
					network.inputs[0]:trainData[permutationL,:],
					network.inputs[1]:trainData[permutationR,:],
					network.target: target})
		
	totalLoss = np.sum(loss)
	if np.isnan(totalLoss):
		print('Model diverged with loss = NaN')
		quit()

	if iter % 10 == 0:
		print ('step %d: loss %.3f' % (iter, totalLoss/numTraining))
		acc = sess.run([network.accuracy],feed_dict={
					network.inputs[0]:testData[testPermutationL,:],
					network.inputs[1]:testData[testPermutationR,:],
					network.target: testTarget});
		print ('step %d: accuracy %.3f' % (iter, np.sum(acc)))

	#debugging
	'''
	print(""Gradients:"")
	print(grad)
	'''
	'''
	print(""First-Layer Weights:"")
	print(sess.run(network.branchWeights[""weights""][0]))
	'''

```"
11187,TF Slim - allow soft placement for devices with train_image_classifier,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS 10.12.5
- **TensorFlow installed from (source or binary)**:source
- **TensorFlow version (use command below)**: git tag 1.2
- **Python version**: 2.7 system install
- **Bazel version (if compiling from source)**: home-brew 0.4.5
- **CUDA/cuDNN version**: NA
- **GPU model and memory**:  NA
- **Exact command to reproduce**: 

train Mobilenet_v1 on CPU like so:

 python train_image_classifier.py     --train_dir=${TRAIN_DIR}     --dataset_dir=${DATASET_DIR}     --dataset_name=Framing     --dataset_split_name=train     --model_name=mobilenet_v1     --checkpoint_path=${CHECKPOINT_PATH}     --checkpoint_exclude_scopes=MobilenetV1/Logits/Conv2d_1c_1x1/biases,MobilenetV1/Logits/Conv2d_1c_1x1/weights 

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

Tensorflow 1.2 has no GPU support for macOS. Thus training/retraining can only happen on CPU.
TF Slim doesnt appear to have an out of the box way to specify soft placement of nodes - therefore I can't appear to train a mobile net checkpoint?


### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.


`INFO:tensorflow:Summary name /clone_loss is illegal; using clone_loss instead.
INFO:tensorflow:Fine-tuning from /Volumes/MediaArchive/datasets/SynopsisCinemaNet/model/mobilenet_v1_1.0_224_2017_06_14/mobilenet_v1_1.0_224.ckpt.index
INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, Cannot assign a device for operation 'MobilenetV1/Logits/Conv2d_1c_1x1/biases/RMSProp_1': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/cpu:0 ]. Make sure the device specification refers to a valid device.
	 [[Node: MobilenetV1/Logits/Conv2d_1c_1x1/biases/RMSProp_1 = VariableV2[_class=[""loc:@MobilenetV1/Logits/Conv2d_1c_1x1/biases""], container="""", dtype=DT_FLOAT, shape=[5], shared_name="""", _device=""/device:GPU:0""]()]]
`"
11186,tf.copy() as alternative to tf.identity(),"`tf.identity(tensor)` does or does not create a copy of the tensor based on whether it's on the same device. This can lead to bugs that are hard to find. The current way of ensuring a copy is to perform an arithmetic/logic operation that doesn't change the value, such as `tensor + 0`, `1 * tensor`, or `tf.equal(tensor, True)`. Needless to say, this makes code hard to read. Moreover, different treatment is needed for different tensor types. Can we have a `tf.copy(tensor)` that does this for us?"
11184,"TF Slim scripts iterate invisible files, don't appear to handle paths with spaces?","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS 10.12
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.2 release (tagged from git)
- **Python version**: system 2.7 from Mac OS X 10.12
- **Bazel version (if compiling from source)**: home-brew 0.4.5
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**:  TF Slim scripts such as train_image_classifier and their installed components, and download_and_convert.py 

### Describe the problem
Hello. Apologies, this seems rather trivial and potentially an oversight on my part, but I think its worth mentioning. 

i'm attempting to follow the TF Slim models readme to get Mobilenet_v1 trained on a custom data set. In looking through the download_and_convert.py scripts and TFRecord creation scripts, I've noticed that:

• conversion functions will iterate over a directory and attempt to load invisible files on macOS such as .DS_Store files as jpegs and cause exceptions in image decode functions
• train_image_classifier does not appear to handle spaces in directory path names, and also attempts to iterate over invisible items such as .DocumentRevisions-V100 (which of course is only an issue if Volume paths with spaces are used).

Im likely missing some basic python understanding, or perhaps some of my issue is an interplay with the nuances of OS X, the OS X installed Python and testing not happening on OS X - but its definitely an issue for folks trying to do work on OS X setting up inference and tuning / retraining end portions of graphs.

### Source code / logs

I don't think I need to include any source, but will try to oblige should anything be requested. Hopefully this isn't an embarrassingly obvious oversight on my part! 

Thank you in advance for taking the time to look this over."
11183,"ConnectionError: HTTPSConnectionPool(host='storage.googleapis.com', port=443): Max retries exceeded with url: /tensorflow/linux/gpu/tensorflow_gpu-1.2.1-cp27-none-linux_x86_64.whl (Caused by <class 'socket.error'>: [Errno 101] Network is unreachable)","I have downloaded and removed Tensorflow a few times in order to try and fix a problems with my numpy package. I now get the error above when I try and download tensorflow. Is there a max amount of times I can download it, is that why I am getting this error? 

Here is the traceback: 
Exception:
Traceback (most recent call last):
  File ""/home/slkapur/tensorflow/local/lib/python2.7/site-packages/pip/basecommand.py"", line 122, in main
    status = self.run(options, args)
  File ""/home/slkapur/tensorflow/local/lib/python2.7/site-packages/pip/commands/install.py"", line 278, in run
    requirement_set.prepare_files(finder, force_root_egg_info=self.bundle, bundle=self.bundle)
  File ""/home/slkapur/tensorflow/local/lib/python2.7/site-packages/pip/req.py"", line 1197, in prepare_files
    do_download,
  File ""/home/slkapur/tensorflow/local/lib/python2.7/site-packages/pip/req.py"", line 1375, in unpack_url
    self.session,
  File ""/home/slkapur/tensorflow/local/lib/python2.7/site-packages/pip/download.py"", line 546, in unpack_http_url
    resp = session.get(target_url, stream=True)
  File ""/home/slkapur/tensorflow/local/lib/python2.7/site-packages/pip/_vendor/requests/sessions.py"", line 395, in get
    return self.request('GET', url, **kwargs)
  File ""/home/slkapur/tensorflow/local/lib/python2.7/site-packages/pip/download.py"", line 237, in request
    return super(PipSession, self).request(method, url, *args, **kwargs)
  File ""/home/slkapur/tensorflow/local/lib/python2.7/site-packages/pip/_vendor/requests/sessions.py"", line 383, in request
    resp = self.send(prep, **send_kwargs)
  File ""/home/slkapur/tensorflow/local/lib/python2.7/site-packages/pip/_vendor/requests/sessions.py"", line 486, in send
    r = adapter.send(request, **kwargs)
  File ""/home/slkapur/tensorflow/local/lib/python2.7/site-packages/pip/_vendor/requests/adapters.py"", line 378, in send
    raise ConnectionError(e)
ConnectionError: HTTPSConnectionPool(host='storage.googleapis.com', port=443): Max retries exceeded with url: /tensorflow/linux/cpu/tensorflow-1.2.1-cp27-none-linux_x86_64.whl (Caused by <class 'socket.error'>: [Errno 101] Network is unreachable)
 
Storing debug log for failure in /tmp/tmp2du06v
"
11182,Quantize weights causes accuracy to plunge when run in mobile but not in computers?,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: 1.2.1
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:
```
/home/kwotsin/tensorflow/bazel-bin/tensorflow/tools/graph_transforms/transform_graph \
--in_graph=./frozen_inception_resnet_v2_for_mobile.pb \
--out_graph=./quantized_inception_resnet_v2_for_mobile_NEW.pb \
--inputs='Placeholder_only' \
--outputs='InceptionResnetV2/Logits/Predictions' \
--transforms='
  add_default_attributes
  strip_unused_nodes(type=float, shape=""1,299,299,3"")
  remove_nodes(op=Identity, op=CheckNumerics)
  fold_constants(ignore_errors=true)
  fold_batch_norms
  fold_old_batch_norms
  quantize_weights
  strip_unused_nodes
  sort_by_execution_order'
```

### Describe the problem
Using the above quantization method, the quantization tool works so well that there is hardly a noticeable difference in accuracy drop (less than 0.5%) for a model like inception v3, with a 1/4 size reduction and slightly faster speed. However, when using the exact same files to be run on mobile, the performance gets so poor that there's more than 70-80% accuracy decrease. I'm unsure whether the issue lies with the quantization not getting optimized on mobile architectures (ARM instead of the usual desktop amd architecture), or whether there is a problem in the operations for the tensorflow mobile library.

Note that `quantize_nodes` is totally unusable. When used to quantize the model, the model size increases a little and then causes the app to crash instantly. The error log produced when using quantize_nodes is this:

```
07-01 00:07:01.760 28272-28357/com.mindorks.tensorflowexample E/art: No implementation found for long org.tensorflow.contrib.android.RunStats.allocate() (tried Java_org_tensorflow_contrib_android_RunStats_allocate and Java_org_tensorflow_contrib_android_RunStats_allocate__)
07-01 00:07:03.508 28272-28357/com.mindorks.tensorflowexample A/libc: Fatal signal 11 (SIGSEGV), code 1, fault addr 0x0 in tid 28357 (pool-1-thread-1)
```

Also, for almost every model I ran, the following error appeared:
`No implementation found for long org.tensorflow.contrib.android.RunStats.allocate()`
What does this mean and how could I resolve it?

FYI: Not sure if it makes a difference, but when I built my lib_tensorflow_inference.so file and the JAR file for using the TF library on mobile, the tensorflow version was cloned from the master branch and not git checked out. Would this make a difference?

Further weird phenomenon:

Although I built my TF from source and bazel built the graph transform tool, the following warnings still appear:

```
2017-07-01 00:05:19.612228: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-01 00:05:19.612262: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-01 00:05:19.612278: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-07-01 00:05:19.612282: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-01 00:05:19.612290: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
```

Thank you."
11181,The 2015 Inception checkpoint gives incorrect results,"### Problems
- The 2015 Inception checkpoint file called `classify_image_graph_def.pb`, which can be found in [`inception-2015-12-05.tgz`](http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz), gives weird results.
- The [tutorial on quantization](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/performance/quantization.md#how-can-you-quantize-your-models) (together with [this one](https://www.tensorflow.org/performance/quantization)) needs corrections.

### Explanation
I originally wanted to try [this tutorial on quantization](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/performance/quantization.md#how-can-you-quantize-your-models) to quantize the model and then check the result with `label_image`.

Using the same name convention as in the tutorial, the quantize step will quantize the original graph, called `classify_image_graph_def.pb`, into a quantized one, called `quantized_graph.pb`. So before checking the latter, I wanted to first `label_image` using this `classify_image_graph_def.pb` and [this sample image](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/label_image/data/grace_hopper.jpg).

The result should be the same as in [this `label_image`'s README](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/label_image/), as shown below. This example, however, uses a newer pre-trained graph, `inception_v3_2016_08_28_frozen.pb`, from [this compressed file](https://storage.googleapis.com/download.tensorflow.org/models/inception_v3_2016_08_28_frozen.pb.tar.gz). In addition to the pb file, the compressed tarball also contains `imagenet_slim_labels.txt`, containing 1,001 lines of label names, e.g. ""military uniform"".

```bash
# expected result
military uniform (653): 0.834306
mortarboard (668): 0.0218692
academic gown (401): 0.0103579
pickelhaube (716): 0.00800814
bulletproof vest (466): 0.00535088
```

So, to check `classify_image_graph_def.pb`, I looked at [the tutorial](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/performance/quantization.md#how-can-you-quantize-your-models) and changed the `--graph` argument from `/tmp/quantized_graph.pb` to `/tmp/classify_image_graph_def.pb`. However, the `--labels` argument also needs to be fixed, because it suggests using `imagenet_synset_to_human_label_map.txt` (from [`inception-2015-12-05.tgz`](http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz)), which actually has 21,842 lines of (synset id, label name). So, **after downloading `imagenet_slim_labels.txt` by following [this `label_image`'s README](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/label_image/)**, fix the `--labels` argument by either leaving it out (because it's the default if following those steps) or explicitly calling the labels file.

The code to run `label_image` for `classify_image_graph_def.pb` becomes:

```bash
bazel build tensorflow/examples/label_image:label_image
bazel-bin/tensorflow/examples/label_image/label_image \
--image=tensorflow/examples/label_image/data/grace_hopper.jpg \
--graph=/tmp/classify_image_class_def.pb \
--input_width=299 \
--input_height=299 \
--input_mean=128 \
--input_std=128 \
--input_layer=""Mul:0"" \
--output_layer=""softmax:0""
```

And here is the result.

```bash
# classify_image_graph_def.pb
toyshop (866): 0.684115
shower cap (794): 0.0394605
warplane (896): 0.0219743
tape player (849): 0.0138034
zucchini (940): 0.013588
```

### Differences between checkpoint files

_There is also another Inception v3 checkpoint file, `inception-v3-2016-03-01.tar.gz`, according to [this tutorial on how to fine-tune Inception](https://github.com/tensorflow/models/tree/master/inception#how-to-fine-tune-a-pre-trained-model-on-a-new-task)!_

So I used [`import_pb_to_tensorboard.py`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/import_pb_to_tensorboard.py) to check why the two checkpoints are different.

Besides the difference in implementation (e.g. how each layers are named), the most important difference I noticed is in the last FC layer. While `inception_v3_2016_08_28_frozen.pb` maps from 2048 to 1001 (the 0th class is ""dummy""), **`classify_image_graph_def.pb` maps from 2048 to 1008!** I'm not sure what 1008 means, but maybe it was trained with a different set of labels in a different order?

The naming difference also makes things a little more complicated. When calling `label_image` with `classify_image_graph_def.pb`, I need to specify `--input_layer=""Mul:0"" --output_layer=""softmax:0""` because these are the names of the input and output layers. However, with the new checkpoint that works, we don't have to specify these two arguments because `input_layer = ""input""` and `output_layer = ""InceptionV3/Predictions/Reshape_1""` are already hard-coded as the default values in the implementations ([C++](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/label_image/main.cc) and [python](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/label_image/label_image.py)).

### Related issues
There are question related to the differences between these two checkpoints and why they give different performances on certain tasks. I've found these issues in the [tensorflow/models](https://github.com/tensorflow/models) repo: [#1314](https://github.com/tensorflow/models/issues/1314), [#1316](https://github.com/tensorflow/models/issues/1316).

### Quantization
Now, back to quantization ... Following the current code in the [tutorial](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/performance/quantization.md) to quantize `classify_image_graph_def.pb` into `quantized_graph.pb` will give an error. This is because the sample code is missing an `--inputs` argument, compared to [this tutorial on `graph_transforms`](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/graph_transforms#eight-bit-calculations). **The `transform_graph` example needs `--inputs=""Mul""`.** Then it will work, i.e. predicting ""toyshop"" as the top choice.

Actually, this quantization process works with the new `inception_v3_2016_08_28_frozen.pb` -- predicting that the picture is ""military uniform"" by both original and quantized graphs.

### Questions
- What are the actual differences between the three checkpoints? Which one should we use? Any clarification would be really helpful. When different tutorials refer to different checkpoint files, at first I thought all of them can be used interchangeably. As it turns out, they are actually not the same and this has caused a lot of confusion.
- Why is the last layer in `classify_image_graph_def.pb` from 2015 have 1008 nodes, not 1001?
- Is there a way to make `classify_image_graph_def.pb` work, following the tutorial? Did I miss any arguments or other settings?
- _Somewhat unrelated question_: The [tutorial](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/performance/quantization.md) on quantization mentioned above seems to be the same as [this one on tensorflow.org](https://www.tensorflow.org/performance/quantization), except for the last few commits. Therefore, the tutorial on the website is not up-to-date. Are they supposed to be the same?
- How should the tutorials on quantization be updated? Personally, I think it can be fixed to use the new checkpoint, then adjust the example codes accordingly.

Thank you!"
11180,Cannot build TensorFlow on macOS 10.12,"When I trying to build TensorFlow with avx, avx2, fma, sse4,1 sse4,2, it shown that
```
clang: error: no such file or directory: 'msse4.1'
clang: error: no such file or directory: 'msse4.2'
```
clang doesn't support sse4.1 and sse4.2?
And I can not change the bazel compiler to gcc anyway"
11178,Inconsistent losses for Keras,"TF 1.2.0, Python 3.5.

## TF Official Keras
```
tf.contrib.keras.backend.sparse_categorical_crossentropy (output, target)
tf.contrib.keras.losses.sparse_categorical_crossentropy  (target, output)
tf.contrib.keras.metrics.sparse_categorical_crossentropy (target, output)
tf.losses.sparse_softmax_cross_entropy (target, output)  - no sentinel
tf.nn.sparse_softmax_cross_entropy_with_logits (target, output)
'sparse_softmax_cross_entropy'
```

## Pure Keras
```
keras.losses.sparse_categorical_crossentropy(target, output)
```

There are many `sparse_softmax_cross_entropy` but they all have different APIs. Some are compatible with `tf.contrib.keras.models.Model.compile()` and  the others are not because of `_sentinel` and different order of `output` and `target`.

Interestingly both the original TF and Keras use (target, output) and only `tf.contrib.keras.backend` version uses (output, target). tf-keras needs to use (output, target) otherwise the model is not trained.

Can we unify the interface and document when to use each version?
"
11171, [Feature] Node mirroring for GPU-memory reduction,"In the paper [Training Deep Nets with Sublinear Memory Cost](https://arxiv.org/abs/1604.06174) Chen et al. introduced a very good idea to greatly reduce GPU memory requirements. 

The idea bowls down to discarding the output of some nodes during the forward pass and recompute those values when they are needed again in the backward pass. Only the output of some key ops is kept in memory. During back-prop all forward computation from those key nodes are redone. They also describe how this can be implemented in a graph based computation model by mirroring non-key ops. This is depicted in figure 3 (see below).

Performing this kind of graph manipulation in [MxNet](https://github.com/dmlc/mxnet) is quite easy and I have played around with this myself. I am able to reduce the memory cost of a SotA segmentation model from `13504 MB` to `3382 MB` for the cost of about ~40% increase in computational time. (Given that we have plenty 1080 TI and view P100 GPUs, I am very happy to pay this cost).

For me as deep learning researcher this is a totally awesome killer feature. In most of my experiments I am limited by the amount of available GPU memory. Doing node mirroring allows me to try a whole bunch of new stuff, I was always wanting to do. 

1. Is anything like this planned to be implemented in Tensorflow any time soon?
2. In the current API, is there already a way to build and / or manipulate the computational graph to perform node mirroring (like in figure 3)?

![](https://i.imgur.com/CnkUzwJ.png)

Regarding question two, I don't mind if it gets messy. Copying some nodes inside the graph is possible in tensorflow. Gradient flow can also be stopped for the first copy. What is missing is to utilize the second node for gradient computation. I don't know how I can archive this using the python API in tensorflow. Any ideas with this?

"
11169,How to run the program coding by python in the Android phone?,"I already wrote a pretrain vgg16 on my computer(python, Linux), now I want to run this program using my android phone`s CPU/GPU, the outcome could show in terminal. However, I cannot find any hint in this situation, so I want some hint and hope you can update the Readme."
11168,LSTMBlockCell variable names changed - old checkpoints cannot be restored,"In TF 1.1 and earlier, bias and weights had the variable names `""biases""` and `""weights""` in the `LSTMBlockCell`.

Since TF 1.2, they have the variable names `""bias""` and `""kernel""`.

Why was that changed? It makes all checkpoint files incompatible, but for no real reason."
11165,"[feature-request] Multi-arity elems in fold{l,r}","The functions ```fold{l,r}``` that are part of ```tensorflow.python.ops.functional_ops``` currently only allow single-arity arguments for ```elems```. This makes it inconvenient for writing operations that involve dynamic concatenation of tensors differing in the dimension along a particular axis without padding (this also means one can't use ```tf.map_fn``` for accomplishing this task).

This scenario is present in cases like object detection where a different number of boxes are emitted for each image in the batch. Currently, the implementation in tensorflow/models (```tensorflow-models:object_detection/core/post_processing.py```) gets around this by fixing the batch size and using ```tf.split``` during graph compilation time. The requested op would make such scenarios dynamic; it would also be the way forward in making ```tf.dynamic_partition``` ..erm, more dynamic (without introducing a List into Tensorflow's semantics).

I currently resort to something like the following,
``` python
zeroq = tf.constant(0) - tf.constant(0)
nkeeps_0 = tf.zeros([zeroq], dtype=tf.int32); keeps_0 = tf.zeros([zeroq], dtype=tf.int32)  
def _compute(ii, nkeeps_r, keeps_r):
  keep_ii = <function that spits a varying tensor of shape [M_ii]>
  return (ii + 1, tf.concat([nkeeps_r, tf.stack([tf.shape(keep_ii)[0]])], axis=0), tf.concat([keeps_r, keep_ii], axis=0))
_, *ret = control_flow_ops.while_loop(lambda ii, *_: ii < bsize, _compute, [tf.constant(0), nkeeps_0, keeps_0], back_prop=False)
```
I'm not sure how this will play with ```back_prop=True```, or as to how this would fit in with the larger goals for the project."
11164,Expose reader.read_up_to in slim parallel reader,"When reading small records (in my case, one example is a a floatlist of about 150 floats), the DataSetProvider from slim is very slow. I found out that things get much faster if I write a custom input pipeline that leverages reader.read_up_to 

```python
def ReadTFRecord(filename_queue):
  num_tfrecords_at_once = 1024 
  reader = tf.TFRecordReader()
  _, queue_batch = reader.read_up_to(filename_queue, num_tfrecords_at_once)
  return [queue_batch]
```
the returned value is then fed to `tf.train.shuffle_batch` with enqueue_many set to true. 

As far as I understand, this behavior is currently not exposed in slim.ParallelReader, see https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/slim/python/slim/data/parallel_reader.py#L132. Are there any plans for adding it?"
11163,"Expected one attr with name u'T' in name: ""swap_out_d_0""","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: r1.2
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: 0.4.5
- **CUDA/cuDNN version**: CUDA8.0
- **GPU model and memory**:  Tesla P100, 16GB

### Describe the problem
I used OptimizeGraph API in Grappler for inserting ""swap_to_host"" nodes in my graph. When I import the new graph_def generated from this API, I got error mesage: ""Expected one attr with name u'T' in swap_out_d_0."" I think the new graph_def misses some attribute information.
I am following this bug and handing on fixing it.

### Source code / logs
source code:

```python
d.op.node_def.attr['_swap_to_host'].i = 0
mg = meta_graph.create_meta_graph_def(graph=ops.get_default_graph())
graph = tf_optimizer.OptimizeGraph(rewriter_config, mg)
tf.import_graph_def(graph)
```
log:

```python
Traceback (most recent call last):
  File ""memory_optimizer_test.py"", line 62, in testSimpleSwap
    tf.import_graph_def(graph)
  File ""/home/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/importer.py"", line 307, in import_graph_def
    output_types = _OutputTypes(node, op_dict)
  File ""/home/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/importer.py"", line 83, in _OutputTypes
    return _ArgsToTypes(node_def, op_def.output_arg)
  File ""/home/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/importer.py"", line 72, in _ArgsToTypes
    types.extend(_SingleArgToTypes(node_def, arg_def))
  File ""/home/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/importer.py"", line 63, in _SingleArgToTypes
    types = _ArgToTypesNoRef(node_def, arg_def)
  File ""/home/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/importer.py"", line 54, in _ArgToTypesNoRef
    return [_GetNodeAttr(node_def, arg_def.type_attr).type]
  File ""/home/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/importer.py"", line 40, in _GetNodeAttr
    % (attr_name, str(node_def)))
ValueError: Expected one attr with name u'T' in name: ""swap_out_d_0""
op: ""Identity""
input: ""b""
device: ""/CPU""
.
```


"
11162,Rank mismatch error when using contrib.seq2seq.AttentionWrapper in a dynamic_rnn with sequence_length,"### System information
Linux Ubuntu 16.04
TensorFlow installed from pip binary
TensorFlow version 1.2.0 (v1.2.0-rc2-21-g12f033d)
Python 3.6.1 Anaconda 4.4.0
CUDA 8.0 / cuDNN 5.1
TITAN X (Pascal) 11.9GB

### Describe the problem

Error: `Shapes must be equal rank, but are 0 and 1 for 'rnn/while/Select_4' (op: 'Select') with input shapes: [10], [], [].` when using `tf.contrib.seq2seq.AttentionWrapper` in a `dynamic_rnn` with `seqence_length` provided.

Code to reproduce:

```
import tensorflow as tf
from tensorflow.contrib.rnn import LSTMCell, MultiRNNCell
import numpy as np

encoder_outputs = tf.constant(np.random.rand(10,20,512).astype(np.float32))
decoder_inputs = tf.constant(np.random.rand(10,20,512).astype(np.float32))
lengths = tf.constant(np.random.randint(5,20,(10,),dtype=np.int32))

cell = LSTMCell(512)
attention_mechanism = tf.contrib.seq2seq.LuongAttention(512, encoder_outputs)
attn_cell = tf.contrib.seq2seq.AttentionWrapper(
          cell, attention_mechanism, attention_layer_size=256)

o, s = tf.nn.dynamic_rnn(attn_cell, decoder_inputs, lengths, dtype=tf.float32)
# this works: o, s = tf.nn.dynamic_rnn(attn_cell, decoder_inputs, dtype=tf.float32)
# this works: o, s = tf.nn.dynamic_rnn(cell, decoder_inputs, lengths, dtype=tf.float32)

with tf.Session() as sess:
    tf.global_variables_initializer().run()
    sess.run(o)
```

### Traceback

```
Traceback (most recent call last):
  File ""/home/dgaddy/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py"", line 671, in _call_cpp_shape_fn_impl
    input_tensors_as_shapes, status)
  File ""/home/dgaddy/anaconda3/lib/python3.6/contextlib.py"", line 89, in __exit__
    next(self.gen)
  File ""/home/dgaddy/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py"", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: Shapes must be equal rank, but are 0 and 1 for 'rnn/while/Select_4' (op: 'Select') with input shapes: [10], [], [].

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""test.py"", line 14, in <module>
    o, s = tf.nn.dynamic_rnn(attn_cell, decoder_inputs, lengths, dtype=tf.float32)
  File ""/home/dgaddy/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py"", line 574, in dynamic_rnn
    dtype=dtype)
  File ""/home/dgaddy/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py"", line 737, in _dynamic_rnn_loop
    swap_memory=swap_memory)
  File ""/home/dgaddy/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2770, in while_loop
    result = context.BuildLoop(cond, body, loop_vars, shape_invariants)
  File ""/home/dgaddy/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2599, in BuildLoop
    pred, body, original_loop_vars, loop_vars, shape_invariants)
  File ""/home/dgaddy/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2549, in _BuildLoop
    body_result = body(*packed_vars_for_body)
  File ""/home/dgaddy/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py"", line 720, in _time_step
    skip_conditionals=True)
  File ""/home/dgaddy/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py"", line 210, in _rnn_step
    final_output_and_state = _copy_some_through(new_output, new_state)
  File ""/home/dgaddy/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py"", line 182, in _copy_some_through
    for state, new_state in zip(flat_state, flat_new_state)]
  File ""/home/dgaddy/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py"", line 182, in <listcomp>
    for state, new_state in zip(flat_state, flat_new_state)]
  File ""/home/dgaddy/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py"", line 171, in _copy_one_through
    return array_ops.where(copy_cond, output, new_output)
  File ""/home/dgaddy/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py"", line 2328, in where
    return gen_math_ops._select(condition=condition, t=x, e=y, name=name)
  File ""/home/dgaddy/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py"", line 2145, in _select
    name=name)
  File ""/home/dgaddy/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 767, in apply_op
    op_def=op_def)
  File ""/home/dgaddy/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 2508, in create_op
    set_shapes_for_outputs(ret)
  File ""/home/dgaddy/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1873, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/home/dgaddy/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1823, in call_with_requiring
    return call_cpp_shape_fn(op, require_shape_fn=True)
  File ""/home/dgaddy/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py"", line 610, in call_cpp_shape_fn
    debug_python_shape_fn, require_shape_fn)
  File ""/home/dgaddy/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py"", line 676, in _call_cpp_shape_fn_impl
    raise ValueError(err.message)
ValueError: Shapes must be equal rank, but are 0 and 1 for 'rnn/while/Select_4' (op: 'Select') with input shapes: [10], [], [].
```"
11160,High variance in training convergence between keras (with tf backend) and tf.contrib.keras,"

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 10
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
1.2
- **Python version**: 
3.6


### Describe the problem
I started to move my keras (Keras 2.0.4) scripts to tf.contrib.keras  (tf version 1.2) but I am achieving worse performance though the porting was seamless. Not sure why there is such huge discrepancy. in training performance

### Source code / logs
Original (Keras 2.0.4 code)
```
import tensorflow as tf
import keras

resnet = keras.applications.ResNet50(include_top=False,weights='imagenet', pooling='avg')
input_ = resnet.input
final_layer = resnet.layers[-1]
output_ = keras.layers.Dense(1,activation='sigmoid')(final_layer.output)
model = keras.models.Model(input_, output_)
num_layers=len(model.layers)
for i,layer in enumerate(model.layers):
    if i == num_layers -1 :
        layer.trainable=True
    else:
        layer.trainable = False

ig=keras.preprocessing.image.ImageDataGenerator(
    preprocessing_function=preprocess_function)
training_data =ig.flow_from_directory('../../../data/dogsvscats/train/', class_mode='binary',target_size=(224,224),batch_size=64)
validation_data = ig.flow_from_directory('../../../data/dogsvscats/validation/',class_mode='binary', target_size=(224,224), batch_size=64)

model.compile(keras.optimizers.Adam(lr=1e-4),keras.losses.binary_crossentropy,metrics=['accuracy'])
model.fit_generator(training_data,steps_per_epoch=4000, epochs=2, validation_data=validation_data, validation_steps=300)
```

___This model achieved 96% accuracy in 1 epoch___ (which is expected)

Same code (tf.contrib.keras)

```
import tensorflow as tf
import tensorflow.contrib.keras as keras

resnet = keras.applications.ResNet50(include_top=False,weights='imagenet', pooling='avg')
input_ = resnet.input
final_layer = resnet.layers[-1]
output_ = keras.layers.Dense(1,activation='sigmoid')(final_layer.output)
model = keras.models.Model(input_, output_)
num_layers=len(model.layers)
for i,layer in enumerate(model.layers):
    if i == num_layers -1 :
        layer.trainable=True
    else:
        layer.trainable = False

ig=keras.preprocessing.image.ImageDataGenerator(
    preprocessing_function=preprocess_function)
training_data =ig.flow_from_directory('../../../data/dogsvscats/train/', class_mode='binary',target_size=(224,224),batch_size=64)
validation_data = ig.flow_from_directory('../../../data/dogsvscats/validation/',class_mode='binary', target_size=(224,224), batch_size=64)

model.compile(keras.optimizers.Adam(lr=1e-4),keras.losses.binary_crossentropy,metrics=['accuracy'])
model.fit_generator(training_data,steps_per_epoch=4000, epochs=2, validation_data=validation_data, validation_steps=300)

```

___This model struggles to achieve 58% accuracy after 1 epoch and 61% after 2 epochs__

Is there something different in terms of hyper-parameter settings that is required when switching between the 2 versions. 

"
11157,TypeError: can't pickle _thread.lock objects,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No, using stock examples
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: pip
- **TensorFlow version (use command below)**: 1.2.1
- **Python version**: 3.6.1 (Anaconda 4.4.0 64-bit)
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**: I'm running the seq2seq example in models/tutorials/rnn/translate, verbatim.

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

Collecting system information...
2017-06-29 18:35:16.672194: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-29 18:35:16.672242: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-29 18:35:16.672250: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
Wrote environment to tf_env.txt. You can review the contents of that file.
and use it to populate the fields in the github issue template.

cat tf_env.txt

== cat /etc/issue ===============================================
Linux GCRGDL171 4.8.0-58-generic #63~16.04.1-Ubuntu SMP Mon Jun 26 18:08:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""16.04.2 LTS (Xenial Xerus)""
VERSION_ID=""16.04""
VERSION_CODENAME=xenial

== are we in docker =============================================
No

== compiler =====================================================
c++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux GCRGDL171 4.8.0-58-generic #63~16.04.1-Ubuntu SMP Mon Jun 26 18:08:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy (1.12.1)
numpydoc (0.6.0)
protobuf (3.3.0)
tensorflow (1.2.1)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.2.1
tf.GIT_VERSION = v1.2.0-5-g435cdfc
tf.COMPILER_VERSION = v1.2.0-5-g435cdfc
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH /usr/local/cuda:/usr/local/cuda/lib64:
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
Thu Jun 29 18:35:19 2017
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 375.66                 Driver Version: 375.66                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K40m          Off  | 0000:27:00.0     Off |                    0 |
| N/A   27C    P8    21W / 235W |      0MiB / 11439MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

== cuda libs  ===================================================
/usr/local/cuda-8.0/lib64/libcudart.so.8.0.61
/usr/local/cuda-8.0/lib64/libcudart_static.a
/usr/local/cuda-8.0/doc/man/man7/libcudart.7
/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I get exception: TypeError: can't pickle _thread.lock objects. It happens on different machines with the same python version. Just running your example code verbatim. 

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

Traceback (most recent call last):
  File ""translate.py"", line 322, in <module>
    tf.app.run()
  File ""/home/t-mabruc/anaconda3/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""translate.py"", line 319, in main
    train()
  File ""translate.py"", line 178, in train
    model = create_model(sess, False)
  File ""translate.py"", line 136, in create_model
    dtype=dtype)
  File ""/home/t-mabruc/models/tutorials/rnn/translate/seq2seq_model.py"", line 179, in __init__
    softmax_loss_function=softmax_loss_function)
  File ""/home/t-mabruc/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py"", line 1206, in model_with_buckets
    decoder_inputs[:bucket[1]])
  File ""/home/t-mabruc/models/tutorials/rnn/translate/seq2seq_model.py"", line 178, in <lambda>
    lambda x, y: seq2seq_f(x, y, False),
  File ""/home/t-mabruc/models/tutorials/rnn/translate/seq2seq_model.py"", line 142, in seq2seq_f
    dtype=dtype)
  File ""/home/t-mabruc/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py"", line 848, in embedding_attention_seq2seq
    encoder_cell = copy.deepcopy(cell)
  File ""/home/t-mabruc/anaconda3/lib/python3.6/copy.py"", line 161, in deepcopy
    y = copier(memo)
  File ""/home/t-mabruc/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py"", line 476, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
  File ""/home/t-mabruc/anaconda3/lib/python3.6/copy.py"", line 150, in deepcopy
    y = copier(x, memo)
  File ""/home/t-mabruc/anaconda3/lib/python3.6/copy.py"", line 215, in _deepcopy_list
    append(deepcopy(a, memo))
  File ""/home/t-mabruc/anaconda3/lib/python3.6/copy.py"", line 180, in deepcopy
    y = _reconstruct(x, memo, *rv)
  File ""/home/t-mabruc/anaconda3/lib/python3.6/copy.py"", line 280, in _reconstruct
    state = deepcopy(state, memo)
  File ""/home/t-mabruc/anaconda3/lib/python3.6/copy.py"", line 150, in deepcopy
    y = copier(x, memo)
  File ""/home/t-mabruc/anaconda3/lib/python3.6/copy.py"", line 240, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File ""/home/t-mabruc/anaconda3/lib/python3.6/copy.py"", line 180, in deepcopy
    y = _reconstruct(x, memo, *rv)
  File ""/home/t-mabruc/anaconda3/lib/python3.6/copy.py"", line 280, in _reconstruct
    state = deepcopy(state, memo)
  File ""/home/t-mabruc/anaconda3/lib/python3.6/copy.py"", line 150, in deepcopy
    y = copier(x, memo)
  File ""/home/t-mabruc/anaconda3/lib/python3.6/copy.py"", line 240, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File ""/home/t-mabruc/anaconda3/lib/python3.6/copy.py"", line 180, in deepcopy
    y = _reconstruct(x, memo, *rv)
  File ""/home/t-mabruc/anaconda3/lib/python3.6/copy.py"", line 280, in _reconstruct
    state = deepcopy(state, memo)
  File ""/home/t-mabruc/anaconda3/lib/python3.6/copy.py"", line 150, in deepcopy
    y = copier(x, memo)
  File ""/home/t-mabruc/anaconda3/lib/python3.6/copy.py"", line 240, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File ""/home/t-mabruc/anaconda3/lib/python3.6/copy.py"", line 180, in deepcopy
    y = _reconstruct(x, memo, *rv)
  File ""/home/t-mabruc/anaconda3/lib/python3.6/copy.py"", line 280, in _reconstruct
    state = deepcopy(state, memo)
  File ""/home/t-mabruc/anaconda3/lib/python3.6/copy.py"", line 150, in deepcopy
    y = copier(x, memo)
  File ""/home/t-mabruc/anaconda3/lib/python3.6/copy.py"", line 240, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File ""/home/t-mabruc/anaconda3/lib/python3.6/copy.py"", line 169, in deepcopy
    rv = reductor(4)
TypeError: can't pickle _thread.lock objects"
11155,head.py still uses scalar_summary,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS Sierra 10.12.5
- **TensorFlow installed from (source or binary)**: pip
- **TensorFlow version (use command below)**: 1.2.1
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

### Describe the problem
head.py still uses `logging_ops.scalar_summary` despite the method being a depreciated, leading to warnings. The problem seems to start from `estimator.fit` and `estimator.evaluate`

### Source code
```
import tensorflow as tf
# NumPy is often used to load, manipulate and preprocess data.
import numpy as np

# Declare list of features. We only have one real-valued feature. There are many
# other types of columns that are more complicated and useful.
features = [tf.contrib.layers.real_valued_column(""x"", dimension=1)]

# An estimator is the front end to invoke training (fitting) and evaluation
# (inference). There are many predefined types like linear regression,
# logistic regression, linear classification, logistic classification, and
# many neural network classifiers and regressors. The following code
# provides an estimator that does linear regression.
estimator = tf.contrib.learn.LinearRegressor(feature_columns=features)

# TensorFlow provides many helper methods to read and set up data sets.
# Here we use two data sets: one for training and one for evaluation
# We have to tell the function how many batches
# of data (num_epochs) we want and how big each batch should be.
x_train = np.array([1., 2., 3., 4.])
y_train = np.array([0., -1., -2., -3.])
x_eval = np.array([2., 5., 8., 1.])
y_eval = np.array([-1.01, -4.1, -7, 0.])
input_fn = tf.contrib.learn.io.numpy_input_fn({""x"":x_train}, y_train,
                                              batch_size=4,
                                              num_epochs=1000)
eval_input_fn = tf.contrib.learn.io.numpy_input_fn(
    {""x"":x_eval}, y_eval, batch_size=4, num_epochs=1000)

# We can invoke 1000 training steps by invoking the  method and passing the
# training data set.
estimator.fit(input_fn=input_fn, steps=1000)
# Here we evaluate how well our model did.
train_loss = estimator.evaluate(input_fn=input_fn)

eval_loss = estimator.evaluate(input_fn=eval_input_fn)

print ""train loss: %r""% train_loss
print ""eval loss: %r""% eval_loss
```

### Logs
```
WARNING:tensorflow:Using temporary folder as model directory: /var/folders/1l/v82bx7_s5zvf7z8wlgjz4j_06gd09g/T/tmpQRR2VF
WARNING:tensorflow:From /Users/admin/Library/Python/2.7/lib/python/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
2017-06-29 16:53:02.952908: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-29 16:53:02.952925: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-06-29 16:53:02.952930: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-29 16:53:02.952934: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
WARNING:tensorflow:From /Users/admin/Library/Python/2.7/lib/python/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
WARNING:tensorflow:From /Users/admin/Library/Python/2.7/lib/python/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
train metrics: {'loss': 9.803332e-07, 'global_step': 1000}
eval metrics: {'loss': 0.0026192721, 'global_step': 1000}
```
"
11152,Threading example at programmers_guide/threading_and_queues broken,"Dear TF folks,

I am trying to reproduce the example listed at [1], 

```
# Thread body: loop until the coordinator indicates a stop was requested.
# If some condition becomes true, ask the coordinator to stop.
def MyLoop(coord):
  while not coord.should_stop():
    ...do something...
    if ...some condition...:
      coord.request_stop()

# Main thread: create a coordinator.
coord = tf.train.Coordinator()

# Create 10 threads that run 'MyLoop()'
threads = [threading.Thread(target=MyLoop, args=(coord,)) for i in xrange(10)]

# Start the threads and wait for all of them to stop.
for t in threads:
  t.start()
coord.join(threads)
```
When running this example, I cannot find the `threading.Thread` class (e.g. by searching for ""Thread"" in the API docs or `tf.threading.Thread`).

Am I missing something where? Is the example maybe broken?

Thanks!

\jv

## Setup

```bash
$ python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""
('v1.2.0-rc2-21-g12f033d', '1.2.0')
```

[1]: https://www.tensorflow.org/programmers_guide/threading_and_queues
"
11151,Train a classifier error tensorflow.python.framework.errors_impl.NotFoundError:,"I train my classifier, but when I'm going to rate an image this error appears:

root@e7bfbff82a10:/tf_files# python label_image.py new/maca/2Q==.jpg
Traceback (most recent call last):
  File ""label_image.py"", line 11, in <module>
    image_data = tf.gfile.FastGFile(image_path, 'rb').read()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/lib/io/file_io.py"", line 115, in read
    self._preread_check()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/lib/io/file_io.py"", line 75, in _preread_check
    compat.as_bytes(self.__name), 1024 * 512, status)
  File ""/usr/lib/python2.7/contextlib.py"", line 24, in __exit__
    self.gen.next()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.py"", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.NotFoundError: new/maca/2Q==.jpg

I follow all steps of code lab TensorFlow for poets, but I still have this problem. "
11149,Self-contained source code package of tensorflow,"Dear TensorFlow development team,
    Government regularization on medical software requires software to be compiled from fully controllable source code. Downloading from outside of the manufacture is not permitted. This literally implies that medical software should be able to compile without Internet connection. Currently, the bazel compilation procedure download from Internet. We post this request for a self-contained package of tensorflow.

"
11148,TFDBG Crashing on Windows 10; 'Causality Violated in Timing Relations of Debug Dumps',"I started using TensorFlow and wrote a simple Siamese neural net. I wrote a small script to test the network, and got NaNs for loss, so I decided to learn how to use tfgbd. 

But when I run tfgbd, it crashes with the error 'Causality violated in timing relations of debug dumps: gradients/sub_1_grad/Shape_1 (1498762743063952): these input(s) are not satisfied: [('Sub_1', 0)]'

------------------------

-Windows 10, up to date
-Python 3.5
-TensorFlow 1.2.0, compiled in CPU-only mode

Source Code:
I have one script to define the network and one to run the actual test. I will include both.

sameDiffNet:

```
import tensorflow as tf

class SameDiffNet:
	# class is a siamese FC network for classifying vectors as same/different
	
	def __init__(self,inputLen):
		# settings
		self.NUM_BRANCHES = 2
		self.LAYER_SIZES = [100,100]
		self.DATA_TYPE = tf.float32
		
		# input
		self.inputs = []
		for branch in range(self.NUM_BRANCHES):
			self.inputs.append(tf.placeholder(self.DATA_TYPE,[None,inputLen]))

		# network branches
		self.branches = []
		self.branchWeights = self.branch_weights(inputLen)
		for branch in range(self.NUM_BRANCHES):
			self.branches.append(self.network_branch(branch))
				
		# combination layer and loss
		self.out = self.distance_layer_euclidean()
		self.target = tf.placeholder(self.DATA_TYPE,None)
		self.loss = self.cross_entropy_loss()
		
	def branch_weights(self,inputLen):
		# weights are shared, so they are computed once and re-used to make multiple graphs
		# They are stored as a dictionary of arrays for flexible layer shapes and sizes
		netWeights = {""weights"": [], ""bias"": []}
		netWeights[""weights""].append(tf.Variable(tf.random_normal([inputLen,self.LAYER_SIZES[1]]),name=""weights""))
		netWeights[""bias""].append(tf.Variable(tf.zeros([self.LAYER_SIZES[0]]),name=""bias""))
		
		for layer in range(1,len(self.LAYER_SIZES)):
			netWeights[""weights""].append(tf.Variable(tf.random_normal([self.LAYER_SIZES[layer-1],self.LAYER_SIZES[layer]]),name=""weights""))
			netWeights[""bias""].append(tf.Variable(tf.zeros([self.LAYER_SIZES[layer]]),name=""bias""))
		
		return netWeights
		
	def network_branch(self,branch):
		fc = self.inputs[branch]
		for layer in range(len(self.LAYER_SIZES)):
			fc = tf.nn.relu(tf.nn.bias_add(tf.matmul(fc,self.branchWeights[""weights""][layer]), self.branchWeights[""bias""][layer]))
		return fc
			
	def distance_layer_euclidean(self):
		assert self.NUM_BRANCHES == 2
		dist = tf.subtract(1.0,tf.nn.sigmoid(tf.sqrt(tf.reduce_sum(tf.pow(tf.subtract(self.branches[0],self.branches[1]),2),1))))
		return dist
		
	def cross_entropy_loss(self):
		loss = tf.add(tf.multiply(self.target,tf.log(self.out)),tf.multiply(1-self.target,tf.log(1-self.out)))
		return loss`
```

toyTestTraining:
```
''' A simple test where we train our siamese network on toy examples
Our training data consists of a pair of 0's and 1's, and our truth output will
simply be the XOR of these two values'''

import numpy as np
import tensorflow as tf
from tensorflow.python import debug as tf_debug
from sameDiffNet import SameDiffNet

numTraining = 1000
numIter = 1000

sess = tf.InteractiveSession()
sess = tf_debug.LocalCLIDebugWrapperSession(sess)
sess.add_tensor_filter(""has_inf_or_nan"", tf_debug.has_inf_or_nan)
network = SameDiffNet(2)
optimizer = tf.train.AdamOptimizer().minimize(network.loss)

data = np.random.randint(0,2,(numTraining,2))
truth = data[:,0] == data[:,1]
truth = [float(not truth[b]) for b in range(numTraining)]
data = data.astype(float)

init = tf.global_variables_initializer().run()
for iter in range(numIter):
	permutationL = np.random.permutation(numTraining)
	permutationR = np.random.permutation(numTraining)
	target = [float(truth[permutationL[i]] == truth[permutationR[i]]) for i in range(numTraining)]

	totalLoss = 0.0
	for v in range(numTraining):
		_, loss = sess.run([optimizer,network.loss], feed_dict={
						network.inputs[0]:[data[permutationL[v],:]],
						network.inputs[1]:[data[permutationR[v],:]],
						network.target: target[v]})
		totalLoss += loss
		
	if np.isnan(totalLoss):
		print('Model diverged with loss = NaN')
		quit()

	if iter % 10 == 0:
		print ('step %d: loss %.3f' % (iter, totalLoss/numTraining))
```


import toyTestTraining opens tfgbd. I enter 'run' at the first pause, and get the following error dump:
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""D:\Computer Vision\Siamese Same-Different Network\toyTestTraining.py"", line 35, in <module>
    network.target: target[v]})
  File ""C:\Users\Christopher\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\debug\wrappers\framework.py"", line 495, in run
    run_end_resp = self.on_run_end(run_end_req)
  File ""C:\Users\Christopher\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\debug\wrappers\local_cli_wrapper.py"", line 312, in on_run_end
    self._dump_root, partition_graphs=partition_graphs)
  File ""C:\Users\Christopher\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\debug\lib\debug_data.py"", line 551, in __init__
    self._load_partition_graphs(partition_graphs, validate)
  File ""C:\Users\Christopher\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\debug\lib\debug_data.py"", line 809, in _load_partition_graphs
    self._validate_dump_with_graphs()
  File ""C:\Users\Christopher\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\debug\lib\debug_data.py"", line 985, in _validate_dump_with_graphs
    (node, datum.timestamp, repr(pending_inputs[node])))
ValueError: Causality violated in timing relations of debug dumps: gradients/sub_1_grad/Shape_1 (1498762743063952): these input(s) are not satisfied: [('Sub_1', 0)]


This error happens 100% of the time I run these commands.
I apologize in advance if I'm overlooking something obvious. Thank you."
11147,having problem to identify porn images -> especaly with penises (NO its not a joke!!!),"i m running a website where a mass on photos are uploaded (upload without registration)... so i get aaaaa lot of penis-trolls or whatever makes them post their private parts... anyhow...

i tried to train inception model with tensorflow (newest version 1.x) - so i made a   folder with ""penises"" (approx 160 pics) and one with different images with person how dont show their penis (approx 160 pics).... 

training accuracy is quit good -> over 90 % - but testing the model with other pictures - it fails really bad on detecting penises.... 

hmmmm, i know.. 160 pics are not that much for training, but i thing the problem is:

guy on the beach in shorts is: ok
guy on the beach with penis lurking out of his pants: is not okay.. 

but the difference is quite small between the pictures... because a penis is (mostly) quite a small part of the human body ... so hard to detect... 

anybody could help? and no, its sounds funny, buts no joke.. i suffering under all the uploads i have to review manualy.... it's really not funny to see over 1000 penises a day :(


cheers, puck"
11144,MultiRNNCell cannot stack PhasedLSTMCell,"### System information
 **TensorFlow version (use command below)**: 1.2

### Describe the problem
tf.contrib.rnn.PhasedLSTMCell takes a tuple of tensors as inputs (time and features).

but the tf.nn.rnn_cell.MultiRNNCell reuse the output of a cell to feed the next one:

`cur_inp, new_state = cell(cur_inp, cur_state)`

### Source code / logs

Something like that works.

[https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/python/ops/rnn_cell_impl.py](https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/python/ops/rnn_cell_impl.py)

```
902c902,903
<     cur_inp = inputs
---
>     times = inputs[0]
>     cur_inp = inputs[1]
916c917
<         cur_inp, new_state = cell(cur_inp, cur_state)
---
>         cur_inp, new_state = cell((times, cur_inp), cur_state)
```

Not sure whether it is a bug report or a feature request (for a dedicated MultiPhasedLSTMCell) though..."
11143,Parameter server of distributed Tensorflow computes unexpected training operations when using Estimator,"Hi, I am trying to use multi GPUs for the Google's seq2seq training (https://github.com/google/seq2seq) through distributed Tensorflow (data parallelism). 

I launched a parameter server (PS) and three worker processes on a machine equipped with 4 GPUs. 
I have each process (including PS) to run on separate GPU through the CUDA_VISIBLE_DEVICES. 
I successfully trained the model faster than the single-node version; however, I noticed a weird behavior. 

The way of enabling data parallelism was to set the ClusterConfig like below:  
`# ps_hosts, worker_hosts, job_name, and task_index are given as program arguments`
`ps_hosts = FLAGS.ps_hosts.split("","")`
`worker_hosts = FLAGS.worker_hosts.split("","")`
`cluster = {""ps"": ps_hosts, ""worker"": worker_hosts}`
`os.environ['TF_CONFIG'] = json.dumps({`
`    'cluster': cluster,`
`    'task': {`
`        'type': FLAGS.job_name,`
`        'index': FLAGS.task_index`
`    }`
`})`
`config = run_config.RunConfig( ..... ) `
`estimator = tf.contrib.learn.Estimator(....., config=config)`
`experiment = tf.contrib.learn.Experiment(estimator=estimator, .....)
learn_runner.run(experiment=experiment, .....)`

I profiled the training of this machine using nvprof and noticed that the parameter server process also uses its GPU for training. I looked into the device placement log messages and there is no MatMul ops associated with the /job:ps but for some reason, GPU calls many gemm calls. 

I think this issue is not specific to GPU because I also ran the same experiment with PS mapped to CPU but the PS also computes training operations. 

Is there anybody else who has experienced this? Is this the Estimator's bug? 
[_get_replica_device_setter](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/estimators/estimator.py#L201) seems to pass /job:ps/task:%d as worker_device and maybe this makes this problem? 

I also thought about the possibility that I did something wrong in deploying distributed Tensorflow but as mentioned earlier, the model is trained successfully with higher performance so I am confused if this is a bug or a feature. 

I would really appreciate any feedback/comments/help. Please let me know if I am misunderstanding anything.  

"
11142,Quantization causes some operations to be missing in the graph?,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: 1.2.1
- **Bazel version (if compiling from source)**: 5.4
- **CUDA/cuDNN version**: 8.0.61, 5.1
- **GPU model and memory**: Titan X Pascal

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
I am currently trying to evaluate the performance of a quantized imagenet pretrained models based on what is available from TF-slim. For my inception models, the quantization works ok (except that if we use quantize_nodes, the performance becomes 20x worse and accuracy drops. Totally the opposite of what we want). However, for the resnet and VGG architectures, it gave me this error:

```
Traceback (most recent call last):
  File ""evaluate_from_pb.py"", line 82, in <module>
    tf.import_graph_def(graph_def)
  File ""/home/kwotsin/.local/lib/python2.7/site-packages/tensorflow/python/framework/importer.py"", line 331, in import_graph_def
    op_to_bind_to, node.name))
ValueError: Specified colocation to an op that does not exist during import: ToFloat_2 in cond/truediv/Switch

```

Which I did not encounter when evaluating my quantized inception models. I am suspecting this might be due to a conversion error during quantization that does not work for some operations that are contained within the VGG_16 and resnet_v1_50 architectures, as defined here:

VGG_16: https://github.com/tensorflow/models/blob/master/slim/nets/vgg.py#L131
Resnet_v1_50: https://github.com/tensorflow/models/blob/master/slim/nets/resnet_v1.py#L241

Yet, due to the limited error traceback produced, I can't seem to identify what went wrong. Because the op name is very strange - something I never named or seen in the model's definition, I suspect it is a quantization op. I don't really know how to reproduce or find this op if I cannot import my graph_def to analyze the graph variables at all.

Thank you.

"
11141,Error while executing the imagenet_train model,"# bazel-bin/inception/imagenet_train --num_gpus=4 --batch_size=256 --train_dir=/tmp --data_dir=/root/kits/dataset
Traceback (most recent call last):
  File ""/root/models/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/imagenet_train.py"", line 41, in <module>
    tf.app.run()
  File ""/root/anaconda2/envs/tensor/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""/root/models/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/imagenet_train.py"", line 37, in main
    inception_train.train(dataset)
  File ""/root/models/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/inception_train.py"", line 217, in train
    num_preprocess_threads=num_preprocess_threads)
  File ""/root/models/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/image_processing.py"", line 136, in distorted_inputs
    num_readers=FLAGS.num_readers)
  File ""/root/models/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/image_processing.py"", line 490, in batch_inputs
    example_serialized)
  File ""/root/models/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/image_processing.py"", line 397, in parse_example_proto
    bbox = tf.concat(0, [ymin, xmin, ymax, xmax])
  File ""/root/anaconda2/envs/tensor/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py"", line 1029, in concat
    dtype=dtypes.int32).get_shape(
  File ""/root/anaconda2/envs/tensor/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 639, in convert_to_tensor
    as_ref=False)
  File ""/root/anaconda2/envs/tensor/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 704, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/root/anaconda2/envs/tensor/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py"", line 113, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/root/anaconda2/envs/tensor/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py"", line 102, in constant
    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))
  File ""/root/anaconda2/envs/tensor/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py"", line 370, in make_tensor_proto
    _AssertCompatible(values, dtype)
  File ""/root/anaconda2/envs/tensor/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py"", line 302, in _AssertCompatible
    (dtype.name, repr(mismatch), type(mismatch).__name__))
TypeError: Expected int32, got list containing Tensors of type '_Message' instead.

Using Tensorflow 1.1 inside Anaconda
Python version 3.6.1
Machine - Power 8
OS - Ubuntu 16.04

**Can someone tell me why am I getting this error?**"
11139,No module named '_pywrap_tensorflow_internal',"---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
D:\Users\laiyi\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py in swig_import_helper()
     17         try:
---> 18             return importlib.import_module(mname)
     19         except ImportError:

D:\Users\laiyi\Anaconda3\lib\importlib\__init__.py in import_module(name, package)
    125             level += 1
--> 126     return _bootstrap._gcd_import(name[level:], package, level)
    127

D:\Users\laiyi\Anaconda3\lib\importlib\_bootstrap.py in _gcd_import(name, package, level)

D:\Users\laiyi\Anaconda3\lib\importlib\_bootstrap.py in _find_and_load(name, import_)

D:\Users\laiyi\Anaconda3\lib\importlib\_bootstrap.py in _find_and_load_unlocked(name, import_)

D:\Users\laiyi\Anaconda3\lib\importlib\_bootstrap.py in _load_unlocked(spec)

D:\Users\laiyi\Anaconda3\lib\importlib\_bootstrap.py in module_from_spec(spec)

D:\Users\laiyi\Anaconda3\lib\importlib\_bootstrap_external.py in create_module(self, spec)

D:\Users\laiyi\Anaconda3\lib\importlib\_bootstrap.py in _call_with_frames_removed(f, *args, **kwds)

ImportError: DLL load failed: 找不到指定的模块。

During handling of the above exception, another exception occurred:

ModuleNotFoundError                       Traceback (most recent call last)
D:\Users\laiyi\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py in <module>()
     40     sys.setdlopenflags(_default_dlopen_flags | ctypes.RTLD_GLOBAL)
---> 41   from tensorflow.python.pywrap_tensorflow_internal import *
     42   from tensorflow.python.pywrap_tensorflow_internal import __version__

D:\Users\laiyi\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py in <module>()
     20             return importlib.import_module('_pywrap_tensorflow_internal')
---> 21     _pywrap_tensorflow_internal = swig_import_helper()
     22     del swig_import_helper

D:\Users\laiyi\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py in swig_import_helper()
     19         except ImportError:
---> 20             return importlib.import_module('_pywrap_tensorflow_internal')
     21     _pywrap_tensorflow_internal = swig_import_helper()

D:\Users\laiyi\Anaconda3\lib\importlib\__init__.py in import_module(name, package)
    125             level += 1
--> 126     return _bootstrap._gcd_import(name[level:], package, level)
    127

ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

ImportError                               Traceback (most recent call last)
<ipython-input-1-a649b509054f> in <module>()
----> 1 import tensorflow

D:\Users\laiyi\Anaconda3\lib\site-packages\tensorflow\__init__.py in <module>()
     22
     23 # pylint: disable=wildcard-import
---> 24 from tensorflow.python import *
     25 # pylint: enable=wildcard-import
     26

D:\Users\laiyi\Anaconda3\lib\site-packages\tensorflow\python\__init__.py in <module>()
     47 import numpy as np
     48
---> 49 from tensorflow.python import pywrap_tensorflow
     50
     51 # Protocol buffers

D:\Users\laiyi\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py in <module>()
     50 for some common reasons and solutions.  Include the entire stack trace
     51 above this error message when asking for help."""""" % traceback.format_exc()
---> 52   raise ImportError(msg)
     53
     54 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long

ImportError: Traceback (most recent call last):
  File ""D:\Users\laiyi\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    return importlib.import_module(mname)
  File ""D:\Users\laiyi\Anaconda3\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 978, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 961, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 950, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 648, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 560, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 922, in create_module
  File ""<frozen importlib._bootstrap>"", line 205, in _call_with_frames_removed
ImportError: DLL load failed: 找不到指定的模块。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""D:\Users\laiyi\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""D:\Users\laiyi\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 21, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""D:\Users\laiyi\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""D:\Users\laiyi\Anaconda3\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help."
11138,Hang when fitting tensorflow learn model which contains crossed sparse_column_with_* columns and the data is loaded with pandas_input_fn,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Run on Databricks GPU cluster (Ubuntu 16.04.1 LTS)
- **TensorFlow installed from (source or binary)**: pip installed tensorflow-gpu
- **TensorFlow version (use command below)**: v1.2.0-rc2-21-g12f033d 1.2.0
- **Bazel version (if compiling from source)**: n/a
- **CUDA/cuDNN version**: CUDA: Version 8.0, cuDNN: Version 5.1 for CUDA 8.0
- **GPU model and memory**:
- **Exact command to reproduce**:

### Describe the problem

When building Linear models with the tensorflow learn libraries the program hangs if the pandas input function (tensorflow.estimator.inputs.pandas_input_fn) is used and a crossed_column (tensorflow.contrib.layers.crossed_column) is constructed from a sparse_column_with_\*. This issue is not seen in the tensorflow tutorials as they use constant tensor's to input the data which does not scale to large datasets. This also only occurs if crossing sparse_column_with_\* columns, bucketized continuous columns do not cause a hang.

The final line of output before the code hangs is: `INFO:tensorflow:Create CheckpointSaverHook.`

### Source code / logs

Minimum working example of bug (with example of code that works and code that breaks):

```python
import pandas as pd
import tensorflow as tf

# Some sample data
df = pd.DataFrame({'label' : [0,1,1,0], 'con1' : [10,20,30,40], 'con2' : [1,4,9,16], 'cat1' : ['a','a','b','b'], 'cat2' : ['c','d','c','d']})

# Sparse base columns
from tensorflow.contrib.layers import sparse_column_with_keys, sparse_column_with_hash_bucket
sparse_cat1 = sparse_column_with_keys('cat1', keys=['a','b'])
sparse_cat2 = sparse_column_with_hash_bucket('cat2', hash_bucket_size=10)

# Bucketised columns
from tensorflow.contrib.layers import real_valued_column, bucketized_column
bucket_con1 = bucketized_column(real_valued_column('con1'), boundaries=[5,15,25,35])
bucket_con2 = bucketized_column(real_valued_column('con2'), boundaries=[5,15,25,35])

# Crossed columns
from tensorflow.contrib.layers import crossed_column
# This works with both inputs:
cross_bb = crossed_column([bucket_con1, bucket_con2], hash_bucket_size=100)
# Both these hang with pandas input:
cross_cc = crossed_column([sparse_cat1, sparse_cat2], hash_bucket_size=100)
cross_bc = crossed_column([bucket_con1, sparse_cat1], hash_bucket_size=100)

feature_columns = [sparse_cat1, sparse_cat2, cross_bb, cross_cc, cross_bc]
model = tf.contrib.learn.LinearClassifier(feature_columns=feature_columns)

# Use pandas input - doesn't work
train_gen_fun = tf.estimator.inputs.pandas_input_fn(df, batch_size=len(df), num_epochs=None, shuffle=True)
# Split out the label from the features
def input_fn1(gen) :
  features = gen()
  target = features.pop('label')
  return features, target

# Use constant input - does work
def input_fn2(df):
  feature_cols = {
    'con1' : tf.constant(df['con1'].values),
    'con2' : tf.constant(df['con2'].values),
    'cat1' : tf.SparseTensor(indices=[[i, 0] for i in range(df['cat1'].size)],
                             values=df['cat1'].values, dense_shape=[df['cat1'].size, 1]),
    'cat2' : tf.SparseTensor(indices=[[i, 0] for i in range(df['cat2'].size)],
                             values=df['cat2'].values, dense_shape=[df['cat2'].size, 1]),
  }
  label = tf.constant(df['label'].values)
  return feature_cols, label

# This hangs
model.fit(input_fn=lambda:input_fn1(train_gen_fun), steps=10)

# This works
model.fit(input_fn=lambda:input_fn2(df), steps=10)
```
"
11137,wide_n_deep Tutorial example not working,"**cd** tensorflow/tensorflow/examples/learn/
**python** wide_n_deep_tutorial.py
## it shows that :
Traceback (most recent call last):
  File ""wide_n_deep_tutorial.py"", line 36, in <module>
    gender = tf.feature_column.categorical_column_with_vocabulary_list(
AttributeError: 'module' object has no attribute 'feature_column'
My tensorflow is '1.0.0-rc2', and do i need to upgrade?
thank you! "
11135,TF API r1.2 Keras TimeDistributed wrapper error,"
import tensorflow.contrib.keras as K
model = K.models.Sequential()
model.add(K.layers.LSTM(150, batch_input_shape=(batch_size, n_in, encoded_length), stateful=True))
model.add(K.layers.RepeatVector(n_out))
model.add(K.layers.LSTM(150, return_sequences=True, stateful=True))
model.add(K.layers.TimeDistributed(K.layers.Dense(encoded_length, activation='softmax')))
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])


AttributeError: module 'tensorflow.contrib.keras.api.keras.layers' has no attribute 'TimeDistributed'

Is there way to avoid that error?

System info:
---------
Windows 10
TensorFlow r1.2
Python 3.6
Miniconda3
------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
11134,"""ImportError: No module named '_pywrap_tensorflow'"" while trying to run TensorFlow","`Traceback (most recent call last):
  File ""c:\Python35-32\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 18, in swig_import_helper
    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])
  File ""c:\Python35-32\lib\imp.py"", line 296, in find_module
    raise ImportError(_ERR_MSG.format(name), name=name)
ImportError: No module named '_pywrap_tensorflow'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""c:\Python35-32\lib\site-packages\tensorflow\python\__init__.py"", line 54, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""c:\Python35-32\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 28, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""c:\Python35-32\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 20, in swig_import_helper
    import _pywrap_tensorflow
ImportError: No module named '_pywrap_tensorflow'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""c:\Python35-32\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""c:\Python35-32\lib\site-packages\tensorflow\python\__init__.py"", line 60, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""c:\Python35-32\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 18, in swig_import_helper
    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])
  File ""c:\Python35-32\lib\imp.py"", line 296, in find_module
    raise ImportError(_ERR_MSG.format(name), name=name)
ImportError: No module named '_pywrap_tensorflow'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""c:\Python35-32\lib\site-packages\tensorflow\python\__init__.py"", line 54, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""c:\Python35-32\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 28, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""c:\Python35-32\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 20, in swig_import_helper
    import _pywrap_tensorflow
ImportError: No module named '_pywrap_tensorflow'


Error importing tensorflow.  Unless you are using bazel,
you should not try to import tensorflow from its source directory;
please exit the tensorflow source tree, and relaunch your python interpreter
from there.`

**SYSTEM DETAILS:**
1. NVIDIA GeForce 920M
2. Cuda Toolkit 8.0
3.  cudNN 5.1 version
4.  Visual Studio 2015, also Visual Studio C++ Redistributable 2015
5. Windows 10"
11132,Go: SIGABRT when executing the same node more than once,"## Problem

In Go, when we pass the same node to the `fetches` list more then once SIGABRT is raised.

### Source code / logs

```go
package poc_test

import (
        ""fmt""
        tf ""github.com/tensorflow/tensorflow/tensorflow/go""
        ""github.com/tensorflow/tensorflow/tensorflow/go/op""
        ""testing""
)

func TestFunc(t *testing.T) {
        // Create root scope
        root := op.NewScope()

        // Define graph

        // Create a constant matrix
        A := op.Const(root.SubScope(""A""), [2][2]int32{{1, 2}, {-1, -2}})
        // Create a constant column vector
        b := op.Const(root.SubScope(""b""), [2][1]int32{{10}, {100}})
        // Create a matmul operation
        mul := op.MatMul(root.SubScope(""MatMul""), A, b)

        // Finalize the graph
        graph, _ := root.Finalize()

        // Create the session
        var sess *tf.Session
        sess, _ = tf.NewSession(graph, &tf.SessionOptions{})
        // Run
        var results []*tf.Tensor
        var err error
        if results, err = sess.Run(nil, []tf.Output{mul, mul}, nil); err != nil {
                t.Errorf(err.Error())
        }
        fmt.Println(results[0].Value())
}
```

Here's the output:

```out
go test poc_test.go 
2017-06-29 10:46:09.154744: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-06-29 10:46:09.155330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:938] Found device 0 with properties: 
name: GeForce GTX 1080 Ti
major: 6 minor: 1 memoryClockRate (GHz) 1.582
pciBusID 0000:03:00.0
Total memory: 10.91GiB
Free memory: 249.38MiB
2017-06-29 10:46:09.267778: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x1f22910 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-06-29 10:46:09.268001: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-06-29 10:46:09.268357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:938] Found device 1 with properties: 
name: GeForce GTX 1060 6GB
major: 6 minor: 1 memoryClockRate (GHz) 1.7845
pciBusID 0000:01:00.0
Total memory: 5.93GiB
Free memory: 5.34GiB
2017-06-29 10:46:09.268390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:830] Peer access not supported between device ordinals 0 and 1
2017-06-29 10:46:09.268399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:830] Peer access not supported between device ordinals 1 and 0
2017-06-29 10:46:09.268409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:959] DMA: 0 1 
2017-06-29 10:46:09.268415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:969] 0:   Y N 
2017-06-29 10:46:09.268421: I tensorflow/core/common_runtime/gpu/gpu_device.cc:969] 1:   N Y 
2017-06-29 10:46:09.268433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1028] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:03:00.0)
2017-06-29 10:46:09.268440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1028] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0)
2017-06-29 10:46:09.290295: F tensorflow/c/c_api.cc:488] Check failed: nelems == 0 (2 vs. 0)
SIGABRT: abort
PC=0x7fa8684dc670 m=0 sigcode=18446744073709551610
signal arrived during cgo execution

goroutine 5 [syscall, locked to thread]:
runtime.cgocall(0x50d580, 0xc420043d68, 0x530100)
        /usr/lib/go/src/runtime/cgocall.go:131 +0xe2 fp=0xc420043d20 sp=0xc420043ce0
github.com/tensorflow/tensorflow/tensorflow/go._Cfunc_TF_SessionRun(0x2beb8a0, 0x0, 0x0, 0x0, 0x0, 0xc42000ce40, 0xc420011040, 0xc400000002, 0x0, 0x0, ...)
        github.com/tensorflow/tensorflow/tensorflow/go/_obj/_cgo_gotypes.go:703 +0x45 fp=0xc420043d68 sp=0xc420043d20
github.com/tensorflow/tensorflow/tensorflow/go.(*Session).Run.func1(0x2beb8a0, 0x0, 0x0, 0x0, 0x0, 0xc42000ce40, 0xc420011040, 0xc400000002, 0x0, 0x0, ...)
        /home/pgaleone/projects/go/src/github.com/tensorflow/tensorflow/tensorflow/go/session.go:87 +0x23a fp=0xc420043dd8 sp=0xc420043d68
github.com/tensorflow/tensorflow/tensorflow/go.(*Session).Run(0xc42000ce20, 0x0, 0xc420043f50, 0x2, 0x2, 0x0, 0x0, 0x0, 0x0, 0x0, ...)
        /home/pgaleone/projects/go/src/github.com/tensorflow/tensorflow/tensorflow/go/session.go:91 +0x243 fp=0xc420043e70 sp=0xc420043dd8
command-line-arguments_test.TestFunc(0xc4200665b0)
        /home/pgaleone/projects/go/src/github.com/galeone/asd/poc_test.go:32 +0x35d fp=0xc420043fa8 sp=0xc420043e70
testing.tRunner(0xc4200665b0, 0x562278)
        /usr/lib/go/src/testing/testing.go:657 +0x96 fp=0xc420043fd0 sp=0xc420043fa8
runtime.goexit()
        /usr/lib/go/src/runtime/asm_amd64.s:2197 +0x1 fp=0xc420043fd8 sp=0xc420043fd0
created by testing.(*T).Run
        /usr/lib/go/src/testing/testing.go:697 +0x2ca

goroutine 1 [chan receive]:
testing.(*T).Run(0xc4200664e0, 0x559659, 0x8, 0x562278, 0xc420053d20)
        /usr/lib/go/src/testing/testing.go:698 +0x2f4
testing.runTests.func1(0xc4200664e0)
        /usr/lib/go/src/testing/testing.go:882 +0x67
testing.tRunner(0xc4200664e0, 0xc420053de0)
        /usr/lib/go/src/testing/testing.go:657 +0x96
testing.runTests(0xc42000cd80, 0x7ecf80, 0x1, 0x1, 0x4131ac)
        /usr/lib/go/src/testing/testing.go:888 +0x2c1
testing.(*M).Run(0xc420053f20, 0xc420053f20)
        /usr/lib/go/src/testing/testing.go:822 +0xfc
main.main()
        command-line-arguments/_test/_testmain.go:42 +0xf7

goroutine 17 [syscall, locked to thread]:
runtime.goexit()
        /usr/lib/go/src/runtime/asm_amd64.s:2197 +0x1

rax    0x0
rbx    0x6
rcx    0x7fa8684dc670
rdx    0x0
rdi    0x2
rsi    0x7ffe4515bf50
rbp    0x7ffe4515c1a0
rsp    0x7ffe4515bf50
r8     0x0
r9     0x7ffe4515bf50
r10    0x8
r11    0x246
r12    0x2
r13    0x2
r14    0x2bf8160
r15    0x20
rip    0x7fa8684dc670
rflags 0x246
cs     0x33
fs     0x0
gs     0x0
FAIL    command-line-arguments  0.544s
```

The same logic,  in python, works without any issue:

```python
import tensorflow as tf

A = tf.constant([[1,2], [-1, -2]])
b = tf.constant([[10], [100]])

mul = tf.matmul(A, b)

with tf.Session() as sess:
    print(sess.run([mul, mul]))

```
outputs
```out
[array([[ 210],
       [-210]], dtype=int32), array([[ 210],
       [-210]], dtype=int32)]
```

as expected.

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Archlinux
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.2.0
- **Bazel version (if compiling from source)**: 0.5.1
- **CUDA/cuDNN version**: cuda 8, cudnn 5.1
- **GPU model and memory**:  GeForce GTX 1080
- **Exact command to reproduce**: `go test`
"
11131,how use tensorflow model in optimization model,"hi
i know how to save, restore and feed a tensorflow model but how can i use tf model in optimization model (like the genetic algorithm, python deep package). my problem is in transforming (convert) tf value to python. if I want to use

`python_variable=sess.run(tf_variable)`

or

`python_variable=tf_variable.eval()`

for each population (genetic run) I should initialize sess and .... this process is very time-consuming. what is the solution?
is there any better solution or tensorflow have any optimization algorithm?"
11127,tf.contrib.keras modules can't Open HDFS file,"- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:CentOS 7
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.1.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:5.1.10

I use keras.preprocessing.image.ImageDataGenerator class,I invoke flow_from_directory function,when train_data_dir is a HDFS directory. the script throw exception. I refer the source code.I found the  ImageDataGenerator class not use GFile class to open path.
So,it's possible to use GFile to open file in tf.contrib.keras modules?
"
11126,ios compile failed : checking whether the C compiler works... no,"



pls help..




my config.log file:


This file contains any messages produced by compilers while
running configure, to aid debugging if configure makes a mistake.

It was created by Protocol Buffers configure 3.2.0, which was
generated by GNU Autoconf 2.69.  Invocation command line was

  $ ./configure --host=i386-apple-darwin14.0.0 --disable-shared --enable-cross-compile --with-protoc=/Users/jakie/tensorflow-master/tensorflow/contrib/makefile/gen/protobuf-host/bin/protoc --prefix=/Users/jakie/tensorflow-master/tensorflow/contrib/makefile/gen/protobuf_ios/lib/iossim_386 --exec-prefix=/Users/jakie/tensorflow-master/tensorflow/contrib/makefile/gen/protobuf_ios/lib/iossim_386 CFLAGS=-DNDEBUG -Os -pipe -fPIC -fno-exceptions -mios-simulator-version-min=8.0 -arch i386 -fembed-bitcode -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator8.4.sdk CXX= CXXFLAGS=-DNDEBUG -Os -pipe -fPIC -fno-exceptions -std=c++11 -stdlib=libc++ -mios-simulator-version-min=8.0 -arch i386 -fembed-bitcode -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator8.4.sdk LDFLAGS=-arch i386 -fembed-bitcode -mios-simulator-version-min=8.0 -stdlib=libc++ -L/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator8.4.sdk/usr/lib/ -L/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator8.4.sdk/usr/lib/system LIBS=-lc++ -lc++abi

## --------- ##
## Platform. ##
## --------- ##

hostname = jakiedeMac.local
uname -m = x86_64
uname -r = 14.0.0
uname -s = Darwin
uname -v = Darwin Kernel Version 14.0.0: Fri Sep 19 00:26:44 PDT 2014; root:xnu-2782.1.97~2/RELEASE_X86_64

/usr/bin/uname -p = i386
/bin/uname -X     = unknown

/bin/arch              = unknown
/usr/bin/arch -k       = unknown
/usr/convex/getsysinfo = unknown
/usr/bin/hostinfo      = Mach kernel version:
	 Darwin Kernel Version 14.0.0: Fri Sep 19 00:26:44 PDT 2014; root:xnu-2782.1.97~2/RELEASE_X86_64
Kernel configured for up to 4 processors.
4 processors are physically available.
4 processors are logically available.
Processor type: x86_64h (Intel x86-64h Haswell)
Processors active: 0 1 2 3
Primary memory available: 8.00 gigabytes
Default processor set: 102 tasks, 394 threads, 4 processors
Load average: 2.19, Mach factor: 1.88
/bin/machine           = unknown
/usr/bin/oslevel       = unknown
/bin/universe          = unknown

PATH: /usr/local/bin
PATH: /usr/bin
PATH: /bin
PATH: /usr/sbin
PATH: /sbin


## ----------- ##
## Core tests. ##
## ----------- ##

configure:2601: checking whether to enable maintainer-specific portions of Makefiles
configure:2610: result: yes
configure:2685: checking build system type
configure:2699: result: x86_64-apple-darwin14.0.0
configure:2719: checking host system type
configure:2732: result: i386-apple-darwin14.0.0
configure:2752: checking target system type
configure:2765: result: i386-apple-darwin14.0.0
configure:2808: checking for a BSD-compatible install
configure:2876: result: /usr/bin/install -c
configure:2887: checking whether build environment is sane
configure:2942: result: yes
configure:3001: checking for i386-apple-darwin14.0.0-strip
configure:3031: result: no
configure:3041: checking for strip
configure:3057: found /usr/bin/strip
configure:3068: result: strip
configure:3093: checking for a thread-safe mkdir -p
configure:3132: result: ./install-sh -c -d
configure:3139: checking for gawk
configure:3169: result: no
configure:3139: checking for mawk
configure:3169: result: no
configure:3139: checking for nawk
configure:3169: result: no
configure:3139: checking for awk
configure:3155: found /usr/bin/awk
configure:3166: result: awk
configure:3177: checking whether make sets $(MAKE)
configure:3199: result: yes
configure:3228: checking whether make supports nested variables
configure:3245: result: yes
configure:3334: checking whether UID '501' is supported by ustar format
configure:3337: result: yes
configure:3344: checking whether GID '20' is supported by ustar format
configure:3347: result: yes
configure:3355: checking how to create a ustar tar archive
configure:3366: tar --version
bsdtar 2.8.3 - libarchive 2.8.3
configure:3369: $? = 0
configure:3409: tardir=conftest.dir && eval tar --format=ustar -chf - ""$tardir"" >conftest.tar
configure:3412: $? = 0
configure:3416: tar -xf - <conftest.tar
configure:3419: $? = 0
configure:3421: cat conftest.dir/file
GrepMe
configure:3424: $? = 0
configure:3437: result: gnutar
configure:3515: checking for i386-apple-darwin14.0.0-gcc
configure:3545: result: no
configure:3555: checking for gcc
configure:3571: found /usr/bin/gcc
configure:3582: result: gcc
configure:3811: checking for C compiler version
configure:3820: gcc --version >&5
Apple LLVM version 6.1.0 (clang-602.0.53) (based on LLVM 3.6.0svn)
Target: x86_64-apple-darwin14.0.0
Thread model: posix
Configured with: --prefix=/Applications/Xcode.app/Contents/Developer/usr --with-gxx-include-dir=/usr/include/c++/4.2.1
configure:3831: $? = 0
configure:3820: gcc -v >&5
Configured with: --prefix=/Applications/Xcode.app/Contents/Developer/usr --with-gxx-include-dir=/usr/include/c++/4.2.1
Apple LLVM version 6.1.0 (clang-602.0.53) (based on LLVM 3.6.0svn)
Target: x86_64-apple-darwin14.0.0
Thread model: posix
configure:3831: $? = 0
configure:3820: gcc -V >&5
clang: error: argument to '-V' is missing (expected 1 value)
clang: error: no input files
configure:3831: $? = 1
configure:3820: gcc -qversion >&5
clang: error: unknown argument: '-qversion'
clang: error: no input files
configure:3831: $? = 1
configure:3851: checking whether the C compiler works
configure:3873: gcc -DNDEBUG -Os -pipe -fPIC -fno-exceptions -mios-simulator-version-min=8.0 -arch i386 -fembed-bitcode -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator8.4.sdk  -arch i386 -fembed-bitcode -mios-simulator-version-min=8.0 -stdlib=libc++ -L/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator8.4.sdk/usr/lib/ -L/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator8.4.sdk/usr/lib/system conftest.c -lc++ -lc++abi >&5
clang: error: unknown argument: '-fembed-bitcode'
clang: error: unknown argument: '-fembed-bitcode'
configure:3877: $? = 1
configure:3915: result: no
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Protocol Buffers""
| #define PACKAGE_TARNAME ""protobuf""
| #define PACKAGE_VERSION ""3.2.0""
| #define PACKAGE_STRING ""Protocol Buffers 3.2.0""
| #define PACKAGE_BUGREPORT ""protobuf@googlegroups.com""
| #define PACKAGE_URL """"
| #define PACKAGE ""protobuf""
| #define VERSION ""3.2.0""
| /* end confdefs.h.  */
| 
| int
| main ()
| {
| 
|   ;
|   return 0;
| }
configure:3920: error: in `/Users/jakie/tensorflow-master/tensorflow/contrib/makefile/downloads/protobuf':
configure:3922: error: C compiler cannot create executables
See `config.log' for more details

## ---------------- ##
## Cache variables. ##
## ---------------- ##

ac_cv_build=x86_64-apple-darwin14.0.0
ac_cv_env_CCC_set=
ac_cv_env_CCC_value=
ac_cv_env_CC_set=
ac_cv_env_CC_value=
ac_cv_env_CFLAGS_set=set
ac_cv_env_CFLAGS_value='-DNDEBUG -Os -pipe -fPIC -fno-exceptions -mios-simulator-version-min=8.0 -arch i386 -fembed-bitcode -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator8.4.sdk'
ac_cv_env_CPPFLAGS_set=
ac_cv_env_CPPFLAGS_value=
ac_cv_env_CPP_set=
ac_cv_env_CPP_value=
ac_cv_env_CXXCPP_set=
ac_cv_env_CXXCPP_value=
ac_cv_env_CXXFLAGS_set=set
ac_cv_env_CXXFLAGS_value='-DNDEBUG -Os -pipe -fPIC -fno-exceptions -std=c++11 -stdlib=libc++ -mios-simulator-version-min=8.0 -arch i386 -fembed-bitcode -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator8.4.sdk'
ac_cv_env_CXX_set=set
ac_cv_env_CXX_value=
ac_cv_env_DIST_LANG_set=
ac_cv_env_DIST_LANG_value=
ac_cv_env_LDFLAGS_set=set
ac_cv_env_LDFLAGS_value='-arch i386 -fembed-bitcode -mios-simulator-version-min=8.0 -stdlib=libc++ -L/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator8.4.sdk/usr/lib/ -L/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator8.4.sdk/usr/lib/system'
ac_cv_env_LIBS_set=set
ac_cv_env_LIBS_value='-lc++ -lc++abi'
ac_cv_env_LT_SYS_LIBRARY_PATH_set=
ac_cv_env_LT_SYS_LIBRARY_PATH_value=
ac_cv_env_OBJCFLAGS_set=
ac_cv_env_OBJCFLAGS_value=
ac_cv_env_OBJC_set=
ac_cv_env_OBJC_value=
ac_cv_env_build_alias_set=
ac_cv_env_build_alias_value=
ac_cv_env_host_alias_set=set
ac_cv_env_host_alias_value=i386-apple-darwin14.0.0
ac_cv_env_target_alias_set=
ac_cv_env_target_alias_value=
ac_cv_host=i386-apple-darwin14.0.0
ac_cv_path_install='/usr/bin/install -c'
ac_cv_prog_AWK=awk
ac_cv_prog_ac_ct_CC=gcc
ac_cv_prog_ac_ct_STRIP=strip
ac_cv_prog_make_make_set=yes
ac_cv_target=i386-apple-darwin14.0.0
am_cv_make_support_nested_variables=yes
am_cv_prog_tar_ustar=gnutar

## ----------------- ##
## Output variables. ##
## ----------------- ##

ACLOCAL='${SHELL} /Users/jakie/tensorflow-master/tensorflow/contrib/makefile/downloads/protobuf/missing aclocal-1.15'
AMDEPBACKSLASH=''
AMDEP_FALSE=''
AMDEP_TRUE=''
AMTAR='$${TAR-tar}'
AM_BACKSLASH='\'
AM_DEFAULT_V='$(AM_DEFAULT_VERBOSITY)'
AM_DEFAULT_VERBOSITY='1'
AM_V='$(V)'
AR=''
AUTOCONF='${SHELL} /Users/jakie/tensorflow-master/tensorflow/contrib/makefile/downloads/protobuf/missing autoconf'
AUTOHEADER='${SHELL} /Users/jakie/tensorflow-master/tensorflow/contrib/makefile/downloads/protobuf/missing autoheader'
AUTOMAKE='${SHELL} /Users/jakie/tensorflow-master/tensorflow/contrib/makefile/downloads/protobuf/missing automake-1.15'
AWK='awk'
BUILD_EXEEXT=''
BUILD_OBJEXT=''
CC='gcc'
CCDEPMODE=''
CC_FOR_BUILD=''
CFLAGS='-DNDEBUG -Os -pipe -fPIC -fno-exceptions -mios-simulator-version-min=8.0 -arch i386 -fembed-bitcode -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator8.4.sdk'
CFLAGS_FOR_BUILD=''
CPP=''
CPPFLAGS=''
CPPFLAGS_FOR_BUILD=''
CPP_FOR_BUILD=''
CXX=''
CXXCPP=''
CXXCPPFLAGS_FOR_BUILD=''
CXXCPP_FOR_BUILD=''
CXXDEPMODE=''
CXXFLAGS='-DNDEBUG -Os -pipe -fPIC -fno-exceptions -std=c++11 -stdlib=libc++ -mios-simulator-version-min=8.0 -arch i386 -fembed-bitcode -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator8.4.sdk'
CXXFLAGS_FOR_BUILD=''
CXX_FOR_BUILD=''
CYGPATH_W='echo'
DEFS=''
DEPDIR=''
DIST_LANG='all'
DLLTOOL=''
DSYMUTIL=''
DUMPBIN=''
ECHO_C='\c'
ECHO_N=''
ECHO_T=''
EGREP=''
EXEEXT=''
FGREP=''
GCC_FALSE=''
GCC_TRUE=''
GREP=''
HAVE_CXX11=''
HAVE_PTHREAD_FALSE=''
HAVE_PTHREAD_TRUE=''
HAVE_ZLIB_FALSE=''
HAVE_ZLIB_TRUE=''
INSTALL_DATA='${INSTALL} -m 644'
INSTALL_PROGRAM='${INSTALL}'
INSTALL_SCRIPT='${INSTALL}'
INSTALL_STRIP_PROGRAM='$(install_sh) -c -s'
ISAINFO=''
LD=''
LDFLAGS='-arch i386 -fembed-bitcode -mios-simulator-version-min=8.0 -stdlib=libc++ -L/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator8.4.sdk/usr/lib/ -L/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator8.4.sdk/usr/lib/system'
LDFLAGS_FOR_BUILD=''
LIBOBJS=''
LIBS='-lc++ -lc++abi'
LIBTOOL=''
LIPO=''
LN_S=''
LTLIBOBJS=''
LT_SYS_LIBRARY_PATH=''
MAINT=''
MAINTAINER_MODE_FALSE='#'
MAINTAINER_MODE_TRUE=''
MAKEINFO='${SHELL} /Users/jakie/tensorflow-master/tensorflow/contrib/makefile/downloads/protobuf/missing makeinfo'
MANIFEST_TOOL=''
MKDIR_P='./install-sh -c -d'
NM=''
NMEDIT=''
OBJC=''
OBJCDEPMODE=''
OBJCFLAGS=''
OBJC_CONFORMANCE_TEST_FALSE=''
OBJC_CONFORMANCE_TEST_TRUE=''
OBJDUMP=''
OBJEXT=''
OTOOL64=''
OTOOL=''
PACKAGE='protobuf'
PACKAGE_BUGREPORT='protobuf@googlegroups.com'
PACKAGE_NAME='Protocol Buffers'
PACKAGE_STRING='Protocol Buffers 3.2.0'
PACKAGE_TARNAME='protobuf'
PACKAGE_URL=''
PACKAGE_VERSION='3.2.0'
PATH_SEPARATOR=':'
POW_LIB=''
PROTOBUF_OPT_FLAG=''
PROTOC=''
PTHREAD_CC=''
PTHREAD_CFLAGS=''
PTHREAD_LIBS=''
RANLIB=''
SED=''
SET_MAKE=''
SHELL='/bin/sh'
STRIP='strip'
USE_EXTERNAL_PROTOC_FALSE=''
USE_EXTERNAL_PROTOC_TRUE=''
VERSION='3.2.0'
ac_ct_AR=''
ac_ct_CC='gcc'
ac_ct_CC_FOR_BUILD=''
ac_ct_CXX=''
ac_ct_CXX_FOR_BUILD=''
ac_ct_DUMPBIN=''
ac_ct_OBJC=''
acx_pthread_config=''
am__EXEEXT_FALSE=''
am__EXEEXT_TRUE=''
am__fastdepCC_FALSE=''
am__fastdepCC_TRUE=''
am__fastdepCXX_FALSE=''
am__fastdepCXX_TRUE=''
am__fastdepOBJC_FALSE=''
am__fastdepOBJC_TRUE=''
am__include=''
am__isrc=''
am__leading_dot='.'
am__nodep=''
am__quote=''
am__tar='tar --format=ustar -chf - ""$$tardir""'
am__untar='tar -xf -'
bindir='${exec_prefix}/bin'
build='x86_64-apple-darwin14.0.0'
build_alias=''
build_cpu='x86_64'
build_os='darwin14.0.0'
build_vendor='apple'
datadir='${datarootdir}'
datarootdir='${prefix}/share'
docdir='${datarootdir}/doc/${PACKAGE_TARNAME}'
dvidir='${docdir}'
exec_prefix='/Users/jakie/tensorflow-master/tensorflow/contrib/makefile/gen/protobuf_ios/lib/iossim_386'
host='i386-apple-darwin14.0.0'
host_alias='i386-apple-darwin14.0.0'
host_cpu='i386'
host_os='darwin14.0.0'
host_vendor='apple'
htmldir='${docdir}'
includedir='${prefix}/include'
infodir='${datarootdir}/info'
install_sh='${SHELL} /Users/jakie/tensorflow-master/tensorflow/contrib/makefile/downloads/protobuf/install-sh'
libdir='${exec_prefix}/lib'
libexecdir='${exec_prefix}/libexec'
localedir='${datarootdir}/locale'
localstatedir='${prefix}/var'
mandir='${datarootdir}/man'
mkdir_p='$(MKDIR_P)'
oldincludedir='/usr/include'
pdfdir='${docdir}'
prefix='/Users/jakie/tensorflow-master/tensorflow/contrib/makefile/gen/protobuf_ios/lib/iossim_386'
program_transform_name='s,x,x,'
psdir='${docdir}'
sbindir='${exec_prefix}/sbin'
sharedstatedir='${prefix}/com'
subdirs=''
sysconfdir='${prefix}/etc'
target='i386-apple-darwin14.0.0'
target_alias=''
target_cpu='i386'
target_os='darwin14.0.0'
target_vendor='apple'

## ----------- ##
## confdefs.h. ##
## ----------- ##

/* confdefs.h */
#define PACKAGE_NAME ""Protocol Buffers""
#define PACKAGE_TARNAME ""protobuf""
#define PACKAGE_VERSION ""3.2.0""
#define PACKAGE_STRING ""Protocol Buffers 3.2.0""
#define PACKAGE_BUGREPORT ""protobuf@googlegroups.com""
#define PACKAGE_URL """"
#define PACKAGE ""protobuf""
#define VERSION ""3.2.0""

configure: exit 77
"
11124,[iOS] Bug: No OpKernel was registered to support Op 'LessEqual',"### System information
Running OS `macOS Sierra` building for `iOS` specifically.
```
$ gcc --version
Apple LLVM version 8.1.0 (clang-802.0.42)
Target: x86_64-apple-darwin16.0.0
```

TensorFlow version `1.2.0`, installed through `pip`.

### Describe the problem

### Case: Build From Source (1.2.0)
Clone the tensorflow repository and build for `iOS`

```sh
cd tensorflow
sh tensorflow/contrib/makefile/build_all_ios.sh
```

Installs with no problem. Follow the [iOS example](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/ios#creating-your-own-app-from-your-source-libraries).

### Case: Pod Install (1.1)
Use `CocoaPods`

```sh
pod install TensorFlow-experimental
```

### Status Not `ok`
For both of the cases, the status from loading and creating session from a frozen graph (binary proto- file) is not `ok` when using `LessEqual` op in a `seq2seq` based model.

**Note**: This example runs without any problems on the `python` (`pip install tensorflow`) distribution.

### Source code / logs
This error occurs when loading from a `.pb` context:

```obj-c
// ...else-where
// ReadBinaryProto(tensorflow::Env::Default(), path.fileSystemRepresentation, &graph)
// ...
status = session->Create(graph);
if (!status.ok()) {
  RCTLogInfo(@""Error adding graph to session: %s"", status.error_message().c_str());
  return false;
}
```

Issue is logged here:
```
No OpKernel was registered to support Op 'LessEqual' with these attrs.  Registered devices: [CPU], Registered kernels:
  <no registered kernels>

	 [[Node: decode/decoder_1/LessEqual = LessEqual[T=DT_INT32](max_target_len, decode/decoder_1/LessEqual/y)]]
```

Checked `tf_op_files.txt` and saw that `LessEqual` op was not included:
```diff
tensorflow/core/kernels/cwise_op_less.cc
+tensorflow/core/kernels/cwise_op_less_equal.cc
tensorflow/core/kernels/cwise_op_isfinite.cc
```

Maybe this has something to do with it?

**Update** it seems that this did have something to do with it.

I rebuilt after adding `/cwise_op_less_equal.cc` to `tf_op_files.txt`:
```sh
$ tensorflow/contrib/makefile/build_all_ios.sh 
```

I re-froze the graph:
```sh
$ python ../tensorflow/tensorflow/python/tools/freeze_graph.py \
--input_graph=./pb/input_graph.pb --input_checkpoint=./save/model \
--output_node_names=predictions --input_binary \
--output_graph=./tmp/frozen.pb
```

Then optimized...
```sh
$ python ../tensorflow/tensorflow/python/tools/optimize_for_inference.py \
--input=./tmp/frozen.pb --output=./tmp/inference.pb \
--input_names=input,target_sequence_length,source_sequence_length,keep_prob \
--output_names=predictions \
--frozen_graph=True
```

And the issue is no-longer there.

#### BUT
There's still an error, which I assume is on my end.
```
2017-06-30 14:44:18.410032: E tensorflow/core/framework/op_kernel.cc:1141] OpKernel ('op: ""BitwiseAnd"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT8 } } }') for unknown op: BitwiseAnd
2017-06-30 14:44:18.410300: E tensorflow/core/framework/op_kernel.cc:1141] OpKernel ('op: ""BitwiseAnd"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT16 } } }') for unknown op: BitwiseAnd
2017-06-30 14:44:18.410421: E tensorflow/core/framework/op_kernel.cc:1141] OpKernel ('op: ""BitwiseAnd"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }') for unknown op: BitwiseAnd
2017-06-30 14:44:18.410519: E tensorflow/core/framework/op_kernel.cc:1141] OpKernel ('op: ""BitwiseAnd"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT64 } } }') for unknown op: BitwiseAnd
2017-06-30 14:44:18.410641: E tensorflow/core/framework/op_kernel.cc:1141] OpKernel ('op: ""BitwiseAnd"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_UINT8 } } }') for unknown op: BitwiseAnd
2017-06-30 14:44:18.410740: E tensorflow/core/framework/op_kernel.cc:1141] OpKernel ('op: ""BitwiseAnd"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_UINT16 } } }') for unknown op: BitwiseAnd
2017-06-30 14:44:18.410833: E tensorflow/core/framework/op_kernel.cc:1141] OpKernel ('op: ""BitwiseOr"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT8 } } }') for unknown op: BitwiseOr
2017-06-30 14:44:18.410921: E tensorflow/core/framework/op_kernel.cc:1141] OpKernel ('op: ""BitwiseOr"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT16 } } }') for unknown op: BitwiseOr
2017-06-30 14:44:18.410998: E tensorflow/core/framework/op_kernel.cc:1141] OpKernel ('op: ""BitwiseOr"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }') for unknown op: BitwiseOr
2017-06-30 14:44:18.411104: E tensorflow/core/framework/op_kernel.cc:1141] OpKernel ('op: ""BitwiseOr"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT64 } } }') for unknown op: BitwiseOr
2017-06-30 14:44:18.411194: E tensorflow/core/framework/op_kernel.cc:1141] OpKernel ('op: ""BitwiseOr"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_UINT8 } } }') for unknown op: BitwiseOr
2017-06-30 14:44:18.411290: E tensorflow/core/framework/op_kernel.cc:1141] OpKernel ('op: ""BitwiseOr"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_UINT16 } } }') for unknown op: BitwiseOr
2017-06-30 14:44:18.411408: E tensorflow/core/framework/op_kernel.cc:1141] OpKernel ('op: ""BitwiseXor"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT8 } } }') for unknown op: BitwiseXor
2017-06-30 14:44:18.411505: E tensorflow/core/framework/op_kernel.cc:1141] OpKernel ('op: ""BitwiseXor"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT16 } } }') for unknown op: BitwiseXor
2017-06-30 14:44:18.411613: E tensorflow/core/framework/op_kernel.cc:1141] OpKernel ('op: ""BitwiseXor"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }') for unknown op: BitwiseXor
2017-06-30 14:44:18.411706: E tensorflow/core/framework/op_kernel.cc:1141] OpKernel ('op: ""BitwiseXor"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT64 } } }') for unknown op: BitwiseXor
2017-06-30 14:44:18.411806: E tensorflow/core/framework/op_kernel.cc:1141] OpKernel ('op: ""BitwiseXor"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_UINT8 } } }') for unknown op: BitwiseXor
2017-06-30 14:44:18.411898: E tensorflow/core/framework/op_kernel.cc:1141] OpKernel ('op: ""BitwiseXor"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_UINT16 } } }') for unknown op: BitwiseXor
2017-06-30 14:44:18.412014: E tensorflow/core/framework/op_kernel.cc:1141] OpKernel ('op: ""Invert"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT8 } } }') for unknown op: Invert
2017-06-30 14:44:18.412106: E tensorflow/core/framework/op_kernel.cc:1141] OpKernel ('op: ""Invert"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT16 } } }') for unknown op: Invert
2017-06-30 14:44:18.412194: E tensorflow/core/framework/op_kernel.cc:1141] OpKernel ('op: ""Invert"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }') for unknown op: Invert
2017-06-30 14:44:18.412297: E tensorflow/core/framework/op_kernel.cc:1141] OpKernel ('op: ""Invert"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT64 } } }') for unknown op: Invert
2017-06-30 14:44:18.412406: E tensorflow/core/framework/op_kernel.cc:1141] OpKernel ('op: ""Invert"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_UINT8 } } }') for unknown op: Invert
2017-06-30 14:44:18.412499: E tensorflow/core/framework/op_kernel.cc:1141] OpKernel ('op: ""Invert"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_UINT16 } } }') for unknown op: Invert
...
```

And all the way at the bottom...
```
Input 0 of node rnn/Shape_1 was passed float from source_sequence_length:0 incompatible with expected int32.
```"
11123,Correction to Getting Started,"Hello,

I would like to submit that there is a programming bug on line 29 of the ""custom model tutorial"" within Getting Started with Tensorflow. 

The line should read:

input_fn = tf.contrib.learn.io.numpy_input_fn({""x"":x_train}, y_train, batch_size=4, num_epochs=1000)


​Best regards.
Jeff​"
11122,Building Tensorflow from source with XLA enabled and without GPU,"Hi,
I built and installed tensorflow from source with XLA enabled and GPU disabled (basically I opted N for everything while configuring via ./config except XLA enabling as Y). There were lot of warnings regrding deprecated syntax while building. but the build was successful.
I am able to import tensorflow and run basic print command in session. But while I try to do some computation (for eg. simple addition) it gives me following error:
**2017-06-28 15:09:22.366052: F tensorflow/compiler/xla/statusor.cc:41] Attempting to fetch value instead of handling error Not found: could not find registered computation placer for platform Executor -- check target linkage
Aborted**

I did a bit of debugging and this error comes just after the call from client/sessions.py:1262  to pywrap_tensorflow:
**tf_session.TF_Run(session, options,
                                   feed_dict, fetch_list, target_list,
                                   status, run_metadata)**
so I believe it's because it is unable to link to _pywrap_tensorflow_internal.so. 
Can you please provide any fix to this or is there something am doing wrong here?
This is blocking my further task so any kind of help is appreciated!

Thanks & Regards
"
11121,reset_default_graph awkwardly breaks graph nesting.,"
### System information
- **Linux Ubuntu 16.04**:
- **TF version 1.1.0, though it should still be present in master**:

### Bug
Running this:
```python
import tensorflow as tf

g = tf.Graph()
with g.as_default():
  tf.reset_default_graph()
  # Build something...
  a = tf.constant(1.0)
  b = tf.constant(1.0)
  c = a + b
  # Bug happens on exit of the with statement
```
Causes this

```
---------------------------------------------------------------------------
IndexError                                Traceback (most recent call last)
<ipython-input-1-af7c5ed96704> in <module>()
      7   a = tf.constant(1.0)
      8   b = tf.constant(1.0)
----> 9   c = a + b

/usr/lib/python3.5/contextlib.py in __exit__(self, type, value, traceback)
     64         if type is None:
     65             try:
---> 66                 next(self.gen)
     67             except StopIteration:
     68                 return

/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py in get_controller(self, default)
   3626     finally:
   3627       if self._enforce_nesting:
-> 3628         if self.stack[-1] is not default:
   3629           raise AssertionError(
   3630               ""Nesting violated for default stack of %s objects""

IndexError: list index out of range
```

This bug causes a confusing error message. The stack should either include the new default graph created by reset_default_graph or a warning/error message should happen when you reset the default within nested graphs."
11115,Unecessary type checking for shape_invariants in tf.while_loop(),"Apologies in advance if this is not the right place to post this or I did something wrong, I am new to GitHhub issues and TensorFlow.

### Describe the problem
In `tf.while_loop`, when passing in `shape_invariants`, it is not (easily) possible to specify a shape invariant for a state variable belonging to a `BasicLSTMCell`. This is because the `tf.while_loop` makes a `nest.assert_same_structure(loop_vars, shape_invariants)` call, and uses the default parameter `type_check=True`. what this means, however, is that there is no way to manually pass a nested tuple in to specify an invariant for the state. For example, if the shape invariant for the LSTM state in the `shape_invariants` tuple is

`tuple(tf.TensorShape((None, size)) for size in lstm_cell.state_size)` 

then `tf.while_loop` fails with the exception 

`TypeError: The two structures don't have the same sequence type. First structure has type <class 'tensorflow.python.ops.rnn_cell_impl.LSTMStateTuple'>, while second structure has type <type 'tuple'>.`

However, LSTMStateTuple is simply a named tuple, so why does this not work? You can circumvent this restriction with the following code:

`tf.contrib.rnn.LSTMStateTuple(*tuple(tf.TensorShape((None, size)) for size in lstm_cell.state_size))`

But this seems like a hack and just feels wrong. I think that either type checking should be turned off for the purposes of `shape_invariants`, or some more intelligent type checking should be applied. Would this make sense?"
11113,Add cosine annealing for learning rate decay,"[SGDR: Stochastic Gradient Descent With Warm Restarts](https://openreview.net/pdf?id=Skq89Scxx), proposes decaying the learning rate according to

![image](https://user-images.githubusercontent.com/2202312/27641761-1bf302c8-5c1d-11e7-8d4b-15988701ff3f.png)


where ![image](https://user-images.githubusercontent.com/2202312/27641775-28b4e0a8-5c1d-11e7-8adc-1dcaea55d77c.png) is the minimum step length, ![image](https://user-images.githubusercontent.com/2202312/27641798-3be6a80a-5c1d-11e7-9b41-d3c25b0b2b96.png) is the maximum step length, ![image](https://user-images.githubusercontent.com/2202312/27641818-4686daf0-5c1d-11e7-8991-533ce8710e8f.png) is the global step and ![image](https://user-images.githubusercontent.com/2202312/27641841-5594f2ac-5c1d-11e7-9f54-e3cc8ccd1566.png) is the maximum number of iterations.

I've personally found this strategy to  be easy to use given that the number of hyperparameters is relatively small and results are good.

Is this something we want added to tensorflow? Would you accept submissions?



"
11112,What is the possible substitute of cc_ops for android/mobile environment,"OS: Ubuntu 16.04 64bits
Android Version: 7.1 (Nougat)
NDK Version: android-ndk-r12b
Development: develop shared library that exposes op's to NDK CPP application.

I am aware, that there is no explicit support for cc_ops on android/mobile env,
I am using few methods in my application. 

```
tensorflow::ops::ReadFile` 
DecodeJpeg
Const(root.WithOpName(""size""), {input_height, input_width})
```



I just copied these headers from **//bazel-out** to **//tensorflow**
but it requires dependencies, 

```
this rule is missing dependency declarations for the following files included by 'tensorflow/imgproject/imgproject_model.cc':
  '/tensorflow/tensorflow/tensorflow/tensorflow/cc/ops/const_op.h'
  '/tensorflow/tensorflow/tensorflow/tensorflow/cc/framework/ops.h'
  '/tensorflow/tensorflow/tensorflow/tensorflow/cc/framework/scope.h'
  '/tensorflow/tensorflow/tensorflow/tensorflow/cc/ops/array_ops.h'
  '/tensorflow/tensorflow/tensorflow/tensorflow/cc/ops/io_ops.h'
  '/tensorflow/tensorflow/tensorflow/tensorflow/cc/ops/image_ops.h'
  '/tensorflow/tensorflow/tensorflow/tensorflow/cc/ops/math_ops.h
```

I am not sure whether libtensorflow_inference.so can be used with this
Is there any possible substitute for above op's in android/mobile?
please provide pointers.

--
thanks"
11109,How can i use saved_model api to save chatbot model? ,"Rencently i train a chatbot model based on seq2seq model , but i failed to save the model use saved_model api! So i wonder to know where i can get some demo about this task?"
11103,Batch normalization layer has new name for each call to `__init__`,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OSX 10.12.5
- **TensorFlow installed from (source or binary)**: `pip install`
- **TensorFlow version (use command below)**: 1.1.0
- **CUDA/cuDNN version**: no GPU
- **Exact command to reproduce**:
```python
import tensorflow as tf
x = tf.placeholder(tf.float32, [None, 28])
x_test = tf.placeholder(tf.float32, [None, 28])
normalized_x = tf.layers.batch_normalization(x, training=True, reuse=None)
normalized_x_test = tf.layers.batch_normalization(x_test, training=False, reuse=True)
```

### Describe the problem
This is the error I get:
```
ValueError: Variable batch_normalization_1/beta does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?
```
However, I can fix it by setting the name of the batch normalization layer. I think the default behavior should not set a new name each time I create a new batch normalization layer (even if it's an easy thing to debug).

### Source code / logs
Working piece of code:
```python
import tensorflow as tf
x = tf.placeholder(tf.float32, [None, 28])
x_test = tf.placeholder(tf.float32, [None, 28])
normalized_x = tf.layers.batch_normalization(x, training=True, reuse=None, name=""batch_normalization"")
normalized_x_test = tf.layers.batch_normalization(x_test, training=False, reuse=True, name=""batch_normalization"")
```
"
11102,using output_layer in seq2seq model?,"Os：liunx
version: v1.2.0

i am writing a seq2seq model using tensorflow. my problem is 

helper = TrainingHelper(...)
decoder = BasicDecoder(...)
decoder_outputs, final_state, seq_len  = tf.contrib.seq2seq.dynamic_decode(decoder)
rnn_out, sample_ids = decoder_outputs

in traing period, we should calculate the loss:
loss = tf.contrib.seq2seq.sequence_loss(rnn_out, targets, weights)

the rnn_out's shape should be (batch_size, seq_len, target_vocab_size), but (batch_size, seq_len, cell_hidden_size)

how to change the shape ? should i add a output_layer in decoder ? 
if add, how to define a output_layer? i found tf.layers.dense has two params (inputs, units), units may be target_vocab_size, but what about inputs?

In addition, is the output_layer is same as the beamSearcheDecoder when decoding?

"
11101,Negative indices support for tf.gather,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.06
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.2.0
- **Bazel version (if compiling from source)**: 5.2
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

### Describe the problem

`tf.gather` does not support negative indices yet. I have implemented this feature. If you are okay with this feature, then can I create a pull request?"
11099,Typo in illustrating figure for XLA/Concatenation operation,"Illustrating image for [Concatenate](https://www.tensorflow.org/performance/xla/operation_semantics#concatenate)
suggests Concat({ 2x4, 2x8 }, dimension=0) is 2x12. Should be dimension=1, and same for the other examples."
11098,tf.check_numerics does not raise error when used in tf.control_dependencies,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS Sierra 10.12.4
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.2.0
- **Bazel version (if compiling from source)**: none
- **CUDA/cuDNN version**: none
- **GPU model and memory**: none
- **Exact command to reproduce**: run the code below

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

`tf.check_numerics` does not raise error when used in `tf.control_dependencies`.  The code below should raise error, but it does not in TensorFlow 1.2.0

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

```python
import numpy as np
import tensorflow as tf

x = tf.constant(np.nan)
with tf.control_dependencies([tf.check_numerics(x, 'nan')]):
    x = tf.identity(x)

with tf.Session().as_default():
    print(x.eval())
```"
11097,Checkpoint restore problem with version 1.1.0,"
#saving
import tensorflow as  tf
v1 = tf.Variable([1,2,3], name=""v1"")
v2 = tf.Variable([4,5,6], name=""v2"")
init_op = tf.global_variables_initializer()
saver = tf.train.Saver()
with tf.Session() as sess:
  sess.run(init_op)
  save_path = saver.save(sess, ""/home/abc/Documents/tensorflow/tmp/model.ckpt"")
  print(""Model saved in file: %s"" % save_path)


#restore 
v1 = tf.Variable([1,1,1], name=""v1"")
v2 = tf.Variable([1,1,1], name=""v2"")
saver = tf.train.Saver()
with tf.Session() as sess:
  saver.restore(sess, ""/home/abc/Documents/tensorflow/tmp/model.ckpt"")
  print(""Model restored."")
  print(sess.run(v1))


NotFoundError: Key v1_5 not found in checkpoint
	 [[Node: save_4/RestoreV2_4 = RestoreV2[dtypes=[DT_INT32], _device=""/job:localhost/replica:0/task:0/cpu:0""](_recv_save_4/Const_0, save_4/RestoreV2_4/tensor_names, save_4/RestoreV2_4/shape_and_slices)]]

Caused by op 'save_4/RestoreV2_4', defined at:
  File ""/home/abc/.conda/envs/tfenv/lib/python3.5/runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""/home/noor/.conda/envs/tfenv/lib/python3.5/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/home/abc/.conda/envs/tfenv/lib/python3.5/site-packages/ipykernel_launcher.py"", line 16, in <module>
    app.launch_new_instance()
  File ""/home/abc/.conda/envs/tfenv/lib/python3.5/site-packages/traitlets/config/application.py"", line 658, in launch_instance
    app.start()


"
11096,"C1002 error when building on Windows 10 64 bit, with vs 2017","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 64 bit, version 1511
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: master branch, commit 90b2a38a1
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: CPU only
- **Exact command to reproduce**:

      C:\cmake-3.9.0-rc4-win64-x64\bin\cmake.exe .. -G ""Visual Studio 15 2017 Win64"" ^
      -DCMAKE_BUILD_TYPE=Release -DSWIG_EXECUTABLE=C:\swigwin-3.0.12\swig.exe ^
      -DPYTHON_EXECUTABLE=C:\Users\x\.conda\envs\tensorflow\python.exe ^
      -DPYTHON_LIBRARIES=C:\Users\x\.conda\envs\tensorflow\libs\python35.lib ^
      -Dtensorflow_BUILD_CC_TESTS=ON ^
      -Dtensorflow_WIN_CPU_SIMD_OPTIONS=/arch:AVX

      C:\cmake-3.9.0-rc4-win64-x64\bin\cmake.exe --build .

You can collect some of this information using our environment capture script:

~https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh~

You can obtain the TensorFlow version with

~python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""~

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

Issued above build command, and got the following error at last.

    ""C:\Users\X\github\tensorflow\tensorflow\contrib\cmake\build\ALL_BUILD.vcxproj"" (default target) (1) ->
    ""C:\Users\X\github\tensorflow\tensorflow\contrib\cmake\build\_beam_search_ops.vcxproj"" (default target) (3) ->
    ""C:\Users\X\github\tensorflow\tensorflow\contrib\cmake\build\pywrap_tensorflow_internal.vcxproj"" (default target)
    (4) ->
    ""C:\Users\X\github\tensorflow\tensorflow\contrib\cmake\build\pywrap_tensorflow_internal_static.vcxproj"" (default t
    arget) (5) ->
    ""C:\Users\X\github\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj"" (default target) (108) ->
    (ClCompile target) ->
      c:\users\x\github\tensorflow\tensorflow\contrib\cmake\build\external\eigen_archive\eigen\src\core\products\gener
    alblockpanelkernel.h(2011): fatal error C1002: compiler is out of heap space in pass 2 [C:\Users\X\github\tensorfl
    ow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj]
      cl : Command line error D8040: error creating or communicating with child process [C:\Users\X\github\tensorflow\
    tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj]

	86 Warning(s)
	2 Error(s)

For the warnings, there are two kinds:

      C:\Users\X\github\tensorflow\tensorflow\c\c_api.cc(1938): warning C4190: 'TF_NewWhile' has C-linkage specified,
    but returns UDT 'TF_WhileParams' which is incompatible with C [C:\Users\X\github\tensorflow\tensorflow\contrib\cma
    ke\build\tf_test_lib.vcxproj]

**and**

      c:\users\X\github\tensorflow\tensorflow\core\kernels\eigen_spatial_convolutions.h(724): warning C4789: buffer ''
     of size 8 bytes will be overrun; 32 bytes will be written starting at offset 0 [C:\Users\X\github\tensorflow\tens
    orflow\contrib\cmake\build\tf_core_kernels.vcxproj]

I saw there're many complains about *compiler is out of heap space in pass 2* error, and some say adding ""/Zm2000"" to the compiler would solve the problem. I applied this patch:

    @@ -78,6 +78,8 @@ if(WIN32)
       set(CMAKE_CXX_FLAGS_RELEASE ""${CMAKE_CXX_FLAGS_RELEASE} /D_ITERATOR_DEBUG_LEVEL=0"")
       set(CMAKE_CXX_FLAGS_MINSIZEREL ""${CMAKE_CXX_FLAGS_MINSIZEREL} /D_ITERATOR_DEBUG_LEVEL=0"")
       set(CMAKE_CXX_FLAGS_RELWITHDEBINFO ""${CMAKE_CXX_FLAGS_RELWITHDEBINFO} /D_ITERATOR_DEBUG_LEVEL=0"")
    +  # Increase heap size
    +  set(CMAKE_CXX_FLAGS ""${CMAKE_CXX_FLAGS} /Zm2000"")

But did not solve this problem.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
11095,Symbol not found with adding new op,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac Sierra
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.1.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: 8.0
- **GPU model and memory**:
- **Exact command to reproduce**: python test.py

### Describe the problem
Created a custom op, but cannot import it from python. Error at command line:

```
tensorflow.python.framework.errors_impl.NotFoundError: dlopen(src/./ops/build/preprocessing.so, 6): Symbol not found: __ZN10tensorflow14AugmentFunctorIN5Eigen9GpuDeviceEEclERKS2_iiiiiiiPKfPfS7_
  Referenced from: src/./ops/build/preprocessing.so
  Expected in: flat namespace
 in src/./ops/build/preprocessing.so

```

### Source code / logs
Makefile
```
TF_INC = `python -c ""import tensorflow; print(tensorflow.sysconfig.get_include())""`

ifndef CUDA_HOME
    CUDA_HOME := /usr/local/cuda
endif

CC        = gcc -O2 -pthread
CXX       = g++
GPUCC     = nvcc
CFLAGS    = -std=c++11 -I$(TF_INC) -I""$(CUDA_HOME)/include"" -DGOOGLE_CUDA=1
GPUCFLAGS = -c
LFLAGS    = -pthread -shared -fPIC
GPULFLAGS = -x cu -Xcompiler -fPIC
CGPUFLAGS = -L$(CUDA_HOME)/lib -L$(CUDA_HOME)/lib64 -lcudart -undefined dynamic_lookup

OUT_DIR   = src/ops/build
PREPROCESSING_SRC = ""src/ops/preprocessing/preprocessing.cc"" ""src/ops/preprocessing/kernels/data_augmentation.cc""
GPU_SRC_DATA_AUG  	= ""src/ops/preprocessing/kernels/data_augmentation.cu.cc""
GPU_PROD_DATA_AUG 	= $(OUT_DIR)/data_augmentation.o
PREPROCESSING_PROD	= $(OUT_DIR)/preprocessing.so

preprocessing:
	$(GPUCC) -g $(CFLAGS) $(GPUCFLAGS) $(GPU_SRC_DATA_AUG) $(GPULFLAGS) $(GPUDEF) -o $(GPU_PROD_DATA_AUG)
	$(CXX) -g $(CFLAGS)  $(PREPROCESSING_SRC) $(GPU_PROD_DATA_AUG) $(LFLAGS) $(CGPUFLAGS) -o $(PREPROCESSING_PROD)

```

test.py
```
import tensorflow as tf
_preprocessing_ops = tf.load_op_library(
    tf.resource_loader.get_path_to_datafile(""./ops/build/preprocessing.so""))
```

data_augmentation.h
```
#ifndef FLOWNET_DATA_AUGMENTATION_H_
#define FLOWNET_DATA_AUGMENTATION_H_

namespace tensorflow {
template<typename Device>
struct AugmentFunctor {
  void operator()(const Device& d);
};
} // namespace tensorflow
#endif // FLOWNET_DATA_AUGMENTATION_H_
```

data_augmentation.cc
```
#define EIGEN_USE_THREADS

#include ""data_augmentation.h""
#include ""tensorflow/core/framework/op_kernel.h""

namespace tensorflow {
typedef Eigen::ThreadPoolDevice CPUDevice;
typedef Eigen::GpuDevice        GPUDevice;

template<>
struct AugmentFunctor<CPUDevice>{
  void operator()(const CPUDevice& d) {
    // CPU implementation here
  }
};

template<typename Device>
class DataAugmentation : public OpKernel {
  public:
    explicit DataAugmentation(OpKernelConstruction *ctx) : OpKernel(ctx) {}

    void Compute(OpKernelContext *ctx) override {
      // Perform augmentation either on CPU or GPU
      AugmentFunctor<Device>()(ctx->eigen_device<Device>());
    }
};

REGISTER_KERNEL_BUILDER(Name(""DataAugmentation"")
                        .Device(DEVICE_CPU),
                        DataAugmentation<CPUDevice>)

#if GOOGLE_CUDA

REGISTER_KERNEL_BUILDER(Name(""DataAugmentation"")
                        .Device(DEVICE_GPU),
                        DataAugmentation<GPUDevice>)
#endif // GOOGLE_CUDA
} // namespace tensorflow
```
data_augmentation.cu.cc
```
#if GOOGLE_CUDA

#define EIGEN_USE_GPU

#include ""augmentation_base.h""
#include ""data_augmentation.h""
#include ""tensorflow/core/util/cuda_kernel_helper.h""

namespace tensorflow {
__global__ void SpatialAugmentation() {
   // CUDA kernel code goes here
}

template<>
struct AugmentFunctor<GPUDevice>{
  void operator()(const GPUDevice& d) {
    // GPU implementation goes here
    CudaLaunchConfig config = GetCudaLaunchConfig(10, d);
    SpatialAugmentation<<<config.block_count, config.thread_per_block, 0, d.stream()>>>(config.virtual_thread_count);
  }
};

typedef Eigen::GpuDevice GPUDevice;
template struct AugmentFunctor<GPUDevice>;
} // namespace tensorflow
```"
11093,Python checkpoint to use with C++,"I have tried everything from freeze_graph.py to bazel  to try and use a python trained saved checkpoint of a model in c++.

Why is it so complicated in TF?Caffe was so much easier.!!

These are the steps that I follow:

1)While training I added the following line just before saving each checkpoint :  
tf.train.write_graph(sess.graph_def, 'modelsprototxt/', 'trainingmodel.pb', as_text=True)

2)I used freeze_graphy.py to send in a trained checkpoint file,the written graph fle and the output graph file and I get the following error:


Traceback (most recent call last):
  File ""/home/anarayanan/TenserflowPlayground/TF_DEEPLAB_UNTOUCHED/tensorflow-deeplab-resnet-master/freeze_graph.py"", line 175, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""/home/anarayanan/TenserflowPlayground/TF_DEEPLAB_UNTOUCHED/tensorflow-deeplab-resnet-master/freeze_graph.py"", line 172, in main
    FLAGS.output_graph, FLAGS.clear_devices)
  File ""/home/anarayanan/TenserflowPlayground/TF_DEEPLAB_UNTOUCHED/tensorflow-deeplab-resnet-master/freeze_graph.py"", line 115, in freeze_graph
    text_format.Merge(f.read(), input_graph_def)
  File ""/usr/local/lib/python2.7/dist-packages/google/protobuf/text_format.py"", line 476, in Merge
    descriptor_pool=descriptor_pool)
  File ""/usr/local/lib/python2.7/dist-packages/google/protobuf/text_format.py"", line 526, in MergeLines
    return parser.MergeLines(lines, message)
  File ""/usr/local/lib/python2.7/dist-packages/google/protobuf/text_format.py"", line 559, in MergeLines
    self._ParseOrMerge(lines, message)
  File ""/usr/local/lib/python2.7/dist-packages/google/protobuf/text_format.py"", line 574, in _ParseOrMerge
    self._MergeField(tokenizer, message)
  File ""/usr/local/lib/python2.7/dist-packages/google/protobuf/text_format.py"", line 619, in _MergeField
    name = tokenizer.ConsumeIdentifierOrNumber()
  File ""/usr/local/lib/python2.7/dist-packages/google/protobuf/text_format.py"", line 1066, in ConsumeIdentifierOrNumber
    raise self.ParseError('Expected identifier or number.')
google.protobuf.text_format.ParseError: 2:1 : Expected identifier or number.

Can someone please help me understand where the error is coming from?"
11092,"conv2d on CPU does not pass numerical gradient check, possibly because the forward has an offset but the backward not when padding values are negative.","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: ('v1.2.0-rc2-21-g12f033d', '1.2.0')
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

### Describe the problem
conv2d (CPU version) gradient function does not pass my gradient check tests when performing 'SAME' convolution in some special cases.
See my code below for details.

TensorFlow uses eigen_spatial_convolution.h and eigen_backward_spatial_convolution.h for performaing conv2d on CPU.
The possible reason is that in this case the padding will be negative. During forward the eigen function SpatialConvolution will apply this negative padding as an offset. However, in backward, it does not apply this offset -- the forward and backward are inconsistent. 

### Source code / logs
```python
import tensorflow as tf
import numpy as np
bH = 4 
bW = 4 
H = 2 
W = 2    
in_c = 2 
out_c = 3 

stride = 4 
batch_size = 2 
batch_data  = np.ones([batch_size, bH, bW, in_c])
for n in range(batch_size):
  for c in range(in_c):
    for h in range(bH):
      for w in range(bW):
        batch_data[n, h, w, c] = n*0.001 + c*0.002 + h*0.003 + w*0.004   
    
batch = tf.placeholder(tf.float32, [2, bH, bW, 2]) 
f = tf.placeholder(tf.float32, [H, W, in_c, out_c])
output = tf.nn.conv2d(batch, f, strides = [1, stride, stride, 1], padding = 'SAME')
s = tf.reduce_sum(output)
grad_y = tf.gradients(s, f)
init = tf.global_variables_initializer()

alpha = 5e-4 
with tf.Session() as sess:
  sess.run(init)
  filters = np.ones([H, W, in_c, out_c], dtype = float)
  result, grads = sess.run([s, grad_y], feed_dict = {batch: batch_data, f: filters})
  print(result)
  for n in range(out_c):
    for c in range(in_c):
      for h in range(H):
        for w in range(W):
          old = filters[h, w, c, n]
          filters[h, w, c, n] = old - alpha
          [result_left] = sess.run([s], feed_dict = {batch: batch_data, f: filters}) 
          filters[h, w, c, n] = old + alpha
          [result_right] = sess.run([s], feed_dict = {batch: batch_data, f: filters})
          filters[h, w, c, n] = old 
          grad_est = (result_right - result_left) / (2 * alpha)
          grad_act = grads[0][h, w, c, n]
          print(""(%d,%d,%d,%d): %f, %f"" % (n, c, h, w, grad_act, grad_est))
```
```
2017-06-27 18:16:36.858424: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-27 18:16:36.858460: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-27 18:16:36.858464: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-06-27 18:16:36.858468: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-27 18:16:36.858472: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
0.576
(0,0,0,0): 0.001000, 0.014961
(0,0,0,1): 0.009000, 0.023007
(0,0,1,0): 0.007000, 0.020981
(0,0,1,1): 0.015000, 0.028968
(0,1,0,0): 0.005000, 0.018954
(0,1,0,1): 0.013000, 0.027061
(0,1,1,0): 0.011000, 0.024974
(0,1,1,1): 0.019000, 0.033021
(1,0,0,0): 0.001000, 0.014961
(1,0,0,1): 0.009000, 0.023007
(1,0,1,0): 0.007000, 0.020981
(1,0,1,1): 0.015000, 0.028968
(1,1,0,0): 0.005000, 0.018954
(1,1,0,1): 0.013000, 0.027001
(1,1,1,0): 0.011000, 0.024974
(1,1,1,1): 0.019000, 0.033021
(2,0,0,0): 0.001000, 0.014961
(2,0,0,1): 0.009000, 0.023007
(2,0,1,0): 0.007000, 0.020981
(2,0,1,1): 0.015000, 0.028968
(2,1,0,0): 0.005000, 0.018954
(2,1,0,1): 0.013000, 0.027001
(2,1,1,0): 0.011000, 0.024974
(2,1,1,1): 0.019000, 0.033021
```

"
11091,tf.nn.elu: incorrect second derivative,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 14.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.2.0
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: CUDA 8.0 / cuDNN 6.0
- **GPU model and memory**: GTX 1080 Ti 11GB
- **Exact command to reproduce**: see below

`tf.nn.elu` gives incorrect second derivatives:

Consider the graph `y = 2 * elu(-x)`.

```python
x = tf.placeholder(tf.float32, ())
y = 2 * tf.nn.elu(-x)
```

We'll be evaluating at x=1:

```python
x_ = 1
```

We can evaluate first derivatives with automatic differentiation:

```python
dy, = tf.gradients(y, x)
dy.eval({x: x_})
=> -0.7357589
```

This lines up with the analytic answer: `y' = -2e^(-x)`

However, for the second derivative:

```python
ddy, = tf.gradients(dy, x)
ddy.eval({x: x_})
=> 0.36787945
```

Whoops, this doesn't look right! Analytically, the derivative is `y'' = 2e^(-x)`. Evaluated at `x=1`, this is `0.7357588`!

### Workaround

Just in case anyone else needs to work around this until it's fixed:

```python
def elu(x):
    return tf.where(x >= 0.0, x, tf.exp(x) - 1)
```

Looks like second derivatives work with that."
11087,[feature] Option to Selectively Disable Certain Graph Optimizations,"repost from: https://github.com/tensorflow/tensorflow/commit/999b794c137d12d73adbf41dcbe9383a0cd94769#commitcomment-22789669 (CC @petewarden).

On iOS when using a graph that has been ""memory mapped"", you want to disable constant folding to prevent the optimization pass from copying all of the weight data. The current way to do so is to set optimization [level `L0` which disables all optimizations](https://github.com/tensorflow/tensorflow/blob/12f033df4c8fa3feb88ce936eb1581eaa92b303e/tensorflow/core/protobuf/config.proto#L101-L102). Ideally there is a way to keep Common subexpression elimination and function inlining, but prevent constant folding."
11086,KMeansClustering fail with Assertion Error,"I try to use KMeansClustering on letter recognition dataset (http://archive.ics.uci.edu/ml/datasets/Letter+Recognition). I use first 16000 rows. I use this code:

import tensorflow as tf
kmeans = tf.contrib.learn.KMeansClustering(10)
training_set = pd.read_csv(""letter_train.csv"", header=None, dtype=np.float64)
FEATURES = [""V"" + str(i) for i in range(16)]
training_set.columns = [""V"" + str(i) for i in range(17)]
LABEL = ""V"" + str(16)
def input_fn(data_set):
    feature_cols = {k: tf.constant(data_set[k].values)
                    for k in FEATURES}
    labels = tf.constant(data_set[LABEL].values)
    return feature_cols, labels

kmeans = tf.contrib.learn.KMeansClustering(10).fit(input_fn=lambda: input_fn(training_set), steps=100)

But I have following error:

AssertionError: Tensor(""Const_16:0"", shape=(16000,), dtype=float64)

For target Variable, I have <tf.Tensor 'Const_7883:0' shape=(16000,) dtype=float64>)

input_fn is built like here: https://www.tensorflow.org/get_started/input_fn
How to make KMeans work?

"
11085,Tensorflow - Metal Support for Mac OS,"Hello!
I have seen and read some requests for OpenCL support and GPU support on Mac OS, this seems to have been abandoned, am I correct?
But it also seems like Apple is really trying to make Metal big, is this something you have thought of implementing? I understand its not just made by thinking of it, but I would just like to know if any progress is made with GPU support for Mac OS?"
11082,Only use weakref.finalize from backports in Python < 3.4,"### System information
- Arch Linux (up-to-date)
- TensorFlow installed from binary (with pacman, Arch package manager)
- TensorFlow version: 1.2.0
- No GPU or CUDA

### Describe the problem
[tensorflow/python/util/tf_should_use.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/util/tf_should_use.py) is doing `from backports import weakref` (introduced by    cf238e1f2f68309822e1adb3f86dd439c0b87441), though I guess this is only useful for Python 2. In Python 3, we could simply `import weakref`. This bug has been observed by other people and reported on the [Arch Linux bug tracker](https://bugs.archlinux.org/task/54606).

### Traceback
```
python -c ""import tensorflow""
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/usr/lib/python3.6/site-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/usr/lib/python3.6/site-packages/tensorflow/python/__init__.py"", line 63, in <module>
    from tensorflow.python.framework.framework_lib import *
  File ""/usr/lib/python3.6/site-packages/tensorflow/python/framework/framework_lib.py"", line 100, in <module>
    from tensorflow.python.framework.subscribe import subscribe
  File ""/usr/lib/python3.6/site-packages/tensorflow/python/framework/subscribe.py"", line 26, in <module>
    from tensorflow.python.ops import variables
  File ""/usr/lib/python3.6/site-packages/tensorflow/python/ops/variables.py"", line 26, in <module>
    from tensorflow.python.ops import control_flow_ops
  File ""/usr/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 70, in <module>
    from tensorflow.python.ops import tensor_array_ops
  File ""/usr/lib/python3.6/site-packages/tensorflow/python/ops/tensor_array_ops.py"", line 33, in <module>
    from tensorflow.python.util import tf_should_use
  File ""/usr/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py"", line 28, in <module>
    from backports import weakref  # pylint: disable=g-bad-import-order
ModuleNotFoundError: No module named 'backports'
```"
11081,Problem with operating system allocated ports in distributed Tensorflow,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes (simple test case to reproduce)
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Reproduced on Ubuntu 16.04.1 and MacOS Sierra (10.12.5).
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: v1.2.0-rc2-21-g12f033d 1.2.0
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: See source code below

### Describe the problem

When using operating system allocated ports (specifying port zero in the cluster spec), distributed Tensorflow seems to wait forever with the message ""CreateSession still waiting for response from worker: /job:ps/replica:0/task:0"" when initializing variables on the parameter server.

The same code works fine with explicitly allocated ports.  

See below for code to reproduce the issue.

### Source code / logs

This code works fine:

```
import tensorflow as tf

cluster = tf.train.ClusterSpec({""ps"": [""localhost:65062""], ""worker"": [""localhost:65063""]})

ps = tf.train.Server(cluster, job_name=""ps"", task_index=0)
worker = tf.train.Server(cluster, job_name=""worker"", task_index=0)

print(""PS: {0}"".format(ps.target))
print(""Worker: {0}"".format(worker.target))

with tf.Session(worker.target) as sess:

    with tf.device(""/job:ps/task:0""):
        W = tf.Variable(tf.zeros([784, 10]))
        b = tf.Variable(tf.zeros([10]))

    init = tf.global_variables_initializer()

    print(""RUNNING SESSION"")
    sess.run(init)
    print(""SESSION FINISHED"")
```

It gets to the end and prints ""SESSION FINISHED"", producing the following output:

```
2017-06-27 10:12:58.482841: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:65062}
2017-06-27 10:12:58.482857: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:65063}
2017-06-27 10:12:58.483156: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:316] Started server with target: grpc://localhost:65062
2017-06-27 10:12:58.493057: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:65062}
2017-06-27 10:12:58.493077: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:65063}
2017-06-27 10:12:58.493263: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:316] Started server with target: grpc://localhost:65063
PS: b'grpc://localhost:65062'
Worker: b'grpc://localhost:65063'
RUNNING SESSION
2017-06-27 10:12:58.525303: I tensorflow/core/distributed_runtime/master_session.cc:999] Start master session 78091edd7d24288b with config: 

SESSION FINISHED
```

However, this code does not work:

```
import tensorflow as tf

cluster = tf.train.ClusterSpec({""ps"": [""localhost:0""], ""worker"": [""localhost:0""]})

ps = tf.train.Server(cluster, job_name=""ps"", task_index=0)
worker = tf.train.Server(cluster, job_name=""worker"", task_index=0)

print(""PS: {0}"".format(ps.target))
print(""Worker: {0}"".format(worker.target))

with tf.Session(worker.target) as sess:

    with tf.device(""/job:ps/task:0""):
        W = tf.Variable(tf.zeros([784, 10]))
        b = tf.Variable(tf.zeros([10]))

    init = tf.global_variables_initializer()

    print(""RUNNING SESSION"")
    sess.run(init)
    print(""SESSION FINISHED"")
```

The only difference in the above code is that we let the operating system allocate ports by specifying zero as the port number, rather than explicitly allocating them.

This code does not reach the end, but instead prints the message ""CreateSession still waiting for response from worker: /job:ps/replica:0/task:0"" repeatedly. The following output is produced:

```
2017-06-27 10:11:31.238753: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:65062}
2017-06-27 10:11:31.238770: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:0}
2017-06-27 10:11:31.239114: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:316] Started server with target: grpc://localhost:65062
2017-06-27 10:11:31.247859: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:0}
2017-06-27 10:11:31.247877: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:65063}
2017-06-27 10:11:31.248059: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:316] Started server with target: grpc://localhost:65063
PS: b'grpc://localhost:65062'
Worker: b'grpc://localhost:65063'
RUNNING SESSION
2017-06-27 10:11:41.283559: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0
2017-06-27 10:11:51.287739: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0
2017-06-27 10:12:01.290028: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0
2017-06-27 10:12:11.290560: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0
2017-06-27 10:12:21.292900: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0
``` 

Note the messages ```Initialize GrpcChannelCache for job worker -> {0 -> localhost:0}``` above, which may indicate the source of the problem."
11080,Feature Request： delete key in MutableHashTable,"A 'delete' method in contrib.lookup.MutableHashTable would be useful when there are too many <key, value> pairs and we can only handle the recent ones! 
Is there any possibility that the delete method will be implemented? Thanks. @vrv @ebrevdo  "
11078,error running object_detection samples TypeError: unorderable types: tuple() < str(),"I cannot run any of the examples from the new object detection api. I followed the documented ""prepare inputs"" and ""run locally"", but when I run the below command I get the following error.

`python3 train.py --pipeline_config_path=/home/chris/tensorflow/models/object_detection/samples/configs/ssd_inception_v2_pets.config --train_dir=.
`
`Traceback (most recent call last):
  File ""train.py"", line 199, in <module>
    tf.app.run()
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""train.py"", line 195, in main
    worker_job_name, is_chief, FLAGS.train_dir)
  File ""/home/chris/tensorflow/models/object_detection/trainer.py"", line 184, in train
    data_augmentation_options)
  File ""/home/chris/tensorflow/models/object_detection/trainer.py"", line 77, in _create_input_queue
    prefetch_queue_capacity=prefetch_queue_capacity)
  File ""/home/chris/tensorflow/models/object_detection/core/batcher.py"", line 93, in __init__
    num_threads=num_batch_queue_threads)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py"", line 924, in batch
    name=name)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py"", line 698, in _batch
    tensor_list = _as_tensor_list(tensors)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py"", line 386, in _as_tensor_list
    return [tensors[k] for k in sorted(tensors)]
TypeError: unorderable types: tuple() < str()
`

I get the feeling this error is because it isn't processing the record file correctly, or something along those lines is wrong. However, as far as I can tell, I followed everything correctly. I edited the paths in the config file and triple checked that they point to real files."
11077,something wrong with attentionwrapper?,"I am trying to write a seq2seq model with attention. But it gets the following error:

    cell_inputs = self._cell_input_fn(inputs, state.attention)
AttributeError: 'tuple' object has no attribute 'attention'

It seems the state which initialize by the encoder state that does't has the attribute 'attention'.
How should I call AttentionWrapper?

Here is my code:

        cell_list = []
        for layer_i in xrange(hps.num_layers):
            cell_list.append( tf.contrib.rnn.LSTMCell(hps.num_hidden) )
            with tf.variable_scope('encoder%d'%layer_i):
                cell_list.append( tf.contrib.rnn.LSTMCell(hps.num_hidden) )
        enc_cell = tf.contrib.rnn.MultiRNNCell(cell_list)

        encoder_outputs, encoder_state = tf.contrib.rnn.static_rnn(enc_cell, enc_inp, dtype=dtype)

        cell_list = []
        for layer_i in xrange(hps.num_layers):
            with tf.variable_scope('decoder%d'%layer_i):
                cell_list.append( tf.contrib.rnn.LSTMCell(hps.num_hidden) )
        dec_cell = tf.contrib.rnn.MultiRNNCell(cell_list)


        new_enc_out = tf.reshape(encoder_outputs, [hps.batch_size, 30, 256])
        attn_mech = tf.contrib.seq2seq.BahdanauAttention(
                num_units = 128, # depth of query mechanism
                memory = new_enc_out, # hidden states to attend (output of RNN)
                normalize=False, # normalize energy term
                name='BahdanauAttention')

        attn_cell = tf.contrib.seq2seq.AttentionWrapper(
                cell = dec_cell,# Instance of RNNCell
                attention_mechanism = attn_mech, # Instance of AttentionMechanism
                name=""attention_wrapper"")

        if hps.mode==""train"":
            # TrainingHelper does no sampling, only uses inputs
            helper = tf.contrib.seq2seq.TrainingHelper(
                    inputs = dec_inp[:decoder_size], # decoder inputs
                    sequence_length = [1]*decoder_size, # decoder input length
                    name = ""decoder_training_helper"")

            decoder = tf.contrib.seq2seq.BasicDecoder(
                    cell = attn_cell,
                    helper = helper, # A Helper instance
                    initial_state = encoder_state, # initial state of decoder
                    output_layer = None) # instance of tf.layers.Layer, like Dense

        decoder_outputs, final_state, _ = tf.contrib.seq2seq.dynamic_decode(decoder)"
11076,"Is it possible to add a feature to tf.Print , so that it will be capable to save tensor value to file?","Since the while_loop operation is hard to debug, usually we use `tf.Print` to visual tensors in the loop. but `tf.Print` only print a summarization of a tensor. Sometimes I need to get all the value in a tensor, and it is not possible to use `sess.run()` to eval the intermediate tensor value in a loop unless use `TensorArray`. any body would add a **save-to-file** option in `tf.Print` ."
11073,Building from source MAC OS: invalid command 'bdist_wheel',"I'm having a problem when building tensorflow from source on MAC OS:

```
tensorflow$ bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg
Mon 26 Jun 2017 21:40:51 MDT : === Using tmpdir: /var/folders/64/q2l17vhn5c75ym7yv5gv1flw0000gn/T/tmp.XXXXXXXXXX.0Xadn5ti
~/tensorflow/bazel-bin/tensorflow/tools/pip_package/build_pip_package.runfiles ~/tensorflow
~/tensorflow
/var/folders/64/q2l17vhn5c75ym7yv5gv1flw0000gn/T/tmp.XXXXXXXXXX.0Xadn5ti ~/tensorflow
Mon 26 Jun 2017 21:40:56 MDT : === Building wheel
usage: setup.py [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]
   or: setup.py --help [cmd1 cmd2 ...]
   or: setup.py --help-commands
   or: setup.py cmd --help

error: invalid command 'bdist_wheel'
```
My python version:
```
>python --version
Python 2.7.10

>python3 --version
Python 3.6.2rc1

>pip3 list
backports.weakref (1.0rc1)
bleach (1.5.0)
html5lib (0.9999999)
Markdown (2.2.0)
numpy (1.13.0)
pip (9.0.1)
protobuf (3.3.0)
setuptools (36.0.1)
six (1.10.0)
tensorflow (1.2.0)
virtualenv (15.1.0)
Werkzeug (0.12.2)
wheel (0.29.0)

```


I tried `pip install wheel`, `pip3 install wheel`, `pyenv global 3.6.2` which didn't work.
```
>pip3 install wheel
Requirement already satisfied: wheel in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages

>pyenv virtualenv 3.6.2
Requirement already satisfied: setuptools in /Users/Jason/.pyenv/versions/3.6.0/envs/3.6.2/lib/python3.6/site-packages
Requirement already satisfied: pip in /Users/Jason/.pyenv/versions/3.6.0/envs/3.6.2/lib/python3.6/site-packages

>pyenv virtualenv 3.6.2 tensorflow
pyenv-virtualenv: `/Users/Jason/.pyenv/versions/tensorflow' already exists.
```

Does anyone encounter this problem or know how to fix it?
Thank you!"
11072,how use tensorflow distributed use mpi version ??,"how use tensorflow distributed use mpi version ??how use tensorflow distributed use mpi version ??how use tensorflow distributed use mpi version ??

how use tensorflow distributed use mpi version ??how use tensorflow distributed use mpi version ??"
11071,non-chief worker stuck in distributed SYNC mode for graph with two optimizers,"Seems distributed tensorflow cannot train graph with two optimizers in sync mode (one for local update, the other for ps update)

There are three parts in my graph: 
1. each worker has its own copy of vars as the ps server, but are defined with local variable `collections=[tf.GraphKeys.LOCAL_VARIABLES]`, each worker has its own forward-backward loop based on the local vars and its own optimizer
2. (local variable - ps variable) as the gradient and apply to ps variable with SyncReplicasOptimizer.apply_gradients
3. broadcast the ps variable to the local variable

The three parts are run in this way: run subgraph 1 several times, then run subgraph 2 in distributed sync mode to update ps params and then run subgraph 3

### Source code / logs
```
    if args.job_name == 'ps':
        server.join()
    elif args.job_name == 'worker':
        is_chief = (args.task_index == 0)
        num_gpus = len(worker_spec)

        ps_device = '/job:ps/cpu:0'
        worker_device = '/job:worker/task:%d/gpu:0' % args.task_index
        with tf.device(
                tf.train.replica_device_setter(cluster=cluster, ps_device=ps_device, worker_device=worker_device)):
            global_step = tf.Variable(args.start_step, name='global_step', trainable=False)

            print 'building ps params'
            ps_tparams = init_tparams()

            print 'building local params'
            with tf.device(worker_device):
                worker_tparams = init_tparams(is_local=True)  # define variable in collection tf.GraphKeys.LOCAL_VARIABLES

            print 'building graph'

            print '-- local update'
            x, x_mask, y, y_mask, cost = build_graph(worker_tparams, config)
            opt = tf.train.MomentumOptimizer(config.lr, config.mr)
            updates = worker_tparams
            grads = tf.gradients(cost, updates, colocate_gradients_with_ops=True)
            clipped_grads, _ = tf.clip_by_global_norm(grads, config.clip_grads)
            train_op = opt.apply_gradients(zip(clipped_grads, updates))

            print '-- reduce average'
            ps_updates = ps_tparams
            avg_grads = [tf.sub(var, ps_var) for var, ps_var in zip(updates, ps_updates)]
            bopt = tf.train.MomentumOptimizer(config.blr, config.bmr, use_nesterov=True)
            bopt = tf.train.SyncReplicasOptimizerV2(bopt, replicas_to_aggregate=num_gpus, total_num_replicas=num_gpus)
            update_op = bopt.apply_gradients(zip(avg_grads, ps_updates), global_step=global_step)

            print '-- broadcast'
            broadcast_ops = []
            for kk, pp in ps_tparams.items():
                broadcast_ops.append(worker_tparams[kk].assign(pp).op)

            # Others related to sync mode
            chief_queue_runner = bopt.get_chief_queue_runner()
            sync_init_op = bopt.get_init_tokens_op()

            sv = tf.train.Supervisor(
                is_chief=is_chief,
                logdir=config.ckp,
                init_op=tf.global_variables_initializer(),
                local_init_op=tf.local_variables_initializer(),
                global_step=global_step)

            if is_chief:
                print('Worker %d: Initializing session' % args.task_index)
            else:
                print('Worker %d: Waiting for session to be initialized' % args.task_index)

            sess_config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False,
                                         device_filters=['/job:ps', '/job:worker/task:%d' % args.task_index])
            with sv.managed_session(server.target, config=sess_config) as sess:
                print('Worker %d: Session initialization completed' % args.task_index)

                if is_chief:
                    # Chief worker will start the chief queue runner and call the init op
                    sess.run(sync_init_op)
                    sv.start_queue_runners(sess, [chief_queue_runner])
```
The non-chief works stuck at `sv.managed_session` and showing below message again and again:
`I tensorflow/core/distributed_runtime/master_session.cc:993] Start master session a4de1cec7011a62d with config:`
The code can run successfully when there is no local optimizer.

### System information
- Linux Ubuntu 14.04
- CUDA 8.0
- tf 0.12.0-rc1
- GPU: GeForce GTX 1080"
11070,deadloop on replaying kernel when profiling DL network with nvprof ,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes, use models from Keras ,e.g. VGG16
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
Binary
- **TensorFlow version (use command below)**:
1.1.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
8.0/5.1
- **GPU model and memory**:
Nvidia K40, 10G
- **Exact command to reproduce**:
nvprof -metrics flop_sp_efficiency python train_vgg
You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

The profiling process will end with a deadloop in replaying some kernels with prompt:
""Replaying kernel ""cgemm_sm35_ldg_tn_64x8x64x16x16""

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
11068,Global Variables of graph not loaded on different computer,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:l
- MacOSx :
- **TensorFlow installed from binary** (pip install):
- Tensorflow version 1.1.0

### Describe the problem
I have been having issues trying to load a model from a checkpoint file. When trying to access any of the global variables created in our tensorflow model (for example `print sess.run(W)`, we get an error 

> NameError: global name 'W' is not defined

We expect W and other global variables to be present, but none are. Thanks for the help.

### Source code / logs

```
        init_op = tf.global_variables_initializer()
        with tf.Session() as sess:
            sess.run(init_op)
            saver = tf.train.import_meta_graph('FinalTensorflowModel/model.ckpt.meta')
            saver.restore(sess,""FinalTensorflowModel/model.ckpt"")
            print sess.run(W)
            for idx, row in df.iterrows():
                profitability = tf.matmul(row,W) + b
                print sess.run(profitability)
```"
11067,Feature Request: How to Access Attention Weights of Attention Wrapper,"OS: macOS Sierra version 10.12.5
TensorFlow Version: v1.2.0-rc2-21-g12f033d 1.2.0

This is a two-part request related to `tensorflow.contrib.seq2seq`. I would like the ability to visualize the attention weights of the `AttentionWrapper`, but I'm hampered by the lack of examples and I'm struggling to infer the input for `BahdanauAttention`'s `__call__` method's argument `previous_alignments`.

First, could someone clarify how to access the attention weights?

Second, would it be possible to add some tool that visualizes the attention weights (possibly to TensorBoard)?"
11066,Can we disable tensorflow's theading?,I'm running tensorflow in a simulator that does not support mult-threading. Is it possible to disable tensorflow's multi-threading?
11065,Unable to install TensorFlow properly on windows for python. Please help!,"I am trying to install TensorFlow on Windows 10 for Python 3.5 64 bit. It says ""successfully installed"" but when I test it using ""import tensorflow as tf"" command in the command prompt, it shows a long error saying ""DLL load failed"" and ""failed to load native tensorflow runtime"".

I had tried installing it earlier but it didn't work. When I uninstalled from cmd: pip uninstall tensorflow, it said ""successfully uninstalled"". But when I try reinstalling, it says, ""requirement already satisfied"" and gives the same long error (DLL load failed etc.) when i type ""import tensorflow as tf"". This doesn't make sense. Please help.

Please see images.
![image](https://user-images.githubusercontent.com/26795925/27552208-0fd2058e-5ac4-11e7-82d1-c3e16bc74261.png)

![image](https://user-images.githubusercontent.com/26795925/27552227-1e0670f4-5ac4-11e7-9ee8-60969c0a91b9.png)
"
11064,Unsupported CPU features cause runtime errors.,I'm having runtime errors when running Tensorflow programs. I tracked down the problem and the source seems to be that the shared object I have compiled includes CPU features that are not supported by my processor. That causes some pointers pointing to invalid addresses. Right now there are 37 CPU feature defined in tensorflow/core/platform/cpu_info.h. My question is how to not include some of those when compiling Tensorflow's source code.
11063,TensorFlow 1.2.0 depends on a 5 year old release of the Markdown package,"### System information

- This is an installation problem
- Windows 10 64 bit
- Tensorflow installed from pip
- Version 1.2.0
- Bazel version: None
- CUDA v8 CuDNN v6
- GTX980Ti and Pascal TITAN X
- python -m pip install tensorflow-gpu==1.2.0

### Describe the problem

TensorFlow 1.2.0 has added a new dependency on the markdown==2.2.0 package. This package is being actively maintained, and the latest version of it is 2.6.8. However, Tensorflow 1.2.0 has a strict dependency on version 2.2.0, which was released July 2012; almost 5 years ago. As such, the package no longer installs cleanly on all modern distributions of python.

I am attempting to use the Windows python-3.6.1-embed-amd64 release, but when attempting to install either Tensorflow==1.2.0 or markdown==2.2.0 on this environment, installation fails due to a syntax issue in the Markdown package. I haven't delved deep into the issue, but have included log output from trying to use pip to install tensorflow on this system.

However, the most recent version of markdown 2.6.8 installs fine under this environment.

Is there a good reason for why Tensorflow specifically requires the old version? Can the dependency be upgraded to a later version that will support the embedded 3.6.1 Windows release of python?

Surely taking on a legacy dependency like this is not ideal, and should hopefully be fixed.

### Source code / logs

```
C:\Users\Valdemar\Downloads\python-3.6.1-embed-amd64>python -m pip install tensorflow==1.2.0
Collecting tensorflow==1.2.0
  Using cached tensorflow-1.2.0-cp36-cp36m-win_amd64.whl
Requirement already satisfied: six>=1.10.0 in c:\users\valdemar\downloads\python-3.6.1-embed-amd64\lib\site-packages (from tensorflow==1.2.0)
Requirement already satisfied: protobuf>=3.2.0 in c:\users\valdemar\downloads\python-3.6.1-embed-amd64\lib\site-packages (from tensorflow==1.2.0)
Collecting numpy>=1.11.0 (from tensorflow==1.2.0)
  Using cached numpy-1.13.0-cp36-none-win_amd64.whl
Requirement already satisfied: html5lib==0.9999999 in c:\users\valdemar\downloads\python-3.6.1-embed-amd64\lib\site-packages (from tensorflow==1.2.0)
Collecting werkzeug>=0.11.10 (from tensorflow==1.2.0)
  Using cached Werkzeug-0.12.2-py2.py3-none-any.whl
Collecting markdown==2.2.0 (from tensorflow==1.2.0)
  Using cached Markdown-2.2.0.tar.gz
Collecting backports.weakref==1.0rc1 (from tensorflow==1.2.0)
  Using cached backports.weakref-1.0rc1-py3-none-any.whl
Requirement already satisfied: bleach==1.5.0 in c:\users\valdemar\downloads\python-3.6.1-embed-amd64\lib\site-packages (from tensorflow==1.2.0)
Requirement already satisfied: wheel>=0.26 in c:\users\valdemar\downloads\python-3.6.1-embed-amd64\lib\site-packages (from tensorflow==1.2.0)
Requirement already satisfied: setuptools in c:\users\valdemar\downloads\python-3.6.1-embed-amd64\lib\site-packages (from protobuf>=3.2.0->tensorflow==1.2.0)
Building wheels for collected packages: markdown
  Running setup.py bdist_wheel for markdown ... error
  Complete output from command C:\Users\Valdemar\Downloads\python-3.6.1-embed-amd64\python.exe -u -c ""import setuptools, tokenize;__file__='C:\\Users\\Valdemar\\AppData\\Local\\Temp\\pip-build-9rmoawj8\\markdown\\setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" bdist_wheel -d C:\Users\Valdemar\AppData\Local\Temp\tmpeowqyarkpip-wheel- --python-tag cp36:
  running bdist_wheel
  running build
  running build_py
  creating build
  creating build\lib
  creating build\lib\markdown
  copying markdown\blockparser.py -> build\lib\markdown
  copying markdown\blockprocessors.py -> build\lib\markdown
  copying markdown\etree_loader.py -> build\lib\markdown
  copying markdown\inlinepatterns.py -> build\lib\markdown
  copying markdown\odict.py -> build\lib\markdown
  copying markdown\postprocessors.py -> build\lib\markdown
  copying markdown\preprocessors.py -> build\lib\markdown
  copying markdown\serializers.py -> build\lib\markdown
  copying markdown\treeprocessors.py -> build\lib\markdown
  copying markdown\util.py -> build\lib\markdown
  copying markdown\__init__.py -> build\lib\markdown
  copying markdown\__main__.py -> build\lib\markdown
  creating build\lib\markdown\extensions
  copying markdown\extensions\abbr.py -> build\lib\markdown\extensions
  copying markdown\extensions\attr_list.py -> build\lib\markdown\extensions
  copying markdown\extensions\codehilite.py -> build\lib\markdown\extensions
  copying markdown\extensions\def_list.py -> build\lib\markdown\extensions
  copying markdown\extensions\extra.py -> build\lib\markdown\extensions
  copying markdown\extensions\fenced_code.py -> build\lib\markdown\extensions
  copying markdown\extensions\footnotes.py -> build\lib\markdown\extensions
  copying markdown\extensions\headerid.py -> build\lib\markdown\extensions
  copying markdown\extensions\html_tidy.py -> build\lib\markdown\extensions
  copying markdown\extensions\meta.py -> build\lib\markdown\extensions
  copying markdown\extensions\nl2br.py -> build\lib\markdown\extensions
  copying markdown\extensions\rss.py -> build\lib\markdown\extensions
  copying markdown\extensions\sane_lists.py -> build\lib\markdown\extensions
  copying markdown\extensions\smart_strong.py -> build\lib\markdown\extensions
  copying markdown\extensions\tables.py -> build\lib\markdown\extensions
  copying markdown\extensions\toc.py -> build\lib\markdown\extensions
  copying markdown\extensions\wikilinks.py -> build\lib\markdown\extensions
  copying markdown\extensions\__init__.py -> build\lib\markdown\extensions
  running build_scripts
  creating build\scripts-3.6
  copying and adjusting bin\markdown_py -> build\scripts-3.6
  running build_docs
  Traceback (most recent call last):
    File ""<string>"", line 1, in <module>
    File ""C:\Users\Valdemar\AppData\Local\Temp\pip-build-9rmoawj8\markdown\setup.py"", line 208, in <module>
      setup(**data)
    File ""distutils\core.py"", line 148, in setup
    File ""distutils\dist.py"", line 955, in run_commands
    File ""distutils\dist.py"", line 974, in run_command
    File ""C:\Users\Valdemar\Downloads\python-3.6.1-embed-amd64\lib\site-packages\wheel\bdist_wheel.py"", line 179, in run
      self.run_command('build')
    File ""distutils\cmd.py"", line 313, in run_command
    File ""distutils\dist.py"", line 974, in run_command
    File ""distutils\command\build.py"", line 135, in run
    File ""distutils\cmd.py"", line 313, in run_command
    File ""distutils\dist.py"", line 974, in run_command
    File ""C:\Users\Valdemar\AppData\Local\Temp\pip-build-9rmoawj8\markdown\setup.py"", line 125, in run
      import markdown
    File ""build\lib\markdown\__init__.py"", line 213
      except AttributeError, e:
                           ^
  SyntaxError: invalid syntax

  ----------------------------------------
  Failed building wheel for markdown
  Running setup.py clean for markdown
Failed to build markdown
Installing collected packages: numpy, werkzeug, markdown, backports.weakref, tensorflow
  Running setup.py install for markdown ... error
    Complete output from command C:\Users\Valdemar\Downloads\python-3.6.1-embed-amd64\python.exe -u -c ""import setuptools, tokenize;__file__='C:\\Users\\Valdemar\\AppData\\Local\\Temp\\pip-build-9rmoawj8\\markdown\\setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record C:\Users\Valdemar\AppData\Local\Temp\pip-6zhxvaeg-record\install-record.txt --single-version-externally-managed --compile:
    running install
    running build
    running build_py
    creating build
    creating build\lib
    creating build\lib\markdown
    copying markdown\blockparser.py -> build\lib\markdown
    copying markdown\blockprocessors.py -> build\lib\markdown
    copying markdown\etree_loader.py -> build\lib\markdown
    copying markdown\inlinepatterns.py -> build\lib\markdown
    copying markdown\odict.py -> build\lib\markdown
    copying markdown\postprocessors.py -> build\lib\markdown
    copying markdown\preprocessors.py -> build\lib\markdown
    copying markdown\serializers.py -> build\lib\markdown
    copying markdown\treeprocessors.py -> build\lib\markdown
    copying markdown\util.py -> build\lib\markdown
    copying markdown\__init__.py -> build\lib\markdown
    copying markdown\__main__.py -> build\lib\markdown
    creating build\lib\markdown\extensions
    copying markdown\extensions\abbr.py -> build\lib\markdown\extensions
    copying markdown\extensions\attr_list.py -> build\lib\markdown\extensions
    copying markdown\extensions\codehilite.py -> build\lib\markdown\extensions
    copying markdown\extensions\def_list.py -> build\lib\markdown\extensions
    copying markdown\extensions\extra.py -> build\lib\markdown\extensions
    copying markdown\extensions\fenced_code.py -> build\lib\markdown\extensions
    copying markdown\extensions\footnotes.py -> build\lib\markdown\extensions
    copying markdown\extensions\headerid.py -> build\lib\markdown\extensions
    copying markdown\extensions\html_tidy.py -> build\lib\markdown\extensions
    copying markdown\extensions\meta.py -> build\lib\markdown\extensions
    copying markdown\extensions\nl2br.py -> build\lib\markdown\extensions
    copying markdown\extensions\rss.py -> build\lib\markdown\extensions
    copying markdown\extensions\sane_lists.py -> build\lib\markdown\extensions
    copying markdown\extensions\smart_strong.py -> build\lib\markdown\extensions
    copying markdown\extensions\tables.py -> build\lib\markdown\extensions
    copying markdown\extensions\toc.py -> build\lib\markdown\extensions
    copying markdown\extensions\wikilinks.py -> build\lib\markdown\extensions
    copying markdown\extensions\__init__.py -> build\lib\markdown\extensions
    running build_scripts
    creating build\scripts-3.6
    copying and adjusting bin\markdown_py -> build\scripts-3.6
    running build_docs
    Traceback (most recent call last):
      File ""<string>"", line 1, in <module>
      File ""C:\Users\Valdemar\AppData\Local\Temp\pip-build-9rmoawj8\markdown\setup.py"", line 208, in <module>
        setup(**data)
      File ""distutils\core.py"", line 148, in setup
      File ""distutils\dist.py"", line 955, in run_commands
      File ""distutils\dist.py"", line 974, in run_command
      File ""C:\Users\Valdemar\Downloads\python-3.6.1-embed-amd64\lib\site-packages\setuptools\command\install.py"", line 61, in run
        return orig.install.run(self)
      File ""distutils\command\install.py"", line 545, in run
      File ""distutils\cmd.py"", line 313, in run_command
      File ""distutils\dist.py"", line 974, in run_command
      File ""distutils\command\build.py"", line 135, in run
      File ""distutils\cmd.py"", line 313, in run_command
      File ""distutils\dist.py"", line 974, in run_command
      File ""C:\Users\Valdemar\AppData\Local\Temp\pip-build-9rmoawj8\markdown\setup.py"", line 125, in run
        import markdown
      File ""build\lib\markdown\__init__.py"", line 213
        except AttributeError, e:
                             ^
    SyntaxError: invalid syntax

    ----------------------------------------
Command ""C:\Users\Valdemar\Downloads\python-3.6.1-embed-amd64\python.exe -u -c ""import setuptools, tokenize;__file__='C:\\Users\\Valdemar\\AppData\\Local\\Temp\\pip-build-9rmoawj8\\markdown\\setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record C:\Users\Valdemar\AppData\Local\Temp\pip-6zhxvaeg-record\install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in C:\Users\Valdemar\AppData\Local\Temp\pip-build-9rmoawj8\markdown\

C:\Users\Valdemar\Downloads\python-3.6.1-embed-amd64>
```"
11062,C lib for windows with GPU support,"I know that there is a windows c library built for cpu https://github.com/tensorflow/tensorflow/issues/10817.

However, I could not find one with gpu support. I've tried https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-gpu-windows-x86_64-1.2.0.zip, but obvious it does not exist. 

Is it possible to have one?

Thank you!"
11061,"what's the different between tf.sub(a,b) and a-b, if i can Subsitute each other","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
11060,windows 10 /Anaconda/ python 3.6.1/ Tensroflow import error,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: 
- **TensorFlow version (use command below)**: 
- **Bazel version (if compiling from source)**: 
- **CUDA/cuDNN version**:  v8.0 / cudnn-8.0-windows10-x64-v6.0
- **GPU model and memory**:  NVIDIA Geforce GTX 1060 6GB
- **Exact command to reproduce**: 

(D:\Anaconda3) C:\Users\user>python
>>> import tensorflow as tf

Traceback (most recent call last):
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    return importlib.import_module(mname)
  File ""D:\Anaconda3\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 978, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 961, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 950, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 648, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 560, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 922, in create_module
  File ""<frozen importlib._bootstrap>"", line 205, in _call_with_frames_removed
ImportError: DLL load failed: 지정된 모듈을 찾을 수 없습니다.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 21, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""D:\Anaconda3\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""D:\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 52, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    return importlib.import_module(mname)
  File ""D:\Anaconda3\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 978, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 961, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 950, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 648, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 560, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 922, in create_module
  File ""<frozen importlib._bootstrap>"", line 205, in _call_with_frames_removed
ImportError: DLL load failed: 지정된 모듈을 찾을 수 없습니다.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 21, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""D:\Anaconda3\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

Here is the errors came up.
I just started python and kinda novice to programming.. 
Can you guys get me any help..?
"
11058,terminate called after throwing an instance of 'std::out_of_range' error when call made to tf.contrib.tensor_forest.random_forest.TensorForestEstimator.predict(),"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
Installed with pip install tensorflow-gpu
- **TensorFlow version (use command below)**:
('v1.2.0-rc2-21-g12f033d', '1.2.0')
- **Bazel version (if compiling from source)**:
n/a
- **CUDA/cuDNN version**:
5.1.10 for CUDA 8.0
- **GPU model and memory**:
name: GeForce GTX 1050 Ti
major: 6 minor: 1 memoryClockRate (GHz) 1.493
pciBusID 0000:01:00.0
Total memory: 3.94GiB
Free memory: 3.46GiB
- **Exact command to reproduce**:
python RandomForestTrainer.py ?? I'd be happy to upload my code
You can collect some of this information using our environment capture script:
Collecting system information...
2017-06-26 02:27:23.087673: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-26 02:27:23.087713: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-26 02:27:23.087720: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-06-26 02:27:23.087727: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-06-26 02:27:23.394076: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: GeForce GTX 1050 Ti
major: 6 minor: 1 memoryClockRate (GHz) 1.493
pciBusID 0000:01:00.0
Total memory: 3.94GiB
Free memory: 3.46GiB
2017-06-26 02:27:23.394119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2017-06-26 02:27:23.394126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2017-06-26 02:27:23.394144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0)
Wrote environment to tf_env.txt. You can review the contents of that file.
and use it to populate the fields in the github issue template.

cat tf_env.txt

== cat /etc/issue ===============================================
Linux Desktop 4.4.0-79-generic #100-Ubuntu SMP Wed May 17 19:58:14 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""16.04.2 LTS (Xenial Xerus)""
VERSION_ID=""16.04""
VERSION_CODENAME=xenial

== are we in docker =============================================
No

== compiler =====================================================
c++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux Desktop 4.4.0-79-generic #100-Ubuntu SMP Wed May 17 19:58:14 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy (1.12.1)
protobuf (3.3.0)
tensorflow-gpu (1.2.0)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.2.0
tf.GIT_VERSION = v1.2.0-rc2-21-g12f033d
tf.COMPILER_VERSION = v1.2.0-rc2-21-g12f033d
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH /usr/local/cuda/lib64/
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
Mon Jun 26 02:27:24 2017       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 375.66                 Driver Version: 375.66                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 105...  Off  | 0000:01:00.0      On |                  N/A |
|  0%   45C    P0    36W / 120W |    448MiB /  4031MiB |      1%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0      1164    G   /usr/lib/xorg/Xorg                             258MiB |
|    0     15045    G   ...el-token=7CE624E5F1863243374CB7B5F4C7B81C    72MiB |
|    0     20044    G   /usr/lib/xorg/Xorg                              41MiB |
|    0     25088    G   compiz                                          38MiB |
+-----------------------------------------------------------------------------+

== cuda libs  ===================================================
/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a
/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61
/usr/local/cuda-8.0/doc/man/man7/libcudart.7
/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7

### Describe the problem
I created and trained a classifier with the tf.contrib.tensor_forest.random_forest.TensorForestEstimator class, but when I try to use the predict() method I get the following error:

2017-06-26 02:30:13.003812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0)
terminate called after throwing an instance of 'std::out_of_range'
terminate called recursively
terminate called recursively
Aborted (core dumped)




"
11055,Keras load model raises ValueError when loading optimizer weights,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: I extended models_test.py to reproduce the bug
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Debian 8.8
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: ('v1.2.0-1106-g1f82b7a', '1.2.0')
- **Bazel version (if compiling from source)**: 0.5.1
- **CUDA/cuDNN version**: 8.0/6.0
- **GPU model and memory**: nvidia Tesla K-80 / 11.17gb
- **Exact command to reproduce**: See test in PR

### Describe the problem
Upon calling keras.models.load_model(fn) against a file generated by keras.models.save_model() a ValueError is raised. I believe it could be related to using padding='same' in the Conv2D layer.

Traceback (most recent call last):
  File ""models_test.py"", line 166, in test_saving_cnn
    model = keras.models.load_model(fname)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/keras/python/keras/models.py"", line 316, in load_model
    model.optimizer.set_weights(optimizer_weight_values)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/keras/python/keras/optimizers.py"", line 95, in set_weights
    'provided weight shape ' + str(w.shape))
ValueError: Optimizer weight shape (512,) not compatible with provided weight shape (64,)

### Source code / logs
Please see PR below.
"
11053,A custom model of Getting Started,"In the section ""A custom model"" of ""Getting Started With TensorFlow "" on [Tensorflow Website](https://www.tensorflow.org/get_started/get_started#a_custom_model)
```
input_fn = tf.contrib.learn.io.numpy_input_fn({""x"": x_train}, y_train, 4, num_epochs=1000)

# train
estimator.fit(input_fn=input_fn, steps=1000)
# Here we evaluate how well our model did. 
train_loss = estimator.evaluate(input_fn=input_fn)
eval_loss = estimator.evaluate(input_fn=eval_input_fn)
```
The `eval_input_fn` is not defined here."
11052, standard_tensorboard_wsgi() missing 1 required positional argument: 'plugins',how set plugins ? thanks
11051,tensorflow inference in iOS produces EXC_BAD_ACCESS error when memory mapped graph is used,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: OSX Sierra (10.12.5)
- **TensorFlow installed from (source or binary)**: source & binary (tested both)
- **TensorFlow version (use command below)**: 1.1.0
- **Bazel version (if compiling from source)**: 0.5.1-homebrew
- **CUDA/cuDNN version**: CPU version used
- **GPU model and memory**: CPU version used
- **Exact command to reproduce**: 

Apologies if I posted an issue not appropriate here.
I asked this issue on stackoverflow a week ago but seems that no one interested in this issue.

===========
I tested both iOS simple and camera example in tensorflow GitHub repo and they worked well.

I checked those projects and recognized that camera example can use memory mapped graph if I modify constant variable ""model_uses_memory_mapping"" to true, while simple example cannot.

So I modified simple example source to implement same function as camera example, and it seems that the mmapped graph loaded without problem, but when I run inference with session->Run method, the app gave me EXE_BAD_ACCESS error.

I think I've done everything what I can do but still same error.

No idea what else I can do for I'm not good at iOS nor tensorflow core functions.

Could someone guide me how can I resolve this?

FYI, run inference with optimized or quantized graph (with model_uses_memory_mapping set to false) works well.

a) here's message I get when i execute session->Run method:

```
tf_ios_makefile_example`tensorflow::Env::NewReadOnlyMemoryRegionFromFile:
    0x103157ad0 <+0>:  pushq  %rbp
    0x103157ad1 <+1>:  movq   %rsp, %rbp
    0x103157ad4 <+4>:  pushq  %r15
    0x103157ad6 <+6>:  pushq  %r14
    0x103157ad8 <+8>:  pushq  %rbx
    0x103157ad9 <+9>:  pushq  %rax
    0x103157ada <+10>: movq   %rcx, %r14
    0x103157add <+13>: movq   %rdx, %r15
    0x103157ae0 <+16>: movq   %rdi, %rbx
    0x103157ae3 <+19>: movq   (%rsi), %rax
    0x103157ae6 <+22>: leaq   -0x20(%rbp), %rcx
->  0x103157aea <+26>: callq  *0x10(%rax)  
    0x103157aed <+29>: cmpq   $0x0, (%rbx)
    0x103157af1 <+33>: jne    0x103157b06               ; <+54>
    0x103157af3 <+35>: movq   -0x20(%rbp), %rsi
    0x103157af7 <+39>: movq   (%rsi), %rax
    0x103157afa <+42>: movq   %rbx, %rdi
    0x103157afd <+45>: movq   %r15, %rdx
    0x103157b00 <+48>: movq   %r14, %rcx
    0x103157b03 <+51>: callq  *0x18(%rax)
    0x103157b06 <+54>: movq   %rbx, %rax
    0x103157b09 <+57>: addq   $0x8, %rsp
    0x103157b0d <+61>: popq   %rbx
    0x103157b0e <+62>: popq   %r14
    0x103157b10 <+64>: popq   %r15
    0x103157b12 <+66>: popq   %rbp
    0x103157b13 <+67>: retq   
    0x103157b14 <+68>: nopw   %cs:(%rax,%rax)
```
and the error message shown on the line was: **Thread19: EXC_BAD_ACCESS(code=EXC_I386_GPFLT)**

b) and here's some of code I added/modified/used in simple example:

**global variable declaration:**

```
static NSString* model_file_name = @""mmapped_graph"";
static NSString* model_file_type = @""pb"";
const bool model_uses_memory_mapping = true;  //use memory mapped graph

static NSString* labels_file_name = @""retrained_labels"";
static NSString* labels_file_type = @""txt"";

const int wanted_width = 299;
const int wanted_height = 299;
const int wanted_channels = 3;
const float input_mean = 128.0f;
const float input_std = 128.0f;
const std::string input_layer = ""Mul"";
const std::string output_layer = ""final_result"";
```
method definition to read mmapped graph

( referenced from camera example)

```
tensorflow::Status LoadMemoryMappedModel(
    NSString* file_name, NSString* file_type,
    std::unique_ptr<tensorflow::Session>* session,
    std::unique_ptr<tensorflow::MemmappedEnv>* memmapped_env) {
    NSString* network_path = FilePathForResourceName(file_name, file_type);
    memmapped_env->reset(
        new tensorflow::MemmappedEnv(tensorflow::Env::Default())
    );
    tensorflow::Status mmap_status =
    (memmapped_env->get())->InitializeFromFile([network_path UTF8String]);
    if (!mmap_status.ok()) {
        LOG(ERROR) << ""MMap failed with "" << mmap_status.error_message();
        return mmap_status;
    }

    tensorflow::GraphDef tensorflow_graph;
    tensorflow::Status load_graph_status = ReadBinaryProto(
                                                           memmapped_env->get(),
                                                           tensorflow::MemmappedFileSystem::kMemmappedPackageDefaultGraphDef,
                                                           &tensorflow_graph);
    if (!load_graph_status.ok()) {
        LOG(ERROR) << ""MMap load graph failed with ""
        << load_graph_status.error_message();
        return load_graph_status;
    }

    tensorflow::SessionOptions options;
    // Disable optimizations on this graph so that constant folding doesn't
    // increase the memory footprint by creating new constant copies of the weight
    // parameters.
    options.config.mutable_graph_options()
    ->mutable_optimizer_options()
    ->set_opt_level(::tensorflow::OptimizerOptions::L0);
    options.env = memmapped_env->get();

    tensorflow::Session* session_pointer = nullptr;
    tensorflow::Status session_status =
    tensorflow::NewSession(options, &session_pointer);
    if (!session_status.ok()) {
        LOG(ERROR) << ""Could not create TensorFlow Session: "" << session_status;
        return session_status;
    }

    tensorflow::Status create_status = session_pointer->Create(tensorflow_graph);
    //tensorflow::Status create_status = session_pointer->Create(*(tensorflow::GraphDef *)tensorflow_graph);

    if (!create_status.ok()) {
        LOG(ERROR) << ""Could not create TensorFlow Graph: "" << create_status;
        return create_status;
    }

    session->reset(session_pointer);


    return tensorflow::Status::OK();
}
```
**and I load the graph and run inference like this**

```
NSString* RunInferenceOnImage() {
  tensorflow::SessionOptions options;
    std::unique_ptr<tensorflow::Session> session;

  tensorflow::GraphDef tensorflow_graph;
  LOG(INFO) << ""Graph created."";

    tensorflow::Status load_status;

    if (model_uses_memory_mapping) {
        //use memmapped graph - gives me an error
        std::unique_ptr<tensorflow::MemmappedEnv>  tf_memmapped_env;
        load_status = LoadMemoryMappedModel(model_file_name, model_file_type, &session, &tf_memmapped_env);
    } else {
        // use optimized or quantized graph - this works well
        NSString* network_path = FilePathForResourceName(model_file_name, model_file_type);
        load_status = PortableReadFileToProto([network_path UTF8String],&session, &tensorflow_graph);
    }

    if (!load_status.ok()) {
        LOG(FATAL) << ""Couldn't load model: "" << load_status;
    }

  // Read the label list
  NSString* labels_path = FilePathForResourceName(@""retrained_labels"", @""txt"");
  std::vector<std::string> label_strings;
  std::ifstream t;
  t.open([labels_path UTF8String]);
  std::string line;
  while(t){
    std::getline(t, line);
    label_strings.push_back(line);
  }
  t.close();

  // Read the image.
  NSString* image_path = FilePathForResourceName(@""testimage"", @""jpg"");
  int image_width;
  int image_height;
  int image_channels;
  std::vector<tensorflow::uint8> image_data = LoadImageFromFile(
    [image_path UTF8String], &image_width, &image_height, &image_channels);
    LOG(INFO) << ""Graph created5."";

  // image_channel is set to 4 from LoadImageFromFile method (not modified)

  assert(image_channels >= wanted_channels);
  tensorflow::Tensor image_tensor(
      tensorflow::DT_FLOAT,
      tensorflow::TensorShape({
          1, wanted_height, wanted_width, wanted_channels}));
  auto image_tensor_mapped = image_tensor.tensor<float, 4>();

  tensorflow::uint8* in = image_data.data();
  tensorflow::uint8* in_end = (in + (image_height * image_width * image_channels));
  float* out = image_tensor_mapped.data();
  for (int y = 0; y < wanted_height; ++y) {
    const int in_y = (y * image_height) / wanted_height;
    tensorflow::uint8* in_row = in + (in_y * image_width * image_channels);
    float* out_row = out + (y * wanted_width * wanted_channels);
    for (int x = 0; x < wanted_width; ++x) {
      const int in_x = (x * image_width) / wanted_width;
      tensorflow::uint8* in_pixel = in_row + (in_x * image_channels);
      float* out_pixel = out_row + (x * wanted_channels);
      for (int c = 0; c < wanted_channels; ++c) {
        out_pixel[c] = (in_pixel[c] - input_mean) / input_std;
      }
    }
  }
    NSString* result = @"" Graph loaded!"";
  result = [NSString stringWithFormat: @""%@ - %d, %s - %dx%d"", result,
    label_strings.size(), label_strings[0].c_str(), image_width, image_height];

  std::vector<tensorflow::Tensor> outputs;
    if(session.get()) {
        LOG(INFO) << ""SESSION OK!!!!!!"";
    }


  tensorflow::Status run_status = session->Run({{input_layer, image_tensor}},
                               {output_layer}, {}, &outputs);
  // EXC_BAD_ACCESS error occur when session Run method called

  if (!run_status.ok()) {
  //  LOG(ERROR) << ""Running model failed: "" << run_status;
    tensorflow::LogAllRegisteredKernels();
    result = @""Error running model"";
    return result;
  }
  tensorflow::string status_string = run_status.ToString();
  result = [NSString stringWithFormat: @""%@ - %s"", result,
    status_string.c_str()];

  tensorflow::Tensor* output = &outputs[0];
  const int kNumResults = 5;
  const float kThreshold = 0.1f;
  std::vector<std::pair<float, int> > top_results;
  GetTopN(output->flat<float>(), kNumResults, kThreshold, &top_results);

  std::stringstream ss;
  ss.precision(3);
  for (const auto& result : top_results) {
    const float confidence = result.first;
    const int index = result.second;

    ss << index << "" "" << confidence << ""  "";

    // Write out the result as a string
    if (index < label_strings.size()) {
      // just for safety: theoretically, the output is under 1000 unless there
      // is some numerical issues leading to a wrong prediction.
      ss << label_strings[index];
    } else {
      ss << ""Prediction: "" << index;
    }

    ss << ""\n"";
  }

  LOG(INFO) << ""Predictions: "" << ss.str();

  tensorflow::string predictions = ss.str();
  result = [NSString stringWithFormat: @""%@ - %s"", result,
    predictions.c_str()];

  return result;
}
```

You can find original (unmodified) simple example project here: https://github.com/tensorflow/tensorflow/tree/v1.1.0/tensorflow/contrib/ios_examples/simple

https://github.com/tensorflow/tensorflow/blob/v1.1.0/tensorflow/contrib/ios_examples/simple/RunModelViewController.mm

also you can find LoadImageFromFile method here: https://github.com/tensorflow/tensorflow/blob/v1.1.0/tensorflow/contrib/ios_examples/simple/ios_image_load.mm"
11048,tensorflow-gpu aborts with CuDNN v6,"### System information
- **The code can be found from the notebook [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/udacity/4_convolutions.ipynb)**:
- **OS Platform and Distribution: Linux Ubuntu 16.04**:
- **TensorFlow installed from pip**:
- **TensorFlow version ('v1.2.0-rc2-21-g12f033d', '1.2.0')**:
- **Bazel version : None**:
- **CUDA/cuDNN version : CUDA v8, CuDNN v6**:
- **GPU:  GeForce GTX 950M (2GB)**:
- **Exact command to reproduce: Run the notebook**:

I was trying out some code for a convolutional network using tensorflow-gpu but the following messages appear.  
```
2017-06-25 21:53:48.099327: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-25 21:53:48.099345: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-25 21:53:48.099361: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-06-25 21:53:48.099367: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-25 21:53:48.099382: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-06-25 21:53:48.188830: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-06-25 21:53:48.189176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: GeForce GTX 950M
major: 5 minor: 0 memoryClockRate (GHz) 1.124
pciBusID 0000:01:00.0
Total memory: 1.96GiB
Free memory: 1.61GiB
2017-06-25 21:53:48.189201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2017-06-25 21:53:48.189207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2017-06-25 21:53:48.189224: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 950M, pci bus id: 0000:01:00.0)
2017-06-25 21:53:48.838272: E tensorflow/stream_executor/cuda/cuda_dnn.cc:352] Loaded runtime CuDNN library: 6021 (compatibility version 6000) but source was compiled with 5110 (compatibility version 5100).  If using a binary install, upgrade your CuDNN library to match.  If building from sources, make sure the library loaded at runtime matches a compatible version specified during compile configuration.
2017-06-25 21:53:48.838557: F tensorflow/core/kernels/conv_ops.cc:671] Check failed: stream->parent()->GetConvolveAlgorithms(&algorithms) 
Aborted (core dumped)
```
The code runs smoothly if I'm only using CPU.  Is it a bug or feature of tensorflow? How do I get around it?"
11046,tf.contrib.xprof not supported on Windows,"opts = tf.contrib.tfprof.model_analyzer.TRAINABLE_VARS_PARAMS_STAT_OPTIONS
AttributeError: module 'tensorflow.contrib.tfprof' has no attribute 'model_analyzer'

I have tensorflow version 1.2 and have made all the other transitioning changes and the above error was thrown later. 
Has the contrib support been resolved for Windows? Please help
"
11045,ModuleNotFoundError: No module named '_pywrap_tensorflow_internal',"### System information
- **custom code**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 Pro 10.0.15063
- **TensorFlow installed from (source or binary)**: binary (pip)
- **TensorFlow version (use command below)**: tensorflow_gpu-1.2.0-cp36-cp36m-win_amd64.wh
- **CUDA/cuDNN version**: 8.0.6.1 / 8.0 
- **GPU model and memory**: Geforce 1080 Ti 11GB
- **Exact command to reproduce**: import tensorflow 

### Describe the problem
Importing tensorflow fails immediately on import with the following log.
I'm running Python 3.6.1 from Anaconda. I installed tensorflow-gpu with `pip install tensorflow-gpu`

I've installed the CUDA/cuDNN libraries per this guide: https://nitishmutha.github.io/tensorflow/2017/01/22/TensorFlow-with-gpu-for-windows.html

Not sure what I am missing here. Any help would be most appreciated!
Tensorflow CPU works great however. This seems limited to the GPU install.

Thank you in advance

### Source code / logs

```python
>>> import tensorflow
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""c:\programdata\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""c:\programdata\anaconda3\lib\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""c:\programdata\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 52, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""c:\programdata\anaconda3\lib\site-packages\ptpython\repl.py"", line 117, in _execute
    code = compile_with_flags(line, 'eval')
  File ""c:\programdata\anaconda3\lib\site-packages\ptpython\repl.py"", line 105, in compile_with_flags
    dont_inherit=True)
  File ""<stdin>"", line 1
    import tensorflow
         ^
SyntaxError: invalid syntax

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""c:\programdata\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    return importlib.import_module(mname)
  File ""c:\programdata\anaconda3\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 978, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 961, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 950, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 648, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 560, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 922, in create_module
  File ""<frozen importlib._bootstrap>"", line 205, in _call_with_frames_removed
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""c:\programdata\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""c:\programdata\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 21, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""c:\programdata\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""c:\programdata\anaconda3\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
Traceback (most recent call last):
  File ""c:\programdata\anaconda3\lib\site-packages\ptpython\repl.py"", line 117, in _execute
    code = compile_with_flags(line, 'eval')
  File ""c:\programdata\anaconda3\lib\site-packages\ptpython\repl.py"", line 105, in compile_with_flags
    dont_inherit=True)
  File ""<stdin>"", line 1
    import tensorflow
         ^
SyntaxError: invalid syntax

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""c:\programdata\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    return importlib.import_module(mname)
  File ""c:\programdata\anaconda3\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 978, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 961, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 950, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 648, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 560, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 922, in create_module
  File ""<frozen importlib._bootstrap>"", line 205, in _call_with_frames_removed
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""c:\programdata\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""c:\programdata\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 21, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""c:\programdata\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""c:\programdata\anaconda3\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

```"
11044,Tensorflow - No valid folders of images found at XXXXX,"So I have a semi custom code written for a new biomedical program that I am developing. I am trying to get my model to begin retraining and I am getting this problem out of nowhere whenever I run 

python retrain.py \
  --bottleneck_dir=/tf_files/bottlenecks\
  --how_many_training_steps=100\
  --model_dir=/tf_files/ inception \
  --output_graph=/tf_files/retrained_graph.pb \
  --output_labels=/tf_files/retrained_labels.txt \
  --image_dir /tf_files/ct 

The 'ct' folder in question and giving me issues and has a stockpile of images. I have made sure that the folder does not have any other files in it, creating the issue of tensor not picking up the image first. Furthermore, I have ensured that each file has been converted to a jpg. I have no hyphens or dashes in the subfolders and they are all lowercased/ no spaces. 

Below are the following inputs that are giving me troubles. I have scoured the net for different answers to this problem and after troubleshooting the above mentioned attributes I still am finding the same error message incur. Thanks in advance. 


root@8c16ee553d5a:/tf_files# python retrain.py \
>   --bottleneck_dir=/tf_files/bottlenecks\
>   --how_many_training_steps=100\
>   --model_dir=/tf_files/ inception \
>   --output_graph=/tf_files/retrained_graph.pb \
>   --output_labels=/tf_files/retrained_labels.txt \
>   --image_dir /Users/maisiemullin/tf_files/ct 
2017-06-25 16:43:47.433755: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-25 16:43:47.443444: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-25 16:43:47.443724: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
Image directory '/Users/maisiemullin/tf_files/ct' not found.
Traceback (most recent call last):
  File ""retrain.py"", line 1062, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""retrain.py"", line 784, in main
    class_count = len(image_lists.keys())
AttributeError: 'NoneType' object has no attribute 'keys'
root@8c16ee553d5a:/tf_files# 

"
11043,Error with building clang unknown argument,"I configured project for building and execute next command in project directory:

`bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer
`

After that i get this error:
> ERROR: /home/eugeny/Git/tensorflow/tensorflow/core/kernels/BUILD:3614:1: C++ compilation of rule '//tensorflow/core/kernels:multinomial_op_gpu' failed: clang failed: error executing command /usr/bin/clang -MD -MF bazel-out/local_linux-py3-opt/bin/tensorflow/core/kernels/_objs/multinomial_op_gpu/tensorflow/core/kernels/multinomial_op_gpu.cu.d ... (remaining 142 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
> clang: error: unknown argument: '-nvcc_options=relaxed-constexpr'
> clang: error: unknown argument: '-nvcc_options=ftz=true'
> clang: error: cannot find libdevice for sm_35. Provide path to different CUDA installation via --cuda-path, or pass -nocudalib to build without linking with libdevice.
> clang: error: cannot find CUDA installation.  Provide its path via --cuda-path, or pass -nocudainc to build without CUDA includes.
> clang: error: cannot find libdevice for sm_52. Provide path to different CUDA installation via --cuda-path, or pass -nocudalib to build without linking with libdevice.
> clang: error: cannot find CUDA installation.  Provide its path via --cuda-path, or pass -nocudainc to build without CUDA includes.
> clang: error: cannot find CUDA installation.  Provide its path via --cuda-path, or pass -nocudainc to build without CUDA includes.
> Target //tensorflow/cc:tutorials_example_trainer failed to build
> 

I'm trying to build it with gpu support by using next libs:


Bazel: 0.5.1
gcc: 7.1.1
Cuda: 8 (version of cuda/bin/gcc is 5.4.0)
CUDNN: 6
protobuf: 3.3.1

What shall i change for normal building?

"
11042,Documentation Error in TenserFlow website,"On website page:
https://www.tensorflow.org/get_started/get_started#a_custom_model

There is a missing line in the sample code provide for Custom Model:
 After this line 
 `input_fn = tf.contrib.learn.io.numpy_input_fn({""x"": x_train}, y_train, 4, num_epochs=1000)`.
in sample code there should be one more line for variable `eval_input_fn ` which is missing right now in the docs.
single line of code to be added in sample code is 
`eval_input_fn = tf.contrib.learn.io.numpy_input_fn({""x"": x_eval}, y_eval,4, num_epochs=1000)`"
11041,Update logging in DNNClassifier to use tf.summary.scalar,"### System information
- I am using the stock DNNClassifier in contrib/learn. The warning is present in every instance where DNNClassifier is called.
- Present in OSX (Mac OS 10.12.5) and Linux (Ubuntu 16.04)
- **TensorFlow installed from (source or binary)**: Present both on binary and when compiled from source
- **TensorFlow version (use command below)**: v1.2.0 (release) and v1.2.0-1371-g97af82d53 1.2.0
- **Bazel version (if compiling from source)**: 0.5.1
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: Call the DNN classifier as indicated in https://www.tensorflow.org/api_docs/python/tf/contrib/learn/DNNClassifier

### Describe the problem
A warning for a deprecated feature is cluttering the logs when using the DNNClassifier. It is due to the use of the deprecated feature scalar_summary while logging. While this has been deprecated in 2016-11-30, it is still used in tensorflow/contrib/learn/python/learn/estimators/head.py:642
This bug report request for updating the the current tf.summary.scalar, as indicated. The usability of the product is much improved as a consequence.

### Logs
```
WARNING:tensorflow:From /opt/local/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:642: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.

```
### Source code
tensorflow/contrib/learn/python/learn/estimators/head.py:642
```
    # Uses the deprecated API to set the tag explicitly.
    # Without it, training and eval losses will show up in different graphs.
    logging_ops.scalar_summary(
        _summary_key(head_name, mkey.LOSS), weighted_average_loss)
```"
11040,Crash:  F tensorflow/core/kernels/conv_ops.cc:659] Check failed: stream‑>parent()‑>GetConvolveAlgorithms(&algorithms),": E tensorflow/stream_executor/cuda/cuda_dnn.cc:352] Loaded runtime CuDNN library: 6021 (compatibility version 6000) but source was compiled with 5110 (compatibility version 5100). If using a binary install, upgrade your CuDNN library to match. If building from sources, make sure the library loaded at runtime matches a compatible version specified during compile configuration.
2017󈚪󈚽 14:02:30.167164: F tensorflow/core/kernels/conv_ops.cc:659] Check failed: stream‑>parent()‑>GetConvolveAlgorithms(&algorithms)
------------------------

### System information
-- OS Platform and Distribution: CentOS 7
- TensorFlow installed from source :
- **TensorFlow version: 1.1.0 
- **CUDA/cuDNN version:  CUDA v8.0, cuDNN v6
- **GPU model and memory**: TITAN X, 12 GB


### Describe the problem
When I run the program I am getting this error. Any idea what may cause this error? 



"
11038,tf.estimator.RunConfig is incompatible with tf.contrib.learn.Experiment.train,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
 **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: ('v1.2.0-rc2-21-g12f033d', '1.2.0')
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: CUDA 8.0.44, libcudnn.so.5.1.10
- **GPU model and memory**: N/A
- **Exact command to reproduce**: See below

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

`tf.estimator.RunConfig` doesn't have an `environment` attribute, which is incompatible with the current implementation of [`tf.contrib.learn.Experiment.train`](https://github.com/tensorflow/tensorflow/blob/77867318b3c89e38828e787f3948ccae21bc0693/tensorflow/contrib/learn/python/learn/experiment.py#L248). A workaround for local training is simply to set `rc.environment = None`; in general I don't know whether a PR should add the attribute to `tf.estimator.RunConfig` or amend the implementation of `tf.contrib.learn.Experiment.train` to check for its existence.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
11037,installation failed with Virtualenv ERROR:The executable is not functioning tensorflow,"Operating System: macOS Sierra 10.12.3
The version of virtualenv is 15.1.0 
issue like these:
`admindeMacBook-Air:~ admin$ virtualenv --system-site-packages ~/tensorflow`
`Using base prefix '//anaconda'`
`New python executable in /Users/admin/tensorflow/bin/python`
`dyld: Library not loaded: @loader_path/../lib/libpython3.5m.dylib`
`  Referenced from: /Users/admin/tensorflow/bin/python`
`  Reason: image not found`
`ERROR: The executable /Users/admin/tensorflow/bin/python is not functioning`
`ERROR: It thinks sys.prefix is '/Users/admin' (should be '/Users/admin/tensorflow')`
`ERROR: virtualenv is not compatible with this system or executable`

I have tried many ways like homebrew, upgrade py, but it does not work at all.
"
11036,Issue while backpropagating through sparse_tensor_dense_multiply,"I have a simple network defined as follows:

    h1 = tf.sparse_tensor_dense_matmul(x, W1)
    h2 = tf.matmul(h1, W2)
    y = tf.matmul(h2, W3)
    loss = tf.nn.l2_loss(y - y_)
    train = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss)

where x is a sparseTensor, rest are dense. 
Dimensions (shapes) of W1 = [1000,200], W2 = [200,400] and W3 = [ 400, 500]. 

When I run the following:

    sess.run([train], feed_dict={x:X, y_:Y})

where X is sparseTensor of shape [N, 1000] and Y is a tensor of shape [N, 500]

I get an error saying: OOM when allocating tensor with shape[3684773,200].
This is happening while the the the gradient for W is being computed. 3684773 also happens to be the number of non-zero elements in X.

Note:

 1. When I compute gradients using tf.gradients, they work completely
    fine.
 2. When I run the same network using dense X and dense multiply( tf.matmul ), it works completely fine.

    

"
11035,tensorboard display nothing after update to v1.2.0,"I update to tensorflow 1.2.0 by building from source. 
after that, tensorboard show nothing.
Is the tensorboard changed?
I use command:
    tensorboard --logdir=log"
11034,There should be tf.fill_like,
11031,"Error building bazel ""gcc: unrecognized option '-no-canonical-prefixes'""","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Description:	SUSE Linux Enterprise Server 11 (x86_64)
- **TensorFlow installed from (source or binary)**:source
- **TensorFlow version (use command below)**:master branch
- **Bazel version (if compiling from source)**:0.5.1
- **CUDA/cuDNN version**:7.5
- **GPU model and memory**:Tesla K20Xm
- **Exact command to reproduce**:`bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --verbose_failures`


### Describe the problem
Can't build bazel

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
![screen shot 2017-06-24 at 7 49 54 pm](https://user-images.githubusercontent.com/20103571/27507974-b650c51c-5916-11e7-978c-3a2e5ade2b2c.png)


"
11029,install with MKL and OpenCL without locate command,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Description:	SUSE Linux Enterprise Server 11 (x86_64)
- **TensorFlow installed from (source or binary)**:source
- **TensorFlow version (use command below)**:master branch
- **Bazel version (if compiling from source)**:0.5.1
- **CUDA/cuDNN version**:7.5
- **GPU model and memory**:Tesla K20Xm
- **Exact command to reproduce**:./configure

### Describe the problem
I am trying to install tensorflow on Tokyo Institute of Technology Supercomputer TSUBAME.
I want to install with MKL support, but locate command is required.
The university says that because TSUBAME is a public service and `locate` can be used to see files from other users, the command is not going to be installed. So it means MKL can't be used even it is installed in the supercomputer.
I suggest a feature to install tensorflow with the supports without locate command.
I guess tensorflow is used in a lot of supercomputers, the same problem may occur elsewhere.

### Source code / logs
`Do you wish to build TensorFlow with MKL support? [y/N] y
MKL support will be enabled for TensorFlow
Do you wish to download MKL LIB from the web? [Y/n] n
Please specify the location where MKL is installed. [Default is /opt/intel/mklml]: /usr/apps.sp3/isv/intel/xe2013.1.046/composer_xe_2013_sp1.2.144/mkl
./configure: line 279: locate: command not found`

"
11028,wrong path for retrain.py,"python /tensorflow/tensorflow/examples/image_retraining/retrain.py \
  --bottleneck_dir=bottlenecks \
  --model_dir=inception \
  --summaries_dir=training_summaries/long \
  --output_graph=retrained_graph.pb \
  --output_labels=retrained_labels.txt \
  --image_dir=flower_photos

The path is wrong for retrain.py with 4000 iterations (default)
Provided the reader is following the article, path should be 
python retrain.py \
  --bottleneck_dir=bottlenecks \
  --model_dir=inception \
  --summaries_dir=training_summaries/long \
  --output_graph=retrained_graph.pb \
  --output_labels=retrained_labels.txt \
  --image_dir=flower_photos"
11027,Tensorflow 1.2.0 : can not load  graph using tf.train.import_meta_graph,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: self written code
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04 on Azure VM
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: 1.2.0
- **Bazel version (if compiling from source)**: 0.5.1
- **CUDA/cuDNN version**: 8.0 and 6.0.21 respectively
- **GPU model and memory**: NVIDIA Tesla K80
- **Exact command to reproduce**: tf.train.import_meta_graph(""graph_name"")

2017-06-24 07:01:44.245235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties:
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 92f4:00:00.0
Total memory: 11.17GiB
Free memory: 11.11GiB
2017-06-24 07:01:44.245278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0
2017-06-24 07:01:44.245291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y
2017-06-24 07:01:44.245304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 92f4:00:00.0)

### Problem
Whenever the code spawns the loading of meta graph, it does not exit. If the process is cancelled, there is no segmentation fault, and the code exits cleanly. 

### Source code / logs
Python 2.7.12 (default, Nov 19 2016, 06:48:10)
[GCC 5.4.0 20160609] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as rd
>>>
KeyboardInterrupt
>>> import tensorflow as tf
>>> tf.__version__
'1.2.0'
>>> tf.layers.conv2d_transpose
<function conv2d_transpose at 0x7fe9ccd5e668>
>>> saver = tf.train.import_meta_graph('../results/nepal/Need/wc2_nepal_2_model.ckpt.meta')                                                                                                                



^CTraceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1686, in import_meta_graph
    **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.py"", line 504, in import_scoped_meta_graph
    producer_op_list=producer_op_list)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.py"", line 387, in import_graph_def
    op._add_input(source_tensor, dtype=input_type)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1473, in _add_input
    self._recompute_node_def()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1542, in _recompute_node_def
    self._node_def.input.extend([t._as_node_def_input() for t in self._inputs])
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 483, in _as_node_def_input
    if not self._op.name:
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1420, in name
    return self._node_def.name
KeyboardInterrupt
>>>"
11025,AttributeError: module 'reader' has no attribute 'ptb_producer',"I use anaconda2 python3.5 with tensorflow1.2. I want to test tensorflow on the PennTree bank (ptb) dataset. 

Referring to the ptb codes provided at https://github.com/tensorflow/models/tree/master/tutorials/rnn/ptb, I run the code
`reader_test.py`
but got the error:
ERROR: testPtbProducer (__main__.PtbReaderTest)
Traceback (most recent call last):
  File ""<ipython-input-15-5eff201b8159>"", line 34, in testPtbProducer
       ` x, y = reader.ptb_producer(raw_data, batch_size, num_steps)
`AttributeError: module 'reader' has no attribute 'ptb_producer'
FAIL: testPtbRawData (__main__.PtbReaderTest)
Traceback (most recent call last):
  File ""<ipython-input-15-5eff201b8159>"", line 28, in testPtbRawData
    self.assertEqual(len(output), 4)
AssertionError: 5 != 4
Ran 3 tests in 0.344s
FAILED (failures=1, errors=1)
An exception has occurred, use %tb to see the full traceback.
SystemExit: <sitecustomize.IPyTesProgram object at 0x000001FF9FADC630>
C:\Users\yl\Anaconda2\envs\tensorflow-gpu\lib\site-packages\IPython\core\interactiveshell.py:2870: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.
  warn(""To exit: use 'exit', 'quit', or Ctrl-D."", stacklevel=1)

Then, running the code:
`ptb_word_lm.py`
also produces errors:
  File ""C:\Users\yl\Anaconda2\envs\tensorflow-gpu\lib\argparse.py"", line 1506, in _handle_conflict_error
    raise ArgumentError(action, message % conflict_string)
ArgumentError: argument --model: conflicting option string: --model

Did I do something wrong or miss some steps?"
11023,Bug: placeholder input to tf.one_hot leads to hang,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 14.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.1.0
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: CUDA 8.0 / cuDNN 6.0
- **GPU model and memory**: GTX 1080 Ti 11GB
- **Exact command to reproduce**: see below

### Describe the problem

I'm not sure if you're not supposed to feed in a placeholder to `tf.one_hot`, but if you do, it hangs and chews up 100% CPU.

### Source code / logs

Minimal example to reproduce bug:

```python
import tensorflow as tf

sess = tf.Session()
p = tf.placeholder(tf.uint8, 1)
x = tf.one_hot(p, depth=10)
res = sess.run(x, feed_dict={p: [3]})
print(res)
```

The expected result should be either (1) it works and prints `[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]`, or (2) it produces some kind of error."
11022,Major performance hit when running two processes on same GPU.,"I've observed a major performance hit when running two identical models on the same GPU, with allow_growth set to True, so that each process, which only needs a small fraction of the GPU memory (~1gb/11gb are used when allow_growth is set to true). When running a single model on a single process, it consistently finished going through the data I have available in approximately 170-174 seconds, and never exceeds 50% Volatile GPU-Utilization according to nvidia-smi . However, when running with two separate, concurrent processes, (each identical to the first), they both finish in approximately 320-340 seconds, which is unexpected, since GPU utilization was not even half in the first scenario, and running two concurrently effectively slows them down to running them sequentially, despite the seemingly available processing power and memory. 

Is this intentional, or is there a better way to do this? (Currently launching two workers via Celery, each of which create their own TF session and load the model into it separately, and run the data through it). I would love to make maximal use of available hardware, and this seems like a very counter-intuitive outcome. 

I can observe each process allocate roughly 1GiB GPU memory, and each adds approximately 45-50% GPU utilization. For testing purposes, data and model used in both parallel runs is completely identical.

Any thoughts? Am I misusing TF? 

### System information
- Using Keras to load model
- Ubuntu 16.04
- CUDA/CUDNN 8.0/5.1
- TF version 1.0.1
- GTX 1080 ti (not being used to render screen, second 1080 ti is doing that)
- Running in nvidia-docker with a single GPU available to worker process (the one not rendering the screen).
- Running two separate sessions initiated via Celery which both create their own session, set allow_growth=True, each load the model into memory separately, and each run with data separately. 

"
11021,bazel does not co-operate with Ubuntu's update-alternatives,"### System information

TF 1.2, Ubuntu 17.04 on GCE, CUDA 8.0, gcc 4.9.4

### Describe the problem
bazel fails to compile tensorflow when multiple versions of gcc are present and the default points to `/etc/alternatives/gcc`. Specifically, it fails to find the C and C++ header files. However, all works well when `configure` is set to use `/usr/bin/gcc`."
11020,TensorArray `name` using a Tensor,"### System information
python-version: ('v1.2.0-rc1-24-gce1d6ec', '1.2.0-rc2')

### Describe the problem
Looks like the name of the TensorArray is a Tensor and that Tensor is being treated as a boolean in a call to `name_scope`. 

### Source code / logs
```
ta = tf.TensorArray(
          dtype=tf.float32,
          size=100,
          dynamic_size=False,
          colocate_with_first_write_call=False,
          clear_after_read=True,
          infer_shape=False)
# write a bunch of stuff
out = ta.gather(0, 12)
```

Trace:
```
    out = ta.gather(0, 12)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/tensor_array_ops.py"", line 360, in gather
    element_shape=element_shape)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_data_flow_ops.py"", line 1814, in _tensor_array_gather_v3
    element_shape=element_shape, name=name)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 374, in apply_op
    with g.as_default(), ops.name_scope(name) as scope:
  File ""/usr/local/Cellar/python/2.7.12/Frameworks/Python.framework/Versions/2.7/lib/python2.7/contextlib.py"", line 17, in __enter__
    return self.gen.next()
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 4359, in name_scope
    with g.as_default(), g.name_scope(n) as scope:
  File ""/usr/local/Cellar/python/2.7.12/Frameworks/Python.framework/Versions/2.7/lib/python2.7/contextlib.py"", line 17, in __enter__
    return self.gen.next()
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 3009, in name_scope
    if name:
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 578, in __nonzero__
    raise TypeError(""Using a `tf.Tensor` as a Python `bool` is not allowed. ""
TypeError: Using a `tf.Tensor` as a Python `bool` is not allowed. Use `if t is not None:` instead of `if t:` to test if a tensor is defined, and use TensorFlow ops such as tf.cond to execute subgraphs conditioned on the value of a tensor.
```"
11017,Tfdbg does not work with Coordinator/QueueRunners,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Mint 18
- **TensorFlow installed from (source or binary)**: Binary (pip)
- **TensorFlow version (use command below)**: v1.2.0-rc2-21-g12f033d 1.2.0
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

### Describe the problem
The Tensorflow debugger does not seem to be working with Queues; data never seems to be fetched by the QueueRunner threads, be it from a file (using `tf.TFRecordReader` and `tf.parse_single_example`) or preloaded (using `tf.train.slice_input_producer`). Instead, the `coordinator.should_stop()` is True right away. This is only the case after wrapping the session in a `tf.python.debug.LocalCLIDebugWrapperSession`. The example should make things clearer.

Moreover, another error occurs at `coordinator.join(threads)`.

I am aware of the [FAQ entry on Threads](https://www.tensorflow.org/programmers_guide/debugger), but that does not explain why the data fetching threads would not be working.

### Source code / logs
To make it easiest to replicate, I simply took the [example on working with preloaded data](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/how_tos/reading_data/fully_connected_preloaded.py), and wrapped the session in there with the debugger. I uploaded the gist with two lines added to https://gist.github.com/rubenvereecken/079cdf1abc76866714ff6f752167481d#file-fully_connected_preloaded_debug-py-L92.

To reproduce, run the file. Once you drop in the debugger, run once. It then exits. The full output is below:

```
Extracting /tmp/data/train-images-idx3-ubyte.gz
Extracting /tmp/data/train-labels-idx1-ubyte.gz
Extracting /tmp/data/t10k-images-idx3-ubyte.gz
Extracting /tmp/data/t10k-labels-idx1-ubyte.gz
Traceback (most recent call last):
  File ""ex.py"", line 191, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/home/ruben/anaconda3/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""ex.py"", line 143, in main
    run_training()
  File ""ex.py"", line 138, in run_training
    coord.join(threads)
  File ""/home/ruben/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/coordinator.py"", line 389, in join
    six.reraise(*self._exc_info_to_raise)
  File ""/home/ruben/anaconda3/lib/python3.6/site-packages/six.py"", line 686, in reraise
    raise value
  File ""/home/ruben/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/queue_runner_impl.py"", line 233, in _run
    enqueue_callable = sess.make_callable(enqueue_op)
AttributeError: 'LocalCLIDebugWrapperSession' object has no attribute 'make_callable'
```

The stacktrace is about `coord.join(threads)`, but this is only possible because `coord.should_stop()` never seems to be `False`, which would indicate there is data to load. Without the added debugger lines, the example simply works."
11016,map_func of tf.contrib.data.Dataset.map gets dict keys instead of values when the nested structure of Dataset is dict,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: b'0.5.0-12520-g1111e06d9' 1.2.0-rc2
- **Bazel version (if compiling from source)**: 0.4.5
- **CUDA/cuDNN version**: 8.0/6
- **GPU model and memory**:

### Describe the problem

If the nested structure of `Dataset` is `dict`, `MapDataset` will call [`map_func(*nested_args)`](https://github.com/tensorflow/tensorflow/blob/1111e06d9cd691cbdfcb67cf9f234a504f4e0f6d/tensorflow/contrib/data/python/ops/dataset_ops.py#L1463) and pass the keys of `nested_args` instead of components in the dataset to `map_func`. It seems that `nested_args` or `*nested_args.values()` need to be passed to `map_func`, so that `map_func` could transform the elements in the dataset.

### Source code / logs
```python
import tensorflow as tf

def foo(*args, **kwargs):
    print(args, kwargs) # ('a', 'b') {}
    return 1 * 100, 2 * 200

tf.contrib.data.Dataset.from_tensors({'a': [1], 'b': [2]}).map(foo)
```"
11015,Link to README.md is broken in NativeLibrary.java,"I'm trying to run TensorFlow in Java, following [this instructions](https://www.tensorflow.org/install/install_java)

I'm using Ubuntu 16 and java 8. I'm not sure what did I wrong, but error message says: 

`$ java -cp libtensorflow-1.2.0.jar:. -Djava.library.path=~/jni HelloTF`

`Exception in thread ""main"" java.lang.UnsatisfiedLinkError: Cannot find TensorFlow native library for OS: linux, architecture: x86_64. See https://github.com/tensorflow/tensorflow/tree/master/java/README.md `

`for possible solutions (such as building the library from source).`
	`at org.tensorflow.NativeLibrary.load(NativeLibrary.java:66)`
	`at org.tensorflow.TensorFlow.init(TensorFlow.java:36)`
	`at org.tensorflow.TensorFlow.<clinit>(TensorFlow.java:40)`
	`at org.tensorflow.Graph.<clinit>(Graph.java:194)`
	`at HelloTF.main(HelloTF.java:8)`

But following  **https://github.com/tensorflow/tensorflow/tree/master/java/README.md**  gets 404 - page not found.
"
11013,Bug: experiment.py continuous_train_and_eval() leads to overfitting,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: YES
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 14.04
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: v1.0.1-4-gbd6743e-dirty 1.0.1
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

### Describe the problem
Our team has found what we believe is a critical bug in [experiment.py continuous_train_and_eval()](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/experiment.py#L506) that pretty much guarantees any model trained with this method will lead to overfitting.

The problem is that every time it alternates from evaluating to training again, it calls [self._call_train()](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/experiment.py#L569), which eventually makes it to [estimator.py _train_model()](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/estimators/estimator.py#L950).

This function first [creates a brand new graph](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/estimators/estimator.py#L952) then [sets up the input pipelines](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/estimators/estimator.py#L956). This necessarily means that the input pipelines are reset from scratch on every training lap, and since a training lap is typically much shorter than an epoch, this means the model is only trained with a small portion of the whole dataset.

Originally we raised this as an issue in [Google's tf-seq2seq](https://github.com/google/seq2seq/issues/262), but as far as we can tell now the bug probably belongs into Tensorflow instead, as we can't see a simple way to modify the tf-seq2seq code to avoid this issue from arising.

Thank you for looking into this matter.

### Source code / logs
N/A"
11011,Install tensorflow with virtualenv failed,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary with virtualenv
- **TensorFlow version (use command below)**: 1.2
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**:
    $ virtualenv --system-site-packages -p python3 tensorflow

### Describe the problem
On my Ubuntu 16.04, I'm trying to install tensorflow with **virtualenv** for **python3** under the guide of https://www.tensorflow.org/versions/master/install/install_linux.

But I got the error message at the step2:

    $ virtualenv --system-site-packages -p python3 tensorflow
    Running virtualenv with interpreter /usr/local/anaconda3/bin/python3
    Using base prefix '/usr/local/anaconda3'
    New python executable in /home/lab/tensorflow/bin/python3
    Also creating executable in /home/lab/tensorflow/bin/python
    /home/lab/tensorflow/bin/python3: error while loading shared libraries: libpython3.6m.so.1.0: cannot open shared object file: No such file or directory
    ERROR: The executable /home/lab/tensorflow/bin/python3 is not functioning
    ERROR: It thinks sys.prefix is '/home/lab' (should be '/home/lab/tensorflow')
    ERROR: virtualenv is not compatible with this system or executable


Notice that I've install **anaconda3**. 

Is anaconda3 incompatible with tensorflow or virtualenv?

Should I uninstall my anaconda3 before installing tensorflow?

Thanks to everybody first!
"
11008,AttributeError: module 'tensorflow' has no attribute 'constant',"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorflow/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
11007,provide project ide setting support,"I'm trying to debug the c++ source code to figure out the function call relation.But I find it's very difficult to import the code to any existing ide on Mac.I had to use the bazel command  to build and test. using gdb to debug is a bit frustrating.If there are some useful tool chains, would you please give some tips which will make it easily for developers to try such great tensorflow?Thanks so much."
11005,"[Bug] tf version 1.2 , dropout layer reject tensor type rate","version 1.2

The following code:

```python
tf.contrib.layers.dropout(tf.zeros((100,10)), keep_prob=tf.placeholder_with_default(0.9,(),'dp'))
```

or 

```python
tf.layers.dropout(tf.zeros((100,10)), 1 - tf.placeholder_with_default(0.9,(),'dp'))
```

will fail with following error:

```txt
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-3-e27328ef830a> in <module>()
----> 1 tf.contrib.layers.dropout(tf.zeros((100,10)), keep_prob=tf.placeholder_with_default(0.9,(),'dp'))

~/miniconda3/envs/t12/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py in func_with_args(*args, **kwargs)
    179       current_args = current_scope[key_func].copy()
    180       current_args.update(kwargs)
--> 181     return func(*args, **current_args)
    182   _add_op(func)
    183   setattr(func_with_args, '_key_op', _key_op(func))

~/miniconda3/envs/t12/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py in dropout(inputs, keep_prob, noise_shape, is_training, outputs_collections, scope)
   1214                                 noise_shape=noise_shape,
   1215                                 name=sc.name,
-> 1216                                 _scope=sc)
   1217     outputs = layer.apply(inputs, training=is_training)
   1218     return utils.collect_named_outputs(

~/miniconda3/envs/t12/lib/python3.6/site-packages/tensorflow/python/layers/core.py in __init__(self, rate, noise_shape, seed, name, **kwargs)
    245                **kwargs):
    246     super(Dropout, self).__init__(name=name, **kwargs)
--> 247     self.rate = min(1., max(0., rate))
    248     self.noise_shape = noise_shape
    249     self.seed = seed

~/miniconda3/envs/t12/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in __bool__(self)
    562       `TypeError`.
    563     """"""
--> 564     raise TypeError(""Using a `tf.Tensor` as a Python `bool` is not allowed. ""
    565                     ""Use `if t is not None:` instead of `if t:` to test if a ""
    566                     ""tensor is defined, and use TensorFlow ops such as ""

TypeError: Using a `tf.Tensor` as a Python `bool` is not allowed. Use `if t is not None:` instead of `if t:` to test if a tensor is defined, and use TensorFlow ops such as tf.cond to execute subgraphs conditioned on the value of a tensor.
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-3-e27328ef830a> in <module>()
----> 1 tf.contrib.layers.dropout(tf.zeros((100,10)), keep_prob=tf.placeholder_with_default(0.9,(),'dp'))

~/miniconda3/envs/t12/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py in func_with_args(*args, **kwargs)
    179       current_args = current_scope[key_func].copy()
    180       current_args.update(kwargs)
--> 181     return func(*args, **current_args)
    182   _add_op(func)
    183   setattr(func_with_args, '_key_op', _key_op(func))

~/miniconda3/envs/t12/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py in dropout(inputs, keep_prob, noise_shape, is_training, outputs_collections, scope)
   1214                                 noise_shape=noise_shape,
   1215                                 name=sc.name,
-> 1216                                 _scope=sc)
   1217     outputs = layer.apply(inputs, training=is_training)
   1218     return utils.collect_named_outputs(

~/miniconda3/envs/t12/lib/python3.6/site-packages/tensorflow/python/layers/core.py in __init__(self, rate, noise_shape, seed, name, **kwargs)
    245                **kwargs):
    246     super(Dropout, self).__init__(name=name, **kwargs)
--> 247     self.rate = min(1., max(0., rate))
    248     self.noise_shape = noise_shape
    249     self.seed = seed

~/miniconda3/envs/t12/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in __bool__(self)
    562       `TypeError`.
    563     """"""
--> 564     raise TypeError(""Using a `tf.Tensor` as a Python `bool` is not allowed. ""
    565                     ""Use `if t is not None:` instead of `if t:` to test if a ""
    566                     ""tensor is defined, and use TensorFlow ops such as ""

TypeError: Using a `tf.Tensor` as a Python `bool` is not allowed. Use `if t is not None:` instead of `if t:` to test if a tensor is defined, and use TensorFlow ops such as tf.cond to execute subgraphs conditioned on the value of a tensor.
```


The same code run successfully on tf version 1.1.0,

I check the documents are not changed : 
[https://www.tensorflow.org/api_docs/python/tf/contrib/layers/dropout](https://www.tensorflow.org/api_docs/python/tf/contrib/layers/dropout)

        keep_prob: A scalar Tensor with the same type as x. The probability that each element is kept.


It accepts tensor, so I guess this should be a bug.



"
11002,`TF_AddGradients` incorrectly reports `Add` has no gradient ,"### System information

OS X with a CPU libtensorflow.so built off master (2336cdf)

### Describe the problem

`TF_AddGradients` reports 

```
No gradient defined for op: Add. Please see https://www.tensorflow.org/code/tensorflow/cc/gradients/README.md for instructions on how to add C++ gradients.
```

when asked to compute dz/dx for z=x+y (see code example). 

and yet `Add` has a [registered gradient](https://github.com/tensorflow/tensorflow/blob/2336cdf7f00434c24f1eb394f255d7de071bdc08/tensorflow/core/ops/math_grad.cc#L372). `Mul` also doesn't work, although gradients of other operations (like `Sin`) do work. 


### Source code / logs

```c
#include ""c_api.h""

void check_status(TF_Status* status) {
  auto code = TF_GetCode(status);
  if (code != TF_OK) {
    cout<<TF_Message(status)<<endl;
    exit(0);
  }
}

int main() {
  auto graph = TF_NewGraph();
  auto x_desc = TF_NewOperation(graph, ""Placeholder"", ""x"");
  TF_SetAttrType(x_desc, ""dtype"", TF_FLOAT);
  auto status = TF_NewStatus();
  auto x = TF_FinishOperation(x_desc, status);
  auto y_desc = TF_NewOperation(graph, ""Placeholder"", ""y"");
  TF_SetAttrType(y_desc, ""dtype"", TF_FLOAT);
  auto y = TF_FinishOperation(y_desc, status);
  auto z_desc = TF_NewOperation(graph, ""Add"", ""z"");
  TF_AddInput(z_desc, {x, 0});
  TF_AddInput(z_desc, {y, 0});
  auto z = TF_FinishOperation(z_desc, status);
  TF_Output output = {z, 0};
  TF_Output input = {x, 0};
  TF_Output grad;
  TF_AddGradients(graph, &output, 1, &input, 1, NULL, status, &grad);
  check_status(status);
  return 0;
}

```"
11000,Upgrade to jemalloc 5.0.0,Contributions welcome! (I won't have bandwidth to do this in the short-term.)
10997,port::AlignedMalloc() may cause a memory leak,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS Sierra Version 10.12.5
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.1.0, Darwin, cpu
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: 
```
# NOTE: Please install Xcode 8.3 first!
$ git clone https://github.com/PerfectlySoft/Perfect-TensorFlow.git
$ cd Perfect-TensorFlow
$ ./test.sh
``` 

### Describe the problem
When developing Perfect-TensorFlow, a Swift Class Wrapper of C api [https://gihub.com/PerfectlySoft/Perfect-TensorFlow](https://gihub.com/PerfectlySoft/Perfect-TensorFlow), I found there might be a memory leak when performing such a test:
testing script: https://github.com/PerfectlySoft/Perfect-TensorFlow/blob/master/Tests/PerfectTensorFlowTests/PerfectTensorFlowTests.swift#L153-L167
currently I am using libtensorflow 1.1.0 CPU version on both macOS / Ubuntu 16.04 LTS and found the same leakage on the both systems, hope to get solution once 1.2+ released.

Using Xcode - Instruments may find the trace as screen shot below:
<p><img src='https://raw.githubusercontent.com/RockfordWei/upfiler/master/alignedmalloc.leak.png'>AlignedMalloc() leak Screenshot</img></p>


### Source code / logs

[Tensor Creation Testing Script](https://github.com/PerfectlySoft/Perfect-TensorFlow/blob/master/Tests/PerfectTensorFlowTests/PerfectTensorFlowTests.swift#L153-L167)"
10994,DLL Problem with fresh tensorflow-gpu installation ,"Hi,

I installed tensorflow-gpu in an anaconda environment on my new notebook. It is a complete fresh installation. I can't get it to work. On my other machine it works fine but not on this new notebook :-(

Machine:
 - Windows 10 Pro
 - i7 7700HQ
 - NVIDIA GTX 1060 - 6GB (newest device driver - **382.53**)
 - 16 GB RAM
 - Anaconda 3
 - CUDA  Toolkit 8.0 installed 
 - CUDnn 5.1 for Cuda Toolkit 8.0 installed

My anaconda3 python environment uses Python35 (**3.5.3**).

-  I installed ""tensorflow-gpu"" via pip.
- I also tried: `pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-1.2.0-cp35-cp35m-win_amd64.whl`

I checked the DDL's. They are all there. I got the following list of DDLs from[ here](https://github.com/tensorflow/tensorflow/issues/5949#issuecomment-263708081)

in C:\windows\system32, i can find:
- KERNEL32.dll
- WSOCK32.dll
- WS2_32.dll
- SHLWAPI.dll
- python35.dll
- MSVCP140.dll
- VCRUNTIME140.dll

in the anaconda folder, i can find:
- api-ms-win-crt-runtime-l1-1-0.dll
- api-ms-win-crt-heap-l1-1-0.dll
- api-ms-win-crt-utility-l1-1-0.dll
- api-ms-win-crt-stdio-l1-1-0.dll
- api-ms-win-crt-string-l1-1-0.dll
- api-ms-win-crt-math-l1-1-0.dll
- api-ms-win-crt-convert-l1-1-0.dll
- api-ms-win-crt-environment-l1-1-0.dll
- api-ms-win-crt-filesystem-l1-1-0.dll
- api-ms-win-crt-time-l1-1-0.dll

when i want to run a mnist example (or when i just execute 'import tensorflow') I get this error message:

```
(tensorflow) c:\bitbucket\masterthesis\anaconda test>python mnist_deep.py
Traceback (most recent call last):
  File ""C:\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    return importlib.import_module(mname)
  File ""C:\Anaconda3\envs\tensorflow\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 666, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 577, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 919, in create_module
  File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed
ImportError: DLL load failed: Das angegebene Modul wurde nicht gefunden.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 21, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""C:\Anaconda3\envs\tensorflow\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""mnist_deep.py"", line 32, in <module>
    from tensorflow.examples.tutorials.mnist import input_data
  File ""C:\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""C:\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 52, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    return importlib.import_module(mname)
  File ""C:\Anaconda3\envs\tensorflow\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 666, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 577, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 919, in create_module
  File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed
ImportError: DLL load failed: Das angegebene Modul wurde nicht gefunden.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 21, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""C:\Anaconda3\envs\tensorflow\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: No module named '_pywrap_tensorflow_internal'


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
```
 "
10992,Feature request: RNN BeamSearchDecoder with Mixture Density Networks For Continuous Truth Values,"For continuous data, there are 3 options to run a beam search when decoding:

1. This is a workaround. Quantize continuous truth values into into either one-hot vector or embedding, effectively transforming the regression into a classification problem.
2. Use a mixture density model with N Gaussian mixtures. When decoding, sample top `beam_width` mixtures.
3. Use the SOTA method described in this paper: https://arxiv.org/pdf/1612.01474.pdf

Of course, the preferred method is number 3.

With a graph similar to https://github.com/tensorflow/tensorflow/issues/10736, how can such a decoder be implemented?

My suggestion is to create a separate decoder subclass that specifically handle this situtation to avoid confusion."
10991,Seq2Seq Documentation is Broken,"A good third of the documentation on https://www.tensorflow.org/api_guides/python/contrib.seq2seq is written about a `DynamicAttentionWrapper` class.

The link posted for an API results in a 404: https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/DynamicAttentionWrapper

This class is not mentioned in `__init__.py` at https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/seq2seq/__init__.py

Can someone please either update the documentation or add the class to git so we can actually use it?"
10990,run on gpu in tensorflow backend .,"Hi,
How can  be sure that the tensorflow+keras  run on GPU?i use tensorflow+keras with backend   . 

Although in keras manual Written ;""If you are running on the TensorFlow or CNTK backends, your code will automatically run on GPU if any available GPU is detected""

How can this be checked?
Thanks.



"
10989,resize_images: Alignment of upsampled image seems incorrect with method=NEAREST_NEIGHBOR and align_corners=True,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: CentOS Linux release 7.2.1511 (Core)
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: ('v1.1.0-0-g1ec6ed5', '1.1.0')
- **Bazel version (if compiling from source)**: 0.4.5- (@non-git)
- **CUDA/cuDNN version**: 7.5/5.1
- **GPU model and memory**: M40, 12GB
- **Exact command to reproduce**:

### Describe the problem

My understanding of the behaviour of `tf.image.resize_images` with `align_corners=True` is that it would resize
```
[A B C D] => [A x x B x x C x x D]
```
if the input size was 4 and the output size was 3*(4-1)+1=10, where the `x` values would be determined by the method of interpolation.
(I will provide 1D examples, although I am actually working with images.)

I see the expected behaviour with `method=tf.image.ResizeMethod.BILINEAR`:
```
[0 3 6 9] => [0 1 2 3 4 5 6 7 8 9]
```
however, with `method=tf.image.ResizeMethod.NEAREST_NEIGHBOR` the result is not what I expect:
```
[0 3 6 9] => [0 0 0 3 3 3 6 6 6 9]    # actual result
[0 3 6 9] => [0 0 3 3 3 6 6 6 9 9]    # desired result
```
Note that the nearest neighbor of the third `0` in the ""actual result"" is the element with value `3`.

### Source code / logs
I have attached a simple example that demonstrates this effect: [nearest.py.zip](https://github.com/tensorflow/tensorflow/files/1095366/nearest.py.zip)"
10986,What should be my --output_node_names for freeze_graph.py ?,I am trying to freeze graph a .pb and .ckpt file of a trained Inception model. I cannot understand what shall by my output-node-names?
10984,Building Tensorflow on Windows with AVX2 enable not compiling,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorflow/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10. Intel Core i7-6600U
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**:1.2.0-rc0
- **Bazel version (if compiling from source)**:No
- **CUDA/cuDNN version**:No
- **GPU model and memory**:No
- **Exact command to reproduce**:

1. Set up toolchain for for 64-bit:
` vcvarsall amd64`
2. Invoked CMAKE
 `C:\Projects\tensorflow\tensorflow\contrib\cmake\build>cmake .. -A x64 -DCMAKE_BUILD_TYPE=Release -DSWIG_EXECUTABLE=C:/tools/swigwin-3.0.12\swigwin-3.0.12/swig.exe -DPYTHON_EXECUTABLE=C:\Users\sergio.murillo\AppData\Local\Programs\Python\Python35/PYTHON.EXE -DPYTHON_LIBRARIES=C:\Users\sergio.murillo\AppData\Local\Programs\Python\Python35\libs\python35.lib -Dtensorflow_WIN_CPU_SIMD_OPTIONS=/arch:AVX2`
3. To build the PIP package
`MSBuild /p:Configuration=Release /filelogger tf_python_build_pip_package.vcxproj`

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
I'm opening a new issue as suggested in [issue 10199](https://github.com/tensorflow/tensorflow/issues/10199) to track AVX2 support on Windows.

I followed the instructions to built tensorflow on Windows using [CMAKE](https://github.com/tensorflow/tensorflow/tree/r0.12/tensorflow/contrib/cmake) and wanted to enable AVX2, but when it was time to build with MSBuild it returned 550 errors all similar to this:

`""C:\Projects\tensorflow\tensorflow\contrib\cmake\build\tf_core_framework.vcxproj"" (default target) (7) -> (ClCompile target) -> c:\projects\tensorflow\third_party\eigen3\unsupported\eigen\cxx11\src\fixedpoint\packetmathavx2.h(274): error C3861: '_mm256_extract_epi16': identifier not found (compiling source file C:\Projects\tensorflow\tensorflow\core\framework\allocator_registry.cc) [C:\Projects\tensorflow\tensorflow\contrib\cmake\build\tf_core_framework.vcxproj] c:\projects\tensorflow\third_party\eigen3\unsupported\eigen\cxx11\src\fixedpoint\packetmathavx2.h(278): error C3861: '_mm256_extract_epi8': identifier not found (compiling source file C:\Projects\tensorflow\tensorflow\core\framework\allocator_registry.cc) [C:\Projects\tensorflow\tensorflow\contrib\cmake\build\tf_core_framework.vcxproj]`

All errors with the same code `C3861: identifier not found` regarding ` _mm256_extract_epi16` and `_mm256_extract_epi8`  
I do have` immintrin.h` in C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include but `_mm256_extract_epi8` and `_mm256_extract_epi16` are not defined in that file.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
10983, freeze_graph script error : google.protobuf.text_format.ParseError ,"I am trying to run the freeze_graph script on my own .pb and .ckpt file. However I am getting this error.

```
google.protobuf.text_format.ParseError: 2:1 : Message type ""tensorflow.GraphDef"" has no field named ""j"".
```
The stack trace is as follows:
```
Traceback (most recent call last):
  File ""/home/gabbar/ML/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py"", line 255, in <module>
    app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/home/gabbar/ML/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""/home/gabbar/ML/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py"", line 187, in main
    FLAGS.variable_names_blacklist)
  File ""/home/gabbar/ML/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py"", line 165, in freeze_graph
    input_graph_def = _parse_input_graph_proto(input_graph, input_binary)
  File ""/home/gabbar/ML/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py"", line 134, in _parse_input_graph_proto
    text_format.Merge(f.read(), input_graph_def)
  File ""/home/gabbar/.cache/bazel/_bazel_gabbar/3ef5463937ccade414be63dae84521e3/execroot/tensorflow/bazel-out/local_linux-opt/bin/tensorflow/python/tools/freeze_graph.runfiles/protobuf/python/google/protobuf/text_format.py"", line 481, in Merge
    descriptor_pool=descriptor_pool)
  File ""/home/gabbar/.cache/bazel/_bazel_gabbar/3ef5463937ccade414be63dae84521e3/execroot/tensorflow/bazel-out/local_linux-opt/bin/tensorflow/python/tools/freeze_graph.runfiles/protobuf/python/google/protobuf/text_format.py"", line 535, in MergeLines
    return parser.MergeLines(lines, message)
  File ""/home/gabbar/.cache/bazel/_bazel_gabbar/3ef5463937ccade414be63dae84521e3/execroot/tensorflow/bazel-out/local_linux-opt/bin/tensorflow/python/tools/freeze_graph.runfiles/protobuf/python/google/protobuf/text_format.py"", line 568, in MergeLines
    self._ParseOrMerge(lines, message)
  File ""/home/gabbar/.cache/bazel/_bazel_gabbar/3ef5463937ccade414be63dae84521e3/execroot/tensorflow/bazel-out/local_linux-opt/bin/tensorflow/python/tools/freeze_graph.runfiles/protobuf/python/google/protobuf/text_format.py"", line 583, in _ParseOrMerge
    self._MergeField(tokenizer, message)
  File ""/home/gabbar/.cache/bazel/_bazel_gabbar/3ef5463937ccade414be63dae84521e3/execroot/tensorflow/bazel-out/local_linux-opt/bin/tensorflow/python/tools/freeze_graph.runfiles/protobuf/python/google/protobuf/text_format.py"", line 652, in _MergeField
    (message_descriptor.full_name, name))
google.protobuf.text_format.ParseError: 2:1 : Message type ""tensorflow.GraphDef"" has no field named ""j"".
```"
10982,python mnist_softmax_xla.py run failure,"Hi,
I run python mnist_softmax_xla.py and got below failure:

linux-swfm:~/workarea/test> python3 mnist_softmax_xla.py   
...
2017-06-22 20:02:52.685534: I tensorflow/compiler/xla/service/service.cc:191]   StreamExecutor device (1): Tesla K40m, Compute Capability 3.5
2017-06-22 20:02:57.741927: F tensorflow/compiler/xla/service/algebraic_simplifier.cc:768] Check failed: user->operand(reshape_or_broadcast_operand_index) == reshape_or_broadcast (0x7f30cc012550 vs. 0x7f30cc021490)
Aborted

my tensorflow version is tensorflow-1.1.0
cuda sdk: 7.5
 "
10979,Not able to import tensorflow .,"Os:  Windows 10.
Python version:3.5.2

**Installed the CPU-only version of TensorFlow:** and via native pip...not anaconda

succesfully installed tensorflow:

But while importing tensorflow below error is coming:


>>> import tensorflow as tf
Traceback (most recent call last):
  File ""C:\Users\Santanu\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    return importlib.import_module(mname)
  File ""C:\Users\Santanu\AppData\Local\Programs\Python\Python35\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 666, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 577, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 906, in create_module
  File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Santanu\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Santanu\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 21, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Santanu\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""C:\Users\Santanu\AppData\Local\Programs\Python\Python35\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<pyshell#2>"", line 1, in <module>
    import tensorflow as tf
  File ""C:\Users\Santanu\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""C:\Users\Santanu\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\Santanu\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 52, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\Santanu\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    return importlib.import_module(mname)
  File ""C:\Users\Santanu\AppData\Local\Programs\Python\Python35\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 666, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 577, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 906, in create_module
  File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Santanu\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Santanu\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 21, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Santanu\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""C:\Users\Santanu\AppData\Local\Programs\Python\Python35\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: No module named '_pywrap_tensorflow_internal'


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.


How to resolve this?????"
10977,Support for tf.nn.max_pool_with_argmax on CPU,"Hello,

Recently I trained a  model using **tf.nn.max_pool_with_argmax** on GPU and its working fine on GPU. I wanted to use the model on CPU but it seems that its not supported on CPU. How can I use this on CPU?

Will there be any support for it in near future? Or any suggestions on how to use this on CPU would be great.

Thanks! "
10976,Adding new classes,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorflow/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:source
- **TensorFlow version (use command below)**:1.2.0rc2
- **Bazel version (if compiling from source)**:0.5.0
- **CUDA/cuDNN version**:--
- **GPU model and memory**:---
- **Exact command to reproduce**:--

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
I want to retrain the inception model with 1003 classes where the first 1000 classes are same as imagenet. So I took with inception model and extracted the  final layer weights and added 3 more columns to it.I popped the final layer created another layer with 1003 classes and with the weights i have changed,as the weights of first 1000 classes remains same as inception but  while training the accuracy is starting from 0 which i didn't expect.What is going wrong..?


### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
10975,The issue template has an incorrect link.,"Ironically, I think the issue template is wrong. I presume that point 3 below is meant to point to the tensorboard repo issue tracker `https://github.com/tensorflow/tensorboard/issues` but as you can see it just points back to the main repo issue tracker! Judging by the activity on that issue tracker perhaps this is on purpose but I doubt it!


`3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorflow/issues).`

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go >>> [here](https://github.com/tensorflow/tensorflow/issues). <<<

Cheers"
10972,Tensorflow 1.2: FileWriter needs to be created after tf.text.summary ops?,"The following works and creates a tf.text.summary which I can find via tensorboard:

```
import tensorflow as tf
sess = tf.InteractiveSession()
summary_op = tf.summary.text('config/config', tf.convert_to_tensor('hello world'))
summary_writer = tf.summary.FileWriter('/tmp/tensorboard', sess.graph)
text = sess.run(summary_op)
summary_writer.add_summary(text, 0)
summary_writer.add_summary(text, 100)
summary_writer.add_summary(text, 200)
summary_writer.flush()
summary_writer.close()
```

![image](https://user-images.githubusercontent.com/6200749/27425155-c4a1199a-5737-11e7-89f8-9ae3bd4159b4.png)

If we change the order of the FileWriter and the summary_op above it does not log anything:

```
import tensorflow as tf
sess = tf.InteractiveSession()
summary_writer = tf.summary.FileWriter('/tmp/tensorboard', sess.graph)
summary_op = tf.summary.text('config/config', tf.convert_to_tensor('hello world'))
text = sess.run(summary_op)
summary_writer.add_summary(text, 0)
summary_writer.add_summary(text, 100)
summary_writer.add_summary(text, 200)
summary_writer.flush()
summary_writer.close()
```

![image](https://user-images.githubusercontent.com/6200749/27425124-a2af2926-5737-11e7-9daa-53cda286cc67.png)
"
10971,TensorFlow 1.2.0 update still not supporting Python 3.6.1 on Windows 10,"
### System information
- **Windows 10 (64-bit)**
- **Python 3.6.1**

Even with the new update the command:

`pip install tensorflow_gpu-1.2.0-cp36-cp36m-win_amd64.whl` 

OR as in the official documentation

`pip3 install --upgrade tensorflow`

returns

> tensorflow_gpu-1.2.0-cp36-cp36m-win_amd64.whl is not a supported wheel on this platform.

AND

> Could not find a version that satisfies the requirement tensorflow (from versions: )
> No matching distribution found for tensorflow

respectively."
10970,Please modify the tensorflow/workspace.bzl's eigen version to make Nvidia TX2 compilation successful,"Hi,all
   I just managed to compile Tensorflow 1.2 successfully in Nvidia TX2. Despite the patches made by this article: http://www.jetsonhacks.com/2017/04/02/tensorflow-on-nvidia-jetson-tx2-development-kit/ , the workspace.bzl file needs to be modified to use the latest eigen version.
Specifically, you need to change the following lines:

>  native.new_http_archive(
>       name = ""eigen_archive"",
>       urls = [
>           ""http://mirror.bazel.build/bitbucket.org/eigen/eigen/get/f3a22f35b044.tar.gz"",
>           ""https://bitbucket.org/eigen/eigen/get/f3a22f35b044.tar.gz"",
>       ],
>       sha256 = ""ca7beac153d4059c02c8fc59816c82d54ea47fe58365e8aded4082ded0b820c4"",
>       strip_prefix = ""eigen-eigen-f3a22f35b044"",
>       build_file = str(Label(""//third_party:eigen.BUILD"")),
>   )

to:

>  native.new_http_archive(
>       name = ""eigen_archive"",
>       urls = [
>           #""http://mirror.bazel.build/bitbucket.org/eigen/eigen/get/f3a22f35b044.tar.gz"",
>           #""https://bitbucket.org/eigen/eigen/get/f3a22f35b044.tar.gz"",
>           ""https://bitbucket.org/eigen/eigen/get/3.3.4.tar.gz"",
>       ],
>       sha256 = ""the sha256 value you used to verify"",
>       strip_prefix = ""eigen-eigen-5a0156e40feb"",
>       build_file = str(Label(""//third_party:eigen.BUILD"")),
>   )

Since I'm not sure if the newest eigen works well in other platform, I don't have confidence to ask for a PR.
I just post this issue in case some of you guys can't compile tensor flow 1.2 in nvidia TX2."
10969,Tensorflow Android how to set multi input for my own model?,"Beside the images that I need to transform into the classifier, I also need to put another input named ""`phase_train`"" and set as  ""`False`"". How to make it?"
10968,bayesflow w/ higher order functions loops endlessly,"**Environment**: TensorFlow v1.2.0-rc2-21-g12f033d 1.2.0 running on Mac OS X (v10.12.5)

**Issue**:
Use of `tensorflow.contrib.bayesflow.stochastic_tensor.StochasticTensor` in conjunction with higher order functions, such as `tf.map_fn` and `tf.while_loop`, results in a seemingly endless loop during construction of the associated stochastic graph's `surrogate_loss`. Within the source code, the aforementioned loop occurs [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/bayesflow/python/ops/stochastic_graph_impl.py#L85). A minimal example is provided below.

**Example**:
```
# Dependencies
import tensorflow as tf
from tensorflow.contrib.distributions import Bernoulli
from tensorflow.contrib.bayesflow import\
	stochastic_tensor as st, stochastic_graph as sg

# Flags and variable declaration
_int, _float = 'int32', 'float32'
num_logits = 0 #doesn't seem to matter
logits = tf.get_variable('logits', shape=[num_logits, 1], dtype=_float)

# Pass `logits` to a distribution and then wrap with a StochasticTensor
dist = Bernoulli(logits, dtype=_float)
with st.value_type(st.SampleValue()):
	samples = st.StochasticTensor(dist)
```
Building off of the above, the following seem to loop endlessly. Using `tf.map_fn`,
```
losses = tf.map_fn(lambda x: x, samples, _float)
loss = sg.surrogate_loss([tf.reduce_mean(losses, axis=0)])# <- loops endlessly
```
Using `tf.while_loop` in conjunction with `tf.TensorArray`,
```
array = tf.TensorArray(_float, num_logits).unstack(samples)
def cond(k, *args):
	return tf.less(k, num_logits)
def body(k, losses):
	return k+1, tf.concat([losses, array.read(k)], 0)
loop_v = [0, tf.zeros([0], _float)]
invars = [tf.TensorShape([]), tf.TensorShape([None])]
losses = tf.while_loop(cond, body, loop_v, shape_invariants=invars)[1]
loss = sg.surrogate_loss([tf.reduce_mean(losses, keep_dims=True)])# <- loops endlessly
```
"
10966,Implementation of algorithms like longest commom subsequence and editting distance?,"Hi everyone, 

I am wondering if there are some shortcuts to implement an new API of algorithms like lcs. Should I implement it from scratch using C++ or C? It seems not efficient to do it in Python.  How can I just get started?

Thanks, 
Best, 
lerner"
10963,"tf.TensorArray.stack(name=""aname"") bug","### System information
- **Code + Interpreter**: Notice the print out is ""stackme/stackme:0"" instead of ""stackme:0"".
This is a really minor error. But I had spent at least half an hour wondering why my operation was called twice. Would be really nice to be fixed :)

```
imemory = tf.TensorArray(tf.float32, size=0, dynamic_size=True, name=""memory"")
imemory.write(0, tf.constant(0))
imemory = imemory.write(0, tf.constant(0))
imemory = imemory.write(1, tf.constant(1))
imemory = imemory.write(2, tf.constant(2))
result = imemory.stack(name=""stackme"")
print(result)

<print out>Tensor(""stackme/stackme:0"", shape=(?,), dtype=float32)

```

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
v1.1.0-rc0-61-g1ec6ed5 1.1.0

"
10961,cudaCheckError() failed on any gpu apart from gpu:0,"I am experiencing a strange issue (similar to  #9489) on both a 4 GPUs and a 2 GPUs machine. 

Basically I have a tensorflow model that trains and performs very well on one GPU, I now want to distribute the training phase by using multiple GPUs at once. I followed the CIFAR10 example to parallelize the model but keep getting errors a few iterations into the training process. I get 
```
""cudaCheckError() failed : invalid resource handle
2017-06-21 19:50:28.168726: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:639] failed to record completion event; therefore, failed to create inter-stream dependency"" 
```
most times but I have also seen shape errors on reshape tensors (while the graph is already running) and segmentation errors. 

I have been playing around with configurations and so far I have noticed that the crash only happens if gpu:1 is being called. I tried using only gpu:1 and encountered the same problem. On the other end, the same script using with tf.device('gpu:0') and only this gpu works fine.

What I tried. 
I reinstalled tensorflow from sources, set up and tested another machine with more GPUs to no avail.

[test_out.txt](https://github.com/tensorflow/tensorflow/files/1092625/test_out.txt)

other errors that have occurred : 
`iter: 1 / 70000, total loss: 2.5591 / 2.5591, rpn_loss_cls: 0.6961, rpn_loss_box: 0.0025, loss_cls: 1.8603, loss_box: 0.0003, lr: 0.001000
speed: 4.586s / iter
iter: 2 / 70000, total loss: 1.3976 / 1.3976, rpn_loss_cls: 0.6869, rpn_loss_box: 0.0078, loss_cls: 0.7021, loss_box: 0.0007, lr: 0.001000
speed: 2.638s / iter
iter: 3 / 70000, total loss: 1.0764 / 1.0764, rpn_loss_cls: 0.6849, rpn_loss_box: 0.0251, loss_cls: 0.2764, loss_box: 0.0900, lr: 0.001000
speed: 1.999s / iter
iter: 4 / 70000, total loss: 0.9941 / 0.9941, rpn_loss_cls: 0.6804, rpn_loss_box: 0.0118, loss_cls: 0.2407, loss_box: 0.0611, lr: 0.001000
speed: 1.673s / iter
cudaCheckError() failed : invalid resource handle
2017-06-22 10:07:47.528133: F tensorflow/stream_executor/cuda/cuda_driver.cc:312] Check failed: CUDA_SUCCESS == cuCtxSetCurrent(cuda_context->context()) (0 vs. 4)
./experiments/scripts/faster_rcnn_end2end.sh: line 58: 30171 Aborted                 (core dumped) python ./tools/train_net.py --device ${DEV} --number_of_devices ${NUM_DEVICES} --weights data/pretrain_model/VGG_imagenet.npy --imdb ${TRAIN_IMDB} --iters ${ITERS} --cfg experiments/cfgs/faster_rcnn_end2end.yml --network VGGnet_train ${EXTRA_ARGS}
`

`2017-06-22 10:10:04.886367: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_1_bfc) ran out of memory trying to allocate 3.51GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
cudaCheckError() failed : invalid resource handle
2017-06-22 10:10:06.489802: E tensorflow/stream_executor/cuda/cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_DEINITIALIZED
2017-06-22 10:10:06.489835: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:203] Unexpected Event status: 1
`
`2017-06-22 10:10:58.935801: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_1_bfc) ran out of memory trying to allocate 3.51GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
iter: 1 / 70000, total loss: 2.8609 / 2.8609, rpn_loss_cls: 0.6944, rpn_loss_box: 0.0092, loss_cls: 2.1569, loss_box: 0.0004, lr: 0.001000
speed: 4.461s / iter
iter: 2 / 70000, total loss: 1.4497 / 1.4497, rpn_loss_cls: 0.6778, rpn_loss_box: 0.0152, loss_cls: 0.7555, loss_box: 0.0012, lr: 0.001000
speed: 2.556s / iter
iter: 3 / 70000, total loss: 1.5660 / 1.5660, rpn_loss_cls: 0.7197, rpn_loss_box: 0.0325, loss_cls: 0.6074, loss_box: 0.2063, lr: 0.001000
speed: 1.921s / iter
2017-06-22 10:11:03.655654: W tensorflow/core/framework/op_kernel.cc:1165] Invalid argument: Input to reshape is a tensor with 178500 values, but the requested shape has 365072219990
	 [[Node: tower_1/Reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/gpu:1""](tower_1/transpose, tower_1/Reshape/shape)]]
2017-06-22 10:11:03.655654: W tensorflow/core/framework/op_kernel.cc:1165] Invalid argument: Input to reshape is a tensor with 178500 values, but the requested shape has 365072219990
	 [[Node: tower_1/Reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/gpu:1""](tower_1/transpose, tower_1/Reshape/shape)]]
2017-06-22 10:11:03.655687: W tensorflow/core/framework/op_kernel.cc:1165] Invalid argument: Input to reshape is a tensor with 178500 values, but the requested shape has 365072219990
	 [[Node: tower_1/Reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/gpu:1""](tower_1/transpose, tower_1/Reshape/shape)]]
2017-06-22 10:11:03.655692: W tensorflow/core/framework/op_kernel.cc:1165] Invalid argument: Input to reshape is a tensor with 178500 values, but the requested shape has 365072219990
	 [[Node: tower_1/Reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/gpu:1""](tower_1/transpose, tower_1/Reshape/shape)]]
Traceback (most recent call last):
  File ""./tools/train_net.py"", line 100, in <module>
    max_iters=args.max_iters)
  File ""/home/SERILOCAL/a.larreche/Faster-RCNN_TF/tools/../lib/fast_rcnn/train.py"", line 375, in train_net
    sw.train_model(sess, max_iters)
  File ""/home/SERILOCAL/a.larreche/Faster-RCNN_TF/tools/../lib/fast_rcnn/train.py"", line 281, in train_model
    run_metadata=run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 896, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1108, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1261, in _do_run
    options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1280, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Input to reshape is a tensor with 178500 values, but the requested shape has 365072219990
	 [[Node: tower_1/Reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/gpu:1""](tower_1/transpose, tower_1/Reshape/shape)]]

Caused by op u'tower_1/Reshape', defined at:
  File ""./tools/train_net.py"", line 100, in <module>
    max_iters=args.max_iters)
  File ""/home/SERILOCAL/a.larreche/Faster-RCNN_TF/tools/../lib/fast_rcnn/train.py"", line 375, in train_net
    sw.train_model(sess, max_iters)
  File ""/home/SERILOCAL/a.larreche/Faster-RCNN_TF/tools/../lib/fast_rcnn/train.py"", line 208, in train_model
    cross_entropy_t, loss_box_t, rpn_cross_entropy_t, rpn_loss_box_t = self.tower_loss(i)
  File ""/home/SERILOCAL/a.larreche/Faster-RCNN_TF/tools/../lib/fast_rcnn/train.py"", line 148, in tower_loss
    outputs_roi_data, outputs_cls_score, outputs_bbox_pred = self.net.inference(gpu_id)
  File ""/home/SERILOCAL/a.larreche/Faster-RCNN_TF/tools/../lib/networks/VGGnet_train.py"", line 89, in inference
    .reshape_layer(2, name='rpn_cls_score_reshape'.format(i))
  File ""/home/SERILOCAL/a.larreche/Faster-RCNN_TF/tools/../lib/networks/network.py"", line 26, in layer_decorated
    layer_output = op(self, layer_input, *args, **kwargs)
  File ""/home/SERILOCAL/a.larreche/Faster-RCNN_TF/tools/../lib/networks/network.py"", line 217, in reshape_layer
    int(d),tf.cast(tf.cast(input_shape[1],tf.float32)*(tf.cast(input_shape[3],tf.float32)/tf.cast(d,tf.float32)),tf.int32),input_shape[2]]),[0,2,3,1],name=name))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py"", line 2472, in reshape
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 767, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2528, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1203, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): Input to reshape is a tensor with 178500 values, but the requested shape has 365072219990
	 [[Node: tower_1/Reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/gpu:1""](tower_1/transpose, tower_1/Reshape/shape)]]
`


"
10959,ModuleNotFoundError: No module named 'tensorflow.tensorboard.tensorboard',"Tensorboard not working on Tensorflow built from sources

### System information
- **Linux Ubuntu 16.04**
- **TensorFlow installed from sources using Bazel**
- **TensorFlow version v1.2.0-1126-gb7acb6a**
- **Bazel version 0.51**
- **CUDA/cuDNN version 8.0/6.0**
- **Found device 0 with properties: 
name: GeForce GTX 1070
major: 6 minor: 1 memoryClockRate (GHz) 1.683
pciBusID 0000:01:00.0
Total memory: 7.92GiB
Free memory: 5.15GiB**
- **Exact command to reproduce**: `$ tensorboard`
Installed into fresh anaconda3 environment 'tensorflow', environment is activated when performing command.
### Description: The TensorBoard visualization doesn't work
### Source code / logs
```
$ tensorboard
Traceback (most recent call last):
  File ""/home/gpu/anaconda3/envs/tensorflow/bin/tensorboard"", line 7, in <module>
    from tensorflow.tensorboard.tensorboard import main
ModuleNotFoundError: No module named 'tensorflow.tensorboard.tensorboard'
```
"
10958,tf.summary.FileWriter doesn't support unicode paths.,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:

Yes. In fact, I use code from Denny Britz's CNN tutorial: 
https://github.com/dennybritz/cnn-text-classification-tf

Line 116, (https://github.com/dennybritz/cnn-text-classification-tf/blob/master/train.py)

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:

Windows 10, x86_64, locale: Russian

- **TensorFlow installed from (source or binary)**:
binary, pip install tensorflow
- **TensorFlow version (use command below)**:
b'unknown' 1.2.0

- **Bazel version (if compiling from source)**:
n/a
- **CUDA/cuDNN version**:
8.0, 5.1
- **GPU model and memory**:
nvidia 970
- **Exact command to reproduce**:
```
out_dir = os.path.abspath(os.path.join(os.path.curdir, ""runs"", timestamp))
train_summary_dir = os.path.join(out_dir, ""summaries"", ""train"")
train_summary_writer = tf.summary.FileWriter(train_summary_dir, sess.graph, flush_secs=5)
```

### Describe the problem
The running directory is: 

`C:\Users\Locky\Google Диск\MachineLearning\wildml-cnn-nlp\cnn-text-classification-tf
`
But FileWriter writes summaries to 

`C:\Users\Locky\Google Р”РёСЃРє\MachineLearning\wildml-cnn-nlp\cnn-text-classification-tf
`
""Р”РёСЃРє"" doesn't make sense in Russian, and perhaps, comes from:

```
File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\summary\writer\event_file_writer.py"", line 70, in __init__
    compat.as_bytes(os.path.join(self._logdir, ""events"")))

```
I suspect that 'as_bytes' corrupts the string with Russian characters. Therefore, I think, this behaviour is a bug.

### Source code / logs

    ```
    # Output directory for models and summaries
        timestamp = str(int(time.time()))
        out_dir = os.path.abspath(os.path.join(os.path.curdir, ""runs"", timestamp))
        print(""Writing to {}\n"".format(out_dir))
       
        # Summaries for loss and accuracy
        loss_summary = tf.summary.scalar(""loss"", cnn.loss)
        acc_summary = tf.summary.scalar(""accuracy"", cnn.accuracy)

        # Train Summaries
        train_summary_op = tf.summary.merge([loss_summary, acc_summary, grad_summaries_merged])
        train_summary_dir = os.path.join(out_dir, ""summaries"", ""train"")
        train_summary_writer = tf.summary.FileWriter(train_summary_dir, sess.graph, flush_secs=5)

        # Dev summaries
        dev_summary_op = tf.summary.merge([loss_summary, acc_summary])
        dev_summary_dir = os.path.join(out_dir, ""summaries"", ""dev"")
        dev_summary_writer = tf.summary.FileWriter(dev_summary_dir, sess.graph)

```"
10954,Supervisor: SummaryWriter and Saver stop after some time,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04 / anaconda3 / python 3.6
- **TensorFlow installed from (source or binary)**: binary, (pip install tensorflow-gpu)
- **TensorFlow version (use command below)**: 1.2.0
- **Bazel version (if compiling from source)**: -
- **CUDA/cuDNN version**: 5.1
- **GPU model and memory**: 1080 / Titan X / K80
- **Exact command to reproduce**: - 

System information: [tf_env.txt](https://github.com/tensorflow/tensorflow/files/1091842/tf_env.txt)

### Describe the problem
Hey guys!

I get the problem on 3 different machines (all on ubuntu 16.04 and the tensorflow 1.2). All experiments were executed on a single machine with a single GPU.
To initialize a session I use a `tf.Supervisor` and `supervisor.managed_sessions()` with the default 
`summary_writer` and `saver`.  It works all well for up to 30mins - 1h30mis. But after that time the
`summary_writer` stops to write events, and the `saver` also stops to save the model parameters. However, the model still runs and produces valid outputs.

I also checked the python-log for tensorflow with level `DEBUG`. But all I got was some information logs, until it suddenly stops (see below).

Is there a way to track the `SVSummaryThread` / `SVTimerCheckpointThread`?

Thanks in advance and keep up the good work!
Cheers

### Source code / logs

```python
supervisor = tf.train.Supervisor(logdir=model_path, save_summaries_secs=60, global_step=model.global_step)
  sess_config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True), allow_soft_placement=True)

  with supervisor.managed_session(config=sess_config) as sess, sess.as_default():
    step_time, loss = 0.0, 0.0
    epoch = 0

    dataset_size = reader.train_size
    epoch_time = time.time()
    avg_lm = 0.

    while epoch < config[""max_epochs""]:
      sess.run(reader.iterator.initializer)

      while True:
        try:
          step_loss, step_lm = model.step(sess)
          avg_lm += step_lm / float(dataset_size) * float(model.batch_size)
          loss += step_loss / float(dataset_size) * float(model.batch_size)
        except tf.errors.OutOfRangeError:
          break

``` 

tensorflow python log:

```
017-06-21 15:57:33,386 - tensorflow - INFO - Starting queue runners.
2017-06-21 15:57:33,393 - tensorflow - INFO - global_step/sec: 0
2017-06-21 15:57:34,539 - tensorflow - INFO - Recording summary at step 0.
2017-06-21 15:58:33,385 - tensorflow - INFO - Recording summary at step 15264.
2017-06-21 15:58:33,391 - tensorflow - INFO - global_step/sec: 254.444
2017-06-21 15:59:33,384 - tensorflow - INFO - Recording summary at step 31239.
2017-06-21 15:59:33,391 - tensorflow - INFO - global_step/sec: 266.25
2017-06-21 16:00:33,385 - tensorflow - INFO - Recording summary at step 47206.
2017-06-21 16:00:33,391 - tensorflow - INFO - global_step/sec: 266.117
2017-06-21 16:01:33,385 - tensorflow - INFO - Recording summary at step 62157.
2017-06-21 16:01:33,391 - tensorflow - INFO - global_step/sec: 249.183
2017-06-21 16:02:33,384 - tensorflow - INFO - Recording summary at step 77621.
2017-06-21 16:02:33,391 - tensorflow - INFO - global_step/sec: 257.733
2017-06-21 16:03:33,383 - tensorflow - INFO - Recording summary at step 93657.
2017-06-21 16:03:33,391 - tensorflow - INFO - global_step/sec: 267.283
2017-06-21 16:04:33,391 - tensorflow - INFO - global_step/sec: 263.883
2017-06-21 16:04:33,545 - tensorflow - INFO - Recording summary at step 109493.
2017-06-21 16:05:33,391 - tensorflow - INFO - global_step/sec: 262.483
2017-06-21 16:05:33,558 - tensorflow - INFO - Recording summary at step 125242.
2017-06-21 16:06:33,383 - tensorflow - INFO - Recording summary at step 141072.
2017-06-21 16:06:33,391 - tensorflow - INFO - global_step/sec: 263.883
2017-06-21 16:07:33,384 - tensorflow - INFO - Recording summary at step 157265.
...
``` 



"
10953,Feature Request for BitwiseXOR for Tensor,"My project requests a new layer, which needs the new operator of Tensor to compute bitwiseXOR between input x and constant Key k.
E.g. x = 4 (bit form: 100), k = 7 (111), the bitwiseXOR(x, k) expects as 3 (011).

As far as I know, Tensor only has LogicXOR operator for bool type. Luckily, Tensorflow has the extended ability to have a new Op. However, I read the document in https://www.tensorflow.org/extend/adding_an_op, I can get the basic idea, but that is far from the implementation, maybe because of the lack of c++ knowledge. If you guys could help to implement the new operator that will be helpful. Then I can use that new Op of Tensor to build the new layers.
"
10952,Cannnot convert Graphs/Models via DarkFlow,"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/src/org/tensorflow/demo/DetectorActivity.java#L69
> // ./flow --model cfg/tiny-yolo-voc.cfg --load bin/tiny-yolo-voc.weights --savepb --verbalise=True

I already reported about this on **darkflow** git https://github.com/thtrieu/darkflow/issues/295 but still didn't get any reply

I shows next error:

`ERROR - Invalid argument: --verbalise=True`"
10950,TF binary incompatible to protobuf?,"I tried with TensorFlow 1.1.0 and 1.2.0, on Python 2.7 (and 3.5).
Note that I also asked about this [on StackOverflow](https://stackoverflow.com/questions/44455722/create-my-own-resource-types-tf-resource) but I think this might actually be a bug (either in the pip packaging of TF or protobuf or sth else), so I post it here.

Summary:

I think the protobuf pip package is binary incompatible with the TF pip package but I'm not exactly sure on this.

I try to write some own operator which creates some own `tf.resource`. I use the C++ header files from the TF pip install, and I link it to the `_message.so` file from the protobuf 3.3.0 pip package, because anything `tf.resource` related will need linking to protobuf.

My current code:


    // For Eigen::ThreadPoolDevice.
    #define EIGEN_USE_THREADS 1

    #include ""tensorflow/core/framework/op.h""
    #include ""tensorflow/core/framework/shape_inference.h""
    #include ""tensorflow/core/framework/op_kernel.h""
    #include ""tensorflow/core/framework/resource_mgr.h""
    #include ""tensorflow/core/framework/resource_op_kernel.h""
    #include ""tensorflow/core/framework/tensor.h""
    #include ""tensorflow/core/framework/tensor_shape.h""
    #include ""tensorflow/core/framework/types.h""
    #include ""tensorflow/core/platform/macros.h""
    #include ""tensorflow/core/platform/mutex.h""
    #include ""tensorflow/core/platform/types.h""

    using namespace tensorflow;

    REGISTER_OP(""ArrayContainerCreate"")
    .Attr(""T: type"")
    .Attr(""container: string = ''"")
    .Attr(""shared_name: string = ''"")
    .Output(""resource: resource"")
    .SetIsStateful()
    .SetShapeFn(shape_inference::ScalarShape)
    .Doc(R""doc(Array container, random index access)doc"");

    REGISTER_OP(""ArrayContainerGetSize"")
    .Input(""handle: resource"")
    .Output(""out: int32"")
    .SetShapeFn(shape_inference::ScalarShape)
    ;

    // https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/resource_mgr.h
    struct ArrayContainer : public ResourceBase {
      ArrayContainer(const DataType& dtype) : dtype_(dtype) {}

      string DebugString() override { return ""ArrayContainer""; }
      int64 MemoryUsed() const override { return 0; };

      mutex mu_;
      const DataType dtype_;

      int32 get_size() {
        mutex_lock l(mu_);
        return (int32) 42;
      }

    };

    // https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/resource_op_kernel.h
    class ArrayContainerCreateOp : public ResourceOpKernel<ArrayContainer> {
    public:
      explicit ArrayContainerCreateOp(OpKernelConstruction* context) : ResourceOpKernel(context) {
        OP_REQUIRES_OK(context, context->GetAttr(""T"", &dtype_));
      }

    private:
      virtual bool IsCancellable() const { return false; }
      virtual void Cancel() {}

      Status CreateResource(ArrayContainer** ret) override EXCLUSIVE_LOCKS_REQUIRED(mu_) {
        *ret = new ArrayContainer(dtype_);
        if(*ret == nullptr)
          return errors::ResourceExhausted(""Failed to allocate"");
        return Status::OK();
      }

      Status VerifyResource(ArrayContainer* ar) override {
        if(ar->dtype_ != dtype_)
          return errors::InvalidArgument(""Data type mismatch: expected "", DataTypeString(dtype_),
                                         "" but got "", DataTypeString(ar->dtype_), ""."");
        return Status::OK();
      }
  
      DataType dtype_;
    };
    REGISTER_KERNEL_BUILDER(Name(""ArrayContainerCreate"").Device(DEVICE_CPU), ArrayContainerCreateOp);

    class ArrayContainerGetSizeOp : public OpKernel {
    public:
      using OpKernel::OpKernel;

      void Compute(OpKernelContext* context) override {
        ArrayContainer* ar;
        OP_REQUIRES_OK(context, GetResourceFromContext(context, ""handle"", &ar));
        core::ScopedUnref unref(ar);

        int32 size = ar->get_size();
        Tensor* tensor_size = nullptr;
        OP_REQUIRES_OK(context, context->allocate_output(0, TensorShape({}), &tensor_size));
        tensor_size->flat<int32>().setConstant(size);
      }
    };
    REGISTER_KERNEL_BUILDER(Name(""ArrayContainerGetSize"").Device(DEVICE_CPU), ArrayContainerGetSizeOp);

I compile that. Note that I first got some `undefined symbol: _ZN6google8protobuf8internal26fixed_address_empty_stringE` error but I resolved that by adding these additional compiler flags:

    from google.protobuf.pyext import _message as msg
    lib = msg.__file__
    
    extra_compiler_flags = [
        ""-Xlinker"", ""-rpath"", ""-Xlinker"", os.path.dirname(lib),
        ""-L"", os.path.dirname(lib), ""-l"", "":"" + os.path.basename(lib)]

I read about that [here](https://github.com/tensorflow/tensorflow/issues/1419).

I end up with flags like these:

`-shared -O2 -std=c++11 -I /u/zeyer/.local/lib/python2.7/site-packages/tensorflow/include -I /usr/local/cuda-8.0/include -L /usr/local/cuda-8.0/lib64 -x cu -DGOOGLE_CUDA=1 -Xcompiler -fPIC -D_GLIBCXX_USE_CXX11_ABI=0 TFArrayContainer.cc -o TFArrayContainer.so -Xlinker -rpath -Xlinker /u/zeyer/.local/lib/python2.7/site-packages/google/protobuf/pyext -L /u/zeyer/.local/lib/python2.7/site-packages/google/protobuf/pyext -l :_message.so`

Then I load that as a module via `tf.load_op_library`.

Then, I have this Python code:

    handle = mod.array_container_create(T=tf.int32)
    size = mod.array_container_get_size(handle=handle)

When I try to evaluate `size`, I get the error:


    InvalidArgumentError (see above for traceback): Trying to access resource located in device 14ArrayContainer from device /job:localhost/replica:0/task:0/cpu:0
             [[Node: ArrayContainerGetSize = ArrayContainerGetSize[_device=""/job:localhost/replica:0/task:0/cpu:0""](array_container)]]

The device name (`14ArrayContainer`) somehow seem to be messed up. Why is that? What is the problem with the code?

For some more testing, I added this additional code in the `ArrayContainerCreateOp`:

        ResourceHandle rhandle = MakeResourceHandle<ArrayContainer>(context, cinfo_.container(), cinfo_.name());
        printf(""created. device: %s\n"", rhandle.device().c_str());
        printf(""container: %s\n"", rhandle.container().c_str());
        printf(""name: %s\n"", rhandle.name().c_str());
        printf(""actual device: %s\n"", context->device()->attributes().name().c_str());
        printf(""actual name: %s\n"", cinfo_.name().c_str());

This gives me the output:

    created. device: 14ArrayContainer
    container: 14ArrayContainer
    name: 14ArrayContainer
    actual device: /job:localhost/replica:0/task:0/cpu:0
    actual name: _2_array_container

So clearly, there is some of the problem.

This looks like something is messed up with the protobuf? Maybe I am linking the wrong lib? But I have not found which lib to link instead.
"
10888,IOS Expected namespace tensorflow::ops,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
    No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
    OS X 10.11.6
- **TensorFlow installed from (source or binary)**:
    binary(pip install)
- **TensorFlow version (use command below)**:
    1.1.0 CPU Only
- **Bazel version (if compiling from source)**:
    0.4.5

### Describe the problem
I want to use pb file in IOS.And I must use `tensorflow::ops::reshape` and ` tensorflow::ops::argmax ` api.But when I add ` using namespace tensorflow::ops; `I get a error --` Expected namespace name `.My TensorFlow-experimental come from Pod.  
How to add namespace tensorflow::ops...


"
10875,how do i retrain net after quantization?,"i had used tensorflow tool, quantization_graph.py, to quantize my graph successfully. how do i retrain this net after quantization? since the tool requires using freeze_graph.py to convert variables in graph to constant. 

BTW, can i set up my graph using quantize ops, and train from the scratch? if can, is there any example?

"
10874,where is a complete API document,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorflow/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
10873,Splitting model and using threads.,"Hello everyone. I am new to tensorflow and had a doubt. How can I split a pre trained model into two parts and then load it onto the GPU simultaneously using different threads ? Is it possible, if yes, please guide me for the same. Thanks :) :)  "
10872,"[win7-64bit,Anaconda,tensorflow 1.2.0,chrome]Tensorboard : No scalar was found ","I can't see any data. It turned out to be : No scalar

 was found 

when I run the tensorboard ,there is no error or warning

**Environment info**

Windows 7 64-bit
Anaconda Python 3.5
Tensoflow installed from binary pip package
tensorflow version:1.2.0
Browser: Chrome 58

**About the code**

I just run the example code mnist_with_summries.py

it is in D:\Anaconda\Lib\site-packages\tensorflow\examples\tutorials\mnist\mnist_with_summaries.py

**What have you tried?**

I can see a log file called events.out.tfevents.*  in the folder I set. The file is about 16Mb big.

I call tensorboard --logdir=/tmp/tensorflow/mnist/logs/mnist_with_summaries --debug and I can verify the log dir is correct.

On the browser I can't see any data or graph is shown.

If I call tensorboard --inspect --logdir=/tmp/tensorflow/mnist/logs/mnist_with_summaries  It shows how  the tfevent file contains.
"
10870, tensorflow-1.2.0  import tensorflow  Segmentation fault,"hi, 
I installed tensorflow-1.2.0  in my machine, and met a segment fault as below.

linux-swfm:~/workarea/test> python
Python 2.7.13 (default, Jun 20 2017, 20:03:45) 
[GCC 4.9.2] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
Segmentation fault

my system is : USE Linux Enterprise Server 11 SP3.
cuda sdk version is 8.0 and cudnn is 6.0.
my command to build tensorflow is below : 
     bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
"
10869,GPU option allow_growth and CUDA_ERROR_OUT_OF_MEMORY,"Hi,

I tried to build a LSTM model on 30G data with a aws machine p2.xlarge with 60G memory and a gpu with 12G memory. The performance is inconsistent. Sometimes we get it to work but sometimes we encounter CUDA_ERROR_OUT_OF_MEMORY. The answer at https://stackoverflow.com/questions/39465503/cuda-error-out-of-memory-in-tensorflow suggests setting a gpu option allow_growth to False. It refers to the source code where the change could be made:
https://github.com/tensorflow/tensorflow/blob/r0.10/tensorflow/core/protobuf/config.proto

But in the code I notice the only line containing ""allow_growth"" is this:
  bool allow_growth = 4;
It looks strange to me. Could you explain why allow_growth is assigned a integer value 4? "
10867,C++ api in Debug x64 mode not building for VS2015,"Hi,

I'm not sure if this is expected behaviour or a problem with the solution file generated by CMake, so my apologies if I'm writing in the wrong place.

I'm trying to build Tensorflow C++ API on Windows using VS2015, and so far I didn't have problems to build Release x64 binaries, which just required me to ensure that the toolset for 64 bits is in use when creating the def file (dump bin.exe and undname.exe in particular).

I could verify that the build works as expected, being able to load models saved in Python and perform inference successfully.

However, when building the debug x64 version of the .dll, I'm being blocked by the following error:

```
104>  tensorflow_static.vcxproj -> D:\out\Debug\tensorflow_static.lib
104>  symbols=1016688, taken=140782, dupes=3472
105>------ Build started: Project: tensorflow, Configuration: Debug x64 ------
105>  Building Custom Rule D:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt
105>  CMake does not need to re-run because D:/out/CMakeFiles/generate.stamp is up-to-date.
105>LINK : fatal error LNK1189: library limit of 65535 objects exceeded
========== Build: 104 succeeded, 1 failed, 1 up-to-date, 0 skipped ==========
```

Is there any workaround for this issue? Has anyone managed to build the debug version of the library? Is it possible at all?

From what I could google around, this linker issue is not easy to overcome, so feedback is most welcome."
10866,"word2vec error sequence index must be integer, not 'slice'","Im tring to run the code :
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/word2vec/word2vec_basic.py#L117

But get the exception on the Line 117 
as 
sequence index must be integer, not 'slice'

I want to ask if this really a problem in the tensorflow file or its just me facing this error."
10864,Feature Request: Sequence to Sequence Bucketing/Batching,"### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS Sierra Version 10.12.5
- **TensorFlow version (use command below)**: v1.2.0-rc2-21-g12f033d 1.2.0

### Describe the feature
`tf.contrib.training.bucket_by_sequence_length()` and `tf.contrib.training.bucket()` are useful for creating batches of similar-length sequences for training dynamic RNNs. I'd like to be able to create batches of similar-length `(input sequence, output sequence)` pairs to train Sequence to Sequence models with dynamic encoders and dynamic decoders. I may be wrong, but as far as I can tell, there is no easy way to adapt either of the current bucketing functions to create batches like this. The seq2seq translate [tutorial](https://github.com/tensorflow/models/blob/master/tutorials/rnn/translate/seq2seq_model.py) relies on a method `def get_batch(self, data, bucket_id)` to get such batches, but I think it'd be nicer if TensorFlow had a built-in function that didn't rely on a custom implementation and that integrated nicely with FIFOQueues for reading data."
10862,Bug: MultiRNNCell.state_size is a tuple,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.2
- **Bazel version (if compiling from source)**: n/a
- **CUDA/cuDNN version**: 8.0
- **GPU model and memory**: 1080 Ti
- **Exact command to reproduce**: see below

### Describe the problem

Version 1:

The follow code will return LSTMStateTuple with `h` and `c`:

```python

        enc_cell = tf.contrib.rnn.LSTMCell(hidden_dim)

        enc_inp_len = np.array([seq_length_in for _ in range(batch_size)])

        ((encoder_fw_outputs,
          encoder_bw_outputs),
         (encoder_fw_final_state,
          encoder_bw_final_state)) = (
            tf.nn.bidirectional_dynamic_rnn(cell_fw=enc_cell,
                                            cell_bw=enc_cell,
                                            inputs=enc_inp,
                                            sequence_length=enc_inp_len,
                                            dtype=tf.float32)
            )
        encoder_outputs = tf.concat((encoder_fw_outputs, encoder_bw_outputs), 2)

        encoder_final_state_c = tf.concat(
            (encoder_fw_final_state.c, encoder_bw_final_state.c), 1)

        encoder_final_state_h = tf.concat(
            (encoder_fw_final_state.h, encoder_bw_final_state.h), 1)

        encoder_final_state = tf.contrib.rnn.LSTMStateTuple(
            c=encoder_final_state_c,
            h=encoder_final_state_h
        )
```

However, if I run the following MultiCellRNN:

```python
        enc_cells = []
        for i in range(0, encoder_depth):
            with tf.variable_scope('enc_RNN_{}'.format(i)):
                cell = tf.contrib.rnn.GRUCell(hidden_dim)  # Or LSTMCell(hidden_dim)
                cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=1.0-dropout)
                enc_cells.append(cell)
        enc_cell = tf.contrib.rnn.MultiRNNCell(enc_cells)

        ((encoder_fw_outputs,
          encoder_bw_outputs),
         (encoder_fw_final_state,
          encoder_bw_final_state)) = (
            tf.nn.bidirectional_dynamic_rnn(cell_fw=enc_cell,
                                            cell_bw=enc_cell,
                                            inputs=enc_inp,
                                            sequence_length=enc_inp_len,
                                            dtype=tf.float32)
            )

        # encoder_fw_final_state is a Tensor from the .c part of LSTMStateTuple
```

It will return state tensor(just the `c` part, not the `h` activation)"
10861,new release for tensorflow 1.2 release,Any plans for a 1.2 release?
10860,control_dependencies possibly broken,"Hi all, I've been playing with control_dependencies in the latest stable version, and I get different results to version 1.0.1. The code below is adapted from the TF Adam optimiser, which might be affected as well.

The code I ran is
```
import tensorflow as tf
import numpy as np

graph = tf.Graph()

with graph.as_default():
    x = tf.Variable(1.0, dtype=tf.float32, name='x')    
    y = tf.Variable(10., dtype=tf.float32, name='y')
    update_x = tf.assign(x, y)
    with tf.control_dependencies([update_x]):
        update_y = tf.assign(y, x * y)
    update_op = tf.group(update_x, update_y)
    init_op = tf.global_variables_initializer()
print tf.__version__

res = []
for _ in range(10):
    if 'sess' in locals():
        locals()['sess'].close()
    if 'sess' in globals():
        globals()['sess'].close()

    sess = tf.Session(graph=graph)
    sess.run(init_op)
    res += [sess.run([update_op, x, y])]
print np.mean([r[-1] for r in res])
print np.mean([r[-2] for r in res])
```

And get results 
```
1.0.1
100.0
10.0
```
vs
```
1.2.0
28.0
5.5
```
suggesting that the control dependencies are not used as expected in version 1.2.0. 
Can anyone spot any mistakes in the way I use the control dependencies?
Cheers,
Yarin"
10857,No way to freeze fused BN stats,"When fine-tuning networks trained with BN sometimes we want to freeze and use the accumulated moving averages while allowing the gradients to be backpropagated through the BN layer, but currently there is no way of doing so with fused BN, since when is_training = False the layer gives erroneous gradients. Of course, we could use the batch statistics from the new task to accumulate the stats, but it isn't possible in the case of batch_size = 1.

I understand that due to the nature of the CuDNN kernel it might be hard to implement such feature, but a fused Batch Renorm layer could be a decent compromise, as it uses the moving averages when training as well as during inference."
10856,Support unknown dimension in tf.SparseTensor,"In doing development calling API (tf.SparseTensor on release 1.1), I got the following error. It appears to be caused by unknown dimension ""batch"" which is present in n_indices, n_val, obj_ref.get_shape(). 

Additionally, I wonder if we could have a list of APIs not supporting unknown dimension ....

```
  File ""/nlp/workspace/nlp-models/tf-seq2seq/seq2seq/..../..../...._model.py"", line 362, in _put_new_memory
    delta = tf.SparseTensor(n_indices, n_val, obj_ref.get_shape())
  File ""/home/..../workspace/prun/seq2seq/lib/python3.5/site-packages/tensorflow/python/framework/sparse_tensor.py"", line 127, in __init__
    dense_shape, name=""dense_shape"", dtype=dtypes.int64)
  File ""/home/..../workspace/prun/seq2seq/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 639, in convert_to_tensor
    as_ref=False)
  File ""/home/..../workspace/prun/seq2seq/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 704, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/home/..../workspace/prun/seq2seq/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py"", line 131, in _tensor_shape_tensor_conversion_function
    ""Cannot convert a partially known TensorShape to a Tensor: %s"" % s)
ValueError: Cannot convert a partially known TensorShape to a Tensor: (?, 16, 30)
```


"
10855,Differentiate Variable (Model Parameters) and Mutable Tensor,"In the current tensorflow, the concept of variables is about same as model parameters and mutable tensors. I would like to see them separate out. For example, it seems perfect legit to me to use tf.scatter_nd_update to update a tensor. However all scatter APIs require ""mutable tensor"". That made operations on tensors with ""batch"" parameter close to impossible.  Having the concept of mutable tensor will help a lot.






"
10854,attribute error when setting PredictionType.MULTIPLE_VALUE in Dynamic RNN Estimator,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorflow/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
10853,Mismatched delete in mkl_tfconv_op.cc,"tensorflow\core\kernels\mkl_tfconv_op.cc line 120
delete in_sizes;

should be: delete [] in_sizes;"
10852,GTX 1080 Ti Cuda Launch Failed,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorflow/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
Source
- **TensorFlow version (use command below)**:
('v1.1.0-rc2-9-gb7f85a7', '1.1.0-rc1')
- **Bazel version (if compiling from source)**:
Bazel Release 0.5.0

- **CUDA/cuDNN version**:
Cuda 8.0 cuDNN 8.0
- **GPU model and memory**:
GTX 1080Ti - 11GB memory
- **Exact command to reproduce**:

bazel-bin/inception/flowers_train \
  --train_dir=""${TRAIN_DIR}"" \
  --data_dir=""${DATA_DIR}"" \
  --pretrained_model_checkpoint_path=""${MODEL_PATH}"" \
  --fine_tune=True \
  --initial_learning_rate=0.001 \
  --input_queue_memory_factor=2

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

[tf_env.txt](https://github.com/tensorflow/tensorflow/files/1088718/tf_env.txt)


You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

When fine tuning inception v3 model using the flowers data script, on custom data, during retraining I see the following error:

2017-06-19 23:46:32.549857: step 5300, loss = 1.40 (61.9 examples/sec; 0.517 sec/batch)
2017-06-19 23:46:39.510009: step 5310, loss = 1.43 (64.2 examples/sec; 0.499 sec/batch)
2017-06-19 23:46:44.667435: step 5320, loss = 1.55 (64.3 examples/sec; 0.498 sec/batch)
2017-06-19 23:46:46.691129: E tensorflow/stream_executor/cuda/cuda_driver.cc:1067] could not synchronize on CUDA context: CUDA_ERROR_LAUNCH_FAILED :: No stack trace available
2017-06-19 23:46:46.691129: E tensorflow/stream_executor/cuda/cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_FAILED
2017-06-19 23:46:46.691162: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:203] Unexpected Event status: 1
2017-06-19 23:46:46.691165: F tensorflow/core/common_runtime/gpu/gpu_util.cc:370] GPU sync failed
./start_image.sh: line 60: 27406 Aborted                 (core dumped) bazel-bin/inception/flowers_train --train_dir=""${TRAIN_DIR}"" --data_dir=""${DATA_DIR}"" --pretrained_model_checkpoint_path=""${MODEL_PATH}"" --fine_tune=True --initial_learning_rate=0.001 --input_queue_memory_factor=2

I changed the num classes and num examples per epoch as follows:
 7    def num_classes(self):
      8      """"""Returns the number of classes in the data set.""""""
      9 -    return 5
     10 +    return 21
     11  
     12    def num_examples_per_epoch(self):
     13      """"""Returns the number of examples in the data subset.""""""
     14      if self.subset == 'train':
     15 -      return 3170
     16 +      return 6342
     17      if self.subset == 'validation':
     18 -      return 500
     19 +      return 1576

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
10851,ValueError: Attempt to reuse RNNCell - reuse flag does not work,"### System information

-  Linux Ubuntu 16.04
- tensorflow-gpu==1.1.0

I am getting this error in quite a complex graph, but I can reproduce it with a minimal (but hopefully representative) example below:

```
import tensorflow as tf
import numpy as np


class Controller(object):
    def __init__(self, batch_size, input_size):

        self.batch_size = batch_size
        self.input_size = input_size

        with tf.name_scope(""controller""):
            self.network_vars()

            self.nn_output_size = None
            with tf.variable_scope(""shape_inference""):
                self.nn_output_size = self.get_nn_output_size()

    def network_vars(self):
        self.lstm_cell = tf.contrib.rnn.BasicLSTMCell(256)
        self.state = self.lstm_cell.zero_state(self.batch_size, tf.float32)

    def network_op(self, x, state):
        x = tf.convert_to_tensor(x)
        return self.lstm_cell(x, state)

    def get_state(self):
        return self.state

    def update_state(self, new_state):
        return tf.no_op()

    def process_input(self, x, state=None):
        nn_output, nn_state = self.network_op(x, state)
        return nn_output, nn_state

    def get_nn_output_size(self):
        input_tensor = np.zeros([self.batch_size, self.input_size], dtype=np.float32)
        output_vector, _ = self.network_op(input_tensor, self.get_state())
        shape = output_vector.get_shape().as_list()

        if len(shape) > 2:
            raise ValueError(""Expected the neural network to output a 1D vector"")
        else:
            return shape[1]


class DNC(object):
    def __init__(self, batch_size, input_size):
        self.batch_size = batch_size
        self.input_size = input_size
        self.controller = Controller(batch_size, input_size)
        self.build_graph()

    def _step_op(self, x, controller_state=None):
        _, nn_state = self.controller.process_input(x, controller_state)
        return [nn_state[0], nn_state[1]]

    def _loop_body(self, t, controller_state):
        x = np.random.random_sample((self.batch_size, self.input_size)).astype(np.float32)
        output_list = self._step_op(x, controller_state)
        new_controller_state = tf.contrib.rnn.LSTMStateTuple(output_list[0], output_list[1])
        return t+1, new_controller_state

    def build_graph(self):
        controller_state = self.controller.get_state()
        if not isinstance(controller_state, tf.contrib.rnn.LSTMStateTuple):
            controller_state = tf.contrib.rnn.LSTMStateTuple(controller_state[0], controller_state[1])

        with tf.variable_scope(""sequence_loop"") as scope:
            time = tf.constant(0, dtype=tf.int32)

            final_results = tf.while_loop(
                cond=lambda time, *_: time < 50,
                body=self._loop_body,
                loop_vars=(time, controller_state),
                parallel_iterations=32,
                swap_memory=True
            )

if __name__ == ""__main__"":
    batch_size = 32
    input_size = 10
    dnc = DNC(batch_size, input_size)
```

The traceback of the issue is:
```
francescoferroni@francescoferroni:~$ python controller.py 
Traceback (most recent call last):
  File ""controller.py"", line 83, in <module>
    dnc = DNC(batch_size, input_size)
  File ""controller.py"", line 52, in __init__
    self.build_graph()
  File ""controller.py"", line 77, in build_graph
    swap_memory=True
  File ""/home/francescoferroni/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2623, in while_loop
    result = context.BuildLoop(cond, body, loop_vars, shape_invariants)
  File ""/home/francescoferroni/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2456, in BuildLoop
    pred, body, original_loop_vars, loop_vars, shape_invariants)
  File ""/home/francescoferroni/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2406, in _BuildLoop
    body_result = body(*packed_vars_for_body)
  File ""controller.py"", line 60, in _loop_body
    output_list = self._step_op(x, controller_state)
  File ""controller.py"", line 55, in _step_op
    _, nn_state = self.controller.process_input(x, controller_state)
  File ""controller.py"", line 33, in process_input
    nn_output, nn_state = self.network_op(x, state)
  File ""controller.py"", line 24, in network_op
    return self.lstm_cell(x, state)
  File ""/home/francescoferroni/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py"", line 235, in __call__
    with _checked_scope(self, scope or ""basic_lstm_cell"", reuse=self._reuse):
  File ""/home/francescoferroni/anaconda3/lib/python3.6/contextlib.py"", line 82, in __enter__
    return next(self.gen)
  File ""/home/francescoferroni/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py"", line 77, in _checked_scope
    type(cell).__name__))
ValueError: Attempt to reuse RNNCell <tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.BasicLSTMCell object at 0x7ff4075754e0> with a different variable scope than its first use.  First use of cell was with scope 'shape_inference/basic_lstm_cell', this attempt is with scope 'sequence_loop/basic_lstm_cell'.  Please create a new instance of the cell if you would like it to use a different set of weights.  If before you were using: MultiRNNCell([BasicLSTMCell(...)] * num_layers), change to: MultiRNNCell([BasicLSTMCell(...) for _ in range(num_layers)]).  If before you were using the same cell instance as both the forward and reverse cell of a bidirectional RNN, simply create two instances (one for forward, one for reverse).  In May 2017, we will start transitioning this cell's behavior to use existing stored weights, if any, when it is called with scope=None (which can lead to silent model degradation, so this error will remain until then.)
```

If I use tensorflow 1.0 rather than 1.1 it causes no issues.
```
francescoferroni@francescoferroni:~$ source Repositories/tfr10/bin/activate
(tfr10) francescoferroni@francescoferroni:~$ python controller.py 
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
(tfr10) francescoferroni@francescoferroni:~$ 
```

For the new tensorflow version, I have tried to add a reuse=True flag, as per [#9401](https://github.com/tensorflow/tensorflow/issues/9401), when defining the LSTM cell, but then I  get another error:
`ValueError: Variable shape_inference/basic_lstm_cell/weights does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?
`

Any help would be greatly appreciated.

Best,
Francesco"
10847,Something error when I run  iris_monitors.py ,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**:1.0.1
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:import tensorflow

### Describe the problem
When I run iris_monitors.py in Pycharm file(https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/monitors/iris_monitors.py), It has an error :
Traceback (most recent call last):
  File ""F:/temp/Python/temp.py"", line 92, in <module>
    tf.app.run()
  File ""C:\software\Python\Python35\lib\site-packages\tensorflow\python\platform\app.py"", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""F:/temp/Python/temp.py"", line 35, in main
    filename=IRIS_TRAINING, target_dtype=np.int, features_dtype=np.float)
  File ""C:\software\Python\Python35\lib\site-packages\tensorflow\contrib\learn\python\learn\datasets\base.py"", line 47, in load_csv_with_header
    header = next(data_file)
StopIteration

### Source code / logs
C:\software\Python\Python35\python.exe F:/temp/Python/temp.py
Traceback (most recent call last):
  File ""F:/temp/Python/temp.py"", line 92, in <module>
    tf.app.run()
  File ""C:\software\Python\Python35\lib\site-packages\tensorflow\python\platform\app.py"", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""F:/temp/Python/temp.py"", line 35, in main
    filename=IRIS_TRAINING, target_dtype=np.int, features_dtype=np.float)
  File ""C:\software\Python\Python35\lib\site-packages\tensorflow\contrib\learn\python\learn\datasets\base.py"", line 47, in load_csv_with_header
    header = next(data_file)
StopIteration

Process finished with exit code 1
"
10845,Keras Dropout layer changes results with dropout=0.0,"I am using the current version pypi 1.2.0, but also found this ""problem"" in the master I compiled about two weeks ago. I am running Gentoo linux and tensorflow is installed in an virtualenv.

Maybe I am misunderstanding the concept of a dropout layer, but when I add a Dropout-Layer with 0% dropout, it still alters my results:

from reuters classification example:
```
model = Sequential()
model.add(Dense(128, input_shape=(max_words,)))
model.add(Activation('relu'))
model.add(Dropout(0.0))
model.add(Dense(num_classes))
model.add(Activation('softmax'))
```
After 3 epochs I get:
```
Epoch 3/3
  32/8083 [..............................] - ETA: 0s - loss: 0.7321 - acc: 0.8125
 512/8083 [>.............................] - ETA: 0s - loss: 0.8597 - acc: 0.8145
 928/8083 [==>...........................] - ETA: 0s - loss: 0.8689 - acc: 0.8017
1344/8083 [===>..........................] - ETA: 0s - loss: 0.9041 - acc: 0.7954
1792/8083 [=====>........................] - ETA: 0s - loss: 0.8979 - acc: 0.7969
2304/8083 [=======>......................] - ETA: 0s - loss: 0.8896 - acc: 0.7969
2784/8083 [=========>....................] - ETA: 0s - loss: 0.8764 - acc: 0.7989
3168/8083 [==========>...................] - ETA: 0s - loss: 0.8678 - acc: 0.8018
3648/8083 [============>.................] - ETA: 0s - loss: 0.8666 - acc: 0.8021
4096/8083 [==============>...............] - ETA: 0s - loss: 0.8656 - acc: 0.8013
4576/8083 [===============>..............] - ETA: 0s - loss: 0.8536 - acc: 0.8018
5120/8083 [==================>...........] - ETA: 0s - loss: 0.8409 - acc: 0.8033
5664/8083 [====================>.........] - ETA: 0s - loss: 0.8369 - acc: 0.8054
6048/8083 [=====================>........] - ETA: 0s - loss: 0.8385 - acc: 0.8042
6592/8083 [=======================>......] - ETA: 0s - loss: 0.8431 - acc: 0.8025
7136/8083 [=========================>....] - ETA: 0s - loss: 0.8448 - acc: 0.8028
7680/8083 [===========================>..] - ETA: 0s - loss: 0.8490 - acc: 0.8025
8083/8083 [==============================] - 0s - loss: 0.8473 - acc: 0.8032 - val_loss: 0.9853 - val_acc: 0.7920
  32/2246 [..............................] - ETA: 0s
1568/2246 [===================>..........] - ETA: 0s
Test score: 0.934106262688
Test accuracy: 0.777382012467
```
and without a dropout layer:
```
Epoch 3/3
  32/8083 [..............................] - ETA: 0s - loss: 0.5419 - acc: 0.8750
 544/8083 [=>............................] - ETA: 0s - loss: 0.4974 - acc: 0.8842
1088/8083 [===>..........................] - ETA: 0s - loss: 0.5429 - acc: 0.8722
1664/8083 [=====>........................] - ETA: 0s - loss: 0.5568 - acc: 0.8762
2208/8083 [=======>......................] - ETA: 0s - loss: 0.5523 - acc: 0.8773
2752/8083 [=========>....................] - ETA: 0s - loss: 0.5494 - acc: 0.8790
3296/8083 [===========>..................] - ETA: 0s - loss: 0.5437 - acc: 0.8799
3808/8083 [=============>................] - ETA: 0s - loss: 0.5420 - acc: 0.8792
4352/8083 [===============>..............] - ETA: 0s - loss: 0.5446 - acc: 0.8750
4896/8083 [=================>............] - ETA: 0s - loss: 0.5405 - acc: 0.8754
5440/8083 [===================>..........] - ETA: 0s - loss: 0.5381 - acc: 0.8756
5984/8083 [=====================>........] - ETA: 0s - loss: 0.5392 - acc: 0.8755
6528/8083 [=======================>......] - ETA: 0s - loss: 0.5459 - acc: 0.8738
7104/8083 [=========================>....] - ETA: 0s - loss: 0.5482 - acc: 0.8740
7648/8083 [===========================>..] - ETA: 0s - loss: 0.5527 - acc: 0.8730
8083/8083 [==============================] - 0s - loss: 0.5525 - acc: 0.8727 - val_loss: 0.9100 - val_acc: 0.7898
  32/2246 [..............................] - ETA: 0s
1664/2246 [=====================>........] - ETA: 0s
Test score: 0.883166806993
Test accuracy: 0.792074799644
```

While the validation and test results are quite similar, the model without dropout overfits much more. 

Also, if I set dropout to 1.0, the model should not be able to learn anything (as everything is dropped):
```
Epoch 3/3
  32/8083 [..............................] - ETA: 0s - loss: 0.8313 - acc: 0.7812
 576/8083 [=>............................] - ETA: 0s - loss: 0.7561 - acc: 0.8351
1120/8083 [===>..........................] - ETA: 0s - loss: 0.8669 - acc: 0.8000
1632/8083 [=====>........................] - ETA: 0s - loss: 0.8805 - acc: 0.7978
2176/8083 [=======>......................] - ETA: 0s - loss: 0.8780 - acc: 0.7973
2720/8083 [=========>....................] - ETA: 0s - loss: 0.8742 - acc: 0.7978
3264/8083 [===========>..................] - ETA: 0s - loss: 0.8693 - acc: 0.7990
3808/8083 [=============>................] - ETA: 0s - loss: 0.8616 - acc: 0.7996
4352/8083 [===============>..............] - ETA: 0s - loss: 0.8565 - acc: 0.8001
4896/8083 [=================>............] - ETA: 0s - loss: 0.8480 - acc: 0.8025
5440/8083 [===================>..........] - ETA: 0s - loss: 0.8499 - acc: 0.8007
5984/8083 [=====================>........] - ETA: 0s - loss: 0.8492 - acc: 0.8025
6560/8083 [=======================>......] - ETA: 0s - loss: 0.8498 - acc: 0.8023
7136/8083 [=========================>....] - ETA: 0s - loss: 0.8505 - acc: 0.8014
7648/8083 [===========================>..] - ETA: 0s - loss: 0.8511 - acc: 0.8010
8083/8083 [==============================] - 0s - loss: 0.8484 - acc: 0.8021 - val_loss: 0.9544 - val_acc: 0.7909
  32/2246 [..............................] - ETA: 0s
1536/2246 [===================>..........] - ETA: 0s
Test score: 0.92991881655
Test accuracy: 0.780498664292
```"
10844,"compiling tensorflow/cc/example/example.cc with error ""You must define TF_LIB_GTL_ALIGNED_CHAR_ARRAY for your compiler."" in Windows 10 Visualstudio 2015"," Hi I am newbie of tensorflow.


 I wanna use tensorflow through C/C++ api on visual studio 2015.

 I have built tensorflow (library?) described in below link with Cmake.

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/cmake/README.md

 
after Cmake,

 I tried to build  ""tensorflow/cc/example/example.cc""
 but occured error

	C1189	#error:  ""You must define TF_LIB_GTL_ALIGNED_CHAR_ARRAY for your compiler.""	tensortest	d:\temp\tensorflow\tensorflow\core\lib\gtl\manual_constructor.h	97	


then  failed to build example.

 What is that mean and how to define TF_LIB_GTL_ALIGNED_CHAR_ARRAY in Visualstudio 2015?

 


 thank you in advance.


/GS /GL /analyze- /W3 /Gy /Zc:wchar_t /I""D:\temp\tensorflow\tensorflow\contrib\cmake\build\protobuf\src\protobuf\src"" /I""D:\temp\tensorflow"" /I""D:\temp\tensorflow\tensorflow\contrib\cmake\build\eigen\src\eigen"" /I""D:\temp\tensorflow\tensorflow\contrib\cmake\build"" /Zi /Gm- /O2 /sdl /Fd""Release\vc140.pdb"" /Zc:inline /fp:precise /D ""WIN32"" /D ""NDEBUG"" /D ""_CONSOLE"" /D ""_UNICODE"" /D ""UNICODE"" /errorReport:prompt /WX- /Zc:forScope /Gd /Oy- /Oi /MD /Fa""Release\"" /EHsc /nologo /Fo""Release\"" /Fp""Release\tensortest.pch"" 
"
10843,"Compiling tensorflow fails with error: no matching function for call to 'Permute(tensorflow::gtl::ArraySlice<long long int>&, const std::vector<llvm::Value*, std::allocator<llvm::Value*> >&)'","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Arch Linux
- **TensorFlow installed from (source or binary)**: Trying to compile from source
- **TensorFlow version (use command below)**: 1.2.0 release
- **Bazel version (if compiling from source)**: 0.5.1
- **CUDA/cuDNN version**: 8.0.61/6.0.21
- **GPU model and memory**: 1080 Ti 11 GB
- **Exact command to reproduce**: The PKGBUILD https://paste.xinu.at/XaChkb/
If you are not familiar with this format, basically just execute `prepare()` and then `build()`.

### Describe the problem
I'm the packager for the official tensorflow package in Arch Linux and I was trying to update 1.1.0 to 1.2.0 and it fails to build. Full build log attached. We always build in clean chroots.

llvm 4.0, gcc 7.1.1

### Source code / logs
[log.txt](https://github.com/tensorflow/tensorflow/files/1087523/log.txt)
"
10842,Feature request: add more options to Luong attention,"Currently, the best results of the Luong attention paper [(Minh-Thang Luong, Hieu Pham, Christopher D. Manning. ""Effective Approaches to Attention-based Neural Machine Translation."" EMNLP 2015.)](https://arxiv.org/abs/1508.04025) cannot be reproduced with the implementation of `tf.contrib.seq2seq.LuongAttention`. Features that are missing:

- **Local attention**: attend to a window of time steps, rather than to all of the time steps of the encoder output (global attention). The window size should be a hyperparameter that the user can tune.
- **Different scoring functions**: currently, the scoring function is limited to a dot products between each encoder output and the decoder output. The paper shows better results with ""general"" scoring (all of the encoder outputs are multiplied by one learnable matrix) and also explores the option of using Bahdanau-like scoring (concatenate and multiply by a learnable matrix, then apply tanh and take a dot product with a learnable vector).
- **Predictive alignments**: while the probability function can be replaced, it would be nice to add predictive alignment as a function, and make the implementation of both monotonic and predictive alignments behave well with local attention limited to a time window (changes shape of learnables).
- **Input-feeding approach**: (please correct me in this one if I am mistaken) the current implementation is missing the final step that computes a prediction by concatenating the context vector with the decoder output, weights them and applies tanh (let this be `s_t=tanh(W [c_t; h_t])`). Passing `s_t` through a softmax layer gives the prediction distribution, but passing it as is to the next input improved performance in the paper.

On a sidenote: it also seems to be that there is no difference in the key and query vectors between the Bahdanau and Luong attention mechanisms, when there should be. Bahdanau attention has a computation pathway starting from the previous decoder output `h_{t-1} -> a_t -> c_t -> h_t`, while Luong attention starts from the current output `h_t -> a_t -> c_t -> s_t`."
10838,Compiling TensorFlow gives 3k lines of warnings!,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04.2 (4.8 kernel)
- **TensorFlow installed from (source or binary)**: Compiling TF from Source
- **TensorFlow version (use command below)**: 1.2.0
- **Bazel version (if compiling from source)**: 0.5.1
- **CUDA/cuDNN version**: CUDA 8.0, CuDNN 5.1
- **GPU model and memory**: 1050Ti 4GB (Notebook version) (Intel i5-7300hq CPU)
- **Exact command to reproduce**: Compiling from source [following documentation](https://www.tensorflow.org/install/install_sources).

### Describe the problem
I compiled tensorflow from source. The process finished successfully and the binary managed to install and run successfully. What seems strange is that during the process I got ~3k lines of warnings. I am linking to them at the end of the issue. I am wondering if that's expected behavior or indication of a (small or _not_so_small_?) problem.

One thing that may affect this is bazel installation. I followed [Bazel Installation Instructions](https://bazel.build/versions/master/docs/install.html) and used the recommended apt method. This led to me running into [this](https://github.com/tensorflow/tensorflow/issues/8092) issue. Installing openjdk-8-jdk on top of the ibm-java80-jdk as suggested in a [comment](https://github.com/tensorflow/tensorflow/issues/8092#issuecomment-304957009) solves the problem (although I am not sure how much technical debt this solution caries, which may have manifested in some of the warnings produced during compilation).

### Source code / logs
**Configuration Script options:**
```{shell}
$ ./configure
Please specify the location of python. [Default is /usr/bin/python]: /usr/bin/python3
Found possible Python library paths:
  /usr/local/lib/python3.5/dist-packages
  /usr/lib/python3/dist-packages
Please input the desired Python library path to use.  Default is [/usr/local/lib/python3.5/dist-packages]
/usr/local/lib/python3.5/dist-packages
Do you wish to build TensorFlow with MKL support? [y/N] y
MKL support will be enabled for TensorFlow
Do you wish to download MKL LIB from the web? [Y/n] y
Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native]: 
Do you wish to use jemalloc as the malloc implementation? [Y/n] y
jemalloc enabled
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N] n
No Google Cloud Platform support will be enabled for TensorFlow
Do you wish to build TensorFlow with Hadoop File System support? [y/N] n
No Hadoop File System support will be enabled for TensorFlow
Do you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N] n
No XLA JIT support will be enabled for TensorFlow
Do you wish to build TensorFlow with VERBS support? [y/N] n
No VERBS support will be enabled for TensorFlow
Do you wish to build TensorFlow with OpenCL support? [y/N] n
No OpenCL support will be enabled for TensorFlow
Do you wish to build TensorFlow with CUDA support? [y/N] y
CUDA support will be enabled for TensorFlow
Do you want to use clang as CUDA compiler? [y/N] n
nvcc will be used as CUDA compiler
Please specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 8.0
Please specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 
Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: 
Please specify the cuDNN version you want to use. [Leave empty to use system default]: 5
Please specify the location where cuDNN 5 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 
Please specify a list of comma-separated Cuda compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size.
[Default is: ""3.5,5.2""]: 6.1
........
INFO: Starting clean (this may take a while). Consider using --async if the clean takes more than several minutes.
Configuration finished
```
[Console output of compilation command](https://github.com/Iolaum/CompileTF/blob/master/CompilationOutput.txt)
Because the output is too big to be placed within the issue I 've put it in it's own repository."
10837,Feature Request: Placeholder support for being set from an Op,"Update: I thought on this some more, and perhaps if tf.Variable could directly support being set from an op with the transfer happening entirely on the C++ side that might cleanly and simply solve the problem.

Often it is not known immediately what kind of Op will be needed for input, but it would be preferable to specify that detail later without the overhead associated with transporting data in python. 

For example, it would be ideal to be able to define a full model for a task like ImageNet labeling with a LazyOp defined for the Input and Labels. Then later on the output of a `Dataset`, `RecordInput`, or `tf.placeholder` could be supplied to finalize the necessary connection.

This request is based on the comments of @fchollet at https://github.com/fchollet/keras/pull/6928#issuecomment-309552423.

"
10836,Installation Fails,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: win10
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: latest from pip
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:  8/5.1
- **GPU model and memory**: Quadro K620
- **Exact command to reproduce**: import tensorflow


### Describe the problem
Have installed CUDA 8 / cuDNN 5.1, get the below error when attempting to import tensorflow.  Have seen other threads on here that all describe this as a $PATH$ issue.  I've ensured the cuDNN/CUDA necessities are in the path and have used @mrry installation check script https://gist.github.com/mrry/ee5dbcfdd045fa48a27d56664411d41c

it returned 

ERROR: Failed to import the TensorFlow module.

- Python version is 3.5.

- TensorFlow is installed at: c:\users\rhalabi\appdata\local\programs\python\python35\lib\site-packages\tensorflow

- All required DLLs are present. Please open an issue on the
  TensorFlow GitHub page: https://github.com/tensorflow/tensorflow/issues
An exception has occurred, use %tb to see the full traceback.

SystemExit: -1






### Source code / logs

In [4]: import tensorflow
---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
c:\users\rhalabi\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py in swig_import_helper()
     17         try:
---> 18             return importlib.import_module(mname)
     19         except ImportError:

c:\users\rhalabi\appdata\local\programs\python\python35\lib\importlib\__init__.py in import_module(name, package)
    125             level += 1
--> 126     return _bootstrap._gcd_import(name[level:], package, level)
    127

c:\users\rhalabi\appdata\local\programs\python\python35\lib\importlib\_bootstrap.py in _gcd_import(name, package, level)

c:\users\rhalabi\appdata\local\programs\python\python35\lib\importlib\_bootstrap.py in _find_and_load(name, import_)

c:\users\rhalabi\appdata\local\programs\python\python35\lib\importlib\_bootstrap.py in _find_and_load_unlocked(name, import_)

c:\users\rhalabi\appdata\local\programs\python\python35\lib\importlib\_bootstrap.py in _load_unlocked(spec)

c:\users\rhalabi\appdata\local\programs\python\python35\lib\importlib\_bootstrap.py in module_from_spec(spec)

c:\users\rhalabi\appdata\local\programs\python\python35\lib\importlib\_bootstrap_external.py in create_module(self, spec)

c:\users\rhalabi\appdata\local\programs\python\python35\lib\importlib\_bootstrap.py in _call_with_frames_removed(f, *args, **kwds)

ImportError: DLL load failed: The specified procedure could not be found.

During handling of the above exception, another exception occurred:

ImportError                               Traceback (most recent call last)
c:\users\rhalabi\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py in <module>()
     40     sys.setdlopenflags(_default_dlopen_flags | ctypes.RTLD_GLOBAL)
---> 41   from tensorflow.python.pywrap_tensorflow_internal import *
     42   from tensorflow.python.pywrap_tensorflow_internal import __version__

c:\users\rhalabi\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py in <module>()
     20             return importlib.import_module('_pywrap_tensorflow_internal')
---> 21     _pywrap_tensorflow_internal = swig_import_helper()
     22     del swig_import_helper

c:\users\rhalabi\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py in swig_import_helper()
     19         except ImportError:
---> 20             return importlib.import_module('_pywrap_tensorflow_internal')
     21     _pywrap_tensorflow_internal = swig_import_helper()

c:\users\rhalabi\appdata\local\programs\python\python35\lib\importlib\__init__.py in import_module(name, package)
    125             level += 1
--> 126     return _bootstrap._gcd_import(name[level:], package, level)
    127

ImportError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

ImportError                               Traceback (most recent call last)
<ipython-input-4-a649b509054f> in <module>()
----> 1 import tensorflow

c:\users\rhalabi\appdata\local\programs\python\python35\lib\site-packages\tensorflow\__init__.py in <module>()
     22
     23 # pylint: disable=wildcard-import
---> 24 from tensorflow.python import *
     25 # pylint: enable=wildcard-import
     26

c:\users\rhalabi\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\__init__.py in <module>()
     47 import numpy as np
     48
---> 49 from tensorflow.python import pywrap_tensorflow
     50
     51 # Protocol buffers

c:\users\rhalabi\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py in <module>()
     50 for some common reasons and solutions.  Include the entire stack trace
     51 above this error message when asking for help."""""" % traceback.format_exc()
---> 52   raise ImportError(msg)
     53
     54 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long

ImportError: Traceback (most recent call last):
  File ""c:\users\rhalabi\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    return importlib.import_module(mname)
  File ""c:\users\rhalabi\appdata\local\programs\python\python35\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 666, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 577, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 914, in create_module
  File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed
ImportError: DLL load failed: The specified procedure could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""c:\users\rhalabi\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""c:\users\rhalabi\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 21, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""c:\users\rhalabi\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""c:\users\rhalabi\appdata\local\programs\python\python35\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: No module named '_pywrap_tensorflow_internal'


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

In [5]:"
10835,Gradient of reduce_prod does not support negative axis,"The gradient of `reduce_prod` does not support negative axis unlike `reduce_prod` itself.
It is apparently caused by `gather` not supporting negative axes.
This code illustrates the problem.
```python
import tensorflow as tf

vars = tf.Variable([[1., 2.], [3., 4.]])
prod = tf.reduce_prod(vars, -1) # Negative axis here

tf.InteractiveSession()
tf.global_variables_initializer().run()
print(prod.eval()) # Works fine
print(tf.gradients(prod, vars)[0].eval()) # Crashes
```"
10834,I am New To Tensorflow How To learn can anyone Provide Step by Step Process,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorflow/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
10832,Error compiling in Linux Mint ,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Mint 18
- **TensorFlow installed from (source or binary)**: Installed from Source
- **TensorFlow version (use command below)**: Error generated when running below command
- **Bazel version (if compiling from source)**: Bazel 0.5.1
- **CUDA/cuDNN version**: Unknown
- **GPU model and memory**: No GPU
- **Exact command to reproduce**: sudo bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package --verbose_failures

### Describe the problem
Error when trying to build from source with Bazel.  Following error code generated:
WARNING: /home/dan/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': Use SavedModel Builder instead.
WARNING: /home/dan/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': Use SavedModel instead.
INFO: Found 1 target...
ERROR: /home/dan/.cache/bazel/_bazel_root/113acdcc7c9d2b1e2c757002415fbd3e/external/io_bazel_rules_closure/java/io/bazel/rules/closure/webfiles/server/BUILD:48:1: error executing shell command: 'JAR='external/local_jdk/bin/jar' OUTPUT='bazel-out/host/bin/external/io_bazel_rules_closure/java/io/bazel/rules/closure/webfiles/server/libbuild_info_java_proto_srcjar.srcjar' PROTO_COMPILER='exter...' failed: bash failed: error executing command
(cd /home/dan/.cache/bazel/_bazel_root/113acdcc7c9d2b1e2c757002415fbd3e/execroot/tensorflow && 
exec env - 
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin 
/bin/bash -c 'JAR='''external/local_jdk/bin/jar''' OUTPUT='''bazel-out/host/bin/external/io_bazel_rules_closure/java/io/bazel/rules/closure/webfiles/server/libbuild_info_java_proto_srcjar.srcjar''' PROTO_COMPILER='''external/com_google_protobuf_protoc/bin/protoc''' SOURCE='''external/io_bazel_rules_closure/java/io/bazel/rules/closure/webfiles/server/build_info.proto''' INCLUDES='''-I. -Iexternal/io_bazel_rules_closure''' bazel-out/host/bin/external/io_bazel_rules_closure/closure/private/gensrcjar'): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
external/com_google_protobuf_protoc/bin/protoc: 1: external/com_google_protobuf_protoc/bin/protoc: cannot create ��/@@��: Directory nonexistent
external/com_google_protobuf_protoc/bin/protoc: 1: external/com_google_protobuf_protoc/bin/protoc: �ELF�����: not found
external/com_google_protobuf_protoc/bin/protoc: 2: external/com_google_protobuf_protoc/bin/protoc: Syntax error: "")"" unexpected
gensrcjar: proto_compiler failed
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 339.557s, Critical Path: 54.04s

### Source code / logs
Log/Error above.

Let me know if you need more information."
10829,Java API does not include quantize operations,"When trying to run a quantized model with the Tensorflow Java API in version 1.2-rc0, I get the following exception in Java:

```
java.lang.IllegalArgumentException: No OpKernel was registered to support Op 'QuantizeV2' with these attrs.  Registered devices: [CPU], Registered kernels:
  <no registered kernels>

	 [[Node: encoder/encoder_layer_0/Conv2D_eightbit_quantize_normalize/sub = QuantizeV2[T=DT_QUINT8, mode=""MIN_FIRST""](normalize/sub, encoder/encoder_layer_0/Conv2D_eightbit_min_normalize/sub, encoder/encoder_layer_0/Conv2D_eightbit_max_normalize/sub)]]

	at org.tensorflow.Session.run(Native Method)
	at org.tensorflow.Session.access$100(Session.java:48)
	at org.tensorflow.Session$Runner.runHelper(Session.java:295)
	at org.tensorflow.Session$Runner.run(Session.java:245)
	...
```

It seams the kernels for quantized graphs are not included in the Java API binary of tensorflow. Can you add these kernels?

Note: The frozen model I used to create the quantized model runs perfect with the same code.
Note2: I quantized the graph with the current r1.2 branch of tensorflow."
10827,version 1.2 doesn't show CUDA and cuDNN information,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: `pip install tensorflow-gpu`
- **TensorFlow version (use command below)**: ('v1.2.0-rc2-21-g12f033d', '1.2.0')
- **CUDA/cuDNN version**: CUDA 8.0, cuDNN 5.1
- **GPU model and memory**: GTX 970M, 3GB

### Describe the problem
In previous version, after importing tensorflow like `import tensorflow as tf` following output will be shown:
```
>>> import tensorflow as tf;
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so.7.5 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so.5.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so.7.5 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so.7.5 locally
```
However, after I installed CUDA and cuDNN, and then installed Tensorflow v1.2, I found there is NO output for `import tensorflow as tf` in python. And I cannot check whether gpu successfully uses CUDA or cuDNN.
I have checked my GPU as follows and GPU works well. I have tried the method in #566 to adjust `TF_CPP_MIN_LOG_LEVEL`, but it seems have no effect.
I suggest it would be great to include CUDA and cuDNN info when importing tensorflow.

```
>>> import tensorflow as tf
>>> sess = tf.Session()
2017-06-20 00:24:38.111017: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-20 00:24:38.111060: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-20 00:24:38.111074: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-06-20 00:24:38.111086: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-20 00:24:38.111097: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-06-20 00:24:38.215890: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-06-20 00:24:38.216159: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: GeForce GTX 970M
major: 5 minor: 2 memoryClockRate (GHz) 1.038
pciBusID 0000:01:00.0
Total memory: 2.95GiB
Free memory: 2.63GiB
2017-06-20 00:24:38.216174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2017-06-20 00:24:38.216180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2017-06-20 00:24:38.216191: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 970M, pci bus id: 0000:01:00.0)
```
"
10826,ResourceExhaustedError : OOM when allocating tensor with shape,"### The problem

I try to compute a very costly loss function using FFT2D, rolling of the tensor and neural network with 3 layers. 
You can find the Python script here : [TestFFT2D_2.py](https://github.com/nicaogr/silver-octo-fortnight/blob/master/TestFFT2D_2.py)

My loss function is the sum of 448 terms. Each of this term is computed with a rolling of the initial tensor, FFT2D, a multiply of two tensor and a IFFT2D. That is why it is very costly and why it needs a lot of memory. 
 
You can find the end of the error message here : 
[MemoryError.txt](https://github.com/tensorflow/tensorflow/files/1084875/MemoryError.txt)

Do you know why the GPU is not able to deal with a memory demanding code ? Do you know a way to avoid this error message even if we need to pay a computing time cost ?

Do you think I need to do a feature request for a better management of the GPU memory ? 

### System information
- **Have I written custom code **: TestFFT2D.py
- **OS Platform and Distribution**: Linux Ubuntu 16.04
- **TensorFlow installed from**: Source
- **TensorFlow version**: 1.2
- **CUDA/cuDNN version**:
Cuda compilation tools, release 7.5, V7.5.17 and  cuDNN  5 with the GeForce GTX 680
- **GPU model and memory**: Tested on GeForce GTX 680 with 2Go
- ** Python version**: Python 3.6.1 |Anaconda 4.4.0 (64-bit)|
- **Exact command to reproduce**: python TestFFT2D_2.py

"
10824,Constant operator is not appropriate for variable initialize,"Tensorflow uses const tensor to initialize variables(for example ones_initializer, zeros_initializer and some optimizer slot creation), this will prevent `AssignOp `to transfer ownership from rhs to lhs and waster a lot of memory when variable shape is very large(for example sparse model). see #9823 #9742"
10823,Excessive chatter in VLOG(1),"IMO:  tensorflow/core/framework/op.cc:82 is rather a chatty and specific output to be included at VLOG(1).

Could it be changed to VLOG(2) or better still VLOG(3)

one person's useful output is 100's of peoples noise.
"
10822,py_func returning string leaks memory,"TF version: 1.2.0

```python
import tensorflow as tf

tf.InteractiveSession()
s = b' '*1000000
x = tf.py_func(lambda: s[1:], [], tf.string) # leaks
# x = tf.py_func(lambda: s, [], tf.string) # does not leak
# x = tf.py_func(lambda: len(s[1:]), [], tf.int64) # does not leak
while True:
    x.op.run()
```"
10820,"how to compile tensorflow for sse4.1 sse 4.2, avx, and sycl?","how can i compile tensorflow for sse4.1 sse 4.2, avx, and sycl?
is there some guide available online?"
10819,Tensorflow Android API version 1.2 not in JCenter,"The freshly released version 1.2 of the tensorflow APIs is not yet fully available in JCenter ( https://bintray.com/google/tensorflow/tensorflow-android/1.2.0). There is a version 1.2.0 but it does not contain any files. 

Can you push these files to the repository?"
10817,TensorFlow C library now available for Windows?,"Does anyone know where  to find the available TensorFlow C library for Windows?
I only get the information about C library on Linux and MacOs."
10816,Training LSTM RNN  model after restoration starting again with high loss,"I have an LSTM based RNN language model where in after the initial training for 1000 iterations, the model is saved as follows
saver = tf.train.Saver()
saver.save(sess,'rnn_model.ckpt',global_step=1000)

I've restored the model by

            saver = tf.train.import_meta_graph(""rnn_model.ckpt-1000.meta"")
            saver.restore(self.sess, tf.train.latest_checkpoint('./'))
            graph = tf.get_default_graph()
            # restore the operations and placeholder as required from the graph
            # perform retraining

so far everything looks good, the model is restored, but however, when I plot the loss summary while training with the same input data as previous training, the loss again starts with high value as if it is training from start again freshly. I've tried to search all means to find the relevant forums but could not find a proper solution. please advise on the corrective steps

 (related links
https://github.com/tensorflow/tensorflow/issues/6683
https://github.com/fchollet/keras/issues/4875
https://stackoverflow.com/questions/41328769/tensorflow-loss-resets-after-successfully-restored-checkpoint

)



"
10815,Feature request: Add a subclass of seq2seq.Decoder to support regression,"Currently, seq2seq decoder class only supports classification which uses 1D softmax with embedding. The library is very good for this particular task. However, seq2seq is also extremely useful in regression tasks by replacing embedding with a dense layer.

As of 1.2, the current architecture only allows 1D sequence data by supplying a Dense layer as _embedding_fn to TrainingHelper. Currently, training is working(loss decreases) but I have yet to find a way to decode.

I have tried to modify these following pieces to support 2D regression:
`TrainingHelper`
`BasicDecoder`
`dynamic_decode`
`GreedyEmbeddingHelper`(used during decoding, not working)

I had to change a lot of seq2seq internals, but here is more or less my code:
```python
            self.decoder_cell, self.decoder_initial_state = self.build_decoder_cell()

            # Input projection layer to feed embedded inputs to the cell
            # ** Essential when use_residual=True to match input/output dims
            input_layer = Dense(self.hidden_units, dtype=self.dtype, name='input_projection')

            # Output projection layer to convert cell_outputs to actual values
            output_layer = Dense(self.dimension, name='output_projection')

```
```python

if self.mode == 'train':
    # decoder_inputs_train :: [batch_size , max_time_steps + 1]
    # Decoder inputs having gone through input projection layer
    self.decoder_inputs_proj = input_layer(self.decoder_inputs_train)

    # Helper to feed inputs for training: read inputs from dense ground truth vectors
    training_helper = seq2seq.TrainingHelper(inputs=self.decoder_inputs_proj,
                                       sequence_length=self.decoder_inputs_length_train,
                                       time_major=False,
                                       name='training_helper')

    training_decoder = seq2seq.BasicDecoder(cell=self.decoder_cell,
                                       helper=training_helper,
                                       initial_state=self.decoder_initial_state,
                                       output_layer=output_layer)
                                       #output_layer=None)

    # Maximum decoder time_steps in current batch
    max_decoder_length = tf.reduce_max(self.decoder_inputs_length_train)

    # decoder_outputs_train: BasicDecoderOutput
    #                        namedtuple(rnn_outputs, sample_id)
    # decoder_outputs_train.rnn_output: [batch_size, max_time_step + 1, dimension] if output_time_major=False
    #                                   [max_time_step + 1, batch_size, dimension] if output_time_major=True
    # decoder_outputs_train.sample_id: [batch_size], tf.int32
    (self.decoder_outputs_train, self.decoder_last_state_train,
     self.decoder_outputs_length_train) = (seq2seq.dynamic_decode(
        decoder=training_decoder,
        output_time_major=False,
        impute_finished=True,
        maximum_iterations=max_decoder_length))

    # More efficient to do the projection on the batch-time-concatenated tensor
    # logits_train: [batch_size, max_time_step + 1, dimension]
    self.decoder_logits_train = tf.identity(self.decoder_outputs_train.rnn_output)

    # RMSE
    self.loss = tf.reduce_mean(tf.sqrt(
          tf.abs(tf.subtract(self.decoder_logits_train, self.decoder_targets_train))
        ), axis=2)
    self.loss = tf.reduce_sum(self.loss)

    # Contruct graphs for minimizing loss
    self.init_optimizer()
```
And here is the code for `decoding` and this is where I get all sorts of errors:

```

elif self.mode == 'decode':

    # Start_tokens: [batch_size,] `int32` vector
    start_tokens = tf.ones([self.batch_size, self.dimension], tf.float32) * 0.1337
    end_token = 0.1337

    def project_inputs(inputs):
        print ""INPUT SHAPE"", inputs.shape
        return input_layer(inputs)

    if not self.use_beamsearch_decode:
        # Helper to feed inputs for greedy decoding: uses the argmax of the output
        decoding_helper = seq2seq.GreedyEmbeddingHelper(start_tokens=start_tokens,
                                                        end_token=end_token,
                                                        embedding=project_inputs)
        # Basic decoder performs greedy decoding at each time step
        print(""building greedy decoder.."")
        inference_decoder = seq2seq.BasicDecoder(cell=self.decoder_cell,
                                                 helper=decoding_helper,
                                                 initial_state=self.decoder_initial_state,
                                                 output_layer=output_layer)
    # For GreedyDecoder, return
    # decoder_outputs_decode: BasicDecoderOutput instance
    #                         namedtuple(rnn_outputs, sample_id)
    # decoder_outputs_decode.rnn_output: [batch_size, max_time_step, num_decoder_symbols]   if output_time_major=False
    #                                    [max_time_step, batch_size, num_decoder_symbols]   if output_time_major=True
    # decoder_outputs_decode.sample_id: [batch_size, max_time_step], tf.int32       if output_time_major=False
    #                                   [max_time_step, batch_size], tf.int32               if output_time_major=True

    (self.decoder_outputs_decode, self.decoder_last_state_decode,
     self.decoder_outputs_length_decode) = (seq2seq.dynamic_decode(
        decoder=inference_decoder,
        output_time_major=False,
        #impute_finished=True,  # error occurs
        maximum_iterations=self.max_decode_step))

    if not self.use_beamsearch_decode:
        # decoder_outputs_decode.sample_id: [batch_size, max_time_step]
        # Or use argmax to find decoder symbols to emit:
        # self.decoder_pred_decode = tf.argmax(self.decoder_outputs_decode.rnn_output,
        #                                      axis=-1, name='decoder_pred_decode')

        # Here, we use expand_dims to be compatible with the result of the beamsearch decoder
        # decoder_pred_decode: [batch_size, max_time_step, 1] (output_major=False)
        self.decoder_pred_decode = tf.expand_dims(self.decoder_outputs_decode.sample_id, -1)
```

It would be great if someone could sort it out and streamline the process."
10814,load_csv_with_header,"When I run iris_monitors.py file, It has an error :
File ""C:\software\Python\Python35\lib\site-packages\tensorflow\contrib\learn\python\learn\datasets\base.py"", line 47, in load_csv_with_header
header = next(data_file)
StopIteration"
10812,`tf.Summary` comparison operator overloading?,"So I was trying to use a comparison operation (`>`) with a `tf.Summary` object. It does not throw an error, but the results are incorrect. I couldn't find any help for this on the [official documentation](https://www.tensorflow.org/api_docs/python/tf/Summary/Value).
Here are my logs --> 
```
(Pdb) type(losses[0])
<class 'tensorflow.core.framework.summary_pb2.Summary'>
(Pdb) type(losses[1])
<class 'tensorflow.core.framework.summary_pb2.Summary'>
(Pdb) losses
[value {
  tag: ""CTC Loss""
  simple_value: 40.2547607422
}
, value {
  tag: ""CTC Loss""
  simple_value: 42.1486358643
}
]
(Pdb) losses[0] > losses[1]
True
```
The objects were created using `tf.Summary(value=[tf.Summary.Value(tag=tag, simple_value=value)])`. What do you think? @dandelionmane ?
"
10811,ImportError: cannot import name bayesflow,"**I am trying to use the command:
`cell = tf.contrib.rnn.BasicLSTMCell(state_size, state_is_tuple=True)`

However, it keeps telling me:  ImportError: cannot import name bayesflow **. Detail is shown as below:

> ImportError                               Traceback (most recent call last)
> <ipython-input-47-316021e54a93> in <module>()
>       4 labels_series = [tf.reshape(x, [batch_size,1]) for x in labels_series]
>       5 # Forward passes
> ----> 6 cell = tf.contrib.rnn.BasicLSTMCell(state_size)
>       7 states_series, current_state = tf.contrib.rnn(cell, inputs_series, init_state)
>       8 
> 
> //anaconda/lib/python2.7/site-packages/tensorflow/python/util/lazy_loader.pyc in __getattr__(self, item)
>      51 
>      52   def __getattr__(self, item):
> ---> 53     module = self._load()
>      54     return getattr(module, item)
>      55 
> 
> //anaconda/lib/python2.7/site-packages/tensorflow/python/util/lazy_loader.pyc in _load(self)
>      40   def _load(self):
>      41     # Import the target module and insert it into the parent's namespace
> ---> 42     module = importlib.import_module(self.__name__)
>      43     self._parent_module_globals[self._local_name] = module
>      44 
> 
> //anaconda/lib/python2.7/importlib/__init__.pyc in import_module(name, package)
>      35             level += 1
>      36         name = _resolve_name(name[level:], package, level)
> ---> 37     __import__(name)
>      38     return sys.modules[name]
> 
> //anaconda/lib/python2.7/site-packages/tensorflow/contrib/__init__.py in <module>()
>      20 
>      21 # Add projects here, they will show up under tf.contrib.
> ---> 22 from tensorflow.contrib import bayesflow
>      23 from tensorflow.contrib import cloud
>      24 from tensorflow.contrib import compiler
> 
> ImportError: cannot import name bayesflow

Anybody know how to fix it? Much appreciated in advance!

Xin"
10810,seq2seq for dynamic length sequences,"The seq2seq model is based on the static_rnn, what should I do if my sequence lengths is not known?"
10809,New changes in tf 1.2 and the seq2seq model,"In the change log it reads: ""The strictness described
in the TensorFlow 1.1 release is gone: The first time an RNNCell is used,
it caches its scope. All future uses of the RNNCell will reuse variables from
that same scope.""

Based on which the seq2seq model (with UNtied decoder weights) no longer remain untied. Can you confirm that this is addressed? I don't see anywhere in the seq2seq model that this is addressed."
10808,Original error was: DLL load failed: The specified procedure could not be found.,"Hello. I've been getting 'Original error was: DLL load failed: The specified procedure could not be found' error when attempting to import tensorflow. I'm on Windows 10 with python 3.6.00. I've checked some issues like mine but I already have visual studio c++ 2017. I attempted to download 2015 however I was told I already have it.  I installed tensorflow with:


    Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?:
    No
    TensorFlow installed from (source or binary)?:
    binary
    TensorFlow version:
    Can't do version because I the error when importing
    Bazel version (if compiling from source):
    NA
    CUDA/cuDNN version:
    8.0 I think
    GPU Model and Memory:
    Nvidia 1080 4gb
    Exact command to reproduce:
    pip3 install --upgrade tensorflow-gpu

Here is the full error:

> Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Users\David\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""C:\Users\David\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\__init__.py"", line 47, in <module>
    import numpy as np
  File ""C:\Users\David\AppData\Local\Programs\Python\Python36\lib\site-packages\numpy\__init__.py"", line 142, in <module>
    from . import add_newdocs
  File ""C:\Users\David\AppData\Local\Programs\Python\Python36\lib\site-packages\numpy\add_newdocs.py"", line 13, in <module>
    from numpy.lib import add_newdoc
  File ""C:\Users\David\AppData\Local\Programs\Python\Python36\lib\site-packages\numpy\lib\__init__.py"", line 8, in <module>
    from .type_check import *
  File ""C:\Users\David\AppData\Local\Programs\Python\Python36\lib\site-packages\numpy\lib\type_check.py"", line 11, in <module>
    import numpy.core.numeric as _nx
  File ""C:\Users\David\AppData\Local\Programs\Python\Python36\lib\site-packages\numpy\core\__init__.py"", line 26, in <module>
    raise ImportError(msg)
ImportError:
Importing the multiarray numpy extension module failed.  Most
likely you are trying to import a failed build of numpy.
If you're working with a numpy git repo, try `git clean -xdf` (removes all
files not under version control).  Otherwise reinstall numpy.
Original error was: DLL load failed: The specified procedure could not be found.

I tried reinstalling numpy too, same error. 


"
10807,Could a 3.7 alpha wheel of tensorflow be provided on pip?,"Python 3.7 alpha exists, I would like to be able to install a wheel. Any idea when tensorflow could be added on pypi for 3.7?"
10806,Error compiling in Linux Mint,"I am trying to compile this from source, but currently getting the following issue:

sudo bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package --verbose_failures
....................................................................................
WARNING: /home/dan/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': Use SavedModel Builder instead.
WARNING: /home/dan/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': Use SavedModel instead.
INFO: Found 1 target...
ERROR: /home/dan/.cache/bazel/_bazel_root/113acdcc7c9d2b1e2c757002415fbd3e/external/io_bazel_rules_closure/java/io/bazel/rules/closure/webfiles/server/BUILD:48:1: error executing shell command: 'JAR='external/local_jdk/bin/jar' OUTPUT='bazel-out/host/bin/external/io_bazel_rules_closure/java/io/bazel/rules/closure/webfiles/server/libbuild_info_java_proto_srcjar.srcjar' PROTO_COMPILER='exter...' failed: bash failed: error executing command 
  (cd /home/dan/.cache/bazel/_bazel_root/113acdcc7c9d2b1e2c757002415fbd3e/execroot/tensorflow && \
  exec env - \
    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin \
  /bin/bash -c 'JAR='\''external/local_jdk/bin/jar'\'' OUTPUT='\''bazel-out/host/bin/external/io_bazel_rules_closure/java/io/bazel/rules/closure/webfiles/server/libbuild_info_java_proto_srcjar.srcjar'\'' PROTO_COMPILER='\''external/com_google_protobuf_protoc/bin/protoc'\'' SOURCE='\''external/io_bazel_rules_closure/java/io/bazel/rules/closure/webfiles/server/build_info.proto'\'' INCLUDES='\''-I. -Iexternal/io_bazel_rules_closure'\'' bazel-out/host/bin/external/io_bazel_rules_closure/closure/private/gensrcjar'): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
external/com_google_protobuf_protoc/bin/protoc: 1: external/com_google_protobuf_protoc/bin/protoc: cannot create �/@@��: Directory nonexistent
external/com_google_protobuf_protoc/bin/protoc: 1: external/com_google_protobuf_protoc/bin/protoc: ELF: not found
external/com_google_protobuf_protoc/bin/protoc: 2: external/com_google_protobuf_protoc/bin/protoc: Syntax error: "")"" unexpected
gensrcjar: proto_compiler failed
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 339.557s, Critical Path: 54.04s
Can anyone help on this?

Thanks.
"
10805,Make `tf.contrib.seq2seq._BaseAttentionMechanism` public,"Currently, if users want to write their own attention mechanisms, they have to do so from scratch by extending the `tf.contrib.seq2seq.AttentionMechanism` class (which has nothing) or import the `_BaseAttentionMechanism` from [attention_wrapper.py](https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py) with the following, inconvenient import statement:

    from tensorflow.contrib.seq2seq.python.ops.attention_wrapper import _BaseAttentionMechanism

It's worth including this class directly accessible from `tf.contrib.seq2seq`, considering that it adds good defaults and that both forms of attention currently available, Bahdanau and Luong, inherit this class.

My proposal is to simply rename the class to `BaseAttentionMechanism` without an underscore (or perhaps a more meaningful name such as `BasicAttentionMechanism`to differentiate it from the parent class `AttentionMechanism`), and add the class to the `__all__` array in [attention_wrapper.py](https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py)."
10804,Not possible to use tf.contrib.training.stratified_sample with a SparseTensor,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.2.0-rc2-21-g12f033d 1.2.0
- **Bazel version (if compiling from source)**: -
- **CUDA/cuDNN version**: - 
- **GPU model and memory**: -
- **Exact command to reproduce**: -

### Describe the problem
**Context**:
I set up an input pipeline that reads `tf.train.SequenceExample`. My dataset is quite unbalanced, so I used `tf.contrib.training.stratified_sample` to resample examples. 

**Problem**:
`tf.contrib.training.stratified_sample` works well with `tf.FixedLenFeature` (context_features) but it raises a `TypeError: Failed to convert object of type <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'> to Tensor. ...` when applied to `tf.VarLenFeature` of sequence_features. 
Using `tf.sparse_tensor_to_dense()` is not applicable either, as it raises `ValueError: All shapes must be fully defined: ...`

**Statement**:
If it is not an intended behaviour, then I'd like to report a bug, as I don't see why `tf.SparseTensor` shouldn't be supported.
If `tf.contrib.training.stratified_sample` works as intended, then I'd like to request a feature of `tf.SparseTensor` support in online data resampling ops.
"
10803,TensorBoard Histogram Dashboard link broken,"The link (https://www.tensorflow.org/get_started/tensorboard_histograms) to the ""TensorBoard Histogram Dashboard"" documentation is broken (404). If that section is currently in the process of being written perhaps add a dummy page saying so."
10802,Decoding images in a given shape from TF records,"I am trying to read images from TFrecords file. The images vary in shapes. After reading, I want to preserve their shape which is why I pass the height, width and depth parameters appropriately. But the code just doesn't print anything after the set_shape command. The sess.run() calls do not respond. I initialized the session in the main function and passed the object. Is there a way to get the values of height,w,d tensors so that I can pass it to set_shape? How do I fix this? Any suggestions are welcome. Thanks in advance

`def read_and_decode(sess,filename_queue):
  reader = tf.TFRecordReader()
  _, serialized_example = reader.read(filename_queue)
  features = tf.parse_single_example(
      serialized_example,
      # Defaults are not specified since both keys are required.
      features={
          'height': tf.FixedLenFeature([], tf.int64),
          'width': tf.FixedLenFeature([], tf.int64),
          'depth': tf.FixedLenFeature([], tf.int64),
          'image_raw': tf.FixedLenFeature([], tf.string),
          'label': tf.FixedLenFeature([], tf.int64),
      })

  image = tf.decode_raw(features['image_raw'], tf.uint8)
  image.set_shape([sess.run(features['height']),sess.run(features['width']),sess.run(features['depth'])])`

"
10801,tf.reshape fails for Tensor with valid shape parameter,"I don't know if my problem is truly a bug with TensorFlow, but I think it is. My problem is that `tf.reshape(x, shape=(sequence_length, 4))` fails even when `x` is a tensor and the shape provided is valid. Reshape returns the following error: `TypeError: List of Tensors when single Tensor expected`

Some background: I have a number of CSVs that I converted to `SequenceExample`s and stored as `TFRecord`s to use to train dynamic RNNs. The length of each sequence can vary. I can successfully read the `SequenceExamples` using `parse_single_sequence_example`, which returns a tensor of shape `(?,)` for each of my four feature tensors and each of my four label tensors. I then stack the four feature tensors to create `x` with shape `(?, 4)` and type `<class 'tensorflow.python.framework.ops.Tensor'>`. I create a similar tensor of labels `y` with shape `(?, 4)` and type `<class 'tensorflow.python.framework.ops.Tensor'>`. Everything is good.

Then, I'd like to create minibatches based on similar length sequences using `tf.contrib.training.bucket_by_sequence_length`, but if I pass in `input_length=x.shape[0]`, I receive the following error: `ValueError: Cannot convert an unknown Dimension to a Tensor: ?`. Since I know the sequence length when creating the `SequenceExample`s, I modified my code to add the sequence length (an integer) as a context feature. Then, when I read my features and labels, I try to reshape them as follows:

```
        sequence_length = context_parsed['length']
        tf.reshape(x, shape=(sequence_length, 4))
```

where `sequence_length` has type `<class 'tensorflow.python.framework.ops.Tensor'>` and shape `()`. This raises the following error: `TypeError: List of Tensors when single Tensor expected`. However, `x` is a Tensor, not a list of Tensors. This is why I think there may be a bug in TensorFlow's `tf.reshape()` function.

My TensorFlow version: TensorFlow version: v1.2.0-rc0-24-g94484aa 1.2.0-rc1

If it helps, I could post one of my .tfrecord files and the code necessary to create this error.
"
10800,tf.cond should be evaluated lazily,"It should be possible to statically analyze the following graph such that the execution of the one branch is stopped early if the other branch is determined to be chosen. Am I missing some different function in TensorFlow that allows to do this? Perhaps using control dependencies?

In the following code the identity matrix is multiplied many times and a placeholder threshold determines whether the second multiplication or the last is chosen as output of the graph.

```
import tensorflow as tf
import numpy as np
import timeit

N = 2048

x = tf.placeholder(tf.float32, [N,N])
t = tf.placeholder(tf.float32)
net = x
stop = None
for i in range(300):
  net = tf.matmul(net, net)
  if i == 1:
    stop = net

net = tf.cond(tf.reduce_sum(stop) < t, lambda: stop * 0., lambda: net)

sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))

r = None

start_time = timeit.default_timer()
for i in range(10):
  r = sess.run(net, feed_dict={x: np.eye(N), t: N})
print(r)
print(timeit.default_timer() - start_time)

start_time = timeit.default_timer()
for i in range(10):
  r = sess.run(net, feed_dict={x: np.eye(N), t: N + 1})
print(r)
print(timeit.default_timer() - start_time)
```

Both runs take roughly the same time even though the second run only depend on the first two matrix multiplications (at least if one accounts for the warm-up phase which give the first run a slight disadvantage).

I hope I am not missing something obvious. Thanks."
10799,Compiler is out of heap space,"I am compiling tensorflow on windows 10 laptop, i7 6700hq 16GB ram with Visual Studio 2015 and all dependencies are ok as it is explained on readme. However at the end of compilation I get the following error:

```
""D:\PRJ\tensorflow\tensorflow\contrib\cmake\build\tf_python_build_pip_package.vcxproj"" (default target) (1) ->
""D:\PRJ\tensorflow\tensorflow\contrib\cmake\build\pywrap_tensorflow_internal.vcxproj"" (default target) (3) ->
""D:\PRJ\tensorflow\tensorflow\contrib\cmake\build\pywrap_tensorflow_internal_static.vcxproj"" (default target) (4) ->
""D:\PRJ\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj"" (default target) (105) ->
(ClCompile target) ->
  d:\prj\tensorflow\tensorflow\contrib\cmake\build\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorBase
.h(832): fatal error C1060: compiler is out of heap space (compiling source file D:\PRJ\tensorflow\tensorflow\core\kern
els\reverse_op.cc) [D:\PRJ\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj]
  d:\prj\tensorflow\tensorflow\contrib\cmake\build\external\eigen_archive\eigen\src\core\../plugins/MatrixCwiseBinaryOp
s.h(116): fatal error C1060: compiler is out of heap space (compiling source file D:\PRJ\tensorflow\tensorflow\core\ker
nels\self_adjoint_eig_v2_op.cc) [D:\PRJ\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj]
  d:\prj\tensorflow\tensorflow\contrib\cmake\build\external\eigen_archive\eigen\src/Core/CoreEvaluators.h(599): fatal e
rror C1060: compiler is out of heap space (compiling source file D:\PRJ\tensorflow\tensorflow\core\kernels\svd_op_doubl
e.cc) [D:\PRJ\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj]
```
How can I solve this problem?"
10798,TF Detect to work with the new Object Detection API model,"Hi there, if I replace the current TF Detect model with the new Object Detection API model, will it still work?"
10795,How to update the variable list for which the optimizer need to train in tensorflow?,"How to update the list of variables for the optimizer to train in tensorflow? In other words, if we have the following optimizer:

`optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost_scalar, var_list=my_var_list)`

I need to update my_var_list for example while fine tuning the network. That is, I am going to remove the variable which I no longer need to train and keep the others. Example, fine tuning the dense layer in a convolutional neural network.

Any help is much appreciated!!"
10794,Failed to load the native TensorFlow runtime.,"## I tried #10026 but I won't work for me . 
-------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
<ipython-input-21-32e52670ef8f> in <module>()
      6 import pattern
      7 from bs4 import BeautifulSoup as bs
----> 8 import tensorflow as tf
```
/root/anaconda2/lib/python2.7/site-packages/tensorflow/__init__.py in <module>()
     22 
     23 # pylint: disable=wildcard-import
---> 24 from tensorflow.python import *
     25 # pylint: enable=wildcard-import
     26 

/root/anaconda2/lib/python2.7/site-packages/tensorflow/python/__init__.py in <module>()
     47 import numpy as np
     48 
---> 49 from tensorflow.python import pywrap_tensorflow
     50 
     51 # Protocol buffers

/root/anaconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py in <module>()
     50 for some common reasons and solutions.  Include the entire stack trace
     51 above this error message when asking for help."""""" % traceback.format_exc()
---> 52   raise ImportError(msg)
     53 
     54 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long

ImportError: Traceback (most recent call last):
  File ""/root/anaconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/root/anaconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/root/anaconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
ImportError: /lib64/libc.so.6: version `GLIBC_2.14' not found (required by /root/anaconda2/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)
```

## Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help."
10792,"Enable sparse_matmul(a,b) when a and b are sparse, conformable","Current tf.sparse_matmul(a,b) requires both a and b to be dense, apparently.

```
n = 500000
k = 5000
with tf.Session() as sess:
    rep = 1.0
    sparse1 = tf.SparseTensor(indices=list(xys),values=np.repeat(rep,k),dense_shape=[n,n])
    sparse2 = tf.SparseTensor(indices=list(xys),values=np.repeat(rep,k),dense_shape=[n,n])
    sparse1 = tf.cast(sparse1, tf.float32)
    sparse2 = tf.cast(sparse2, tf.float32)

    sq = tf.sparse_matmul(
            tf.sparse_tensor_to_dense(sparse1, 0.0)
            , tf.sparse_tensor_to_dense(sparse2, 0.0)
            , a_is_sparse=True
            , b_is_sparse=True
)
```

The cast of `sparse_tensor_to_dense()` seem inappropriate.  Please enable

```
n = 500000
k = 5000
with tf.Session() as sess:
    rep = 1.0
    sparse1 = tf.SparseTensor(indices=list(xys),values=np.repeat(rep,k),dense_shape=[n,n])
    sparse2 = tf.SparseTensor(indices=list(xys),values=np.repeat(rep,k),dense_shape=[n,n])
    sparse1 = tf.cast(sparse1, tf.float32)
    sparse2 = tf.cast(sparse2, tf.float32)

    sq = tf.sparse_matmul(
            sparse1
            , sparse2
            , a_is_sparse=True
            , b_is_sparse=True
)
```"
10790,conv1d not in tf.contrib.layers,"As of tensorflow 1.2, conv1d can be found under `tf.layers`, and not `tf.contrib.layers`, where you find conv2d. Shouldn't it be available under the contrib namespace? By the way, what's the conceptual difference between both submodules?"
10789,quantize_graph error in simple graph,"
when my graph is as follows, it will fail to quantize, the error info is **AssertionError: Failed to quantized constant ones_1 of type**
`x = tf.ones((1000,1),'int32')
**ones = tf.ones((1, 100), ""int32"")**
x = tf.reshape(x, shape=(-1,1))`

when i change graph to the following, it works:
`x = tf.ones((1000,1),'int32')
**ones = tf.ones((1, 100), ""int32"")
ones = tf.reshape(ones, shape=(1,-1))**
x = tf.reshape(x, shape=(-1,1))`

is there anyone can help me to find out the reason, because even i change my code and successfully generated quantized graph, the graph is wrong when importing, BTW my graph is much more complex than the code above."
10788,Where is ios_examples?,"Hi,

I'm trying to follow your iOS guide in the README, which tells me to use: tensorflow/contrib/ios_examples. 

But this folder is completely missing.

Can anyone advise? "
10787,quantize_graph,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorflow/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
10786, Unable to install tenser flow  on python 3.6.1 on windows 10 x64,"![pip](https://user-images.githubusercontent.com/29494774/27248510-24b7f1f6-5322-11e7-9067-1ba4dfb700ac.PNG)


Unable to install tenserflow "
10785,Feature Request-Randomized Hashing,"This is feature request to see if randomized hashing can be implemented to relevant part of the library to allow the option to be utilized for better computational resource utilization:

https://arxiv.org/abs/1602.08194"
10784,build fails for r1.2 on linux,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No

OS: Ubuntu 16.04.2 LTS
I have cloned tensorflow from github.
checked out release r1.2

I have rune the configure script:
$ ./configure
Please specify the location of python. [Default is /usr/bin/python]: /usr/bin/python3
Found possible Python library paths:
  /usr/lib/python3/dist-packages
  /usr/local/lib/python3.5/dist-packages
Please input the desired Python library path to use.  Default is [/usr/lib/python3/dist-packages]
/usr/lib/python3/dist-packages
Do you wish to build TensorFlow with MKL support? [y/N] N
No MKL support will be enabled for TensorFlow
Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native]: -march=native
Do you wish to use jemalloc as the malloc implementation? [Y/n] Y
jemalloc enabled
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N] N
No Google Cloud Platform support will be enabled for TensorFlow
Do you wish to build TensorFlow with Hadoop File System support? [y/N] N
No Hadoop File System support will be enabled for TensorFlow
Do you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N] N
No XLA JIT support will be enabled for TensorFlow
Do you wish to build TensorFlow with VERBS support? [y/N] N
No VERBS support will be enabled for TensorFlow
Do you wish to build TensorFlow with OpenCL support? [y/N] N
No OpenCL support will be enabled for TensorFlow
Do you wish to build TensorFlow with CUDA support? [y/N] N
No CUDA support will be enabled for TensorFlow
..................................................
INFO: Starting clean (this may take a while). Consider using --async if the clean takes more than several minutes.
Configuration finished
shaeffer@ip-10-164-47-27:/srv/projects/c++/tfgit1.2$ bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package
ERROR: /srv/projects/c++/tfgit1.2/third_party/py/python_configure.bzl:285:20: unexpected keyword 'environ' in call to repository_rule(implementation: function, *, attrs: dict or NoneType = None, local: bool = False).
ERROR: com.google.devtools.build.lib.packages.BuildFileContainsErrorsException: error loading package '': Extension file 'third_party/py/python_configure.bzl' has errors.
INFO: Elapsed time: 3.281s

The tensorflow r1.2 build fails as described directly above.

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**: GitHub clone of source code
- **TensorFlow version (use command below)**: r1.2

- **Bazel version (if compiling from source)**:

$ bazel version
Build label: 0.4.4
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Wed Feb 1 18:54:21 2017 (1485975261)
Build timestamp: 1485975261
Build timestamp as int: 1485975261

- **Exact command to reproduce**:

$ bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package"
10780,1.2 release python pip version is incorrect,"The python pip package still has the version label 1.2.0-rc2 even though 1.2.0 was released proper today. Can you change please.

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/pip_package/setup.py#L32
"
10779,Mac + Python 3.6.1: Attempting to download mnist data results in CERTIFICATE_VERIFY_FAILED error,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS X 10.12.5
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.2.0-rc2-21-g12f033d 1.2.0
- **Bazel version (if compiling from source)**: n/a
- **CUDA/cuDNN version**: none
- **GPU model and memory**: n/a
- **Exact command to reproduce**:

```
$ python3 --version
Python 3.6.1

$ python3 -m virtualenv venv
Using base prefix '/Library/Frameworks/Python.framework/Versions/3.6'
New python executable in .../venv/bin/python3
Also creating executable in .../venv/bin/python
Installing setuptools, pip, wheel...done.

$ source venv/bin/activate
$ pip install tensorflow
Collecting tensorflow
  Using cached tensorflow-1.2.0-cp36-cp36m-macosx_10_11_x86_64.whl
  ....

$ python
Python 3.6.1 (v3.6.1:69c0db5050, Mar 21 2017, 01:21:04) 
[GCC 4.2.1 (Apple Inc. build 5666) (dot 3)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> from tensorflow.examples.tutorials.mnist import input_data
>>> mnist = input_data.read_data_sets(""/tmp/data/"")
Traceback (most recent call last):
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py"", line 1318, in do_open
    encode_chunked=req.has_header('Transfer-encoding'))
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py"", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py"", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py"", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py"", line 1026, in _send_output
    self.send(msg)
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py"", line 964, in send
    self.connect()
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py"", line 1400, in connect
    server_hostname=server_hostname)
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/ssl.py"", line 401, in wrap_socket
    _context=self, _session=session)
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/ssl.py"", line 808, in __init__
    self.do_handshake()
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/ssl.py"", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/ssl.py"", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:749)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File "".../venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py"", line 235, in read_data_sets
    SOURCE_URL + TRAIN_IMAGES)
  File "".../venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py"", line 208, in maybe_download
    temp_file_name, _ = urlretrieve_with_retry(source_url)
  File "".../venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py"", line 165, in wrapped_fn
    return fn(*args, **kwargs)
  File "".../venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py"", line 190, in urlretrieve_with_retry
    return urllib.request.urlretrieve(url, filename)
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py"", line 248, in urlretrieve
    with contextlib.closing(urlopen(url, data)) as fp:
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py"", line 223, in urlopen
    return opener.open(url, data, timeout)
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py"", line 526, in open
    response = self._open(req, data)
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py"", line 544, in _open
    '_open', req)
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py"", line 504, in _call_chain
    result = func(*args)
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py"", line 1361, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py"", line 1320, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:749)>
```

This doesn't reproduce with TensorFlow 1.1.
"
10777,Error: map_fn = tf.python.functional_ops.map_fn AttributeError: module 'tensorflow' has no attribute 'python',"Error on System: py3.5, win7, tf 1.2 cpu version.

map_fn = tf.python.functional_ops.map_fn
AttributeError: module 'tensorflow' has no attribute 'python'
"
10776,Docker build issues -- libcuda.so.1 cannot be found,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No, I'm using baidu's warp-ctc which has custom code
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: N/A, using docker
- **TensorFlow installed from (source or binary)**: provided docker image
- **TensorFlow version (use command below)**: 1.2.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: Provided
- **GPU model and memory**: N/A
- **Exact command to reproduce**: See below

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

Unable to install warp-ctc with tensorflow in version 1.2, while it works in version 1.0.0

This is screenshot of dockerfile for version 1.0: http://i.imgur.com/Zl9ikYT.png
For newer tensorflow versions (e.g. 1.1 and 1.2 have the same issue) problems occur: http://i.imgur.com/UEcCkOm.png

That is libcuda.so.1 cannot be found. 

I've opened similar issue on nvidia-docker https://github.com/NVIDIA/nvidia-docker/issues/374 since I've used their images and installed tensorflow via pip with same exact issues. Only change is tensorflow verions while everything else remains the same.

I'm unable to test this outside docker contained due to machine permissions (or lack thereof, no admin and cannot install newer CUDA/cuDNN/etc.)

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

Here is dockerfile used in the reproduction:
```
FROM tensorflow/tensorflow:1.2.0-devel-gpu-py3
 
RUN apt-get update && apt-get install -y --no-install-recommends \
        build-essential \
        python3-setuptools \
        python3-dev \
        python3-pip \
        python3-numpy \
        python3-scipy \
        software-properties-common \
        libhdf5-serial-dev \
        cmake \
        git \
        && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*
 
WORKDIR /opt
ENV TENSORFLOW_SRC_PATH=/opt/tensorflow
ENV WARP_CTC_PATH=/opt/warp-ctc/build
ENV CUDA_HOME=/usr/local/cuda
 
RUN git clone https://github.com/tensorflow/tensorflow.git tensorflow
RUN git clone https://github.com/nmiculinic/warp-ctc.git warp-ctc
 
WORKDIR $TENSORFLOW_SRC_PATH
RUN git checkout tags/v1.2.0
 
WORKDIR /opt/warp-ctc
RUN git checkout 4875195a4444991b5c8c6027ffd4bd485e2aac3a
 
RUN mkdir build
WORKDIR /opt/warp-ctc/build
RUN cmake .. && make
WORKDIR /opt/warp-ctc/tensorflow_binding
RUN python3 setup.py install
```"
10773,PIP: Don't lock markdown version to 2.2.0,"https://github.com/tensorflow/tensorflow/issues/10744

> This markdown version lock could cause versioning conflict for downstream (e.g. if requirements are compiled and resolved by pip-compile). Wondering If there's a reason to lock this version. And it's already not sync with the CI install script (those --upgrade with locked version also doesn't seem right to me)."
10769,RunMetadata giving inconsistent RAM values,"When viewing the GPU memory usage of a run metadata in TensorBoard, it shows for example one node ""model"" with 9.99 GB and another node ""optimization"" with 14.1 GB. The sum of these values exceeds the available memory on the GPU (12 GB) by far."
10768,Undefined Symbol Import error ,"Hi,

SO: Linux Mint 17 x64
Version 1.1
Compiling from source
Options: sycl (Opencl)
Python 2.7

_Using TensorFlow backend.
Traceback (most recent call last):
  File ""/home/kafka/PycharmProjects/Test1/Test1.py"", line 1, in <module>
    from keras.models import Sequential
  File ""/usr/local/lib/python2.7/dist-packages/keras/__init__.py"", line 3, in <module>
    from . import activations
  File ""/usr/local/lib/python2.7/dist-packages/keras/activations.py"", line 4, in <module>
    from . import backend as K
  File ""/usr/local/lib/python2.7/dist-packages/keras/backend/__init__.py"", line 73, in <module>
    from .tensorflow_backend import *
  File ""/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py"", line 1, in <module>
    import tensorflow as tf
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 51, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 52, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
ImportError: /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZN2cl4sycl7program30create_program_for_kernel_implESsPKhiPKPKcSt10shared_ptrINS0_6detail7contextEE


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help._




"
10767,[Feature Request] Exclude ties in function in_top_k,"This is a feature request related to #10489 (tie handling in function in_top_k)

Would it be possible to add an option/argument specifying whether ties should be included or excluded?
In other words, make it possible for ties to return False instead of True.

Thanks!"
10766,MultivariateNormalDiag probability gradient fails,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS 10.12.5
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: v1.2.0-rc2-0-gce1d6ec49 1.2.0-rc2
- **Bazel version (if compiling from source)**: 0.5.1-homebrew
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: python test_diag.py

### Describe the problem
The gradients for the tensorflow.contrib.distributions.MultiVariateNormalDiag throw an error.  This might be related to #10149.  Notice that the tensorflow.contrib.distributions.Normal works as expected so I think this is a bug in the gradient implementation of the MultiVarateNormalDiag.

### Source code
```python
import numpy as np
import tensorflow as tf
import tensorflow.contrib.distributions as td

assert_args = dict(validate_args=True, allow_nan_stats=False)

# tf Graph Input
x = tf.placeholder(shape=(4, 6), dtype=tf.float32, name=""X"")
y = tf.placeholder(shape=(4, 2), dtype=tf.float32, name=""Y"")

# Set model weights
b = tf.Variable(np.ones((4, 6)), dtype=np.float32, name=""b"")
W = tf.Variable(np.ones((6, 6)), dtype=np.float32, name=""W"")

pred_mu = tf.reshape(x@W + b, (4, 3, 2))
pred_sigma = tf.reshape(tf.exp(x@W + b), (4, 3, 2))

# fails below
dist = td.MultivariateNormalDiag(loc=pred_mu, scale_diag=pred_sigma, **assert_args)
prob = dist.prob(y[:, tf.newaxis])

# this works fine
# dist_x = td.Normal(loc=pred_mu[:, :, 0], scale=pred_sigma[:, :, 0], **assert_args)
# dist_y = td.Normal(loc=pred_mu[:, :, 1], scale=pred_sigma[:, :, 1], **assert_args)
# prob = dist_x.prob(y[:, 0, tf.newaxis]) * dist_y.prob(y[:, 1, tf.newaxis])

gradients = tf.gradients(prob, [b, W])

feed_dict = {
    x: np.ones((4, 6), dtype=np.float32),
    y: np.ones((4, 2), dtype=np.float32)
}

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    sess.run(prob, feed_dict=feed_dict)  # works fine
    retval = sess.run(gradients, feed_dict=feed_dict)  # throws
    print(retval)
```

### Output
```
Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1139, in _do_call
    return fn(*args)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1121, in _run_fn
    status, run_metadata)
  File ""/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/contextlib.py"", line 89, in __exit__
    next(self.gen)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py"", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: indices[0] = -1 is not in [0, 3)
	 [[Node: gradients/MultivariateNormalDiag_3/prob/Prod_grad/Gather = Gather[Tindices=DT_INT32, Tparams=DT_INT32, validate_indices=true, _device=""/job:localhost/replica:0/task:0/cpu:0""](gradients/MultivariateNormalDiag_3/prob/Prod_grad/Shape, gradients/MultivariateNormalDiag_3/prob/Prod_grad/Reshape)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""test_diag.py"", line 41, in <module>
    retval = sess.run(gradients, feed_dict=feed_dict) # throws
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 789, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 997, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1132, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1152, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: indices[0] = -1 is not in [0, 3)
	 [[Node: gradients/MultivariateNormalDiag_3/prob/Prod_grad/Gather = Gather[Tindices=DT_INT32, Tparams=DT_INT32, validate_indices=true, _device=""/job:localhost/replica:0/task:0/cpu:0""](gradients/MultivariateNormalDiag_3/prob/Prod_grad/Shape, gradients/MultivariateNormalDiag_3/prob/Prod_grad/Reshape)]]

Caused by op 'gradients/MultivariateNormalDiag_3/prob/Prod_grad/Gather', defined at:
  File ""test_diag.py"", line 31, in <module>
    gradients = tf.gradients(prob, [b, W])
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py"", line 540, in gradients
    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py"", line 346, in _MaybeCompile
    return grad_fn()  # Exit early
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py"", line 540, in <lambda>
    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py"", line 129, in _ProdGrad
    reduced_num = math_ops.reduce_prod(array_ops.gather(input_shape, reduced))
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 1179, in gather
    validate_indices=validate_indices, name=name)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 767, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 2506, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1269, in __init__
    self._traceback = _extract_stack()

...which was originally created as op 'MultivariateNormalDiag_3/prob/Prod', defined at:
  File ""test_diag.py"", line 24, in <module>
    prob = dist.prob(y[:,tf.newaxis])
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/distributions/distribution.py"", line 712, in prob
    return self._call_prob(value, name)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/distributions/distribution.py"", line 694, in _call_prob
    return self._prob(value, **kwargs)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/distributions/util.py"", line 688, in _fn
    return fn(*args, **kwargs)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_linear_operator.py"", line 216, in _prob
    return super(MultivariateNormalLinearOperator, self)._prob(x)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/distributions/transformed_distribution.py"", line 406, in _prob
    prob = math_ops.reduce_prod(prob, self._reduce_event_indices)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py"", line 1392, in reduce_prod
    name=name)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py"", line 1488, in _prod
    keep_dims=keep_dims, name=name)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 767, in apply_op
    op_def=op_def)

InvalidArgumentError (see above for traceback): indices[0] = -1 is not in [0, 3)
	 [[Node: gradients/MultivariateNormalDiag_3/prob/Prod_grad/Gather = Gather[Tindices=DT_INT32, Tparams=DT_INT32, validate_indices=true, _device=""/job:localhost/replica:0/task:0/cpu:0""](gradients/MultivariateNormalDiag_3/prob/Prod_grad/Shape, gradients/MultivariateNormalDiag_3/prob/Prod_grad/Reshape)]]
```"
10765,[Performance] contirb.seq2seq.attention_wrapper slower due to using matmul instead of reduce_sum,"tf version '1.2.0-rc0' contirb.seq2seq.attention_wrapper is great, it make using attention much easier.
However I found using attention_wrapper will be much slower then tf version 1.0.
After some experiment I found it is due to using matmul instead of reduce_sum.

from attetntion_wrapper.py 731
      
      expanded_alignments = array_ops.expand_dims(alignments, 1)
      attention_mechanism_values = self._attention_mechanism.values
      context = math_ops.matmul(expanded_alignments, attention_mechanism_values)
      context = array_ops.squeeze(context, [1])

Using above code for one of my application got 2.2 batch/s, after changing to use reduce_sum(as tf version 1.0 did), the speed is 3.4 batch/s, improve a lot.

      expanded_alignments = array_ops.expand_dims(alignments, 2)
      attention_mechanism_values = self._attention_mechanism.values
      context = math_ops.reduce_sum(expanded_alignments * attention_mechanism_values, [1])"
10764,"There is QuantizedInstanceNorm operation registered, But I could not find InstanceNorm operation anywhere.","OS: Ubuntu 16.04 64bits
Android Version: 7.1 (Nougat)
NDK Version: android-ndk-r12b
HEXAGON SDK: 3.1

There is **QuantizedInstanceNorm** operation registered, But I could not find **InstanceNorm** operation anywhere.

I am not sure why Quantized form is added without its original instance form, Maybe to convert graphs trained using other nets into pb and quantize them. Well this is my assumption.

Could anyone tell how can I get **instancenorm** operation.


thanks"
10763,What is the possible op substitute for set of OPerations on CPU to DSP Hexagon,"OS: Ubuntu 16.04 64bits
Android Version: 7.1 (Nougat)
NDK Version: android-ndk-r12b
HEXAGON SDK: 3.1
nnlib source: https://source.codeaurora.org/quic/hexagon_nn/nnlib

I am trying to build a graph to run on hexagon,
it uses few op's which hexagon doesn't support.

native : graph_transferer.cc:109 Failed to transfer graph Invalid argument: Mean has not been implemented yet.

OP's details are as below:-

 {""Mean"", SupportedOpType::**??**},
 {""RealDiv"", SupportedOpType::**??**},
 {""Pow"", SupportedOpType::**??**},
 {""Conv2DBackpropInput"", SupportedOpType::**??**},
 {""Square"", SupportedOpType::**??**},
 {""SquaredDifference"", SupportedOpType::**??**},
 {""StopGradient"", SupportedOpType::**??**},
 {""Reciprocal"", SupportedOpType::**??**},

Is there any possible substitute for the operation types Mean, Pow, Conv2DBackpropInput etc.. for hexagon.

thanks in advance."
10761,Feature Request : Tensor Roll,"Could you add an equivalent to [Numpy roll](https://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.roll.html) on Tensor in tensorflow in order to allow the user to roll a Tensor along one of the axis of the tensor ?
"
10759,GPU->CPU Memcpy failed Error or InternalError c2c fft failed Error when using FFT2D ,"### The problem
I wrote a python script that used FFT2D from tensorflow you can find the Python script attached : TestFFT2D.py using GPU.

In this script, I first create a convolution apply to a tensor and than compute a loss between a reference input tensor and a variable one with ftt2d and ifft2d operations.

When I launch my script, I get a GPU->CPU Memcpy failed Error or an InternalError c2c fft failed Error. I don't know why the error change when I run again my script. 
I test my code on two differents machine with Ubuntu 16.04 one with a GeForce GTX 680 GPU and one with a GeForce GTX 1080. In both case, I can randomly get both of the error messages.
[Abandon.txt](https://github.com/tensorflow/tensorflow/files/1080533/Abandon.txt)
[InternalError.txt](https://github.com/tensorflow/tensorflow/files/1080532/InternalError.txt)
Sometimes, my machine just crashes and I need to reboot it.

### Source code / logs
You can find the terminal messages errors attached.
This is the TestFFT2D.py code : [TestFFT2D.py ](https://github.com/nicaogr/silver-octo-fortnight/blob/master/TestFFT2D.py)
`
import tensorflow as tf
import numpy as np

def get_loss(sess,net,img_ref,layer):
    
    total_loss  = 0.
    
    sess.run(net['input'].assign(img_ref))  
    x = net[layer]
    a = sess.run(net[layer])
    x = tf.transpose(x, [0,3,1,2])
    a = tf.transpose(a, [0,3,1,2])
    _,N,_,_ = a.shape
    F_x = tf.fft2d(tf.complex(x,0.))
    F_x_conj = tf.conj(F_x)
    F_a = tf.fft2d(tf.complex(a,0.))
    F_a_conj = tf.conj(F_a)
    
    for i in range(N):
        inter_corr_x = tf.multiply(F_x,F_x_conj)
        inter_corr_a = tf.multiply(F_a,F_a_conj)
        
        ifft2_corr_x = tf.ifft2d(inter_corr_x)
        ifft2_corr_a = tf.ifft2d(inter_corr_a)
        
        R_x = tf.real(ifft2_corr_x)
        R_a = tf.real(ifft2_corr_a)
        
        style_loss = tf.nn.l2_loss(tf.subtract(R_x,R_a))  
        total_loss += style_loss
        
        # Shift the tensor from on 1 unit on the dimension 1
        F_x = tf.concat([tf.expand_dims(F_x[:,-1,:,:],0), F_x[:,:-1,:,:]], axis=1)
        F_a = tf.concat([tf.expand_dims(F_a[:,-1,:,:],0), F_a[:,:-1,:,:]], axis=1)
            
    return(total_loss)

def main(args):
    
    # Definition of the first operations :
    height, width, numberChannels = 400,300,3
    net = {}
    current = tf.Variable(np.zeros((1, height, width, numberChannels), dtype=np.float32))
    net['input'] = current
    kernel = tf.constant(np.random.uniform(low=-1,high=1,size=(400,300,3,64)),dtype=np.float32)
    conv = tf.nn.conv2d(current, kernel, strides=(1, 1, 1, 1),padding='SAME',name='conv')
    bias = tf.constant(np.random.uniform(low=-1,high=1,size=(64)),dtype=np.float32)
    conv_add_bias = tf.nn.bias_add(conv, bias)
    net['conv1_1'] = conv_add_bias
    
    img_ref = np.random.uniform(low=-128,high=128,size=(1, height, width, numberChannels))
    init_img = np.random.uniform(low=-128,high=128,size=(1, height, width, numberChannels))
    
    sess = tf.Session()
    
    sess.run(net['input'].assign(img_ref))  
    # Definition of the loss 
    loss = get_loss(sess,net,img_ref,'conv1_1')
        
    # Preparation of the assignation operation
    placeholder = tf.placeholder(tf.float32, shape=init_img.shape)
    assign_op = net['input'].assign(placeholder)
        
    sess.run(tf.global_variables_initializer())
    sess.run(assign_op, {placeholder: init_img})
    print(""Before loss evaluation"")
    loss_evaluation = sess.run(loss)
    print(""loss_evaluation"",loss_evaluation)
    
    return(0)

if __name__ == '__main__':
    import sys
    sys.exit(main(sys.argv))
`
### System information
- **Have I written custom code **: TestFFT2D.py
- **OS Platform and Distribution**: Linux Ubuntu 16.04
- **TensorFlow installed from**: Source
- **TensorFlow version**: v1.0.0-65-g4763edf-dirty 1.0.1
- **CUDA/cuDNN version**:
Cuda compilation tools, release 7.5, V7.5.17 and  cuDNN  5 with the GeForce GTX 680
 Cuda compilation tools, release 8.0, V8.0.61and cuDNN 5 with the GeForce GTX 1080
- **GPU model and memory**: Tested on GeForce GTX 680 with 2Go and on GeForce GTX 1080 with 12Go
- ** Python version**: Python 3.6.1 |Anaconda 4.4.0 (64-bit)|
- **Exact command to reproduce**: python TestFFT2D.py : copy-paste the code above and run it with python 3


"
10757, SparseMatmulOpTest.BroadcastPacketTest is failing on ppc64le,"### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
     Ubuntu 16.04 (ppc64le)
- **TensorFlow installed from (source or binary)**:
      Installed from source (v1.0.1)
- **TensorFlow version (use command below)**:
     ('v1.0.1-0-ge895d5c-dirty', '1.0.1')
- **Bazel version (if compiling from source)**:
     0.4.4-2017-05-26 (@80a07b5)
- **CUDA/cuDNN version**:
      CUDA = 8.0 and cuDNN = 5.1
- **GPU model and memory**:
      GPU 0: Tesla P100-SXM2-16GB
      GPU 1: Tesla P100-SXM2-16GB
- **Exact command to reproduce**:
      bazel test --config=opt --config=cuda //tensorflow/core/kernels:sparse_matmul_op_test_gpu

### Describe the problem
This is regarding failure of test case `SparseMatmulOpTest.BroadcastPacketTest` in `tensorflow/core/kernels/sparse_matmul_op_test.cc` file.While executing this test case on ppc64le, it was observed that following line returns unexpected results:
https://github.com/tensorflow/tensorflow/blob/v1.0.1/tensorflow/core/kernels/sparse_matmul_op_test.cc#L255
```
internal::pstoreu(data2, internal::pbroadcast_first<Packet>(
                              internal::ploadu<Packet>(data1)));

```
Here we are getting expected result on `x86` for data2 array = `[0.170094 0.170094 0.170094 0.170094]`, however on `ppc64le` getting incorrect result i.e. `[  0.170094    0.14922 -0.0823886   0.026985]`

I have done some investigation around this - using `print/cout` statement I tried to understand the code flow on `ppc64le `as well as on `X86 `platform.
Here I found that for `internal::pbroadcast_first<Packet>` line ,on both the platform executed different functions, see below-
On x86 executed `EIGEN_STRONG_INLINE Packet4f pbroadcast_first<Packet4f>(const Packet4f& a) ` function(https://github.com/tensorflow/tensorflow/blob/v1.0.1/tensorflow/core/kernels/sparse_matmul_op.h#L197)
And on ppc64le executed some different function i.e. `EIGEN_DEVICE_FUNC inline Packet pbroadcast_first(const Packet& a)` (https://github.com/tensorflow/tensorflow/blob/v1.0.1/tensorflow/core/kernels/sparse_matmul_op.h#L92)

That is why we are getting incorrect result on ppc64le for data2 array and test fails.
I have done some debugging on this but couldn't find the reason - why control is going to different functions on both the platform for `internal::pbroadcast_first<Packet>` ?

If could get any suggestions/pointers to why this is happening that would be great! 
(I am new to tensorflow code but interested/would-like-to debug & help)

Thanks!

### Source code / logs
```
$  bazel test --config=opt --config=cuda //tensorflow/core/kernels:sparse_matmul_op_test_gpu

exec ${PAGER:-/usr/bin/less} ""$0"" || exit 1
-----------------------------------------------------------------------------
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
Running main() from test_main.cc
[==========] Running 4 tests from 1 test case.
[----------] Global test environment set-up.
[----------] 4 tests from SparseMatmulOpTest
[ RUN      ] SparseMatmulOpTest.BroadcastPacketTest
[0.170094 0.170094 0.170094 0.170094] != [  0.170094    0.14922 -0.0823886   0.026985], differences: [         0 -0.0208738  -0.252482  -0.143109]
tensorflow/core/kernels/sparse_matmul_op_test.cc:257: Failure
Value of: areApprox(ref, data2, PacketSize)
  Actual: false
Expected: true
[  FAILED  ] SparseMatmulOpTest.BroadcastPacketTest (0 ms)
[ RUN      ] SparseMatmulOpTest.InterleavePacketTest
[       OK ] SparseMatmulOpTest.InterleavePacketTest (0 ms)
[ RUN      ] SparseMatmulOpTest.Bfloat16ExpandTest
[       OK ] SparseMatmulOpTest.Bfloat16ExpandTest (0 ms)
[ RUN      ] SparseMatmulOpTest.Bfloat16LoadTest
[       OK ] SparseMatmulOpTest.Bfloat16LoadTest (0 ms)
[----------] 4 tests from SparseMatmulOpTest (0 ms total)

[----------] Global test environment tear-down
[==========] 4 tests from 1 test case ran. (0 ms total)
[  PASSED  ] 3 tests.
[  FAILED  ] 1 test, listed below:
[  FAILED  ] SparseMatmulOpTest.BroadcastPacketTest

 1 FAILED TEST

```"
10756,Embedding visualizer of tensorboard is a blank page,"### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: master c007ee2c1f8701effb410f632e9d8c4cd120f9c0
- **Bazel version (if compiling from source)**: 0.5.0
- **CUDA/cuDNN version**: 8.0.44/7.0
- **GPU model and memory**: Titan X (Pascal)
- **Exact command to reproduce**: tensorboard --logdir <path to model>

### Describe the problem

Similarily to [this stackoverflow question](https://stackoverflow.com/questions/44201246/tensorboard-embedding-projector-blank) I have completely blank page without any controls when I'm trying to use the tensorboard embedding visualizer from the latest master. There is nothing in logs (at least on default log level).

Tensorboard from 1.0, 1.1, 1.2 binaries is working."
10755,Weird behavior of tf.train.Saver,"### System information
- Linux Ubuntu 14.04
- TensorFlow installed from binary:
- TensorFlow version v1.0.0-rc2:
- CUDA: 8.0, CuDNN: 5.1
- Tesla K80, 12GB

### Describe the problem
I have a problem with the tf.train.Saver, specifically with the 'max_to_keep' argument. If I create a Saver with 'max_to_keep' set to let's say 3 and use the saver.save function to save my model in the current directory it keeps all files and doesn't delete the old ones after 3 or more are created. If I set the path where to save the model to a different location it works just fine.

See also my [stackoverflow question](https://stackoverflow.com/questions/44458947/tensorflow-keeps-all-files-how-to-prevent-that)

### Source code / logs
Creates for the numbers 1 to 10 each 3 files:

- testfile-1.data-00000-of-00001
- testfile-1.index
- testfile-1.meta

```
import tensorflow as tf

a = tf.Variable(name='a', initial_value=0)
addops = a+1

saver = tf.train.Saver(max_to_keep=3)
config = tf.ConfigProto()
config.gpu_options.allow_growth = True
sess = tf.Session(config=config)
sess.run(tf.global_variables_initializer())
for i in range(10):
    sess.run(addops)
    save_path = saver.save(sess, 'testfile', global_step=i+1)

sess.close()
```

This code works as expected and deletes all the old files and I only end up with the numbers 8 to 10:

```
import tensorflow as tf

a = tf.Variable(name='a', initial_value=0)
addops = a+1

saver = tf.train.Saver(max_to_keep=3)
config = tf.ConfigProto()
config.gpu_options.allow_growth = True
sess = tf.Session(config=config)
sess.run(tf.global_variables_initializer())
for i in range(10):
    sess.run(addops)
    save_path = saver.save(sess, 'test/testfile', global_step=i+1)

sess.close()
```"
10754,The current makefile is incomplete,Can someone provide a makefile that is equivalent to //tensorflow:libtensorflow_cc.so? This current makefile is missing many C++ API's. Is there a way to find all the files needed to build //tensorflow:libtensorflow_cc.so (recursively)?
10749,Numpy.fft.fft2() gives different result than tf.fft2d(),"as mentioned in the issue #6401, the tf.fft2d() gives different result compared to np.fft.fft2(). Is there a reason for this ?

Note : numpy gives proper fourier transform after np.fft.fftshift(), and I have taken care of that in my code.
The differences are not visible here, but the mean squared error is significant.

![image1](https://user-images.githubusercontent.com/18488880/27207200-84637a88-5202-11e7-9d49-d22cf9a8057d.png)![image2](https://user-images.githubusercontent.com/18488880/27207198-8462f2b6-5202-11e7-88c2-7114b36c696a.png)    ![image3](https://user-images.githubusercontent.com/18488880/27207199-8462fe50-5202-11e7-8d7b-bca01bba063b.png)   ![image4](https://user-images.githubusercontent.com/18488880/27207631-f2a41284-5205-11e7-91a6-336d75755787.png)

Second image is the fft using tensorflow, and third one is using numpy. You can see the difference in the corners. The fourth image is the difference between the two images times 10.

 (tf has some features while numpy does not)

I am working on an application which uses fft in backpropagation and thus it is of absolute importance that the fft in numpy are same as fft by tf.

My question is - Why is there a difference and how can I get the same fft as numpy ?


"
10747,Striding behaviour different between caffe and tensorflow,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 14.04
- **TensorFlow installed from (source or binary)**: Binary (pip install)
- **TensorFlow version (use command below)**: ('v1.2.0-rc2-21-g12f033d', '1.2.0')
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: 8.0
- **GPU model and memory**: Tesla P100-SXM2 16MB
- **Exact command to reproduce**: python caffe_to_tf_test.py

### Describe the problem
Caffe convolution produce different results then tensorflow with the same parameters.   This has something to do with striding - the attached test fails with striding equal to 2, and succeeds with striding equal to 1.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

[x.zip](https://github.com/tensorflow/tensorflow/files/1079200/x.zip)

"
10744,[PIP] Markdown version locked to `2.2.0`,This markdown version lock could cause versioning conflict for downstream (e.g. if requirements are compiled and resolved by pip-compile). Wondering If there's a reason to lock this version. And it's already not sync with the [CI install script](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/install/install_pip_packages.sh) (those `--upgrade` with locked version also doesn't seem right to me). 
10742,The current makefile builds incomplete Tensorflow,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.1
- **Bazel version (if compiling from source)**: not using bazel
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
I have managed to cross compile using the Makefile approach but the API's are incomplete. I think it is because not all source files are included in the Makefile and the text files. Can someone provides a Makefile that is equivalent to bazel build //tensorflow:libtensorflow_cc.so? I want to cross compile a library and use that on my custom platform.

### Source code / logs

"
10741,[go] bug in Shape.size for dim == NumDimensions,"### System information
This does not matter.

### Describe the problem
(go) when dim equals s.NumDimensions(), the function should return -1, instead it panics.

### Source code / logs
In [shape.go](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/go/shape.go#L62), `Shape.Size` method

        func (s Shape) Size(dim int) int64 {
    ---   if dim < 0 || dim > s.NumDimensions() {
            return -1
should be:

        func (s Shape) Size(dim int) int64 {
    +++   if dim < 0 || dim >= s.NumDimensions() {
            return -1
"
10740,"Type error occurring in the input pipeline should give more descriptive error messages than ""RandomShuffleQueue is closed and has insufficient elements""","I don't have a particular code example, but I had the case that a `tf.py_func` node returned the wrong data type and thus caused the queue to stall. It was impossible to tell what the error was from the error messages that TensorFlow produced. What is the reason that there are no error messages about type mismatches?"
10739,Quantized graph using graph transform fails to work,"**System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): v1.1
Bazel version (if compiling from source): N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A
Exact command to reproduce:**

I am using a quantized graph created using following command:

bazel-bin/tensorflow/tools/graph_transforms/transform_graph 
--in_graph=./frozen_model_inception_resnet_v2.pb 
--out_graph=./quantized_weights_and_nodes_inception_resnet_v2.pb 
--inputs='InputImage:0' 
--outputs='InceptionResnetV2/Logits/Predictions' 
--transforms='
add_default_attributes
strip_unused_nodes(type=float, shape=""1,299,299,3"")
remove_nodes(op=Identity, op=CheckNumerics)
fold_constants(ignore_errors=true)
fold_batch_norms
fold_old_batch_norms
quantize_weights
quantize_nodes
strip_unused_nodes
sort_by_execution_order'

I try to use the graph in a program as below:

graph_def = tf.GraphDef()
    with open(os.path.join(FLAGS.model_dir, GRAPH_FILE), ""rb"") as f:
        model_str = f.read()
        graph_def.ParseFromString(model_str)
        tf.import_graph_def(graph_def, name='')

However, I get error ""ValueError: No op named QuantizedAdd in defined operations"" now when tf.import_graph_def(graph_def, name='') is called.

I also tried to use :         dir(tf.contrib) as explained in one of the issues : https://github.com/tensorflow/tensorflow/issues/10130

graph_def = tf.GraphDef()
    with open(os.path.join(FLAGS.model_dir, GRAPH_FILE), ""rb"") as f:
        model_str = f.read()
        graph_def.ParseFromString(model_str)
        dir(tf.contrib)
        tf.import_graph_def(graph_def, name='')

but this did not solve the problem for me, I still get same error."
10738,"hexagon graph execution has put checks for inputs to be of square dimensions, why is it so?","OS: Ubuntu 16.04 64bits
Android Version: 7.1 (Nougat)
NDK Version: android-ndk-r12b
HEXAGON SDK: 3.1
nnlib source: https://source.codeaurora.org/quic/hexagon_nn/nnlib

I want to test against input shape 1 640 480 3
Below check is returning with error as it is looking for square dimensions.
(https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/hexagon/hexagon_graph_execution_test.cc#L136)
`CHECK(fsize >= (WIDTH + 1) * WIDTH * 3 + header_size);`

I am not sure whether I can comment that and I did following that I got this error:
(https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/hexagon/hexagon_graph_execution_test.cc#L147)
```
CHECK(src_pos + 2 + header_size < fsize);
CHECK(dst_pos + 2 < pixel_count);
```

Also cannot give input graph as argument while running -> hexagon_graph_execution.
it needs to be changed @ 
(https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/hexagon/hexagon_graph_execution_test.cc#L52)
```

constexpr const char* const IMAGE_FILENAME = ""/data/local/tmp/img_299x299.bmp"";
constexpr const char* const MODEL_FILENAME =
""/data/local/tmp/tensorflow_inception_v3_stripped_optimized_quantized.pb"";
```

any plans for standard interface to change 
1) input shape
2) model filename
3) Image filename

thanks,"
10736,seq2seq.BasicDecoder incompatible with seq2seq.ScheduledOutputTrainingHelper,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source 
- **TensorFlow version (use command below)**:  b'v1.1.0-0-g1ec6ed5' 1.1.0
- **Bazel version (if compiling from source)**: 0.5.1
- **CUDA/cuDNN version**: 5.1.3
- **GPU model and memory**: TitanX 12GB
- **Exact command to reproduce**: See script below

### Describe the problem
`seq2seq.ScheduledOutputTrainingHelper.sample(...)` outputs a `tf.bool` tensor but `seq2seq.BasicDecoder.output_dtype` assumes `tf.int32` output.

### Source code / logs
Minimal case script:
```python
import tensorflow as tf
with tf.Graph().as_default():
    batch_size = 32
    nsteps = 100
    ndims = 5
    sequence_length = [nsteps] * batch_size
    sampling_probability = 0.5
    num_units = 20

    cell = tf.contrib.rnn.BasicRNNCell(
        num_units,
    )

    inputs = tf.random_uniform((batch_size, nsteps, ndims))

    output, state = tf.nn.dynamic_rnn(
        cell,
        inputs,
        dtype=tf.float32,
    )

    cell = tf.contrib.rnn.BasicRNNCell(
        num_units,
    )

    helper = tf.contrib.seq2seq.ScheduledOutputTrainingHelper(
        output,
        sequence_length,
        sampling_probability,
    )

    initial_state = tf.zeros((batch_size, num_units))
    decoder = tf.contrib.seq2seq.BasicDecoder(
        cell,
        helper,
        initial_state,
    )

    decoded = tf.contrib.seq2seq.dynamic_decode(
        decoder,
    )

    run_ops = {'decoded': decoded}
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        ret = sess.run(run_ops)
```
Output:
```bash
2017-06-15 12:28:39.868640: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-06-15 12:28:39.868659: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-15 12:28:39.868664: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-06-15 12:28:40.234562: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-06-15 12:28:40.234768: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties:
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.076
pciBusID 0000:01:00.0
Total memory: 11.92GiB
Free memory: 384.19MiB
2017-06-15 12:28:40.234817: W tensorflow/stream_executor/cuda/cuda_driver.cc:485] creating context when one is currently active; existing: 0x31b49d0
2017-06-15 12:28:40.315855: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-06-15 12:28:40.316063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 1 with properties:
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.076
pciBusID 0000:02:00.0
Total memory: 11.92GiB
Free memory: 384.19MiB
2017-06-15 12:28:40.318076: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 1
2017-06-15 12:28:40.318084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y Y
2017-06-15 12:28:40.318088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 1:   Y Y
2017-06-15 12:28:40.318093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:01:00.0)
2017-06-15 12:28:40.318098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX TITAN X, pci bus id: 0000:02:00.0)
2017-06-15 12:28:40.927295: W tensorflow/core/framework/op_kernel.cc:1152] Invalid argument: TensorArray dtype is int32 but Op is trying to write dtype bool.
	 [[Node: decoder/while/TensorArrayWrite_1/TensorArrayWriteV3 = TensorArrayWriteV3[T=DT_BOOL, _class=[""loc:@decoder/TensorArray_1""], _device=""/job:localhost/replica:0/task:0/cpu:0""](decoder/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter, decoder/while/Identity/_47, decoder/while/BasicDecoderStep/ScheduledOutputTrainingHelperSample/Cast/_49, decoder/while/Identity_2/_51)]]
2017-06-15 12:28:40.927295: W tensorflow/core/framework/op_kernel.cc:1152] Invalid argument: TensorArray dtype is int32 but Op is trying to write dtype bool.
	 [[Node: decoder/while/TensorArrayWrite_1/TensorArrayWriteV3 = TensorArrayWriteV3[T=DT_BOOL, _class=[""loc:@decoder/TensorArray_1""], _device=""/job:localhost/replica:0/task:0/cpu:0""](decoder/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter, decoder/while/Identity/_47, decoder/while/BasicDecoderStep/ScheduledOutputTrainingHelperSample/Cast/_49, decoder/while/Identity_2/_51)]]
2017-06-15 12:28:40.927369: W tensorflow/core/framework/op_kernel.cc:1152] Invalid argument: TensorArray dtype is int32 but Op is trying to write dtype bool.
	 [[Node: decoder/while/TensorArrayWrite_1/TensorArrayWriteV3 = TensorArrayWriteV3[T=DT_BOOL, _class=[""loc:@decoder/TensorArray_1""], _device=""/job:localhost/replica:0/task:0/cpu:0""](decoder/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter, decoder/while/Identity/_47, decoder/while/BasicDecoderStep/ScheduledOutputTrainingHelperSample/Cast/_49, decoder/while/Identity_2/_51)]]
2017-06-15 12:28:40.927384: W tensorflow/core/framework/op_kernel.cc:1152] Invalid argument: TensorArray dtype is int32 but Op is trying to write dtype bool.
	 [[Node: decoder/while/TensorArrayWrite_1/TensorArrayWriteV3 = TensorArrayWriteV3[T=DT_BOOL, _class=[""loc:@decoder/TensorArray_1""], _device=""/job:localhost/replica:0/task:0/cpu:0""](decoder/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter, decoder/while/Identity/_47, decoder/while/BasicDecoderStep/ScheduledOutputTrainingHelperSample/Cast/_49, decoder/while/Identity_2/_51)]]
2017-06-15 12:28:40.927443: W tensorflow/core/framework/op_kernel.cc:1152] Invalid argument: TensorArray dtype is int32 but Op is trying to write dtype bool.
	 [[Node: decoder/while/TensorArrayWrite_1/TensorArrayWriteV3 = TensorArrayWriteV3[T=DT_BOOL, _class=[""loc:@decoder/TensorArray_1""], _device=""/job:localhost/replica:0/task:0/cpu:0""](decoder/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter, decoder/while/Identity/_47, decoder/while/BasicDecoderStep/ScheduledOutputTrainingHelperSample/Cast/_49, decoder/while/Identity_2/_51)]]
2017-06-15 12:28:40.927469: W tensorflow/core/framework/op_kernel.cc:1152] Invalid argument: TensorArray dtype is int32 but Op is trying to write dtype bool.
	 [[Node: decoder/while/TensorArrayWrite_1/TensorArrayWriteV3 = TensorArrayWriteV3[T=DT_BOOL, _class=[""loc:@decoder/TensorArray_1""], _device=""/job:localhost/replica:0/task:0/cpu:0""](decoder/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter, decoder/while/Identity/_47, decoder/while/BasicDecoderStep/ScheduledOutputTrainingHelperSample/Cast/_49, decoder/while/Identity_2/_51)]]
2017-06-15 12:28:41.647498: W tensorflow/core/framework/op_kernel.cc:1152] Invalid argument: TensorArray dtype is int32 but Op is trying to write dtype bool.
	 [[Node: decoder/while/TensorArrayWrite_1/TensorArrayWriteV3 = TensorArrayWriteV3[T=DT_BOOL, _class=[""loc:@decoder/TensorArray_1""], _device=""/job:localhost/replica:0/task:0/cpu:0""](decoder/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter, decoder/while/Identity/_47, decoder/while/BasicDecoderStep/ScheduledOutputTrainingHelperSample/Cast/_49, decoder/while/Identity_2/_51)]]
Traceback (most recent call last):
  File ""/home/sarroff/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1039, in _do_call
    return fn(*args)
  File ""/home/sarroff/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1021, in _run_fn
    status, run_metadata)
  File ""/home/sarroff/anaconda2/envs/py3/lib/python3.6/contextlib.py"", line 89, in __exit__
    next(self.gen)
  File ""/home/sarroff/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py"", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: TensorArray dtype is int32 but Op is trying to write dtype bool.
	 [[Node: decoder/while/TensorArrayWrite_1/TensorArrayWriteV3 = TensorArrayWriteV3[T=DT_BOOL, _class=[""loc:@decoder/TensorArray_1""], _device=""/job:localhost/replica:0/task:0/cpu:0""](decoder/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter, decoder/while/Identity/_47, decoder/while/BasicDecoderStep/ScheduledOutputTrainingHelperSample/Cast/_49, decoder/while/Identity_2/_51)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""tmp/scratch2.py"", line 46, in <module>
    ret = sess.run(run_ops)
  File ""/home/sarroff/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 778, in run
    run_metadata_ptr)
  File ""/home/sarroff/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 982, in _run
    feed_dict_string, options, run_metadata)
  File ""/home/sarroff/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1032, in _do_run
    target_list, options, run_metadata)
  File ""/home/sarroff/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1052, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: TensorArray dtype is int32 but Op is trying to write dtype bool.
	 [[Node: decoder/while/TensorArrayWrite_1/TensorArrayWriteV3 = TensorArrayWriteV3[T=DT_BOOL, _class=[""loc:@decoder/TensorArray_1""], _device=""/job:localhost/replica:0/task:0/cpu:0""](decoder/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter, decoder/while/Identity/_47, decoder/while/BasicDecoderStep/ScheduledOutputTrainingHelperSample/Cast/_49, decoder/while/Identity_2/_51)]]

Caused by op 'decoder/while/TensorArrayWrite_1/TensorArrayWriteV3', defined at:
  File ""tmp/scratch2.py"", line 40, in <module>
    decoder,
  File ""/home/sarroff/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py"", line 278, in dynamic_decode
    swap_memory=swap_memory)
  File ""/home/sarroff/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2623, in while_loop
    result = context.BuildLoop(cond, body, loop_vars, shape_invariants)
  File ""/home/sarroff/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2456, in BuildLoop
    pred, body, original_loop_vars, loop_vars, shape_invariants)
  File ""/home/sarroff/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2406, in _BuildLoop
    body_result = body(*packed_vars_for_body)
  File ""/home/sarroff/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py"", line 267, in body
    outputs_ta, emit)
  File ""/home/sarroff/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/util/nest.py"", line 305, in map_structure
    structure[0], [func(*x) for x in entries])
  File ""/home/sarroff/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/util/nest.py"", line 305, in <listcomp>
    structure[0], [func(*x) for x in entries])
  File ""/home/sarroff/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py"", line 266, in <lambda>
    outputs_ta = nest.map_structure(lambda ta, out: ta.write(time, out),
  File ""/home/sarroff/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/ops/tensor_array_ops.py"", line 279, in write
    name=name)
  File ""/home/sarroff/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/ops/gen_data_flow_ops.py"", line 2823, in _tensor_array_write_v3
    name=name)
  File ""/home/sarroff/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 768, in apply_op
    op_def=op_def)
  File ""/home/sarroff/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 2336, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/home/sarroff/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1228, in __init__
    self._traceback = _extract_stack()

InvalidArgumentError (see above for traceback): TensorArray dtype is int32 but Op is trying to write dtype bool.
	 [[Node: decoder/while/TensorArrayWrite_1/TensorArrayWriteV3 = TensorArrayWriteV3[T=DT_BOOL, _class=[""loc:@decoder/TensorArray_1""], _device=""/job:localhost/replica:0/task:0/cpu:0""](decoder/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter, decoder/while/Identity/_47, decoder/while/BasicDecoderStep/ScheduledOutputTrainingHelperSample/Cast/_49, decoder/while/Identity_2/_51)]]
```
"
10735,[BUG] Get different image value each feed,"### System information
- OS: Centos 7
- TensorFlow installed from source
- Tensorflow version: both 1.1.0rc1 and 1.2.0rc1
- Bazel version: 0.4.5-jdk7
- CUDA 8.0/ cuDNN 5.1
- GeForce GTX 1080 / 8G

### Describe the problem
Get different values of the same feeded image. 

### Source code
Below is a minimal script that reproduce the problem:
```python
import tensorflow as tf
import numpy as np
from scipy.misc import imread

test_im = some-test-img-path
im = imread(test_im)
im_batch = np.stack([im])

img_feed = tf.placeholder(tf.uint8, (None, None, None, 3))
img_mean = tf.reduce_mean(tf.to_float(img_feed))

with tf.Session() as sess:
  for i in range(10):
    img_mean_tf = sess.run(img_mean, feed_dict={img_feed: im_batch})
    img_mean_np = np.mean(im_batch)
    print('tf img mean: {}, np img mean: {}'.format(img_mean_tf, img_mean_np))
```
"
10733,Timeline incorrectly show most ops on gpu:0,"Timeline show most ops on gpu:0, which disagree with nvidia-smi and device placement log.

TF version v1.2.0-rc0-735-gf48673b (less than two weeks ago)

Attachments (remove txt suffix)
[chrome___tracing.pdf](https://github.com/tensorflow/tensorflow/files/1077664/chrome___tracing.pdf)
[trace.json.txt](https://github.com/tensorflow/tensorflow/files/1077680/trace.json.txt)
[jupyter.log.txt](https://github.com/tensorflow/tensorflow/files/1077682/jupyter.log.txt)
[run_metadata.pb.txt](https://github.com/tensorflow/tensorflow/files/1077683/run_metadata.pb.txt)

"
10731,scope reuse problem variable not exist for using Dense(in contirb.seq2seq.attention_wrapper),"tf version '1.2.0-rc0' 
in attention_wrapper.py(contirb.seq2seq.attention_wrapper), it use below
      
    from tensorflow.python.layers import core as layers_core 
    memory_layer = layers_core.Dense(10, name=""memory_layer"", use_bias=False)  #line 416

but this usage will cause un expected result when trying to reuse memory_layer, see below

    input = tf.constant([[1,2,3], [4,5,6]], dtype=tf.float32)
    with tf.variable_scope('main') as scope:
        memory_layer = layers_core.Dense(10, name=""memory_layer"", use_bias=False)
        x = memory_layer(input)
        scope.reuse_variables()
        memory_layer = layers_core.Dense(10, name=""memory_layer"", use_bias=False)
        y = memory_layer(input)

ValueError: Variable main/memory_layer_1/kernel does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?

One workaround is to change name=""memory_layer"" to _scope=""memory_layer""

    with tf.variable_scope('main') as scope:
        memory_layer = layers_core.Dense(10, _scope=""memory_layer"", use_bias=False)
        x = memory_layer(input)
        scope.reuse_variables()
        memory_layer = layers_core.Dense(10, _scope=""memory_layer"", use_bias=False)
        y = memory_layer(input)

I think this is a bug for atttention_wrapper.py ? since we can not reuse memory_layer, then we can not train/evaluate in one graph when using attention cell wrapper.
"
10730,All the graph have an operation _Retval that makes the train loop slow,"I have tried to train the model in [tf_cnn_benchmarks.py](https://github.com/tensorflow/benchmarks/blob/master/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py) and [cifar10_multi_gpu_train.py](https://github.com/tensorflow/models/blob/master/tutorials/image/cifar10/cifar10_multi_gpu_train.py).

All the timelines results like the image bellow. There is an operation named '_Retval' in the end of training loop. But as we see, long idle time was leaved in the timeline. How can I make the training faster by getting rid of the operation '_Retval' ? Is there other method to let the gpu be at full power?

![2017-06-15 19 57 31](https://user-images.githubusercontent.com/9522983/27180240-0e26c2f0-5205-11e7-9f7e-98be45a6a2b2.png)
![2017-06-15 19 58 33](https://user-images.githubusercontent.com/9522983/27180242-120350fa-5205-11e7-89f1-5d3fe6261293.png)

The images above were got by the script:

python tf_cnn_benchmarks.py local_parameter_device=cpu --num_gpus=2 --batch_size=64 --model=vgg16 --variable_update=independent --optimizer=sgd --trace_file=/home/zhaoerchao/timeline_benchmark.json --distortions"
10729,tf.nn.max_pool wrong docs?,"### System information
Not Applicable

### Describe the problem
[API](https://www.tensorflow.org/api_docs/python/tf/nn/max_pool) states that ksize has length >= 4, the size of window for each dimension of the input tensor. However, value is a 4-D Tensor so doesn't this mean that ksize should be length == 4? Same for strides.

Digging into maxpooling_op.cc shows that there's some check that does `==`. Line 212:

```
    OP_REQUIRES(context, ksize_.size() == 4,
                errors::InvalidArgument(""Sliding window ksize field must ""
                                        ""specify 4 dimensions""));
```


"
10728,tensorflow.contrib.keras.python.keras.models throwing errors for a valid keras code,"### System information
== cat /etc/issue ===============================================
Linux parikshit-XPS-L322X 4.4.0-79-generic #100-Ubuntu SMP Wed May 17 19:58:14 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""16.04.2 LTS (Xenial Xerus)""
VERSION_ID=""16.04""
VERSION_CODENAME=xenial

== are we in docker =============================================
No

== compiler =====================================================
c++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux parikshit-XPS-L322X 4.4.0-79-generic #100-Ubuntu SMP Wed May 17 19:58:14 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy (1.13.0)
protobuf (3.3.0)
tensorflow (1.2.0rc1)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.2.0-rc1
tf.GIT_VERSION = v1.2.0-rc0-24-g94484aa
tf.COMPILER_VERSION = v1.2.0-rc0-24-g94484aa
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
./tf_env_collect.sh: line 105: nvidia-smi: command not found

== cuda libs  ===================================================

Keras version 2.0.5 with Tensorflow backend

Using PyCharm Community edition 2017.1.3 as editor 

### Describe the problem
I was trying to implement a toy example for One Shot Siamese paper (Gregory Koch etc.) using Keras and found difference in behaviour (errors) between tensorflow.contrib.keras.python.keras.models (i.e using Tensorflow's contrib library for Keras) and keras.models (i.e Keras library with tensorflow backend). Here we have to train two separate CNNs with tied weights and tensorflow contrib library for keras is throwing errors for valid Keras code. Please refer to the code below for difference in behaviour / error

### Source code (using tensorflow contrib lib for keras)
```python
from __future__ import absolute_import, print_function, division
from tensorflow.contrib.keras.python.keras.layers import LSTM, Input, Conv2D, Lambda, merge, Dense, Flatten,MaxPooling2D
from tensorflow.contrib.keras.python.keras.models import Model, Sequential
from tensorflow.contrib.keras.python.keras.regularizers import l2
from tensorflow.contrib.keras.python.keras import backend as K
from tensorflow.contrib.keras.python.keras.optimizers import SGD
from tensorflow.contrib.keras.python.keras.initializers import RandomNormal

input_shape = (105, 105, 1)
left_input = Input(input_shape)
right_input = Input(input_shape)

w_init = RandomNormal(mean=0, stddev=1e-2)
b_init = RandomNormal(mean=0.5, stddev=1e-2)

convnet = Sequential()
convnet.add(Conv2D(64, (10, 10), activation='relu', input_shape=input_shape,
                   kernel_initializer=w_init, kernel_regularizer=l2(2e-4)))
convnet.add(MaxPooling2D())
convnet.add(Conv2D(128, (7, 7), activation='relu',
                   kernel_regularizer=l2(2e-4), kernel_initializer=w_init,
                   bias_initializer=b_init))
convnet.add(MaxPooling2D())
convnet.add(Conv2D(128, (4, 4), activation='relu', kernel_initializer=w_init,
                   kernel_regularizer=l2(2e-4), bias_initializer=b_init))
convnet.add(MaxPooling2D())
convnet.add(Conv2D(256, (4, 4), activation='relu', kernel_initializer=w_init,
                   kernel_regularizer=l2(2e-4), bias_initializer=b_init))
convnet.add(Flatten())
convnet.add(Dense(4096, activation=""sigmoid"", kernel_regularizer=l2(1e-3),
                  kernel_initializer=w_init, bias_initializer=b_init))

l_side = convnet(left_input)
r_side = convnet(right_input)
```
### Output/Error (tensorflow contrib lib for keras)
```
Traceback (most recent call last):
  File ""/home/parikshit/PycharmProjects/Toy_example/one_shot.py"", line 53, in <module>
    l_side = convnet(left_input)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/keras/python/keras/engine/topology.py"", line 432, in __call__
    output = super(Layer, self).__call__(inputs, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/base.py"", line 439, in __call__
    outputs = self.call(inputs, *args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/keras/python/keras/models.py"", line 560, in call
    return self.model.call(inputs, mask)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/keras/python/keras/engine/topology.py"", line 1743, in call
    output_tensors, _, _ = self.run_internal_graph(inputs, masks)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/keras/python/keras/engine/topology.py"", line 1957, in run_internal_graph
    self.add_loss(layer.get_losses_for(None), None)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/base.py"", line 254, in add_loss
    self._losses += losses
AttributeError: 'Model' object has no attribute '_losses'
```
### Source code (using Keras library with tensorflow backend)
```python
from __future__ import absolute_import, print_function, division
from keras.layers import LSTM, Input, Conv2D, Lambda, merge, Dense, Flatten,MaxPooling2D
from keras.models import Model, Sequential
from keras.regularizers import l2
from keras import backend as K
from keras.optimizers import SGD
from keras.initializers import RandomNormal

input_shape = (105, 105, 1)
left_input = Input(input_shape)
right_input = Input(input_shape)

w_init = RandomNormal(mean=0, stddev=1e-2)
b_init = RandomNormal(mean=0.5, stddev=1e-2)

convnet = Sequential()
convnet.add(Conv2D(64, (10, 10), activation='relu', input_shape=input_shape,
                   kernel_initializer=w_init, kernel_regularizer=l2(2e-4)))
convnet.add(MaxPooling2D())
convnet.add(Conv2D(128, (7, 7), activation='relu',
                   kernel_regularizer=l2(2e-4), kernel_initializer=w_init,
                   bias_initializer=b_init))
convnet.add(MaxPooling2D())
convnet.add(Conv2D(128, (4, 4), activation='relu', kernel_initializer=w_init,
                   kernel_regularizer=l2(2e-4), bias_initializer=b_init))
convnet.add(MaxPooling2D())
convnet.add(Conv2D(256, (4, 4), activation='relu', kernel_initializer=w_init,
                   kernel_regularizer=l2(2e-4), bias_initializer=b_init))
convnet.add(Flatten())
convnet.add(Dense(4096, activation=""sigmoid"", kernel_regularizer=l2(1e-3),
                  kernel_initializer=w_init, bias_initializer=b_init))

l_side = convnet(left_input)
r_side = convnet(right_input)
```
### Output/Error (Keras library with tensorflow backend)
```
Using TensorFlow backend.

Process finished with exit code 0
```"
10727,Redundant Computation of tf.cond(),"### System information (Runs all right)
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
-  OS: Linux Ubuntu 14.04.01
- **TensorFlow installed from pip:
- **TensorFlow version (use command below)**:'v1.0.0-65-g4763edf-dirty', '1.0.1
- **CUDA/cuDNN version: CUDA8.0/cuDNN5.1
- **GPU model and memory**: GTX1060 6GB

### Describe the problem
tf.cond(pred, fn1, fn2) have redundant computation when fn1 and fn2 have dependencies on other tensors. See the example code, you'll know.

### Source code / logs
```
import tensorflow as tf
def tf_fun1(a):
    def func1(a):
        print 'a1 %s\n'% a
        return a
    r = tf.py_func(func1, [a], tf.int32)
    return r

def tf_fun2(a):
    def func2(a):
        print 'a2 %s\n'% a
        return a
    r = tf.py_func(func2, [a], tf.int32)
    return r

def test():
    is_training = tf.placeholder(tf.bool)
    tensor_a = tf_fun1(1)
    tensor_b = tf_fun2(2)
    cond_tensor = tf.cond(is_training, lambda: tensor_a, lambda: tensor_b)
    cond_func = tf.cond(is_training, lambda: tf_fun1(1),lambda: tf_fun2(2))
    cond_func_with_tensor = tf.cond(is_training, lambda: tf_fun1(tensor_a),lambda: tf_fun2(tensor_b))
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        print 'run cond_tensor'
        value = sess.run(cond_tensor,feed_dict={is_training:True})
        print 'run cond_func'
        value = sess.run(cond_func,feed_dict={is_training:True})
        print 'run cond_func_with_tensor'
        value = sess.run(cond_func_with_tensor,feed_dict={is_training:True})

```
The result of running:
```
run cond_tensor
a2 2
a1 1
run cond_func
a1 1
run cond_func_with_tensor
a2 2
a1 1
a1 1
```
"
10726,"in the test dataset the use of different batch_size will get different results. ,why?","
When I used kears and tensorflow training after the checkpoint, after stopping the process, when I was found in the test, the use of different batch_size will get different results. The When batch_size = 1 when the error rate is high, but when the batch_size = 128, the error rate is not so high. The The The Why is this? The So what about my online service?"
10725,tf.contrib.data.Dataset.filter kernel error on excluded element,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary (nightly build)
- **TensorFlow version (use command below)**:  1.2.0-rc2 (git version v1.2.0-rc0-1066-g4c0052d)
- **CUDA/cuDNN version**: 8.0
- **GPU model and memory**: GTX 970
- **Exact command to reproduce**: See script

### Describe the problem
I am trying to use Dataset's `filter()` function to exclude certain examples, but when the iterator hits the index of the first excluded example, a kernel error occurs and the program crashes.

### Source code / logs

This example creates a data set of 100 integers and filters out every third one by checking `x % 3 != 2`. The first two calls to `sess.run()` produce the digits 0 and 1 and they get printed correctly. At the third `sess.run()` call, the program crashes.

Running this

```python
import tensorflow as tf

dataset = tf.contrib.data.Dataset.range(100)
dataset = dataset.filter(lambda x: tf.not_equal(tf.mod(x, 3), 2))

iterator = dataset.make_one_shot_iterator()
next_element = iterator.get_next()

sess = tf.Session()
print(sess.run(next_element))
print(sess.run(next_element))
print(sess.run(next_element))
```

It results in this

```
2017-06-15 10:18:44.797870: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-15 10:18:44.797884: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-15 10:18:44.797886: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-06-15 10:18:44.797888: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-15 10:18:44.797891: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-06-15 10:18:44.896171: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-06-15 10:18:44.896367: I tensorflow/core/common_runtime/gpu/gpu_device.cc:938] Found device 0 with properties: 
name: GeForce GTX 970
major: 5 minor: 2 memoryClockRate (GHz) 1.253
pciBusID 0000:01:00.0
Total memory: 3.94GiB
Free memory: 3.42GiB
2017-06-15 10:18:44.896377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:959] DMA: 0 
2017-06-15 10:18:44.896379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:969] 0:   Y 
2017-06-15 10:18:44.896384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1028] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 970, pci bus id: 0000:01:00.0)
0
1
2017-06-15 10:18:45.918333: W tensorflow/core/framework/op_kernel.cc:1165] Invalid argument: Expects 1 arguments, but 2 is provided
Traceback (most recent call last):
  File ""/home/ede/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1267, in _do_call
    return fn(*args)
  File ""/home/ede/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1248, in _run_fn
    status, run_metadata)
  File ""/usr/lib/python3.5/contextlib.py"", line 66, in __exit__
    next(self.gen)
  File ""/home/ede/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py"", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: Expects 1 arguments, but 2 is provided
	 [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[]], output_types=[DT_INT64], _device=""/job:localhost/replica:0/task:0/cpu:0""](OneShotIterator)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/ede/.IntelliJIdea2017.1/config/scratches/scratch_6.py"", line 14, in <module>
    print(sess.run(next_element))
  File ""/home/ede/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 896, in run
    run_metadata_ptr)
  File ""/home/ede/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1108, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/ede/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1261, in _do_run
    options, run_metadata)
  File ""/home/ede/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1280, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Expects 1 arguments, but 2 is provided
	 [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[]], output_types=[DT_INT64], _device=""/job:localhost/replica:0/task:0/cpu:0""](OneShotIterator)]]

Caused by op 'IteratorGetNext', defined at:
  File ""/home/ede/.IntelliJIdea2017.1/config/scratches/scratch_6.py"", line 8, in <module>
    next_element = iterator.get_next()
  File ""/home/ede/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/data/python/ops/dataset_ops.py"", line 247, in get_next
    name=name))
  File ""/home/ede/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 282, in iterator_get_next
    output_shapes=output_shapes, name=name)
  File ""/home/ede/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py"", line 767, in apply_op
    op_def=op_def)
  File ""/home/ede/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 2528, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/home/ede/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1203, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): Expects 1 arguments, but 2 is provided
	 [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[]], output_types=[DT_INT64], _device=""/job:localhost/replica:0/task:0/cpu:0""](OneShotIterator)]]
```
"
10723,Poor Scalability of TensorFlow MultiGPU Training on a Single Machine [Performance Bug],"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Debian 3.16.7
- **TensorFlow installed from (source or binary)**: source, hash: b1e174e
- **TensorFlow version (use command below)**: v1.1.0-rc2-119-gb1e174e 1.1.0-rc2
- **Bazel version (if compiling from source)**:  0.4.5-jdk7
- **CUDA/cuDNN version**: CUDA 8.0, cudnn-v5.1
- **GPU model and memory**: Titan X with 12 GiB
- **Exact command to reproduce**: ./tf_multiGPU.py

- **tensorflow/benchmark version**: source, hash: 9165a70

### Describe the problem
Recently, we are testing the TensorFlow scalability on multiGPU machines. We use the official scripts provided in the [benchmarks](https://www.tensorflow.org/performance/benchmarks) using codes from GitHub repository tensorflow/benchmark. We execute the script according to the official website to test the scalability of TensorFlow on the machine equipped with 8 Titan X GPUs. We test the model VGG16 with batch size equaling to 64.

The results are shown in the following table:

| Num of GPUs | Throughput (images/sec) |
|-------------|-------------------------|
| 1           | 83.13                   |
| 2           | 155.06                  |
| 3           | 211.8                   |
| 4           | 278.51                  |
| 5           | 265.53                  |
| 6           | 268.19                  |
| 7           | 272.8                   |
| 8           | 302.27                  |

We are surprised to find that the total throughput of 5 GPUs is smaller than 4 GPUs, which means TensorFlow incurs significant overheads when the number of GPU is larger than 4. Because I don't know whether this performance issue belongs to the tensorflow/tensorflow repository or tensorflow/benchmark repository, I submit this issue here looking forward to the official response. The script for reproducing this issue can be found in Source code/logs section with the results.

The scalability is strongly related to the topology of GPU interconnection. In our machine, we have a tree topology for GPUs. The topology details can be found at the [nv-topo-matrix.txt](https://gist.github.com/583d689fd16ee24f1924b83ca3dea5b9.git)

We believe this is a performance bug since if more GPUs can not achieve higher throughput, at least they should obtain similar throughput. 

### Source code / logs
Source code: [tf_multiGPU.py](https://gist.github.com/b4024e1d8bfbbdf0cf917798d677aaae.git)
The log after executing the script above: https://drive.google.com/file/d/0Bw3_V-EwBVToYXVqZDkzQkN6c3M/view?usp=sharing"
10722,tf.image.resize_bicubic() produces artifacts in output image,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes. See below.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: All platforms
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.0
- **Bazel version (if compiling from source)**: 0.4.5
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**:

### Describe the problem
tf.image.resize_bicubic() produces weird artifacts in output image. To reproduce, please save this image as bbf.png, and run the program below:

https://www.dramafever.com/st/news/images/e09901b7-bb86-4acd-94e3-ee93d2e301cc.png

This is what tf.image.resize_bicubic() produces:

![output](https://user-images.githubusercontent.com/19349719/27169091-41a12772-515d-11e7-9e17-6240f4a07634.jpg)

### Source code / logs
```
import tensorflow as tf

with open('bbf.png', 'rb') as f:
    image_bytes = f.read()

image = tf.image.decode_image(image_bytes)
image = tf.expand_dims(image, 0)

resized_image = tf.image.resize_bicubic(image, [256, 256])

resized_image = tf.cast(resized_image, tf.uint8)
resized_image = tf.squeeze(resized_image)
encoded_image = tf.image.encode_jpeg(resized_image)

with tf.Session() as sess:
    jpg_image = sess.run(encoded_image)
    with open('output.jpg', 'wb') as f:
        f.write(jpg_image)
```"
10720,freeze_graph problem,"When I use freeze_graph, the --input_checkpoint=model.ckpt-8361242, the data is V1 version. But I use the tensorflow v1.1,the data save as model.ckpt-569500.data-00000-of-00001,model.ckpt-569500.index,model.ckpt-569500.meta.How can I deal with?"
10718,bazel build error: no such package '@protobuf//',"Build from master 0d2f691, but encounter with the error of ""/tensorflow/tools/pip_package/BUILD:94:1: no such package '@protobuf//': Traceback (most recent call last)"". They are operated in virtualenv with bazel 0.5.1 on a centos 7.3.1611. 

The package can be downloaded in a browser from the url ""http://mirror.bazel.build/github.com/google/protobuf/archive/2b7430d96aeff2bb624c8d52182ff5e4b9f7f18a.tar.gz"". I'm in China, where it is difficult to access the google service. I have no idea about whether the network is the problem.

**Here is the terminal log** of brach version, configure and bazel build.

`
(tf-source) [huwh1@huwh1-centos tensorflow]$ git branch -v
* master 0d2f691 [ahead 16] Create tf_env_collect.sh

(tf-source) [huwh1@huwh1-centos tensorflow]$ ./configure 
You have bazel 0.5.1 installed.
Please specify the location of python. [Default is /home/huwh1/virtualenv/tf-source/bin/python]: 
Found possible Python library paths:
  /home/huwh1/virtualenv/tf-source/lib/python2.7/site-packages
Please input the desired Python library path to use.  Default is [/home/huwh1/virtualenv/tf-source/lib/python2.7/site-packages]

Using python library path: /home/huwh1/virtualenv/tf-source/lib/python2.7/site-packages
Do you wish to build TensorFlow with MKL support? [y/N] 
No MKL support will be enabled for TensorFlow
Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native]: 
Do you wish to use jemalloc as the malloc implementation? [Y/n] 
jemalloc enabled
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N] 
No Google Cloud Platform support will be enabled for TensorFlow
Do you wish to build TensorFlow with Hadoop File System support? [y/N] 
No Hadoop File System support will be enabled for TensorFlow
Do you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N] 
No XLA support will be enabled for TensorFlow
Do you wish to build TensorFlow with VERBS support? [y/N] 
No VERBS support will be enabled for TensorFlow
Do you wish to build TensorFlow with OpenCL support? [y/N] 
No OpenCL support will be enabled for TensorFlow
Do you wish to build TensorFlow with CUDA support? [y/N] y
CUDA support will be enabled for TensorFlow
Do you want to use clang as CUDA compiler? [y/N] 
nvcc will be used as CUDA compiler
Please specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 8.0]: 8.0
Please specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 
Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: 
Please specify the cuDNN version you want to use. [Leave empty to default to cuDNN 6.0]: 5
Please specify the location where cuDNN 5 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 
Please specify a list of comma-separated Cuda compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size.
[Default is: ""3.5,5.2""]: 3.0
Do you wish to build TensorFlow with MPI support? [y/N] 
MPI support will not be enabled for TensorFlow
Configuration finished

(tf-source) [huwh1@huwh1-centos tensorflow]$ bazel clean
INFO: Starting clean (this may take a while). Consider using --async if the clean takes more than several minutes.
(tf-source) [huwh1@huwh1-centos tensorflow]$ bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package | tee
____Loading package: tensorflow/tools/pip_package
____Loading package: @bazel_tools//tools/cpp
____Loading package: tensorflow/contrib/specs
____Loading package: @zlib_archive//
____Loading package: third_party/eigen3
____Downloading http://mirror.bazel.build/github.com/google/protobuf/archive/2b7430d96aeff2bb624c8d52182ff5e4b9f7f18a.tar.gz: 87,161 bytes
____Downloading http://mirror.bazel.build/github.com/google/protobuf/archive/2b7430d96aeff2bb624c8d52182ff5e4b9f7f18a.tar.gz: 311,205 bytes
____Downloading http://mirror.bazel.build/github.com/google/protobuf/archive/2b7430d96aeff2bb624c8d52182ff5e4b9f7f18a.tar.gz: 1,475,383 bytes
____Downloading http://mirror.bazel.build/github.com/google/protobuf/archive/2b7430d96aeff2bb624c8d52182ff5e4b9f7f18a.tar.gz: 1,957,187 bytes
____Downloading http://mirror.bazel.build/github.com/google/protobuf/archive/2b7430d96aeff2bb624c8d52182ff5e4b9f7f18a.tar.gz: 4,274,206 bytes
____Downloading http://mirror.bazel.build/github.com/google/protobuf/archive/2b7430d96aeff2bb624c8d52182ff5e4b9f7f18a.tar.gz: 2,138,182 bytes
____Downloading http://mirror.bazel.build/github.com/google/protobuf/archive/2b7430d96aeff2bb624c8d52182ff5e4b9f7f18a.tar.gz: 1,875,852 bytes
____Downloading http://mirror.bazel.build/github.com/google/protobuf/archive/2b7430d96aeff2bb624c8d52182ff5e4b9f7f18a.tar.gz: 4,264,858 bytes
ERROR: /home/huwh1/git/tensorflow/tensorflow/tools/pip_package/BUILD:94:1: no such package '@protobuf//': Traceback (most recent call last):
	File ""/home/huwh1/git/tensorflow/tensorflow/workspace.bzl"", line 122
		_apply_patch(repo_ctx, repo_ctx.attr.patch_file)
	File ""/home/huwh1/git/tensorflow/tensorflow/workspace.bzl"", line 113, in _apply_patch
		_execute_and_check_ret_code(repo_ctx, cmd)
	File ""/home/huwh1/git/tensorflow/tensorflow/workspace.bzl"", line 97, in _execute_and_check_ret_code
		fail(""Non-zero return code({1}) when ..., <2 more arguments>))
Non-zero return code(256) when executing 'patch -p1 -d /home/huwh1/.cache/bazel/_bazel_huwh1/571d325cc1cf529816d64b96c622cea4/external/protobuf -i /home/huwh1/git/tensorflow/third_party/protobuf/add_noinlines.patch':
Stdout: 
Stderr: java.io.IOException: Cannot run program ""patch"" (in directory ""/home/huwh1/.cache/bazel/_bazel_huwh1/571d325cc1cf529816d64b96c622cea4/external/protobuf""): error=2, No such file or directory and referenced by '//tensorflow/tools/pip_package:licenses'.
ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted.
____Elapsed time: 3.457s
`

**Here is the system information:**

`== cat /etc/issue ===============================================
Linux huwh1-centos 3.10.0-514.21.1.el7.x86_64 #1 SMP Thu May 25 17:04:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""7 (Core)""
VERSION_ID=""7""
CENTOS_MANTISBT_PROJECT_VERSION=""7""
REDHAT_SUPPORT_PRODUCT_VERSION=""7""

== are we in docker =============================================
No

== compiler =====================================================
c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-11)
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux huwh1-centos 3.10.0-514.21.1.el7.x86_64 #1 SMP Thu May 25 17:04:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy (1.13.0)
protobuf (3.3.0)

== check for virtualenv =========================================
True

== tensorflow import ============================================
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""tensorflow/python/pywrap_tensorflow.py"", line 52, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""tensorflow/python/pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
ImportError: No module named pywrap_tensorflow_internal


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

== env ==========================================================
LD_LIBRARY_PATH /opt/intel/compilers_and_libraries_2017.4.196/linux/compiler/lib/intel64:/opt/intel/compilers_and_libraries_2017.4.196/linux/compiler/lib/intel64_lin:/opt/intel/compilers_and_libraries_2017.4.196/linux/tbb/lib/intel64_lin/gcc4.7:/opt/intel/compilers_and_libraries_2017.4.196/linux/compiler/lib/intel64_lin:/opt/intel/compilers_and_libraries_2017.4.196/linux/mkl/lib/intel64_lin:/usr/local/cuda-8.0/lib64
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
Thu Jun 15 10:28:42 2017       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 375.26                 Driver Version: 375.26                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Quadro K420         Off  | 0000:01:00.0     Off |                  N/A |
| 25%   44C    P8    N/A /  N/A |      9MiB /  1998MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0      6899    C   /home/huwh1/virtualenv/tf-gpu/bin/python         7MiB |
+-----------------------------------------------------------------------------+

== cuda libs  ===================================================
/usr/local/cuda-8.0/lib64/libcudart_static.a
/usr/local/cuda-8.0/lib64/libcudart.so.8.0.61
/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7
/usr/local/cuda-8.0/doc/man/man7/libcudart.7
`
"
10715,Feature Request: Update tf.image.sample_distorted_bounding_box to use Scalar Tensor Inputs,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 14.04
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
1.1
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
8.0/5.1
- **GPU model and memory**:
Titan X
- **Exact command to reproduce**:

Can you please update the scalar inputs to tf.image.sample_distorted_bounding_box to also be accepted as Tensors.  I am dynamically creating min_object_covered values (random values) but currently can not input them to the function"
10714,undefined symbol error when loading zero_out custom op,"### System information
- **Implement zero_out custom op as defined in tensorflow tutorial**: no custom code at all
- **OS Platform and Distribution**: Ubuntu 16.04.2 LTS (Xenial Xerus) / 4.4.0-75-generic #96-Ubuntu SMP Thu Apr 20 09:56:33 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux 
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.1.0-rc2 / v1.1.0-rc2-817-geb11d6b
- **Bazel version (if compiling from source)**: 0.4.5
- **CUDA/cuDNN version**: None
- **GPU model and memory**: None

### The problem
Undefined symbol error when using zero_out custom op. It appears after I follow the tensorflow tutorial:

$ bazel build --config opt //tensorflow/core/user_ops:zero_out.so is OK
> ____Loading complete.  Analyzing...
____Found 1 target...
____Building...
____[0 / 1] BazelWorkspaceStatusAction stable-status.txt
Target //tensorflow/core/user_ops:zero_out.so up-to-date:
  bazel-bin/tensorflow/core/user_ops/zero_out.so
____Elapsed time: 0.464s, Critical Path: 0.01s

$ python zero_output_op_test.py**:
>======================================================================
ERROR: testZeroOut (__main__.ZeroOutTest)
Traceback (most recent call last):
  File ""zero_out_op_test.py"", line 5, in testZeroOut
    zero_out_module = tf.load_op_library('/srv/workspace/tensorflow/bazel-bin/tensorflow/core/user_ops/zero_out.so')
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/load_library.py"", line 64, in load_op_library
    None, None, error_msg, error_code)
NotFoundError: /srv/workspace/tensorflow/bazel-bin/tensorflow/core/user_ops/zero_out.so: undefined symbol: _ZN10tensorflow8internal21CheckOpMessageBuilder9NewStringB5cxx11Ev
Ran 2 tests in 0.040s
FAILED (errors=1)

### Source code / logs
- **zero_out.cc**:
```
#include ""tensorflow/core/framework/op.h""
#include ""tensorflow/core/framework/shape_inference.h""
#include ""tensorflow/core/framework/op_kernel.h""

using namespace tensorflow;

class ZeroOutOp : public OpKernel {
 public:
  explicit ZeroOutOp(OpKernelConstruction* context) : OpKernel(context) {}

  void Compute(OpKernelContext* context) override {
    // Grab the input tensor
    const Tensor& input_tensor = context->input(0);
    auto input = input_tensor.flat<int32>();

    // Create an output tensor
    Tensor* output_tensor = NULL;
    OP_REQUIRES_OK(context, context->allocate_output(0, input_tensor.shape(),
                                                     &output_tensor));
    auto output = output_tensor->flat<int32>();

    // Set all but the first element of the output tensor to 0.
    const int N = input.size();
    for (int i = 1; i < N; i++) {
      output(i) = 0;
    }

    // Preserve the first input value if possible.
    if (N > 0) output(0) = input(0);
  }
};

REGISTER_OP(""ZeroOut"")
    .Input(""to_zero: int32"")
    .Output(""zeroed: int32"")
    .SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {
      c->set_output(0, c->input(0));
      return Status::OK();
    });

REGISTER_KERNEL_BUILDER(Name(""ZeroOut"").Device(DEVICE_CPU), ZeroOutOp);
```

-**BUILD**:
```
load(""//tensorflow:tensorflow.bzl"", ""tf_custom_op_library"")

tf_custom_op_library(
    name = ""zero_out.so"",
    srcs = [""zero_out.cc""],
)
```
-**zero_out_op_test.py**:
```import tensorflow as tf

class ZeroOutTest(tf.test.TestCase):
  def testZeroOut(self):
    zero_out_module = tf.load_op_library('zero_out.so')
    with self.test_session():
      result = zero_out_module.zero_out([5, 4, 3, 2, 1])
      self.assertAllEqual(result.eval(), [5, 0, 0, 0, 0])

if __name__ == ""__main__"":
  tf.test.main()
```


"
10713,[Documentation] cifar10_input.py is referenced but missing on master,"### Describe the problem
File `cifar10_input.py` is referenced in documentation, but is missing on `master`.

Documentation piece:
https://www.tensorflow.org/programmers_guide/reading_data

r0.7 version
https://github.com/tensorflow/tensorflow/blob/r0.7/tensorflow/models/image/cifar10/cifar10_input.py
"
10712,GPU Error with tf.losses.sparse_softmax_cross_entropy,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: See below
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Binary (PIP)
- **TensorFlow version (use command below)**: v1.1.0-rc0-61-g1ec6ed5 1.1.0
- **Bazel version (if compiling from source)**: n/a
- **CUDA/cuDNN version**: 8.0/5.1.5
- **GPU model and memory**: NVIDIA Titan X - 12GB
- **Exact command to reproduce**:

```
import tensorflow as tf
import numpy as np

y = np.random.randint(0, 10, size=40, dtype=np.int32)
logits = np.float32(np.random.rand(40, 10))
weights = np.ones(40, dtype=np.float32)

y_t = tf.placeholder(tf.int32)
logits_t = tf.placeholder(tf.float32)

cost = tf.losses.sparse_softmax_cross_entropy(labels=y,logits=logits, weights=tf.ones(40,dtype=tf.float32))
sess = tf.Session()
sess.run(cost, feed_dict={y_t: y, logits_t: logits})
```

### Describe the problem
Am I doing something wrong or does this function not have a GPU implementation yet?  I guess I can do this on the CPU, but I thought I would check.  It does work on the CPU, I did check that.

### Source code / logs
The error message is attached.

[error_message.txt](https://github.com/tensorflow/tensorflow/files/1075808/error_message.txt)

"
10711,Broken Link for CIFAR-10 tutorial,"On the main page of Tensorflow tutorial for CIFAR-10 i.e.
( [https://www.tensorflow.org/tutorials/deep_cnn#model_inputs](url) ), the links in the **[Code Organisation](https://www.tensorflow.org/tutorials/deep_cnn#code_organization)** section are ALL broken. 
To be precise, the on clicking them - **Github** page says '_Page not found_'

Please remove this bug ASAP"
10708,"Building Java Tensorflow for GPU, from Source, Does not Work as Described.","First of all, I will not address this in Stackoverflow. This question belongs here. I tried going to Stackflow but nobody responded.

I need to build tensorflow for Java from source with GPU support in Windows. How can I do this successfully? I need to build the JNI DLLs. Please advise!

I get:
```
bazel build --config opt //tensorflow/java:tensorflow //tensorflow/java:libtensorflow_jni
ERROR: C:/development/projects/tensorflow/tensorflow/java/BUILD:142:1: error loading package 'tensorflow/java/src/main/native': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):
        File ""C:/development/projects/tensorflow/third_party/gpus/cuda_configure.bzl"", line 958
                _create_cuda_repository(repository_ctx)
        File ""C:/development/projects/tensorflow/third_party/gpus/cuda_configure.bzl"", line 846, in _create_cuda_repository
                _get_cuda_config(repository_ctx)
        File ""C:/development/projects/tensorflow/third_party/gpus/cuda_configure.bzl"", line 656, in _get_cuda_config
                _cudnn_install_basedir(repository_ctx)
        File ""C:/development/projects/tensorflow/third_party/gpus/cuda_configure.bzl"", line 211, in _cudnn_install_basedir
                auto_configure_fail(""Cannot find cudnn install path....)
        File ""C:/development/projects/tensorflow/third_party/gpus/cuda_configure.bzl"", line 128, in auto_configure_fail
                fail(""\n%sAuto-Configuration Error:%s...))

Auto-Configuration Error: Cannot find cudnn install path.
 and referenced by //tensorflow/java:libtensorflow_jni.so.
ERROR: Analysis of target '//tensorflow/java:tensorflow' failed; build aborted.
INFO: Elapsed time: 0.464s`
```

Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows
- **TensorFlow installed from (source or binary)**: r1.2
- **TensorFlow version (use command below)**:r1.2
- **Bazel version (if compiling from source)**: 0.5.0
- **CUDA/cuDNN version**: 8.0/5.1
- **GPU model and memory**: Nvidia Quadro - K5200
- **Exact command to reproduce**:bazel build --config opt //tensorflow/java:tensorflow //tensorflow/java:libtensorflow_jni

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
10706,[Feature Request] can tfdbg support printing or writing into file the whole (complete) tensor ?,"### Describe the problem

I used tensorflow's new debugger named tfdbg to debug tensorflow's application, which I need to see some intermediate tensors, but, for example, I tried to debug `wide_n_deep_tutorial.py`, 
when I type command like 
`print_tensor linear/linear/native_country/native_country_weights/embedding_lookup_sparse:0`

it gives me following lines:
```
Tensor ""linear/linear/native_country/native_country_weights/embedding_lookup_sparse:0:DebugIdentity"":
  dtype: float32
  shape: (32561, 1)

array([[-0.11688102],
       [-0.11688102],
       [-0.11688102],
       ..., 
       [-0.11688102],
       [-0.11688102],
       [-0.11688102]], dtype=float32)
```

if I run redirect it to a local file, it also appear like above.

So, there is any method that can print / save the whole tensor ?
If not, can tensorflow add this feature ?
thanks in advance.

###  Source Code

add
```
hooks = None
  if FLAGS.debug:
      debug_hook = tf_debug.LocalCLIDebugHook(ui_type=FLAGS.ui_type)
      debug_hook.add_tensor_filter(""has_inf_or_nan"", tf_debug.has_inf_or_nan)
      hooks = [debug_hook]
      m.fit(input_fn=lambda: input_fn(df_train),
                steps=train_steps,
                monitors=hooks)

      results = m.evaluate(input_fn=lambda: input_fn(df_test), steps=1)
      for key in sorted(results):
        print(""%s: %s"" % (key, results[key]))
  else:
      m.fit(input_fn=lambda: input_fn(df_train),
            steps=train_steps)
```
after `wide_n_deep_tutorial.py` 's `m = build_estimator(..)`
and add some args in main function :
```
parser.add_argument(
      ""--ui_type"",
      type=str,
      default=""curses"",
      help=""Command-line user interface type (curses | readline)"")
  parser.add_argument(
      ""--debug"",
      type=""bool"",
      nargs=""?"",
      const=True,
      default=False,
      help=""Use debugger to track down bad values during training"")
```

"
10705,undocumented change in variable scope from tf 1.0.1 to tf 1.1.0,"**System Information**
- **Custom code, a minimal reproducible example provided below**
- **Linux Fedora 24 and Fedora 25**
- **TensorFlow installed from binary using pip**
- **TensorFlow version 1.0.1 and 1.1.0**
- **CUDA 8.0/cuDNN 5.1**
- **GeForce GTX 1080**

**Problem**
I'm trying to run some code that I wrote for tensorflow 1.0.1 on tensorflow 1.1.0.
It seems like tf.contrib.layers.fully_connected is showing different behaviour for 1.1.0 compared to 1.0.1. See below for a minimal reproducible example showing the difference.

**Source code and logs**
Tensorflow 1.0.1, Fedora 24:
```
Python 2.7.13 (default, May 10 2017, 20:04:36) 
[GCC 6.3.1 20161221 (Red Hat 6.3.1-1)] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
>>> tf.contrib.layers.fully_connected(inputs=tf.placeholder(shape=[None,3],dtype=tf.float32),num_outputs=3,reuse=True,scope='DNN')
<tf.Tensor 'DNN/Relu:0' shape=(?, 3) dtype=float32>
>>> tf.__version__
'1.0.1'
```
Tensorflow 1.1.0, Fedora 25:
```
Python 2.7.13 (default, May 10 2017, 20:04:28) 
[GCC 6.3.1 20161221 (Red Hat 6.3.1-1)] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
>>> tf.contrib.layers.fully_connected(inputs=tf.placeholder(shape=[None,3],dtype=tf.float32),num_outputs=3,reuse=True,scope='DNN')
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py"", line 181, in func_with_args
    return func(*args, **current_args)
  File ""/usr/lib/python2.7/site-packages/tensorflow/contrib/layers/python/layers/layers.py"", line 1433, in fully_connected
    outputs = layer.apply(inputs)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/layers/base.py"", line 320, in apply
    return self.__call__(inputs, **kwargs)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/layers/base.py"", line 286, in __call__
    self.build(input_shapes[0])
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/layers/core.py"", line 123, in build
    trainable=True)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 1049, in get_variable
    use_resource=use_resource, custom_getter=custom_getter)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 948, in get_variable
    use_resource=use_resource, custom_getter=custom_getter)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 349, in get_variable
    validate_shape=validate_shape, use_resource=use_resource)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 1389, in wrapped_custom_getter
    *args, **kwargs)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/layers/base.py"", line 275, in variable_getter
    variable_getter=functools.partial(getter, **kwargs))
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/layers/base.py"", line 228, in _add_variable
    trainable=trainable and self.trainable)
  File ""/usr/lib/python2.7/site-packages/tensorflow/contrib/layers/python/layers/layers.py"", line 1334, in layer_variable_getter
    return _model_variable_getter(getter, *args, **kwargs)
  File ""/usr/lib/python2.7/site-packages/tensorflow/contrib/layers/python/layers/layers.py"", line 1326, in _model_variable_getter
    custom_getter=getter, use_resource=use_resource)
  File ""/usr/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py"", line 181, in func_with_args
    return func(*args, **current_args)
  File ""/usr/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/variables.py"", line 262, in model_variable
    use_resource=use_resource)
  File ""/usr/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py"", line 181, in func_with_args
    return func(*args, **current_args)
  File ""/usr/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/variables.py"", line 217, in variable
    use_resource=use_resource)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 341, in _true_getter
    use_resource=use_resource)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 671, in _get_single_variable
    ""VarScope?"" % name)
ValueError: Variable DNN/weights does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?
>>> tf.__version__
'1.1.0'
```
Looking at the release notes for Tensorflow 1.1, there is no mention of change in behaviour of variable scope for tf.contrib.layers.fully_connected. But it seems like in 1.1 we have to create variables manually using tf.get_variable() before using tf.contrib.layers.fully_connected. Am I missing something?
"
10703,Bazel bring up for ROCm,"Hi,
I am trying to add new backend to tensorflow. As a first step, I started changing bazel files around [(Commit here)](https://github.com/ROCmSoftwarePlatform/tensorflow/commit/b75ea3f499a5f63f2580066ae132c93e2b03d0ad). When I enable XLA + ROCM during configure, and run `bazel build -s --config=opt --config=rocm //tensorflow/tools/pip_package:build_pip_package `, I am getting the following error:
```
ERROR: no such package '@local_config_rocm//': error loading package 'external': The repository named 'local_config_rocm' could not be resolved.
INFO: Elapsed time: 0.227s
```

It would be great if someone can parse the commit mentioned and suggest changes. 
Thank you!"
10699,RDMA transport should support variable sized tensor,"RDMA transport disabled variable size tensor https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/verbs/rdma.cc#L738 and https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/verbs/rdma.cc#L759.

However, in the embedding lookup model, the tensor has variable size. It's a common model parallelism case."
10697,how can combining cnn with convlutional lstm,"Hi,

i want to process a image in cnn+convolutinal_lstm , in the connection point  between to network , shape(None,100,100,64) for cnn the should insert to convolution_lstm network ,
but not  match output cnn with input convlutinal_lstm.
is any example for this combination?

"
10695,import Tensorflow not working,"I get following error when installing under anaconda (python 2.7) environment.

```
>>> import tensorflow as tf
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/Users/quintendewilde/anaconda2/envs/TensorFlow/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/Users/quintendewilde/anaconda2/envs/TensorFlow/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 60, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/Users/quintendewilde/anaconda2/envs/TensorFlow/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/Users/quintendewilde/anaconda2/envs/TensorFlow/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 28, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""/Users/quintendewilde/anaconda2/envs/TensorFlow/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)
ImportError: dlopen(/Users/quintendewilde/anaconda2/envs/TensorFlow/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so, 10): Library not loaded: @rpath/libcudart.8.0.dylib
  Referenced from: /Users/quintendewilde/anaconda2/envs/TensorFlow/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
  Reason: image not found


Error importing tensorflow.  Unless you are using bazel,
you should not try to import tensorflow from its source directory;
please exit the tensorflow source tree, and relaunch your python interpreter
from there.

```"
10694,Cannot build tensorflow at all,"OS/X, building on a branch not master.

After pulling the repo this morning (previous pull 12 hours ago) I can no longer build at all:

```
ERROR: /Users/davidn/workspace/tensorflowview/tensorflow/tensorflow/core/BUILD:1394:1: no such target '//tensorflow/tools/git:gen/branch_ref': target 'gen/branch_ref' not declared in package 'tensorflow/tools/git' defined by /Users/davidn/workspace/tensorflowview/tensorflow/tensorflow/tools/git/BUILD and referenced by '//tensorflow/core:version_info_gen'.
ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted.
``

"
10693,NotFoundError (see above for traceback): Key conv13/weights not found in checkpoin,"Caused by op u'save/RestoreV2_4', defined at:
  File ""test_go.py"", line 140, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""test_go.py"", line 137, in main
    evaluate()
  File ""test_go.py"", line 119, in evaluate
    saver = tf.train.Saver()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1139, in __init__
    self.build()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1170, in build
    restore_sequentially=self._restore_sequentially)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 691, in build
    restore_sequentially, reshape)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 407, in _AddRestoreOps
    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 247, in restore_op
    [spec.tensor.dtype])[0])
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 680, in restore_v2
    dtypes=dtypes, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 767, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2336, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1228, in __init__
    self._traceback = _extract_stack()

NotFoundError (see above for traceback): Key conv13/weights not found in checkpoint
	 [[Node: save/RestoreV2_4 = RestoreV2[dtypes=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/cpu:0""](_arg_save/Const_0_0, save/RestoreV2_4/tensor_names, save/RestoreV2_4/shape_and_slices)]]
"
10689,Tensorflow build fails with -mavx512f,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Fedora 25
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: latest commit f58e6ce , happens with older versions as well (23caaa5, f48673b, 9a15e0a, 3c4cb08 to only name a few)
- **Bazel version (if compiling from source)**: 0.4.5
- **CUDA/cuDNN version**: none
- **CPU model and memory**: XEON PHI 7250, 96GiB ram
- **Exact command to reproduce**: 
./configure
specify optimization flags: -mavx512f
bazel  build --config=opt --verbose_failures //tensorflow/tools/pip_package:build_pip_package

### Describe the problem
Building Tensorflow from source fails when avx512 instructions are activated.
After managing to compile most of the source the build fails somewhere in the eigen part of the code.

[builderror.txt](https://github.com/tensorflow/tensorflow/files/1072902/builderror.txt)

Don't let yourself get thrown off by the ""MKL"" in some path names, its just the name of the virtualenv, for this report MKL was turned off in the configure.
See also similar Issue #9849


"
10685,Darwin support for MKL build / configure script,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Mac OS X 10.12.4, Darwin
- **TensorFlow installed from (source or binary)**:
Source, git tag 1.2.0 RC 2
- **TensorFlow version (use command below)**:
1.2 RC 2
- **Bazel version (if compiling from source)**:
bazel version
..............
Build label: 0.4.3-homebrew
Build target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Thu Dec 22 15:20:15 2016 (1482420015)
Build timestamp: 1482420015
Build timestamp as int: 1482420015
- **CUDA/cuDNN version**:
N/A
- **GPU model and memory**:
N/A
- **Exact command to reproduce**:
./configure 
Please specify the location of python. [Default is /usr/bin/python]: 
Found possible Python library paths:
  /Library/Python/2.7/site-packages
Please input the desired Python library path to use.  Default is [/Library/Python/2.7/site-packages]

Using python library path: /Library/Python/2.7/site-packages
Do you wish to build TensorFlow with MKL support? [y/N] y
MKL support will be enabled for TensorFlow
Do you wish to download MKL LIB from the web? [Y/n] Y
Darwin is unsupported yet

You can collect some of this information using our environment capture script:
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh
N/A
You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Darwin / Mac OS X support for Intel's optional MKL optimizations. MKL appears to have darwin support, so I am unsure why it is not supported in Tensorflow. I imagine this is on a to-do, but a publicly tracked feature request might be helpful. Thank you.

### Source code / logs
N/A"
10681,Build with Bazel on Windows: missing input file '@local_config_cuda//cuda:cuda-extras,"### System information
- **Have I written custom code**: No
- **OS Platform**: `Windows 10`
- **TensorFlow installed from**: `source`
- **TensorFlow version**: `v1.2.0-rc2`
- **Bazel version**: `git/master`
- **CUDA/cuDNN version**: `8.0` / `5.1`
- **GPU model**: `Nvidia GTX 1080`
- **Exact command to reproduce**: `bazel build -c opt --config=win-cuda --cpu=x64_windows_msvc --host_cpu=x64_windows_msvc --copt=-w --host_copt=-w tensorflow/tools/pip_package:build_pip_package`

### Describe the problem

I try to compile TensorFlow on Windows with Bazel (without GPU support at first). But i run into a error (see down below).

Does anyone have a idea how i can fix this or what the problem is?

### Error log
```
ERROR: missing input file '@local_config_cuda//cuda:cuda-extras'.
ERROR: C:/users/spenh/appdata/local/temp/_bazel_spen/icnq02mb/external/highwayhash/BUILD.bazel:22:1: C++ compilation of rule '@highwayhash//:arch_specific' failed: msvc_cl.bat failed: error executing command external/local_config_cc/wrapper/bin/msvc_cl.bat /DOS_WINDOWS=OS_WINDOWS /DCOMPILER_MSVC /DNOGDI /DNOMINMAX /DPRAGMA_SUPPORTED /D_WIN32_WINNT=0x0600 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS ... (remaining 26 argument(s) skipped): com.google.devtools.build.lib.shell.AbnormalTerminationException: Process terminated by signal 2.
ERROR: C:/users/spenh/appdata/local/temp/_bazel_spen/icnq02mb/external/local_config_cuda/cuda/BUILD:142:1: @local_config_cuda//cuda:cupti_headers: missing input file '@local_config_cuda//cuda:cuda-extras'.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
ERROR: C:/users/spenh/appdata/local/temp/_bazel_spen/icnq02mb/external/local_config_cuda/cuda/BUILD:142:1 1 input file(s) do not exist.
```
"
10680,tf.estimator generator_input_fn no padding queue?,"Hello again! 
While I was examining TF source code for [10597 issue](https://github.com/tensorflow/tensorflow/issues/10597) solution, I found another bug or lack of important feature, such as `PaddingFIFOQueue` for all of `tf.estimator` input pipelines. Such option is very important for seq2seq tasks with dynamic shapes.

As a solution I found a hacky way to generate `[1, batch_size, time]` batches and squeeze them to `[batch_size, time]` in the model. Source code: [tensorflow](https://github.com/Scitator/tensorflow), [model](https://github.com/Scitator/TF-seq2seq/tree/tf_master_seq2seq), [notebook](https://gist.github.com/Scitator/d72cef607d23200074dfbbc1cbce3b55).

As you can understand, I am not very happy with such solution, that's why I am asking for help to solve it in more correct and tensorflow way. Any suggestions?"
10679,recovery_wait_secs feature for tf.train.MonitoredTrainingSession() similar to the one present in tf.train.SessionManager(),"I ran the distributed model for a small data set and for very few epochs for some test run.

The chief worker started normally and finished training (training time was less than 30 seconds) but the other workers did not start.

Below log message has been displayed in all the workers other than chief:
`Waiting for model to be ready.  Ready_for_local_init_op:  Variables not initialized: <list_of_variables >`

Then I found the reason behind this in [this](https://stackoverflow.com/questions/42986653/distributed-tensorflow-not-running-some-workers/43007657#43007657) Stackoverflow answer.

A `recover_wait_secs` feature would make it easier rather handling that timeout period manually."
10677, No OpKernel was registered to support Op 'Maximum' with these attrs.---iOS,"Consult: excuse me, write own model file, called collapse, iOS,

![snip20170613_6](https://user-images.githubusercontent.com/8908244/27081496-407ad54a-5073-11e7-8464-faab2ca4836e.png)"
10676,DSP process time investigation,"Hello,

I am evaluating the DSP process time by the bellows source code.

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/hexagon/hexagon_graph_execution_test.cc

And, The result was short process time.
As one factor, I think that the reason is quantization to input data of  DSP.
Could you please tell me a change procedure for quantization ?
And, Could I please have the pb file(NOT quantizate) before the bellows quantization pb file ?

tensorflow_inception_v3_stripped_optimized_quantized.pb 

I want to compare between DSP process time(quantizate input data) and CPU process time(NOT quantizate input data)"
10675,Inner tf.device inherits device index when using wildcard index,"TF version: v1.2.0-rc0-735-gf48673b (about one week ago)

```python
with tf.device('gpu:7'):
    with tf.device('cpu:*'):
        print(tf.constant(0).device) # /device:CPU:7
```

workaround:

```python
with tf.device('gpu:7'):
    with tf.device(None), tf.device('cpu:*'):
        print(tf.constant(0).device) # /device:CPU:*
```"
10674,Tensor flow importing error please help very important,"![error1](https://user-images.githubusercontent.com/29398681/27076888-0a944dde-504c-11e7-8549-6882eda7cff9.PNG)
![error2](https://user-images.githubusercontent.com/29398681/27076889-0a947b9c-504c-11e7-8c59-4de236a9d328.PNG)
"
10673,Public head of master is failing windows CMAKE tests (?),"The following tests are failing for several of the public pull requests.  I suggest that the current head of master would also fail in the same way.

```
The following tests FAILED:
	171 - C:/tf_jenkins/home/workspace/tensorflow-pr-win-cmake-py/tensorflow/python/kernel_tests/sparse_ops_test.py (Failed)
	173 - C:/tf_jenkins/home/workspace/tensorflow-pr-win-cmake-py/tensorflow/python/kernel_tests/sparse_reshape_op_test.py (Failed)
```

"
10672,Strange performance: sparse tensor matmul in kernel_test,"Sorry for the previous issue 
According to the document [HERE](https://www.tensorflow.org/api_docs/python/tf/sparse_tensor_dense_matmul)

> tensorflow/python/sparse_tensor_dense_matmul_op_test --benchmarks
A sparse [m, k] with % nonzero values between 1% and 80%
B dense [k, n]

When I run [sparse_tensor_dense_matmul_op_test.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/kernel_tests/sparse_tensor_dense_matmul_op_test.py) with large n,m,k
I get:
```
% nnz 	 n 	 gpu 	 m 	 k 	 dt(dense) 	 dt(sparse) 	 dt(sparse)/dt(dense)
0.5 	 512 	 True 	 1822 	 4608 	 0.0222946 	 0.0130646 	 0.585998
0.5 	 512 	 True 	 1821 	 4608 	 0.0224976 	 0.0130761 	 0.581222
0.5 	 512 	 True 	 1820 	 4608 	 0.022529 	 0.79513 	 35.2936
0.5 	 512 	 True 	 1819 	 4608 	 0.0217343 	 0.795709 	 36.6107
```
It is strange that `dt(sparse)/dt(dense)` are very different when m=1821 -> 1820
BTY, I set the iterations to 10 for time saving...
```
delta_dense = _timer(sess, ops_fn, 10)
delta_sparse = _timer(sess, ops_fn, 10)
```

Here's some information:
OS: Ubuntu 14.04
tf-version: 1.1.0  installed from source
GPU: NVIDIA K80, 4 kernels (only '/gpu:0' is used)
CUDA: 8.0
cudnn: 5.1.5

You can run sparse_tensor_dense_matmul_op_test.py with my settings
```
  for thresh in (0.5,):
    for n in (512,):
      for use_gpu in (True,):
        for m in (1822, 1821, 1820, 1819):
          for k in (9*512,):
            sparse_tensor_dense_vs_dense_matmul_benchmark(
                thresh, m, k, n, False, False, use_gpu=use_gpu)
```
"
10671,Linux CPU smoke tests failing due to merged API change,"This commit appears to break the Linux CPU tests (at least for me).  It seems that when the smoke tests passed for this commit, the Linux CPU tests didn't include the api_compatibility_test, but now they do.  However, the golden API and the real API have already diverged, so there isn't any possibility of successful passing any more.

```
commit e6f58186363279496c46563e6f065ce7ea16c501
Author: Bo Wang <david.b.wang@gmail.com>
Date:   Mon Jun 5 11:41:32 2017 -0700
```
"
10669,Running session using c++ api is significantly slower than using python,"### System information
- **OS Platform and Distribution**: Linux 13.1 (Bottle)
- **TensorFlow installed from**: source
- **TensorFlow version**: 1.1.0 (git version: v1.1.0-1-g10ec24a, compiler version: v1.1.0-1-g10ec24a)
- **Compiler**: c++ (SUSE Linux) 4.8.1 20130909 [gcc-4_8-branch revision 202388]
- **Bazel version**: 0.4.5
- **Packages**: numpy (1.11.3), numpydoc (0.6.0), protobuf (3.1.0)

No docker, no virtual environment.
All tests were done using CPU only. 
All optimization flags are set, no warnings are shown.
tcmalloc is also used.
Batching also helps to increase the performance both for c++ and python, but the gap stays the same.

### Describe the problem
I have written a simple benchmark based on official Deep MNIST example (https://www.tensorflow.org/get_started/mnist/pros). I create a simple convolutional net, train it on MNIST (number of training steps is small as we are interested in speed, not accuracy), freeze the graph and load it to c++. Then I do tests using python and using c++ and measure average time that it takes to run a tensorflow session. My tests show that running session in python takes ~2ms, while doing the same using c++ api is slower: ~3ms.
The code of the benchmark can be found here:
https://github.com/July-Morning/MNIST_convnet_tensorflow
It should also be mentioned that the same tests were done for the multilayer perceptron. In that case c++ api was significantly (~7-10x times) faster than python just as was expected."
10668,Get strange results by running sparse_tensor_dense_matmul_op_test.py,"When I run sparse_tensor_dense_matmul_op_test.py with large n,m,k
I get:
```
% nnz 	 n 	 gpu 	 m 	 k 	 dt(dense) 	 dt(sparse) 	 dt(sparse)/dt(dense)
0.5 	 512 	 True 	 1822 	 4608 	 0.0222946 	 0.0130646 	 0.585998
0.5 	 512 	 True 	 1821 	 4608 	 0.0224976 	 0.0130761 	 0.581222
0.5 	 512 	 True 	 1820 	 4608 	 0.022529 	 0.79513 	 35.2936
0.5 	 512 	 True 	 1819 	 4608 	 0.0217343 	 0.795709 	 36.6107
```
It is strange that `dt(sparse)/dt(dense)` are very different when m=1821 -> 1820
BTY, I set the iterations to 10 for time saving...
```
delta_dense = _timer(sess, ops_fn, 10)
delta_sparse = _timer(sess, ops_fn, 10)
```"
10665,The issue of compling from source code: undeclared inclusion(s) in rule '@nccl_archive//:nccl',"Hey guys,

I can compile the cpu version of tensorflow 1.2.0-rc2 without any problem, however, i am blocked when i try to compile the gpu version. I spend almost the whole day to install tensorflow 1.2.0-rc2 gpu version in our cluster, however there is no lucky.

### Here is the error from the terminal: 

ERROR: /home/hpc-xin/.cache/bazel/_bazel_hpc-xin/c5e302e32d7acb9c3e4fce8142d1cd66/external/nccl_archive/BUILD:33:1: undeclared inclusion(s) in rule '@nccl_archive//:nccl':
this rule is missing dependency declarations for the following files included by 'external/nccl_archive/src/libwrap.cu.cc':
  '/gpfs/gpfs1/apps2/gcc/5.4.0/lib/gcc/x86_64-unknown-linux-gnu/5.4.0/include-fixed/limits.h'
  '/gpfs/gpfs1/apps2/gcc/5.4.0/lib/gcc/x86_64-unknown-linux-gnu/5.4.0/include-fixed/syslimits.h'
  '/gpfs/gpfs1/apps2/gcc/5.4.0/lib/gcc/x86_64-unknown-linux-gnu/5.4.0/include/stddef.h'
  '/gpfs/gpfs1/apps2/gcc/5.4.0/include/c++/5.4.0/new'
  '/gpfs/gpfs1/apps2/gcc/5.4.0/include/c++/5.4.0/x86_64-unknown-linux-gnu/bits/c++config.h'
  '/gpfs/gpfs1/apps2/gcc/5.4.0/include/c++/5.4.0/x86_64-unknown-linux-gnu/bits/os_defines.h'
  '/gpfs/gpfs1/apps2/gcc/5.4.0/include/c++/5.4.0/x86_64-unknown-linux-gnu/bits/cpu_defines.h'
  '/gpfs/gpfs1/apps2/gcc/5.4.0/include/c++/5.4.0/exception'
  '/gpfs/gpfs1/apps2/gcc/5.4.0/include/c++/5.4.0/bits/atomic_lockfree_defines.h'
  '/gpfs/gpfs1/apps2/gcc/5.4.0/include/c++/5.4.0/bits/exception_ptr.h'
  '/gpfs/gpfs1/apps2/gcc/5.4.0/include/c++/5.4.0/bits/exception_defines.h'
  '/gpfs/gpfs1/apps2/gcc/5.4.0/include/c++/5.4.0/bits/nested_exception.h'
  '/gpfs/gpfs1/apps2/gcc/5.4.0/lib/gcc/x86_64-unknown-linux-gnu/5.4.0/include/stdarg.h'
  '/gpfs/gpfs1/apps2/gcc/5.4.0/include/c++/5.4.0/cmath'
  '/gpfs/gpfs1/apps2/gcc/5.4.0/include/c++/5.4.0/bits/cpp_type_traits.h'
  '/gpfs/gpfs1/apps2/gcc/5.4.0/include/c++/5.4.0/ext/type_traits.h'
  '/gpfs/gpfs1/apps2/gcc/5.4.0/include/c++/5.4.0/cstdlib'
  '/gpfs/gpfs1/apps2/gcc/5.4.0/include/c++/5.4.0/cstdio'.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 22.226s, Critical Path: 5.20s

### OS Information 
Red Hat Enterprise Linux Workstation release 6.7 (Santiago)

### Modules I loaded
gcc/5.4.0, cuda/8.0.61, cudnn/6.0, java/1.8.0_31, sqlite/3.18.0, tcl/8.6.6.8606, python/3.6.1

### Here is how i make the configuration
gcc (v5.4.0): /apps2/gcc/5.4.0 (customized path）
enabled cuda (v8.0): /apps2/cuda/8.0.61 (customized path）
enabled cudnn: /apps2/cudnn/6.0 (customized path）
python (v3.6.1, which is compiled with gcc 5.4.0): /apps2/python/3.6.1 (customized path)
Other options are disabled (such as hadoop, google cloud). 

### Here are some files i modified manually before compiling
(1) /tensorflow-1.2.0-rc2/third_party/gpus/crosstool/CROSSTOOL_clang.tpl
     /tensorflow-1.2.0-rc2/third_party/gpus/crosstool/CROSSTOOL_nvcc.tpl
    Add the following contents in all of ""toolchain"": 
    cxx_builtin_include_directory: ""/apps2/gcc/5.4.0/lib/gcc/x86_64-unknown-linux-gnu/5.4.0/include""
    cxx_builtin_include_directory: ""/apps2/gcc/5.4.0/lib/gcc/x86_64-unknown-linux-gnu/5.4.0/include-fixed""
    cxx_builtin_include_directory: ""/apps2/gcc/5.4.0/include/c++/5.4.0""
    cxx_builtin_include_directory: ""/apps2/gcc/5.4.0/include""
    cxx_builtin_include_directory: ""/apps2/cuda/8.0.61/include""
    cxx_builtin_include_directory: ""/apps2/cudnn/6.0/include""

(2) /home/hpc-xin/.cache/bazel/_bazel_hpc-xin/c5e302e32d7acb9c3e4fce8142d1cd66/external/protobuf/protobuf.bzl
     Add the following content in ""ctx.action""
     env=ctx.configuration.default_shell_env

(3) /home/hpc-xin/.cache/bazel/_bazel_hpc-xin/c5e302e32d7acb9c3e4fce8142d1cd66/external/nccl_archive/Makefile
     Some modification as below:
     CUDA_HOME ?= /usr/local/cuda --> CUDA_HOME ?= /apps2/cuda/8.0.61

I noticed that some of people said this issue could be bypassed by delete the nccl dependence in ""/tensorflow-1.2.0-rc2/tensorflow/contrib/BUILD"". However, i do not think this is the correct way to solve this issue. I wanna keep this dependence.

Thanks so much for your help. Any comments are appreciated.
Best Regards
Xin"
10664,Forcing symmetric quantization,
10663,MemoryError when freezing large model,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.2.0-rc2
- **Bazel version (if compiling from source)**: 0.5.1
- **CUDA/cuDNN version**: CUDA8 / CuDNN6
- **GPU model and memory**: Tesla K80, 11439MiB
- **Exact command to reproduce**: ```~/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph --input_graph=fcn.pbtxt --output_graph=frozen.pb --input_checkpoint=ckpt --output_nodes_names=""Softmax""```

### Describe the problem
I'm attempting to freeze a large model with the `freeze_graph` tool and I get a `MemoryError`. This seems really weird to me since the machine should have more than enough memory. I also tried running with `CUDA_VISIBLE_DEVICES=""""` but got the same result.

```
ubuntu@ip-172-31-33-208:~/code/segnet$ free -g
              total        used        free      shared  buff/cache   available
Mem:             59           1          51           0           7          58
Swap:             0           0           0
```

``` $ ls -larth
drwxr-xr-x 2 ubuntu ubuntu 4.0K Jun  7 22:37 variables
-rw-r--r-- 1 ubuntu ubuntu 513M Jun  7 22:37 saved_model.pb
drwxrwxr-x 2 ubuntu ubuntu 4.0K Jun 12 20:45 data
drwxrwxr-x 3 ubuntu ubuntu 4.0K Jun 12 21:39 ..
-rw-rw-r-- 1 ubuntu ubuntu 1.1K Jun 12 23:07 load.py
-rw-rw-r-- 1 ubuntu ubuntu 1.5G Jun 12 23:09 fcn.pbtxt
-rw-rw-r-- 1 ubuntu ubuntu 4.8K Jun 12 23:09 ckpt.index
-rw-rw-r-- 1 ubuntu ubuntu 1.6G Jun 12 23:09 ckpt.data-00000-of-00001
-rw-rw-r-- 1 ubuntu ubuntu   65 Jun 12 23:09 checkpoint
-rw-rw-r-- 1 ubuntu ubuntu 513M Jun 12 23:09 ckpt.meta
drwxrwxr-x 4 ubuntu ubuntu 4.0K Jun 12 23:09 .
```

I first converted the `saved_model.pb` to a `.pbtxt`, `fcn.pbtxt` with a checkpoint `ckpt` with this script https://gist.github.com/domluna/ed477cb5698c787f29c7d56fba381fed. I couldn't get the freeze tool to work with `saved_model.pb` which was created based on `tf.saved_model`.

### Source code / logs

```
ubuntu@ip-172-31-33-208:~/code/segnet$ ~/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph --input_graph=fcn.pbtxt --output_graph=frozen.pb --output_nodes_names=""Softmax""
Traceback (most recent call last):
  File ""/home/ubuntu/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py"", line 255, in <module>
    app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/home/ubuntu/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""/home/ubuntu/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py"", line 187, in main
    FLAGS.variable_names_blacklist)
  File ""/home/ubuntu/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py"", line 165, in freeze_graph
    input_graph_def = _parse_input_graph_proto(input_graph, input_binary)
  File ""/home/ubuntu/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py"", line 134, in _parse_input_graph_proto
    text_format.Merge(f.read(), input_graph_def)
  File ""/home/ubuntu/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/protobuf/python/google/protobuf/text_format.py"", line 476, in Merge
    descriptor_pool=descriptor_pool)
  File ""/home/ubuntu/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/protobuf/python/google/protobuf/text_format.py"", line 526, in MergeLines
    return parser.MergeLines(lines, message)
  File ""/home/ubuntu/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/protobuf/python/google/protobuf/text_format.py"", line 559, in MergeLines
    self._ParseOrMerge(lines, message)
  File ""/home/ubuntu/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/protobuf/python/google/protobuf/text_format.py"", line 574, in _ParseOrMerge
    self._MergeField(tokenizer, message)
  File ""/home/ubuntu/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/protobuf/python/google/protobuf/text_format.py"", line 675, in _MergeField
    merger(tokenizer, message, field)
  File ""/home/ubuntu/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/protobuf/python/google/protobuf/text_format.py"", line 764, in _MergeMessageField
    self._MergeField(tokenizer, sub_message)
  File ""/home/ubuntu/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/protobuf/python/google/protobuf/text_format.py"", line 675, in _MergeField
    merger(tokenizer, message, field)
  File ""/home/ubuntu/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/protobuf/python/google/protobuf/text_format.py"", line 764, in _MergeMessageField
    self._MergeField(tokenizer, sub_message)
  File ""/home/ubuntu/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/protobuf/python/google/protobuf/text_format.py"", line 675, in _MergeField
    merger(tokenizer, message, field)
  File ""/home/ubuntu/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/protobuf/python/google/protobuf/text_format.py"", line 764, in _MergeMessageField
    self._MergeField(tokenizer, sub_message)
  File ""/home/ubuntu/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/protobuf/python/google/protobuf/text_format.py"", line 675, in _MergeField
    merger(tokenizer, message, field)
  File ""/home/ubuntu/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/protobuf/python/google/protobuf/text_format.py"", line 764, in _MergeMessageField
    self._MergeField(tokenizer, sub_message)
  File ""/home/ubuntu/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/protobuf/python/google/protobuf/text_format.py"", line 662, in _MergeField
    tokenizer.Consume(':')
  File ""/home/ubuntu/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/protobuf/python/google/protobuf/text_format.py"", line 1016, in Consume
    if not self.TryConsume(token):
  File ""/home/ubuntu/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/protobuf/python/google/protobuf/text_format.py"", line 1003, in TryConsume
    self.NextToken()
  File ""/home/ubuntu/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/protobuf/python/google/protobuf/text_format.py"", line 1236, in NextToken
    match = self._TOKEN.match(self._current_line, self._column)
MemoryError
```
"
10662,TF_BINARY_URL,"Would be so grateful for some guidance.

Please advise on the appropriate TF_BINARY_URL for compiling Tensor Flow on an Odroid XU4 which uses a Samsung Exynos5422 Cortex™-A15 2Ghz and Cortex™-A7 Octa core CPUs and a Mali-T628 MP6(OpenGL ES 3.1/2.0/1.1 and OpenCL 1.2 Full profile).

Please advise on the TF_BINARY_URL to use for:
Ubuntu/Linux 64-bit, CPU only, Python 2.7
Ubuntu/Linux 64-bit, CPU only, Python 3.5

Is there a GPU version that supports the Mali-T628 MP6(OpenGL ES 3.1/2.0/1.1 and OpenCL 1.2 Full profile) on the Odroid XU4

Thank you!
"
10661,tf.train.Scaffold missing global_step attribute,"According to the docstring of `tf.train.Scaffold`, there is a `global_step` attribute with the following description:

* `global_step`: A tensor containing the global step counter.  Picked
    from and stored into the `GLOBAL_STEP` collection in the graph by default.

(see https://github.com/tensorflow/tensorflow/blob/f60b6bdcb59f5538f3301207eabc30c10a9b6d46/tensorflow/python/training/monitored_session.py#L84)

The problem is that no such attribute actually exists.
"
10659,seq2seq.dynamic_rnn_decoder not working for multilayered encoder in TF 1.0,"I am trying to implement **Multilayer Bidirectional Attention based seq2seq** in **TF 1.0** using `**tf.contrib.seq2seq library**`. 
[This is my implementation.](https://github.com/adakum/seq2seq/blob/master/seq2seq_model.py)
It works perfectly fine for single layered encoder and decoder but gives error with multi layer. 

`Error : ""ValueError: Shape must be rank 2 but is rank 4 for 'Decoder/dynamic_rnn_decoder/Decoder/attention_decoder/concat' (op: 'ConcatV2') with input shapes: [?,10], [2,2,?,20], [].""`

The problem is , when running single layer, the encoder just returns **LSTM state tuple**(for 1 layer) but in multi layer it returns an **array of LSTMStateTuple(i.e. one for each layer.)** which is fed into the decoder and creating problem I guess. 

So isn't `seq2seq.dynamic_rnn_decoder` made to work `MultiRNNCell  `, i.e. multilayered decoder ? 

Encoder part is running perfectly fine for multi layers and **returning encoder states for each layer**. 

**_If u want to run my implementation : 
1.	clone repo
2.	switch to tf 1.0 env
3.	python generate_questions.py 

This will just create computation graph. In case of `num_layer=1`, graph is created is successfully but fails with `num_layer>1`._**
"
10656,Ignoring visible gpu device,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Arch Linux with linux kernel version 4.11
- **TensorFlow installed from (source or binary)**:source
- **TensorFlow version (use command below)**:1.2.0-rc2
- **Bazel version (if compiling from source)**:0.5.0-1
- **CUDA/cuDNN version**:8.0.61-2/6.0.21-1
- **GPU model and memory**:Quadro M1200, 32Gig of RAM
- **Exact command to reproduce**:running ` sess = tf.session()` inside the python interactive shell.

### Describe the problem
I have followed the [official document](https://www.tensorflow.org/install/install_sources) to install from source. The build process and the install process shows no issues, but when I run the command:
```
>>> import tensorflow as tf
>>> hello = tf.constant('Hello, TensorFlow!')
>>> sess = tf.Session()
```
It says:
```
>>> sess = tf.Session()
2017-06-13 00:53:55.614764: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-06-13 00:53:55.614999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Quadro M1200
major: 5 minor: 0 memoryClockRate (GHz) 1.148
pciBusID 0000:01:00.0
Total memory: 3.95GiB
Free memory: 3.92GiB
2017-06-13 00:53:55.615013: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2017-06-13 00:53:55.615017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2017-06-13 00:53:55.615022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] Ignoring visible gpu device (device: 0, name: Quadro M1200, pci bus id: 0000:01:00.0) with Cuda compute capability 5.0. The minimum required Cuda capability is 5.2.
```
But when I visit the [nvidia website](https://developer.nvidia.com/cuda-gpus), it says that the Quadro M1200 have Compute Capability 5.2.
"
10655,Feature Request: Add an optional command-line argument for a prefix URL,"Would like to add a command-line argument that allows TensorBoard to run at a different URL location than the root domain.  So for example:
* command-line: `--base_url runhere`
* URL location: `http://<address>:6006/runhere/`

Motivation for request: There are locations where only minimal ports are open and it would be great to use nginx (or similar) to route TensorBoard through port 80.

"
10654,"build from sources on amazon EC2 failed,  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE ","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
10652,Undocumented change in sharing variables from version 1.0 to 1.1,"
### System information
- **Custom code, a minimal reproducible example provided below**:
- **Linux Ubuntu 14.04**:
- **TensorFlow installed from binary using pip**:
- **TensorFlow version 1.0.1 and 1.1.0**:
- **CUDA 8.0/cuDNN 5.1**:
- **GeForce GTX 1080**:


### Problem
Variable scopes and sharing works different in versions 1.0.1 and 1.1.0. I try to enter a non-reusing variable scope after executing tf.get_variable_scope().reuse_variables(). This results in different values of tf.get_variable_scope().reuse inside this scope. When using version 1.0.1 it is False while when using 1.1.0 it is True. [The sharing variable guide](https://www.tensorflow.org/versions/r1.0/programmers_guide/variable_scope) states that setting reuse = False inside a reusing scope is not the desired behavior, but the guide is completely the same for both versions. Moreover, no changes in handling variable scopes are mentioned in release notes for version 1.1. 

### Source code / logs
```
import tensorflow as tf
print tf.__version__

with tf.variable_scope('foo'):
    assert tf.get_variable_scope().reuse == False, tf.get_variable_scope().reuse
    tf.get_variable_scope().reuse_variables()
    assert tf.get_variable_scope().reuse == True, tf.get_variable_scope().reuse
    with tf.variable_scope(tf.get_variable_scope(), reuse=False):
       print tf.get_variable_scope().reuse
```
Output:

- Version 1.0.1
```
1.0.1
False
```
- Version 1.1.0
```
1.1.0
True
```"
10651,Different results using tf.train.batch and tf.train.shuffle_batch,"### System information
- **Custom code**:
Yes
- **OS Platform and Distribution**:
Linux Ubuntu 16.04
- **TensorFlow installed from**:
binary
- **TensorFlow version (use command below)**:
v1.1.0-rc0-61-g1ec6ed5
- **CUDA/cuDNN version**:
CUDA 8 and cuDNN 5.1
- **GPU model and memory**:
GTX Titan X (Maxwell) with 12GB of RAM

Hello,

I am currently working on sequential data with variable length and would like to build a dynamic graph with respect to the ""time"" of the sequence. Because tf.train.shuffle_batch does not handle dynamic padding, the only official solution is to work with tf.train.batch. To assert the problem, I am preprocessing the data before batching to get sequences with constant length in order to be able to use shuffle_batch and tf.train.batch to compare them. So, **the only difference** between the two compared pipelines is the swap between tf.train.batch and tf.train.shuffle_batch. Problem : the results drop significantly at test time using tf.train.batch instead of tf.train.shuffle_batch.

![tboard](https://user-images.githubusercontent.com/13334577/27040041-1c421dfc-4f90-11e7-8fea-ded0f5edc1a3.png)

My database is self made and I believe properly shuffled initially : the database is cross subject and all occurrences of a user are shuffled using Python's random.shuffle (the size of the lists is small enough for the pseudo random to be relevant), then added to the TFRecords. 

Queue randomization doesn't seem to be the problem either : using standy66's workaround showed in #5147 doesn't change the outcome of the tf.train.batch pipeline. 

Should we expect different behaviors from these two functions (except for the random queue shuffling) or is this behavior abnormal?

Thanks,
Quentin"
10650,tf.reshape does not take tf.Dimension as argument ,"Minimal code to reproduce

```
import tensorflow as tf
t = tf.constant([1, 2, 3])
d = tf.Dimension(3)
t = tf.reshape(t, [-1, d])
```

Gives stack trace:

```
TypeError: Expected binary or unicode string, got -1
```


The reason this would be useful to allow is because when you access tensor shapes (with, e.g. ```t.shape```) you get it in tf.Dimension so if you want to assign relative to the current shape then you don't need to convert to int


If there is some reason why tensorflow doesn't allow this behaviour than I think at least the stack trace should be more verbose (e.g. in the example above it shouldn't be complaining about -1, it should be complaining about the value in tf.Dimension class)"
10649,Implement architecture-independent fallback in tensorflow/workspace.bzl,"Archictecture-dependent binaries such as `nodejs` limits portability to different targets (namely, I'm interested in Tensorflow ppc64le builds). I tried replacing x64 binaries with ppc64 in the cached dirs and managed to compile Tensorflow (see https://github.com/tensorflow/tensorflow/issues/10306).

This issue is similar to https://github.com/bazelbuild/rules_closure/issues/207.
"
10648,Segmentation Fault (core dumped) on exit from unit test that imports `tf.contrib.rnn`,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 14.04
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: 1.0.0
- **Bazel version (if compiling from source)**: 0.4.4
- **CUDA/cuDNN version**: 8.0/5110
- **GPU model and memory**: GeForce GTX 980 Ti
- **Exact command to reproduce**: `python -m unittest discover -s tests -p ""example_test.py""`(see below for details)

### Describe the problem
I am running Tensorflow code from within the Python `unittest` module. The individual unit-tests, each of which train a specific architecture, run successfully with an OK. However, I observed that given the above described system configuration, I receive a `Segmentation Fault (core dumped)` just before the program exits. And this leads to the overall test being marked as `FAIL` (despite the individual tests passing).

On further investigation, I observed that the segmentation fault can be prevented from occurring by preventing the `tensorflow/contrib/rnn/python/ops/_gru_ops.so` file from being loaded by the `load_op_library` function inside `tensorflow.contrib.rnn.python.ops.gru_ops`

### Source code / logs
Say I have a folder `my_code` that contains a `tests` folder where my unit-tests are all located. The error can be reproduced by running an `example_test.py` (given below) within the `unittest` module using the call `python -m unittest discover -s tests -p ""example_test.py"" from within the `my_code` directory. The file `my_code/tests/example_tests.py` contains the following:

```
import unittest                               
import tensorflow as tf                       
                                              
class SomeTestClass(unittest.TestCase): 
    """"""Some docstring.""""""              
                                              
    def test_something(self):          
        print(""Testing something...\n"")
        print tf.contrib.rnn.LSTMCell         
        session = tf.Session()                
        session.close()                       
```

Note that the error occurs only when both `session` is created and there is a reference to `tf.contrib.rnn`."
10647,SyntaxError: invalid syntax when import tensorflow-gpu as tf  ,"hiiiii,,,,
iam newbie in tensorflow, i have followed tutorial from https://www.tensorflow.org/versions/r0.12/get_started/os_setup#using_conda. Every step that i take,  no error,

but when import tensorflow, it's appears error, like this

> import tensorflow-gpu as tf
  File ""<stdin>"", line 1
    import tensorflow-gpu as tf
                     ^
SyntaxError: invalid syntax


please help me "
10646,Clarify Installation Docs for Windows (32-bit),"Quick feature/docs request. I've noticed a few people on Stack Overflow asking about running Tensorflow on 32-bit machines. I'm aware that some people have had some success as described by @mrry 's post here:

[S/O: ""TensorFlow on 32-bit Linux?""](https://stackoverflow.com/a/33635450/7604321)

One example of a confused user trying to use Windows: 

[S/O: ""how to install tensorflow for windows 7 32bit system?i installed python 3.5(32 bit) into my system and also installed anaconda 3.4.4(32 bit)""](https://stackoverflow.com/questions/44449972/how-to-install-tensorflow-for-windows-7-32bit-systemi-installed-python-3-532-b)

I was wondering whether it was worth putting a little system requirement that reminded users that Tensorflow is only supported on 64 bit machines on the install page? Unless it is not then perhaps some little clarification? Cheers"
10645,"The official code about:Reading data from Tfrecord file, I do not this it is a good way.Because it do not real random shuffle data, any one have a better way, and how to sample data with tfrecord file. ","tensorflow official code about read data from tfrecord like this:
1. creat a shuffle file queue
2. several thread read data from file that dequeue from file queue(The reader will read data from the file until the file is empty, and then the file queue dequeue a new file)
3. put the data read by the reader to a randomshufflequeue, to make a batch data for training or testing.(this way likes one people drinking sweet water problem:drinking a mouthful of sweet water, and adding equal water.)
Even though you shuffle data before convert it to tfrecord, it is not real random.
If you convert each data to a tfrecord file, I think this is real random, but the efficiency is reduced.
Any one has a better way?
Imbalance data is common, sample is a good way to solve this problem, how to sample data with tfrecord file.
Thanks
"
10644,TFRecordWriter.flush() for Python bundle?,"TFRecords.Writer seems to take up too much memory when dealing with large dateset and may cause out-of-memory issue. 

Also, the `.TFRecords` file seems not appendable right now, so it's pretty hard to write large dataset to a single `.TFRecords` file at one run.

`Flush()` is available on the C++ side in tensorflow::core::lib::io::RecordWriter but is not exposed in the Python bindings. Is it possible to add a python interface to make it easier?"
10642,[1.1.0-gpu image] Can't open shared object file libcuda.so.1,"#### Version info
GPU: Nvidia K40 and K80
Docker : 1.12.6
Image tag: 1.1.0-gpu and latest-gpu
#### Reproduce
I pulled the [tensorflow/tensorflow:1.1.0-gpu](https://hub.docker.com/r/tensorflow/tensorflow/tags/) docker image and I got the error as below when I started to run it:
```
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 51, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 52, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
ImportError: libcuda.so.1: cannot open shared object file: No such file or directory

Failed to load the native TensorFlow runtime.
```"
10641,bug: BeamSearchDecoder should not assume that  when time > 0 beam will be full,"```
  scores_flat = control_flow_ops.cond(
      time > 0,
      lambda: array_ops.reshape(scores, [batch_size, -1]),
      lambda: scores[:, 0])
  num_available_beam = control_flow_ops.cond(
      time > 0,
      lambda: math_ops.reduce_prod(scores_shape[1:]),
      lambda: math_ops.reduce_prod(scores_shape[2:]))

  # Pick the next beams according to the specified successors function
  next_beam_size = math_ops.minimum(
      ops.convert_to_tensor(
          beam_width, dtype=dtypes.int32, name=""beam_width""),
      num_available_beam)
  next_beam_scores, word_indices = nn_ops.top_k(scores_flat, k=next_beam_size)
  next_beam_scores.set_shape([static_batch_size, beam_width])
  word_indices.set_shape([static_batch_size, beam_width])
``` 
code start from
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py#L510

Correct me if I am wrong, but I think this code is assuming that, when time > 0 the beam will be full. It is true when the vocabulary is big such as is the case in machine translation. but if the vocabulary is small, the beam might won't be full when time > 0 and might pose a problem.  the value of `next_beam_size ` in the code seems must be `beam_width` or it will raise an error since `next_beam_scores.set_shape([static_batch_size, beam_width])`, which make ` next_beam_size = math_ops.minimum` useless.

I am trying to write a Pointer Network BeamSearch Decoder by modifying this source file. And the vocabulary is usually small, so there is a possibility that when time == 1 the beam won't be fully filled. 

I appreciate finally some one wrote a general BeamSeach decoder, that will make my life easier.

"
10640,Estimator missing `tf.convert_to_tensor`,"#10623 shows, there is `tf.convert_to_tensor` missing somewhere.
@magixsno Could you provide the whole stacktrace, please?"
10638,Might be a bug for contrib.legacy_seq2seq,"Hi, 

I am using the embedding_attention_seq2seq with output_projection. The document from https://www.tensorflow.org/api_docs/python/tf/contrib/legacy_seq2seq/embedding_rnn_decoder says,
> outputs: A list of the same length as decoder_inputs of 2D Tensors with shape [batch_size x num_decoder_symbols] containing the generated outputs.

But the output seems to be the output before projection when I used it. So I go through the source code from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py , 

embedding_attention_seq2seq is base on the embedding_attention_decoder and attention_decoder. It has to give output_size to attention_decoder, but output_size is set to None when output_projection is not None.
```python
def embedding_attention_seq2seq(encoder_inputs,
                                decoder_inputs,
                                cell,
                                num_encoder_symbols,
                                num_decoder_symbols,
                                embedding_size,
                                num_heads=1,
                                output_projection=None,
                                feed_previous=False,
                                dtype=None,
                                scope=None,
                                initial_state_attention=False):
    ... # skip
    output_size = None
    if output_projection is None:
      cell = core_rnn_cell.OutputProjectionWrapper(cell, num_decoder_symbols)
      output_size = num_decoder_symbols

    if isinstance(feed_previous, bool):
      return embedding_attention_decoder(
          decoder_inputs,
          encoder_state,
          attention_states,
          cell,
          num_decoder_symbols,
          embedding_size,
          num_heads=num_heads,
          output_size=output_size,
          output_projection=output_projection,
          feed_previous=feed_previous,
          initial_state_attention=initial_state_attention)
```

When output_size is None, the output_size is simply the cell's output_size. And so the shape of output for embedding_attention_seq2seq will be [batch_size x cell's output_size]  rather than [batch_size x num_decoder_symbols]
```python
def attention_decoder(decoder_inputs,
                      initial_state,
                      attention_states,
                      cell,
                      output_size=None,
                      num_heads=1,
                      loop_function=None,
                      dtype=None,
                      scope=None,
                      initial_state_attention=False):
  ... # skip
  if output_size is None:
    output_size = cell.output_size
  ... # skip
      with variable_scope.variable_scope(""AttnOutputProjection""):
        output = linear([cell_output] + attns, output_size, True)
      if loop_function is not None:
        prev = output
      outputs.append(output)

  return outputs, state
```


Thanks.


"
10634,Cannot find Eigen source code,"I got confused by the directory structure after I compiled the code.
There are some folders starting with `bazel-`, so what are they?
I want to find where is the source code for Eigen library (e.g., implementation for `extract_image_patches` function) and I want to change some lines inside.
Currently I only found them under `bazel-tensorflow/external/eigen_archive/unsupported/Eigen/CXX11`, but `bazel-tensorflow` is a soft link and it points to a tmp dir on my mac where I found there's a README file says 

> This directory was generated by Blaze.
Do not attempt to modify or delete any files in this directory.

So, where is the original source code for Eigen so I can modify it?

I guess this question is better to be asked on stackoverflow but I tried there is no reply.
I hope I won't waste too much of your time. It's a very quick question I suppose :)"
10633,How can I code this android imagery app from scratch? ,How can I code this android imagery app from scratch? 
10632,InvalidArgumentError: You must feed a value for placeholder tensor 'Placeholder_9' with dtype float,"Hi, I'm wondering what is causing this problem seems to be persistent. The data I'm feeding into the graph is indeed float

```
WARNING:tensorflow:From <ipython-input-98-ea92c0cb6f5e>:18: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.
Instructions for updating:
Use `tf.global_variables_initializer` instead.
[2017-06-11 20:48:41,474] From <ipython-input-98-ea92c0cb6f5e>:18: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.
Instructions for updating:
Use `tf.global_variables_initializer` instead.
0
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-99-2436fc2ab63a> in <module>()
      1 if __name__ == '__main__':
----> 2     main()

<ipython-input-92-503a02b9fa94> in main()
     19                 state, action, next_state, reward, done, portfolio, portfolio_value = env_stage_data(agent, step, episode_data, portfolio, portfolio_value, True)
     20                 total_reward += reward
---> 21                 agent.perceive(state,action,reward,next_state,done)
     22                 if done:
     23                     break

<ipython-input-98-ea92c0cb6f5e> in perceive(self, state, action, reward, next_state, done)
     76 
     77         if len(self.replay_buffer) > 2000:
---> 78             self.train_Q_network()
     79 
     80     def train_Q_network(self):

<ipython-input-98-ea92c0cb6f5e> in train_Q_network(self)
    105         summary_str = self.session.run(merged_summary_op,feed_dict={
    106                 self.y_input : y_batch,
--> 107                 self.action_input : action_batch,
    108                 #self.state_input : state_batch
    109                 })    

/Users/jiewwantan/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict, options, run_metadata)
    776     try:
    777       result = self._run(None, fetches, feed_dict, options_ptr,
--> 778                          run_metadata_ptr)
    779       if run_metadata:
    780         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/Users/jiewwantan/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _run(self, handle, fetches, feed_dict, options, run_metadata)
    980     if final_fetches or final_targets:
    981       results = self._do_run(handle, final_targets, final_fetches,
--> 982                              feed_dict_string, options, run_metadata)
    983     else:
    984       results = []

/Users/jiewwantan/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
   1030     if handle is None:
   1031       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,
-> 1032                            target_list, options, run_metadata)
   1033     else:
   1034       return self._do_call(_prun_fn, self._session, handle, feed_dict,

/Users/jiewwantan/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_call(self, fn, *args)
   1050         except KeyError:
   1051           pass
-> 1052       raise type(e)(node_def, op, message)
   1053 
   1054   def _extend_graph(self):

InvalidArgumentError: You must feed a value for placeholder tensor 'Placeholder_9' with dtype float
	 [[Node: Placeholder_9 = Placeholder[dtype=DT_FLOAT, shape=[], _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

Caused by op u'Placeholder_9', defined at:
  File ""/Users/jiewwantan/anaconda2/envs/tensorflow/lib/python2.7/runpy.py"", line 174, in _run_module_as_main
    ""__main__"", fname, loader, pkg_name)
  File ""/Users/jiewwantan/anaconda2/envs/tensorflow/lib/python2.7/runpy.py"", line 72, in _run_code
    exec code in run_globals
  File ""/Users/jiewwantan/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py"", line 16, in <module>
    app.launch_new_instance()
  File ""/Users/jiewwantan/anaconda2/envs/tensorflow/lib/python2.7/site-packages/traitlets/config/application.py"", line 658, in launch_instance
    app.start()
  File ""/Users/jiewwantan/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel/kernelapp.py"", line 477, in start
    ioloop.IOLoop.instance().start()
  File ""/Users/jiewwantan/anaconda2/envs/tensorflow/lib/python2.7/site-packages/zmq/eventloop/ioloop.py"", line 177, in start
    super(ZMQIOLoop, self).start()
  File ""/Users/jiewwantan/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tornado/ioloop.py"", line 888, in start
    handler_func(fd_obj, events)
  File ""/Users/jiewwantan/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tornado/stack_context.py"", line 277, in null_wrapper
    return fn(*args, **kwargs)
  File ""/Users/jiewwantan/anaconda2/envs/tensorflow/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py"", line 440, in _handle_events
    self._handle_recv()
  File ""/Users/jiewwantan/anaconda2/envs/tensorflow/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py"", line 472, in _handle_recv
    self._run_callback(callback, msg)
  File ""/Users/jiewwantan/anaconda2/envs/tensorflow/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py"", line 414, in _run_callback
    callback(*args, **kwargs)
  File ""/Users/jiewwantan/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tornado/stack_context.py"", line 277, in null_wrapper
    return fn(*args, **kwargs)
  File ""/Users/jiewwantan/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel/kernelbase.py"", line 283, in dispatcher
    return self.dispatch_shell(stream, msg)
  File ""/Users/jiewwantan/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel/kernelbase.py"", line 235, in dispatch_shell
    handler(stream, idents, msg)
  File ""/Users/jiewwantan/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel/kernelbase.py"", line 399, in execute_request
    user_expressions, allow_stdin)
  File ""/Users/jiewwantan/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel/ipkernel.py"", line 196, in do_execute
    res = shell.run_cell(code, store_history=store_history, silent=silent)
  File ""/Users/jiewwantan/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel/zmqshell.py"", line 533, in run_cell
    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
  File ""/Users/jiewwantan/anaconda2/envs/tensorflow/lib/python2.7/site-packages/IPython/core/interactiveshell.py"", line 2718, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""/Users/jiewwantan/anaconda2/envs/tensorflow/lib/python2.7/site-packages/IPython/core/interactiveshell.py"", line 2822, in run_ast_nodes
    if self.run_code(code, result):
  File ""/Users/jiewwantan/anaconda2/envs/tensorflow/lib/python2.7/site-packages/IPython/core/interactiveshell.py"", line 2882, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-75-2436fc2ab63a>"", line 2, in <module>
    main()
  File ""<ipython-input-74-503a02b9fa94>"", line 5, in main
    agent = DQN(data_dictionary)
  File ""<ipython-input-73-76942abbcce5>"", line 13, in __init__
    self.create_Q_network(data_dictionary)
  File ""<ipython-input-73-76942abbcce5>"", line 45, in create_Q_network
    self.state_input = tf.placeholder(""float"",[None,self.state_dim])
  File ""/Users/jiewwantan/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py"", line 1507, in placeholder
    name=name)
  File ""/Users/jiewwantan/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 1997, in _placeholder
    name=name)
  File ""/Users/jiewwantan/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 768, in apply_op
    op_def=op_def)
  File ""/Users/jiewwantan/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2336, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/Users/jiewwantan/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1228, in __init__
    self._traceback = _extract_stack()

InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_9' with dtype float
	 [[Node: Placeholder_9 = Placeholder[dtype=DT_FLOAT, shape=[], _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
```"
10631,i get an error when i build tensorflow by bazel on windows,"PS C:\WINDOWS\system32> cd tensorflow
PS C:\WINDOWS\system32\tensorflow> bazel build -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both --cop
t=-msse4.2 --copt=-msse --copt=-msse2 --copt=-msse3 --copt=-msse4.1 //tensorflow/tools/pip_package:build_pip_package
>>
.....................
ERROR: C:/windows/system32/tensorflow/tensorflow/tools/pip_package/BUILD:27:1: error loading package 'tensorflow/core':
Encountered error while reading extension file 'protobuf.bzl': no such package '@protobuf//': Traceback (most recent cal
l last):
        File ""C:/windows/system32/tensorflow/tensorflow/workspace.bzl"", line 117
                _apply_patch(repo_ctx, repo_ctx.attr.patch_file)
        File ""C:/windows/system32/tensorflow/tensorflow/workspace.bzl"", line 108, in _apply_patch
                _execute_and_check_ret_code(repo_ctx, cmd)
        File ""C:/windows/system32/tensorflow/tensorflow/workspace.bzl"", line 92, in _execute_and_check_ret_code
                fail(""Non-zero return code({1}) when ..., <2 more arguments>))
Non-zero return code(127) when executing 'C:\tools\msys64\usr\bin\bash.exe -c patch -p1 -d C:/users/godw/appdata/local/t
emp/_bazel_godw/nseddbsr/external/protobuf -i C:/windows/system32/tensorflow/third_party/protobuf/add_noinlines.patch':
Stdout:
Stderr: /usr/bin/bash: patch: command not found
 and referenced by '//tensorflow/tools/pip_package:included_headers_gather'."
10624,Support multi-processing on tf.py_func,"This would be a great feature to have. The tf.py_func op is very handy for certain custom operations, but when training on multiple GPUs it ends up becoming a bottleneck that slows everything down. One way to get around that is to allow tf.py_fun to run on a different process each time, and by doing so avoid the GIL bottleneck. This could be enabled only when stateful = False, to avoid unintended side effects.


"
10622,RecordInput Documentation in API doc site,"[RecordInput is in the tf 1.2 code](https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/python/ops/data_flow_ops.py#L1602) but I don't see it in the [tf 1.2 API docs](https://www.tensorflow.org/versions/r1.2/api_docs/python/). Should it be present?
"
10621,when i use bazel to build i got error that  no such package '@protobuf,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
10620,How to code this imaging android app from scratch? ,How can I code this imaging android app from scratch? 
10619,Feature Request: Tensorboard visualization of what parts of a given training image were deemed as 'important' after a inception v3 has been retrained,"After retraining inception v3 on my own image set, I'm running into where any new image that I ask it to recognize, that _shouldn't_ match any of the training categories, is confidently scored as one of the image categories. 

For example, if I train it on two types of steering wheels that are exactly the same except one category/type has two buttons on the right. After training has finished, if I show inception an image of some other random thing, like a horse, it confidently scores it as one of the steering wheel categories! 

The issue is that there is no way to get insight as to _why_ this is happening. In other words, there is no way to tell that the model has correctly learned that the real difference between the two steering wheel categories is presence or absence of the the two buttons on the right. It would be extremely useful to be able to upload an image in tensorboard and have it show you a heat map, overlaid on the image, of what specific parts of the image the model deemed important when classifying it as a particular category. 

To elaborate further, if you have two categories that you retrained inception on, you would be able to upload an image, and you would see different regions of the image highlighted using two different colors (one color per category). Then you would be able to clearly see that the model has or has not correctly learned the real difference between the images. In addition, you could upload a image that should not be classified as one of the two categories and you would be able to see _why_ it incorrectly thought it was one of the two categories.
![00c0c_jygsfznatmv_600x450](https://user-images.githubusercontent.com/13044220/27007360-baed3810-4e05-11e7-9e68-5e895fd5562b.jpg)
![112_0905_04z-2010_toyota_prius-interior_view](https://user-images.githubusercontent.com/13044220/27007362-c6e05bc0-4e05-11e7-9280-4f40c4585545.jpg)
"
10618,crop_and_resize issue with box_index on 1.2rc2,"I use crop_and_resize() in a standard way as such:
```
pool = tf.image.crop_and_resize(features, boxes, box_indicies, pool_shape, method=""bilinear"")
```

And it works great. Then I tried to train on multiple GPUs, and I got this error:
```
OutOfRangeError: box_index has values outside [0, batch_size)
	 [[Node: tower_2/mask_rcnn/roi_align/CropAndResize = CropAndResize[T=DT_FLOAT, extrapolation_value=0, method=""bilinear"", _device=""/job:localhost/replica:0/task:0/gpu:2""](tower_2/mask_rcnn/activation_40/Relu, tower_2/mask_rcnn/roi_align/StopGradient, tower_2/mask_rcnn/roi_align/StopGradient_1/_5871, tower_2/mask_rcnn/roi_align/CropAndResize/crop_size)]]
	 [[Node: tower_5/mask_rcnn/mrcnn_mask/Reshape_1/_6389 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:5"", send_device_incarnation=1, tensor_name=""edge_33119_tower_5/mask_rcnn/mrcnn_mask/Reshape_1"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
```
I verified that box_index is within the correct range (all zeros in my case because I use one image per batch), and verified that all the other inputs to crop_and_resize() look good. I ended up spending almost two days checking and rechecking every line of my code to make sure I didn't make a mistake somewhere. It drove me nuts. Finally, I tried downgrading TF to 1.1 and suddenly everything worked. And to make sure this is the problem, I upgraded to 1.2rc2 again and got the error again. 

### A few points that might help:
- On 1.1 it works whether I use 1 GPU or 8 GPUs. On 1.2rc2 it works on 1 GPU but fails on 8GPUs.
- The way I do multi-GPU training is by running 8 copies of my model, one on each GPU (shared weights). My input batch size is 8 and I split the inputs by the batch dimension and feed one sample to each GPU, and then I concatenate the outputs to get a batch size of 8 again and then apply the loss function.
- If you're wondering why I'm using 1.2rc2, it's because 1.1 has an issue that causes Batch normalization to run on CPU and it was fixed in 1.2rc2.

### System information
- Ubuntu 16.04
- Python 3.5
- TensorFlow 1.2.0-rc2. Installed using 
```
sudo pip3 install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.2.0rc2-cp35-cp35m-linux_x86_64.whl
```
- On EC2 p2.8xlarge (8 GPUs)
"
10617,nda,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
10616,[feature] Support S3 Filesystem for Tensorflow,"At the moment Tensorflow supports distributed file system implementations such as HDFS or GCS which has been very useful for handling cases in a distributed environment. Both of them utilize Tensorflow's FileSystem C++ interface.

In case Tensorflow is used in AWS, it would be great to have a S3 Filesystem for Tensorflow as well.

We have a preliminary implementation of S3 Filesystem on Tensorflow, based on AWS's C++ SDK:
https://github.com/tensorflow/tensorflow/compare/master...yongtang:s3

The code is placed under the directory of tensorflow/contrib/s3.

As AWS is widely used, I am just wondering if it make sense to have a pull request to add S3 File system on Tensorflow?

It will be better to have feedback from community so that we could improve our implementation and help those deploying Tensorflow on AWS.
"
10614,Issue adding external Library (OpenCL),"Description of the problem / feature request / question:

I am trying to use bazel to build TensorFlow Library. It builds fine.

Additional Feature :
I would like to add OpenCL code in one of the files of TensorFlow. Added all the required code
AND added the following in one of the build files (tensorflow/core/BUILD), considering 'opencl' as the root directory of opencl.

cc_library(
name = ""opencl"",
hdrs=glob([""opencl/include/CL/*h""]),
visibility =[""//visibility:public""],
)

cc_library(
name=""all_kernels"" ,
visibility= [""//visibility:public""],
copts=tf_copts() + [""-Ithird_party/opencl/include""],
deps= [
""//third_party/opencl"",
],

If possible, provide a minimal example to reproduce the problem:

By running
bazel build //tensorflow/examples/android:tensorflow_demo --fat_apk_cpu=armeabi-v7a --copt=""-Ithird_party/opencl/include""

Issues Faced while building :
error: undefined reference to 'clEnqueueReadBuffer'
error: undefined reference to 'clReleaseMemObject'
error: undefined reference to 'clReleaseMemObject'

etc

Environment info

Operating System: Ubuntu 17.04

Bazel version (output of bazel info release): release 0.5.1

Have you found anything relevant by searching the web?

https://stackoverflow.com/questions/37761469/how-to-add-external-header-files-during-bazel-tensorflow-build/37844376

Anything else, information or logs or outputs that would be helpful?

bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-fastbuild/bin/tensorflow/core/kernels/libandroid_tensorflow_kernels.lo(conv_ops.o):conv_ops.cc:function matrixMul(float*, float*, int, int, int, int, int, int): error: undefined reference to 'clGetPlatformIDs'
bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-fastbuild/bin/tensorflow/core/kernels/libandroid_tensorflow_kernels.lo(conv_ops.o):conv_ops.cc:function matrixMul(float*, float*, int, int, int, int, int, int): error: undefined reference to 'clGetDeviceIDs'
bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-fastbuild/bin/tensorflow/core/kernels/libandroid_tensorflow_kernels.lo(conv_ops.o):conv_ops.cc:function matrixMul(float*, float*, int, int, int, int, int, int): error: undefined reference to 'clCreateContext'

I tried linking directly to libOpenCL.so as shown below by referring https://bazel.build/versions/master/docs/tutorial/cpp.html#adding-dependencies-on-precompiled-libraries
, but still same issue

cc_library(
    name = ""opencl"",
    srcs = glob([""lib/x86_64/*.so""]),
    hdrs = glob([""include/CL/*.h""]),
visibility = [""//visibility:public""],
)

Please help me in resolving the issuee"
10613,"Binaries missing from the ""frontpage""?","Hi,

The downloads for the latest RC which link to the ci domain all give me a 404 right now. I understand they may be CI builds that are somewhat superseded, but they cannot possibly be deleted so quickly, without more recent binary, can they?
Thanks!

************************************************************




Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
10612,"Implement components for ""Self-normalizing networks""","Hochreiter's group has recently come up with a new dropout technique and activation function in a recent paper (https://arxiv.org/abs/1706.02515). Presented experiments demonstrate that these lead to better learning in standard feed forward networks. 

I would like to implement these components in TensorFlow. Creating this issue to gauge the community's interest level in such components. Feedback will be extremely helpful."
10611,[1.2.0 rc2] Tensorboard does not show graph on Windows 10,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:

I used the following minimal example:
```python
import tensorflow as tf
a = tf.constant(5)
b = tf.constant(4)
c = a+b
with tf.Session() as sess:
  Writer = tf.summary.FileWriter(""Test"", sess.graph)
  Writer.close()
```

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: 

I installed the wheel: https://ci.tensorflow.org/job/tf-master-win-gpu-cmake/lastSuccessfulBuild/artifact/cmake_build/tf_python/dist/tensorflow_gpu-1.2.0rc2-cp35-cp35m-win_amd64.whl
Which is the build ""694"" on Jenkins of the job ""tf-master-win-gpu-cmake""

On version 1.1 (provided by pip), the graph was shown correctly. I needed to update to this version to get text-events in Tensorboard.

- **TensorFlow version (use command below)**: 1.2.0-rc2 (build 694 of job ""tf-master-win-gpu-cmake"")
- **Bazel version (if compiling from source)**: - 
- **CUDA/cuDNN version**: 8.0/5.1
- **GPU model and memory**: GTX680 with 4 GB
- **Exact command to reproduce**:
```
tensorboard --logdir=Test
```

If I use ""inspect"" I get the following output:

```
tensorboard --logdir=Test --inspect
======================================================================
Processing event files... (this can take a few minutes)
======================================================================

Found event files in:
Test

These tags are in Test:
audio -
histograms -
images -
scalars -
tensor -
======================================================================

Event statistics for Test:
audio -
graph
   first_step           0
   last_step            0
   max_step             0
   min_step             0
   num_steps            1
   outoforder_steps     []
histograms -
images -
scalars -
sessionlog:checkpoint -
sessionlog:start -
sessionlog:stop -
tensor -
======================================================================

```
I'm using Chrome Browser for Tensorboard (Firefox does not show anything for that version).

### Describe the problem
No Graph is shown on Tensorboard.

### Source code / logs
See above"
10610,how can convert pascal voc dataset  labels?,"Hi,
how can conversioning  the pascal voc 2012 dataset and the berkely extended version.
has the tensorflow  solution for this  problem. or a link for download with prepossessing annotation.

Thanks."
10609,Reshape cannot infer the missing input size for an empty tensor unless all specified,"I trained faster-rcnn on coco dataset, when iter =11410, it appears a problem:
image: COCO_train2014_000000076146.jpg iter: 11410 / 200000, total loss: 3.3490, rpn_loss_cls: 0.7608, rpn_loss_box: 1.0145, loss_cls: 0.7640, loss_box: 0.8098, lr: 0.001000
speed: 0.327s / iter
2017-06-08 22:59:42.143627: W tensorflow/core/framework/op_kernel.cc:1152] Invalid argument: **Reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero**
[[Node: gradients/TopKV2_grad/Reshape = Reshape[T=DT_INT32, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/gpu:0""](TopKV2/_131, gradients/TopKV2_grad/stack)]]
2017-06-08 22:59:42.143670: W tensorflow/core/framework/op_kernel.cc:1152] Invalid argument: **Reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero**
[[Node: gradients/TopKV2_grad/Reshape = Reshape[T=DT_INT32, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/gpu:0""](TopKV2/_131, gradients/TopKV2_grad/stack)]]
2017-06-08 22:59:42.143965: W tensorflow/core/framework/op_kernel.cc:1152] Invalid argument: Reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero
[[Node: gradients/TopKV2_grad/Reshape = Reshape[T=DT_INT32, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/gpu:0""](TopKV2/_131, gradients/TopKV2_grad/stack)]]
2017-06-08 22:59:42.144042: W tensorflow/core/framework/op_kernel.cc:1152] Invalid argument: Reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero
[[Node: gradients/TopKV2_grad/Reshape = Reshape[T=DT_INT32, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/gpu:0""](TopKV2/_131, gradients/TopKV2_grad/stack)]]
2017-06-08 22:59:42.145758: W tensorflow/core/framework/op_kernel.cc:1152] Invalid argument: Reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero
[[Node: gradients/TopKV2_grad/Reshape = Reshape[T=DT_INT32, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/gpu:0""](TopKV2/_131, gradients/TopKV2_grad/stack)]]
Traceback (most recent call last):
File ""/home/yanchao/TFFRCNN/faster_rcnn/train_net.py"", line 132, in 
restore=bool(int(args.restore)))
File ""/home/yanchao/TFFRCNN/faster_rcnn/../lib/fast_rcnn/train.py"", line 400, in train_net
sw.train_model(sess, max_iters, restore=restore)
File ""/home/yanchao/TFFRCNN/faster_rcnn/../lib/fast_rcnn/train.py"", line 255, in train_model
cls_prob, bbox_pred, rois = sess.run(fetches=fetch_list, feed_dict=feed_dict)
File ""/home/yanchao/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 778, in run
run_metadata_ptr)
File ""/home/yanchao/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 982, in _run
feed_dict_string, options, run_metadata)
File ""/home/yanchao/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1032, in _do_run
target_list, options, run_metadata)
File ""/home/yanchao/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1052, in _do_call
raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: **Reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero**
[[Node: gradients/TopKV2_grad/Reshape = Reshape[T=DT_INT32, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/gpu:0""](TopKV2/_131, gradients/TopKV2_grad/stack)]]

Caused by op u'gradients/TopKV2_grad/Reshape', defined at:
File ""/home/yanchao/TFFRCNN/faster_rcnn/train_net.py"", line 132, in 
restore=bool(int(args.restore)))
File ""/home/yanchao/TFFRCNN/faster_rcnn/../lib/fast_rcnn/train.py"", line 400, in train_net
sw.train_model(sess, max_iters, restore=restore)
File ""/home/yanchao/TFFRCNN/faster_rcnn/../lib/fast_rcnn/train.py"", line 142, in train_model
grads, norm = tf.clip_by_global_norm(tf.gradients(loss, tvars), 10.0)
File ""/home/yanchao/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py"", line 560, in gradients
grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))
File ""/home/yanchao/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py"", line 368, in _MaybeCompile
return grad_fn() # Exit early
File ""/home/yanchao/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py"", line 560, in 
grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))
File ""/home/yanchao/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/nn_grad.py"", line 577, in _TopKGrad
ind_2d = array_ops.reshape(op.outputs[1], array_ops.stack([-1, ind_lastdim]))
File ""/home/yanchao/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 2510, in reshape
name=name)
File ""/home/yanchao/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 768, in apply_op
op_def=op_def)
File ""/home/yanchao/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2336, in create_op
original_op=self._default_original_op, op_def=op_def)
File ""/home/yanchao/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1228, in init
self._traceback = _extract_stack()

...which was originally created as op u'TopKV2', defined at:
File ""/home/yanchao/TFFRCNN/faster_rcnn/train_net.py"", line 132, in 
restore=bool(int(args.restore)))
[elided 0 identical lines from previous traceback]
File ""/home/yanchao/TFFRCNN/faster_rcnn/../lib/fast_rcnn/train.py"", line 400, in train_net
sw.train_model(sess, max_iters, restore=restore)
File ""/home/yanchao/TFFRCNN/faster_rcnn/../lib/fast_rcnn/train.py"", line 112, in train_model
self.net.build_loss(ohem=cfg.TRAIN.OHEM)
File ""/home/yanchao/TFFRCNN/faster_rcnn/../lib/networks/network.py"", line 643, in build_loss
rpn_cross_entropy_n_neg, _ = tf.nn.top_k(rpn_cross_entropy_n_neg, k=top_k)
File ""/home/yanchao/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.py"", line 1998, in top_k
return gen_nn_ops._top_kv2(input, k=k, sorted=sorted, name=name)
File ""/home/yanchao/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 2502, in _top_kv2
name=name)
File ""/home/yanchao/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 768, in apply_op
op_def=op_def)
File ""/home/yanchao/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2336, in create_op
original_op=self._default_original_op, op_def=op_def)
File ""/home/yanchao/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1228, in init
self._traceback = _extract_stack()

InvalidArgumentError (see above for traceback): **Reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero**
[[Node: gradients/TopKV2_grad/Reshape = Reshape[T=DT_INT32, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/gpu:0""](TopKV2/_131, gradients/TopKV2_grad/stack)]]

Process finished with exit code 1

Does anyone meet the same things? Or this is a bug of tensorflow. It's really a strange problem."
10607,functional add_n: compose a new (differentiable) op from a list of ops without memory footprint,"### Describe the problem

It is a feature request, and should be very related to the current high memory cost of tensorflow. 

In my case, I am building a graph which I should be able to compute gradients. In this graph, I heavily use the `add_n` op which returns a tensor from a list of tensors. I want to remark that this is very inefficient for two reasons:

1. Memory wise, it requires to cache all input tensors in the list before it actually aggregates. Technically, such process can be replaced by `accumulate_n` if one does not care computing its gradient. In facts, I have been tried with `add_n` with input list size goes to tens or a hundred, it quickly fills up the memory of GPUs. 

2. Besides high memory footprint, it also prohibits the use of multi-thread framework of tensorflow, ultimately affecting the efficiency. This is because the idea of `add_n` actually introduces an extra layer of tensors whose controlled dependency prevents deallocating any of these tensors computed in time. Consider the following example:

```python
a=tf.Variable(0.2)
b=tf.Variable(0.1)

c=[tf.sin(a), tf.cos(a), tf.sin(b)]
d=[tf.sin(a), tf.cos(b)]

e=add_n(c)
f=add_n(d)
# ... initialization 
sess.run([e, f])
```
In the above example, suppose given variables `a` and `b` what we really need is tensors `e` and `f`, but the introduction of tensor list `c` and `d` occupies what I consider as redundant memory. Note that the computation of tensors in `c` and `d` can be made multi-threaded / parallel if we have infinite memory. But the real situation is if the caching tensors in `c` already eat up all memory, no tenors in `d` will be executed simultaneously until `e` is complete (at which time `c` is released). 

In fact, one can calculate `e` and its gradients `de/da`, `de/db` without explicitly storing any tensors in `c`. This trick is by introducing a functional which takes a set of ops and their inputs, and return a global summed-up tensor, which may look like:

```python

a=tf.Variable(0.2)
b=tf.Variable(0.1)

e_func=add_n_functional([tf.sin, tf.cos, tf.sin])
e=e_func([a, a, b])
f_func=add_n_functional([tf.sin, tf.cos])
f=f_fun([a, b])

# ... initialization 
sess.run([e, f])
```
Note `add_n_functional` returns a new op from a list of given ops. With this new functional, we can avoid buffering a lot intermediate tensors. At the same time, `e_func` and `f_func` are still differentiable.

I was thinking how to implement this idea at python level, but it seems to only be feasible via rewriting some C++ parts. I will appreciate if this feature is added to tensorflow in the near future.   



"
10605,tensorflow/tools/git script breaks when git repo has packed references,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Not applicable to bug
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
Source build
- **TensorFlow version (use command below)**:
tip of tree
- **Bazel version (if compiling from source)**:
0.5.1
- **CUDA/cuDNN version**:
n/a
- **GPU model and memory**:
n/a
- **Exact command to reproduce**:
```
git pack-refs
git gc
bazel clean
configure
bazel build -c opt --copt=-g --copt=-mavx --copt=-msse4.2 //tensorflow/tools/pip_package:build_pip_package
```

- **Results**:
```
ERROR: /local/chip/git/tensorflow-knureon/tensorflow/core/BUILD:1404:1: no such target '//tensorflow/tools/git:gen/branch_ref': target 'gen/branch_ref' not declared in package 'tensorflow/tools/git' defined by /local/chip/git/tensorflow-knureon/tensorflow/tools/git/BUILD and referenced by '//tensorflow/core:version_info_gen'.
ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted.
```


The problem is due to the fact that the link in tensorflow/tools/git/gen/branch_ref is supposed to point to a valid file in my .git directory: .git/refs/heads/tf-tip.  However, I have been doing some reorganizing of our tree structure, and in the process of removing deprecated branches my calls to git caused this file to be deleted.  So the .git/refs/heads directory is empty and the hash is found in .git/packed-refs:

rdubielzig@swpl-000224:/local/chip/git/tensorflow-knureon/.git$ grep tf-tip packed-refs 
504965336d1432ee96b4f0e9b78f65ee201e9be5 refs/heads/tf-tip


WORKAROUND:
Recreate the missing ref file by writing  'tf-tip' in .git/refs/heads with the contents consisting of the hash above."
10602,TensorBoard:  enable text-selection (for copy/paste) of tf.summary.text items,The way tensorboard is currently implemented seems to prevent one from selecting (in a web browser) the text of tf.summary.text summaries.  It would be nice if it were possible to copy/paste such text.
10599,Pretrain NLP embeddings,"I found a lot of pretrain CNN models in `tf.contrib.keras.applications`. Nevertheless, for NLP researchers there is no even well-know GoogleNews word2vec vectors or Glove, or...something. 

Is it possible to add functionality for simplified embedding download and future usage? Some official `maybe_download_google_news_w2v` or something like that."
10597,tf.estimator generator_input_fn multi thread bug ,"I would like to use python generators as input pipeline for tf.estimator's. Finally I found generator_input_fn (announced [here](https://youtu.be/5DknTFbcGVM?t=12m30s)).

Nevertheless, when I start first experiments, I found I bug with learning curve. After some experiments I found the purpose of it - all blows up if you set `num_threads` > 1 in generator_input_fn.

For example, here is loss plot with python generator and `num_threads=1`:
![tf_py_generator_1_thread](https://user-images.githubusercontent.com/7606451/26978620-d58faec2-4d34-11e7-8f8b-14e4e50f6844.png)

And with `num_threads=2`:
![tf_py_generator_2_threads](https://user-images.githubusercontent.com/7606451/26978619-d58a9e3c-4d34-11e7-8f1b-8bab67a957aa.png)

**But** if I use `tf.estimator.inputs.numpy_input_fn` with 4 thread all work pretty well:
![tf_numpy_generator_4_threads](https://user-images.githubusercontent.com/7606451/26978621-d591c11c-4d34-11e7-85ce-2340bd2ed01c.png)
Except the fact, that I cannot save all my data in one numpy array (GBs of data).

Any suggestions why so? Or I need just wait for TF 1.2 with working `tf.estimators.inputs.generator_input_fn`?

Jupyter notebook with my experiments [here](https://gist.github.com/Scitator/184c8d676f36a9b7c04fb504d9088590)."
10596,Can't import tensorflow 1.2 since last anaconda 4.4 update,"I installed tf 1.2 from source on Ubuntu 16.04, and It worked as it should until I updated anaconda to 4.4 yesterday. It refuses to load and gives me this error:

```
>>> import tensorflow
Traceback (most recent call last):
  File ""/home/jingw222/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/home/jingw222/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/home/jingw222/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/home/jingw222/anaconda3/lib/python3.6/imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""/home/jingw222/anaconda3/lib/python3.6/imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: /home/jingw222/anaconda3/bin/../lib/libstdc++.so.6: version `GLIBCXX_3.4.20' not found (required by /home/jingw222/anaconda3/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/jingw222/anaconda3/lib/python3.6/site-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/home/jingw222/anaconda3/lib/python3.6/site-packages/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/home/jingw222/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 52, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/home/jingw222/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/home/jingw222/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/home/jingw222/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/home/jingw222/anaconda3/lib/python3.6/imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""/home/jingw222/anaconda3/lib/python3.6/imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: /home/jingw222/anaconda3/bin/../lib/libstdc++.so.6: version `GLIBCXX_3.4.20' not found (required by /home/jingw222/anaconda3/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

```

Anyone knows what went wrong?"
10594,Windows GPU Installation Documentation,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
YES
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 10
- **TensorFlow installed from (source or binary)**:
Binary
- **TensorFlow version (use command below)**:
1.1.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
5 and 6 (that's the issue)
- **GPU model and memory**:
GTX 965M, 2GB memory
- **Exact command to reproduce**:
sess = tf.InteractiveSession()
### Describe the problem
This is a request to add information to your installation website. The documentation for installing the gpu version in Windows omits a crucial piece of information: the version of cudnn64_X.dll must exactly match the version used when the binary for tensorflow was compiled. The installation instructions advise you to be sure that cudnn64_X.dll is in the path. However, this is of zero use if it is the wrong dll. 

I'm currently running tensorflow 1.1.0, which I installed from the binary distribution. That version requires cudnn64_5.dll, but this critical information is nowhere to be found in the documentation. Instead, I just got the error message that tensorflow failed to start. The current version from nVidia is cudnn64_6.dll. Tensorflow won't run if it doesn't find cudnn64_5.dll. However, if you rename version 6 to version 5, tensorflow will load, but it will stop with errors. (Actually, that's how I tracked down the problem - it mentioned version 5100 of the GPU, which I assumed meant release 5).

Please add to the installation page the required version of nVidia's dll: cudnn64_X.dll. Otherwise, the gpu version won't start, and it is remarkably difficult to figure out that the problem is as simple as using the wrong (e.g., latest) version of the cudnn64_x driver. 

### Source code / logs
NA
"
10590,Saving embeddings or output evaluations in parallel to training,"Feature request to create an async embedding saving buffer, which runs on the processor while the code trains on a GPU

The aim would be make sure that training is not affected by saving the model. That anyway takes a single thread, therefore it is a process that is done using an async buffer, it could optimize the training of models.
------------------------

### System information
- Linux Ubuntu 16.04:
- Installed from source with GPU implementation:
- 1.0.1:
- CUDA, cuDNN : 7.5
- GPU: Nividia Titan X

There was a **57x** slowdown to in line saving. 

"
10588,Simplify getting variable by name,"Suppose we created a variable `foo/v`
```
with tf.variable_scope(""foo""):
    v = tf.get_variable(""v"", [1])
```
To get this variable from its name one currently needs to write two lines:
```
with tf.variable_scope(""foo"", reuse=True):
    v1 = tf.get_variable(""v"")
```
Instead, it would be much more intuitive to just write:
```
v1 = tf.get_variable(""foo/v"", reuse=True)
```

"
10587,TensorFlow is failing on ci.bazel.io with Bazel@HEAD,"http://ci.bazel.io/job/TensorFlow/BAZEL_VERSION=HEAD,PLATFORM_NAME=linux-x86_64/870/console

```
==== bazel version ====
...........
Build label: 
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Thu Jun 8 20:25:30 2017 (1496953530)
Build timestamp: 1496953530
Build timestamp as int: 1496953530


+ ./tensorflow/tools/ci_build/builds/configured CPU
~/workspace/TensorFlow/BAZEL_VERSION/HEAD/PLATFORM_NAME/linux-x86_64 ~/workspace/TensorFlow/BAZEL_VERSION/HEAD/PLATFORM_NAME/linux-x86_64
You have bazel  installed.
Please upgrade your bazel installation to version 0.4.5 or higher to build TensorFlow!
Exiting...
```
The reason is Bazel@HEAD doesn't generate a version number, the new way of version check introduced in 88d648f3beedfa6123efabb756be372f69382983 fails.

Maybe skip the check if the version number is empty? Because this also means users cannot use their custom bazel to build TF unless they add `--embed_label ${version_number}` as a build option.

"
10585,Run convert_graphdef_memmapped_format fail,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
    No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
    OS X EI Caption 10.11.6
- **TensorFlow installed from (source or binary)**:
    binary (pip install)
- **TensorFlow version (use command below)**:
    TensorFlow 1.2.0-rc1 CPU Only
- **Bazel version (if compiling from source)**:
    Build label: 0.4.5-homebrew
    Build target: bazel-out/local-
    opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
    Build time: Thu Mar 16 13:37:54 2017 (1489671474)
    Build timestamp: 1489671474
    Build timestamp as int: 1489671474
- **CUDA/cuDNN version**:
    CPU Only

### Describe the problem
Because the buffers holding the model weight values are 77MB in size, the memory needed to load these into the app can crash in Android, even before the model is run. So I want to run `convert_graphdef_memmapped_format` to map them into memory.So I build it.When I run it ,it get me a error`tensorflow/contrib/util/convert_graphdef_memmapped_format.cc:61] Unknown argument –-in_graph=/Users/liba/Desktop/OptimizeCTNModel.pb
`

### Source code / logs
log:
``` 
ZHANGSH7-MP:tensorflow liba$ bazel-bin/tensorflow/contrib/util/convert_graphdef_memmapped_format –-in_graph=/Users/liba/Desktop/OptimizeCTNModel.pb –-out_graph=/Users/liba/Desktop/MemmappedCTNModel.pb
2017-06-09 14:59:12.633589: E tensorflow/contrib/util/convert_graphdef_memmapped_format.cc:61] Unknown argument –-in_graph=/Users/liba/Desktop/OptimizeCTNModel.pb
usage: bazel-bin/tensorflow/contrib/util/convert_graphdef_memmapped_format
Flags:
	--in_graph=""""                    	string	input graph
	--out_graph=""""                   	string	output graph
	--min_conversion_tensor_size=10000	int32	constants with tensors that have less than this number elements won't be converted into ImmutableConst (be memmapped)

```
"
10582,executor.cc:334 Executor failed to create kernel. Invalid argument: NodeDef mentions attr 'Tshape' not in Op,"I got this error message when I used this setting inside TensorFlowImageListener.java

```
  private static final int NUM_CLASSES = 1001;
  private static final int INPUT_SIZE = 299;
  private static final int IMAGE_MEAN = 128;
  private static final float IMAGE_STD = 128;
  private static final String INPUT_NAME = ""Mul:0"";
  private static final String OUTPUT_NAME = ""final_result:0"";
```

Error message

```
06-09 09:09:49.880 27618-27659/my.xxxxx E/native: executor.cc:334 Executor failed to create kernel. Invalid argument: NodeDef mentions attr 'Tshape' not in Op<name=Reshape; signature=tensor:T, shape:int32 -> output:T; attr=T:type>; NodeDef: pool_3/_reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/cpu:0""](pool_3, pool_3/_reshape/shape)
                                                                                  	 [[Node: pool_3/_reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/cpu:0""](pool_3, pool_3/_reshape/shape)]]
                                                                                  
                                                                                  [ 06-09 09:09:49.890 27618:27685 E/         ]
                                                                                  [android_ws] Format: 5, Width: 1080, Height: 1620
```

My machine setting

```
== cat /etc/issue ===============================================
Darwin Mohammads-MacBook-Air.local 15.6.0 Darwin Kernel Version 15.6.0: Thu Jun 23 18:25:34 PDT 2016; root:xnu-3248.60.10~1/RELEASE_X86_64 x86_64
Mac OS X 10.11.6

== are we in docker =============================================
No

== compiler =====================================================
Apple LLVM version 7.3.0 (clang-703.0.31)
Target: x86_64-apple-darwin15.6.0
Thread model: posix
InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin

== uname -a =====================================================
Darwin Mohammads-MacBook-Air.local 15.6.0 Darwin Kernel Version 15.6.0: Thu Jun 23 18:25:34 PDT 2016; root:xnu-3248.60.10~1/RELEASE_X86_64 x86_64

== check pips ===================================================
numpy (1.11.1)
protobuf (3.3.0)
tensorflow (1.1.0)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.1.0
tf.GIT_VERSION = v1.1.0-rc0-61-g1ec6ed5
tf.COMPILER_VERSION = v1.1.0-rc0-61-g1ec6ed5
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================

== cuda libs  ===================================================
```

Please advice. Thank you."
10581,Run quantize_graph error,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
    No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
    OS X EI Caption 10.11.6
- **TensorFlow installed from (source or binary)**:
    binary (pip install)
- **TensorFlow version (use command below)**:
    TensorFlow 1.2.0-rc1 CPU Only
- **Bazel version (if compiling from source)**:
    Build label: 0.4.5-homebrew
    Build target: bazel-out/local-
    opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
    Build time: Thu Mar 16 13:37:54 2017 (1489671474)
    Build timestamp: 1489671474
    Build timestamp as int: 1489671474
- **CUDA/cuDNN version**:
    CPU Only

### Describe the problem
Because of the buffers holding the model weight values are 77MB in size, the memory needed to load these into the app can put a lot of pressure on RAM in Android even before the model is run.  
So, I need to further compress the model and round the weights,Even at the expense of accuracy.  
So I build `/tensorflow/tools/quantization/quantize_graph`.There are something wrongs when I run `quantize_graph` .
### Source code / logs
Source code:
``` 
bazel-bin/tensorflow/tools/quantization/quantize_graph \
–input=/Users/liba/Desktop/OptimizeCTNModel.pb \
–output=/Users/liba/Desktop/RoundedCTNModel.pb \ 
–output_node_names=output/outputs \
–mode=weights_rounded
```

log:
``` 
Traceback (most recent call last):
  File ""/Users/liba/Desktop/tensorflow/bazel-bin/tensorflow/tools/quantization/quantize_graph.runfiles/org_tensorflow/tensorflow/tools/quantization/quantize_graph.py"", line 1301, in <module>
    app.run()
  File ""/Users/liba/Desktop/tensorflow/bazel-bin/tensorflow/tools/quantization/quantize_graph.runfiles/org_tensorflow/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""/Users/liba/Desktop/tensorflow/bazel-bin/tensorflow/tools/quantization/quantize_graph.runfiles/org_tensorflow/tensorflow/tools/quantization/quantize_graph.py"", line 1267, in main
    data = f.read()
  File ""/Users/liba/Desktop/tensorflow/bazel-bin/tensorflow/tools/quantization/quantize_graph.runfiles/org_tensorflow/tensorflow/python/lib/io/file_io.py"", line 125, in read
    pywrap_tensorflow.ReadFromStream(self._read_buf, length, status))
  File ""/Users/liba/anaconda/lib/python2.7/contextlib.py"", line 24, in __exit__
    self.gen.next()
  File ""/Users/liba/Desktop/tensorflow/bazel-bin/tensorflow/tools/quantization/quantize_graph.runfiles/org_tensorflow/tensorflow/python/framework/errors_impl.py"", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.FailedPreconditionError: .

```

"
10580,contrib.keras TypeError with HDF5Matrix and validation_split,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: v1.2.0-rc2
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: v8.0/v5.1
- **GPU model and memory**: NVIDIA M4000, 8GB
- **Exact command to reproduce**: https://gist.github.com/droidicus/4a55c83e522d90b103b81bf5fb63e610

### Describe the problem
When using tf.contrib.keras.HDF5Matrix as an input to model.fit, a TypeError is thrown if validation_split is used. If no validation_split is used then the model.fit command proceeds as expected.

### Source code / logs
A gist of a minimal example is available here: https://gist.github.com/droidicus/4a55c83e522d90b103b81bf5fb63e610

The trace of the error is as follows:
```
TypeError                                 Traceback (most recent call last)
<ipython-input-2-bdaf6d0caaa7> in <module>()
     13 # This call to fit uses a validation_split, and causes:
     14 # TypeError: unsupported operand type(s) for +: 'NoneType' and 'int'
---> 15 model.fit(X_train, y_train, validation_split=0.1, shuffle='batch')
 
C:\Program Files\Anaconda3\envs\tensorflow_rc\lib\site-packages\tensorflow\contrib\keras\python\keras\models.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)
    842         class_weight=class_weight,
    843         sample_weight=sample_weight,
--> 844         initial_epoch=initial_epoch)
    845
    846   def evaluate(self, x, y, batch_size=32, verbose=1, sample_weight=None):
 
C:\Program Files\Anaconda3\envs\tensorflow_rc\lib\site-packages\tensorflow\contrib\keras\python\keras\engine\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)
   1436       do_validation = True
   1437       split_at = int(len(x[0]) * (1. - validation_split))
-> 1438       x, val_x = (_slice_arrays(x, 0, split_at), _slice_arrays(x, split_at))
   1439       y, val_y = (_slice_arrays(y, 0, split_at), _slice_arrays(y, split_at))
   1440       sample_weights, val_sample_weights = (_slice_arrays(
 
C:\Program Files\Anaconda3\envs\tensorflow_rc\lib\site-packages\tensorflow\contrib\keras\python\keras\engine\training.py in _slice_arrays(arrays, start, stop)
    395       return [x[start] for x in arrays]
    396     else:
--> 397       return [x[start:stop] for x in arrays]
    398   else:
    399     if hasattr(start, '__len__'):
 
C:\Program Files\Anaconda3\envs\tensorflow_rc\lib\site-packages\tensorflow\contrib\keras\python\keras\engine\training.py in <listcomp>(.0)
    395       return [x[start] for x in arrays]
    396     else:
--> 397       return [x[start:stop] for x in arrays]
    398   else:
    399     if hasattr(start, '__len__'):
 
C:\Program Files\Anaconda3\envs\tensorflow_rc\lib\site-packages\tensorflow\contrib\keras\python\keras\utils\io_utils.py in __getitem__(self, key)
     81   def __getitem__(self, key):
     82     if isinstance(key, slice):
---> 83       if key.stop + self.start <= self.end:
     84         idx = slice(key.start + self.start, key.stop + self.start)
     85       else:
 
TypeError: unsupported operand type(s) for +: 'NoneType' and 'int'
```"
10576,OOM error after some number of steps ( Inputsize remains constant),"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Custom Code
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux version 3.10.0-229.11.1.el7.x86_64 (builder@kbuilder.dev.centos.org) (gcc version 4.8.3 20140911 (Red Hat 4.8.3-9) (GCC) )
- **TensorFlow installed from (source or binary)**:
Installed from sources

- **TensorFlow version (use command below)**:
'v1.1.0-rc2-1003-g3792dd9' 1.1.0-rc2
- **Bazel version (if compiling from source)**:
0.4.5
- **CUDA/cuDNN version**:
  CUDA 8.0
: CuDNN 5.1
- **GPU model and memory**:
: NVidia GTX 1080 (Pascal)

### Describe the problem
While running training on a six layer CNN on 2 GPUs, the training starts fine, but after about 450 iterations, the OOM error comes up. During the whole time, the input size remains the same `[2, 221, 221, 3]` . I am unable to find any anomaly in the tensorboard or in my data.  Complete output and error log below

### Source code / logs
attached with the post

[stderr.txt](https://github.com/tensorflow/tensorflow/files/1062484/stderr.txt)
[stdout.txt](https://github.com/tensorflow/tensorflow/files/1062485/stdout.txt)

"
10559,MODEL_NAME_FLAG appears unused,"In the bash script [`tensorflow/tools/dist_test/local_test.sh`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dist_test/local_test.sh) the variable `MODEL_NAME_FLAG` declared in [line 94](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dist_test/local_test.sh#L94) appears to be unused.

Variables not used for anything are often associated with bugs.
Could someone take a look at this?"
10558,LOCAL_K8S_CACHE appears unused,"In the bash script [`tensorflow/tools/dist_test/local_test.sh`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dist_test/local_test.sh) the variable `LOCAL_K8S_CACHE` declared in [line 66](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dist_test/local_test.sh#L66) appears to be unused.

Variables not used for anything are often associated with bugs.
Could someone take a look at this?"
10548,BAZEL_BUILD_ONLY_CMD appears unused,"In the bash script [`tensorflow/tools/ci_build/ci_parameterized_build.sh`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/ci_parameterized_build.sh) the variable `BAZEL_BUILD_ONLY_CMD` declared in [line 129](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/ci_parameterized_build.sh#L129) appears to be unused.

Variables not used for anything are often associated with bugs.
Could someone take a look at this?"
10545,incorrect documentation for deep_cnn tutorial,"### System information
not relevant to issue

### Describe the problem
The addresses provided for seeing the code in the ""Code Organization"" chapter of this tutorial https://www.tensorflow.org/tutorials/deep_cnn are no longer valid. 

I think the right place could be https://github.com/tensorflow/models/tree/master/tutorials/image/cifar10

### Source code / logs
Address of the tutorial: https://www.tensorflow.org/tutorials/deep_cnn
One the addresses provided for the code: https://github.com/tensorflow/tensorflow/blob/r1.1/tensorflow_models/tutorials/image/cifar10/
"
10537,"tf.layers: Add weights, biases and activations to the respective collections","For generating weight, bias and activation summaries one needs to have access to these tensors. Similar to how regularization losses are added to the GraphKeys.REGULARIZATION_LOSSES collection, it would make sense to add weights, biases and activations to the collections GraphKeys.WEIGHTS, GraphKeys.BIASES and GraphKeys.ACTIVATIONS. Right now, layers only add the weights and bias tensors to GraphKeys.TRAINABLE_VARIABLES. 

The summarization of the these collections is already supported [here](https://github.com/tensorflow/tensorflow/blob/r1.1/tensorflow/contrib/layers/python/layers/summaries.py)."
10535,tf.nn.conv3d_transpose really slow on i7 CPU with 100+G free memory,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: virtualenv pip
- **TensorFlow version (use command below)**: 1.1.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: 8.0
- **GPU model and memory**: on CPU
- **Exact command to reproduce**:

### Describe the problem
It takes about 10 mins to do the tf.nn.conv3d_transpose computation.
The input size is [1, 97, 128, 256, 32], kernel size is 3*3*3, strides is [1, 2, 2, 2, 1], and the output size is [1, 193, 256, 512, 1].

At first my model runs with normal speed. Before this layer, there is several tf.nn.conv3d and tf.nn.conv3d_transpose computation.
After this step's computation, it seems the computation become really slow down.

But my model runs smoothly on 12G GPU, if using 4 GPUs, 1.8 examples/sec.

I notice a similar issue #3128. That issue also reports some problem on CPU, but not on GPU. Is that issue resolved?

### Source code / logs
Since I am training a large model on a large dataset. I will only include the model's code. If is needed, I will include more codes. 

The computationally cost layer is the last layer in the variable_scope learning_regularization, right before the scope soft_argmin in `def _build_model`.

For more details, I am reimplementing https://arxiv.org/pdf/1703.04309.pdf.

```python
from collections import namedtuple

import numpy as np
import tensorflow as tf
import six

from tensorflow.python.training import moving_averages

# If a model is trained using multiple GPUs, prefix all Op names with tower_name
# to differentiate the operations. Note that this prefix is removed from the
# names of the summaries when visualizing a model.
TOWER_NAME = 'tower'

# Batch normalization. Constant governing the exponential moving average of
# the 'global' mean and variance for all activations.
BATCHNORM_MOVING_AVERAGE_DECAY = 0.9997

# The decay to use for the moving average.
MOVING_AVERAGE_DECAY = 0.9999


HParams = namedtuple('HParams',
                     ['batch_size', 'lrn_rate',
                     'weight_decay_rate',
                     'relu_leakiness', 'optimizer', 'max_disparity'])


class GCNet(object):
  """"""GCNet model.""""""

  def __init__(self, hps, left_images, right_images, gt_disparity, mask, mode): 
    """"""ResNet constructor.

    Args:
      hps: Hyperparameters.
      images: Batches of images. [batch_size, image_size, image_size, 3]
      labels: Batches of labels. [batch_size, num_classes]
      mode: One of 'train', 'eval' and 'predict'.
    """"""
    self.hps = hps
    self._left_images = left_images
    self._right_images = right_images
    self.gt_disparity = gt_disparity
    self.mask = mask
    self.mode = mode
    self.debug_op_list = []  

    self._extra_train_ops = []
    
  def build_graph_to_loss(self):
    self._build_model()
    self._build_loss_op()

  def _stride_arr(self, stride):
    """"""Map a stride scalar to the stride array for tf.nn.conv2d.""""""
    return [1, stride, stride, 1]
    
  def _stride_3d_arr(self, stride):
    """"""Map a stride scalar to the stride array for tf.nn.conv2d.""""""
    return [1, stride, stride, stride, 1]

  def _build_model(self):
    """"""Build the core model within the graph.""""""

    layer_idx = 1
    with tf.variable_scope('unary_features', reuse=False):
      with tf.variable_scope('layer_'+str(layer_idx)):
        layer_idx += 1
        left_x = self._left_images
        left_x = self._conv('conv', left_x, 5, 3, 32, self._stride_arr(2))
        left_x = self._relu(left_x, self.hps.relu_leakiness)
        left_x = self._batch_norm('bn', left_x)
      tf.add_to_collection('shapes', tf.shape(left_x))
        
      for i in six.moves.range(8):
        left_x, layer_idx = self._unary_feat_residual(left_x, 3, 32, 32, self._stride_arr(1), layer_idx)
        tf.add_to_collection('shapes', tf.shape(left_x))
    
      with tf.variable_scope('layer_'+str(layer_idx)):
        layer_idx += 1
        left_x = self._conv('conv', left_x, 3, 32, 32, self._stride_arr(1))
      tf.add_to_collection('shapes', tf.shape(left_x))
    
    layer_idx = 1    
    with tf.variable_scope('unary_features', reuse=True):
      with tf.variable_scope('layer_'+str(layer_idx)):
        layer_idx += 1
        right_x = self._left_images
        right_x = self._conv('conv', right_x, 5, 3, 32, self._stride_arr(2))
        right_x = self._relu(right_x, self.hps.relu_leakiness)
        right_x = self._batch_norm('bn', right_x)
        
      for i in six.moves.range(8):
        right_x, layer_idx = self._unary_feat_residual(right_x, 3, 32, 32, self._stride_arr(1), layer_idx)

      with tf.variable_scope('layer_'+str(layer_idx)):
        layer_idx += 1
        right_x = self._conv('conv', right_x, 3, 32, 32, self._stride_arr(1))
      
    with tf.variable_scope('cost_volumn'):
      left_cost_volume = tf.stack([tf.identity(left_x)] * (self.hps.max_disparity/2+1), axis=1, name='left_stack')
      right_cost_volume = []
      cur_width = tf.shape(right_x)[2]

      for depth in six.moves.range(self.hps.max_disparity/2+1):
        right_cost_volume.append(tf.pad(tf.slice(right_x, [0, 0, 0, 0], [-1, -1, cur_width - depth, -1], name='right_slice_'+str(depth)),
                                        [[0, 0], [0, 0], [depth, 0], [0, 0]],
                                        name='right_pad_'+str(depth)
                                        ))
      right_cost_volume = tf.stack(right_cost_volume, axis=1, name='right_stack')
      x = tf.concat([left_cost_volume, right_cost_volume], 4)
      tf.add_to_collection('shapes', tf.shape(x))
      
          
    with tf.variable_scope('learning_regularization'):
      stored_features = []

      in_filters = [64, 64, 64, 64]
      out_filters = [32, 64, 64, 64]
      in_filters_stride_2 = [64, 64, 64, 64]
      out_filters_stride_2 = [64, 64, 64, 128]
      for i in six.moves.range(4):
        tmp_x, layer_idx = self._regularization_subsample(x, 3, in_filters[i], out_filters[i], self._stride_3d_arr(1), layer_idx)
        tf.add_to_collection('shapes', tf.shape(tmp_x))
        stored_features.append(tmp_x)
        
        with tf.variable_scope('layer_'+str(layer_idx)):
          layer_idx += 1
          x = self._conv3d('conv3d', x, 3, in_filters_stride_2[i], out_filters_stride_2[i], self._stride_3d_arr(2))
          x = self._relu(x, self.hps.relu_leakiness)
          x = self._batch_norm('bn', x)
          tf.add_to_collection('shapes', tf.shape(x))

      
      assert stored_features[0] is not stored_features[1]

      for i in six.moves.range(2):
        with tf.variable_scope('layer_'+str(layer_idx)):
          layer_idx += 1
          x = self._conv3d('conv3d', x, 3, 128, 128, self._stride_3d_arr(1))
          x = self._relu(x, self.hps.relu_leakiness)
          x = self._batch_norm('bn', x)
          tf.add_to_collection('shapes', tf.shape(x))

      transposed_in_filters = [128, 64, 64, 64]
      transposed_out_filters = [64, 64, 64, 32]
      
      for i in six.moves.range(4):
        x, layer_idx = self._regularization_upsample(x, stored_features[-i-1], 3, transposed_in_filters[i], transposed_out_filters[i], self._stride_3d_arr(2), layer_idx)
        tf.add_to_collection('shapes', tf.shape(x))
      
      with tf.variable_scope('layer_'+str(layer_idx)):
        layer_idx += 1
        input_shape = tf.shape(self.gt_disparity)
        x = self._conv3d_trans('conv_trans', x, 3, 32, 1, self._stride_3d_arr(2), [input_shape[0], self.hps.max_disparity+1, input_shape[1], input_shape[2], 1])
        tf.add_to_collection('shapes', tf.shape(x))
        self.debug_op_list.append(tf.shape(x))

    
    with tf.variable_scope('soft_argmin'):
        x = tf.squeeze(x, squeeze_dims=[4], name='squeeze')
        tf.add_to_collection('shapes', tf.shape(x))
        x = tf.transpose(x, perm=[0, 2, 3, 1], name='transpose')
        tf.add_to_collection('shapes', tf.shape(x))
        x = tf.nn.softmax(x, dim=-1, name='softmax')
        tf.add_to_collection('shapes', tf.shape(x))

        multiplier = tf.range(0, self.hps.max_disparity+1, dtype=tf.float32, name='depth_range')
        x = tf.multiply(x, multiplier, name='softmax_mul_depth')
        tf.add_to_collection('shapes', tf.shape(x))
        self.predicted_disparity = tf.reduce_sum(x, axis=3, name='reduce_sum')       
        tf.add_to_collection('shapes', tf.shape(self.predicted_disparity))
    self.shapes = tf.get_collection('shapes')
    self.debug_op_list.append(self.shapes)

  def _build_loss_op(self):
    with tf.variable_scope('loss'):
      self.abs_loss = tf.reduce_mean(tf.abs((self.gt_disparity - self.predicted_disparity) * self.mask), name='abs_loss')
      self.total_loss = self.abs_loss + self._decay()

      
  def _add_loss_summaries(self):
    """"""Add summaries for losses in CIFAR-10 model.

    Generates moving average for all losses and associated summaries for
    visualizing the performance of the network.

    Args:
      total_loss: Total loss from loss().
    Returns:
      loss_averages_op: op for generating moving averages of losses.
    """"""
    # Compute the moving average of all individual losses and the total loss.
    loss_averages = tf.train.ExponentialMovingAverage(0.9, name='loss_avg')
    self.loss_averages_op = loss_averages.apply([self.abs_loss, self.total_loss])

    # Attach a scalar summary to all individual losses and the total loss; do the
    # same for the averaged version of the losses.
    for l in [self.abs_loss, self.total_loss]:
      # Name each loss as '(raw)' and name the moving average version of the loss
      # as the original loss name.
      tf.summary.scalar(l.op.name + ' (raw)', l)
      tf.summary.scalar(l.op.name, loss_averages.average(l))
    
  def _build_train_op(self, global_step):
    """"""Build training specific ops for the graph.""""""
    self.lrn_rate = tf.constant(self.hps.lrn_rate, tf.float32)
    tf.summary.scalar('learning_rate', self.lrn_rate)

    loss_averages_op = self._add_loss_summaries()
    
    with tf.control_dependencies([loss_averages_op]):
      if self.hps.optimizer == 'sgd':
        optimizer = tf.train.GradientDescentOptimizer(self.lrn_rate)
      elif self.hps.optimizer == 'mom':
        optimizer = tf.train.MomentumOptimizer(self.lrn_rate, 0.9)
      elif self.hps.optimizer == 'RMSProp':
        optimizer = tf.train.RMSPropOptimizer(self.lrn_rate, decay=0.9, momentum=0.9, epsilon=1)
        
        trainable_variables = tf.trainable_variables()
        grads = optimizer.compute_gradients(self.total_loss, trainable_variables)


    apply_op = optimizer.apply_gradients(
        grads,
        global_step=global_step, 
        name='train_step')
        
    # Track the moving averages of all trainable variables.
    variable_averages = tf.train.ExponentialMovingAverage(
        MOVING_AVERAGE_DECAY, global_step)
    variables_averages_op = variable_averages.apply(tf.trainable_variables())

    with tf.control_dependencies([apply_op, variables_averages_op]):
      self.train_op = tf.no_op(name='train')

  def _regularization_upsample(self, x, feature, filter_size, in_filter, out_filter, stride, layer_idx):
    with tf.variable_scope('layer_'+str(layer_idx)):
      layer_idx += 1
      x = self._conv3d_trans('conv_trans', x, filter_size, in_filter, out_filter, stride, tf.shape(feature))
      x = self._relu(x, self.hps.relu_leakiness)
      x = self._batch_norm('bn', x)
      
    with tf.variable_scope('residual_after_'+str(layer_idx-1)):
      x += feature

    tf.logging.debug('image after unit %s', x.get_shape())
    return x, layer_idx

  def _regularization_subsample(self, x, filter_size, in_filter, out_filter, stride, layer_idx):

    with tf.variable_scope('layer_'+str(layer_idx)):
      layer_idx += 1
      x = self._conv3d('conv3d', x, filter_size, in_filter, out_filter, stride)
      x = self._relu(x, self.hps.relu_leakiness)
      x = self._batch_norm('bn', x)

    with tf.variable_scope('layer_'+str(layer_idx)):
      layer_idx += 1
      x = self._conv3d('conv3d', x, filter_size, out_filter, out_filter, stride)
      x = self._relu(x, self.hps.relu_leakiness)
      x = self._batch_norm('bn', x)
      
    tf.logging.debug('image after unit %s', x.get_shape())
    return x, layer_idx

  def _unary_feat_residual(self, x, filter_size, in_filter, out_filter, stride, layer_idx):
    orig_x = x
    orig_layer_idx = layer_idx - 1
    
    for i in six.moves.range(2):
      with tf.variable_scope('layer_'+str(layer_idx)):
        layer_idx += 1
        x = self._conv('conv', x, 3, in_filter, out_filter, stride)
        x = self._relu(x, self.hps.relu_leakiness)
        x = self._batch_norm('bn', x)
          
    with tf.variable_scope('residual_btw_'+str(layer_idx-1)+'_'+str(orig_layer_idx)):
      x += orig_x

    tf.logging.debug('image after unit %s', x.get_shape())
    return x, layer_idx


  def _decay(self):
    """"""L2 weight decay loss.""""""
    costs = []
    for var in tf.trainable_variables():
      if var.op.name.find(r'DW') > 0:
        costs.append(tf.nn.l2_loss(var))
        # tf.summary.histogram(var.op.name, var)

    return tf.multiply(self.hps.weight_decay_rate, tf.add_n(costs))

  def _conv(self, name, x, filter_size, in_filters, out_filters, strides):
    """"""Convolution.""""""
    with tf.variable_scope(name):
      n = filter_size * filter_size * out_filters
      kernel = self._variable_on_cpu(
          'DW', [filter_size, filter_size, in_filters, out_filters],
          initializer=tf.random_normal_initializer(
              stddev=np.sqrt(2.0/n)))
      return tf.nn.conv2d(x, kernel, strides, padding='SAME')
      
  def _conv3d(self, name, x, filter_size, in_filters, out_filters, strides):
    """"""Convolution.""""""
    with tf.variable_scope(name):
      n = filter_size * filter_size * filter_size * out_filters
      kernel = self._variable_on_cpu(
          'DW', [filter_size, filter_size, filter_size, in_filters, out_filters],
           initializer=tf.random_normal_initializer(
              stddev=np.sqrt(2.0/n)))
      return tf.nn.conv3d(x, kernel, strides, padding='SAME')
      
  def _conv3d_trans(self, name, x, filter_size, in_filters, out_filters, strides, output_shape):
    """"""Convolution.""""""
    with tf.variable_scope(name):
      n = filter_size * filter_size * filter_size * out_filters
      kernel = self._variable_on_cpu(
          'DW', [filter_size, filter_size, filter_size, out_filters, in_filters],
            initializer=tf.random_normal_initializer(
              stddev=np.sqrt(2.0/n)))
      x_shape = tf.shape(x)
      self.debug_op_list.append(tf.shape(kernel))
      return tf.nn.conv3d_transpose(
                x, 
                kernel, 
                output_shape,
                strides, 
                padding='SAME')

  def _relu(self, x, leakiness=0.0):
    """"""Relu, with optional leaky support.""""""
    return tf.where(tf.less(x, 0.0), leakiness * x, x, name='leaky_relu')

  # TODO(xpan): Consider batch_norm in contrib/layers/python/layers/layers.py
  def _batch_norm(self, name, x):
    """"""Batch normalization.""""""
    with tf.variable_scope(name):
      params_shape = [x.get_shape()[-1]]

      beta = self._variable_on_cpu(
          'beta', params_shape,
          initializer=tf.constant_initializer(0.0, tf.float32))
      gamma = self._variable_on_cpu(
          'gamma', params_shape,
          initializer=tf.constant_initializer(1.0, tf.float32))

      if self.mode == 'train':
        mean, variance = tf.nn.moments(x, range(len(x.get_shape())-1), name='moments')

        moving_mean = self._variable_on_cpu(
            'moving_mean', params_shape,
            initializer=tf.constant_initializer(0.0, tf.float32),
            trainable=False)
        moving_variance = self._variable_on_cpu(
            'moving_variance', params_shape,
            initializer=tf.constant_initializer(1.0, tf.float32),
            trainable=False)

        self._extra_train_ops.append(moving_averages.assign_moving_average(
            moving_mean, mean, BATCHNORM_MOVING_AVERAGE_DECAY))
        self._extra_train_ops.append(moving_averages.assign_moving_average(
            moving_variance, variance, BATCHNORM_MOVING_AVERAGE_DECAY))
      else:
        mean = self._variable_on_cpu(
            'moving_mean', params_shape,
            initializer=tf.constant_initializer(0.0, tf.float32),
            trainable=False)
        variance = self._variable_on_cpu(
            'moving_variance', params_shape,
            initializer=tf.constant_initializer(1.0, tf.float32),
            trainable=False)
      y = tf.nn.batch_normalization(
          x, mean, variance, beta, gamma, 0.001)
      y.set_shape(x.get_shape())
      return y

  def _variable_on_cpu(self, name, shape, initializer, dtype=tf.float32, trainable=True):
    """"""Helper to create a Variable stored on CPU memory.

    Args:
      name: name of the variable
      shape: list of ints
      initializer: initializer for Variable

    Returns:
      Variable Tensor
    """"""
    with tf.device('/cpu:0'):
      var = tf.get_variable(name, shape, initializer=initializer, dtype=dtype, trainable=trainable)
    return var
```"
10532,Quantized inception-resnet-v2 doesn't predict the images correctly,"I did quantization on inception-resnet-v2 model using https://www.tensorflow.org/performance/quantization#how_can_you_quantize_your_models. Size of freezed graph(input for quantization) is 224,6 MB and quantized graph is 58,6 MB. I ran some tests for quantized graph and the predicted output is totally wrong. I ran accuracy test for certain dataset wherein, for freezed graph the accuracy is 97.4% whereas for quantized graph it is 0%.

Is there a different way to quantize the model for inception-resnet versions? or, for inception-resnet model, quantization is not support at all?
"
10530,Protobuf serialization slows down RDMA,"According to a test similar to https://github.com/tensorflow/tensorflow/issues/6116, the current RDMA implementation has performance issues.

This tensor copy throughput according to [this test](https://gist.github.com/yaroslavvb/1124bb02a9fd4abce3d86caf2f950cb2) (change `assign_add` to `assign` in L53, and test with tensor size 100MB):
```
Distributed rate: 536.72 MB per second
```
Which is just slightly higher than the gRPC implementation (the gRPC fixed version: https://github.com/tensorflow/tensorflow/pull/7466)

Here is the profiling result:
[device1 worker profiling report](https://github.com/tensorflow/tensorflow/files/1060989/dev1.pdf)
[device2 worker profiling report](https://github.com/tensorflow/tensorflow/files/1060990/dev2.pdf)


There are some obvious issue, for example, the [string resize issue](https://github.com/google/protobuf/blob/master/src/google/protobuf/stubs/stl_util.h#L67), the unnecessary memory copy and the single threaded serialization/deserialization.

"
10529,source build fails: cannot find python bin due to empty environment,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Gentoo Linux
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: master (commit 02dbe153afe2c7f418fcf9044e2e3a8795a21d3a)
- **Bazel version (if compiling from source)**:  0.4.5
- **CUDA/cuDNN version**: No CUDA
- **GPU model and memory**: No CUDA
- **Exact command to reproduce**: `./configure && bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package`

### Environment
```== cat /etc/issue ===============================================
Linux mace 4.8.17-hardened-r2 #2 SMP Thu Jun 1 15:39:15 CEST 2017 x86_64 Intel(R) Xeon(R) CPU E5-2407 v2 @ 2.40GHz GenuineIntel GNU/Linux

== are we in docker =============================================
No

== compiler =====================================================
c++ (Gentoo Hardened 4.9.4 p1.0, pie-0.6.4) 4.9.4
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux mace 4.8.17-hardened-r2 #2 SMP Thu Jun 1 15:39:15 CEST 2017 x86_64 Intel(R) Xeon(R) CPU E5-2407 v2 @ 2.40GHz GenuineIntel GNU/Linux

== check pips ===================================================
numpy (1.13.0)

== check for virtualenv =========================================
True

== tensorflow import ============================================
Traceback (most recent call last):
  File ""/root/src/tensorflow_src/tensorflow/python/pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
ImportError: No module named 'tensorflow.python.pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/root/src/tensorflow_src/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/root/src/tensorflow_src/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/root/src/tensorflow_src/tensorflow/python/pywrap_tensorflow.py"", line 52, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/root/src/tensorflow_src/tensorflow/python/pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
ImportError: No module named 'tensorflow.python.pywrap_tensorflow_internal'


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================

== cuda libs  ===================================================
```

### Describe the problem

I configured the source code (with MKL, no CUDA, nothing else enabled) and the bazel build fails 120s with
```ERROR: /root/src/tensorflow_src/tensorflow/tensorboard/components/vz_sorting/BUILD:8:1: Compiling 4 TypeScript files //tensorflow/tensorboard/components/vz_sorting:vz_sorting failed: execrooter failed: error executing command 
  (cd /root/.cache/bazel/_bazel_root/07ee3a30c05d85d959138fae6c764ebf/execroot/tensorflow_src && \
  exec env - \
  bazel-out/host/bin/tensorflow/tensorboard/scripts/execrooter bazel-out/local-py3-opt/bin/tensorflow/tensorboard/components/vz_sorting/vz_sorting-tsc-execroot.json): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 127.
python: unable to find executable in PATH.
```

While the command runs ok, when I omit running inside a clean environment `env -`. I am running inside a virtualenv. But also without a virtual env I am running into this problem:

```$ which python
/usr/bin/python
$ env - which python 
which: no python in ((null))
```"
10527,tensor_array.h not part of pip include header files,"I'm not sure if it is supposed to be part of it. If so, then this is a bug, because it is missing currently.
"
10523,I update libprotobuf but tendoflow still use the old version,"i update libprotobuf 

>    ldconfig -p
>         libprotobuf.so.13 (libc6,x86-64) => /usr/local/lib/libprotobuf.so.13
>         libprotobuf.so.10 (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libprotobuf.so.10
>         libprotobuf.so (libc6,x86-64) => /usr/local/lib/libprotobuf.so
>         libprotobuf-lite.so.13 (libc6,x86-64) => /usr/local/lib/libprotobuf-lite.so.13
>         libprotobuf-lite.so.10 (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libprotobuf-lite.so.10
>         libprotobuf-lite.so (libc6,x86-64) => /usr/local/lib/libprotobuf-lite.so


and it worked 
     

>   protoc --version
>           libprotoc 3.3.0

but tensorflow still use uses the 3.0.0. version

> 
>   [libprotobuf FATAL google/protobuf/stubs/common.cc:67] This program requires version 3.3.0 of the   Protocol Buffer runtime library, but the installed version is 3.0.0.  Please update your library.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed in ""google/protobuf/descriptor.pb.cc"".)
 terminate called after throwing an instance of 'google::protobuf::FatalException'
  what():  This program requires version 3.3.0 of the Protocol Buffer runtime library, but the installed version is 3.0.0.  Please update your library.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed in ""google/protobuf/descriptor.pb.cc"".)

can someone help me
 "
10521,Windows: conv_grad_ops_3d.cc and conv_ops_3d.cc take a long time to compile,"From http://ci.tensorflow.org/job/tf-master-win-bzl/1073/console, I see:
```
00:54:33 [3,344 / 3,367] Compiling tensorflow/core/kernels/conv_grad_ops_3d.cc; 906s standalone ... (2 actions running)
00:58:07 [3,344 / 3,367] Compiling tensorflow/core/kernels/conv_grad_ops_3d.cc; 1121s standalone ... (2 actions running)
01:01:55 [3,344 / 3,367] Compiling tensorflow/core/kernels/conv_grad_ops_3d.cc; 1348s standalone ... (2 actions running)
01:06:33 [3,344 / 3,367] Compiling tensorflow/core/kernels/conv_grad_ops_3d.cc; 1626s standalone ... (2 actions running)
01:12:26 [3,345 / 3,367] Compiling tensorflow/core/kernels/conv_ops_3d.cc; 1978s standalone
```
As you can see, it takes about half an hour to compile these two files.
This has been a bottleneck of the TF Windows Bazel build time for a while.
I guess it's because we are compiling with `/O2` option, so compiler was spending too much time on optimizing. But is there anything we can do to optimize the build time?
"
10520,tf.layers.conv3d_transpose() gives error,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04.2 LTS (Xenial Xerus)
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
1.2.0-rc2
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
8/5.1.10
- **GPU model and memory**:
GeForce GTX 1080
- **Exact command to reproduce**:
```
import tensorflow as tf
x_3d = tf.placeholder(tf.float32,shape=[None,5,5,5,1])
conv_t = tf.layers.conv3d_transpose(x_3d,20,[3,3,3])
```

### Describe the problem
I am getting a TypeError when I use a placeholder with batch size as None as inputs to the conv3d_transpose. This problem does not happen with the tf.layers.conv2d_transpose()

### Source code / logs
```
import tensorflow as tf
x_2d = tf.placeholder(tf.float32,shape=[None,5,5,1])
conv2d_t = tf.layers.conv2d_transpose(x_2d,20,[3,3])
x_3d = tf.placeholder(tf.float32,shape=[None,5,5,5,1])
conv_t = tf.layers.conv3d_transpose(x_3d,20,[3,3,3])
```

> ---------------------------------------------------------------------------
> TypeError                                 Traceback (most recent call last)
> <ipython-input-3-94e71945bcae> in <module>()
>       4 
>       5 x_3d = tf.placeholder(tf.float32,shape=[None,5,5,5,1])
> ----> 6 conv_t = tf.layers.conv3d_transpose(x_3d,20,[3,3,3])
> 
> /usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/convolutional.pyc in conv3d_transpose(inputs, filters, kernel_size, strides, padding, data_format, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, trainable, name, reuse)
>    1538       _reuse=reuse,
>    1539       _scope=name)
> -> 1540   return layer.apply(inputs)
>    1541 
>    1542 
> 
> /usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/base.pyc in apply(self, inputs, *args, **kwargs)
>     490       Output tensor(s).
>     491     """"""
> --> 492     return self.__call__(inputs, *args, **kwargs)
>     493 
>     494   def _assert_input_compatibility(self, inputs):
> 
> /usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/base.pyc in __call__(self, inputs, *args, **kwargs)
>     439         # Check input assumptions set after layer building, e.g. input shape.
>     440         self._assert_input_compatibility(inputs)
> --> 441         outputs = self.call(inputs, *args, **kwargs)
>     442 
>     443         # Apply activity regularization.
> 
> /usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/convolutional.pyc in call(self, inputs)
>    1456         outputs_4d = array_ops.reshape(outputs, [
>    1457             outputs_shape[0], outputs_shape[1] * outputs_shape[2],
> -> 1458             outputs_shape[3], outputs_shape[4]
>    1459         ])
>    1460       outputs_4d = nn.bias_add(
> 
> /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.pyc in reshape(tensor, shape, name)
>    2449   """"""
>    2450   result = _op_def_lib.apply_op(""Reshape"", tensor=tensor, shape=shape,
> -> 2451                                 name=name)
>    2452   return result
>    2453 
> 
> /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.pyc in apply_op(self, op_type_name, name, **keywords)
>     491           except TypeError as err:
>     492             if dtype is None:
> --> 493               raise err
>     494             else:
>     495               raise TypeError(
> 
> TypeError: Failed to convert object of type <type 'list'> to Tensor. Contents: [None, 49, 7, 20]. Consider casting elements to a supported type.
> 
> "
10519,tf.contrib.data: tf-slim training pipeline gets stuck,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux leto28 3.16.0-4-amd64 1 SMP Debian 3.16.39-1+deb8u2 (2017-03-07) x86_64 GNU/Linux
VERSION_ID=""8""
VERSION=""8 (jessie)""

- **TensorFlow installed from (source or binary)**:
Binary

- **TensorFlow version (use command below)**:
tf.VERSION = 1.2.0-rc2
tf.GIT_VERSION = v1.2.0-rc1-24-gce1d6ec
tf.COMPILER_VERSION = v1.2.0-rc1-24-gce1d6ec

- **Bazel version (if compiling from source)**:
None

- **CUDA/cuDNN version**:
8.0/5.1

- **GPU model and memory**:
TITAN X (Pascal), 12189MiB

- **Exact command to reproduce**:
`python ./mwe.py`

### Describe the problem
I recently ported my dataset handling to the new dataset API from `tf.contrib.data`. Now it seems that the `tf-slim` training pipeline stalls if I request just 1 or 2 CPUs for my job (it used to work just fine with the dataset API provided by `tf-slim`). I does work if I grab 4 CPUs. I tried to come up with a MWE (see below). The interesting thing is that it is not getting stuck if I remove one of the `tf.summary.scalar`s or `.map()` at line 39. I suspect this issue is related to #10369.

### Source code / logs
```python
import os
import tensorflow as tf
import tensorflow.contrib.data as tcd
import tensorflow.contrib.slim as slim

from tensorflow.contrib.data.python.ops.dataset_ops import _get_file_names

DATASET_DIR = '/path_to_the_dataset'
FILE_PATTERN = 'shapes_{}_*.tfrecord'
IMAGE_SHAPE = [48, 48, 3]


def _parse_function(example_proto):
    features = {
        ""image/encoded"": tf.FixedLenFeature(
            (), tf.string, default_value=""""),
        'image/annotation/color': tf.FixedLenFeature(
            (), tf.int64, default_value=0),
        'image/annotation/shape': tf.FixedLenFeature(
            (), tf.int64, default_value=0),
    }
    parsed_features = tf.parse_single_example(example_proto, features)
    image_decoded = tf.image.decode_image(parsed_features[""image/encoded""])
    color = parsed_features['image/annotation/color']
    shape = parsed_features['image/annotation/shape']

    return image_decoded, color, shape


def get_batch(batch_size=32, group_size=3, split_name='train'):
    file_pattern = os.path.join(
        DATASET_DIR, FILE_PATTERN.format(split_name))

    file_names = _get_file_names(file_pattern, randomize_input=True)

    dataset = tcd.TFRecordDataset(file_names)
    dataset = dataset.map(_parse_function)

    dataset = dataset.map(lambda image, color, shape: image)
    dataset = dataset.shuffle(buffer_size=10000)
    dataset = dataset.repeat().batch(group_size * batch_size)

    iterator = dataset.make_one_shot_iterator()
    images = iterator.get_next()

    images = tf.split(images, group_size, axis=0)
    images = [tf.reshape(x, [batch_size] + IMAGE_SHAPE) for x in images]

    return images


if __name__ == ""__main__"":
    with tf.Graph().as_default():
        x_1, x_2, x_3 = get_batch(batch_size=32,
                                  group_size=3)

        val = tf.reduce_sum(tf.add_n([x_1, x_2, x_3]))
        val = tf.Print(val, [tf.constant(0)], ""I'm alive! "")

        global_step = slim.get_or_create_global_step()
        with tf.control_dependencies([val]):
            update_global_step_op = tf.assign_add(global_step, 1)

        train_op = update_global_step_op

        tf.summary.scalar('Summary 1', val)
        tf.summary.scalar('Summary 2', train_op)

        logdir = 'mwe_logdir'
        slim.learning.train(
            train_op=train_op,
            logdir=logdir,
            number_of_steps=1000000)
```
"
10518,some op frequently disappears in the log of tfprof,"Please go to Stack Overflow for help and support:


### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Red Hat 4.8.3-9
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.0
- **Bazel version (if compiling from source)**: 0.4.5
- **CUDA/cuDNN version**: N.A   the code is runned with CPU
- **GPU model and memory**: N.A
- **Exact command to reproduce**: python the_source_code.py

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
I tried to use the scripts below to profile the running time of tf.matmul(). But, with each different runs, some ops frequently disappear from the log of tfprof. I tried to add time stamp in the Compute() method of the underlying op, and it shows that the running time is quite stable for different runs. The same problem also happens with larger networks. I'm using CPU other than GPU in this case.

sometimes the log is like this, MatMul reports 0us, which is definitely not true:

==================Model Analysis Report======================
_TFProfRoot (0B/47.32MB, 0us/104.00ms)
  **MatMul (6.76MB/6.76MB, 0us/0us)**
  random_normal (6.76MB/20.28MB, 1.20ms/52.71ms)
    random_normal/RandomStandardNormal (6.76MB/6.76MB, 50.20ms/50.20ms)
    random_normal/mean (4B/4B, 0us/0us)
    random_normal/mul (6.76MB/6.76MB, 1.30ms/1.30ms)
    random_normal/shape (8B/8B, 2us/2us)
    random_normal/stddev (4B/4B, 0us/0us)
  random_normal_1 (6.76MB/20.28MB, 0us/51.29ms)
    random_normal_1/RandomStandardNormal (6.76MB/6.76MB, 51.29ms/51.29ms)
    random_normal_1/mean (0B/0B, 0us/0us)
    random_normal_1/mul (6.76MB/6.76MB, 0us/0us)
    random_normal_1/shape (0B/0B, 0us/0us)
    random_normal_1/stddev (0B/0B, 0us/0us)



some times like this, which is expected:

==================Model Analysis Report======================
_TFProfRoot (0B/47.32MB, 0us/82.61ms)
  **MatMul (6.76MB/6.76MB, 36.83ms/36.83ms)**
  random_normal (6.76MB/20.28MB, 2.21ms/41.42ms)
    random_normal/RandomStandardNormal (6.76MB/6.76MB, 37.09ms/37.09ms)
    random_normal/mean (4B/4B, 0us/0us)
    random_normal/mul (6.76MB/6.76MB, 2.13ms/2.13ms)
    random_normal/shape (8B/8B, 0us/0us)
    random_normal/stddev (4B/4B, 0us/0us)
  random_normal_1 (6.76MB/20.28MB, 2.17ms/4.36ms)
    random_normal_1/RandomStandardNormal (6.76MB/6.76MB, 0us/0us)
    random_normal_1/mean (0B/0B, 0us/0us)
    random_normal_1/mul (6.76MB/6.76MB, 2.19ms/2.19ms)
    random_normal_1/shape (0B/0B, 0us/0us)
    random_normal_1/stddev (0B/0B, 0us/0us)



### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.


```
import tensorflow as tf
import time

size = 1300

def main():
  x = tf.random_normal(shape = [1, size])
  w = tf.random_normal(shape = [size, 2*size])
  y = tf.matmul(x,w)

  with tf.Session(config=tf.ConfigProto(device_count={'GPU': 0, 'CPU': 1}, \
    inter_op_parallelism_threads = 1, intra_op_parallelism_threads = 1, \
    log_device_placement=True)) as sess:

    run_metadata = tf.RunMetadata()
    opts = tf.contrib.tfprof.model_analyzer.PRINT_ALL_TIMING_MEMORY
    opts['min_micros'] = 0
    opts['min_bytes'] = 0
    predictions = sess.run(y,
                         options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE),
                         run_metadata=run_metadata)
    tf.contrib.tfprof.model_analyzer.print_model_analysis(
                        tf.get_default_graph(),
                        run_meta=run_metadata,
                        tfprof_options=opts)
 
if __name__ == '__main__':
  main()


```"
10517,TensorFlow Convolution Code Optmization,"I am using C++ version of TensorFLow and have built 'TensorFlow for Android' successfully using below command
'bazel build -c opt //tensorflow/examples/android:tensorflow_demo'
 as described in https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android#bazel

I am trying to optimize the convolution code. Below are the issues faced

1. Unable to find the exact location of convolution code. 
    I am able to debug the code till below function in  

   'return choose(
      Cond<internal::traits<Input>::Layout == ColMajor>(),
      kernel.reshape(kernel_dims)
          .contract(input
                        .extract_image_patches(
                            kernelRows, kernelCols, row_stride, col_stride,
                            row_in_stride, col_in_stride, padding_type)
                        .reshape(pre_contract_dims),
                    contract_dims)
          .reshape(post_contract_dims),
      input
          .extract_image_patches(kernelRows, kernelCols, row_stride, col_stride,
                                 row_in_stride, col_in_stride, padding_type)
          .reshape(pre_contract_dims)
          .contract(kernel.reshape(kernel_dims), contract_dims)
          .reshape(post_contract_dims));'

as present in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/eigen_spatial_convolutions.h

I have few questions related to the above function.

1.1 Is the above function really performing convolution ? If so where is the code ?
1.2 Is contraction (contract function ) same as convolution ? If both convolution and contraction are same, why is the contract operation being performed to both input and kernel matrix ?
1.3 Where are the definitions of functions - choose, reshape, contract ,extract image patches etc ?

2. Unable to extract data (matrices ) from input and kernel matrix .This is in reference to the same page
 https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/eigen_spatial_convolutions.h 

2.1 I have found a line of code 'kern(kernel);' at line no 946 in the above page. Can I know the location definition of the above function ?

2.2 I am unable to extract input and kernel matrices from the corresponding 4d tensors(input and kernel) as a float array, as i would like to try optimizing the convolution code using parallel processing.I have looked at https://www.tensorflow.org/api_docs/cc/class/tensorflow/tensor  but I coudn'yt find any method to convert Tensor Matrices from Tensor 4D to an array. 

Please help me in answering the above questions

  


"
10515,Tensorboard 'Site cannot be reached' error,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Installed with Docker as per https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#1
- **TensorFlow version (use command below)**: ('v1.1.0-rc0-61-g1ec6ed5', '1.1.0')
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: not being used
- **GPU model and memory**: GPU not being used
- **Exact command to reproduce**: 

		:/tf_files# tensorboard --logdir training_summaries --debug
		Starting TensorBoard 47 at http://0.0.0.0:6006
		(Press CTRL+C to quit)

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

Hi. I'm following this tutorial for image classification: https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#4 but with my own image dataset. I let the retraining run overnight, and it successfully completed. Now I am trying to visualize the results with Tensorboard. 

I ran tensorboard and this is the only terminal output:

    	:/tf_files# tensorboard --logdir training_summaries --debug
		Starting TensorBoard 47 at http://0.0.0.0:6006
		(Press CTRL+C to quit)

When I visit http://0.0.0.0:6006 the page does not load and it says 'Site cannot be reached.'

My retraining command was: 

    python retrain.py \
	  --bottleneck_dir=bottlenecks \
	  --model_dir=inception \
	  --summaries_dir=training_summaries/long \
	  --output_graph=retrained_graph.pb \
	  --output_labels=retrained_labels.txt \
	  --image_dir=data
	  
Can anyone help? I'm new to TF so I appreciate the advice. 
"
10499,reader_ops_test failing on windows for Bazel CI,"On Bazel's CI system, TensorFlow's reader_ops_test is failing on all Windows builds, and has been since between June 1 and June 5:
http://ci.bazel.io/view/Dashboard/job/TensorFlow/863/

The logs don't show anything useful, unfortunately.:
http://ci.bazel.io/view/Dashboard/job/TensorFlow/862/BAZEL_VERSION=HEAD,PLATFORM_NAME=windows-msvc-x86_64/consoleFull
```
FAIL: //py_test_dir/tensorflow/python/kernel_tests:reader_ops_test (see C:/tmp/_bazel_system/bcthfi-n/execroot/org_tensorflow/bazel-out/msvc_x64-py3-opt/testlogs/py_test_dir/tensorflow/python/kernel_tests/reader_ops_test/test.log)
INFO: From Testing //py_test_dir/tensorflow/python/kernel_tests:reader_ops_test:
==================== Test output for //py_test_dir/tensorflow/python/kernel_tests:reader_ops_test:
..........================================================================================
```

"
10498,TensorFlow logging configuration is non-standard,"Ref https://github.com/tensorflow/tensorflow/issues/8023

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Docker image
- **TensorFlow version (use command below)**: 1.1.0
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: Per Docker image
- **GPU model and memory**: K80
- **Exact command to reproduce**: N/A

### Describe the problem
The logging configuration in `tf_logging` is odd and inconsistent with how things are generally done in Python.

In general, it's typical to attach handlers to the root logger in Python: https://docs.python.org/2/library/logging.html#logging.Logger.propagate

However, because `tf_logging` sets up its own stream handler, and does not disable the propagate flag, anybody who does follow the standard Python convention of attaching handlers to the root logger gets duplicated log output from TensorFlow.

Per https://github.com/tensorflow/tensorflow/issues/8023, while this isn't a bug per se, it's still wrong and undesirable.

The cleanest way forward is probably to just set `propagate=False` on the TF logger."
10494,incorrect documentation in _SliceHelper,"The outputs shown for several of the examples in the `_SliceHelper` docstring are incorrect (based on some previous examples?).

See, for example, this line: https://github.com/tensorflow/tensorflow/blob/359d6f9716c0bb9bd8201ce600da98b0481a8049/tensorflow/python/ops/array_ops.py#L412
"
10493,Typo in text,"Typo at this address: https://www.tensorflow.org/api_docs/java/reference/org/tensorflow/Graph
I thought it primes in our mind that TensorFlow for Java is not yet mature. Fixing it might help new comers!

WARNING: Resources consumed by the Graph object **msut** be explicitly freed by invoking the close() method then the Graph object is no longer needed.

"
10492,Read images with various sizes from TFRecord,"I posted this issue in [StackOverflow](https://stackoverflow.com/questions/44152661/random-crop-a-patch-from-a-various-sized-image-read-in-tfrecord) and I got a response as well. However the replied answer would raise a **ValueError: All shapes must be fully defined** .
I'm just wondering might it be a limitation or even a bug that it's impossible to read images with various sizes from TFRecord? 
"
10491,TF-Keras dont see TF variables,"It is a feature or a bug?

For example, I have 2 models:
typical imports:
```
import numpy as np
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
from tensorflow.contrib.keras import layers as klayers
from tensorflow.contrib.keras import activations as kacts
from tensorflow.contrib.keras import models as kmodels
from tensorflow.contrib.keras import optimizers as kopts
from tensorflow.contrib.keras import losses as kloss
from tensorflow.contrib.keras import backend as kback
```

Keras model
```
# keras model
features = klayers.Input(shape=(28, 28, 1))
x = klayers.Conv2D(64, 3, strides=(2, 2))(features)
x = klayers.MaxPool2D()(x)
x = klayers.Conv2D(32, 3, strides=(2, 2))(x)
x = klayers.Flatten()(x)
prelogits = klayers.Dense(128, activation=kacts.elu)(x)
pred = klayers.Dense(10, activation=kacts.softmax)(prelogits)
```

and TF one:
```
features = klayers.Input(shape=(28, 28, 1))
def convolution_network(
        states, n_filters=None, kernels=None, strides=None,
        activation_fn=tf.nn.elu, use_bn=False, dropout=-1):
    n_filters = n_filters or [64, 32]
    kernels = kernels or [3, 3]
    strides = strides or [2, 2]
    x = states
    for n_filter, kernel, stride in zip(n_filters, kernels, strides):
        x = tf.layers.conv2d(x, n_filter, kernel, stride, activation=None)
        if use_bn:
            x = tf.layers.batch_normalization(x, training=is_training)
        x = tf.layers.max_pooling2d(x, 2, 2)
        x = activation_fn(x)
        if dropout > 0:
            x = tf.layers.dropout(x, rate=dropout, training=is_training)
    x = tf.contrib.layers.flatten(x)
    return x

def simple_model(features):
    features = convolution_network(features)
    prelogits = tf.layers.dense(features, 128, activation=tf.nn.elu)
    logits = tf.layers.dense(prelogits, 10, activation=tf.nn.softmax)
    
    return logits

pred = tf.contrib.keras.layers.Lambda(simple_model)(features)
```

Both of them then made with `model = kmodels.Model(inputs=features, outputs=pred)`

Nevertheless, when I use `model.summary()` , Kesar model give me correct output:
```
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 28, 28, 1)         0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 13, 13, 64)        640       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 2, 2, 32)          18464     
_________________________________________________________________
flatten_1 (Flatten)          (None, 128)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 128)               16512     
_________________________________________________________________
dense_2 (Dense)              (None, 10)                1290      
=================================================================
Total params: 36,906
Trainable params: 36,906
Non-trainable params: 0
_________________________________________________________________
```
**but** TF one, give only:
```
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 28, 28, 1)         0         
_________________________________________________________________
lambda_1 (Lambda)            (None, 10)                0         
=================================================================
Total params: 0
Trainable params: 0
Non-trainable params: 0
_________________________________________________________________
```

Is it correct, that TF-Keras cannot see TF variables and optimize them? So we still have separated Tensorflow an Keras frameworks?
Why cannot I use TF as Keras backend?
TF-versions: from 1.1.0 to 1.2.0rc1"
10489,"when logits is all zero, why in_top_k will return true?","
x = tf.constant([[2.0,9.0],[7.0,5.0],[0.0,0.0]])
y = tf.constant([1,0,1])
 tf.nn.in_top_k(x,y,1).eval()
Out : array([ True,  True,  True], dtype=bool)
why not output array([ True,  True,  False], dtype=bool)
"
10488,Changing the cache_size in Gemmlowp/meta/single_thread_gemm.h cause random error in Requantize nodes,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux ubuntu 16.04

- **TensorFlow installed from (source or binary)**:

source, NDK built Android ARM64 binary

- **TensorFlow version (use command below)**:

commit id: f48673b5054b474fa1e51823edd075088cd16d5f
Author: Luke Iwanski <luke@codeplay.com>

- **Bazel version (if compiling from source)**:
0.4.5

- **CUDA/cuDNN version**:
no

- **GPU model and memory**:
no

- **Exact command to reproduce**:
1. bazel --output_base=../out/armv8_benchmark_model/ build -s -c opt --jobs=1 --crosstool_top=//external:android/crosstool --cpu=arm64-v8a --host_crosstool_top=@bazel_tools//tools/cpp:toolchain  tensorflow/tools/benchmark:benchmark_model 2>&1 |tee log.txt
2.adb push benchmark_model /data/local/tmp/
 
3. run_vgg1 on Nexus5X6P phone:
script:
time ./$1 --graph=$2   --input_layer=""images:0""   --input_layer_shape=""1,224,224,3""   --input_layer_type=""float""   --output_layer=""prob:0"" --num_runs=1

The final command line that I use:
./run_vgg1.sh benchmark_model vgg16.8bit.weightsnodes.model

### My problem
When I change the cache_size from 256*1024 to 128*1024 in the Gemmlowp/meta/single_thread_gemm.h, the benchmark_model randomly failed on the 8 bit quantized both node and weights vgg16 model.

### Source code / logs
My Tensorflow commit-id:
commit f48673b5054b474fa1e51823edd075088cd16d5f

My modify for the Gemmlowp:
in file  gemmlowp/meta/single_thread_gemm.h:
change all the ""int cache_size = 256 * 1024"" to ""int cache_size = 128 * 1024"".

The error log is :
native : benchmark_model.cc:381 Graph: [vgg16.8bit.weightsnodes.model]
native : benchmark_model.cc:382 Input layers: [images:0]
native : benchmark_model.cc:383 Input shapes: [1,224,224,3]
native : benchmark_model.cc:384 Input types: [float]
native : benchmark_model.cc:385 Output layers: [prob:0]
native : benchmark_model.cc:386 Num runs: [1]
native : benchmark_model.cc:387 Inter-run delay (seconds): [-1.0]
native : benchmark_model.cc:388 Num threads: [-1]
native : benchmark_model.cc:389 Benchmark name: []
native : benchmark_model.cc:390 Output prefix: []
native : benchmark_model.cc:391 Show sizes: [0]
native : benchmark_model.cc:392 Warmup runs: [2]
native : benchmark_model.cc:52 Loading TensorFlow.
native : benchmark_model.cc:59 Got config, 0 devices
can't determine number of CPU cores: assuming 4
can't determine number of CPU cores: assuming 4
native : benchmark_model.cc:257 Running benchmark for 2 iterations without detailed stat logging:
native : benchmark_model.cc:233 Error during inference: Invalid argument: requested_output_max must be >= requested_output_min, but got nan and 0
	 [[Node: fc8/BiasAdd/eightbit/requantize = Requantize[Tinput=DT_QINT32, out_type=DT_QUINT8, _device=""/job:localhost/replica:0/task:0/cpu:0""](fc8/BiasAdd/eightbit, fc8/BiasAdd/eightbit:1, fc8/BiasAdd/eightbit:2, fc8/BiasAdd/eightbit/requant_range, fc8/BiasAdd/eightbit/requant_range:1)]]
native : benchmark_model.cc:268 Failed on run 0
native : benchmark_model.cc:451 Timing failed with Invalid argument: requested_output_max must be >= requested_output_min, but got nan and 0
	 [[Node: fc8/BiasAdd/eightbit/requantize = Requantize[Tinput=DT_QINT32, out_type=DT_QUINT8, _device=""/job:localhost/replica:0/task:0/cpu:0""](fc8/BiasAdd/eightbit, fc8/BiasAdd/eightbit:1, fc8/BiasAdd/eightbit:2, fc8/BiasAdd/eightbit/requant_range, fc8/BiasAdd/eightbit/requant_range:1)]]
    0m11.12s real     0m27.55s user     0m01.87s system



"
10487,"Variable ""weights"" does not exist with BasicLSTMcell or LSTMBlockCell ","### System information

- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: via pip with GPU support
- **TensorFlow version (use command below)**: 1.1
- **GPU model and memory**: GPU Titan X

### Describtion of the problem

I am trying to use LSTM cell, but when I make the __call__ to it, I receive an ValueError message saying that the variable weights is does not exist or not created with get_variable().

I looked into the tensorflow source code of the BasicLSTMCell or LSTMBlockCell and we can see that the weights matrix is getted by a call to tf.get_variable()... So it seems to be a bug, right ? 
Does someone can tell me if I made a mistake of if it is a bug ?

NB: Note that i tried several other solution with variable_scope instead of name_scope, with reuse = True, of False , with no success ... 

### Source code / logs : 
**here is the source code of BasicLSTMCell and LSTMBlockCell**
the call to get_variable into LSTMBlockCell __call_ funtion
```
w = vs.get_variable(self._names[""W""], [input_size + self._num_units,
                                             self._num_units * 4])
```
and into the _linear function used by BasicLSTMCell
```
weights = vs.get_variable(
_WEIGHTS_VARIABLE_NAME, [total_arg_size, output_size], dtype=dtype)
```

**here is my source code**
```
lstm_cell = tf.contrib.rnn.LSTMBlockCell(num_units=self._state_size)
for t in range(self._rnn_step):
    with tf.name_scope('lstm'):
    _, (c, h) = lstm_cell(lstm_input, [c, h], scope=tf.get_variable_scope())
```

**here is the error message**
```
  File ""/home/toto/workspace/model.py"", line 441, in _rnn
    _, (c, h) = lstm_cell(lstm_input, [c, h], scope=tf.get_variable_scope())
  File ""/home/toto/PythonEnv/tensorflow/local/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/lstm_ops.py"", line 382, in __call__
    self._num_units * 4])
  File ""/home/toto/PythonEnv/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 1049, in get_variable
    use_resource=use_resource, custom_getter=custom_getter)
  File ""/home/toto/PythonEnv/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 948, in get_variable
    use_resource=use_resource, custom_getter=custom_getter)
  File ""/home/toto/PythonEnv/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 356, in get_variable
    validate_shape=validate_shape, use_resource=use_resource)
  File ""/home/toto/PythonEnv/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 341, in _true_getter
    use_resource=use_resource)
  File ""/home/toto/PythonEnv/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 671, in _get_single_variable
    ""VarScope?"" % name)
ValueError: Variable weights does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?
```"
10486,[BUG] control_dependencies + sess.run(tf.global_variables_initializer()),"### System information
- **OS Platform and Distribution**: Linux Ubuntu 16.04 and mac osx
- **TensorFlow installed from (source or binary)**: pip install tensorflow
- **TensorFlow version (use command below)**: v1.1.0-rc0-61-g1ec6ed5 and 1.1.0

Hi TF team, I've stumbled upon a strange behaviour that I believe is a bug:

If I try to run the code below i end up with : `FailedPreconditionError (see above for traceback): Attempting to use uninitialized value timestep
	 [[Node: AssignAdd = AssignAdd[T=DT_INT32, _class=[""loc:@timestep""], use_locking=false, _device=""/job:localhost/replica:0/task:0/cpu:0""](timestep, AssignAdd/value)]]`

If I remove the `tf.zeros_like(Qs_t)` statement (as in the commented line), the problem disappears.

```python
import tensorflow as tf

with tf.Graph().as_default():
    Qs_t = tf.ones([3, 2], dtype=tf.float32)
    timestep = tf.Variable(0, dtype=tf.int32, trainable=False, name=""timestep"")
    inc_t = tf.assign_add(timestep, 1)
    with tf.control_dependencies([inc_t]):
        Ns_t = tf.Variable(tf.zeros_like(Qs_t), dtype=tf.float32, name=""N"", trainable=False)
        # Ns_t = tf.Variable(0., dtype=tf.float32, name=""N"", trainable=False)

    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
```


"
10485,Unable to install tensorflow-gpu==0.11.0,"I am having issues with installing the v0.11.0 version of tensorflow-gpu. My code works on `tensorflow==0.11.0` but really slow. I had a `tensorflow-gpu==0.11.0` but i had lost it due to an upgrade. The pip repository doesn't have a v0.11 anymore and starts with v0.12 only. I got the v0.11 wheel from the TF_BINARY_URLs for v0.11. I am able to install `tensorflow==0.11.0` using the wheel at `export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.11.0-cp27-none-linux_x86_64.whl`

but I am unable to install the GPU version of `tensorflow-gpu==0.11.0` using the corresponding link at export `TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0-cp27-none-linux_x86_64.whl`

The link looks same to me with just the folder different from `gpu/` and `cpu/`. Upon using the link for GPU, it installs `tensorflow==0.11.0` and not `tensorflow-gpu=0.11.0`. Where can I find a `tensorflow-gpu==0.11.0` wheel?"
10484,Can not execute hexagon_graph_execution on hexagon-sim,"@satok16 I have followed the [build_and_run_inception_hexagon.sh](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/makefile/samples/build_and_run_inception_hexagon.sh) and generated the hexagon_graph_execution executable. Now instead of using a real device I would like to test inception model with ""hexagon-sim"" available at SDK 3.0. So there is no need to use adb push commands as the SDK can simulate HVX device with hexagon-sim. 
I have put the run-time libraries and the inception model plus the image at the same folder. After execution It gives me this error:

```
 ~/Qualcomm/HEXAGON_Tools/7.2.12/Tools/bin/hexagon-sim ./hexagon_graph_execution ""/home/aashouri/Qualcomm/Hexagon_SDK/3.0/test/common/inception""
Error: Unsupported machine type 0x0 in ELF image ""./hexagon_graph_execution"" - exiting.
```

Could you comment on this ? Thanks"
10483,How to reduce the package size?,"Even if I only use arm64 size is 98.2 M, how to reduce the size?Please answer
![snip20170607_1](https://user-images.githubusercontent.com/8908244/26865045-7de7b23a-4b8d-11e7-9503-6f07943645a8.png)
"
10481,how to download tensorflow history version=1.0.0.  please give me some tips,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
10479,Possible bug: LSTMCell with use_peephole=True breaks when using initializer=tf.orthogonal_initializer,"- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, below.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: OSX Sierra
- **TensorFlow installed from (source or binary)**: binary - pip
- **TensorFlow version (use command below)**: 1.2rc0
- **Bazel version (if compiling from source)**: NA
- **CUDA/cuDNN version**: NA
- **GPU model and memory**: NA
- **Exact command to reproduce**:
```

class ToyModel(object):
	def __init__(self):
		x = tf.get_variable(""x"", shape=[5, 3, 7],
							initializer=tf.random_normal_initializer(),
							trainable=False)
		cell = tf.contrib.rnn.LSTMCell(7, use_peepholes=True, initializer=tf.orthogonal_initializer)
		self.rnn_out, self.final_state = tf.nn.dynamic_rnn(cell=cell,
														   inputs=x,
														   parallel_iterations=8,
														   time_major=True,
														   dtype=tf.float32)


graph_context = tf.Graph()
with graph_context.as_default():
	m1 = ToyModel()

	tf_init = tf.global_variables_initializer()
	save_dir = ""/Users/delkind/Desktop/whd/tf_checkpoints/unit_test""

	sv = tf.train.Supervisor(logdir=save_dir)
	with sv.managed_session() as sess:
		y1 = m1.rnn_out.eval(session=sess)

		print(y1)
```
### Describe the problem
I believe this is a bug. When using this code, the following error is raised.
```

Traceback (most recent call last):
  File ""src/tensorflow_unit_tests.py"", line 84, in <module>
    m1 = ToyModel()
  File ""src/tensorflow_unit_tests.py"", line 79, in __init__
    dtype=tf.float32)
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py"", line 566, in dynamic_rnn
    dtype=dtype)
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py"", line 729, in _dynamic_rnn_loop
    swap_memory=swap_memory)
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2766, in while_loop
    result = context.BuildLoop(cond, body, loop_vars, shape_invariants)
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2595, in BuildLoop
    pred, body, original_loop_vars, loop_vars, shape_invariants)
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2545, in _BuildLoop
    body_result = body(*packed_vars_for_body)
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py"", line 712, in _time_step
    skip_conditionals=True)
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py"", line 198, in _rnn_step
    new_output, new_state = call_cell()
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py"", line 700, in <lambda>
    call_cell = lambda: cell(input_t, state)
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py"", line 685, in __call__
    output, new_state = self._cell(inputs, state, scope)
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py"", line 165, in __call__
    return super(_RNNCell, self).__call__(inputs, state)
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/python/layers/base.py"", line 439, in __call__
    outputs = self.call(inputs, *args, **kwargs)
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py"", line 376, in call
    ""w_f_diag"", shape=[self._num_units], dtype=dtype)
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 1065, in get_variable
    use_resource=use_resource, custom_getter=custom_getter)
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 962, in get_variable
    use_resource=use_resource, custom_getter=custom_getter)
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 360, in get_variable
    validate_shape=validate_shape, use_resource=use_resource)
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py"", line 168, in _rnn_get_variable
    variable = getter(*args, **kwargs)
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 352, in _true_getter
    use_resource=use_resource)
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 725, in _get_single_variable
    validate_shape=validate_shape)
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/python/ops/variables.py"", line 200, in __init__
    expected_shape=expected_shape)
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/python/ops/variables.py"", line 278, in _init_from_args
    initial_value(), name=""initial_value"", dtype=dtype)
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 701, in <lambda>
    shape.as_list(), dtype=dtype, partition_info=partition_info)
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/python/ops/init_ops.py"", line 481, in __call__
    raise ValueError(""The tensor to initialize must be ""
ValueError: The tensor to initialize must be at least two-dimensional

```
This is unexpected behavior. If you omit either of ```initializer=tf.orthogonal_initializer``` or ```use_peephole=True```, the graph can be built and evaluated as expected. I'm not aware of a mathematical reason the weights in this model cannot be orthogonal.

"
10478,tfdbg error when stepping through a graph that uses tf.train.shuffle_batch,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 17.04
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: v1.2.0-rc1-24-gce1d6ec 1.2.0-rc2
(I also got the same error with tf 1.1.0)
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: CUDA 8.0, cuDNN 5.1
- **GPU model and memory**: Nvidia GTX 1060
- **Exact command to reproduce**:
The following code will start a tfdbg session. Inside this session, enter these commands to get the error:
tfdbg> invoke_stepper
tfdbg> s
tfdbg> s
tfdbg> s
```
import tensorflow as tf
from tensorflow.python import debug as tf_debug

def read_records(filename_queue, enqueue_many_size=1024):
    reader = tf.TFRecordReader()
    _, queue_batch = reader.read_up_to(filename_queue, enqueue_many_size)
    return queue_batch

def input_batch(filenames, batch_size, num_epochs, min_after_dequeue=128, num_threads=8):
    filename_queue = tf.train.string_input_producer(filenames, num_epochs=num_epochs)
    queue_batch = read_records(filename_queue)

    capacity = min_after_dequeue + (num_threads + 3) * batch_size
    batch_serialized_example = tf.train.shuffle_batch(
        [queue_batch],
        batch_size=batch_size,
        num_threads=num_threads,
        capacity=capacity,
        min_after_dequeue=min_after_dequeue,
        enqueue_many=True)

    return batch_serialized_example

b = input_batch(['test_filename'], 32, 5)
sess = tf_debug.LocalCLIDebugWrapperSession(tf.Session())
sess.run(b)
```

### Describe the problem
tfdbg seemingly cannot step through a graph that uses tf.train.shuffle_batch. I cannot work around it by ""stepping over"" the node using step -t either.

### Source code / logs
Running the code provided above and stepping through the graph produces this stack trace. In a real graph, the error stops me from stepping any further. I worked out from looking at types_pb2.py that the value 20 is DT_RESOURCE. It seems like the error is triggered when tfdbg tries to convert this datatype to a numpy array.

```
--- Node Stepper: run #1: 1 fetch (shuffle_batch:0); 0 feeds ------
| <-- --> | s
Error occurred during handling of command: step :
<class 'KeyError'>: 20                                                                                                                                                                                    UP

Traceback (most recent call last):
  File ""/home/ed/.pyenv/versions/neda/lib/python3.6/site-packages/tensorflow/python/debug/cli/debugger_cli_common.py"", line 664, in dispatch_command
    output = handler(argv, screen_info=screen_info)
  File ""/home/ed/.pyenv/versions/neda/lib/python3.6/site-packages/tensorflow/python/debug/cli/stepper_cli.py"", line 487, in step
    screen_output = self.cont([self._sorted_nodes[self._next]], screen_info)
  File ""/home/ed/.pyenv/versions/neda/lib/python3.6/site-packages/tensorflow/python/debug/cli/stepper_cli.py"", line 397, in cont
    restore_variable_values=parsed.restore_variable_values)
  File ""/home/ed/.pyenv/versions/neda/lib/python3.6/site-packages/tensorflow/python/debug/lib/stepper.py"", line 679, in cont
    options=run_options)
  File ""/home/ed/.pyenv/versions/neda/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 789, in run
    run_metadata_ptr)
  File ""/home/ed/.pyenv/versions/neda/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 952, in _run
    subfeed_dtype = subfeed_t.dtype.as_numpy_dtype
  File ""/home/ed/.pyenv/versions/neda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py"", line 122, in as_numpy_dtype
    return _TF_TO_NP[self._type_enum]
KeyError: 20
```
"
10474,No module named 'tensorflow',"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
