Issue Number,Issue Title,Issue Body
14897,A bug in tensorflow r1.4 when applying  MultiRNNCell,"
### System information
- **TensorFlow installed from source :
- **TensorFlow version: r1.4
- **Python version: 3.5.4
- **Bazel version: 0.5.4
- **GCC/Compiler version 5.4.0
- **CUDA/cuDNN version: 9.0 &5.0
- **GPU model and memory*: GeForce GTX 1080

### Describe the problem
when applying the MultiRNNCell as below, an error occurs. The code went well in tensorflow r1.3
# Source code
input_list is a list of tensor with shape[None, 8]
n_hidden = 32
lstm = tf.nn.rnn_cell.BasicLSTMCell(n_hidden)
stacked_lstm = tf.nn.rnn_cell.MultiRNNCell([lstm]*2)
outputs, states = tf.nn.static_rnn(stacked_lstm, input_list, dtype=tf.float32)
# error
ValueError: Dimensions must be equal, but are 64 and 40 for 'rnn/rnn/multi_rnn_cell/cell_0/cell_0/basic_lstm_cell/MatMul_1' (op: 'MatMul') with input shapes: [?,64], [40,128].

However when only applying one single lstm, i works well.

opinions:
when calculating, the basiclstmcell will be called, where a class named Linear will be initialized, as an example, in my case, the variable self.weight in this class will be initialized as [40,128]([32+8,32*4]). 
*** code from rnn_cell_impl.py***
if self._linear is None:
    self._linear = _Linear([inputs, h], 4 * self._num_units, True)

But, when MultiRNNCell is the case, for example,  a 2 layers lstm. in the second layer, the weight should be [64,128]('h' in last layer (32)+'o' in  last layer(32)). Disappointingly, the weight will only be initialized once and stay with the shape [40,128] due to the sentence ""if self._linear is None:"". So that the reason why such error occurs.

i try to comment out this sentence, but since share variable mechanism is related. it dosen't work, and induces other problem.

ValueError: Trying to share variable rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel, but specified shape (64, 128) and found shape (40, 128).

Any idea how to solve this problem efficiently?



"
14896,[bug report] CMakeList config error,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
When using cmake config to build tensorflow under windows, after enabling gpu, following error appears:

```
CMake Error at tf_core_framework.cmake:215 (list):
  list sub-command REMOVE_ITEM requires two or more arguments.
Call Stack (most recent call first):
  CMakeLists.txt:385 (include)
```
after checking tf_core_framwork.cmake, it is requesting to remove ""${tensorflow_source_dir}/tensorflow/core/platform/default/gpu_tracer.cc"" from core resources. However, this file is missing from the latest tensorflow. Commenting this line help to finish cmake config but I don't think this is a good practice.

Would the development team consider to update the cmake file?

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
14894,"'No gradients provided for any variable, check your graph for ops that do not support gradients'","I write the code like following
```
import tensorflow as tf
input1=tf.Variable([1.0,2.0,3.0,4.0,5.0,6.0],name='input1')
input2=tf.Variable([2.0,3.0,4.0,6.0,8.0,9.0],name='input2')
values_range = tf.constant([0., 10.], dtype = tf.float32)
source_hist = tf.histogram_fixed_width(tf.to_float(input1), values_range, 11)
template_hist = tf.histogram_fixed_width(tf.to_float(input2), values_range, 11)
source_hist=tf.cast(source_hist,tf.float32)
template_hist=tf.cast(template_hist,tf.float32)
loss=2*tf.nn.l2_loss(source_hist-template_hist)
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    writer=tf.summary.FileWriter('./',sess.graph)
    train_step=tf.train.AdamOptimizer(0.001).minimize(loss)
    for i in range(0,10000,1):
        sess.run(train_step)
        print('input1_value',input1.eval())
        print('input2_value',input2.eval())
    writer.close()
```
Tensorflow throws an error and shows 
''ValueError: No gradients provided for any variable, check your graph for ops that do not support gradients, between variables [""<tf.Variable 'input1:0' shape=(6,) dtype=float32_ref>"", ""<tf.Variable 'input2:0' shape=(6,) dtype=float32_ref>""] and loss Tensor(""mul:0"", shape=(), dtype=float32).''

  I know the op  tf.histogram_fixed_width doesn't support backpropagation and is not differentiable. While 
the op tf.floor has the same attribute as  tf.histogram_fixed_width. And the code below can run  without any error which surprises me a lot.

```
import tensorflow as tf
cst=tf.constant([1.2,1.4,2.8,4.6,6.8], dtype=tf.float32)
input=tf.Variable(cst)
new=tf.floor(input)
loss=2*tf.nn.l2_loss(input-new)
train_step=tf.train.AdamOptimizer(0.001).minimize(loss)
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    for i in range(0,10000,1):
        sess.run(train_step)
        print('input_value',input.eval())
        print('new_value',new.eval())
```
I could not figure it out for days, please help"
14891,`panic: runtime error: cgo argument has Go pointer to Go pointer` when using FIFOQueueV2 with non scalar shapes,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Arch Linux
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: NA, using go bindings
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**: NA, using CPU
- **Exact command to reproduce**:

### Describe the problem
When using `op.FIFOQueueV2()` from the go bindings and passing it only scalar shapes in `op.FIFOQueueV2Shapes`, the OP works as expected. However when using multi dimensional shapes, it panics with `panic: runtime error: cgo argument has Go pointer to Go pointer`.

### Source code / logs
For a working example with scalar shapes, replace the `dataShapes` and `data` lines with the commented versions below them.
```
package main

import (
	""fmt""

	tf ""github.com/tensorflow/tensorflow/tensorflow/go""
	""github.com/tensorflow/tensorflow/tensorflow/go/op""
)

func main() {
	s := op.NewScope()
	dataType := []tf.DataType{tf.Int32}

	dataShapes := []tf.Shape{tf.MakeShape(2)} // Panics
	//dataShapes := []tf.Shape{tf.ScalarShape()} // Works

	data := op.Const(s, []int32{3, 4}) // Panics
	//data := op.Const(s, int32(3)) // Works

	queue := op.FIFOQueueV2(s, dataType, op.FIFOQueueV2Shapes(dataShapes))
	enqueue := op.QueueEnqueueV2(s, queue, []tf.Output{data})
	components := op.QueueDequeueV2(s, queue, dataType)
	graph, err := s.Finalize()
	if err != nil {
		panic(err)
	}
	sess, err := tf.NewSession(graph, nil)
	if err != nil {
		panic(err)
	}
	_, err = sess.Run(nil, nil, []*tf.Operation{enqueue})
	if err != nil {
		panic(err)
	}
	results, err := sess.Run(nil, components, nil)
	if err != nil {
		panic(err)
	}
	fmt.Println(results[0].Value())
}
```
```
[isaac@d6-arch tfes]$ go run queue_shape_error.go 
2017-11-26 14:51:13.523481: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
panic: runtime error: cgo argument has Go pointer to Go pointer

goroutine 1 [running]:
github.com/tensorflow/tensorflow/tensorflow/go.setAttr.func21(0xc42000e040, 0x1, 0x1, 0xe4a9c0, 0xc714a0, 0xc42000e040, 0xc42001614c, 0x1)
	/home/isaac/go/src/github.com/tensorflow/tensorflow/tensorflow/go/graph.go:308 +0x100
github.com/tensorflow/tensorflow/tensorflow/go.setAttr(0xe4a9c0, 0xc42000e038, 0x4dc10a, 0x6, 0x4b6e00, 0xc42000c100, 0x0, 0x0)
	/home/isaac/go/src/github.com/tensorflow/tensorflow/tensorflow/go/graph.go:309 +0x9b0
github.com/tensorflow/tensorflow/tensorflow/go.(*Graph).AddOperation(0xc42000e028, 0x4dcaa4, 0xb, 0x4dcaa4, 0xb, 0x0, 0x0, 0x0, 0xc42007c1e0, 0xc42008e1b8, ...)
	/home/isaac/go/src/github.com/tensorflow/tensorflow/tensorflow/go/graph.go:176 +0x4a0
github.com/tensorflow/tensorflow/tensorflow/go/op.(*Scope).AddOperation(0xc42007c180, 0x4dcaa4, 0xb, 0x4dcaa4, 0xb, 0x0, 0x0, 0x0, 0xc42007c1e0, 0x7f05e202e000)
	/home/isaac/go/src/github.com/tensorflow/tensorflow/tensorflow/go/op/scope.go:83 +0xa0
github.com/tensorflow/tensorflow/tensorflow/go/op.FIFOQueueV2(0xc42007c180, 0xc4200160e8, 0x1, 0x1, 0xc420057f40, 0x1, 0x1, 0x0, 0x7f05e20322f8)
	/home/isaac/go/src/github.com/tensorflow/tensorflow/tensorflow/go/op/wrappers.go:5136 +0x1ea
main.main()
	/home/isaac/go/src/github.com/is8ac/tfes/queue_shape_error.go:20 +0x238
exit status 2
```"
14890,Tensorflow installation for python version 3.6,"I am trying to install tensorflow framework on my Windows 10 system and the framework is showing me the similar error of 
![image](https://user-images.githubusercontent.com/31855851/33243068-c272b944-d2ac-11e7-97fc-327b8b18bafa.png)
I have checked my system architecture which is 32 bit. I have tried it installing using the conda - 3.5 python version fix but then again same error arises. Please help me resolve this issue as I am on a fix for last few days."
14888,Is it possible to extend normal operators like add/minus with convolution-like operating?,"This is a feature request, and so far I haven't got any solution from tensorflow source code or websites like stackoverflow. 
It may be confusing to state the problem like my title, so, I am going to give it a demo:
1. The input matrix A has shape of [5,5], and the operation matrix B has shape of [3,3];
2. In convolution manner, tf.nn.conv2d(A, B, padding='VALID') will compute like this:
     create a sliding window C with the same size of the filter matrix B on matrix A, and apply 
     computation DOT(C, B) for all possible position of C on A. All obtained product of B and C 
     form the matrix of convolution result,
3. Here, if we enables the users to replace the DOT(C, B) with other element-wise operators 
   like ADD(C, B) or user defined ones, it will enable tons of more creative layer designs to 
   explore the power of AI. 
   A more flexiable interface will help users to avoid building his own operators by hacking the ops lib.
Sorry for interruption. If this request get passed, I hope I can help implementing it."
14887,feature request - decode_compressed,"It will be great if you could add **tf.decode_compressed** to be used in **situations that tfrecords cannot be used**.

Currently, only **tf.decode_raw()** can be used in such situations, which becomes a big issue with massive amount/size of files.



"
14886,"avg_pool ignores channel stride dimension, but max_pool does not","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary (conda-tensorflow-gpu)
- **TensorFlow version (use command below)**: `b'unknown' 1.3.0`
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: 9/7
- **GPU model and memory**: GeForce GTX 1050 Ti
- **Exact command to reproduce**:
```
import tensorflow as tf

x = tf.get_variable('x', shape=(100, 32, 32, 64),
        initializer=tf.constant_initializer(5), dtype=tf.float32)
ksize = (1, 2, 2, 2)
strides = (1, 2, 2, 2)
max_pool = tf.nn.max_pool(x, ksize, strides, padding='SAME')
avg_pool = tf.nn.avg_pool(x, ksize, strides, padding='SAME')
print(max_pool.shape)
print(avg_pool.shape)
``` 

The unexpected output is
```
(100, 16, 16, 32)
(100, 16, 16, 64)
```

It says [here](https://github.com/Hvass-Labs/TensorFlow-Tutorials/issues/19#issuecomment-274249942) that first and last stride dimension must be 1, but apparently it isn't implemented like this. If this is a feature, there should be consistent behaviour and documentation.

Link to StackOverflow question: https://stackoverflow.com/q/47423172/2397253"
14885,tensorflow-terminate called after throwing an instance of 'std::system_error'   ,"Hi
I am training a resNet50 with tensorflow, using a shared server with these properties:

ubuntu 16.04
3 gtx 1080 gpus
tensorflow 1.3
python 2.7
CUDA 8.0.4
CUDNN 6
but always after two epochs, and during the third epoch, I encounter this error:
`terminate called after throwing an instance of 'std::system_error' what():
Resource temporarily unavailable
Aborted (core dumped)`
with adding some print in my code, I have found where is the problem:
this is convert tfrecord to dataset:
`filenames = [""balanced_t.tfrecords""]
dataset = tf.contrib.data.TFRecordDataset(filenames)
    def parser(record):
    keys_to_features = {
        # ""label"": tf.FixedLenFeature((), tf.string, default_value=""""),
        ""mhot_label_raw"": tf.FixedLenFeature((), tf.string, default_value=""""),
        ""mel_spec_raw"": tf.FixedLenFeature((), tf.string, default_value=""""),
    }
    parsed = tf.parse_single_example(record, keys_to_features)

    mel_spec1d = tf.decode_raw(parsed['mel_spec_raw'], tf.float64)
    # label = tf.cast(parsed[""label""], tf.string)
    mhot_label = tf.decode_raw(parsed['mhot_label_raw'], tf.float64)
    mel_spec = tf.reshape(mel_spec1d, [96, 64])
    # aa=mel_spec
    return {""mel_data"": mel_spec}, mhot_label
    dataset = dataset.map(parser)
    dataset = dataset.batch(batch_size)
    dataset = dataset.repeat(3)
    iterator = dataset.make_one_shot_iterator()`
and this is my input pipline:
`while True:
            try:
               (features, labels) = sess.run(iterator.get_next())
            except tf.errors.OutOfRangeError:
               print(""end of training dataset"")
`
due to my prints output,the error is for this line:
`(features, labels) = sess.run(iterator.get_next())`
but I dont see any problem,can you help me now?

reproduce:replace any tfrecord with mine

"
14884,Object detection works on Linux but not Mac,"------------------------

### System information
- **OS Platform and Distribution **: Linux 16.04 and Mac OS 10.12.6
- **TensorFlow installed from (source or binary)**: Mac – Binary, Linux – Source
- **TensorFlow version (use command below)**: Mac – ('v1.3.0-rc2-20-g0787eee', '1.3.0')
Linux – ('v1.3.0-rc1-4003-g1f582aa', '1.4.0-rc0')
- **Python version**: Mac – 2.7.14, Linux – 2.7.12
- **Bazel version (if compiling from source)**: Linux – 0.7.0
- **GCC/Compiler version (if compiling from source)**: Linux GCC 5.4.0
- **CUDA/cuDNN version**: Linux CUDA 9, cuDNN 7
- **GPU model and memory**: Linux TitanXp

### Describe the problem

I trained a model using the tensor flow object detection api with faster_rcnn_resnet101. I then exported the model using the provided export_inference_graph.py. The model works on Linux, but does not work on Mac. Both platforms are using tensor flow 1.3.0. I've provided the crash log.

### Source code / logs
2017-11-25 20:39:12.847344: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Invalid argument: NodeDef mentions attr 'T' not in Op<name=Where; signature=input:bool -> index:int64>; NodeDef: ClipToWindow/Where = Where[T=DT_BOOL, _device=""/job:localhost/replica:0/task:0/cpu:0""](ClipToWindow/Greater). (Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).
	 [[Node: ClipToWindow/Where = Where[T=DT_BOOL, _device=""/job:localhost/replica:0/task:0/cpu:0""](ClipToWindow/Greater)]]
Traceback (most recent call last):
  File ""/Documents/detect.py"", line 13, in <module>
    model.detect(image)
  File ""/Documents/object_detector.py"", line 71, in detect
    feed_dict={self.image_tensor: image_np_expanded})
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 895, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1124, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1321, in _do_run
    options, run_metadata)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1340, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: NodeDef mentions attr 'T' not in Op<name=Where; signature=input:bool -> index:int64>; NodeDef: ClipToWindow/Where = Where[T=DT_BOOL, _device=""/job:localhost/replica:0/task:0/cpu:0""](ClipToWindow/Greater). (Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).
	 [[Node: ClipToWindow/Where = Where[T=DT_BOOL, _device=""/job:localhost/replica:0/task:0/cpu:0""](ClipToWindow/Greater)]]

Caused by op u'ClipToWindow/Where', defined at:
  File ""/Documents/detect.py"", line 7, in <module>
    limbs = det.object_detector(""/Documents/graph.pbtxt"",""/Documents/graph.pb"", 2)
  File ""/Documents/object_detector.py"", line 49, in __init__
    tf.import_graph_def(od_graph_def, name='')
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/importer.py"", line 313, in import_graph_def
    op_def=op_def)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2630, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1204, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): NodeDef mentions attr 'T' not in Op<name=Where; signature=input:bool -> index:int64>; NodeDef: ClipToWindow/Where = Where[T=DT_BOOL, _device=""/job:localhost/replica:0/task:0/cpu:0""](ClipToWindow/Greater). (Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).
	 [[Node: ClipToWindow/Where = Where[T=DT_BOOL, _device=""/job:localhost/replica:0/task:0/cpu:0""](ClipToWindow/Greater)]]
"
14882,What if we don't install tensorflow under a new environment?,"How come we need to install tensorflow as a [separate](https://user-images.githubusercontent.com/33768560/33234120-05bba17a-d1ef-11e7-9f8a-0390d005aa6a.png) environment?

If we do it this way, many common libraries are not available when tensorflow is activated. 
![image](https://i.stack.imgur.com/zOslW.png)

Most of the common libraries such as matplotlib, panda, etc. are not within tensorflow environment. So we have to install again to use them.
![image](https://user-images.githubusercontent.com/33768560/33233620-c2242610-d1e6-11e7-9a23-44a20991daff.png)

So why not just install under root so we don't have to re-install all those libraries under the new environment?

Thanks.

"
14879,Extend estimators.md to cover Keras,Can you extend the estimators.md tutorial to cover `tf.keras.estimator.model_to_estimator` use case?
14876,How to get the preivous batch after running Iteration.get_next() in tensorflow?,"This problem is in the stackoverflow.
https://stackoverflow.com/questions/47485023/how-to-get-the-preivous-batch-after-running-iteration-get-next-in-tensorflow
I hope someone to help me to solve it.
Thanks."
14875,tf.data cannot be loaded with r1.4,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Debian GNU/Linux 8 (jessie)
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: b'v1.4.0-14-gb5df90f' 1.4.1
- **Python version**: Python 3.6.3 |Anaconda, Inc.| (default, Nov 20 2017, 20:41:42)
- **Bazel version (if compiling from source)**: 0.5.4
- **GCC/Compiler version (if compiling from source)**: gcc (Debian 4.9.2-10) 4.9.2
- **CUDA/cuDNN version**: CUDA 8, cnDNN 5.1
- **GPU model and memory**: TITAN X (Pascal), 12G
- **Exact command to reproduce**: `from tensorflow.data import TFRecordDataset`

### Describe the problem
After checking out r1.4 and compiling TF, tf.data cannot be loaded. Training works fine. But 'data' is listed when executing `print(dir(tf))`.

### Source code / logs
(tensorflow140) [13:08 user@server ~] > `python`
Python 3.6.3 |Anaconda, Inc.| (default, Nov 20 2017, 20:41:42)
[GCC 7.2.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
\>\>\> `import tensorflow as tf`
\>\>\> `tf.__version__`
'1.4.1'
\>\>\> `from tensorflow.data import TFRecordDataset`
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ModuleNotFoundError: No module named 'tensorflow.data'
\>\>\> `print(dir(tf))`
['AUTO_REUSE', 'AggregationMethod', 'Assert', 'AttrValue', 'COMPILER_VERSION', 'ConditionalAccumulator', 'ConditionalAccumulatorBase', 'ConfigProto', 'DType', 'DeviceSpec', 'Dimension', 'Event', 'FIFOQueue', 'FixedLenFeature', 'FixedLenSequenceFeature', 'FixedLengthRecordReader', 'GIT_VERSION', 'GPUOptions', 'GRAPH_DEF_VERSION', 'GRAPH_DEF_VERSION_MIN_CONSUMER', 'GRAPH_DEF_VERSION_MIN_PRODUCER', 'Graph', 'GraphDef', 'GraphKeys', 'GraphOptions', 'HistogramProto', 'IdentityReader', 'IndexedSlices', 'InteractiveSession', 'LMDBReader', 'LogMessage', 'MetaGraphDef', 'NameAttrList', 'NoGradient', 'NodeDef', 'NotDifferentiable', 'OpError', 'Operation', 'OptimizerOptions', 'PaddingFIFOQueue', 'Print', 'PriorityQueue', 'QUANTIZED_DTYPES', 'QueueBase', 'RandomShuffleQueue', 'ReaderBase', 'RegisterGradient', 'RunMetadata', 'RunOptions', 'Session', 'SessionLog', 'SparseConditionalAccumulator', 'SparseFeature', 'SparseTensor', 'SparseTensorValue', 'Summary', 'SummaryMetadata', 'TFRecordReader', 'Tensor', 'TensorArray', 'TensorInfo', 'TensorShape', 'TextLineReader', 'VERSION', 'VarLenFeature', 'Variable', 'VariableScope', 'WholeFileReader', '\_\_builtins\_\_', '\_\_cached\_\_', '\_\_compiler_version\_\_', '\_\_doc\_\_', '\_\_file\_\_', '\_\_git_version\_\_', '\_\_loader\_\_', '\_\_name\_\_', '\_\_package\_\_', '\_\_path\_\_', '\_\_spec\_\_', '\_\_version\_\_', 'abs', 'accumulate_n', 'acos', 'acosh', 'add', 'add_check_numerics_ops', 'add_n', 'add_to_collection', 'all_variables', 'angle', 'app', 'arg_max', 'arg_min', 'argmax', 'argmin', 'as_dtype', 'as_string', 'asin', 'asinh', 'assert_equal', 'assert_greater', 'assert_greater_equal', 'assert_integer', 'assert_less', 'assert_less_equal', 'assert_negative', 'assert_non_negative', 'assert_non_positive', 'assert_none_equal', 'assert_positive', 'assert_proper_iterable', 'assert_rank', 'assert_rank_at_least', 'assert_rank_in', 'assert_same_float_dtype', 'assert_scalar', 'assert_type', 'assert_variables_initialized', 'assign', 'assign_add', 'assign_sub', 'atan', 'atan2', 'atanh', 'batch_to_space', 'batch_to_space_nd', 'betainc', 'bfloat16', 'bincount', 'bitcast', 'bitwise', 'bool', 'boolean_mask', 'broadcast_dynamic_shape', 'broadcast_static_shape', 'case', 'cast', 'ceil', 'check_numerics', 'cholesky', 'cholesky_solve', 'clip_by_average_norm', 'clip_by_global_norm', 'clip_by_norm', 'clip_by_value', 'colocate_with', 'compat', 'complex', 'complex128', 'complex64', 'concat', 'cond', 'confusion_matrix', 'conj', 'constant', 'constant_initializer', 'container', 'contrib', 'control_dependencies', 'convert_to_tensor', 'convert_to_tensor_or_indexed_slices', 'convert_to_tensor_or_sparse_tensor', 'cos', 'cosh', 'count_nonzero', 'count_up_to', 'create_partitioned_variables', 'cross', 'cumprod', 'cumsum', '**data**', 'decode_base64', 'decode_csv', 'decode_json_example', 'decode_raw', 'delete_session_tensor', 'depth_to_space', 'dequantize', 'deserialize_many_sparse', 'device', 'diag', 'diag_part', 'digamma', 'distributions', 'div', 'divide', 'double', 'dynamic_partition', 'dynamic_stitch', 'edit_distance', 'einsum', 'encode_base64', 'equal', 'erf', 'erfc', 'errors', 'estimator', 'exp', 'expand_dims', 'expm1', 'extract_image_patches', 'eye', 'fake_quant_with_min_max_args', 'fake_quant_with_min_max_args_gradient', 'fake_quant_with_min_max_vars', 'fake_quant_with_min_max_vars_gradient', 'fake_quant_with_min_max_vars_per_channel', 'fake_quant_with_min_max_vars_per_channel_gradient', 'feature_column', 'fft', 'fft2d', 'fft3d', 'fill', 'fixed_size_partitioner', 'flags', 'float16', 'float32', 'float64', 'floor', 'floor_div', 'floordiv', 'floormod', 'foldl', 'foldr', 'gather', 'gather_nd', 'get_collection', 'get_collection_ref', 'get_default_graph', 'get_default_session', 'get_local_variable', 'get_seed', 'get_session_handle', 'get_session_tensor', 'get_variable', 'get_variable_scope', 'gfile', 'global_norm', 'global_variables', 'global_variables_initializer', 'glorot_normal_initializer', 'glorot_uniform_initializer', 'gradients', 'graph_util', 'greater', 'greater_equal', 'group', 'half', 'hessians', 'histogram_fixed_width', 'identity', 'identity_n', 'ifft', 'ifft2d', 'ifft3d', 'igamma', 'igammac', 'imag', 'image', 'import_graph_def', 'initialize_all_tables', 'initialize_all_variables', 'initialize_local_variables', 'initialize_variables', 'initializers', 'int16', 'int32', 'int64', 'int8', 'invert_permutation', 'is_finite', 'is_inf', 'is_nan', 'is_non_decreasing', 'is_numeric_tensor', 'is_strictly_increasing', 'is_variable_initialized', 'keras', 'layers', 'lbeta', 'less', 'less_equal', 'lgamma', 'lin_space', 'linalg', 'linspace', 'load_file_system_library', 'load_op_library', 'local_variables', 'local_variables_initializer', 'log', 'log1p', 'log_sigmoid', 'logging', 'logical_and', 'logical_not', 'logical_or', 'logical_xor', 'losses', 'make_ndarray', 'make_template', 'make_tensor_proto', 'map_fn', 'matching_files', 'matmul', 'matrix_band_part', 'matrix_determinant', 'matrix_diag', 'matrix_diag_part', 'matrix_inverse', 'matrix_set_diag', 'matrix_solve', 'matrix_solve_ls', 'matrix_transpose', 'matrix_triangular_solve', 'maximum', 'meshgrid', 'metrics', 'min_max_variable_partitioner', 'minimum', 'mod', 'model_variables', 'moving_average_variables', 'multinomial', 'multiply', 'name_scope', 'negative', 'newaxis', 'nn', 'no_op', 'no_regularizer', 'norm', 'not_equal', 'one_hot', 'ones', 'ones_initializer', 'ones_like', 'op_scope', 'orthogonal_initializer', 'pad', 'parallel_stack', 'parse_example', 'parse_single_example', 'parse_single_sequence_example', 'parse_tensor', 'placeholder', 'placeholder_with_default', 'polygamma', 'pow', 'profiler', 'py_func', 'python_io', 'pywrap_tensorflow', 'qint16', 'qint32', 'qint8', 'qr', 'quantize_v2', 'quantized_concat', 'quint16', 'quint8', 'random_crop', 'random_gamma', 'random_normal', 'random_normal_initializer', 'random_poisson', 'random_shuffle', 'random_uniform', 'random_uniform_initializer', 'range', 'rank', 'read_file', 'real', 'realdiv', 'reciprocal', 'reduce_all', 'reduce_any', 'reduce_join', 'reduce_logsumexp', 'reduce_max', 'reduce_mean', 'reduce_min', 'reduce_prod', 'reduce_sum', 'register_tensor_conversion_function', 'report_uninitialized_variables', 'required_space_to_batch_paddings', 'reset_default_graph', 'reshape', 'resource', 'resource_loader', 'reverse', 'reverse_sequence', 'reverse_v2', 'rint', 'round', 'rsqrt', 'saturate_cast', 'saved_model', 'scalar_mul', 'scan', 'scatter_add', 'scatter_div', 'scatter_mul', 'scatter_nd', 'scatter_nd_add', 'scatter_nd_sub', 'scatter_nd_update', 'scatter_sub', 'scatter_update', 'segment_max', 'segment_mean', 'segment_min', 'segment_prod', 'segment_sum', 'self_adjoint_eig', 'self_adjoint_eigvals', 'sequence_mask', 'serialize_many_sparse', 'serialize_sparse', 'serialize_tensor', 'set_random_seed', 'setdiff1d', 'sets', 'shape', 'shape_n', 'sigmoid', 'sign', 'sin', 'sinh', 'size', 'slice', 'space_to_batch', 'space_to_batch_nd', 'space_to_depth', 'sparse_add', 'sparse_concat', 'sparse_fill_empty_rows', 'sparse_mask', 'sparse_matmul', 'sparse_maximum', 'sparse_merge', 'sparse_minimum', 'sparse_placeholder', 'sparse_reduce_max', 'sparse_reduce_max_sparse', 'sparse_reduce_sum', 'sparse_reduce_sum_sparse', 'sparse_reorder', 'sparse_reset_shape', 'sparse_reshape', 'sparse_retain', 'sparse_segment_mean', 'sparse_segment_sqrt_n', 'sparse_segment_sum', 'sparse_slice', 'sparse_softmax', 'sparse_split', 'sparse_tensor_dense_matmul', 'sparse_tensor_to_dense', 'sparse_to_dense', 'sparse_to_indicator', 'sparse_transpose', 'spectral', 'split', 'sqrt', 'square', 'squared_difference', 'squeeze', 'stack', 'stop_gradient', 'strided_slice', 'string', 'string_join', 'string_split', 'string_to_hash_bucket', 'string_to_hash_bucket_fast', 'string_to_hash_bucket_strong', 'string_to_number', 'substr', 'subtract', 'summary', 'svd', 'sysconfig', 'tables_initializer', 'tan', 'tanh', 'tensordot', 'test', 'tile', 'to_bfloat16', 'to_double', 'to_float', 'to_int32', 'to_int64', 'trace', 'train', 'trainable_variables', 'transpose', 'truediv', 'truncated_normal', 'truncated_normal_initializer', 'truncatediv', 'truncatemod', 'tuple', 'uint16', 'uint8', 'uniform_unit_scaling_initializer', 'unique', 'unique_with_counts', 'unsorted_segment_max', 'unsorted_segment_sum', 'unstack', 'user_ops', 'variable_axis_size_partitioner', 'variable_op_scope', 'variable_scope', 'variables_initializer', 'variance_scaling_initializer', 'variant', 'verify_tensor_all_finite', 'where', 'while_loop', 'write_file', 'zeros', 'zeros_initializer', 'zeros_like', 'zeta']"
14873,[Feature Request] Support for Flutter,"I recently moved from native development to Flutter seeing Google backing its development.
Since both TensorFlow and Flutter is by Google will there be a support for Flutter in Future?"
14871,SpaceToDepth for DT_HALF is not supported on GPU,"space_to_depth can be placed on GPU for float32, but there is no a GPU kernel for float16"
14868,"consuming Dataset becomes slower and slower, if make_one_shot_iterator each epoch ","### Problem

I run make_one_shot_iterator() each epoch because  I want re-shuffle the dataset each epoch. I Know that the dataset.shuffle().repeat().batch() pipeline can do almost the same thing, but when data_num can not be divided exactly by batch_size, the pipeline merges two epochs at their boundary to construct a complete batch,  which I HATE.

So, I choose to run dataset.shuffle().batch() and make_one_shot_iterator() before each epoch. But I find that the speed of consuming dataset becomes slower and slower, significantly. I tried different settings to find out that it is make_one_shot_iterator() which makes consuming slow. 

By the way, I build tensorflow 1.4 from source on OS X with support of GPU, some hacky workaround. 

### Code

```
num_data = 1000
num_epoch = 50
batch_size = 32
dataset = tf.data.Dataset.range(num_data)

mode=3 
# model = 1,2,or 3
# 1: re-shuffle, re-batch and re-make-iterator each epoch
# 2: re-batch and re-make-iterator
# 3: only re-make-iterator

with tf.Session() as sess:
    for epoch in xrange(num_epoch):
        t1 = time.time()
        if mode==1: 
            _dataset = dataset.shuffle(num_data).batch(batch_size)
            iterator = _dataset.make_one_shot_iterator()
        elif mode==2:
            _dataset = dataset.batch(batch_size)
            iterator = _dataset.make_one_shot_iterator()
        elif mode==3: 
            iterator = dataset.make_one_shot_iterator()
        t2 = time.time()
        for i in xrange(num_data/batch_size):
            a = sess.run(iterator.get_next())
        t3 =time.time()
        print 'epoch %d make_iterator_time %.4f comsuming_time %.4f'%(epoch,t2-t1,t3-t2)
```

and the outputs:

```
epoch 0 make_iterator_time 0.0181 comsuming_time 0.1366
epoch 1 make_iterator_time 0.0036 comsuming_time 0.1444
epoch 2 make_iterator_time 0.0040 comsuming_time 0.1559
epoch 3 make_iterator_time 0.0036 comsuming_time 0.1695
epoch 4 make_iterator_time 0.0036 comsuming_time 0.1899
epoch 5 make_iterator_time 0.0036 comsuming_time 0.1955
epoch 6 make_iterator_time 0.0036 comsuming_time 0.2082
epoch 7 make_iterator_time 0.0037 comsuming_time 0.2191
epoch 8 make_iterator_time 0.0036 comsuming_time 0.2334
epoch 9 make_iterator_time 0.0040 comsuming_time 0.2461
epoch 10 make_iterator_time 0.0036 comsuming_time 0.2621
epoch 11 make_iterator_time 0.0036 comsuming_time 0.2720
epoch 12 make_iterator_time 0.0036 comsuming_time 0.2886
epoch 13 make_iterator_time 0.0036 comsuming_time 0.3006
epoch 14 make_iterator_time 0.0037 comsuming_time 0.3134
epoch 15 make_iterator_time 0.0039 comsuming_time 0.3260
epoch 16 make_iterator_time 0.0445 comsuming_time 0.3438
epoch 17 make_iterator_time 0.0037 comsuming_time 0.3576
epoch 18 make_iterator_time 0.0037 comsuming_time 0.3678
epoch 19 make_iterator_time 0.0040 comsuming_time 0.3827
epoch 20 make_iterator_time 0.0037 comsuming_time 0.3937
epoch 21 make_iterator_time 0.0038 comsuming_time 0.4172
epoch 22 make_iterator_time 0.0036 comsuming_time 0.4222
...
 ```

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: OS X 10.12.5
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.4
- **Python version**:  2.7
- **Bazel version (if compiling from source)**: 0.7.0
- **GCC/Compiler version (if compiling from source)**: clang-802.0.42
- **CUDA/cuDNN version**: 9.0/7
- **GPU model and memory**: GTX1080 8G
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"""
14866,"If I import cv2, "" tf.global_variables_initializer() "" will be very slow.","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04.3
- **TensorFlow installed from (source or binary)**:
Binary.
- **TensorFlow version (use command below)**:
1.3.0
- **Python version**: 
2.7.12
- **CUDA/cuDNN version**:
CUDA Version 8.0.61
- **GPU model and memory**:
NVIDIA GTX 1080Ti  12G

### Describe the problem
If I import cv2, "" tf.global_variables_initializer() "" will be very slow, about 143s. You can run my test code below, when "" import cv2 "" is commented out, the time is about 5s. The version of opencv is 2.4.13.4.

### Source code / logs
```Python
import tensorflow as tf
import time
import cv2

weight = tf.Variable(tf.truncated_normal([5,5,1,32], stddev=0.1))

ot = time.time()
init_op = tf.global_variables_initializer()
with tf.Session() as sess:
    sess.run(init_op)
nt = time.time()
print('time: {:.3f}'.format(nt-ot))
```"
14861,Cant install tensorflow on my laptop,"pip3 install --upgrade tensorflow-gpu

Collecting tensorflow-gpu

Could not find a version that satisfies the requirement tensorflow-gpu (from versions: )
No matching distribution found for tensorflow-gpu

this is what it shows please help"
14859,Accuracy drop down after freezing,"System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): 1.3.0
Python version: 2.7.12
Bazel version (if compiling from source): 0.5.4
CUDA/cuDNN version: 8.0.61
GPU model and memory: NVIDIA Corporation Device 1b06
Exact command to reproduce:

Evaluate the accuracy of ckeckpoint
```
python eval_image_classifier.py \
    --batch_size=100 \
    --checkpoint_path=.../model.ckpt-100000 \
    --dataset_dir=.../coco_tfrecord \
    --dataset_name=flowers \
    --dataset_split_name=validation \
    --model_name=mobilenet_v1 \
    --eval_dir=/tmp/eval
```

Export slim inference graph
```
python export_inference_graph.py \
--alsologtostderr \
--model_name=mobilenet_v1 \
--dataset_name=flowers \
--is_training=False \
--batch_size=1 \
--image_size=224 \
--output_file=.../mobilenet_v1.pb
```

Freeze checkpoint using slim inference graph
```
bazel-bin/tensorflow/python/tools/freeze_graph \
--input_checkpoint=.../model.ckpt-100000 \
--input_graph=.../mobilenet_v1.pb \
--input_binary=true \
--output_graph=.../frozen_graph.pb \
--output_node_names=MobilenetV1/Predictions/Reshape_1
```

### Describe the problem
I am doing some fine-tune of Mobilenet using the pretrained model.

And I follow the tutorial of slim to freeze and evaluate the performence.

I separate the validation set from train set , evaluate it using checkpoint , and do it again after freezing model , however the evaluation of  the accuracy of frozen model is far away from ckeckpoint's .

Here is some familiar issues , the situations are a little different , but I think it's referable.
#9724 
#12450

@MyHumbleSelf said "" some docs should probably be adjusted "" , means slim tutorial ? Do these problems remain ? 
Where might be wrong ?

Thank you ! "
14858,off-by-one bug in graph_editor get_forward_walk_ops,"This [line](https://github.com/tensorflow/tensorflow/blob/c9de294d0a0980b1636f76757c175afbf4f58ea8/tensorflow/contrib/graph_editor/select.py#L414) converts Tensor to its corresponding op by replacing it with its consuming op

`seed_ops = util.get_consuming_ops(ts)
`

Instead it should replace it with its producing op

`seed_ops = [t.op for t in ts]
`

This would makes `get_forward_walk_ops(tensor` give same result as `get_forward_walk_ops(tensor.op` which was probably the intention of this function

I know `contrib` isn't really supported, but wanted to file this bug in order to reference it in work-arounds in my code"
14857,how can I ues Dataset to shuffle a large  whole dataset?,"I know we can ues dataset.shuffle(buffer=10000) to shuffle dataset.
But I have a large image dataset with 2,325,000 images, if I use the follwing code with 'dataset = dataset.shuffle(buffer_size=2325000) ' ,the cost of time to load images is too long for me.

Is there any way to shuffle the whole dataset in Dataset  API??

```
from tensorflow.contrib import data
def input_pipeline(filenames, batch_size):
    # Define a `tf.contrib.data.Dataset` for iterating over one epoch of the data.
    dataset = data.TextLineDataset(filenames)
    dataset = dataset.map(decode_func)
    dataset = dataset.shuffle(buffer_size=2325000)  # Equivalent to min_after_dequeue=10000.
    dataset = dataset.batch(batch_size)

    # Return an *initializable* iterator over the dataset, which will allow us to
    # re-initialize it at the beginning of each epoch.
    return dataset.make_initializable_iterator() 
```"
14855,tensorboard ImportError: cannot import name 'run_main',"I install the tensorflow on Mac from source.
but when I run the tensorboard,and got a error like this

> Pro-2:Desktop xxh$ tensorboard
Traceback (most recent call last):
  File ""/Users/xxh/anaconda3/bin/tensorboard"", line 7, in <module>
    from tensorboard.main import run_main
ImportError: cannot import name 'run_main'`

How to fix it?"
14852,tensorflow lite build for iOS,"error ：./download_dependencies.sh: line 50: 1: Usage: download_and_extract URL DIR
how to do it？"
14851,"Got NAN when calling embedding_lookup_sparse with weights and ""mean"" combiner","### System information
- **OS Platform and Distribution**: Win7 64bit
- **TensorFlow installed from**: anaconda binary
- **TensorFlow version**: 1.2.1
- **Python version**: 3.6

### Describe the problem
I always got nan when I call embedding_lookup_sparse with weights and ""mean"" combiner.
Code pieces are listed below:

### Source code / logs
from __future__ import absolute_import
from __future__ import print_function
import os
import numpy as np
import tensorflow as tf
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

a = np.arange(192).reshape(24, 8)
print(a)

a = tf.Variable(a, dtype=tf.float32)
ids = tf.SparseTensor(
    indices=[[1, 0], [2, 0], [2, 1], [2, 2], [3, 0], [9, 1]],
    values=[10, 1, 2, 3, 4, 5],
    dense_shape=[1, 1])
weights = tf.SparseTensor(
    indices=[[1, 0], [2, 0], [2, 1], [2, 2], [3, 0], [9, 1]],
    values=[1, 0.2, 0.4, 0.4, 1, 1],
    dense_shape=[1, 1])
b = tf.nn.embedding_lookup_sparse(
    a, ids, weights, partition_strategy='mod', combiner='sum')
c = tf.pad(b, [[0, 16 - tf.shape(b)[0]], [0, 0]], mode='CONSTANT')

sess = tf.Session()
sess.run(tf.global_variables_initializer())
[value] = sess.run([c])
print(value)
"
14850,Tensorflow v1.4.0 rpc crash,"I built tensorflow v1.4.0 from source code, sometimes it crashed inside kernel. This happened on both Linux and Windows platform.

Linux call stack:
```
C  [_pywrap_tensorflow_internal.so+0x1117eef]  cc_destroy_call_elem+0xdf
C  [_pywrap_tensorflow_internal.so+0x1138c77]  grpc_call_stack_destroy+0x57
C  [_pywrap_tensorflow_internal.so+0x114b2fc]  grpc_exec_ctx_flush+0x5c
C  [_pywrap_tensorflow_internal.so+0x115d8ad]  grpc_call_unref+0xed
C  [_pywrap_tensorflow_internal.so+0x10fa9ae]  grpc::ClientContext::~ClientContext()+0x1e
C  [_pywrap_tensorflow_internal.so+0x1027e07]  tensorflow::GrpcRemoteWorker::RPCState<tensorflow::TensorResponse>::~RPCState()+0x197
C  [_pywrap_tensorflow_internal.so+0x103180e]  tensorflow::GrpcRemoteWorker::RPCState<tensorflow::TensorResponse>::OnCompleted(bool)+0x29e
```

Windows call stack:
```
00 00000042`801ef5c0 00007ffa`737e3c67 ucrtbase!abort+0x4e [d:\rs1\minkernel\crts\ucrt\src\appcrt\startup\abort.cpp @ 77]
01 00000042`801ef5f0 00007ffa`737a96d8 _pywrap_tensorflow_internal!tensorflow::Allocator::AllocatedSize+0x227d7
02 00000042`801ef630 00007ffa`737ba61f _pywrap_tensorflow_internal!tensorflow::lookup::SubtleMustCopyUnlessStringOrFloat<__int64>+0x10ee8
03 00000042`801ef660 00007ffa`737cc5ac _pywrap_tensorflow_internal!tensorflow::lookup::SubtleMustCopyUnlessStringOrFloat<__int64>+0x21e2f
04 00000042`801ef6a0 00007ffa`737a4eb7 _pywrap_tensorflow_internal!tensorflow::Allocator::AllocatedSize+0xb11c
05 00000042`801ef6d0 00007ffa`7379111e _pywrap_tensorflow_internal!tensorflow::lookup::SubtleMustCopyUnlessStringOrFloat<__int64>+0xc6c7
06 00000042`801ef740 00007ffa`737964ca _pywrap_tensorflow_internal!std::vector<std::unique_ptr<tensorflow::NodeDef,std::default_delete<tensorflow::NodeDef> >,std::allocator<std::unique_ptr<tensorflow::NodeDef,std::default_delete<tensorflow::NodeDef> > > >::~vector<std::unique_ptr<tensorflow::NodeDef,std::default_delete<tensorflow::NodeDef> >,std::allocator<std::unique_ptr<tensorflow::NodeDef,std::default_delete<tensorflow::NodeDef> > > >+0x1244e
07 00000042`801ef790 00007ffa`73785fb2 _pywrap_tensorflow_internal!std::vector<std::unique_ptr<tensorflow::NodeDef,std::default_delete<tensorflow::NodeDef> >,std::allocator<std::unique_ptr<tensorflow::NodeDef,std::default_delete<tensorflow::NodeDef> > > >::~vector<std::unique_ptr<tensorflow::NodeDef,std::default_delete<tensorflow::NodeDef> >,std::allocator<std::unique_ptr<tensorflow::NodeDef,std::default_delete<tensorflow::NodeDef> > > >+0x177fa
08 00000042`801ef810 00007ffa`72077041 _pywrap_tensorflow_internal!std::vector<std::unique_ptr<tensorflow::NodeDef,std::default_delete<tensorflow::NodeDef> >,std::allocator<std::unique_ptr<tensorflow::NodeDef,std::default_delete<tensorflow::NodeDef> > > >::~vector<std::unique_ptr<tensorflow::NodeDef,std::default_delete<tensorflow::NodeDef> >,std::allocator<std::unique_ptr<tensorflow::NodeDef,std::default_delete<tensorflow::NodeDef> > > >+0x72e2
09 00000042`801ef860 00007ffa`720778b4 _pywrap_tensorflow_internal!tensorflow::GrpcRemoteWorker::RPCState<google::protobuf::Message>::~RPCState<google::protobuf::Message>+0xf1
0a 00000042`801ef8a0 00007ffa`72078803 _pywrap_tensorflow_internal!tensorflow::WorkerInterface::~WorkerInterface+0x574
0b 00000042`801ef8d0 00007ffa`72082cf0 _pywrap_tensorflow_internal!tensorflow::GrpcRemoteWorker::RPCState<google::protobuf::Message>::OnCompleted+0x283
0c 00000042`801efa10 00007ffa`71b8ae25 _pywrap_tensorflow_internal!tensorflow::WorkerCachePartial::~WorkerCachePartial+0xf0
```
Both indicating that tensorflow rpc framework may have some bug."
14848,HistogramSummary  not support fp16 ？,"There is a issue when I train my model with adm optimizer (tf.train.AdamOptimizer),  It seems HistogramSummary not support DT_HALF.   

2017-11-24 09:19:36.954820: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: Infinity in summary histogram for: local4/BatchNorm/beta_1
         [[Node: local4/BatchNorm/beta_1 = HistogramSummary[T=DT_HALF, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](local4/BatchNorm/beta_1/tag, local4/BatchNorm/beta/read/_171)]]


But if i use the other optimizer such as GradientDescentOptimizer or RMSPropOptimizer， there is no the issue above.  I don't know why,  Is there anyone meet this error
"
14845,No gradient defined for op: Select,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 x64
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.4
- **Python version**: None
- **CUDA/cuDNN version**: None
- **GPU model and memory**: None
- **Exact command to reproduce**: -

### Describe the problem
It seems there is no gradient defined for the Select operation in the C++ API.

I am actually getting this issue while using the C++ API through the C# bindings provided by the TensorFlowSharp project, and for this reason I didn't fill the ""exact command to reproduce"" field above. However, seeing that [```@ops.RegisterGradient(""Select"")``` is placed in math.grad.py](https://github.com/tensorflow/tensorflow/blob/27767d8e9c1325979cf32ff5b81c10df9006fd57/tensorflow/python/ops/math_grad.py#L919), and given that there is no analogous ```REGISTER_GRADIENT_OP(""Select"", SelectGrad)``` instruction in [math_grad.cc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/cc/gradients/math_grad.cc), tells me that the gradient for the ```Select``` op is indeed still missing from the C++ API.

Hope its not a false alarm given that I didn't test libtensorflow.dll directly.


"
14841,Estimators cause Out of range warning on FIFOQueue and fail to run all training steps,"### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 4.13.12-1-ARCH
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 3.6.3
- **CUDA/cuDNN version**: 9.0.176-4/7.0.3-1
- **GPU model and memory**: 1080/1070

### Describe the problem
Trying to use estimators with a trivially small network fails to train for more than one step due to FIFOQueue closing with insufficient elements.

### Source code / logs
In the following example I try to train a single neuron for 1000 steps at a time.  set_size changes the training set's size.  With set_size=1000 I would expect training to complete 1000 steps however only 8 steps are completed and an Out of range warning is printed.  Setting set_size to 10 leads to only a single step being completed, I would expect at least 10 steps to complete, possible all 1000 if the input_fn is called repeatedly to fill a queue(not sure what default behaviour is supposed to be).  Setting set_size=1000000 allows the entire 1k training steps to complete.

code:

```
import numpy as np
import tensorflow as tf
import models

set_size = 1000

params = {""learning_rate"":0.00001}

def model_fn(features, labels, mode, params):
    """"""Build model for Estimator here""""""
    ####Build graph
    input_layer = tf.reshape(features[""x""],[-1,1])
    hidden_layer = tf.layers.dense(input_layer,1,activation=tf.nn.relu)
    output_layer = hidden_layer
    
    ####Prediction mode
    if mode == tf.estimator.ModeKeys.PREDICT:
        predictions = {""y"":output_layer}
        return tf.estimator.EstimatorSpec(mode=mode,predictions=predictions)
    
    loss = tf.losses.mean_squared_error(labels,output_layer)
    
    ####Training mode
    if mode == tf.estimator.ModeKeys.TRAIN:
        optimizer = tf.train.GradientDescentOptimizer(learning_rate=params[""learning_rate""])
        train_op = optimizer.minimize(loss=loss,global_step=tf.train.get_global_step())
        return tf.estimator.EstimatorSpec(
            mode=mode,
            loss=loss,
            train_op=train_op)
    
    ####Eval mode
    elif mode == tf.estimator.ModeKeys.EVAL:
        eval_metric_ops = {""rmse"":tf.metrics.root_mean_squared_error(labels,output_layer)}
        return tf.estimator.EstimatorSpec(
            mode=mode,
            loss=loss,
            eval_metric_ops=eval_metric_ops)
        

input_fn = tf.estimator.inputs.numpy_input_fn(
    x={'x':np.array([[float(x)] for x in range(set_size)])},
    y=np.array([[float(x*2)] for x in range(set_size)]),
    shuffle=False
)


def test():
    nn = tf.estimator.Estimator(model_fn=model_fn, params=params)
    for x in range(5):
        print('START LOOP:',x)
        a = nn.train(input_fn=input_fn,steps=1000)
        print('--------')
        b = nn.evaluate(input_fn=input_fn)
        print(""----STATS----"",b)
    print('Done loop')
    c = nn.predict(input_fn=input_fn)
    #print('Predictions:',[x for x in c])

if __name__ == ""__main__"":
    test()
```
warning:
> 2017-11-23 11:23:52.370395: W tensorflow/core/framework/op_kernel.cc:1192] Out of range: FIFOQueue '_2_enqueue_input/fifo_queue' is closed and has insufficient elements (requested 128, current size 0)
> 	 [[Node: fifo_queue_DequeueUpTo = QueueDequeueUpToV2[component_types=[DT_INT64, DT_DOUBLE, DT_DOUBLE], timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](enqueue_input/fifo_queue, fifo_queue_DequeueUpTo/n)]]

Edit: This may be due to something in tf.estimator.inputs.numpy_input_fn as creating the input_fn manually does not cause the warning and early termination of training."
14835,"tensorflow_serving build error on Windows, bazel 0.7, tensorflow 1.4","C:\serving>bazel build //tensorflow_serving/example:mnist_saved_model
ERROR: error loading package 'tensorflow_serving/example': Encountered error while reading extension file 'protobuf.bzl': no such package '@protobuf_archive//': Traceback (most recent call last):
File ""C:/users/akhil/appdata/local/temp/_bazel_akhil/-8r_kqmg/external/org_tensorflow/tensorflow/workspace.bzl"", line 119
_apply_patch(repo_ctx, repo_ctx.attr.patch_file)
File ""C:/users/akhil/appdata/local/temp/_bazel_akhil/-8r_kqmg/external/org_tensorflow/tensorflow/workspace.bzl"", line 111, in _apply_patch
_execute_and_check_ret_code(repo_ctx, cmd)
File ""C:/users/akhil/appdata/local/temp/_bazel_akhil/-8r_kqmg/external/org_tensorflow/tensorflow/workspace.bzl"", line 92, in _execute_and_check_ret_code
fail(""Non-zero return code({1}) when ...))
Non-zero return code(127) when executing 'C:\msys64\usr\bin\bash.exe -l -c patch -p1 -d C:/users/akhil/appdata/local/temp/_bazel_akhil/-8r_kqmg/external/protobuf_archive -i C:/users/akhil/appdata/local/temp/_bazel_akhil/-8r_kqmg/external/org_tensorflow/third_party/protobuf/add_noinlines.patch':
Stdout:
Stderr: /usr/bin/bash: patch: command not found
.
INFO: Elapsed time: 42.062s"
14834,[AUC] result of tf.metrics.auc doesnot match with sklearn's,"My tensorflow version is ('v1.3.0-rc1-4263-gc81acfb', '1.4.0-rc1'), and the system is Rehat with gcc version 4.8.5 20150623 (Red Hat 4.8.5-16). I run the program use CPU only.

I wrote a NN  use tensorflow for binary classification. I create the an `auc_op` in the following way:
 
```python
net = input_layer(features,) # get dense input layer from features
for layer_id in xrange(1, num_layer):
    net  = tf.add(tf.matmul(net, self._weights[layer_id]), self._bias[layer_id])
    if layer_id < num_layer - 1: # output layer without activation function to get `wx + b`
        net =tf.nn.relu(net)
logits = net
labels = tf.expand_dims(tf.cast(tf.convert_to_tensor(labels), dtype = tf.float32), axis = -1)
auc_op = tf.metrics.auc(labels = labels, predictions = tf.sigmoid(logits), num_thresholds = 102400)
```

I run the `auc_op` like this:
```python
for step in xrange(1, self._max_steps + 1):
    auc = self._sess.run(auc_op)
```

I also keep all the logits and labels in each step and concatenate them, then call sklearn like this:
```python
from sklearn.metrics import roc_auc_score
roc_auc_score(labels, sigmoid(logits))
```

Are there anything wrong in the way I use tf.metrics.auc? When I run the `auc_op`, it returns a tuple with two values and I don't which one is the correct auc. But both of them are not equal with sklearn's. 
I once wrote an program to calculate auc and it was exactly the same with sklearn's even in 1M data, thus I tend to think sklearn's result is the ground truth. "
14832,"Error building with cmake - on Win10, Python3.5 ,Tensorflow 1.4 (Pywrap_tensorflow Issue)","Hi , I m trying to build tensorflow with cmake. Firstly my system information is here; 
### System information
- Windows 10
- Tensorflow 1.4.0
- Anaconda 3 (Python3.5)
- I used swingwin Version: 2.0.0 (2 June 2010)
- CUDA 8 CuDnn 5.1
- Quadro P3000 ,  NVIDIA-SMI 382.16 - Driver Version: 382.16

 I followed  the instruction here : https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/cmake/README.md   

- Install  the pre-requisites detailed above, and set up your environment. ✓
- Clone  the TensorFlow repository and create a working directory for your build:    ✓
- Invoke  CMake to create Visual Studio solution and project files. ✓
- Invoke  MSBuild to build TensorFlow   (Errors :( )

The errors here ;
C:\...\tensorflow\tensorflow\contrib\cmake\build\pywrap_tensorflow_internal.cc(4143): error C3861: 'PyString_FromString': identifier not found [C:\...\tensorflow\tensorflow\contrib\cmake\build\pywrap_tensorflow_internal_static.vcxproj]

C:\..\tensorflow\tensorflow\contrib\cmake\build\pywrap_tensorflow_internal.cc(4154): error C3861: 'PyString_FromString': identifier not found [C:\..\tensorflow\tensorflow\contrib\cmake\build\pywrap_tensorflow_internal_static.vcxproj]

C:\..\tensorflow\tensorflow\contrib\cmake\build\pywrap_tensorflow_internal.cc(4246): error C3861: 'PyString_FromString': identifier not found [C:\...\tensorflow\tensorflow\contrib\cmake\build\pywrap_tensorflow_internal_static.vcxproj]

C:\..\tensorflow\tensorflow\contrib\cmake\build\pywrap_tensorflow_internal.cc(4246): error C2661: 'tensorflow::internal::Check_EQImpl': no overloaded function takes 2 arguments [C:\..\tensorflow\tensorflow\contrib\cmake\build\pywrap_tensorflow_internal_static.vcxproj]

C:\..\tensorflow\tensorflow\contrib\cmake\build\pywrap_tensorflow_internal.cc(4246): error C2512: 'tensorflow::internal::CheckOpString': no appropriate default constructor available [C:\..\tensorflow\tensorflow\contrib\cmake\build\pywrap_tensorflow_internal_static.vcxproj]

I found this page https://github.com/tensorflow/tensorflow/issues/5949 about the issue, It is not building with cmake -maybe cosofthat it is another issue but  , Main solution is to update   Microsoft Visual C++ 2015 Redistributable Update 3 (x64 version) and I uninstalled,then installed it ,just in case.
But It didnot work.  

Do you have any idea?
"
14830,Feature request: Tensorflow lite on memory constrained bare-metal systems,"I'm interested in running Tensorflow Lite on devices with limited memory resources and possibly no operating systems abstractions available. 

This means removing any dependencies on file systems, threads, synchronization primitives, etc. and keeping the binary size as small as possible. I don't know if you discuss your roadmap openly here, but I'm wondering whether this is something that is planned for TFLite? If not, I may go ahead and try to implement this myself."
14829,Visualizing Embeddings,"https://www.tensorflow.org/programmers_guide/embedding#projections
n the visual for data exploration there are 2 options for distance. One of them should be ""Euclidean"" as against ""Euclidian"""
14828,Eager: Can't take gradient of element-wise tf functions,"Maybe I'm missing something, but taking the gradient of functions like `tf.sin` and `tf.log` in eager mode is failing on a recent master (80e7c9f45c):

```python
In [1]: import tensorflow as tf

In [2]: import tensorflow.contrib.eager as tfe

In [3]: tfe.enable_eager_execution()

In [4]: g=tfe.gradients_function(tf.sin)

In [5]: g([1.0])
```

```
---------------------------------------------------------------------------
IndexError                                Traceback (most recent call last)
<ipython-input-5-e4ceb6f55b16> in <module>()
----> 1 g([1.0])

~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py in decorated(*args, **kwds)
    509     """"""Computes the gradient of the decorated function.""""""
    510
--> 511     _, grad = val_and_grad_function(f, params=params)(*args, **kwds)
    512     return grad
    513

~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py in decorated(*args, **kwds)
    608       raise ValueError(""Functions to be differentiated cannot ""
    609                        ""receive keyword arguments."")
--> 610     val, vjp = make_vjp(f, params)(*args, **kwds)
    611     return val, vjp(dy=dy)
    612

~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py in decorated(*args, **kwds)
    660       args = _ensure_unique_tensor_objects(parameter_positions, args)
    661       for i in parameter_positions:
--> 662         sources.append(args[i])
    663         tape.watch(args[i])
    664       result = f(*args)

IndexError: list index out of range
```"
14827,how to make shear transform in tensorflow like tensorflow.image.random_flip_left_right(image) ?,"in keras, you can make shear transform by **random_shear** in keras.preprocessing.image.

but how to make shear transform in tensorflow?

what I want is something like **tensorflow.image.random_flip_left_right(image)** in tensorflow.

it will be done by **tf.contrib.image.transform**"
14826,bug about tensorflow can not call opencv imread properly,"
------------------------

### System information
**- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ubuntu 14.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.4
- **Python version**: 2.7(but actually i am talking about c++ code)
- **Bazel version (if compiling from source)**: 0.5.4/0.7.0 all tried
- **GCC/Compiler version (if compiling from source)**:  4.8.4
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: CPU mode
- **Exact command to reproduce**: bazel run -c opt //tensorflow/cc/face:face**

### Describe the problem
i add opencv as a third party lib to tensorflow, and modify the workspace and BUILD file to include it to the project. it works well when i use tensorflow 1.2.1 or version before it. recently i update my tensorflow to the newest version, it recommand i must update my bazel at least 0.5.4(i use 0.5.2 with jdk7 before).
and when i update bazel, and move my own code to the new project, compiling seems ok. but when i run the binary, it seems not right. i can not load a jpeg file when i use cv::imread, it doesn't crash, but return a cv::Mat with size 0. in the new project, i can load a bmp file properly, so i guess it is because the project does not link the libjpeg.
but i never need to link the libjpeg manually, because it is included in the opencv library. so i guess there is a bug in the new version of tensorflow.
i have tried the linkopt with -ljpeg, but it does not work.

### Source code / logs
WORKSPACE File:
new_local_repository(
  name = ""opencv"",
  path = ""/usr/local"",
  build_file = ""opencv.BUILD"",
)
BUILD file of opencv:
cc_library(
    name = ""opencv"",
    srcs = glob([""lib/*.so*""]),
    hdrs = glob([""include/**/*.hpp""]),
    includes = [""include""],
    visibility = [""//visibility:public""], 
    linkstatic = 1,
)
BUILD file of my code
tf_cc_binary(
    name = ""face"",
    srcs = [""face.cc""],
    includes = ["".""],
    deps = [
        ""//tensorflow/cc:cc_ops"",
        ""//tensorflow/cc:client_session"",
        ""//tensorflow/core:tensorflow"",
        ""@opencv//:opencv"",
    ],
    copts = [""-fopenmp""],
    linkopts = [""-lgomp"", ""-ljpeg""],
)
my code:
        cv::Mat img = cv::imread(""pic.jpg"");
        std::cout<<line<<"" ""<<img.channels()<<"" ""<<img.cols<<"" ""<<img.rows<<endl;
the log will be: pic.jpg 1 0 0
but if i read a bmp file:
        cv::Mat img = cv::imread(""pic.bmp"");
        std::cout<<line<<"" ""<<img.channels()<<"" ""<<img.cols<<"" ""<<img.rows<<endl;
the log will be: pic.bmp 3 500 355
"
14825,how to extract parameters of sim.batch_norm,"using slim.batch_norm for normalize and here are the batch_norm_params:


![image](https://user-images.githubusercontent.com/31264567/33162735-1b13082c-d066-11e7-918c-62bec95e328c.png)


in this way, i think all the trainable variables (beta, gamma, moving_mean, moving_variance) was stored. and when i print elements in tf.trainable_variables, here is the result. 



![image](https://user-images.githubusercontent.com/31264567/33162835-8c4c091c-d066-11e7-96c9-da7f9b85865e.png)


missing gamma, 
i extracted the output tensor of the first layer, and manually calculate correspond feature map through these parameters.  its not the same, but can be transformed into the same through linear transformation.
so, i'm sure there's something wrong with batch_norm params. where can i find the correct ones. "
14824,'output' does not exist in model 'file:///android_asset/retrained_graph.pb',"I was retrain a inception model with food images,i got the final test prediction and retrained_graph.pb ,retrained_labels.txt file.i check the prediction using command prompt in windows and its work.but i was put the retrained_graph.ph and retrained_labels.txt files into android studio asset folder for deploying mobile,i got the exception like:
output' does not exist in model 'file:///android_asset/retrained_graph.pb

Can anyone help me solve this issue."
14822,third_party\eigen3\unsupported\Eigen\CXX11,"when testing tensorflow.dll in vs2015. but  vs2015 can not recongnize ""third_party\eigen3\unsupported\Eigen\CXX11\Tensor"".

I succeeded in compiling tf1.4 on windows 10+vs2015+cuda8.0+cudnn5.1.  tensorflow.lib and tensorflow.dll  are there.

the error log:
E:\tensorflow2\third_party\eigen3\unsupported/Eigen/CXX11/Tensor(1): fatal error C1014: 包含文件太多: 深度 = 1024

My win32 console program does nothing ,only include some files .src code as follow:
#include <memory>
#include <string>
#include <vector>
#include ""tensorflow/core/framework/tensor.h""
//#include ""tensorflow/core/framework/graph.pb.h""
//#include ""tensorflow/core/public/session.h""
"
14819,Keras Dropout support_masking gets reset to False,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS X 10.12.6
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**: 3.6.1
- **Bazel version (if compiling from source)**: n/a
- **GCC/Compiler version (if compiling from source)**: n/a
- **CUDA/cuDNN version**: n/a
- **GPU model and memory**: n/a
- **Exact command to reproduce**: see below

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

The Keras Dropout layer constructor (tensorflow/python/keras/_impl/keras/layers/core.py) sets support_masking=True and then calls its super constructor, which sets it back to False. Other layers defined in that module appear to set support_masking=True after the super constructor call.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

```
from tensorflow.contrib.keras.api.keras.models import Sequential
from tensorflow.contrib.keras.api.keras.layers import Dropout, InputLayer, LSTM, Masking 

if __name__ == '__main__':

    test1 = True

    def model1():
        model = Sequential()
        model.add(InputLayer([8, 64]))
        model.add(Masking())
        model.add(Dropout(0.5))

    def model2():
        model = Sequential()
        model.add(InputLayer([8, 64]))
        model.add(Masking())
        model.add(LSTM(128, return_sequences=True))
        model.add(Dropout(0.5))

    if test1:
        model1()
    else:
        model2()
```

```
Traceback (most recent call last):
  File ""expose_dropout_bug.py"", line 16, in <module>
    model.add(Dropout(0.5))
  File ""/.venv/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/models.py"", line 501, in add
    output_tensor = layer(self.outputs[0])
  File ""/.venv/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/topology.py"", line 252, in __call__
    output = super(Layer, self).__call__(inputs, **kwargs)
  File ""/.venv/lib/python3.6/site-packages/tensorflow/python/layers/base.py"", line 594, in __call__
    output_mask = self.compute_mask(inputs, previous_mask)
  File ""/.venv/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/topology.py"", line 308, in compute_mask
    'but was passed an input_mask: ' + str(mask))
TypeError: Layer dropout_1 does not support masking, but was passed an input_mask: Tensor(""masking/Any_1:0"", shape=(?, 8), dtype=bool)
```"
14818,Error when setting model_dir for tf.keras.estimator.estimator_from_model(),"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: tf.VERSION = 1.4.0 tf.GIT_VERSION = v1.4.0-rc1-11-g130a514
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: 8.0.61/6.0.21
- **GPU model and memory**: NVIDIA Tesla M60 8 GB
- **Exact command to reproduce**: See Below

### Describe the problem
When trying to use an estimator that is derived from ```tf.keras.estimator.estimator_from_model()``` and training with ```tf.estimator.train_and_evaluate()```, setting ```model_dir``` either in the ```RunConfig``` or in ```tf.keras.estimator.model_to_estimator``` causes a ```NotFoundError``` to be thrown. If the model_dir is not set, then a tmp directory is used as expected and the training is completed successfully.

I also tested this with the canned estimator ```tf.estimator.DNNRegressor```, and the settings were applied as expected when the RunConfig was passed to the estimator or the model_dir passed to the estimator directly.

Below is code to demonstrate this issue. 

### Source code / logs
Minimal example, NotFoundError is thrown:
```python
import os
import numpy as np
import tensorflow as tf

tf.logging.set_verbosity(tf.logging.INFO)

inputs = tf.keras.layers.Input(shape=(10,))
outputs = tf.keras.layers.Dense(10)(inputs)
model = tf.keras.models.Model(inputs, outputs)
model.compile(optimizer='sgd', loss='mse')

# Both of these result in a NotFoundError
run_config = tf.estimator.RunConfig(model_dir='min_out')
est_keras = tf.keras.estimator.model_to_estimator(keras_model=model, config=run_config)
#est_keras = tf.keras.estimator.model_to_estimator(keras_model=model, model_dir='min_out')

input_name = model.input_names[0]
data = np.random.rand(1000,10).astype(np.float32)
train_input_fn = tf.estimator.inputs.numpy_input_fn({input_name:data}, data, batch_size=10, num_epochs=None, shuffle=False)

train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, max_steps=1000)
eval_spec = tf.estimator.EvalSpec(input_fn=train_input_fn, steps=10)
tf.estimator.train_and_evaluate(est_keras, train_spec, eval_spec)
```

Error generated:
```python
$ python minimal_modeldir.py
INFO:tensorflow:Using the Keras model from memory.
2017-11-22 21:40:44.540162: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2017-11-22 21:40:46.525335: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-11-22 21:40:46.525573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:
name: Tesla M60 major: 5 minor: 2 memoryClockRate(GHz): 1.1775
pciBusID: 0000:00:1e.0
totalMemory: 7.43GiB freeMemory: 7.35GiB
2017-11-22 21:40:46.525595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla M60, pci bus id: 0000:00:1e.0, compute capability: 5.2)
INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa7fe724890>, '_model_dir': 'min_out', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_save_summary_steps': 100, '_num_ps_replicas': 0}
INFO:tensorflow:Running training and evaluation locally (non-distributed).
INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 600 secs (eval_spec.throttle_secs) or training is finished.
INFO:tensorflow:Create CheckpointSaverHook.
2017-11-22 21:40:47.048052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla M60, pci bus id: 0000:00:1e.0, compute capability: 5.2)
INFO:tensorflow:Restoring parameters from min_out/model.ckpt-1
2017-11-22 21:40:47.076405: W tensorflow/core/framework/op_kernel.cc:1192] Not found: Key dense_1/kernel not found in checkpoint
2017-11-22 21:40:47.079173: W tensorflow/core/framework/op_kernel.cc:1192] Not found: Key SGD/iterations not found in checkpoint
2017-11-22 21:40:47.079637: W tensorflow/core/framework/op_kernel.cc:1192] Not found: Key dense_1/kernel not found in checkpoint
         [[Node: save/RestoreV2_5 = RestoreV2[dtypes=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/RestoreV2_5/tensor_names, save/RestoreV2_5/shape_and_slices)]]
2017-11-22 21:40:47.080045: W tensorflow/core/framework/op_kernel.cc:1192] Not found: Key SGD/lr not found in checkpoint
2017-11-22 21:40:47.080601: W tensorflow/core/framework/op_kernel.cc:1192] Not found: Key SGD/decay not found in checkpoint
2017-11-22 21:40:47.081693: W tensorflow/core/framework/op_kernel.cc:1192] Not found: Key dense_1/bias not found in checkpoint
2017-11-22 21:40:47.081871: W tensorflow/core/framework/op_kernel.cc:1192] Not found: Key training/SGD/Variable not found in checkpoint
2017-11-22 21:40:47.082097: W tensorflow/core/framework/op_kernel.cc:1192] Not found: Key SGD/momentum not found in checkpoint
2017-11-22 21:40:47.082403: W tensorflow/core/framework/op_kernel.cc:1192] Not found: Key training/SGD/Variable_1 not found in checkpoint
Traceback (most recent call last):
  File ""minimal_modeldir.py"", line 23, in <module>
    tf.estimator.train_and_evaluate(est_keras, train_spec, eval_spec)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py"", line 430, in train_and_evaluate
    executor.run_local()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py"", line 609, in run_local
    hooks=train_hooks)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 302, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 780, in _train_model
    log_step_count_steps=self._config.log_step_count_steps) as mon_sess:
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 368, in MonitoredTrainingSession
    stop_grace_period_secs=stop_grace_period_secs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 673, in __init__
    stop_grace_period_secs=stop_grace_period_secs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 493, in __init__
    self._sess = _RecoverableSession(self._coordinated_creator)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 851, in __init__
    _WrappedSession.__init__(self, self._create_session())
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 856, in _create_session
    return self._sess_creator.create_session()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 554, in create_session
    self.tf_sess = self._session_creator.create_session()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 428, in create_session
    init_fn=self._scaffold.init_fn)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 273, in prepare_session
    config=config)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 205, in _restore_checkpoint
    saver.restore(sess, ckpt.model_checkpoint_path)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1666, in restore
    {self.saver_def.filename_tensor_name: save_path})
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 889, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1120, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1317, in _do_run
    options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1336, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.NotFoundError: Key dense_1/kernel not found in checkpoint
         [[Node: save/RestoreV2_5 = RestoreV2[dtypes=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/RestoreV2_5/tensor_names, save/RestoreV2_5/shape_and_slices)]]
         [[Node: save/RestoreV2_2/_9 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_30_save/RestoreV2_2"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]

Caused by op u'save/RestoreV2_5', defined at:
  File ""minimal_modeldir.py"", line 23, in <module>
    tf.estimator.train_and_evaluate(est_keras, train_spec, eval_spec)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py"", line 430, in train_and_evaluate
    executor.run_local()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py"", line 609, in run_local
    hooks=train_hooks)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 302, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 780, in _train_model
    log_step_count_steps=self._config.log_step_count_steps) as mon_sess:
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 368, in MonitoredTrainingSession
    stop_grace_period_secs=stop_grace_period_secs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 673, in __init__
    stop_grace_period_secs=stop_grace_period_secs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 493, in __init__
    self._sess = _RecoverableSession(self._coordinated_creator)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 851, in __init__
    _WrappedSession.__init__(self, self._create_session())
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 856, in _create_session
    return self._sess_creator.create_session()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 554, in create_session
    self.tf_sess = self._session_creator.create_session()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 419, in create_session
    self._scaffold.finalize()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 212, in finalize
    self._saver.build()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1227, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1263, in _build
    build_save=build_save, build_restore=build_restore)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 745, in _build_internal
    restore_sequentially, reshape)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 470, in _AddShardedRestoreOps
    name=""restore_shard""))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 427, in _AddRestoreOps
    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 267, in restore_op
    [spec.tensor.dtype])[0])
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1021, in restore_v2
    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2956, in create_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1470, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

NotFoundError (see above for traceback): Key dense_1/kernel not found in checkpoint
         [[Node: save/RestoreV2_5 = RestoreV2[dtypes=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/RestoreV2_5/tensor_names, save/RestoreV2_5/shape_and_slices)]]
         [[Node: save/RestoreV2_2/_9 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_30_save/RestoreV2_2"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]
```
"
14815,cant downlod tensorflow it shows could not find a versone,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
14812,segmentation fault due to pytorch and tensorflow conflictions,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Debian GNU/Linux 8 (jessie)
- **TensorFlow installed from (source or binary)**: from Anaconda, with command:
`pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.4.0-cp35-cp35m-linux_x86_64.whl`

- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**: 3.5.4
- **Bazel version (if compiling from source)**: -
- **GCC/Compiler version (if compiling from source)**: -
- **CUDA/cuDNN version**: cuda 8.0
- **GPU model and memory**: TITAN Xp, 12G
- **Exact command to reproduce**:
This fails:
```python
>>> import torch
>>> import tensorflow as tf
Segmentation fault (core dumped)
```


### Describe the problem
I am using pytorch version 0.2.0_4, for python 3.5, with cuda support. I installed it from the following command:

`conda install pytorch torchvision cuda80 -c soumith`

When I use tensorflow alone, it works fine; i.e., doing an import like 
```python
>>> import tensorflow as tf
```
has no problem. Also, Importing tensorflow before torch seems fine as well.


However if I import pytorch before tensorflow, it fails and reported a segmentation error (as shown above).

 "
14811,VERBS and OpenMPI not building anymore without CUDA ?,"Hello,

When activating MPI or VERBS without CUDA, build fails with the following error:

```
ERROR: /build/python-tensorflow-cuda-1.4.0/tensorflow/contrib/verbs/BUILD:133:1: C++ compilation of rule '//tensorflow/contrib/verbs:rdma' failed (Exit 1): gcc failed: error executing command 
  (cd /tmp/tmp.plGX4Xhgql/.cache/bazel/_bazel_pbuilder/436710022b7d9d872ccd97b57710586f/execroot/org_tensorflow && \
  exec env - \
    LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu/libfakeroot:/usr/lib64/libfakeroot:/usr/lib32/libfakeroot \
    PATH=/usr/sbin:/usr/bin:/sbin:/bin \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/usr/bin/python3.4 \
    PYTHON_LIB_PATH=/usr/lib/python3/dist-packages/ \
    TF_NEED_CUDA=0 \
    TF_NEED_OPENCL=0 \
  /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -mavx -msse4.1 -msse4.2 '-std=c++0x' -mavx -msse4.1 -msse4.2 -MD -MF bazel-out/local-py3-opt/bin/tensorflow/contrib/verbs/_objs/rdma/tensorflow/contrib/verbs/rdma.pic.d '-frandom-seed=bazel-out/local-py3-opt/bin/tensorflow/contrib/verbs/_objs/rdma/tensorflow/contrib/verbs/rdma.pic.o' -fPIC -DEIGEN_MPL2_ONLY -DTENSORFLOW_USE_JEMALLOC -DSNAPPY -DTENSORFLOW_USE_VERBS -iquote . -iquote bazel-out/local-py3-opt/genfiles -iquote external/bazel_tools -iquote bazel-out/local-py3-opt/genfiles/external/bazel_tools -iquote external/eigen_archive -iquote bazel-out/local-py3-opt/genfiles/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/local-py3-opt/genfiles/external/local_config_sycl -iquote external/nsync -iquote bazel-out/local-py3-opt/genfiles/external/nsync -iquote external/jemalloc -iquote bazel-out/local-py3-opt/genfiles/external/jemalloc -iquote external/gif_archive -iquote bazel-out/local-py3-opt/genfiles/external/gif_archive -iquote external/jpeg -iquote bazel-out/local-py3-opt/genfiles/external/jpeg -iquote external/protobuf_archive -iquote bazel-out/local-py3-opt/genfiles/external/protobuf_archive -iquote external/com_googlesource_code_re2 -iquote bazel-out/local-py3-opt/genfiles/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/local-py3-opt/genfiles/external/farmhash_archive -iquote external/fft2d -iquote bazel-out/local-py3-opt/genfiles/external/fft2d -iquote external/highwayhash -iquote bazel-out/local-py3-opt/genfiles/external/highwayhash -iquote external/png_archive -iquote bazel-out/local-py3-opt/genfiles/external/png_archive -iquote external/zlib_archive -iquote bazel-out/local-py3-opt/genfiles/external/zlib_archive -iquote external/curl -iquote bazel-out/local-py3-opt/genfiles/external/curl -iquote external/boringssl -iquote bazel-out/local-py3-opt/genfiles/external/boringssl -iquote external/jsoncpp_git -iquote bazel-out/local-py3-opt/genfiles/external/jsoncpp_git -iquote external/grpc -iquote bazel-out/local-py3-opt/genfiles/external/grpc -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/eigen_archive -isystem bazel-out/local-py3-opt/genfiles/external/eigen_archive -isystem external/nsync/public -isystem bazel-out/local-py3-opt/genfiles/external/nsync/public -isystem external/jemalloc/include -isystem bazel-out/local-py3-opt/genfiles/external/jemalloc/include -isystem external/gif_archive/lib -isystem bazel-out/local-py3-opt/genfiles/external/gif_archive/lib -isystem external/protobuf_archive/src -isystem bazel-out/local-py3-opt/genfiles/external/protobuf_archive/src -isystem external/farmhash_archive/src -isystem bazel-out/local-py3-opt/genfiles/external/farmhash_archive/src -isystem external/png_archive -isystem bazel-out/local-py3-opt/genfiles/external/png_archive -isystem external/zlib_archive -isystem bazel-out/local-py3-opt/genfiles/external/zlib_archive -isystem external/curl/include -isystem bazel-out/local-py3-opt/genfiles/external/curl/include -isystem external/boringssl/src/include -isystem bazel-out/local-py3-opt/genfiles/external/boringssl/src/include -isystem external/jsoncpp_git/include -isystem bazel-out/local-py3-opt/genfiles/external/jsoncpp_git/include -isystem external/grpc/include -isystem bazel-out/local-py3-opt/genfiles/external/grpc/include -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c tensorflow/contrib/verbs/rdma.cc -o bazel-out/local-py3-opt/bin/tensorflow/contrib/verbs/_objs/rdma/tensorflow/contrib/verbs/rdma.pic.o).
In file included from ./tensorflow/core/platform/stream_executor.h:26:0,
                 from ./tensorflow/core/common_runtime/gpu/gpu_util.h:23,
                 from tensorflow/contrib/verbs/rdma.cc:23:
./tensorflow/stream_executor/dso_loader.h:32:30: fatal error: cuda/cuda_config.h: No such file or directory
 #include ""cuda/cuda_config.h""
```

Is that expected ?

Thanks"
14809,Batch Normalization layer is unusable,"Despite the numerous submitted issues, `tf.layers.batch_normalization` still feels completely unusable. The major problems are:

1. It does not allow for input tensors with varying shapes. It is complete nonsense to have a fixed batch size. It should be allowed for the batch dimension to be vary.

2. One needs to manually update the running mean and variance. This is very uncomfortable and a very common pitfall for many beginners, while it would take just a couple of lines to do the update internally based on the value of the `training` parameter.

I have recently seen too many custom implementations of a batch normalization layer because of the above problems and it will definitely be very useful if these problems are fixed ASAP.

I am using `tensorflow-gpu`, version `1.4`"
14807,seg fault training tf.nn.conv3d with minibatch size >2,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Custom code! You can find it here: https://github.com/NERSC/CosmoFlow/tree/master/SegFault
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: SUSE Linux 12.2
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: ('v1.3.0-rc1-3112-g65b6a75', '1.4.0-rc0') Note this is NOT compiled with the Intel MKL options. 
- **Python version**: 2.7.13 
- **Bazel version (if compiling from source)**: 0.6.0
- **GCC/Compiler version (if compiling from source)**: 4.8.5
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A, Running on x86_64 Intel Haswell node
- **Exact command to reproduce**: See README in https://github.com/NERSC/CosmoFlow/tree/master/SegFault


### Describe the problem

A seg fault when training a tf.nn.conv3d with minibatch size more than 2 on a single Intel Haswell. The seg fault occurs at [line 187](https://github.com/NERSC/CosmoFlow/blob/master/SegFault/CosmoNet.py#L187).  

### Source code / logs

GDB log: https://github.com/NERSC/CosmoFlow/blob/master/SegFault/gdbTrace.log
It looks like some kind of cyclic dependency in Eigen::TensorEvaluator. "
14806,Go TensorFlow 1.4.0: DataType 21 is not supported,"
------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Arch linux
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: NA (using go)
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: 9.0.176-4 / 7.0.3-1
- **GPU model and memory**: GTX 1060 6GB
- **Exact command to reproduce**:

### Describe the problem
Calling the Value() method on the evaluated output tensor of dataset related operations from the go package fails with the error `DataType 21 is not supported`. It looks like `op.TextLineDataset()` produces a tensor of type `tf.Half` can't be converted to a go type?
I may be using the datasets wrong. If so, the error and/or documentation should be improved.

### Source code / logs

```
package main

import (
	tf ""github.com/tensorflow/tensorflow/tensorflow/go""
	""github.com/tensorflow/tensorflow/tensorflow/go/op""
)

func main() {
	s := op.NewScope()
	textLineHandle := op.TextLineDataset(s,
		op.Const(s.SubScope(""filename""), ""dataset.txt""),
		op.Const(s.SubScope(""compression_type""), """"),
		op.Const(s.SubScope(""buffer_size""), int64(1)),
	)
	graph, err := s.Finalize()
	if err != nil {
		panic(err)
	}
	sess, err := tf.NewSession(graph, nil)
	if err != nil {
		panic(err)
	}
	results, err := sess.Run(nil, []tf.Output{textLineHandle}, []*tf.Operation{})
	if err != nil {
		panic(err)
	}
	_ = results[0].Value()
}
```
Produces:
```
[isaac@d6-arch tfes]$ go run dataset_demo.go 
2017-11-22 11:06:36.945842: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2017-11-22 11:06:37.042484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-11-22 11:06:37.042786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: GeForce GTX 1060 6GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:01:00.0
totalMemory: 5.93GiB freeMemory: 4.58GiB
2017-11-22 11:06:37.042801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1)
panic: BUG: Please report at https://github.com/tensorflow/tensorflow/issues with the note: Go TensorFlow 1.4.0: DataType 21 is not supported

goroutine 1 [running]:
github.com/tensorflow/tensorflow/tensorflow/go.typeOf(0xc400000015, 0x0, 0x0, 0x0, 0x49d72d, 0x4c6e40)
	/home/isaac/go/src/github.com/tensorflow/tensorflow/tensorflow/go/tensor.go:273 +0x14d
github.com/tensorflow/tensorflow/tensorflow/go.(*Tensor).Value(0xc42000c0e0, 0x0, 0xc420057f60)
	/home/isaac/go/src/github.com/tensorflow/tensorflow/tensorflow/go/tensor.go:175 +0x8d
main.main()
	/home/isaac/go/src/github.com/is8ac/tfes/dataset_demo.go:27 +0x2b0
exit status 2
```"
14805,"Installation says to use cuDNN v6.1, but NVIDIA only offers 6.0 and 7.0.4","Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem

NVIDIA only offers the following from their website

https://developer.nvidia.com/rdp/cudnn-download

Download cuDNN v7.0.4 (Nov 13, 2017), for CUDA 9.0
Download cuDNN v7.0.4 (Nov 13, 2017), for CUDA 8.0
Download cuDNN v6.0 (April 27, 2017), for CUDA 8.0
Download cuDNN v6.0 (April 27, 2017), for CUDA 7.5
Download cuDNN v5.1 (Jan 20, 2017), for CUDA 8.0
Download cuDNN v5.1 (Jan 20, 2017), for CUDA 7.5

installation instructions say to use 
https://www.tensorflow.org/install/install_windows

cuDNN v6.1. For details, ....

If you have a different version of one of the preceding packages, please change to the specified versions. In particular, the cuDNN version must match exactly: TensorFlow will not load if it cannot find cuDNN64_6.dll.



### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
14802,Setup.py on CentOS7 pywrap_tensorflow_internal error,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux CentOS7
- **TensorFlow installed from (source or binary)**:
Setup.py
- **TensorFlow version (use command below)**:
1.3
- **Python version**: 
2.7
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
4.8.5
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:
import tensorflow as tf

You can collect some of this information using our environment capture script:
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

tf_env_collect.sh output:

== cat /etc/issue ===============================================
Linux rs-control1 3.10.0-327.36.1.el7.x86_64 #1 SMP Sun Sep 18 13:04:29 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""7 (Core)""
VERSION_ID=""7""
CENTOS_MANTISBT_PROJECT_VERSION=""7""
REDHAT_SUPPORT_PRODUCT_VERSION=""7""

== are we in docker =============================================
No

== compiler =====================================================
c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-16)
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux rs-control1 3.10.0-327.36.1.el7.x86_64 #1 SMP Sun Sep 18 13:04:29 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================

== check for virtualenv =========================================
False

== tensorflow import ============================================
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/usr/local/python-tgt-201701/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/usr/local/python-tgt-201701/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/usr/local/python-tgt-201701/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 52, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/usr/local/python-tgt-201701/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
ImportError: No module named pywrap_tensorflow_internal


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
=========================================================

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

Installing using setup.py works until trying to import tensorflow, causing an Import Error for pywrap_tensorflow_internal

Dependencies I believe are met and using setup.py because I'm building this into an rpm to deploy to different nodes and clusters.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

Simply running setup.py and then import tensorflow as tf produces Import Error:
Traceback (most recent call last):
  File ""/tmp/check_tf.py"", line 1, in <module>
    import tensorflow as tf;
  File ""/usr/local/python-tgt-201701/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/usr/local/python-tgt-201701/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/usr/local/python-tgt-201701/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 52, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/usr/local/python-tgt-201701/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
ImportError: No module named pywrap_tensorflow_internal"
14801,"On the way to latest CMake, VS2017, CUDA 9, cudNN 7, Win10","As many of us (#14126,#14691,#12052), I am trying to get TF1.4 build successfully on windows using the latest version of everything. As far as I can judge **I could do it** but with some hacks. As it is too long for me to complete, I would like to share what I did for help finalizing. It is too early for a PR.

I am using CMake 3.9.6 (though 3.10 came out). I have low cmake skill level.
I am not trying the python bindings.
VS2017 is the community edition.

Without GPU it is easy. The only issue is the heap overflow (C1002 or C1006 #11096). The trick is to reduce parallel build by `msbuild /m:4 /p:CL_MPCount=2 ...` such that 4*2 is approximately the number of core you really have (at least it worked for me). Using `/Zm2000` did not work for me, despite a lot of available memory (32G).

With GPU it is more tricky: the `tf_core_gpu_kernels.vcxproj` does not compile at all. AFAIU, the CMake strategy changed from v3.6, to allow parallel computing. CUDA is now treated as another language. Without modifications nvcc simply returns with code error 1 (or nothing happen I am not sure). Here are my modifications (from v1.4).

From `tensorflow/tensorflow/contrib/cmake/`
1/ adapt `cmakelists.txt` a little: 
- Change `CUDA 8.0` to `CUDA 9.0` l.223.
- Add `enable_language(""CUDA"")` l.224.
- **The `set(CUDA_NVCC_FLAGS ...)` directives do not work anymore**. See below.
- Add capabilities 6.0 and 6.1 in l.232, as well l.246. Might not be needed (it is only for performance).
- Change `64_80` to `64_90` and `64_6` to `64_7` l.247 and 248, similarly in l.272-276.

2/ in `tf_core_kernels.cmake`:
- Add `set_source_files_properties(${tf_core_gpu_kernels_srcs} PROPERTIES LANGUAGE CUDA)` to recognize '.cu.cc' extensions as cuda files in l.209.
- Rename `cuda_add_library(...)` as `add_library(...)` l.210.

3/ edit **(this is the trick)** `tf_core_gpu_kernels.vcxproj`, in the release section:
- Encompass cl.exe flags, ie `/bigobj /nologo ... -Ob2`  with the `-Xcompiler=""/bigobj ... -Ob2""` directive l.147. These former flags are for the c++ compiler not for nvcc and result in the crash.
- Add just before `--expt-relaxed-constexpr`, still in the `AdditionalOptions`.
- Switch `PerformDeviceLink`from `false` to `true` l.164.

Then everything compile (msbuild on  tf_tutorials_example_trainer.vcxproj) (and this tuto works). The remaining point before PR is to avoid third step, i.e. give the right directives to nvcc, by understanding how the CUDA_NVCC_FLAGS works, and add the linking. Hope this solution will work without missing symbols (#6396).

Otherwise it is a nightmare: both CUDA 8 and CMake 3.6 are not aware of VS2017. CMake compilation is not incremental (#14194) and takes about 4-5H (could use precompiled headers especially in tf_core_kernels)...
"
14800,Potential memory leak from deleting array and closing file handler,"Here are couple of minor memory leak for review.
1. https://github.com/tensorflow/tensorflow/blob/6c95675492aa8d25619f5e4ce1674582c051a7fe/tensorflow/c/c_api.cc#L569-L593 ""delete []base;"" looks missing.
   

2. https://github.com/tensorflow/tensorflow/blob/6c95675492aa8d25619f5e4ce1674582c051a7fe/tensorflow/core/lib/io/snappy/snappy_outputbuffer.cc#L164-L173  ""delete []compressed_length_array;"" looks missing when macro TF_RETURN_IF_ERROR() fails.

3. https://github.com/tensorflow/tensorflow/blob/6c95675492aa8d25619f5e4ce1674582c051a7fe/tensorflow/core/platform/profile_utils/android_armv7a_cpu_utils_helper.cc#L113-L123 Two potential problems:
    a. There is no ""fclose()"" being called after fscanf() fails
    b. ""fclose()"" could be called instead of ""pclose()""

4. https://github.com/tensorflow/tensorflow/blob/6c95675492aa8d25619f5e4ce1674582c051a7fe/tensorflow/tools/proto_text/gen_proto_text_functions.cc#L132-L137 When ""fwrite() fails"", ""fclose()"" could be called before ""return -1"".

PS: I don't have handy working environment setup yet, currently browsing code may be better fit for me."
14798,Provide a list of supported XLA operations like TensorFlow Lite,TensorFlow Lite provides a list of currently supported ops [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/tf_ops_compatibility.md) and I wonder if XLA could also have such a list. It's rough to develop and train a model with the full TensorFlow Python API only to get stuck during AOT compilation because of missing ops kernels in the tf2xla bridge.
14797,XLA AOT tfcompile failure due to undeclared inclusions in cc_binary rule,"This happens on a freshly cloned TensorFlow master with Bazel 0.7 on Ubuntu 17.04:

```sh
ERROR: tensorflow/BUILD:13:1: undeclared inclusion(s) in rule '//:model':
this rule is missing dependency declarations for the following files included by 'graph.cc':
  'tensorflow/compiler/tf2xla/xla_compiled_cpu_function.h'
  'tensorflow/compiler/tf2xla/xla_local_runtime_context.h'
  'tensorflow/core/platform/macros.h'
  '/tensorflow/core/platform/types.h'
  '/tensorflow/core/platform/platform.h'
  '/tensorflow/core/platform/default/integral_types.h'
  '/tensorflow/compiler/xla/executable_run_options.h'
```
graph.cc pretty much just does `#include ""graph.h""` as per the tfcompile tutorial and it's weird because these headers [seem to be included](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/aot/tfcompile.bzl#L209-L230) in the tf_library rule but Bazel still complains that the subsequent cc_binary rule doesn't list them as dependencies.

This is my BUILD file, placed in the repo root (so I use TensorFlow's Bazel workspace after going through ./configure):
```sh
load(""@org_tensorflow//tensorflow/compiler/aot:tfcompile.bzl"", ""tf_library"")

tf_library(
  name = ""graph"",
  cpp_class = ""Graph"",
  graph = ""graph.pb"",
  config = ""graph.config.pb"",
)

cc_binary(
  name = ""model"",
  srcs = [""graph.cc""],
  deps = ["":graph"", ""//third_party/eigen3""],
  linkopts = [""-lpthread""]
)
```
I'm not comfortable with Bazel yet but building worked fine with earlier TensorFlow versions. Stuff started to become wonky somewhere around when @org_tensorflow was introduced throughout tfcompile.bzl, I think."
14796,Error Too many value to unpack during export_savedmodel in tensorflow,"TensorFlow 1.4.0

 sendingcurrency = tf.feature_column.categorical_column_with_vocabulary_list('sendincurrency', vocabulary_list=['AUD', 'EUR','GBP','USD'])
    recievercurrency = tf.feature_column.categorical_column_with_vocabulary_list('recievercurrency', vocabulary_list=['AUD', 'EUR','GBP','INR','NZD','USD','XCD','XOF'])
    CBRate = tf.feature_column.numeric_column(""CBRate"",dtype=tf.float32)
linear_features = [sendingcurrency,recievercurrency,CBRate]
regressor = tf.contrib.learn.LinearRegressor(feature_columns=linear_features,config=tf.contrib.learn.RunConfig(model_dir=""/tmp/akhil""))
       
feature_spec = tf.feature_column.make_parse_example_spec(linear_features)
export_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)
model.export_savedmodel(""/tmp/akhil/"",serving_input_fn=export_input_fn)"
14795,TypeError: __call__() got an unexpected keyword argument 'input_c',"I am using `tensorflow.contrib.cudnn_rnn.python.ops.cudnn_rnn_ops.CudnnGRU` as cudnn_cell.
But when I call cudnn_cell as follows
`  	    hiddens, output_h, output_c = cudnn_cell(
   	        inputs,
   	        input_h=init_state,
   	        input_c=init_state,
   	        params=cudnn_params,
 	        is_training=True)
`, an error occurs saying that input_c was an unexpected keyword.
But I have checked the source code and I'am certain that there is a keyword argument 'input_c'."
14793,[feature request] custom GraphKeys QUEUE_RUNNERS for input pipeline,"i find no perfect answer about using input pipeline to train and eval in same Session
===========
[switch input pipeline at stackoverflow](eg: https://stackoverflow.com/questions/41162955/tensorflow-queues-switching-between-train-and-validation-data)
===========
if we define different input pipeline for train and eval,  the following code will start both train and eval input pipeline, that is not we want
```
    coord = tf.train.Coordinator()
    threads = tf.train.start_queue_runners(sess=sess, coord=coord)
```
if we can custom GraphKeys.QUEUE_RUNNERS  collection for different input pipeline , i think we can start input pipeline through parameter of collection.
`    tf.train.add_queue_runner(qr, collection=tf.GraphKeys.QUEUE_RUNNERS)`
`   eg: tf.train.add_queue_runner(qr, collection=tf.GraphKeys.TRAIN_QUEUE_RUNNERS)`
`   eg: tf.train.add_queue_runner(qr, collection=tf.GraphKeys.EVAL_QUEUE_RUNNERS)`
is it right ?  
@mrry  @all 
thanks "
14788,tf.print makes a variable a constant?,"```
In [1]: import tensorflow as tf

In [2]: # using print

In [3]: entcoeff =  tf.Variable([0], dtype=tf.float32, trainable=False)
   ...: entcoeff = tf.Print(entcoeff,[entcoeff,""printing""])

In [4]: tf.assign(entcoeff, [-1.])
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-4-dd57efca5923> in <module>()
----> 1 tf.assign(entcoeff, [-1.])

/nohome/jaan/abhishek/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py in assign(ref, value, validate_shape, use_locking, name)
    270         ref, value, use_locking=use_locking, name=name,
    271         validate_shape=validate_shape)
--> 272   return ref.assign(value)

AttributeError: 'Tensor' object has no attribute 'assign'

In [5]: # not using print

In [6]: entcoeff =  tf.Variable([0], dtype=tf.float32, trainable=False)

In [7]: tf.assign(entcoeff, [-1.])
Out[7]: <tf.Tensor 'Assign:0' shape=(1,) dtype=float32_ref>

```"
14787,TF Lite README.md lacks link to the mentioned mobilenet_v1_224.pb file,https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/README.md
14786,"compile grpc , fail to download something  from china.",Is there anyone give me advice on solving the problem? and give some other https to download?
14784,"Does TF provide C++ interface corresponding to the Python ops ""tensorflow.nn.ctc_greedy_decoder""?","As the title, thanksss!"
14783,Debugging control flow gradients code,"Hi,

I've been trying to debug some code I have for computing gradients over control flow ops and I've encountered a couple issues:

1. @itsmeolivia The shape check introduced in commit bac56b3 breaks the code [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/control_flow_ops.py#L2466) when creating a backprop indexed slices accumulator. That's because when concatenating the indices in line [2528](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/control_flow_ops.py#L2528), the shape changes.
2. I have implemented most of the same unit tests and all works well. I also have support for RNNs and things are fine. However, when I implement a decoder that involves a while loop with a cond nested within it, there are cases where I have a problem. More specifically, if I use an existing tensor (created outside the while loop) within a cond branch, I get this error: `Retval[0] does not have value`. I realize this comes from a switch output of a dead branch being used, but can't figure out exactly what's wrong. Note that this only happens when computing gradients and only when I use an existing tensor within a branch. What would be a good way to debug this?
3. More generally, how can I debug error like `Retval[0] does not have value`. No stack trace is provided and I'm not sure how I could configure TensorFlow when compiling to add some debugging information (e.g., stack trace). @asimshankar @skye @alextp Is there some way to setup and run TensorFlow in a debug mode of some sort?

Thanks! :)"
14782,[Android] Failed to resolve: org.tensorflow:tensorflow-lite,"Hi, I am trying to run tensorflow lite application on my android device.
I get the following error when syncing gradle project:
Failed to resolve: org.tensorflow:tensorflow-lite

Any clues on why this is happening?
My system information is:
OS: Windows 7 64 bit
Android Studio 3.0.1
Android SDK Platform-tools: 26.0.2
Android SDK Tools: 26.1.1

Thanks in advance."
14780,Bazel Compile tensorflow failure,"System information
windows 10 64bit

bazel version
Build label: 0.7.0
Build target: bazel-out/msvc_x64-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Wed Oct 18 14:25:56 2017 (1508336756)
Build timestamp: 1508336756
Build timestamp as int: 1508336756

i run ./configure:
configure
WARNING: Running Bazel server needs to be killed, because the startup options are different.
You have bazel 0.7.0 installed.
Please specify the location of python. [Default is F:\barzel\py2.7\python.exe]: D:/Anaconda3/python.exe
Found possible Python library paths:
  D:\Anaconda3\lib\site-packages
Please input the desired Python library path to use.  Default is [D:\Anaconda3\lib\site-packages]

Do you wish to build TensorFlow with XLA JIT support? [y/N]: n
No XLA JIT support will be enabled for TensorFlow.

Do you wish to build TensorFlow with GDR support? [y/N]: n
No GDR support will be enabled for TensorFlow.

Do you wish to build TensorFlow with VERBS support? [y/N]: n
No VERBS support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: n
No CUDA support will be enabled for TensorFlow.

Do you wish to build TensorFlow with MPI support? [y/N]: n
No MPI support will be enabled for TensorFlow.

Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native]:


Add ""--config=mkl"" to your bazel command to build with MKL support.
Please note that MKL on MacOS or windows is still not supported.
If you would like to use a local MKL instead of downloading, please set the environment variable ""TF_MKL_ROOT"" every time before build.

then i run:
bazel build --verbose_failures //tensorflow:libtensorflow_cc.so

ERROR: F:/barzel/tensorflow1/tensorflow-master/tensorflow/cc/BUILD:422:1: Linking of rule '//tensorflow/cc:ops/sparse_ops_gen_cc' failed (Exit 1181): link.exe failed: error executing command
  cd C:/users/cfenich/appdata/local/temp/_bazel_cfenich/ku2zcbwb/execroot/org_tensorflow
  SET INCLUDE=C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE;C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\ATLMFC\INCLUDE;C:\Program Files (x86)\Windows Kits\10\include\10.0.10240.0\ucrt;C:\Program Files (x86)\Windows Kits\NETFXSDK\4.6.1\include\um;C:\Program Files (x86)\Windows Kits\8.1\include\\shared;C:\Program Files (x86)\Windows Kits\8.1\include\\um;C:\Program Files (x86)\Windows Kits\8.1\include\\winrt;
    SET LIB=C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\LIB\amd64;C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\ATLMFC\LIB\amd64;C:\Program Files (x86)\Windows Kits\10\lib\10.0.10240.0\ucrt\x64;C:\Program Files (x86)\Windows Kits\NETFXSDK\4.6.1\lib\um\x64;C:\Program Files (x86)\Windows Kits\8.1\lib\winv6.3\um\x64;
    SET PATH=C:\Program Files (x86)\Microsoft Visual Studio 14.0\Common7\IDE\CommonExtensions\Microsoft\TestWindow;C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\BIN\amd64;C:\Windows\Microsoft.NET\Framework64\v4.0.30319;C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\VCPackages;C:\Program Files (x86)\Microsoft Visual Studio 14.0\Common7\IDE;C:\Program Files (x86)\Microsoft Visual Studio 14.0\Common7\Tools;C:\Program Files (x86)\Microsoft Visual Studio 14.0\Team Tools\Performance Tools\x64;C:\Program Files (x86)\Microsoft Visual Studio 14.0\Team Tools\Performance Tools;C:\Program Files (x86)\Windows Kits\8.1\bin\x64;C:\Program Files (x86)\Windows Kits\8.1\bin\x86;C:\Program Files (x86)\Microsoft SDKs\Windows\v10.0A\bin\NETFX 4.6.1 Tools\x64\;;C:\WINDOWS\system32
    SET PWD=/proc/self/cwd
    SET TEMP=C:\Users\CFenich\AppData\Local\Temp
    SET TMP=C:\Users\CFenich\AppData\Local\Temp
    SET USE_LINKER=1
  C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/amd64/link.exe /nologo /OUT:bazel-out/host/bin/tensorflow/cc/ops/sparse_ops_gen_cc.exe tensorflow_framework /SUBSYSTEM:CONSOLE -Wl,-rpath,$ORIGIN/,-rpath,$ORIGIN/..,-rpath,$ORIGIN/../.. -pthread /MACHINE:X64 @bazel-out/host/bin/tensorflow/cc/ops/sparse_ops_gen_cc.exe-2.params /DEFAULTLIB:msvcrt.lib.
LINK : warning LNK4044: 无法识别的选项“/Wl,-rpath,$ORIGIN/,-rpath,$ORIGIN/..,-rpath,$ORIGIN/../..”；已忽略
LINK : warning LNK4044: 无法识别的选项“/pthread”；已忽略
LINK : warning LNK4044: 无法识别的选项“/lm”；已忽略
LINK : warning LNK4044: 无法识别的选项“/lm”；已忽略
LINK : warning LNK4044: 无法识别的选项“/lm”；已忽略
LINK : fatal error LNK1181: 无法打开输入文件“tensorflow_framework.obj”
"
14779,"""error in tensorflow setup command"" error when running building the TensorFlow pip package","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 14.04
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: TensorFlow commit 70ba44b46bb9e5f5e55b2357676ffa7196b9bda7
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: 0.7.0
- **GCC/Compiler version (if compiling from source)**: 4.8.4
- **CUDA/cuDNN version**: CUDA 8.0, cuDNN 6.0
- **GPU model and memory**: GTX 1080 8 GB
- **Exact command to reproduce**:
```
bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --config=monolithic
bazel-bin/tensorflow/tools/pip_package/build_pip_package ~/tensorflow_pkg/
```

### Describe the problem
When I try to build TensorFlow at commit 70ba44b46bb9e5f5e55b2357676ffa7196b9bda7 or later, I get the following error after running `bazel-bin/tensorflow/tools/pip_package/build_pip_package ~/tensorflow_pkg`:

```
reedwm@reedwm2:~/tensorflow_test$ bazel-bin/tensorflow/tools/pip_package/build_pip_package ~/tensorflow_ec2_pkg/
Tue Nov 21 18:22:34 PST 2017 : === Using tmpdir: /tmp/tmp.m24Ub0Z2z4
~/tensorflow_test/bazel-bin/tensorflow/tools/pip_package/build_pip_package.runfiles ~/tensorflow_test
~/tensorflow_test
/tmp/tmp.m24Ub0Z2z4 ~/tensorflow_test
Tue Nov 21 18:22:35 PST 2017 : === Building wheel
error in tensorflow setup command: 'install_requires' must be a string or list of strings containing valid project/version requirement specifiers
```

This does not occur on the commit before 70ba44b46bb9e5f5e55b2357676ffa7196b9bda7. When running `./configure`, I choose the default option for everything except that I choose to use CUDA.

Note I use `--config=monolithic` to get around #13243.

/CC @alanhdu @gunan, any ideas what the issue could be?"
14778,v2 to v1,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
14777,"After quantized ssd_mobilenet_v1_coco model, loaded error on Android ","### System information
- **OS Platform and Distribution** : Linux Ubuntu 14.04.5 LTS
- **TensorFlow installed from** : binary
- **TensorFlow version** : 1.2.1
- **Python version**: 2.7
- **Bazel version**: 0.70
- **GCC/Compiler version (if compiling from source)**: 4.8.4 
- **CUDA/cuDNN version**: 8.0
- **GPU model and memory**: Tesla P100-PCIE 
- **Exact command to reproduce**:


### Describe the problem
Load a quantized ssd_mobilenet_v1 model on Android meet error
Caused by: java.io.IOException: Not a valid TensorFlow Graph serialization: NodeDef mentions attr 'T' not in Op<name=Where; signature=input:bool -> index:int64>; 

I quantize the ssd_mobilenet_v1 model o ubuntu 14,  using the below command
```
bazel-bin/tensorflow/tools/graph_transforms/transform_graph 
--in_graph=/data5/zxt/coco_log/export/frozen_inference_graph.pb  
--out_graph=/home/zxt/git/ssd_optimized.pb --inputs='image_tensor'
 --outputs='detection_boxes,detection_scores,num_detections,detection_classes' --transforms='
  add_default_attributes
  strip_unused_nodes(type=float, shape=""-1,-1,-1,3"")
  remove_nodes(op=Identity, op=CheckNumerics)
  fold_batch_norms
  fold_old_batch_norms
  quantize_weights
  strip_unused_nodes
  sort_by_execution_order'
```
I also have tried some other parameters，but all failed with same issue.
the  frozen_inference_graph.pb   is ok on Android, but the quantized pb is can NOT load.
When run the quantized pb on android phone, met errors
```
      at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:799)
   at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:689)
    Caused by: java.io.IOException: Not a valid TensorFlow Graph serialization: NodeDef mentions attr 'T' not in Op<name=Where; signature=input:bool -> index:int64>; 
NodeDef: Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/FilterGreaterThan/Where = Where[T=DT_BOOL](Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/FilterGreaterThan/Greater). 
(Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).
           at org.tensorflow.contrib.android.TensorFlowInferenceInterface.loadGraph(TensorFlowInferenceInterface.java:535)
 
```"
14776,tf.keras.estimator.estimator_from_model does not respect options set in RunConfig,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: tf.VERSION = 1.4.0 tf.GIT_VERSION = v1.4.0-rc1-11-g130a514
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: 8.0.61/6.0.21
- **GPU model and memory**: NVIDIA Tesla M60 8 GB
- **Exact command to reproduce**: See Below

### Describe the problem
When trying to use an estimator that is derived from ```tf.keras.estimator.estimator_from_model()``` and training with ```tf.estimator.train_and_evaluate()```, setting ```gpu_options``` in the ```session_config``` of ```tf.estimator.RunConfig``` does not cause the settings to be respected when passed to the estimator_from_model function. For example setting ```per_process_gpu_memory_fraction=0.5``` does not decrease the memory allocated to the process on the GPU, similarly setting ```allow_growth=True``` continues to allocate all of the memory and does not allow memory growth.

I also tested this with the canned estimator ```tf.estimator.DNNRegressor```, and the settings were applied as expected when the RunConfig was passed to the estimator.

Below is code to demonstrate this issue. 

### Source code / logs
Minimal example, runs to completion and trains successfully. But, changing the GPUOptions settings does not cause the GPU memory to be utilized as expected:
```python
import os
import numpy as np
import tensorflow as tf

tf.logging.set_verbosity(tf.logging.INFO)

# Neither of these GPUOptions are respected
gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.5)
#gpu_options = tf.GPUOptions(allow_growth=True)
sess_config = tf.ConfigProto(gpu_options=gpu_options)
run_config = tf.estimator.RunConfig(session_config=sess_config)

inputs = tf.keras.layers.Input(shape=(10,))
outputs = tf.keras.layers.Dense(10)(inputs)
model = tf.keras.models.Model(inputs, outputs)
model.compile(optimizer='sgd', loss='mse')
est_keras = tf.keras.estimator.model_to_estimator(keras_model=model, config=run_config)

input_name = model.input_names[0]
data = np.random.rand(1000,10).astype(np.float32)
train_input_fn = tf.estimator.inputs.numpy_input_fn({input_name:data}, data, batch_size=10, num_epochs=None, shuffle=False)

train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, max_steps=100000)
eval_spec = tf.estimator.EvalSpec(input_fn=train_input_fn, steps=10)
tf.estimator.train_and_evaluate(est_keras, train_spec, eval_spec)
```"
14775,tf.set_random_seed doesn't work after any operations have been constructed,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes, just switching the order of this:
```
tf.set_random_seed(1234)
a = tf.random_uniform([1])
b = tf.random_normal([1])
```

to this:

```
a = tf.random_uniform([1])
b = tf.random_normal([1])
tf.set_random_seed(1234)
```

in this example:

https://www.tensorflow.org/api_docs/python/tf/set_random_seed

No longer sets the seed.

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:

Binary via pip

- **TensorFlow version (use command below)**:
```
$ python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""
v1.3.0-rc2-20-g0787eee 1.3.0
```

- **Python version**: 
```
$ python --version
Python 3.6.1
```

- **Bazel version (if compiling from source)**:
n/a
- **GCC/Compiler version (if compiling from source)**:
n/a
- **CUDA/cuDNN version**:
n/a
- **GPU model and memory**:
n/a

- **Exact command to reproduce**:
`python tf-test.py`

where tf-test is below:




You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem

If we would like to deterministically run a tensorflow graph, we want to be able to pass in the seed without rebuilding the graph from scratch (which is slow in our interactive application).

Also, this ordering constraint makes it tricky to debug what's going on and no mention is given to the fact that the seed is read in the op _creation_ not _execution_ in the documentation as far as I can tell.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

As written on example page:

```
$ python tf-test.py 
Session 1
2017-11-21 15:38:24.133822: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-11-21 15:38:24.133854: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
[ 0.96046877]
[ 0.83621562]
[ 0.4987599]
[ 0.54880583]
Session 2
[ 0.96046877]
[ 0.83621562]
[ 0.4987599]
[ 0.54880583]


```


With `set_random_seed` after:
```
$ python tf-test.py 
Session 1
2017-11-21 15:41:57.602615: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-11-21 15:41:57.602638: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
[ 0.53137994]
[ 0.32236636]
[ 1.07008374]
[ 0.49122357]
Session 2
[ 0.07862437]
[ 0.18420935]
[ 0.76287955]
[ 0.47924194]
```



Full tf-test.py:

```
import tensorflow as tf

a = tf.random_uniform([1])
b = tf.random_normal([1])

tf.set_random_seed(1234)

# Repeatedly running this block with the same graph will generate the same
# sequences of 'a' and 'b'.
print(""Session 1"")
with tf.Session() as sess1:
  print(sess1.run(a))  # generates 'A1'
  print(sess1.run(a))  # generates 'A2'
  print(sess1.run(b))  # generates 'B1'
  print(sess1.run(b))  # generates 'B2'

print(""Session 2"")
with tf.Session() as sess2:
  print(sess2.run(a))  # generates 'A1'
  print(sess2.run(a))  # generates 'A2'
  print(sess2.run(b))  # generates 'B1'
  print(sess2.run(b))  # generates 'B2'
```"
14772,TFRecordReader keeps files locked after session closes,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:windows 7 64bit
- **TensorFlow installed from (source or binary)**: pip install
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 3.5.2
- **Bazel version (if compiling from source)**:-
- **GCC/Compiler version (if compiling from source)**:-
- **CUDA/cuDNN version**:-
- **GPU model and memory**:-
- **Exact command to reproduce**:

Running this script (you need some tfrecords from [here][1]):

```python
import os
import shutil
import sys
import tempfile

import tensorflow as tf

data_dir = r'/path/to/tfrecords'

def test_generate_tfrecords_from_csv():
    with tempfile.TemporaryDirectory() as tmpdirname:
        filenames = os.listdir(data_dir)
        for f in filenames:
            shutil.copy(os.path.join(data_dir, f), os.path.join(tmpdirname, f))
        filenames = sorted([os.path.join(tmpdirname, f) for f in filenames])
        # Create a queue that produces the filenames to read.
        queue = tf.train.string_input_producer(filenames, num_epochs=1,
                                               shuffle=False)
        with tf.Session() as sess:
            sess.run(tf.local_variables_initializer()) # Local !
            tf.train.start_queue_runners(sess=sess)
            reader = tf.TFRecordReader()
            for j in range(len(filenames)):
                key, value = reader.read(queue)
                features_dict = tf.parse_single_example(value, features={
                    'label': tf.FixedLenFeature([], tf.string),})
                # the decode call below is needed, if you replace it with
                # label = tf.constant(0) no files are locked
                label = tf.decode_raw(features_dict['label'], tf.float32)
                _ = sess.run([label]) # files are locked here
        listdir = os.listdir(tmpdirname)
        print(tmpdirname, listdir)
        for f in sorted(listdir):
            os.remove(os.path.join(tmpdirname, f))

print(tf.__version__)
print(sys.version)
test_generate_tfrecords_from_csv()
```


Produces:


```
C:\_\Python35>python.exe C:\Users\MrD\.PyCharm2017.2\config\scratches\so_46259067.py
1.4.0
3.5.2 (v3.5.2:4def2a2901a5, Jun 25 2016, 22:18:55) [MSC v.1900 64 bit (AMD64)]
C:\Users\MrD\AppData\Local\Temp\tmp3hqhkgy0 ['img_2013-01-01-00-00.tfrecords', 'img_2013-01-01-00-01.tfrecords', 'img_2013-01-01-00-02.tfrecords']
Traceback (most recent call last):
  File ""C:\Users\MrD\.PyCharm2017.2\config\scratches\so_46259067.py"", line 38, in <module>
    test_generate_tfrecords_from_csv()
  File ""C:\Users\MrD\.PyCharm2017.2\config\scratches\so_46259067.py"", line 34, in test_generate_tfrecords_from_csv
    os.remove(os.path.join(tmpdirname, f))
  File ""C:\_\Python35\lib\tempfile.py"", line 808, in __exit__
    self.cleanup()
  File ""C:\_\Python35\lib\tempfile.py"", line 812, in cleanup
    _shutil.rmtree(self.name)
  File ""C:\_\Python35\lib\shutil.py"", line 488, in rmtree
    return _rmtree_unsafe(path, onerror)
  File ""C:\_\Python35\lib\shutil.py"", line 383, in _rmtree_unsafe
    onerror(os.unlink, fullname, sys.exc_info())
  File ""C:\_\Python35\lib\shutil.py"", line 381, in _rmtree_unsafe
    os.unlink(fullname)
PermissionError: [WinError 5] Access is denied: 'C:\\Users\\MrD\\AppData\\Local\\Temp\\tmp3hqhkgy0\\img_2013-01-01-00-02.tfrecords'
```

(I had also asked at stack overflow [here](https://stackoverflow.com/questions/46259067/tfrecordreader-keeps-files-locked-after-session-closes). Unless I am doing something stupid shouldn't the tfrecord file be free for deleting after the session closes ? Do I have to explicitly close it (is it even possible) ?

The equivalent dataset code has the same issue:

```python
def test_generate_tfrecords_from_csv_dataset():
    with tempfile.TemporaryDirectory() as tmpdirname:
        filenames = os.listdir(data_dir)
        for f in filenames:
            shutil.copy(os.path.join(data_dir, f), os.path.join(tmpdirname, f))
        filenames = sorted([os.path.join(tmpdirname, f) for f in filenames])
        def _parse_rec(value):
            features_dict = tf.parse_single_example(value, features={
                    'label': tf.FixedLenFeature([], tf.string),})
            # return tf.constant(0, tf.float32)  # files are locked all the same
            return tf.decode_raw(features_dict['label'], tf.float32)
        dataset = tf.data.TFRecordDataset(filenames).map(_parse_rec)
        get_next = dataset.make_one_shot_iterator().get_next
        with tf.Session() as sess:
            for j in range(len(filenames)):
                label = get_next()
                _ = sess.run([label]) # files are locked here
        listdir = os.listdir(tmpdirname)
        print(tmpdirname, listdir)
        for f in sorted(listdir):
            os.remove(os.path.join(tmpdirname, f))
```

It seems in both cases it locks the last file - the others are removed ok.

  [1]: https://www.dropbox.com/sh/wrx8pv546rq4iev/AACER-9HbMxE6T3w9hJdieLCa?dl=0"
14771,"bazel 0.5.4 says ""ERROR: infinite symlink expansion detected""","Hi,

I just tried to update my build script (that worked perfectly fine on 1.2.1 and 1.3.0) and it fails with a not-understandable error.
Everything is exactly the same, build is done in a clean ephemeral environment. The only difference is that I updated bazel to 0.5.4 per TF configure script request...

```
____Loading package: @boringssl//
____Loading package: @org_python_license//
____Loading package: tensorflow/compiler/xla
____Loading package: tensorflow/core/kernels/neon
____Downloading http://www.sqlite.org/2017/sqlite-amalgamation-3200000.zip: 41,040 bytes
____Downloading http://www.sqlite.org/2017/sqlite-amalgamation-3200000.zip: 98,480 bytes
____Downloading http://www.sqlite.org/2017/sqlite-amalgamation-3200000.zip: 288,648 bytes
____Downloading http://www.sqlite.org/2017/sqlite-amalgamation-3200000.zip: 430,920 bytes
____Downloading http://www.sqlite.org/2017/sqlite-amalgamation-3200000.zip: 584,136 bytes
____Downloading http://www.sqlite.org/2017/sqlite-amalgamation-3200000.zip: 746,928 bytes
____Downloading http://www.sqlite.org/2017/sqlite-amalgamation-3200000.zip: 918,008 bytes
____Downloading http://www.sqlite.org/2017/sqlite-amalgamation-3200000.zip: 1,090,296 bytes
____Downloading http://www.sqlite.org/2017/sqlite-amalgamation-3200000.zip: 1,254,456 bytes
____Downloading http://www.sqlite.org/2017/sqlite-amalgamation-3200000.zip: 1,363,896 bytes
____Downloading http://www.sqlite.org/2017/sqlite-amalgamation-3200000.zip: 1,545,840 bytes
____Downloading http://www.sqlite.org/2017/sqlite-amalgamation-3200000.zip: 1,716,840 bytes
____Downloading http://www.sqlite.org/2017/sqlite-amalgamation-3200000.zip: 1,838,592 bytes
____Downloading http://www.sqlite.org/2017/sqlite-amalgamation-3200000.zip: 2,023,272 bytes
____Loading package: @sqlite_archive//
____Loading package: tensorflow/core/kernels/hexagon
____Loading package: tensorflow/compiler/xla/legacy_flags
ERROR: infinite symlink expansion detected
[start of symlink chain]
/build/python-tensorflow-cuda-1.4.0/.cache/bazel/_bazel_pbuilder/436710022b7d9d872ccd97b57710586f/external/org_tensorflow
/build/python-tensorflow-cuda-1.4.0
[end of symlink chain]
.
ERROR: /build/python-tensorflow-cuda-1.4.0/.cache/bazel/_bazel_pbuilder/436710022b7d9d872ccd97b57710586f/external/llvm/BUILD:186:1: no such package '@org_tensorflow//third_party/llvm': Could not access /build/python-tensorflow-cuda-1.4.0/.cache/bazel/_bazel_pbuilder/436710022b7d9d872ccd97b57710586f/external/org_tensorflow: Infinite symlink expansion and referenced by '@llvm//:abi_breaking_gen'.
ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted.
```
And the configure-script:

```
Please specify the location of python. [Default is /usr/bin/python]: /usr/bin/python3.4

Found possible Python library paths:
  /usr/local/lib/python3.4/dist-packages
  /usr/lib/python3/dist-packages
Please input the desired Python library path to use.  Default is [/usr/local/lib/python3.4/dist-packages]
/usr/lib/python3/dist-packages/
Do you wish to build TensorFlow with jemalloc as malloc support? [Y/n]: Y
jemalloc as malloc support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Google Cloud Platform support? [Y/n]: Y
Google Cloud Platform support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Hadoop File System support? [Y/n]: Y
Hadoop File System support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Amazon S3 File System support? [Y/n]: Y
Amazon S3 File System support will be enabled for TensorFlow.

Do you wish to build TensorFlow with XLA JIT support? [y/N]: Y
XLA JIT support will be enabled for TensorFlow.

Do you wish to build TensorFlow with GDR support? [y/N]: Y
GDR support will be enabled for TensorFlow.

Do you wish to build TensorFlow with VERBS support? [y/N]: Y
VERBS support will be enabled for TensorFlow.

Do you wish to build TensorFlow with OpenCL support? [y/N]: N
No OpenCL support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: N
No CUDA support will be enabled for TensorFlow.

Do you wish to build TensorFlow with MPI support? [y/N]: N
No MPI support will be enabled for TensorFlow.

Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native]: -mavx -msse4.1 -msse4.2
```"
14769,Type Serialization in as_graph_def function,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: OSX
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**:  v1.3.0-rc2-20-g0787eee
- **Python version**: 2.7.14
- **Bazel version (if compiling from source)**: 0.7
- **GCC/Compiler version (if compiling from source)**: Apple LLVM version 8.1.0 (clang-802.0.42)
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Problem is that as_graph_def sometimes serialize the type information and sometimes doesn't.

### Source code / logs
```
import tensorflow as tf

# bool typed Op, no type serialized
x = tf.placeholder(tf.bool)
y = tf.placeholder(tf.bool)
op = tf.logical_or(x, y)
print op.graph.as_graph_def(add_shapes=True)

# float typed Op, type serialized
x = tf.placeholder(tf.float32)
y = tf.placeholder(tf.float32)
op = tf.add(x, y)
print op.graph.as_graph_def(add_shapes=True)
```

node for logical_or is, note no `T` in attr:
```
node {
  name: ""LogicalOr""
  op: ""LogicalOr""
  input: ""Placeholder""
  input: ""Placeholder_1""
  attr {
    key: ""_output_shapes""
    value {
      list {
        shape {
          unknown_rank: true
        }
      }
    }
  }
}
```

node for add is, note with `T` in attr:
```
node {
  name: ""Add""
  op: ""Add""
  input: ""Placeholder_2""
  input: ""Placeholder_3""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_output_shapes""
    value {
      list {
        shape {
          unknown_rank: true
        }
      }
    }
  }
}
```
If you print out `print tf.logical_or(x, y)`, the output is 
```
Tensor(""LogicalOr_1:0"", dtype=bool)
```
So problem might be with the serialization?
This seems like a bug to me.
"
14768,Feature request: Control order of 'feature_column.input_layer',"On master (80e7c9f45c).

It seems that the mapping of features to columns in dense the input matrix is always sorted by the alphabetical order of the feature names. It would be nice is this was customizable, perhaps by respecting the order of the feature columns in the second argument to `input_layer`. Mainly useful  for debugging and introspecting the network to know which columns correspond to which features.

eg:

```python
sess.run(tf.feature_column.input_layer({'a': [1], 'b': [2]}, [tf.feature_column.numeric_column('a'), tf.feature_column.numeric_column('b')]))
```

gives `[1, 2`],

as does switching the order of the feature columns:

```python
sess.run(tf.feature_column.input_layer({'a': [1], 'b': [2]}, [tf.feature_column.numeric_column('b'), tf.feature_column.numeric_column('a')]))
```

I also tried giving the features as an `OrderedDict`, but `input_layer` doesn't seem to care about the ordering in that  situation either. 
"
14764,./,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
14762,tf.TensorShape concatenation converts shape information to values,"Tensorflow: 1.4.0

Example code:
```python
import tensorflow as tf
tf.InteractiveSession()
>>> tf.concat([tf.TensorShape([4,1]), tf.constant([1,1,1,1])], 0).eval()
array([4, 1, 1, 1, 1, 1])
```

Is it intended that this works and produces the output where the shape information gets converted into actual values?"
14761,tensorflow lite: error when convert frozen model to lite format,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 14.04
- **TensorFlow installed from (source or binary)**:
source
- **TensorFlow version (use command below)**:
1.3.0
- **Python version**: 
2.7
- **Bazel version (if compiling from source)**:
0.7.0
- **GCC/Compiler version (if compiling from source)**:
gcc (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4
- **CUDA/cuDNN version**:
cuda8.0/cudnn6.0


I tried to convert squeezenet frozen model to lite format with the following command:
""bazel run --config=opt tensorflow/contrib/lite/toco:toco -- --input_file=/home/xxx/caffe-tensorflow/npy2ckpt/squeezenet/frozen_model.pb --input_format=TENSORFLOW_GRAPHDEF  --output_format=TFLITE --output_file=/home/xxx/caffe-tensorflow/npy2ckpt/squeezenet/squeezenet.lite --inference_type=FLOAT --input_type=FLOAT --input_arrays=input --output_arrays=prob --input_shapes=1,227,227,3""

the output is shown below:
2017-11-21 18:35:29.977505: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 170 operators, 231 arrays (0 quantized)
2017-11-21 18:35:29.981856: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 40 operators, 93 arrays (0 quantized)
2017-11-21 18:35:29.982061: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 40 operators, 93 arrays (0 quantized)
2017-11-21 18:35:29.982201: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:312] Total transient array allocated size: 4071680 bytes, theoretical optimal value: 4071680 bytes.
2017-11-21 18:35:29.982317: I tensorflow/contrib/lite/toco/toco_tooling.cc:255] Estimated count of arithmetic ops: 0.781679 billion (note that a multiply-add is counted as 2 ops).
2017-11-21 18:35:29.982482: F tensorflow/contrib/lite/toco/tflite/export.cc:192] Unsupported operator: Squeeze

Then I tried to convert mobilenet_v1_1.0_224.pb to lite format, the same error as above.
""bazel run --config=opt tensorflow/contrib/lite/toco:toco -- --input_file=/home/xxx/Downloads/freeze_mobilenet/MobileNet/img224/mobilenet_v1_1.0_224.pb --input_format=TENSORFLOW_GRAPHDEF  --output_format=TFLITE --output_file=/home/xxx/Downloads/freeze_mobilenet/MobileNet/img224/mobilenet.lite --inference_type=FLOAT --input_type=FLOAT --input_arrays=input --output_arrays=output --input_shapes=1,224,224,3""

output:
2017-11-21 22:07:39.747095: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 418 operators, 584 arrays (0 quantized)
2017-11-21 22:07:39.766175: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 31 operators, 88 arrays (0 quantized)
2017-11-21 22:07:39.766390: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 31 operators, 88 arrays (0 quantized)
2017-11-21 22:07:39.766592: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:312] Total transient array allocated size: 6422528 bytes, theoretical optimal value: 4816896 bytes.
2017-11-21 22:07:39.766751: I tensorflow/contrib/lite/toco/toco_tooling.cc:255] Estimated count of arithmetic ops: 1.14264 billion (note that a multiply-add is counted as 2 ops).
2017-11-21 22:07:39.766952: F tensorflow/contrib/lite/toco/tflite/export.cc:192] Unsupported operator: Squeeze

Although I installed tensorflow with ""pip install tensorflow-gpu"", in order to convert model to lite format, I git clone the tensorflow files and  configure, bazel to compile the files. I don't know whether this affect the converting of models, but the error is really strange!
"
14759,Version 1.4.0 Can't enable peer access between some devices,"
If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: RHEL 7-3
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**:  3.4.5
- **Bazel version (if compiling from source)**: 0.7.0
- **GCC/Compiler version (if compiling from source)**: 5.3.0
- **CUDA/cuDNN version**: CUDA 9.0.175 / cuDNN 7.0
- **GPU model and memory**:  10 x GeForce GTX 1080 Ti  12 GB
- **Exact command to reproduce**: 

### Describe the problem
System has 10 GPUs on one pci root hub but Tensorflow can not enable peer access to all devices. Nvidia CUDA-Example 1_Utilities/p2pBandwidthLatencyTest is able to enable these

### Source code / logs
Tensorflow output:
> 2017-11-21 13:58:12.914211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:04:00.0
totalMemory: 10.91GiB freeMemory: 10.72GiB
2017-11-21 13:58:13.249428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 1 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:05:00.0
totalMemory: 10.91GiB freeMemory: 10.74GiB
2017-11-21 13:58:13.574464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 2 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:06:00.0
totalMemory: 10.91GiB freeMemory: 10.74GiB
2017-11-21 13:58:13.899631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 3 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:07:00.0
totalMemory: 10.91GiB freeMemory: 10.74GiB
2017-11-21 13:58:14.219023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 4 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:08:00.0
totalMemory: 10.91GiB freeMemory: 10.74GiB
2017-11-21 13:58:14.553864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 5 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:0b:00.0
totalMemory: 10.91GiB freeMemory: 10.74GiB
2017-11-21 13:58:14.888727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 6 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:0c:00.0
totalMemory: 10.91GiB freeMemory: 10.74GiB
2017-11-21 13:58:15.208341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 7 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:0d:00.0
totalMemory: 10.91GiB freeMemory: 10.74GiB
2017-11-21 13:58:15.524748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 8 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:0e:00.0
totalMemory: 10.91GiB freeMemory: 10.74GiB
2017-11-21 13:58:15.831437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 9 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:0f:00.0
totalMemory: 10.91GiB freeMemory: 10.74GiB
2017-11-21 13:58:15.837982: W tensorflow/core/common_runtime/gpu/gpu_device.cc:918] Unable to enable peer access between device ordinals 0 and 9
2017-11-21 13:58:15.843596: W tensorflow/core/common_runtime/gpu/gpu_device.cc:918] Unable to enable peer access between device ordinals 1 and 9
2017-11-21 13:58:15.848661: W tensorflow/core/common_runtime/gpu/gpu_device.cc:918] Unable to enable peer access between device ordinals 2 and 9
2017-11-21 13:58:15.852889: W tensorflow/core/common_runtime/gpu/gpu_device.cc:918] Unable to enable peer access between device ordinals 3 and 9
2017-11-21 13:58:15.856213: W tensorflow/core/common_runtime/gpu/gpu_device.cc:918] Unable to enable peer access between device ordinals 4 and 9
2017-11-21 13:58:15.858748: W tensorflow/core/common_runtime/gpu/gpu_device.cc:918] Unable to enable peer access between device ordinals 5 and 9
2017-11-21 13:58:15.860537: W tensorflow/core/common_runtime/gpu/gpu_device.cc:918] Unable to enable peer access between device ordinals 6 and 9
2017-11-21 13:58:15.861548: W tensorflow/core/common_runtime/gpu/gpu_device.cc:918] Unable to enable peer access between device ordinals 7 and 9
2017-11-21 13:58:15.861791: W tensorflow/core/common_runtime/gpu/gpu_device.cc:918] Unable to enable peer access between device ordinals 8 and 9
2017-11-21 13:58:15.861915: W tensorflow/core/common_runtime/gpu/gpu_device.cc:918] Unable to enable peer access between device ordinals 9 and 0
2017-11-21 13:58:15.862038: W tensorflow/core/common_runtime/gpu/gpu_device.cc:918] Unable to enable peer access between device ordinals 9 and 1
2017-11-21 13:58:15.862161: W tensorflow/core/common_runtime/gpu/gpu_device.cc:918] Unable to enable peer access between device ordinals 9 and 2
2017-11-21 13:58:15.862283: W tensorflow/core/common_runtime/gpu/gpu_device.cc:918] Unable to enable peer access between device ordinals 9 and 3
2017-11-21 13:58:15.862405: W tensorflow/core/common_runtime/gpu/gpu_device.cc:918] Unable to enable peer access between device ordinals 9 and 4
2017-11-21 13:58:15.862523: W tensorflow/core/common_runtime/gpu/gpu_device.cc:918] Unable to enable peer access between device ordinals 9 and 5
2017-11-21 13:58:15.862642: W tensorflow/core/common_runtime/gpu/gpu_device.cc:918] Unable to enable peer access between device ordinals 9 and 6
2017-11-21 13:58:15.862759: W tensorflow/core/common_runtime/gpu/gpu_device.cc:918] Unable to enable peer access between device ordinals 9 and 7
2017-11-21 13:58:15.862878: W tensorflow/core/common_runtime/gpu/gpu_device.cc:918] Unable to enable peer access between device ordinals 9 and 8
2017-11-21 13:54:16.736201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Device peer to peer matrix
2017-11-21 13:54:16.736590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1051] DMA: 0 1 2 3 4 5 6 7 8 9 
2017-11-21 13:54:16.736598: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1061] 0:   Y Y Y Y Y Y Y Y Y Y 
2017-11-21 13:54:16.736602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1061] 1:   Y Y Y Y Y Y Y Y Y Y 
2017-11-21 13:54:16.736606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1061] 2:   Y Y Y Y Y Y Y Y Y Y 
2017-11-21 13:54:16.736610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1061] 3:   Y Y Y Y Y Y Y Y Y Y 
2017-11-21 13:54:16.736613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1061] 4:   Y Y Y Y Y Y Y Y Y Y 
2017-11-21 13:54:16.736617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1061] 5:   Y Y Y Y Y Y Y Y Y Y 
2017-11-21 13:54:16.736621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1061] 6:   Y Y Y Y Y Y Y Y Y Y 
2017-11-21 13:54:16.736625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1061] 7:   Y Y Y Y Y Y Y Y Y Y 
2017-11-21 13:54:16.736629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1061] 8:   Y Y Y Y Y Y Y Y Y Y 
2017-11-21 13:54:16.736633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1061] 9:   Y Y Y Y Y Y Y Y Y Y 


Nvidia CUDA P2P Output:

> [P2P (Peer-to-Peer) GPU Bandwidth Latency Test]
Device: 0, GeForce GTX 1080 Ti, pciBusID: 4, pciDeviceID: 0, pciDomainID:0
Device: 1, GeForce GTX 1080 Ti, pciBusID: 5, pciDeviceID: 0, pciDomainID:0
Device: 2, GeForce GTX 1080 Ti, pciBusID: 6, pciDeviceID: 0, pciDomainID:0
Device: 3, GeForce GTX 1080 Ti, pciBusID: 7, pciDeviceID: 0, pciDomainID:0
Device: 4, GeForce GTX 1080 Ti, pciBusID: 8, pciDeviceID: 0, pciDomainID:0
Device: 5, GeForce GTX 1080 Ti, pciBusID: b, pciDeviceID: 0, pciDomainID:0
Device: 6, GeForce GTX 1080 Ti, pciBusID: c, pciDeviceID: 0, pciDomainID:0
Device: 7, GeForce GTX 1080 Ti, pciBusID: d, pciDeviceID: 0, pciDomainID:0
Device: 8, GeForce GTX 1080 Ti, pciBusID: e, pciDeviceID: 0, pciDomainID:0
Device: 9, GeForce GTX 1080 Ti, pciBusID: f, pciDeviceID: 0, pciDomainID:0
Device=0 CAN Access Peer Device=1
Device=0 CAN Access Peer Device=2
Device=0 CAN Access Peer Device=3
Device=0 CAN Access Peer Device=4
Device=0 CAN Access Peer Device=5
Device=0 CAN Access Peer Device=6
Device=0 CAN Access Peer Device=7
Device=0 CAN Access Peer Device=8
Device=0 CAN Access Peer Device=9
Device=1 CAN Access Peer Device=0
Device=1 CAN Access Peer Device=2
Device=1 CAN Access Peer Device=3
Device=1 CAN Access Peer Device=4
Device=1 CAN Access Peer Device=5
Device=1 CAN Access Peer Device=6
Device=1 CAN Access Peer Device=7
Device=1 CAN Access Peer Device=8
Device=1 CAN Access Peer Device=9
Device=2 CAN Access Peer Device=0
Device=2 CAN Access Peer Device=1
Device=2 CAN Access Peer Device=3
Device=2 CAN Access Peer Device=4
Device=2 CAN Access Peer Device=5
Device=2 CAN Access Peer Device=6
Device=2 CAN Access Peer Device=7
Device=2 CAN Access Peer Device=8
Device=2 CAN Access Peer Device=9
Device=3 CAN Access Peer Device=0
Device=3 CAN Access Peer Device=1
Device=3 CAN Access Peer Device=2
Device=3 CAN Access Peer Device=4
Device=3 CAN Access Peer Device=5
Device=3 CAN Access Peer Device=6
Device=3 CAN Access Peer Device=7
Device=3 CAN Access Peer Device=8
Device=3 CAN Access Peer Device=9
Device=4 CAN Access Peer Device=0
Device=4 CAN Access Peer Device=1
Device=4 CAN Access Peer Device=2
Device=4 CAN Access Peer Device=3
Device=4 CAN Access Peer Device=5
Device=4 CAN Access Peer Device=6
Device=4 CAN Access Peer Device=7
Device=4 CAN Access Peer Device=8
Device=4 CAN Access Peer Device=9
Device=5 CAN Access Peer Device=0
Device=5 CAN Access Peer Device=1
Device=5 CAN Access Peer Device=2
Device=5 CAN Access Peer Device=3
Device=5 CAN Access Peer Device=4
Device=5 CAN Access Peer Device=6
Device=5 CAN Access Peer Device=7
Device=5 CAN Access Peer Device=8
Device=5 CAN Access Peer Device=9
Device=6 CAN Access Peer Device=0
Device=6 CAN Access Peer Device=1
Device=6 CAN Access Peer Device=2
Device=6 CAN Access Peer Device=3
Device=6 CAN Access Peer Device=4
Device=6 CAN Access Peer Device=5
Device=6 CAN Access Peer Device=7
Device=6 CAN Access Peer Device=8
Device=6 CAN Access Peer Device=9
Device=7 CAN Access Peer Device=0
Device=7 CAN Access Peer Device=1
Device=7 CAN Access Peer Device=2
Device=7 CAN Access Peer Device=3
Device=7 CAN Access Peer Device=4
Device=7 CAN Access Peer Device=5
Device=7 CAN Access Peer Device=6
Device=7 CAN Access Peer Device=8
Device=7 CAN Access Peer Device=9
Device=8 CAN Access Peer Device=0
Device=8 CAN Access Peer Device=1
Device=8 CAN Access Peer Device=2
Device=8 CAN Access Peer Device=3
Device=8 CAN Access Peer Device=4
Device=8 CAN Access Peer Device=5
Device=8 CAN Access Peer Device=6
Device=8 CAN Access Peer Device=7
Device=8 CAN Access Peer Device=9
Device=9 CAN Access Peer Device=0
Device=9 CAN Access Peer Device=1
Device=9 CAN Access Peer Device=2
Device=9 CAN Access Peer Device=3
Device=9 CAN Access Peer Device=4
Device=9 CAN Access Peer Device=5
Device=9 CAN Access Peer Device=6
Device=9 CAN Access Peer Device=7
Device=9 CAN Access Peer Device=8

Any idea how i can fix it ?
"
14758,Build Tensorflow Lite C++ API into a dynamic library for Android,"Is there any way of building the Tensorflow Lite C++ API into a dynamic library for Android?
I have tried to build with bazel for armv7a but this only gives the corresponding static libraries:
`bazel build -c opt //tensorflow/contrib/lite:* --crosstool_top=//external:android/crosstool --cpu=armeabi-v7a --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --cxxopt=""-std=c++11"" --verbose_failures
`

"
14756,Downgrade to Bazel 0.4.2 for Tensorflow r1.0,"Hello, 

I need to checkout to Tensorflow r1.0 and as suggested the Bazel version should be 0.4.2

I have already installed Bazel and after upgrade bazel version is 0.7.0

Do you know the steps so I can downgrade to Bazel 0.4.2? 

I have tried with apt-get install bazel=0.4.2 but this does not work, 

and I have also tried to uninstall by executing the command rm -fr ~/.bazel ~/.bazelrc and deleting relevant data in ~/.cache/bazel/ folder, but this did not also work.

Any suggestions ?

Thank you in advance"
14755,Problem with assigning values to matrix indices in tensorflow,"Hi,

I am constructing a NN with tensorflow that uses a custom stddev function. I have for a batch and indices i and j a function `AcrossBatchSD(batch, i, j)`. Of course, `import tensorflow as tf`.

```
def AcrossBatchSD(batch, i, j):

    _, varR = tf.nn.moments(batch[:, i, j, 0], axes=[0])
    _, varG = tf.nn.moments(batch[:, i, j, 1], axes=[0])
    _, varB = tf.nn.moments(batch[:, i, j, 2], axes=[0]) 
 
    return tf.sqrt(varR), tf.sqrt(varG), tf.sqrt(varB)
```

This function seems to work, but then I would like to do the following:

```
def MinibatchStdDev(batch, window, mb_size):

    n = batch[0].shape[0].value 
    f1 = tf.Variable(tf.zeros([n, n]))
    f2 = tf.Variable(tf.zeros([n, n]))
    f3 = tf.Variable(tf.zeros([n, n]))

    for i in range(n):
        for j in range(n):

            sqrtR, sqrtG, sqrtB = AcrossBatchSD(batch, i, j)          
            f1[i, j].assign(sqrtR)
            f2[i, j].assign(sqrtG)
            f3[i, j].assign(sqrtB) 
                
    f = tf.divide(tf.add(tf.add(f1, f2), f3), 3)
    F = tf.reduce_mean(f)

    return tf.multiply(F, tf.ones(([mb_size, window, window]))))
```

My problem is that the function `assign` in tensorflow is not differentiable, so `tf.gradients` will outout a `NoneType`. Therefore, my network cannot be trained.

A test can be done with

```
mb_size = 3
window = 4
batch = tf.Variable(tf.random_normal([mb_size, 1024, 1024, 3]), tf.float32)
out = MinibatchStdDev(batch=batch, window=window, mb_size=mb_size)
init = tf.global_variables_initializer()
sess = tf.Session()
sess.run(init)
sess.run(out)
```"
14754,"Hi,","Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
14753,compile tensorflow lite static library using QCC on QNX Platform,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**:master latest
- **Python version**: 2.7
- **Bazel version (if compiling from source)**:0.7

### Describe the problem

my goal is compile tensorflow lite static library using QNX-QCC compiler。 This is possible?
And do I need to modify the code in kernels/*.cc or other souce code , and how do。

Please give me some advice, thx。

**the make script is just  like below：**

**make script file:**

function make_qnx() {
	if [ ! -d $1 ];then
		mkdir $1 || exit_popd 1
	fi
	cd $1
	export QNX_ABI=$1
	source /opt/qnx660/qnx660-env.sh
	~/DevTools/cmake-3.9.0-rc5-Linux-x86_64/bin/cmake -G ""Unix Makefiles"" -DQNX_PLATFORM_ABI=""$1"" -DPLATFORM_ABI=qnx -DCMAKE_TOOLCHAIN_FILE=${CURRENT_SCRIPT_DIR}/toolchains/**qnx.toolchain.cmake**
	make
}

**qnx.toolchain.cmake file :**

cmake_minimum_required(VERSION 2.8)
set(CMAKE_SYSTEM_NAME QNX)
set(QNX_PLATFORM_ABI ""$ENV{QNX_ABI}"")

if(QNX_PLATFORM_ABI STREQUAL ""x86"")
	set(ARCH_NAME gcc_ntox86)

	set(CMAKE_C_COMPILER /opt/qnx660/host/linux/x86/usr/bin/qcc)
	set(CMAKE_C_COMPILER_TARGET ${ARCH_NAME})
	set(CMAKE_CXX_COMPILER /opt/qnx660/host/linux/x86/usr/bin/QCC)
	set(CMAKE_CXX_COMPILER_TARGET ${ARCH_NAME})
elseif(QNX_PLATFORM_ABI STREQUAL ""armv7"")
	set(ARCH_NAME gcc_ntoarmv7le)
	
	set(CMAKE_C_COMPILER /opt/qnx660/host/linux/x86/usr/bin/qcc)
	set(CMAKE_C_COMPILER_TARGET ${ARCH_NAME})
	set(CMAKE_CXX_COMPILER /opt/qnx660/host/linux/x86/usr/bin/QCC)
	set(CMAKE_CXX_COMPILER_TARGET ${ARCH_NAME})
else()
 message( SEND_ERROR ""Unknown QNX_PLATFORM_ABI=\""${QNX_PLATFORM_ABI}\"" is specified."" )
endif()

@andrehentz @aselle 


"
14752,How to solve the error: tensorflow.python.framework.errors_impl.NotFoundError: Key conv_layer3/bias not found in checkpoint,"
#coding=utf-8
#tensorflow 1.4
#python 3.6
import os
import numpy as np
import tensorflow as tf
from PIL import Image

#获取dataset
def load_data(dataset_path):
    img = Image.open(dataset_path)
    # 定义一个20 × 20的训练样本，一共有40个人，每个人都10张样本照片
    img_ndarray = np.asarray(img, dtype='float64') / 256        #图片灰度值输出
    #img_ndarray = np.asarray(img, dtype='float32') / 32
    # 记录脸数据矩阵，57 * 47为每张脸的像素矩阵
    faces = np.empty((400, 57 * 47))        #脸数据矩阵
    # 脸数据矩阵化为一维向量
    for row in range(20):
        for column in range(20):
            faces[20 * row + column] = np.ndarray.flatten(
                img_ndarray[row * 57: (row + 1) * 57, column * 47 : (column + 1) * 47]
                )

    label = np.zeros((400, 40))     #空白的label矩阵
    for i in range(40):
        label[i * 10: (i + 1) * 10, i] = 1      #初始分类矩阵

    # 将数据分成训练集，验证集，测试集
    train_data = np.empty((320, 57 * 47))
    train_label = np.zeros((320, 40))

    vaild_data = np.empty((40, 57 * 47))
    vaild_label = np.zeros((40, 40))

    test_data = np.empty((40, 57 * 47))
    test_label = np.zeros((40, 40))

    # 各数据集初始化
    for i in range(40):
        train_data[i * 8: i * 8 + 8] = faces[i * 10: i * 10 + 8]
        train_label[i * 8: i * 8 + 8] = label[i * 10: i * 10 + 8]

        vaild_data[i] = faces[i * 10 + 8]
        vaild_label[i] = label[i * 10 + 8]

        test_data[i] = faces[i * 10 + 9]
        test_label[i] = label[i * 10 + 9]

    train_data = train_data.astype('float32')
    vaild_data = vaild_data.astype('float32')
    test_data = test_data.astype('float32')

    return [
        (train_data, train_label),
        (vaild_data, vaild_label),
        (test_data, test_label)
    ]

def convolutional_layer(data, kernel_size, bias_size, pooling_size):        #数据，卷积核，偏差，池
    kernel = tf.get_variable(""conv"", kernel_size, initializer=tf.random_normal_initializer())
    bias = tf.get_variable('bias', bias_size, initializer=tf.random_normal_initializer())
    conv = tf.nn.conv2d(data, kernel, strides=[1, 1, 1, 1], padding='SAME')     #strides步长，padding卷积方式，表示卷积核可以停留在图像边缘
    linear_output = tf.nn.relu(tf.add(conv, bias))      #激活函数
    # pooling: Tensor(""conv_layer2/MaxPool:0"", shape=(40, 15, 12, 64), dtype=float32)
    pooling = tf.nn.max_pool(linear_output, ksize=pooling_size, strides=pooling_size, padding=""SAME"")#池化函数
    return pooling

def linear_layer(data, weights_size, biases_size):
    weights = tf.get_variable(""weigths"", weights_size, initializer=tf.random_normal_initializer())      #卷积权重矩阵
    biases = tf.get_variable(""biases"", biases_size, initializer=tf.random_normal_initializer())
    return tf.add(tf.matmul(data, weights), biases)     #f(x) = Wx + b

def convolutional_neural_network(data):
    # 根据类别个数定义最后输出层的神经元
    n_ouput_layer = 40

    kernel_shape1 = [5, 5, 1, 32]       #卷积核的大小
    kernel_shape2 = [5, 5, 32, 64]
    kernel_shape3 = [5, 5, 64, 128]

    bias_shape1 = [32]      #第一层偏差矩阵的大小
    bias_shape2 = [64]      #第二层偏差矩阵的大小
    bias_shape3 = [128]

    full_conn_w_shape = [8 * 6 * 128, 1024]        #Softmax Regression模型参数
    full_conn_b_shape = [1024]

    out_b_shape = [n_ouput_layer]
    out_w_shape = [1024, n_ouput_layer]  # 输出层权重矩阵

    data = tf.reshape(data, [-1, 57, 47, 1])

    # 经过第一层卷积神经网络后，得到的张量shape为：[batch, 29, 24, 32]
    with tf.variable_scope(""conv_layer1"") as layer1:
        layer1_output = convolutional_layer(
            data = data,
            kernel_size = kernel_shape1,
            bias_size = bias_shape1,
            pooling_size = [1, 2, 2, 1]
        )
    # 经过第二层卷积神经网络后，得到的张量shape为：[batch, 15, 12, 64]
    with tf.variable_scope(""conv_layer2"") as layer2:
        layer2_output = convolutional_layer(
            data=layer1_output,
            kernel_size=kernel_shape2,
            bias_size=bias_shape2,
            pooling_size=[1, 2, 2, 1]
        )
    with tf.variable_scope(""conv_layer3"") as layer3:
        layer3_output = convolutional_layer(
            data=layer2_output,
            kernel_size=kernel_shape3,
            bias_size=bias_shape3,
            pooling_size=[1, 2, 2, 1]
        )
    with tf.variable_scope(""full_connection"") as full_layer4:
        # 讲卷积层张量数据拉成2-D张量只有有一列的列向量
        layer3_output_flatten = tf.contrib.layers.flatten(layer3_output)
        layer4_output = tf.nn.relu(
            linear_layer(
                data=layer3_output_flatten,
                weights_size=full_conn_w_shape,
                biases_size=full_conn_b_shape
            )
        )

    with tf.variable_scope(""output"") as output_layer5:
        output = linear_layer(
            data=layer4_output,
            weights_size=out_w_shape,
            biases_size=out_b_shape
        )
    print(data)
    return output

def train_facedata(dataset, model_dir,model_path):

    # train_set_x = data[0][0]
    # train_set_y = data[0][1]
    # valid_set_x = data[1][0]
    # valid_set_y = data[1][1]
    # test_set_x = data[2][0]
    # test_set_y = data[2][1]
    # X = tf.placeholder(tf.float32, shape=(None, None), name=""x-input"")  # 输入数据
    # Y = tf.placeholder(tf.float32, shape=(None, None), name='y-input')  # 输入标签

    batch_size = 40

    # train_set_x, train_set_y = dataset[0]
    # valid_set_x, valid_set_y = dataset[1]
    # test_set_x, test_set_y = dataset[2]
    train_set_x = dataset[0][0]
    train_set_y = dataset[0][1]
    valid_set_x = dataset[1][0]
    valid_set_y = dataset[1][1]
    test_set_x = dataset[2][0]
    test_set_y = dataset[2][1]

    X = tf.placeholder(tf.float32, [batch_size, 57 * 47])
    Y = tf.placeholder(tf.float32, [batch_size, 40])

    predict = convolutional_neural_network(X)
    cost_func = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predict, labels=Y))
    optimizer = tf.train.AdamOptimizer(1e-2).minimize(cost_func)

    # 用于保存训练的最佳模型
    saver = tf.train.Saver()
    #model_dir = './model'
    #model_path = model_dir + '/best.ckpt'

    with tf.Session() as session:

        # 若不存在模型数据，需要训练模型参数
        if not os.path.exists(model_path + "".index""):

            session.run(tf.global_variables_initializer())  ##

            best_loss = float('Inf')
            for epoch in range(20):

                epoch_loss = 0
                for i in range((int)(np.shape(train_set_x)[0] / batch_size)):
                    x = train_set_x[i * batch_size: (i + 1) * batch_size]
                    y = train_set_y[i * batch_size: (i + 1) * batch_size]
                    _, cost = session.run([optimizer, cost_func], feed_dict={X: x, Y: y})
                    epoch_loss += cost

                print(epoch, ' : ', epoch_loss)
                if best_loss > epoch_loss:
                    best_loss = epoch_loss
                    if not os.path.exists(model_dir):
                        os.mkdir(model_dir)
                        print(""create the directory: %s"" % model_dir)
                    save_path = saver.save(session, model_path)
                    print(""Model saved in file: %s"" % save_path)

        # 恢复数据并校验和测试
        saver.restore(session, model_path)
        correct = tf.equal(tf.argmax(predict,1), tf.argmax(Y,1))
        valid_accuracy = tf.reduce_mean(tf.cast(correct,'float'))
        print('valid set accuracy: ', valid_accuracy.eval({X: valid_set_x, Y: valid_set_y}))

        test_pred = tf.argmax(predict, 1).eval({X: test_set_x})
        test_true = np.argmax(test_set_y, 1)
        test_correct = correct.eval({X: test_set_x, Y: test_set_y})
        incorrect_index = [i for i in range(np.shape(test_correct)[0]) if not test_correct[i]]
        for i in incorrect_index:
            print('picture person is %i, but mis-predicted as person %i'
                %(test_true[i], test_pred[i]))


def main():
    dataset_path = ""olivettifaces.gif""
    data = load_data(dataset_path)
    model_dir = './model'
    model_path = model_dir + '/best.ckpt'
    print(len(data))
    train_facedata(data, model_dir, model_path)

if __name__ == ""__main__"" :
    main()

**I am sure I have set the bias and the convince of the conv_layer3, but it calls me they are not exist.**"
14750,Test case with multiple threads do not work in TF-1.4,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
RedHat7.2
- **TensorFlow installed from (source or binary)**:
tensorflow_gpu binary
- **TensorFlow version (use command below)**:
r1.4
- **Python version**: 
python 2.7
- **CUDA/cuDNN version**:
CUDA-8.0 CUDNN-6.0
- **GPU model and memory**:
NVIDIA-K80
- **Exact command to reproduce**:
python tensorflow/python/training/sync_replicas_optimizer_test.py

### Describe the problem

When I start a test case for sync optimizer, it always shows that ps:0,ps:1,worker:1 are not ready.
It seems this only happens in TF-1.4

### Source code / logs

Source Code:
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/sync_replicas_optimizer_test.py

Logs:
2017-11-21 18:37:58.627374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:                                                                                                                [6/1673]
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:06:00.0
totalMemory: 11.17GiB freeMemory: 11.11GiB
2017-11-21 18:37:58.874015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 1 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:07:00.0
totalMemory: 11.17GiB freeMemory: 11.11GiB
2017-11-21 18:37:58.874455: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Device peer to peer matrix
2017-11-21 18:37:58.874488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1051] DMA: 0 1 
2017-11-21 18:37:58.874499: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1061] 0:   Y Y 
2017-11-21 18:37:58.874505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1061] 1:   Y Y 
2017-11-21 18:37:58.874523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:06:00.0, compute capability: 3.7)
2017-11-21 18:37:58.874532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:1) -> (device: 1, name: Tesla K80, pci bus id: 0000:07:00.0, compute capability: 3.7)
E1121 18:37:59.075062187   32596 ev_epoll1_linux.c:1051]     grpc epoll fd: 31
2017-11-21 18:37:59.081712: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:17358, 1 -> localhost:24102}
2017-11-21 18:37:59.081747: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:15405, 1 -> localhost:17501}
2017-11-21 18:37:59.083912: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:324] Started server with target: grpc://localhost:15405
2017-11-21 18:37:59.084202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:06:00.0, compute capability: 3.7)
2017-11-21 18:37:59.084222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:1) -> (device: 1, name: Tesla K80, pci bus id: 0000:07:00.0, compute capability: 3.7)
2017-11-21 18:37:59.090916: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:17358, 1 -> localhost:24102}
2017-11-21 18:37:59.090943: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:15405, 1 -> localhost:17501}
2017-11-21 18:37:59.091077: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:324] Started server with target: grpc://localhost:17501
2017-11-21 18:37:59.091268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:06:00.0, compute capability: 3.7)
2017-11-21 18:37:59.091286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:1) -> (device: 1, name: Tesla K80, pci bus id: 0000:07:00.0, compute capability: 3.7)
2017-11-21 18:37:59.097254: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:17358, 1 -> localhost:24102}
2017-11-21 18:37:59.097277: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:15405, 1 -> localhost:17501}
2017-11-21 18:37:59.097399: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:324] Started server with target: grpc://localhost:17358
2017-11-21 18:37:59.097548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:06:00.0, compute capability: 3.7)
2017-11-21 18:37:59.097566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:1) -> (device: 1, name: Tesla K80, pci bus id: 0000:07:00.0, compute capability: 3.7)
2017-11-21 18:37:59.104080: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:17358, 1 -> localhost:24102}
2017-11-21 18:37:59.104127: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:15405, 1 -> localhost:17501}
2017-11-21 18:37:59.104281: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:324] Started server with target: grpc://localhost:24102
2017-11-21 18:38:09.222879: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0
2017-11-21 18:38:09.222931: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:ps/replica:0/task:1
2017-11-21 18:38:09.222941: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:1
2017-11-21 18:38:19.223062: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0
2017-11-21 18:38:19.223102: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:ps/replica:0/task:1
2017-11-21 18:38:19.223110: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:1
2017-11-21 18:38:29.223253: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0
2017-11-21 18:38:29.223284: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:ps/replica:0/task:1
2017-11-21 18:38:29.223291: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:1
2017-11-21 18:38:39.223379: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0
2017-11-21 18:38:39.224059: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:ps/replica:0/task:1
2017-11-21 18:38:39.224068: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:1
"
14749,Feature Request : Hierarchical Softmax implementation using Tensorflow,"I am trying to multi-level classify with Hierarchical Softmax by using Tensorflow. But I could find any existing HS implementation in Tensorflow.

Is there any other way to implement HS using tensorflow?

It would be helpful if Hierarchical Softmax support is given in TF."
14746,How to use `tf.nn.dropout` to implement embedding dropout,"Recent papers in language modeling use a specific form of embedding dropout that was proposed in [this paper](https://arxiv.org/pdf/1512.05287.pdf). The paper also proposed variational recurrent dropout which was discussed already in [this issue](https://github.com/tensorflow/tensorflow/issues/7927).

In embedding dropout, the same dropout mask is used at each timestep and entire words are dropped (i.e. the whole word vector of a word is set to zero). This behavior can be achieved by providing a `noise_shape` to `tf.nn.dropout`.  In addition, the same words are dropped throughout a sequence: 

""Since we repeat the same mask at each time step, we drop the same words throughout the sequence – i.e. we drop word types at random rather than word tokens (as an example, the sentence “the dog and the cat” might become “— dog and — cat” or “the — and the cat”, but never “— dog and the cat”). ""

I couldn't find a way to implement this functionality of embedding dropout efficiently. Are there any plans to incorporate these advances?"
14744,Quantization: error during quantizing inception v3 model,"Hi experts,

I met issues during quantizing retained inception v3 model. could someone help take a look? Thanks!

**Environment:** tensorflow-1.4.0, python 3.5.2(Anaconda 4.2.0)
**Issue description:**
I am using the downloaded inception v3 model, and try to follow the guide written by @petewarden [,](https://petewarden.com/2016/05/03/how-to-quantize-neural-networks-with-tensorflow/). always met the error below:
```
ValueError: No inputs to quantize for op: name: ""conv/Conv2D""
op: ""Conv2D""
input: ""Mul""
input: ""conv/conv2d_params""
...
```
my python script is as below:
```
from tensorflow.contrib.quantize.python import quantize_graph
from tensorflow import gfile, GraphDef,import_graph_def,get_default_graph

model_file=""classify_image_graph_def.pb""
with gfile.FastGFile(model_file,'rb') as f:
    graph_def = GraphDef()
    graph_def.ParseFromString(f.read())
    import_graph_def(graph_def,name='')

    graph=get_default_graph()
    q_graph=quantize_graph.create_eval_graph(graph)
    with gfile.FastGFile(""output.pb"",'wb') as f1:
        f1.write(q_graph.as_graph_def().SerializeToString())
```

"
14743,The API doc for tensorflow.keras.backend.set_learning_phase is wrong.,"### System information
- **TensorFlow version (use command below)**:
1.4.0
- **Python version**: 
Python 2.7.13 :: Anaconda, Inc.

### Describe the problem
When I implemented Custom Estimator API with tf.keras, I countered following error: 

```python
TypeError: `pred` must be a Tensor, a Variable, or a Python bool.
```

This happens if I set {0, 1} to tensorflow.keras.backend.set_learning_phase, and doesn't happen if I set {False, True} instead of {0, 1}. However, [the API doc](https://www.tensorflow.org/api_docs/python/tf/keras/backend/set_learning_phase) for tensorflow.keras.backend.set_learning_phase says the method is supposed to take {0, 1}. So, I think that the API doc should be modified.

### Source code / logs
- Source code (You can find more details [here](https://github.com/tensorflow/tensorflow/files/1490186/How.to.integrate.keras.into.Experiment.pdf))

```python
def inference(images, mode):
  if mode == tf.estimator.ModeKeys.TRAIN:
    tf.keras.backend.set_learning_phase(1) # this should be True
  else:
    tf.keras.backend.set_learning_phase(0) # this should be False
        
  model = tf.keras.models.Sequential()
  # Define input tensor in Keras world.
  model.add(tf.keras.layers.InputLayer(input_tensor=images))

  # The first convolutional layer.
  model.add(tf.keras.layers.Conv2D(
      filters=32, kernel_size=(3, 3), padding='same', activation='relu'))
  model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='same'))

  # The second convolutional layer.
  model.add(tf.keras.layers.Conv2D(
      filters=32, kernel_size=(3, 3), padding='same', activation='relu'))
  model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='same'))
  model.add(tf.keras.layers.Dropout(0.25))

  # The third convolutional layer
  model.add(tf.keras.layers.Conv2D(
      filters=64, kernel_size=(3, 3), padding='same', activation='relu'))

  # The fourth convolutional layer
  model.add(tf.keras.layers.Conv2D(
      filters=64, kernel_size=(3, 3), padding='same', activation='relu'))
  model.add(tf.keras.layers.Dropout(0.25))

  model.add(tf.keras.layers.Flatten())
  model.add(tf.keras.layers.Dense(512, activation='relu'))
  model.add(tf.keras.layers.Dropout(0.5))
  model.add(tf.keras.layers.Dense(NUM_CLASSES))
  logits = model.output
  return logits
```




- Error logs
```python
TypeError                                 Traceback (most recent call last)
<ipython-input-38-4dbe7b3f6667> in <module>()
     20   schedule='train_and_evaluate',
     21   run_config=run_config,
---> 22   hparams=hparams
     23 )
     24 

/usr/local/google/home/yaboo/Resources/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/learn_runner.pyc in run(experiment_fn, output_dir, schedule, run_config, hparams)
    216   schedule = schedule or _get_default_schedule(run_config)
    217 
--> 218   return _execute_schedule(experiment, schedule)
    219 
    220 

/usr/local/google/home/yaboo/Resources/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/learn_runner.pyc in _execute_schedule(experiment, schedule)
     44     logging.error('Allowed values for this experiment are: %s', valid_tasks)
     45     raise TypeError('Schedule references non-callable member %s' % schedule)
---> 46   return task()
     47 
     48 

/usr/local/google/home/yaboo/Resources/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/experiment.pyc in train_and_evaluate(self)
    623                   hooks=self._eval_hooks)
    624           ]
--> 625       self.train(delay_secs=0)
    626 
    627     # If the checkpoint_and_export flag and appropriate estimator configuration

/usr/local/google/home/yaboo/Resources/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/experiment.pyc in train(self, delay_secs)
    365     return self._call_train(input_fn=self._train_input_fn,
    366                             max_steps=self._train_steps,
--> 367                             hooks=self._train_monitors + extra_hooks)
    368 
    369   def evaluate(self, delay_secs=None, name=None):

/usr/local/google/home/yaboo/Resources/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/experiment.pyc in _call_train(self, _sentinel, input_fn, steps, hooks, max_steps)
    805                                    steps=steps,
    806                                    max_steps=max_steps,
--> 807                                    hooks=hooks)
    808     else:
    809       return self._estimator.fit(input_fn=input_fn,

/usr/local/google/home/yaboo/Resources/anaconda2/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.pyc in train(self, input_fn, hooks, steps, max_steps, saving_listeners)
    300 
    301     saving_listeners = _check_listeners_type(saving_listeners)
--> 302     loss = self._train_model(input_fn, hooks, saving_listeners)
    303     logging.info('Loss for final step: %s.', loss)
    304     return self

/usr/local/google/home/yaboo/Resources/anaconda2/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.pyc in _train_model(self, input_fn, hooks, saving_listeners)
    709       with ops.control_dependencies([global_step_read_tensor]):
    710         estimator_spec = self._call_model_fn(
--> 711             features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)
    712       # Check if the user created a loss summary, and add one if they didn't.
    713       # We assume here that the summary is called 'loss'. If it is not, we will

/usr/local/google/home/yaboo/Resources/anaconda2/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.pyc in _call_model_fn(self, features, labels, mode, config)
    692     if 'config' in model_fn_args:
    693       kwargs['config'] = config
--> 694     model_fn_results = self._model_fn(features=features, **kwargs)
    695 
    696     if not isinstance(model_fn_results, model_fn_lib.EstimatorSpec):

<ipython-input-29-a5666390b8b0> in cifar10_model_fn(features, labels, mode, params)
     10 
     11   # Calculate logits through CNN
---> 12   logits = inference(images, mode)
     13 
     14   # Get predictions

<ipython-input-37-23187df0ff6c> in inference(images, mode)
     20 
     21     # NOTE: Dropout is not working with model_fn in TF1.4
---> 22     model.add(tf.keras.layers.Dropout(0.25))
     23 
     24     # The third convolutional layer

/usr/local/google/home/yaboo/Resources/anaconda2/lib/python2.7/site-packages/tensorflow/python/keras/_impl/keras/models.pyc in add(self, layer)
    499           output_tensors=self.outputs)
    500     else:
--> 501       output_tensor = layer(self.outputs[0])
    502       if isinstance(output_tensor, list):
    503         raise TypeError('All layers in a Sequential model '

/usr/local/google/home/yaboo/Resources/anaconda2/lib/python2.7/site-packages/tensorflow/python/keras/_impl/keras/engine/topology.pyc in __call__(self, inputs, **kwargs)
    250     """"""
    251     # Actually call the layer (optionally building it).
--> 252     output = super(Layer, self).__call__(inputs, **kwargs)
    253 
    254     # Update learning phase info.

/usr/local/google/home/yaboo/Resources/anaconda2/lib/python2.7/site-packages/tensorflow/python/layers/base.pyc in __call__(self, inputs, *args, **kwargs)
    573         if in_graph_mode:
    574           self._assert_input_compatibility(inputs)
--> 575         outputs = self.call(inputs, *args, **kwargs)
    576 
    577         if outputs is None:

/usr/local/google/home/yaboo/Resources/anaconda2/lib/python2.7/site-packages/tensorflow/python/keras/_impl/keras/layers/core.pyc in call(self, inputs, training)
    116     if training is None:
    117       training = K.learning_phase()
--> 118     output = super(Dropout, self).call(inputs, training=training)
    119     if training is K.learning_phase():
    120       output._uses_learning_phase = True  # pylint: disable=protected-access

/usr/local/google/home/yaboo/Resources/anaconda2/lib/python2.7/site-packages/tensorflow/python/layers/core.pyc in call(self, inputs, training)
    298     return utils.smart_cond(training,
    299                             dropped_inputs,
--> 300                             lambda: array_ops.identity(inputs))
    301 
    302 

/usr/local/google/home/yaboo/Resources/anaconda2/lib/python2.7/site-packages/tensorflow/python/layers/utils.pyc in smart_cond(pred, fn1, fn2, name)
    201     raise TypeError('`fn2` must be callable.')
    202 
--> 203   pred_value = constant_value(pred)
    204   if pred_value is not None:
    205     if pred_value:

/usr/local/google/home/yaboo/Resources/anaconda2/lib/python2.7/site-packages/tensorflow/python/layers/utils.pyc in constant_value(pred)
    231     pred_value = tensor_util.constant_value(pred)
    232   else:
--> 233     raise TypeError('`pred` must be a Tensor, a Variable, or a Python bool.')
    234   return pred_value

TypeError: `pred` must be a Tensor, a Variable, or a Python bool.
```"
14742,foldl and foldr gives different results on gpu vs cpu in tensorflow 1.4,"

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: - Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: - Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: - source
- **TensorFlow version (use command below)**: v1.4.0-3-g5addbae, 1.4.0
- **Python version**:  2.7.12
- **Bazel version (if compiling from source)**:  0.7.0
- **GCC/Compiler version (if compiling from source)**: 5.4.0
- **CUDA/cuDNN version**: default 
- **GPU model and memory**: 1080ti (11GB)
- **Exact command to reproduce**:  
See code below

### Describe the problem
While testing foldl and foldr, I get the expected result when run on cpu, but get a zero result when running on gpu.  

### Source code / logs
import tensorflow as tf

with tf.device('/gpu:0'):
    els = tf.constant([1.0,2.0,3.0])
    f = tf.foldl(lambda a, x: a + x, els)

with tf.Session() as sess:
    print tf.GIT_VERSION,tf.VERSION
    print sess.run([els,f])

------------
Result: 
v1.4.0-3-g5addbae 1.4.0
[array([ 1.,  2.,  3.], dtype=float32), 0.0]

The last number should be 6.0, ie the sum of the input array.  I get this if I change the device to /cpu:0

"
14740,Tensorflow lite doesn't support Gather Op with multiple dims?,"Hello,

Following up this SO question which didn't get too much attention:
https://stackoverflow.com/questions/47321911/cant-convert-model-to-tensorflows-lite-format
I'm filling this form as a question/feature request.

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: YES
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS, builing and trying to use TF Lite for iOS
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: Latest, made a pull from HEAD 3 days ago
- **Python version**:  2.7.14
- **Bazel version (if compiling from source)**: 0.7.0
- **GCC/Compiler version (if compiling from source)**: clang 9.0.0
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: 

`bazel-bin/tensorflow/contrib/lite/toco/toco '--input_file=/Users/valentinradu/Playgrounds/char-rnn-tensorflow/remote_save/latest/graph_frz.pb' '--output_file=/Users/valentinradu/Playgrounds/char-rnn-tensorflow/remote_save/latest/graph.tflite' '--input_format=TENSORFLOW_GRAPHDEF' '--output_format=TFLITE' '--input_type=FLOAT' '--inference_type=FLOAT' '--input_shapes=1,128:1,50,50' '--input_arrays=state_in,data_in' '--output_arrays=state_out,data_out'`

### Describe the problem
I have a trained rnn that I try to use on mobile. Problem is, when I use toco to convert my .pb file to .tflite it fails with the following error message. Having a look over the source code that generated that exception, I think it's because of the toco's lack of support for multidimensional inputs. But I'm not sure. If so, will this be added later?

```
WARNING: Config values are not defined in any .rc file: opt.
INFO: Found 1 target...
Target //tensorflow/contrib/lite/toco:toco up-to-date:
  bazel-bin/tensorflow/contrib/lite/toco/toco
INFO: Elapsed time: 0.287s, Critical Path: 0.00s

INFO: Running command line: bazel-bin/tensorflow/contrib/lite/toco/toco '--input_file=/Users/valentinradu/Playgrounds/char-rnn-tensorflow/remote_save/latest/graph_frz.pb' '--output_file=/Users/valentinradu/Playgrounds/char-rnn-tensorflow/remote_save/latest/graph.tflite' '--input_format=TENSORFLOW_GRAPHDEF' '--output_format=TFLITE' '--input_type=FLOAT' '--inference_type=FLOAT' '--input_shapes=1,128:1,50,50' '--input_arrays=state_in,data_in' '--output_arrays=state_out,data_out'
2017-11-16 06:48:00.156091: I tensorflow/contrib/lite/toco/import_tensorflow.cc:937] Converting unsupported operation: Fill
2017-11-16 06:48:00.156811: I tensorflow/contrib/lite/toco/import_tensorflow.cc:937] Converting unsupported operation: Fill
2017-11-16 06:48:00.156821: I tensorflow/contrib/lite/toco/import_tensorflow.cc:937] Converting unsupported operation: Pack
2017-11-16 06:48:00.156829: I tensorflow/contrib/lite/toco/import_tensorflow.cc:937] Converting unsupported operation: Pack
2017-11-16 06:48:00.156841: I tensorflow/contrib/lite/toco/import_tensorflow.cc:937] Converting unsupported operation: Unpack
2017-11-16 06:48:00.156856: I tensorflow/contrib/lite/toco/import_tensorflow.cc:937] Converting unsupported operation: StridedSlice
2017-11-16 06:48:00.156872: I tensorflow/contrib/lite/toco/import_tensorflow.cc:937] Converting unsupported operation: StridedSlice
2017-11-16 06:48:00.157260: I tensorflow/contrib/lite/toco/import_tensorflow.cc:937] Converting unsupported operation: Pack
2017-11-16 06:48:00.157277: I tensorflow/contrib/lite/toco/import_tensorflow.cc:937] Converting unsupported operation: Pack
2017-11-16 06:48:00.158053: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 40 operators, 64 arrays (0 quantized)
2017-11-16 06:48:00.158141: F tensorflow/contrib/lite/toco/graph_transformations/propagate_fixed_sizes.cc:793] Check failed: indices_shape.dimensions_count() == 1 (2 vs. 1)
```

### Source code / logs
The repository I user to train the model can be found in full here:
https://github.com/valentinradu/char-rnn-tensorflow/blob/master/char_rnn/model.py
"
14739,Eager: Warn with invalid policy,"If a user accidentally writes `tfe.enable_eager_execution(tfe.DEVICE_PLACEMENT_WARN)` instead of the correct `tfe.enable_eager_execution(device_policy=tfe.DEVICE_PLACEMENT_WARN)`, they won't get an error until later in their program.

For example, `tfe.num_gpus()` after  the incorrect enable call produces

```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-8-71d6509178f5> in <module>()
----> 1 tfe.num_gpus()

~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/context.py in num_gpus()
    458     The number of available GPU devices.
    459   """"""
--> 460   return context().num_gpus()

~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/context.py in num_gpus(self)
    286   def num_gpus(self):
    287     """"""The number of GPUs available to execute operations.""""""
--> 288     self._initialize_handle_and_devices()
    289     return self._num_gpus
    290 

~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/context.py in _initialize_handle_and_devices(self)
    121         with errors.raise_exception_on_not_ok_status() as status:
    122           if self._config is not None:
--> 123             config_str = self._config.SerializeToString()
    124             pywrap_tensorflow.TFE_ContextOptionsSetConfig(
    125                 opts, config_str, len(config_str), status)

AttributeError: 'int' object has no attribute 'SerializeToString'
```

I'd think it makes more sense to throw an error immediately after the incorrect `enable_eager_execution`. 

This is on `master` (ab00df9)."
14736,Does Tensorflow support Graphic for AMD (GPU also)  like NVIDIA (GPU),"Dear All

I have laptop lenovo G50-80 I7 5500 with AMD RADEON R5 M230-2GB for graphic (it is also gpu based on this link ( https://www.futuremark.com/hardware/gpu/AMD+Radeon+R5+M230/review ), does tensorflow support this amd for computing  the same like what tensorflow did with GPU from NVIDIA ?. if it has to be configured from the source, what is the setting of tensorflow that when i compile it it will run the gpu?

Thx"
14733,tf.contrib.ffmpeg.decode_audio console flood,"When we evaluate the tensor returned by `tensorflow.contrib.ffmpeg.decode_audio()`, the ffmpeg log shows up in the terminal, leading to a flood of messages when decoding a large number of files.

Asked [here](https://stackoverflow.com/questions/47361507/tf-contrib-ffmpeg-decode-audio-verbosity) as well. I could not find an easy way such as an environment variable for ffmpeg to turn off the output log, there is only a command-line argument `loglevel` but TF's `decode_audio()` does not support it.

Currently using `ffmpeg 3.4 (gcc 7.2.0)` and `tensorflow 1.4.0` on linux.

Issue filed as instructed [here](https://github.com/tensorflow/tensorflow/issues/11339#issuecomment-345836714). @rryan @fredbertsch "
14732,Eager: Eager execution of tf.data pipelines,"# System information
Tensorflow version:

1.5.0-dev20171120

Python version:

python 3.6.3 |Anaconda, Inc.| (default, Nov  8 2017, 15:10:56) [MSC v.1900 64 bit (AMD64)]

# Problem

When debugging, calling the `numpy()` method on a `Tensor` object results in `AttributeError: 'Tensor' object has no attribute 'numpy' ` in certain situations.

# Steps to reproduce

1.  Put this code in a script:


```
import tensorflow as tf
import tensorflow.contrib.eager as tfe
import numpy as np
import tensorflow as tf
from collections import defaultdict, Counter

tfe.enable_eager_execution()

class_probs = dict(
    a=0.15,
    b=0.3,
    c=0.8,
    d=0.9,
    e=0.2,
    f=0.02
)
num_classes = len(class_probs)

class_probs = {k: v / sum(class_probs.values()) for k, v in class_probs.items()}
class_mapping = {n: i for i, n in enumerate(class_probs.keys())}

class_names = list(class_probs.keys())
class_weights = list(class_probs.values())
sampled_dataset = np.random.choice(class_names, size=1000, p=class_weights)

dataset_data = defaultdict(list)
for i, d in enumerate(sampled_dataset):
    dataset_data['class_name'].append(d)
    dataset_data['class_id'].append(class_mapping[d])
    dataset_data['data'].append(np.array([i]))
    dataset_data['class_prob'].append(class_probs[d])

    dataset_data['class_target_prob'].append(1 / num_classes)

for k, v in dataset_data.items():
    dataset_data[k] = np.array(dataset_data[k])

class_counts = Counter(sampled_dataset)

oversampling_coef = 0.9


def oversample_classes(example):
    """"""
    Returns the number of copies of given example
    """"""
    class_prob = example['class_prob']
    class_target_prob = example['class_target_prob']
    prob_ratio = tf.cast(class_target_prob / class_prob, dtype=tf.float32)

    prob_ratio = prob_ratio ** oversampling_coef

    prob_ratio = tf.maximum(prob_ratio, 1)
    # Breakpoint 1
    repeat_count = tf.floor(prob_ratio)

    repeat_residual = prob_ratio - repeat_count  # a number between 0-1
    residual_acceptance = tf.less_equal(
        tf.random_uniform([], dtype=tf.float32), repeat_residual
    )

    residual_acceptance = tf.cast(residual_acceptance, tf.int64)
    repeat_count = tf.cast(repeat_count, dtype=tf.int64)

    return repeat_count + residual_acceptance


dataset = tf.data.Dataset.from_tensor_slices(dict(dataset_data))

dataset = dataset.flat_map(
    lambda x: tf.data.Dataset.from_tensors(x).repeat(oversample_classes(x))
)

i = tfe.Iterator(dataset)
x = i.next()['class_id']

# Breakpoint 2
print('end')
```

2. Insert the breakpoints in the lines following the comments Breakpoint 1 and Breakpoint 2

3. Debug the script

4. When breakpoint 1 is reached, evaluate the following:
     `prob_ratio.numpy()`
     This will result in the attribute error message.

5. When breakpoint 2 is reached, evaluate the following:
     `x.numpy()`
     This will not result in the attribute error message."
14731,Tensorflow lite - object detection - ssd-mobilenet-v1,"Hi guys,

I have trained a custom ssd-mobilenet-v1 (300x300 input) and currently running it via Tensorflow Android demo (Tensorflow mobile). I would love to convert this model to the lite format and possibly quantize it and run it via Tensorflow Lite to see how much has the performance improved. Currently the inference takes around 400-500ms on Google Pixel (version 1). 

Could you please let me know what's the best way to deploy my custom model for object detection?

Thank you very much in advance!

Martin Peniak "
14729,Unhelpful error for dynamic_rnn in version 1.4.0,"This code:
```python
import tensorflow as tf

x = tf.constant([
		[[0,0],[5,0],[1,0],[1,0],[2,3],[4,0]],
		[[0,0],[0,0],[1,3],[2,0],[0,0],[0,0]]
	], dtype=tf.int32) #changing this to tf.float32 solves the problem


cell = tf.nn.rnn_cell.LSTMCell(num_units=15) 
initial_state = cell.zero_state(tf.shape(x)[0], dtype=tf.float32)
outputs, state = tf.nn.dynamic_rnn(cell, x, initial_state=initial_state, dtype=tf.float32)

init_op = tf.group(tf.global_variables_initializer(),
		tf.local_variables_initializer())

with tf.Session() as sess:
	sess.run(init_op)
	print(sess.run([outputs, state]))
```
Does not work, because the inputs to the LSTM are integers and they need to be float. However, in version 1.4.0 I get this error:
```
ValueError: Initializer for variable rnn/lstm_cell/kernel/ is from inside a control-flow construct, such as a loop or conditional. When creating a variable inside a loop or conditional, use a lambda as the initializer.
```
Which has nothing to do with what is wrong with the code. Version 1.2.0 however, generates this error which correctly refers to the problem:
```
TypeError: Tensors in list passed to 'values' of 'ConcatV2' Op have types [int32, float32] that don't all match.
```
"
14726,Make a copy of a model,"Hi,  is there a canonical method in Tensorflow for this? For example, in Keras, we can use keras.models.clone_model for this purpose.  I though that model's copy would be such a nice feature, since copy.deepcopy does not work for me in Tensorflow. 
I want to copy weights from this model to another model of identical structure,  and I do not want to save a model then restore it to another instance for this situation. Specifically, the situation at every iteration we train model1 then make model2 as a copy of current model1, adding noise to model1 parameters and sample from model2 and then use these samples to update model1.
```
Class Model1(object):
    def method1(self):
        ....
    def method2(self):
        ....
```"
14725,NameError: global name 'xrange' is not defined in Python 3 - and solution proposal,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04 Docker image
- **TensorFlow installed from (source or binary)**: pip install
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 3.6
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**: https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/contrib/boosted_trees/examples/boston.py


You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Running the example code under python 3.6 in Docker environment I got xrange error: NameError: global name 'xrange' is not defined in Python 3

I propose to change every xrange to range under the 3.x versions:
# patch for xrange
find /opt/conda/lib/python3.6/site-packages/tensorflow/contrib/boosted_trees -type f -print0 | xargs -0 sed -i 's/ xrange(/ range(/g'


### Source code / logs
NameError: global name 'xrange' is not defined in Python 3
"
14724,Using GPU mnist_deep.py throws OOM when allocating tensor with shape...,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No, I am using the mnist_deep.py with tensorflow 1.4.0
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 & Tensorflow 1.4.0 binary installation, Linux Ubuntu 16.04 & Tensorflow 1.4.0 built form source
- **TensorFlow installed from (source or binary)**: Windows 10 installed with TF binary, Linux Ubuntu 16.04 TF built from source
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 3.6.2 on Windows 10, 3.5.2 on Linux
- **Bazel version (if compiling from source)**: 0.7.0
- **GCC/Compiler version (if compiling from source)**: 5.4.0
- **CUDA/cuDNN version**: CUDA 8.0, CuDNN 6.0 
- **GPU model and memory**: For Windows 10: NVIDIA GeForce 940MX, For Linux: HW similar to NVIDIA Jetson TX2
- **Exact command to reproduce**: python mnist_deep.py

### Describe the problem
The mnist_deep.py sample given in Tensorflow examples/tutorials works fine when run on CPU. But when the same example is run using GPU, an OOM occurs when trying to allocate memory for tensor (specifically 10000) in both the cases. It does not matter if one increases/decreases the number of iterations to train the model, the OOM occurs even after a single iteration is executed.

The other examples like mnist.py, mnist_softmax.py, mnist_softmax_xla.py, etc. runs properly without any issues on the GPU. I have also tried to use the config_proto options but none of them seem to help.

### Source code / logs
************************************************
#### Windows 10:
tensor_name=""edge_75_Mean_1"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]

Caused by op 'conv1/Conv2D', defined at:
  File ""mnist_deep.py"", line 176, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\python\platform\app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""mnist_deep.py"", line 137, in main
    y_conv, keep_prob = deepnn(x)
  File ""mnist_deep.py"", line 63, in deepnn
    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)
  File ""mnist_deep.py"", line 105, in conv2d
    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\python\ops\gen_nn_ops.py"", line 630, in conv2d
    data_format=data_format, name=name)
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\python\framework\ops.py"", line 2956, in create_op
    op_def=op_def)
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\python\framework\ops.py"", line 1470, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[10000,32,28,28]
         [[Node: conv1/Conv2D = Conv2D[T=DT_FLOAT, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](reshape/Reshape, conv1/Variable/read)]]
         [[Node: Mean_1/_7 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_75_Mean_1"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]
************************************************
####Linux:
tensor_name=""edge_75_Mean_1"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]

Caused by op 'conv1/Conv2D', defined at:
  File ""mnist_deep.py"", line 176, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\python\platform\app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""mnist_deep.py"", line 137, in main
    y_conv, keep_prob = deepnn(x)
  File ""mnist_deep.py"", line 63, in deepnn
    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)
  File ""mnist_deep.py"", line 105, in conv2d
    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\python\ops\gen_nn_ops.py"", line 630, in conv2d
    data_format=data_format, name=name)
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\python\framework\ops.py"", line 2956, in create_op
    op_def=op_def)
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\python\framework\ops.py"", line 1470, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[10000,32,28,28]
         [[Node: conv1/Conv2D = Conv2D[T=DT_FLOAT, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](reshape/Reshape, conv1/Variable/read)]]
         [[Node: Mean_1/_7 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_75_Mean_1"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]
************************************************

Further detailed logs can be attached if needed. Your help and pointers to solve this will be much appreciated."
14720,ImageUtils.convertYUV420SPToARGB8888 resulting distorted image,"


Hi @andrewharp 

I did some modification in TF detect android app to detect person from loaded picture rather than clicking it by camera(Not using cameraActivity).

Everything is working fine except the function named ImageUtils.convertYUV420SPToARGB8888. This function returns distorted image (please find attachment)

actual image:
![actual_image](https://user-images.githubusercontent.com/2331214/33017067-f6c5dd42-ce16-11e7-9cb0-7827cf490c8b.png)

After converting image from YUV 4:2:0 to ARGB:
![converted_image](https://user-images.githubusercontent.com/2331214/33017069-f6f60e2c-ce16-11e7-9772-89d0a7d22612.png)

Sharing part of code below:

            newbitmap = Bitmap.createScaledBitmap(bitmap, 640, 480, false);
            ByteArrayOutputStream output = new ByteArrayOutputStream();
            newbitmap.compress(Bitmap.CompressFormat.JPEG, 100, output);
            imgbytes = output.toByteArray();

            imageConverter =
                new Runnable() {
                    @Override
                    public void run() {
                        ImageUtils.convertYUV420SPToARGB8888(imgbytes, previewWidth, previewHeight, rgbBytes);
                    }
                };"
14719,Tensorflow Lite demo app with inception-v3/Mobilenet_v1 (float) model crashes,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 14.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 14.04
- **Python version**: 3.4.3
- **Bazel version (if compiling from source)**: 0.5.4


### Describe the problem
Device: Galaxy S8
I downloaded the ""Inception V3 Slim 2016"" from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/models.md . I pushed the imagenet_2015_label_strings.txt and the ""inceptionv3_non_slim_2015.tflite"" to the asset folder

I edited the ImageClassifier.java of tflite demo app. The changes are the followings:
private static final String MODEL_PATH = ""/inceptionv3_non_slim_2015.tflite"";
static final int DIM_IMG_SIZE_X = 299;
static final int DIM_IMG_SIZE_Y = 299;

The app hangs when it starts! (I could run the app with the default mobilenet quantized graph).
Similar is the case with mobilenet_v1_224_Float graph as well (the app hangs or crashes). I assume, the float model graph is not yet supported by TF Lite. However, in the documentation its written that it does support float for most operations. I am thinking the error is due to image pre-processing output and input size of float model grpah. The error log is stated below:

The Error log:
11-21 14:31:43.034 2111-2416/android.example.com.tflitecamerademo E/AndroidRuntime: FATAL EXCEPTION: CameraBackground
                                                                                    Process: android.example.com.tflitecamerademo, PID: 2111
                                                                                    java.lang.IllegalArgumentException: Failed to get input dimensions. 0-th input should have 1072812 bytes, but found 268203 bytes.
                                                                                        at org.tensorflow.lite.NativeInterpreterWrapper.getInputDims(Native Method)
                                                                                        at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:82)
                                                                                        at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:112)
                                                                                        at org.tensorflow.lite.Interpreter.run(Interpreter.java:93)
                                                                                        at com.example.android.tflitecamerademo.ImageClassifier.classifyFrame(ImageClassifier.java:112)
                                                                                        at com.example.android.tflitecamerademo.Camera2BasicFragment.classifyFrame(Camera2BasicFragment.java:663)
                                                                                        at com.example.android.tflitecamerademo.Camera2BasicFragment.-wrap0(Camera2BasicFragment.java)
                                                                                        at com.example.android.tflitecamerademo.Camera2BasicFragment$4.run(Camera2BasicFragment.java:558)
                                                                                        at android.os.Handler.handleCallback(Handler.java:751)
                                                                                        at android.os.Handler.dispatchMessage(Handler.java:95)
                                                                                        at android.os.Looper.loop(Looper.java:154)
                                                                                        at android.os.HandlerThread.run(HandlerThread.java:61)


### Additional Questions:
1) On the app the the tensorflow lite graph format is "".tflite"". However, on the documentation https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/toco/g3doc/cmdline_examples.md the format is written as "".lite""


"
14718,tensorflow/contrib/lite/download_dependencies.sh does not finish without error!,"for tensorflow/contrib/lite/download_dependencies.sh, I can not run successfully with commit 049a34d692095b7e137bca27d2445415314ceaf7.
And I rollback to 4b4b51cdd9e8c3c748b76dd8649bcd5556e84d76, everything is good."
14717,Coverage for NMT,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 14.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.3
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: NA
- **GCC/Compiler version (if compiling from source)**: 4.8.4
- **CUDA/cuDNN version**: 8.0
- **GPU model and memory**: NVIDIA TITAN X (12GB)
- **Exact command to reproduce**:  NA

Modelling coverage is a very useful feature in NMT to reduce over-translations.

Ref.: 
https://www.aclweb.org/anthology/P/P16/P16-1008.pdf,
https://arxiv.org/pdf/1704.04368.pdf

Is this feature available right now or, if not, how can I hack the current attention mechanism (say, Bahadanau) to add this feature ? "
14716,"failed to convert model with ""FusedBatchNorm"" to TFLITE format","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
14.04
- **TensorFlow installed from (source or binary)**:
both source and binary tried
- **TensorFlow version (use command below)**:
1.4
- **Python version**: 
2.7
- **Bazel version (if compiling from source)**:
7
- **GCC/Compiler version (if compiling from source)**:
4.8
- **CUDA/cuDNN version**:
8.0-5.1
- **GPU model and memory**:
gtx1080-8G
- **Exact command to reproduce**:


###Problem###
My original model is with node ""FusedBatchNorm"", when I run the script  ```bazel build tensorflow/contrib/lite/toco:toco``` and ```bazel run --config=opt tensorflow/contrib/lite/toco:toco -- --input_file=/home/wz/Desktop/rt-mobilenet.pb --input_format=TENSORFLOW_GRAPHDEF  --output_format=TFLITE --output_file=/home/wz/Desktop/tflite-pose.lite --inference_type=FLOAT --input_type=FLOAT --input_arrays=image --output_arrays=Openpose/concat_stage7 --input_shapes=1,368,368,3``` 
Everything seems fine, but the result file is empty. And I traced the code, founding that code returned at file 'resolve_constant_binary' 's function 'EvaluateBinaryOperatorOnConstantInputs'.
My model can be get [here](https://www.dropbox.com/s/09xivpuboecge56/mobilenet_0.75_0.50_model-388003.zip?dl=0).
God help me! Thanks a lot!
"
14715,where is mobile  ssd model?,where is mobile  ssd model? where is it.where  is  mobile net model??
14713,Estimator API and transfer learning/fine-tuning,"I've been using the Estimator API with the model_fn and input_fn as shown in the official examples (https://github.com/tensorflow/models/blob/master/official/resnet/cifar10_main.py for instance).

This all looks great and wonderful. However, I'm now facing an issue for going further with it. I'd like to use a model trained on a dataset and transfer it to another dataset. In practice, I would like to take the weights from the trained model up to the softmax layer and only initialize randomly this final layer. Then, I can do fine-tuning on the new dataset, which has different labels for instance.

I haven't found a way to do what I want. Is it something missing in the interface? Can we have something  like a variable list to restore from a checkpoint and some other not? Ideally, it would be also good to specify variables to be frozen. Does that all make sense?"
14712,cmake error on MacOS,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS 10.12.6
- **TensorFlow installed from (source or binary)**: source
- **Python version**: python 3.6.2
- **TensorFlow version**: master
- **Bazel version**: 0.7.0-homebrew. Build timestamp: 1510456291
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **GCC/Compiler version (if compiling from source)**: Apple LLVM version 9.0.0 (clang-900.0.38)
- **Exact command to reproduce**:
```
# in tensorflow directory
cd tensorflow/contrib/cmake
mkdir build
cd build
cmake .. -DCMAKE_BUILD_TYPE=Release -DPYTHON_EXECUTABLE=/usr/local/bin/python3
make tf_tutorials_example_trainer
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I'm following the instructions [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/cmake/README.md) to build using cmake on Mac. However during make, the following error is thrown.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

```
# ...
Scanning dependencies of target tf_tutorials_example_trainer
[100%] Building CXX object CMakeFiles/tf_tutorials_example_trainer.dir/Users/kevenwang/VirtualBoxShared/another_tf/tensorflow/cc/tutorials/example_trainer.cc.o
[100%] Linking CXX executable tf_tutorials_example_trainer
Undefined symbols for architecture x86_64:
  ""_ares_cancel"", referenced from:
      on_readable_cb(grpc_exec_ctx*, void*, grpc_error*) in libgrpc_unsecure.a(grpc_ares_ev_driver_posix.cc.o)
      on_writable_cb(grpc_exec_ctx*, void*, grpc_error*) in libgrpc_unsecure.a(grpc_ares_ev_driver_posix.cc.o)
  ""_ares_destroy"", referenced from:
      grpc_ares_ev_driver_unref(grpc_ares_ev_driver*) in libgrpc_unsecure.a(grpc_ares_ev_driver_posix.cc.o)
  ""_ares_free_data"", referenced from:
      on_srv_query_done_cb(void*, int, int, unsigned char*, int) in libgrpc_unsecure.a(grpc_ares_wrapper.cc.o)
      on_txt_done_cb(void*, int, int, unsigned char*, int) in libgrpc_unsecure.a(grpc_ares_wrapper.cc.o)
  ""_ares_gethostbyname"", referenced from:
      grpc_dns_lookup_ares_impl(grpc_exec_ctx*, char const*, char const*, char const*, grpc_pollset_set*, grpc_closure*, grpc_lb_addresses**, bool, char**) in libgrpc_unsecure.a(grpc_ares_wrapper.cc.o)
      on_srv_query_done_cb(void*, int, int, unsigned char*, int) in libgrpc_unsecure.a(grpc_ares_wrapper.cc.o)
  ""_ares_getsock"", referenced from:
      grpc_ares_notify_on_event_locked(grpc_exec_ctx*, grpc_ares_ev_driver*) in libgrpc_unsecure.a(grpc_ares_ev_driver_posix.cc.o)
  ""_ares_inet_ntop"", referenced from:
      on_hostbyname_done_cb(void*, int, int, hostent*) in libgrpc_unsecure.a(grpc_ares_wrapper.cc.o)
  ""_ares_init"", referenced from:
      _grpc_ares_ev_driver_create in libgrpc_unsecure.a(grpc_ares_ev_driver_posix.cc.o)
     (maybe you meant: _grpc_ares_init, _grpc_resolver_dns_ares_init )
  ""_ares_library_cleanup"", referenced from:
      _grpc_ares_cleanup in libgrpc_unsecure.a(grpc_ares_wrapper.cc.o)
  ""_ares_library_init"", referenced from:
      _grpc_ares_init in libgrpc_unsecure.a(grpc_ares_wrapper.cc.o)
  ""_ares_parse_srv_reply"", referenced from:
      on_srv_query_done_cb(void*, int, int, unsigned char*, int) in libgrpc_unsecure.a(grpc_ares_wrapper.cc.o)
  ""_ares_parse_txt_reply_ext"", referenced from:
      on_txt_done_cb(void*, int, int, unsigned char*, int) in libgrpc_unsecure.a(grpc_ares_wrapper.cc.o)
  ""_ares_process_fd"", referenced from:
      on_readable_cb(grpc_exec_ctx*, void*, grpc_error*) in libgrpc_unsecure.a(grpc_ares_ev_driver_posix.cc.o)
      on_writable_cb(grpc_exec_ctx*, void*, grpc_error*) in libgrpc_unsecure.a(grpc_ares_ev_driver_posix.cc.o)
  ""_ares_query"", referenced from:
      grpc_dns_lookup_ares_impl(grpc_exec_ctx*, char const*, char const*, char const*, grpc_pollset_set*, grpc_closure*, grpc_lb_addresses**, bool, char**) in libgrpc_unsecure.a(grpc_ares_wrapper.cc.o)
  ""_ares_search"", referenced from:
      grpc_dns_lookup_ares_impl(grpc_exec_ctx*, char const*, char const*, char const*, grpc_pollset_set*, grpc_closure*, grpc_lb_addresses**, bool, char**) in libgrpc_unsecure.a(grpc_ares_wrapper.cc.o)
  ""_ares_set_servers_ports"", referenced from:
      grpc_dns_lookup_ares_impl(grpc_exec_ctx*, char const*, char const*, char const*, grpc_pollset_set*, grpc_closure*, grpc_lb_addresses**, bool, char**) in libgrpc_unsecure.a(grpc_ares_wrapper.cc.o)
  ""_ares_strerror"", referenced from:
      grpc_dns_lookup_ares_impl(grpc_exec_ctx*, char const*, char const*, char const*, grpc_pollset_set*, grpc_closure*, grpc_lb_addresses**, bool, char**) in libgrpc_unsecure.a(grpc_ares_wrapper.cc.o)
      _grpc_ares_init in libgrpc_unsecure.a(grpc_ares_wrapper.cc.o)
      on_hostbyname_done_cb(void*, int, int, hostent*) in libgrpc_unsecure.a(grpc_ares_wrapper.cc.o)
      on_srv_query_done_cb(void*, int, int, unsigned char*, int) in libgrpc_unsecure.a(grpc_ares_wrapper.cc.o)
      on_txt_done_cb(void*, int, int, unsigned char*, int) in libgrpc_unsecure.a(grpc_ares_wrapper.cc.o)
      _grpc_ares_ev_driver_create in libgrpc_unsecure.a(grpc_ares_ev_driver_posix.cc.o)
ld: symbol(s) not found for architecture x86_64
clang: error: linker command failed with exit code 1 (use -v to see invocation)
make[3]: *** [tf_tutorials_example_trainer] Error 1
make[2]: *** [CMakeFiles/tf_tutorials_example_trainer.dir/all] Error 2
make[1]: *** [CMakeFiles/tf_tutorials_example_trainer.dir/rule] Error 2
```"
14711,//tensorflow/python:session_list_devices_test fails on X86,"### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
     Ubuntu 16.04 
- **TensorFlow installed from (source or binary)**:
      Installed from source
- **TensorFlow version (use command below)**:
      TF-1.3.1
- **Python version**:
      Python 2.7.12
- **Bazel version (if compiling from source)**:
      Bazel - 0.5.4
- **CUDA/cuDNN version**:
      NA
- **GPU model and memory**:
      NA
- **Exact command to reproduce**:
     ` bazel test --config=opt  //tensorflow/python:session_list_devices_test `

### Describe the problem
Following 3 sub-tests are failing on Ubuntu:16.04 (x86) with the assertion errors
1) FAIL: testListDevices (__main__.SessionListDevicesWithCApiTest)
https://github.com/tensorflow/tensorflow/blob/v1.3.1/tensorflow/python/client/session_list_devices_test.py#L39
 `self.assertGreaterEqual(1, len(devices), devices)` .....# Getting AssertionError due to: ""1"" unexpectedly not greater than or equal to ""3""  
2) FAIL: testListDevicesGrpcSession (__main__.SessionListDevicesWithCApiTest)
https://github.com/tensorflow/tensorflow/blob/v1.3.1/tensorflow/python/client/session_list_devices_test.py#L47
 `self.assertGreaterEqual(1, len(devices), devices`) .....#  Getting AssertionError due to: ""1"" unexpectedly not greater than or equal to ""3""  
3) FAIL: testListDevicesClusterSpecPropagation (__main__.SessionListDevicesWithCApiTest)
https://github.com/tensorflow/tensorflow/blob/v1.3.1/tensorflow/python/client/session_list_devices_test.py#L66
 `self.assertGreaterEqual(2, len(devices), devices)` ..... #  Getting AssertionError due to: ""2"" unexpectedly not greater than or equal to ""6""

Is this is a known failure (can we ignore ) or I am missing something here ?. Please provide your comments on this.Thanks!
### Source code / logs
```

$  bazel test --config=opt  //tensorflow/python:session_list_devices_test

2017-11-20 08:35:46.791667: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:343] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
2017-11-20 08:35:46.795931: I tensorflow/core/distributed_runtime/master_session.cc:998] Start master session 026f646fb0c59742 with config:
F.
======================================================================
FAIL: testListDevices (__main__.SessionListDevicesTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/0cb601a163d4c4c6c065cdaa9629611b/execroot/tensorflow/bazel-out/local-opt/bin/tensorflow/python/session_list_devices_test.runfiles/org_tensorflow/tensorflow/python/client/session_list_devices_test.py"", line 39, in testListDevices
    self.assertGreaterEqual(1, len(devices), devices)
AssertionError: [_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 42115744), _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_EXEC:0, XLA_EXEC, 42116496), _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 42116608)]

======================================================================
FAIL: testListDevicesClusterSpecPropagation (__main__.SessionListDevicesTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/0cb601a163d4c4c6c065cdaa9629611b/execroot/tensorflow/bazel-out/local-opt/bin/tensorflow/python/session_list_devices_test.runfiles/org_tensorflow/tensorflow/python/client/session_list_devices_test.py"", line 66, in testListDevicesClusterSpecPropagation
    self.assertGreaterEqual(2, len(devices), devices)
AssertionError: [_DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 42238272), _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_EXEC:0, XLA_EXEC, 42238864), _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 42238896), _DeviceAttributes(/job:worker/replica:0/task:1/device:CPU:0, CPU, 42238928), _DeviceAttributes(/job:worker/replica:0/task:1/device:XLA_EXEC:0, XLA_EXEC, 42238960), _DeviceAttributes(/job:worker/replica:0/task:1/device:XLA_CPU:0, XLA_CPU, 42238992)]

======================================================================
FAIL: testListDevicesGrpcSession (__main__.SessionListDevicesTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/0cb601a163d4c4c6c065cdaa9629611b/execroot/tensorflow/bazel-out/local-opt/bin/tensorflow/python/session_list_devices_test.runfiles/org_tensorflow/tensorflow/python/client/session_list_devices_test.py"", line 47, in testListDevicesGrpcSession
    self.assertGreaterEqual(1, len(devices), devices)
AssertionError: [_DeviceAttributes(/job:local/replica:0/task:0/device:CPU:0, CPU, 42226672), _DeviceAttributes(/job:local/replica:0/task:0/device:XLA_EXEC:0, XLA_EXEC, 41891296), _DeviceAttributes(/job:local/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 41891328)]

======================================================================
FAIL: testListDevices (__main__.SessionListDevicesWithCApiTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/0cb601a163d4c4c6c065cdaa9629611b/execroot/tensorflow/bazel-out/local-opt/bin/tensorflow/python/session_list_devices_test.runfiles/org_tensorflow/tensorflow/python/client/session_list_devices_test.py"", line 39, in testListDevices
    self.assertGreaterEqual(1, len(devices), devices)
AssertionError: [_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 42268048), _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_EXEC:0, XLA_EXEC, 42268800), _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 42268912)]

======================================================================
FAIL: testListDevicesClusterSpecPropagation (__main__.SessionListDevicesWithCApiTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/0cb601a163d4c4c6c065cdaa9629611b/execroot/tensorflow/bazel-out/local-opt/bin/tensorflow/python/session_list_devices_test.runfiles/org_tensorflow/tensorflow/python/client/session_list_devices_test.py"", line 66, in testListDevicesClusterSpecPropagation
    self.assertGreaterEqual(2, len(devices), devices)
AssertionError: [_DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 42313280), _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_EXEC:0, XLA_EXEC, 42313872), _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 42313904), _DeviceAttributes(/job:worker/replica:0/task:1/device:CPU:0, CPU, 42313936), _DeviceAttributes(/job:worker/replica:0/task:1/device:XLA_EXEC:0, XLA_EXEC, 42313968), _DeviceAttributes(/job:worker/replica:0/task:1/device:XLA_CPU:0, XLA_CPU, 42314000)]

======================================================================
FAIL: testListDevicesGrpcSession (__main__.SessionListDevicesWithCApiTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/0cb601a163d4c4c6c065cdaa9629611b/execroot/tensorflow/bazel-out/local-opt/bin/tensorflow/python/session_list_devices_test.runfiles/org_tensorflow/tensorflow/python/client/session_list_devices_test.py"", line 47, in testListDevicesGrpcSession
    self.assertGreaterEqual(1, len(devices), devices)
AssertionError: [_DeviceAttributes(/job:local/replica:0/task:0/device:CPU:0, CPU, 42260656), _DeviceAttributes(/job:local/replica:0/task:0/device:XLA_EXEC:0, XLA_EXEC, 42260688), _DeviceAttributes(/job:local/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 42331824)]

----------------------------------------------------------------------
Ran 8 tests in 1.857s

FAILED (failures=6)
swig/python detected a memory leak of type 'int64_t *', no destructor found.
swig/python detected a memory leak of type 'int64_t *', no destructor found.
swig/python detected a memory leak of type 'int64_t *', no destructor found.
swig/python detected a memory leak of type 'int64_t *', no destructor found.
swig/python detected a memory leak of type 'int64_t *', no destructor found.
swig/python detected a memory leak of type 'int64_t *', no destructor found.
swig/python detected a memory leak of type 'int64_t *', no destructor found.
swig/python detected a memory leak of type 'int64_t *', no destructor found.
swig/python detected a memory leak of type 'int64_t *', no destructor found.
swig/python detected a memory leak of type 'int64_t *', no destructor found.
swig/python detected a memory leak of type 'int64_t *', no destructor found.
swig/python detected a memory leak of type 'int64_t *', no destructor found.
swig/python detected a memory leak of type 'int64_t *', no destructor found.
swig/python detected a memory leak of type 'int64_t *', no destructor found.
swig/python detected a memory leak of type 'int64_t *', no destructor found.
swig/python detected a memory leak of type 'int64_t *', no destructor found.
swig/python detected a memory leak of type 'int64_t *', no destructor found.
swig/python detected a memory leak of type 'int64_t *', no destructor found.
swig/python detected a memory leak of type 'int64_t *', no destructor found.
swig/python detected a memory leak of type 'int64_t *', no destructor found.
swig/python detected a memory leak of type 'int64_t *', no destructor found.
swig/python detected a memory leak of type 'int64_t *', no destructor found.
swig/python detected a memory leak of type 'int64_t *', no destructor found.
swig/python detected a memory leak of type 'int64_t *', no destructor found.

```"
14708,android library not loading saved model due to invalid graphdef error.,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
YES
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 16.x
- **TensorFlow installed from (source or binary)**:
Using VirtualEnv as described on website
- **TensorFlow version (use command below)**:
1.4 (also tried 1.0, and 1.2)
- **Python version**: 
2.7.1.2
- **Bazel version (if compiling from source)**:
NA
- **GCC/Compiler version (if compiling from source)**:
NA
- **CUDA/cuDNN version**:
NA
- **GPU model and memory**:
NA
- **Exact command to reproduce**:

I have a bug where a frozen model will not load in an android app. The code is at

https://github.com/cooledge/Chatbot

In ChatActivity on line 39 I load an model that is trivial and built by running ""cd nn; python ./train_noop.py --epochs 5 --save_words --freeze"". That loads thus showing the Android app is setup correctly for loading models. On line 40 I load a model that I got from your tensorflow demo. That also loads showing that complex models can be loaded. On line 41 I load the model that I actually want to load and that fails with the error invalid GraphDef. That model is build by running 'cd nn; python ./train.py --epochs 5 --save_words --freeze"". Why is that not loading. It loads under python on ubuntu and can generate samples. The bug is repoducable by running the app after syncing you don't need to run the training.

"
14706,failed to bazel build tensorflow lite ,"build tensorflow lite  demo with ""bazel --output_base=/data/wjx/bazel/tensorflow/output --output_user_root=/data/wjx/bazel/tensorflow build --cxxopt='--std=c++11'  //tensorflow/contrib/
lite/java/demo/app/src/main:TfLiteCameraDemo""

Environment:
OS: ubuntu 16.04
tf version: tensorflow 1.4 master
python:2.7.12
AndroidSDK: 27 BuildToolsVersion: 27.0.1
NDK: android-ndk-r14e

ERROR: /data/wjx/bazel/tensorflow/output/external/androidsdk/com.android.support/BUILD:4277:1: Merging Android resources for @androidsdk//com.android.support:support-compat-25.2.0 failed (Exit 1)
Nov 20, 2017 1:31:06 AM com.google.devtools.build.android.AndroidResourceMergingAction main
SEVERE: Unexpected
java.io.IOException: Mount point not found
	at sun.nio.fs.LinuxFileStore.findMountEntry(LinuxFileStore.java:91)
	at sun.nio.fs.UnixFileStore.<init>(UnixFileStore.java:65)
	at sun.nio.fs.LinuxFileStore.<init>(LinuxFileStore.java:44)
	at sun.nio.fs.LinuxFileSystemProvider.getFileStore(LinuxFileSystemProvider.java:51)
	at sun.nio.fs.LinuxFileSystemProvider.getFileStore(LinuxFileSystemProvider.java:39)
	at sun.nio.fs.UnixFileSystemProvider.getFileStore(UnixFileSystemProvider.java:368)
	at java.nio.file.Files.getFileStore(Files.java:1461)
	at com.google.devtools.build.android.ScopedTemporaryDirectory.makeWritable(ScopedTemporaryDirectory.java:59)
	at com.google.devtools.build.android.ScopedTemporaryDirectory.visitFile(ScopedTemporaryDirectory.java:83)
	at com.google.devtools.build.android.ScopedTemporaryDirectory.visitFile(ScopedTemporaryDirectory.java:36)
	at java.nio.file.Files.walkFileTree(Files.java:2670)
	at java.nio.file.Files.walkFileTree(Files.java:2742)
	at com.google.devtools.build.android.ScopedTemporaryDirectory.close(ScopedTemporaryDirectory.java:96)
	at com.google.devtools.build.android.AndroidResourceMergingAction.main(AndroidResourceMergingAction.java:289)
	at com.google.devtools.build.android.ResourceProcessorBusyBox$Tool$7.call(ResourceProcessorBusyBox.java:91)
	at com.google.devtools.build.android.ResourceProcessorBusyBox.main(ResourceProcessorBusyBox.java:172)

Exception in thread ""main"" java.io.IOException: Mount point not found
	at sun.nio.fs.LinuxFileStore.findMountEntry(LinuxFileStore.java:91)
	at sun.nio.fs.UnixFileStore.<init>(UnixFileStore.java:65)
	at sun.nio.fs.LinuxFileStore.<init>(LinuxFileStore.java:44)
	at sun.nio.fs.LinuxFileSystemProvider.getFileStore(LinuxFileSystemProvider.java:51)
	at sun.nio.fs.LinuxFileSystemProvider.getFileStore(LinuxFileSystemProvider.java:39)
	at sun.nio.fs.UnixFileSystemProvider.getFileStore(UnixFileSystemProvider.java:368)
	at java.nio.file.Files.getFileStore(Files.java:1461)
	at com.google.devtools.build.android.ScopedTemporaryDirectory.makeWritable(ScopedTemporaryDirectory.java:59)
	at com.google.devtools.build.android.ScopedTemporaryDirectory.visitFile(ScopedTemporaryDirectory.java:83)
	at com.google.devtools.build.android.ScopedTemporaryDirectory.visitFile(ScopedTemporaryDirectory.java:36)
	at java.nio.file.Files.walkFileTree(Files.java:2670)
	at java.nio.file.Files.walkFileTree(Files.java:2742)
	at com.google.devtools.build.android.ScopedTemporaryDirectory.close(ScopedTemporaryDirectory.java:96)
	at com.google.devtools.build.android.AndroidResourceMergingAction.main(AndroidResourceMergingAction.java:289)
	at com.google.devtools.build.android.ResourceProcessorBusyBox$Tool$7.call(ResourceProcessorBusyBox.java:91)
	at com.google.devtools.build.android.ResourceProcessorBusyBox.main(ResourceProcessorBusyBox.java:172)
Target //tensorflow/contrib/lite/java/demo/app/src/main:TfLiteCameraDemo failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 16.750s, Critical Path: 3.39s
FAILED: Build did NOT complete successfully


can anyone help me?"
14705,Complie error with cuda9.0+cudnn7.0+tensorflow-r1.4 on Ubuntu 16.04LTS,"```
ERROR: /home/wavy/Ten/tensorflow/tensorflow/contrib/factorization/BUILD:116:1: Linking of rule '//tensorflow/contrib/factorization:gen_gen_factorization_ops_py_wrappers_cc' failed (Exit 1)
```
This is the error output.

Thanks!
"
14704,tf.data.Dataset.padded_batch() doesn't work with nested elements,"### System information

TF 1.4 (pip install)
Python version 3.5.2 (Anaconda)

### Problem description

`tf.data.Dataset.padded_batch()` fails if a dataset element has some nested structure instead of being a tensor. Dataset API is supposed to work with Estimator's input_fn functionality which should return
features and labels as separate python objects and it is very inconvenient to merge everything into a single tensor, make a batch and then split.

### Source

    import tensorflow as tf
    print(tf.__version__)    

    dataset = tf.data.Dataset.range(100)
    dataset = dataset.map(lambda x: {'x': tf.fill([tf.cast(x, tf.int32)], x),
                                                           'y': tf.fill([tf.cast(x, tf.int32)], x)})
    dataset = dataset.padded_batch(4, padded_shapes=[None])

    iterator = dataset.make_one_shot_iterator()
    next_element = iterator.get_next()

    with tf.train.MonitoredSession() as sess:
        print(sess.run(next_element))
        print(sess.run(next_element))

### Actual

    ---------------------------------------------------------------------------
    TypeError                                 Traceback (most recent call last)
    <ipython-input-38-bb9f335976ed> in <module>()
          2 dataset = dataset.map(lambda x: {'x': tf.fill([tf.cast(x, tf.int32)], x),
          3                                  'y': tf.fill([tf.cast(x, tf.int32)], x)})
    ----> 4 dataset = dataset.padded_batch(4, padded_shapes=[None])
          5 
          6 iterator = dataset.make_one_shot_iterator()

    ~/anaconda3/lib/python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py in padded_batch(self, batch_size, padded_shapes, padding_values)
        693       A `Dataset`.
        694     """"""
    --> 695     return PaddedBatchDataset(self, batch_size, padded_shapes, padding_values)
        696 
        697   def map(self, map_func, num_parallel_calls=None):

    ~/anaconda3/lib/python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py in __init__(self, input_dataset, batch_size, padded_shapes, padding_values)
       1290                       self._default_padding(input_dataset))
       1291     self._padded_shapes = nest.map_structure_up_to(
    -> 1292         input_dataset.output_shapes, _partial_shape_to_tensor, padded_shapes)
       1293     self._padding_values = nest.map_structure_up_to(
       1294         input_dataset.output_shapes, _padding_value_to_tensor, padding_values,

    ~/anaconda3/lib/python3.5/site-packages/tensorflow/python/data/util/nest.py in map_structure_up_to(shallow_tree, func, *inputs)
        510     raise ValueError(""Cannot map over no sequences"")
        511   for input_tree in inputs:
    --> 512     assert_shallow_structure(shallow_tree, input_tree)
        513 
        514   # Flatten each input separately, apply the function to corresponding elements,

    ~/anaconda3/lib/python3.5/site-packages/tensorflow/python/data/util/nest.py in assert_shallow_structure(shallow_tree, input_tree, check_types)
        354       raise TypeError(
        355           ""If shallow structure is a sequence, input must also be a sequence. ""
    --> 356           ""Input has type: %s."" % type(input_tree))
        357 
        358     if check_types and not isinstance(input_tree, type(shallow_tree)):

    TypeError: If shallow structure is a sequence, input must also be a sequence. Input has type: <class 'list'>.

### Expected

It should produce dictionary, where x and y values are batch tensors with proper paddings.
"
14703,tf.layers uses wrong variable scope,"TF 1.4.
```python
import tensorflow as tf
def f(x):
    return tf.layers.conv2d(x, 30, 3)

x = tf.zeros([3, 20, 20, 1])

with tf.variable_scope('a'):
    print(f(x))
with tf.variable_scope('a', reuse=True):
    print(f(x)) # works

print(f(x))
with tf.variable_scope(tf.get_variable_scope(), reuse=True):
    print(f(x)) # failed with:
""""""
ValueError: Variable conv2d_1/kernel does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?
""""""
```

From what I can see, tf.layers is trying to create the variables under a wrong variable scope name, making variable sharing impossible if used under the root scope.

I found that this works:
```python
with tf.variable_scope(tf.get_variable_scope()):
    print(f(x))
with tf.variable_scope(tf.get_variable_scope(), reuse=True):
    print(f(x)) # works
```
But the first line seems redundant and counter-intuitive.

//UPDATE:
It also works if I don't use tf.layers:
```python
def f(x):
    W = tf.get_variable('w', shape=[1])
    return x + W
```"
14701,"startup time (_make_train_function()) very slow on Tesla V100-SXM2-16GB GPU, compared to less powerful GPU","cross posted on keras: https://github.com/fchollet/keras/issues/8537

Running mnist_cnn.py (slightly modified - mainly adding logging) from tensorflow 1.4
running was done using a prebuilt docker image: tensorflow/tensorflow:1.4.0-gpu-py3
on a p2.xlarge aws machine (that has a Tesla K80 GPU) performance is good, the 1st batch (which is dominated by the call to _make_train_function) takes about 2 seconds: (see time stamp for begin batch and end batch)

```
2017-11-19 08:26:26,172 : INFO : fit

2017-11-19 08:26:26,637 : INFO : begin batch
2017-11-19 08:26:26.638409: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2017-11-19 08:26:26.760940: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-11-19 08:26:26.761478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:00:1e.0
totalMemory: 11.17GiB freeMemory: 11.11GiB
2017-11-19 08:26:26.761506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)

2017-11-19 08:26:28,135 : INFO : end batch
x_train shape: (60000, 28, 28, 1)
60000 train samples
10000 test samples
Train on 60000 samples, validate on 10000 samples
Epoch 1/1
60000/60000 [==============================] - 12s - loss: 0.3526 - acc: 0.8920 - val_loss: 0.0818 - val_acc: 0.9755
Test loss: 0.081773182778
Test accuracy: 0.9755
```

on a p3.2xlarge machine (with a Tesla V100-SXM2-16GB GPU) the same part takes about 10 minutes

```
2017-11-19 08:26:44,120 : INFO : fit

2017-11-19 08:26:44,715 : INFO : begin batch
2017-11-19 08:26:44.716680: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2017-11-19 08:26:46.108295: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-11-19 08:26:46.108775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:1e.0
totalMemory: 15.77GiB freeMemory: 15.36GiB
2017-11-19 08:26:46.108815: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1e.0, compute capability: 7.0)

2017-11-19 08:36:16,552 : INFO : end batch
x_train shape: (60000, 28, 28, 1)
60000 train samples
10000 test samples
Train on 60000 samples, validate on 10000 samples
Epoch 1/1
60000/60000 [==============================] - 576s - loss: 0.3418 - acc: 0.8949 - val_loss: 0.0769 - val_acc: 0.9772
Test loss: 0.0769035610346
Test accuracy: 0.9772
```

the code that was used:
```
#!/usr/bin/env python
'''Trains a simple convnet on the MNIST dataset.

Gets to 99.25% test accuracy after 12 epochs
(there is still a lot of margin for parameter tuning).
16 seconds per epoch on a GRID K520 GPU.
'''

from __future__ import print_function
import cProfile
import os
from tensorflow.contrib import keras
from tensorflow.contrib.keras import backend as K
import logging


logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO, format='\n%(asctime)s : %(levelname)s : %(message)s')

class callback(keras.callbacks.Callback):
    def on_batch_begin(self, batch, logs=None):
      if batch <= 1:
            logger.info('begin batch')

class callback(keras.callbacks.Callback):
    def on_batch_end(self, batch, logs=None):
        if batch <= 1:
            logger.info('end batch')

batch_size = 128
num_classes = 10
epochs = 1

# input image dimensions
img_rows, img_cols = 28, 28

# the data, shuffled and split between train and test sets
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

if K.image_data_format() == 'channels_first':
    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)
    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)
    input_shape = (1, img_rows, img_cols)
else:
    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)
    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)
    input_shape = (img_rows, img_cols, 1)

x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train /= 255
x_test /= 255
print('x_train shape:', x_train.shape)
print(x_train.shape[0], 'train samples')
print(x_test.shape[0], 'test samples')

# convert class vectors to binary class matrices
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)

model = keras.models.Sequential()
model.add(keras.layers.Conv2D(32, kernel_size=(3, 3),
                 activation='relu',
                 input_shape=input_shape))
model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))
model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))
model.add(keras.layers.Dropout(0.25))
model.add(keras.layers.Flatten())
model.add(keras.layers.Dense(128, activation='relu'))
model.add(keras.layers.Dropout(0.5))
model.add(keras.layers.Dense(num_classes, activation='softmax'))

model.compile(loss=keras.losses.categorical_crossentropy,
              optimizer=keras.optimizers.Adadelta(),
              metrics=['accuracy'])
profiler = cProfile.Profile()
profiler.enable()
logger.info('fit')
model.fit(x_train, y_train,
          batch_size=batch_size,
          epochs=epochs,
          verbose=1,
          validation_data=(x_test, y_test), callbacks=[callback()])
profiler.dump_stats(os.path.expanduser('~/profiler.pstats'))
score = model.evaluate(x_test, y_test, verbose=0)

print('Test loss:', score[0])
print('Test accuracy:', score[1])

```
"
14700,"when validate my tensorflow installation using ""hello tensorflow"": *** stack smashing detected ***: python terminated Aborted (core dumped)","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: installed from native pip3, for Python 3.5, GPU support
- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**:  Python 3.5.2
- **Bazel version (if compiling from source)**: GCC 4.4.7 20120313 (Red Hat 4.4.7-1)
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: Cuda compilation tools, release 9.0, V9.0.176
- **GPU model and memory**: name: GeForce GTX 1080 Ti, totalMemory: 10.91GiB, freeMemory: 10.51GiB

### Describe the problem

when validate my tensorflow installation using ""hello tensorflow"": *** stack smashing detected ***: python terminated Aborted (core dumped)

### Source code / logs
python: 
import tensorflow as tf
hello = tf.constant('Hello, TensorFlow!')
sess = tf.Session()
print(sess.run(hello))


![screenshot from 2017-11-19 15-21-37](https://user-images.githubusercontent.com/25097258/32988464-59c8e696-cd40-11e7-97a5-a56b8f438f9c.png)


"
14699,"A very strange bug with tf.cond, update_ops and global_step","I'm using tf.Estimator with custom model_fn. When training, the estimator usually outputs log like:

INFO:tensorflow:loss = 1109.14, step = 1
INFO:tensorflow:loss = 937.876, step = 101 (6.245 sec)
INFO:tensorflow:loss = 632.192, step = 201 (6.195 sec)

By default, the printed steps should be 1, 101, 201... However, when I use the following function (which is simplified to reproduce the bug) in any place of the model:

```
def my_op(inputs, name=None):
  with tf.variable_scope(name, default_name='my_scope', reuse=False):
    count = tf.get_variable('count', shape=[],
      initializer=tf.zeros_initializer(), trainable=False)

    def myfunc1():
      return 1

    def myfunc2():
      tf.add_to_collection(tf.GraphKeys.UPDATE_OPS, count.assign_add(10.0))
      return 1

    tf.cond(tf.less(1, 2), myfunc1, myfunc2)
    return inputs

```

The log becomes something like:

INFO:tensorflow:loss = 1130.58, step = 0
INFO:tensorflow:loss = 940.298, step = 0 (6.352 sec)

The global step is always 0. After some tests, I found that the global step is not updated if myfunc2 is not executed. For example, if I write
`    tf.cond(tf.less(count, 2), myfunc1, myfunc2)`
then the global step is always 1.

I suspect that this is caused by the tf.add_to_collection(tf.GraphKeys.UPDATE_OPS, ...) in myfunc2, in which my intend is to update a variable when some condition holds. Maybe op created inside tf.cond can not be used as a dependency outside, but no error message is reported.

If I cannot add ops to UPDATE_OPS inside tf.cond, does this imply that stateful operations (like tf.layers.batch_normalization) can not be used inside tf.cond? So I cannot dynamically choose a network module from a set of network modules to execute if the network modules use any stateful operations like tf.layers.batch_normalization?

my tensorflow version: ('v1.4.0-rc0-10-g756a7fc', '1.4.0-rc1')"
14698,MemoryError from tensorflow.contrib.learning.datasets in Python3,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 17.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**: 3.5.3
- **Bazel version (if compiling from source)**: NA
- **GCC/Compiler version (if compiling from source)**: NA
- **CUDA/cuDNN version**: NA
- **GPU model and memory**: NA
- **Exact command to reproduce**: python -c ""import tensorflow as tf; tf.contrib.learn.datasets.load_dataset('dbpedia', size='full')""



### Describe the problem
The command results in an MemoryError, even though the dataset easily fits into my memory (64GB), and also works with Python 2. 

### Source code / logs
Here is the traceback:

Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/home/james/python3.5-ve/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/__init__.py"", line 71, in load_dataset
    return DATASETS[name](size, test_with_fake_data)
  File ""/home/james/python3.5-ve/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/text_datasets.py"", line 65, in load_dbpedia
    train_path, target_dtype=np.int32, features_dtype=np.str, target_column=0)
  File ""/home/james/python3.5-ve/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py"", line 72, in load_csv_without_header
    data = np.array(data)
MemoryError

"
14697,"tf.train.Scaffold does't accept global_step, and therefore only one checkpoint (0) is saved","Disclaimer: Issue #10661 might be related. 

When I create a Scaffold object and attempt to use it in a MonitoredTrainingSession, there is no ability to specify the global step.  As a consequence (I think), only one checkpoint is created, labeled ""model.ckpt-0"". 

As I understand it, the code below (taken from a custom class I've written...hence the `self`s) should save a new checkpoint every 10 seconds, but only actually creates a single checkpoint at the start of training, and then never again.

    self.GLOBAL_STEP = tf.train.get_or_create_global_step()
    self.init_op = tf.global_variables_initializer()       
    self.Saver = tf.train.Saver()

    self.Scaffold = tf.train.Scaffold( init_op=self.init_op,
                                       saver=self.Saver
                                   #   global_step=self.GLOBAL_STEP  
                                           )

    self.sess = tf.train.MonitoredTrainingSession( master='',
                                                   is_chief=True,
                                                   scaffold = self.Scaffold,
                                                   checkpoint_dir='./chkpt/',
                                                   save_checkpoint_secs=10,
                                                       )

If I uncomment the `global_step=...` line above, I get an error (as expected) since `Scaffold.__init__()` doesn't take a global_step argument, however shouldn't it?"
14693,Why did you call BasicLSTMCell a cell and not a layer?,"`BasicLSTMCell` is actually a layer (as for a layer in MLPs) of LSTM units. Each of these LSTM units contains a cell. Each cell of an LSTM unit contains a **scalar value** for the CEC and a **scalar** representing the previous state.

People are usually first introduced to MLPs or feed-forward (and fully connected) neural networks, before being introduced to RNNs and, in particular, LSTMs. 

Why would you call `BasicLSTMCell` a **cell**, if it can be thought more intuitively (at least for me) as a layer of LSTM units (as I describe them above) containing just one scalar-based cell? Wouldn't it be less ambiguous to call a `BasicLSTMCell` `BasicLSTMLayer`???

Moreover, the first parameter to `BasicLSTMCell`'s `__init__` method is `num_units`, i.e. the number of LSTM units, i.e. the number of LSTM cells and gates (if we have 3 gates for every LSTM unit, then the total number of gates in one layer of LSTMs is 3 * `num_units`). 

It almost seems that you created TF to make it as confusing as possible to make it seem hard. It also almost seems that the person who wrote the name of the class `BasicLSTMCell` is a different person of the person who wrote its `__init__` method. What's going on??? A little bit of consistency, for once, no???

A similar argument can be said for `MultiRNNCell`, which, a lot more intuitively, can be thought as a sequence of layers.

### Request

Change classes such as `BasicLSTMCell` and `MultiRNNCell` to have more descriptive names of what they actually are in future versions of TF. Then change the corresponding documentation to be more compliant with these changes."
14692,Does 'distributed tensorflow' support Keras training?,"[distributed tensorflow in the official site](https://www.tensorflow.org/deploy/distributed)

Instread of tensorflow model,  is Keras model and training possible?

 If I put the Keras model and training, is it working??
![image](https://user-images.githubusercontent.com/9244296/32982719-3394322e-cccc-11e7-9b58-ea5f326e63ff.png)
I want to know if distributed tensorflow support keras model too."
14691,"compile failed for tf-gpu 1.4, cuda 9, cudnn 7, vc 2017, windows 10.","I would greatly appreciate if anyone could help me out with compiling.
I followed #5600 and #13962 in compiling the wheel, however when building i got into 6 types of in total 90 errors. Respectively c2070, c2059, c2064, c2001, c1057, c2146.

My build command was:
`cmake .. -A x64 -DCMAKE_BUILD_TYPE=Release ^
-DSWIG_EXECUTABLE=C:/swigwin-3.0.12/swig.exe ^
-DPYTHON_EXECUTABLE=python.exe ^
-DPYTHON_LIBRARIES=C:/ProgramData/Anaconda3/libs/python36_lib ^
-DPYTHON_INCLUDE_DIR=C:/ProgramData/Anaconda3/Include ^
-DNUMPY_INCLUDE_DIR=C:/ProgramData/Anaconda3/lib/site-packages/numpy/core/include ^
-Dtensorflow_ENABLE_GPU=ON ^
-DCUDNN_HOME=""C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0"" ^
-Dtensorflow_WIN_CPU_SIMD_OPTIONS=/arch:AVX `

Everything looks good until the compiler_arch_native_support failed.
It manage to configure the build so I continue with: 
MSBuild /p:Configuration=Release tf_python_build_pip_package.vcxproj 

The last 9999 line of the failed log is here. 
[tf-compile-build-error-log.txt](https://github.com/tensorflow/tensorflow/files/1484750/tf-compile-build-error-log.txt)

Warmest Regards,
Colman"
14689,Couldn't find field google.protobuf.EnumDescriptorProto.EnumReservedRange.start,"Im trying to run the following code 

```
import tensorflow as tf

print(""Hello TensorFlow version"", tf.__Version__)
```


It is firing the following error 

> Users/anaconda/envs/cnn/bin/python /Users/Downloads/rude-carnie/version.py
> Traceback (most recent call last):
>   File ""/Users/Downloads/rude-carnie/version.py"", line 1, in <module>
>     import tensorflow as tf
>   File ""/Users/anaconda/envs/cnn/lib/python3.6/site-packages/tensorflow/__init__.py"", line 24, in <module>
>     from tensorflow.python import *
>   File ""/Users/anaconda/envs/cnn/lib/python3.6/site-packages/tensorflow/python/__init__.py"", line 52, in <module>
>     from tensorflow.core.framework.graph_pb2 import *
>   File ""/Users/anaconda/envs/cnn/lib/python3.6/site-packages/tensorflow/core/framework/graph_pb2.py"", line 10, in <module>
>     from google.protobuf import descriptor_pb2
>   File ""/Users/anaconda/envs/cnn/lib/python3.6/site-packages/google/protobuf/descriptor_pb2.py"", line 735, in <module>
>     options=None, file=DESCRIPTOR),
>   File ""/Users/anaconda/envs/cnn/lib/python3.6/site-packages/google/protobuf/descriptor.py"", line 501, in __new__
>     return _message.default_pool.FindFieldByName(full_name)
> KeyError: ""Couldn't find field google.protobuf.EnumDescriptorProto.EnumReservedRange.start"""
14688,how to build tensorflow lite into a static c++ library using android ndk,"I want to write some c++ test binary using tensorflow lite.
from the README.md I can only see how to build the demo app.
Could you please tell me how to build tensorflow lite into a static library using android ndk?"
14686,"i'm a newcomer , and met the following problem!!","i install tensorflow following the guide explanation in 
**www.tensorflow.org/install/install_windows**
### System information
- **OS Platform and Distribution:win10
- **TensorFlow installed from (source or binary)**:source
- **TensorFlow version (use command below): i use the following command: pip3 install --upgrade tensorflow-gpu
- **Python version:3.5.2 
- **CUDA/cuDNN version**:cuda 8.0 /cudnn 8.0
- **GPU model and memory:GTX1070 8g
i download the source successfully and when i enter the following short program inside the python interactive shell:   import tensorflow as tf
it goes wrong:
Traceback (most recent call last):
  File ""E:\SoftWare\Python\lib\site-packages\tensorflow\python\platform\self_check.py"", line 87, in preload_check
    ctypes.WinDLL(build_info.cudnn_dll_name)
  File ""E:\SoftWare\Python\lib\ctypes\__init__.py"", line 347, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: [WinError 126] Could not find the specified module

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""E:\SoftWare\Python\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""E:\SoftWare\Python\lib\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""E:\SoftWare\Python\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 30, in <module>
    self_check.preload_check()
  File ""E:\SoftWare\Python\lib\site-packages\tensorflow\python\platform\self_check.py"", line 97, in preload_check
    % (build_info.cudnn_dll_name, build_info.cudnn_version_number))
ImportError: Could not find 'cudnn64_6.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Note that installing cuDNN is a separate step from installing CUDA, and this DLL is often found in a different directory from the CUDA DLLs. You may install the necessary DLL by downloading cuDNN 6 from this URL: https://developer.nvidia.com/cudnn


in my file sys ,the dll file's name is cudnn64_5.dll
and following is my path:
![image](https://user-images.githubusercontent.com/33776263/32978257-56054f12-cc79-11e7-838e-a10a1b138b07.png)
(i can find my msvcp140.dll)
please help ,thx"
14684,Does SavedModelBuilder save checkpoints ?,"Does SavedModelBuilder.save() create checkpoint files ? The documentation says this is a wrapper for Saver but doesn't mention checkpoints. It looks like this function doesn't create checkpoints.   

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS X 10.13.1
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A"
14683,Cannot convert a string input to combination of tensors as defined in the Input function,"While working on the tensor flow java api, I trained a model in python and saved it using the code below -

There are two problems I'm facing now while making predictions in Python and Java as below - 

1. Making predictions in Python
2.  Making prediction in Java with input as string 
3.  How to convert data to complex input types like CrossColumn tensors, bucketized tensors, embedding tensors etc in Java

**_1] Making predictions in Python -_** 

Gist for training code can be found at - https://gist.github.com/gaganmalhotra/8c40e7650f27cf3f894bad092fbe01ab

While loading the model using the Predictor and making predictions as : 

```
# Preparing the single test dataframe to be used for prediction
input_single_predict = df_test[2:3] #this is just a single row from the test dataframe I'm using to test for prediction

K_CATEGORICAL_COLUMNS = [""gender"", ""native_country"", ""education"", ""occupation"", ""workclass"", ""marital_status"", ""race""]

def predict_ip_fn(df):
  categorical_cols = {k: tf.SparseTensor(
      indices=[[i, 0] for i in range(df[k].size)],
      values=df[k].values,
      dense_shape=[df[k].size, 1])
                      for k in K_CATEGORICAL_COLUMNS}
  return categorical_cols

dict_predict = predict_ip_fn(input_single_predict)

# Loading the model from disk
from tensorflow.contrib import predictor
export_dir = ""/Users/Documents/SampleTF_projects/temp/1510957027""
predict_fn = predictor.from_saved_model(export_dir, signature_def_key=None)

predictions = predict_fn(dict_predict) . #<<<<<< ****** Error is caused here ******
print(predictions['probabilities'])

```
**But it leads to the error as below -** 
`
ValueError: Got unexpected keys in input_dict: set(['workclass', 'gender', 'marital_status', 'race', 'native_country', 'education', 'occupation'])
`

**Just to cross verify with the model features, you can find the feature columns used in the model as below -** 

```
LinearClassifier(params = {
	'gradient_clip_norm': None,
	'head': < tensorflow.contrib.learn.python.learn.estimators.head._BinaryLogisticHead object at 0x121e5a310 > ,
	'joint_weights': False,
	'optimizer': None,
	'feature_columns': [_SparseColumn(column_name = 'gender', is_integerized = False, bucket_size = None, lookup_config = _SparseIdLookupConfig(vocabulary_file = None, keys = ('Female', 'Male'), num_oov_buckets = 0, vocab_size = 2, default_value = -1), combiner = 'sum', dtype = tf.string), 
  _SparseColumn(column_name = 'native_country', is_integerized = False, bucket_size = 1000, lookup_config = None, combiner = 'sum', dtype = tf.string),
  _SparseColumn(column_name = 'education', is_integerized = False, bucket_size = 1000, lookup_config = None, combiner = 'sum', dtype = tf.string), 
  _SparseColumn(column_name = 'occupation', is_integerized = False, bucket_size = 1000, lookup_config = None, combiner = 'sum', dtype = tf.string), 
  _SparseColumn(column_name = 'workclass', is_integerized = False, bucket_size = 100, lookup_config = None, combiner = 'sum', dtype = tf.string), 
  _SparseColumn(column_name = 'marital_status', is_integerized = False, bucket_size = 1000, lookup_config = None, combiner = 'sum', dtype = tf.string), 
  _SparseColumn(column_name = 'race', is_integerized = False, bucket_size = 1000, lookup_config = None, combiner = 'sum', dtype = tf.string)]
})
```

**_2] Making predictions in Java_** 

Below is the java code for making the predictions from the loaded model:
```

public static void main(String[] args) throws UnsupportedEncodingException {
TensorFlow.loadLibrary(""/Users/gagandeep.malhotra/Documents/gcTensorFlowPredictIncome/census_keras/lib/python2.7/site-packages/tensorflow/contrib/layers/python/ops/_sparse_feature_cross_op.so"");
		
		  try (SavedModelBundle b = SavedModelBundle.load(""/Users/Documents/SampleTF_projects/temp/1510957027/"", ""serve"")) {

	          
	          /**
			 * 
			 * The given SavedModel SignatureDef contains the following input(s):
			 * inputs['inputs'] tensor_info: dtype: DT_STRING shape: (-1) name:
			 * input_example_tensor:0 The given SavedModel SignatureDef contains the
			 * following output(s): outputs['classes'] tensor_info: dtype: DT_STRING shape:
			 * (-1, -1) name:
			 * linear/binary_logistic_head/_classification_output_alternatives/classes_tensor:0
			 * outputs['scores'] tensor_info: dtype: DT_FLOAT shape: (-1, 2) name:
			 * linear/binary_logistic_head/predictions/probabilities:0 Method name is:
			 * tensorflow/serving/classify
			 * 
			 * 
			 */
			String[] inputs = new String[] { ""HS-grad"", ""Male"", ""Divorced"", ""United-States"", ""Handlers-cleaners"",
					""White"", ""Private"" };

			byte[][][] stringMatrix = new byte[7][1][];
			for (int i = 0; i < 7; ++i) {
				stringMatrix[i][0] = String.format(inputs[i]).getBytes(""UTF-8"");
			}

			Tensor<String> t = Tensors.create(stringMatrix);

			Session sess = b.session();

			final String xName = ""input_example_tensor:0"";
			final String scoresName = ""linear/binary_logistic_head/predictions/probabilities:0"";
			List<Tensor<?>> outputs = s.runner().feed(xName, t).fetch(scoresName).run();

			float[][] classes = new float[2][2];
			outputs.get(0).copyTo(classes);

	      }
		  
```

**_3] How to create a Complex Input data types in JAVA_**

In python, we can create different input tensors like CrossedColumn, Bucketized etc , Is there a way that we can convert similarly in Java as we dont have estimators or contrib libraries present in JAVA API.


If anyone you could help or guide in the right direction.. @eggie5 @asimshankar @ry"
14676,XLA operation semantics documentation BatchNormTrain error,"Hey! I think there are a few errors in the documentation for the XLA BatchNormTrain operation in https://www.tensorflow.org/performance/xla/operation_semantics#batchnormgrad.

The gradient of the scaling factor `gamma` should be
<a href=""https://www.codecogs.com/eqnedit.php?latex=\nabla&space;\gamma&space;=&space;\text{sum}\Big(&space;\nabla&space;y&space;*&space;\frac{(&space;x&space;-&space;\mu&space;)}{&space;\sqrt{\sigma^2&space;&plus;&space;\epsilon}}&space;\Big)"" target=""_blank""><img src=""https://latex.codecogs.com/gif.latex?\nabla&space;\gamma&space;=&space;\text{sum}\Big(&space;\nabla&space;y&space;*&space;\frac{(&space;x&space;-&space;\mu&space;)}{&space;\sqrt{\sigma^2&space;&plus;&space;\epsilon}}&space;\Big)"" title=""\nabla \gamma = \text{sum}\Big( \nabla y * \frac{( x - \mu )}{ \sqrt{\sigma^2 + \epsilon}} \Big)"" /></a>
instead of 
<a href=""https://www.codecogs.com/eqnedit.php?latex=\nabla&space;\gamma&space;=&space;\text{sum}\Big(&space;\nabla&space;y&space;*&space;(&space;x&space;-&space;\mu&space;)&space;*&space;\sqrt{\sigma^2&space;&plus;&space;\epsilon}&space;\Big)"" target=""_blank""><img src=""https://latex.codecogs.com/gif.latex?\nabla&space;\gamma&space;=&space;\text{sum}\Big(&space;\nabla&space;y&space;*&space;(&space;x&space;-&space;\mu&space;)&space;*&space;\sqrt{\sigma^2&space;&plus;&space;\epsilon}&space;\Big)"" title=""\nabla \gamma = \text{sum}\Big( \nabla y * ( x - \mu ) * \sqrt{\sigma^2 + \epsilon} \Big)"" /></a>

Moreover, the gradient for the input tensor is also not correct. It should instead read something like this:
<a href=""https://www.codecogs.com/eqnedit.php?latex=\Big(&space;\nabla&space;y&space;-&space;\frac{\hat{x}&space;\times&space;\nabla&space;\gamma&space;&plus;&space;\nabla&space;\beta}{m&space;w&space;h}\Big)&space;\times&space;\frac{\gamma}{\sqrt{\sigma^2&space;&plus;&space;\epsilon}}"" target=""_blank""><img src=""https://latex.codecogs.com/gif.latex?\Big(&space;\nabla&space;y&space;-&space;\frac{\hat{x}&space;\times&space;\nabla&space;\gamma&space;&plus;&space;\nabla&space;\beta}{m&space;w&space;h}\Big)&space;\times&space;\frac{\gamma}{\sqrt{\sigma^2&space;&plus;&space;\epsilon}}"" title=""\Big( \nabla y - \frac{\hat{x} \times \nabla \gamma + \nabla \beta}{m w h}\Big) \times \frac{\gamma}{\sqrt{\sigma^2 + \epsilon}}"" /></a>

Where the products and summations are done in a ""broadcasted"" manner when shapes don't match and <a href=""https://www.codecogs.com/eqnedit.php?latex=\hat{x}"" target=""_blank""><img src=""https://latex.codecogs.com/gif.latex?\hat{x}"" title=""\hat{x}"" /></a> is the whitened input tensor. That is:
<a href=""https://www.codecogs.com/eqnedit.php?latex=\hat{x}&space;=&space;\frac{x&space;-&space;\mu}{\sqrt{\sigma^2&space;&plus;&space;\epsilon}}"" target=""_blank""><img src=""https://latex.codecogs.com/gif.latex?\hat{x}&space;=&space;\frac{x&space;-&space;\mu}{\sqrt{\sigma^2&space;&plus;&space;\epsilon}}"" title=""\hat{x} = \frac{x - \mu}{\sqrt{\sigma^2 + \epsilon}}"" /></a>


There also seem to be a typo in the table explaining the output of this XLA node. The second row should say `grad_offset` in the first column, `ComputationalDataHandle` in the second column, and the semantics column should say something like `gradient with respect to input offset`.

 
Finally, it may be good if it could be specified that the summation used for the gradients of the scaling and offset tensors is performed over all dimensions that were used to compute the different statistics during normalization."
14675,Small change to graph changes initial values of variables,"I'm running TensorFlow 1.2 with CUDA.

Error case:
I call ``tf.set_random_seed(2017)`` and then build a graph ``g1`` that includes trainable variables and an optimizer. I create a session, run the ``tf.global_variables_initializer()`` op, and then immediately fetch the value of a scalar variable (without running any train steps, so this is the initial value of the variable). As expected, this value stays the same if I launch this process multiple times.

I then build a graph ``g2`` that is identical to ``g1`` except for a slight change. ``g1`` contained ``mu = tf.reduce_sum(x) / tf.size(x)[0]``, and ``g2`` contains ``mu = tf.reduce_mean(x)``. ``g2`` is seeded the same way as ``g1`` and has the same variable names and shapes as ``g1``. The only differently named tensors are those relating to the modification mentioned above. When I fetch the initial value of the same scalar variable from ``g2``, there is a completely different value from when fetched from ``g1``.

I've tried to isolate this into a small test case but have not been successful yet. I will continue to work on this. Apologies for bug report without test case.
My current intention is to workaround this with a Numpy based initialization scheme.

Questions:
(1) Is this expected behavior? Ideally the variables would be initialized in the same way to help make results more reproducible. In my case, the different variable initialization makes it more difficult to test that ``g1`` and ``g2`` produce the same values. If variables were initialized the same way, would be easy to see that refactoring the mean computation in the graph did not break anything.

(2) Any idea why this occurs? Perhaps relevantly, ``tf.make_template`` is used within this graph. My current (evidence-free) hunch is the small change in graph causes a variable to move from CPU resident to GPU resident and caused a different PRNG kernel (provided with the same seed) to be used."
14672,Compilation Flags,"Can someone please explain the flags that can be enabled when compiling TensorFlow from source? I don't seem to understand the functionality of most of them and they are not documented.
"
14670,Tensorflow Lite toco conversion error on SSD fails,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOSX 10.12.6
- **TensorFlow installed from (source or binary)**: source 
- **TensorFlow version (use command below)**: master
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: 0.7.0-homebrew
- **GCC/Compiler version (if compiling from source)**: Apple LLVM version 9.0.0 (clang-900.0.38)
- **CUDA/cuDNN version**: -
- **GPU model and memory**: -
- **Exact command to reproduce**: see below

### Describe the problem
I'm trying to convert a model from the object-detection framework to a tflite file. Here's the command I run:

 bazel run --config=opt tensorflow/contrib/lite/toco:toco -- \
                                                         --input_file=(path)/models/research/object_detection/output_inference_graph/frozen_inference_graph.pb \
                                                         --input_format=TENSORFLOW_GRAPHDEF  --output_format=TFLITE \
                                                         --output_file=(pwd)/mobilenet_v1_1.0_224.lite --inference_type=FLOAT \
                                                         --input_type=FLOAT --input_arrays=image_tensor \
                                                         --output_arrays=detection_boxes --input_shapes=1,320,320,3

here's the output:

...
2017-11-17 22:02:12.888007: I tensorflow/contrib/lite/toco/import_tensorflow.cc:937] Converting unsupported operation: TensorArrayGatherV3
2017-11-17 22:02:12.888037: I tensorflow/contrib/lite/toco/import_tensorflow.cc:937] Converting unsupported operation: StridedSlice
2017-11-17 22:02:12.888065: I tensorflow/contrib/lite/toco/import_tensorflow.cc:937] Converting unsupported operation: StridedSlice
2017-11-17 22:02:12.888077: I tensorflow/contrib/lite/toco/import_tensorflow.cc:937] Converting unsupported operation: LogicalAnd
2017-11-17 22:02:12.888123: F tensorflow/contrib/lite/toco/import_tensorflow.cc:281] Check failed: GetInputsCount(node, model->flags.drop_control_dependency()) == 2 (3 vs. 2)

I freezed the model using the python script from the object detection framework:

python export_inference_graph.py  --input_type image_tensor --pipeline_config_path samples/configs/ssd_mobilenet_v1_coco.config  --trained_checkpoint_prefix ../../../ssd_mobilenet_v1_coco_11_06_2017/model.ckpt  --output_directory output_inference_graph --input_shape 1,320,320,3

Any idea why the conversion fails?
Thanks for any help!"
14669,Feature Request | Set keras random state with tensorflow,Is it possible to set the `random_seed` in `keras` with `tensorflow`?  Would you need to set it to a specific graph? I have not found out how to set the random state in `keras` and if this doesn't exist could this be a feature in future versions? 
14666,feature request in examples/image_retraining/retrain.py,"Hi all, 
This script is working great but please add projector / embedding and images in tensorboard. 
"
14664,TensorFlow Lite Android example doesn't compile with Bazel,"TensorFlow Lite Android example doesn't compile with Bazel, as explained in its README.

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 17.10
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: master (c0662f1620c2b97abb79b8ae6a8a30f7c7719475)
- **Python version**: 2.7.14
- **Bazel version (if compiling from source)**: 0.7.0
- **GCC/Compiler version (if compiling from source)**: 7.2.0
- **CUDA/cuDNN version**: (not using cuda)
- **GPU model and memory**: (not using GPU)
- **Exact command to reproduce**: `bazel build --cxxopt='--std=c++11'   //tensorflow/contrib/lite/java/demo/app/src/main:TfLiteCameraDemo`

### Describe the problem
When trying to compile the TF Lite Android demo with Bazel, it doesn't work, yielding:

```
WARNING: The major revision of the Android NDK referenced by android_ndk_repository rule 'androidndk' is 16. The major revisions supported by Bazel are [10, 11, 12, 13, 14]. Defaulting to revision 14.
INFO: Analysed target //tensorflow/contrib/lite/java/demo/app/src/main:TfLiteCameraDemo (0 packages loaded).
INFO: Found 1 target...
ERROR: /home/santiago/repos/tensorflow/tensorflow/contrib/lite/kernels/internal/BUILD:273:1: C++ compilation of rule '//tensorflow/contrib/lite/kernels/internal:tensor_utils' failed (Exit 1)
In file included from tensorflow/contrib/lite/kernels/internal/tensor_utils.cc:24:
In file included from ./tensorflow/contrib/lite/kernels/internal/optimized/neon_tensor_utils.h:21:
In file included from ./tensorflow/contrib/lite/kernels/internal/optimized/cpu_check.h:21:
external/androidndk/ndk/sources/android/cpufeatures/cpu-features.h:31:10: fatal error: 'sys/cdefs.h' file not found
#include <sys/cdefs.h>
         ^~~~~~~~~~~~~
1 error generated.
Target //tensorflow/contrib/lite/java/demo/app/src/main:TfLiteCameraDemo failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 14.636s, Critical Path: 7.92s
FAILED: Build did NOT complete successfully
```

I have already tried installing all APT packages that contain a file named `sys/cdefs.h`, including `g{cc,++}-{5,6,7}-multilib`. NDK 16 is installed, along with LLDB 3.0 and cmake.

### Source code / logs
tf_env.txt:

```
== cat /etc/issue ===============================================
Linux s.local 4.13.0-16-lowlatency #19-Ubuntu SMP PREEMPT Wed Oct 11 19:51:52 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""17.10 (Artful Aardvark)""
VERSION_ID=""17.10""
VERSION_CODENAME=artful

== are we in docker =============================================
No

== compiler =====================================================
c++ (Ubuntu 7.2.0-8ubuntu3) 7.2.0
Copyright (C) 2017 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux s.local 4.13.0-16-lowlatency #19-Ubuntu SMP PREEMPT Wed Oct 11 19:51:52 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy (1.13.3)

== check for virtualenv =========================================
True

== tensorflow import ============================================
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""tensorflow/python/pywrap_tensorflow.py"", line 25, in <module>
    from tensorflow.python.platform import self_check
ImportError: No module named platform

== env ==========================================================
LD_LIBRARY_PATH /home/santiago/torch/install/lib:/home/santiago/torch/install/lib:
DYLD_LIBRARY_PATH /home/santiago/torch/install/lib:/home/santiago/torch/install/lib:

== nvidia-smi ===================================================
/dev/fd/63: línea 105: nvidia-smi: orden no encontrada

== cuda libs  ===================================================
```"
14663,DropoutWrapper and dynamic_rnn with parallel iterations not reproducible,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: CPU Binary (pip wheel)
- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**: 3.6.3 and 3.5.2
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**:
The following script fails with an assertion error, even though I've explicitly set the random seed:
```python
import tensorflow as tf
import numpy as np

def run():
    tf.reset_default_graph()
    tf.set_random_seed(0)

    sess = tf.Session()
    x = tf.placeholder(tf.float32, [None, None, 1])
    cell = tf.nn.rnn_cell.DropoutWrapper(
        tf.nn.rnn_cell.LSTMCell(100), input_keep_prob=0.5)
    output, state = tf.nn.dynamic_rnn(
        cell, x, dtype=tf.float32, parallel_iterations=100)
    # if parallel_iterations=1, then everything works

    sess.run(tf.global_variables_initializer())
    return sess.run([output, state], {x: np.arange(100).reshape(1, 100, 1)})

o1, (c1, h1) = run()
o2, (c2, h2) = run()
  
assert (o1 == o2).all()
assert (c1 == c2).all()
assert (h1 == h2).all()
```

### Describe the problem
It looks like using parallel iterations options creates some non-determinism when using `DropoutWrapper` (and `parallel_iterations=32` by default). Ideally, when setting the random seed, all TensorFlow operations should be deterministic and reproducible (or the non-determinism should at least be documented).

cc @tudorgt @adamAlnatsheh"
14662,"Distributed TF hangs because of ""CreateSession still waiting for response from worker....""","**UPDATE:** The first 2 posts are no longer appropriate to describe the issue. Please jump to my 3rd post.

Hi,

I followed the idea of this https://github.com/tensorflow/benchmarks/blob/master/scripts/tf_cnn_benchmarks/benchmark_cnn.py#L1670 to implement a worker sync queue. Everything seemed to work fine except when I increased the size of the dataset or number of workers: all workers hang when they try to evaluate the sync op. Typical example of my code is as follow:

For each worker:
```
    def create_sync_queue_ops(self, op_prefix):
        """"""
        op_prefix: a string that denote where the sync is being used.
        """"""
        #Evenly distribute queues to all ps or workers
        device_name = ""/job:ps/task:{}/cpu:0"".format(self.sync_queue_counter % self.num_ps_nodes)
        self.sync_queue_counter += 1
        with tf.device(device_name):
            sync_queues = [tf.FIFOQueue(self.num_worker_nodes, [tf.bool], shapes=[[]], shared_name=""{0}_{1}"".format(op_prefix,i)) for i in xrange(self.num_worker_nodes)]
            token = tf.constant(False)
            queue_ops = []
            for i, q in enumerate(sync_queues):
                if i == self.worker_id:
                    queue_ops.append(tf.no_op())
                else:
                    queue_ops.append(q.enqueue(token))
            #Drain tokens off queue for this worker after enqueuing ops
            with tf.control_dependencies(queue_ops):
                wait_ops = sync_queues[self.worker_id].dequeue_many(len(sync_queues)-1)
            return wait_ops

(some graph definition...)
sess = tf.Session()
demo_sync_ops = self.create_sync_queue_ops(""demo"")
if self.is_chief_worker: #only execute by worker 0, other workers do nothing
    sess.run(tf.global_variables_initializer())
print ""finishing message""
sess.run(demo_sync_ops)
```

I could **occasionally** see all workers hang after printing the ""finishing message"". 
My observation so far is that this only happened when dataset is huge or number of worker is big. e.g. 10+TB dataset with 300-500 workers.

I haven't been able to see why this occurred, not sure if it is a TF issue or some network bottleneck that I was not aware of. Any help would be much appreciated!
  "
14661,TensorFlowMaximum operator in TF Lite,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Docker 
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 3.5
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: NA
- **GPU model and memory**: NA
- **Exact command to reproduce**:


### Describe the problem
I am trying to convert a graph from .pb to .lite format using toco, but I get this error:
`2017-11-17 10:20:47.738777: F tensorflow/contrib/lite/toco/tflite/export.cc:192] Unsupported operator: TensorFlowMaximum`

I had a look inside the code, and found `TensorFlowMaximum` operator defined inside `lite/kernels/internal/optimized/optimized_ops.h`, but apparently it's not linked or defined anywhere else.

What's the fastest way to get this defined and linked?

Thanks a lot.
"
14659,Feature request: tf.nn.ctc_loss lacks the API to handle sequences with all blanks,"It is trivial to calculate the CTC loss of a sequence with all blanks. But tf.nn.ctc_loss cannot handle the situation that one or more sequences in the batch have no non-blank labels. This is a big limitation.   

P.S.: I pulled these requests before:
I reported this previously at
https://github.com/tensorflow/tensorflow/issues/13457
I asked this on stackoverflow
https://stackoverflow.com/questions/46652720/how-to-calculate-ctc-loss-of-a-sequence-with-all-blanks-using-tf-nn-ctc-loss  "
14658,tf.metrics.mean_relative error doesn't handle complex inputs,"The offending line is here: 

https://github.com/tensorflow/tensorflow/blob/9c4bdb865452e418a1d69cd5f5cdccb51d6a0e1d/tensorflow/python/ops/metrics_impl.py#L1057

`array_ops.where` expects the second and third inputs to be of the same shape and **type**. Unfortunately, when the `labels` input is complex, `array_ops.zeros_like(labels)` returns an (unnecessarily) complex tensor, whereas the third input returns a float tensor. 

I haven't checked, but suspect similar problems might occur with other metrics (and perhaps elsewhere). "
14657,FusedBatchNorm & Conv2D backwards doesn't support zero batch size,"Most ops in TF work well with tensors with zero elements. However, <del>convolution</del> fusedbatchnorm with cudnn gives the following error:
```
2017-11-17 08:00:20.835113: F tensorflow/stream_executor/cuda/cuda_dnn.cc:444] could not convert BatchDescriptor {count: 0 feature_map_count: 1024 spatial: 28 28  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX} to cudnn tensor descriptor: CUDNN_STATUS_BAD_PARAM 
```

I would expect it checks and returns a 4D tensor with zero batch-size. Currently I have to work around it by `tf.cond`."
14655,Support dynamic partition in loss function,"

### System information

Python 3.6.1, Ubuntu 16.04, TF 1.3

### Describe the problem

I am trying to implement a loss function in Tensorflow similar to the Theano loss function described here: https://github.com/Lasagne/Lasagne/issues/767

I have tried several code but they all lead to runtime error.  Seems that dynamically sized tensors aren't supported in loss function.  I have tried various optimizers, including adam, without success.

When tested standalone, the function works fine and produces results similar to a numpy based implementation.

### Source code / logs
  Here is one code I tried:

    import tensorflow as tf
    
    def pair_loss(y_true, y_pred):
        y_true = tf.cast(y_true, tf.int32)
        parts = tf.dynamic_partition(y_pred, y_true, 2)
        y_pos = parts[1]
        y_neg = parts[0]
        y_pos = tf.expand_dims(y_pos, 0)
        y_neg = tf.expand_dims(y_neg, -1)
        out = tf.sigmoid(y_neg - y_pos)
        return tf.reduce_mean(out, axis=-1)

Here is the theano code for reference:

    import theano
    
    def calc_auroc_loss(pred_vr, y_vr):
        pos_pred_vr = pred_vr[y_vr.nonzero()]
        neg_pred_vr = pred_vr[theano.tensor.eq(y_vr, 0).nonzero()]
        pred_diffs_vr = pos_pred_vr.dimshuffle(0, 'x') - neg_pred_vr.dimshuffle('x', 0)
        num_pairs_vr = theano.tensor.sum(theano.tensor.eq(y_vr, 1)) * theano.tensor.sum(theano.tensor.eq(y_vr, 0))
        auroc_vr = theano.tensor.sum(theano.tensor.nnet.sigmoid(pred_diffs_vr)) / num_pairs_vr
        return -auroc_vr"
14654,Unable to install Tensorflow on Ubuntu - Anaconda error trace,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Ubuntu 16.04.2 LTS
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**:1.4.0
- **Python version**: 3.5.4
- **Bazel version (if compiling from source)**:NA
- **GCC/Compiler version (if compiling from source)**:NA
- **CUDA/cuDNN version**:NA
- **GPU model and memory**:NA
- **Exact command to reproduce**: 

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh


### Describe the problem
I am installing the latest version of tensorflow 1.4.0 and I am getting an error when I try to install it inside a conda environment.

`
conda create -n py36-tensorflow python=3.6
`
`
source activate py36-tensorflow
`
`
pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.4.0-cp36-cp36m-linux_x86_64.whl
`

the above are the commands I ran and below is the error trace I am getting.

### Source code / logs
Logs:


`ubuntuvm@ubuntuvm:~$ conda create -n py36-tensorflow python=3.6`
`Fetching package metadata ...........`
`Solving package specifications: .`

Package plan for installation in environment /home/ubuntuvm/anaconda3/envs/py36-tensorflow:

The following NEW packages will be INSTALLED:

    ca-certificates: 2017.08.26-h1d4fec5_0
    certifi:         2017.7.27.1-py36h8b7b77e_0
    libedit:         3.1-heed3624_0
    libffi:          3.2.1-hd88cf55_4
    libgcc-ng:       7.2.0-h7cc24e2_2
    libstdcxx-ng:    7.2.0-h7a57d05_2
    ncurses:         6.0-h9df7e31_2
    openssl:         1.0.2m-h26d622b_1
    pip:             9.0.1-py36h6c6f9ce_4
    python:          3.6.3-h1284df2_4
    readline:        7.0-ha6073c6_4
    setuptools:      36.5.0-py36he42e2e1_0
    sqlite:          3.20.1-hb898158_2
    tk:              8.6.7-hc745277_3
    wheel:           0.29.0-py36he7f4e38_1
    xz:              5.2.3-h55aa19d_2
    zlib:            1.2.11-ha838bed_2

Proceed ([y]/n)? y
```
python-3.6.3-h 100% |#################################################################| Time: 0:00:01  16.93 MB/s
pip-9.0.1-py36 100% |#################################################################| Time: 0:00:00  54.97 MB/s
`#`
`# To activate this environment, use:`
`# > source activate py36-tensorflow`
`#`
`# To deactivate an active environment, use:`
`# > source deactivate`
`#`

`ubuntuvm@ubuntuvm:~$ source activate py36-tensorflow`
`(py36-tensorflow) ubuntuvm@ubuntuvm:~$ pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.4.0-cp36-cp36m-linux_x86_64.whl`
`Collecting tensorflow==1.4.0 from https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.4.0-cp36-cp36m-linux_x86_64.whl`
  `Downloading https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.4.0-cp36-cp36m-linux_x86_64.whl (41.2MB)`
    100% |████████████████████████████████| 41.2MB 33kB/s
`Collecting protobuf>=3.3.0 (from tensorflow==1.4.0)`
  Using cached protobuf-3.5.0-py2.py3-none-any.whl
`Collecting tensorflow-tensorboard<0.5.0,>=0.4.0rc1 (from tensorflow==1.4.0)`
  Using cached tensorflow_tensorboard-0.4.0rc3-py3-none-any.whl
`Collecting six>=1.10.0 (from tensorflow==1.4.0)`
  Using cached six-1.11.0-py2.py3-none-any.whl
`Collecting enum34>=1.1.6 (from tensorflow==1.4.0)`
  Using cached enum34-1.1.6-py3-none-any.whl
`Collecting wheel>=0.26 (from tensorflow==1.4.0)`
  Using cached wheel-0.30.0-py2.py3-none-any.whl
`Collecting numpy>=1.12.1 (from tensorflow==1.4.0)`
Exception:
Traceback (most recent call last):
  File ""/home/ubuntuvm/anaconda3/envs/py36-tensorflow/lib/python3.6/site-packages/pip/basecommand.py"", line 215,in main
    status = self.run(options, args)
  File ""/home/ubuntuvm/anaconda3/envs/py36-tensorflow/lib/python3.6/site-packages/pip/commands/install.py"", line335, in run
    wb.build(autobuilding=True)
  File ""/home/ubuntuvm/anaconda3/envs/py36-tensorflow/lib/python3.6/site-packages/pip/wheel.py"", line 749, in build
    self.requirement_set.prepare_files(self.finder)
  File ""/home/ubuntuvm/anaconda3/envs/py36-tensorflow/lib/python3.6/site-packages/pip/req/req_set.py"", line 380,in prepare_files
    ignore_dependencies=self.ignore_dependencies))
  File ""/home/ubuntuvm/anaconda3/envs/py36-tensorflow/lib/python3.6/site-packages/pip/req/req_set.py"", line 554,in _prepare_file
    require_hashes
  File ""/home/ubuntuvm/anaconda3/envs/py36-tensorflow/lib/python3.6/site-packages/pip/req/req_install.py"", line 278, in populate_link
    self.link = finder.find_requirement(self, upgrade)
  File ""/home/ubuntuvm/anaconda3/envs/py36-tensorflow/lib/python3.6/site-packages/pip/index.py"", line 465, in find_requirement
    all_candidates = self.find_all_candidates(req.name)
  File ""/home/ubuntuvm/anaconda3/envs/py36-tensorflow/lib/python3.6/site-packages/pip/index.py"", line 423, in find_all_candidates
    for page in self._get_pages(url_locations, project_name):
  File ""/home/ubuntuvm/anaconda3/envs/py36-tensorflow/lib/python3.6/site-packages/pip/index.py"", line 568, in _get_pages
    page = self._get_page(location)
  File ""/home/ubuntuvm/anaconda3/envs/py36-tensorflow/lib/python3.6/site-packages/pip/index.py"", line 683, in _get_page
    return HTMLPage.get_page(link, session=self.session)
  File ""/home/ubuntuvm/anaconda3/envs/py36-tensorflow/lib/python3.6/site-packages/pip/index.py"", line 792, in get_page
    ""Cache-Control"": ""max-age=600"",
  File ""/home/ubuntuvm/anaconda3/envs/py36-tensorflow/lib/python3.6/site-packages/pip/_vendor/requests/sessions.py"", line 488, in get
    return self.request('GET', url, **kwargs)
  File ""/home/ubuntuvm/anaconda3/envs/py36-tensorflow/lib/python3.6/site-packages/pip/download.py"", line 386, inrequest
    return super(PipSession, self).request(method, url, *args, **kwargs)
  File ""/home/ubuntuvm/anaconda3/envs/py36-tensorflow/lib/python3.6/site-packages/pip/_vendor/requests/sessions.py"", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File ""/home/ubuntuvm/anaconda3/envs/py36-tensorflow/lib/python3.6/site-packages/pip/_vendor/requests/sessions.py"", line 596, in send
    r = adapter.send(request, **kwargs)
  File ""/home/ubuntuvm/anaconda3/envs/py36-tensorflow/lib/python3.6/site-packages/pip/_vendor/cachecontrol/adapter.py"", line 37, in send
    cached_response = self.controller.cached_request(request)
  File ""/home/ubuntuvm/anaconda3/envs/py36-tensorflow/lib/python3.6/site-packages/pip/_vendor/cachecontrol/controller.py"", line 111, in cached_request
    resp = self.serializer.loads(request, cache_data)
  File ""/home/ubuntuvm/anaconda3/envs/py36-tensorflow/lib/python3.6/site-packages/pip/_vendor/cachecontrol/serialize.py"", line 114, in loads
    return getattr(self, ""_loads_v{0}"".format(ver))(request, data)
  File ""/home/ubuntuvm/anaconda3/envs/py36-tensorflow/lib/python3.6/site-packages/pip/_vendor/cachecontrol/serialize.py"", line 176, in _loads_v2
    cached = json.loads(zlib.decompress(data).decode(""utf8""))
zlib.error: Error -5 while decompressing data: incomplete or truncated stream
(py36-tensorflow) ubuntuvm@ubuntuvm:~$`
```"
14652,a document bug,"from https://www.tensorflow.org/mobile/prepare_models
in the section: How do you get a model you can use on mobile?
the right path is ：
```
bazel build tensorflow/python/tools:freeze_graph
```
not 
```
bazel build tensorflow/tools:freeze_graph
```"
14651,crash,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
14650,tensorflow lite: how to set  --input_shapes param with batchsize when gen the pb lite file,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: lastest master
- **Python version**: 2.7

### Describe the problem

my python train script input tensor define as below :
tf.placeholder(dtype=tf.float32, shape=[None, 440], name=conf.input_features_tensor)

when i execute ""bazel run --config=opt tensorflow/contrib/lite/toco:toco
 --others --input_shapes={None, 440} ""

an error show as below :

2017-11-17 17:00:10.285456: F tensorflow/contrib/lite/toco/model_cmdline_flags.cc:269] Check failed: absl::SimpleAtoi(dim_str, &size) Failed to parse input_shape: None,440.

how i can set input batch size?

@andrehentz thx
"
14648,"labels produced by Dataset  API can not be well operated!  when use tf.reduce_sum or tf.split on labels ,it returnss the wrong result ","my system :
     cuda 8.0
     tensorflow-gpu (1.3.0)
     tensorflow-tensorboard (0.1.7)
      python 2.7
       ubuntu 14.04
### *************description：**************

>  I use Dataset and Estimator to train my model.  When I test the  
>  return value  of Dataset , the return value(images and labels) of input_fn is right.   
>  But when I use tf.reduce_sum or tf.split to the labels, all results got wrong.  
>  I can't undenstand what had happend.

### **************key code*******
def dataset_parser(value,is_training): # return signal  imagel and label
def input_fn(is_training,num_epochs=1) # return batch imagel and label

FLAGS.batch_size=5
sess = tf.InteractiveSession()
images,labels = input_fn(True,1)
sess.run(labels)

> the labels of one batch
>>array([[ 0.        ,  1.        ,  2.75984216,  5.86036015],
       [ 1.        ,  0.        ,  3.82080388,  4.23745823],
       [ 1.        ,  0.        ,  7.59959507,  4.93859673],
       [ 0.        ,  1.        ,  3.29546738,  5.50357151],
       [ 0.        ,  1.        ,  2.0612247 ,  6.73015881]], dtype=float32)

label,weight,score = tf.split(value=labels,num_or_size_splits=[2,1,1],axis=1)
i = 1
print labels
print sess.run(label[i]) 
print sess.run(weight[i])
print sess.run(score[i])  

>  we expected to get the split value of [1,0] [3.82080388,],[ 4.23745823] ,but the result is following
>>Tensor(""IteratorGetNext:1"", shape=(?, 4), dtype=float32)
>>[ 0.  1.]
>>[ 2.85865355]
>>[ 5.57142878]

a = tf.reduce_sum(labels,0)
print  sess.run(a)
> we expected to get the values of [  2. 　　 , 3.　　　,  19.53693319　　 , 27.27014543],but we get the following result.
 >>[  4.           1.          25.82047653  24.87050629]


### # """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""code detail """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

```
def dataset_parser(value,is_training):
    features = {}
    features['image'] = tf.FixedLenFeature([], tf.string)
    features['average_score'] = tf.FixedLenFeature((),tf.float32,default_value=0)
    features['aes_tag'] = tf.FixedLenFeature((),tf.float32,default_value=0)
 
    parsed = tf.parse_single_example(value, features=features)
    image = tf.decode_raw(parsed['image'],tf.uint8)
    image = tf.reshape(image,[256,256,3])

    aes_tag = tf.one_hot(tf.cast(parsed['aes_tag'],tf.int32),FLAGS.num_classes)
    if is_training:
        weight = tf.where(tf.greater(score,5),FLAGS.beta,FLAGS.alpha)
        label = tf.reshape(tf.concat([aes_tag,[weight],[score]],0),(4,))
    
    else:
        weight = tf.ones(1,dtype=tf.float32)
        label = tf.reshape(tf.concat([aes_tag,weight],0),(3,))

    
    return image,label


def input_fn(is_training,num_epochs=1):
    """"""Input function which provides batches for train or eval.""""""
    dataset = tf.contrib.data.TFRecordDataset([FLAGS.train_data_path if is_training  else FLAGS.test_data_path])

    if is_training:
        dataset = dataset.repeat(num_epochs)

    dataset = dataset.map(lambda value: dataset_parser(value, is_training),
        num_threads=5,output_buffer_size=FLAGS.batch_size)

    if is_training:
        buffer_size = 1250 + 2 * FLAGS.batch_size
        dataset = dataset.shuffle(buffer_size=buffer_size)
    iterator = dataset.batch(FLAGS.batch_size).make_one_shot_iterator()
    images, labels = iterator.get_next()
    return images, labels
     
```"
14646,tf.bitwise.bitwise_and and friends have bad shape functions,"The bitwise ops are componentwise and do normal broadcasting at the kernel level.  However, they claim unchanged shape during op registration:

    #define BINARY_BITWISE()                                                     \
      Input(""x: T"")                                                              \
          .Input(""y: T"")                                                         \
          .Output(""z: T"")                                                        \
          .SetIsCommutative()                                                    \
          .Attr(""T: {int8, int16, int32, int64, uint8, uint16, uint32, uint64}"") \
          .SetShapeFn(shape_inference::UnchangedShape)

To reproduce, do

    >>> import tensorflow as tf
    >>> tf.bitwise.bitwise_and(tf.zeros([3,1], dtype=tf.int32), tf.zeros([1,3], dtype=tf.int32))
    <tf.Tensor 'BitwiseAnd:0' shape=(3, 1) dtype=int32>

The result shape should be `(3, 3)`, not `(3, 1)`."
14645,"Is tensorflow Lite support for detection, like SSD？","Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
14643,"Can google publish checkpoint file for some common network:VGG, AlexNet","In tensorflow/models repository, developer maintains some pre-built model and checkpoint files from some famous network, it is very convenient  for some developer don't have too much computation resources, train a network from scratch can take a very long time.  The author of these networks do publish weights file but It is not for tensorflow, mostly for caffe. "
14642,Android tensorflow lite kernel_util.cc:34 input_product_scale < output_scale,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Windows 7.0
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 3.0
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

### Describe the problem
1.down load Quantilized MobileNet model 0.75_224 from [here](https://storage.googleapis.com/download.tensorflow.org/models/mobilenet_v1_0.75_224_frozen.tgz
)

2.Transform the frozen .pb model to .tflite file:
 bazel run --config=opt tensorflow/contrib/lite/toco:toco -- --input_file=tmp/mobilenet_v1_0.75_224/frozen_graph.pb --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --output_file=tmp/mobilenet_v1_0.75_224/mobilenet_v1_0.75_224.tflite --inference_type=QUANTIZED_UINT8  --input_type=QUANTIZED_UINT8  --input_arrays=input --default_ranges_min=0 --default_ranges_max=6 --output_arrays=MobilenetV1/Predictions/Reshape_1 --input_shapes=1,224,224,3

3.Change the ""MODEL_PATH"" in Tensorflow lite Android demo to ""mobilenet_v1_0.75_224.tflite""

### logs
4.Then run the demo, make the error:
FATAL EXCEPTION: CameraBackground
                                                                                      Process: android.example.com.tflitecamerademo, PID: 13909
                                                                                      java.lang.NullPointerException: Can not allocate memory for the given inputs: tensorflow/contrib/lite/kernels/kernel_util.cc:34 input_product_scale < output_scale was not true.
                                                                                          at org.tensorflow.lite.NativeInterpreterWrapper.run(Native Method)
                                                                                          at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:95)
                                                                                          at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:112)
                                                                                          at org.tensorflow.lite.Interpreter.run(Interpreter.java:93)
                                                                                          at com.example.android.tflitecamerademo.ImageClassifier.classifyFrame(ImageClassifier.java:109)
                                                                                          at com.example.android.tflitecamerademo.Camera2BasicFragment.classifyFrame(Camera2BasicFragment.java:663)
                                                                                          at com.example.android.tflitecamerademo.Camera2BasicFragment.-wrap0(Camera2BasicFragment.java)
                                                                                          at com.example.android.tflitecamerademo.Camera2BasicFragment$4.run(Camera2BasicFragment.java:558)
                                                                                          at android.os.Handler.handleCallback(Handler.java:739)
                                                                                          at android.os.Handler.dispatchMessage(Handler.java:95)
                                                                                          at android.os.Looper.loop(Looper.java:135)
                                                                                          at android.os.HandlerThread.run(HandlerThread.java:61)

need your help?

Followed the same steps , transform other mobilenet models, only the  ""mobilenet_v1_1.0_128"" can run successfully.
"
14641,Incorrect second derivative for softmax cross entropy,"
### System information
-  I've written custom code
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: tensorflow-gpu==1.2.1
- python version: 2.7.12
- **CUDA/cuDNN version**: CUDA version: 8.0 and CUDNN version is: 8.0
- **GPU model and memory**: GeForce GTX 750 2GB

Incorrect second derivative for softmax cross entropy

### Source code / logs
```
import tensorflow as tf
import tensorflow.contrib.eager as tfe
import numpy as np

tfe.enable_eager_execution()

logits = [0.5, 0.5]
y = [1, 0]

def loss_function(x):
    loss2 = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=x)
    return loss2

grad_loss = tfe.gradients_function(loss_function)
print grad_loss(logits)[0] # prints correct gradient [-0.5 0.5]

gradgrad_loss = tfe.gradients_function(lambda x: grad_loss(x)[0])
print gradgrad_loss(logits)[0] # this should be [-0.25,  0.25], but it prints [0. 0.]
```"
14636,Tensorflow Python ,"Hi This is my code for tensorflow_serve python client :

```
data = f.read()
data = base64.urlsafe_b64encode(data)
request = predict_pb2.PredictRequest()
request.model_spec.name = 'test'
request.model_spec.signature_name = 'serving_default'
data = tf.contrib.util.make_tensor_proto(data,shape=[1])

req=request.inputs['input'].CopyFrom(data)
```
could you please do me a favor and tell me how to convert(change) :
```

dtype: DT_STRING
tensor_shape {
dim {
size: 1
 }
}
string_val: ""_9j_4AAQSkZJRgABAQEAYABgAAD_4QAWRXhpZgAASUk
```

to :
```

inputs: {
dtype: DT_STRING
tensor_shape {
dim {
size: 1
 }
}
string_val: ""_9j_4AAQSkZJRgABAQEAYABgAAD_4QAWRXhpZgAASUk
```
"
14633,[FEATURE REQUEST] Report uninitialized data iterators.,"At https://github.com/GPflow/GPflow/issues/561 we found that, iterators are not variables :), therefore `report_uninitalized_variables` fails with:

```
...
~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py in is_variable_initialized(ref, name)
    182     A `Tensor` of type `bool`.
    183   """"""
--> 184   if ref.dtype._is_ref_dtype:
    185     return gen_state_ops.is_variable_initialized(ref=ref, name=name)
    186   # Handle resource variables.

AttributeError: 'Iterator' object has no attribute 'dtype'
```

```
import numpy as np
from tensorflow import data
Dataset = data.Dataset
pl = tf.placeholder(tf.float32)
data = Dataset.from_tensor_slices(pl)
iterator = data.make_initializable_iterator()
batch = iterator.get_next()

## In fact it fails for TensorFlow 1.3 and 1.4
sess.run(tf.report_uninitialized_variables([iterator]))
```

Frankly, it must be very easy to adapt `report_unitialized_variables` to report data's unitialized iterators. This would be helpful to avoid re-initializing datasets each time when we call `session.run` in GPflow. Right now, it provides initializing by demand feature.

Best,
Artem Artemev"
14632,libtensorflow_cc.so linker issues with release 1.4 Undefined reference ,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
  Yes, code similar to the example label_image.cc

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
 Linux Ubuntu 16.04

- **TensorFlow installed from (source or binary)**:
From source

- **TensorFlow version (use command below)**:
1.4.0

- **Python version**: 
3.6.1

- **Bazel version (if compiling from source)**:
0.7

- **GCC/Compiler version (if compiling from source)**:
5.4.0

- **CUDA/cuDNN version**:
N/A

- **GPU model and memory**:
N/A

- **Exact command to reproduce**:
build libtensorflow_cc.so from command:
bazel build --config=opt --config=mkl --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-msse4.2 //tensorflow:libtensorflow_cc.so //tensorflow/tools/pip_package:build_pip_package

### Describe the problem
After successfully build the library, try to compile my code with the library using following gcc command:

g++ -I/usr/local/include -L/usr/local/lib -ltensorflow -std=c++11 rtclassifier.cc

result in 'undefined reference to `tensorflow::GraphDef::GraphDef()' error

### Source code / logs

/tmp/ccxBMZph.o: In function `LoadGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::unique_ptr<tensorflow::Session, std::default_delete<tensorflow::Session> >*)':
tl_classifier.cc:(.text+0x90): undefined reference to `tensorflow::GraphDef::GraphDef()'
tl_classifier.cc:(.text+0xa4): undefined reference to `tensorflow::Env::Default()'
tl_classifier.cc:(.text+0xc4): undefined reference to `tensorflow::ReadBinaryProto(tensorflow::Env*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, google::protobuf::MessageLite*)'
tl_classifier.cc:(.text+0x15e): undefined reference to `tensorflow::SessionOptions::SessionOptions()'
tl_classifier.cc:(.text+0x16d): undefined reference to `tensorflow::NewSession(tensorflow::SessionOptions const&)'
tl_classifier.cc:(.text+0x22a): undefined reference to `tensorflow::GraphDef::~GraphDef()'
tl_classifier.cc:(.text+0x2b7): undefined reference to `tensorflow::GraphDef::~GraphDef()'
/tmp/ccxBMZph.o: In function `ReadTensorFromImageFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, int, int, float, float, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*)':
tl_classifier.cc:(.text+0x332): undefined reference to `tensorflow::Scope::NewRootScope()'
tl_classifier.cc:(.text+0x3dd): undefined reference to `tensorflow::Scope::WithOpName(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'
tl_classifier.cc:(.text+0x3fd): undefined reference to `tensorflow::ops::ReadFile::ReadFile(tensorflow::Scope const&, tensorflow::Input)'
tl_classifier.cc:(.text+0x40c): undefined reference to `tensorflow::Scope::~Scope()'
tl_classifier.cc:(.text+0x504): undefined reference to `tensorflow::Scope::WithOpName(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'
tl_classifier.cc:(.text+0x528): undefined reference to `tensorflow::ops::DecodePng::DecodePng(tensorflow::Scope const&, tensorflow::Input, tensorflow::ops::DecodePng::Attrs const&)'
tl_classifier.cc:(.text+0x587): undefined reference to `tensorflow::Scope::~Scope()'
tl_classifier.cc:(.text+0x671): undefined reference to `tensorflow::Scope::WithOpName(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'
tl_classifier.cc:(.text+0x691): undefined reference to `tensorflow::ops::DecodeGif::DecodeGif(tensorflow::Scope const&, tensorflow::Input)'
tl_classifier.cc:(.text+0x6f4): undefined reference to `tensorflow::Scope::WithOpName(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'
tl_classifier.cc:(.text+0x714): undefined reference to `tensorflow::ops::Squeeze::Squeeze(tensorflow::Scope const&, tensorflow::Input)'
tl_classifier.cc:(.text+0x773): undefined reference to `tensorflow::Scope::~Scope()'
tl_classifier.cc:(.text+0x7be): undefined reference to `tensorflow::Scope::~Scope()'
tl_classifier.cc:(.text+0x867): undefined reference to `tensorflow::Scope::WithOpName(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'
tl_classifier.cc:(.text+0x88b): undefined reference to `tensorflow::ops::DecodeJpeg::DecodeJpeg(tensorflow::Scope const&, tensorflow::Input, tensorflow::ops::DecodeJpeg::Attrs const&)'
tl_classifier.cc:(.text+0x8ea): undefined reference to `tensorflow::Scope::~Scope()'
tl_classifier.cc:(.text+0x97a): undefined reference to `tensorflow::Scope::WithOpName(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'
tl_classifier.cc:(.text+0x99c): undefined reference to `tensorflow::ops::Cast::Cast(tensorflow::Scope const&, tensorflow::Input, tensorflow::DataType)'
tl_classifier.cc:(.text+0x9ab): undefined reference to `tensorflow::Scope::~Scope()'
tl_classifier.cc:(.text+0xa38): undefined reference to `tensorflow::ops::ExpandDims::ExpandDims(tensorflow::Scope const&, tensorflow::Input, tensorflow::Input)'
tl_classifier.cc:(.text+0xaea): undefined reference to `tensorflow::Scope::WithOpName(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'
tl_classifier.cc:(.text+0xb0a): undefined reference to `tensorflow::ops::Const(tensorflow::Scope const&, tensorflow::Input::Initializer const&)'
tl_classifier.cc:(.text+0xb60): undefined reference to `tensorflow::ops::ResizeBilinear::ResizeBilinear(tensorflow::Scope const&, tensorflow::Input, tensorflow::Input)'
tl_classifier.cc:(.text+0xb9c): undefined reference to `tensorflow::Scope::~Scope()'
tl_classifier.cc:(.text+0xc9c): undefined reference to `tensorflow::ops::Subtract::Subtract(tensorflow::Scope const&, tensorflow::Input, tensorflow::Input)'
tl_classifier.cc:(.text+0xcd5): undefined reference to `tensorflow::Scope::WithOpName(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'
tl_classifier.cc:(.text+0xcf9): undefined reference to `tensorflow::ops::Div::Div(tensorflow::Scope const&, tensorflow::Input, tensorflow::Input)'
tl_classifier.cc:(.text+0xd17): undefined reference to `tensorflow::Scope::~Scope()'
tl_classifier.cc:(.text+0xdbb): undefined reference to `tensorflow::GraphDef::GraphDef()'
tl_classifier.cc:(.text+0xddb): undefined reference to `tensorflow::Scope::ToGraphDef(tensorflow::GraphDef*) const'
tl_classifier.cc:(.text+0xe3e): undefined reference to `tensorflow::SessionOptions::SessionOptions()'
tl_classifier.cc:(.text+0xe4d): undefined reference to `tensorflow::NewSession(tensorflow::SessionOptions const&)'
tl_classifier.cc:(.text+0x109e): undefined reference to `tensorflow::GraphDef::~GraphDef()'
tl_classifier.cc:(.text+0x1116): undefined reference to `tensorflow::Scope::~Scope()'
tl_classifier.cc:(.text+0x1175): undefined reference to `tensorflow::Scope::~Scope()'
tl_classifier.cc:(.text+0x11b4): undefined reference to `tensorflow::Scope::~Scope()'
tl_classifier.cc:(.text+0x1216): undefined reference to `tensorflow::Scope::~Scope()'
tl_classifier.cc:(.text+0x1275): undefined reference to `tensorflow::Scope::~Scope()'
/tmp/ccxBMZph.o:tl_classifier.cc:(.text+0x12d7): more undefined references to `tensorflow::Scope::~Scope()' follow
/tmp/ccxBMZph.o: In function `ReadTensorFromImageFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, int, int, float, float, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*)':
tl_classifier.cc:(.text+0x15ee): undefined reference to `tensorflow::GraphDef::~GraphDef()'
tl_classifier.cc:(.text+0x167a): undefined reference to `tensorflow::Scope::~Scope()'
/tmp/ccxBMZph.o: In function `GetTopLabels(std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> > const&, int, tensorflow::Tensor*, tensorflow::Tensor*)':
tl_classifier.cc:(.text+0x18fe): undefined reference to `tensorflow::Scope::NewRootScope()'
tl_classifier.cc:(.text+0x1999): undefined reference to `tensorflow::Scope::WithOpName(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'
tl_classifier.cc:(.text+0x19bd): undefined reference to `tensorflow::ops::TopK::TopK(tensorflow::Scope const&, tensorflow::Input, tensorflow::Input)'
tl_classifier.cc:(.text+0x19db): undefined reference to `tensorflow::Scope::~Scope()'
tl_classifier.cc:(.text+0x1a08): undefined reference to `tensorflow::GraphDef::GraphDef()'
tl_classifier.cc:(.text+0x1a28): undefined reference to `tensorflow::Scope::ToGraphDef(tensorflow::GraphDef*) const'
tl_classifier.cc:(.text+0x1a8b): undefined reference to `tensorflow::SessionOptions::SessionOptions()'
tl_classifier.cc:(.text+0x1a9a): undefined reference to `tensorflow::NewSession(tensorflow::SessionOptions const&)'
tl_classifier.cc:(.text+0x1d7e): undefined reference to `tensorflow::GraphDef::~GraphDef()'
tl_classifier.cc:(.text+0x1d9c): undefined reference to `tensorflow::Scope::~Scope()'
tl_classifier.cc:(.text+0x1de4): undefined reference to `tensorflow::Scope::~Scope()'
tl_classifier.cc:(.text+0x1f1a): undefined reference to `tensorflow::GraphDef::~GraphDef()'
tl_classifier.cc:(.text+0x1f3d): undefined reference to `tensorflow::Scope::~Scope()'
/tmp/ccxBMZph.o: In function `PrintTopLabels(std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)':
tl_classifier.cc:(.text+0x1ff4): undefined reference to `tensorflow::internal::LogMessage::LogMessage(char const*, int, int)'
tl_classifier.cc:(.text+0x201c): undefined reference to `tensorflow::internal::LogMessage::~LogMessage()'
tl_classifier.cc:(.text+0x2081): undefined reference to `tensorflow::Tensor::Tensor()'
tl_classifier.cc:(.text+0x2090): undefined reference to `tensorflow::Tensor::Tensor()'
tl_classifier.cc:(.text+0x21ed): undefined reference to `tensorflow::internal::LogMessage::LogMessage(char const*, int, int)'
tl_classifier.cc:(.text+0x225a): undefined reference to `tensorflow::internal::LogMessage::~LogMessage()'
tl_classifier.cc:(.text+0x2284): undefined reference to `tensorflow::Tensor::~Tensor()'
tl_classifier.cc:(.text+0x2293): undefined reference to `tensorflow::Tensor::~Tensor()'
tl_classifier.cc:(.text+0x22e2): undefined reference to `tensorflow::internal::LogMessage::~LogMessage()'
"
14629,Documentation error in attention_wrapper.py,"In tf.contrib.seq2seq.attention_wrapper.py file, in line 295, it should be [batch_size, 1, max_time], instead of [batch_time, ...], hope to fix it soon!! Thanks !!"
14626,[FR] Target for Cortex-M7,"With the recent availability of TensorFlow Lite, it seems now possible to target embedded systems other than mobiles. [Cortex-M7](https://developer.arm.com/products/processors/cortex-m/cortex-m7) is the highest performing processor in the Cortex MCU family has ICs from [several](http://www.st.com/en/microcontrollers/stm32-high-performance-mcus.html?querycriteria=productId=SC2154) [big](https://www.microchip.com/design-centers/32-bit/sam-32-bit-mcus/sam-s-mcus) [names](https://www.nxp.com/products/processors-and-microcontrollers/arm-based-processors-and-mcus/kinetis-cortex-m-mcus/v-seriesreal-time-ctlm0-plus-m4-m7/kinetis-kv5x-240-mhz-motor-control-and-power-conversion-ethernet-mcus-based-on-arm-cortex-m7:KV5x). Would it be feasible to get a target for the M7? For those interested in playing around with one, I'd suggest the ST [NUCLEO-F767ZI](http://www.st.com/content/st_com/en/products/evaluation-tools/product-evaluation-tools/mcu-eval-tools/stm32-mcu-eval-tools/stm32-mcu-nucleo/nucleo-f767zi.html) as it is affordable and available (I got one at an event.) Its bigger brother, the [NUCLEO-H743ZI](http://www.st.com/content/st_com/en/products/evaluation-tools/product-evaluation-tools/mcu-eval-tools/stm32-mcu-eval-tools/stm32-mcu-nucleo/nucleo-h743zi.html), doesn't seem to be available just yet."
14625,float16 support for separable_convolutions,"### System information
- **Have I written custom code**:
No
- **OS Platform and Distribution **:
16.04
- **TensorFlow installed from**:
from pip package
- **TensorFlow version**:
1.4.0
- **Python version**: 
3.5.2
- **CUDA/cuDNN version**:
CUDA 8.0, cuDNN 6.0
- **GPU model and memory**:
1080Ti with 12GB Memory
- **Exact command to reproduce**:

It appears that half precision support is still not available for separable_convolutions even with tf 1.4.0 release.

```
inputs_32 = tf.placeholder(tf.float32, shape=(1,16,16,3))
inputs_16 = tf.placeholder(tf.float16, shape=(1,16,16,3))
slim.separable_conv2d(inputs_32,16,[3,3],depth_multiplier=1)
slim.separable_conv2d(inputs_16,16,[3,3],depth_multiplier=1)
```

The first call succeeds (as expected), while the second fails with the following error:
`TypeError: Value passed to parameter 'input' has DataType float16 not in list of allowed values: float32, float64`

I also tried that with tf.nn.separable_conv2d(.), but with same results.

**Full Error Traceback**
```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-6-61a1fd560923> in <module>()
----> 1 slim.separable_conv2d(inputs_16,16,[3,3],depth_multiplier=1)

~/.virtualenvs/p3.5-tf1.4/lib/python3.5/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py in func_with_args(*args, **kwargs)
    179       current_args = current_scope[key_func].copy()
    180       current_args.update(kwargs)
--> 181     return func(*args, **current_args)
    182   _add_op(func)
    183   setattr(func_with_args, '_key_op', _key_op(func))

~/.virtualenvs/p3.5-tf1.4/lib/python3.5/site-packages/tensorflow/contrib/layers/python/layers/layers.py in separable_convolution2d(inputs, num_outputs, kernel_size, depth_multiplier, stride, padding, data_format, rate, activation_fn, normalizer_fn, normalizer_params, weights_initializer, weights_regularizer, biases_initializer, biases_regularizer, reuse, variables_collections, outputs_collections, trainable, scope)
   2500           _scope=sc,
   2501           _reuse=reuse)
-> 2502       outputs = layer.apply(inputs)
   2503 
   2504       # Add variables to collections.

~/.virtualenvs/p3.5-tf1.4/lib/python3.5/site-packages/tensorflow/python/layers/base.py in apply(self, inputs, *args, **kwargs)
    669       Output tensor(s).
    670     """"""
--> 671     return self.__call__(inputs, *args, **kwargs)
    672 
    673   def _add_inbound_node(self,

~/.virtualenvs/p3.5-tf1.4/lib/python3.5/site-packages/tensorflow/python/layers/base.py in __call__(self, inputs, *args, **kwargs)
    573         if in_graph_mode:
    574           self._assert_input_compatibility(inputs)
--> 575         outputs = self.call(inputs, *args, **kwargs)
    576 
    577         if outputs is None:

~/.virtualenvs/p3.5-tf1.4/lib/python3.5/site-packages/tensorflow/python/layers/convolutional.py in call(self, inputs)
    982         padding=self.padding.upper(),
    983         rate=self.dilation_rate,
--> 984         data_format=utils.convert_data_format(self.data_format, ndim=4))
    985 
    986     if self.use_bias:

~/.virtualenvs/p3.5-tf1.4/lib/python3.5/site-packages/tensorflow/python/ops/nn_impl.py in separable_conv2d(input, depthwise_filter, pointwise_filter, strides, padding, rate, name, data_format)
    488         padding=padding,
    489         data_format=data_format,
--> 490         op=op)
    491 
    492     return nn_ops.conv2d(

~/.virtualenvs/p3.5-tf1.4/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py in with_space_to_batch(input, dilation_rate, padding, op, filter_shape, spatial_dims, data_format)
    343                              spatial_dims=spatial_dims,
    344                              data_format=data_format)
--> 345   return new_op(input, None)
    346 
    347 

~/.virtualenvs/p3.5-tf1.4/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py in __call__(self, inp, filter)
    497 
    498   def __call__(self, inp, filter):  # pylint: disable=redefined-builtin
--> 499     return self.call(inp, filter)
    500 
    501 

~/.virtualenvs/p3.5-tf1.4/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py in <lambda>(inp, _)
    334 
    335   def build_op(num_spatial_dims, padding):
--> 336     return lambda inp, _: op(inp, num_spatial_dims, padding)
    337 
    338   new_op = _WithSpaceToBatch(input_shape,

~/.virtualenvs/p3.5-tf1.4/lib/python3.5/site-packages/tensorflow/python/ops/nn_impl.py in op(input_converted, _, padding)
    480           padding=padding,
    481           data_format=data_format,
--> 482           name=""depthwise"")
    483 
    484     depthwise = nn_ops.with_space_to_batch(

~/.virtualenvs/p3.5-tf1.4/lib/python3.5/site-packages/tensorflow/python/ops/gen_nn_ops.py in depthwise_conv2d_native(input, filter, strides, padding, data_format, name)
   1159     _, _, _op = _op_def_lib._apply_op_helper(
   1160         ""DepthwiseConv2dNative"", input=input, filter=filter, strides=strides,
-> 1161         padding=padding, data_format=data_format, name=name)
   1162     _result = _op.outputs[:]
   1163     _inputs_flat = _op.inputs

~/.virtualenvs/p3.5-tf1.4/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py in _apply_op_helper(self, op_type_name, name, **keywords)
    607               _SatisfiesTypeConstraint(base_type,
    608                                        _Attr(op_def, input_arg.type_attr),
--> 609                                        param_name=input_name)
    610             attrs[input_arg.type_attr] = attr_value
    611             inferred_from[input_arg.type_attr] = input_name

~/.virtualenvs/p3.5-tf1.4/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py in _SatisfiesTypeConstraint(dtype, attr_def, param_name)
     58           ""allowed values: %s"" %
     59           (param_name, dtypes.as_dtype(dtype).name,
---> 60            "", "".join(dtypes.as_dtype(x).name for x in allowed_list)))
     61 
     62 

TypeError: Value passed to parameter 'input' has DataType float16 not in list of allowed values: float32, float64
```

"
14624,Bug: using regularizer for shared variables in tf.cond branches ,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS X 10.13.1
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.3.0
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**:


### Describe the problem
Setting the `regularizer` of a shared variable in `tf.cond` branches gives an unexpected behaviour - only one copy of the regularization op is added to `tf.GraphKeys.REGULARIZATION_LOSSES`. This is different from adding operations to a collection explicitly. And optimizing the regularization loss doesn't raise an error.


### Source code
```python
import tensorflow as tf
from tensorflow.contrib.layers.python.layers import regularizers


def regularised_model(is_training):
    scope_name = 'foo'
    with tf.variable_scope(scope_name) as scope:
        if is_training:
            scope.reuse_variables()
        y = tf.get_variable(
            name='y', shape=(),
            initializer=tf.constant_initializer(1.0),
            regularizer=regularizers.l2_regularizer(scale=0.1, scope=scope_name))
        reg = tf.nn.l2_loss(y) * 0.1
        tf.add_to_collection('test_collection', reg)
    return y

binary_flag = tf.placeholder(dtype=tf.bool, shape=())
y_cond = tf.cond(binary_flag,
                 lambda: regularised_model(False),
                 lambda: regularised_model(True))

reg_loss = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)
assert(len(reg_loss) == 1)
output = y_cond + reg_loss[0]
opt = tf.train.AdamOptimizer(0.1).minimize(output)

reg_test = tf.get_collection('test_collection')
assert(len(reg_test) == 2)
output_reg_true = y_cond + reg_test[0]
output_reg_false = y_cond + reg_test[1]


with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    print(sess.run(output_reg_true, feed_dict={binary_flag: True})) # 1.05
    print(sess.run(output_reg_false, feed_dict={binary_flag: False})) # 1.05

    print(sess.run(output, feed_dict={binary_flag: True})) # 1.05
    
    print(sess.run([opt], feed_dict={binary_flag: True})) # [None]
    print(sess.run([opt], feed_dict={binary_flag: False})) # [None]

    print(sess.run(output, feed_dict={binary_flag: False})) # Error: Retval[0] does not have value

```
### Log
```
1.05
1.05
1.05
[None]
[None]
Traceback (most recent call last):
  File ""test_tf_cond.py"", line 43, in <module>
    print(sess.run(output, feed_dict={binary_flag: False})) # Error: Retval[0] does not have value
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 895, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1124, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1321, in _do_run
    options, run_metadata)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1340, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Retval[0] does not have value
```"
14623,[BUG] tf.while_loop creates a seg-fault when setting parallel_iterations to high values,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: both
- **TensorFlow version (use command below)**: 1.3 / 1.4
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: 0.5.4
- **GCC/Compiler version (if compiling from source)**: 5.4.0
- **CUDA/cuDNN version**: 8
- **GPU model and memory**: Tesla P100-PCIE-16GB
- **Exact command to reproduce**:
### Describe the problem

The following code crashes on all of my test systems, with tensorflow 1.3 or 1.4.
Doesn't matter if build with MKL or without or using the pip-version.
```
import numpy as np
import tensorflow as tf

num_dim = 20
FORMAT = tf.float64 #32 or 64 does not matter
n = 3500 #reducing the number results in normal execution

def simpeLoop(alpha):
      i = tf.constant(0)
      m0 = tf.zeros([num_dim, 1], dtype=FORMAT)
      cond = lambda i, m: i < n
      def body(ic, vec): 
            #a meaningless example, summing up the first num_dim elements of a vector 
            op = alpha[ic * num_dim:(ic + 1) * num_dim, :]
            # with tf.control_dependencies([op]): #if you uncomment this, it will not fault!
            return ic + 1, vec + op
      loop = tf.while_loop(cond, body, [i, m0], parallel_iterations=10**4, back_prop=False)
      return loop[1]

with tf.device('/cpu:0'):
      alpha = tf.placeholder(FORMAT, [None, 1], name=""alpha"")
      fdict = {
          alpha: np.random.rand(n * num_dim, 1),
      }
      op = simpeLoop(alpha)
      op = tf.reduce_sum(op) #not necessary for the seg fault
      init = tf.global_variables_initializer()

config = tf.ConfigProto()
threads = 1
config.intra_op_parallelism_threads = threads
config.inter_op_parallelism_threads = threads
sess = tf.Session(config=config)
sess.run(init, feed_dict=fdict)
print(""init"")
print(sess.run(op, feed_dict=fdict))
```
Adding the control_dependencies results in normal execution.

The documentation states 

> The maximum number of parallel iterations can be controlled by parallel_iterations, which gives users some control over memory consumption and execution order

so I would expect parallel_iterations to be some kind of upper bound. 
Small tests like presented in  #12937 showed that increasing the parallel_iterations number results in higher performance. But setting it to high results in a seg fault.
 



"
14622,ImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory,"I'm trying to run Tensorflow-gpu through virtualenv via pip3 in Ubuntu 16.04. I have installed Cuda-9.0 and cuDNN v7.0.3, then tested both and they are working fine. However, when attempting to import Tensorflow in Python I get the following error:

> Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/usr/lib/python3.5/imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""/usr/lib/python3.5/imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory

I located libcublas.so in /usr/local/cuda/lib64. However, I see that it references a new version of the library (9.0.176), My question is whether something simple can be done (like creating a symbolic link to the library with the name of libcublas.so.8.0) or I have to wait for an update in TF that can run with Cuda9/cuDNN 7

Cheers!
"
14621,Tensorflow Lite Error: when convert frozen Graphdef  to flatbuffer format (.lite) ,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**:master lastest
- **Python version**: 2.7
- **Bazel version (if compiling from source)**:0.7

### Describe the problem
Tensorflow Lite Error: when convert frozen Graphdef  to flatbuffer format (.lite) 

ERROR：
2017-11-16 19:38:54.835542: F tensorflow/contrib/lite/toco/tflite/export.cc:294] Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If you have a custom implementation for them you can disable this error with --allow_custom_ops. Here is a list of operators for which you will need custom implementations: ArgMax.

Can anyone tell me how to solve this problem? 

"
14620,tf r1.4 bazel build error: nsync?,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: r1.4
- **Python version**: 
- **Bazel version (if compiling from source)**: 0.7.0 
- **GCC/Compiler version (if compiling from source)**: ****gcc (Ubuntu 5.4.1-2ubuntu1~16.04) 5.4.1 20160904
- **CUDA/cuDNN version**: 8.0 / 6 

- **Exact command to reproduce**:
    sudo bazel build -c opt --config=cuda --copt=""-mtune=native"" --copt=""-O3"" tensorflow:libtensorflow_cc.so tensorflow:libtensorflow.so --genrule_strategy=standalone --spawn_strategy=standalone

### Problem
I use tensorflow c++ api to run some RL applications.
When I run my project, I get this error. It was okay with tensorflow r1.3 or older versions.

/home/joonho/workspace/rai/deepLearning/tensorflow/tensorflow/core/platform/default/mutex.h:25:22: fatal error: nsync_cv.h: No such file or directory
 #include ""nsync_cv.h""
                      ^

I think there's linking error. I clearly have the headers in my environment.  
How can I fix this? is this bug in tf r1.4 or am I doing something wrong?

joonho@joonho-HP-Z440-Workstation:~$ locate nsync_cv.h
/home/joonho/.cache/bazel/_bazel_root/4eb2082608889a2b4334c89631226226/external/nsync/public/nsync_cv.h
/home/joonho/.virtualenvs/tensorflow/lib/python3.5/site-packages/external/nsync/public/nsync_cv.h
/home/joonho/.virtualenvs/tensorflow/lib/python3.5/site-packages/tensorflow/include/external/nsync/public/nsync_cv.h
"
14619,"Undefined symbols ""_cblas_sgemm"" on iOS","Hello,

I downloaded the latest release 1.4.0 and builded it for iOS with build_all_ios.sh, and can successfully build libtensorflow-core.a, libprotobuf-lite.a and libprotobuf.a, and added the libtensorflow-core.a with -force_load

but error happened when link these libs to iOS project, the detail info as follows, can anybody know how to fix it? thanks
Undefined symbols for architecture arm64:
  ""_cblas_sgemm"", referenced from:
      tensorflow::Conv2DUsingGemmOp<float, tensorflow::(anonymous namespace)::Im2ColConvFunctor<float, float, float, FastGemmFunctor<float, float, float> > >::Compute(tensorflow::OpKernelContext*) in libtensorflow-core.a(conv_ops_using_gemm.o)
      tensorflow::FusedResizeConv2DUsingGemmOp<float, tensorflow::(anonymous namespace)::FusedResizeAndPadConvFunctor<float, float, float, FastGemmFunctor<float, float, float>, (tensorflow::(anonymous namespace)::SamplingMode)0>, true>::Compute(tensorflow::OpKernelContext*) in libtensorflow-core.a(conv_ops_fused.o)
      tensorflow::FusedResizeConv2DUsingGemmOp<float, tensorflow::(anonymous namespace)::FusedResizeAndPadConvFunctor<float, float, float, FastGemmFunctor<float, float, float>, (tensorflow::(anonymous namespace)::SamplingMode)1>, false>::Compute(tensorflow::OpKernelContext*) in libtensorflow-core.a(conv_ops_fused.o)
ld: symbol(s) not found for architecture arm64
clang: error: linker command failed with exit code 1 (use -v to see invocation)
"
14618,Error in tf.image.extract_glimpse documentation,"Hi,
I think there is an error into the documentation of the **tf.image.extract_glimpse** into the **offsets** definition:

**offsets**: A Tensor of type float32. A 2-D integer tensor of shape [batch_size, 2] containing the **x, y** locations of the center of each window.

Are you sure it is not **y,x** instead? Also into the previous field:

**size**: A Tensor of type int32. A 1-D tensor of 2 elements containing the size of the glimpses to extract. **The glimpse height must be specified first, following by the glimpse width.**

So for **size** you place height (y) **before** width (x) which is the usual thing to do, but in **offsets** you require to have x (width) before y (height) which I think is wrong.

Thanks,
Andrea"
14617,ValueError: graph_def is invalid at node u'decode/DecodeJpeg': Input tensor 'image_feed:0' Cannot convert a tensor of type float32 to an input of type string.,"when i try to quantize the graph after optimize, i get the error 
ValueError: graph_def is invalid at node u'decode/DecodeJpeg': Input tensor 'image_feed:0' Cannot convert a tensor of type float32 to an input of type string.

python ./tensorflow/tools/quantization/quantize_graph.py \
--input=/Users/jie/tensorflow/models/models/im2txt/im2txt/model/train/optimize_graph.pb \
--output=/Users/jie/tensorflow/models/models/im2txt/im2txt/model/train/rounded_graph.pb \
--output_node_names=lstm/initial_state,softmax,lstm/state \
--mode=weights_rounded 



"
14616,help me with tensorflow!,"wxf@wxf-K56L:~$ source activate tensorflow
(tensorflow) wxf@wxf-K56L:~$ python
Python 2.7.14 |Anaconda, Inc.| (default, Nov  8 2017, 22:44:41) 
[GCC 7.2.0] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/wxf/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/home/wxf/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/home/wxf/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 72, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/home/wxf/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/home/wxf/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/home/wxf/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
ImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
>>> 
"
14615,"For Android, Tensorflow Lite  C++ interface and static library","Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**: master latest
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: 0.7

### Describe the problem
For Android, Tensorflow Lite currently only supports Java interface calls, how do I use the C++ interface and static library? have any reference materials or guidance ? @aselle @petewarden
"
14614,Which c++ source code Should I modify to allocate GPU memory dynamically?,"I am using Spark with tensorflow. Spark make many tensorflow process, so I want tensorflow to allocate GPU memory dynamically. 
Adding the below code is **not workin**g for me
```
config = tf.ConfigProto() 
config.gpu_options.allow_growth=True 
sess = tf.Session(config=config)
```
Although I found  the way to set gpu memory fraction in 'tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc' ,
I want to set 'allow_growth' in c++ source.
Which part shoud I modify?"
14613,tf.data.Iterator.from_string_handle() breaking behaviour in r1.4 compared to r1.3.1,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: +
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**: Python 3.5.2
- **Bazel version (if compiling from source)**: -
- **GCC/Compiler version (if compiling from source)**: -
- **CUDA/cuDNN version**: nvidia/cuda:8.0-cudnn6-devel-ubuntu16.04
- **GPU model and memory**: NVIDIA® Tesla® K80 (GCE)
- **Exact command to reproduce**:

### Context:
Same setup/context as in the previous issue https://github.com/tensorflow/tensorflow/issues/12859 including this fix https://github.com/tensorflow/tensorflow/issues/12859#issuecomment-327783827.
In addition the training is now in a Multi-task Learning mode, so feedable contrib Iterator was used to accommodate different datasets for each task.
Simplified snippet:
~~~python
        self.handle = tf.placeholder(tf.string, shape=[])

        ...

        # targets -> Multi-task training targets.
        # datasets -> dict of Multi-task target tf.Datasets.
        for target in self.targets:
            self.datasets[target] = self.create_TFDataset()

        self.iterator = tf.contrib.data.Iterator.from_string_handle(
            self.handle,
            self.datasets[targets[-1]].output_types,
            self.datasets[targets[-1]].output_shapes)

        # iter_init_ops and iter_handles -> init_ops & handles per each task.
        for target in self.targets:
            self.iterators[target] = self.datasets[target].make_initializable_iterator()
            self.iter_init_ops[target] = self.iterators[target].initializer
            self.iter_handles[target] = self.iterators[target].string_handle()

        ...
        # Within tf.train.MonitoredTrainingSession as mon_sess.
        for target in targets:
            # Get all target datasets handles.
            handle[target] = mon_sess._coordinated_creator.tf_sess.run(
                training_model.iter_handles[target])
            # Init all target datasets.
            mon_sess._coordinated_creator.tf_sess.run(training_model.iter_init_ops[target])

        ...
        # Training step for a specific target.
        input_feed = {self.handle:handle[target]}
        output_feed = [
            self.update_ops[target],
            self.losses[target], 
            self.metrics[target],
        ]
        outputs = session.run(output_feed, input_feed, options=options,
                                             run_metadata=run_metadata)
~~~
### Problem:
This system worked flawlessly for tf 1.3 & tf 1.3.1. 
After a planned update this week to tf 1.4 the following Error would appear at absolute random (it might appear after 5 seconds or after a few hours of training):
~~~console
...
W tensorflow/core/framework/op_kernel.cc:1192] Unavailable: Endpoint read failed
	 [[Node: Model/Generate_BiRNN/BiRNN_Logic/bidirectional_rnn/fw/carry_w_S543 = _Recv[_start_time=0, client_terminated=false, recv_device=""/job:worker/replica:0/task:0/device:GPU:0"", send_device=""/job:ps/replica:0/task:1/device:CPU:0"", send_device_incarnation=-458934800929363750, tensor_name=""edge_9_Model/Generate_BiRNN/BiRNN_Logic/bidirectional_rnn/fw/carry_w"", tensor_type=DT_FLOAT, _device=""/job:worker/replica:0/task:0/device:GPU:0""]()]]
	 [[Node: Training_Graph/Model/TARGET/TARGET_Metrics/Select_G315 = _Recv[client_terminated=false, recv_device=""/job:worker/replica:0/task:0/device:CPU:0"", send_device=""/job:worker/replica:0/task:0/device:GPU:0"", send_device_incarnation=3243841103411587778, tensor_name=""edge_4692_Training_Graph/Model/TARGET/TARGET_Metrics/Select"", tensor_type=DT_DOUBLE, _device=""/job:worker/replica:0/task:0/device:CPU:0""]()]]
...
W tensorflow/core/framework/op_kernel.cc:1192] Not found: Resource worker/_3_Training_Graph/Model/Iterator/N10tensorflow12_GLOBAL__N_116IteratorResourceE does not exist.
	 [[Node: Training_Graph/Model/IteratorFromStringHandle = IteratorFromStringHandle[output_shapes=[[?,?,?], [?,?,?], [?], [?,?], [?,?], [?], [?]], output_types=[DT_INT64, DT_INT64, DT_INT64, DT_INT64, DT_INT64, DT_FLOAT, DT_INT32], _device=""/job:worker/replica:0/task:0/device:CPU:0""](_recv_Training_Graph/Model/Placeholder_0)]]
	 [[Node: Training_Graph/Model/TARGET/TARGET_Metrics/DenseToDenseSetOperation_26_G1265 = _Recv[client_terminated=false, recv_device=""/job:worker/replica:0/task:0/device:GPU:0"", send_device=""/job:worker/replica:0/task:0/device:CPU:0"", send_device_incarnation=-3380386273340330983, tensor_name=""edge_4280_Training_Graph/Model/TARGET/TARGET_Metrics/DenseToDenseSetOperation_26"", tensor_type=DT_INT64, _device=""/job:worker/replica:0/task:0/device:GPU:0""]()]]
...
Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 1323, in _do_call
    return fn(*args)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 1302, in _run_fn
    status, run_metadata)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py"", line 473, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.NotFoundError: Resource worker/_3_Training_Graph/Model/Iterator/N10tensorflow12_GLOBAL__N_116IteratorResourceE does not exist.
	 [[Node: Training_Graph/Model/IteratorFromStringHandle = IteratorFromStringHandle[output_shapes=[[?,?,?], [?,?,?], [?], [?,?], [?,?], [?], [?]], output_types=[DT_INT64, DT_INT64, DT_INT64, DT_INT64, DT_INT64, DT_FLOAT, DT_INT32], _device=""/job:worker/replica:0/task:0/device:CPU:0""](_recv_Training_Graph/Model/Placeholder_0)]]
	 [[Node: Training_Graph/Model/TARGET/TARGET_Metrics/DenseToDenseSetOperation_26_G1265 = _Recv[client_terminated=false, recv_device=""/job:worker/replica:0/task:0/device:GPU:0"", send_device=""/job:worker/replica:0/task:0/device:CPU:0"", send_device_incarnation=-3380386273340330983, tensor_name=""edge_4280_Training_Graph/Model/TARGET/TARGET_Metrics/DenseToDenseSetOperation_26"", tensor_type=DT_INT64, _device=""/job:worker/replica:0/task:0/device:GPU:0""]()]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""dist_train.py"", line 684, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""dist_train.py"", line 640, in main
    create_job()
  File ""dist_train.py"", line 628, in create_job
    run_worker(server, cluster)
  File ""dist_train.py"", line 429, in run_worker
    profile=profile
  File ""/HARNN.py"", line 1576, in step_dist_gpu
    run_metadata=run_metadata)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py"", line 521, in run
    run_metadata=run_metadata)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py"", line 892, in run
    run_metadata=run_metadata)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py"", line 967, in run
    raise six.reraise(*original_exc_info)
  File ""/usr/local/lib/python3.5/dist-packages/six.py"", line 693, in reraise
    raise value
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py"", line 952, in run
    return self._sess.run(*args, **kwargs)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py"", line 1024, in run
    run_metadata=run_metadata)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py"", line 827, in run
    return self._sess.run(*args, **kwargs)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 889, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 1120, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 1317, in _do_run
    options, run_metadata)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 1336, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.NotFoundError: Resource worker/_3_Training_Graph/Model/Iterator/N10tensorflow12_GLOBAL__N_116IteratorResourceE does not exist.
	 [[Node: Training_Graph/Model/IteratorFromStringHandle = IteratorFromStringHandle[output_shapes=[[?,?,?], [?,?,?], [?], [?,?], [?,?], [?], [?]], output_types=[DT_INT64, DT_INT64, DT_INT64, DT_INT64, DT_INT64, DT_FLOAT, DT_INT32], _device=""/job:worker/replica:0/task:0/device:CPU:0""](_recv_Training_Graph/Model/Placeholder_0)]]
	 [[Node: Training_Graph/Model/TARGET/TARGET_Metrics/DenseToDenseSetOperation_26_G1265 = _Recv[client_terminated=false, recv_device=""/job:worker/replica:0/task:0/device:GPU:0"", send_device=""/job:worker/replica:0/task:0/device:CPU:0"", send_device_incarnation=-3380386273340330983, tensor_name=""edge_4280_Training_Graph/Model/TARGET/TARGET_Metrics/DenseToDenseSetOperation_26"", tensor_type=DT_INT64, _device=""/job:worker/replica:0/task:0/device:GPU:0""]()]]

Caused by op 'Training_Graph/Model/IteratorFromStringHandle', defined at:
  File ""dist_train.py"", line 684, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""dist_train.py"", line 640, in main
    create_job()
  File ""dist_train.py"", line 628, in create_job
    run_worker(server, cluster)
  File ""dist_train.py"", line 272, in run_worker
    training_model.build_graph()
  File ""/HARNN.py"", line 221, in build_graph
    self._init_dataset()
  File ""/HARNN.py"", line 329, in _init_dataset
    self.datasets[self.targets[-1]].output_shapes)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 189, in from_string_handle
    output_shapes=nest.flatten(output_shapes))
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 662, in iterator_from_string_handle
    output_types=output_types, output_shapes=output_shapes, name=name)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py"", line 2956, in create_op
    op_def=op_def)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py"", line 1470, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

NotFoundError (see above for traceback): Resource worker/_3_Training_Graph/Model/Iterator/N10tensorflow12_GLOBAL__N_116IteratorResourceE does not exist.
	 [[Node: Training_Graph/Model/IteratorFromStringHandle = IteratorFromStringHandle[output_shapes=[[?,?,?], [?,?,?], [?], [?,?], [?,?], [?], [?]], output_types=[DT_INT64, DT_INT64, DT_INT64, DT_INT64, DT_INT64, DT_FLOAT, DT_INT32], _device=""/job:worker/replica:0/task:0/device:CPU:0""](_recv_Training_Graph/Model/Placeholder_0)]]
	 [[Node: Training_Graph/Model/TARGET/TARGET_Metrics/DenseToDenseSetOperation_26_G1265 = _Recv[client_terminated=false, recv_device=""/job:worker/replica:0/task:0/device:GPU:0"", send_device=""/job:worker/replica:0/task:0/device:CPU:0"", send_device_incarnation=-3380386273340330983, tensor_name=""edge_4280_Training_Graph/Model/TARGET/TARGET_Metrics/DenseToDenseSetOperation_26"", tensor_type=DT_INT64, _device=""/job:worker/replica:0/task:0/device:GPU:0""]()]]
~~~

### Statement:
What exactly have changed in tf.data.Iterator between versions r1.4 and r1.3.1 that causes such an unpleasant behaviour? What can be done to counteract `NotFoundError`?"
14612,bazel build command failed for tensorflow serving ,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Ubuntu 16.04 docker container
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:1.3.0
- **Python version**: 3.5.2
- **Bazel version (if compiling from source)**:0.5.4
- **GCC/Compiler version (if compiling from source)**:5.4.0
- **CUDA/cuDNN version**:NA
- **GPU model and memory**:NA
- **Exact command to reproduce**:
bazel build -c opt --jobs 1 --local_resources 5,2.0,2.0 --verbose_failures  tensorflow_serving/...


== cat /etc/issue ===============================================
Linux 25b038d948eb 4.9.49-moby #1 SMP Wed Sep 27 23:17:17 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""16.04.3 LTS (Xenial Xerus)""
VERSION_ID=""16.04""
VERSION_CODENAME=xenial

== are we in docker =============================================
Yes

== compiler =====================================================
c++ (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux 25b038d948eb 4.9.49-moby #1 SMP Wed Sep 27 23:17:17 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy (1.13.3)
protobuf (3.4.0)
tensorflow (1.3.0)
tensorflow-tensorboard (0.1.8)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.3.0
tf.GIT_VERSION = v1.3.0-rc2-20-g0787eee
tf.COMPILER_VERSION = v1.3.0-rc2-20-g0787eee
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
env_collect.sh: line 105: nvidia-smi: command not found

== cuda libs  ===================================================

== cat /etc/issue ===============================================
Linux 25b038d948eb 4.9.49-moby #1 SMP Wed Sep 27 23:17:17 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""16.04.3 LTS (Xenial Xerus)""
VERSION_ID=""16.04""
VERSION_CODENAME=xenial

== are we in docker =============================================
Yes

== compiler =====================================================
c++ (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux 25b038d948eb 4.9.49-moby #1 SMP Wed Sep 27 23:17:17 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy (1.13.3)
protobuf (3.4.0)
tensorflow (1.3.0)
tensorflow-tensorboard (0.1.8)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.3.0
tf.GIT_VERSION = v1.3.0-rc2-20-g0787eee
tf.COMPILER_VERSION = v1.3.0-rc2-20-g0787eee
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
bash: nvidia-smi: command not found

== cuda libs  ===================================================

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I am facing issues while running bazel build command in order to install tensorflow serving in the docker container.
COMMAND RAN:-
bazel build -c opt --jobs 1 --local_resources 5,2.0,2.0 --verbose_failures  tensorflow_serving/...

ERROR:-
/root/.cache/bazel/_bazel_root/f8d1071c69ea316497c31e40fe01608c/external/inception_model/inception/slim/BUILD:55:1: Converting to Python 3: external/inception_model/inception/slim/ops.py failed (Exit 1): 2to3 failed: error executing command 
  (cd /root/.cache/bazel/_bazel_root/f8d1071c69ea316497c31e40fe01608c/execroot/tf_serving && \
  exec env - \
  bazel-out/host/bin/external/bazel_tools/tools/python/2to3 --no-diffs --nobackups --write --output-dir bazel-out/local-py3-opt/genfiles/python3/external/inception_model/inception/slim --write-unchanged-files external/inception_model/inception/slim/ops.py).

I am trying to create a tensorflow serving container with python3 and tensorflow 1.3. I have successfully create tensorflow serving with python2 and tested mnist and inception models.

"
14611,"KeyError: ""Couldn't find field google.protobuf.DescriptorProto.ExtensionRange.options""","My tensorflow was working fine a few days ago and now I get this error:

```
Last login: Mon Nov 13 17:56:32 on ttys001
pWed Nov 15 22:38:01 :~$ python
Python 3.6.2 |Anaconda custom (x86_64)| (default, Jul 20 2017, 13:14:59)
[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/Users/mona/anaconda/lib/python3.6/site-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/Users/mona/anaconda/lib/python3.6/site-packages/tensorflow/python/__init__.py"", line 52, in <module>
    from tensorflow.core.framework.graph_pb2 import *
  File ""/Users/mona/anaconda/lib/python3.6/site-packages/tensorflow/core/framework/graph_pb2.py"", line 10, in <module>
    from google.protobuf import descriptor_pb2
  File ""/Users/mona/anaconda/lib/python3.6/site-packages/google/protobuf/descriptor_pb2.py"", line 409, in <module>
    options=None),
  File ""/Users/mona/anaconda/lib/python3.6/site-packages/google/protobuf/descriptor.py"", line 501, in __new__
    return _message.default_pool.FindFieldByName(full_name)
KeyError: ""Couldn't find field google.protobuf.DescriptorProto.ExtensionRange.options""
>>>
```

And my sys info is:
```
Wed Nov 15 23:41:58 :~$ uname -a
Darwin Monas-MacBook-Pro.local 17.0.0 Darwin Kernel Version 17.0.0: Thu Aug 24 21:48:19 PDT 2017; root:xnu-4570.1.46~2/RELEASE_X86_64 x86_64
Wed Nov 15 23:42:05 :~$ conda list | grep tensorflow
tensorflow                1.1.0               np112py36_0
tensorflow                1.4.0                     <pip>
tensorflow-tensorboard    0.1.8                     <pip>
```"
14610,Error when bazel building after pull down newest master branch,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.3.0
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**: 0.5.4
- **CUDA/cuDNN version**:  8.0.61
- **GPU model and memory**: NVIDIA Corporation Device 1b06
- **Exact command to reproduce**: 

```
bazel build tensorflow/python/tools:freeze_graph
```

### Describe the problem
Here is the warning and error message I got :

```
WARNING: tensorflow/tensorflow/core/BUILD:1801:1: in includes attribute of cc_library rule //tensorflow/core:framework_headers_lib: '../../external/nsync/public' resolves to 'external/nsync/public' not below the relative path of its package 'tensorflow/core'. This will be an error in the future. Since this rule was created by the macro 'cc_header_only_library', the error might have been caused by the macro implementation in tensorflow/tensorflow/tensorflow.bzl:1108:30
WARNING: tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': No longer supported. Switch to SavedModel immediately.
WARNING: /home/simonlee/Work/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': No longer supported. Switch to SavedModel immediately.
INFO: Analysed target //tensorflow/python/tools:freeze_graph (0 packages loaded).
INFO: Found 1 target...
ERROR: tensorflow/tensorflow/contrib/lite/toco/BUILD:158:1: C++ compilation of rule '//tensorflow/contrib/lite/toco:graph_transformations' failed (Exit 1)
In file included from external/gemmlowp/public/../internal/dispatch_gemm_shape.h:20:0,
                 from external/gemmlowp/public/gemmlowp.h:19,
                 from ./tensorflow/contrib/lite/kernels/internal/common.h:48,
                 from ./tensorflow/contrib/lite/toco/runtime/types.h:18,
                 from ./tensorflow/contrib/lite/toco/model.h:25,
                 from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23,
                 from tensorflow/contrib/lite/toco/graph_transformations/identify_l2_pool.cc:20:
external/gemmlowp/public/../internal/../internal/kernel_default.h:88:2: error: #error ""SIMD not enabled, you'd be getting a slow software fallback. Consider enabling SIMD extensions (for example using -msse4 if you're on modern x86). If that's not an option, and you would like to continue with the slow fallback, define GEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK.""
 #error \
  ^
Target //tensorflow/python/tools:freeze_graph failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 1.120s, Critical Path: 0.85s
FAILED: Build did NOT complete successfully
```
"
14609,Why cannot use tf.Print() ?,"I just want to print out the executing data like this:
![t](https://user-images.githubusercontent.com/14851411/32872558-47be9c0c-ca7f-11e7-8e5d-6fa6796cb043.jpg)
But I got :""**Cannot assign a device for operation 'Print': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available**""
I'm sure this piece of code can work in python console with tf.device('/gpu:0') assigned:
Anyone help ?


"
14608,save restore from a incomplete model,"# problem
Each time the trainning programe begining to run will restore model from where the last model was saved。but sometimes the last model is incompleted.the model restore fail. In order to make programe restore from a normal model，I hava tomodify the checkpoint file manually。 

# the checkpoint file as follow:
```
model_checkpoint_path: ""model.ckpt-88663487""
all_model_checkpoint_paths: ""model.ckpt-88598144""
all_model_checkpoint_paths: ""model.ckpt-88631248""
all_model_checkpoint_paths: ""model.ckpt-88631251""
all_model_checkpoint_paths: ""model.ckpt-88631617""
all_model_checkpoint_paths: ""model.ckpt-88663473""
all_model_checkpoint_paths: ""model.ckpt-88663487""
```
# model.ckpt-88663487 is incomplete
```
model.ckpt-88663487.data-00000-of-00040
model.ckpt-88663487.data-00002-of-00040
model.ckpt-88663487.data-00003-of-00040
model.ckpt-88663487.data-00004-of-00040
model.ckpt-88663487.data-00005-of-00040
model.ckpt-88663487.data-00006-of-00040
model.ckpt-88663487.data-00007-of-00040
model.ckpt-88663487.data-00008-of-00040
model.ckpt-88663487.data-00009-of-00040
model.ckpt-88663487.data-00010-of-00040
model.ckpt-88663487.data-00011-of-00040
model.ckpt-88663487.data-00012-of-00040
model.ckpt-88663487.data-00013-of-00040
model.ckpt-88663487.data-00014-of-00040
model.ckpt-88663487.data-00015-of-00040
model.ckpt-88663487.data-00016-of-00040
model.ckpt-88663487.data-00017-of-00040
model.ckpt-88663487.data-00018-of-00040
model.ckpt-88663487.data-00019-of-00040
model.ckpt-88663487.data-00020-of-00040
model.ckpt-88663487.data-00021-of-00040
model.ckpt-88663487.data-00022-of-00040
model.ckpt-88663487.data-00023-of-00040
model.ckpt-88663487.data-00024-of-00040
model.ckpt-88663487.data-00025-of-00040
model.ckpt-88663487.data-00026-of-00040
model.ckpt-88663487.data-00027-of-00040
model.ckpt-88663487.data-00028-of-00040
model.ckpt-88663487.data-00029-of-00040
model.ckpt-88663487.data-00030-of-00040
model.ckpt-88663487.data-00031-of-00040
model.ckpt-88663487.data-00032-of-00040
model.ckpt-88663487.data-00033-of-00040
model.ckpt-88663487.data-00034-of-00040
model.ckpt-88663487.data-00035-of-00040
model.ckpt-88663487.data-00036-of-00040
model.ckpt-88663487.data-00037-of-00040
model.ckpt-88663487.data-00038-of-00040
model.ckpt-88663487.data-00039-of-00040
model.ckpt-88663487.index
model.ckpt-88663487_temp_c555bad9d4a149fca7fa899d665d3ea3
```
# confuse
The model will restort from model.ckpt-88663487,but model.ckpt-88663487 is incompleted.because during the programe save model, the programe is stoped. why change the checkpoint's model_checkpoint_path,when the model is not saved completely
"
14607,Tensorflow Lite Support for Windows,Are you planning to support Tensorflow Lite on Windows? Specifically Windows 32bit.
14606,Converting unsupported operation: Dequantize,"
------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: centos 7
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**:  2.7
- **Bazel version (if compiling from source)**: 0.5.4
- **GCC/Compiler version (if compiling from source)**: 4.8.5
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

### Describe the problem
I use the command:
bazel-bin/tensorflow/contrib/lite/toco/toco '--input_file=/home/guoxiang/workspace/tensorflow/sms_model/optimized_sms.pb' '--input_format=TENSORFLOW_GRAPHDEF' '--output_format=TFLITE' '--output_file=/home/guoxiang/workspace/tensorflow/sms_model/sms_char_cnn.lite' '--inference_type=QUANTIZED_UINT8' '--input_type=QUANTIZED_UINT8' '--input_arrays=embedding_matrix' '--output_arrays=final_scores' '--input_shapes=1,5000,64,1' --logtostderr '--v=2'

to convert a quantized model to a  lite model, got the following error:
Unimplemented: this graph contains an operator of type (Unsupported TensorFlow op: Dequantize) for which the quantized form is not yet implemented. Sorry, and patches welcome (that's a relatively fun patch to write, mostly providing the actual quantized arithmetic code for this op).

so , now qutianzed model is still not supported ?
"
14605,"Linking error ""Undefined symbols for architecture x86_64:   ""nsync::nsync_mu_init(nsync::nsync_mu_s_*)"""" on iOS","Hello,

I downloaded the latest release 1.4.0 and builded it for iOS with build_all_ios.sh, and can successfully build libtensorflow-core.a, libprotobuf-lite.a and libprotobuf.a

but error happened when link these libs to iOS project, the detail info as follows, can anybody know how to fix it? thanks

Undefined symbols for architecture x86_64:
  ""nsync::nsync_mu_init(nsync::nsync_mu_s_*)"", referenced from:
      tensorflow::Env::Env() in libtensorflow-core.a(env.o)
      __GLOBAL__sub_I_allocator.cc in libtensorflow-core.a(allocator.o)
      tensorflow::SessionFactory::Register(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tensorflow::SessionFactory*) in libtensorflow-core.a(session_factory.o)
      tensorflow::SessionFactory::GetFactory(tensorflow::SessionOptions const&, tensorflow::SessionFactory**) in libtensorflow-core.a(session_factory.o)
      tensorflow::TrackingAllocator::TrackingAllocator(tensorflow::Allocator*, bool) in libtensorflow-core.a(tracking_allocator.o)
      tensorflow::TrackingAllocator::TrackingAllocator(tensorflow::Allocator*, bool) in libtensorflow-core.a(tracking_allocator.o)
  ""nsync::nsync_mu_lock(nsync::nsync_mu_s_*)"", referenced from:
      tensorflow::FileSystemRegistryImpl::Register(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::function<tensorflow::FileSystem* ()>) in libtensorflow-core.a(env.o)
      tensorflow::FileSystemRegistryImpl::Lookup(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) in libtensorflow-core.a(env.o)
      tensorflow::FileSystemRegistryImpl::GetRegisteredFileSystemSchemes(std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > >*) in libtensorflow-core.a(env.o)
      tensorflow::CPUAllocator::AllocateRaw(unsigned long, unsigned long) in libtensorflow-core.a(allocator.o)
      tensorflow::CPUAllocator::DeallocateRaw(void*) in libtensorflow-core.a(allocator.o)
      tensorflow::CPUAllocator::GetStats(tensorflow::AllocatorStats*) in libtensorflow-core.a(allocator.o)
      tensorflow::SessionFactory::Register(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tensorflow::SessionFactory*) in libtensorflow-core.a(session_factory.o)
      ...
  ""nsync::nsync_mu_unlock(nsync::nsync_mu_s_*)"", referenced from:
      tensorflow::FileSystemRegistryImpl::Register(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::function<tensorflow::FileSystem* ()>) in libtensorflow-core.a(env.o)
      tensorflow::FileSystemRegistryImpl::Lookup(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) in libtensorflow-core.a(env.o)
      tensorflow::FileSystemRegistryImpl::GetRegisteredFileSystemSchemes(std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > >*) in libtensorflow-core.a(env.o)
      tensorflow::CPUAllocator::AllocateRaw(unsigned long, unsigned long) in libtensorflow-core.a(allocator.o)
      tensorflow::CPUAllocator::DeallocateRaw(void*) in libtensorflow-core.a(allocator.o)
      tensorflow::CPUAllocator::GetStats(tensorflow::AllocatorStats*) in libtensorflow-core.a(allocator.o)
      tensorflow::SessionFactory::Register(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tensorflow::SessionFactory*) in libtensorflow-core.a(session_factory.o)
      ...
ld: symbol(s) not found for architecture x86_64
clang: error: linker command failed with exit code 1 (use -v to see invocation)"
14603,add Unspecified dimension to an existing tensor.,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: osx
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**:  ('v1.3.0-rc2-20-g0787eee', '1.3.0')
- **Python version**:   Python 2.7.11
- **Bazel version (if compiling from source)**: 0.7.0-homebrew
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

== cat /etc/issue ===============================================
Darwin Pengs-MacBook-Pro.local 16.7.0 Darwin Kernel Version 16.7.0: Thu Jun 15 17:36:27 PDT 2017; root:xnu-3789.70.16~2/RELEASE_X86_64 x86_64
Mac OS X 10.12.6

== are we in docker =============================================
No

== compiler =====================================================
Apple LLVM version 9.0.0 (clang-900.0.38)
Target: x86_64-apple-darwin16.7.0
Thread model: posix
InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin

== uname -a =====================================================
Darwin Pengs-MacBook-Pro.local 16.7.0 Darwin Kernel Version 16.7.0: Thu Jun 15 17:36:27 PDT 2017; root:xnu-3789.70.16~2/RELEASE_X86_64 x86_64

== check pips ===================================================
numpy (1.13.1)
protobuf (3.4.0)
tensorflow (1.3.0)
tensorflow-serving-api (1.3.0)
tensorflow-tensorboard (0.1.8)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.3.0
tf.GIT_VERSION = v1.3.0-rc2-20-g0787eee
tf.COMPILER_VERSION = v1.3.0-rc2-20-g0787eee
Sanity check: array([1], dtype=int32)
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""tensorflow/python/pywrap_tensorflow.py"", line 25, in <module>
    from tensorflow.python.platform import self_check
ImportError: No module named platform

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
./tools/tf_env_collect.sh: line 105: nvidia-smi: command not found

== cuda libs  ===================================================

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
subgraph one have output:
```
state = Tensor(80, 80, 4)
```
subgraph two have input:
```
states = Tensor(None, 80, 80, 4)
```
right now `tf.expand_dims` can only make state a `Tensor(1, 80, 80, 4)` which can not being assigned to `states`. so that i have to do multiple sess execution and make two graph


### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
14601,Conv2D operator with SAME padding when Stride > kernel size showing unexpected results,"### System information
- **Have I written custom code -- YES, only to demonstrate the problem (source code is below)**:
- **OS Platform and Distribution (Linux Ubuntu 16.04)**:
- **TensorFlow installed from (binary (PIP))**:
- **TensorFlow version (1.4.0)**:
- **Python version (2.7.12)**: 
- **Bazel version (N/A)**:
- **GCC/Compiler version (N/A)**:
- **CUDA/cuDNN version (N/A)**:
- **GPU model and memory (N/A -- CPU only)**:
- **Exact command to reproduce (See Source Code Below)**:

### Describe the problem
There is an inconsistency between the convolution documentation on padding with 'SAME' located [here](https://www.tensorflow.org/api_guides/python/nn#Convolution) and the behavior of the tf.nn.conv2d operator. In the example below I create a 3x1 input with values [[1.0][1.1][1.2]] and a 1x1 filter of value [1.0]. I specify the stride to be 1x3x1x1 which should result in only a single element be output and the padding to be 'SAME'. From the padding calculation in the above link: 

pad_along_height:
    
    in_height ( = 3) % strides[1]( = 3) == 0 so
    pad_along_height = max(filter_height ( = 1) - strides[1] ( = 3), 0)
    pad_along_height = max(-2, 0) = 0

pad along_width:

    in_width ( = 1) % strides[2] ( = 1) == 0 so
    pad_along_width = max(filter_width( = 1) - strides[2] ( = 1), 0
    pad_along_width = max(0,0) = 0

My hypothesis is that pad_along_* is not using the max(x,0) and as a result, pad_along_height = -2. Therefore pad_top = -1 and pad_bottom = -1. If that was the case, then our input is reduced to only the middle element [1.1] which explains why the TF result of the code below is 1.1 rather than the expected 1.0 (value of first input).

If I change the padding to be VALID (no padding) then this code below gives the result of 1.0 or if i instead change the stride to 1,2,1,1 i get the expected value of 1.0 (although in this case my hypothesis proposes that pad_bottom is still -1).

### Source code / logs
    import tensorflow as tf
    import numpy as np

    i = tf.constant((np.ones(3) + np.arange(3) * 0.1).reshape(1,3,1,1), dtype=tf.float32, name='input')
    f = tf.constant(np.ones(1).reshape(1,1,1,1), dtype=tf.float32, name='filter')

    conv = tf.nn.conv2d(input=i, filter=f, strides=(1,3,1,1), padding='SAME')

    with tf.Session() as sess:
        out = sess.run(conv)
        print out

Output:
`[[[[ 1.10000002]]]]`"
14596,Bug: tf.data.Dataset.map computes unrequested graph parts ,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: See code example at the bottom
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**: Python 3.6.1 :: Anaconda custom (64-bit)
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

### Describe the problem
**Short**: `tf.Session.run` does not compute unnecessary things that are not requested, except for the case the tensorflow code in inside a `tf.data.Dataset.map`. 
So is it possible to add this feature to `tf.data.Dataset.map`?
Maybe the problem is in `tensorflow.python.framework.function.Defun`.

**Long**: I want to build a fully featured input pipeline that provides everything. Than should tensorflow determine what is necessary to compute. When I tried to figure out if this is possible I found that the dataset has some code for parallel execution. So preprocessing should be inside the `Dataset` pipeline. 
When I looked at the source code I think the reason may be connected to `tensorflow.python.framework.function.Defun`, but I can not find the motivation to use Defun and the initial commit (2017-05-17) under contrib had already `Defun` used.
With my knowledge as a tensorflow beginner, I can only fix this when I ignore parallel execution (i.e. remove all `Defun`s), but then I can also do the transform after `Iterator.get_next()`.

Maybe @mrry knows more about this?

### Source code / logs

Here a small example that demonstrates this behavior. (Node the `tf_sleep(idx, 0.1)` is a open end in the graph and the print should never be executed.)
```python
import tensorflow as tf
import functools

# -----------------simple print when this is executed------------------------------------
def sleep(tensor, seconds):
    time.sleep(seconds)
    print(f'Sleeped for {seconds}s')
    return tensor

def tf_sleep(tensor, seconds):
    return tf.py_func(sleep, [tensor, seconds], tensor.dtype, name='speep')
# ------------------------------------------------------------------------------------------------
def transform(idx):    
    tf_sleep(idx, 0.1)  # Dead graph end, should never be executed
    return tf_sleep(idx, 0.2)
    
ds = tf.data.Dataset.range(20)
ds = ds.map(transform)  # will produce ""Sleeped for 0.1s""

iterator = ds.make_one_shot_iterator()
entry = iterator.get_next()

entry = transform(entry)  # does not produce ""Sleeped for 0.1s""

with tf.Session() as sess:
    print(sess.run(entry))
# Output: 
# Sleeped for 0.20000000298023224s
# Sleeped for 0.10000000149011612s  # <-- this should not be printed
# Sleeped for 0.20000000298023224s
# 0
```
"
14595,Adding a custom Tensorflow Op under Windows/cmake does not work with TF_LoadLibrary,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
I have a custom fork (https://github.com/stefanseibert/tensorflow/tree/r1.3) which is forked from r1.3 and the only modifications are some commented out lines to be able to build AVX support as described in another ticket, and the recent added fix for wide strings.

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 10, 64 bit, cmake

- **TensorFlow installed from (source or binary)**:
Built from source under windows with the cmake setup

- **TensorFlow version (use command below)**:
1.3.1

- **Python version**: 
3.6

- **Bazel version (if compiling from source)**:
Does not apply

- **GCC/Compiler version (if compiling from source)**:
Microsoft (R) Build Engine version 14.0.25420.1

- **CUDA/cuDNN version**:
CUDA 8 / cuDNN 5.1`

- **GPU model and memory**:
GTX 980 Ti 6GB, 64GB main memory

- **Exact command to reproduce**:
Does not apply

### Describe the problem
When using the cmake setup on windows to build Tensorflow from source and using AddUserOps which was added from @guschmue some time ago (example like https://gist.github.com/guschmue/2908e4411edc2faef6ddfe87a2ce4a1d), I am able to build GPU enabled tensorflow ops. I can load the DLL in python with tf.load_op_library() and can actually use it there. I can built GraphDefs with my custom Op and export it as protobuf file.

When I try to use this graph for inference in another application where I use the C++ API its not possible for me to get the op loaded and registered. Loading the same DLL (as which with the python API succeeds) works on a system level with C/C++ (the DLL is loaded successfully as seen through procmon.exe or dependency walker and TF_LoadLibrary returns with status ok) but when trying to run the Graph afterwards the custom op is not recognized from Tensorflow and Tensorflow errors with ""Not found: Op type not registered..."". Trying to get the OpList afterwards with the Lib handle also returns no ops. So somehow the ops are not seen here even though they are recognized from python side. I tried a lot of different things to circumvent this like described in my Stack Overflow Question here:

https://stackoverflow.com/questions/47309425/tensorflow-op-and-kernel-do-not-register-on-windows-with-cmake

but none of the approaches worked. It seems like that the op registration which is done after loading the DLL on python side is not properly done when performing the same operation with TF_LoadLibrary from C/C++. Since I cannot get tensorflow built with debug symbols I dont have a callstack where this registration fails unfortunately.
"
14594,Unable to download  quantized Mobilenet TensorFlow Lite model ,"### Describe the problem
I am trying to build TensorFlow Lite Android app,  was following the [instruction](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite#building-in-android-studio-using-tensorflow-lite-aar-from-jcenter). 

> Download the quantized Mobilenet TensorFlow Lite model from [here](https://storage.googleapis.com/download.tensorflow.org/models/tflite/mobilenet_v1_224_android_quant_2017_11_08.zip)
> unzip and copy mobilenet_quant_v1_224.tflite to the assets directory: tensorflow/contrib/lite/java/demo/app/src/main/assets/

however, the link is not open to the public 

https://storage.googleapis.com/download.tensorflow.org/models/tflite/mobilenet_v1_224_android_quant_2017_11_08.zip

```
<Error>
<Code>AccessDenied</Code>
<Message>Access denied.</Message>
<Details>
Anonymous users does not have storage.objects.get access to download.tensorflow.org/models/tflite/mobilenet_v1_224_android_quant_2017_11_08.zip.
</Details>
</Error>
```
"
14593,TextLineReader is missing compression option (see TFRecordReader),"`tf.TextLineReader` does not currently provide a way to read GZIP encoded files

This option exists in `TFRecordReader`:
```
options = tf_record.TFRecordOptions(TFRecordCompressionType.GZIP)
reader = io_ops.TFRecordReader(name=""test_reader"", options=options)
```

It would be great to be able to ingest gzipped files into the TextLineReader as well:
```
reader = tf.TextLineReader(compression_type=""gzip"")
```

This `compression_type` argument could pass down to

```
rr = gen_io_ops._text_line_reader_v2(skip_header_lines=skip_header_lines, name=name, compression_type=compression_type)
```
 in the same way the TFRecordReader passes down to `_tf_record_reader_v2`: 
```rr = gen_io_ops._tf_record_reader_v2(name=name, compression_type=compression_type)```

Which would seem to require implementing compression here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/text_line_reader_op.cc"
14590,Loading TF 1.1 model in TF 1.4,"There is a model which has been trained in TF 1.1 (it's a seq2seq model with bahdanau attention). It uses DynamicAttentionWrapper (which has been renamed to AttentionWrapper). After updating TF to version 1.4 and switching to renamed AttentionWrapper the model can't be loaded. I get multiple errors like the following:

```
2017-11-15 19:45:26.550430: W tensorflow/core/framework/op_kernel.cc:1192] Not found: Key decoder/decoder/attention_wrapper/attention_layer/kernel/Adam not found in checkpoint
2017-11-15 19:45:26.550440: W tensorflow/core/framework/op_kernel.cc:1192] Not found: Key decoder/decoder/attention_wrapper/attention_layer/kernel/Adam_1 not found in checkpoint
2017-11-15 19:45:26.550481: W tensorflow/core/framework/op_kernel.cc:1192] Not found: Key decoder/decoder/attention_wrapper/bahdanau_attention/attention_v/Adam not found in checkpoint
2017-11-15 19:45:26.552201: W tensorflow/core/framework/op_kernel.cc:1192] Not found: Key encoder/bidirectional_rnn/fw/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Adam not found in checkpoint
2017-11-15 19:45:26.552300: W tensorflow/core/framework/op_kernel.cc:1192] Not found: Key decoder/decoder/attention_wrapper/bahdanau_attention/attention_v/Adam_1 not found in checkpoint
2017-11-15 19:45:26.552426: W tensorflow/core/framework/op_kernel.cc:1192] Not found: Key decoder/decoder/attention_wrapper/bahdanau_attention/query_layer/kernel not found in checkpoint
2017-11-15 19:45:26.552434: W tensorflow/core/framework/op_kernel.cc:1192] Not found: Key decoder/decoder/attention_wrapper/bahdanau_attention/query_layer/kernel/Adam_1 not found in checkpoint
2017-11-15 19:45:26.552440: W tensorflow/core/framework/op_kernel.cc:1192] Not found: Key decoder/decoder/attention_wrapper/multi_rnn_cell/cell_0/basic_lstm_cell/bias not found in checkpoint
2017-11-15 19:45:26.552496: W tensorflow/core/framework/op_kernel.cc:1192] Not found: Key decoder/decoder/attention_wrapper/bahdanau_attention/query_layer/kernel/Adam not found in checkpoint
2017-11-15 19:45:26.553055: W tensorflow/core/framework/op_kernel.cc:1192] Not found: Key decoder/decoder/attention_wrapper/multi_rnn_cell/cell_0/basic_lstm_cell/bias/Adam_1 not found in checkpoint
```

Setting name to dynamic_attention_wrapper in AttentionWrapper constructor parameters does not resolve the issue. Am I missing something? Taking into account that production models take a lot of resources to be trained it would be good for them to be compatible between TF versions.  Thank you."
14589,Tensorflow Lite Support for Raspberry PI,"### Describe the problem
Are you planning to support Tensorflow Lite on Raspberry Pi? Specifically Raspberry Pi 3.
"
14586,TF Lite C++ standalone Interpreter,"**Feature request**

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: 1.4
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**: 0.7.0
- **GCC/Compiler version (if compiling from source)**: 5.4.0
- **CUDA/cuDNN version**: None
- **GPU model and memory**: None
- **Exact command to reproduce**: None

I deploy TensorFlow models to environments with very limited memory, and was very excited to see how tiny the TF Lite kernel is (several hundred kilobytes). I know the project is young, but I was wondering if there are any plans to support a standalone C++ build for the Lite architecture, for deployment to (Linux) environments that do not have a TensorFlow runtime. 

For my purposes, this package should support the following:
- Loading a model configuration
- Loading input tensors
- Invoking the model with input tensors
- Storing the result in output tensors
- Some serialization method for the input- and output tensors

I would like to know:
- Is this a possible feature for TF Lite?
- What would the scope be of implementing this?
- Are there any plans to do so?"
14585,how to change the gpu_fraction_per_process from default 1 to 0.5 or 0.7?,"I want to change the gpu_fraction_per_process from default 1 to 0.5 or 0.7.
Not by adding the below in my code
```
import tensorflow as tf
gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.2)
sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))
```
Is there other method to change it in the tensorflow source file??

In the case of Keras, I can change it by modifying keras.json file.
I spent a lot of time to find the way though, I cannot find the way ..
Is it impossible???"
14584,Contradicting behaviour in variations of tf.cond usage with tf.nn.static_state_saving_rnn,"[Model.txt](https://github.com/tensorflow/tensorflow/files/1474854/Model.txt)
[Training.txt](https://github.com/tensorflow/tensorflow/files/1474855/Training.txt)

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Custom
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: 1.2/1.3/1.4 (tested on all)
- **Bazel Version** : N/A
- **Python version**: 2.7
- **CUDA/cuDNN version**: Cuda 8, CuDNN 6
- **GPU model and memory**: GeForce GTX 1080 , 12 GB
- **Exact command to reproduce**: python Training.py

### Problem
I am dealing with long sequential data which has to be passed to an RNN. To do truncated BPTT and batching, I am using tf.contrib.training.batch_sequences_with_states API with tf.nn.static_state_saving_rnn API to transfer RNN state information to subsequent segments of the same sequence. I am using tf.RandomShuffleQueue() to store my data and to decouple the I/O from training I am running the enqueue operations asynchronously in a different thread. 

To facilitate a testing run after each training epoch I am using two separate `tf.RandomShuffleQueue()` structures and hence two different `tf.contrib.training.batch_sequences_with_states()` and `tf.nn.static_state_saving_rnn()` instances for train/test data correspondingly. Just the RNN cell which is passed to `tf.nn.static_state_saving_rnn` instances remains the same, so that the modified set of weights are used at test time.

Moreover, I use a placeholder which is a boolean flag using which the appropriate nodes in the computation graph are switched at train/test time. This switching is done using `tf.cond()` operation.

#### Situation 1

The problem is that of a deadlock situation at a specific stage between the enqueue operations and training operations, both running in separate threads. The enqueue operation timeouts mostly because the queue has reached the maximum capacity and for some reason training operation never returns and is waiting to get some more data and hence no dequeue operation is called.

#### Situation 2

In file Model.py, if I uncomment the lines from 97-101 and comment line 104, then there is no such deadlock situation. The only difference is in the way that specific `tf.cond()` operation is written. One is in a declarative form(working code) and other is in an inline form(broken/deadlock code).

#### Situation 3

In file - Training.py, dummy data is generated by the `gen_data()` procedure(lines - 43-48) and called on line 61. The second parameter to this function is the number of time steps for each sequence. If this number is fixed to a value which is less than the unroll length parameter of `tf.contrib.training.batch_sequences_with_states()` instances(i.e. each sequence can very well fit in one batch itself), this deadlock does not occur irrespective of situation 1 or situation 2 described above.

Hence, we suspect there is some minute intricacy in `tf.cond()` and `tf.nn.static_state_saving_rnn()` which gives rise to such a deadlock.

### Source code / logs
Two files are attached(.txt files since the interface does not allow attaching files with extension .py) - 

1. Model.txt - Contains the Model class and the inference() method where the majority of the computation graph is built.
2. Training.txt - Contains the client code which generates dummy data and calls to sess.run()

The current code is according to Situation 1 as described above and the behaviour can be seen by running the command - `python Training.py`

Regards,
Daksh

"
14583,contrib.slim.conv2d doesn't check input dimension,"tensorflow version: v1.4.0-rc1-11-g130a514 (installed from pip)

contrib.slim.conv2d doesn't check for input dimensionality. So if you give it a 5D tensor it instead performs a 3D convolution.

Here is a quick way to see this:
```
sess = tf.InteractiveSession()

image_ph = tf.placeholder(tf.float32,
                          shape=(None, None, 10, 10),
                          name='image')
image = tf.expand_dims(image_ph, -1)
conv = tf.contrib.slim.conv2d(image, 3, 3, padding=""VALID"")

sess.run(tf.global_variables_initializer())
conv_out = conv.eval({image_ph: np.random.random((16, 20, 10, 10))})
```

conv_out will have shape `[16, 18, 8, 8, 3]`, meaning that the time dimension (dim 1) has decreased due to the VALID padding. 

As a side note I think it would be convenient if all conv2d implementations let you specify which dimensions to act on (or acted on the last 3 dims of the input by default). This is useful for example if you have sequential data and want to apply a 2d convolution to each frame independently.  "
14581,Generate benchmark_model (android arm64-v8a) executable in case of tensorflow lite ,"Hello i tried the sameway defined in the Readme.md of ""tensorflow/contrib/makefile"" folder to build benchmark_model for  tensorflow lite (tensorflow/contrib/lite/). However, it failed and seems that ""TARGET=ANDROID"" is not working in caseof Makefile of ""tensorflow/contrib/lite/"" folder.

ERROR LOG:
/tensorflow/tensorflow/contrib/lite/downloads/gemmlowp/public/../internal/../internal/kernel_default.h:89:2: error: #error ""SIMD not enabled, you'd be getting a slow software fallback. Consider enabling SIMD extensions (for example using -msse4 if you're on modern x86). If that's not an option, and you would like to continue with the slow fallback, define GEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK.""
 #error \
make: *** [/tensorflow/tensorflow/contrib/lite/gen/obj/tensorflow/contrib/lite/interpreter.o] Error 1

"
14580,"freeze_graph ""No variables to save""","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
I do not modify any of the source code
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
1.4.0
- **Python version**: 
3.5
_ **Bazel version
N
_ **CUDA/cuDNN version
N
_ **GPU model and memory
N

### Describe the problem
First, I download mobilenet_v1_0.25_224 pretrained model from [here](http://download.tensorflow.org/models/mobilenet_v1_0.25_224_2017_06_14.tar.gz)

Then,Exporting the Inference Graph, I use the commond:
python export_inference_graph.py \
  --alsologtostderr \
  --model_name=mobilenet_v1_025 \
  --image_size=224 \
  --output_file=/tmp/mobilenet_v1_025_224.pb

Next, freeze graph, I use the command:
python tensorflow/python/tools/freeze_graph.py --input_graph= tmp/mobilenet_v1_025_224.pb --input_checkpoint=tmp/mobilenet_v1_0.25_224.ckpt --input_binary=true --output_graph=tmp/frozen_mobilenet_v1_025_224.pb --output_node_names=MobileNetV1/Predictions/Reshape_1

Finally, I got the error:
 I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
Traceback (most recent call last):
  File ""tensorflow/python/tools/freeze_graph.py"", line 350, in <module>
    app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/home/libs/anaconda3/envs/python35/lib/python3.5/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""tensorflow/python/tools/freeze_graph.py"", line 249, in main
    FLAGS.saved_model_tags)
  File ""tensorflow/python/tools/freeze_graph.py"", line 239, in freeze_graph
    input_meta_graph_def, input_saved_model_dir, saved_model_tags.split("",""))
  File ""tensorflow/python/tools/freeze_graph.py"", line 127, in freeze_graph_with_def_protos
    saver = saver_lib.Saver(var_list=var_list)
  File ""/home/libs/anaconda3/envs/python35/lib/python3.5/site-packages/tensorflow/python/training/saver.py"", line 1218, in __init__
    self.build()
  File ""/home/libs/anaconda3/envs/python35/lib/python3.5/site-packages/tensorflow/python/training/saver.py"", line 1227, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File ""/home/libs/anaconda3/envs/python35/lib/python3.5/site-packages/tensorflow/python/training/saver.py"", line 1251, in _build
    raise ValueError(""No variables to save"")
ValueError: No variables to save

Another machine:
windows 7
tensorflow 1.4.0
python 3.6

Using the same operations, I can get the frozen .pb file successfully.

All source code are not modified.I also  changed the other models to test, and get the same error, need your help?"
14579,"Is it possible to optimize the network's likelihood function over a function of parameters? Or putting it the other way, can we optimize a function of parameter instead of parameters?","Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
14577,modify tensorflow/core/protobuf/config.proto,"I try to modify config.proto.
I want to change per_process_gpu_memory_fraction from 1 to 0.2.
I modified it and builded it.

After I modified it, I compiled by using bazel
```
. /configure
bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_packag
```
But I got error and I cannot compile."
14576,FAIL://tensorflow/core:common_runtime_direct_session_with_tracking_alloc_test with GPU support,"
### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
     Ubuntu 16.04 (ppc64le)
- **TensorFlow installed from (source or binary)**:
      Installed from source
- **TensorFlow version (use command below)**:
      TF-1.3.1
- **Python version**:
      Python 2.7.5 
- **Bazel version (if compiling from source)**:
      Bazel - 0.5.4
- **CUDA/cuDNN version**:
      cuda-8.0 and cuDNN-6.0.21
- **GPU model and memory**:
        0   Tesla P100-SXM2 16276MiB
        1   Tesla P100-SXM2 16276MiB
- **Exact command to reproduce**:
     ` bazel test --config=opt --config=cuda -k //tensorflow/core:common_runtime_direct_session_with_tracking_alloc_test`

### Describe the problem
This test passed successfully with CPU only. However its failing for GPU , getting following error :
`F tensorflow/core/common_runtime/direct_session_with_tracking_alloc_test.cc:141] Check failed: cost_models.size() == 1 (2 vs. 1)`

(Test expects cost_models.size() == '1' , but we are getting '2' with GPU)

I was looking into this test failure and I found some relevant discussion links -
1) https://github.com/lukeiwanski/tensorflow/issues/75  - Here mentioned , this test is marked for no_gpu
2) https://github.com/lukeiwanski/tensorflow/pull/115 - Here I found following comments:

The aim of this test is to ensure that there is at least one cost model (that of the CPU), as if there are no cost models then the test should fail and there is no point in trying to run the other tests on the cost
model.

The number of cost models provided by a session should matches the number of devices used by that session. When additional devices are present there will be more than one cost model, so we should not be checking for equality, but rather that the number of cost models is at least one.

As per above comments , I think we should raise a PR with following changes to pass on GPU as well -
https://github.com/tensorflow/tensorflow/blob/v1.3.1/tensorflow/core/common_runtime/direct_session_with_tracking_alloc_test.cc#L141
Original - `CHECK_EQ(cost_models.size(), 1);`
Updated to - `CHECK_GE(cost_models.size(), 1); `

Please provide your comments on this. Thanks!
### Source code / logs
```
$  bazel test --config=opt --config=cuda -k //tensorflow/core:common_runtime_direct_session_with_tracking_alloc_test

...
2017-11-15 08:42:51.345108: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla P100-SXM2-16GB, pci bus id: 0006:01:00.0)
2017-11-15 08:42:51.352293: F tensorflow/core/common_runtime/direct_session_with_tracking_alloc_test.cc:141] Check failed: cost_models.size() == 1 (2 vs. 1)
================================================================================
Target //tensorflow/core:common_runtime_direct_session_with_tracking_alloc_test up-to-date:
  bazel-bin/tensorflow/core/common_runtime_direct_session_with_tracking_alloc_test
INFO: Elapsed time: 80.635s, Critical Path: 80.25s
//tensorflow/core:common_runtime_direct_session_with_tracking_alloc_test FAILED in 75.0s
```
"
14575,How to configure gpu memory fraction outside of my own code?,"My tensorflow automatically allocates all of my GPU memory.
I know the way to configure 'gpu memory fraction' in my own code like the below
```
import tensorflow as tf
gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.2)
sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))
```
I added the codes at the front of my code, so it worked well.

BUT I want to use tensorflow in distributed processing (e.g. spark)
Adding the configuration code in the code is not working in the distributed processing since configuration in the code is applied to only master machine, not to other machines.

SO, I try to configure gpu memory fraction of tensorflow itself.
how can I do??"
14573,bazel build failure of current master in Docker container due to contrib/lite,"Building current GPU version of master branch tensorflow/tensorflow@31b79e42b9e1643b3bcdc9df992eb3ce216804c5 fails in Docker container, saying

    /usr/bin/ld: warning: libcuda.so.1, needed by bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scc_Cops_Sdata_Uflow_Uops_Ugen_Ucc___Utensorflow/libtensorflow_framework.so, not found (try using -rpath or -rpath-link)

and I find that it is due to [`contrib/lite`](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite): when I comment out the related dependencies in [`tensorflow/tools/pip_package/BUILD`](https://github.com/tensorflow/tensorflow/blob/31b79e42b9e1643b3bcdc9df992eb3ce216804c5/tensorflow/tools/pip_package/BUILD#L164-L166), the build success.

I know this error is typically solved when I create a soft link inside the container before to build (c.f. #10776):

    RUN ln -s /usr/local/cuda/lib64/stubs/libcuda.so /usr/local/cuda/lib64/stubs/libcuda.so.1

but this time, it doesn't help."
14572,it's slow to train model when loading dataset and checkpoints from S3,"# System information

**Have I written custom code (as opposed to using a stock example script provided in TensorFlow):**  No

**OS Platform and Distribution (e.g., Linux Ubuntu 16.04):** Amazon Linux, P2 Instance

**TensorFlow installed from (source or binary):** pip

**TensorFlow version (use command below):** 1.5.0.dev20171113

**Python version:** 2.7

**CUDA/cuDNN version:** CUDA 8.0 / cuDNN 6.0

**GPU model and memory:** Tesla K80 12GB

# Describe the problem

The dataset and checkpoints are stored in S3 filesystem. It's slowly when training model. Howevery, The structure of network is simple and the speed is fast when load dataset and checkpoints from local filesystem

# Source code / logs

some code like 

```bash
def input_fn(mode):
    """""" Input callback for Estimator
    
    Arguments
    ----
    mode: str, tf.estimator.ModelKey
    file_pattern: tensorflow file pattern, refer to `tf.gfile.Glob`

    Return
    ---
    features: dict of Tensor, the input features for model
    label: single Tensor, the input label for model, must be integeral
    """"""
    is_train = tf.estimator.ModeKeys.TRAIN == mode

    vocab_dir = hparams.vocab_dir

    ds_dir = 'train' if is_train else 'test'
    file_pattern = os.path.join(hparams.dataset_dir, ds_dir, 'part-')

    tfrecords_files = [] 
    if file_pattern.startswith('s3'):
        tfrecords_files = list_s3_file(file_pattern)
    else:
        tfrecords_files = tf.gfile.Glob(file_pattern)

    example = create_example(vocab_dir)
    example_spec = tf.feature_column.make_parse_example_spec(feature_columns=example)

    batch_size = hparams.batch_size
    num_epochs = hparams.num_epochs if is_train else 1
    example_parsed = tf.contrib.learn.read_batch_record_features(file_pattern=tfrecords_files,
                            batch_size=batch_size,
                            num_epochs=num_epochs,
                            features=example_spec)

    label = example_parsed.pop('label')
    features = example_parsed

    return features, label
```

The log 

```bash

INFO:tensorflow:Into main function
INFO:tensorflow:vocab_dir: s3://experiements/yajun/youtube-match/data/raw/vocab
INFO:tensorflow:Create Estimator
INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7efcfa4bff90>, '_model_dir': 's3://experiements/yajun/youtube-match/data/model', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_save_summary_steps': 100, '_num_ps_replicas': 0}
INFO:tensorflow:Begin to train model
INFO:tensorflow:List files in S3 according to the file pattern: s3://experiements/yajun/youtube-match/data/raw/train/part-
INFO:tensorflow:Create CheckpointSaverHook.
2017-11-15 03:03:41.798030: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2017-11-15 03:03:45.623759: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-11-15 03:03:45.624258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1031] Found device 0 with properties:
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:00:1e.0
totalMemory: 11.17GiB freeMemory: 11.11GiB
2017-11-15 03:03:45.624285: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)
INFO:tensorflow:Restoring parameters from s3://experiements/yajun/youtube-match/data/model/model.ckpt-1400
^[[O^[[I
^[[OINFO:tensorflow:Saving checkpoints for 1401 into s3://experiements/yajun/youtube-match/data/model/model.ckpt.
INFO:tensorflow:loss = 4.90536, step = 1401
INFO:tensorflow:global_step/sec: 188.871
INFO:tensorflow:loss = 7.86743, step = 1501 (0.530 sec)
INFO:tensorflow:global_step/sec: 219.692
INFO:tensorflow:loss = 2.34025, step = 1601 (0.455 sec)
INFO:tensorflow:global_step/sec: 224.707
INFO:tensorflow:loss = 2.32145, step = 1701 (0.445 sec)
2017-11-15 03:14:24.980234: W tensorflow/core/framework/op_kernel.cc:1192] Out of range: FIFOQueue '_4_dequeue_record_examples/fifo_queue' is closed and has insufficient elements (requested 1, current size 0)
	 [[Node: dequeue_record_examples/fifo_queue_Dequeue = QueueDequeueV2[component_types=[DT_INT64, DT_INT64, DT_STRING, DT_INT64, DT_STRING], timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](dequeue_record_examples/fifo_queue)]]
INFO:tensorflow:Saving checkpoints for 1750 into s3://experiements/yajun/youtube-match/data/model/model.ckpt.
INFO:tensorflow:Loss for final step: 6.49392.
INFO:tensorflow:Begin to export model to s3://experiements/yajun/youtube-match/data/model/exports
2017-11-15 03:14:29.600289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)
INFO:tensorflow:Restoring parameters from s3://experiements/yajun/youtube-match/data/model/model.ckpt-1750
INFO:tensorflow:Assets added to graph.
INFO:tensorflow:No assets to write.
INFO:tensorflow:SavedModel written to: s3://experiements/yajun/youtube-match/data/model/exports/temp-1510715669/saved_model.pb
INFO:tensorflow:Finish to run
```"
14571,Links in tensorflow/tensorflow/contrib/lite/g3doc/models.md are not working,"The links in tensorflow/tensorflow/contrib/lite/g3doc/models.md are not working, please fix it?
When I click the Link, get the error ""AccessDenied"".
I try to modify the link from
https://storage.googleapis.com/download.tensorflow.org/models/mobilenet_v1_1.0_224_float_2017_11_08.zip
to
https://storage.googleapis.com/download.tensorflow.org/models/tflite/mobilenet_v1_1.0_224_float_2017_11_08.zip

it works.
But for inception model I don't know how to fix it , need your help?"
14568,Cmake TF1.4 GUP on windows 10,"Who can give me some recent samples about ""Cmake TF1.4 GUP on windows 10""? 
I have tried several times  following some old links ,but failed.




System information

•OS Platform and Distribution :win10/64
•TensorFlow version (use command below): 1.4.0
•Python version: 3.5.2
•CUDA/cuDNN version: 9.0 /7.0.3
•GPU model and memory: GTX 1080Ti
•VS2015
•Have I written custom code:
•TensorFlow installed from:
•Bazel version：
•Exact command to reproduce：
"
14567,Convert SavedModel files into TFLite file with toco convertor,"### Feature request

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: 
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 2.7
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

### Describe the problem

TensorFlow Lite is great and we can use the [toco](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite/toco) tools to convert freeze_graph. And we can specify the input and output tensors for this model.

However, we use SavedModel a lot for TensorFlow Serving. It has all the weights of the model and described the model signature in the better way.

It would be great if we can convert SavedModel file format into the final TFLite so that we don't need to export the model in many ways.

"
14566,Feature request for making dynamic gradient clipping ,"That I know about gradient, tf has 
https://www.tensorflow.org/versions/r0.12/api_docs/python/train/gradient_clipping

But I need the clipping gradient can change at training, and I see the all clip gradient doc, not found this function.

- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: python pip 
- **TensorFlow version (use command below)**: v 1.3.0
- **Python version**: 3.5.2
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:5.4.0
- **CUDA/cuDNN version**:Cuda compilation tools, release 8.0, V8.0.61
- **GPU model and memory**: 1080Ti 8G
- **Exact command to reproduce**:

Thanks"
14562,[Bug] tf.contrib.layers.layer_norm: third-party implementation does not reflect the original paper,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.3
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: CUDA 8.0/cuDNN 6.0
- **GPU model and memory**: Titan X
- **Exact command to reproduce**: 

### Describe the problem
In the [original layer normalization paper](https://arxiv.org/pdf/1607.06450.pdf), it's been said that beta/gamma should have the same dimension as hidden variable (see the lines below Eq (4) in Page 3). Based on current implementation, there is no such option that reflects the original paper.

Please run the following source code to verify that.

Also, see the comment #3671 .

### Source code / logs
`import tensorflow as tf`
`layer_norm = tf.contrib.layers.layer_norm`
`batch_size = 10`
`hidden_dim = 5`
`input = tf.zeros((batch_size, hidden_dim), dtype=tf.float32)`
`output = layer_norm(input)`
`tf.trainable_variables()`"
14558,Bug: Inclusion missing in TF 1.4 BUILD file for mpi component,"
### System information
- **I'm compiling TF from sources to have AVX512F instruction support**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: **16.04**
- **TensorFlow installed from (source or binary)**: **source (11/14/2017)**
- **TensorFlow version (use command below)**: **1.4.0**
- **Python version**: **3.6.1**
- **Bazel version (if compiling from source)**: **0.7.0**
- **GCC/Compiler version (if compiling from source)**: **5.4.0**
- **CUDA/cuDNN version**: **9.0 /7.0.3**
- **GPU model and memory**: **GTX 1080Ti**
- CPU i9 7900x
- **Exact command to reproduce**:


bazel build --config=mkl  --config=cuda  --copt=""-O3"" --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --copt=""-DOMPI_SKIP_MPICXX""  //tensorflow/tools/pip_package:build_pip_package

### Describe the problem
error in compile/build
....
**ERROR**: /home/tadeusz/temp/TF14a/tensorflow-master/tensorflow/contrib/mpi/BUILD:60:1: undeclared inclusion(s) in rule '//tensorflow/contrib/mpi:mpi_rendezvous_mgr':
this rule is missing dependency declarations for the following files included by 'tensorflow/contrib/mpi/mpi_rendezvous_mgr.cc':
  '/home/tadeusz/temp/TF14a/tensorflow-master/tensorflow/core/distributed_runtime/tensor_coding.h'
In file included from ./tensorflow/core/platform/default/logging.h:24:0,
                 from ./tensorflow/core/platform/logging.h:25,
                 from ./tensorflow/core/lib/gtl/array_slice_internal.h:32,
                 from ./tensorflow/core/lib/gtl/array_slice.h:101,
                 from ./tensorflow/core/lib/strings/str_util.h:23,
                 from ./tensorflow/contrib/mpi/mpi_utils.h:25,
                 from ./tensorflow/contrib/mpi/mpi_rendezvous_mgr.h:33,
                 from tensorflow/contrib/mpi/mpi_rendezvous_mgr.cc:18:
./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetTensorDim(tensorflow::gtl::ArraySlice<T>, tensorflow::TensorFormat, char) [with T = long long int]':
./tensorflow/core/util/tensor_format.h:372:47:   required from here
./tensorflow/core/util/tensor_format.h:340:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]

### Source code / logs
the following helps
in file //tensorflow/contrib/mpi/BUILD
```
....
cc_library(
    name = ""mpi_rendezvous_mgr"",
    srcs = [""mpi_rendezvous_mgr.cc""],
    hdrs = [""mpi_rendezvous_mgr.h""],
    deps = [
        "":mpi_msg_proto_cc"",
        "":mpi_utils"",
        ""//tensorflow/core:core_cpu_internal"",
        ""//tensorflow/core:framework"",
        ""//tensorflow/core:gpu_runtime"",
        ""//tensorflow/core:lib"",
        ""//tensorflow/core:protos_cc"",
        ""//tensorflow/core:worker_proto_cc"",
        ""//tensorflow/core/distributed_runtime:base_rendezvous_mgr"",
        ""//tensorflow/core/distributed_runtime:session_mgr"",
        ""//tensorflow/core/distributed_runtime:worker_env"",
        ""//third_party/mpi"",
        ""//tensorflow/core/distributed_runtime:tensor_coding"",   ## <<<<< add this line <<<<<<<
    ],
)

```
"
14550,Log version of the SoftmaxFunctor implementation is numerically unstable,"The following code in the log version of SoftmaxFunctor, should use reduce_logsumexp() instead of .exp().sum().log()

```
    if (log) {
      // Calculate the log of the softmax
      // softmax = logits - max(logits along classes);
      softmax.device(d) = shifted_logits;
      // softmax = softmax - log(sum(exp(softmax along classes)));
      softmax.device(d) = (softmax -
                           softmax.exp()
                               .sum(along_class)
                               .eval()
                               .reshape(batch_by_one)
                               .log()
                               .broadcast(one_by_class));

```

Additionally, the following code in the tests only passes without generating NANs because the data is generated using standard normals, never resulting in the values that are too small to be converted to zeroes when exponentiated:

```
class LogSoftmaxTest(test_lib.TestCase):

  def _log_softmax(self, x):
    assert len(x.shape) == 2
    m = x.max(1)[:, np.newaxis]
    u = x - m
    return u - np.log(np.sum(np.exp(u), 1, keepdims=True))
```"
14549,Windows Bazel build is failing due to compiling error for //tensorflow/compiler/xla:util,"http://ci.tensorflow.org/job/tf-master-win-bzl/1902/console
```
09:28:12 bazel-out/msvc_x64-py3-opt/genfiles\tensorflow/compiler/xla/xla_data.pb.h(280): error C2059: syntax error: 'constant'
09:28:12 bazel-out/msvc_x64-py3-opt/genfiles\tensorflow/compiler/xla/xla_data.pb.h(280): error C3805: 'constant': unexpected token, expected either '}' or a ','
```

Culprit: https://github.com/tensorflow/tensorflow/commit/64d9aa1ace99c66f20b65532f633acb34ee3c057

The dependency from pip package to this target is:
```
//tensorflow/tools/pip_package:build_pip_package
//tensorflow/python/eager:eager_pip
//tensorflow/python:pywrap_tensorflow
//tensorflow/python:pywrap_tensorflow_internal
//tensorflow/python:_pywrap_tensorflow_internal.so
//tensorflow/python:tf_session_helper
//tensorflow/core:all_kernels
//tensorflow/core/kernels:summary_kernels
//tensorflow/core/kernels:summary_interface
//tensorflow/compiler/xla:util
```
This dependency exists even when xla is disabled.

https://github.com/tensorflow/tensorflow/commit/64d9aa1ace99c66f20b65532f633acb34ee3c057 changed [xla_data.proto](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/xla/xla_data.proto), which somehow caused this problem. 

Because the code is generated by protobuf, I'm not sure if this is a protobuf bug.
@yunxing @gunan 
"
14547,Tensorflow Java Api Graph support any other than InceptionV3,"I'm fairly new to tensorflow, but I've got a general idea of it.

I've retrained Faster RCNN coco model on my own images in ubuntu. and exported the frozen graph.
Now I'm busy writing an Java app in windows that will use the model for object detection, I need bounding boxes etc to can't just use the normal classifier.

In my java app when I try to load/importGraphDef the frozen graph(converted to bytes), I get the following error.
""Op type not registered 'NonMaxSuppressionV2'""
Any and all examples I find online of implementing the tensorflow java api uses inceptionv3.
So my guess is that the java API doesn't yet support other types(faster rcnn in my case) models

Is that correct or are there something else I should be looking at, if it is then I have to rewrite my java app in python...
And if so does anyone know when support will be implemented ?

Thank you."
14546,"[Go] SIGABRT when running go test, using tensorflow 1.4 compiled form source","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Archlinux
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: Build label: 0.7.0- (@non-git)
- **GCC/Compiler version (if compiling from source)**: gcc-6
- **CUDA/cuDNN version**: CUDA 9 / cuDNN 7
- **GPU model and memory**: Dual Nvidia 1080 Ti
- **Exact command to reproduce**:

```
go test github.com/tensorflow/tensorflow/tensorflow/go
```

### Describe the problem

I have build tensorflow with CUDA support. Since Go requires the C library, I built `libtensorflow.so` and `libtensorflow_framework.so`, with:

```
bazel build //tensorflow:libtensorflow_framework.so
bazel build //tensorflow:libtensorflow.so
```

I updated `LD_LIBRARY_PATH` accordingly:

```bash
TENSORFLOW_LIBLIB=""${HOME}/sources/tensorflow/bazel-bin/tensorflow/""
export LD_LIBRARY_PATH=""$LD_LIBRARY_PATH:/opt/cuda/lib64:/opt/cuda/extras/CUPTI/lib64:${TENSORFLOW_LIBLIB}""
export LIBRARY_PATH=""${TENSORFLOW_LIBLIB}:${LIBRARY_PATH}""
```

I can now go get tensorflow without problems, I can hence compile it and use the `-ltensorflow` linker flag.

When I run `go test` on the tensorflow package, the following error (`tensorflow/core/framework/tensor.cc:822] Unexpected type: 23 `) is thrown and causes SIGABRT.

### Source code / logs

```
go test github.com/tensorflow/tensorflow/tensorflow/go                                                                                                                                                                                                    
2017-11-14 12:12:06.299645: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA                                                                        
2017-11-14 12:12:06.303492: F tensorflow/core/framework/tensor.cc:822] Unexpected type: 23                                                                                                                                                                                     
SIGABRT: abort                                                                                                                                                                                                                                                                 
PC=0x7f1d39a098a0 m=6 sigcode=18446744073709551610                        
signal arrived during cgo execution                                                                                                                                                                                                                                            
                                                                                                                                                                                                                                                                               goroutine 40 [syscall, locked to thread]:                                                                                                                                                                                                                                      
runtime.cgocall(0x656af0, 0xc4200519c8, 0xc4200519f0)
        /usr/lib/go/src/runtime/cgocall.go:132 +0xe4 fp=0xc420051998 sp=0xc420051958 pc=0x4054c4                                                                                                                                                                        
github.com/tensorflow/tensorflow/tensorflow/go._Cfunc_TF_SetAttrTensor(0x7f1cf000a9a0, 0x7f1cf000b5a0, 0x7f1cf000b6b0, 0x7f1cf000cc00)                                                                                                                                         
        github.com/tensorflow/tensorflow/tensorflow/go/_test/_obj_test/_cgo_gotypes.go:890 +0x45 fp=0xc4200519c8 sp=0xc420051998 pc=0x52ce85                                                                                                                                   
github.com/tensorflow/tensorflow/tensorflow/go.setAttr.func18(0x7f1cf000a9a0, 0x7f1cf000b5a0, 0x7f1cf000b6b0, 0x7f1cf000cc00)                                                                                                                                                  
        /home/pgaleone/go/src/github.com/tensorflow/tensorflow/tensorflow/go/graph.go:273 +0xec fp=0xc420051a00 sp=0xc4200519c8 pc=0x53907c
github.com/tensorflow/tensorflow/tensorflow/go.setAttr(0x7f1cf000a9a0, 0xc42000e0c0, 0x6ef59e, 0x5, 0x6b6560, 0xc4200f6460, 0x0, 0x0)
        /home/pgaleone/go/src/github.com/tensorflow/tensorflow/tensorflow/go/graph.go:273 +0x11b9 fp=0xc420051c00 sp=0xc420051a00 pc=0x52fab9                                                                                                                                  
github.com/tensorflow/tensorflow/tensorflow/go.(*Graph).AddOperation(0xc42000e080, 0x6ef404, 0x5, 0xc42050c4e0, 0x6, 0x0, 0x0, 0x0, 0xc42008af00, 0x4b388b, ...)                                                                                                               
        /home/pgaleone/go/src/github.com/tensorflow/tensorflow/tensorflow/go/graph.go:176 +0x4a0 fp=0xc420051d60 sp=0xc420051c00 pc=0x52e700                                                                                                                                   
github.com/tensorflow/tensorflow/tensorflow/go.Const(0xc42000e080, 0xc42050c4e0, 0x6, 0x682c40, 0xc4200f62e0, 0xc42050c4e0, 0x6, 0x4d48ed, 0x7ab068)
        /home/pgaleone/go/src/github.com/tensorflow/tensorflow/tensorflow/go/util_test.go:38 +0x221 fp=0xc420051e38 sp=0xc420051d60 pc=0x52a0a1
github.com/tensorflow/tensorflow/tensorflow/go.TestOutputDataTypeAndShape.func1(0xc420110780)                                                                                                                                                                                  
        /home/pgaleone/go/src/github.com/tensorflow/tensorflow/tensorflow/go/operation_test.go:137 +0x11e fp=0xc420051fa8 sp=0xc420051e38 pc=0x53650e                                                                                                                          
testing.tRunner(0xc420110780, 0xc4200f6420)                                                                                                                                                                                                                                    
        /usr/lib/go/src/testing/testing.go:746 +0xd0 fp=0xc420051fd0 sp=0xc420051fa8 pc=0x4d4990
runtime.goexit()                                                                                                                                                                                                                                                               
        /usr/lib/go/src/runtime/asm_amd64.s:2337 +0x1 fp=0xc420051fd8 sp=0xc420051fd0 pc=0x45f981                                                                                                                                                                              
created by testing.(*T).Run                                                                                                                                                                                                                                                    
        /usr/lib/go/src/testing/testing.go:789 +0x2de                                                                                                                                                                                                                          
                                                                                                                                                                                                                                                                               
goroutine 1 [chan receive]:                                                                                                                                                                                                                                                    
testing.(*T).Run(0xc420110000, 0x6f567b, 0x1a, 0x702ab0, 0x47b301)             
        /usr/lib/go/src/testing/testing.go:790 +0x2fc                                                                                                                                                                                                                          
testing.runTests.func1(0xc420110000)                                           
        /usr/lib/go/src/testing/testing.go:1004 +0x64                          
testing.tRunner(0xc420110000, 0xc420061de0)                                    
        /usr/lib/go/src/testing/testing.go:746 +0xd0
testing.runTests(0xc4200f6240, 0xa413c0, 0x11, 0x11, 0xc420061e78)
        /usr/lib/go/src/testing/testing.go:1002 +0x2d8
testing.(*M).Run(0xc420061f18, 0xc420061f70)
        /usr/lib/go/src/testing/testing.go:921 +0x111                                                         
main.main()                                                                            
        github.com/tensorflow/tensorflow/tensorflow/go/_test/_testmain.go:82 +0xdb

goroutine 36 [chan receive]:         
testing.(*T).Run(0xc4201103c0, 0xc4200145e0, 0x13, 0xc4200f6420, 0x2)                                                                                                                                                                                                          
        /usr/lib/go/src/testing/testing.go:790 +0x2fc                                                                                                                                                                                                                          
github.com/tensorflow/tensorflow/tensorflow/go.TestOutputDataTypeAndShape(0xc4201103c0)                                                                                                                                                                                        
        /home/pgaleone/go/src/github.com/tensorflow/tensorflow/tensorflow/go/operation_test.go:136 +0x56e                                                                                                                                                                      
testing.tRunner(0xc4201103c0, 0x702ab0)                                                                                                                                                                                                                                        
        /usr/lib/go/src/testing/testing.go:746 +0xd0
created by testing.(*T).Run
        /usr/lib/go/src/testing/testing.go:789 +0x2de

rax    0x0
rbx    0x6
rcx    0x7f1d39a098a0
rdx    0x0
rdi    0x2
rsi    0x7f1cf67fb7b0
rbp    0x7f1cf67fba00
rsp    0x7f1cf67fb7b0
r8     0x0
r9     0x7f1cf67fb7b0
r10    0x8
r11    0x246
r12    0x7f1cf000c210
r13    0x17
r14    0x7f1cf000b5a0
r15    0x7f1cf67fbc40
rip    0x7f1d39a098a0
rflags 0x246
cs     0x33
fs     0x0
gs     0x0
FAIL    github.com/tensorflow/tensorflow/tensorflow/go  0.059s
```"
14545,Nan in summary histogram error for training images if faster_rcnn_resnet101_coco_11_06_2017 model is used.,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.3.0
- **Python version**: 3.7
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: cudnn-8.0
- **GPU model and memory**:  GeForce GTX 1060 6GB 
- **Exact command to reproduce**: python train.py --logtostderr --train_dir=training/ (path to training directory) --pipeline_config_path=training/faster_rcnn_resnet101.config (path to .config file)

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

InvalidArgumentError (see above for traceback): Nan in summary histogram for: FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/weights_1
	 [[Node: FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/weights_1 = HistogramSummary[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/weights_1/tag, FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/weights/read)]]
	 [[Node: FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/BatchNorm/gamma/read/_777 = _Recv client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_2768_FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/BatchNorm/gamma/read"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0"" ()]]



### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
14544,"ValueError: Variable RNNLM/RNNLM/embedding_layer/embedding/Adam_2/ does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=tf.AUTO_REUSE in VarScope?","  when running following code, 
    
**with tf.variable_scope('RNNLM') as scope:
          model = RNNLM_Model(config)
          scope.reuse_variables()
          gen_model = RNNLM_Model(gen_config)**

this problem occurs:
       **ValueError: Variable RNNLM/RNNLM/embedding_layer/embedding/Adam_2/ does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=tf.AUTO_REUSE in VarScope?**
 why it is 'RNNLM/RNNLM/embedding_layer'?

the following code can run successfully
 
 **model = RNNLM_Model(config)
  tf.get_variable_scope().reuse_variables()
  gen_model = RNNLM_Model(gen_config)**

  "
14543,Failed to calculate FLOPs for Tensorflow Object Detection API (SSD_Mobilenet & SSD_Inception),"System information

    Have I written custom code: No
    OS Platform and Distribution: Linux Ubuntu 14.04
    TensorFlow installed from: source
    TensorFlow version: ('v1.3.0-rc1-1951-g04c318b', '1.3.0')
    Python version: 2.7.12
    Bazel version (if compiling from source): 0.7.0
    CUDA/cuDNN version: 8.0/6.0
    GPU model and memory: Tesla K40 12Gb
    Exact command to reproduce: bazel-bin/tensorflow/tools/benchmark/benchmark_model --graph=ssd_inception.pb --input_layer=""image_tensor"" --input_layer_shape=""1,224,224,3"" --input_layer_type=""uint8"" --output_layer=""detection_boxes,detection_scores,detection_classes,num_detections"" --show_flops=true

Problem
The ssd_inception.pb is one of the model that trained from Tensorflow object detection API. When I tried the FLOPs calculation, it failed with  Invalid argument: Tried to fetch data for '^FeatureExtractor/Assert/Assert', which produces no output.  To run to a node but not fetch any data, pass '^FeatureExtractor/Assert/Assert' as an argument to the 'target_node_names' argument of the Session::Run API.

Logs
2017-11-14 19:01:29.405289: E tensorflow/tools/benchmark/benchmark_model.cc:593] FLOPs calculation failed with Invalid argument: Tried to fetch data for '^FeatureExtractor/Assert/Assert', which produces no output.  To run to a node but not fetch any data, pass '^FeatureExtractor/Assert/Assert' as an argument to the 'target_node_names' argument of the Session::Run API."
14542,'Model' object has no attribute 'container_nodes',"## Problem
```python
model = tf.keras.models.Model()
model.add(...)
tf.keras.utils.plot_model(model, to_file=""model.png"")
```
Output:
```
Traceback (most recent call last):
  File ""model.py"", line 36, in <module>
    K.utils.plot_model(model, to_file=""model.png"")
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/utils/vis_utils.py"", line 148, in plot_model
    dot = model_to_dot(model, show_shapes, show_layer_names, rankdir)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/utils/vis_utils.py"", line 123, in model_to_dot
    if node_key in model.container_nodes:
AttributeError: 'Model' object has no attribute 'container_nodes'
```

## Environment
-System: Ubuntu 16.04
-Tensorflow-gpu bin v1.4.0-rc1-11-g130a514 1.4.0

"
14540,Wrong protobuf BUILD rule while compiling tensorflow on powerpc ,"### System Info
- **No custom code is written**
- **Ubuntu 16.04 on powerpc (ppc64le)**
- **Installing from source**
- **Tensorflow v1.4.0**
- **python 3.5.2**
- **bazel 0.7.0**
- **`gcc --version` output: gcc (Ubuntu/IBM 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609**
- **CUDA 8.0, cuDNN 5.1**
- **NVIDIA Tesla P100**

### Describe the problem
I tried to build Tensorflow from sources. While `./configure`ing, I did the following;

`Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -mcpu=native]: -mcpu=native -mtune=native`

because I'm on a powerpc. (-march=native is not recognized, already denoted by [Default -mcpu=native])

After executing `bazel build --config=opt --config=cuda tensorflow/tools/pip_package:build_pip_package`, it starts to download and compile protobuf, I immediately get the following, 

`ERROR: /home/powerpc/.cache/bazel/_bazel_powerpc/7ad07c846e34c4f733a905eaa47f3cba/external/protobuf_archive/BUILD:265:1: C++ compilation of rule '@protobuf_archive//:js_embed' failed (Exit 1).
gcc: error: unrecognized command line option '-march=native'
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 18.579s, Critical Path: 6.01s`

I believe this stems from a wrong BUILD rule for protobuf, it defaults to [-march=native]. I wasn't able to find the relevant BUILD file to fix.

### Edit
After trying again, this time I get the same error for highwayhash. This is about third_party packages, should I have to edit all BUILD rules manually?"
14539,Build Custom GPU Op Failed with TF-1.3.1,"### System information
- **Have I written custom code**: 
YES
- **OS Platform and Distribution**:
Ubuntu 14.04 LTS
- **TensorFlow installed from**:
source
- **TensorFlow version**:
1.3.1
- **Python version**: 
2.7.6
- **Bazel version**:
0.5.4
- **GCC/Compiler version**:
4.8.4
- **CUDA/cuDNN version**:
7.5/6.0
- **GPU model and memory**:
Geforce GTX TITAN X, 12GB
- **Exact command to reproduce**:
```bash
TF_INC=$(python -c 'import tensorflow as tf; print tf.sysconfig.get_include()')
nvcc -std=c++11 -c -o interpolate.cu.o interpolate_gpu.cu.cc \
        -I $TF_INC -D GOOGLE_CUDA=1 -x cu -Xcompiler -fPIC -D_MWAITXINTRIN_H_INCLUDED
```

### Describe the problem
I want to compile a custom gpu op by nvcc with tf-1.3.1, however it returns the following result:
```
/usr/local/lib/python2.7/dist-packages/tensorflow/include/tensorflow/core/framework/op_kernel.h(317): warning: type qualifier on return type is meaningless

/usr/local/lib/python2.7/dist-packages/tensorflow/include/tensorflow/stream_executor/kernel.h(307): warning: variable ""result"" is used before its value is set

/usr/local/lib/python2.7/dist-packages/tensorflow/include/tensorflow/stream_executor/device_description.h(85): warning: type qualifier on return type is meaningless

/usr/local/lib/python2.7/dist-packages/tensorflow/include/tensorflow/stream_executor/device_description.h(144): warning: type qualifier on return type is meaningless

/usr/local/lib/python2.7/dist-packages/tensorflow/include/tensorflow/core/util/cuda_kernel_helper.h(620): error: identifier ""__shfl"" is undefined

/usr/local/lib/python2.7/dist-packages/tensorflow/include/tensorflow/core/util/cuda_kernel_helper.h(640): error: identifier ""__shfl_up"" is undefined

/usr/local/lib/python2.7/dist-packages/tensorflow/include/tensorflow/core/util/cuda_kernel_helper.h(660): error: identifier ""__shfl_down"" is undefined

/usr/local/lib/python2.7/dist-packages/tensorflow/include/tensorflow/core/util/cuda_kernel_helper.h(680): error: identifier ""__shfl_xor"" is undefined

4 errors detected in the compilation of ""/tmp/tmpxft_00001c41_00000000-7_interpolate_gpu.cu.cpp1.ii"".

```
"
14535,Can not import transformed and quantized model using tf.import_graph_def,"Hello guys,
I am trying to quantized the pretrain SSD_mobilenet_v1_coco from the Tensorflow Object Detection API using the following command:
`bazel build tensorflow/tools/graph_transforms:transform_graph
bazel-bin/tensorflow/tools/graph_transforms/transform_graph \
--in_graph=MobileNetSSD.pb \
--out_graph=optimized_SSD.pb \
--inputs='image_tensor' \
--outputs='detection_boxes,detection_scores,detection_classes,num_detections' \
--transforms='
  add_default_attributes
  strip_unused_nodes(type=uint8, shape=""1,300,300,3"")  
  fold_constants(ignore_errors=true)
  fold_batch_norms
  fold_old_batch_norms
  quantize_weights
  quantize_nodes
  strip_unused_nodes
  sort_by_execution_order'`

The command run successfully and I had the optimized_SSD.pb with only 6MB. However, when I try to use this pb model in the provided IPython Notebook file [title](https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb) I received this error:
`Traceback (most recent call last):
  File ""/home/phong/PycharmProjects/ConvertDarknet2VOC/evaluation.py"", line 52, in <module>
    tf.import_graph_def(od_graph_def, name='')
  File ""/home/phong/.virtualenvs/tensorflow_pycharm/local/lib/python2.7/site-packages/tensorflow/python/framework/importer.py"", line 283, in import_graph_def
    raise ValueError('No op named %s in defined operations.' % node.op)
ValueError: No op named QuantizedResizeBilinear in defined operations.`

Is there any way to load the quantized model using tensorflow ? 


"
14533,Tensorflow Website XSRF Token missing or incorrect,"The error occurs when I read current TF API documentation. My default lang is set to Russian (but it does not matter and has influence only on the bottom menu). But when I'm trying to change the language to English or Chinese I get the following error message:

>XSRF Token missing or incorrect

Is it ok or this is the TF Website bug?

Windows 10
Firefox 56.0.2 x64
![1setlang](https://user-images.githubusercontent.com/7415950/32767632-4ab78b0e-c925-11e7-8cff-6843af74ef71.png)
![2xsrf](https://user-images.githubusercontent.com/7415950/32767633-4ada17c8-c925-11e7-8e82-4f2bd322350a.PNG)

"
14529,[feature request]time out option for tf.Data.from_generator,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 10/7
- **TensorFlow installed from (source or binary)**:
pip installed tensorflow-gpu binary
- **TensorFlow version (use command below)**:
1.40
- **Python version**: 
3.5/3.6
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
CUDA8/cuDNN6.0
- **GPU model and memory**:
gtx980m(8g)/Quadro 4000M(8g)
- **Exact command to reproduce**:
from_generator

### Describe the problem
Unnecessary background:
I previously using a customized python function to load (one epoch of) images from disc, perform pre-processing and data augmentation and return as generator, and feed into corresponding placeholder via feed_dict. This function worked out fine for 100,000+ steps.

I recently refactored my codes using tf.Data and put the exact same function into the tf.Data.from_generator function. However, the pipeline would stuck indefinitely every 200 epochs (3,000 steps) or so, just before it should break out from ""except tf.errors.OutOfRangeError:""; also it's not throwing any exception which could be cached by ""except Exception as e"". However, by manually pressing ""enter"", the program would continue to run while dumping out a full screen of getNext() error messages from previous runs. Unfortunately I can not supply any customized pre-processing functions and data to help you debug this ""bug"", and I am not sure it's reproduce-able with a reduced example, since the occurrence seems rather arbitrary.

**Feature wish:**
I am hoping for a time out feature for the general tf.Data class to break out from bad loops. 
I suppose any customized solution would involve using standalone thread which could interfere with tf threadpool, therefore this feature must be supported in the tf scope.


"
14528,Tensorflow would sometimes get rather slow during training,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: pip
- **TensorFlow version (use command below)**: 1.4
- **Python version**: 3.5
- **CUDA/cuDNN version**: CUDA 8.0 / cuDNN 6.0
- **GPU model and memory**: GTX1060 6GB
### Describe the problem
When I train my network, at first it works properly, however sometimes it gets rather slower (about 10 times slower than normal speed, shown below). When I type nvidia-smi to check the GPU state, I find the GPU-Util is rather low (2-3%)
The normal speed is about 1 minute per 100 steps while it would sometimes cost 10 minminutes per 100 steps. 
I used to use Tensorflow v1.1 and did not find this problem. However I updated Tensorflow to v1.4 several days ago and this problem occurred.

### Source code / logs
> 2017-11-12 23:43:55  Step: 770900, loss: 1.6261, accuracy: 68.7500%
2017-11-12 23:45:37  Step: 771000, loss: 1.4571, accuracy: 65.6250%
2017-11-12 23:48:37  Step: 771100, loss: 1.3790, accuracy: 73.4375%
2017-11-12 23:49:50  Step: 771200, loss: 1.6311, accuracy: 57.8125%
2017-11-12 23:51:11  Step: 771300, loss: 1.3248, accuracy: 67.1875%
2017-11-12 23:52:31  Step: 771400, loss: 1.6924, accuracy: 64.0625%
2017-11-12 23:53:44  Step: 771500, loss: 1.3097, accuracy: 67.1875%
2017-11-12 23:55:02  Step: 771600, loss: 1.7720, accuracy: 64.0625%
2017-11-12 23:56:15  Step: 771700, loss: 1.5915, accuracy: 68.7500%
2017-11-12 23:57:28  Step: 771800, loss: 1.7489, accuracy: 60.9375%
2017-11-12 23:58:50  Step: 771900, loss: 1.2855, accuracy: 68.7500%
2017-11-13 00:00:03  Step: 772000, loss: 1.3734, accuracy: 65.6250%
2017-11-13 00:01:16  Step: 772100, loss: 1.4637, accuracy: 70.3125%
2017-11-13 00:02:38  Step: 772200, loss: 1.6229, accuracy: 60.9375%
2017-11-13 00:03:51  Step: 772300, loss: 1.3330, accuracy: 65.6250%
2017-11-13 00:05:04  Step: 772400, loss: 1.7729, accuracy: 56.2500%
2017-11-13 00:06:37  Step: 772500, loss: 1.2806, accuracy: 65.6250%
2017-11-13 00:07:59  Step: 772600, loss: 1.0916, accuracy: 70.3125%
2017-11-13 00:09:31  Step: 772700, loss: 1.4440, accuracy: 73.4375%
2017-11-13 00:10:43  Step: 772800, loss: 0.9338, accuracy: 76.5625%
2017-11-13 00:13:03  Step: 772900, loss: 1.6038, accuracy: 57.8125%
2017-11-13 00:14:15  Step: 773000, loss: 1.2853, accuracy: 64.0625%
2017-11-13 00:16:43  Step: 773100, loss: 1.1761, accuracy: 75.0000%
2017-11-13 00:17:56  Step: 773200, loss: 1.0927, accuracy: 68.7500%
2017-11-13 00:23:23  Step: 773300, loss: 1.3884, accuracy: 73.4375%
2017-11-13 00:24:37  Step: 773400, loss: 1.3729, accuracy: 67.1875%
2017-11-13 00:25:50  Step: 773500, loss: 1.0257, accuracy: 76.5625%
2017-11-13 00:29:01  Step: 773600, loss: 1.4766, accuracy: 68.7500%
2017-11-13 00:38:35  Step: 773700, loss: 1.3401, accuracy: 68.7500%
2017-11-13 00:47:49  Step: 773800, loss: 1.4850, accuracy: 68.7500%
2017-11-13 00:57:39  Step: 773900, loss: 1.2555, accuracy: 68.7500%
2017-11-13 01:06:59  Step: 774000, loss: 1.6202, accuracy: 60.9375%
2017-11-13 01:16:28  Step: 774100, loss: 1.4673, accuracy: 59.3750%
2017-11-13 01:26:11  Step: 774200, loss: 1.3678, accuracy: 67.1875%
2017-11-13 01:35:38  Step: 774300, loss: 1.2268, accuracy: 67.1875%
2017-11-13 01:45:14  Step: 774400, loss: 1.5675, accuracy: 60.9375%
2017-11-13 01:55:00  Step: 774500, loss: 1.7380, accuracy: 59.3750%
2017-11-13 02:04:42  Step: 774600, loss: 1.9971, accuracy: 56.2500%
2017-11-13 02:15:26  Step: 774700, loss: 1.9669, accuracy: 54.6875%
2017-11-13 02:28:05  Step: 774800, loss: 1.3680, accuracy: 67.1875%
2017-11-13 02:39:03  Step: 774900, loss: 1.1381, accuracy: 76.5625%"
14526,Doubt in the implementation of gan's training critera,"I read the code of gan implementation in tf.contrib.gan, but I'm not quite sure whether the generator_train_op and discriminator_train_op use the same batch of data. 

Here is the code in [https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/gan/python/train.py](url)
```python
class RunTrainOpsHook(session_run_hook.SessionRunHook):
  """"""A hook to run train ops a fixed number of times.""""""

  def __init__(self, train_ops, train_steps):
    """"""Run train ops a certain number of times.
    Args:
      train_ops: A train op or iterable of train ops to run.
      train_steps: The number of times to run the op(s).
    """"""
    if not isinstance(train_ops, (list, tuple)):
      train_ops = [train_ops]
    self._train_ops = train_ops
    self._train_steps = train_steps

  def before_run(self, run_context):
    for _ in range(self._train_steps):
      run_context.session.run(self._train_ops)

def get_sequential_train_hooks(train_steps=namedtuples.GANTrainSteps(1, 1)):
  """"""Returns a hooks function for sequential GAN training.
  Args:
    train_steps: A `GANTrainSteps` tuple that determines how many generator
      and discriminator training steps to take.
  Returns:
    A function that takes a GANTrainOps tuple and returns a list of hooks.
  """"""
  def get_hooks(train_ops):
    generator_hook = RunTrainOpsHook(train_ops.generator_train_op,
                                     train_steps.generator_train_steps)
    discriminator_hook = RunTrainOpsHook(train_ops.discriminator_train_op,
                                         train_steps.discriminator_train_steps)
    return [generator_hook, discriminator_hook]
  return get_hooks
```

Can we guarantee that both hooks run the optimizer on the same batch, along with that each hook run the respective optimizer several times on the same batch? I think that's needed for gan training, and consistent with relative papers.



"
14523,[Fetaure Request] Layer normalization for NCHW/NHWC with fast gpu kernel,tf.contrib.layers.layer_norm is slow and only supports NHWC layout. It is beneficial to have a fast gpu kernel for layer normalization that supports both NCHW and NHWC. I think layer normalization is quite useful when the minibatch is extremely small or comprises only one sample (in which case batch norm/renorm doesn't work) and when local receptive fields is desired (in which case instance norm is bad).
14522,bazel build: can't install tensor flow,"I did ""bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package""
and this is what I got:

""ERROR: /home/simon/Downloads/tensorflow/tensorflow/contrib/rnn/BUILD:259:1: Illegal ambiguous match on configurable attribute ""copts"" in //tensorflow/contrib/rnn:gen_gru_ops_py_wrappers_cc:
@local_config_cuda//cuda:using_clang
@local_config_cuda//cuda:using_nvcc
Multiple matches are not allowed unless one is unambiguously more specialized.
ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted:

/home/simon/Downloads/tensorflow/tensorflow/contrib/rnn/BUILD:259:1: Illegal ambiguous match on configurable attribute ""copts"" in //tensorflow/contrib/rnn:gen_gru_ops_py_wrappers_cc:
@local_config_cuda//cuda:using_clang
@local_config_cuda//cuda:using_nvcc
Multiple matches are not allowed unless one is unambiguously more specialized.
INFO: Elapsed time: 0.454s
FAILED: Build did NOT complete successfully (0 packages loaded)
currently loading: tensorflow/python""

What do I Do?"
14520,upgrades to boosted_trees: an example with feature importance + tuning + savedmodel,"### System information
N/A

### Describe the problem
*Feature Request*: I hate to make a trite request, but is there any plan to add more documentation or examples to the `tensorflow.contrib.boosted_trees` submodule? Now that there's a GB classifier available, I am hoping to replace my production XGBoost code with `boosted_trees` as soon as I can prove it out. Perhaps it's my newness to `tf.contrib.learn`'s `Estimator`s and `Experiment`s, but I found the examples a bit opaque and repetitive. For example, would it be possible to have an example script demonstrating these properties:
* some feature importance metrics (I see the Hooks but don't know how to use them)
* some type of hyperparameter tuning (max_depth, examples_per_layer, etc.)
* the implementation of an ExportStrategy in the Experiment; or better yet, throw away the experiment and directly operate on a trained Estimator. I'm struggling to write a proper serving input function
* a (perhaps commented out) example of using each input in the `GradientBoostedTreeClassifier` constructor

Sorry to ask for hand-holding here. It's just taking me longer than usual to figure these things out from the source code.

Also, to the extent that I've figured out some of these, are you welcoming PRs for more thorough examples?"
14518,DataSet user provided shuffled order,"It would be very useful if a user will be able to provide the order of examples within a dataset (with repetitions allowed, as only indices are shuffled).
This would allow having a more complicated logic (which involves balancing data of different types).

I assume it can be somehow supported by zip-ing together different DataSets, but it would be MUCH easier and more flexible if we could just pass a list of indices. Probably light as well as it shouldn't be a big deal passing one list per epoch.

Please tell me if this feature already exists, and if not, please add it :)"
14515,//tensorflow/python:session_clusterspec_prop_test is failing with GPU support ,"### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
     Ubuntu 16.04 (ppc64le)
- **TensorFlow installed from (source or binary)**:
     Installed from source
- **TensorFlow version (use command below)**:
     TF1.3.1
- **Python version**:
     Python 2.7.5 
- **Bazel version (if compiling from source)**:
     Bazel - 0.5.4
- **GCC/Compiler version (if compiling from source)**:
     gcc - 4.8.5
- **CUDA/cuDNN version**:
     cuda-8.0  and cuDNN-6.0.21
- **GPU model and memory**:
      0 Tesla P100-SXM2   16276MiB
      1 Tesla P100-SXM2   16276MiB
- **Exact command to reproduce**:
`bazel test  --config=opt --config=cuda -k  //tensorflow/python:session_clusterspec_prop_test`

### Describe the problem
This test passed successfully with CPU only.
However its failing with GPU support , getting assertion error `1 != 0`. 

I was debugging this test failure and found following code fails for GPU -
https://github.com/tensorflow/tensorflow/blob/v1.3.1/tensorflow/python/client/session_clusterspec_prop_test.py#L86-L92
   ```
self.assertEqual(1,
                     len([
                         node_stats
                         for dev_stats in run_metadata.step_stats.dev_stats
                         for node_stats in dev_stats.node_stats
                         if '/job:worker/replica:0/task:1/device:CPU:0' ==
                         dev_stats.device and 'Const' == node_stats.node_name
                     ]))
```
Test expects output '1' , but len function returns '0', because of following  lines 
```
  if '/job:worker/replica:0/task:1/device:CPU:0' ==
  dev_stats.device and 'Const' == node_stats.node_name

```
I have printed/checked values of `dev_stats.device` using print statements, see below -
1) With CPU only support - we are getting CPU:0 device for task0 and task1 :
```
 dev_stats.device =  /job:worker/replica:0/task:0/device:CPU:0
 dev_stats.device = /job:worker/replica:0/task:1/device:CPU:0
```
2) But with GPU support - for task0 ---> device:CPU:0 and for task1 ---> device:GPU:0
```
 dev_stats.device = /job:worker/replica:0/task:0/device:CPU:0
 dev_stats.device = /job:worker/replica:0/task:1/device:GPU:0
```
That's why this test is failing with GPU support , as if condition is not satisfied ( `  if '/job:worker/replica:0/task:1/device:CPU:0' ! = /job:worker/replica:0/task:1/device:GPU:0 `)

I tried changing if condition from  `if '/job:worker/replica:0/task:1/device:CPU:0'` to `if '/job:worker/replica:0/task:1/device:GPU:0'` and test passed successfully (with GPU).

This is my overall understanding.
I want to fix this test, please provide your comments/suggestions.
### Source code / logs
..
```
$  bazel test  --config=opt --config=cuda -k  //tensorflow/python:session_clusterspec_prop_test
...
======================================================================
FAIL: testClusterSpecPropagationWorker2Placement (__main__.SessionClusterSpecPropagationTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/home/sandip/.cache/bazel/_bazel_sandip/a43c7182abc6db034a12d4266337a49c/execroot/org_tensorflow/bazel-out/local_linux-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/client/session_clusterspec_prop_test.py"", line 92, in testClusterSpecPropagationWorker2Placement
    dev_stats.device and 'Const' == node_stats.node_name
AssertionError: 1 != 0

----------------------------------------------------------------------
Ran 12 tests in 1.797s

FAILED (failures=1)
================================================================================

```"
14514,tensorboard not deployed,"It appears Tensorboard is not installed under the following condictions:
- Win 10
- GPU (+Cuda 8)
- Anaconda 1.6.9
- NEW installation of TF GPU, as per instructions at https://www.tensorflow.org/install/install_windows

Thanks for checking
"
14512,gfile random access file seek implementation inappropriate,"the call stack for tensorflow.python.platform.gfile.GFile.seek function is as follows:
https://github.com/tensorflow/tensorflow/blob/294442996b2aeff00b1bfdc7e7169f7cb35bbf3d/tensorflow/python/lib/io/file_io.py#L118
https://github.com/tensorflow/tensorflow/blob/18f36927160d05b941c056f10dc7f9aecaa05e23/tensorflow/core/lib/io/buffered_inputstream.cc#L153
https://github.com/tensorflow/tensorflow/blob/18f36927160d05b941c056f10dc7f9aecaa05e23/tensorflow/core/lib/io/buffered_inputstream.cc#L126
https://github.com/tensorflow/tensorflow/blob/d44d271c9da4d244ce4b2ffaf808adbe4cff759d/tensorflow/core/lib/io/random_inputstream.h#L27
https://github.com/tensorflow/tensorflow/blob/d44d271c9da4d244ce4b2ffaf808adbe4cff759d/tensorflow/core/lib/io/inputstream_interface.cc#L27

The implementation of SkipNBytes for random access file is read out N bytes. It's not efficient if we seek through one huge file. I think we should override the implementation for random access file.

I tried seek API for one large hdfs file, it took more than one hour to finish.
"
14511,How can I have an Online Data Augmentation like Keras in Tensorflow (tf-slim)?,"Hi all,

I use tf-slim [(this network)][1] for my classification problem. I want to do online data augmentation like [Keras ImageDataGenerator][2] for my images. I know [these functions][3] in Tensorflow, but I need a tutorial or an example in Tensorflow or tf-slim that does this online data augmentation. Would you please, help me to find a way to do this?


  [1]: https://github.com/pudae/tensorflow-densenet
  [2]: https://keras.io/preprocessing/image/
  [3]: https://www.tensorflow.org/api_guides/python/image"
14509,Function for explicit broadcasting,"It would be convenient to have an explicit function for broadcasting in TensorFlow's Python API, like to [`numpy.broadcast_to`](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.broadcast_to.html) or XLA's [Broadcast](https://www.tensorflow.org/performance/xla/operation_semantics#broadcast), and as [requested on StackOverFlow](https://stackoverflow.com/questions/34362193/how-to-explicitly-broadcast-a-tensor-to-match-anothers-shape-in-tensorflow). This would facilitate adding broadcasting-like behavior to the many TensorFlow operations that don't support it out of the box.

I understand that in general TensorFlow does not implement NumPy's the strided N-dimensional array data model, so unlike the case for NumPy, broadcasting (e.g., with Eigen tensors) can require a copy. This is a good reason to not necessarily build such a version of broadcasting into ops. However, explicit broadcasting rather than using tile/expand_dims can still be very convenient.
"
14507,XLA reports error with 1000 steps of static_bidirectional_rnn,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.2.1 or 1.3
- **Python version**: 2.7.4
- **Bazel version (if compiling from source)**: 0.4.5
- **GCC/Compiler version (if compiling from source)**: 4.8.5
- **CUDA/cuDNN version**: 5.1
- **GPU model and memory**: M40
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
This issue can only be reproduced when XLA works with static_bidirectional_rnn with 1000 steps, and the ""seq_len"" of static_bidirectional_rnn must be assigned, which means it works with ""dynamic calculation"". When the issue is reproduced, it reports:

```
2017-11-01 18:47:16.497266: E tensorflow/stream_executor/cuda/cuda_driver.cc:731] failed to load PTX text as a module: CUDA_ERROR_NO_BINARY_FOR_GPU
2017-11-01 18:47:16.497294: E tensorflow/stream_executor/cuda/cuda_driver.cc:736] error log buffer (163 bytes): ptxas application ptx input, line 7231; error   : Kernel '_fusion_1' exceeds parameter space limit of 4352 bytes
ptxas fatal   : Ptx assembly aborted due to error

```
From my analysis, a fused XLA instruction requires for more than 1000 input parameters. This further leads to a PTX kernel with 1000+ parameters, which is not accepted by the cuda driver.

This is what I found from the PTX ISA documents:
`The maximum memory size supported by PTX for normal (non-opaque type) parameters is 4352 bytes. Prior to PTX ISA version 1.5, the maximum size was 256 bytes.`

Read more at: http://docs.nvidia.com/cuda/parallel-thread-execution/index.html#ixzz4yGwCVOB7
Follow us: @GPUComputing on Twitter | NVIDIA on Facebook


### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
14506,poor performance when XLA works with dynamic control_flow ops,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.2.1
- **Python version**:  2.7.14
- **Bazel version (if compiling from source)**: 0.4.5
- **GCC/Compiler version (if compiling from source)**: 4.8.5
- **CUDA/cuDNN version**: 8.0/5.1.10
- **GPU model and memory**: M40
- **Exact command to reproduce**: 

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
When XLA works with:
1, dynamic_rnn
2, static_rnn with ""dynamic calculation"" enabled, specificaly, when the seq_len is assigned.

In these cases, the performance of XLA is poor, even result in negative performance optimization.
From the time line it seems that the switch/merge ops are breaking the XLA fused instructions into pieces. But i still don't understand why it leads to negative optimization.

Pls let me know if this is a known issue, are there any special reasons for XLA not to support control flow ops? or if there's anything i can do to fix it. Thanks.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
14505,index_to_string_table_from_file cannot use tf.string as vocabulary file,"Running stock tensorflow on macOS I get:

```
import tensorflow as tf

print (tf.__version__)

with open('test', 'w') as f:
  f.write('hello\n')
  f.write('world\n')
  f.write('!\n')

file_path = tf.constant('test')
#file_path = 'test' # this works

a = tf.constant(['world', 'hello'])

with tf.Session() as sess:
  str2i = tf.contrib.lookup.index_table_from_file(vocabulary_file=file_path)
  sess.run(str2i.init)
  i = str2i.lookup(a)
  print(sess.run(i))

  # Other way doesn't work
  i2str = tf.contrib.lookup.index_to_string_table_from_file(vocabulary_file=file_path)
  sess.run(i2str.init)
  s = i2str.lookup(i)
  print(sess.run(s))
```

results in:

```
1.4.0
2017-11-12 23:29:51.316725: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[1 0]
Traceback (most recent call last):
  File ""test.py"", line 22, in <module>
    i2str = tf.contrib.lookup.index_to_string_table_from_file(vocabulary_file=file_path)
  File ""/Users/olanymoe/anaconda2/envs/tf3/lib/python3.5/site-packages/tensorflow/python/ops/lookup_ops.py"", line 1121, in index_to_string_table_from_file
    if not vocabulary_file:
  File ""/Users/olanymoe/anaconda2/envs/tf3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 528, in __bool__
    raise TypeError(""Using a `tf.Tensor` as a Python `bool` is not allowed. ""
TypeError: Using a `tf.Tensor` as a Python `bool` is not allowed. Use `if t is not None:` instead of `if t:` to test if a tensor is defined, and use TensorFlow ops such as tf.cond to execute subgraphs conditioned on the value of a tensor.
```

Expected:

```
1.4.0
2017-11-12 23:30:22.082767: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[1 0]
[b'world' b'hello']
```

Due to None check at https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/lookup_ops.py#L1126

This is an issue because I can't seem to be able to make `index_to_string_table_from_file` read the vocabulary_file from a `GraphKeys.ASSET_FILEPATHS` collection when storing the graph as a saved_model"
14504,Cannot use keras estimator_from_model() in distributed cluster,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: tf.VERSION = 1.4.0 tf.GIT_VERSION = v1.4.0-rc1-11-g130a514
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: 8.0.61/6.0.21
- **GPU model and memory**: NVIDIA Tesla M60 8 GB
- **Exact command to reproduce**: See Below

### Describe the problem
When trying to use an estimator that is derived from ```tf.keras.estimator.estimator_from_model()``` and training with ```tf.estimator.train_and_evaluate()```, it will work as expected if in a standalone non-distributed session. However, when in a distributed training cluster and the TF_CONFIG has the cluster information set, there is a an explicit device assignment of an op to a device that is not valid in the current cluster spec.

Below is code to reproduce this issue. When ```simulate_cluster``` is set to True an error is throws as shown in the log below. When ```simulate_cluster``` is set to False the network is constructed and trained as intended. It should be noted that the error occurs when calling ```tf.keras.estimator.model_to_estimator(keras_model=model)``` and not when doing the training, the cluster config is required for the distributed training to take place.

The TF_CONFIG that is set below is derived from calling the code using the gcloud SDK as follows:
```gcloud ml-engine local train --distributed --parameter-server-count=1 --worker-count=2 --package-path=trainer --module-name=trainer.task --```

### Source code / logs
Minimal example:
```python
import os
import numpy as np
import tensorflow as tf

tf.logging.set_verbosity(tf.logging.INFO)

simulate_cluster = True
if simulate_cluster:
    os.environ[""TF_CONFIG""] = '{""environment"": ""cloud"", ""cluster"": {""worker"": [""localhost:27184"", ""localhost:27185""], \
               ""ps"": [""localhost:27183""], ""master"": [""localhost:27182""]}, ""job"": {""args"": [""""], \
               ""job_name"": ""trainer.task""}, ""task"": {""index"": 0, ""type"": ""master""}}'
else:
    os.environ[""TF_CONFIG""] = ''

inputs = tf.keras.layers.Input(shape=(10,))
outputs = tf.keras.layers.Dense(10)(inputs)
model = tf.keras.models.Model(inputs, outputs)
model.compile(optimizer='Adam', loss='binary_crossentropy')
est_keras = tf.keras.estimator.model_to_estimator(keras_model=model) # InvalidArgumentError thrown here if simulate_cluster is True

input_name = model.input_names[0]
data = np.random.rand(1000,10).astype(np.float32)
train_input_fn = tf.estimator.inputs.numpy_input_fn({input_name:data}, data, batch_size=10, num_epochs=None, shuffle=False)

train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, max_steps=100)
eval_spec = tf.estimator.EvalSpec(input_fn=train_input_fn, steps=10)
tf.estimator.train_and_evaluate(est_keras, train_spec, eval_spec)
```

InvalidArgumentError emitted when ```simulate_cluster = True```:
```python
Traceback (most recent call last):
  File ""minimal.py"", line 19, in <module>
    est_keras = tf.keras.estimator.model_to_estimator(keras_model=model)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/_impl/keras/estimator.py"", line 280, in model_to_estimator
    _save_first_checkpoint(keras_model, est, custom_objects, keras_weights)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/_impl/keras/estimator.py"", line 217, in _save_first_checkpoint
    model.set_weights(keras_weights)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/_impl/keras/engine/topology.py"", line 766, in set_weights
    K.batch_set_value(tuples)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/_impl/keras/backend.py"", line 2406, in batch_set_value
    get_session().run(assign_ops, feed_dict=feed_dict)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/_impl/keras/backend.py"", line 376, in get_session
    _initialize_variables(session)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/_impl/keras/backend.py"", line 554, in _initialize_variables
    [variables_module.is_variable_initialized(v) for v in candidate_vars])
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 889, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1120, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1317, in _do_run
    options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1336, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation 'loss/dense_1_loss/sub': Operation was explicitly assigned to /job:master/task:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:GPU:0, /job:localhost/replica:0/task:0/device:GPU:1, /job:localhost/replica:0/task:0/device:GPU:2, /job:localhost/replica:0/task:0/device:GPU:3 ]. Make sure the device specification refers to a valid device.
         [[Node: loss/dense_1_loss/sub = Sub[T=DT_FLOAT, _device=""/job:master/task:0""](loss/dense_1_loss/sub/x, loss/dense_1_loss/Const)]]

Caused by op u'loss/dense_1_loss/sub', defined at:
  File ""minimal.py"", line 19, in <module>
    est_keras = tf.keras.estimator.model_to_estimator(keras_model=model)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/_impl/keras/estimator.py"", line 280, in model_to_estimator
    _save_first_checkpoint(keras_model, est, custom_objects, keras_weights)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/_impl/keras/estimator.py"", line 209, in _save_first_checkpoint
    custom_objects)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/_impl/keras/estimator.py"", line 124, in _clone_and_build_model
    target_tensors=target_tensors)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/_impl/keras/engine/training.py"", line 840, in compile
    output_loss = weighted_loss(y_true, y_pred, sample_weight, mask)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/_impl/keras/engine/training.py"", line 444, in weighted
    score_array = fn(y_true, y_pred)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/_impl/keras/losses.py"", line 78, in binary_crossentropy
    return K.mean(K.binary_crossentropy(y_true, y_pred), axis=-1)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/_impl/keras/backend.py"", line 3027, in binary_crossentropy
    output = clip_ops.clip_by_value(output, epsilon_, 1 - epsilon_)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py"", line 910, in r_binary_op_wrapper
    return func(x, y, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py"", line 4636, in _sub
    ""Sub"", x=x, y=y, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2956, in create_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1470, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): Cannot assign a device for operation 'loss/dense_1_loss/sub': Operation was explicitly assigned to /job:master/task:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:GPU:0, /job:localhost/replica:0/task:0/device:GPU:1, /job:localhost/replica:0/task:0/device:GPU:2, /job:localhost/replica:0/task:0/device:GPU:3 ]. Make sure the device specification refers to a valid device.
         [[Node: loss/dense_1_loss/sub = Sub[T=DT_FLOAT, _device=""/job:master/task:0""](loss/dense_1_loss/sub/x, loss/dense_1_loss/Const)]]
```

Full logs, tf_env, and more are here: https://gist.github.com/droidicus/2abd4ddad81a1e9169a1c7a100057b15
"
14503,Error: CUDNN_STATUS_INTERNAL_ERROR Any help is appreciated. ,"Dears, I am struglling with tensorflow installation. 

I have GeForce GTX1080 , Ubuntu16.04 cuda 9 cudnn7 . nvidia driver 384.98. I try to run the mnist samle coud from cudd_samples v7 and I got this error: 
Error: CUDNN_STATUS_INTERNAL_ERROR
here is nvidia-smi
-----------------------------------------------------------------------------+
| NVIDIA-SMI 384.98                 Driver Version: 384.98                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 108...  Off  | 00000000:03:00.0  On |                  N/A |
| 30%   47C    P8    13W / 250W |    581MiB / 11171MiB |      1%      Default |
+-------------------------------+----------------------+----------------------+
|   1  GeForce GTX 108...  Off  | 00000000:04:00.0 Off |                  N/A |
| 23%   36C    P8     9W / 250W |      2MiB / 11172MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0      1390      G   /usr/lib/xorg/Xorg                           331MiB |
|    0      2158      G   compiz                                       196MiB |
|    0      2878      G   ...-token=04563B517E2C68A632F4C6B61B846229    51MiB |


nvcc -V
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2017 NVIDIA Corporation
Built on Fri_Sep__1_21:08:03_CDT_2017
Cuda compilation tools, release 9.0, V9.0.176


Please help. "
14502,Estimator does not not support sparse jobs,"You need sparse jobs (https://github.com/tensorflow/tensorflow/commit/8177edd7700ccbe0c831e680a1acb5275819d762) if you want async training to proceed without having all workers available.

This currently doesn't work because estimator [uses json](https://github.com/tensorflow/tensorflow/blob/9ff1aebc2b3dcb07f15b92c0a58027b0438f502a/tensorflow/python/estimator/run_config.py#L379) to dump values into `TF_CONFIG` env var, and json does not allow numeric keys. `json.dumps` automatically converts numeric keys into strings.

However, clusterspec for sparse job must have integers like `{""local"": {37: ""localhost:0""}}` and will crash if we have `""37""` instead of `37`.

Suggestion 1: Modify sparse job support to allow strings as task indices

Suggestion 2: use pickle + base16 encoding to transmit these values

Base16 is shell-friendly, it allows you to copy paste the value into ""export TF_...."" in terminal

```
 # saving
 cluster_config = {'cluster': cluster_spec, 'task': task_spec}
 pickle_string = pickle.dumps(sparse_cluster_config)
 pickle_string_encoded = base64.b16encode(pickle_string)
 pickle_string_encoded = pickle_string_encoded.decode('ascii')
 export_command = ""export TF_PICKLE_BASE16=%s""%(pickle_string_encoded,)
 os.system(export_command)

# loading
config_dict = pickle.loads(base64.b16decode(os.environ[""TF_PICKLE_BASE16""]))
config.task_type = config_dict[""task""][""type""]
config.task_id = config_dict[""task""][""index""]
config.cluster_spec = config_dict[""cluster""]
return config
```

cc @ispirmustafa "
14498,The result of tf.control_dependencies is undetermined.,"```python
import tensorflow as tf

w = tf.Variable(0)
op1 = tf.assign(w, 1)
op2 = tf.assign(w, 2)
op_1 = tf.constant('op1')
op_2 = tf.constant('op2')

op1 = tf.Print(op1, [op_1])
op2 = tf.Print(op2, [op_2])

with tf.control_dependencies([op2]):
    with tf.control_dependencies([op1]):
        op = tf.no_op()

with tf.Session() as sess:
    tf.global_variables_initializer().run()
    sess.run(op)
    print(sess.run(w))
```
It sometimes prints `1` and sometimes prints `2`.

Another example:
```python
import tensorflow as tf

w = tf.Variable(0)
op1 = tf.assign(w, 0)
op2 = tf.assign(w, 2)
op_1 = tf.constant('op1')
op_2 = tf.constant('op2')

op1 = tf.Print(op1, [op_1])
op2 = tf.Print(op2, [op_2])

with tf.control_dependencies([op1]):
    op3 = tf.no_op()

with tf.control_dependencies([op3, op2]):
    op4 = tf.no_op()


with tf.Session() as sess:
    tf.global_variables_initializer().run()
    sess.run(op4)
    print(sess.run(w))
```
Sometimes `0` and sometimes `2`."
14496,Building with MKL reduces CPU performance,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: both
- **TensorFlow version (use command below)**: 1.4
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: 0.5.4
- **GCC/Compiler version (if compiling from source)**: 5.4.0
- **CUDA/cuDNN version**: 8
- **GPU model and memory**: Tesla P100-PCIE-16GB
- **Exact command to reproduce**:

### Describe the problem
Building tensorflow with mkl (--config=mkl) prevents the system from using all its cores.
CPU load remains always below 20% in my testcase. Using the same build flags but without mkl achieve 100% CPU load and a nearly 10 times faster execution.

While playing with the MKL flags described here https://www.tensorflow.org/performance/performance_guide#optimizing_for_cpu
i noticed some strange behavior:

Running the MKL-build with 
`OMP_NUM_THREADS=27 KMP_SETTINGS=1 KMP_AFFINITY=verbose `
results in the following print:

```
User settings:

   KMP_AFFINITY=verbose
   KMP_SETTINGS=1
   OMP_NUM_THREADS=27

Effective settings:

   KMP_ABORT_DELAY=0
   KMP_ADAPTIVE_LOCK_PROPS='1,1024'
   KMP_ALIGN_ALLOC=64
   KMP_ALL_THREADPRIVATE=224
   KMP_ATOMIC_MODE=2
   KMP_BLOCKTIME=200
   KMP_CPUINFO_FILE: value is not defined
   KMP_DETERMINISTIC_REDUCTION=false
   KMP_DEVICE_THREAD_LIMIT=2147483647
   KMP_DISP_NUM_BUFFERS=7
   KMP_DUPLICATE_LIB_OK=false
   KMP_FORCE_REDUCTION: value is not defined
   KMP_FOREIGN_THREADS_THREADPRIVATE=true
   KMP_FORKJOIN_BARRIER='2,2'
   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'
   KMP_FORKJOIN_FRAMES=true
   KMP_FORKJOIN_FRAMES_MODE=3
   KMP_GTID_MODE=3
   KMP_HANDLE_SIGNALS=false
   KMP_HOT_TEAMS_MAX_LEVEL=1
   KMP_HOT_TEAMS_MODE=0
   KMP_INIT_AT_FORK=true
   KMP_INIT_WAIT=2048
   KMP_ITT_PREPARE_DELAY=0
   KMP_LIBRARY=throughput
   KMP_LOCK_KIND=queuing
   KMP_MALLOC_POOL_INCR=1M
   KMP_NEXT_WAIT=1024
   KMP_NUM_LOCKS_IN_BLOCK=1
   KMP_PLAIN_BARRIER='2,2'
   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'
   KMP_REDUCTION_BARRIER='1,1'
   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'
   KMP_SCHEDULE='static,balanced;guided,iterative'
   KMP_SETTINGS=true
   KMP_SPIN_BACKOFF_PARAMS='4096,100'
   KMP_STACKOFFSET=64
   KMP_STACKPAD=0
   KMP_STACKSIZE=4M
   KMP_STORAGE_MAP=false
   KMP_TASKING=2
   KMP_TASKLOOP_MIN_TASKS=0
   KMP_TASK_STEALING_CONSTRAINT=1
   KMP_TEAMS_THREAD_LIMIT=56
   KMP_TOPOLOGY_METHOD=all
   KMP_USER_LEVEL_MWAIT=false
   KMP_VERSION=false
   KMP_WARNINGS=true
   OMP_CANCELLATION=false
   OMP_DEFAULT_DEVICE=0
   OMP_DISPLAY_ENV=false
   OMP_DYNAMIC=false
   OMP_MAX_ACTIVE_LEVELS=2147483647
   OMP_MAX_TASK_PRIORITY=0
   OMP_NESTED=false
   OMP_NUM_THREADS='27'
   OMP_PLACES: value is not defined
   OMP_PROC_BIND='false'
   OMP_SCHEDULE='static'
   OMP_STACKSIZE=4M
   OMP_THREAD_LIMIT=2147483647
   OMP_WAIT_POLICY=PASSIVE
   KMP_AFFINITY='verbose,warnings,respect,granularity=core,none'

OMP: Info #209: KMP_AFFINITY: decoding x2APIC ids.
OMP: Info #207: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info
OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55}
OMP: Info #156: KMP_AFFINITY: 56 available OS procs
OMP: Info #157: KMP_AFFINITY: Uniform topology
OMP: Info #179: KMP_AFFINITY: 2 packages x 14 cores/pkg x 2 threads/core (28 total cores)
OMP: Info #247: KMP_AFFINITY: pid 35537 tid 35708 thread 0 bound to OS proc set {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55}
OMP: Info #247: KMP_AFFINITY: pid 35537 tid 35706 thread 1 bound to OS proc set {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55}
OMP: Info #247: KMP_AFFINITY: pid 35537 tid 35707 thread 2 bound to OS proc set {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55}
OMP: Info #247: KMP_AFFINITY: pid 35537 tid 35704 thread 3 bound to OS proc set {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55}
OMP: Info #247: KMP_AFFINITY: pid 35537 tid 35701 thread 4 bound to OS proc set {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55}
OMP: Info #247: KMP_AFFINITY: pid 35537 tid 35711 thread 5 bound to OS proc set {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55}
OMP: Info #247: KMP_AFFINITY: pid 35537 tid 35712 thread 6 bound to OS proc set {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55}
OMP: Info #247: KMP_AFFINITY: pid 35537 tid 35713 thread 7 bound to OS proc set {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55}
OMP: Info #247: KMP_AFFINITY: pid 35537 tid 35705 thread 8 bound to OS proc set {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55}
OMP: Info #247: KMP_AFFINITY: pid 35537 tid 35710 thread 9 bound to OS proc set {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55}
OMP: Info #247: KMP_AFFINITY: pid 35537 tid 35702 thread 10 bound to OS proc set {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55}
OMP: Info #247: KMP_AFFINITY: pid 35537 tid 35717 thread 11 bound to OS proc set {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55}
...
OMP: Info #247: KMP_AFFINITY: pid 35537 tid 35678 thread 78 bound to OS proc set {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55}
OMP: Info #247: KMP_AFFINITY: pid 35537 tid 35672 thread 79 bound to OS proc set {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55}
OMP: Info #247: KMP_AFFINITY: pid 35537 tid 35674 thread 80 bound to OS proc set {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55}
....
(continues with a higher thread number each time)
```

If I use the same execution flags with a build without MKL or with the pip version I get the same ouput up to 
`
...
OMP: Info #247: KMP_AFFINITY: pid 36958 tid 37191 thread 27 bound to OS proc set {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55}
`
Afterwards no OMP prints are created. It seems like, if I build with mkl, tensorflow continues to create more and more threads but cant utilize them. 

Is this a configuration issue or a bug? 
If its a known issue, please expand the performance guide :) 

pinging @skye because of its help with the performance issue with while_loop 

"
14495,FATAL EXCEPTION on running the custom app after including libraries. java.lang.UnsatisfiedLinkError,"java.lang.UnsatisfiedLinkError: com.android.tools.fd.runtime.IncrementalClassLoader$DelegateClassLoader[DexPathList[[dex file ""/data/data/com.example.iiti.earcheck/files/instant-run/dex/slice-support-annotations-25.0.1_ef28e13c9736d79b0dc9b87816fdb5d73ab6b4a6-classes.dex"", dex file ""/data/data/com.example.iiti.earcheck/files/instant-run/dex/slice-slice_9-classes.dex"", dex file ""/data/data/com.example.iiti.earcheck/files/instant-run/dex/slice-slice_8-classes.dex"", dex file ""/data/data/com.example.iiti.earcheck/files/instant-run/dex/slice-slice_7-classes.dex"", dex file ""/data/data/com.example.iiti.earcheck/files/instant-run/dex/slice-slice_6-classes.dex"", dex file ""/data/data/com.example.iiti.earcheck/files/instant-run/dex/slice-slice_5-classes.dex"", dex file ""/data/data/com.example.iiti.earcheck/files/instant-run/dex/slice-slice_4-classes.dex"", dex file ""/data/data/com.example.iiti.earcheck/files/instant-run/dex/slice-slice_3-classes.dex"", dex file ""/data/data/com.example.iiti.earcheck/files/instant-run/dex/slice-slice_2-classes.dex"", dex file ""/data/data/com.example.iiti.earcheck/files/instant-run/dex/slice-slice_1-classes.dex"", dex file ""/data/data/com.example.iiti.earcheck/files/instant-run/dex/slice-slice_0-classes.dex"", dex file ""/data/data/com.example.iiti.earcheck/files/instant-run/dex/slice-org.tensorflow-tensorflow-android-1.4.0_d5862dbeef875a2fd03edd55b52916408a0fdae3-classes.dex"", dex file ""/data/data/com.example.iiti.earcheck/files/instant-run/dex/slice-libandroid_tensorflow_inference_java_8b98de511efe4c9135a05cbc7896de53b57dba53-classes.dex"", dex file ""/data/data/com.example.iiti.earcheck/files/instant-run/dex/slice-internal_impl-25.0.1_fe869e8b718f7d011b42911906bd8102f80b5a3e-classes.dex"", dex file ""/data/data/com.example.iiti.earcheck/files/instant-run/dex/slice-internal_impl-25.0.1_e684d856bf1ea2afc0785de8b2275aa12611114e-classes.dex"", dex file ""/data/data/com.example.iiti.earcheck/files/instant-run/dex/slice-internal_impl-25.0.1_aa673af4dcf22bcd43d00f80c8888302b9bc278f-classes.dex"", dex file ""/data/data/com.example.iiti.earcheck/files/instant-run/dex/slice-internal_impl-25.0.1_73c7d1a62ae7807eb7fd020f01cc2e0e5fd6f9f0-classes.dex"", dex file ""/data/data/com.example.iiti.earcheck/files/instant-run/dex/slice-internal_impl-25.0.1_2002db2ec303ce7ff6c3fba7cf2a064df60d63e4-classes.dex"", dex file ""/data/data/com.example.iiti.earcheck/files/instant-run/dex/slice-com.android.support-support-vector-drawable-25.0.1_6f89a35e510cd2b99a51cac7fbf50945d73d2434-classes.dex"", dex file ""/data/data/com.example.iiti.earcheck/files/instant-run/dex/slice-com.android.support-support-v4-25.0.1_7519131df48ff71670e81da58ca765ab77bce972-classes.dex"", dex file ""/data/data/com.example.iiti.earcheck/files/instant-run/dex/slice-com.android.support-support-media-compat-25.0.1_d42d2937b0925301d8bc24c4d82fa264d601340d-classes.dex"", dex file ""/data/data/com.example.iiti.earcheck/files/instant-run/dex/slice-com.android.support-support-fragment-25.0.1_130afa5cd91643b7e407f699e25e8953be2af0b8-classes.dex"", dex file ""/data/data/com.example.iiti.earcheck/files/instant-run/dex/slice-com.android.support-support-core-utils-25.0.1_39638966b982d2402411d64d18981a4ce8677c1f-classes.dex"", dex file ""/data/data/com.example.iiti.earcheck/files/instant-run/dex/slice-com.android.support-support-core-ui-25.0.1_a6406a5ff5aa24fae58de96cd3218c571f49607d-classes.dex"", dex file ""/data/data/com.example.iiti.earcheck/files/instant-run/dex/slice-com.android.support-support-compat-25.0.1_5b463be571b727968d5b5d68f9c9b17d4dd40809-classes.dex"", dex file ""/data/data/com.example.iiti.earcheck/files/instant-run/dex/slice-com.android.support-appcompat-v7-25.0.1_17a51234c0d6cd6e15ec23d8be2aa38790811b00-classes.dex"", dex file ""/data/data/com.example.iiti.earcheck/files/instant-run/dex/slice-com.android.support-animated-vector-drawable-25.0.1_df8c5ec44495c7c6a687ebfe83e9e46b0bcc5d42-classes.dex""],nativeLibraryDirectories=[/data/app/com.example.iiti.earcheck


Help!
"
14494,Difference between distribute and local machine version when training by tensorflow ," I use a common DNN network with less than 4 layers for a regression task. When I test my codes in local single machine with CPU, everything is fine. But when I train it on distribute system, which uses 30 machines' CPU and in the asynchronous parameters update way, all the layers' output values, including the last prediction values, come into Nan. The learning rate in local and distribute training are both 0.01. I changed it to 0.0001 in distribute way, it seems fine that the outputs are in normal range. I am confused about why learning rate cause this phenomenon. Any friend can try to explain it ? Thanks.


--
The label is a float, ranging from 0 to 1. Most of them falls into 0.1 to 0.3


"
14493,Feature Request: C++ gradient for Prod (PR done),Pull request opened. https://github.com/tensorflow/tensorflow/pull/14422
14491,n 6,"Had the wrong window highlighted, hit enter and opened this issue by mistake. Can be removed."
14490,tf.contrib.metrics.streaming_mean,"```python
def streaming_mean_weight_test():
    '''
        Average by weight
    '''
    values = tf.constant([[1.0, 2.0], [3.3, 2.5]])
    weights = tf.constant([[0.3, 3.1], [-1.3, 1.2]])
    mean_value, update_op = tf.contrib.metrics.streaming_mean(values, weights=weights)
    tf_weight_mean = tf.truediv(tf.reduce_sum(tf.multiply(values, weights)), tf.reduce_sum(weights))
    with tf.Session() as sess:
        tf.local_variables_initializer().run()
        print(update_op.eval())
        _mean_value = mean_value.eval()
        _tf_weight_mean = tf_weight_mean.eval()
        print(_mean_value)
        print(_tf_weight_mean)
    assert np.all(np.isclose(_mean_value, _tf_weight_mean)), 'streaming_mean_weight_test is wrong!'
```
It works well. But when I use `weights = tf.constant([[0.3, -3.1], [-1.3, 1.2]])` instead of weights above,
It can't work, `_mean_value=0.0`, what's  wrong?
"
14489,sess.run hangs forever despite operation_timeout_in_ms being set,"`sess.run` waits indefinitely on worker when one of the parameter server machines in the cluster fails despite `operation_timeout_in_ms` being set.

Because waiting happens inside TensorFlow runtime, there's no way for client to regain control to provide a helpful error message/fix the situation.

```
sess=tf.Session(config=...operation_timeout_in_ms=1000)  # succeeds even though TF cluster is partially dead
sess.run(remote_op)       # hangs forever
```
You see this during worker's `session.run`
```
2017-11-11 16:06:12.524442: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0
2017-11-11 16:06:22.525582: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0
2017-11-11 16:06:32.525718: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0
```

Suggestion: since `CreateSession` happens during `session.run`, make it subject to `.operation_timeout_in_ms` deadline

cc @mrry 
"
14488,Problem to install tensorflow,"Hello, I am trying to install the tensorflow to use it in the digits of nvdia and am having this problem :/

> Exception:
Traceback (most recent call last):
  File ""/home/felipe/.local/lib/python2.7/site-packages/pip/basecommand.py"", line 215, in main
    status = self.run(options, args)
  File ""/home/felipe/.local/lib/python2.7/site-packages/pip/commands/install.py"", line 342, in run
    prefix=options.prefix_path,
  File ""/home/felipe/.local/lib/python2.7/site-packages/pip/req/req_set.py"", line 784, in install
    **kwargs
  File ""/home/felipe/.local/lib/python2.7/site-packages/pip/req/req_install.py"", line 851, in install
    self.move_wheel_files(self.source_dir, root=root, prefix=prefix)
  File ""/home/felipe/.local/lib/python2.7/site-packages/pip/req/req_install.py"", line 1064, in move_wheel_files
    isolated=self.isolated,
  File ""/home/felipe/.local/lib/python2.7/site-packages/pip/wheel.py"", line 345, in move_wheel_files
    clobber(source, lib_dir, True)
  File ""/home/felipe/.local/lib/python2.7/site-packages/pip/wheel.py"", line 316, in clobber
    ensure_dir(destdir)
  File ""/home/felipe/.local/lib/python2.7/site-packages/pip/utils/__init__.py"", line 83, in ensure_dir
    os.makedirs(path)
  File ""/usr/lib/python2.7/os.py"", line 157, in makedirs
    mkdir(name, mode)
OSError: [Errno 13] Permissão negada: '/usr/local/lib/python2.7/dist-packages/funcsigs-1.0.2.dist-info'"
14486,"TowerLoss(Multiple GPU) will hurt final accuracy/performance so much when doing image finetune, is it a bug?","From the paper ""Show and Tell: Lessons learned from the 2015 MSCOCO Image Captioning Challenge""
Writer say ""Training was
done using a single GPU (Nvidia K20), and step time was
about 3 seconds. Thus, training took over 3 weeks – **parallelizing
training yielded somewhat worse results,** though it
increased the speed to convergence.""
For my applications, I find tower loss is ok when you do anything without finetune image mode, even 
if you use image model(inception resnet nasnet etc.) is fine.
But if you do finetune, either for image caption or image classification, the performance will hurt 
a lot(using mulitple gpu wether increase total batch size or keep total batch size the same as single gpu), might not convergent.  Is it a known bug, can we avoid this ?
"
14484,My trained checkpoint doesn't work.,"    $ python3 tests/test_snapshot.py lsp out/lsp_alexnet_imagenet_small/checkpoint-370000.data-00000-of-00001

But it shows this error

Data loss: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator? Traceback (most recent call last):

DataLossError (see above for traceback): Unable to open table file out/lsp_alexnet_imagenet_small/checkpoint-370000.data-00000-of-00001: Data loss: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?


"
14482,[Fetaure Request] Bicubic interpolation using map coordinates,"I would like to train a two CNN in single graph. The architecture of model is 
![capture](https://user-images.githubusercontent.com/18436807/32688705-3ea9e54c-c6d6-11e7-84ba-fb01a3be2755.PNG)

This one is not like end to end training. In the warping of images(refer attachment), I use scipy for mapping coordinates from the disparity map to an input image and I am unable to build a model(graph) in tensorflow using scipy. Tensorflow supports only resize of images using bicubic/bilinear interpolation. [https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.ndimage.interpolation.map_coordinates.html](url)

For reference, original paper is implemented using matconvnet in [matlab.](http://cseweb.ucsd.edu/~viscomp/projects/LF/papers/SIGASIA16/) 


"
14481,Tensorflow stops training on random epoch,"When I run the following code on GPU, it trains well for some epoches and then just hangs.
While hanged processes are still alive but the GPU usages become 0%.
In the below code I am using Dataset API from tf.contrib.data.Dataset. But I also tried using placeholder and feed dictionary approach which hangs as well on random epoch during training. 
I am struggling with the problem for last 2-3 weeks and cannot find a way out.
I am running the code on a remote GPU cluster. Here are some information about cluster node,
Using tensorflow gpu version 1.4
```
   NodeName=node050 Arch=x86_64 CoresPerSocket=1
   CPUAlloc=0 CPUErr=0 CPUTot=24 CPULoad=12.03 Features=Proc24,GPU4
   Gres=gpu:4
   NodeAddr=node050 NodeHostName=node050 Version=15.08
   OS=Linux RealMemory=129088 AllocMem=0 FreeMem=125664 Sockets=24 Boards=1
   State=IDLE ThreadsPerCore=1 TmpDisk=0 Weight=1 Owner=N/A
   BootTime=2017-11-07T08:20:00 SlurmdStartTime=2017-11-07T08:24:06
   CapWatts=n/a
   CurrentWatts=0 LowestJoules=0 ConsumedJoules=0
   ExtSensorsJoules=n/s ExtSensorsWatts=0 ExtSensorsTemp=n/s
```
CODE

```
dat_split = np.load('data/dat_split2.npy')
X_train = dat_split[0].astype(np.float32)
X_test = dat_split[1].astype(np.float32)
y_train = dat_split[2].astype(np.int32)
y_test = dat_split[3].astype(np.int32)

num_epochs = 100


train_data_len = X_train.shape[0]
test_data_len = X_test.shape[0]
num_joints = len(considered_joints)
num_classes = len(classes)


############ taking batch_size even data##########
even_train_len = (train_data_len//batch_size)*batch_size
even_test_len = (test_data_len//batch_size)*batch_size

X_train = X_train[:even_train_len]
X_test = X_test[:even_test_len]
y_train = y_train[:even_train_len]
y_test = y_test[:even_test_len]


train_dat = Dataset.from_tensor_slices((X_train, y_train))
train_dat = train_dat.batch(batch_size)

test_dat  = Dataset.from_tensor_slices((X_test, y_test))
test_dat = test_dat.batch(batch_size)
    
iterator = Iterator.from_structure(train_dat.output_types, train_dat.output_shapes)

trainig_iterator_init = iterator.make_initializer(train_dat)
test_iterator_init = iterator.make_initializer(test_dat)
   
if __name__ == '__main__':
   
    global_cell = GlobalLSTM(num_units=num_units_each_cell, num_joints=num_joints)   #GlobalLSTM is a subtype of RNNCell
    next_element = iterator.get_next()
    X_loaded2, Y_loaded = next_element
    X_loaded = tf.where(tf.is_nan(X_loaded2), tf.zeros_like(X_loaded2), X_loaded2)
    
    init_state = global_cell.zero_state((batch_size), tf.float32)
    rnn_ops, rnn_state = tf.nn.dynamic_rnn(global_cell, X_loaded, dtype=tf.float32)
    
    with tf.variable_scope('softmax__'):
        W = tf.get_variable('W', [(num_joints)*num_units_each_cell, num_classes], initializer=tf.truncated_normal_initializer(0.0, 1.0))
        b = tf.get_variable('b', [num_classes], initializer=tf.truncated_normal_initializer(0.0, 1.0))

  
      
    final_logits = tf.matmul(rnn_state[1], W) + b       # taking h state of rnn 
    with tf.name_scope(""loss_comp""):
        total_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=final_logits, labels=tf.one_hot(Y_loaded, num_classes)))
    with tf.name_scope(""train_step""):
        train_step = tf.train.AdamOptimizer(learning_rate).minimize(total_loss)

    with tf.name_scope(""pred_accu""):
        predictions = tf.nn.softmax(final_logits)
        pred2 = tf.reshape(tf.argmax(predictions, 1), [-1, 1])
        correct_pred = tf.equal(pred2, tf.cast(Y_loaded, tf.int64))
        accuracy_ = tf.reduce_mean(tf.cast(correct_pred, tf.float32))

    
    
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
  
        tic = time.clock()    
        for step in range(num_epochs):
            sess.run(trainig_iterator_init)
            batch_cnt = train_data_len//batch_size
            epch_loss = 0.0
            epch_acc = 0.0
            for bt in range(batch_cnt):
                _, loss_, acc = sess.run([train_step, total_loss, accuracy_])
                epch_loss += loss_
                epch_acc += acc
            print ('loss after epoch, ', step,': ', epch_loss/batch_cnt, ' ## accuracy : ', epch_acc/batch_cnt)
            
        print (""optimization finished, time required: "", time.clock()-tic)
		
		
		#############test accuracy##############
        batch_cnt = test_data_len//batch_size
        sess.run(test_iterator_init)
        print ('testing accuracy on test data : batch number', batch_cnt)
        epch_acc = 0.0
        for bt in range(batch_cnt):
            acc = sess.run(accuracy_)
            epch_acc += acc
        print ('testing accuracy : ', epch_acc/batch_cnt)  
```
Here are some screen shot of different hangs,
**Hanged on an epoch**
![hanged_epc](https://user-images.githubusercontent.com/15855504/32688711-1be4b622-c6a4-11e7-93eb-92f29ad8ee37.JPG)
**GPU usage that time**
![hanged](https://user-images.githubusercontent.com/15855504/32688718-3763037c-c6a4-11e7-9ed0-d89efd1663c6.JPG)
**GPU usage while running (not hanged)**
![running_gpuusage](https://user-images.githubusercontent.com/15855504/32688721-4b8d42cc-c6a4-11e7-9ebe-61d48ed2bcac.JPG)
**Hanged on another eopch**
![hanged2](https://user-images.githubusercontent.com/15855504/32688742-b35474de-c6a4-11e7-8492-493d9ce128cb.JPG)


This type of random hanging behavior keeps repeating on each run. 
Each time it hangs on a random epoch. That's why I cannot figure out what is going wrong.
By looking at code or other set up can anybody please give me any idea about what is going wrong or how can I debug this out? Thanks 



"
14480,Dataset API batching is slow for numpy arrays,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: 
Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
source
- **TensorFlow version (use command below)**:
1.4rc1
- **Python version**:
3.5.2
- **Bazel version (if compiling from source)**:
Not sure, think 0.7?
- **GCC/Compiler version (if compiling from source)**:
5.4
- **CUDA/cuDNN version**:
8/6
- **GPU model and memory**:
gtx980
- **Exact command to reproduce**:
see attached

### Describe the problem
The ```tf.data.Dataset.batch()``` functions seems to be slow when concatenating numpy arrays into batches.

The attached code basically pushes dummy data ([0, 1, 2, ... , NUM_ITEMS] resembling the output of ```range()```) through tensorflow by different approaches.

There are basically two ways to go about this:
1. Use the ```tf.data.Dataset.range()```
2. Use custom generators and ```tf.data.Dataset.from_generator()```

Also the data can be batched to increase throughput as it is usually done in deep learning. This can be done either in the generator itself or via ```tf.data.Dataset.batch()```. The latter appears to be ~30x slower for numpy arrays. Somehow this is not the case for 'native' tensorflow generation.

I attached a benchmark to reproduce this. Please note that the behavior for larger amounts of data e.g. images is similar, resulting in only tens of images per second instead of hundreds.

### Comments to the source code:
```gen()``` is a python generator resembling ```range()```.
```gen_batch()``` is also a python generator, but yields batches of 100 numbers instead of single numbers.

These two generators are benchmarked first, yielding millions of elements per second. They should not be a bottleneck.

Then we define a few ```tf.data.Dataset```:
```ds_range_single``` is similar to ```gen()```, using ```tf.data.Dataset.range()```
```ds_range_batch``` is similar to ```gen_batch()```, using ```tf.data.Dataset.range().batch()```

```ds_npy_single``` uses ```gen()``` with ```tf.data.Dataset.from_generator()```
```ds_npy_batch``` uses ```gen()``` with ```tf.data.Dataset.from_generator().batch()```
```ds_npy_single_batch``` uses uses ```gen_batch()``` and will perform much better than ```ds_npy_batch```. In fact it will be close to the 'native' ```ds_range_batch```.

### Source code / logs
```python
from time import time
import numpy as np
import tensorflow as tf

NUM_ITEMS = 100000
BATCH_SIZE = 100


def gen():
    for x in np.arange(0, NUM_ITEMS, 1, dtype=np.int64):
        yield x


def gen_batch():
    for x in np.arange(0, NUM_ITEMS, 1, dtype=np.int64).reshape(NUM_ITEMS//BATCH_SIZE, BATCH_SIZE):
        yield x

start = time()
for _ in gen():
    pass
py_single_generator_time = time() - start

start = time()
for _ in gen_batch():
    pass
py_batch_generator_time = time() - start

ds_range_single = tf.data.Dataset.range(NUM_ITEMS)\
    .make_one_shot_iterator().get_next()

ds_range_batch = tf.data.Dataset.range(NUM_ITEMS)\
    .batch(BATCH_SIZE).make_one_shot_iterator().get_next()

ds_npy_single = tf.data.Dataset.from_generator(
    gen, output_types=tf.int64, output_shapes=tf.TensorShape([]))\
    .make_one_shot_iterator().get_next()

ds_npy_batch = tf.data.Dataset.from_generator(
    gen, output_types=tf.int64, output_shapes=tf.TensorShape([]))\
    .batch(BATCH_SIZE).make_one_shot_iterator().get_next()

ds_npy_single_batch = tf.data.Dataset.from_generator(
    gen_batch, output_types=tf.int64, output_shapes=tf.TensorShape([BATCH_SIZE]))\
    .make_one_shot_iterator().get_next()

with tf.Session() as sess:
    start = time()
    for _ in range(NUM_ITEMS):
        sess.run(ds_npy_single)
    npy_single_time = time() - start

    start = time()
    for _ in range(NUM_ITEMS // BATCH_SIZE):
        sess.run(ds_npy_batch)
    npy_batch_time = time() - start

    start = time()
    for _ in range(NUM_ITEMS // BATCH_SIZE):
        sess.run(ds_npy_single_batch)
    npy_single_batch_time = time() - start

    start = time()
    for _ in range(NUM_ITEMS):
        sess.run(ds_range_single)
    range_single_time = time() - start

    start = time()
    for _ in range(NUM_ITEMS // BATCH_SIZE):
        sess.run(ds_range_batch)
    range_batch_time = time() - start


print('Python single generator examples/s :', NUM_ITEMS/py_single_generator_time)
print('Python batch generator examples/s :', NUM_ITEMS/py_batch_generator_time)
print('tf npy single examples/s :', NUM_ITEMS/npy_single_time)
print('tf npy batch examples/s :', NUM_ITEMS/npy_batch_time)
print('tf npy single batch examples/s', NUM_ITEMS/npy_single_batch_time)
print('tf range single examples/s :', NUM_ITEMS/range_single_time)
print('tf range batch examples/s :', NUM_ITEMS/range_batch_time)
```
### Prints the following on my machine:
Python single generator examples/s : 3779128.899140432
Python batch generator examples/s : 137113566.52500817
tf npy single examples/s : 2623.528591111384
tf npy batch examples/s : 10184.987886595052
tf npy single batch examples/s 308841.62594729604
tf range single examples/s : 4673.512357184766
tf range batch examples/s : 352137.31184393575"
14479,Wrong link in tensorflow-for-poets codelab,"https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#3

There's a link for `Inception V3 model` pointing to https://github.com/tensorflow/models/tree/master/slim#pre-trained-models which 404's.

I assume it can point to https://arxiv.org/abs/1512.00567 instead.

<img width=""375"" alt=""screen shot 2017-11-11 at 06 37 47"" src=""https://user-images.githubusercontent.com/287584/32687045-e22af624-c6aa-11e7-9773-a189f761a5ba.png"">

I would've sent a PR fixing the link, but the codelab text doesn't seem to be available on anywhere Github. 😞 "
14477,error message show while compiling tensorflow from source,"bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDgemm_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCtrsv_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasIdamin_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasChpr2_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSscal_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSgemmBatched'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSsyr2_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDznrm2_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDtpmv_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCsymm_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSspmv_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZtbmv_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnBatchNormalizationForwardTraining'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCsyrk_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSger_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCgbmv_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasIdamax_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftSetStream'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSasum_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuDevicePrimaryCtxSetFlags'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftExecZ2D'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSgbmv_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZtrmm_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCtpmv_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCreate_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZhpr_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftMakePlanMany'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCher_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDtrsv_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZdotu_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasScasum_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCscal_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasChemm_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `curandGenerateNormal'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasIcamax_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetConvolutionBackwardDataAlgorithm'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDtrmm_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCtrmv_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCgeru_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZdrot_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftMakePlan3d'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDsyr2_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZtpsv_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreate'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSspr_v2'
"
14476,IOS camera example load map_data  from in_pix is incorrect!,"    
//    for (int y = 0; y < wanted_input_height; ++y) {
//        float *out_row = out + (y * wanted_input_width * wanted_input_channels); //0+height
//        for (int x = 0; x < wanted_input_width; ++x) {
//            const int in_x = (y * image_width) / wanted_input_width;
//            const int in_y = (x * image_height) / wanted_input_height;
//            tensorflow::uint8 *in_pixel =
//            in + (in_y * image_width * image_channels) + (in_x * image_channels);
//            float *out_pixel = out_row + (x * wanted_input_channels);
//            for (int c = 0; c < wanted_input_channels; ++c) {
//                out_pixel[c] = (in_pixel[c] - input_mean) / input_std;
//            }
//        }
//    }

fixed code ：rotoate 90 and resized

   for (int y = 0; y < wanted_input_width; ++y) {
        float *out_row = out + (y * wanted_input_width * wanted_input_channels); 
        for (int x = 0; x < wanted_input_height; ++x) {
            const int in_x = (y * image_width) / wanted_input_width;
            const int in_y =image_height - (x * image_height) / wanted_input_height;
            tensorflow::uint8 *in_pixel =
            in + (in_y * image_width * image_channels) + (in_x * image_channels);
            float *out_pixel = out_row + (x * wanted_input_channels);
            for (int c = 0; c < wanted_input_channels; ++c) {
                out_pixel[c] = (in_pixel[c] - input_mean) / input_std;
            }
        }
    }"
14475,Internal: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain,"### SYSTEM Infomation
ubuntu16.04
cuda7.5
cudnn5
gtx1060
tensorflow1.0.1
python3.5
memory 15.6G ,used 5.3GB

$ nvidia-smi
```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 384.90                 Driver Version: 384.90                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 106...  Off  | 00000000:01:00.0  On |                  N/A |
| 33%   38C    P2    27W / 120W |   6012MiB /  6071MiB |      3%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0      1536      G   /usr/lib/xorg/Xorg                           273MiB |
|    0      3210      G   compiz                                       115MiB |
|    0      3811      G   ...-token=C6D7A354DD6B35830E1B2860115A47BF    82MiB |
+-----------------------------------------------------------------------------+
```
### run train script get this error:

```
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
Called with args:
Namespace(cfg_file='./lstm/lstm.yml', gpu_id=0, max_iters=700000, network_name='LSTM_train', pre_train=None, randomize=False, restore=0, set_cfgs=None)
Using config:
{'CHARSET': '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ',
 'EXP_DIR': 'lstm_ctc',
 'FONT': 'fonts/Ubuntu-M.ttf',
 'GPU_ID': 0,
 'IMG_SHAPE': [180, 60],
 'LOG_DIR': 'lstm_ctc',
 'MAX_CHAR_LEN': 6,
 'MAX_LEN': 6,
 'MIN_LEN': 4,
 'NCHANNELS': 1,
 'NCLASSES': 64,
 'NET_NAME': 'LSTM',
 'NUM_FEATURES': 60,
 'POOL_SCALE': 2,
 'RNG_SEED': 3,
 'ROOT_DIR': '/srv/python/lstm_ctc_ocr_with_tf_1.0.1',
 'SPACE_INDEX': 0,
 'SPACE_TOKEN': '',
 'TEST': {},
 'TIME_STEP': 90,
 'TRAIN': {'BATCH_SIZE': 32,
           'DISPLAY': 100,
           'GAMMA': 1.0,
           'LEARNING_RATE': 0.001,
           'LOG_IMAGE_ITERS': 100,
           'MOMENTUM': 0.9,
           'NUM_EPOCHS': 2000,
           'NUM_HID': 128,
           'NUM_LAYERS': 2,
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 2000,
           'SNAPSHOT_PREFIX': 'lstm',
           'SOLVER': 'RMS',
           'STEPSIZE': 2000,
           'WEIGHT_DECAY': 1e-05},
 'VAL': {'BATCH_SIZE': 128,
         'NUM_EPOCHS': 1000,
         'PRINT_NUM': 5,
         'VAL_STEP': 500}}
Output will be saved to `/srv/python/lstm_ctc_ocr_with_tf_1.0.1/output/lstm_ctc`
Logs will be saved to `/srv/python/lstm_ctc_ocr_with_tf_1.0.1/logs/lstm_ctc/lstm_train/2017-11-11-11-13-49`
/gpu:0
Tensor(""data:0"", shape=(?, ?, 60), dtype=float32)
Tensor(""conv4/BiasAdd:0"", shape=(?, ?, 30, 1), dtype=float32)
Tensor(""time_step_len:0"", shape=(?,), dtype=int32)
Use network `LSTM_train` in training
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
E tensorflow/core/common_runtime/direct_session.cc:137] 
Internal: failed initializing StreamExecutor 
for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: 
CUDA_ERROR_OUT_OF_MEMORY; total memory reported: 18446744073709551615
Traceback (most recent call last):
  File ""./lstm/train_net.py"", line 89, in <module>
    restore=bool(int(args.restore)))
  File ""./lstm/../lib/lstm/train.py"", line 187, in train_net
    with tf.Session(config=config) as sess:
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 1176, in __init__
    super(Session, self).__init__(target, graph, config=config)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 552, in __init__
    self._session = tf_session.TF_NewDeprecatedSession(opts, status)
  File ""/usr/lib/python3.5/contextlib.py"", line 66, in __exit__
    next(self.gen)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py"", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InternalError: Failed to create session.

```

I will be grateful to anyone for helping me
Thanks everyone

"
14462,OpKernel errors after building tensorflow from sources,"Instead of using pip to install pre-built tensorflow library, I downloaded the sources and manually built the library to support using my machine's CPU SIMD instructions (SSE4.1, SSE4.2, AVX, AVX2, FMA).

I've installed tensorflow from sources using the official documentation (https://www.tensorflow.org/install/install_sources#PrepareMac)

But now I'm facing an array of OpKernel errors when I use tensorflow, here is a screenshot of my terminal...

<img width=""1264"" alt=""screen shot 2017-11-10 at 9 39 24 pm"" src=""https://user-images.githubusercontent.com/11311073/32675491-bd1047cc-c65f-11e7-97a9-6f936f2cc7da.png"">

Although I ran the following commands, 
`pip3 install --upgrade '/tmp/tensorflow_pkg/tensorflow-1.4.0-cp35-cp35m-macosx_10_6_intel.whl'`

`pip3 install --upgrade 'https://storage.googleapis.com/tensorflow/mac/cpu/protobuf-3.1.0-cp35m-none-macosx_10_11_x86_64.whl'`

tensorflow still raises the same errors when being imported in a session. Any help?

**Operating System:** OS X El Captain 10.+

**Versions of installed libraries**
nltk (3.2.1)
numpy (1.13.3)
olefile (0.44)
pandas (0.20.0)
pigar (0.7.1)
Pillow (4.0.0)
pip (9.0.1)
pipreqs (0.4.9)
protobuf (3.4.0)
pyparsing (2.1.10)
python-dateutil (2.6.0)
python-xlib (0.18)
pytz (2016.10)
PyYAML (3.12)
requests (2.18.4)
scikit-learn (0.18.1)
scipy (0.18.1)
setuptools (36.7.0)
six (1.11.0)
sklearn (0.0)
tensorboard (1.0.0a5)
tensorflow (1.4.0)
tensorflow-tensorboard (0.4.0rc2)
Theano (0.8.2)
urllib3 (1.22)
Werkzeug (0.12.2)
wheel (0.30.0)
yarg (0.1.9)
"
14460,Apparent incorrect behavior from resize_to_range() in models/preprocessor.py,"From the comments for resize_to_range():

  The output size can be described by two cases:
  1. If the image can be rescaled so its minimum dimension is equal to the
     provided value without the other dimension exceeding max_dimension,
     then do so.
  2. Otherwise, resize so the largest dimension is equal to max_dimension.

This logic would yield the wrong behavior for images with an aspect ratio near 1.  For instance, if we had a 1200x1200 image, and we had settings min_dimension = 600 and max_dimension = 1024, it seems that the desired behavior would be to rescale the image to 1024x1024.  Instead, following the logic above, the image would be rescaled to 600x600.

Am I missing something?"
14456,Windows native library (tensorflow_jni.dll) is dynamically linked to msvcp140.dll,"### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 7 SP1 x64
- **TensorFlow installed from (source or binary)**: Downloaded from Maven repository
- **TensorFlow version (use command below)**: 1.4.0

### Describe the problem
I need to run TensorFlow on a Windows PC where I don't have admin rights. So I cannot install MS Visual C++ 2015 Redistributable package. And TensorFlow Windows native library (tensorflow_jni.dll) is dynamically linked to msvcp140.dll from that package.

Thus the only option to run TensorFlow for me is to download the DLL from some untrusted ""get any DLL"" site and put it somewhere in PATH.

I believe it should not be the case. Please consider dropping dependency on MS Visual C++ 2015 Redistributable package.
Or at least mention this dependency clearly in the ""Using TensorFlow with a Maven project"" section as well as ""Install on Windows"" here https://www.tensorflow.org/install/install_java

### Source code / logs
The problem manifests itself as
`Exception in thread ""main"" java.lang.UnsatisfiedLinkError: C:\Users\...\AppData\Local\Temp\tensorflow_native_libraries-...-0\tensorflow_jni.dll: Can't find dependent libraries`"
14455,Tensorflow cannot be installed with default Windows Python 3.5 stack,"After installing Python 3.5.0 using the Windows 64 bit installer (which includes pip in the install):

pip3 install --upgrade tensorflow
Collecting tensorflow
  Could not find a version that satisfies the requirement tensorflow (from versions: )
No matching distribution found for tensorflow
You are using pip version 7.1.2, however version 9.0.1 is available.
You should consider upgrading via the 'python -m pip install --upgrade pip' command.

I tried on a different machine that worked, and found the only difference to be the pip version.  Updating to pip 9.0.1 solved the issue.

It's not explicitly stated anywhere that you need a newer version of pip.  When an old version of something is required to run something, people tend to ignore the messages indicating there is a newer version of it because that's exactly what they are expecting: ""yeah I know there's a newer version, I meant to do this"".

If this cannot be resolved for older version of pip (specifically, versions included with the required Python versions), could you please state this in the documentation."
14454,cuda_config.h is required to build non-CUDA release,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: NixOS 18.03.git.869485a (Impala)
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.4
- **Python version**: 3.5
- **Bazel version (if compiling from source)**: 0.7.0
- **GCC/Compiler version (if compiling from source)**: 6.4.0
- **CUDA/cuDNN version**: -
- **GPU model and memory**: -
- **Exact command to reproduce**: bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package

### Describe the problem
TensorFlow with CUDA support disabled doesn't build. CUDA support is disabled in `./configure`.

### Source code / logs
```
./tensorflow/stream_executor/dso_loader.h:32:30: fatal error: cuda/cuda_config.h: No such file or directory
 #include ""cuda/cuda_config.h""
```"
14452,Bug - freeze_graph producing invalid graph_def in tensorflow 1.4,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: release 1.4
- **Python version**: 3.5
- **Bazel version (if compiling from source)**: -
- **GCC/Compiler version (if compiling from source)**: -
- **CUDA/cuDNN version**: 8/6
- **GPU model and memory**: GTX 970, 4GB
- **Exact command to reproduce**: 

1. Download [dbg.zip](https://github.com/tensorflow/tensorflow/files/1461735/dbg.zip) (contains `graph.pbtxt`, checkpoint and the resulting `frozen_model.pb` generated on my machine .)
2. Unzip and open terminal in the unzipped folder
3. Run <tensorflow_root>/python/tools/freeze_graph.py --input_graph=graph.pbtxt --input_binary=False --input_checkpoint=model.ckpt-1 --output_node_names=softmax_tensor --output_graph=frozen_model_test.pb --clear_devices=True
4. Start python, attempt to import the frozen graph:
```
import tensorflow as tf
from tensorflow.python.platform import gfile
with gfile.FastGFile('frozen_model_test.pb','rb') as f:
    graph_def = tf.GraphDef()
    graph_def.ParseFromString(f.read())
    tf.import_graph_def(graph_def, name='')
```
### Describe the problem
Trying to import the graph, I get this error:
> ValueError: graph_def is invalid at node 'IsVariableInitialized': Input tensor 'global_step:0' Cannot convert a tensor of type int64 to an input of type int64_ref.

The error is raised in `tf.import_graph_def(graph_def, name='')`. The dump of `str(graph_def)` can be seen in this text file: [graph_def_dbg.txt](https://github.com/tensorflow/tensorflow/files/1461768/graph_def_dbg.txt)

The error happens sine the upgrade to TF 1.4, with TF 1.3 the graph freezing and importing works as expected.
"
14451,Oversampling functionality in dataset API,"Hello,
I would like to ask if current API of datasets allows for implementation of oversampling algorithm? I deal with highly imbalanced class problem. I was thinking that it would be nice to oversample specific classes during dataset parsing i.e. online generation. I've seen the implementation for `rejection_resample`  function, however this removes samples instead of duplicating them and its slows down batch generation (when target distribution is much different then initial one). The thing I would like to achieve is: to take an example, look at its class probability decide if duplicate it or not. Then call `dataset.shuffle(...)` `dataset.batch(...)` and get iterator. The best (in my opinion) approach would be to oversample low probable classes and subsample most probable ones. I would like to do it online since it's more flexible. Just wondering if this is possible with current API? "
14450,tf.nn.sparse_softmax_cross_entropy_with_logits documentation error,"It looks like there may be a documentation error in [tf.nn.sparse_softmax_cross_entropy_with_logits](https://www.tensorflow.org/api_docs/python/tf/nn/sparse_softmax_cross_entropy_with_logits). 

It mentions ""ValueError: If logits are scalars (need to have rank >= 1) or if the **rank of the labels is not equal to the rank of the labels minus one**."" 

Based on the argument requirements above, I believe this should read ""ValueError: If logits are scalars (need to have rank >= 1) or if the rank of the labels is not equal to the rank of the **logits** minus one."" "
14449,Is it a bug of tf.summary.image?,"Look at the code: 

```
tf.summary.image('xx', tf.constant(1.), collections='A')
print(len(tf.get_collection('A')))
```

It prints `1`.

```
tf.summary.image('xx', tf.constant(1.), collections='IMAGE_SUMMARY')
print(len(tf.get_collection('IMAGE_SUMMARY')))
```
But it prints `0`."
14448,[Feature request] Improve syntax for accessing Python objects in dataset pipelines,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary 
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 3.6
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**: 

### Describe the problem

Hey, I have a python database class
```python
class MyDatabase:
    def __len__(self): return ...
    def __getitem__(self, item): return ...  # slow code without gitlock, i.e. io and numpy
```
that supports indexing and returns a dict. The loading of the data is longer than a NN iteration, therefore it would be nice when tensorflow loads the data in parallel. When I use tf.data.Dataset.from_generator I have to convert my Database to a generator
```python
def generator():
    db = MyDatabase()
    yield from [db[i] for i in range(len(db))]
```
`from_generator` has no argument `num_parallel_calls`, therefore the loading is serial.
I am not sure how difficult it is to add such an argument. 
But in the case that `MyDatabase` has above structure it is possible to combine `tf.data.Dataset.range` with `tf.data.Dataset.map` and `tf.py_func` to get a parallel load. 
In my mind, it could be easier to implement a parallel load for an indexable object.

Further point the interface of `tf.py_func` has more constraints than `tf.data.Dataset.from_generator` (dict's are not allowed and it hat no output_shape argument).

Since I am new to tensorflow and have problems to understand the `tf.data.Dataset` code, here my feature request for a `num_parallel_calls` argument in `tf.data.Dataset.from_generator` or a new function `tf.data.Dataset.from_generator` with a `num_parallel_calls` argument.

### Source code / logs

Here a toy example, that demonstrate the non-parallel from_generator

```python
import time

start = time.perf_counter()
    
def body(i):
    global start
    if i == 0:
        start = time.perf_counter()
    time.sleep(0.2)
    return np.array([float(i), time.perf_counter() - start])

def gen():
    for i in range(5):
        yield body(i)
        
ds = tf.data.Dataset.from_generator(gen, tf.float64)
ds = ds.prefetch(5)
iterator = ds.make_one_shot_iterator()

entry = iterator.get_next()

with tf.Session() as sess:
    
    try:
        while True:
            print(sess.run(entry))
    except tf.errors.OutOfRangeError:
        pass
# Serial execution:  [index, time from start of first load to return of current load]
# [ 0.          0.20034038]
# [ 1.          0.40189139]
# [ 2.          0.60322792]
# [ 3.          0.80472201]
# [ 4.          1.00612245]
```
and here the parallel version (Less nice code and does not generalise so good as from_generator, e.g. no return dict support)
```python
ds = tf.data.Dataset.range(5)

def map_func(i):
    return tf.py_func(body, [i], tf.float64, stateful=False)

ds = ds.map(map_func, num_parallel_calls=4)
ds = ds.prefetch(1)
iterator = ds.make_one_shot_iterator()

entry = iterator.get_next()

with tf.Session() as sess:
    
    try:
        while True:
            print(sess.run(entry))
    except tf.errors.OutOfRangeError:
        pass

# Parallel execution:  [index, time from start of first load to return of current load]
# [ 0.          0.20026697]
# [ 1.          0.20084557]
# [ 2.          0.20095535]
# [ 3.          0.20048737]
# [ 4.          0.40154806]
```"
14446,[Mac] Changes in fast-math-flags LLVM API cause XLA enabled build to fail,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS 10.13 High Sierra
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: HEAD
- **Python version**: 3.6/2.7
- **Bazel version (if compiling from source)**: 0.7.0
- **GCC/Compiler version (if compiling from source)**: 9.0.0
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**:

Follow instructions in docs and build optimized for native architecture with XLA enabled (assumes fix in https://github.com/tensorflow/tensorflow/pull/14288).

### Describe the problem
LLVM latest release v5.0.0 does not include [recent fast-math-flags LLVM API changes](https://reviews.llvm.org/rL317488) already [updated](https://github.com/tensorflow/tensorflow/commit/4e69e02241067129379f73dd4fefe57f0a12bdc9#diff-866fd5845e79e513efd00ed931aa56f5L559) into TensorFlow codebase. 
Next LLVM release (v5.0.1) scheduled for the end of November, in the meanwhile besides building LLVM with CMake (?) there is no solution (?) but to wait.

Disclaimer: I'm new to LLVM and stuff so if I'm missing something I apologize and appreciate any insight.

```
tensorflow/compiler/xla/service/llvm_ir/llvm_util.cc:560:11: error: no member named 'setFast' in 'llvm::FastMathFlags'
    flags.setFast();
    ~~~~~ ^
```

"
14445,Target '@llvm//:support' is not visible from target '@org_tensorflow//tensorflow/compiler/xla/client:compile_only_client'.,"I was doing an XLA compilation that worked before TensorFlow 1.4 but now errors with

> ERROR: /home/travis/build/carl/project/cache/bazel/external/org_tensorflow/tensorflow/compiler/xla/client/BUILD:107:1: Target '@llvm//:support' is not visible from target '@org_tensorflow//tensorflow/compiler/xla/client:compile_only_client'.

This is how I get tfcompile:
```sh
git clone https://github.com/tensorflow/tensorflow
cd tensorflow
git checkout v1.4.0 # Note: master also fails
PYTHON_BIN_PATH=$(which python) USE_DEFAULT_PYTHON_LIB_PATH=1 CC_OPT_FLAGS='-march=native'
  TF_ENABLE_XLA=0 TF_NEED_MPI=0 TF_NEED_JEMALLOC=1 TF_NEED_GCP=0 TF_NEED_HDFS=0
  TF_NEED_VERBS=0 TF_NEED_OPENCL=0 TF_NEED_CUDA=0 TF_NEED_GDR=0 TF_NEED_S3=0 TF_NEED_OPENCL_SYCL=0 ./configure
```"
14444,Can not import graph after transform_graph with quantize_nodes,"### System information
- **What is the top-level directory of the model you are using**: models/object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.4.0-rc0
- **Bazel version (if compiling from source)**: 0.7.0
- **CUDA/cuDNN version**: 375.82
- **GPU model and memory**: GeForce GTX 770 4GB
- **Exact command to reproduce**:

```
bazel-bin/tensorflow/tools/graph_transforms/transform_graph \
  --in_graph=""/home/.../mobilenet_v2.pb"" \
  --out_graph=""/home/.../mobilenet_v2_clean.pb"" \
  --inputs=image_tensor\
  --outputs=""detection_boxes,detection_scores,detection_classes,num_detections""\
  --transforms='add_default_attributes
  strip_unused_nodes
  remove_nodes(op=Identity, op=CheckNumerics)
  fold_constants(ignore_errors=true)
  fold_batch_norms
  fold_old_batch_norms
  quantize_weights
  quantize_nodes
  sort_by_execution_order'
```

### Problem
I'm trying to quantize default SSD Mobilenet from models rep.
After execution transformation as above, I can not import graph:
```
detection_graph = tf.Graph()
with detection_graph.as_default():
  od_graph_def = tf.GraphDef()
  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:
    serialized_graph = fid.read()
    od_graph_def.ParseFromString(serialized_graph)
    tf.import_graph_def(od_graph_def, name='')

---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-5-0d8b8f2357e8> in <module>()
      5     serialized_graph = fid.read()
      6     od_graph_def.ParseFromString(serialized_graph)
----> 7     tf.import_graph_def(od_graph_def, name='')

/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)
    314                 'in a future version' if date is None else ('after %s' % date),
    315                 instructions)
--> 316       return func(*args, **kwargs)
    317     return tf_decorator.make_decorator(func, new_func, 'deprecated',
    318                                        _add_deprecated_arg_notice_to_docstring(

/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/importer.py in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list)
    337                 raise ValueError('Specified colocation to an op that '
    338                                  'does not exist during import: %s in %s' % (
--> 339                                      op_to_bind_to, node.name))
    340               original_op = name_to_op[op_to_bind_to]
    341               new_class_values.append(compat.as_bytes(

ValueError: Specified colocation to an op that does not exist during import: Postprocessor/BatchMultiClassNonMaxSuppression/map/while/strided_slice in Postprocessor/BatchMultiClassNonMaxSuppression/map/while/TensorArrayWrite_4/TensorArrayWriteV3/Enter
```"
14442,Session.run() hangs in child thread if something was executed in main thread first,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Confirmed on Mac OS X (10.12.6) + Ubuntu 16.04 on GCP
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**: Anaconda Python 3.6.1 
- **GPU model and memory**: no gpu

### Describe the problem
`Session.run()` hangs in thread if it has executed something in the main thread. If we don't execute the first `calculate_something()` in the main thread- or execute it after we submitted to the pool, everything works. Only when first calculating something in the main thread, and then in the child thread does tensorflow hang. 

### Reproducing example
```python
from concurrent.futures import ProcessPoolExecutor as ProcessPool


def calculate_something():
    import tensorflow as tf

    with tf.Session() as sess:
        a = tf.constant(2)
        b = tf.constant(3)

        print(""a=2, b=3"")
        print(""Addition with constants: %i"" % sess.run(a+b))
        print(""Multiplication with constants: %i"" % sess.run(a*b))

calculate_something()

pool = ProcessPool(1)
pool.submit(calculate_something)
```
"
14441,GPU support for sparse_dense_binary_op_shared.cc,"Are you planning to add GPU support for the operations defined in 
tensorflow/tensorflow/core/kernels/sparse_dense_binary_op_shared.cc

I see that there is a GPU version for the sparse to dense Matrix-Multiplication version 
tensorflow/tensorflow/core/kernels/sparse_tensor_dense_matmul_op.cc 

but being able to use the GPU for Component-Wise operations would be very helpful.

Thank you.

Regards,
Pierre"
14436,Setting up a Jenkins job for ppc64le for Tensorflow ,"We are interested in setting up a Jenkins job for ppc64le for Tensorflow  @ http://ci.tensorflow.org/. We can work on providing and configuring a ppc64le slave node that can be hooked in to the Jenkins master. Please let me know if that can be done and if yes, what would be the minimum configuration requirements for the slave node? Thanks."
14433,tensorflow.python.framework.errors_impl.InternalError: Failed to create session.,"**I am running some preparation code with tf, it seems it doesn't to much memory for it. But:**

(tensorflow) lab-huang.zhongyi@gpu-2:~/workspace/vae-npvc$ python build.py
452 files found
Processing Tensor(""ReaderReadV2:0"", shape=(), dtype=string)
2017-11-10 12:24:55.938368: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-11-10 12:24:55.938398: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-11-10 12:24:55.938408: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-11-10 12:24:55.938427: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-11-10 12:24:55.938435: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.

2017-11-10 12:24:57.272601: E tensorflow/core/common_runtime/direct_session.cc:138] Internal: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_OUT_OF_MEMORY; total memory reported: 8508145664
Traceback (most recent call last):
  File ""build.py"", line 100, in <module>
    main()
  File ""build.py"", line 24, in main
    with sv.managed_session() as sess:
  File ""/home/lab-huang.zhongyi/anaconda3/envs/tensorflow/lib/python3.5/contextlib.py"", line 59, in __enter__
    return next(self.gen)
  File ""/home/lab-huang.zhongyi/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/supervisor.py"", line 964, in managed_session
    self.stop(close_summary_writer=close_summary_writer)
  File ""/home/lab-huang.zhongyi/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/supervisor.py"", line 792, in stop
    stop_grace_period_secs=self._stop_grace_secs)
  File ""/home/lab-huang.zhongyi/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/coordinator.py"", line 389, in join
    six.reraise(*self._exc_info_to_raise)
  File ""/home/lab-huang.zhongyi/.local/lib/python3.5/site-packages/six.py"", line 693, in reraise
    raise value
  File ""/home/lab-huang.zhongyi/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/supervisor.py"", line 953, in managed_session
    start_standard_services=start_standard_services)
  File ""/home/lab-huang.zhongyi/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/supervisor.py"", line 708, in prepare_or_wait_for_session
    init_feed_dict=self._init_feed_dict, init_fn=self._init_fn)
  File ""/home/lab-huang.zhongyi/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/session_manager.py"", line 273, in prepare_session
    config=config)
  File ""/home/lab-huang.zhongyi/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/session_manager.py"", line 178, in _restore_checkpoint
    sess = session.Session(self._target, graph=self._graph, config=config)
  File ""/home/lab-huang.zhongyi/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1292, in __init__
    super(Session, self).__init__(target, graph, config=config)
  File ""/home/lab-huang.zhongyi/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 562, in __init__
    self._session = tf_session.TF_NewDeprecatedSession(opts, status)
  File ""/home/lab-huang.zhongyi/anaconda3/envs/tensorflow/lib/python3.5/contextlib.py"", line 66, in __exit__
    next(self.gen)
  File ""/home/lab-huang.zhongyi/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py"", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InternalError: Failed to create session.

**and when I checkout ""nvidia-smi"", some GPUs still have many memory:**

+-----------------------------------------------------------------------------+
| NVIDIA-SMI 375.66                 Driver Version: 375.66                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 1080    On   | 0000:04:00.0     Off |                  N/A |
| 49%   69C    P2    57W / 180W |   8046MiB /  8114MiB |     45%      Default |
+-------------------------------+----------------------+----------------------+
|   1  GeForce GTX 1080    On   | 0000:05:00.0     Off |                  N/A |
| 48%   69C    P2    53W / 180W |   7393MiB /  8114MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  GeForce GTX 1080    On   | 0000:08:00.0     Off |                  N/A |
| 53%   72C    P2    54W / 180W |   7917MiB /  8114MiB |     19%      Default |
+-------------------------------+----------------------+----------------------+
|   3  GeForce GTX 1080    On   | 0000:09:00.0     Off |                  N/A |
| 60%   76C    P2    54W / 180W |   7413MiB /  8114MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   4  GeForce GTX 1080    On   | 0000:84:00.0     Off |                  N/A |
| 24%   41C    P8    12W / 180W |   2684MiB /  8114MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   5  GeForce GTX 1080    On   | 0000:85:00.0     Off |                  N/A |
| 24%   35C    P8    12W / 180W |   1895MiB /  8114MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   6  GeForce GTX 1080    On   | 0000:88:00.0     Off |                  N/A |
| 67%   82C    P2   163W / 180W |   6105MiB /  8114MiB |     88%      Default |
+-------------------------------+----------------------+----------------------+
|   7  GeForce GTX 1080    On   | 0000:89:00.0     Off |                  N/A |
| 67%   82C    P2   144W / 180W |   6097MiB /  8114MiB |     89%      Default |
+-------------------------------+----------------------+----------------------+


**and here is the code:**
 https://github.com/JeremyCCHsu/vae-npvc/blob/master/build.py

**Thank you all so much, I am really just a beginner.**"
14432,Errors and warnings through op_kernel.cc and core/grappler/utils.cc,"### Description of the problem

I installed tensorflow from sources.
There was no errors during configure as well as build. 

But I get the several errors [E] and warnings [W]. 

But if I run neural network example from the repository [here](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/neural_network.py), I get several warnings, but the code runs, gives output as expected.

In the logs below, I show the two examples. 

First one on the command line, trying to run ""Hello, World!"". I get the few errors of the form (op: ""some_operation"", device_type: ""CPU"") for unknown op: some_operation. Exact op's are in the log below. 

Second one, example from the repository: [here](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/neural_network.py). I get warnings [W] saying that ""MatMul_1_fused is not in the graph"".

Files involved are 

1. tensorflow/core/framework/op_kernel.cc:1142
2. tensorflow/core/grappler/utils.cc:48

```
### Source code / logs
********************************** log for validation script ***************************************************
Python 3.6.1 |Anaconda custom (64-bit)| (default, May 11 2017, 13:09:58) 
[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
>>> hello = tf.constant('Hello, Tensorflow!')
>>> sess = tf.Session()
>>> print(sess.run(hello))
2017-11-09 21:54:07.579195: E tensorflow/core/framework/op_kernel.cc:1142] OpKernel ('op: ""DenseToSparseBatchDataset"" device_type: ""CPU""') for unknown op: DenseToSparseBatchDataset
2017-11-09 21:54:07.579255: E tensorflow/core/framework/op_kernel.cc:1142] OpKernel ('op: ""GroupByWindowDataset"" device_type: ""CPU""') for unknown op: GroupByWindowDataset
2017-11-09 21:54:07.579261: E tensorflow/core/framework/op_kernel.cc:1142] OpKernel ('op: ""IgnoreErrorsDataset"" device_type: ""CPU""') for unknown op: IgnoreErrorsDataset
2017-11-09 21:54:07.579286: E tensorflow/core/framework/op_kernel.cc:1142] OpKernel ('op: ""DatasetToSingleElement"" device_type: ""CPU""') for unknown op: DatasetToSingleElement
2017-11-09 21:54:07.579301: E tensorflow/core/framework/op_kernel.cc:1142] OpKernel ('op: ""DeserializeIterator"" device_type: ""CPU""') for unknown op: DeserializeIterator
2017-11-09 21:54:07.579307: E tensorflow/core/framework/op_kernel.cc:1142] OpKernel ('op: ""MapAndBatchDataset"" device_type: ""CPU""') for unknown op: MapAndBatchDataset
2017-11-09 21:54:07.579324: E tensorflow/core/framework/op_kernel.cc:1142] OpKernel ('op: ""ParallelInterleaveDataset"" device_type: ""CPU""') for unknown op: ParallelInterleaveDataset
2017-11-09 21:54:07.579336: E tensorflow/core/framework/op_kernel.cc:1142] OpKernel ('op: ""ScanDataset"" device_type: ""CPU""') for unknown op: ScanDataset
2017-11-09 21:54:07.579345: E tensorflow/core/framework/op_kernel.cc:1142] OpKernel ('op: ""SqlDataset"" device_type: ""CPU""') for unknown op: SqlDataset
2017-11-09 21:54:07.579410: E tensorflow/core/framework/op_kernel.cc:1142] OpKernel ('op: ""SerializeIterator"" device_type: ""CPU""') for unknown op: SerializeIterator
b'Hello, Tensorflow!'
```
```
****************************************************************************************************************

********************************** log for neural network code from examples *****************************
Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.
Extracting /tmp/data/train-images-idx3-ubyte.gz
Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.
Extracting /tmp/data/train-labels-idx1-ubyte.gz
Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.
Extracting /tmp/data/t10k-images-idx3-ubyte.gz
Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.
Extracting /tmp/data/t10k-labels-idx1-ubyte.gz
WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpvak_s5_3
2017-11-09 22:31:36.069140: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:900] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-11-09 22:31:36.069505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1061] Found device 0 with properties: 
name: GeForce GTX 1050 major: 6 minor: 1 memoryClockRate(GHz): 1.493
pciBusID: 0000:01:00.0
totalMemory: 3.95GiB freeMemory: 3.50GiB
2017-11-09 22:31:36.069519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1151] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1)
2017-11-09 22:31:36.368840: W tensorflow/core/grappler/utils.cc:48] Node dense_3/MatMul_fused is not in the graph.
2017-11-09 22:31:36.368900: W tensorflow/core/grappler/utils.cc:48] Node dense_2/MatMul_fused is not in the graph.
2017-11-09 22:31:36.368918: W tensorflow/core/grappler/utils.cc:48] Node dense/MatMul_fused is not in the graph.
2017-11-09 22:31:36.368996: W tensorflow/core/grappler/utils.cc:48] Node gradients/dense_3/MatMul_grad/MatMul_1_fused is not in the graph.
2017-11-09 22:31:36.369024: W tensorflow/core/grappler/utils.cc:48] Node gradients/dense_3/MatMul_grad/MatMul_fused is not in the graph.
2017-11-09 22:31:36.369045: W tensorflow/core/grappler/utils.cc:48] Node gradients/dense_2/MatMul_grad/MatMul_1_fused is not in the graph.
2017-11-09 22:31:36.369074: W tensorflow/core/grappler/utils.cc:48] Node gradients/dense_2/MatMul_grad/MatMul_fused is not in the graph.
2017-11-09 22:31:36.369097: W tensorflow/core/grappler/utils.cc:48] Node gradients/dense/MatMul_grad/MatMul_1_fused is not in the graph.
2017-11-09 22:31:36.369122: W tensorflow/core/grappler/utils.cc:48] Node gradients/dense/MatMul_grad/MatMul_fused is not in the graph.
2017-11-09 22:31:36.526452: W tensorflow/core/grappler/utils.cc:48] Node dense_3/MatMul_fused is not in the graph.
2017-11-09 22:31:36.526488: W tensorflow/core/grappler/utils.cc:48] Node dense_2/MatMul_fused is not in the graph.
2017-11-09 22:31:36.526504: W tensorflow/core/grappler/utils.cc:48] Node dense/MatMul_fused is not in the graph.
2017-11-09 22:31:36.526534: W tensorflow/core/grappler/utils.cc:48] Node gradients/dense_3/MatMul_grad/MatMul_1_fused is not in the graph.
2017-11-09 22:31:36.526543: W tensorflow/core/grappler/utils.cc:48] Node gradients/dense_3/MatMul_grad/MatMul_fused is not in the graph.
2017-11-09 22:31:36.526562: W tensorflow/core/grappler/utils.cc:48] Node gradients/dense_2/MatMul_grad/MatMul_1_fused is not in the graph.
2017-11-09 22:31:36.526570: W tensorflow/core/grappler/utils.cc:48] Node gradients/dense_2/MatMul_grad/MatMul_fused is not in the graph.
2017-11-09 22:31:36.526589: W tensorflow/core/grappler/utils.cc:48] Node gradients/dense/MatMul_grad/MatMul_1_fused is not in the graph.
2017-11-09 22:31:36.526597: W tensorflow/core/grappler/utils.cc:48] Node gradients/dense/MatMul_grad/MatMul_fused is not in the graph.
2017-11-09 22:31:38.129805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1151] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1)
2017-11-09 22:31:38.168010: W tensorflow/core/grappler/utils.cc:48] Node dense_3/MatMul_fused is not in the graph.
2017-11-09 22:31:38.168065: W tensorflow/core/grappler/utils.cc:48] Node dense_2/MatMul_fused is not in the graph.
2017-11-09 22:31:38.168081: W tensorflow/core/grappler/utils.cc:48] Node dense/MatMul_fused is not in the graph.
Testing Accuracy: 0.9167

*****************************************************************************************************************

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 3.6.1
- **Bazel version (if compiling from source)**: 0.7.0
- **GCC/Compiler version (if compiling from source)**: 5.4.0
- **CUDA/cuDNN version**: CUDA-8.0, cuDNN - 6.1
- **GPU model and memory**: GTX 1050, 4GB
- **Exact command to reproduce**: sample code to validate installation"
14430,Some errors in docker tf notebooks,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:CentOS 7
- **TensorFlow installed from (source or binary)**: docker images
- **TensorFlow version (use command below)**: latest

### Describe the problem

it is just a documentation problem.

in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/docker/notebooks/2_getting_started.ipynb

in section **the code again**, in the comments:

```py
    # Perform gradient descent. 
    # This essentially just updates weights, like weights += grads * learning_rate
    # using the partial derivative of the loss with respect to the
    # weights. It's the direction we want to go to move toward lower error.
    update_weights = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)
```
I do think to update weights, you should use `weights := weights - grads * learning_rate`, I think using `+=` is not a right choice

And another one is also in this section, you should use `bias_with_x` instead of `x_with_bias`

That's all."
14429,tensorflow.python.framework.errors_impl.NotFoundError:,"I got this erros.
I tried to convert csv to tfrecord with https://www.youtube.com/watch?v=kq2Gjv_pPe8

kimvlvl@cmlabUbuntu:~/object-detection$ python3 generate_tfrecord.py --csv_input=data/train_labels.csv  --output_path=datacord
Traceback (most recent call last):
  File ""generate_tfrecord.py"", line 107, in <module>
    tf.app.run()
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""generate_tfrecord.py"", line 98, in main
    tf_example = create_tf_example(group, path)
  File ""generate_tfrecord.py"", line 53, in create_tf_example
    encoded_jpg = fid.read()
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/lib/io/file_io.py"", line 118, in read
    self._preread_check()
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/lib/io/file_io.py"", line 78, in _preread_check
    compat.as_bytes(self.__name), 1024 * 512, status)
  File ""/usr/lib/python3.5/contextlib.py"", line 66, in __exit__
    next(self.gen)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py"", line 466, in raise_exception_ostatus
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.NotFoundError: /home/kimvlvl/object-detection/images/0265.png

I cheacked all the names and labels of xxx.png

please help"
14428,error when I try mpi_collectives features,"I want to try mpi_collectives features in tensorflow 1.4, but when I run mpi_allreduce_test.py example using python2.7 in contrib/mpi_collectives, I got error.

I installed tensorflow with openmpi.

mpirun -n 2 python mpi_allreduce_test.py
======================================================================
ERROR: test_mpi_allreduce (__main__.AllreduceTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""mpi_allreduce_test.py"", line 82, in test_mpi_allreduce
    average=average_allreduce)
  File ""/usr/lib/python2.7/site-packages/tensorflow/contrib/mpi_collectives/__init__.py"", line 160, in allreduce
    mpi_size = tf.cast(size(), tensor.dtype)
  File ""/usr/lib/python2.7/site-packages/tensorflow/contrib/mpi_collectives/mpi_ops.py"", line 71, in size
    return MPI_LIB.mpi_size(name=name)
AttributeError: 'module' object has no attribute 'mpi_size'

----------------------------------------------------------------------
Ran 2 tests in 0.034s
"
14425,Support Windows builds through clang,"Right now, the tested configurations for Linux, Mac and Windows use gcc, clang and MSVC, as seen at 
https://www.tensorflow.org/install/install_sources#tested_source_configurations

Linux can be made to compile with clang, too, if you use the right magic trick (`--config=cuda_clang`). All that's left is Windows, which is probably the trickiest of the three.

Bonus points for allowing to cross-build for Windows under Linux. The main problem there might be with CUDA and getting its SDK installed on a Linux system (just a wild guess).

(Forked from an existing discussion under https://github.com/tensorflow/tensorflow/issues/12052)"
14423,Using newer NVIDIA drivers causes TF to freeze the entire system if terminated,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04.3 LTS (Xenial Xerus)""
- **TensorFlow installed from (source or binary)**: Binary, through `pip install tensorflow-gpu`
- **TensorFlow version (use command below)**: 1.3.0, Git Version - `v1.3.0-rc2-20-g0787eee`
- **Python version**: 2.7.13
- **CUDA/cuDNN version**: CUDA - 8.0.61, cuDNN - 6
- **GPU model and memory**: GeForce GTX 950M, 2GB

### Describe the problem
I had changed my NVIDIA driver version to 387.12 some time ago. After that, sometimes when I'd terminate TF code (either with `^C` in terminal or closing IPython tab in Spyder) it would successfully terminate with `KeyBoardInterrupt`. However the other times when I'd terminate, my entire computer would freeze and become unresponsive. Couldn't use `Ctrl + Alt + F1` to login into a virtual console and kill the process as keyboard also became unresponsive. However, if I was playing music through Spotify, it would continue playing without any interruption. 
This would happen with different files, not one specific file. But I noticed it would usually happen during the run of `sess.run(tf.global_variables_initializer())` in any of the files. It also has happened some other times like - 
 - Training completed in Spyder console and Python was idle and I closed the console tab in Spyder
 - Training completed in Spyder IPython tab and another file was run in terminal. I closed the IPython tab (which was idle) in Spyder when the new TF session in the terminal was initializing variables and then my computer froze completely. 

I don't think the contents of the code mattered. It would still freeze even if all my code did was define a variable and then initialize it.
So I tried reverting back to NVIDIA 384.98 to see if anything changed but it was still freezing. Now I've reverted back to NVIDIA 381.22 and I've tried terminating TF when it is initializing variables and so far the freezing hasn't happened. 

Another thing I'd noticed after changing to NVIDIA 387 is that `tf.global_variables_initializer()` became very slow, always taking 10+ seconds. I found #7755 where I saw it could be because of CUDA generating PTX. So I tried calling the init a second time in the same session and it would run in milliseconds. Same for calling init on CPU. I understand the init can be slow when run on GPU, however I never noticed it running slow prior to when I changed to a newer NVIDIA driver. Even after the revert to 381, it still runs slow. 


### Source code / logs
I'd really like to know what I can log and how to do that. I'm not sure if I can use gdb as my computer becomes unresponsive so I have no way of going into a terminal. 
Below is the sample code I would run and terminate during init to see if computer froze.
```
import tensorflow as tf
initial = tf.Variable(tf.truncated_normal([1,3], stddev=0.01, seed=1))
sess = tf.Session()
print ""Starting initialization""
sess.run(tf.global_variables_initializer())
```
"
14417,cuda 8.0 is not available now on NVIDIA's website,"latest cuda version is 9.0.x, but what tf depends on is 8.0.x! and it seems that nvidia does not provide downloading site for 8.0 now~~~
how can i solve this problem?"
14416,can eager mode make use of multi-thread automatically?,"just like session mode:

config = tf.ConfigProto(device_count={""CPU"": 4},
                inter_op_parallelism_threads = 1,   
                intra_op_parallelism_threads = 4,  
                log_device_placement=True)  
with tf.Session(config = config) as sess:  
..."
14415,tensorflow-master install from sources doesn't install with pip3,"### System information
- **OS Platform and Distribution**: Ubuntu 17.04
- **TensorFlow installed from**: source
- **TensorFlow version**:  tensorflow-master
- **Python version**:  3.5.3
- **Bazel version (if compiling from source)**: 0.7.0
- **GCC/Compiler version (if compiling from source)**: 4.9.4
- **CUDA/cuDNN version**: 8.0
- **GPU model and memory**: NVIDIA 1080

### Describe the problem
The bazel commands only appear to build Python 2.7 packages, not Python 3.5 packages.

### To reproduce
Following [Installing TensorFlow from Sources: Ubuntu][https://www.tensorflow.org/install/install_sources], I get  [this bazel configuration](https://github.com/tensorflow/tensorflow/files/1458780/tf_configure.bazelrc.txt) from running configure.

I build and install with
```
bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
sudo bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg/
```
but the wheel generated is for Python 2.7:
```
ls /tmp/tensorflow_pkg
tensorflow-1.4.0rc1-cp27-cp27mu-linux_x86_64.whl
```
and so I can't install it with pip3:
```
$ sudo -H  pip3 install  /tmp/tensorflow_pkg/tensorflow-1.4.0rc1-cp27-cp27mu-linux_x86_64.whl
[sudo] password for kevin: 
tensorflow-1.4.0rc1-cp27-cp27mu-linux_x86_64.whl is not a supported wheel on this platform.

$ sudo -H  pip install  /tmp/tensorflow_pkg/tensorflow-1.4.0rc1-cp27-cp27mu-linux_x86_64.whl
Requirement already satisfied: tensorflow==1.4.0rc1 from file:///tmp/tensorflow_pkg/tensorflow-1.4.0rc1-cp27-cp27mu-linux_x86_64.whl in /usr/local/lib/python2.7/dist-packages
```
Importing tensorflow with Python3 fails.
"
14414,Error importing Tensorflow,"I have tensorflow 1.4.0rc1 installed, I get errors when I tried to import tensorflow in my project.

```
Traceback (most recent call last):
  File ""D:\Program Files (x86)\Python\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 18, in swig_import_helper
    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])
  File ""D:\Program Files (x86)\Python\lib\imp.py"", line 296, in find_module
    raise ImportError(_ERR_MSG.format(name), name=name)
ImportError: No module named '_pywrap_tensorflow'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""D:\Program Files (x86)\Python\lib\site-packages\tensorflow\python\__init__.py"", line 54, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""D:\Program Files (x86)\Python\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 28, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""D:\Program Files (x86)\Python\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 20, in swig_import_helper
    import _pywrap_tensorflow
ModuleNotFoundError: No module named '_pywrap_tensorflow'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""E:/Documents/TA/Skripsi/Python/TI08/Revisi Team/timeseries.py"", line 5, in <module>
    from tensorflow.contrib import learn
  File ""D:\Program Files (x86)\Python\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""D:\Program Files (x86)\Python\lib\site-packages\tensorflow\python\__init__.py"", line 60, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""D:\Program Files (x86)\Python\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 18, in swig_import_helper
    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])
  File ""D:\Program Files (x86)\Python\lib\imp.py"", line 296, in find_module
    raise ImportError(_ERR_MSG.format(name), name=name)
ImportError: No module named '_pywrap_tensorflow'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""D:\Program Files (x86)\Python\lib\site-packages\tensorflow\python\__init__.py"", line 54, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""D:\Program Files (x86)\Python\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 28, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""D:\Program Files (x86)\Python\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 20, in swig_import_helper
    import _pywrap_tensorflow
ModuleNotFoundError: No module named '_pywrap_tensorflow'



Error importing tensorflow.  Unless you are using bazel,
you should not try to import tensorflow from its source directory;
please exit the tensorflow source tree, and relaunch your python interpreter
from there.
```

Can someone help me how to solve this error? Thanks!"
14413,Can't get support template,"I seem to have lost the support template when I open issues in tensorflow on Chrome.

Any way to get it back?"
14410,Is there a clean way to upgrade my TF (built from sources in production env) from current 1.31 to 1.4?,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
14407,Failed to connect to dl.google.com port 443: Operation timed out,"when I run the simple project of ios, I just run ""pod install"", but I get the error message of the title, however, if I copy the url ""https://dl.google.com/dl/cpdc/2cf20b661cbb3374/TensorFlow-experimental-1.1.1.tar.gz"" to my safari, it download speed is fast, who can help me? By the way, my ruby/cocoapods all are newest, thx."
14406,cmake build type is hard coded in grpc.cmake,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows Server 2012
- **TensorFlow installed from (source or binary)**:
Source

- **TensorFlow version (use command below)**:
92838685241ca22ea2797e937e380bdbe8325784

- **Python version**: 
3.5.4
- **Bazel version (if compiling from source)**:

- **GCC/Compiler version (if compiling from source)**:
VS 2015

- **CUDA/cuDNN version**:
None
- **GPU model and memory**:
None
- **Exact command to reproduce**:
""D:\src\tensorflow\b\packages\cmake\bin\cmake"" -G ""Visual Studio 14 2015 Win64"" D:\src\tensorflow\s\tensorflow\contrib\cmake -DCMAKE_BUILD_TYPE=Debug -DPYTHON_EXECUTABLE=""D:\src\tensorflow\b\packages\python\python.exe"" -DPYTHON_LIBRARIES=""D:\src\tensorflow\b\packages\python\libs\python35.lib"" -DSWIG_EXECUTABLE=D:\src\tensorflow\b\packages\swigwin.3.0.9\tools\swigwin-3.0.9\swig.exe -Dtensorflow_BUILD_SHARED_LIB=ON -Dtensorflow_BUILD_PYTHON_TESTS=OFF 

Then build tensorflow.vcxproj

### Describe the problem
build failed

### Source code / logs
"
14405,`keras` model with `tf.keras.layers.Conv2D` layers compiled with `tf.losses.softmax_cross_entropy` loss does not converge,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: simple MNIST model in keras
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Debian GNU/Linux 8
- **TensorFlow installed from (source or binary)**: binary from pip
- **TensorFlow version (use command below)**: 1.4
- **Python version**: 3.5.3

### Describe the problem
When using `tf.losses.softmax_cross_entropy` in a `tf.keras` model with `tf.keras.layers.Conv2D` layer, `model.fit()` does not converge, although no exception raised loss does not change.
When change loss function to `tf.keras.losses.categorical_crossentropy`, or layer to `tf.layers.Conv2D`, it converges quickly.

### Source code / logs
`model.fit()` log:
Train on 50000 samples, validate on 10000 samples
Epoch 1/5
50000/50000 [==============================] - 84s - loss: 2.3622 - acc: 0.0986 - val_loss: 2.3662 - val_acc: 0.0950
Epoch 2/5
50000/50000 [==============================] - 83s - loss: 2.3633 - acc: 0.0978 - val_loss: 2.3662 - val_acc: 0.0950
Epoch 3/5
50000/50000 [==============================] - 83s - loss: 2.3633 - acc: 0.0978 - val_loss: 2.3662 - val_acc: 0.0950
Epoch 4/5
50000/50000 [==============================] - 83s - loss: 2.3633 - acc: 0.0978 - val_loss: 2.3662 - val_acc: 0.0950
Epoch 5/5
50000/50000 [==============================] - 84s - loss: 2.3633 - acc: 0.0978 - val_loss: 2.3662 - val_acc: 0.0950
9984/10000 [============================>.] - ETA: 0s 
Test loss: 2.362950. Test accuracy: 0.098200"
14402,Encountered a training error when using slim with multi-GPU connect by PIX type,"Hi all, I encountered a training error when I training model in multi GPU.    
The key condition is using slim to write model and training in multi GPU(GTX TITAN X) which connect by PIX type.

How to reproduce:
 * 1. checkout office code in [here](https://github.com/tensorflow/models/tree/master/tutorials/image/cifar10)
 * 2. copy code in below(slim model code) and replace it to cifar10.py file. (Because only slim code can reproduce this issue)
 * 3. start to training: ```CUDA_VISIBLE_DEVICES=1,0 python cifar10_multi_gpu_train.py --num_gpus=2```
 * 4. an incorrect loss will appear. (Also GPU usage is incorrect)

Note 1: Check GPU info in below. this issue only happend when I using GPU 0,1 or GPU 2,3 or GPU 4,5 or GPU 6,7(connect by PIX). In this case, everything is ok If I using other combinations   
Note 2: I can't reproduce this issue in GTX 1080 ti   

Thank you so much!

The training error log in below:

```
linux@172.25.52.02:~/models/tutorials/image/cifar10: CUDA_VISIBLE_DEVICES=1,0 python cifar10_multi_gpu_train.py --num_gpus=2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-11-09 18:13:02.264529: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are
available on your machine and could speed up CPU computations.
2017-11-09 18:13:06.359127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties:
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.076
pciBusID 0000:05:00.0
Total memory: 11.92GiB
Free memory: 11.81GiB
2017-11-09 18:13:06.784690: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x5f00120 exists before initializing the StreamExecutor
. We haven't verified StreamExecutor works with that.
2017-11-09 18:13:06.786072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 1 with properties:
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.076
pciBusID 0000:04:00.0
Total memory: 11.92GiB
Free memory: 11.81GiB
2017-11-09 18:13:06.786507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 1
2017-11-09 18:13:06.786527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y Y
2017-11-09 18:13:06.786592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 1:   Y Y
2017-11-09 18:13:06.786623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)
2017-11-09 18:13:06.786635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX TITAN X, pci bus id: 0000:04:00.0)
2017-11-09 18:13:06.830077: I tensorflow/core/common_runtime/simple_placer.cc:697] Ignoring device specification /device:GPU:1 for node 'tower_1/fifo_queue_Dequeue' because the input edge from 'prefetch_queue/fifo_queue' is a reference connection and already has a device field set to /device:CPU:0
2017-11-09 18:13:06.830125: I tensorflow/core/common_runtime/simple_placer.cc:697] Ignoring device specification /device:GPU:0 for node 'tower_0/fifo_queue_Dequeue' because the input edge from 'prefetch_queue/fifo_queue' is a reference connection and already has a device field set to /device:CPU:0
2017-11-09 18:13:09.804877: step 0, loss = 2.30 (119.9 examples/sec; 1.067 sec/batch)
2017-11-09 18:13:17.096214: step 10, loss = 2.30 (421.3 examples/sec; 0.304 sec/batch)
2017-11-09 18:13:23.708459: step 20, loss = 2.30 (390.0 examples/sec; 0.328 sec/batch)
2017-11-09 18:13:31.362454: step 30, loss = 2.30 (362.5 examples/sec; 0.353 sec/batch)
2017-11-09 18:13:38.225150: step 40, loss = 2.30 (363.3 examples/sec; 0.352 sec/batch)
2017-11-09 18:13:44.695175: step 50, loss = 2.30 (389.8 examples/sec; 0.328 sec/batch)
2017-11-09 18:13:51.994245: step 60, loss = 2.30 (362.5 examples/sec; 0.353 sec/batch)
2017-11-09 18:13:58.623306: step 70, loss = 2.30 (421.2 examples/sec; 0.304 sec/batch)
2017-11-09 18:14:05.480061: step 80, loss = 2.30 (390.6 examples/sec; 0.328 sec/batch)
2017-11-09 18:14:11.952376: step 90, loss = 2.30 (389.2 examples/sec; 0.329 sec/batch)
2017-11-09 18:14:18.375831: step 100, loss = 293778.34 (362.7 examples/sec; 0.353 sec/batch)
Traceback (most recent call last):
  File ""cifar10_multi_gpu_train.py"", line 283, in <module>
    tf.app.run()
  File ""/home/zhangjiguo/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""cifar10_multi_gpu_train.py"", line 278, in main
    train()
  File ""cifar10_multi_gpu_train.py"", line 251, in train
    assert not np.isnan(loss_value), 'Model diverged with loss = NaN'
AssertionError: Model diverged with loss = NaN
```

My GPU list with command `nvidia-smi -L`    

```
GPU 0: GeForce GTX TITAN X (UUID: GPU-2c9601fc-369e-fce7-d139-8c7144700def)
GPU 1: GeForce GTX TITAN X (UUID: GPU-eb4d8327-7058-39fe-e510-3437fe258745)
GPU 2: GeForce GTX TITAN X (UUID: GPU-62fbacf7-0120-5c6b-ceea-ad026fddc537)
GPU 3: GeForce GTX TITAN X (UUID: GPU-15be755d-9982-f4f4-4455-1d648d836b6e)
GPU 4: GeForce GTX TITAN X (UUID: GPU-e48fae89-debd-9769-3851-61ba44acd6e1)
GPU 5: GeForce GTX TITAN X (UUID: GPU-f796ad02-e104-04b5-d6c1-ff72d872654f)
GPU 6: GeForce GTX TITAN X (UUID: GPU-7e27fd1e-ba3b-2dd3-6d03-960b8c76a0be)
GPU 7: GeForce GTX TITAN X (UUID: GPU-8de522e7-f375-ab05-28ff-5ddfd9e325b0)
```

and GPU connection info with command `nvidia-smi topo -m`

```
       	GPU0   	GPU1   	GPU2   	GPU3   	GPU4   	GPU5   	GPU6   	GPU7   	mlx4_0 	CPU Affinity
GPU0   	 X     	PIX    	PHB    	PHB    	SOC    	SOC    	SOC    	SOC    	SOC    	0-13,28-41
GPU1   	PIX    	 X     	PHB    	PHB    	SOC    	SOC    	SOC    	SOC    	SOC    	0-13,28-41
GPU2   	PHB    	PHB    	 X     	PIX    	SOC    	SOC    	SOC    	SOC    	SOC    	0-13,28-41
GPU3   	PHB    	PHB    	PIX    	 X     	SOC    	SOC    	SOC    	SOC    	SOC    	0-13,28-41
GPU4   	SOC    	SOC    	SOC    	SOC    	 X     	PIX    	PHB    	PHB    	PHB    	14-27,42-55
GPU5   	SOC    	SOC    	SOC    	SOC    	PIX    	 X     	PHB    	PHB    	PHB    	14-27,42-55
GPU6   	SOC    	SOC    	SOC    	SOC    	PHB    	PHB    	 X     	PIX    	PHB    	14-27,42-55
GPU7   	SOC    	SOC    	SOC    	SOC    	PHB    	PHB    	PIX    	 X     	PHB    	14-27,42-55
mlx4_0 	SOC    	SOC    	SOC    	SOC    	PHB    	PHB    	PHB    	PHB    	 X

Legend:

  X   = Self
  SOC  = Connection traversing PCIe as well as the SMP link between CPU sockets(e.g. QPI)
  PHB  = Connection traversing PCIe as well as a PCIe Host Bridge (typically the CPU)
  PXB  = Connection traversing multiple PCIe switches (without traversing the PCIe Host Bridge)
  PIX  = Connection traversing a single PCIe switch
  NV#  = Connection traversing a bonded set of # NVLinks
```

slim model code: (Please replace these code to cifar10.py)

```
def inference(images):
	# reimplement by slim
    slim = tf.contrib.slim
    conv1 = slim.conv2d(images, 64, [5, 5], scope='conv1',
                       weights_regularizer=slim.l2_regularizer(0.0),
                       weights_initializer=tf.truncated_normal_initializer(stddev=0.1),
                       activation_fn=tf.nn.relu)
    pool1 = slim.max_pool2d(conv1, [3, 3], 2, padding='SAME', scope='poll1')
    norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm1')
    conv2 = slim.conv2d(norm1, 64, [5, 5], scope='conv2',
                       weights_regularizer=slim.l2_regularizer(0.0),
                       weights_initializer=tf.truncated_normal_initializer(stddev=5e-2),
                       biases_initializer=tf.constant_initializer(0.1),
                       activation_fn=tf.nn.relu)
    norm2 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm2')
    pool2 = slim.max_pool2d(norm2, [3, 3], 2, padding='SAME', scope='poll2')
    flatten2 = slim.flatten(pool2)
    local3 = slim.fully_connected(flatten2, 384, scope='local3',
                       weights_regularizer=slim.l2_regularizer(0.004),
                       weights_initializer=tf.truncated_normal_initializer(stddev=0.04),
                       biases_initializer=tf.constant_initializer(0.1),
                       activation_fn=tf.nn.relu)
    local4 = slim.fully_connected(local3, 192, scope='local4',
                       weights_regularizer=slim.l2_regularizer(0.004),
                       weights_initializer=tf.truncated_normal_initializer(stddev=0.04),
                       biases_initializer=tf.constant_initializer(0.1),
                       activation_fn=tf.nn.relu)
    softmax_linear = slim.fully_connected(local4, NUM_CLASSES, scope='softmax_linear',
                       weights_regularizer=slim.l2_regularizer(0.0),
                       weights_initializer=tf.truncated_normal_initializer(stddev=1/192.0),
                       biases_initializer=tf.constant_initializer(0.0),
                       activation_fn=None)
    return softmax_linear
```


### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:CentOS Linux release 7.2.1511
- **TensorFlow installed from (source or binary)**:source
- **TensorFlow version (use command below)**:Tensorflow 1.2.0/ 1.0.1
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: 1.4.5
- **GCC/Compiler version (if compiling from source)**:4.8.5
- **CUDA/cuDNN version**:CUDA 8.0 and cuDNN 5.0
- **GPU model and memory**:TITAN X with 12GB
- **Exact command to reproduce**:
"
14400,[CMake] Default values of some options are not properly set,"```tensorflow_PATH_CUDNN_STATIC_LIB``` and ```tensorflow_PATH_NCCL_STATIC_LIB``` are supposed to be configured as the value of ```tensorflow_PATH_STATIC_LIB``` by default.

However, because cmake options's default values are either OFF or ON, this doesn't work as supposed.

I'll post a Pull Request addressing this issue in a few minutes."
14398,name_scope is indistinguishable from string type ,"variable_scope yields a class VariableScope when entered, while name_scope yields a string. 

```python
import tensorflow as tf

with tf.name_scope(""n1""):
    with tf.name_scope(""n2"") as n2:
        print(""name_scope: {}"".format(n2))
        print(""get_name_scope: {}"".format(tf.contrib.framework.get_name_scope()))

with tf.variable_scope(""v1""):
    with tf.variable_scope(""v2"") as v2:
        print(""variable_scope: {}"".format(v2))
        print(""get_name_scope: {}"".format(tf.get_variable_scope()))

# output
# name_scope: n1/n2/
# get_name_scope: n1/n2
# variable_scope: <tensorflow.python.ops.variable_scope.VariableScope object at 0x11ba34d68>
# get_name_scope: <tensorflow.python.ops.variable_scope.VariableScope object at 0x11ba34d68>
```

I think string might be unsafe. Moreover, sometimes we have to hack a ""/"" suffix if we want to reenter the current name scope. 

Especially, it's difficult to check the type when `name_scope` is an argument for a function.
```python
def func(my_name_scope, my_variable_scope):
    if isinstance(my_variable_scope, (VariableScope, variable_scope)):
        # do something
    else:
        raise TypeError()

    if isinstance(my_name_scope, (six.string_types, name_scope)):
        # how to do if it's an invalid string?
    else:
        raise TypeError()
```

Will tensorflow plan to introduce a class like VariableScope, say NameScope, in the future? Thanks."
14396,Unable to compile tensorflow in Win/Debug mode,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows Server 2012
- **TensorFlow installed from (source or binary)**:
Source

- **TensorFlow version (use command below)**:
92838685241ca22ea2797e937e380bdbe8325784

- **Python version**: 
3.5.4
- **Bazel version (if compiling from source)**:

- **GCC/Compiler version (if compiling from source)**:
VS 2015

- **CUDA/cuDNN version**:
None
- **GPU model and memory**:
None
- **Exact command to reproduce**:
""D:\src\tensorflow\b\packages\cmake\bin\cmake"" -G ""Visual Studio 14 2015 Win64"" D:\src\tensorflow\s\tensorflow\contrib\cmake -DCMAKE_BUILD_TYPE=Debug -DPYTHON_EXECUTABLE=""D:\src\tensorflow\b\packages\python\python.exe"" -DPYTHON_LIBRARIES=""D:\src\tensorflow\b\packages\python\libs\python35.lib"" -DSWIG_EXECUTABLE=D:\src\tensorflow\b\packages\swigwin.3.0.9\tools\swigwin-3.0.9\swig.exe -Dtensorflow_BUILD_SHARED_LIB=ON -Dtensorflow_BUILD_PYTHON_TESTS=OFF 

Then build tensorflow.vcxproj

### Describe the problem
build failed

### Source code / logs
```
 ##[error]C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\xutility(958,0): Error C2678: binary '<': no operator found which takes a left-hand operand of type 'tensorflow::boosted_trees::utils::`anonymous-namespace'::IndicesRowIterator' (or there is no acceptable conversion) (compiling source file D:\src\tensorflow\s\tensorflow\contrib\boosted_trees\lib\utils\sparse_column_iterable.cc)
     11>C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\xutility(958): error C2678: binary '<': no operator found which takes a left-hand operand of type 'tensorflow::boosted_trees::utils::`anonymous-namespace'::IndicesRowIterator' (or there is no acceptable conversion) (compiling source file D:\src\tensorflow\s\tensorflow\contrib\boosted_trees\lib\utils\sparse_column_iterable.cc) [D:\src\tensorflow\b\debug\tf_core_kernels.vcxproj]
          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\thread(224): note: could be 'bool std::operator <(std::thread::id,std::thread::id) noexcept' (compiling source file D:\src\tensorflow\s\tensorflow\contrib\boosted_trees\lib\utils\sparse_column_iterable.cc)
          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\system_error(436): note: or       'bool std::operator <(const std::error_condition &,const std::error_condition &) noexcept' (compiling source file D:\src\tensorflow\s\tensorflow\contrib\boosted_trees\lib\utils\sparse_column_iterable.cc)
          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\system_error(427): note: or       'bool std::operator <(const std::error_code &,const std::error_code &) noexcept' (compiling source file D:\src\tensorflow\s\tensorflow\contrib\boosted_trees\lib\utils\sparse_column_iterable.cc)
          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\xutility(958): note: while trying to match the argument list '(tensorflow::boosted_trees::utils::`anonymous-namespace'::IndicesRowIterator, tensorflow::boosted_trees::utils::`anonymous-namespace'::IndicesRowIterator)' (compiling source file D:\src\tensorflow\s\tensorflow\contrib\boosted_trees\lib\utils\sparse_column_iterable.cc)
          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\xutility(967): note: see reference to function template instantiation 'void std::_Debug_range2<_InIt>(_RanIt,_RanIt,std::_Dbfile_t,std::_Dbline_t,std::random_access_iterator_tag)' being compiled
                  with
                  [
                      _InIt=tensorflow::boosted_trees::utils::`anonymous-namespace'::IndicesRowIterator,
                      _RanIt=tensorflow::boosted_trees::utils::`anonymous-namespace'::IndicesRowIterator
                  ] (compiling source file D:\src\tensorflow\s\tensorflow\contrib\boosted_trees\lib\utils\sparse_column_iterable.cc)
          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\algorithm(2196): note: see reference to function template instantiation 'void std::_Debug_range<_FwdIt>(_InIt,_InIt,std::_Dbfile_t,std::_Dbline_t)' being compiled
                  with
                  [
                      _FwdIt=tensorflow::boosted_trees::utils::`anonymous-namespace'::IndicesRowIterator,
                      _InIt=tensorflow::boosted_trees::utils::`anonymous-namespace'::IndicesRowIterator
                  ] (compiling source file D:\src\tensorflow\s\tensorflow\contrib\boosted_trees\lib\utils\sparse_column_iterable.cc)
          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\algorithm(2206): note: see reference to function template instantiation '_FwdIt std::lower_bound<_FwdIt,_Ty,std::less<void>>(_FwdIt,_FwdIt,const _Ty &,_Pr)' being compiled
                  with
                  [
                      _FwdIt=tensorflow::boosted_trees::utils::`anonymous-namespace'::IndicesRowIterator,
                      _Ty=tensorflow::int64,
                      _Pr=std::less<void>
                  ] (compiling source file D:\src\tensorflow\s\tensorflow\contrib\boosted_trees\lib\utils\sparse_column_iterable.cc)
          D:\src\tensorflow\s\tensorflow\contrib\boosted_trees\lib\utils\sparse_column_iterable.cc(115): note: see reference to function template instantiation '_FwdIt std::lower_bound<tensorflow::boosted_trees::utils::`anonymous-namespace'::IndicesRowIterator,tensorflow::int64>(_FwdIt,_FwdIt,const _Ty &)' being compiled
                  with
                  [
                      _FwdIt=tensorflow::boosted_trees::utils::`anonymous-namespace'::IndicesRowIterator,
                      _Ty=tensorflow::int64
                  ]
```"
14394,TF Detect app doesnt work with my own weights,"Hello guys, I followed the instruction of object detection android app and successfully run the app using the pretrained tiny-yolo-voc. 

Now I have trained another model by myself with my own dataset(1class) using Darknet. Then I convert the weights file to pb type format using the Darkflow command
`./flow --model cfg/yolo-1class.cfg --load bin/yolo-marker_1class.weights --savepb --verbalise`

Using the summerize_graph tool, I checked the yolo-marker_1class.pb has the same 'input' and 'output' node.

After i manually copy this pb file into the asset folder and click Run button, I had this error which is not happened when I build when the pretrained tiny-yolo-voc.pb
Can anyone help me please ? 
![1](https://user-images.githubusercontent.com/11288381/32594925-38e2801c-c571-11e7-8992-4cd36675fb34.png)





"
14393,Error:Execution failed for task ':buildNativeBazel'.," This problem occured with the android example in android studio.
 ->A problem occurred starting process 'command '/usr/local/bin/bazel''"
14392,The weights argument in Keras's Embedding does not work,"I am using Tensorflow 1.4.0.

According to this [blog post](https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html), we can use the weights argument in the call to Embedding to specify some matrix that represents a pre-trained word embeddings (see the section titled Preparing the Embedding Layer).

However, this code does not work:

```
import tensorflow as tf
import numpy as np

from tensorflow.python.estimator.model_fn import EstimatorSpec
from tensorflow.contrib.keras.api.keras.layers import Embedding, Dense
from tensorflow.contrib.keras.api.keras.initializers import Constant


def model_fn(features, labels, mode):
    x = tf.constant([[1]])
    labels = tf.constant([[10.]])
    
    # Let m be our pre-trained word embeddings
    m = np.array([[1, 2], [3, 4]], np.float32)
    with tf.name_scope('Embedding_Layer'):
        # Create an embedding layer and load m into it
        n = Embedding(2, 2, weights=[m], input_length=1, name='embedding_matrix_1', trainable=False)

    lookup = n(x)
    lookup = tf.Print(lookup, [lookup])

    preds = Dense(1)(lookup)
    loss = tf.reduce_mean(labels - preds)
    train_op = tf.train.GradientDescentOptimizer(0.01).minimize(loss, tf.train.get_global_step())

    eval_metric_ops = {'accuracy': tf.metrics.accuracy(labels, preds)}
    return EstimatorSpec(mode=mode, loss=loss, train_op=train_op, eval_metric_ops=eval_metric_ops)


model = tf.estimator.Estimator(model_fn)
model.train(input_fn=lambda: None, steps=1)
```

`lookup` should print [[3 4]] but instead random numbers are printed.

The solution is to define `n` as follows:

```
n = Embedding(2, 2, embeddings_initializer=Constant(m), input_length=1, name='embedding_matrix_1',
                      trainable=False)
```"
14391,MonitoredTrainingSession does not initialize after restore,"### Describe the problem
`local_init_op` can be passed to the SessionManager through the scaffold argument in MonitoredTrainingSession. From the doc's from session manager: The `local_init_op` is an `Operation` that is run always after a new session was created. This does not work as expected in the below example.

### Exact command to reproduce
```
global_step = tf.contrib.framework.get_or_create_global_step()
a1 = tf.Variable([1,2,3], name='a1')
a2 = tf.Variable([1,2,3], name='a2')
train = tf.assign(global_step, global_step +1)
saver = tf.train.Saver(var_list=[a1],
                        reshape = False,
                        sharded = False,
                        max_to_keep = 100,
                        keep_checkpoint_every_n_hours = 10000.0,
                        name = ""CheckpointSaver"",
                        restore_sequentially = False,
                        saver_def = None,
                        builder = None,
                        defer_build = False,
                        allow_empty = False,
                        write_version = tf.train.SaverDef.V2,
                        pad_step_number = False,
                        save_relative_paths = False)
hooks = [tf.train.CheckpointSaverHook(checkpoint_dir = ""ckpt/"",
                         save_secs = None,
                         save_steps = 1,
                         saver = saver,
                         checkpoint_basename = 'model_to_test.ckpt',
                         scaffold = None,
                         listeners = None)]
scaffold = tf.train.Scaffold(saver=saver, local_init_op = tf.variables_initializer([a2]))
with tf.train.MonitoredTrainingSession(master = '',
                         is_chief = True,
                         checkpoint_dir = ""ckpt/"",
                         scaffold=scaffold,
                         hooks = hooks,
                         chief_only_hooks = [],
                         save_checkpoint_secs=None,
                         save_summaries_steps=None,
                         save_summaries_secs=None,
                         config=None,
                         stop_grace_period_secs=120,
                         log_step_count_steps=100) as mon_sess:
    print(mon_sess.run(a1))
    print(mon_sess.run(a2))
    mon_sess.run(train)
```
The first time you run this, two variables `a1` and `a2` will be initialized by the implied (default) initializer from the `MonitoredTrainingSession` and a checkpoint file will be written to disk for only a1; expected behavior, no errors. The second time you run this, it should load a1 from the previous checkpoint and initialize `a2` through the `local_init_op` given through the scaffold. But it doesn't, instead: 

> RuntimeError: Init operations did not make model ready for local_init.  Init op: group_deps, init fn: None, error: Variables not initialized: global_step, a2

A hack that circumvents the problem by not using `local_init_op` is suggested here (as well as a reiteration of the expected behavior):
https://stackoverflow.com/questions/43336553/how-to-use-tf-train-monitoredtrainingsession-to-restore-only-certain-variables




### System information
- **TensorFlow version (use command below)**:
('v1.2.0-rc2-21-g12f033d', '1.2.0')
- **Python version**: 
2.7.10

"
14388,"mutex.h, private member is inaccessible","### System information
- **msvc v140**:

### Problem
mutex.h, Ln 145
condition_variable cannot access private member mu_ in mutex, when compiling a standalone c++ project on Windows. 

### Solution
Forward declare condition variable in mutex.h. I have created a pull request.
"
14387,tensorflow-gpu looks for the wrong driver version,"### System information
- **OS Platform and Distribution**: Ubuntu 16.04
- **TensorFlow installed from**: binary
- **TensorFlow version**: 1.4
- **Python version**: 2.7.12
- **CUDA/cuDNN version**: 8.0 / 6.0
- **GPU model and memory**: GTX 1060 
- **GPU driver version**: 387.12
- **Exact command to reproduce**: 
`import tensorflow as tf`


### Problem
It looks for the wrong version of libnvidia-fatbinaryloader.so.xxx.xx. 

```
Traceback (most recent call last):
  File ""/home/stefano/PycharmProjects/lstm/robot_LSTM.py"", line 2, in <module>
    from keras.models import Sequential
  File ""/home/stefano/PycharmProjects/lstm/env/local/lib/python2.7/site-packages/keras/__init__.py"", line 3, in <module>
    from . import utils
  File ""/home/stefano/PycharmProjects/lstm/env/local/lib/python2.7/site-packages/keras/utils/__init__.py"", line 6, in <module>
    from . import conv_utils
  File ""/home/stefano/PycharmProjects/lstm/env/local/lib/python2.7/site-packages/keras/utils/conv_utils.py"", line 3, in <module>
    from .. import backend as K
  File ""/home/stefano/PycharmProjects/lstm/env/local/lib/python2.7/site-packages/keras/backend/__init__.py"", line 83, in <module>
    from .tensorflow_backend import *
  File ""/home/stefano/PycharmProjects/lstm/env/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py"", line 1, in <module>
    import tensorflow as tf
  File ""/home/stefano/PycharmProjects/lstm/env/local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/home/stefano/PycharmProjects/lstm/env/local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/home/stefano/PycharmProjects/lstm/env/local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 72, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/home/stefano/PycharmProjects/lstm/env/local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/home/stefano/PycharmProjects/lstm/env/local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/home/stefano/PycharmProjects/lstm/env/local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
ImportError: libnvidia-fatbinaryloader.so.384.90: cannot open shared object file: No such file or directory
```
"
14384,Cannot make an input layer that takes scalars with the keras functional api,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source (branch 1.4)
- **TensorFlow version (use command below)**: 1.4.0-dev
- **Python version**: 3.5
- **Bazel version (if compiling from source)**: 5.4.0
- **CUDA/cuDNN version**: 8.0/6.0
- **GPU model and memory**: nVidia 1080Ti 11G
- **Exact command to reproduce**: run the script below

### Describe the problem

The following is an attempt to use the keras functional api to make a model that accepts scalars as input:
```
import tensorflow as tf
from tensorflow.contrib.keras.api.keras.models import Model
from tensorflow.contrib.keras.api.keras.layers import Input
i = Input(batch_shape=(None, ), dtype=tf.uint8, name=""input"")
m = Model(inputs=i, outputs=i)
```
which fails like so:
```
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-54-dd00bec66757> in <module>()
----> 1 i = Input(batch_shape=(None, ), dtype=tf.uint8, name=""input"")
      2 m = Model(inputs=i, outputs=i)

/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/engine/topology.py in Input(shape, batch_size, name, dtype, sparse, tensor, **kwargs)
    611     dtype = K.floatx()
    612   if not shape and tensor is None:
--> 613     raise ValueError('Please provide to Input either a `shape`'
    614                      ' or a `tensor` argument. Note that '
    615                      '`shape` does not include the batch '

ValueError: Please provide to Input either a `shape` or a `tensor` argument. Note that `shape` does not include the batch dimension.
```
Using a sequential model instead works fine:
```
import tensorflow as tf
from tensorflow.contrib.keras.api.keras.models import Sequential
from tensorflow.contrib.keras.api.keras.layers import InputLayer
m = Sequential()
m.add(InputLayer(batch_input_shape=(None, ), dtype=tf.uint8, name=""input""))
```
Additionally using the external keras works fine:
```
import tensorflow as tf
from keras.models import Model
from keras.layers import Input
i = Input(batch_shape=(None, ), dtype=tf.uint8, name=""input"")
m = Model(inputs=i, outputs=i)
```
It appears that this broke when the tensor and batch_size arguments were added to the internal version.
Here is one possible way to fix it which I can propose if people are ok with it:
```
diff --git a/tensorflow/python/keras/_impl/keras/engine/topology.py b/tensorflow/python/keras/_impl/keras/engine/topology.py
index f9be782..74df725 100644
--- a/tensorflow/python/keras/_impl/keras/engine/topology.py
+++ b/tensorflow/python/keras/_impl/keras/engine/topology.py
@@ -605,21 +605,20 @@ def Input(  # pylint: disable=invalid-name
       raise ValueError('Only provide the shape OR '
                        'batch_shape argument to '
                        'Input, not both at the same time.')
-    batch_size = batch_shape[0]
-    shape = batch_shape[1:]
+  else:
+    if not shape and tensor is None:
+      raise ValueError('Please provide to Input either a `shape`'
+                       ' or a `batch_shape` or a `tensor` argument.'
+                       ' Note that `shape` does not include the batch '
+                       'dimension.')
+    batch_shape = (batch_size,) + tuple(shape)
   if kwargs:
     raise ValueError('Unrecognized keyword arguments:', kwargs.keys())
 
   if dtype is None:
     dtype = K.floatx()
-  if not shape and tensor is None:
-    raise ValueError('Please provide to Input either a `shape`'
-                     ' or a `tensor` argument. Note that '
-                     '`shape` does not include the batch '
-                     'dimension.')
   input_layer = InputLayer(
-      input_shape=shape,
-      batch_size=batch_size,
+      batch_input_shape=batch_shape,
       name=name,
       dtype=dtype,
       sparse=sparse,
```

"
14381,Can't access predictions ,"

------------------------

### System information

- OS Platform and Distribution: Windows 10
- TensorFlow installed from: binary
- TensorFlow version: Tensorflow 1.4.0
- Python version: Python 3.6
- CUDA/cuDNN version: CUDA 8 / cuDNN 6
- GPU model and memory: GTX M950



### Describe the problem
When trying to print the predictions from DNNClassifier class i only get ""<generator object Estimator.predict at 0x000001AFE1E24EB8>"". I used the exact code written in the Tensorflow tutorials.

### Source code / logs
train_input_fn = tf.estimator.inputs.numpy_input_fn(x={""x"": np.array(X_train)}, y=y_train,num_epochs=None,shuffle=False)
test_input_fn = tf.estimator.inputs.numpy_input_fn(x={""x"": np.array(X_test)}, y=None,shuffle=False)
classifier.train(input_fn=train_input_fn, steps=100)
preds = classifier.predict(input_fn=test_input_fn)
print(preds)
"
14380,"Bazel Build Fails with ""undeclared inclusion(s) in rule '@nccl_archive//:nccl'""","### System information
The environment used is:
[tf_env.txt](https://github.com/tensorflow/tensorflow/files/1455194/tf_env.txt)

The branch downloaded is tensorflow-master branch

When I run the configure script the configuration is
[.tf_configure.bazelrc](https://github.com/tensorflow/tensorflow/files/1455688/tf_configure.bazelrc.txt)
 

### Describe the problem
When I run
```
bazel build --config=opt --config=cuda --config=mkl //tensorflow/tools/pip_package:build_pip_package
```
The build fails with the error
``` ""/home/kevin/.cache/bazel/_bazel_kevin/1bfc1cc47be0eab35fef533f37af7359/external/nccl_archive/BUILD:33:1: undeclared inclusion(s) in rule '@nccl_archive//:nccl':
this rule is missing dependency declarations for the following files included by 'external/nccl_archive/src/core.cu.cc':
  '/usr/lib/gcc/x86_64-linux-gnu/4.9/include-fixed/limits.h'
  '/usr/lib/gcc/x86_64-linux-gnu/4.9/include-fixed/syslimits.h'
  '/usr/lib/gcc/x86_64-linux-gnu/4.9/include/stddef.h'
  '/usr/lib/gcc/x86_64-linux-gnu/4.9/include/stdarg.h'
Target //tensorflow/tools/pip_package:build_pip_package failed to build
FAILED: Build did NOT complete successfully
```
but the files are present:
```
ls /usr/lib/gcc/x86_64-linux-gnu/4.9/include-fixed/limits.h
/usr/lib/gcc/x86_64-linux-gnu/4.9/include-fixed/limits.h
```
There appears to be a problem with bazel build with MKL enabled.  I have been able to compile this with MKL disabled. MKL for Ubuntu should be supported, yes?"
14375,Build is broken at HEAD,"From ci.bazel.io (mac and Linux: https://ci.bazel.io/blue/organizations/jenkins/TensorFlow/detail/TensorFlow/1544/pipeline/):

```
ERROR: /home/ci/.cache/bazel/_bazel_ci/9630feff78264ece04615e9d6bad98b7/external/local_config_sycl/sycl/BUILD:14:14: Traceback (most recent call last):
	File ""/home/ci/.cache/bazel/_bazel_ci/9630feff78264ece04615e9d6bad98b7/external/local_config_sycl/sycl/BUILD"", line 12
		config_setting(name = ""using_sycl_ccpp"", values =...""})
	File ""/home/ci/.cache/bazel/_bazel_ci/9630feff78264ece04615e9d6bad98b7/external/local_config_sycl/sycl/BUILD"", line 14, in config_setting
		{""define"": ""using_sycl=true"", ""define"": ""using_trisycl=false""}
Duplicated key ""define"" when creating dictionary.
ERROR: /home/ci/.cache/bazel/_bazel_ci/9630feff78264ece04615e9d6bad98b7/external/local_config_sycl/sycl/BUILD:22:14: Traceback (most recent call last):
	File ""/home/ci/.cache/bazel/_bazel_ci/9630feff78264ece04615e9d6bad98b7/external/local_config_sycl/sycl/BUILD"", line 20
		config_setting(name = ""using_sycl_trisycl"", value...""})
	File ""/home/ci/.cache/bazel/_bazel_ci/9630feff78264ece04615e9d6bad98b7/external/local_config_sycl/sycl/BUILD"", line 22, in config_setting
		{""define"": ""using_sycl=true"", ""define"": ""using_trisycl=true""}
Duplicated key ""define"" when creating dictionary.
```

Repro:
```
$ bazel build @local_config_sycl//sycl:sycl
..........
ERROR: /usr/local/google/home/dmarting/.cache/bazel/_bazel_dmarting/7d9873875fd56d2bc53371f0098a5332/external/local_config_sycl/sycl/BUILD:14:14: Traceback (most recent call last):
        File ""/usr/local/google/home/dmarting/.cache/bazel/_bazel_dmarting/7d9873875fd56d2bc53371f0098a5332/external/local_config_sycl/sycl/BUILD"", line 12
                config_setting(name = ""using_sycl_ccpp"", values =...""})
        File ""/usr/local/google/home/dmarting/.cache/bazel/_bazel_dmarting/7d9873875fd56d2bc53371f0098a5332/external/local_config_sycl/sycl/BUILD"", line 14, in config_setting
                {""define"": ""using_sycl=true"", ""define"": ""using_trisycl=false""}
Duplicated key ""define"" when creating dictionary
ERROR: /usr/local/google/home/dmarting/.cache/bazel/_bazel_dmarting/7d9873875fd56d2bc53371f0098a5332/external/local_config_sycl/sycl/BUILD:22:14: Traceback (most recent call last):
        File ""/usr/local/google/home/dmarting/.cache/bazel/_bazel_dmarting/7d9873875fd56d2bc53371f0098a5332/external/local_config_sycl/sycl/BUILD"", line 20
                config_setting(name = ""using_sycl_trisycl"", value...""})
        File ""/usr/local/google/home/dmarting/.cache/bazel/_bazel_dmarting/7d9873875fd56d2bc53371f0098a5332/external/local_config_sycl/sycl/BUILD"", line 22, in config_setting
                {""define"": ""using_sycl=true"", ""define"": ""using_trisycl=true""}
Duplicated key ""define"" when creating dictionary
ERROR: error loading package '@local_config_sycl//sycl': Package 'sycl' contains errors
INFO: Elapsed time: 2.250s
FAILED: Build did NOT complete successfully (1 packages loaded)
```
After configuring.


Bisecting blame fe197f7dc5bd3b986141bcdaa27928206e74741a

/cc @gunan"
14374,Get all placeholders of the graph,"According to [this](https://stackoverflow.com/questions/38933793/how-to-get-reference-by-name-of-variable-placeholder):, there are two ways to get placeholders of the graph. 

However, neither of them are very convenient.  

When I reuse a pretrained model, it is common to inspect the shape of **all placeholders**. But there is no API to **get all placeholders easily**.

Is it good for all placeholders to be added to a ""placeholder"" collection automatically? "
14373,pip3 syntax error,"I put in the code in python but it does not work i made sure that pip3 and python is updated and installed but it gives me this:
>>> pip3 install tensorflow
  File ""<stdin>"", line 1
    pip3 install tensorflow
               ^
SyntaxError: invalid syntax
>>> pip install tensorflow
  File ""<stdin>"", line 1
    pip install tensorflow
              ^
SyntaxError: invalid syntax
>>>
>>> pip3 install --upgrade tensorflow
  File ""<stdin>"", line 1
    pip3 install --upgrade tensorflow
               ^
SyntaxError: invalid syntax
>>> pip3 install --upgrade tensorflow
  File ""<stdin>"", line 1
    pip3 install --upgrade tensorflow
               ^
(I tryed multiple times)



 "
14369,configure.py should remember previous session as defaults,"### System information
[tf_env.txt](https://github.com/tensorflow/tensorflow/files/1454666/tf_env.txt)

Branch tensorflow-r1.4

### Describe the problem

Using instructions at https://www.tensorflow.org/install/install_sources to build from source.  When run configure.py a second time, defaults should be the options chosen the previous time.  Filling out all the questions again is exceedingly tedious.
"
14366,Question: How to feed a batch of variable sized images to the Tensorflow C/C++ or Java API on Android?,"I asked this question on Stackoverflow before but got no answers: https://stackoverflow.com/questions/46906269/how-to-process-variable-sized-images-with-tensorflow-java-api

In short: I have a CNN model that is doing some preprocessing of the images in the tensorflow graph before running the CNN on the data. This preprocessing includes resizing the images after normalizing them etc. Thus, I need to feed my model with a batch of differently sized images. While I could try to do this in OpenCV, I don't want to, as it seems messy to reimplement the complicated preprocessing and not as efficient. 

I found a way to do it in the standard version of tensorflow. I encoded the images as png strings and used the new Java API 1.4 to feed a batch of these strings to my tensorflow model. There I first decoded the png string to get back the image.

Unfortunately, this does not work on Android. There are several problems:
* png encoding is not available (I then used .bmp; but that has no grayscale support; I then made my gray image colored and make it gray again in the model (https://github.com/tensorflow/tensorflow/issues/13942) )
* The Android API does not seem to be able to handle string tensors (https://github.com/tensorflow/tensorflow/issues/14291)

So my question is, if it is possible to feed a model with a batch of differently sized images via the C/C++ or Java API on Android."
14365,Unable to read saved model from SMB directory,"I am using Tensorflow GPU version 1.1.0, my model can run well if I save it to computer 's hard drives. However, if I save checkpoint files to a samba network drive, I can not restore it and here are the logs.


2017-11-08 17:25:27.795833: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)
2017-11-08 17:26:13.335734: W tensorflow/core/framework/op_kernel.cc:1152] Unavailable: /path/to/network/drive/runs/1510129519/checkpoints/model-100.index
2017-11-08 17:26:13.339605: W tensorflow/core/framework/op_kernel.cc:1152] Unknown: /path/to/network/drive/runs/1510129519/checkpoints/model-100.index; Input/output error
2017-11-08 17:26:13.361089: W tensorflow/core/framework/op_kernel.cc:1152] Unavailable: /path/to/network/drive/runs/1510129519/checkpoints/model-100.index
	 [[Node: save/RestoreV2_2 = RestoreV2[dtypes=[DT_INT32], _device=""/job:localhost/replica:0/task:0/cpu:0""](_recv_save/Const_0, save/RestoreV2_2/tensor_names, save/RestoreV2_2/shape_and_slices)]]
^C^C^C^C^C^C2017-11-08 17:26:58.362630: W tensorflow/core/framework/op_kernel.cc:1152] Unavailable: /path/to/network/drive/runs/1510129519/checkpoints/model-100.index

Many thanks"
14364,What is the instruction of checking which version of cuda and cudnn the tensorflow is running on?,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:1.4
- **Python version**: 2.7
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:8.0/6.0
- **GPU model and memory**:Tesla P100-PCIE-16GB
- **Exact command to reproduce**:



### Describe the problem

What is the instruction of checking which version of cuda and cudnn the tensorflow is running on?
like the tensorflow version could be checked by the instruction tf.__version__ .
I want to check my tensorflow 1.4 running on the 8.0 cuda and 6.0 cudnn, not running on the 9.0 cuda and 7.0 cudnn.


"
14363,Failed to synchronize the stop event,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04

- **TensorFlow installed from (source or binary)**:
source

- **TensorFlow version (use command below)**:
b'v1.4.0-0-gd752244' 1.4.0

- **Python version**: 
3.5.2

- **Bazel version (if compiling from source)**:
0.7.0

- **GCC/Compiler version (if compiling from source)**:
gcc (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609

- **CUDA/cuDNN version**:
9.0/7.0

- **GPU model and memory**:
Tesla V100-SXM2-16GB

- **Exact command to reproduce**:
```
git clone https://github.com/ljanyst/image-segmentation-fcn.git
cd image-segmentation-fcn                                       
wget http://www.cvlibs.net/download.php?file=data_road.zip
unzip data_road.zip                                     
./train.py  --data-dir data_road
````
### Describe the problem
It seems like I am hitting some sort of a CUDA/cuDNN synchronization/race issue. Please see the snippet in the next section for the exact error message. The problem only happens with the KITTI dataset. The exact same TensorFlow code works fine for the Cityscapes dataset. Also, the problem only happens on Tesla V100. I tested the same exact software configuration on Tesla K80 and GeForce GTX1080 Ti as well, and things work fine.

### Source code / logs
```
2017-11-08 12:24:52.838039: E tensorflow/stream_executor/cuda/cuda_driver.cc:1080] failed to synchronize the stop event: CUDA_ERROR_ILLEGAL_ADDRESS
2017-11-08 12:24:52.838090: E tensorflow/stream_executor/cuda/cuda_timer.cc:54] Internal: error destroying CUDA event in context 0x51f18f0: CUDA_ERROR_ILLEGAL_ADDRESS
2017-11-08 12:24:52.838106: E tensorflow/stream_executor/cuda/cuda_timer.cc:59] Internal: error destroying CUDA event in context 0x51f18f0: CUDA_ERROR_ILLEGAL_ADDRESS
2017-11-08 12:24:52.838137: F tensorflow/stream_executor/cuda/cuda_dnn.cc:3218] failed to set stream for cudnn handle: CUDNN_STATUS_MAPPING_ERROR
zsh: abort (core dumped)  ./train.py --data-dir data_road
```
"
14361,tf.name_scope() is not propagated to variables created by Keras layers,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: YES
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS 10.12.6
- **TensorFlow installed from (source or binary)**: BINARY
- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**: 3.5.4
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

### Describe the problem
When using Keras layers in combination with `tf.name_scope(a_name)`, `a_name` is added to the name of the layers. I would also expect it to be added to the name of the weights/variables that Keras creates internally. However, that is not the case. Having an automatic way of adding a name scope to the weights is highly desirable, though.

### Source code / logs
```
with tf.name_scope(""test""):
     a = tf.keras.layers.Input(shape=(5,))
     b = tf.keras.layers.Dense(5)(a)
```

_Output_:

Executing `a.name` returns `test/input_1:0` as expected. 

`tf.trainable_variables()` returns:
`[<tf.Variable 'dense/kernel:0' shape=(5, 5) dtype=float32_ref>, <tf.Variable 'dense/bias:0' shape=(5,) dtype=float32_ref>]`"
14360,Cannot build TF 1.4 with CUDNN 1.4,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Centos 7
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.4
- **Python version**: 3.4.5 
- **Bazel version (if compiling from source)**: 0.7.0- (@non-git)
- **GCC/Compiler version (if compiling from source)**: 4.9
- **CUDA/cuDNN version**: 8.0/5.0.5
- **GPU model and memory**: Tesla K80
- **Exact command to reproduce**: bazel build --config=opt --config=cuda --config=mkl //tensorflow/tools/pip_package:build_pip_packag

### Describe the problem

I'm trying to install Tensorflow 1.4 from sources with CUDA 8.0 and CUDNN 5.0.5. It's indicated in the documentation that it should work with CUDNN 3 and higher. 

Unfortunately, it doesn't work and ends up with an error that seems to indicate that CUDNN v6 is needed (I may be wrong on the cause of the error). 

Here is the error:

```
ERROR: /home/localuser/tensorflow/tensorflow/stream_executor/BUILD:52:1: C++ compilation of rule '//tensorflow/stream_executor:cuda_platform' failed (Exit 1).
tensorflow/stream_executor/cuda/cuda_dnn.cc: In member function 'cudnnStatus_t perftools::gputools::cuda::wrap::WrapperShim__cudnnSetRNNDescriptor_v6::operator()(perftools::gputools::cuda::CUDAExecutor*, Args ...)':
tensorflow/stream_executor/cuda/cuda_dnn.cc:140:30: error: '::cudnnSetRNNDescriptor_v6' has not been declared
       cudnnStatus_t retval = ::__name(args...);                    \
                              ^
tensorflow/stream_executor/cuda/cuda_dnn.cc:235:3: note: in expansion of macro 'PERFTOOLS_GPUTOOLS_CUDNN_WRAP'
   __macro(cudnnSetRNNDescriptor_v6)                           \
   ^
tensorflow/stream_executor/cuda/cuda_dnn.cc:240:1: note: in expansion of macro 'CUDNN_DNN_ROUTINE_EACH_R5'
 CUDNN_DNN_ROUTINE_EACH_R5(PERFTOOLS_GPUTOOLS_CUDNN_WRAP)
```

Is there anything I can do to install TF 1.4 using CUDNN 5 ?

Thanks"
14359,Keras model.trainable_weights does not return all trainable weights,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: YES
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS 10.12.6
- **TensorFlow installed from (source or binary)**: BINARY
- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**: 3.5.4
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

### Describe the problem
When creating a Keras model where two ""towers"" are merged with help of a Lambda layer, not all trainable weights are added to `trainable_weights`.

### Source code / logs
The code below creates a model with four trainable variables: 2 weights and 2 biases. However, `model.trainable_weights` returns only one weight and one bias. 

```
def func(x,y):
    return tf.add(x,y)

a= tf.keras.layers.Input(shape= (64,))
b = tf.keras.layers.Dense(5)(a)
c = tf.keras.layers.Dense(5)(a)
d = tf.keras.layers.Lambda(func, arguments={'y':c})(b)
model = tf.keras.models.Model(a, d)
model.trainable_weights
```
_Output_:
`[<tf.Variable 'dense/kernel:0' shape=(64, 5) dtype=float32_ref>, <tf.Variable 'dense/bias:0' shape=(5,) dtype=float32_ref>]
`"
14358,Not found Op type not registered 'CountExtremelyRandomStats',"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: 
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS sierra 10.12.6
- **TensorFlow installed from (source or binary)**:source
- **TensorFlow version (use command below)**: 1.3
- **Python version**: 3.5.2
- **Bazel version (if compiling from source)**: 0.5.4
- **GCC/Compiler version (if compiling from source)**: 
- **CUDA/cuDNN version**:NA
- **GPU model and memory**: NA
- **Exact command to reproduce**: 
bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_name=rf_quora --model_base_path=/serving/rf_model &> rf_log &

You can collect some of this information using our environment capture script:
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

== cat /etc/issue ===============================================
Darwin xxxxxxxxxx 16.7.0 Darwin Kernel Version 16.7.0: Thu Jun 15 17:36:27 PDT 2017; root:xnu-3789.70.16~2/RELEASE_X86_64 x86_64
Mac OS X 10.12.6

== are we in docker =============================================
No

== compiler =====================================================
Apple LLVM version 9.0.0 (clang-900.0.38)
Target: x86_64-apple-darwin16.7.0
Thread model: posix
InstalledDir: /Library/Developer/CommandLineTools/usr/bin

== uname -a =====================================================
Darwin xxxxxxxxxx 16.7.0 Darwin Kernel Version 16.7.0: Thu Jun 15 17:36:27 PDT 2017; root:xnu-3789.70.16~2/RELEASE_X86_64 x86_64

== check pips ===================================================
numpy (1.13.1)
protobuf (3.4.0)
tensorflow (1.3.0)
tensorflow-tensorboard (0.1.8)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.3.0
tf.GIT_VERSION = v1.3.0-rc2-20-g0787eee
tf.COMPILER_VERSION = v1.3.0-rc2-20-g0787eee
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
abc.sh: line 105: nvidia-smi: command not found

== cuda libs  ===================================================


### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

 I am getting the following error while running bazel command in the docker container.
command ran :- 
bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_name=rf_quora --model_base_path=/serving/rf_model &> rf_log &error:- Not found: Op type not registered 'CountExtremelyRandomStats' in binary running on 864822af1c6c. Make sure the Op and Kernel are registered in the binary running in this process.

I tried my search with the following link but in vain. https://github.com/tensorflow/tensorflow/issues/11847

I am trying to do inference using tensorflow tensorserving, but I am getting blocked by the above error. 
Using Tensorflow 1.3 and using tensor_forest api present in tf.contrib.tensor_forest_python.
Can anyone help me with this error as it is blocking my testing. Note:- I have successfully ran tensorserving inference for mnist and inception examples models.
-- | --

### Source code / logs
2017-11-08 07:27:45.038637: I tensorflow_serving/model_servers/main.cc:147] Building single TensorFlow model file config:  model_name: rf_quora model_base_path: /serving/rf_model
2017-11-08 07:27:45.038846: I tensorflow_serving/model_servers/server_core.cc:441] Adding/updating models.
2017-11-08 07:27:45.038879: I tensorflow_serving/model_servers/server_core.cc:492]  (Re-)adding model: rf_quora
2017-11-08 07:27:45.140519: I tensorflow_serving/core/basic_manager.cc:705] Successfully reserved resources to load servable {name: rf_quora version: 1}
2017-11-08 07:27:45.140575: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: rf_quora version: 1}
2017-11-08 07:27:45.140608: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: rf_quora version: 1}
2017-11-08 07:27:45.140647: I external/org_tensorflow/tensorflow/contrib/session_bundle/bundle_shim.cc:360] Attempting to load native SavedModelBundle in bundle-shim from: /serving/rf_model/1
2017-11-08 07:27:45.140685: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:236] Loading SavedModel from: /serving/rf_model/1
2017-11-08 07:27:45.159712: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2017-11-08 07:27:45.192628: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:284] Loading SavedModel: fail. Took 51931 microseconds.
2017-11-08 07:27:45.192711: E tensorflow_serving/util/retrier.cc:38] Loading servable: {name: rf_quora version: 1} failed: Not found: Op type not registered 'CountExtremelyRandomStats' in binary running on 864822af1c6c. Make sure the Op and Kernel are registered in the binary running in this process.
"
14357,Following instructions in batch_normalization docs produces an exception,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 17.10
- **TensorFlow installed from (source or binary)**: Binary (pip install tensorflow)
- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**: 3.6.3
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: (see the ""Source code"" section)

### Describe the problem
I was following the instructions for updating `moving_mean` and `moving_variance` by using the code snippet provided in [batch_normalization documentation](https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization) and it resulted in an ""tensorflow.python.framework.errors_impl.InvalidArgumentError: Retval[0] does not have value"" exception.

### Source code / logs

Full instructions to reproduce: 

    git clone -b control-dependencies-exc https://github.com/naktinis/language-id.git ctrl-dep-exc
    cd ctrl-dep-exc/
    python3 -m venv venv
    . venv/bin/activate
    pip install tensorflow==1.4.0 Pillow
    python3 main.py --image-dir test_data/ --label-file test_data/labels.csv --model rnn

The specific code change that was enough to produce the exception (seems to match the snippet in the official [documentation](https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization)):
https://github.com/naktinis/language-id/commit/50740f

Full exception:
```
Traceback (most recent call last):
  File ""main.py"", line 173, in <module>
    tf.app.run(main=run_experiment)
  File ""/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""main.py"", line 165, in run_experiment
    hparams=params,
  File ""/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/learn_runner.py"", line 218, in run
    return _execute_schedule(experiment, schedule)
  File ""/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/learn_runner.py"", line 46, in _execute_schedule
    return task()
  File ""/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/experiment.py"", line 625, in train_and_evaluate
    self.train(delay_secs=0)
  File ""/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/experiment.py"", line 367, in train
    hooks=self._train_monitors + extra_hooks)
  File ""/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/experiment.py"", line 807, in _call_train
    hooks=hooks)
  File ""/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 302, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 783, in _train_model
    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])
  File ""/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 521, in run
    run_metadata=run_metadata)
  File ""/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 892, in run
    run_metadata=run_metadata)
  File ""/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 967, in run
    raise six.reraise(*original_exc_info)
  File ""/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/six.py"", line 693, in reraise
    raise value
  File ""/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 952, in run
    return self._sess.run(*args, **kwargs)
  File ""/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 1024, in run
    run_metadata=run_metadata)
  File ""/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 827, in run
    return self._sess.run(*args, **kwargs)
  File ""/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 889, in run
    run_metadata_ptr)
  File ""/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1120, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1317, in _do_run
    options, run_metadata)
  File ""/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1336, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Retval[0] does not have value

```"
14356,Keras application - Tensor is not an element of this graph on eval after train,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS 10.13.1
- **TensorFlow installed from (source or binary)**: pip
- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**: 3.6.3
- **CUDA/cuDNN version**: N/A CPU only
- **Exact command to reproduce**:

### Describe the problem
Using the estimator API and using `tf.keras.applications.VGG16` and it's output for transfer learning, I get an exception raised of `TypeError: Cannot interpret feed_dict key as Tensor: Tensor Tensor(""vgg_base/Placeholder:0"", shape=(3, 3, 3, 64), dtype=float32) is not an element of this graph.` when the model is run a second time. 

This is raised when it runs the eval step after train from `tf.estimator.train_and_evaluate`. See source code for model and estimator output. This also occurs if I re-run the train_and_evaluate a second time. I am running in a Jupyter notebook and my assumption about memory is that if I do a Kernel ➝ Restart it will run a training run again without the error, but cannot be run in two executions without this.

See https://github.com/damienpontifex/fastai-course/blob/master/deeplearning1/lesson1%2B3/DogsVsCats.ipynb for full notebook, but main parts for estimator model and output are below:

### Source code / logs
#### Estimator Model
```python
def vgg16_model_fn(features, mode, params):
    
    is_training = mode == tf.estimator.ModeKeys.TRAIN
    
    with tf.variable_scope('vgg_base'):
        # Use a pre-trained VGG16 model and drop off the top layers as we will retrain 
        # with our own dense output for our custom classes
        vgg16_base = tf.keras.applications.VGG16(
            include_top=False,
            input_shape=(224, 224, 3),
            input_tensor=features['image'],
            pooling='avg')

        # Disable training for all layers to increase speed for transfer learning
        # If new classes significantely different from ImageNet, this may be worth leaving as trainable = True
        for layer in vgg16_base.layers:
            layer.trainable = False

        x = vgg16_base.output
    
    with tf.variable_scope(""fc""):
        x = tf.layers.flatten(x)
        x = tf.layers.dense(x, units=4096, activation=tf.nn.relu, trainable=is_training, name='fc1')
        x = tf.layers.dense(x, units=4096, activation=tf.nn.relu, trainable=is_training, name='fc2')
        x = tf.layers.dropout(x, rate=0.5, training=is_training)
        
    # Finally add a 2 dense layer for class predictions
    with tf.variable_scope(""Prediction""):
        x = tf.layers.dense(x, units=NUM_CLASSES, trainable=is_training)
        return x
```
#### Estimator setup
```python
dog_cat_estimator = tf.estimator.Estimator(
    model_fn=model_fn,
    config=run_config,
    params=params
)
train_spec = tf.estimator.TrainSpec(
    input_fn=data_input_fn(train_record_filenames, num_epochs=None, batch_size=10, shuffle=True), 
    max_steps=10)
eval_spec = tf.estimator.EvalSpec(
    input_fn=data_input_fn(validation_record_filenames)
)
tf.estimator.train_and_evaluate(dog_cat_estimator, train_spec, eval_spec)
```
#### train_and_evaluate output
```
INFO:tensorflow:Running training and evaluation locally (non-distributed).
INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 600 secs (eval_spec.throttle_secs) or training is finished.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Restoring parameters from /tmp/DogsVsCats/model.ckpt-1
INFO:tensorflow:Saving checkpoints for 2 into /tmp/DogsVsCats/model.ckpt.
INFO:tensorflow:loss = 0.0, step = 2
INFO:tensorflow:Saving checkpoints for 10 into /tmp/DogsVsCats/model.ckpt.
INFO:tensorflow:Loss for final step: 0.0.
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
   1063             subfeed_t = self.graph.as_graph_element(subfeed, allow_tensor=True,
-> 1064                                                     allow_operation=False)
   1065           except Exception as e:

/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in as_graph_element(self, obj, allow_tensor, allow_operation)
   3034     with self._lock:
-> 3035       return self._as_graph_element_locked(obj, allow_tensor, allow_operation)
   3036 

/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in _as_graph_element_locked(self, obj, allow_tensor, allow_operation)
   3113       if obj.graph is not self:
-> 3114         raise ValueError(""Tensor %s is not an element of this graph."" % obj)
   3115       return obj

ValueError: Tensor Tensor(""vgg_base/Placeholder:0"", shape=(3, 3, 3, 64), dtype=float32) is not an element of this graph.

During handling of the above exception, another exception occurred:

TypeError                                 Traceback (most recent call last)
<ipython-input-12-67c818ea66c5> in <module>()
----> 1 tf.estimator.train_and_evaluate(dog_cat_estimator, train_spec, eval_spec)

/usr/local/lib/python3.6/site-packages/tensorflow/python/estimator/training.py in train_and_evaluate(estimator, train_spec, eval_spec)
    428       config.task_type != run_config_lib.TaskType.EVALUATOR):
    429     logging.info('Running training and evaluation locally (non-distributed).')
--> 430     executor.run_local()
    431     return
    432 

/usr/local/lib/python3.6/site-packages/tensorflow/python/estimator/training.py in run_local(self)
    614       # condition is satisfied (both checks use the same global_step value,
    615       # i.e., no race condition)
--> 616       metrics = evaluator.evaluate_and_export()
    617 
    618       if not metrics:

/usr/local/lib/python3.6/site-packages/tensorflow/python/estimator/training.py in evaluate_and_export(self)
    749           name=self._eval_spec.name,
    750           checkpoint_path=latest_ckpt_path,
--> 751           hooks=self._eval_spec.hooks)
    752 
    753       if not eval_result:

/usr/local/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in evaluate(self, input_fn, steps, hooks, checkpoint_path, name)
    353         hooks=hooks,
    354         checkpoint_path=checkpoint_path,
--> 355         name=name)
    356 
    357   def _convert_eval_steps_to_hooks(self, steps):

/usr/local/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in _evaluate_model(self, input_fn, hooks, checkpoint_path, name)
    808           input_fn, model_fn_lib.ModeKeys.EVAL)
    809       estimator_spec = self._call_model_fn(
--> 810           features, labels, model_fn_lib.ModeKeys.EVAL, self.config)
    811 
    812       if model_fn_lib.LOSS_METRIC_KEY in estimator_spec.eval_metric_ops:

/usr/local/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in _call_model_fn(self, features, labels, mode, config)
    692     if 'config' in model_fn_args:
    693       kwargs['config'] = config
--> 694     model_fn_results = self._model_fn(features=features, **kwargs)
    695 
    696     if not isinstance(model_fn_results, model_fn_lib.EstimatorSpec):

<ipython-input-8-e251e8b8fccf> in model_fn(features, labels, mode, params)
      3     tf.summary.image('images', features['image'], max_outputs=6)
      4 
----> 5     logits = vgg16_model_fn(features, mode, params)
      6 
      7     # Dictionary with label as outcome with greatest probability

<ipython-input-7-93330b8a5aa6> in vgg16_model_fn(features, mode, params)
     10             input_shape=(224, 224, 3),
     11             input_tensor=features['image'],
---> 12             pooling='avg')
     13 
     14         # Disable training for all layers to increase speed for transfer learning

/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/applications/vgg16.py in VGG16(include_top, weights, input_tensor, input_shape, pooling, classes)
    199           WEIGHTS_PATH_NO_TOP,
    200           cache_subdir='models')
--> 201     model.load_weights(weights_path)
    202     if K.backend() == 'theano':
    203       layer_utils.convert_all_kernels_in_model(model)

/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/topology.py in load_weights(self, filepath, by_name)
   1097       load_weights_from_hdf5_group_by_name(f, self.layers)
   1098     else:
-> 1099       load_weights_from_hdf5_group(f, self.layers)
   1100 
   1101     if hasattr(f, 'close'):

/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/topology.py in load_weights_from_hdf5_group(f, layers)
   1484                        str(len(weight_values)) + ' elements.')
   1485     weight_value_tuples += zip(symbolic_weights, weight_values)
-> 1486   K.batch_set_value(weight_value_tuples)
   1487 
   1488 

/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py in batch_set_value(tuples)
   2404       assign_ops.append(assign_op)
   2405       feed_dict[assign_placeholder] = value
-> 2406     get_session().run(assign_ops, feed_dict=feed_dict)
   2407 
   2408 

/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)
    887     try:
    888       result = self._run(None, fetches, feed_dict, options_ptr,
--> 889                          run_metadata_ptr)
    890       if run_metadata:
    891         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
   1065           except Exception as e:
   1066             raise TypeError('Cannot interpret feed_dict key as Tensor: '
-> 1067                             + e.args[0])
   1068 
   1069           if isinstance(subfeed_val, ops.Tensor):

TypeError: Cannot interpret feed_dict key as Tensor: Tensor Tensor(""vgg_base/Placeholder:0"", shape=(3, 3, 3, 64), dtype=float32) is not an element of this graph.
```
"
14355,Java API and Node.js: java.lang.IllegalArgumentException: graphDef and prefix cannot be null,"I'm using [node-java](https://github.com/joeferner/node-java) to run the JAVA API within a `Node.js` application. Most of the work is done in Java, but I have some issues when loading the graph through node using the Java api `graph.importGraphDef` I get a `java.lang.IllegalArgumentException: graphDef and prefix cannot be null`.
I'm loading the inception graph as a binary file `tensorflow_inception_graph.pb` and passing it to the api like:

```javascript
var graph = java.newInstanceSync(""org.tensorflow.Graph"");
var builder = java.newInstanceSync(""org.example.GraphBuilder"", graph);

const getBinary = (graphPath, asBuffer = false, cb) => {
    let readStream = fs.createReadStream(graphPath)
    let data = ''
    readStream.setEncoding('binary')
    readStream.once('error', err => {
        return cb(err)
    })
    readStream.on('data', chunk => (data += chunk))
    readStream.on('end', () => {
        return cb(null, asBuffer ? Buffer.from(data, 'binary') : data)
    })
}

getBinary(graphPath, true, (error, graphDef) => {
    console.log(""type is"", typeof(graphDef));
    console.log(""read graph %d"", graphDef.length);
    graph.importGraphDefSync(graphDef, """");
});
```

The graph object is loaded by `Node.js` since I can see its bytes length in the logs:
The output is:

```bash
Tensorflow.getVersion: 1.4.0
2017-11-08 09:59:51.249872: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.2 AVX AVX2 FMA
type is object
read graph 53884595
/MyProject/tensorflow/index.js:106
                        graph.importGraphDefSync(graphDef,"""");
                              ^

Error: Error running instance method
java.lang.IllegalArgumentException: graphDef and prefix cannot be null
	at org.tensorflow.Graph.importGraphDef(Graph.java:127)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)

    at Error (native)
    at getBinary (/MyProject/tensorflow/index.js:106:31)
    at ReadStream.readStream.on (/MyProject/tensorflow/index.js:99:34)
    at emitNone (events.js:91:20)
    at ReadStream.emit (events.js:185:7)
    at endReadableNT (_stream_readable.js:974:12)
    at _combinedTickCallback (internal/process/next_tick.js:74:11)
    at process._tickCallback (internal/process/next_tick.js:98:9)
```"
14353,variance goes negative when set layers.batch_norm reuse=True,"#### TF 1.2.1 running on cpu & distributed version

#### layers.batch_norm set reuse=True
I use a sequence of items features which contains n (feature length) * N (sequence length) real-value features. And do batch_norm on each item of the sequence, then do some full_connected, etc. Finally concat them as dnn input.
Here is a simple code of the this. In order to make variance quickly go negative, I set decay=0.6.

	import tensorflow as tf
	from tensorflow.contrib import layers
	import numpy as np
	
	seq_length = 1000
	batch = 100
	length = 3
	place_holders = []
	seq_raw_f = []
	for i in range(seq_length):
	  x = True if i != 0 else None
	  sequence_place_holder = tf.placeholder(dtype=tf.float32, shape=[None, length])
	  place_holders.append(sequence_place_holder)
	  sequence = layers.batch_norm(inputs=sequence_place_holder, scope=""bn"", reuse=x, decay=0.6, scale=True,
	                               # updates_collections=None,
	                               zero_debias_moving_mean=True)
	  seq_raw_f.append(sequence)
	
	input = tf.concat(seq_raw_f, axis=0)
	
	update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)
	
	sess = tf.Session()
	sess.run(tf.initialize_all_variables())
	
	place_holder = {}
	for i in range(seq_length):
	  place_holder[place_holders[i]] = np.random.rand(batch, length)
	
	for i in range(10000):
	  sess.run(update_ops, place_holder)
	  # sess.run(input, place_holder)
	  print sess.run(""bn/moving_variance:0"")
	  
#### variance can be :

	[ 0.08063364  0.08680637  0.08229597]
	[ 0.09141719  0.08313672  0.08208766]
	[ 0.07279671  0.08088712  0.08174741]
	[-0.1192904  -0.13598624 -0.31083935]
	[ 0.24966593  0.26548591  0.16420737]
	[ 0.07931737  0.07920683  0.0833094 ]
	[ 0.08559028  0.08299339  0.08146621]
	[ 0.08117087  0.08168832  0.08265808]
	

#### Reason probably the code below. 
When reuse=True, this code will subtract update_delta many times according to reuse times. Then the formula goes wrong. `a * m_v - (1-a) v -> a * m_v -N * (1-a) v.`
	
	update_delta = (variable - value) * decay
	return state_ops.assign_sub(variable, update_delta, name=scope)
	
when, updates_collections=None,  to force update variance, it still happened.

#### temporary fix
     
     if not zero_debias:
       # variable * decay + value * (1 - decay)
       state_ops.assign(variable, variable * decay + value * (1 - decay))

	

"
14352,How can I export the model as serving format?,"# I want to get the serving model format for using server.
To export estimator m there are four steps:
1.Define estimator's features.

2.Create a feature config.

3.Build an export_input_fn suitable for use in serving.

4.Export the model using export_savedmodel().


I try to use ：
    export_dir_base = ""./serving_save_model""
    feature_spec = {
                    'times': tf.placeholder(tf.float32, name='times')
                    }
    serving_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)

    estimator.export_savedmodel(export_dir_base, serving_input_fn)

But I encountered an error like this:

Traceback (most recent call last):
  File ""E:/MyProject/Py/tensorFlow_time_series_predict/train_lstm_multivariate.py"", line 231, in <module>
    estimator.export_savedmodel(export_dir_base, serving_input_fn)
  File ""H:\ProgramFiles\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\estimator\estimator.py"", line 504, in export_savedmodel
    serving_input_receiver = serving_input_receiver_fn()
  File ""H:\ProgramFiles\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\estimator\export\export.py"", line 142, in serving_input_receiver_fn
    features = parsing_ops.parse_example(serialized_tf_example, feature_spec)
  File ""H:\ProgramFiles\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\ops\parsing_ops.py"", line 577, in parse_example
    [VarLenFeature, SparseFeature, FixedLenFeature, FixedLenSequenceFeature])
  File ""H:\ProgramFiles\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\ops\parsing_ops.py"", line 291, in _features_to_raw_params
    raise ValueError(""Invalid feature %s:%s."" % (key, feature))
ValueError: Invalid feature times:Tensor(""times:0"", dtype=float32).


How should I use it correctly?
Thanks so much！
"
14349,The efficiency of data access,"   
def test_tf():
    with  tf.Session() as sess:
        array=tf.ones([1024,5],dtype=tf.float32) 
        t0=time.clock()
        out=0
        for i in range(array.shape[0]):
            out+=array[i]
        out=sess.run([out])
        t1=time.clock()
        print(""test_tf:"",out,t1-t0)  
     
def test_np():
    array=np.ones((1024,5),dtype=np.float32)
    print array.shape
    t0=time.clock()
    out=0
    for i in range(array.shape[0]):
        out+=array[i]
    t1=time.clock()
    print(""test_np:"",out,t1-t0)  
                        
console output:
('test_tf:', [array([ 1024.,  1024.,  1024.,  1024.,  1024.], dtype=float32)], 2.395962)
(1024, 5)
('test_np:', array([ 1024.,  1024.,  1024.,  1024.,  1024.], dtype=float32), 0.0008499999999997954)

how to speed up the data access?"
14348,how to use java client to request tensorflow serving for wide&deep model or how to use java to load wide&deep model and predict?,"i have write python client to request wide&deep model by tensorflow serving successful, but i am am doubt how to use java to resolve it, because example and document is too lack"
14347,Is my code right to use batch normalization layers in tensorflow?,"I have two inputs: `qi_pos & qi_neg` with the same shape. They should be processed by the two mlp layers, and finally get two results which acts as score. Here is my codes:
```
  self.mlp1_pos  =    nn_layers.full_connect_(qi_pos,        256, activation='relu', use_bn = None, keep_prob=self.keep_prob,  name = 'deep_mlp_1')
  self.mlp2_pos  =    nn_layers.full_connect_(self.mlp1_pos, 128,  activation='relu', use_bn = True, keep_prob=self.keep_prob,  name = 'deep_mlp_2')
  self.pos_pair_sim = nn_layers.full_connect_(self.mlp2_pos,  1,  activation=None, use_bn = True, keep_prob=self.keep_prob,  name = 'deep_mlp_3')
  tf.get_variable_scope().reuse_variables()
  self.mlp1_neg  =    nn_layers.full_connect_(qi_neg,        256, activation='relu', use_bn = None, keep_prob=self.keep_prob,  name = 'deep_mlp_1')
  self.mlp2_neg  =    nn_layers.full_connect_(self.mlp1_neg, 128,  activation='relu', use_bn = True, keep_prob=self.keep_prob,  name = 'deep_mlp_2')
  self.neg_pair_sim = nn_layers.full_connect_(self.mlp2_neg,  1,  activation=None, use_bn = True, keep_prob=self.keep_prob,  name = 'deep_mlp_3')
```

I use BN layer to normalize the nodes in hidden layers:

```
def full_connect_(inputs, num_units, activation=None, use_bn = None, keep_prob = 1.0, name='full_connect_'):
  with tf.variable_scope(name):
    shape = [inputs.get_shape()[-1], num_units]
    weight = weight_variable(shape)
    bias = bias_variable(shape[-1])
    outputs_ = tf.matmul(inputs, weight) + bias
    if use_bn:
        outputs_ = tf.contrib.layers.batch_norm(outputs_, center=True, scale=True, is_training=True,decay=0.9,epsilon=1e-5, scope='bn')
    if activation==""relu"":
      outputs = tf.nn.relu(outputs_)
    elif activation == ""tanh"":
      outputs = tf.tanh(outputs_)
    elif activation == ""sigmoid"":
      outputs = tf.nn.sigmoid(outputs_)
    else:
      outputs = outputs_
    return  outputs

   with tf.name_scope('predictions'):
      self.sim_diff = self.pos_pair_sim - self.neg_pair_sim # shape = (batch_size, 1)
      self.preds = tf.sigmoid(self.sim_diff) # shape = (batch_size, 1)
      self.infers = self.pos_pair_sim
```

Below is the loss definition.It seems all right.

with tf.name_scope('predictions'):
  sim_diff = pos_pair_sim - neg_pair_sim
  predictions = tf.sigmoid(sim_diff)
  self.infers = pos_pair_sim
## loss and optim
with tf.name_scope('loss'):
  self.loss = nn_layers.cross_entropy_loss_with_reg(self.labels, self.preds)
  tf.summary.scalar('loss', self.loss)

I am not sure whether I have use the BN layers in right way. I mean that the BN parameters are derived from the hidden units from the two separate parts, which are based on qi_pos and qi_neg tensors as inputs. Anyway, anyone could help check it ?"
14346,how to use java client to request tensorflow serving for wide&deep model or how to use java to load wide&deep model and predict?,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
14345,CUBLAS_STATUS_ALLOC_FAILED when attempting to train linear regressor,"### System information
- This is my code.
- Windows 10 x64
- installed tensorflow using pip
- tensorflow-gpu v1.4.0
- Python 3.6.0
- CUDA v8.0, Cudunn v6.0
- EVGA GTX 980 SC ATX 4GB

### Describe the problem
Whenever I try to train a linear regression network with this dataset, it gives me a CUDA error saying CUBLAS_STATUS_ALLOC_FAILED. I suspect it's not because I'm using too much memory, as when it does occasionally work, it always maxes out my gpu memory usage, no matter what size the network is.
I've included my script and my data file that i ran it with, and a log of the error occurring.
[error.log](https://github.com/tensorflow/tensorflow/files/1452557/error.log)
Here is my source:
[predictlaptimes.txt](https://github.com/tensorflow/tensorflow/files/1452561/predictlaptimes.txt)
(just pretend it's a python file)
And here's my data:
[carnumbers.txt](https://github.com/tensorflow/tensorflow/files/1452562/carnumbers.txt)
pretend it's a csv file.
Github won't let me upload .py or .csv files for some reason.

----

Looking online I found a solution by changing the allow_growth option to True. I added this line to my code;

    regressor._session_options.gpu_options.allow_growth = True

And now it runs without any problems."
14342,[Feature Request] Add payload only compression support for TFRecord files,"This feature request is a follow up to PR #12369 and issue #12344.

Issue #12344 raised the feature request of supporting gzipped TFRecord files. However, the compression means the TFRecord file is gzipped as a whole and the header is compressed as well.

In certain situations, it might be desirable to expose the header and only compress the payload for better visibility and lookup performance.

This issue is a feature request to support payload only compression for TFRecord files."
14334,Float16 not supported by Maxpool3D,"I was trying to switch the training of my neural net to Mixed-precision but while conv/deconv3d layers are supporting the float16 type,  Maxpool3D layers still require a float32 input. Can we expect these to support float16 precision soon?

Thanks!"
14328,"DataLossError (see above for traceback): corrupted record at 46064268          [[Node: parallel_read/ReaderReadV2_2 = ReaderReadV2[_device=""/job:localhost/replica:0/task:0/cpu:0""](parallel_read/TFRecordReaderV2_2, parallel_read/filenames)]]","I am trying to train AlexNet from scratch through slim (https://github.com/tensorflow/models/tree/master/research/slim). 
My setup is Python 2.7.12, Tensorflow 1.0.0, in a Linux16.04 system. Below is my error report after 3 hours training.
![screen shot 2017-11-07 at 12 57 15](https://user-images.githubusercontent.com/15274537/32509450-53bbcde2-c3bb-11e7-9dcb-e5fa2eab2783.png)
A similar problem also exists when I train vgg_16 using slim. May I know how to solve this?"
14327,Mixed precision not enabled with TF1.4 on Tesla V100,"Hi there,

I was interested in testing my neural net (an Autoencoder that serves as a generator + a CNN as a discriminator)  that uses 3dconv/deconv layers with the new Volta architecture and benefit from the Mixed-Precision training. I compiled the most recent source code of Tensorflow 1.4 with CUDA 9 and CudNN 7.0 and cast all the trainable variables used by my conv/deconv layers to tf.float16. Also, all my input and output tensors have sizes that are multiple of 8. 

I have two issues so far:
- I do not see any substantial speed improvement, the training time is roughly similar to when using tf.float32. My understanding is that with the Volta and cuDNN 7.0, Mixed Precision should be  automatically detected by TF and hence should use Tensor Core math. Am I wrong, or is there anything I should do to enable it? FYI, I also tried the TF1.5 nighlty build, and it seems that it is even slower than my custom 1.4.
- I also noticed that the Maxpool3D layers are not supporting TF.float16 yet and need a float32 input. Any plan to change that anytime soon ?

Thanks for your support!"
14325,Issue while importing tensorflow,"I am trying to import tensorflow in Ubuntu 14.04 having cuda 7.5 installed. I am using tensorflow 1.4. There is issue related to
 importerror: libcudart.so.8.0: cannot open shared object file: no such file or directory.
Kindly help!!
![screenshot from 2017-11-07 17-31-46 1](https://user-images.githubusercontent.com/33459515/32506944-dd8f450e-c3dd-11e7-91b8-0870e086f137.png)
"
14324,input_dims not a constant expression in slice_op.cc ,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Debian 9.0 (with a Gentoo Prefix)
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: c81acfb025abe417d80ffa677edfe2dd1bcda58e (15 hours old)
- **Python version**: 3.6.3
- **Bazel version (if compiling from source)**: 0.6.1
- **GCC/Compiler version (if compiling from source)**: 6.4.0
- **CUDA/cuDNN version**: no CUDA
- **GPU model and memory**: no GPU
- **Exact command to reproduce**: bazel build --config=mkl --config=opt //tensorflow/tools/pip_package:build_pip_package

### Describe the problem
It seems that 8011eda4b7 merged a C++ error in file [tensorflow/core/kernels/slice_op.cc line 255](https://github.com/tensorflow/tensorflow/blob/db430c4bb275e05ee65dc27c7f771f778bfcbcf2/tensorflow/core/kernels/slice_op.cc#L255).
As seen [line 232](https://github.com/tensorflow/tensorflow/blob/db430c4bb275e05ee65dc27c7f771f778bfcbcf2/tensorflow/core/kernels/slice_op.cc#L232), input_dims is a constant (const), but is not a constant expression (constexpr), thus it should not be used as a template parameter.

### Source code / logs
```
ERROR: /local/esimon/prefix/usr/local/src/tensorflow/tensorflow/core/kernels/BUILD:780:1: C++ compilation of rule '//tensorflow/core/kernel$
:slice_op' failed (Exit 1).
tensorflow/core/kernels/slice_op.cc: In member function 'void tensorflow::MklSliceOp<Device, T>::Compute(tensorflow::OpKernelContext*)':
tensorflow/core/kernels/slice_op.cc:255:35: error: the value of 'input_dims' is not usable in a constant expression
         functor::Slice<Device, T, input_dims>()(
                                   ^~~~~~~~~~
tensorflow/core/kernels/slice_op.cc:232:15: note: 'input_dims' was not initialized with a constant expression
     const int input_dims = input.dims();
               ^~~~~~~~~~
tensorflow/core/kernels/slice_op.cc:255:45: error: the value of 'input_dims' is not usable in a constant expression
         functor::Slice<Device, T, input_dims>()(
                                             ^
tensorflow/core/kernels/slice_op.cc:232:15: note: 'input_dims' was not initialized with a constant expression
     const int input_dims = input.dims();
               ^~~~~~~~~~
tensorflow/core/kernels/slice_op.cc:255:45: note: in template argument for type 'int'
         functor::Slice<Device, T, input_dims>()(
                                             ^
```"
14323,tensorflow.python.framework.errors_impl.InvalidArgumentError: Shape mismatch in tuple component 0,"When I use tensorflow to build my own neural network and run it, I meet a very strange error. The error is that tensorflow.python.framework.errors_impl.InvalidArgumentError: Shape mismatch in tuple component 0. Expected [400], got [3200]. I have no idea about how [3200] comes, could anyone can help to fix this problem? The input of the neural network is a 400-dimension vector.

Here is my code:


tf.logging.set_verbosity(tf.logging.INFO)


def _cnn_model_fn(features,labels,mode):
  input_layer = tf.reshape(features['inputs'],[-1,400])
  print(features['inputs'].shape)
  fc1 = tf.layers.dense(input_layer,1024,activation=tf.nn.relu)
  fc2 = tf.layers.dense(fc1,1024,activation=tf.nn.relu)
  fc3 = tf.layers.dense(fc2,1024,activation=tf.nn.relu)
  fc4 = tf.layers.dense(fc3,1,activation=tf.nn.sigmoid)
  print(fc4.shape)
  labels = tf.reshape(labels,[-1,1])
  fc4 = tf.reshape(fc4,[-1,1])
  print(labels.shape)
  print(fc4.shape)
  if mode in (Modes.PREDICT,Modes.EVAL):
    print(""P and E"")
    pre = fc4
  if mode in (Modes.TRAIN,Modes.EVAL):
    print('T and E')
    global_step = tf.contrib.framework.get_or_create_global_step()
    loss = tf.losses.mean_squared_error(labels=labels,predictions=fc4)
    tf.summary.scalar('OptimizeLoss',loss)
  if mode == Modes.PREDICT:
    print('P')
    predictions = {
        'vaule': pre
    }
    export_outputs = {
        'prediction': tf.estimator.export.PredictOutput(predictions)
    }
    return tf.estimator.EstimatorSpec(
        mode, predictions=predictions, export_outputs=export_outputs)
  if mode == Modes.TRAIN:
    print('T')
    optimizer = tf.train.AdamOptimizer(learning_rate=0.01)
    print('optimizer')
    train_op = optimizer.minimize(loss)
    print('train_op')
    return tf.estimator.EstimatorSpec(mode,loss=loss,train_op=train_op)
  if mode == Modes.EVAL:
    print('E')
    eval_metric_ops = {
    'accuracy':tf.metrics.accuray(labels,pre)
    }
    return tf.estimator.EstimatorSpec(mode,loss=loss,eval_metric_ops=eval_metric_ops)


def build_estimator(model_dir):
  return tf.estimator.Estimator(
      model_fn=_cnn_model_fn,
      model_dir=model_dir,
      config=tf.contrib.learn.RunConfig(save_checkpoints_secs=60))


def serving_input_fn():
  inputs = {'inputs': tf.placeholder(tf.float32, [None, 400])}
  return tf.estimator.export.ServingInputReceiver(inputs, inputs)


def read_and_decode(filename_queue):
  reader = tf.TFRecordReader()
  _, serialized_example = reader.read(filename_queue)

  features = tf.parse_single_example(
      serialized_example,
      features={
          'image_raw': tf.FixedLenFeature([], tf.string),
          'label': tf.FixedLenFeature([], tf.float32),
      })

  image = tf.decode_raw(features['image_raw'], tf.uint8)
  image.set_shape([400])
  print('image')
  print(image.shape)
  image = tf.cast(image, tf.float32)
  label = tf.cast(features['label'], tf.float32)
  return image, label


def input_fn(filename, batch_size=100):
  filename_queue = tf.train.string_input_producer([filename])

  image, label = read_and_decode(filename_queue)
  images, labels = tf.train.batch(
      [image, label], batch_size=batch_size)
  print(images.shape)

  return {'inputs': images}, labels


def get_input_fn(filename, batch_size=100):
  return lambda: input_fn(filename, batch_size)


def generate_experiment_fn(data_dir,
                           train_batch_size=100,
                           eval_batch_size=100,
                           train_steps=5000,
                           eval_steps=100,
                           **experiment_args):

  def _experiment_fn(output_dir):
    return Experiment(
        build_estimator(output_dir),
        train_input_fn=get_input_fn(
            filename=os.path.join(data_dir, 'train.tfrecords'),
            batch_size=train_batch_size),
        eval_input_fn=get_input_fn(
            filename=os.path.join(data_dir, 'test.tfrecords'),
            batch_size=eval_batch_size),
        export_strategies=[saved_model_export_utils.make_export_strategy(
            serving_input_fn,
            default_output_alternative_key=None,
            exports_to_keep=1)],
        train_steps=train_steps,
        eval_steps=eval_steps,
        **experiment_args
    )
  return _experiment_fn


if __name__ == '__main__':
  parser = argparse.ArgumentParser()
  parser.add_argument(
      '--data_dir',
      help='GCS or local path to training data',
      type = str,
      default = '/Users/hanjun/Desktop/OS/scripts'
      #required=True
  )
  parser.add_argument(
      '--train_batch_size',
      help='Batch size for training steps',
      type=int,
      default=100
  )

  parser.add_argument(
      '--eval_batch_size',
      help='Batch size for evaluation steps',
      type=int,
      default=100
  )

  parser.add_argument(
      '--train_steps',
      help='Steps to run the training job for.',
      type=int,
      default=5000
  )

  parser.add_argument(
      '--eval_steps',
      help='Number of steps to run evalution for at each checkpoint',
      default=100,
      type=int
  )

  parser.add_argument(
      '--output_dir',
      help='GCS location to write checkpoints and export models',
      type = str,
      default = '/Users/hanjun/Desktop/OS/Model'
      #required=True
  )
  parser.add_argument(
      '--job-dir',
      help='this model ignores this field, but it is required by gcloud',
      default='junk'
  )

  parser.add_argument(
      '--eval_delay_secs',
      help='How long to wait before running first evaluation',
      default=10,
      type=int
  )
  parser.add_argument(
      '--min_eval_frequency',
      help='Minimum number of training steps between evaluations',
      default=1,
      type=int
  )


  args = parser.parse_args()
  arguments = args.__dict__

  # unused args provided by service
  arguments.pop('job_dir', None)
  arguments.pop('job-dir', None)

  output_dir = arguments.pop('output_dir')

  # Run the training job
  learn_runner.run(generate_experiment_fn(**arguments), output_dir)"
14322,Cannot reload tensorflow with importlib,"System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
I just tried reloading tensorflow using importlib
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 10
- **TensorFlow installed from (source or binary)**:
tensorflow-gpu from pip
- **TensorFlow version (use command below)**:
1.3.0
- **Python version**: 
3.6.2
- **CUDA/cuDNN version**:
CUDA 8, CuDNN 6
- **GPU model and memory**:
GeForce GTX 960M, 2GB
- **Exact command to reproduce**:
import tensorflow as tf
import importlib
importlib.reload(tf)

### Describe the problem
I won't really call it a problem. I was just trying to explore some part of tensorflow by checking out some stuffs. I just thought of reloading the module but it won't work. I don't know if this is something that should work or it's just a side effect of how tensorflow is implemented. Just adding it in in case it's something that should work.

### Source code / logs
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""D:\VirtualEnv\tensorflow\lib\importlib\__init__.py"", line 166, in reload
    _bootstrap._exec(spec, module)
  File ""<frozen importlib._bootstrap>"", line 608, in _exec
  File ""<frozen importlib._bootstrap_external>"", line 678, in exec_module
  File ""<frozen importlib._bootstrap>"", line 205, in _call_with_frames_removed
  File ""D:\VirtualEnv\tensorflow\lib\site-packages\tensorflow\__init__.py"", line 40, in <module>
    del python
NameError: name 'python' is not defined
"
14320,Supervisor does not initialize parameters,"Hi， 
      It throws an exception when I tried to initialize parameters with tf.train.Supervisor where the net is contructed with tensorlayer. The code is like this:
 
```
    init_op = tf.global_variables_initializer()
    saver = tf.train.Saver()
    config = tf.ConfigProto()
    config.gpu_options.allow_growth = True
    sv = tf.train.Supervisor(logdir=FLAGS.summary_dir, save_summaries_secs=0, saver=None)
    with sv.managed_session(config=config) as sess:
           init_ = sess.run(init_op)
           net.print_params()
           net.print_layers()
            tl.layers.print_all_variables()
```
and the exception is:

```
Cannot evaluate tensor using `eval()`: No default session is registered. Use `with sess.as_default()` or pass an explicit session to `eval(session=sess)`
Traceback (most recent call last):
  File ""/home/recsys/anaconda3/envs/tf1.2/lib/python3.6/site-packages/tensorlayer/layers.py"", line 309, in print_params
    val = p.eval()
  File ""/home/recsys/anaconda3/envs/tf1.2/lib/python3.6/site-packages/tensorflow/python/ops/variables.py"", line 463, in eval
    return self._variable.eval(session=session)
  File ""/home/recsys/anaconda3/envs/tf1.2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 606, in eval
    return _eval_using_default_session(self, feed_dict, self.graph, session)
  File ""/home/recsys/anaconda3/envs/tf1.2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3914, in _eval_using_default_session
    raise ValueError(""Cannot evaluate tensor using `eval()`: No default ""
ValueError: Cannot evaluate tensor using `eval()`: No default session is registered. Use `with sess.as_default()` or pass an explicit session to `eval(session=sess)`

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""MainEntryPtb.py"", line 65, in <module>
    train_rnn(FLAGS)
  File ""/home/recsys/wangjian/learntf/TFTemplate/examples/ptb.py"", line 122, in train_rnn
    net.print_params()
  File ""/home/recsys/anaconda3/envs/tf1.2/lib/python3.6/site-packages/tensorlayer/layers.py"", line 313, in print_params
    raise Exception(""Hint: print params details after tl.layers.initialize_global_variables(sess) or use network.print_params(False)."")
Exception: Hint: print params details after tl.layers.initialize_global_variables(sess) or use network.print_params(False).
```

It seems that when I run initialize op `init_ = sess.run(init_op)`  it does not really work.

I use tensorflow v1.2.1 and python3.6"
14316,C++ model Saving(after training) not generating 'modelName.meta' file for Prediction,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 17.04
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: 1.3.0
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: 0.5.1
- **GCC/Compiler version (if compiling from source)**: 6.0.3
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**:

`session->Run({{""save/Const:0"", newModelFile}}, {}, {""save/control_dependency""}, nullptr)`

### Describe the problem
I am trying to train a model file in C++ and save the trained model file.

when I save the model file with below command in C++

`session->Run({{""save/Const:0"", 'newModelFile'}}, {}, {""save/control_dependency""}, nullptr)`

Following files are generated
1. newModelFile.index
2. newModelFile.data-00000-of-00001

But when the training and saving is done in Python with below command 

```
with tf.Session() as sess:
    tf.train.Saver(tf.trainable_variables()).save(sess, 'newModelFile')

```
Following files are getting generated
1. newModelFile.index
2. newModelFile.data-00000-of-00001
3. newModelFile.meta

As we can see 'newModelFile.meta' is not getting generated in C++

**Requirement - To do prediction in C++ from trained model file (in C++)**   

I have found the code in C++ which meets the above requirement at https://stackoverflow.com/questions/35508866/tensorflow-different-ways-to-export-and-run-graph-in-c/43639305#43639305

BUT

the code makes use of 'newModelFile.meta' file which is not generated during training in C++

1. Can I please know how to generate 'newModelFile.meta' file in C++ to use it for prediction
2. Is there any other way to make predictions in c++ from the checkpoint files 
3. Is there a way to generate .pb in c++ after training instead of generating checkpoint files so that it can directly be loaded for prediction

Stackoverflow :  https://stackoverflow.com/questions/47154881/tensorflow-c-model-savingafter-training-not-generating-modelname-meta-file
"
14315,Does tensorflow support RowSparsePull and RowSparsePush when using embedding_lookup_sparse?,
14314,eager module has no attributes,"My OS is Ubuntu 16.04
Python version is 3.5
Tensorflow version is 14.0
when I tried a simple code for TF Eager module

`import tensorflow as tf`
`import tensorflow.contrib.eager as tfe`
`tfe.enable_eager_execution()`
`x = [[2.]]`
`m = tf.matmul(x, x)`

I got a error
AttributeError: module 'tensorflow.contrib.eager' has no attribute 'enable_eager_execution'
So what's wrong?"
14313,Feature request: add tf.decode_libsvm op,"Hi, since libsvm format is used widespreadly to store sparse data, and is supported by many main-stream frameworks:
+ spark: [LibSVMDataSource](https://spark.apache.org/docs/2.0.0/api/java/org/apache/spark/ml/source/libsvm/LibSVMDataSource.html)
+ sklearn: [load_svmlight_file](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_svmlight_file.html)
+ xgboost: [LibSVM format](https://github.com/dmlc/xgboost/blob/master/demo/binary_classification/README.md)

Could tensorflow support to parse libsvm format like [`tf.decode_csv`](https://www.tensorflow.org/versions/master/api_docs/python/tf/decode_csv)?"
14306,Segmentation fault when using bidirectional_dynamic_rnn + orthogonal_initializer,"### System information
- **Have I written custom code**: Yes
- **OS Platform and Distribution**: Ubuntu 14.04 LTS (kernel: 3.16.0-77-generic)
- **TensorFlow installed from**: source
- **TensorFlow version**: 1.4.0rc1 (ae04712e3b74bc85445e12c90e375f980a907e2d) 
- **Python version**:  2.7.10
- **Bazel version**: 0.7.0
- **GCC/Compiler version**: 4.8.5
- **CUDA/cuDNN version**: 8.0/6.0.21
- **GPU model and memory**: Maxwell Titan X with 12 GiB memory
- **Exact command to reproduce**: see https://gist.github.com/nryant/57f7810e333fa94379cad201eeff24c8


### Describe the problem
I recently upgraded from 1.4.0-rc0 to 1.4.0-rc1 and found that a number of my model architectures fail to compile. After a bit of a detective work, I tracked the issue down to the use of ``bidirectional_dynamic_rnn`` in conjunction with a ``VariableScope`` in which ``initializer=orthogonal_initializer()``. See, for example, the test program at

    https://gist.github.com/nryant/57f7810e333fa94379cad201eeff24c8

Running this will result in a segfault with 1.4.0-rc1, but not with earlier versions. The problem is specific to the combination of ``orthogonal_initializer`` and ``bidirectional_dynamic_rnn`` and does not replicate with other initializers (e.g., ``uniform_unit_scaling_initializer``) or ``dynamic_rnn``. Nor does the choice of RNN cell appear to matter.
"
14303,tf.metrics.mean_per_class_accuracy does not assume num_classes,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 14.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: ('v1.2.0-5-g435cdfc', '1.2.1')
- **Python version**: 2.7.6
- **CUDA/cuDNN version**: 5.1
- **Exact command to reproduce**:

### Describe the problem
When I run an Experiment with `tf.metrics.mean_per_class_accuracy` as a metric, I get the following error. This is unexpected because all other metrics simply need predictions and labels. Also, `num_classes` is already known by the graph in the model head.
```
ERROR:tensorflow:Could not create metric ops for MetricSpec(metric_fn=mean_per_class_accuracy, prediction_key=classes, label_key=None, weight_key=None), mean_per_class_accuracy() takes at least 3 arguments (2 given).
Traceback (most recent call last):
  File ""/usr/lib/python2.7/runpy.py"", line 162, in _run_module_as_main
    ""__main__"", fname, loader, pkg_name)
  File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code
    exec code in run_globals
  File ""/usr/local/home/rasmi/trainer/task.py"", line 282, in <module>
    learn_runner.run(generate_experiment_fn(args), args.job_dir)
  File ""/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/learn_runner.py"", line 210, in run
    return _execute_schedule(experiment, schedule)
  File ""/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/learn_runner.py"", line 47, in _execute_schedule
    return task()
  File ""/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/experiment.py"", line 495, in train_and_evaluate
    self.train(delay_secs=0)
  File ""/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/experiment.py"", line 275, in train
    hooks=self._train_monitors + extra_hooks)
  File ""/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/experiment.py"", line 665, in _call_train
    monitors=hooks)
  File ""/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py"", line 289, in new_func
    return func(*args, **kwargs)
  File ""/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 455, in fit
    loss = self._train_model(input_fn=input_fn, hooks=hooks)
  File ""/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 1007, in _train_model
    _, loss = mon_sess.run([model_fn_ops.train_op, model_fn_ops.loss])
  File ""/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 505, in run
    run_metadata=run_metadata)
  File ""/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 842, in run
    run_metadata=run_metadata)
  File ""/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 798, in run
    return self._sess.run(*args, **kwargs)
  File ""/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 960, in run
    run_metadata=run_metadata))
  File ""/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/monitors.py"", line 1178, in after_run
    induce_stop = m.step_end(self._last_step, result)
  File ""/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/monitors.py"", line 357, in step_end
    return self.every_n_step_end(step, output)
  File ""/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/monitors.py"", line 677, in every_n_step_end
    validation_outputs = self._evaluate_estimator()
  File ""/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/monitors.py"", line 653, in _evaluate_estimator
    metrics=self.metrics, hooks=self.hooks, name=self.name)
  File ""/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py"", line 289, in new_func
    return func(*args, **kwargs)
  File ""/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 543, in evaluate
    log_progress=log_progress)
  File ""/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 829, in _evaluate_model
    model_fn_results = self._get_eval_ops(features, labels, metrics)
  File ""/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 1196, in _get_eval_ops
    metrics, features, labels, model_fn_ops.predictions))
  File ""/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 269, in _make_metrics_ops
    result[name] = metric.create_metric_ops(features, labels, predictions)
  File ""/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/metric_spec.py"", line 428, in create_metric_ops
    weights=inputs[self.weight_key] if self.weight_key else None)
  File ""/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/metric_spec.py"", line 166, in _named_metric_fn
    return metric_fn(**kwargs)
TypeError: mean_per_class_accuracy() takes at least 3 arguments (2 given)
```

### Source code / logs
I create my Experiment as follows:
```
    return tf.contrib.learn.Experiment(
        train_input_fn = train_input,
        eval_input_fn = eval_input,
        train_steps = 10000,
        eval_steps = 100,
        eval_metrics = {
          ""mean_per_class_accuracy"": tf.contrib.learn.MetricSpec(
            metric_fn=tf.metrics.mean_per_class_accuracy,
            prediction_key=tf.contrib.learn.PredictionKey.CLASSES
          )
      }
```"
14302,TF CNN benchmark resnet-50 not freeing up GPU memory after being terminated,"Hi

I've ran some of the cnn benchmarks on an cluster that uses SLURM, on a Nvidia XP. One of my jobs got stuck. When I cancelled the script, it seems not to free up the GPU memory anymore after that.
totalMemory: 11.90GiB freeMemory: 365.94MiB

Now I can't run any more scripts. How can I free up my GPU memory again?

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: cnn_benchmarks 
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Cluster node with amd cpu and NVidia XP
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.4
- **Python version**: 2.7 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**: GCC version:  gcc version 4.8.5 20150623 (Red Hat 4.8.5-16) (GCC) 
- **CUDA/cuDNN version**: Cuda8, Cudnn 6
- **GPU model and memory**: Nvidia XP
- **Exact command to reproduce**: python tf_cnn_benchmarks.py --model=resnet50 --num_gpus=1 --local_parameter_device=gpu

### Source code / logs
2017-11-06 21:45:35.243801: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX FMA
2017-11-06 21:45:35.832723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:41:00.0
totalMemory: 11.90GiB freeMemory: 365.94MiB
2017-11-06 21:45:35.832780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN Xp, pci bus id: 0000:41:00.0, compute capability: 6.1)
2017-11-06 21:45:46.271894: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 144.00MiB.  Current allocation summary follows.
2017-11-06 21:45:46.271976: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (256): 	Total Chunks: 18, Chunks in use: 18. 4.5KiB allocated for chunks. 4.5KiB in use in bin. 576B client-requested in use in bin.
2017-11-06 21:45:46.271992: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (512): 	Total Chunks: 2, Chunks in use: 2. 1.5KiB allocated for chunks. 1.5KiB in use in bin. 1.5KiB client-requested in use in bin.
2017-11-06 21:45:46.272005: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (1024): 	Total Chunks: 7, Chunks in use: 7. 9.2KiB allocated for chunks. 9.2KiB in use in bin. 9.0KiB client-requested in use in bin.
2017-11-06 21:45:46.272016: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (2048): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:46.272029: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (4096): 	Total Chunks: 1, Chunks in use: 1. 4.0KiB allocated for chunks. 4.0KiB in use in bin. 3.9KiB client-requested in use in bin.
2017-11-06 21:45:46.272040: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (8192): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:46.272052: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (16384): 	Total Chunks: 2, Chunks in use: 2. 32.0KiB allocated for chunks. 32.0KiB in use in bin. 32.0KiB client-requested in use in bin.
2017-11-06 21:45:46.272063: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (32768): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:46.272076: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (65536): 	Total Chunks: 1, Chunks in use: 1. 90.8KiB allocated for chunks. 90.8KiB in use in bin. 90.8KiB client-requested in use in bin.
2017-11-06 21:45:46.272087: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (131072): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:46.272097: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (262144): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:46.272108: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (524288): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:46.272120: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (1048576): 	Total Chunks: 1, Chunks in use: 1. 1.17MiB allocated for chunks. 1.17MiB in use in bin. 1.17MiB client-requested in use in bin.
2017-11-06 21:45:46.272131: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (2097152): 	Total Chunks: 2, Chunks in use: 2. 5.91MiB allocated for chunks. 5.91MiB in use in bin. 5.91MiB client-requested in use in bin.
2017-11-06 21:45:46.272143: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (4194304): 	Total Chunks: 1, Chunks in use: 1. 5.06MiB allocated for chunks. 5.06MiB in use in bin. 5.06MiB client-requested in use in bin.
2017-11-06 21:45:46.272153: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:46.272164: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:46.272176: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:46.272186: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:46.272197: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (134217728): 	Total Chunks: 1, Chunks in use: 0. 128.66MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:46.272208: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:46.272220: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin for 144.00MiB was 128.00MiB, Chunk State: 
2017-11-06 21:45:46.272296: I tensorflow/core/common_runtime/bfc_allocator.cc:649]   Size: 128.66MiB | Requested Size: 0B | in_use: 0, prev:   Size: 1.0KiB | Requested Size: 1.0KiB | in_use: 1
2017-11-06 21:45:46.272309: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400000 of size 1280
2017-11-06 21:45:46.272318: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400500 of size 256
2017-11-06 21:45:46.272326: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400600 of size 256
2017-11-06 21:45:46.272341: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400700 of size 256
2017-11-06 21:45:46.272350: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400800 of size 256
2017-11-06 21:45:46.272358: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400900 of size 256
2017-11-06 21:45:46.272368: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400a00 of size 768
2017-11-06 21:45:46.272376: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400d00 of size 256
2017-11-06 21:45:46.272385: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400e00 of size 256
2017-11-06 21:45:46.272393: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400f00 of size 1536
2017-11-06 21:45:46.272402: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e401500 of size 256
2017-11-06 21:45:46.272411: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e401600 of size 256
2017-11-06 21:45:46.272420: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e401700 of size 1536
2017-11-06 21:45:46.272428: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e401d00 of size 256
2017-11-06 21:45:46.272438: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e401e00 of size 256
2017-11-06 21:45:46.272447: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e401f00 of size 1024
2017-11-06 21:45:46.272455: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e402300 of size 256
2017-11-06 21:45:46.272465: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e402400 of size 256
2017-11-06 21:45:46.272474: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e402500 of size 16384
2017-11-06 21:45:46.272482: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e406500 of size 256
2017-11-06 21:45:46.272491: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e406600 of size 256
2017-11-06 21:45:46.272499: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e406700 of size 16384
2017-11-06 21:45:46.272507: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e40a700 of size 256
2017-11-06 21:45:46.272516: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e40a800 of size 256
2017-11-06 21:45:46.272528: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e40a900 of size 4096
2017-11-06 21:45:46.272537: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e40b900 of size 92928
2017-11-06 21:45:46.272546: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e422400 of size 256
2017-11-06 21:45:46.272554: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e422500 of size 1228800
2017-11-06 21:45:46.272562: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e54e500 of size 768
2017-11-06 21:45:46.272571: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e54e800 of size 2654208
2017-11-06 21:45:46.272580: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e7d6800 of size 1536
2017-11-06 21:45:46.272589: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e7d6e00 of size 5308416
2017-11-06 21:45:46.272597: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ece6e00 of size 1536
2017-11-06 21:45:46.272606: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ece7400 of size 3538944
2017-11-06 21:45:46.272614: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f047400 of size 1024
2017-11-06 21:45:46.272623: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x1020f047800 of size 134907904
2017-11-06 21:45:46.272631: I tensorflow/core/common_runtime/bfc_allocator.cc:676]      Summary of in-use Chunks by size: 
2017-11-06 21:45:46.272645: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 18 Chunks of size 256 totalling 4.5KiB
2017-11-06 21:45:46.272655: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 2 Chunks of size 768 totalling 1.5KiB
2017-11-06 21:45:46.272665: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 2 Chunks of size 1024 totalling 2.0KiB
2017-11-06 21:45:46.272675: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 1280 totalling 1.2KiB
2017-11-06 21:45:46.272686: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 4 Chunks of size 1536 totalling 6.0KiB
2017-11-06 21:45:46.272695: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 4096 totalling 4.0KiB
2017-11-06 21:45:46.272706: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 2 Chunks of size 16384 totalling 32.0KiB
2017-11-06 21:45:46.272716: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 92928 totalling 90.8KiB
2017-11-06 21:45:46.272725: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 1228800 totalling 1.17MiB
2017-11-06 21:45:46.272735: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 2654208 totalling 2.53MiB
2017-11-06 21:45:46.272749: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 3538944 totalling 3.38MiB
2017-11-06 21:45:46.272760: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 5308416 totalling 5.06MiB
2017-11-06 21:45:46.272772: I tensorflow/core/common_runtime/bfc_allocator.cc:683] Sum Total of in-use chunks: 12.28MiB
2017-11-06 21:45:46.272786: I tensorflow/core/common_runtime/bfc_allocator.cc:685] Stats: 
Limit:                   147783680
InUse:                    12875776
MaxInUse:                 12875776
NumAllocs:                      35
MaxAllocSize:              5308416

2017-11-06 21:45:46.272799: W tensorflow/core/common_runtime/bfc_allocator.cc:277] *********___________________________________________________________________________________________
2017-11-06 21:45:46.272823: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[9216,4096]
2017-11-06 21:45:56.273596: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 64.00MiB.  Current allocation summary follows.
2017-11-06 21:45:56.273635: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (256): 	Total Chunks: 18, Chunks in use: 18. 4.5KiB allocated for chunks. 4.5KiB in use in bin. 576B client-requested in use in bin.
2017-11-06 21:45:56.273649: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (512): 	Total Chunks: 2, Chunks in use: 2. 1.5KiB allocated for chunks. 1.5KiB in use in bin. 1.5KiB client-requested in use in bin.
2017-11-06 21:45:56.273661: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (1024): 	Total Chunks: 7, Chunks in use: 7. 9.2KiB allocated for chunks. 9.2KiB in use in bin. 9.0KiB client-requested in use in bin.
2017-11-06 21:45:56.273672: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (2048): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:56.273684: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (4096): 	Total Chunks: 2, Chunks in use: 2. 8.0KiB allocated for chunks. 8.0KiB in use in bin. 7.8KiB client-requested in use in bin.
2017-11-06 21:45:56.273695: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (8192): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:56.273707: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (16384): 	Total Chunks: 4, Chunks in use: 4. 64.0KiB allocated for chunks. 64.0KiB in use in bin. 64.0KiB client-requested in use in bin.
2017-11-06 21:45:56.273718: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (32768): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:56.273731: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (65536): 	Total Chunks: 2, Chunks in use: 1. 181.5KiB allocated for chunks. 90.8KiB in use in bin. 90.8KiB client-requested in use in bin.
2017-11-06 21:45:56.273742: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (131072): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:56.273754: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (262144): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:56.273765: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (524288): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:56.273777: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (1048576): 	Total Chunks: 2, Chunks in use: 1. 2.34MiB allocated for chunks. 1.17MiB in use in bin. 1.17MiB client-requested in use in bin.
2017-11-06 21:45:56.273788: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (2097152): 	Total Chunks: 3, Chunks in use: 1. 8.44MiB allocated for chunks. 2.53MiB in use in bin. 2.53MiB client-requested in use in bin.
2017-11-06 21:45:56.273800: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (4194304): 	Total Chunks: 2, Chunks in use: 2. 10.12MiB allocated for chunks. 10.12MiB in use in bin. 8.44MiB client-requested in use in bin.
2017-11-06 21:45:56.273813: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (8388608): 	Total Chunks: 1, Chunks in use: 1. 15.64MiB allocated for chunks. 15.64MiB in use in bin. 15.64MiB client-requested in use in bin.
2017-11-06 21:45:56.273823: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:56.273834: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (33554432): 	Total Chunks: 1, Chunks in use: 0. 40.13MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:56.273852: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (67108864): 	Total Chunks: 1, Chunks in use: 1. 64.00MiB allocated for chunks. 64.00MiB in use in bin. 64.00MiB client-requested in use in bin.
2017-11-06 21:45:56.273863: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:56.273874: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:56.273884: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin for 64.00MiB was 64.00MiB, Chunk State: 
2017-11-06 21:45:56.273895: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400000 of size 1280
2017-11-06 21:45:56.273904: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400500 of size 256
2017-11-06 21:45:56.273913: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400600 of size 256
2017-11-06 21:45:56.273921: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400700 of size 256
2017-11-06 21:45:56.273929: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400800 of size 256
2017-11-06 21:45:56.273937: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400900 of size 256
2017-11-06 21:45:56.273946: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400a00 of size 768
2017-11-06 21:45:56.273955: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400d00 of size 256
2017-11-06 21:45:56.273963: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400e00 of size 256
2017-11-06 21:45:56.273972: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400f00 of size 1536
2017-11-06 21:45:56.273981: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e401500 of size 256
2017-11-06 21:45:56.273989: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e401600 of size 256
2017-11-06 21:45:56.273997: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e401700 of size 1536
2017-11-06 21:45:56.274005: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e401d00 of size 256
2017-11-06 21:45:56.274014: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e401e00 of size 256
2017-11-06 21:45:56.274029: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e401f00 of size 1024
2017-11-06 21:45:56.274038: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e402300 of size 256
2017-11-06 21:45:56.274046: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e402400 of size 256
2017-11-06 21:45:56.274056: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e402500 of size 16384
2017-11-06 21:45:56.274065: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e406500 of size 256
2017-11-06 21:45:56.274074: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e406600 of size 256
2017-11-06 21:45:56.274084: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e406700 of size 16384
2017-11-06 21:45:56.274093: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e40a700 of size 256
2017-11-06 21:45:56.274101: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e40a800 of size 256
2017-11-06 21:45:56.274109: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e40a900 of size 4096
2017-11-06 21:45:56.274117: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e422400 of size 256
2017-11-06 21:45:56.274126: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e54e500 of size 768
2017-11-06 21:45:56.274138: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e7d6800 of size 1536
2017-11-06 21:45:56.274149: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e7d6e00 of size 5308416
2017-11-06 21:45:56.274157: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ece6e00 of size 1536
2017-11-06 21:45:56.274166: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f047400 of size 1024
2017-11-06 21:45:56.274174: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f047800 of size 16384
2017-11-06 21:45:56.274182: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f04b800 of size 67108864
2017-11-06 21:45:56.274191: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021304b800 of size 16384
2017-11-06 21:45:56.274199: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021304f800 of size 16400384
2017-11-06 21:45:56.274207: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10213ff3800 of size 4096
2017-11-06 21:45:56.274216: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10213ff4800 of size 92928
2017-11-06 21:45:56.274225: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021400b300 of size 1228800
2017-11-06 21:45:56.274299: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10214137300 of size 2654208
2017-11-06 21:45:56.274308: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102143bf300 of size 5308416
2017-11-06 21:45:56.274317: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x1020e40b900 of size 92928
2017-11-06 21:45:56.274325: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x1020e422500 of size 1228800
2017-11-06 21:45:56.274333: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x1020e54e800 of size 2654208
2017-11-06 21:45:56.274342: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x1020ece7400 of size 3538944
2017-11-06 21:45:56.274351: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x102148cf300 of size 42077440
2017-11-06 21:45:56.274359: I tensorflow/core/common_runtime/bfc_allocator.cc:676]      Summary of in-use Chunks by size: 
2017-11-06 21:45:56.274369: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 18 Chunks of size 256 totalling 4.5KiB
2017-11-06 21:45:56.274381: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 2 Chunks of size 768 totalling 1.5KiB
2017-11-06 21:45:56.274391: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 2 Chunks of size 1024 totalling 2.0KiB
2017-11-06 21:45:56.274401: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 1280 totalling 1.2KiB
2017-11-06 21:45:56.274412: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 4 Chunks of size 1536 totalling 6.0KiB
2017-11-06 21:45:56.274422: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 2 Chunks of size 4096 totalling 8.0KiB
2017-11-06 21:45:56.274433: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 4 Chunks of size 16384 totalling 64.0KiB
2017-11-06 21:45:56.274443: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 92928 totalling 90.8KiB
2017-11-06 21:45:56.274454: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 1228800 totalling 1.17MiB
2017-11-06 21:45:56.274463: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 2654208 totalling 2.53MiB
2017-11-06 21:45:56.274474: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 2 Chunks of size 5308416 totalling 10.12MiB
2017-11-06 21:45:56.274489: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 16400384 totalling 15.64MiB
2017-11-06 21:45:56.274500: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 67108864 totalling 64.00MiB
2017-11-06 21:45:56.274510: I tensorflow/core/common_runtime/bfc_allocator.cc:683] Sum Total of in-use chunks: 93.64MiB
2017-11-06 21:45:56.274522: I tensorflow/core/common_runtime/bfc_allocator.cc:685] Stats: 
Limit:                   147783680
InUse:                    98191360
MaxInUse:                101730304
NumAllocs:                      45
MaxAllocSize:             67108864

2017-11-06 21:45:56.274536: W tensorflow/core/common_runtime/bfc_allocator.cc:277] *_*****_****************************************************************____________________________
2017-11-06 21:45:56.274550: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[4096,4096]
TensorFlow:  1.4
Model:       alexnet
Mode:        training
SingleSess:  False
Batch size:  32 global
             32 per device
Devices:     ['/gpu:0']
Data format: NCHW
Optimizer:   sgd
Variables:   parameter_server
==========
Generating model
Traceback (most recent call last):
  File ""tf_cnn_benchmarks.py"", line 46, in <module>
    tf.app.run()
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""tf_cnn_benchmarks.py"", line 42, in main
    bench.run()
  File ""/home/kklein/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 892, in run
    return self._benchmark_cnn()
  File ""/home/kklein/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 1068, in _benchmark_cnn
    start_standard_services=start_standard_services) as sess:
  File ""/usr/lib64/python2.7/contextlib.py"", line 17, in __enter__
    return self.gen.next()
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/supervisor.py"", line 964, in managed_session
    self.stop(close_summary_writer=close_summary_writer)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/supervisor.py"", line 792, in stop
    stop_grace_period_secs=self._stop_grace_secs)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/coordinator.py"", line 389, in join
    six.reraise(*self._exc_info_to_raise)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/supervisor.py"", line 953, in managed_session
    start_standard_services=start_standard_services)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/supervisor.py"", line 708, in prepare_or_wait_for_session
    init_feed_dict=self._init_feed_dict, init_fn=self._init_fn)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 279, in prepare_session
    sess.run(init_op, feed_dict=init_feed_dict)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 889, in run
    run_metadata_ptr)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1120, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1317, in _do_run
    options, run_metadata)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1336, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[9216,4096]
	 [[Node: v/cg/affine0/weights/Initializer/truncated_normal/TruncatedNormal = TruncatedNormal[T=DT_INT32, _class=[""loc:@v/cg/affine0/weights""], dtype=DT_FLOAT, seed=1234, seed2=149, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](v/cg/affine0/weights/Initializer/truncated_normal/shape)]]

Caused by op u'v/cg/affine0/weights/Initializer/truncated_normal/TruncatedNormal', defined at:
  File ""tf_cnn_benchmarks.py"", line 46, in <module>
    tf.app.run()
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""tf_cnn_benchmarks.py"", line 42, in main
    bench.run()
  File ""/home/kklein/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 892, in run
    return self._benchmark_cnn()
  File ""/home/kklein/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 986, in _benchmark_cnn
    (image_producer_ops, enqueue_ops, fetches) = self._build_model()
  File ""/home/kklein/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 1236, in _build_model
    gpu_compute_stage_ops, gpu_grad_stage_ops)
  File ""/home/kklein/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 1524, in add_forward_pass_and_gradients
    self.model.add_inference(network)
  File ""/home/kklein/benchmarks/scripts/tf_cnn_benchmarks/models/alexnet_model.py"", line 45, in add_inference
    cnn.affine(4096)
  File ""/home/kklein/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py"", line 311, in affine
    initializer=tf.truncated_normal_initializer(stddev=stddev))
  File ""/home/kklein/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py"", line 117, in get_variable
    var = tf.get_variable(name, shape, dtype, *args, **kwargs)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 1203, in get_variable
    constraint=constraint)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 1092, in get_variable
    constraint=constraint)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 417, in get_variable
    return custom_getter(**custom_getter_kwargs)
  File ""/home/kklein/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py"", line 86, in inner_custom_getter
    var = getter(*args, **kwargs)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 394, in _true_getter
    use_resource=use_resource, constraint=constraint)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 805, in _get_single_variable
    constraint=constraint)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/variables.py"", line 213, in __init__
    constraint=constraint)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/variables.py"", line 303, in _init_from_args
    initial_value(), name=""initial_value"", dtype=dtype)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 779, in <lambda>
    shape.as_list(), dtype=dtype, partition_info=partition_info)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/init_ops.py"", line 309, in __call__
    shape, self.mean, self.stddev, dtype, seed=self.seed)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/random_ops.py"", line 172, in truncated_normal
    shape_tensor, dtype, seed=seed1, seed2=seed2)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/gen_random_ops.py"", line 588, in _truncated_normal
    name=name)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2956, in create_op
    op_def=op_def)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1470, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[9216,4096]
	 [[Node: v/cg/affine0/weights/Initializer/truncated_normal/TruncatedNormal = TruncatedNormal[T=DT_INT32, _class=[""loc:@v/cg/affine0/weights""], dtype=DT_FLOAT, seed=1234, seed2=149, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](v/cg/affine0/weights/Initializer/truncated_normal/shape)]]

srun: error: gpu08: task 0: Exited with exit code 1

"
14301,CUDA_ERROR_OUT_OF_MEMORY tensorflow 1.4,"### System information
OS - High Sierra 10.13
Tensorflow - 1.4
Keras - 2.0.9
CUDA - 9
cuDNN - 7

### Describe the problem
CUDA_ERROR_OUT_OF_MEMORY running tensorflow on GPU

Simple program:
```
import tensorflow as tf
with tf.device('/gpu:0'):
    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')
    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')
    c = tf.matmul(a, b)

with tf.Session() as sess:
    print (sess.run(c))
```

Output:
```
(tensorflow) Smit-Shilu:Desktop smitshilu$ python gputest.py 
2017-11-07 08:55:50.690390: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:856] OS X does not support NUMA - returning NUMA node zero
2017-11-07 08:55:50.690536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1031] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.6705
pciBusID: 0000:c3:00.0
totalMemory: 11.00GiB freeMemory: 10.81GiB
2017-11-07 08:55:50.690560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:c3:00.0, compute capability: 6.1)
2017-11-07 08:55:50.690914: E tensorflow/stream_executor/cuda/cuda_driver.cc:936] failed to allocate 10.27G (11026294784 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-07 08:55:50.691022: E tensorflow/stream_executor/cuda/cuda_driver.cc:936] failed to allocate 9.24G (9923664896 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
[[ 22.  28.]
 [ 49.  64.]]
```

CUDA_ERROR_OUT_OF_MEMORY when import Keras after upgrading to 10.13 and 1.4

```
>>> from keras.callbacks import *
Using TensorFlow backend.
2017-11-06 16:30:54.704584: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:856] OS X does not support NUMA - returning NUMA node zero
2017-11-06 16:30:54.704700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1031] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.6705
pciBusID: 0000:c3:00.0
totalMemory: 11.00GiB freeMemory: 10.81GiB
2017-11-06 16:30:54.704725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:c3:00.0, compute capability: 6.1)
2017-11-06 16:30:54.705019: E tensorflow/stream_executor/cuda/cuda_driver.cc:936] failed to allocate 10.27G (11026489344 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-06 16:30:54.705125: E tensorflow/stream_executor/cuda/cuda_driver.cc:936] failed to allocate 9.24G (9923840000 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
```"
14299,padded_batch fails on nested shapes,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Arch Linux, fully updated
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: v1.3.0-rc1-4086-g028809769d 1.4.0-rc1
- **Python version**: 3.6.3
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**: gcc (GCC) 7.2.0
- **CUDA/cuDNN version**: cuda 9.0.176-4 cuDNN 7.0.3-1
- **GPU model and memory**: N/A
- **Exact command to reproduce**:

### Describe the problem
Trying to use tf.data.Dataset.padded_batch fails with type error for any nested shape
see [stack overflow question](https://stackoverflow.com/questions/47103249/how-to-use-tf-data-dataset-padded-batch-with-a-nested-shape)

### Source code / logs
```
import tensorflow as tf
def generator():
    while 1:
        yield [[[1]*3 for y in range(32)] for x in range(32)],[[[0]*cnum for y in range(1)]for x in range(1)]
dataset = tf.data.Dataset.from_generator(generator,tf.float32)
shapes = (tf.TensorShape([None,None,None,3]),tf.TensorShape([None,5]))
batch = dataset.padded_batch(1,shapes)
```
note: I'm not sure if the additional None dimension representing batch should be added to the generator or not but this code does reproduce the error I'm having.

```
Traceback (most recent call last):
  File ""/usr/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 1263, in _partial_shape_to_tensor
    shape_like = tensor_shape.as_shape(shape_like)
  File ""/usr/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py"", line 849, in as_shape
    return TensorShape(shape)
  File ""/usr/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py"", line 455, in __init__
    self._dims = [as_dimension(d) for d in dims_iter]
  File ""/usr/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py"", line 455, in <listcomp>
    self._dims = [as_dimension(d) for d in dims_iter]
  File ""/usr/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py"", line 397, in as_dimension
    return Dimension(value)
  File ""/usr/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py"", line 32, in __init__
    self._value = int(value)
TypeError: int() argument must be a string, a bytes-like object or a number, not 'TensorShape'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 710, in padded_batch
    return PaddedBatchDataset(self, batch_size, padded_shapes, padding_values)
  File ""/usr/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 1309, in __init__
    input_dataset.output_shapes, _partial_shape_to_tensor, padded_shapes)
  File ""/usr/lib/python3.6/site-packages/tensorflow/python/data/util/nest.py"", line 519, in map_structure_up_to
    results = [func(*tensors) for tensors in zip(*all_flattened_up_to)]
  File ""/usr/lib/python3.6/site-packages/tensorflow/python/data/util/nest.py"", line 519, in <listcomp>
    results = [func(*tensors) for tensors in zip(*all_flattened_up_to)]
  File ""/usr/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 1271, in _partial_shape_to_tensor
    return ops.convert_to_tensor(shape_like, dtype=dtypes.int64)
  File ""/usr/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 887, in convert_to_tensor
    as_ref=False)
  File ""/usr/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 977, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/usr/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py"", line 233, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/usr/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py"", line 212, in constant
    value, dtype=dtype, shape=shape, verify_shape=verify_shape))
  File ""/usr/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py"", line 399, in make_tensor_proto
    _AssertCompatible(values, dtype)
  File ""/usr/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py"", line 314, in _AssertCompatible
    (dtype.name, repr(mismatch), type(mismatch).__name__))
TypeError: Expected int64, got TensorShape([Dimension(None), Dimension(None), Dimension(None), Dimension(3)]) of type 'TensorShape' instead.
```
"
14295,Documentation: Java Tutorials,"There is only one example for the Java API `LabelImage.java` that is also outdated. It would be great to add more examples for different tasks like text classification, sentence matching, seq2seq, etc.

I have a small example that put the java api all together. See [tensorflow-java](https://github.com/loretoparisi/tensorflow-java)"
14294,Compilation progress indicator is useless,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS 10.12.6
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: `master` from around now
- **Python version**:  -
- **Bazel version (if compiling from source)**: 0.6.1
- **GCC/Compiler version (if compiling from source)**: Apple LLVM 9.0.0
- **CUDA/cuDNN version**: -
- **GPU model and memory**: -
- **Exact command to reproduce**: Any compilation, e.g. `bazel build //tensorflow/tools/pip_package:build_pip_package`

Whenever I compile Tensorflow, Bazel shows a nice progress indicator, for example:

    [1,428 / 1,437] Compiling tensorflow/core/kernels/cast_op_impl_int64.cc

However that progress proceeds something like this:

    [4 / 15]
    [20 / 26]
    ...
    [264 / 275]
    ...
    [1,821 / 1,832]
    ...
    [3,456 / 3,470]

Pretty useless. Compiling Tensorflow takes about 45 minutes on my system and it seems to want to do a complete recompile at the drop of a hat so it would be useful at least if I know whether I should wait for it or go and cook dinner. Is there anything that could be done to improve this?"
14293,external symbol unresolved external symbol VS2015,"I have one error while trying to build my program:

### System information
Windows 10 x64 bit
TensorFlow version 1.3
Python version 3.5
cmake
visual studio 2015

- **Additional Dependencies**:
zlib\install\lib\zlibstatic.lib
gif\install\lib\giflib.lib
png\install\lib\libpng12_static.lib
jpeg\install\lib\libjpeg.lib
lmdb\install\lib\lmdb.lib
jsoncpp\src\jsoncpp\src\lib_json\Release\jsoncpp.lib
farmhash\install\lib\farmhash.lib
fft2d\\src\lib\fft2d.lib
highwayhash\install\lib\highwayhash.lib
libprotobuf.lib
tf_protos_cc.lib
tf_cc.lib
tf_cc_ops.lib
tf_cc_framework.lib
tf_core_cpu.lib
tf_core_direct_session.lib
tf_core_framework.lib
tf_core_kernels.lib
tf_core_lib.lib
tf_core_ops.dir\Release\tf_core_ops.lib
nsync\src\nsync\Release\nsync.lib
sqlite\src\sqlite-build\Release\sqlite.lib
snappy\src\snappy\Release\snappy.lib

- **Error**:
`Severity	Code	Description	Project	File	Line	Suppression State
Error	LNK2019	unresolved external symbol ""class tensorflow::Status __cdecl tensorflow::ops::BuildWhileLoop(class tensorflow::Scope const &,class std::vector<class tensorflow::Output,class std::allocator<class tensorflow::Output> > const &,class std::function<class tensorflow::Status __cdecl(class tensorflow::Scope const &,class std::vector<class tensorflow::Output,class std::allocator<class tensorflow::Output> > const &,class tensorflow::Output *)> const &,class std::function<class tensorflow::Status __cdecl(class tensorflow::Scope const &,class std::vector<class tensorflow::Output,class std::allocator<class tensorflow::Output> > const &,class std::vector<class tensorflow::Output,class std::allocator<class tensorflow::Output> > *)> const &,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &,class std::vector<class tensorflow::Output,class std::allocator<class tensorflow::Output> > *,bool,class tensorflow::Output *)"" (?BuildWhileLoop@ops@tensorflow@@YA?AVStatus@2@AEBVScope@2@AEBV?$vector@VOutput@tensorflow@@V?$allocator@VOutput@tensorflow@@@std@@@std@@AEBV?$function@$$A6A?AVStatus@tensorflow@@AEBVScope@2@AEBV?$vector@VOutput@tensorflow@@V?$allocator@VOutput@tensorflow@@@std@@@std@@PEAVOutput@2@@Z@6@AEBV?$function@$$A6A?AVStatus@tensorflow@@AEBVScope@2@AEBV?$vector@VOutput@tensorflow@@V?$allocator@VOutput@tensorflow@@@std@@@std@@PEAV45@@Z@6@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@6@PEAV56@_NPEAVOutput@2@@Z) referenced in function ""class tensorflow::Status __cdecl tensorflow::`anonymous namespace'::AddBackPropLoopCounter(class tensorflow::WhileContext *,class tensorflow::Output const &,class tensorflow::Scope const &,class tensorflow::Output *)"" (?AddBackPropLoopCounter@?A0xb5093d1e@tensorflow@@YA?AVStatus@2@PEAVWhileContext@2@AEBVOutput@2@AEBVScope@2@PEAV52@@Z)	tensorflow_test2	C:\Users\mcuevas\Documents\Visual Studio 2015\Projects\tensorflow_test2\tensorflow_test2\tf_cc.lib(while_gradients.obj)	1	
`"
14292,Can't import contrib.boosted_trees,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
== cat /etc/issue ===============================================                                               
Linux 5508912-0913 4.4.0-43-Microsoft #1-Microsoft Wed Dec 31 14:42:53 PST 2014 x86_64 x86_64 x86_64 GNU/Linux  
VERSION=""16.04.3 LTS (Xenial Xerus)""                                                                            
VERSION_ID=""16.04""                                                                                              
VERSION_CODENAME=xenial                                                                                         
                                                                                                                
== are we in docker =============================================                                               
No                                                                                                              
                                                                                                                
== compiler =====================================================                                               
c++ (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609                                                              
Copyright (C) 2015 Free Software Foundation, Inc.                                                               
This is free software; see the source for copying conditions.  There is NO                                      
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.                                     
                                                                                                                
                                                                                                                
== uname -a =====================================================                                               
Linux 5508912-0913 4.4.0-43-Microsoft #1-Microsoft Wed Dec 31 14:42:53 PST 2014 x86_64 x86_64 x86_64 GNU/Linux  
                                                                                                                
== check pips ===================================================                                               
numpy (1.13.3)                                                                                                  
protobuf (3.4.0)                                                                                                
tensorflow (1.4.0)                                                                                              
tensorflow-tensorboard (0.4.0rc1)                                                                               
                                                                                                                
== check for virtualenv =========================================                                               
False                                                                                                           
                                                                                                                
== tensorflow import ============================================                                               
tf.VERSION = 1.4.0                                                                                              
tf.GIT_VERSION = v1.4.0-0-gd752244                                                                              
tf.COMPILER_VERSION = v1.4.0-0-gd752244                                                                         
Sanity check: array([1], dtype=int32)                                                                           
                                                                                                                
== env ==========================================================                                               
LD_LIBRARY_PATH is unset                                                                                        
DYLD_LIBRARY_PATH is unset                                                                                      
                                                                                                                
== nvidia-smi ===================================================                                               
../../tf_env_collect.sh: line 105: nvidia-smi: command not found                                                
                                                                                                                
== cuda libs  ===================================================                                               

### Describe the problem
Can't import the boosted_trees module.
Boosted_trees isn't properly listed in contrib/__init__.py, so I get:
>>> import tensorflow as tf
>>> est = tf.contrib.boosted_trees.estimator_batch.estimator.GradientBoostedDecisionTreeClassifier()
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/lazy_loader.py"", line 54, in __getattr__
    return getattr(module, item)
AttributeError: 'module' object has no attribute 'boosted_trees'


### Source code / logs
See above.
"
14291,map_fn not working with string tensor on Android,"It seems that the tensorflow Android version (1.4.0) does not include the kernel for TensorArrayScatterV3 for string tensors (see stacktrace below). This leads to the problem that I cannot use map_fn with string tensors on Android. 

The same code and model runs fine with the desktop Java API in the same version. 

Can you please add the missing kernel?

Stacktrace

```
11-06 15:14:45.760 32605-1644/de.test.android.fisheye.local W/System.err: java.util.concurrent.ExecutionException: java.lang.IllegalArgumentException: No OpKernel was registered to support Op 'TensorArrayScatterV3' with these attrs.  Registered devices: [CPU], Registered kernels:
11-06 15:14:45.760 32605-1644/de.test.android.fisheye.local W/System.err:   device='CPU'; T in [DT_BOOL]
11-06 15:14:45.760 32605-1644/de.test.android.fisheye.local W/System.err:   device='CPU'; T in [DT_FLOAT]
11-06 15:14:45.760 32605-1644/de.test.android.fisheye.local W/System.err:   device='CPU'; T in [DT_INT32]
11-06 15:14:45.760 32605-1644/de.test.android.fisheye.local W/System.err: 	 [[Node: map/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3 = TensorArrayScatterV3[T=DT_STRING, _class=[""loc:@image_strings""]](map/TensorArray, map/TensorArrayUnstack/range, image_strings, map/TensorArray:1)]]
11-06 15:14:45.760 32605-1644/de.test.android.fisheye.local W/System.err:     at java.util.concurrent.FutureTask.report(FutureTask.java:94)
11-06 15:14:45.760 32605-1644/de.test.android.fisheye.local W/System.err:     at java.util.concurrent.FutureTask.get(FutureTask.java:164)
11-06 15:14:45.760 32605-1644/de.test.android.fisheye.local W/System.err:     at de.test.neuronalnetwork.service.TaskWorkerLoop$Loop.run(TaskWorkerLoop.java:71)
11-06 15:14:45.761 32605-1644/de.test.android.fisheye.local W/System.err:     at java.lang.Thread.run(Thread.java:762)
11-06 15:14:45.761 32605-1644/de.test.android.fisheye.local W/System.err: Caused by: java.lang.IllegalArgumentException: No OpKernel was registered to support Op 'TensorArrayScatterV3' with these attrs.  Registered devices: [CPU], Registered kernels:
11-06 15:14:45.761 32605-1644/de.test.android.fisheye.local W/System.err:   device='CPU'; T in [DT_BOOL]
11-06 15:14:45.761 32605-1644/de.test.android.fisheye.local W/System.err:   device='CPU'; T in [DT_FLOAT]
11-06 15:14:45.761 32605-1644/de.test.android.fisheye.local W/System.err:   device='CPU'; T in [DT_INT32]
11-06 15:14:45.761 32605-1644/de.test.android.fisheye.local W/System.err: 	 [[Node: map/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3 = TensorArrayScatterV3[T=DT_STRING, _class=[""loc:@image_strings""]](map/TensorArray, map/TensorArrayUnstack/range, image_strings, map/TensorArray:1)]]
11-06 15:14:45.761 32605-1644/de.test.android.fisheye.local W/System.err:     at org.tensorflow.Session.run(Native Method)
11-06 15:14:45.761 32605-1644/de.test.android.fisheye.local W/System.err:     at org.tensorflow.Session.access$100(Session.java:48)
11-06 15:14:45.761 32605-1644/de.test.android.fisheye.local W/System.err:     at org.tensorflow.Session$Runner.runHelper(Session.java:298)
11-06 15:14:45.761 32605-1644/de.test.android.fisheye.local W/System.err:     at org.tensorflow.Session$Runner.run(Session.java:248)
11-06 15:14:45.761 32605-1644/de.test.android.fisheye.local W/System.err:     at de.test.brain.Api.run(Api.java:39)
11-06 15:14:45.761 32605-1644/de.test.android.fisheye.local W/System.err:     at de.test.client.api.Evaluator.evaluateBatch(Evaluator.java:66)
11-06 15:14:45.761 32605-1644/de.test.android.fisheye.local W/System.err:     at de.test.client.api.Evaluator.evaluate(Evaluator.java:54)
11-06 15:14:45.761 32605-1644/de.test.android.fisheye.local W/System.err:     at de.test.client.api.EvaluationService.evaluateNN(EvaluationService.java:114)
11-06 15:14:45.761 32605-1644/de.test.android.fisheye.local W/System.err:     at de.test.client.api.EvaluationService.evaluateSections(EvaluationService.java:73)
11-06 15:14:45.761 32605-1644/de.test.android.fisheye.local W/System.err:     at de.test.neuronalnetwork.service.engine.NetworkEngine.lambda$calculate$0(NetworkEngine.java:59)
11-06 15:14:45.762 32605-1644/de.test.android.fisheye.local W/System.err:     at de.test.neuronalnetwork.service.engine.NetworkEngine$$Lambda$1.call(Unknown Source)
11-06 15:14:45.762 32605-1644/de.test.android.fisheye.local W/System.err:     at java.util.concurrent.FutureTask.run(FutureTask.java:237)
11-06 15:14:45.762 32605-1644/de.test.android.fisheye.local W/System.err:     at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:428)
11-06 15:14:45.762 32605-1644/de.test.android.fisheye.local W/System.err:     at java.util.concurrent.FutureTask.run(FutureTask.java:237)
11-06 15:14:45.762 32605-1644/de.test.android.fisheye.local W/System.err:     at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1133)
11-06 15:14:45.762 32605-1644/de.test.android.fisheye.local W/System.err:     at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:607)
11-06 15:14:45.762 32605-1644/de.test.android.fisheye.local W/System.err: 	... 1 more
```"
14289,Is something wrong about slim.learning.train?,"[source code](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/slim/python/slim/learning.py)

My code is so complex and very very long, so I just describe my code logic.

I add two parameters `run_tensor` and `run_placeholder` to `slim.learning.train`, the `run_tensor` is the tensor I want to run and the `run_placeholder` is placeholder I need to feed. And I also add two parameters `run_tensor` and `run_placeholder` to [`train_step`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/slim/python/slim/learning.py#L456), and `train_step` is passed to `slim.learning.train`'s `train_step_fn`. So every training step, I can run `run_tensor` in the  `train_step`  function, and I'm sure I have fed the `run_placeholder`, but when I run the program, it raise an error, like:

```
Invalid argument: You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape
[...]
``` 

~~I debug for long time, and find it may be the [line](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/slim/python/slim/learning.py#L779)~~ 

~~I have updated tensorflow to 1.4.0, but I  find my `slim.learning.train` only use `sv.stop(threads, close_summary_writer=True)`, without `ignore_live_threads=ignore_live_threads`.~~

I find what's wrong, it is `tf.summary.scalar`, slim doesn't run `summary` op with feed_dict.
Maybe I think slim need to support feed_dict on every training step.
"
14285,"TF 1.4.0 on MacOSX: crash, object was probably modified after being freed","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOSX 10.13
- **TensorFlow installed from (source or binary)**: binary, via `pip3.6 install tensorflow`
- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**:  3.6.3, via Homebrew

### Describe the problem

TensorFlow crashes in some cases. This occurred only now with version TF 1.4.0. It is a test of my test suite ([this one](https://github.com/rwth-i6/returnn/blob/4a69d0a1e74fb1ac7f76fc8c27694d906f9a8642/tests/test_TFEngine.py#L459)). I can try to come up with a reduced test case but maybe the current information is already enough to identify the problem.

On the terminal, I see this:
```
Python(60770,0x70000fafb000) malloc: *** error for object 0x7fb861518b48: incorrect checksum for freed object - object was probably modified after being freed.
*** set a breakpoint in malloc_error_break to debug
fish: Job 1, 'python3 tests/test_TFEngine.py test_engine_train_simple_attention' terminated by signal SIGABRT (Abort)
```

The crashed thread stacktrace:
```
Thread 15 Crashed:
0   libsystem_kernel.dylib        	0x00007fff7c559fce __pthread_kill + 10
1   libsystem_pthread.dylib       	0x00007fff7c697150 pthread_kill + 333
2   libsystem_c.dylib             	0x00007fff7c4b632a abort + 127
3   libsystem_malloc.dylib        	0x00007fff7c5beb28 szone_error + 596
4   libsystem_malloc.dylib        	0x00007fff7c5c9ea5 tiny_free_no_lock + 2439
5   libsystem_malloc.dylib        	0x00007fff7c5ca254 free_tiny + 628
6   libtensorflow_framework.so    	0x00000001091927c2 tensorflow::Tensor::~Tensor() + 50
7   libtensorflow_framework.so    	0x00000001095d1b2e tensorflow::(anonymous namespace)::ExecutorState::Process(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long) + 5646
8   libtensorflow_framework.so    	0x00000001095d9d90 std::__1::__function::__func<std::__1::__bind<void (tensorflow::(anonymous namespace)::ExecutorState::*)(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long), tensorflow::(anonymous namespace)::ExecutorState*, tensorflow::(anonymous namespace)::ExecutorState::TaggedNode const&, long long&>, std::__1::allocator<std::__1::__bind<void (tensorflow::(anonymous namespace)::ExecutorState::*)(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long), tensorflow::(anonymous namespace)::ExecutorState*, tensorflow::(anonymous namespace)::ExecutorState::TaggedNode const&, long long&> >, void ()>::operator()() + 80
9   libtensorflow_framework.so    	0x0000000109277fc2 Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 1922
10  libtensorflow_framework.so    	0x0000000109277734 std::__1::__function::__func<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'(), std::__1::allocator<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()>, void ()>::operator()() + 52
11  libtensorflow_framework.so    	0x000000010929a9c0 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::function<void ()> > >(void*) + 96
12  libsystem_pthread.dylib       	0x00007fff7c6946c1 _pthread_body + 340
13  libsystem_pthread.dylib       	0x00007fff7c69456d _pthread_start + 377
14  libsystem_pthread.dylib       	0x00007fff7c693c5d thread_start + 13
```

Alternatively, I sometimes get this crashed thread stacktrace:
```
Thread 12 Crashed:
0   libtensorflow_framework.so    	0x000000010e9fd5b7 tensorflow::Tensor::CheckTypeAndIsAligned(tensorflow::DataType) const + 71
1   _pywrap_tensorflow_internal.so	0x0000000108b16932 tensorflow::(anonymous namespace)::CheckNumericsOp<Eigen::ThreadPoolDevice, float>::Compute(tensorflow::OpKernelContext*) + 98
2   libtensorflow_framework.so    	0x000000010ee6d88d tensorflow::ThreadPoolDevice::Compute(tensorflow::OpKernel*, tensorflow::OpKernelContext*) + 301
3   libtensorflow_framework.so    	0x000000010ee3c82b tensorflow::(anonymous namespace)::ExecutorState::Process(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long) + 4875
4   libtensorflow_framework.so    	0x000000010ee44d90 std::__1::__function::__func<std::__1::__bind<void (tensorflow::(anonymous namespace)::ExecutorState::*)(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long), tensorflow::(anonymous namespace)::ExecutorState*, tensorflow::(anonymous namespace)::ExecutorState::TaggedNode const&, long long&>, std::__1::allocator<std::__1::__bind<void (tensorflow::(anonymous namespace)::ExecutorState::*)(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long), tensorflow::(anonymous namespace)::ExecutorState*, tensorflow::(anonymous namespace)::ExecutorState::TaggedNode const&, long long&> >, void ()>::operator()() + 80
5   libtensorflow_framework.so    	0x000000010eae2fc2 Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 1922
6   libtensorflow_framework.so    	0x000000010eae2734 std::__1::__function::__func<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'(), std::__1::allocator<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()>, void ()>::operator()() + 52
7   libtensorflow_framework.so    	0x000000010eb059c0 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::function<void ()> > >(void*) + 96
8   libsystem_pthread.dylib       	0x00007fff7c6946c1 _pthread_body + 340
9   libsystem_pthread.dylib       	0x00007fff7c69456d _pthread_start + 377
10  libsystem_pthread.dylib       	0x00007fff7c693c5d thread_start + 13
```

Maybe the main thread stacktrace is also relevant:
```
Thread 0:: Dispatch queue: com.apple.main-thread
0   libsystem_kernel.dylib        	0x00007fff7c559e7e __psynch_cvwait + 10
1   libsystem_pthread.dylib       	0x00007fff7c695662 _pthread_cond_wait + 732
2   libc++.1.dylib                	0x00007fff7a449cb0 std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18
3   _pywrap_tensorflow_internal.so	0x000000010dc2d23b nsync::nsync_mu_semaphore_p_with_deadline(nsync::nsync_semaphore_s_*, timespec) + 363
4   _pywrap_tensorflow_internal.so	0x000000010dc29c97 nsync::nsync_cv_wait_with_deadline_generic(nsync::nsync_cv_s_*, void*, void (*)(void*), void (*)(void*), timespec, nsync::nsync_note_s_*) + 423
5   _pywrap_tensorflow_internal.so	0x000000010dc2a3d1 nsync::nsync_cv_wait(nsync::nsync_cv_s_*, nsync::nsync_mu_s_*) + 49
6   _pywrap_tensorflow_internal.so	0x000000010dc3771b tensorflow::DirectSession::WaitForNotification(tensorflow::Notification*, long long) + 107
7   _pywrap_tensorflow_internal.so	0x000000010dc332a6 tensorflow::DirectSession::WaitForNotification(tensorflow::DirectSession::RunState*, tensorflow::CancellationManager*, long long) + 38
8   _pywrap_tensorflow_internal.so	0x000000010dc2fe3e tensorflow::DirectSession::Run(tensorflow::RunOptions const&, std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::Tensor>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::Tensor> > > const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, std::__1::vector<tensorflow::Tensor, std::__1::allocator<tensorflow::Tensor> >*, tensorflow::RunMetadata*) + 3438
9   _pywrap_tensorflow_internal.so	0x000000010bf0827e TF_Run_Helper(tensorflow::Session*, char const*, TF_Buffer const*, std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::Tensor>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::Tensor> > > const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, TF_Tensor**, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, TF_Buffer*, TF_Status*) + 750
10  _pywrap_tensorflow_internal.so	0x000000010bf07eb6 TF_Run + 1286
11  _pywrap_tensorflow_internal.so	0x000000010bc990b3 tensorflow::TF_Run_wrapper_helper(TF_DeprecatedSession*, char const*, TF_Buffer const*, _object*, tensorflow::gtl::InlinedVector<char const*, 8> const&, tensorflow::gtl::InlinedVector<char const*, 8> const&, TF_Status*, tensorflow::gtl::InlinedVector<_object*, 8>*, TF_Buffer*) + 1683
12  _pywrap_tensorflow_internal.so	0x000000010bc997e4 tensorflow::TF_Run_wrapper(TF_DeprecatedSession*, TF_Buffer const*, _object*, tensorflow::gtl::InlinedVector<char const*, 8> const&, tensorflow::gtl::InlinedVector<char const*, 8> const&, TF_Status*, tensorflow::gtl::InlinedVector<_object*, 8>*, TF_Buffer*) + 52
13  _pywrap_tensorflow_internal.so	0x000000010bc5b885 _wrap_TF_Run(_object*, _object*) + 1861
14  org.python.python             	0x000000010797b5dd _PyCFunction_FastCallDict + 166
...
```

The full MacOSX crash report with the stacktrace of all threads can be seen [here](https://gist.github.com/albertz/6f92b691d6025f47f8ec3a738a8ba970).

On another run, I also got this stacktrace:
```
Crashed Thread:        0  Dispatch queue: com.apple.main-thread

Exception Type:        EXC_BAD_ACCESS (SIGSEGV)
Exception Codes:       EXC_I386_GPFLT
Exception Note:        EXC_CORPSE_NOTIFY

Termination Signal:    Segmentation fault: 11
Termination Reason:    Namespace SIGNAL, Code 0xb
Terminating Process:   exc handler [0]

Thread 0 Crashed:: Dispatch queue: com.apple.main-thread
0   libtensorflow_framework.so    	0x0000000115d21a1e tensorflow::(anonymous namespace)::AddArgToSig(tensorflow::NodeDef const&, tensorflow::OpDef_ArgDef const&, tensorflow::gtl::InlinedVector<tensorflow::DataType, 4>*) + 78
1   libtensorflow_framework.so    	0x0000000115d21942 tensorflow::InOutTypesForNode(tensorflow::NodeDef const&, tensorflow::OpDef const&, tensorflow::gtl::InlinedVector<tensorflow::DataType, 4>*, tensorflow::gtl::InlinedVector<tensorflow::DataType, 4>*) + 82
2   libtensorflow_framework.so    	0x0000000115d22829 tensorflow::ValidateNodeDef(tensorflow::NodeDef const&, tensorflow::OpDef const&) + 1881
3   _pywrap_tensorflow_internal.so	0x0000000110f83e16 tensorflow::graph::ValidateGraphDef(tensorflow::GraphDef const&, tensorflow::OpRegistryInterface const&) + 134
4   _pywrap_tensorflow_internal.so	0x0000000110eef9c3 tensorflow::GraphExecutionState::Extend(tensorflow::GraphDef const&, std::__1::unique_ptr<tensorflow::GraphExecutionState, std::__1::default_delete<tensorflow::GraphExecutionState> >*) const + 2147
5   _pywrap_tensorflow_internal.so	0x0000000110d18e03 tensorflow::DirectSession::ExtendLocked(tensorflow::GraphDef const&) + 131
6   _pywrap_tensorflow_internal.so	0x0000000110d18eb3 tensorflow::DirectSession::Extend(tensorflow::GraphDef const&) + 67
7   _pywrap_tensorflow_internal.so	0x000000010eff04f6 TF_ExtendGraph + 102
8   _pywrap_tensorflow_internal.so	0x000000010ed43b71 _wrap_TF_ExtendGraph(_object*, _object*) + 273
9   org.python.python             	0x000000010d57d5dd _PyCFunction_FastCallDict + 166
...
```

And yet another stacktrace:
```
Thread 13 Crashed:
0   _pywrap_tensorflow_internal.so	0x0000000107a4016a tensorflow::TTypes<int, 3ul, long>::ConstTensor tensorflow::Tensor::bit_casted_shaped<int, 3ul>(tensorflow::gtl::ArraySlice<long long>) const + 42
1   _pywrap_tensorflow_internal.so	0x0000000107a45a6e void tensorflow::HandleStridedSliceGradCase<Eigen::ThreadPoolDevice, float, 3>(tensorflow::OpKernelContext*, tensorflow::gtl::ArraySlice<long long> const&, tensorflow::gtl::ArraySlice<long long> const&, tensorflow::gtl::ArraySlice<long long> const&, tensorflow::TensorShape const&, bool, tensorflow::Tensor*) + 302
2   _pywrap_tensorflow_internal.so	0x00000001079ff7ac tensorflow::StridedSliceGradOp<Eigen::ThreadPoolDevice, float>::Compute(tensorflow::OpKernelContext*) + 2556
3   libtensorflow_framework.so    	0x000000010644788d tensorflow::ThreadPoolDevice::Compute(tensorflow::OpKernel*, tensorflow::OpKernelContext*) + 301
4   libtensorflow_framework.so    	0x000000010641682b tensorflow::(anonymous namespace)::ExecutorState::Process(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long) + 4875
5   libtensorflow_framework.so    	0x000000010641ed90 std::__1::__function::__func<std::__1::__bind<void (tensorflow::(anonymous namespace)::ExecutorState::*)(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long), tensorflow::(anonymous namespace)::ExecutorState*, tensorflow::(anonymous namespace)::ExecutorState::TaggedNode const&, long long&>, std::__1::allocator<std::__1::__bind<void (tensorflow::(anonymous namespace)::ExecutorState::*)(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long), tensorflow::(anonymous namespace)::ExecutorState*, tensorflow::(anonymous namespace)::ExecutorState::TaggedNode const&, long long&> >, void ()>::operator()() + 80
6   libtensorflow_framework.so    	0x00000001060bcfc2 Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 1922
7   libtensorflow_framework.so    	0x00000001060bc734 std::__1::__function::__func<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'(), std::__1::allocator<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()>, void ()>::operator()() + 52
8   libtensorflow_framework.so    	0x00000001060df9c0 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::function<void ()> > >(void*) + 96
9   libsystem_pthread.dylib       	0x00007fff7c6946c1 _pthread_body + 340
10  libsystem_pthread.dylib       	0x00007fff7c69456d _pthread_start + 377
11  libsystem_pthread.dylib       	0x00007fff7c693c5d thread_start + 13
```

Or this:
```
Thread 12 Crashed:
0   libsystem_kernel.dylib        	0x00007fff7c55a1ea __semwait_signal_nocancel + 10
1   libsystem_c.dylib             	0x00007fff7c460097 nanosleep$NOCANCEL + 188
2   libsystem_c.dylib             	0x00007fff7c488931 usleep$NOCANCEL + 53
3   libsystem_c.dylib             	0x00007fff7c4b6334 abort + 137
4   libsystem_malloc.dylib        	0x00007fff7c5beb28 szone_error + 596
5   libsystem_malloc.dylib        	0x00007fff7c5b3658 tiny_malloc_from_free_list + 1155
6   libsystem_malloc.dylib        	0x00007fff7c5b2403 szone_malloc_should_clear + 422
7   libsystem_malloc.dylib        	0x00007fff7c5b2201 malloc_zone_malloc + 103
8   libsystem_malloc.dylib        	0x00007fff7c5b150b malloc + 24
9   libc++abi.dylib               	0x00007fff7a49b628 operator new(unsigned long) + 40
10  _pywrap_tensorflow_internal.so	0x0000000108c9bc16 tensorflow::ApplyAdamOp<Eigen::ThreadPoolDevice, float>::Compute(tensorflow::OpKernelContext*) + 70
11  libtensorflow_framework.so    	0x000000010e45488d tensorflow::ThreadPoolDevice::Compute(tensorflow::OpKernel*, tensorflow::OpKernelContext*) + 301
12  libtensorflow_framework.so    	0x000000010e42382b tensorflow::(anonymous namespace)::ExecutorState::Process(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long) + 4875
13  libtensorflow_framework.so    	0x000000010e42bd90 std::__1::__function::__func<std::__1::__bind<void (tensorflow::(anonymous namespace)::ExecutorState::*)(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long), tensorflow::(anonymous namespace)::ExecutorState*, tensorflow::(anonymous namespace)::ExecutorState::TaggedNode const&, long long&>, std::__1::allocator<std::__1::__bind<void (tensorflow::(anonymous namespace)::ExecutorState::*)(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long), tensorflow::(anonymous namespace)::ExecutorState*, tensorflow::(anonymous namespace)::ExecutorState::TaggedNode const&, long long&> >, void ()>::operator()() + 80
14  libtensorflow_framework.so    	0x000000010e0c9fc2 Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 1922
15  libtensorflow_framework.so    	0x000000010e0c9734 std::__1::__function::__func<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'(), std::__1::allocator<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()>, void ()>::operator()() + 52
16  libtensorflow_framework.so    	0x000000010e0ec9c0 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::function<void ()> > >(void*) + 96
17  libsystem_pthread.dylib       	0x00007fff7c6946c1 _pthread_body + 340
18  libsystem_pthread.dylib       	0x00007fff7c69456d _pthread_start + 377
19  libsystem_pthread.dylib       	0x00007fff7c693c5d thread_start + 13
```

This might be related to our own C++ operation which has worked fine so far (we used it since TF 0.8), although of course this might be triggered only now by some race condition. Is there anything new I need to take care of? I think this NSync stuff is new?
"
14284,Estimator from Keras by model_to_estimator cannot export,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS 10.12
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: 1.4 or Master 


### Describe the problem
when calling model_to_estimator, the model_fn create by _create_keras_model_fn didn't set ```export_outputs``` in the returned ```EstimatorSpec```, see [this](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/_impl/keras/estimator.py#L182). That make it unable to export to SavedModel, the following error raised when call ```estimator.export_savedmodel()```

```
packages/tensorflow/python/estimator/export/export.py"", line 193, in build_all_signature_defs
    raise ValueError('export_outputs must be a dict.')
ValueError: export_outputs must be a dict.
```

I would like contrib a PR for fixing this if is OK

"
14283,Can't use estimator + dataset and train for less than one epoch,"TensorFlow 1.4 moves TF Dataset to core (tf.data.Dataset) and doc/tutorial suggest to use tf.estimator to train models.

However, as recommended at the end of this [page](https://www.tensorflow.org/programmers_guide/datasets), the Dataset object and its iterator must be instantiated inside the input_fn function. This means the iterations through the dataset will start over for each call to estimator.train(input_fn, steps). Thus, calling is with steps < number of samples in epoch, will lead to train the model on a subset of the dataset.

Thus my question. Is it possible to implement something like this with Estimator + Dataset:

```
for i in range(num_epochs):
    # Train for some steps
    estimator.train(input_fn=train_input_fn, steps=valid_freq)

   validation_iterator.
    # Evaluate on the validation set (steps=None, we evaluate on the full validation set)
   estimator.evaluate(input_fn=valid_input_fn)
```

without starting training samples iterations from scratch at each call to `estimator.train(input_fn=train_input_fn, steps=valid_freq)
`

For example, unlike [here](https://www.tensorflow.org/programmers_guide/datasets), instantiate the Dataset and its iterator outside input_fn. I tried it but it does not work because then the input (from the dataset iterator) and the model (from the estimator model_fn) are not part of the same graph.

Thanks"
14282,Neural Net regression in Tensorflow,"### Describe the problem
Hi, I am trying to perform a Neural Network in tensorflow for The Bike-Sharing-Dataset with a regresion model. I checked out the tensorflow tutorials but I couldn't find  a solution. Something's wrong with the tf.matmul() and the input and  targets matrix. 

### Source code / logs
Here is my [repository](https://github.com/deepSalva/bikes_in_tensorflow.git) and the dataset.

Thanks so much!
"
14280,Failed to load the native TensorFlow runtime.,"when I import tensorflow-gpu,

>>import tensorflow as tf


this message occurs


Traceback (most recent call last):
  File ""/home/wonjinlee/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/home/wonjinlee/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/home/wonjinlee/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/usr/lib/python3.5/imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""/usr/lib/python3.5/imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/wonjinlee/.local/lib/python3.5/site-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/home/wonjinlee/.local/lib/python3.5/site-packages/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/home/wonjinlee/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 72, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/home/wonjinlee/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/home/wonjinlee/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/home/wonjinlee/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/usr/lib/python3.5/imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""/usr/lib/python3.5/imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

"
14279,"Cannot interpret feed_dict key as tensor: tensor tensor(import/input:0, shape=(1, 299, 299, 3), dtype=float32) is not an element of this graph.","I'm running `label_image.py` code given at [https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/label_image/label_image.py](url) for inference on an image using InceptionV3 model trained on my own dataset. But it's giving the following error

> Cannot interpret feed_dict key as tensor: tensor tensor(import/input:0, shape=(1, 299, 299, 3), dtype=float32) is not an element of this graph.

Could anyone please help me with this issue ? Thanks in advance."
14278,depthwise_ops build incorrect on MSVC debug mode,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 10
- **TensorFlow installed from (source or binary)**:
Source
- **TensorFlow version (use command below)**:
1.4
- **Python version**: 
3.5.4
- **Bazel version (if compiling from source)**:
0.7.0
- **GCC/Compiler version (if compiling from source)**:
VS 2017
- **CUDA/cuDNN version**:
None
- **GPU model and memory**:
None
- **Exact command to reproduce**:
bazel --output_base C:\os\t build --config=monolithic --incompatible_disallow_set_constructor=false --action_env=USE_DYNAMIC_CRT=1  --color=no --compilation_mode fastbuild --verbose_failures --experimental_ui  //tensorflow/tools/pip_package:build_pip_package

### Describe the problem
Compile tensorflow in fastbuild mode( release mode,but without any optimization) failed.

### Source code / logs
848123e61c95b030a5034b2cdaa504870ebf7da6 is a dirty hack for this problem.  First,  you shouldn't simply remove the double type kernel in Windows Debug build, it will make some unitests fail.   Second, this fix doesn't fit for the ""fastbuild"" mode, as ""_DEBUG"" is not defined.

The root cause is VC cannot eliminate the dead code which is introduced by std::is_same. This problem also exists in tensorflow/core/kernels/depthtospace_op.cc and tensorflow/core/kernels/spacetodepth_op.cc.

"
14277,How to realize model parallelism,"I cannot find the model parallelism in the tensorflow, there are many examples about data parallelism. I write a programm to realize the model parallelism, but it cannot work.

from __future__ import print_function
import tensorflow as tf
import numpy as np



tf.train.ClusterSpec({
    ""worker"": [
        ""node1:2222""
    ],
    ""ps"": [
        ""node2:2222""
    ]})

with tf.device(""/job:ps/task:0""):
    weights = tf.Variable(tf.random_normal([1]),dtype=tf.float32,name='weights')
    bias = tf.Variable(tf.ones([1])+0.5,dtype=tf.float32, name='bias')

with tf.device(""/job:worker/task:0""):
    X = np.random.normal(0, 100, 100000)
    y = X * 0.5 + 10 + np.random.normal(0, 0.1, len(X))
    results = weights * X + bias
    loss = tf.reduce_mean(tf.square(y-results))
    optimizer = tf.train.GradientDescentOptimizer(0.1)
    train_op = optimizer.minimize(loss)
    init = tf.global_variables_initializer()

with tf.Session(""grpc://node2:2222"") as sess:
    sess.run(init)
    for _ in range(10000):
        Loss, T = sess.run([loss, train_op])
        print(Loss)"
14276,"Cannot interpret feed_dict key as tensor: tensor tensor(import/input:0, shape=(1, 299, 299, 3), dtype=float32) is not an element of this graph.","I'm running `label_image.py` given at [https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/label_image/label_image.py](url) on `inception_resnet_v2` frozen graph. When I run this code it's giving me the following error
`cannot interpret feed_dict key as tensor: tensor tensor(import/input:0, shape=(1, 299, 299, 3), dtype=float32) is not an element of this graph.`

But when I print the tensors, there exists the above tensor in the graph. Could anyone please help me with this ? Thanks in advance."
14275,changes in  ops_to_register.h file does not effect resulting compilation ,"
------------------------

### System information
- **Have I written custom code (https://github.com/tensorflow/tensorflow/issues/14215)**:
- **OS Platform and Distribution (Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source )**:
- **TensorFlow version (1.4)**:
- **Python version  2.7: 
- **Bazel version (0.7.0)**:



### Describe the problem
I have been running print_selective_registration_header to produce libtensorflow_inference.so
for android as described in : tensorflow/tensorflow/python/tools/print_selective_registration_header.py
i saw that ops_to_register.h was created correctly but the resulting    libtensorflow_inference.so did not work in android and there were always missing kernel ops errors,
i repeated the process with a few different graphs and i have noticed that the ops_to_register.h is being updated but there were no changes in the resulting libtensorflow_inference.so file.
i have tried all the possible bazel clean option and bazel dump thinking it is a bazel caching issue.
none helped ,
i opened this issue thinking it is an android bug :https://github.com/tensorflow/tensorflow/issues/14215
and closed it once i understood that the issue is that the result of the bazel build is worng

can anyone check this out?

"
14274,how can I print predictions  in TF-Slim's eval_image_classifier.py?,"I want to print prediction results into txt files  in TF-Slim [eval_image_classifier.py](https://github.com/tensorflow/models/blob/master/research/slim/eval_image_classifier.py) .  I have tried many times, but failed to do it.  
Thank you in advance.



===============================================================
`from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import math
import tensorflow as tf

from datasets import dataset_factory
from nets import nets_factory
from preprocessing import preprocessing_factory

slim = tf.contrib.slim

tf.app.flags.DEFINE_integer(
    'batch_size', 100, 'The number of samples in each batch.')

tf.app.flags.DEFINE_integer(
    'max_num_batches', None,
    'Max number of batches to evaluate by default use all.')

tf.app.flags.DEFINE_string(
    'master', '', 'The address of the TensorFlow master to use.')

tf.app.flags.DEFINE_string(
    'checkpoint_path', '/tmp/tfmodel/',
    'The directory where the model was written to or an absolute path to a '
    'checkpoint file.')

tf.app.flags.DEFINE_string(
    'eval_dir', '/tmp/tfmodel/', 'Directory where the results are saved to.')

tf.app.flags.DEFINE_integer(
    'num_preprocessing_threads', 4,
    'The number of threads used to create the batches.')

tf.app.flags.DEFINE_string(
    'dataset_name', 'imagenet', 'The name of the dataset to load.')

tf.app.flags.DEFINE_string(
    'dataset_split_name', 'test', 'The name of the train/test split.')

tf.app.flags.DEFINE_string(
    'dataset_dir', None, 'The directory where the dataset files are stored.')

tf.app.flags.DEFINE_integer(
    'labels_offset', 0,
    'An offset for the labels in the dataset. This flag is primarily used to '
    'evaluate the VGG and ResNet architectures which do not use a background '
    'class for the ImageNet dataset.')

tf.app.flags.DEFINE_string(
    'model_name', 'inception_v3', 'The name of the architecture to evaluate.')

tf.app.flags.DEFINE_string(
    'preprocessing_name', None, 'The name of the preprocessing to use. If left '
    'as `None`, then the model_name flag is used.')

tf.app.flags.DEFINE_float(
    'moving_average_decay', None,
    'The decay to use for the moving average.'
    'If left as None, then moving averages are not used.')

tf.app.flags.DEFINE_integer(
    'eval_image_size', None, 'Eval image size')

FLAGS = tf.app.flags.FLAGS


def main(_):
  if not FLAGS.dataset_dir:
    raise ValueError('You must supply the dataset directory with --dataset_dir')

  tf.logging.set_verbosity(tf.logging.INFO)
  with tf.Graph().as_default():
    tf_global_step = slim.get_or_create_global_step()

    ######################
    # Select the dataset #
    ######################
    dataset = dataset_factory.get_dataset(
        FLAGS.dataset_name, FLAGS.dataset_split_name, FLAGS.dataset_dir)

    ####################
    # Select the model #
    ####################
    network_fn = nets_factory.get_network_fn(
        FLAGS.model_name,
        num_classes=(dataset.num_classes - FLAGS.labels_offset),
        is_training=False)

    ##############################################################
    # Create a dataset provider that loads data from the dataset #
    ##############################################################
    provider = slim.dataset_data_provider.DatasetDataProvider(
        dataset,
        shuffle=False,
        common_queue_capacity=2 * FLAGS.batch_size,
        common_queue_min=FLAGS.batch_size)
    [image, label] = provider.get(['image', 'label'])
    label -= FLAGS.labels_offset

    #####################################
    # Select the preprocessing function #
    #####################################
    preprocessing_name = FLAGS.preprocessing_name or FLAGS.model_name
    image_preprocessing_fn = preprocessing_factory.get_preprocessing(
        preprocessing_name,
        is_training=False)

    eval_image_size = FLAGS.eval_image_size or network_fn.default_image_size

    image = image_preprocessing_fn(image, eval_image_size, eval_image_size)

    images, labels = tf.train.batch(
        [image, label],
        batch_size=FLAGS.batch_size,
        num_threads=FLAGS.num_preprocessing_threads,
        capacity=5 * FLAGS.batch_size)

    ####################
    # Define the model #
    ####################
    logits, _ = network_fn(images)

    if FLAGS.moving_average_decay:
      variable_averages = tf.train.ExponentialMovingAverage(
          FLAGS.moving_average_decay, tf_global_step)
      variables_to_restore = variable_averages.variables_to_restore(
          slim.get_model_variables())
      variables_to_restore[tf_global_step.op.name] = tf_global_step
    else:
      variables_to_restore = slim.get_variables_to_restore()

    predictions = tf.argmax(logits, 1)
    labels = tf.squeeze(labels)

    # Define the metrics:
    names_to_values, names_to_updates = slim.metrics.aggregate_metric_map({
        'Accuracy': slim.metrics.streaming_accuracy(predictions, labels),
        'Recall_5': slim.metrics.streaming_recall_at_k(
            logits, labels, 5),
    })

    # Print the summaries to screen.
    for name, value in names_to_values.items():
      summary_name = 'eval/%s' % name
      op = tf.summary.scalar(summary_name, value, collections=[])
      op = tf.Print(op, [value], summary_name)
      tf.add_to_collection(tf.GraphKeys.SUMMARIES, op)

    # TODO(sguada) use num_epochs=1
    if FLAGS.max_num_batches:
      num_batches = FLAGS.max_num_batches
    else:
      # This ensures that we make a single pass over all of the data.
      num_batches = math.ceil(dataset.num_samples / float(FLAGS.batch_size))

    if tf.gfile.IsDirectory(FLAGS.checkpoint_path):
      checkpoint_path = tf.train.latest_checkpoint(FLAGS.checkpoint_path)
    else:
      checkpoint_path = FLAGS.checkpoint_path

    tf.logging.info('Evaluating %s' % checkpoint_path)

    slim.evaluation.evaluate_once(
        master=FLAGS.master,
        checkpoint_path=checkpoint_path,
        logdir=FLAGS.eval_dir,
        num_evals=num_batches,
        eval_op=list(names_to_updates.values()),
        variables_to_restore=variables_to_restore)


if __name__ == '__main__':
  tf.app.run()`"
14273,RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
macOS High Sierra 10.13.1
- **TensorFlow installed from (source or binary)**:
pip3 install tensor flow
- **TensorFlow version (use command below)**:
1.4.0
- **Python version**: 
3.6.3
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
GCC: stable 7.2.0 
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:
python3 -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Error after install Tensorflow:

python3 -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6
  return f(*args, **kwds)
v1.4.0-rc1-11-g130a514 1.4.0

getting this and ONE MORE error when running:
python3 -c ""import keras; print (keras.__version__)""
Using TensorFlow backend.
/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6
  return f(*args, **kwds)
2017-11-06 15:12:09.361728: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2.0.9




### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
14271,tf.gradients return NaN when batch_norm is in inference mode (is_training=False)?,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**:('v1.3.0-rc2-20-g0787eee', '1.3.0')
- **Python version**: Python 2.7.11 |Anaconda custom (64-bit)
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:/usr/local/cuda-8.0 & libcudnn.so.6.0.21
- **GPU model and memory**:GeForce GTX 1080
- **Exact command to reproduce**:
```
git clone https://github.com/wenwei202/models.git
cd models
git checkout bug-fixing
cd research/slim
python eval_image_classifier_bn_grad.py -alsologtostderr --checkpoint_path /tmp/resnet_v1_152.ckpt  --dataset_dir /tmp/imagenet-data \
--dataset_name imagenet \
--dataset_split_name validation \
--model_name resnet_v1_152 \
--batch_size 5 --eval_dir /tmp/bn_grad \
--labels_offset=1  --max_num_batches 1
```

### Describe the problem, Source code / logs
I need to compute the gradients of dy/dx, where y is the max logit and x is input image. I just add a few lines to the standard [research/slim/eval_image_classifier.py](https://github.com/tensorflow/models/blob/master/research/slim/eval_image_classifier.py):
```
    max_logits = tf.reduce_max(logits, axis=1)
    themaps = tf.gradients(max_logits, images)
    themaps = themaps[0]
    with tf.control_dependencies([tf.Print(themaps,[themaps],first_n=3)]):
      themaps = tf.abs(themaps)
```
which is [here](https://github.com/wenwei202/models/blob/bug-fixing/research/slim/eval_image_classifier_bn_grad.py#L155-L159).
When I run `eval_image_classifier_bn_grad.py` to evaluate models [here](https://github.com/tensorflow/models/tree/master/research/slim#pre-trained-models), vgg and lenet work well, but `tf.gradients` always return `nan` when I evaluate inception and resnet models.
Command:
```
python eval_image_classifier_bn_grad.py -alsologtostderr --checkpoint_path /tmp/resnet_v1_152.ckpt  --dataset_dir /tmp/imagenet-data \
--dataset_name imagenet \
--dataset_split_name validation \
--model_name resnet_v1_152 \
--batch_size 5 --eval_dir /tmp/bn_grad \
--labels_offset=1  --max_num_batches 1
```
Output:
```
...
2017-11-05 23:25:19.751859: I tensorflow/core/kernels/logging_ops.cc:79] [[[[nan nan nan]]]...]
...
```

I guess the issue comes from the`slim.batch_norm` when it is in inference mode, and somehow, `tf.gradients` does not work anymore. Why?
  1. vgg and lenet without batch_norm layers work well 
  2. inception and resnet with batch_norm layers return `nan`
  3. inception and resnet work after I enforce the `is_training=True` of `slim.batch_norm`
  4. it seems ""reasonable"" to ignore the possibility of the usage of `tf.gradients` when `batch_norm` is in inference mode.
"
14267,opencv cannot read any image with tensorflow,"It is the same issue as #1924, since the bug is closed, I open a new one, because this bug haven't been solved yet.

From subashp

> I am using the TF 1.4 and linking against C++ code. Below code always says it failed to read the file. I have incorporated above suggestions and it doesnt make any difference. Thoughts/suggestions?


```
cv::String pathImg = argv[1];
cv::Mat img = cv::imread(pathImg, CV_LOAD_IMAGE_COLOR | CV_LOAD_IMAGE_ANYDEPTH);
if (img.empty()) {
error(""Failed to read the file {}"", argv[1]);
return -1;
}

```

From rmmal

> we cloned the latest version of tensorflow and still there is a problem of reading images using opencv , everytime i initiate a TENSOR object the opencv doesn't work.

From me, using tensor1.4, build from source

```
#include <opencv2/core.hpp>
#include <opencv2/highgui.hpp>

//unable to read any image if I include this header, no matter
//it before or after opencv
#include <tensorflow/cc/ops/const_op.h>

#include <iostream>

int main(int argc, char *argv[])
{
    cv::Mat input_mat = cv::imread(argv[1], cv::IMREAD_COLOR);
    std::cout<<argv[1]<<"", size:""<<input_mat.size()<<std::endl;    
}

```"
14266,Tensorflow splitting?,"I want to split tensor into two parts:   
 
    ipdb> mean_log_std
    <tf.Tensor 'pi/add_5:0' shape=(?, 2) dtype=float32>
  
Context: ? is for number of samples and the other dimension is 2. I want to split along the second dimension into two tensorflow of shape 1 along that dimension.

What I tried?(https://www.tensorflow.org/api_docs/python/tf/slice)
 
    ipdb> tf.slice(mean_log_std,[0,2],[0,1])
    <tf.Tensor 'pi/Slice_6:0' shape=(0, 1) dtype=float32>
    ipdb> tf.slice(mean_log_std,[0,1],[0,1])
    <tf.Tensor 'pi/Slice_7:0' shape=(0, 1) dtype=float32>
    ipdb>

I would expect the shape to be (?,1) and (?,1) for the above two splits.
"
14265,tf.layers generates an extra op when not specifying the name,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
pip install
- **TensorFlow version (use command below)**:
v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**: 
3.5.2
- **Bazel version (if compiling from source)**:
NA
- **GCC/Compiler version (if compiling from source)**:
NA
- **CUDA/cuDNN version**:
8.0.61
- **GPU model and memory**:
GeForce GTX 1080 Ti, 11GB
- **Exact command to reproduce**:

### Describe the problem
When using tf.layers, I notice that an extra op is generated when not specifying the name. 

For example, here is an example using tf.layers.dense. ""dense_1"" is an extra op. Similar problem has been observed for tf.layers.conv2d also. 
```
x = tf.placeholder(tf.float32, [None, 16], name='x')
hidden = tf.layers.dense(x, 32)
hidden = tf.layers.dense(hidden, 32)
y = tf.layers.dense(hidden, 1, name='y')
```
The graph in tensorboard is as follows. 
![image](https://user-images.githubusercontent.com/13603534/32421364-b057853e-c24c-11e7-8aa7-865a42fc22ee.png)

If I add the name, 
```
x = tf.placeholder(tf.float32, [None, 16], name='x')
hidden = tf.layers.dense(x, 32, name='h1')
hidden = tf.layers.dense(hidden, 32, name='h2')
y = tf.layers.dense(hidden, 1, name='y')
```
then the graph looks as expected,
![image](https://user-images.githubusercontent.com/13603534/32421378-daedd956-c24c-11e7-9487-ecf9ed0d8027.png)


"
14264,the version for windows,"Hi, could you build the new version of tensorflow for windows? the cuda version just tensorflow 1.1."
14261,'MultivariateNormalDiag' object has no attribute 'pdf' ERROR,"Hi,

I am trying to use tf.contrib.distributions.MultivariateNormalDiag 
 as explained  in the API https://www.tensorflow.org/versions/r0.12/api_docs/python/contrib.distributions/multivariate_distributions 

- macOS High Sierra
- **TensorFlow version**: v1.3.0-rc2-20-g0787eee 1.3.0
- **Python version**:  Python 3.6.1

Here is the code that throws the error:

	mu1 = tf.to_float(tf.fill([batch_size, z_dim], 0))
	diag_stdev1 = tf.to_float(tf.fill([batch_size, z_dim], 1))

	dist1 = tf.contrib.distributions.MultivariateNormalDiag(mu1, diag_stdev1)

	mu2 = tf.to_float(tf.fill([batch_size, z_dim], -1))
	diag_stdev2 = tf.to_float(tf.fill([batch_size, z_dim], 1))

	dist2 = tf.contrib.distributions.MultivariateNormalDiag(mu2, diag_stdev2)

	z_gmm = dist1.pdf(z) + dist2.pdf(z)

And the error I get is: 
AttributeError: 'MultivariateNormalDiag' object has no attribute 'pdf'

Does anybody have the same problem?
Thank you for you time."
14257,TFGAN gan_model tensor conversion necessary?,"I would like to use the `Dataset` API with the `GANEstimator`/`TFGAN`.

I know that `MakeIterator` cannot be cast to a tensor, but I would like to pass it to `generator_fn` anyways. Is the conversion of `generator_inputs` to tensors really necessary?

With the plain `Estimator` API I also do not have this restriction.

I am passing the following object to `gan_model` through `generator_inputs`:
```python
TextInput(initializer=<tf.Operation 'MakeIterator' type=MakeIterator>, batch_size=<tf.Tensor 'Size:0' shape=() dtype=int32>, source=<tf.Tensor 'IteratorGetNext:0' shape=(?, ?) dtype=int32>, target_input=<tf.Tensor 'IteratorGetNext:1' shape=(?, ?) dtype=int32>, target_output=<tf.Tensor 'IteratorGetNext:2' shape=(?, ?) dtype=int32>, source_sequence_length=<tf.Tensor 'IteratorGetNext:3' shape=(?,) dtype=int32>, target_sequence_length=<tf.Tensor 'IteratorGetNext:4' shape=(?,) dtype=int32>)
``` 

When running my program `_convert_tensor_or_l_or_d` throws an error:
```
  File ""C:\Development\Tools\miniconda\envs\tf-backbone\lib\site-packages\tensorflow\contrib\gan\python\train.py"", line 103, in gan_model
    with variable_scope.variable_scope(generator_scope) as gen_scope:
  File ""C:\Development\Tools\miniconda\envs\tf-backbone\lib\site-packages\tensorflow\contrib\gan\python\train.py"", line 789, in _convert_tensor_or_l_or_d
    return [ops.convert_to_tensor(x) for x in tensor_or_l_or_d]
  File ""C:\Development\Tools\miniconda\envs\tf-backbone\lib\site-packages\tensorflow\contrib\gan\python\train.py"", line 789, in <listcomp>
    return [ops.convert_to_tensor(x) for x in tensor_or_l_or_d]
  File ""C:\Development\Tools\miniconda\envs\tf-backbone\lib\site-packages\tensorflow\python\framework\ops.py"", line 836, in convert_to_tensor
    as_ref=False)
  File ""C:\Development\Tools\miniconda\envs\tf-backbone\lib\site-packages\tensorflow\python\framework\ops.py"", line 926, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""C:\Development\Tools\miniconda\envs\tf-backbone\lib\site-packages\tensorflow\python\framework\ops.py"", line 5069, in _operation_conversion_error
    name, as_ref))
TypeError: Can't convert Operation 'MakeIterator' to Tensor (target dtype=None, name=None, as_ref=False)
```

https://github.com/tensorflow/tensorflow/blob/7f84d88d39f236e5c0cea492a2248782e696c972/tensorflow/contrib/gan/python/train.py#L104"
14254,Tensors erroneously zero when an existing session is running on the same device,"UPDATE: Restarting my machine fixed the issue.

To reproduce, run two processes with
```python
import tensorflow as tf
import time
z = tf.constant([1.8, 2.2], dtype=tf.float32)
z = tf.cast(z, tf.int32)
with tf.Session() as sess:
    while True:
        print('z is', sess.run(z), 'but should be [1, 2]')
        time.sleep(1)
```
Second process output
```
z is [0 0] but should be [1, 2]
z is [0 0] but should be [1, 2]
...
```
Stopping the first process will fix the problem immediately without needing to restart the second process!

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.3.0-rc2-20-g0787eee 1.3.0
- **Python version**: 3.5.2
- **CUDA/cuDNN version**: CUDA 8 cuDNN 5.1.10
- **GPU model and memory**: GeForce GTX 980 4GB"
14252,"[Feature request] tf.edit_distance return deletions, substitutions, insertions","Hi,
When analysing the performance of a speech recognition model, it is very useful to know the distribution of deletions, substitutions and insertions on the test set.

Could you make `tf.edit_distance` return these three metrics too, in addition to the cheapest cost?
It appears to me that the [cpp code](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/lib/gtl/edit_distance.h#L47) already computes them. What do you think, @ebrevdo ?"
14250,[Feature request] tf.data.Dataset sort and skip buckets,"Hi
It would be useful to sort the variable length inputs by their lengths in order to accelerate the training process. However I cannot find this functionality yet.

In [[1]](https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-308789560), @guillaumekln already suggested something similar through his code snippet, yet the requested feature was batching inputs of similar length together, regardless of the processing order of the batches, and the solution of @mrry in [[2]](https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-326098305) using `group_by_window()` addressed this request just fine. _First question_: Would it be possible to make the iterator return the batches in the ascending order of their ids (given by `key_func`), while maintaining the shuffling operation applied before batching?

Additionally, I would like to skip the longer sentences early in training, with a length threshold that would gradually increase depending on the `global_step`. _Second question_: Could you reserve one batch id (e.g. -1) in `group_by_window` to tag the batches that will be skipped ? At the moment, it seems that all the ids are considered, even the negative values, and it would not be restrictive at all to allow only positive values (as there would still be 63 bits left to group the inputs). Thus, in `key_func` we could simply compare the input length with the threshold and return a negative value when it is above it.

Apologies if both functionalities are already available, feel free to stackoverflow me."
14249,Issue with installing TensorFlow with pip,"Hi!

I'm using Python 3.6.3
I'm trying to install TensorFlow using:
_pip3 install --upgrade tensorflow_

I get the following error:
_Collecting tensorflow
  Could not find a version that satisfies the requirement tensorflow (from versi
ons: )
No matching distribution found for tensorflow_

Could someone help to fix this?
"
14248,Keras backend functionality changed?,"Hi,

I have been using keras from within tensorflow since it was included into the contrib package - but it seems that in the 1.4 release the keras backend is missing some functionality ...

For example:

    >> from tensorflow.python.keras import backend as K
    >> K.tile
    Traceback (most recent call last):
      File ""<stdin>"", line 1, in <module>
    AttributeError: module 'tensorflow.python.keras.backend' has no attribute 'tile'

Whereas in tensorflow 1.1:

    >>> from tensorflow.contrib.keras.python.keras import backend as K
    >>> K.tile
    <function tile at 0x7fbd9024fb70>

And using pure keras:

    >>> from keras import backend as K
    Using TensorFlow backend.
    
    >>> K.tile
    <function tile at 0x7fe9743c5950>


Is this just an omission, or has the functionality been deliberately removed?  I know I can use the equivalent tensorflow operation - but it's nice to be able to use a reasonably portable api and if I wanted to switch backend I could just change the import path.  I also try not too mix keras and tensorflow too much as I think the code is more readable just using one!

Regards,

Alex

"
14247,BUG: ImportError: No module named 'tensorflow.contrib.eager',"### System information

##### I tried to `import tensorflow.contrib.eager as tfe` after installation and it throws No module error.
##### OS Platform and Distribution Linux Ubuntu 16.04:
##### TensorFlow installed from python pip in virtualenv:
##### TensorFlow version 1.1.0:
##### Python version 3.5:
##### GPU model and memory: GeForce GTX 1080
##### CUDA 8.0 /cuDNN 6.0:


### Describe the problem
After I install the eager, i.e. `pip install tf-nightly-gpu` in my virtualenv activated I run
```
(tensorflow-gpu-3.5) marija@dhcp-90-160:~/DCGAN-tensorflow$ python
Python 3.5.3 |Continuum Analytics, Inc.| (default, Mar  6 2017, 11:58:13) 
[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
>>> import tensorflow.contrib.eager as tfe
```
and get:
```
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ImportError: No module named 'tensorflow.contrib.eager'
```
"
14245,Issue building libtensorflow_cc.so for arm64-v8a,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 17.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.3
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: 0.5.1
- **GCC/Compiler version (if compiling from source)**: 6.0.3
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**:

> bazel build -c opt //tensorflow:libtensorflow_cc.so    --crosstool_top=//external:android/crosstool    --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --cpu=arm64-v8a


### Describe the problem
I am trying to build libtensorflow_cc.so for android for arm64-v8a  architecture.
I needed it to create and train a model file in Android NDK through C++ at runtime.
I was able do so on Desktop using C++ with the help of 'libtensorflow_cc.so' generated by 

> bazel build -c opt //tensorflow:libtensorflow_cc.so

, but wanted to integrate with Android NDK now and train on mobile.

I tried with 'libtensorflow.so' , but i get below error

> tensorflow_jni.cc:359 Non-OK-status: session->Create (graph_def) status: Invalid argument: No OpKernel was registered to support Op 'SparseSoftmaxCrossEntropyWithLogits' with these attrs.  Registered devices: [CPU], Registered kernels:
>                                                                    <no registered kernels>
>                                                                  
>                                                                  	 [[Node: SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT64](add, Cast)]]

I also tried with 'libtensorflow_inference.so' but I get many undefined reference errors like below

> In function `tensorflow::TensorShapeRep::~TensorShapeRep()':
> /home/ashok/AndroidStudioProjects/Android-arm64-v8a-dnn/facerecognitionlibrary/jni-build/jni/include/include1/tensorflow/core/framework/tensor_shape.h:492: undefined reference to `tensorflow::TensorShapeRep::DestructorOutOfLine()'
> ./obj/local/arm64-v8a/objs-debug/tensorflow_cc1/tensorflowTrian_jni.o: In function `std::pair<std::string, tensorflow::Tensor>::~pair()':
> /home/ashok/Ashok/android-ndk-r12b/sources/cxx-stl/gnu-libstdc++/4.9/include/bits/stl_pair.h:96: undefined reference to `tensorflow::Tensor::~Tensor()'
> ./obj/local/arm64-v8a/objs-debug/tensorflow_cc1/tensorflowTrian_jni.o: In function `std::string* tensorflow::internal::MakeCheckOpString<long, int>(long const&, int const&, char const*)':
> /home/ashok/AndroidStudioProjects/Android-arm64-v8a-dnn/facerecognitionlibrary/jni-build/jni/include/include1/tensorflow/core/platform/default/logging.h:184: undefined reference to `tensorflow::internal::CheckOpMessageBuilder::CheckOpMessageBuilder(char const*)'



### Source code / logs for

> bazel build -c opt //tensorflow:libtensorflow_cc.so --crosstool_top=//external:android/crosstool --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --cpu=arm64-v8a

> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:avgpooling_op.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:bounds_check.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:cwise_ops.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:cwise_ops_common.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:cwise_ops_gradients.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_activations.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_attention.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_backward_cuboid_convolutions.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_backward_spatial_convolutions.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_cuboid_convolution.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_pooling.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_softmax.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_spatial_convolutions.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_volume_patch.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:fifo_queue.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:maxpooling_op.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:ops_util.cc' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:ops_util.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:padding_fifo_queue.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:pooling_ops_common.cc' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:pooling_ops_common.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:queue_base.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:queue_op.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:typed_queue.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_entry.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_scorer.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_search.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_decoder.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_loss_util.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:naming.cc' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:naming.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:tensor_bundle.cc' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:tensor_bundle.h' directly. You should either move the file to this package or depend on an appropriate rule there
> ERROR: /home/ashok/Ashok/tensorflow/tensorflow/c/eager/BUILD:11:1: in deps attribute of cc_library rule //tensorflow/c/eager:c_api: target '//tensorflow/c/eager:c_api_internal' does not exist. Since this rule was created by the macro 'tf_cuda_library', the error might have been caused by the macro implementation in /home/ashok/Ashok/tensorflow/tensorflow/tensorflow.bzl:667:12
> ERROR: Analysis of target '//tensorflow:libtensorflow_cc.so' failed; build aborted
> INFO: Elapsed time: 0.252s
> FAILED: Build did NOT complete successfully (0 packages loaded)
> 

Stackoverflow - https://stackoverflow.com/questions/47108420/issue-building-libtensorflow-cc-so-for-arm64-v8a"
14244,Can Tensorflow 1.4 use CUDA 9?,"I upgraded to tensorflow 1.4. I found that this version can not load ""cudart64_90.dll"" when i import tensorflow in python.

It can work when i use  tensorflow 1.4 rc-0. But now it goes error:   Could not find 'cudart64_80.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Download and install CUDA 8.0 from this URL: https://developer.nvidia.com/cuda-toolkit.





"
14243,SpaceToDepthGrad and DepthToSpaceGrad are not aware of data_format,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**: 3.5
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: CUDA 8.0 / cuDNN 6
- **GPU model and memory**:
- **Exact command to reproduce**:

`tf.depth_to_space` and `tf.space_to_depth` support `data_format='NCHW'` on GPU. However, [`_SpaceToDepthGrad`](https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/python/ops/array_grad.py#L626) and [`_DepthToSpaceGrad`](https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/python/ops/array_grad.py#L633) are not aware of `data_format`. Maybe they would need to propagate `op.get_attr('data_format')`.

### Source code / logs

``` python
import tensorflow as tf
x = tf.zeros([1, 4, 1, 1])
y = tf.depth_to_space(x, 2, data_format='NCHW')
# ValueError: Dimension size must be evenly divisible by 2 but is 1 for 'gradients ...
g = tf.gradients(y, x)
```
"
14242,Concert keras model to tf.Keras model,"here is my original keras model

def inference(image_tensor):
    # the input size is 90*30*3
    x = Conv2D(32,(3,3),name='conv1')(image_tensor)
    x = MaxPool2D((2,2),name='pool1')(x)
    x = BatchNormalization(name='bn1')(x)
    x = Activation('relu')(x)

    x = Conv2D(64,(3,3),name='conv2')(x)
    x = MaxPool2D((2, 2),name='pool2')(x)
    x = BatchNormalization(name='bn2')(x)
    x = Activation('relu')(x)

    x = Conv2D(64,(3,3), name='conv3')(x)
    x = MaxPool2D((2, 2), name='pool3')(x)
    x = BatchNormalization(name='bn3')(x)
    x = Activation('relu')(x)

    x = Flatten(name='flatte1',inputs=x)

    x = Dense(256,name='fc1')(x)

    # max_length of sentence
    x = RepeatVector(7,name='repeat')(x)

    #2*GRU the output shape is (None,7,256)
    x = Bidirectional(GRU(units=128,name='GRU',return_sequences=True))(x)

    #apply (None,7,256) to all GRUs output (None,7,16)
    x = TimeDistributed(Dense(16,name='fc2'))(x)
    x = Activation('softmax')(x)
    x = Flatten(name='Flatten2',inputs=x)

when I show my summary, it print like this
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 90, 30, 3)         0         
_________________________________________________________________
conv1 (Conv2D)               (None, 88, 28, 32)        896       
_________________________________________________________________
pool1 (MaxPooling2D)         (None, 44, 14, 32)        0         
_________________________________________________________________
bn1 (BatchNormalization)     (None, 44, 14, 32)        128       
_________________________________________________________________
activation_1 (Activation)    (None, 44, 14, 32)        0         
_________________________________________________________________
conv2 (Conv2D)               (None, 42, 12, 64)        18496     
_________________________________________________________________
pool2 (MaxPooling2D)         (None, 21, 6, 64)         0         
_________________________________________________________________
bn2 (BatchNormalization)     (None, 21, 6, 64)         256       
_________________________________________________________________
activation_2 (Activation)    (None, 21, 6, 64)         0         
_________________________________________________________________
conv3 (Conv2D)               (None, 19, 4, 64)         36928     
_________________________________________________________________
pool3 (MaxPooling2D)         (None, 9, 2, 64)          0         
_________________________________________________________________
bn3 (BatchNormalization)     (None, 9, 2, 64)          256       
_________________________________________________________________
activation_3 (Activation)    (None, 9, 2, 64)          0         
_________________________________________________________________
flatte1 (Flatten)            (None, 1152)              0         
_________________________________________________________________
fc1 (Dense)                  (None, 256)               295168    
_________________________________________________________________
repeat (RepeatVector)        (None, 7, 256)            0         
_________________________________________________________________
bidirectional_1 (Bidirection (None, 7, 256)            295680    
_________________________________________________________________
time_distributed_1 (TimeDist (None, 7, 16)             4112      
_________________________________________________________________
Flatten2 (Flatten)           (None, 112)               0         
=================================================================

but when I change my codes to tf.keras like this(the architecture do not change! )
_________________________________________________________________
repeat (RepeatVector)        (None, 7, 256)            0         
_________________________________________________________________
bidirectional_1 (Bidirection (None, None, 256)         295680    
_________________________________________________________________
time_distributed_1 (TimeDist (None, None, 16)          4112      
_________________________________________________________________
activation_4 (Activation)    (None, None, 16)          0         
_________________________________________________________________
Flatten2 (Flatten)           (None, None)              0         
=================================================================
Total params: 651,920
Trainable params: 651,600
Non-trainable params: 320
_________________________________________________________________


the output of bidirectional_1 is (None, None, 256), I just wonder why the GRU output was flase.
And how can I change my code?
Thanks a lot!



"
14241,`Network` behaviour inconsistent with `Layer` w.r.t `build`,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes (provided below)
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary, `pip install tf-nightly-gpu`
- **TensorFlow version (use command below)**: git: v1.3.0-rc1-4090-g4e75ae1, tf: 1.5.0-dev20171103
- **Python version**:  2.7.12
- **Bazel version (if compiling from source)**: -
- **GCC/Compiler version (if compiling from source)**: -
- **CUDA/cuDNN version**: 8.0
- **GPU model and memory**: GTX-1070 8GB

### Describe the problem
The `tf.layers.Layer` class exposes a `build` method which can optionally be called prior to first `__call__` e.g. to construct variables in a different scope to where the call is made. The documentation does not explicitly promise that layers are built during `build` and not elsewhere, but this seems to be the pattern with the implemented layers and is very useful in a narrow set of circumstances.

The `tensorflow.python.layers.base.Network` class implements `tf.layers.Layer` and exposes the same method, but there is no way to construct the constructor arguments without building constituent layers. This is unexpected and misleading, and prevents use of `Network`s where unbuilt `Layer`s are expected/required.

A lazily-built `Network` implementation would be greatly appreciated, as would clarity on whether it is the intention that all classes implementing `Layer` should be `build` separately from their constructor. 

Illustrative example/ basic lazy implementation below.

### Source code
```
from tensorflow.python.layers import base
import tensorflow as tf

n_features = 16
n_hidden = 8
n_out = 3


def n_vars():
    return len(tf.trainable_variables())


# Layers, variable created on build
x = tf.placeholder(shape=(None, n_features), dtype=tf.float32)
l0 = tf.layers.Dense(n_hidden)
l1 = tf.layers.Dense(n_out)
print(n_vars())  # 0
l0.build((n_features,))
l1.build((n_hidden,))
print(n_vars())  # 4


print('---------')
# Network, variables must be created prior to Network construction.
tf.reset_default_graph()
x = tf.placeholder(shape=(None, n_features), dtype=tf.float32)

l0 = tf.layers.Dense(n_hidden)
l1 = tf.layers.Dense(n_out)

inp = base.Input((n_features,))
outputs = l1(l0(inp))
print(n_vars())  # 4
network = base.Network(inp, outputs)

print(network.built)  # Already true: no way around with constructor signature
network.build(None)
print(network.built)  # True as expected


def _transform_inputs(inputs):
    if isinstance(inputs, base.InputSpec):
        return inputs
    elif isinstance(inputs, (tuple, tf.TensorShape)):
        return base.Input(shape=inputs[1:], batch_size=inputs[0])
    elif isinstance(inputs, tf.Tensor):
        return base.Input(tensor=inputs)
    elif isinstance(inputs, list):
        return [_transform_inputs(inp) for inp in inputs]
    else:
        raise NotImplementedError(
            'Unrecognized type for _transform_inputs: %s' % type(inputs))


class LazyNetwork(base.Network):
    def __init__(self, outputs_fn, **kwargs):
        self._outputs_fn = outputs_fn
        self._kwargs = kwargs
        self.built = False

    def build(self, inputs):
        if self.built:
            return
        inputs = _transform_inputs(inputs)
        outputs = self._outputs_fn(inputs)
        super(LazyNetwork, self).__init__(
            inputs, outputs, **self._kwargs)

    def __call__(self, inputs):
        if not self.built:
            self.build(_transform_inputs(inputs))
        return super(LazyNetwork, self).__call__(inputs)


print('---------')
# LazyNetwork, variables created on build
tf.reset_default_graph()
x = tf.placeholder(shape=(None, n_features), dtype=tf.float32)

l0 = tf.layers.Dense(n_hidden)
l1 = tf.layers.Dense(n_out)
network = LazyNetwork(lambda x: l1(l0(x)))

print(n_vars())  # 0
print(network.built)  # False
network.build(base.Input((n_features,)))
print(n_vars())  # 4
print(network.built)  # True
```"
14235,Retraining the lower layers of the inception model for a better classifier. ,"https://github.com/tensorflow/tensorflow/blob/4e75ae1f1e8c6479cfa86fde1a940453945e6671/tensorflow/examples/image_retraining/retrain.py#L26

Hi, I am trying to use the inception model to learn to classify between about 200 different object types.  I tried the approach mentioned here, which seems to only retrain the last few layer of the model, and I can't get about ~ 60% accuracy even when I am training the model. I imagine if I pass on the gradient and change the weights in the lower layers, that I will be able to improve the accuracy of the model when applied to my data set. 

How do I go about doing this ? Any guidance on this being done else where would be extremely helpful. "
14233,graph_editor doesn't update graph_version,"Symptom:
1. session.run
2. modify the graph with tf.contrib.graph_editor
3. session.run

Session.run in step 3 will use the same graph as in step 1 (pre-modification)

The reason is that session.py looks at [self._graph.version]( https://github.com/tensorflow/tensorflow/blob/4e75ae1f1e8c6479cfa86fde1a940453945e6671/tensorflow/python/client/session.py#L1345) when deciding whether to trigger TF_ExtendGraph. Since `graph_editor` doesn't update graph_version, it will reuse the previous graph.

Suggestion: every graph-modifying method in `graph_editor` should increment `version` attribute for the graph

@purpledog "
14232,[Feature Request] Automatic ClusterSpec Propagation for multiple hosts,"Currently, when launching a distributed TensorFlow job, user need to manually input all the worker hosts' IP and port number. This is not too convenient and does not scale well. It would be really nice to have the native TensorFlow functionality that workers can automatically register themselves on master service without knowing all the host IP and port beforehand. Not sure if there is existing solution to solve this problem. But I used some of the building blocks (ClusterSpec Propagation and ClusterResolver) to enable this feature on my client code. Please let me know if it is a good approach to do this, I'd love to contribute if there's interest in this functionality. 

The solution I have involve the following steps:
1) Master service start server with user specified port and wait for all workers to register
2) Worker register themselves by sending ClusterSpec to Master service and wait for response
3) Master service waits until numbers of workers registered matches requested worker number
4) Master service merges ClusterSpecs and propagates to all registered workers
5) Master service and workers continues"
14231,CUDA_ERROR_OUT_OF_MEMORY on multiple and single GPU set up (1080Ti),"Hi. I am having troubles running any tensorflow code on my 4x1080Ti GPU set up.

This is the code I am running (just to reproduce the issue):
----------------------------------------------------------------
import tensorflow as tf
a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')
b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')
c = tf.matmul(a, b)
gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.6) #with or without this line of code
sess = tf.Session(config=tf.ConfigProto(log_device_placement=True, gpu_options=gpu_options))
print(sess.run(c))
sess.close()

But eventually my python session crashes with out of memory error. The log allso indicate that.
When I force the session to only use one GPU (using environment variable CUDA_VISIBLE_DEVICES=0), it becomes more stable but crashed later when I run an actual training code (quite basic also).

------------------------
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 Pro 64bits
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: b'unknown' 1.3.0
- **Python version**: Python 3.5.3 :: Intel Corporation
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: cuda_8.0.61.2 / cuDNN 8.0
- **GPU model and memory**: 1080Ti 11GB
- **Exact command to reproduce**:


Here is the log:
------------------------


C:\Users\Riad\Desktop\Courses>jupyter notebook
[W 11:33:32.835 NotebookApp] All authentication is disabled.  Anyone who can connect to this server will be able to run code.
[I 11:33:32.887 NotebookApp] Serving notebooks from local directory: C:\Users\Riad\Desktop\Courses
[I 11:33:32.887 NotebookApp] 0 active kernels
[I 11:33:32.888 NotebookApp] The Jupyter Notebook is running at: http://0.0.0.0:8888/
[I 11:33:32.888 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[W 11:34:06.855 NotebookApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20171103113331 (192.168.100.9) 15.23ms referer=http://rrig01:8888/notebooks/Untitled.ipynb
[I 11:34:07.181 NotebookApp] Kernel started: a846f3bb-429b-49d9-b3dc-90e8d47d67fc
2017-11-03 11:34:25.408488: W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-11-03 11:34:25.408577: W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-11-03 11:34:26.328062: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\common_runtime\gpu\gpu_device.cc:955] Found device 0 with properties:
name: GeForce GTX 1080 Ti
major: 6 minor: 1 memoryClockRate (GHz) 1.6705
pciBusID 0000:01:00.0
Total memory: 11.00GiB
Free memory: 9.08GiB
2017-11-03 11:34:26.762169: W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:523] A non-primary context 00000171274F5980 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-11-03 11:34:26.763254: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\common_runtime\gpu\gpu_device.cc:955] Found device 1 with properties:
name: GeForce GTX 1080 Ti
major: 6 minor: 1 memoryClockRate (GHz) 1.6705
pciBusID 0000:02:00.0
Total memory: 11.00GiB
Free memory: 9.08GiB
2017-11-03 11:34:27.217289: W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:523] A non-primary context 00000171274EB2C0 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-11-03 11:34:27.218417: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\common_runtime\gpu\gpu_device.cc:955] Found device 2 with properties:
name: GeForce GTX 1080 Ti
major: 6 minor: 1 memoryClockRate (GHz) 1.6705
pciBusID 0000:04:00.0
Total memory: 11.00GiB
Free memory: 9.08GiB
2017-11-03 11:34:27.652094: W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:523] A non-primary context 000001712754BC30 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-11-03 11:34:27.654175: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\common_runtime\gpu\gpu_device.cc:955] Found device 3 with properties:
name: GeForce GTX 1080 Ti
major: 6 minor: 1 memoryClockRate (GHz) 1.6705
pciBusID 0000:05:00.0
Total memory: 11.00GiB
Free memory: 9.08GiB
2017-11-03 11:34:27.654302: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\common_runtime\gpu\gpu_device.cc:847] Peer access not supported between device ordinals 0 and 1
2017-11-03 11:34:27.654690: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\common_runtime\gpu\gpu_device.cc:847] Peer access not supported between device ordinals 0 and 2
2017-11-03 11:34:27.654941: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\common_runtime\gpu\gpu_device.cc:847] Peer access not supported between device ordinals 0 and 3
2017-11-03 11:34:27.655238: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\common_runtime\gpu\gpu_device.cc:847] Peer access not supported between device ordinals 1 and 0
2017-11-03 11:34:27.655512: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\common_runtime\gpu\gpu_device.cc:847] Peer access not supported between device ordinals 1 and 2
2017-11-03 11:34:27.655806: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\common_runtime\gpu\gpu_device.cc:847] Peer access not supported between device ordinals 1 and 3
2017-11-03 11:34:27.656091: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\common_runtime\gpu\gpu_device.cc:847] Peer access not supported between device ordinals 2 and 0
2017-11-03 11:34:27.656392: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\common_runtime\gpu\gpu_device.cc:847] Peer access not supported between device ordinals 2 and 1
2017-11-03 11:34:27.656680: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\common_runtime\gpu\gpu_device.cc:847] Peer access not supported between device ordinals 2 and 3
2017-11-03 11:34:27.656974: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\common_runtime\gpu\gpu_device.cc:847] Peer access not supported between device ordinals 3 and 0
2017-11-03 11:34:27.657493: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\common_runtime\gpu\gpu_device.cc:847] Peer access not supported between device ordinals 3 and 1
2017-11-03 11:34:27.657800: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\common_runtime\gpu\gpu_device.cc:847] Peer access not supported between device ordinals 3 and 2
2017-11-03 11:34:27.658247: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\common_runtime\gpu\gpu_device.cc:976] DMA: 0 1 2 3
2017-11-03 11:34:27.658286: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\common_runtime\gpu\gpu_device.cc:986] 0:   Y N N N
2017-11-03 11:34:27.658545: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\common_runtime\gpu\gpu_device.cc:986] 1:   N Y N N
2017-11-03 11:34:27.658580: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\common_runtime\gpu\gpu_device.cc:986] 2:   N N Y N
2017-11-03 11:34:27.658606: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\common_runtime\gpu\gpu_device.cc:986] 3:   N N N Y
2017-11-03 11:34:27.658660: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\common_runtime\gpu\gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0)
2017-11-03 11:34:27.658997: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\common_runtime\gpu\gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0)
2017-11-03 11:34:27.659402: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\common_runtime\gpu\gpu_device.cc:1045] Creating TensorFlow device (/gpu:2) -> (device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0)
2017-11-03 11:34:27.659795: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\common_runtime\gpu\gpu_device.cc:1045] Creating TensorFlow device (/gpu:3) -> (device: 3, name: GeForce GTX 1080 Ti, pci bus id: 0000:05:00.0)
2017-11-03 11:34:28.549763: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 8.63G (9267854592 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:28.986715: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 7.77G (8341068800 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:29.440854: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 6.99G (7506961920 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:29.887158: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 6.29G (6756265472 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:30.135809: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 8.63G (9267854592 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:30.168426: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 7.77G (8341068800 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:30.201799: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 6.99G (7506961920 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:30.247813: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 6.29G (6756265472 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:30.287203: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 5.66G (6080638976 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:30.320556: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 5.10G (5472574976 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:30.357686: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 4.59G (4925317120 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:30.394005: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 4.13G (4432785408 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:30.426176: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 3.71G (3989506816 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:30.457480: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 3.34G (3590556160 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:30.491576: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 3.01G (3231500544 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:30.527402: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 2.71G (2908350464 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:30.561202: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 2.44G (2617515264 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:30.594297: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 2.19G (2355763712 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:30.628747: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 1.97G (2120187392 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:30.665536: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 1.78G (1908168704 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:30.707833: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 1.60G (1717351936 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:30.743971: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 1.44G (1545616640 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:30.779594: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 1.29G (1391055104 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:30.810792: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 1.17G (1251949568 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:30.841555: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 1.05G (1126754560 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:30.873425: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 967.10M (1014079232 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:30.943823: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 870.39M (912671488 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:30.977474: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 783.35M (821404416 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.010872: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 705.02M (739264000 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.041557: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 634.51M (665337600 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.101954: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 571.06M (598803968 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.132940: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 513.96M (538923776 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.152136: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 8.63G (9267854592 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.160670: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 7.77G (8341068800 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.161213: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 6.99G (7506961920 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.162127: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 6.29G (6756265472 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.163461: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 5.66G (6080638976 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.164258: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 5.10G (5472574976 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.212887: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 4.59G (4925317120 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.214000: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 4.13G (4432785408 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.214529: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 3.71G (3989506816 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.215007: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 3.34G (3590556160 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.215633: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 3.01G (3231500544 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.216019: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 2.71G (2908350464 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.216421: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 2.44G (2617515264 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.216896: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 2.19G (2355763712 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.217393: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 1.97G (2120187392 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.218201: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 1.78G (1908168704 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.219158: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 1.60G (1717351936 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.220334: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 1.44G (1545616640 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.223796: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 1.29G (1391055104 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.224705: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 1.17G (1251949568 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.228203: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 1.05G (1126754560 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.228790: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 967.10M (1014079232 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.240002: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 870.39M (912671488 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.240616: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 783.35M (821404416 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.241031: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 705.02M (739264000 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.241440: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 634.51M (665337600 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.241912: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 571.06M (598803968 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.243669: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 513.96M (538923776 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.244271: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 462.56M (485031424 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.370999: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 416.31M (436528384 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.371450: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 374.67M (392875520 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.382825: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 337.21M (353587968 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.383636: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 303.49M (318229248 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.384740: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 273.14M (286406400 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.446815: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 245.82M (257765888 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.447603: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 221.24M (231989504 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.448226: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 199.12M (208790784 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.448853: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 179.21M (187911936 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.449435: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 161.29M (169120768 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.450162: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 145.16M (152208896 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.456715: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 130.64M (136988160 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.457435: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 117.58M (123289344 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.457901: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 105.82M (110960640 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.458436: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 95.24M (99864576 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.458854: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 85.71M (89878272 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.459447: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 77.14M (80890624 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.460854: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 69.43M (72801792 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.461332: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 62.49M (65521664 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.461884: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 56.24M (58969600 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.462263: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 50.61M (53072640 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.462685: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 45.55M (47765504 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.463065: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 41.00M (42989056 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.465693: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 36.90M (38690304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.466117: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 33.21M (34821376 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.466556: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 29.89M (31339264 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.474153: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 26.90M (28205568 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.474574: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 24.21M (25385216 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2017-11-03 11:34:31.475153: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_driver.cc:924] failed to allocate 21.79M (22846720 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
Device mapping:
/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0
/job:localhost/replica:0/task:0/gpu:1 -> device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0
/job:localhost/replica:0/task:0/gpu:2 -> device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0
/job:localhost/replica:0/task:0/gpu:3 -> device: 3, name: GeForce GTX 1080 Ti, pci bus id: 0000:05:00.0
2017-11-03 11:34:31.586968: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\common_runtime\direct_session.cc:300] Device mapping:
/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0
/job:localhost/replica:0/task:0/gpu:1 -> device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0
/job:localhost/replica:0/task:0/gpu:2 -> device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0
/job:localhost/replica:0/task:0/gpu:3 -> device: 3, name: GeForce GTX 1080 Ti, pci bus id: 0000:05:00.0

MatMul: (MatMul): /job:localhost/replica:0/task:0/gpu:0
2017-11-03 11:34:31.596219: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\common_runtime\simple_placer.cc:872] MatMul: (MatMul)/job:localhost/replica:0/task:0/gpu:0
b: (Const): /job:localhost/replica:0/task:0/gpu:0
2017-11-03 11:34:31.674827: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\common_runtime\simple_placer.cc:872] b: (Const)/job:localhost/replica:0/task:0/gpu:0
a: (Const): /job:localhost/replica:0/task:0/gpu:0
2017-11-03 11:34:31.675394: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\common_runtime\simple_placer.cc:872] a: (Const)/job:localhost/replica:0/task:0/gpu:0
[I 11:36:07.126 NotebookApp] Saving file at /Untitled.ipynb



"
14230,Build from source documentation is incorrect,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 14.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 3.6.3
- **Bazel version (if compiling from source)**: **4.5**
- **GCC/Compiler version (if compiling from source)**: 4.8
- **CUDA/cuDNN version**: 8/6
- **GPU model and memory**: nvidia
- **Exact command to reproduce**: bazel build --config=opt --config=cuda --verbose_failures //tensorflow/tools/pip_package:build_pip_package


### Describe the problem
Documentation is incorrect: https://www.tensorflow.org/install/install_sources

""Tested source configurations"" lists bazel 0.4.5 for tensorflow 1.4.0. Tensorflow 1.4.0 rejects this version of bazel with an error message:

Current Bazel version is 0.4.5, expected at least 0.5.4

### Source code / logs
```
$ bazel build --config=opt --config=cuda --verbose_failures //tensorflow/tools/pip_package:build_pip_package
 ---> Running in 547db5b015bf
WARNING: Config values are not defined in any .rc file: opt
ERROR: /tmp/tensorflow/WORKSPACE:41:1: Traceback (most recent call last):
File ""/tmp/tensorflow/WORKSPACE"", line 41
		tf_workspace()
	File ""/tmp/tensorflow/tensorflow/workspace.bzl"", line 146, in tf_workspace
		check_version(""0.5.4"")
	File ""/tmp/tensorflow/tensorflow/workspace.bzl"", line 56, in check_version
		fail(""
Current Bazel version is {}, e...))

Current Bazel version is 0.4.5, expected at least 0.5.4
```
"
14229,tf.contrib.learn.Experiment - train_monitors should be renamed,"Shouldn't **train_monitors** be renamed to **train_hooks**? As far as I understand hooks replaced monitors.

I look at TF v1.4.0-rc1.

tf.contrib.learn.Experiment(estimator, train_input_fn, eval_input_fn, eval_metrics=None, train_steps=None, eval_steps=100, **train_monitors**=None, **eval_hooks**=None, local_eval_frequency=None, eval_delay_secs=120, continuous_eval_throttle_secs=60, min_eval_frequency=None, delay_workers_by_global_step=False, export_strategies=None, train_steps_per_iteration=None, checkpoint_and_export=False)"
14228,Feature request: an op that returns timestamp,"This is useful for stats tracking in distributed TensorFlow (ie, measuring TF communication latency between workers and plotting it in TensorBoard). Perhaps it could be called `CurrentTimestamp`, `tf.current_timestamp()`

```
#include ""tensorflow/core/platform/env.h""
static EnvTime* env_time = tensorflow::EnvTime::Default();
uint64 now_micros = env_time->NowMicros();
```"
14226,decode_image resize_images workflow does not work,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: ('v1.3.0-rc2-20-g0787eee', '1.3.0')
- **Python version**: 2.7
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: 
- **GPU model and memory**:
- **Exact command to reproduce**: Performing `resize_images` with output of `decode_image`

### Describe the problem
This problem was addressed in https://github.com/tensorflow/tensorflow/issues/1029 but was closed. https://github.com/tensorflow/tensorflow/issues/8551 and https://github.com/tensorflow/tensorflow/issues/9356 are also relevant. 

The basic problem is that the output of `tf.image.decode_image` cannot be passed to `tf.image.resize_images`. It raises `ValueError: 'images' contains no shape.` in the call to `resize_images`. 

Possible workarounds to this include using `decode_jpeg`, `decode_png` or adding `decoded_image.set_shape([None, None, None])` before calling `tf.image.resize_images`. However, as @girving pointed out in #1029, nothing about the underlying op requires knowing a static shape. 

### Source code / logs
    decoded_image = tf.image.decode_jpeg(tf.read_file(image_filename))
    tf.image.resize_images(decoded_image, (100, 100))
"
14224,tensorflow/tensorflow:1.4.0-devel-gpu uses libcuda.so stub at runtime,"```
$ nvidia-docker run -ti tensorflow/tensorflow:1.4.0-devel-gpu /bin/bash
root@2ad65cce2269:~# ldd /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
[...]
        libcuda.so.1 => /usr/local/cuda/lib64/stubs/libcuda.so.1 (0x00007f9de7215000)
```
As a result, you can't use CUDA in this image:
```
2017-11-03 17:57:11.181620: E tensorflow/stream_executor/cuda/cuda_driver.cc:406] failed call to cuInit: CUresult(-1)
2017-11-03 17:57:11.181660: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:158] retrieving CUDA diagnostic information for host: 939b58c94187
2017-11-03 17:57:11.181677: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hostname: 939b58c94187
2017-11-03 17:57:11.181848: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program
```

Issue was caused by: https://github.com/tensorflow/tensorflow/pull/13399
Please backport https://github.com/tensorflow/tensorflow/pull/13456 into `r1.4`"
14223,what's is forget_bias? ,what's is forget_bias? I checked the basicllstmcell variable. but I found the biases are 0 althought I changed forget_bias to 0 or 1. I heard the func of it is that don't forget input of  first time .  please feedback
14221,bayeslfow.hmc - provide option for skipping the MH step,"Currently `tf.contrib.bayesflow.hmc.kernel` returns directly the update x and value of the potential after the Metropolis-Hasting steps. It would be useful to have an option to omitting the MH step. This, for instance, is required for implementing HVI [1], where we want to propagate gradients through the HMC step and not reject any samples:

[1] https://arxiv.org/pdf/1410.6460.pdf
"
14220,64MB protobuf limit,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 3.5
- **Exact command to reproduce**:

```
import tensorflow as tf
import numpy as np

a = tf.constant(np.zeros(10000000))
profiler = tf.profiler.Profiler(tf.get_default_graph())
```

### Describe the problem
Running the above code results in the error message:
```
[libprotobuf ERROR C:\tf_jenkins\home\workspace\rel-win\M\windows\PY\35\cmake_build\protobuf\src\protobuf\src\google\protobuf\io\coded_stream.cc:208] A protocol message was rejected because it was too big (more than 67108864 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf ERROR C:\tf_jenkins\home\workspace\rel-win\M\windows\PY\35\cmake_build\protobuf\src\protobuf\src\google\protobuf\text_format.cc:298] Error parsing text-format tensorflow.GraphDef: 2:1: Interpreting non ascii codepoint 224.
[libprotobuf ERROR C:\tf_jenkins\home\workspace\rel-win\M\windows\PY\35\cmake_build\protobuf\src\protobuf\src\google\protobuf\text_format.cc:298] Error parsing text-format tensorflow.GraphDef: 2:1: Expected identifier, got: à
Failed to parse graph
```

Reading #582 suggests that this problem should have been fixed in `protobuf 3.2.0`, but that doesn't seem to be the case in my system.  This may be a Windows-specific issue?

### Source code / logs
Here is the output of `pip freeze` showing the installed versions of tensorflow/protobuf (this is all starting from a fresh environment, and installed via `pip install tensorflow`).

```
bleach==1.5.0
certifi==2016.2.28
enum34==1.1.6
html5lib==0.9999999
Markdown==2.6.9
numpy==1.13.1
protobuf==3.4.0
six==1.11.0
tensorflow==1.4.0
tensorflow-tensorboard==0.4.0rc2
Werkzeug==0.12.2
wincertstore==0.2
```
"
14219,"tf.layers.Network is in the documentation, but not the library","**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: OS X 10.12.6
- **TensorFlow installed from (source or binary)**: source, latest 1.4 branch
- **TensorFlow version (use command below)**: v1.4.0-rc1-12-gd752244fba 1.4.0
- **Python version**: 3.6.3
- **Bazel version (if compiling from source)**: 0.7.0
- **GCC/Compiler version (if compiling from source)**: Apple LLVM version 9.0.0 (clang-900.0.38)
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**:

see below

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem

The 1.4 version of the documentation mentions tf.layers.Network in its examples of using the new function based layers (here is a link to the specific doc, https://www.tensorflow.org/api_docs/python/tf/layers/Input), so all you have to do is copy/paste the example code and run it.

### Source code / logs
the most basic code to verify is

```
import tensorflow as tf
print(tf.layers.Network)
```

on my system this results in 

```
AttributeError: module 'tensorflow.python.layers.layers' has no attribute 'Network'
```"
14218,TensorFlow 1.4 (gpu Linux) Py36 not built with Py36,"Installed TF 1.4 with pip install --ignore-installed --upgrade  https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.4.0-cp36-cp36m-linux_x86_64.whl
Gives me this error on import:
/home/tom/anaconda3/envs/tf4/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6
  return f(*args, **kwds)
Similar error reported form Tensorboard:
/home/tom/anaconda3/envs/tf4/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6
  return f(*args, **kwds)
TensorBoard 0.4.0rc2 at http://tomServal:6006 (Press CTRL+C to quit)
"
14217,ios documentation for tensorflow-experimental,"Could we have a proper documentation (either in the pod files with a custom header) or in the readme?
It would help greatly to have the list of available methods and what they do (unless method name is self-explanatory).
Having to dig into ~20 objective-c files to get a grasp of what is possible in swift is not equivalent to a proper documentation"
14215, org.tensorflow.TensorFlowException: Op type not registered 'Sum' in binary running on localhost. Make sure the Op and Kernel are registered in the binary running in this process.," 

### System information
- **Have I written custom code**:
I worte a code that is based on this : https://www.tensorflow.org/api_guides/python/contrib.signal
trying to produce mfcc works fine in python but i cannot make it work in Android

- **OS Platform and Distribution  Linux Ubuntu 16.04 
- **TensorFlow installed from source  **:
- **TensorFlow version 1.4.2:
- **Python version - 2.7 
- **Bazel version  0.7.0
-
 

### Describe the problem
i have reduced my graph to this - 
****PYTHON CODE that creates the pb *****
import sugartensor as tf
from tensorflow.python.framework import graph_util
from model import *
import data
import os
import sys
from tensorflow.contrib.framework.python.ops import audio_ops as contrib_audio
import functools


from tensorflow.contrib.session_bundle import exporter
from tensorflow.python.tools import freeze_graph
global session_config
exportfilename = 'out2/export_mfcc_only.pb'
with tf.device('/cpu:0'):
	session_config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)
	 
	tf.app.flags.DEFINE_integer ('export_version',   1,           'version number of the exported model')
	session = tf.InteractiveSession()
	#session = tf.Session()
	# Run inference
	batch_size = 1
	voca_size = data.voca_size
	sample_rate = 16000.0	
	wavdata = tf.placeholder(tf.float32, [ None], name=""wav_float_input"")
	pcm = tf.expand_dims(wavdata, 0)
	stfts = tf.contrib.signal.stft(pcm, frame_length=2048, frame_step=512,
                             fft_length=2048,window_fn=functools.partial(tf.contrib.signal.hann_window, periodic=False), pad_end=True)
	spectrograms = tf.abs(stfts)
	# Warp the linear scale spectrograms into the mel-scale.
	num_spectrogram_bins = stfts.shape[-1].value
	lower_edge_hertz, upper_edge_hertz, num_mel_bins = 0.0,8000.0, 128
	linear_to_mel_weight_matrix = tf.contrib.signal.linear_to_mel_weight_matrix(
	num_mel_bins, num_spectrogram_bins, sample_rate, lower_edge_hertz,
	upper_edge_hertz)
	mel_spectrograms = tf.tensordot(
	spectrograms, linear_to_mel_weight_matrix, 1)
	mel_spectrograms.set_shape(spectrograms.shape[:-1].concatenate(
	linear_to_mel_weight_matrix.shape[-1:]))
	# Compute a stabilized log to get log-magnitude mel-scale spectrograms.
	log_mel_spectrograms = tf.log(mel_spectrograms + 1e-6)
	# Compute MFCCs from log_mel_spectrograms and take the first 13.
	mfccs = tf.contrib.signal.mfccs_from_log_mel_spectrograms(
	log_mel_spectrograms)[..., :20]

	seq_len =[tf.size(mfccs.sg_int().sg_sum(axis=2), name=""output_node"" )]

  
	

	session.run(tf.local_variables_initializer() )
	tf.global_variables_initializer()
	subgraph = tf.graph_util.extract_sub_graph(session.graph_def, [""output_node""])

	frozen_graph_def = graph_util.convert_variables_to_constants(
	      session, subgraph, [""output_node""])
	tf.train.write_graph(
	      frozen_graph_def,
	      os.path.dirname(exportfilename),
	      os.path.basename(exportfilename),
	      as_text=False)
	tf.logging.info('Saved frozen graph to %s',exportfilename)
***END OF PYTHON CODE***
 
i manage to load it and test the created pb it in python

i create libtensorflow_inference.so
using print_selective_registration_header as described in - 
tensorflow/tensorflow/python/tools/print_selective_registration_header.py

testing the code in Androids results in an Error when i load the model - 

11-03 16:15:31.790 8639-8639/org.tensorflow.demo E/native: executor.cc:651 Executor failed to create kernel. Not found: No registered 'ListDiff' OpKernel for CPU devices compatible with node Tensordot/ListDiff_1 = ListDiff[T=DT_INT32, out_idx=DT_INT32, _device=""/device:CPU:0""](Tensordot/range_3, Tensordot/add_3)
                                                           	.  Registered:  <no registered kernels>
                                                           
                                                           	 [[Node: Tensordot/ListDiff_1 = ListDiff[T=DT_INT32, out_idx=DT_INT32, _device=""/device:CPU:0""](Tensordot/range_3, Tensordot/add_3)]]
11-03 16:15:31.790 8639-8639/org.tensorflow.demo E/native: executor.cc:651 Executor failed to create kernel. Not found: No registered 'ListDiff' OpKernel for CPU devices compatible with node Tensordot/ListDiff_1 = ListDiff[T=DT_INT32, out_idx=DT_INT32, _device=""/device:CPU:0""](Tensordot/range_3, Tensordot/add_3)
                                                           	.  Registered:  <no registered kernels>
                                                           
                                                           	 [[Node: Tensordot/ListDiff_1 = ListDiff[T=DT_INT32, out_idx=DT_INT32, _device=""/device:CPU:0""](Tensordot/range_3, Tensordot/add_3)]]
11-03 16:15:31.800 8639-8639/org.tensorflow.demo E/native: executor.cc:651 Executor failed to create kernel. Not found: No registered 'ListDiff' OpKernel for CPU devices compatible with node Tensordot/ListDiff_1 = ListDiff[T=DT_INT32, out_idx=DT_INT32, _device=""/device:CPU:0""](Tensordot/range_3, Tensordot/add_3)
                                                           	.  Registered:  <no registered kernels>
                                                           
                                                           	 [[Node: Tensordot/ListDiff_1 = ListDiff[T=DT_INT32, out_idx=DT_INT32, _device=""/device:CPU:0""](Tensordot/range_3, Tensordot/add_3)]]
11-03 16:15:31.810 8639-8639/org.tensorflow.demo E/native: executor.cc:651 Executor failed to create kernel. Not found: No registered 'ListDiff' OpKernel for CPU devices compatible with node Tensordot/ListDiff = ListDiff[T=DT_INT32, out_idx=DT_INT32, _device=""/device:CPU:0""](Tensordot/range_2, Tensordot/add_1)
                                                           	.  Registered:  <no registered kernels>
                                                           
                                                           	 [[Node: Tensordot/ListDiff = ListDiff[T=DT_INT32, out_idx=DT_INT32, _device=""/device:CPU:0""](Tensordot/range_2, Tensordot/add_1)]]
11-03 16:15:31.870 8639-8639/org.tensorflow.demo E/AndroidRuntime: FATAL EXCEPTION: main
                                                                   Process: org.tensorflow.demo, PID: 8639
                                                                   org.tensorflow.TensorFlowException: Op type not registered 'Sum' in binary running on localhost. Make sure the Op and Kernel are registered in the binary running in this process.


i see that both 'ListDiff' and 'Sum' ops are in the ops_to_register.h file that is generated by the print_selective_registration_header process

is there a workaround for this?
	 "
14214,do fine tuning with my own image size ,"I would like to do transfer learning and fine tuning with some pretrained model in tensorflow.contrib.slim. I searched some examples about this. However, almost all of these examples will resize images to the specified size that the model needs. For example, 224×224 is the size that vgg16 needed. Will it be possible to set my own image size? Like 512×512. In keras, I can do this like following:

    `base_model= VGG16(include_top=False, input_shape=(512, 512, 3))` 

Up till now, I have not found the solution, can this be down in tensorflow and slim?
"
14213,Feature tf.image : scale image and keep aspect/ratio,"Hi, I'm working on a FCN (Fully Convolutional Network) and use Tensorflow for this work. I have a lot of images in input, and they have very different dimensions, like 2340x4160 or 512x512. So my input need to be dynamic. It's why I search a way to resize images for having the greater dimension to a specific value, with respect to the aspect/ratio.

Unfortunatly, Tensorflow doesn't provide this feature or, if I'm wrong, please just ignore this issue.

So I write my own code. (It's probably not the most beautiful way to write this, sorry if this code seems ugly!)

``` python3
#!/usr/bin/env python
import tensorflow as tf

MAX_SIZE = 512

# Image (for example: 2340x4160)
image_path = ""your_image.jpg""

# Open image
image_string = tf.read_file(image_path)
image        = tf.image.decode_jpeg(image_string, channels=3)

# Take width/height
initial_width = tf.shape(image)[0]
initial_height = tf.shape(image)[1]

# Function for resizing 
def _resize(x, y):
  # Take the greater value, and use it for the ratio 
  max_ = tf.maximum(initial_width, initial_height)
  ratio = tf.to_float(max_) / tf.constant(MAX_SIZE, dtype=tf.float32)

  new_width = tf.to_float(initial_width) / ratio
  new_height = tf.to_float(initial_height) / ratio

  return tf.to_int32(new_width), tf.to_int32(new_height)

# Useless function for the next condition
def _useless(x, y):
  return x, y

new_w, new_h = tf.cond(tf.logical_or(
                         tf.greater(initial_width, tf.constant(MAX_SIZE)),
                         tf.greater(initial_height, tf.constant(MAX_SIZE))
                       ),
        lambda: _resize(initial_width, initial_height),
        lambda: _useless(initial_width, initial_height))

resized_image = tf.image.resize_images(image, [new_w, new_h])
image_int     = tf.cast(resized_image, tf.uint8)
image_enc     = tf.image.encode_jpeg(image_int)
fwrite        = tf.write_file(""my_resized_image.jpeg"", image_enc)

sess = tf.Session()
sess.run([fwrite])
```

I think this feature could be very useful when working with image input to have a function (here: **""tf.image.resize_image_keep_aspect""**) which allow us to do the operation more quickly (and I hope more efficiently!)

```
#!/usr/bin/env python
import tensorflow as tf

MAX_SIZE = 512

# Image (for example: 2340x4160)
image_path = ""your_image.jpg""

# Open image
image_string  = tf.read_file(image_path)
image         = tf.image.decode_jpeg(image_string, channels=3)
resized_image = tf.image.resize_image_keep_aspect(image, MAX_SIZE)
image_enc     = tf.image.encode_jpeg(resized_image)
fwrite        = tf.write_file(""my_resized_image.jpeg"", image_enc)

sess = tf.Session()
sess.run([fwrite])
```

If the feature already exist, sorry but I search on git/stackoverflow/google and didn't find any viable solution.

If you have any question or if I'm not clear, ask to me.
Have a nice day :)
"
14212,Suggestion: Add Image Captioning Model Example for Android,"This is a suggestion to add Android example for our deep-learning based tensorflow-android app which captions live camera frames in real-time.
https://github.com/neural-nuts/Cam2Caption

This app uses pre-trained model generated using 
https://github.com/neural-nuts/image-caption-generator"
14211,SWIGing tensorflow/python/tensorflow.i failed (Exit 1) on Centos 6.2,"Hi,

Trying to build on Centos 6.2 with the following command:
```
bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --verbose_failures
```
gives the following error:
```
INFO: $TEST_TMPDIR defined: output root default is '/tmp'.
........................
WARNING: /home/username/src/tensorflow/tensorflow/core/BUILD:1787:1: in includes attribute of cc_library rule //tensorflow/core:framework_headers_lib: '../../external/nsync/public' resolves to 'external/nsync/public' not below the relative path of its package 'tensorflow/core'. This will be an error in the future. Since this rule was created by the macro 'cc_header_only_library', the error might have been caused by the macro implementation in /home/username/src/tensorflow/tensorflow/tensorflow.bzl:1073:30.
WARNING: /home/username/src/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': No longer supported. Switch to SavedModel immediately.
WARNING: /home/username/src/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': No longer supported. Switch to SavedModel immediately.
INFO: Found 1 target...
ERROR: /home/username/src/tensorflow/tensorflow/python/BUILD:2974:1: SWIGing tensorflow/python/tensorflow.i failed (Exit 1): swig failed: error executing command
  (cd /tmp/_bazel_username/dcca333cc36b578f4473c754fbbc85ff/execroot/org_tensorflow && \
  exec env - \
  bazel-out/host/bin/external/swig/swig -c++ -python -module pywrap_tensorflow_internal -o bazel-out/local-py3-opt/bin/tensorflow/python/pywrap_tensorflow_internal.cc -outdir bazel-out/local-py3-opt/bin/tensorflow/python -ltensorflow/python/client/device_lib.i -ltensorflow/python/client/events_writer.i -ltensorflow/python/client/tf_session.i -ltensorflow/python/client/tf_sessionrun_wrapper.i -ltensorflow/python/framework/cpp_shape_inference.i -ltensorflow/python/framework/python_op_gen.i -ltensorflow/python/grappler/cluster.i -ltensorflow/python/grappler/cost_analyzer.i -ltensorflow/python/grappler/item.i -ltensorflow/python/grappler/model_analyzer.i -ltensorflow/python/grappler/tf_optimizer.i -ltensorflow/python/lib/core/py_func.i -ltensorflow/python/lib/core/strings.i -ltensorflow/python/lib/io/file_io.i -ltensorflow/python/lib/io/py_record_reader.i -ltensorflow/python/lib/io/py_record_writer.i -ltensorflow/python/platform/base.i -ltensorflow/python/pywrap_tfe.i -ltensorflow/python/training/quantize_training.i -ltensorflow/python/training/server_lib.i -ltensorflow/python/util/kernel_registry.i -ltensorflow/python/util/port.i -ltensorflow/python/util/py_checkpoint_reader.i -ltensorflow/python/util/stat_summarizer.i -ltensorflow/python/util/tfprof.i -ltensorflow/python/util/transform_graph.i -ltensorflow/python/util/util.i -Ibazel-out/local-py3-opt/genfiles -Iexternal/eigen_archive -Iexternal/grpc -Iexternal/protobuf_archive -Iexternal/swig -Iexternal/boringssl -Ibazel-out/local-py3-opt/genfiles/external/local_config_python -Iexternal/nsync -Iexternal/gemmlowp -Iexternal/jpeg -Iexternal/com_googlesource_code_re2 -Iexternal/jsoncpp_git -Iexternal/zlib_archive -Iexternal/highwayhash -Iexternal/gif_archive -Ibazel-out/local-py3-opt/genfiles/external/jpeg -Iexternal/lmdb -Iexternal/png_archive -Iexternal/farmhash_archive -Iexternal/local_config_cuda -Iexternal/sqlite_archive -Iexternal/swig/Lib -Iexternal/swig/Lib/cffi -Iexternal/swig/Lib/python -Iexternal/swig/Lib/std -Iexternal/swig/Lib/typemaps tensorflow/python/tensorflow.i).
Target //tensorflow/tools/pip_package:build_pip_package failed to build
```

Is there any way to at least see what the error from swig is? Running the reported command manually works fine."
14209,Why eager concat  inputs?,"I am using eager to implement a seq2seq model. 
Here is a [toy model](https://github.com/soenkyo/toy_seq2seq_4_debug):
No error arise in forward calculate, but in backprop, I get:

`Traceback (most recent call last):
  File ""/home/usr/eager/test.py"", line 18, in <module>
    tf.app.run()
  File ""/home/usr/miniconda2/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""/home/usr/eager/test.py"", line 14, in main
    empirical_loss, gradients_and_variables = cal_gradient()
  File ""/home/usr/miniconda2/lib/python2.7/site-packages/tensorflow/python/eager/backprop.py"", line 362, in grad_fn
    sources)
  File ""/home/usr/miniconda2/lib/python2.7/site-packages/tensorflow/python/eager/imperative_grad.py"", line 230, in imperative_grad
    result.append(vspace.aggregate_fn(g))
  File ""/home/usr/miniconda2/lib/python2.7/site-packages/tensorflow/python/eager/backprop.py"", line 716, in _aggregate_grads
    for x in indexed_slices_list], 0)
  File ""/home/usr/miniconda2/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py"", line 1110, in concat
    return gen_array_ops._concat_v2(values=values, axis=axis, name=name)
  File ""/home/usr/miniconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 719, in _concat_v2
    attrs=_attrs, ctx=_ctx, name=name)
  File ""/home/usr/miniconda2/lib/python2.7/site-packages/tensorflow/python/eager/execute.py"", line 67, in execute
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""/home/usr/miniconda2/lib/python2.7/site-packages/six.py"", line 718, in raise_from
    raise value
tensorflow.python.framework.errors_impl.InvalidArgumentError: ConcatOp : Dimensions of inputs should match: shape[0] = [16,100] vs. shape[1] = [16,400] [Op:ConcatV2] name: concat
`
"
14208,java.lang.UnsatisfiedLinkError: tensorflow_native_libraries-1509708652238-0/libtensorflow_jni.so: /lib64/libc.so.6: version `GLIBC_2.16' not found (required bytensorflow_native_libraries-1509708652238-0/libtensorflow_jni.so),The exception is caught when I run Tensorflow API in java. There is no GLIBC_2.16. The lowest version is 2.2.5. what should I do? Could I package the .so file by myself?
14207,Could not find any downloads that satisfy the requirement tensorflow,"I cannot install Tensorflow using `pip install tensorflow`

> Installing TensorFlow on Ubuntu
> 
> This guide explains how to install TensorFlow on Ubuntu. These instructions might also work on other Linux variants, but we have only tested (and we only support) these instructions on **Ubuntu 14.04 or higher**.


```
>>> python -V
Python 2.7.6

>>> pip -V
pip 1.5.4 from /usr/lib/python2.7/dist-packages (python 2.7)

>>> uname -a
Linux 241f7b925fda 3.16.0-36-generic #48~14.04.1-Ubuntu SMP Wed Apr 15 13:11:28 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux

>>> lsb_release -a
No LSB modules are available.
Distributor ID:	Ubuntu
Description:	Ubuntu 14.04.2 LTS
Release:	14.04
Codename:	trusty

>>> pip install tensorflow
Downloading/unpacking tensorflow
  Could not find any downloads that satisfy the requirement tensorflow
Cleaning up...
No distributions at all found for tensorflow
Storing debug log for failure in /root/.pip/pip.log

>>> tail -n 20 /root/.pip/pip.log
    Skipping https://pypi.python.org/packages/fd/1a/7935eb82b9a9b89a3a8ef7e54f7d538698c85d248d8bedb533eab5afd293/tensorflow-1.0.1-cp36-cp36m-manylinux1_x86_64.whl#md5=61d704d2c563b2569524545f106f0a4a (from https://pypi.python.org/simple/tensorflow/) because it is not compatible with this Python
    Skipping https://pypi.python.org/packages/fd/1a/b6e78223c8e05a8bdee8f9bb20d4926f81db50e583632a1cde6e5b5ec2f0/tensorflow-1.1.0-cp35-cp35m-manylinux1_x86_64.whl#md5=fc5ed08795ef5afa60b48ae916def79c (from https://pypi.python.org/simple/tensorflow/) because it is not compatible with this Python
    Skipping https://pypi.python.org/packages/fd/cb/21c20d0597cbf67e952f590355b2cdb93544b699cd6ee46a4dc9069d037d/tensorflow-1.4.0rc0-cp33-cp33m-macosx_10_11_x86_64.whl#md5=05c4cfd97ed74ddd1753312aa5b19fca (from https://pypi.python.org/simple/tensorflow/) because it is not compatible with this Python
    Skipping https://pypi.python.org/packages/fe/d0/49d9d8e6e781acde22b7bcbee693a1be86bcf8f6c21e915159ab61d12bd8/tensorflow-1.3.0-cp33-cp33m-macosx_10_11_x86_64.whl#md5=2855104686160b99a64910d33935d7d8 (from https://pypi.python.org/simple/tensorflow/) because it is not compatible with this Python
    Skipping https://pypi.python.org/packages/fe/dd/8764ae59e8ff74421d615ddb9c86a1b404c27708dfde3caa8f17c183788d/tensorflow-1.3.0-cp27-cp27mu-manylinux1_x86_64.whl#md5=e82e309e6af0996f2083f59cf21d392c (from https://pypi.python.org/simple/tensorflow/) because it is not compatible with this Python
  Could not find any downloads that satisfy the requirement tensorflow
Cleaning up...
  Removing temporary dir /tmp/pip_build_root...
No distributions at all found for tensorflow
Exception information:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/dist-packages/pip/basecommand.py"", line 122, in main
    status = self.run(options, args)
  File ""/usr/lib/python2.7/dist-packages/pip/commands/install.py"", line 278, in run
    requirement_set.prepare_files(finder, force_root_egg_info=self.bundle, bundle=self.bundle)
  File ""/usr/lib/python2.7/dist-packages/pip/req.py"", line 1178, in prepare_files
    url = finder.find_requirement(req_to_install, upgrade=self.upgrade)
  File ""/usr/lib/python2.7/dist-packages/pip/index.py"", line 277, in find_requirement
    raise DistributionNotFound('No distributions at all found for %s' % req)
DistributionNotFound: No distributions at all found for tensorflow
```"
14205,TensorFlow r1.4 does not be compiled from 32bit environment.,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: None
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Slackware 14.2 32bit
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: r1.4
- **Python version**: 3.6.3
- **Bazel version (if compiling from source)**: 0.5.4
- **GCC/Compiler version (if compiling from source)**: 5.3.0
- **CUDA/cuDNN version**: None
- **GPU model and memory**: None
- **Exact command to reproduce**: bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package and set optimization flags to -march=i686

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

Installing TensorFlow r1.4 on a Linux system with 32bit kernel does not work. I think the error comes from the configuration of the nsync, which does not care 32bit environment. 

I googled it, and found a workaround.
[https://lengerrong.blogspot.kr/2017/09/fix-up-configurable-attribute-copts.html](https://lengerrong.blogspot.kr/2017/09/fix-up-configurable-attribute-copts.html)

and added 

`""//conditions""default"": []'`

to the appropriate place.

However, I think that it will be much better if the official configure system of the TensorFlow supports the 32bit system.

Thanks.
Sungjin.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

None.
"
14203,Convert keras model to estimator model,"ValueError: ('Expected `model` argument to be a `Model` instance, got ', <keras.engine.training.Model object at 0x00000230F36F0E10>)
"
14202,Fails to optimize MultivariateNormalFullCovariance. It breaks on Cholesky decomposition . I have cherry picked the mentioned commit to update gradient issue in  MultivariateNormalFullCovariance. Still it fails in optimization,"I am trying to optimize a distribution with Mu=Nx4 and covariance matrix = Nx4x4 using MultivariateNormalFullCovariance. The optimization runs for few iterations, loss seems to be reducing (gradients are not exploding !). The code breaks with following   

InvalidArgumentError (see above for traceback): Got info = 4 for batch index 0, expected info = 0. Debug_info =potrf

[[Node: MultivariateNormalFullCovariance/init/Cholesky = Cholesky[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""](Reshape_2)]]
	 [[Node: gradients/AddN_30/_49 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_3080_gradients/AddN_30"", tensor_type=DT_FL

I have debugged,  analyzing the covarince,pdf and gradients they all seem to be alright(giving expecting values). Suddenly at one iteration code breaks."
14198,Tensorflow 1.4 Keras issue with respect to model_fn,"I have a model function which accepts Features, targets and mode but when I add tf.keras layers I'm currently getting Exception **`pred` must be a Tensor, a Variable, or a Python bool.**

But, When I run the same code with out using tf.keras but directly from keras(i.e. **from keras.layers**), It's working.

**Code :**

```python
def model_fn(features, labels, mode):

    if mode == tf.estimator.ModeKeys.TRAIN:
        tf.keras.backend.set_learning_phase(1)
    else:
        tf.keras.backend.set_learning_phase(0)

    input_feature = features['x']
    table = lookup.index_table_from_file(vocabulary_file='vocab.txt', num_oov_buckets=1, default_value=-1)
    text = tf.squeeze(input_feature, [1])
    words = tf.string_split(text)
    densewords = tf.sparse_tensor_to_dense(words, default_value=PADWORD)
    numbers = table.lookup(densewords)
    padding = tf.constant([[0, 0], [0, MAX_FEATURES]])
    padded = tf.pad(numbers, padding)
    sliced = tf.slice(padded, [0, 0], [-1, MAX_FEATURES])
    print('words_sliced={}'.format(words))

    #embeds = tf.keras.layers.Embedding(MAX_FEATURES, 50, input_length=MAX_FEATURES)(sliced)
    embeds = tf.contrib.layers.embed_sequence(sliced, vocab_size=MAX_FEATURES, embed_dim=50)
    print('words_embed={}'.format(embeds))

    f1 = tf.keras.layers.Dropout(0.2)(embeds)
    f1 = tf.keras.layers.Conv1D(filters, kernel_size, padding='valid', activation='relu', strides=1)(f1)
    f1 = tf.keras.layers.GlobalAveragePooling1D()(f1)
    # f1 = layers.BatchNormalization()(f1)
    f1 = tf.keras.layers.Dense(hidden_dims)(f1)
    f1 = tf.keras.layers.Dropout(0.5)(f1)
    f1 = tf.keras.layers.Activation('relu')(f1)
    logits = tf.keras.layers.Dense(11)(f1)

    predictions_dict = {
        'class': tf.argmax(logits, 1),
        'prob': tf.nn.softmax(logits)
    }

    prediction_output = tf.estimator.export.PredictOutput({""classes"": tf.argmax(input=logits, axis=1),
                                                           ""probabilities"": tf.nn.softmax(logits,
                                                                                          name=""softmax_tensor"")})

    if mode == tf.estimator.ModeKeys.PREDICT:
        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions_dict, export_outputs={
            tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: prediction_output
        })

    # one_hot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=11)
    loss = tf.losses.sparse_softmax_cross_entropy(labels, logits=logits)

    if mode == tf.contrib.learn.ModeKeys.TRAIN:
        train_op = tf.contrib.layers.optimize_loss(loss, tf.contrib.framework.get_global_step(), optimizer='Adam',
                                                   learning_rate=0.001)
        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)

    eval_metrics_ops = {
        'accuracy': tf.metrics.accuracy(labels=labels, predictions=predictions_dict['class'])
    }
    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metrics_ops)
```

**Exception:**

  File ""D:/PyCharm-Workspace/Keras-Exp/finance-complaints/tensorflow/tf_finance_complaints.py"", line 149, in <module>
    finance_classifier.train(input_fn=lambda: input_fn('dataset/train.csv', batch_size=32, repeat_count=5, shuffle=True))
  File ""E:\Programs\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\estimator\estimator.py"", line 302, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""E:\Programs\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\estimator\estimator.py"", line 711, in _train_model
    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)
  File ""E:\Programs\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\estimator\estimator.py"", line 694, in _call_model_fn
    model_fn_results = self._model_fn(features=features, **kwargs)
  File ""D:/PyCharm-Workspace/Keras-Exp/finance-complaints/tensorflow/tf_finance_complaints.py"", line 108, in model_fn
    f1 = tf.keras.layers.Dropout(0.2)(embeds)
  File ""E:\Programs\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\keras\_impl\keras\engine\topology.py"", line 252, in __call__
    output = super(Layer, self).__call__(inputs, **kwargs)
  File ""E:\Programs\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\layers\base.py"", line 575, in __call__
    outputs = self.call(inputs, *args, **kwargs)
  File ""E:\Programs\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\keras\_impl\keras\layers\core.py"", line 118, in call
    output = super(Dropout, self).call(inputs, training=training)
  File ""E:\Programs\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\layers\core.py"", line 300, in call
    lambda: array_ops.identity(inputs))
  File ""E:\Programs\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\layers\utils.py"", line 203, in smart_cond
    pred_value = constant_value(pred)
  File ""E:\Programs\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\layers\utils.py"", line 233, in constant_value
    raise TypeError('`pred` must be a Tensor, a Variable, or a Python bool.')
TypeError: `pred` must be a Tensor, a Variable, or a Python bool."
14196,Dataset memory bottleneck not showing in debug mode,"im fitting word2vec models using distributed gpus which require me to assemble multiple towers and so copy my model several times over. to load data i am using the get_next method of a contrib.dataset iterator initialized with one_shot. before starting up i run into the 2gb protobuf memory bottleneck. so in debug mode i compared 3 models: one where dataset is given full data, another where dataset is given 30% of my data and a last where dataset is given 1% of my data. the first doesnt run. but most importantly, for the second two, i compared the size of all of my tensors and they are all the same. this makes debugging difficult. any thoughts? i suspect there's something going on with folding of constants? 

Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
14194,Make CMake on TensorFlow Incrementally Compile on Windows,"I'm working with the tensorflow r1.4 branch on Windows 7 with Visual Studio 2015.   When I configure

```
cmake C:\Users\Kevin\dev\tensorflow-r1.4\tensorflow\contrib\cmake -A x64 -DCMAKE_BUILD_TYPE=Release -DSWIG_EXECUTABLE=C:/Users/Kevin/dev/swigwin-3.0.12/swig.exe -DPYTHON_EXECUTABLE=C:/ProgramData/Anaconda3/python.exe -DPYTHON_LIBRARIES=C:/ProgramData/Anaconda3/libs/python35.lib -DPYTHON_INCLUDE_DIR=C:\ProgramData\Anaconda3\include -DNUMPY_INCLUDE_DIR=C:\ProgramData\Anaconda3\Lib\site-packages\numpy\core\include -Dtensorflow_ENABLE_GPU=ON -DCUDNN_HOME=""C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v8.0""
```
and run

```
powershell ""MSBuild /m /p:Configuration=Release tf_python_build_pip_package.vcxproj | tee msbuild.txt""
```
the build always compiles all the projects, even the projects already compiled.

Looking at the first few lines of msbuild.txt I see

```
Microsoft (R) Build Engine version 14.0.25420.1
Copyright (C) Microsoft Corporation. All rights reserved.

Build started 11/2/2017 4:35:58 PM.
     1>Project ""C:\users\kevin\dev\tensorflow-r1.4\tensorflow\contrib\cmake\tf_python_build_pip_package.vcxproj"" on node 1 (default targets).
     1>Project ""C:\users\kevin\dev\tensorflow-r1.4\tensorflow\contrib\cmake\tf_python_build_pip_package.vcxproj"" (1) is building ""C:\Users\Kevin\dev\tensorflow-r1.4\tensorflow\contrib\cmake\ZERO_CHECK.vcxproj"" (2) on node 1 (default targets).
     2>InitializeBuildStatus:
         Creating ""x64\Release\ZERO_CHECK\ZERO_CHECK.tlog\unsuccessfulbuild"" because ""AlwaysCreate"" was specified.
       CustomBuild:
         Checking Build System
         CMake is re-running because C:/Users/Kevin/dev/tensorflow-r1.4/tensorflow/contrib/cmake/CMakeFiles/generate.stamp is out-of-date.
           the file 'C:/Users/Kevin/dev/tensorflow-r1.4/tensorflow/contrib/cmake/CMakeFiles/tf_core_gpu_kernels.dir/__/__/core/kernels/tf_core_gpu_kernels_generated_cwise_op_gpu_igammas.cu.cc.obj.depend'
           is newer than 'C:/Users/Kevin/dev/tensorflow-r1.4/tensorflow/contrib/cmake/CMakeFiles/generate.stamp.depend'
           result='-1'
         -- Configuring done
```
The issue isn't the multicore builds, I'm just using multicore builds to speed up the overall build, which takes 5 hours on one core.

The problem appears to be that the generate.stamp isn't what's expected."
14193,"TypeError: Cannot interpret feed_dict key as Tensor: The name 'save/Const:0' refers to a Tensor which does not exist. The operation, 'save/Const', does not exist in the graph.","From this file: https://github.com/llSourcell/pong_neural_network_live/blob/master/RL.py

I've updated the lines 

    #first convolutional layer. bias vector
    #creates an empty tensor with all elements set to zero with a shape
    W_conv1 = tf.Variable(tf.zeros([8, 8, 4, 32]) , name='W_conv1')
    b_conv1 = tf.Variable(tf.zeros([32]), name='b_conv1')

    W_conv2 = tf.Variable(tf.zeros([4, 4, 32, 64]), name='W_conv2')
    b_conv2 = tf.Variable(tf.zeros([64]), name='b_conv2')

    W_conv3 = tf.Variable(tf.zeros([3, 3, 64, 64]), name='W_conv3')
    b_conv3 = tf.Variable(tf.zeros([64]), name='b_conv3')

    W_fc4 = tf.Variable(tf.zeros([3136, 784]), name='W_fc4')
    b_fc4 = tf.Variable(tf.zeros([784]), name='b_fc4')

    W_fc5 = tf.Variable(tf.zeros([784, ACTIONS]), name='W_fc5')
    b_fc5 = tf.Variable(tf.zeros([ACTIONS]), name='b_fc5')

and:

    saver.save(sess, './' + 'pong' + '-dqn', global_step = timestamp )

and in:

    def main():
        # ////
        tf.reset_default_graph()    
        imported_meta = tf.train.import_meta_graph('./' + 'pong' + '-dqn-' + '48000' + '.meta')  
        imported_meta.restore(sess, tf.train.latest_checkpoint('./'))
        # ////

To try and restore the model but I get this error:

TypeError: Cannot interpret feed_dict key as Tensor: The name 'save/Const:0' refers to a Tensor which does not exist. The operation, 'save/Const', does not exist in the graph.

When I try this:

     graph = tf.get_default_graph() 
     W_conv1 = graph.get_tensor_by_name(""W_conv1:0"")
     b_conv1 = graph.get_tensor_by_name(""wb_conv1:0"") 
     W_conv2 = graph.get_tensor_by_name(""W_conv2:0"")
     b_conv2 = graph.get_tensor_by_name(""wb_conv2:0"") 
     W_conv3 = graph.get_tensor_by_name(""W_conv3:0"")
     b_conv3 = graph.get_tensor_by_name(""b_conv3:0"") 
     W_fc4 = graph.get_tensor_by_name(""W_fc4:0"")
     b_fc4 = graph.get_tensor_by_name(""b_fc4:0"") 
     W_fc5 = graph.get_tensor_by_name(""W_fc5:0"")
     b_fc5 = graph.get_tensor_by_name(""b_fc5:0"")  

I get this error:

""The name 'W_conv1:0' refers to a Tensor which does not exist. The operation, 'W_conv1', does not exist in the graph.

Why is this happening? I've created my game in pygame and I'm trying to connect it to the RL. I'd like to make sure I can save and load my progress. I'm just having trouble with the logic of how to save and load.

Thanks in advance!

Why is this happening?
"
14191,tf.nn.l2_normalize takes dim instead of axis,"At master, `tf.nn.l2_normalize` still takes the axis parameter as `dim`.  Everything else has been standardized on `axis`, so it'd be nice if this one was `axis` too.  Since `dim` can't be changed for backwards compatibility reasons, presumably the right approach is adding an extra `axis` argument and requiring that at most one of them is set.

@aselle: Is that right?"
14190,tf.contrib.boosted_trees still cannot be used in official 1.4.0,"Hi, i have raised an [issue](https://github.com/tensorflow/tensorflow/issues/14087#event-1319398254) before, however after i upgrade to official 1.4.0, the problem is still the same.

I am sorry about raising this again, but GBDT in TF seems so appealing to users.

TF version: 1.4.0
Py version: 2.7.10
OS: Mac OS

The testing script i am using is:
```python
import argparse
import numpy as np
import tensorflow as tf
from tensorflow.contrib.boosted_trees.estimator_batch.estimator import GradientBoostedDecisionTreeClassifier
from tensorflow.contrib.boosted_trees.proto import learner_pb2
from tensorflow.contrib.learn import learn_runner

tf.logging.set_verbosity(tf.logging.INFO)

parser = argparse.ArgumentParser()
parser.add_argument(""--batch_size"",type=int,default=1000)
parser.add_argument(""--depth"", type=int, default=4, help=""Maximum depth of weak learners."")
parser.add_argument(""--l2"", type=float, default=1.0, help=""l2 regularization per batch."")
parser.add_argument(""--learning_rate"",type=float,default=0.1)
parser.add_argument(""--examples_per_layer"", type=int, default=1000)
parser.add_argument(""--num_trees"", type=int, default=10)
args = parser.parse_args()

learner_config = learner_pb2.LearnerConfig()
num_classes = 10
learner_config.learning_rate_tuner.fixed.learning_rate = args.learning_rate
learner_config.num_classes = num_classes
learner_config.regularization.l1 = 0.0
learner_config.regularization.l2 = args.l2 / args.examples_per_layer
learner_config.constraints.max_tree_depth = args.depth

growing_mode = learner_pb2.LearnerConfig.LAYER_BY_LAYER
learner_config.growing_mode = growing_mode
learner_config.multi_class_strategy = (
    learner_pb2.LearnerConfig.DIAGONAL_HESSIAN)

estimator = GradientBoostedDecisionTreeClassifier(
    learner_config=learner_config,
    n_classes=num_classes,
    examples_per_layer=args.examples_per_layer,
    num_trees=args.num_trees,
    center_bias=False)

(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()
X_train = (X_train / 255.).reshape(-1, 28*28).astype(np.float32)
y_train = y_train.astype(np.int32)

estimator.fit(input_fn=tf.estimator.inputs.numpy_input_fn(
    x={'_':X_train}, y=y_train, batch_size=args.batch_size, num_epochs=1, shuffle=True))
```
The full error i am getting is:
```
(tf_1.4) Zhedongs-MacBook-Pro:desktop zhedongzheng$ python tf_boost_test.py
INFO:tensorflow:Using default config.
WARNING:tensorflow:Using temporary folder as model directory: /var/folders/sx/fv0r97j96fz8njp14dt5g7940000gn/T/tmpCFdPSc
INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x110dac810>, '_model_dir': '/var/folders/sx/fv0r97j96fz8njp14dt5g7940000gn/T/tmpCFdPSc', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_tf_random_seed': None, '_save_summary_steps': 100, '_environment': 'local', '_num_worker_replicas': 0, '_task_id': 0, '_log_step_count_steps': 100, '_tf_config': gpu_options {
  per_process_gpu_memory_fraction: 1
}
, '_evaluation_master': '', '_master': ''}
INFO:tensorflow:Active Feature Columns: ['__0', '__1', '__2', '__3', '__4', '__5', '__6', '__7', '__8', '__9', '__10', '__11', '__12', '__13', '__14', '__15', '__16', '__17', '__18', '__19', '__20', '__21', '__22', '__23', '__24', '__25', '__26', '__27', '__28', '__29', '__30', '__31', '__32', '__33', '__34', '__35', '__36', '__37', '__38', '__39', '__40', '__41', '__42', '__43', '__44', '__45', '__46', '__47', '__48', '__49', '__50', '__51', '__52', '__53', '__54', '__55', '__56', '__57', '__58', '__59', '__60', '__61', '__62', '__63', '__64', '__65', '__66', '__67', '__68', '__69', '__70', '__71', '__72', '__73', '__74', '__75', '__76', '__77', '__78', '__79', '__80', '__81', '__82', '__83', '__84', '__85', '__86', '__87', '__88', '__89', '__90', '__91', '__92', '__93', '__94', '__95', '__96', '__97', '__98', '__99', '__100', '__101', '__102', '__103', '__104', '__105', '__106', '__107', '__108', '__109', '__110', '__111', '__112', '__113', '__114', '__115', '__116', '__117', '__118', '__119', '__120', '__121', '__122', '__123', '__124', '__125', '__126', '__127', '__128', '__129', '__130', '__131', '__132', '__133', '__134', '__135', '__136', '__137', '__138', '__139', '__140', '__141', '__142', '__143', '__144', '__145', '__146', '__147', '__148', '__149', '__150', '__151', '__152', '__153', '__154', '__155', '__156', '__157', '__158', '__159', '__160', '__161', '__162', '__163', '__164', '__165', '__166', '__167', '__168', '__169', '__170', '__171', '__172', '__173', '__174', '__175', '__176', '__177', '__178', '__179', '__180', '__181', '__182', '__183', '__184', '__185', '__186', '__187', '__188', '__189', '__190', '__191', '__192', '__193', '__194', '__195', '__196', '__197', '__198', '__199', '__200', '__201', '__202', '__203', '__204', '__205', '__206', '__207', '__208', '__209', '__210', '__211', '__212', '__213', '__214', '__215', '__216', '__217', '__218', '__219', '__220', '__221', '__222', '__223', '__224', '__225', '__226', '__227', '__228', '__229', '__230', '__231', '__232', '__233', '__234', '__235', '__236', '__237', '__238', '__239', '__240', '__241', '__242', '__243', '__244', '__245', '__246', '__247', '__248', '__249', '__250', '__251', '__252', '__253', '__254', '__255', '__256', '__257', '__258', '__259', '__260', '__261', '__262', '__263', '__264', '__265', '__266', '__267', '__268', '__269', '__270', '__271', '__272', '__273', '__274', '__275', '__276', '__277', '__278', '__279', '__280', '__281', '__282', '__283', '__284', '__285', '__286', '__287', '__288', '__289', '__290', '__291', '__292', '__293', '__294', '__295', '__296', '__297', '__298', '__299', '__300', '__301', '__302', '__303', '__304', '__305', '__306', '__307', '__308', '__309', '__310', '__311', '__312', '__313', '__314', '__315', '__316', '__317', '__318', '__319', '__320', '__321', '__322', '__323', '__324', '__325', '__326', '__327', '__328', '__329', '__330', '__331', '__332', '__333', '__334', '__335', '__336', '__337', '__338', '__339', '__340', '__341', '__342', '__343', '__344', '__345', '__346', '__347', '__348', '__349', '__350', '__351', '__352', '__353', '__354', '__355', '__356', '__357', '__358', '__359', '__360', '__361', '__362', '__363', '__364', '__365', '__366', '__367', '__368', '__369', '__370', '__371', '__372', '__373', '__374', '__375', '__376', '__377', '__378', '__379', '__380', '__381', '__382', '__383', '__384', '__385', '__386', '__387', '__388', '__389', '__390', '__391', '__392', '__393', '__394', '__395', '__396', '__397', '__398', '__399', '__400', '__401', '__402', '__403', '__404', '__405', '__406', '__407', '__408', '__409', '__410', '__411', '__412', '__413', '__414', '__415', '__416', '__417', '__418', '__419', '__420', '__421', '__422', '__423', '__424', '__425', '__426', '__427', '__428', '__429', '__430', '__431', '__432', '__433', '__434', '__435', '__436', '__437', '__438', '__439', '__440', '__441', '__442', '__443', '__444', '__445', '__446', '__447', '__448', '__449', '__450', '__451', '__452', '__453', '__454', '__455', '__456', '__457', '__458', '__459', '__460', '__461', '__462', '__463', '__464', '__465', '__466', '__467', '__468', '__469', '__470', '__471', '__472', '__473', '__474', '__475', '__476', '__477', '__478', '__479', '__480', '__481', '__482', '__483', '__484', '__485', '__486', '__487', '__488', '__489', '__490', '__491', '__492', '__493', '__494', '__495', '__496', '__497', '__498', '__499', '__500', '__501', '__502', '__503', '__504', '__505', '__506', '__507', '__508', '__509', '__510', '__511', '__512', '__513', '__514', '__515', '__516', '__517', '__518', '__519', '__520', '__521', '__522', '__523', '__524', '__525', '__526', '__527', '__528', '__529', '__530', '__531', '__532', '__533', '__534', '__535', '__536', '__537', '__538', '__539', '__540', '__541', '__542', '__543', '__544', '__545', '__546', '__547', '__548', '__549', '__550', '__551', '__552', '__553', '__554', '__555', '__556', '__557', '__558', '__559', '__560', '__561', '__562', '__563', '__564', '__565', '__566', '__567', '__568', '__569', '__570', '__571', '__572', '__573', '__574', '__575', '__576', '__577', '__578', '__579', '__580', '__581', '__582', '__583', '__584', '__585', '__586', '__587', '__588', '__589', '__590', '__591', '__592', '__593', '__594', '__595', '__596', '__597', '__598', '__599', '__600', '__601', '__602', '__603', '__604', '__605', '__606', '__607', '__608', '__609', '__610', '__611', '__612', '__613', '__614', '__615', '__616', '__617', '__618', '__619', '__620', '__621', '__622', '__623', '__624', '__625', '__626', '__627', '__628', '__629', '__630', '__631', '__632', '__633', '__634', '__635', '__636', '__637', '__638', '__639', '__640', '__641', '__642', '__643', '__644', '__645', '__646', '__647', '__648', '__649', '__650', '__651', '__652', '__653', '__654', '__655', '__656', '__657', '__658', '__659', '__660', '__661', '__662', '__663', '__664', '__665', '__666', '__667', '__668', '__669', '__670', '__671', '__672', '__673', '__674', '__675', '__676', '__677', '__678', '__679', '__680', '__681', '__682', '__683', '__684', '__685', '__686', '__687', '__688', '__689', '__690', '__691', '__692', '__693', '__694', '__695', '__696', '__697', '__698', '__699', '__700', '__701', '__702', '__703', '__704', '__705', '__706', '__707', '__708', '__709', '__710', '__711', '__712', '__713', '__714', '__715', '__716', '__717', '__718', '__719', '__720', '__721', '__722', '__723', '__724', '__725', '__726', '__727', '__728', '__729', '__730', '__731', '__732', '__733', '__734', '__735', '__736', '__737', '__738', '__739', '__740', '__741', '__742', '__743', '__744', '__745', '__746', '__747', '__748', '__749', '__750', '__751', '__752', '__753', '__754', '__755', '__756', '__757', '__758', '__759', '__760', '__761', '__762', '__763', '__764', '__765', '__766', '__767', '__768', '__769', '__770', '__771', '__772', '__773', '__774', '__775', '__776', '__777', '__778', '__779', '__780', '__781', '__782', '__783']
Traceback (most recent call last):
  File ""tf_boost_test.py"", line 52, in <module>
    x={'_':X_train}, y=y_train, batch_size=args.batch_size, num_epochs=1, shuffle=True))
  File ""/Users/zhedongzheng/pyenv/py2.7/tf_1.4/tf_1.4/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py"", line 316, in new_func
    return func(*args, **kwargs)
  File ""/Users/zhedongzheng/pyenv/py2.7/tf_1.4/tf_1.4/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 480, in fit
    loss = self._train_model(input_fn=input_fn, hooks=hooks)
  File ""/Users/zhedongzheng/pyenv/py2.7/tf_1.4/tf_1.4/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 986, in _train_model
    model_fn_ops = self._get_train_ops(features, labels)
  File ""/Users/zhedongzheng/pyenv/py2.7/tf_1.4/tf_1.4/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 1202, in _get_train_ops
    return self._call_model_fn(features, labels, model_fn_lib.ModeKeys.TRAIN)
  File ""/Users/zhedongzheng/pyenv/py2.7/tf_1.4/tf_1.4/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 1166, in _call_model_fn
    model_fn_results = self._model_fn(features, labels, **kwargs)
  File ""/Users/zhedongzheng/pyenv/py2.7/tf_1.4/tf_1.4/lib/python2.7/site-packages/tensorflow/contrib/boosted_trees/estimator_batch/model.py"", line 116, in model_builder
    logits=logits)
  File ""/Users/zhedongzheng/pyenv/py2.7/tf_1.4/tf_1.4/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py"", line 1064, in create_model_fn_ops
    enable_centered_bias=self._enable_centered_bias)
  File ""/Users/zhedongzheng/pyenv/py2.7/tf_1.4/tf_1.4/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py"", line 648, in _create_model_fn_ops
    batch_size, loss_fn, weight_tensor)
  File ""/Users/zhedongzheng/pyenv/py2.7/tf_1.4/tf_1.4/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py"", line 1923, in _train_op
    train_op = train_op_fn(loss)
  File ""/Users/zhedongzheng/pyenv/py2.7/tf_1.4/tf_1.4/lib/python2.7/site-packages/tensorflow/contrib/boosted_trees/estimator_batch/model.py"", line 105, in _train_op_fn
    update_op = gbdt_model.train(loss, predictions_dict, labels)
  File ""/Users/zhedongzheng/pyenv/py2.7/tf_1.4/tf_1.4/lib/python2.7/site-packages/tensorflow/contrib/boosted_trees/python/training/functions/gbdt_batch.py"", line 543, in train
    hessian_list = self._diagonal_hessian(gradients, predictions)
  File ""/Users/zhedongzheng/pyenv/py2.7/tf_1.4/tf_1.4/lib/python2.7/site-packages/tensorflow/contrib/boosted_trees/python/training/functions/gbdt_batch.py"", line 845, in _diagonal_hessian
    aggregation_method=None)
  File ""/Users/zhedongzheng/pyenv/py2.7/tf_1.4/tf_1.4/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py"", line 581, in gradients
    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))
  File ""/Users/zhedongzheng/pyenv/py2.7/tf_1.4/tf_1.4/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py"", line 353, in _MaybeCompile
    return grad_fn()  # Exit early
  File ""/Users/zhedongzheng/pyenv/py2.7/tf_1.4/tf_1.4/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py"", line 581, in <lambda>
    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))
  File ""/Users/zhedongzheng/pyenv/py2.7/tf_1.4/tf_1.4/lib/python2.7/site-packages/tensorflow/python/ops/array_grad.py"", line 352, in _PreventGradientGrad
    ""Gradient explicitly disabled. Reason: %s"" % op.get_attr(""message""))
LookupError: Gradient explicitly disabled. Reason: Currently there is no way to take the second derivative of sparse_softmax_cross_entropy_with_logits due to the fused implementation's interaction with tf.gradients()
```"
14189,Cannot deepcopy index_table_from_file object,"Tensorflow 1.4.0
Windows 10

Code:
```python
import copy
vt = tf.contrib.lookup.index_table_from_file('test.vocab', 0)
copy.deepcopy(vt)
```

Error
```
.....
File ""C:\Development\Tools\miniconda\envs\py36\lib\copy.py"", line 240, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File ""C:\Development\Tools\miniconda\envs\py36\lib\copy.py"", line 169, in deepcopy
    rv = reductor(4)
TypeError: can't pickle _thread.lock objects
```

Is it intended that this object cannot be deepcopied?"
14188,Retval[0] does not have value in a multithreaded context with FIFOQueue and  tf.scan(...),"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: I provide a working script showing the buggy behaviour
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: none
- **GPU model and memory**: GeForce GTX 280M 1GB

Note: I reproduced the buggy behaviour on different platforms too: macOS High Sierra, openSUSE 42.3 and with Tensorflow 1.3

###  problem context
I found the buggy behaviour in one of the helper methods the queue loader of the DeepSpeech project (ctc_label_dense_to_sparse). That implementation is partially clumsy in particular when using tf.scan where a scan history context is not used. Nevertheless the algorithm should have worked under any circumstances. I could reduce the problem scenario to a small standalone example. This example uses a number of threads for filling a queue from which batches are requested by dequeu_up_to (the same buggy behaviour if replaced by dequeue_many). Afterwards the batch is postproccessed. For this postprocessing I provided the buggy version (function_buggy, using tf.scan) and an own implementation (function_ok). Both versions produce the same output data in cases there the buggy versions does not fail. 

### buggy behaviour description
Very often, but not always a test with a larger batch_size and smaller thread_count leads to the following output: tensorflow.python.framework.errors_impl.InvalidArgumentError: Retval[0] does not have value. I include the complete log in the next section. With a larger thread_count and smaller batch_size it works. If the switch-Parameter --use_buggy_version is set to 0 (False) no choice of batch_size and thread_count produces a bug. This proves that the problem is located in the buggy function and the rest of the workflow is OK. I could prove that an implementation without the tf.scan works fine too. In experiments using the context in tf.scan instead of ignoring it didn't change the behaviour. Even as tf.scan doesn't make much sense in the context it was used for in DeepSpeech it  should not have failed and its correct function is essential for many tensorflow based projects. And maybe a similar flaw is hidden in the other ""Higher Order operators"" too: tf.map_fn, tf.foldl, tf.foldr

### log

usage: scan_bug_demo.py [-h] [--batch_size BATCH_SIZE]
                        [--thread_count THREAD_COUNT]
                        [--use_buggy_version USE_BUGGY_VERSION]
batch_size=15
thread_count=1
use_buggy_version=True
using buggy implementation: True
Traceback (most recent call last):
  File ""scan_bug_demo.py"", line 127, in <module>
    retval = do_it(batch_size, thread_count, use_buggy_version, rnd_seed)
  File ""scan_bug_demo.py"", line 99, in do_it
    coord.join(queue_threads)
  File ""/home/uli/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/training/coordinator.py"", line 389, in join
    six.reraise(*self._exc_info_to_raise)
  File ""scan_bug_demo.py"", line 92, in do_it
    res = sess.run(batch)
  File ""/home/uli/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 889, in run
    run_metadata_ptr)
  File ""/home/uli/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1120, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/uli/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1317, in _do_run
    options, run_metadata)
  File ""/home/uli/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1336, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Retval[0] does not have value

### bug demonstration python source

import tensorflow as tf
from random import Random
from threading import Thread
import numpy as np
import sys
from argparse import ArgumentParser


def function_buggy(value_sequence_lengths):
    max_len = tf.reduce_max(value_sequence_lengths)

    max_value_seuence_lenght_tns = tf.expand_dims(max_len, 0)
    init = tf.expand_dims(tf.cast(tf.fill(max_value_seuence_lenght_tns, 0), tf.bool), 0)

    def scan_function(previous_state, current_input):
        return tf.expand_dims(tf.range(max_len), 0) < current_input

    retval = tf.squeeze(tf.scan(scan_function, value_sequence_lengths, initializer=init, parallel_iterations=1),
                        axis=[1])

    return retval


def function_ok(value_sequence_lengths):
    max_len = tf.reduce_max(value_sequence_lengths)
    value_sequence_lengths_shape = tf.shape(value_sequence_lengths)

    x_repeated_lenghts = tf.tile(tf.expand_dims(value_sequence_lengths, 1), (1, max_len))
    y_repeated_x_indices = tf.tile(tf.expand_dims(tf.range(max_len), 0), (value_sequence_lengths_shape[0], 1))

    retval = y_repeated_x_indices < x_repeated_lenghts

    return retval


class BatchProvider(object):
    def __init__(self, batch_size, function, thread_count, rnd_seed):
        self._coord = None
        self.batch_size = batch_size
        self._random = Random(rnd_seed)
        self._capacity = 2 * batch_size
        self._thread_count = thread_count
        self._queue = tf.FIFOQueue(shapes=[[]], dtypes=[tf.int32], capacity=self._capacity)
        self._y_length = tf.placeholder(tf.int32, [])
        self._enqueue_op = self._queue.enqueue(self._y_length)
        self._close_op = self._queue.close(cancel_pending_enqueues=True)
        self._function = function

    def start_queue_threads(self, session, coord):
        self._coord = coord
        batch_threads = [Thread(target=self._populate_batch_queue, args=(session,)) for i in range(self._thread_count)]
        for batch_thread in batch_threads:
            self._coord.register_thread(batch_thread)
            batch_thread.daemon = True
            batch_thread.start()
        return batch_threads

    def close_queue(self, session):
        session.run(self._close_op)

    def _populate_batch_queue(self, session):
        while True:
            length = self._random.randint(5, 10)
            target_len = length
            try:
                self._enqueue_op.run(session=session, feed_dict={self._y_length: target_len})
            except tf.errors.CancelledError:
                return

    def next_batch(self):
        target_lengths = self._queue.dequeue_up_to(self.batch_size)
        retval = self._function(target_lengths)
        return retval


def do_it(batch_size, thread_count, use_buggy_version, rnd_seed):
    function = function_buggy if use_buggy_version else function_ok

    batch_provider = BatchProvider(batch_size=batch_size, function=function,
                                   thread_count=thread_count, rnd_seed=rnd_seed)

    sess = tf.Session()

    coord = tf.train.Coordinator()
    queue_threads = batch_provider.start_queue_threads(sess, coord)
    batch = batch_provider.next_batch()

    try:
        for _ in range(1):
            if coord.should_stop():
                break
            res = sess.run(batch)
            print batch
            print res
    except Exception, ex:
        coord.request_stop(ex)
    finally:
        batch_provider.close_queue(sess)
        coord.join(queue_threads)
        sess.close()

    return res


if __name__ == '__main__':
    args = sys.argv[1:]
    argparser = ArgumentParser()
    argparser.add_argument(""--batch_size"", dest=""batch_size"", type=int, default=15)
    argparser.add_argument(""--thread_count"", dest=""thread_count"", type=int, default=1)
    argparser.add_argument(""--use_buggy_version"", dest=""use_buggy_version"", type=int, default=True)
    if len(args) == 0:
        argparser.print_usage()
    parsed = argparser.parse_args(args=args)
    batch_size = parsed.batch_size
    thread_count = parsed.thread_count
    use_buggy_version = parsed.use_buggy_version

    print ""batch_size="" + str(batch_size)
    print ""thread_count="" + str(thread_count)
    print ""use_buggy_version="" + str(use_buggy_version)

    rnd_seed = Random().random()

    print ""using buggy implementation: "" + str(use_buggy_version)
    retval = do_it(batch_size, thread_count, use_buggy_version, rnd_seed)
    print ""success""
"
14186,TF 1.4 build_all_android.sh fails with nsync.a,"Running

    NDK_ROOT=""$HOME/Library/Android/sdk/ndk-bundle"" bash $MAKEFILE_DIR/build_all_android.sh

results in this error

```
/Users/era/Library/Android/sdk/ndk-bundle/toolchains/arm-linux-androideabi-4.9/prebuilt/darwin-x86_64/bin/../lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: error: tensorflow/contrib/makefile/downloads/nsync/builds/armeabi-v7a.android.c++11/nsync.a: malformed archive header name at 8
/Users/era/Library/Android/sdk/ndk-bundle/toolchains/arm-linux-androideabi-4.9/prebuilt/darwin-x86_64/bin/../lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: error: tensorflow/contrib/makefile/downloads/nsync/builds/armeabi-v7a.android.c++11/nsync.a: malformed archive header name at 8
/Users/era/Library/Android/sdk/ndk-bundle/toolchains/arm-linux-androideabi-4.9/prebuilt/darwin-x86_64/bin/../lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: fatal error: tensorflow/contrib/makefile/downloads/nsync/builds/armeabi-v7a.android.c++11/nsync.a: attempt to map 60 bytes at offset 67800 exceeds size of file; the file may be corrupt
collect2: error: ld returned 1 exit status
make: *** [.../tensorflow/tensorflow/contrib/makefile/gen/bin/benchmark] Error 1
```

NDK version 15c, Android Studio 3.0, macOS High Sierra 10.13.1"
14185,memory leak with tf.image.encode_jpeg,"I encountered an issue with tf.image.encode_jpeg. I got a lot of images to preprocess. The code that caused the problem is like this:

for imagefile in image_list:
  im = cv2.imread(imagefile)
  image_data = tf.image.encode_jpeg(im, format='rgb')

The memory usage kept increasing as image.encode_jpeg was called. Eventually the 256G mem server ran out of memory."
14184,memory leak with tf.image.encode_jpeg,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
14182,Creating a specific 3.6 binary for Linux,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 14.04
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: 
- **Python version**: Python3.6
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**: -NA-
- **CUDA/cuDNN version**: -NA-
- **GPU model and memory**: -NA-
- **Exact command to reproduce**: import tensorflow as tf

**Environment capture text:**

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh
[tf_env.txt](https://github.com/tensorflow/tensorflow/files/1437609/tf_env.txt)

You can obtain the TensorFlow version with
python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""
This command also results in the same error.
/home/raju/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6
  return f(*args, **kwds)

### Describe the problem
When importing tensorflow , I get this error. I found some information on ""Feature request: nightly build for python 3.6 #12935"" --""Yes, we unfortunately copy the 3.5 binary for 3.6 I'll look into creating a specific 3.6 binary for Linux.""

### Source code / logs
$import tensorflow as tf
**result is** 
/home/raju/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6
  return f(*args, **kwds)

"
14181,Tensorflow or python having memory cleanup issues when using multiple models in iterative loop,"### System information
- **Have I written custom code**: yes
- **OS Platform and Distribution**: Linux Ubuntu 17.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version**: v1.3.0-rc2-20-g0787eee 1.3.0
- **Python version**: Python 3.6.1 :: Anaconda 4.4.0 (64-bit)
- **CUDA/cuDNN version**: none
- **GPU model and memory**: none

== cat /etc/issue ===============================================
Linux Bragi 4.10.0-37-generic #41-Ubuntu SMP Fri Oct 6 20:20:37 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""17.04 (Zesty Zapus)""
VERSION_ID=""17.04""
VERSION_CODENAME=zesty

== are we in docker =============================================
No

== compiler =====================================================
c++ (Ubuntu 6.3.0-12ubuntu2) 6.3.0 20170406
Copyright (C) 2016 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux Bragi 4.10.0-37-generic #41-Ubuntu SMP Fri Oct 6 20:20:37 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy (1.12.1)
numpydoc (0.6.0)
protobuf (3.4.0)
tensorflow (1.3.0)
tensorflow-tensorboard (0.1.8)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.3.0
tf.GIT_VERSION = v1.3.0-rc2-20-g0787eee
tf.COMPILER_VERSION = v1.3.0-rc2-20-g0787eee
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
./tf_env_collect.sh: line 105: nvidia-smi: command not found


### Describe the problem
I am working on a tensorflow model which takes pretty much RAM. It is executed iteratively to process given tasks.

However, with increasing time the whole process starts consuming more and more RAM although it should clean it up. This sounds like as if I'd keep data of one graph over the iterations, but I am almost sure that the graphs are cleanly separated.

Problem
-------
I reduced the code to the following:

    import tensorflow as tf
    import numpy as np

    reps = 30
    for i in range(reps):
        with tf.Graph().as_default() as graph:
            with tf.Session(graph=graph) as sess:
                tf.constant(np.random.random((1000,1000,200,1)))

I have 32GB RAM available, working on a ubuntu 17.04 with CPU Tensorflow 1.3. This will give following error message after about the 25th or 27th iteration:

> terminate called after throwing an instance of 'std::bad_alloc'
  what():  std::bad_alloc

Giving the process some time after each iteration results in no improvement:

    import tensorflow as tf
    import numpy as np
    import time

    reps = 30
    for i in range(reps):
        with tf.Graph().as_default() as graph:
            with tf.Session(graph=graph) as sess:
                tf.constant(np.random.random((1000,1000,200,1)))
        time.sleep(1)

However, it works if I force garbage collection invocation after each repetition:

    import tensorflow as tf
    import numpy as np
    import gc

    reps = 30
    for i in range(reps):
        with tf.Graph().as_default() as graph:
            with tf.Session(graph=graph) as sess:
                tf.constant(np.random.random((1000,1000,200,1)))
        gc.collect()

Question
--------
Now I wonder why I need to force garbage collection to run even though tensorflow should have closed the session and de-referenced the graph object.

Back to my original model I am not sure, yet, if the gc invocation actually helps. The memory usage grows pretty intense, especially when I am about to persist the model to disk.

Thanks for any insights.
"
14180,error during install.,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: windows10
- **TensorFlow installed from (source or binary)**: anaconda 5.0.0
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
i'm trying to install tensorflow through anaconda 5.0.0
and i got this lines and i can't finish my install. plz help me

### Source code / logs
Exception:
Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\pip\basecommand.py"", line 215, in main
    status = self.run(options, args)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\pip\commands\install.py"", line 342, in run
    prefix=options.prefix_path,
  File ""C:\ProgramData\Anaconda3\lib\site-packages\pip\req\req_set.py"", line 784, in install
    **kwargs
  File ""C:\ProgramData\Anaconda3\lib\site-packages\pip\req\req_install.py"", line 851, in install
    self.move_wheel_files(self.source_dir, root=root, prefix=prefix)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\pip\req\req_install.py"", line 1064, in move_wheel_files
    isolated=self.isolated,
  File ""C:\ProgramData\Anaconda3\lib\site-packages\pip\wheel.py"", line 345, in move_wheel_files
    clobber(source, lib_dir, True)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\pip\wheel.py"", line 323, in clobber
    shutil.copyfile(srcfile, destfile)
  File ""C:\ProgramData\Anaconda3\lib\shutil.py"", line 121, in copyfile
    with open(dst, 'wb') as fdst:
PermissionError: [Errno 13] Permission denied: 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\wheel\\archive.py'
"
14179,tensorflow model convert to other dl tools?,are there some tools that can convert tensorflow model to caffe、mxnet or other dl tools?
14178,what is this error stands for.?,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
14177,Getting wrong value with placeholder,"### System information


- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No, I have used code which is on the [link](https://www.tensorflow.org/get_started/get_started). 
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04 LTS
- **TensorFlow installed from (source or binary)**:
Installing with native pip (tensorflow-gpu)
- **TensorFlow version (use command below)**:
'1.3.0'
- **Python version**: 
 Python 2.7.12
('v1.3.0-rc2-20-g0787eee', '1.3.0')
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
gcc (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609
- **CUDA/cuDNN version**:
CUDA : release 8.0, V8.0.61
cuDNN: CUDNN_MAJOR      6
- **GPU model and memory**:
GeForce 940MX 
Memory: 2GB
Driver Version: 384.90



### Describe the problem
When I run at below code, I think i am getting the wrong result.

### Source code / logs
```
import tensorflow as tf
sess = tf.Session()
a = tf.placeholder(tf.float32)
b = tf.placeholder(tf.float32)
adder_node = a + b
print(sess.run(adder_node, {a: 3, b: 4.5}))
print(sess.run(adder_node, {a: [1, 3], b: [2, 4]}))
```

> **My Output :**
>  **3.0**
> **[ 1. 3.]**

> **I think the true result should be;**
> **7.5**
> **[ 3. 7.]**
> 

### Logs
Also, when i type `sess = tf.Session()` , i am getting that output
> 2017-11-02 12:09:04.184601: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
> 2017-11-02 12:09:04.184689: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
> 2017-11-02 12:09:04.184717: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
> 2017-11-02 12:09:04.184753: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
> 2017-11-02 12:09:04.184805: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
> 2017-11-02 12:09:04.368504: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
> 2017-11-02 12:09:04.368855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: 
> name: GeForce 940MX
> major: 5 minor: 0 memoryClockRate (GHz) 1.2415
> pciBusID 0000:01:00.0
> Total memory: 1.96GiB
> Free memory: 1.53GiB
> 2017-11-02 12:09:04.368870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 
> 2017-11-02 12:09:04.368874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y 
> 2017-11-02 12:09:04.368882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce 940MX, pci bus id: 0000:01:00.0)
"
14174,macOS build failed,"macOS 10.13
CUDA9.0 CUDNN7.0
bazel 0.7.0


```
tensorflow/core/kernels/split_lib_gpu.cu.cc(122): error: specified alignment (4) is different from alignment (2) specified on a previous declaration
          detected during:
            instantiation of ""void tensorflow::split_v_kernel<T,IntType,useSmem>(const T *, tensorflow::CudaDeviceArrayStruct<IntType, 8>, IntType, IntType, tensorflow::CudaDeviceArrayStruct<T *, 8>) [with T=float, IntType=tensorflow::int32, useSmem=true]"" 
(231): here
            instantiation of ""void tensorflow::SplitVOpGPULaunch<T, IntType>::Run(const Eigen::GpuDevice &, __nv_bool, const T *, int, int, const tensorflow::CudaDeviceArrayStruct<IntType, 8> &, const tensorflow::CudaDeviceArrayStruct<T *, 8> &) [with T=float, IntType=tensorflow::int32]"" 
(251): here

tensorflow/core/kernels/split_lib_gpu.cu.cc(122): error: specified alignment (4) is different from alignment (2) specified on a previous declaration
          detected during:
            instantiation of ""void tensorflow::split_v_kernel<T,IntType,useSmem>(const T *, tensorflow::CudaDeviceArrayStruct<IntType, 8>, IntType, IntType, tensorflow::CudaDeviceArrayStruct<T *, 8>) [with T=float, IntType=tensorflow::int32, useSmem=false]"" 
(236): here
            instantiation of ""void tensorflow::SplitVOpGPULaunch<T, IntType>::Run(const Eigen::GpuDevice &, __nv_bool, const T *, int, int, const tensorflow::CudaDeviceArrayStruct<IntType, 8> &, const tensorflow::CudaDeviceArrayStruct<T *, 8> &) [with T=float, IntType=tensorflow::int32]"" 
(251): here

tensorflow/core/kernels/split_lib_gpu.cu.cc(122): error: specified alignment (4) is different from alignment (2) specified on a previous declaration
          detected during:
            instantiation of ""void tensorflow::split_v_kernel<T,IntType,useSmem>(const T *, tensorflow::CudaDeviceArrayStruct<IntType, 8>, IntType, IntType, tensorflow::CudaDeviceArrayStruct<T *, 8>) [with T=float, IntType=tensorflow::int64, useSmem=true]"" 
(231): here
            instantiation of ""void tensorflow::SplitVOpGPULaunch<T, IntType>::Run(const Eigen::GpuDevice &, __nv_bool, const T *, int, int, const tensorflow::CudaDeviceArrayStruct<IntType, 8> &, const tensorflow::CudaDeviceArrayStruct<T *, 8> &) [with T=float, IntType=tensorflow::int64]"" 
(251): here

tensorflow/core/kernels/split_lib_gpu.cu.cc(122): error: specified alignment (4) is different from alignment (2) specified on a previous declaration
          detected during:
            instantiation of ""void tensorflow::split_v_kernel<T,IntType,useSmem>(const T *, tensorflow::CudaDeviceArrayStruct<IntType, 8>, IntType, IntType, tensorflow::CudaDeviceArrayStruct<T *, 8>) [with T=float, IntType=tensorflow::int64, useSmem=false]"" 
(236): here
            instantiation of ""void tensorflow::SplitVOpGPULaunch<T, IntType>::Run(const Eigen::GpuDevice &, __nv_bool, const T *, int, int, const tensorflow::CudaDeviceArrayStruct<IntType, 8> &, const tensorflow::CudaDeviceArrayStruct<T *, 8> &) [with T=float, IntType=tensorflow::int64]"" 
(251): here

tensorflow/core/kernels/split_lib_gpu.cu.cc(122): error: specified alignment (8) is different from alignment (2) specified on a previous declaration
          detected during:
            instantiation of ""void tensorflow::split_v_kernel<T,IntType,useSmem>(const T *, tensorflow::CudaDeviceArrayStruct<IntType, 8>, IntType, IntType, tensorflow::CudaDeviceArrayStruct<T *, 8>) [with T=double, IntType=tensorflow::int32, useSmem=true]"" 
(231): here
            instantiation of ""void tensorflow::SplitVOpGPULaunch<T, IntType>::Run(const Eigen::GpuDevice &, __nv_bool, const T *, int, int, const tensorflow::CudaDeviceArrayStruct<IntType, 8> &, const tensorflow::CudaDeviceArrayStruct<T *, 8> &) [with T=double, IntType=tensorflow::int32]"" 
(251): here

tensorflow/core/kernels/split_lib_gpu.cu.cc(122): error: specified alignment (8) is different from alignment (2) specified on a previous declaration
          detected during:
            instantiation of ""void tensorflow::split_v_kernel<T,IntType,useSmem>(const T *, tensorflow::CudaDeviceArrayStruct<IntType, 8>, IntType, IntType, tensorflow::CudaDeviceArrayStruct<T *, 8>) [with T=double, IntType=tensorflow::int32, useSmem=false]"" 
(236): here
            instantiation of ""void tensorflow::SplitVOpGPULaunch<T, IntType>::Run(const Eigen::GpuDevice &, __nv_bool, const T *, int, int, const tensorflow::CudaDeviceArrayStruct<IntType, 8> &, const tensorflow::CudaDeviceArrayStruct<T *, 8> &) [with T=double, IntType=tensorflow::int32]"" 
(251): here

tensorflow/core/kernels/split_lib_gpu.cu.cc(122): error: specified alignment (8) is different from alignment (2) specified on a previous declaration
          detected during:
            instantiation of ""void tensorflow::split_v_kernel<T,IntType,useSmem>(const T *, tensorflow::CudaDeviceArrayStruct<IntType, 8>, IntType, IntType, tensorflow::CudaDeviceArrayStruct<T *, 8>) [with T=double, IntType=tensorflow::int64, useSmem=true]"" 
(231): here
            instantiation of ""void tensorflow::SplitVOpGPULaunch<T, IntType>::Run(const Eigen::GpuDevice &, __nv_bool, const T *, int, int, const tensorflow::CudaDeviceArrayStruct<IntType, 8> &, const tensorflow::CudaDeviceArrayStruct<T *, 8> &) [with T=double, IntType=tensorflow::int64]"" 
(251): here

tensorflow/core/kernels/split_lib_gpu.cu.cc(122): error: specified alignment (8) is different from alignment (2) specified on a previous declaration
          detected during:
            instantiation of ""void tensorflow::split_v_kernel<T,IntType,useSmem>(const T *, tensorflow::CudaDeviceArrayStruct<IntType, 8>, IntType, IntType, tensorflow::CudaDeviceArrayStruct<T *, 8>) [with T=double, IntType=tensorflow::int64, useSmem=false]"" 
(236): here
            instantiation of ""void tensorflow::SplitVOpGPULaunch<T, IntType>::Run(const Eigen::GpuDevice &, __nv_bool, const T *, int, int, const tensorflow::CudaDeviceArrayStruct<IntType, 8> &, const tensorflow::CudaDeviceArrayStruct<T *, 8> &) [with T=double, IntType=tensorflow::int64]"" 
(251): here

tensorflow/core/kernels/split_lib_gpu.cu.cc(122): error: specified alignment (8) is different from alignment (2) specified on a previous declaration
          detected during:
            instantiation of ""void tensorflow::split_v_kernel<T,IntType,useSmem>(const T *, tensorflow::CudaDeviceArrayStruct<IntType, 8>, IntType, IntType, tensorflow::CudaDeviceArrayStruct<T *, 8>) [with T=tensorflow::complex64, IntType=tensorflow::int32, useSmem=true]"" 
(231): here
            instantiation of ""void tensorflow::SplitVOpGPULaunch<T, IntType>::Run(const Eigen::GpuDevice &, __nv_bool, const T *, int, int, const tensorflow::CudaDeviceArrayStruct<IntType, 8> &, const tensorflow::CudaDeviceArrayStruct<T *, 8> &) [with T=tensorflow::complex64, IntType=tensorflow::int32]"" 
(252): here

tensorflow/core/kernels/split_lib_gpu.cu.cc(122): error: specified alignment (8) is different from alignment (2) specified on a previous declaration
          detected during:
            instantiation of ""void tensorflow::split_v_kernel<T,IntType,useSmem>(const T *, tensorflow::CudaDeviceArrayStruct<IntType, 8>, IntType, IntType, tensorflow::CudaDeviceArrayStruct<T *, 8>) [with T=tensorflow::complex64, IntType=tensorflow::int32, useSmem=false]"" 
(236): here
            instantiation of ""void tensorflow::SplitVOpGPULaunch<T, IntType>::Run(const Eigen::GpuDevice &, __nv_bool, const T *, int, int, const tensorflow::CudaDeviceArrayStruct<IntType, 8> &, const tensorflow::CudaDeviceArrayStruct<T *, 8> &) [with T=tensorflow::complex64, IntType=tensorflow::int32]"" 
(252): here

tensorflow/core/kernels/split_lib_gpu.cu.cc(122): error: specified alignment (8) is different from alignment (2) specified on a previous declaration
          detected during:
            instantiation of ""void tensorflow::split_v_kernel<T,IntType,useSmem>(const T *, tensorflow::CudaDeviceArrayStruct<IntType, 8>, IntType, IntType, tensorflow::CudaDeviceArrayStruct<T *, 8>) [with T=tensorflow::complex64, IntType=tensorflow::int64, useSmem=true]"" 
(231): here
            instantiation of ""void tensorflow::SplitVOpGPULaunch<T, IntType>::Run(const Eigen::GpuDevice &, __nv_bool, const T *, int, int, const tensorflow::CudaDeviceArrayStruct<IntType, 8> &, const tensorflow::CudaDeviceArrayStruct<T *, 8> &) [with T=tensorflow::complex64, IntType=tensorflow::int64]"" 
(252): here

tensorflow/core/kernels/split_lib_gpu.cu.cc(122): error: specified alignment (8) is different from alignment (2) specified on a previous declaration
          detected during:
            instantiation of ""void tensorflow::split_v_kernel<T,IntType,useSmem>(const T *, tensorflow::CudaDeviceArrayStruct<IntType, 8>, IntType, IntType, tensorflow::CudaDeviceArrayStruct<T *, 8>) [with T=tensorflow::complex64, IntType=tensorflow::int64, useSmem=false]"" 
(236): here
            instantiation of ""void tensorflow::SplitVOpGPULaunch<T, IntType>::Run(const Eigen::GpuDevice &, __nv_bool, const T *, int, int, const tensorflow::CudaDeviceArrayStruct<IntType, 8> &, const tensorflow::CudaDeviceArrayStruct<T *, 8> &) [with T=tensorflow::complex64, IntType=tensorflow::int64]"" 
(252): here

tensorflow/core/kernels/split_lib_gpu.cu.cc(122): error: specified alignment (16) is different from alignment (2) specified on a previous declaration
          detected during:
            instantiation of ""void tensorflow::split_v_kernel<T,IntType,useSmem>(const T *, tensorflow::CudaDeviceArrayStruct<IntType, 8>, IntType, IntType, tensorflow::CudaDeviceArrayStruct<T *, 8>) [with T=tensorflow::complex128, IntType=tensorflow::int32, useSmem=true]"" 
(231): here
            instantiation of ""void tensorflow::SplitVOpGPULaunch<T, IntType>::Run(const Eigen::GpuDevice &, __nv_bool, const T *, int, int, const tensorflow::CudaDeviceArrayStruct<IntType, 8> &, const tensorflow::CudaDeviceArrayStruct<T *, 8> &) [with T=tensorflow::complex128, IntType=tensorflow::int32]"" 
(253): here

tensorflow/core/kernels/split_lib_gpu.cu.cc(122): error: specified alignment (16) is different from alignment (2) specified on a previous declaration
          detected during:
            instantiation of ""void tensorflow::split_v_kernel<T,IntType,useSmem>(const T *, tensorflow::CudaDeviceArrayStruct<IntType, 8>, IntType, IntType, tensorflow::CudaDeviceArrayStruct<T *, 8>) [with T=tensorflow::complex128, IntType=tensorflow::int32, useSmem=false]"" 
(236): here
            instantiation of ""void tensorflow::SplitVOpGPULaunch<T, IntType>::Run(const Eigen::GpuDevice &, __nv_bool, const T *, int, int, const tensorflow::CudaDeviceArrayStruct<IntType, 8> &, const tensorflow::CudaDeviceArrayStruct<T *, 8> &) [with T=tensorflow::complex128, IntType=tensorflow::int32]"" 
(253): here

tensorflow/core/kernels/split_lib_gpu.cu.cc(122): error: specified alignment (16) is different from alignment (2) specified on a previous declaration
          detected during:
            instantiation of ""void tensorflow::split_v_kernel<T,IntType,useSmem>(const T *, tensorflow::CudaDeviceArrayStruct<IntType, 8>, IntType, IntType, tensorflow::CudaDeviceArrayStruct<T *, 8>) [with T=tensorflow::complex128, IntType=tensorflow::int64, useSmem=true]"" 
(231): here
            instantiation of ""void tensorflow::SplitVOpGPULaunch<T, IntType>::Run(const Eigen::GpuDevice &, __nv_bool, const T *, int, int, const tensorflow::CudaDeviceArrayStruct<IntType, 8> &, const tensorflow::CudaDeviceArrayStruct<T *, 8> &) [with T=tensorflow::complex128, IntType=tensorflow::int64]"" 
(253): here

tensorflow/core/kernels/split_lib_gpu.cu.cc(122): error: specified alignment (16) is different from alignment (2) specified on a previous declaration
          detected during:
            instantiation of ""void tensorflow::split_v_kernel<T,IntType,useSmem>(const T *, tensorflow::CudaDeviceArrayStruct<IntType, 8>, IntType, IntType, tensorflow::CudaDeviceArrayStruct<T *, 8>) [with T=tensorflow::complex128, IntType=tensorflow::int64, useSmem=false]"" 
(236): here
            instantiation of ""void tensorflow::SplitVOpGPULaunch<T, IntType>::Run(const Eigen::GpuDevice &, __nv_bool, const T *, int, int, const tensorflow::CudaDeviceArrayStruct<IntType, 8> &, const tensorflow::CudaDeviceArrayStruct<T *, 8> &) [with T=tensorflow::complex128, IntType=tensorflow::int64]"" 
(253): here

16 errors detected in the compilation of ""/var/folders/2f/891g9y691gzcy23blt644z6m0000gn/T//tmpxft_00002e92_00000000-6_split_lib_gpu.cu.cpp1.ii"".
ERROR: /Users/odin/local/tensorflow/tensorflow/core/kernels/BUILD:387:1: output 'tensorflow/core/kernels/_objs/split_lib_gpu/tensorflow/core/kernels/split_lib_gpu.cu.pic.o' was not created.
ERROR: /Users/odin/local/tensorflow/tensorflow/core/kernels/BUILD:387:1: not all outputs were created or valid.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
```"
14173,using batchnorm in conv2d discard the bias,"Hi!
I observed that whenever I applied batch normalization to conv2d, the bias variable are not created!
version : Tensorflow 1.3

```
import tensorflow

image = tf.placeholder(tf.float32, [None, 14, 14, 1024])

tf.contrib.layers.conv2d(image,
                                 num_outputs=128,
                                 kernel_size=[3,3],
                                 normalizer_fn=tf.layers.batch_normalization,
                                 normalizer_params={""training"": False, ""reuse"": False},
                                 activation_fn=tf.nn.relu,
                                 reuse=False,
                                 scope=""conv1"")
                                 
tf.contrib.layers.conv2d(image,
                                 num_outputs=128,
                                 kernel_size=[3,3],
                                 #normalizer_fn=tf.layers.batch_normalization,
                                 #normalizer_params={""training"": False, ""reuse"": False},
                                 #activation_fn=tf.nn.relu,
                                 reuse=False,
                                 scope=""conv2"")
                                 
for v in tf.trainable_variables():
	print(v)
```
output:

<tf.Variable 'conv1/weights:0' shape=(3, 3, 1024, 128) dtype=float32_ref>
<tf.Variable 'conv1/batch_normalization/beta:0' shape=(128,) dtype=float32_ref>
<tf.Variable 'conv1/batch_normalization/gamma:0' shape=(128,) dtype=float32_ref>
<tf.Variable 'conv2/weights:0' shape=(3, 3, 1024, 128) dtype=float32_ref>
**<tf.Variable 'conv2/biases:0' shape=(128,) dtype=float32_ref>**

no bias for conv1 !

Question: Is it a bug or a feature :)

[edit] I also observed the same behavior with mlp.

Thank you very much!

Florian

"
14171,Memory leak in conv2d(),"### System information

Python: 3.5.2
TensorFlow version 1.3.0 via pip, 1.3.1 via source, 1.4.0-rc1 from source (confirmed the problem on all three of them)
Bazel: 0.7.0
Ubuntu 16.04
GPU: GeForce GTX 1080 with 8GB
Nvidia drivers: 384.90
CUDA: 8.0
CuDNN: 6.0
Optimizer: Adam with default parameters

### Problem Description

I will post here some evidence that makes me think that there's a major leak in `conv_2d()`.
Unfortunately I can't provide code and data replicate this as my employer doesn't allow me to as both are confidential, but hopefully the information i will provide will make it possible for you to replicate it.

The setting:
I'm training a word cnn on text data on GPU. The length of the sequence of text is 256, the dimension of the embeddings is 256, I have 4 convolutional layers in parallel with different sizes (2, 3, 4 and 5 x 256). The inputs to the conv layers are `batch_size x 256 x 256 x 1`.
In my code I run a full epoch of training, then I evaluate on the training set, the validation set and the test set, then I start a new epoch.

The problem:
Depending on the batch_size the memory needed by TensorFlow to compute his operations changes, but it is in the order of few hundreds MB. At the last batch of training, the memory consumption increases dramatically, as happens at the last batch of evaluation on validation set and the last batch of evaluation on the test set.
As _traini_set_size mod batch_size is not 0 (the same happens for validation and test set too), the last batch has a different dimension with respect to all others batches. For instance in my case with a batch_size of 100, the last batch of the validation set is of size 25.
What happens is that, in the `conv2d()` function TF allocates a lot of memory if the batch size is not the same that was used so far. In my case, that operation goes from needing 50 MB to 3.18 GB. As it seems too much, I suspect there's a memory leak somehow.

I'm attaching 2 screenshots taken from TensorBoard. What they show is the same node in the second last batch of the validation set and the last batch of the validation set. The memory consumption is in the node state on the right of the image. I can share the log directory if needed as it contains the graph of the model and the memory information at all steps of training and evaluation.

![eval_vali_step_8](https://user-images.githubusercontent.com/349256/32309260-99a53ab4-bf47-11e7-96d0-a429180f0e1c.png)
![eval_vali_step_9](https://user-images.githubusercontent.com/349256/32309259-99895934-bf47-11e7-8b3f-08306321cb8e.png)

The weird thing is that when batch_size is 256 or 512 it doesn't happen, but with batch_size 100 or 128 or 200 (the other 3 I tested) it happens. testing on another bigger dataset, even with 256 as the batch size the supposed memory leak happens, but in that case TF tries to allocate around 33 GB of ram and goes out of memory. My temporary workaround is just throwing away the last batch of the train, validation and test set. Doing so the memory consumption keeps constant.

Hopefully this is enough information for investigate the problem, otherwise feel free to request me additional information, even if, as I said, unfortunately I can't provide code and data.

"
14170,"List of functions could be improved with ""const std::string&"" or ""std::string&"" instead ""std::string""","After a quick scan in the latest tensorflow ""master"" branch, here is the list of functions which could improve passing parameter by ""std::string"":

After a quick scan in the latest tensorflow ""master"" branch, here is the list of functions which could improve passing parameter by ""std::string"":

1. c/c_api_function.cc:  static string Normalize(string name);
   Suggestion: string& name;
2. c/c_api_function.cc:string NodeNameMapping::Normalize(string name) {
   Suggestion: string& name
#
3. compiler/jit/graph_to_functiondef.cc:  string NormalizeHelper(string name) const;
   Suggestion: string& name
4. compiler/jit/graph_to_functiondef.cc:  string UniquifyHelper(string name);
   Suggestion: const string&
5. compiler/jit/graph_to_functiondef.cc:string NodeNameMapping::NormalizeHelper(string name) const {
   Suggestion: string& name
6. compiler/jit/graph_to_functiondef.cc:string NodeNameMapping::UniquifyHelper(string name) {
   Suggestion: const string&
7. compiler/tf2xla/dump_graph.cc:string MakeUniquePath(string name) {
   Suggestion: string& name
8. compiler/xla/service/llvm_ir/llvm_util.cc:string IrName(string a) {
    Suggestion: string& a
9. compiler/xla/service/llvm_ir/llvm_util.cc:string SanitizeFunctionName(string function_name) {
    Suggestion: string& function_name
10. compiler/xla/service/llvm_ir/llvm_util.h:string IrName(string a);
    Suggestion: string& a
11. compiler/xla/service/llvm_ir/llvm_util.h:string SanitizeFunctionName(string function_name);
    Suggestion: string& function_name
12. compiler/xla/util.cc:string SanitizeFileName(string file_name) {
    Suggestion: string& file_name
13. compiler/xla/util.h:string SanitizeFileName(string file_name);
    Suggestion: string& file_name
#
14. contrib/verbs/rdma.cc:RdmaBuffer::RdmaBuffer(RdmaChannel* channel, string name)
    Suggestion: const string& name
15. contrib/verbs/rdma.cc:RdmaAckBuffer::RdmaAckBuffer(RdmaChannel* channel, string name)
    Suggestion: const string& name
16. contrib/verbs/rdma.cc:RdmaMessageBuffer::RdmaMessageBuffer(RdmaChannel* channel, string name)
    Suggestion: const string& name
17. contrib/verbs/rdma.cc:RdmaTensorBuffer::RdmaTensorBuffer(RdmaChannel* channel, string name)
    Suggestion: const string& name
18. contrib/verbs/rdma.h:  explicit RdmaBuffer(RdmaChannel* channel, string name);
    Suggestion: const string& name
19. contrib/verbs/rdma.h:  explicit RdmaAckBuffer(RdmaChannel* channel, string name);
    Suggestion: const string& name
20. contrib/verbs/rdma.h:  explicit RdmaMessageBuffer(RdmaChannel* channel, string name);
    Suggestion: const string& name
21. contrib/verbs/rdma.h:  explicit RdmaTensorBuffer(RdmaChannel* channel, string name);
    Suggestion: const string& name
#
22. core/common_runtime/step_stats_collector.cc:static int ExtractGpuWithStreamAll(string device_name) {
    Suggestion: string& device_name
23. core/common_runtime/step_stats_collector.cc:static int ExtractGpuWithoutStream(string device_name) {
    Suggestion: string& device_name
24. core/kernels/ops_util.cc:string SanitizeThreadSuffix(string suffix) {
    Suggestion: const string& suffix
25. core/kernels/ops_util.h:string SanitizeThreadSuffix(string suffix);
    Suggestion: const string& suffix
26. core/kernels/xsmm_conv2d.cc:static void chk_libxsmm_err(libxsmm_dnn_err_t status, string msg) {
    Suggestion: const string& msg
#
27. stream_executor/platform.cc:PlatformKind PlatformKindFromString(string kind) {
    Suggestion: const string& kind
28. stream_executor/platform.h:PlatformKind PlatformKindFromString(string platform_string);
    Suggestion: const string& platform_string
"
14169,Tensorflow predicts odd results with insufficient GPU memory,"Hi all, 

I am currently having a problem that, when my code tries to initialize two or more predict instances in a GPU with insufficient memory, instead of throwing an OOM exception, the instances are initialized normally. However, when I try to predict an image with these instances, they produce weird results like [1.0, 0.0, 0.0, …].

Is this a bug when two or more sessions try to race for limited amount of GPU memory? 

Please see below for my system information and the exact steps to reproduce the problem. I would very much appreciate it if you could take a look.

Cheers, 
Vincent

System information

- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution: CentOS Linux release 7.2.1511
- TensorFlow installed from (source or binary): official binaries
- TensorFlow version (use command below): 1.3.0/ 1.2.0/ 1.1.0
- Python version: 2.7.5
- CUDA/cuDNN version: CUDA 8.0.61, CUDNN 6.0
- GPU model and memory: 1080 Ti (11172MB)
- Exact steps to reproduce:
1. Download and uncompress the file below with two scripts;
2. Download the official inception_v1 imagenet pretrained model  from http://download.tensorflow.org/models/inception_v1_2016_08_28.tar.gz
3. Try to occupy most of the memory in the GPU to run on - the exact amount of memory to occupy needs to be carefully tuned to reproduce the problem, in my case, I use pycuda to allocate 10720 out of the 11172MB of my 1080 Ti. 
4. Run test_monitor.py in two separate command prompts, we should see weird results within a few minutes (the scripts stop when encounter such results).

[reproduce_code.zip](https://github.com/tensorflow/tensorflow/files/1436321/reproduce_code.zip)
"
14165,Equivalent of caffe iter_size in TF,"
Can we get the equivalent of caffe's iter_size parameter in TF? This accumulates gradient calcs over several GPU cycles before doing the weight update. It effectively allows a larger batch size. TensorFlow doesn't natively have this but some ppl seem to have implemented sth like it themselves, e.g

https://stackoverflow.com/questions/42156957/how-to-update-model-parameters-with-accumulated-gradients

I think it'd be a useful parameter to have as part of official TF ... or is there some easy way to implement this functionality already?

Shaun"
14164,tfe.Network created inside variable_scopes,"This is a feature request. 
Currently `tfe.Network` cannot be created under variable scopes. This is particularly useful to still have when composing very complicated models. "
14163,The tensorflow doesn't work suddenly,"Hi,

I am so confused that the tensorflow cannot use today.  It is perfectly run yesterday and the days before.  I am sure that the coding are right (It can run on other computers and before on my computer). I tried reinstall the graphics driver, cuda and cudnn but did not work. Here is the problem when I run the program:

2017-11-01 14:07:43.309592: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-11-01 14:07:43.309643: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-11-01 14:07:43.309660: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-11-01 14:07:43.309674: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-11-01 14:07:43.309693: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-11-01 14:07:43.453723: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-11-01 14:07:43.454015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: GeForce GTX 1080
major: 6 minor: 1 memoryClockRate (GHz) 1.835
pciBusID 0000:01:00.0
Total memory: 7.92GiB
Free memory: 7.62GiB
2017-11-01 14:07:43.454027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2017-11-01 14:07:43.454030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2017-11-01 14:07:43.454051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)
========Recognition=========
2017-11-01 14:07:44.790433: E tensorflow/stream_executor/cuda/cuda_dnn.cc:359] could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2017-11-01 14:07:44.790460: E tensorflow/stream_executor/cuda/cuda_dnn.cc:326] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM
2017-11-01 14:07:44.790467: F tensorflow/core/kernels/conv_ops.cc:671] Check failed: stream->parent()->GetConvolveAlgorithms(&algorithms) 
Aborted (core dumped)

Thanks so much!"
14162,[Feature Request] tf.resume_gradient,"tf.stop_gradient provides a convenient way for various uses. However, sometimes, it may be useful to resume the gradient passing after some conditions are met. 

For example, in Faster-RCNN algorithm, the RPN layers' gradients are stopped because they may cause unstable results in early rounds. However, this indicates that these layers' weights would be kept the initial random values forever. If we could resume the gradients back propagation after several steps, the results may be better. Therefore, I believe that the resume_gradient function would be useful. Thank you."
14158,"Android - No OpKernel was registered to support Op 'Cos' with these attrs.  Registered devices: [CPU], Registered kernels:                                                                        <no registered kernels>                                                                                                                                            	 [[Node: stft/hann_window/Cos = Cos[T=DT_FLOAT, _device=""/device:CPU:0""](stft/hann_window/truediv)]]","I've exported a model to Android that uses : 
stfts = tf.contrib.signal.stft(transwav, frame_length=2048, frame_step=512,
                             fft_length=2048,window_fn=functools.partial(tf.contrib.signal.hann_window, periodic=False), pad_end=True)
the model works properly in pyhton
but when i load it in Android using the downloaded compiled tensorflow - compile 'org.tensorflow:tensorflow-android:+'
I get this error - 
FATAL EXCEPTION: main
                                                                     Process: org.tensorflow.demo, PID: 25836
                                                                     java.lang.IllegalArgumentException: No OpKernel was registered to support Op 'Cos' with these attrs.  Registered devices: [CPU], Registered kernels:
                                                                       <no registered kernels> 	 [[Node: stft/hann_window/Cos = Cos[T=DT_FLOAT, _device=""/device:CPU:0""](stft/hann_window/truediv)]]

which comes from the hann_window

any recommended work around?
"
14157,build with tensorflow_cc with cmake.,"I found https://github.com/FloopCZ/tensorflow_cc/ 
as a good solution.
should somebody add it to official repository"
14155,time to restore saved model increases over time ,"### System information
- Manjaro Linux
- TensorFlow installed with pip:
- TensorFlow version: v1.3.0-rc2-20-g0787eee 1.3.0:
- Python version: 3.6.2 
- CUDA/cuDNN version: 8.0.61-3 / 7.0.3-1
- GPU model and memory: GeForce GTX 1080 (8 GB)


### Describe the problem
Executing the code below in a loop slows down linearly with
number of iteration as can be seen in the figures below.
(The use case being a long running app where different models
are loaded (multiple times) depending on user inputs) 

```python
gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.25)
config = tf.ConfigProto(gpu_options=gpu_options)

with tf.Session(config=config) as sess:
    saver = tf.train.import_meta_graph(modelname)
    saver.restore(sess, tf.train.latest_checkpoint(""./""))
```

### Source code / logs
Reproducible code and plots of the time increase can be found here:
[https://www.dropbox.com/s/rgbqp9z3m5vnr9d/test.zip?dl=1](url)

To reproduce do the following from withing the extracted zip archive:
```
python train_model.py
python test_a.py
```

![import_metagraph](https://user-images.githubusercontent.com/7083141/32281142-4b2c3eec-bf1e-11e7-85f0-5da5af5e4135.png)

![saver_restore](https://user-images.githubusercontent.com/7083141/32281147-4f1244d4-bf1e-11e7-8126-28eb01df3c8a.png)"
14154,Clarify documentation of stacked cuDNN RNNs,"Currently the documentation for cuDNN RNNs is unclear as to whether the RNNs (LSTMs or GRUs), when they are bidirectional and configured with multiple layers, integrate the outputs from both directions at a given layer n before sending it to the next layer n+1, or whether each direction works independently of the other. I.e. forward layers send information just to the forward layers above, and similarly for the backward direction. The difference in behavior is quite important and it would be great if the documentation is updated to state which behavior is being carried out."
14151,The new version of the code about Wide and Deep model has not yet defined 'centered_bias',"Hi,
I'm reading the new version tensorflow code about Wide and deep model. the model is in tf.estimator.DNNLinearCombinedClassifier. In the tf.contrib.learn.DNNLinearCombinedClassifier,we can find that the variable 'centered_bias' is defined in head.py,It;s the bias of model's output.However, in the new version code. eg. the implemention based on 'tf.feature_column' and 'tf.estimator', this variale has not been find.It's only add dnn_logits and linear_logits. Is it a bug? or I do not find it.
thanks.
Xiangfu Shi"
14150,Unable to use tf.multinomial in Android. No OpKernel was registered to support Op 'Multinomial',"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS Sierra 10.12.6, Android APK 23
- **TensorFlow installed from (source or binary)**: pip
- **TensorFlow version (use command below)**: 1.3
- **Python version**: 2.7
- **Bazel version (if compiling from source)**:N/A
- **CUDA/cuDNN version**:N/A
- **GPU model and memory**:N/A

### Describe the problem
I cannot use tf.multinomial in Android while it works in mac. The error message is in the next section. I'm using tensorflow from [TensorFlowSharp](https://github.com/migueldeicaza/TensorFlowSharp) and [ml-agents](https://github.com/Unity-Technologies/ml-agents) in Unity. Unity builds my game uisng tensorflow for Android.

### Source code / logs
TFException: No OpKernel was registered to support Op 'Multinomial' with these attrs.  Registered devices: [CPU], Registered kernels:\<no registered kernels\>
[[Node: multinomial/Multinomial = Multinomial[T=DT_FLOAT, seed=0, seed2=0](dense_2/MatMul, multinomial/Multinomial/num_samples)]]
  at TensorFlow.TFStatus.CheckMaybeRaise (TensorFlow.TFStatus incomingStatus, System.Boolean last) [0x0004a] in <252020d87a4e4581ad2cfe3f9cc7a0ac>:0 "
14148,Nameerror: could not find operator mpisize in dynamic library mpi_collectives.so,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:ubuntu 16.04 with 4.4 kernel
- **TensorFlow installed from (source or binary)**: source code
- **TensorFlow version (use command below)**: latest(git clone from github in 2017/10/30)
- **Python version**: 2.7 
- **Bazel version (if compiling from source) : 0.70(latest)
- **CUDA/cuDNN version**: 8.0/6.0
- **GPU model and memory**: tesla k40c
- **Exact command to reproduce**: python -c ""import tensforflow.contrib.mpi_collectives"""
14147,tf.cast zeroes out input tensor when GPU does not have any free memory,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: tf-nightly-gpu binary from 10/31/2017
- **TensorFlow version (use command below)**: ('v1.3.0-rc1-4007-gc44f67a', '1.5.0-dev20171031')
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: CUDA v8, cuDNN v6
- **GPU model and memory**: 1080 Ti (11 GB)
- **Exact command to reproduce**:

x = tf.cast(tensor, tf.float32)
x = tf.to_float(tensor)

Above commands return a tensor with all values of `tensor` set to zero WHEN:
The gpu is in full use by another tensorflow process. I'm trying to cast the tensor from dtype=tf.uint16 to tf.float32, using above commands, but whenever this runs while the gpu is in full use (i.e. I get a CUDA out-of-memory error), the program completes execution normally but the casting commands set the tensor to zeros.
I upgraded from an older nightly-gpu binary to the current one, but didn't help. User should not try to use an already in-use gpu, but this error should at least be communicated to the user.

If I set the gpu to a different gpu with available memory, or if I hide all gpus to force it to use CPU, I do not observe this issue."
14146,[feature request] Adding c++ serving session api to c api ,Or is it recommended to just use TF_NewSession C API for session serving?  Is TF_Session.Run thread safe?  Thanks in advance!
14145,generator_input_fn for tensorflow estimator?,"I find there is `numpy_input_fn` and `pandas_input_fn` to construct the input_fn for tensorflow estimator. 

However, sometimes I need a more flexible constructor that can create the `input_fn` from a custom generator/iterator. It seems that Tensorflow doesn't have this feature currently. 

There is a [generator_input_fn](https://github.com/tensorflow/tensorflow/pull/7045/files#diff-58e32b22d643f3a61d9bbeee2bec89b6R27) for `tensorflow.contrib.learn` but I think that is not compatible with Tensorflow Estimator. 

Is there any plan to add `generator_input_fn` for tensorflow estimator?"
14144,Eager: Device Placement of Constant Eager Tensors,"When eager execution is enabled on 64bit machine, the following code snippet causes an error:
```python
with tf.device(""/gpu:0""):
  tf.split(np.array([1.0, 2.0]), np.array([1, 1]))`
```
```
Tensors on conflicting devices: cannot compute SplitV as input #1 was expected to be on 
/job:localhost/replica:0/task:0/device:CPU:0 but is actually on 
/job:localhost/replica:0/task:0/device:GPU:0 (operation running on 
/job:localhost/replica:0/task:0/device:GPU:0) Tensors can be copied explicitly using .gpu() or .cpu(),
or transparently copied by using tfe.enable_eager_execution(tfe.DEVICE_PLACEMENT_SILENT).
Copying tensors between devices may slow down your model [Op:SplitV] name: split
```
There are a couple of ways to fix this:
```python
with tf.device(""/gpu:0""):
  tf.split(np.array([1.0, 2.0]), np.array([1, 1], dtype=np.int32))`
```
or 
```python
with tf.device(""/gpu:0""):
  tf.split(np.array([1.0, 2.0]), [1, 1])`
```

The error is thrown for the following reason. Kernel of operation `split` expects the `num_or_size_splits` argument to be in host memory (CPU RAM). For a tensor to be placed in host memory, it needs to be either created in the CPU context (e.g. `with tf.device(""/cpu:0"")`) or have dtype of `int32`.  `numpy` defaults to creating `int64` tensors on 64bit machines. Hence the fixes - either explicitly request `int32` dtype from numpy or use python list (tensorflow defaults to `int32` for python sequences of small integers)

Another, more global, workaround is to enable automatic copying of tensors between devices as described in https://github.com/tensorflow/tensorflow/issues/14133.."
14143,Passing `clear_devices=True` to `SavedModelBuilder.add_meta_graph_and_variables()` loses function definitions,"The `SavedModelBuilder` inadvertently strips all function definitions from the `MetaGraphDef` when `clear_devices=True`. See this gist for a repro (thanks @eggie5 for finding it!):

https://gist.github.com/eggie5/f0838a1289ca851aa5a72593575b7f06

The bug appears to stem from `export_meta_graph()`, which builds a `GraphDef` by selective field copying when certain options (such as `clear_devices=True`) are passed. Passing `clear_devices=False` enables the code to succeed. However, it breaks compatibility between `tf.data` (and potentially other code) and `SavedModel`, so we should find a sustainable fix.

@sukritiramesh Can you please take a look? Thanks!"
14142,Tensorflow seq-to-seq Arabic chatbot,"
i'm working on an AI-chatbot for Arabic Language. I follow this tutorial in tensrflow seq-to-seq model. So far everything is doing great where i trained the model on my Arabic data using GPU and test the pre-trained model.But the some of them answers were correct while other are unrelated at all.

So, my questions are:

1. the model uses GRU in creating the model, should i change it to LSTM?

2. i used the same tokenizer in the (French to English translation tutorial), should i change it and use an Arabic tokenizer?

3. Even if i write an input it will reply with Arabic sentence, what i need is if the inout is new to the chatbot it should say ""sorry i don't understand"" for example

Basically, is there are changes should be done to make the chatbot handles the Arabic language very well"
14138,feature request for TensorFlow  Speech Recognizer .apk,"the Android .apk file is a great way to test TensorFlow  Speech Recognizer.
It would be even more useful with the addition of these two features:
1. once any word is detected, specify the scores for all 10 words in the list.
2. specify silence detection

Thank you in advance to anyone who is able to add these features!"
14134,Eager: Random seeds,"(This applies only when [eager execution](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/README.md) has been enabled via `tfe.enable_eager_execution()`) 

Setting the [graph-level random](https://www.tensorflow.org/api_docs/python/tf/set_random_seed) seed exactly once, before any operations are executed, works as intended; however, subsequent invocations to `tf.set_random_seed()` will not reset operation randomness. Furthermore, keyword arguments that set operation-level seeds have no effect when executing in eager mode. Random sequences generated by the same graph-seed will vary depending upon whether you are constructing a graph or executing eagerly.
"
14133,Eager: Automatic Device Placement,"When a GPU is available, TensorFlow automatically copies tensors between CPU and GPU memory (see [Using GPUs](https://www.tensorflow.org/tutorials/using_gpu)).

When eager execution is enabled, automatic copying between devices is disabled by default. When executing imperatively, copying data between CPU and GPU is more likely to become a performance bottleneck. Avoiding automatic copying makes it easier to identify such bottlenecks. For example, consider the program:


```python
with tf.device(“/cpu:0”):
  x = tf.ones([2, 2])
with tf.device(“/gpu:0”):
  y = tf.matmul(x, x)
```

This will fail with an error like:

```
Tensors on conflicting devices: cannot compute MatMul as input #0 was expected to be on /job:localhost/replica:0/task:0/device:GPU:0 but is actually on /job:localhost/replica:0/task:0/device:CPU:0 …
```


indicating that the `matmul` operation cannot be conducted on the GPU as its inputs were host memory.

If you run into this situation, your options are:

- Accept the potential performance hit by explicitly enabling automatic copying between devices:


```python
tfe.enable_eager_execution(device_policy=tfe.DEVICE_PLACEMENT_SILENT)
```

-  Explicitly copy the tensor yourself using `tf.identity` or `Tensor.gpu()`:

```python
with tf.device(“/gpu:0”):
  x = tf.identity(x)
  y = tf.matmul(x, x)
```"
14132,Eager: Variable item-assignment,"(This applies only when [eager execution](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/README.md) has been enabled via `tfe.enable_eager_execution()`)

Currently, the following does not work:

```python
import tensorflow as tf
import tensorflow.contrib.eager as tfe

tfe.enable_eager_execution()
x = tfe.Variable(tf.ones([10]), name=’x’)
x[3] = 2.
```

That last line, assigning a value to an element of the tensor will fail with: `object does not support item assignment`.

While it would be possible to make item assignment for `Tensor` and `Variable` objects work when eager execution is enabled, it is trickier to make the same line of code work with graph construction (since the line `x[3] = 2.` does not return a `tf.Operation` object that can be provided to a `Session.run()` call).

At this early stage of eager execution, we’re taking the conservative approach and disallowing Tensor assignment. This is probably worth revisiting at a future date. In the meantime, the verbose form of item assignment using `tf.scatter_update`:

```python
tf.scatter_update(x, [3], [2.])
```
"
14131,Eager: Using graphs in the same Python process,"Once eager execution is enabled via `tfe.enable_eager_execution()`, it cannot be disabled in the same process. This means that eager and graph execution cannot be mixed in the same Python session.

This issue has been filed to track development of features to make the transition between eager and graph execution smoother -- allowing users to pick and choose portions of the computation that will be “compiled” into graphs for optimized execution, and portions that will execute eagerly.
"
14130,Eager: CPU Performance/Operation Overheads,"(This applies only when [eager execution](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/README.md) has been enabled via `tfe.enable_eager_execution()`)

Eager execution re-uses most of the same Python code used for constructing TensorFlow graphs. Many of these paths have not been optimized for part of the critical path of computation. As a result, the CPU overheads of executing Python code for every operation are higher than we’d like.

Consequently, the performance of eager execution on models with many small computations, or models executed on CPU may be dominated by these overheads.

Overheads are measured using microbenchmarks such as in [`benchmarks_test.py`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/eager/benchmarks_test.py) and model-level benchmarks such as those used for [ResNet50](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples/resnet50) and the [PTB RNN](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples/rnn_ptb)"
14129,Eager: Distributed Execution,"(This applies only when [eager execution](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/README.md) has been enabled via `tfe.enable_eager_execution()`)


If the model does not involve dynamic control flow in Python (i.e., changing the computation based on input), then the same model code can be used to construct a TensorFlow graph, which can then be trained with [distributed TensorFlow](https://www.tensorflow.org/deploy/distributed)

Some example models like [MNIST](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples/mnist), [ResNet50](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples/resnet50), and the [PTB RNN](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples/rnn_ptb) include unittests outlining how the same model code can be used to construct and train TensorFlow graphs.

A smoother path to distributed TensorFlow when eager execution is enabled is being charted out.
"
14127,[Mac] Build @HEAD fails with XLA errors,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac High Sierra 10.13
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: HEAD at c44f67a7ed5870fe8a1c0d6257ce597ca2ef7564
- **Python version**: 2.7
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**:

1. Clone repo at head
2. configure
3. build with CPU support only and native arch optimization

Building TensorFlow at TensorFlow@c44f67a7ed5870fe8a1c0d6257ce597ca2ef7564 (HEAD) yields the errors below related to XLA (optimized for Intel(R) Core(TM) i7-7700HQ).

```
tensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:220:3: error: reinterpret_cast cannot resolve overloaded function 'acos' to type 'void *'
  REGISTER_LIBM_SYMBOL(acos);
  ^~~~~~~~~~~~~~~~~~~~~~~~~~
tensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:217:31: note: expanded from macro 'REGISTER_LIBM_SYMBOL'
    registry->Register(#name, reinterpret_cast<void*>(name));         \
                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:714:1: note: candidate function
acos(_A1 __lcpp_x) _NOEXCEPT {return ::acos((double)__lcpp_x);}
^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:708:46: note: candidate function
inline _LIBCPP_INLINE_VISIBILITY long double acos(long double __lcpp_x) _NOEXCEPT {return ::acosl(__lcpp_x);}
                                             ^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:707:46: note: candidate function
inline _LIBCPP_INLINE_VISIBILITY float       acos(float __lcpp_x) _NOEXCEPT       {return ::acosf(__lcpp_x);}
                                             ^
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk/usr/include/math.h:323:15: note: candidate function
extern double acos(double);
              ^
tensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:221:3: error: reinterpret_cast cannot resolve overloaded function 'acosh' to type 'void *'
  REGISTER_LIBM_SYMBOL(acosh);
  ^~~~~~~~~~~~~~~~~~~~~~~~~~~
tensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:217:31: note: expanded from macro 'REGISTER_LIBM_SYMBOL'
    registry->Register(#name, reinterpret_cast<void*>(name));         \
                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1005:1: note: candidate function
acosh(_A1 __lcpp_x) _NOEXCEPT {return ::acosh((double)__lcpp_x);}
^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1000:46: note: candidate function
inline _LIBCPP_INLINE_VISIBILITY long double acosh(long double __lcpp_x) _NOEXCEPT {return ::acoshl(__lcpp_x);}
                                             ^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:999:46: note: candidate function
inline _LIBCPP_INLINE_VISIBILITY float       acosh(float __lcpp_x) _NOEXCEPT       {return ::acoshf(__lcpp_x);}
                                             ^
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk/usr/include/math.h:351:15: note: candidate function
extern double acosh(double);
              ^
tensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:222:3: error: reinterpret_cast cannot resolve overloaded function 'asin' to type 'void *'
  REGISTER_LIBM_SYMBOL(asin);
  ^~~~~~~~~~~~~~~~~~~~~~~~~~
tensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:217:31: note: expanded from macro 'REGISTER_LIBM_SYMBOL'
    registry->Register(#name, reinterpret_cast<void*>(name));         \
                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:726:1: note: candidate function
asin(_A1 __lcpp_x) _NOEXCEPT {return ::asin((double)__lcpp_x);}
^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:720:46: note: candidate function
inline _LIBCPP_INLINE_VISIBILITY long double asin(long double __lcpp_x) _NOEXCEPT {return ::asinl(__lcpp_x);}
                                             ^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:719:46: note: candidate function
inline _LIBCPP_INLINE_VISIBILITY float       asin(float __lcpp_x) _NOEXCEPT       {return ::asinf(__lcpp_x);}
                                             ^
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk/usr/include/math.h:327:15: note: candidate function
extern double asin(double);
              ^
tensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:223:3: error: reinterpret_cast cannot resolve overloaded function 'asinh' to type 'void *'
  REGISTER_LIBM_SYMBOL(asinh);
  ^~~~~~~~~~~~~~~~~~~~~~~~~~~
tensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:217:31: note: expanded from macro 'REGISTER_LIBM_SYMBOL'
    registry->Register(#name, reinterpret_cast<void*>(name));         \
                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1017:1: note: candidate function
asinh(_A1 __lcpp_x) _NOEXCEPT {return ::asinh((double)__lcpp_x);}
^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1012:46: note: candidate function
inline _LIBCPP_INLINE_VISIBILITY long double asinh(long double __lcpp_x) _NOEXCEPT {return ::asinhl(__lcpp_x);}
                                             ^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1011:46: note: candidate function
inline _LIBCPP_INLINE_VISIBILITY float       asinh(float __lcpp_x) _NOEXCEPT       {return ::asinhf(__lcpp_x);}
                                             ^
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk/usr/include/math.h:355:15: note: candidate function
extern double asinh(double);
              ^
tensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:224:3: error: reinterpret_cast cannot resolve overloaded function 'atan' to type 'void *'
  REGISTER_LIBM_SYMBOL(atan);
  ^~~~~~~~~~~~~~~~~~~~~~~~~~
tensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:217:31: note: expanded from macro 'REGISTER_LIBM_SYMBOL'
    registry->Register(#name, reinterpret_cast<void*>(name));         \
                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:738:1: note: candidate function
atan(_A1 __lcpp_x) _NOEXCEPT {return ::atan((double)__lcpp_x);}
^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:732:46: note: candidate function
inline _LIBCPP_INLINE_VISIBILITY long double atan(long double __lcpp_x) _NOEXCEPT {return ::atanl(__lcpp_x);}
                                             ^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:731:46: note: candidate function
inline _LIBCPP_INLINE_VISIBILITY float       atan(float __lcpp_x) _NOEXCEPT       {return ::atanf(__lcpp_x);}
                                             ^
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk/usr/include/math.h:331:15: note: candidate function
extern double atan(double);
              ^
tensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:225:3: error: reinterpret_cast cannot resolve overloaded function 'atan2' to type 'void *'
  REGISTER_LIBM_SYMBOL(atan2);
  ^~~~~~~~~~~~~~~~~~~~~~~~~~~
tensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:217:31: note: expanded from macro 'REGISTER_LIBM_SYMBOL'
    registry->Register(#name, reinterpret_cast<void*>(name));         \
                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:755:1: note: candidate function
atan2(_A1 __lcpp_y, _A2 __lcpp_x) _NOEXCEPT
^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:744:46: note: candidate function
inline _LIBCPP_INLINE_VISIBILITY long double atan2(long double __lcpp_y, long double __lcpp_x) _NOEXCEPT {return ::atan2l(__lcpp_y, __lcpp_x);}
                                             ^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:743:46: note: candidate function
inline _LIBCPP_INLINE_VISIBILITY float       atan2(float __lcpp_y, float __lcpp_x) _NOEXCEPT             {return ::atan2f(__lcpp_y, __lcpp_x);}
                                             ^
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk/usr/include/math.h:335:15: note: candidate function
extern double atan2(double, double);
              ^
tensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:226:3: error: reinterpret_cast cannot resolve overloaded function 'atanh' to type 'void *'
  REGISTER_LIBM_SYMBOL(atanh);
  ^~~~~~~~~~~~~~~~~~~~~~~~~~~
tensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:217:31: note: expanded from macro 'REGISTER_LIBM_SYMBOL'
    registry->Register(#name, reinterpret_cast<void*>(name));         \
                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1029:1: note: candidate function
atanh(_A1 __lcpp_x) _NOEXCEPT {return ::atanh((double)__lcpp_x);}
^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1024:46: note: candidate function
inline _LIBCPP_INLINE_VISIBILITY long double atanh(long double __lcpp_x) _NOEXCEPT {return ::atanhl(__lcpp_x);}
                                             ^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1023:46: note: candidate function
inline _LIBCPP_INLINE_VISIBILITY float       atanh(float __lcpp_x) _NOEXCEPT       {return ::atanhf(__lcpp_x);}
                                             ^
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk/usr/include/math.h:359:15: note: candidate function
extern double atanh(double);
              ^
tensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:227:3: error: reinterpret_cast cannot resolve overloaded function 'cbrt' to type 'void *'
  REGISTER_LIBM_SYMBOL(cbrt);
  ^~~~~~~~~~~~~~~~~~~~~~~~~~
tensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:217:31: note: expanded from macro 'REGISTER_LIBM_SYMBOL'
    registry->Register(#name, reinterpret_cast<void*>(name));         \
                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1041:1: note: candidate function
cbrt(_A1 __lcpp_x) _NOEXCEPT {return ::cbrt((double)__lcpp_x);}
^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1036:46: note: candidate function
inline _LIBCPP_INLINE_VISIBILITY long double cbrt(long double __lcpp_x) _NOEXCEPT {return ::cbrtl(__lcpp_x);}
                                             ^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1035:46: note: candidate function
inline _LIBCPP_INLINE_VISIBILITY float       cbrt(float __lcpp_x) _NOEXCEPT       {return ::cbrtf(__lcpp_x);}
                                             ^
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk/usr/include/math.h:435:15: note: candidate function
extern double cbrt(double);
              ^
tensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:228:3: error: reinterpret_cast cannot resolve overloaded function 'ceil' to type 'void *'
  REGISTER_LIBM_SYMBOL(ceil);
  ^~~~~~~~~~~~~~~~~~~~~~~~~~
tensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:217:31: note: expanded from macro 'REGISTER_LIBM_SYMBOL'
    registry->Register(#name, reinterpret_cast<void*>(name));         \
                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:773:1: note: candidate function
ceil(_A1 __lcpp_x) _NOEXCEPT {return ::ceil((double)__lcpp_x);}
^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:767:46: note: candidate function
inline _LIBCPP_INLINE_VISIBILITY long double ceil(long double __lcpp_x) _NOEXCEPT {return ::ceill(__lcpp_x);}
                                             ^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:766:46: note: candidate function
inline _LIBCPP_INLINE_VISIBILITY float       ceil(float __lcpp_x) _NOEXCEPT       {return ::ceilf(__lcpp_x);}
                                             ^
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk/usr/include/math.h:470:15: note: candidate function
extern double ceil(double);
              ^
tensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:229:3: error: reinterpret_cast cannot resolve overloaded function 'copysign' to type 'void *'
  REGISTER_LIBM_SYMBOL(copysign);
  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
tensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:217:31: note: expanded from macro 'REGISTER_LIBM_SYMBOL'
    registry->Register(#name, reinterpret_cast<void*>(name));         \
                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1065:1: note: candidate function
copysign(_A1 __lcpp_x, _A2 __lcpp_y) _NOEXCEPT
^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1052:1: note: candidate function
copysign(long double __lcpp_x, long double __lcpp_y) _NOEXCEPT {
^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1047:40: note: candidate function
inline _LIBCPP_INLINE_VISIBILITY float copysign(float __lcpp_x,
                                       ^
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk/usr/include/math.h:526:15: note: candidate function
extern double copysign(double, double);
              ^
tensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:230:3: error: reinterpret_cast cannot resolve overloaded function 'cos' to type 'void *'
  REGISTER_LIBM_SYMBOL(cos);
  ^~~~~~~~~~~~~~~~~~~~~~~~~
tensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:217:31: note: expanded from macro 'REGISTER_LIBM_SYMBOL'
    registry->Register(#name, reinterpret_cast<void*>(name));         \
                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:785:1: note: candidate function
cos(_A1 __lcpp_x) _NOEXCEPT {return ::cos((double)__lcpp_x);}
^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:779:46: note: candidate function
inline _LIBCPP_INLINE_VISIBILITY long double cos(long double __lcpp_x) _NOEXCEPT {return ::cosl(__lcpp_x);}
                                             ^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:778:46: note: candidate function
inline _LIBCPP_INLINE_VISIBILITY float       cos(float __lcpp_x) _NOEXCEPT       {return ::cosf(__lcpp_x);}
                                             ^
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk/usr/include/math.h:339:15: note: candidate function
extern double cos(double);
              ^
tensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:231:3: error: reinterpret_cast cannot resolve overloaded function 'cosh' to type 'void *'
  REGISTER_LIBM_SYMBOL(cosh);
  ^~~~~~~~~~~~~~~~~~~~~~~~~~
tensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:217:31: note: expanded from macro 'REGISTER_LIBM_SYMBOL'
    registry->Register(#name, reinterpret_cast<void*>(name));         \
                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:797:1: note: candidate function
cosh(_A1 __lcpp_x) _NOEXCEPT {return ::cosh((double)__lcpp_x);}
^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:791:46: note: candidate function
inline _LIBCPP_INLINE_VISIBILITY long double cosh(long double __lcpp_x) _NOEXCEPT {return ::coshl(__lcpp_x);}
                                             ^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:790:46: note: candidate function
inline _LIBCPP_INLINE_VISIBILITY float       cosh(float __lcpp_x) _NOEXCEPT       {return ::coshf(__lcpp_x);}
                                             ^
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk/usr/include/math.h:363:15: note: candidate function
extern double cosh(double);
              ^
tensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:232:3: error: reinterpret_cast cannot resolve overloaded function 'erf' to type 'void *'
  REGISTER_LIBM_SYMBOL(erf);
  ^~~~~~~~~~~~~~~~~~~~~~~~~
tensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:217:31: note: expanded from macro 'REGISTER_LIBM_SYMBOL'
    registry->Register(#name, reinterpret_cast<void*>(name));         \
                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1083:1: note: candidate function
erf(_A1 __lcpp_x) _NOEXCEPT {return ::erf((double)__lcpp_x);}
^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1078:46: note: candidate function
inline _LIBCPP_INLINE_VISIBILITY long double erf(long double __lcpp_x) _NOEXCEPT {return ::erfl(__lcpp_x);}
                                             ^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1077:46: note: candidate function
inline _LIBCPP_INLINE_VISIBILITY float       erf(float __lcpp_x) _NOEXCEPT       {return ::erff(__lcpp_x);}
                                             ^
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk/usr/include/math.h:451:15: note: candidate function
extern double erf(double);
              ^
tensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:233:3: error: reinterpret_cast cannot resolve overloaded function 'erfc' to type 'void *'
  REGISTER_LIBM_SYMBOL(erfc);
  ^~~~~~~~~~~~~~~~~~~~~~~~~~
tensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:217:31: note: expanded from macro 'REGISTER_LIBM_SYMBOL'
    registry->Register(#name, reinterpret_cast<void*>(name));         \
                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1093:1: note: candidate function
erfc(_A1 __lcpp_x) _NOEXCEPT {return ::erfc((double)__lcpp_x);}
^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1088:46: note: candidate function
inline _LIBCPP_INLINE_VISIBILITY long double erfc(long double __lcpp_x) _NOEXCEPT {return ::erfcl(__lcpp_x);}
                                             ^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1087:46: note: candidate function
inline _LIBCPP_INLINE_VISIBILITY float       erfc(float __lcpp_x) _NOEXCEPT       {return ::erfcf(__lcpp_x);}
                                             ^
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk/usr/include/math.h:455:15: note: candidate function
extern double erfc(double);
              ^
tensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:234:3: error: reinterpret_cast cannot resolve overloaded function 'exp' to type 'void *'
  REGISTER_LIBM_SYMBOL(exp);
  ^~~~~~~~~~~~~~~~~~~~~~~~~
tensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:217:31: note: expanded from macro 'REGISTER_LIBM_SYMBOL'
    registry->Register(#name, reinterpret_cast<void*>(name));         \
                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:809:1: note: candidate function
exp(_A1 __lcpp_x) _NOEXCEPT {return ::exp((double)__lcpp_x);}
^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:803:46: note: candidate function
inline _LIBCPP_INLINE_VISIBILITY long double exp(long double __lcpp_x) _NOEXCEPT {return ::expl(__lcpp_x);}
                                             ^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:802:46: note: candidate function
inline _LIBCPP_INLINE_VISIBILITY float       exp(float __lcpp_x) _NOEXCEPT       {return ::expf(__lcpp_x);}
                                             ^
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk/usr/include/math.h:375:15: note: candidate function
extern double exp(double);
              ^
tensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:235:3: error: reinterpret_cast cannot resolve overloaded function 'exp2' to type 'void *'
  REGISTER_LIBM_SYMBOL(exp2);
  ^~~~~~~~~~~~~~~~~~~~~~~~~~
tensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:217:31: note: expanded from macro 'REGISTER_LIBM_SYMBOL'
    registry->Register(#name, reinterpret_cast<void*>(name));         \
                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1103:1: note: candidate function
exp2(_A1 __lcpp_x) _NOEXCEPT {return ::exp2((double)__lcpp_x);}
^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1098:46: note: candidate function
inline _LIBCPP_INLINE_VISIBILITY long double exp2(long double __lcpp_x) _NOEXCEPT {return ::exp2l(__lcpp_x);}
                                             ^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1097:46: note: candidate function
inline _LIBCPP_INLINE_VISIBILITY float       exp2(float __lcpp_x) _NOEXCEPT       {return ::exp2f(__lcpp_x);}
                                             ^
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk/usr/include/math.h:379:15: note: candidate function
extern double exp2(double); 
              ^
tensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:236:3: error: reinterpret_cast cannot resolve overloaded function 'expm1' to type 'void *'
  REGISTER_LIBM_SYMBOL(expm1);
  ^~~~~~~~~~~~~~~~~~~~~~~~~~~
tensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:217:31: note: expanded from macro 'REGISTER_LIBM_SYMBOL'
    registry->Register(#name, reinterpret_cast<void*>(name));         \
                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1113:1: note: candidate function
expm1(_A1 __lcpp_x) _NOEXCEPT {return ::expm1((double)__lcpp_x);}
^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1108:46: note: candidate function
inline _LIBCPP_INLINE_VISIBILITY long double expm1(long double __lcpp_x) _NOEXCEPT {return ::expm1l(__lcpp_x);}
                                             ^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1107:46: note: candidate function
inline _LIBCPP_INLINE_VISIBILITY float       expm1(float __lcpp_x) _NOEXCEPT       {return ::expm1f(__lcpp_x);}
                                             ^
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk/usr/include/math.h:383:15: note: candidate function
extern double expm1(double); 
              ^
tensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:237:3: error: reinterpret_cast cannot resolve overloaded function 'fabs' to type 'void *'
  REGISTER_LIBM_SYMBOL(fabs);
  ^~~~~~~~~~~~~~~~~~~~~~~~~~
tensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:217:31: note: expanded from macro 'REGISTER_LIBM_SYMBOL'
    registry->Register(#name, reinterpret_cast<void*>(name));         \
                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:821:1: note: candidate function
fabs(_A1 __lcpp_x) _NOEXCEPT {return ::fabs((double)__lcpp_x);}
^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:815:46: note: candidate function
inline _LIBCPP_INLINE_VISIBILITY long double fabs(long double __lcpp_x) _NOEXCEPT {return ::fabsl(__lcpp_x);}
                                             ^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:814:46: note: candidate function
inline _LIBCPP_INLINE_VISIBILITY float       fabs(float __lcpp_x) _NOEXCEPT       {return ::fabsf(__lcpp_x);}
                                             ^
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk/usr/include/math.h:431:15: note: candidate function
extern double fabs(double);
              ^
tensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:238:3: error: reinterpret_cast cannot resolve overloaded function 'fdim' to type 'void *'
  REGISTER_LIBM_SYMBOL(fdim);
  ^~~~~~~~~~~~~~~~~~~~~~~~~~
tensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:217:31: note: expanded from macro 'REGISTER_LIBM_SYMBOL'
    registry->Register(#name, reinterpret_cast<void*>(name));         \
                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1128:1: note: candidate function
fdim(_A1 __lcpp_x, _A2 __lcpp_y) _NOEXCEPT
^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1118:46: note: candidate function
inline _LIBCPP_INLINE_VISIBILITY long double fdim(long double __lcpp_x, long double __lcpp_y) _NOEXCEPT {return ::fdiml(__lcpp_x, __lcpp_y);}
                                             ^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1117:46: note: candidate function
inline _LIBCPP_INLINE_VISIBILITY float       fdim(float __lcpp_x, float __lcpp_y) _NOEXCEPT             {return ::fdimf(__lcpp_x, __lcpp_y);}
                                             ^
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk/usr/include/math.h:542:15: note: candidate function
extern double fdim(double, double);
              ^
fatal error: too many errors emitted, stopping now [-ferror-limit=]
2 warnings and 20 errors generated.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 2220.010s, Critical Path: 87.74s


```"
14126,fail to build tensorflow-gpu by CUDA 9.0 cuDNN 7 at win10 envs ,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: window 10 64bit
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: tensorflow-1.4.0 or tensorflow-1.3.0
- **Python version**: python 3.5.4
- **Bazel version (if compiling from source)**: cmake 3.6.3
- **CUDA/cuDNN version**: CUDA 9.0 + cuDNN 7
- **GPU model and memory**: gtx 1080ti (11GB)
- **Exact command to reproduce**:

### Describe the problem

hello，for i can't use tensorflow gpu packet at win10, so i try to build tensorflow gpu by win10 env，then met those issue， can anyone help me，thanks first.
my environment：
win10 + gtx 1080ti + cuda 9.0 + cuDNN 7 + visual studio profession 2015 + cmake 3.6.3 + python 3.5.4
when i switch to tensorflow r1.4，and build by cmake at win10 environment，issue accur that：
`CUSTOMBUILD : Internal error : assertion failed at: ""C:/dvs/p4/build/sw/rel/gpu_drv/r384/r384_00/drivers/compiler/edg/EDG_4.12/src/lookup.c"", line 2652 [C:\TF\tensorflow\tensorflow\contrib\cmake\build\tf_core_gpu_kernels.vcxproj]
1 catastrophic error detected in the compilation of ""C:/Users/ADMINI~1/AppData/Local/Temp/tmpxft_00000c94_00000000-8_adjust_contrast_op_gpu.cu.cpp4.ii"".
Compilation aborted.
adjust_contrast_op_gpu.cu.cc
CUSTOMBUILD : nvcc error : 'cudafe++' died with status 0xC0000409 [C:\TF\tensorflow\tensorflow\contrib\cmake\build\tf_core_gpu_kernels.vcxproj]
CMake Error at tf_core_gpu_kernels_generated_adjust_contrast_op_gpu.cu.cc.obj.Release.cmake:267 (message):
Error generating file
C:/TF/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/tf_core_gpu_kernels.dir///core/kernels/Release/tf_core_gpu_kernels_generated_adjust_contrast_op_gpu.cu.cc.obj`
![image](https://user-images.githubusercontent.com/32933617/32231202-ee18adfa-be8f-11e7-87fd-0dff8854ae96.png)

above issue look like cuda compolie itself problem，but when i switch tensorflow version to r1.3，another issue accur：
`c:\tf\test\tensorflow\tensorflow\contrib\cmake\build\external\eigen_archive\eigen\src/Core/util/Macros.h(416): fatal error C1017:
无效的整数常量表达式 [C:\TF\test\tensorflow\tensorflow\contrib\cmake\build\tf_core_gpu_kernels.vcxproj]
CMake Error at tf_core_gpu_kernels_generated_adjust_contrast_op_gpu.cu.cc.obj.Release.cmake:267 (message):
Error generating file
C:/TF/test/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/tf_core_gpu_kernels.dir///core/kernels/Release/tf_core_gpu_kernels_generated_adjust_contrast_op_gpu.cu.cc.obj`
![image](https://user-images.githubusercontent.com/32933617/32231220-f8c0802a-be8f-11e7-9dcb-623cbc2a3429.png)

it look like the file adjust_contrast_op_gpu.cu.cc have some problem，but i can't find any error from it.
such above issues trouble me few days，wish to someone help me going this try and success，and strong expect google upgrade tensorflow support cuda 9.0 and cudnn 7 at win10 environment.
"
14125,[feature request] Does android tensorflow make the without considering front-camera and landscape mode ?  ,"Fist bump.
I want to make a tensorflow application available in landscape also, facing-mode 

But, during the development- 
There was a problem that  coordinates were displayed wrong when the front camera and landscape mode was used to detect the object, after inference
Do you have  any reference code or other resources ?

Have a nice day  :) "
14122,Access denied to download faster_rcnn_nas_17_10_2017.tar.gz trained on COCO from the network zoo found in object detection,"Following is link on which it says the network is available to download
https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md
But when i click the link to download http://download.tensorflow.org/models/object_detection/faster_rcnn_nas_17_10_2017.tar.gz
it says access denied"
14118,How to print shape of tensors in tf.contrib.learn.Estimator,"tf.contrib.learn.Estimator and tf.contrib.learn.Experiment  are very convenience to build a model. But how to debug the user defined model? For example, in the [Abalone Age Predictor example,](https://www.tensorflow.org/extend/estimators) how to print shape of 'first_hidden_layer', 'second_hidden_layer' and 'predictions' in user defined 'model_fn' function? 

 It is easy to print  shape of tensors if we build a model with session, and an example is as follows:
`a = tf.Variable(tf.zeros(shape=(2, 3, 4)))
with tf.Session() as sess:
    print sess.run(tf.shape(a))`

By the way, I also tried to debug  [Abalone Age Predictor example,](https://www.tensorflow.org/extend/estimators) with tf.python.debug.LocalCLIDebugHook, but 'first_hidden_layer', 'second_hidden_layer' and 'predictions' are not in debug window.

Many thanks in advance.
"
14117,Error in CMake generated build script,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 1709
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.4.0-rc1
- **Python version**: 3.5
- **Bazel version (if compiling from source)**: - (I use cmake)
- **CUDA/cuDNN version**: 9.0/7
- **GPU model and memory**: Notebook 1070 8G
- **Exact command to reproduce**: 
Use cmake to generate build script for `Visual Studio 2017 Win64`
`CMAKE_C_COMPILER`, `CMAKE_CXX_COMPILER` and `CUDA_HOST_COMPILER` should be set manually, otherwise, it will failed the compilation phase calling to NVCC


### Describe the problem
This problem happens when building with Visual Studio 2017.4 + CUDA 9.0 + cuDNN 7 + CMake + GPU build.

Sorry for lack of information. I build it yesterday (and failed) and it take so long the compile through and I didn't keep the log. This problem is LINK ERRORs. What I can identify is they are in the generated build script. The problems happens exactly  in
```
_beam_search_ops.vcxproj
_gru_ops.vcxproj
_lstm_ops.vcxproj
_nearest_neighbor_ops.vcxproj
```
e.g. in  `_beam_search_ops.vcxproj` around line 103
```
    <Link>
      <AdditionalDependencies>\pywrap_tensorflow_internal.lib;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\lib\x64\cudart_static.lib;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\lib\x64\cuda.lib;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\lib\x64\cublas.lib;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\lib\x64\cublas_device.lib;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\lib\x64\cufft.lib;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\lib\x64\curand.lib;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\extras\CUPTI\libx64\cupti.lib;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\lib\x64\cusolver.lib;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\lib\x64\cudnn.lib;kernel32.lib;user32.lib;gdi32.lib;winspool.lib;shell32.lib;ole32.lib;oleaut32.lib;uuid.lib;comdlg32.lib;advapi32.lib</AdditionalDependencies>
      <AdditionalLibraryDirectories>%(AdditionalLibraryDirectories)</AdditionalLibraryDirectories>
      <AdditionalOptions>%(AdditionalOptions) /machine:x64 /ignore:4049 /ignore:4197 /ignore:4217 /ignore:4221</AdditionalOptions>
      <GenerateDebugInformation>false</GenerateDebugInformation>
      <IgnoreSpecificDefaultLibraries>%(IgnoreSpecificDefaultLibraries)</IgnoreSpecificDefaultLibraries>
      <ImportLibrary>D:/workspaces/tensorflow/tensorflow/contrib/cmake/build/Release/_beam_search_ops.lib</ImportLibrary>
      <ProgramDataBaseFile>D:/workspaces/tensorflow/tensorflow/contrib/cmake/build/Release/_beam_search_ops.pdb</ProgramDataBaseFile>
      <SubSystem>Console</SubSystem>
    </Link>
```

You can see a `\pywrap_tensorflow_internal.lib` in `<AdditionalDependencies>` cause the LINK ERROR, since the linker can't find file `pywrap_tensorflow_internal.lib`.

The prefix **backslash** seems to be the cause. I suspect it should be some `${BLAH_env_VARIBALE}pywrap_tensorflow_internal.lib` and this `${BLAH_env_VARIBALE}` happens to be empty string and results to a `\pywrap_tensorflow_internal.lib`.

All four `.vcxproj` files comes from function call `AddUserOps` in `tf_python.cmake` , where the `AddUserOps` is defined in `tf_cc_ops.cmake` file. Due to my poor eye sight, I can't decide where is the problem from here...

Notice, I CAN see the file `pywrap_tensorflow_internal.lib` in some directory so it should be problem related with the path ."
14116,py_func cannot handle Chinese string correctly,"tensorflow: 1.3.0

I write a simple code to split and concatenate utf8 string. However, I found that only English string works well on python 2.7. 

### script:
```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import tensorflow as tf

def test_string(x):
    return u""/"".join(x.split())

str_en = tf.py_func(
        test_string,
        [tf.constant(u""hello, world"")],
        tf.string)

str_zh = tf.py_func(
        test_string,
        [tf.constant(u""你好, 世界"")],
        tf.string)

with tf.Session() as sess:
    print(""English:"")
    print(sess.run(str_en))
    print(""Chinese:"")
    print(sess.run(str_zh))
```

### logs

#### python: 2.7

success for English, failed for Chinese.

```python
(py27) ~/Downloads ❯❯❯ python test.py
English:
hello,/world
Chinese:
2017-10-31 11:23:39.491876: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: exceptions.UnicodeDecodeError: 'ascii' codec can't decode byte 0xe4 in position 0: ordinal not in range(128)
Traceback (most recent call last):
  File ""test.py"", line 23, in <module>
    print(sess.run(str_zh))
  File ""/Users/facai/Library/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 895, in run
    run_metadata_ptr)
  File ""/Users/facai/Library/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1124, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/Users/facai/Library/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1321, in _do_run
    options, run_metadata)
  File ""/Users/facai/Library/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1340, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: exceptions.UnicodeDecodeError: 'ascii' codec can't decode byte 0xe4 in position 0: ordinal not in range(128)
         [[Node: PyFunc_1 = PyFunc[Tin=[DT_STRING], Tout=[DT_STRING], token=""pyfunc_1"", _device=""/job:localhost/replica:0/task:0/cpu:0""](Const_1)]]

Caused by op u'PyFunc_1', defined at:
  File ""test.py"", line 17, in <module>
    tf.string)
  File ""/Users/facai/Library/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/ops/script_ops.py"", line 203, in py_func
    input=inp, token=token, Tout=Tout, name=name)
  File ""/Users/facai/Library/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/ops/gen_script_ops.py"", line 36, in _py_func
    name=name)
  File ""/Users/facai/Library/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 767, in apply_op
    op_def=op_def)
  File ""/Users/facai/Library/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2630, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/Users/facai/Library/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1204, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): exceptions.UnicodeDecodeError: 'ascii' codec can't decode byte 0xe4 in position 0: ordinal not in range(128)
         [[Node: PyFunc_1 = PyFunc[Tin=[DT_STRING], Tout=[DT_STRING], token=""pyfunc_1"", _device=""/job:localhost/replica:0/task:0/cpu:0""](Const_1)]]
```

#### python 3.5.2

both failed.

```python
~/Downloads ❯❯❯ python test.py
English:
2017-10-31 11:24:52.706080: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: TypeError: sequence item 0: expected str instance, bytes found
Traceback (most recent call last):
  File ""/Users/facai/Library/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1327, in _do_call
    return fn(*args)
  File ""/Users/facai/Library/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1306, in _run_fn
    status, run_metadata)
  File ""/Users/facai/Library/anaconda3/lib/python3.5/contextlib.py"", line 66, in __exit__
    next(self.gen)
  File ""/Users/facai/Library/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py"", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: TypeError: sequence item 0: expected str instance, bytes found
         [[Node: PyFunc = PyFunc[Tin=[DT_STRING], Tout=[DT_STRING], token=""pyfunc_0"", _device=""/job:localhost/replica:0/task:0/cpu:0""](Const)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""test.py"", line 21, in <module>
    print(sess.run(str_en))
  File ""/Users/facai/Library/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 895, in run
    run_metadata_ptr)
  File ""/Users/facai/Library/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1124, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/Users/facai/Library/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1321, in _do_run
    options, run_metadata)
  File ""/Users/facai/Library/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1340, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: TypeError: sequence item 0: expected str instance, bytes found
         [[Node: PyFunc = PyFunc[Tin=[DT_STRING], Tout=[DT_STRING], token=""pyfunc_0"", _device=""/job:localhost/replica:0/task:0/cpu:0""](Const)]]

Caused by op 'PyFunc', defined at:
  File ""test.py"", line 12, in <module>
    tf.string)
  File ""/Users/facai/Library/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/script_ops.py"", line 203, in py_func
    input=inp, token=token, Tout=Tout, name=name)
  File ""/Users/facai/Library/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_script_ops.py"", line 36, in _py_func
    name=name)
  File ""/Users/facai/Library/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py"", line 767, in apply_op
    op_def=op_def)
  File ""/Users/facai/Library/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 2630, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/Users/facai/Library/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1204, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): TypeError: sequence item 0: expected str instance, bytes found
         [[Node: PyFunc = PyFunc[Tin=[DT_STRING], Tout=[DT_STRING], token=""pyfunc_0"", _device=""/job:localhost/replica:0/task:0/cpu:0""](Const)]]
```"
14112,[iOS] No OpKernel was registered to support Op 'Prod' with these attrs,"I'm trying to load the faster_rcnn_resnet101_coco model from the [Tensorflow Object Detection model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md) onto the iOS camera example.  Currently, I'm running in to the issue with 
```
No OpKernel was registered to support Op 'Prod' with these attrs.  Registered devices: [CPU], Registered kernels:
  <no registered kernels>
```

The environment is as follows:

- python 3.6
- xcode 9.0.1
- mac os 10.12
- tensorflow built from source using r1.4
- bazel 0.5.4

I have done things as follow:

1. Following the iOS static library build [instructions](https://github.com/tensorflow/tensorflow/tree/r1.4/tensorflow/contrib/makefile),

2. Successfully ran 

`tensorflow/contrib/makefile/download_dependencies.sh
`
3. Successfully ran 

`tensorflow/contrib/makefile/compile_ios_protobuf.sh`

4. Successfully ran 

```
export HOST_NSYNC_LIB=`tensorflow/contrib/makefile/compile_nsync.sh`
export TARGET_NSYNC_LIB=`tensorflow/contrib/makefile/compile_nsync.sh -t ios`
```

5. Created faster-rcnn specific ops:
```
  bazel build tensorflow/python/tools:print_selective_registration_header 
  bazel-bin/tensorflow/python/tools/print_selective_registration_header \
    --graphs=frozen_inference_graph.pb > ops_to_register.h
```

6. Moved `ops_to_register.h` under `tensorflow/core/framework/`

7. Successfully built `libtensorflow-core.a` to account for additional types and custom ops
```
tensorflow/contrib/makefile/compile_ios_tensorflow.sh ""-O3  -DANDROID_TYPES=ANDROID_TYPES_FULL -DSELECTIVE_REGISTRATION -DSUPPORT_SELECTIVE_REGISTRATION""
```

8. Verified the creation of 
```
tensorflow/contrib/makefile/gen/lib/libtensorflow-core.a
tensorflow/contrib/makefile/gen/protobuf_ios/lib/libprotobuf.a
tensorflow/contrib/makefile/gen/protobuf_ios/lib/libprotobuf-lite.a
```

9. Check for `tf_op_files.txt`, and made sure `tensorflow/core/ops/math_ops.cc` exists (I think this is where ""Prod"" is covered since there's no such file as `cwise_op_prod.cc`?)

10. Updated iOS camera example with faster-rcnn model, imported ""mscoco_label_map"", and corresponding input/output layers.

When running, I can't get pass error 
```
2017-10-30 18:00:28.307769: E [path]/tensorflow_utils.mm:209] Could not create TensorFlow Graph: Invalid argument: No OpKernel was registered to support Op 'Prod' with these attrs.  Registered devices: [CPU], Registered kernels:
  <no registered kernels>

	 [[Node: SecondStageBoxPredictor/Flatten/Prod = Prod[T=DT_INT32, Tidx=DT_INT32, keep_dims=false](SecondStageBoxPredictor/Flatten/Slice_1, SecondStageBoxPredictor/Flatten/Const)]]
2017-10-30 18:00:28.320101: F [path]CameraExampleViewController.mm:495] Couldn't load model: Invalid argument: No OpKernel was registered to support Op 'Prod' with these attrs.  Registered devices: [CPU], Registered kernels:
  <no registered kernels>

	 [[Node: SecondStageBoxPredictor/Flatten/Prod = Prod[T=DT_INT32, Tidx=DT_INT32, keep_dims=false](SecondStageBoxPredictor/Flatten/Slice_1, SecondStageBoxPredictor/Flatten/Const)]]
```

If I try the same steps with the model `ssd_mobilenet_v1_coco` from the same model zoo, it works fine.  I've also tried the instructions from [JieHe96/iOS_Tensorflow_ObjectDetection_Example](https://github.com/JieHe96/iOS_Tensorflow_ObjectDetection_Example) but runs into the exact same problem.

Can anyone help?

"
14111,CUDNN_STATUS_INTERNAL_ERROR,"Hi, 

I did not do anything but find all my programs about tensorflow could not work. That is very strange that my two computers has the same error at the same time.

The error is showed here:

2017-10-30 17:55:23.525428: E tensorflow/stream_executor/cuda/cuda_dnn.cc:371] could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2017-10-30 17:55:23.525452: E tensorflow/stream_executor/cuda/cuda_dnn.cc:338] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM
2017-10-30 17:55:23.525458: F tensorflow/core/kernels/conv_ops.cc:672] Check failed: stream->parent()->GetConvolveAlgorithms( conv_parameters.ShouldIncludeWinogradNonfusedAlgo<T>(), &algorithms) 
Aborted (core dumped)


Thanks so much
"
14110,GPU underutilized using DNNClassifier,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Using stock code: https://www.tensorflow.org/get_started/estimator
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary from pip
- **TensorFlow version (use command below)**: 1.3.1, 1.4rc1, master
- **Python version**: 3.5
- **Bazel version (if compiling from source)**: 0.7
- **CUDA/cuDNN version**: CUDA 8; cuDNN 6.0
- **GPU model and memory**: NVidia GeForce 1070 (8GB)
- **Exact command to reproduce**: run the above code for the estimator (or see below)

### Describe the problem
Running this code results in GPU use of up to 5-10% of GPU resources (measured using nvidia-smi). Changing the network nodes won't improve performance. Using derived code (but essentially the same) on much larger datasets increases GPU performance up to 25%. I would expect max GPU utilization. Memory allocation is in any case 100%.

### Source code / logs
The code used is from https://www.tensorflow.org/get_started/estimator , here reproduced with minor fixes (it won't run on python3 otherwise):

```from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import os, json
#import urllib
from urllib.request import urlopen

import numpy as np
import tensorflow as tf

# Data sets
IRIS_TRAINING = ""iris_training.csv""
IRIS_TRAINING_URL = ""http://download.tensorflow.org/data/iris_training.csv""

IRIS_TEST = ""iris_test.csv""
IRIS_TEST_URL = ""http://download.tensorflow.org/data/iris_test.csv""

def main():
  # If the training and test sets aren't stored locally, download them.
  if not os.path.exists(IRIS_TRAINING):
    raw = urlopen(IRIS_TRAINING_URL).read()
    print(raw)
    with open(IRIS_TRAINING, ""w"") as f:
      #f.write(raw)
      f.write(json.loads(raw.decode('utf-8')))

  if not os.path.exists(IRIS_TEST):
    raw = urlopen(IRIS_TEST_URL).read()
    with open(IRIS_TEST, ""w"") as f:
      #f.write(raw)
      f.write(json.loads(raw.decode('utf-8')))


  # Load datasets.
  training_set = tf.contrib.learn.datasets.base.load_csv_with_header(
      filename=IRIS_TRAINING,
      target_dtype=np.int,
      features_dtype=np.float32)
  test_set = tf.contrib.learn.datasets.base.load_csv_with_header(
      filename=IRIS_TEST,
      target_dtype=np.int,
      features_dtype=np.float32)

  # Specify that all features have real-value data
  feature_columns = [tf.feature_column.numeric_column(""x"", shape=[4])]

  # Build 3 layer DNN with 10, 20, 10 units respectively.
  classifier = tf.estimator.DNNClassifier(feature_columns=feature_columns,
                                          hidden_units=[100],
                                          n_classes=3,
                                          model_dir=""./iris_model"")
  # Define the training inputs
  train_input_fn = tf.estimator.inputs.numpy_input_fn(
      x={""x"": np.array(training_set.data)},
      y=np.array(training_set.target),
      num_epochs=None,
      shuffle=True)

  # Train model.
  classifier.train(input_fn=train_input_fn, steps=2000)

  # Define the test inputs
  test_input_fn = tf.estimator.inputs.numpy_input_fn(
      x={""x"": np.array(test_set.data)},
      y=np.array(test_set.target),
      num_epochs=1,
      shuffle=False)

  # Evaluate accuracy.
  accuracy_score = classifier.evaluate(input_fn=test_input_fn)[""accuracy""]

  print(""\nTest Accuracy: {0:f}\n"".format(accuracy_score))

  # Classify two new flower samples.
  new_samples = np.array(
      [[6.4, 3.2, 4.5, 1.5],
       [5.8, 3.1, 5.0, 1.7]], dtype=np.float32)
  predict_input_fn = tf.estimator.inputs.numpy_input_fn(
      x={""x"": new_samples},
      num_epochs=1,
      shuffle=False)

  predictions = list(classifier.predict(input_fn=predict_input_fn))
  predicted_classes = [p[""classes""] for p in predictions]

  print(
      ""New Samples, Class Predictions:    {}\n""
      .format(predicted_classes))

if __name__ == ""__main__"":
    main()
```
"
14109,The implementation in source code of Backpropagation in TensorFlow (Conv2DBackpropFilter and Conv2DBackpropInput),"Hi,

Since two operations Conv2DBackpropFilter and Conv2DBackpropInput count most of the time for lots of applications(AlexNet/VGG/GAN/Inception, etc.), I am analyzing the complexity of these two operations (back-propagation) in TensorFlow and I found out that there are three implementation versions (custom, fast and slot) for Conv2DBackpropFilter (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/conv_grad_filter_ops.cc ) and Conv2DBackpropInput (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/conv_grad_input_ops.cc). While I profile, all computations are passed to ""custom"" version instead of ""fast"" or ""slow"" which directly calls Eigen function SpatialConvolutionBackwardInput to do that. 

The issue is:
Conv2DBackpropFilter uses Eigen:“TensorMap.contract"" to do the tensor contraction and Conv2DBackpropInput uses Eigen:""MatrixMap.transpose"" to do the matrix transposition in the Compute() function. Beside these two functions, I didn't see any convolutional operations which are needed for back-propagation theoretically. Beside convolutions, what else would be run inside these two operations for back-propagation? Does anyone know how to analyze the computation complexity of ""back propagation"" operation in TensorFlow?

I am looking for any advise/suggestion. Thank you!"
14108,Custom OP Reader AttributeError: 'module' object has no attribute 'read',"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Custom Code
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
Source
- **TensorFlow version (use command below)**:
1.4.0
- **Python version**: 
2.7
- **Bazel version (if compiling from source)**:
0.6.1
- **CUDA/cuDNN version**:
Laptop CPU
- **GPU model and memory**:
Laptop CPU
- **Exact command to reproduce**:
```
import tensorflow as tf
filename_queue = tf.train.string_input_producer([""test.csv""])
reader = tf.load_op_library('./tensorflow/bazel-bin/tensorflow/core/user_ops/redis_reader.so')
key, value = reader.read(filename_queue) 
```

### Describe the problem
For my custom op reader, I am getting `AttributeError: 'module' object has no attribute 'read'`. This is most puzzling to me because I thought the python wrapper would inherit `read` from `/tensorflow/python/ops/io_ops.py`. Furthermore, `gen_user_ops.py` in my bazel-genfiles doesn't seem to have code that reflects my custom op reader. Is it suppose to show in that file? 

### Source code / logs
Here I have registed the OP:

```
REGISTER_OP(""RedisReader"")
    .Output(""reader_handle: resource"")                            
    .Attr(""container: string = ''"")                               
    .Attr(""shared_name: string = ''"")                             
    .SetIsStateful()                                              
    .SetShapeFn(TwoElementOutput)
    .Doc(R""doc(Description Goes Here)doc"");
```

Here is my kernel and kernel registration:

```
class RedisReaderOp : public ReaderOpKernel {
    public:
        explicit RedisReaderOp(OpKernelConstruction* context) : ReaderOpKernel(context) {
            
            Env* env = context->env();

            SetReaderFactory([this, env]() {
                return new RedisReader(name(), env);
            });
        }
};

REGISTER_KERNEL_BUILDER(Name(""RedisReader"").Device(DEVICE_CPU), RedisReaderOp);
```

And here is my python wrapper located in `user_ops.py`:

```
from tensorflow.python.ops import gen_user_ops as _gen_user_ops

# go/tf-wildcard-import
from tensorflow.python.ops.gen_user_ops import *  # pylint: disable=wildcard-import

from tensorflow.python.framework import ops
from tensorflow.python.ops import common_shapes
from tensorflow.python.ops import io_ops

class RedisReader(io_ops.ReaderBase) :

	def __init__(self, name=None):
        	rr = _gen_user_ops.redis_reader(name=name)
        	super(RedisReader, self).__init__(rr)	

ops.NotDifferentiable(""RedisReader"")
```"
14107,TensorFlow 1.4.0 takes more resources and is slower on GPU and CPU,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: https://github.com/tkuanlun350/Tensorflow-SegNet
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 7 x64
- **TensorFlow installed from (source or binary)**:  https://pypi.python.org/pypi/tensorflow-gpu/1.4.0rc1
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 3.5
- **CUDA/cuDNN version**:  Cuda release 8.0, V8.0.60. cuDNN 6.
- **GPU model and memory**:  NVIDIA P4 
- **Exact command to reproduce**:   `c:\python35\python3 main.py --log_dir=./logs --image_dir={image dir} --val_dir= {validation dir} --batch_size=15 --training=True`

### Describe the problem
Under 1.3.0 I was able to use a batch size of {15, put your max batch size here} for training.  Under 1.4.0 I get Resource Exhausted errors for that batch size.  So use of GPU resources is going up.  Not the right direction.

For me here are the performance effects:

- TensorFlow GPU 1.3.0: 9.8 images/sec for batch size: 15
- TensorFlow GPU 1.4.0:  Can't do batch size: 15. 7.8 images/sec for batch size: 12

### Source code / logs
[tf_bug2.txt](https://github.com/tensorflow/tensorflow/files/1428590/tf_bug2.txt)
"
14105,tf.reshape() fails for shapes containing non-32 bit precision TF integer types,"**Environment**: TensorFlow v1.3.0-rc2-20-g0787eee 1.3.0 running on Mac OS X (v10.12.6)

**Issue**:
Function `tensorflow.reshape()` works when provided a list-based shape containing `tf.int32`; but, fails for, e.g., `tf.int16` and `tf.int64` with error message `TypeError: List of Tensors when single Tensor expected`.

**Example**:
```
import tensorflow as tf
src = tf.constant(list(range(32)))
for dtype in ['int32', 'int64', 'int16']:
	print(""Calling tf.reshape using 'tf.{:s}'"".format(dtype))
	tf.reshape(src, [tf.cast(16, dtype), 2])
```"
14104,tf.scatter_add causes error in loop,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, it's below.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOSX
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.3.0-rc2-20-g0787eee 1.3.0
- **Python version**:  3.5
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: no CUDA
- **GPU model and memory**: no GPU
- **Exact command to reproduce**:

### Describe the problem
I found very strange behavior of tf.scatter_add: I created a tf.while_loop that creates a Tensor wrapped inside a tf.Variable. If I don't add something to the Variable outside the loop, tensorflow causes an error telling me that the Variable is not mutable.

I asked the on StackOverflow and was told to create a bug report.
https://stackoverflow.com/questions/46935216/tf-scatter-add-causes-error-in-loop?noredirect=1#comment80914069_46935216

Uncommenting the commented line removes the error. But I don't think this is intended behavior.

### Source code / logs
import tensorflow as tf        

m = 25
batch_num = 32
num_bus = 50

C = tf.zeros((m, batch_num, num_bus, m),tf.float64)
C = tf.Variable(C)

c = tf.ones((batch_num, num_bus, m), tf.float64)
#C = tf.scatter_add(C,0,c)

k = tf.constant(1)

stop_cond = lambda k,C: k<m

def construct_C(k, C):
    upd_c = c+1
    C = tf.scatter_add(C,k,upd_c)
    return k+1,C

k,C = tf.while_loop(stop_cond,construct_C, (k,C))

sess = tf.Session()
sess.run(tf.global_variables_initializer())
C1 = sess.run(C)
"
14101,Computing gradients within tf.while_loop,"I am posting this here because [a similar question on stackoverflow](https://stackoverflow.com/questions/42313788/how-to-do-opt-compute-gradients-multiple-times-in-single-sess-run) is still unanswered, so I suspect it might be a bug. 

Adding gradient ops within a tf.while_loop for computing gradients of loop variables w.r.t external variables results in an error. 

Program reproducing the error:
```
import numpy as np
import tensorflow as tf
tf.reset_default_graph()
F = lambda x: tf.cumsum(x)
G = lambda x: x[-1]
H = lambda x: x
encoder_emb_inp = tf.placeholder(dtype=tf.float32, shape=[4])
encoder_outputs = F(encoder_emb_inp)
decoder_initial_state = G(encoder_outputs)
decoder_initial_output = H(decoder_initial_state)
def cond(time, unused_state, unused_output):
    return tf.less(time, 3)

def body(time, state, inputs):
    step = lambda s, i: (tf.multiply(s,s), tf.multiply(s,i))
    (next_state, next_output) = step(state, inputs)
    next_grads = tf.gradients(next_output, decoder_initial_state)
    tf.Print(next_grads, next_grads)
    return (time + 1, next_state, next_output)

initial_time = tf.constant(0, dtype=tf.int32)


final_time, final_state, final_outputs = tf.while_loop(cond, body, loop_vars = [initial_time, decoder_initial_state, decoder_initial_output])
```
Error message: 
```
<ipython-input-126-5205901211cc> in body(time, state, inputs)
      6     (next_state, next_output) = step(state, inputs)
      7 #    next_grads = tf.gradients(next_output, state)
----> 8     next_grads = tf.gradients(next_output, decoder_initial_state)
      9     tf.Print(next_grads, next_grads)
     10     return (time + 1, next_state, next_output)

/home/pramodkm/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.pyc in gradients(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients)
    591                 out_grads[i] = loop_state.ZerosLike(op, i)
    592               else:
--> 593                 out_grads[i] = control_flow_ops.ZerosLikeOutsideLoop(op, i)
    594           with ops.name_scope(op.name + ""_grad""):
    595             # pylint: disable=protected-access

/home/pramodkm/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.pyc in ZerosLikeOutsideLoop(op, index)
   1342     if op_ctxt:
   1343       # We are in a cond context. Use a switch to create zeros only when needed.
-> 1344       pred = op_ctxt.pred
   1345       branch = op_ctxt.branch
   1346       switch_val = switch(op.inputs[0], pred)[1 - branch]

AttributeError: 'WhileContext' object has no attribute 'pred'
```
I am using tf-nightly-gpu 1.5.0-dev20171026

Thanks!"
14097,how can i get a specific version of tf,"## platform
raspbian 8.0

## problem
I need this specific release of tensorflow... and does anyone have the repository of that version?
it needs to be a source file.. because of some specific situation and some difficulties that hard to solve, I have to compile it from source and get a consequence similar to `git clone --recurse-submodules https://github.com/tensorflow/tensorflow.git` but in the version of 1.1.0

**related:**
https://github.com/samjabrahams/tensorflow-on-raspberry-pi/blob/master/GUIDE.md
after bazel build in this guidance, the contributor gave the command like this:
`sudo pip install /tmp/tensorflow_pkg/tensorflow-1.1.0-cp27-none-linux_armv7l.whl `
I don't know whether this command will have some influence.. but an release can adapt to this command will be ideal...

many thx!"
14096,Unable to use NeonDepthwiseConv2dNativeOp ,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
14095,matrix_triangular_solve has broken docstring,"### System information
not applicable (regards documentation)

### Describe the problem
The docstring of matrix_triangular_solve is not clear, see https://www.tensorflow.org/api_docs/python/tf/matrix_triangular_solve. There are formatting issues, but moreover, it is not immediately clear what the effect of `adjoint=True` is. It would be helpful to describe the effect using linear algebra notation.

### Source code / logs
not applicable (regards documentation)"
14093,Error: E tensorflow/core/common_runtime/direct_session.cc:138] Internal: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_INVALID_DEVICE,"Hi, I am working on a remote machine with many GPU cards that has CUDA v8.0.61 and Cudnn 5.1.10 installed. Upgrading these is not possible because of permission rights. In my own environment I installed TensorFlow version 1.2.1, but I get the following error when launching a `Session()`:

```
import tensorflow as tf
sess=tf.Session()
2017-10-30 13:48:47.652605: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-10-30 13:48:47.652665: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-10-30 13:48:47.652680: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-10-30 13:48:47.652694: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-10-30 13:48:47.652708: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-10-30 13:48:47.930480: E tensorflow/core/common_runtime/direct_session.cc:138] Internal: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_INVALID_DEVICE
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/user/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1292, in __init__
    super(Session, self).__init__(target, graph, config=config)
  File ""/home/user/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 562, in __init__
    self._session = tf_session.TF_NewDeprecatedSession(opts, status)
  File ""/home/user/anaconda2/lib/python2.7/contextlib.py"", line 24, in __exit__
    self.gen.next()
  File ""/home/user/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/errors_impl.py"", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InternalError: Failed to create session.'
```

The output when calling `nvidia-smi` is

```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 375.51                 Driver Version: 375.51                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K80           Off  | 0000:06:00.0     Off |                    0 |
| N/A   52C    P0    61W / 149W |     65MiB / 11439MiB |      0%   E. Process |
+-------------------------------+----------------------+----------------------+
|   1  Tesla K80           Off  | 0000:07:00.0     Off |                    0 |
| N/A   40C    P0    76W / 149W |     65MiB / 11439MiB |      0%   E. Process |
+-------------------------------+----------------------+----------------------+
|   2  Tesla K80           Off  | 0000:0A:00.0     Off |                    0 |
| N/A   46C    P0    60W / 149W |     65MiB / 11439MiB |      0%   E. Process |
+-------------------------------+----------------------+----------------------+
|   3  Tesla K80           Off  | 0000:0B:00.0     Off |                    0 |
| N/A   37C    P0    74W / 149W |     65MiB / 11439MiB |      0%   E. Process |
+-------------------------------+----------------------+----------------------+
|   4  Tesla K80           Off  | 0000:10:00.0     Off |                    0 |
| N/A   44C    P0    59W / 149W |     65MiB / 11439MiB |      0%   E. Process |
+-------------------------------+----------------------+----------------------+
|   5  Tesla K80           Off  | 0000:11:00.0     Off |                    0 |
| N/A   33C    P0    75W / 149W |     65MiB / 11439MiB |      0%   E. Process |
+-------------------------------+----------------------+----------------------+
|   6  Tesla K80           Off  | 0000:14:00.0     Off |                    0 |
| N/A   43C    P0    58W / 149W |     65MiB / 11439MiB |      0%   E. Process |
+-------------------------------+----------------------+----------------------+
|   7  Tesla K80           Off  | 0000:15:00.0     Off |                    0 |
| N/A   33C    P0    73W / 149W |     65MiB / 11439MiB |      0%   E. Process |
+-------------------------------+----------------------+----------------------+
|   8  Tesla K80           Off  | 0000:87:00.0     Off |                    0 |
| N/A   35C    P0    58W / 149W |     65MiB / 11439MiB |      0%   E. Process |
+-------------------------------+----------------------+----------------------+
|   9  Tesla K80           Off  | 0000:88:00.0     Off |                    0 |
| N/A   31C    P0    74W / 149W |     65MiB / 11439MiB |      0%   E. Process |
+-------------------------------+----------------------+----------------------+
|  10  Tesla K80           Off  | 0000:8B:00.0     Off |                    0 |
| N/A   51C    P0   142W / 149W |   8361MiB / 11439MiB |    100%   E. Process |
+-------------------------------+----------------------+----------------------+
|  11  Tesla K80           Off  | 0000:8C:00.0     Off |                    0 |
| N/A   31C    P0    86W / 149W |     86MiB / 11439MiB |     48%   E. Process |
+-------------------------------+----------------------+----------------------+
|  12  Tesla K80           Off  | 0000:91:00.0     Off |                    0 |
| N/A   51C    P0   143W / 149W |   8330MiB / 11439MiB |     99%   E. Process |
+-------------------------------+----------------------+----------------------+
|  13  Tesla K80           Off  | 0000:92:00.0     Off |                    0 |
| N/A   23C    P8    30W / 149W |      2MiB / 11439MiB |      0%   E. Process |
+-------------------------------+----------------------+----------------------+
|  14  Tesla K80           Off  | 0000:95:00.0     Off |                    0 |
| N/A   25C    P8    28W / 149W |      2MiB / 11439MiB |      0%   E. Process |
+-------------------------------+----------------------+----------------------+
|  15  Tesla K80           Off  | 0000:96:00.0     Off |                    0 |
| N/A   23C    P8    30W / 149W |      2MiB / 11439MiB |      0%   E. Process |
+-------------------------------+----------------------+----------------------+
```
                                                                               
Any ideas on the error `E tensorflow/core/common_runtime/direct_session.cc:138] Internal: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_INVALID_DEVICE`? Running `tf.Session()` multiple times results in the same error but will increase the number behind ""ordinal"".
"
14092,There is a Error about: Too many include files,"when i try to built example/label_image/main.cc . Visual studio will throw an error :c1014 too many include files . Click the message , this error point to a file of Tensor.  can anybody tell me how to fix this problem.thank you.
This is my first time to write English litter , and i am not good at english , wish you can understood what i said . lol "
14089,Unable to download the training images from curl http://download.tensorflow.org/example_images/flower_photos.tgz,"![image](https://user-images.githubusercontent.com/16485968/32168606-5394209a-bd93-11e7-91a2-003a3f08e743.png)
"
14087,tf.contrib.boosted_trees cannot be used in 1.4.0rc1,"TF Version: 1.4.0rc1
Py Version: 2.7
OS: Mac OS

```python
import tensorflow as tf
from tensorflow.contrib.boosted_trees.estimator_batch.estimator import GradientBoostedDecisionTreeClassifier
from tensorflow.contrib.boosted_trees.proto import learner_pb2

learner_config = learner_pb2.LearnerConfig()

learner_config.learning_rate_tuner.fixed.learning_rate = 0.1
learner_config.num_classes = 10
learner_config.regularization.l1 = 0.0
learner_config.regularization.l2 = 1.0 / 1000
learner_config.constraints.max_tree_depth = 4
learner_config.growing_mode = learner_pb2.LearnerConfig.LAYER_BY_LAYER
learner_config.multi_class_strategy = (learner_pb2.LearnerConfig.DIAGONAL_HESSIAN)

estimator = GradientBoostedDecisionTreeClassifier(
    learner_config = learner_config,
    n_classes = 10,
    examples_per_layer = 1000,
    num_trees = 10,
    center_bias = False)

(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()
X_train = (X_train / 255.).reshape(-1, 28*28).astype(np.float32)
y_train = y_train.astype(np.int32)

estimator.fit(input_fn=tf.estimator.inputs.numpy_input_fn(
    x={'features':X_train}, y=y_train, batch_size=128, num_epochs=1, shuffle=True))
```

A minimal example to train on mnist dataset throws error:
```
Traceback (most recent call last):
  File ""boost_tree.py"", line 29, in <module>
    x={'features':X_train}, y=y_train, batch_size=128, num_epochs=1, shuffle=True))
  File ""/Users/zhedongzheng/pyenv/py2.7/tf_1.4/tf_1.4/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py"", line 316, in new_func
    return func(*args, **kwargs)
  File ""/Users/zhedongzheng/pyenv/py2.7/tf_1.4/tf_1.4/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 480, in fit
    loss = self._train_model(input_fn=input_fn, hooks=hooks)
  File ""/Users/zhedongzheng/pyenv/py2.7/tf_1.4/tf_1.4/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 986, in _train_model
    model_fn_ops = self._get_train_ops(features, labels)
  File ""/Users/zhedongzheng/pyenv/py2.7/tf_1.4/tf_1.4/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 1202, in _get_train_ops
    return self._call_model_fn(features, labels, model_fn_lib.ModeKeys.TRAIN)
  File ""/Users/zhedongzheng/pyenv/py2.7/tf_1.4/tf_1.4/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 1166, in _call_model_fn
    model_fn_results = self._model_fn(features, labels, **kwargs)
  File ""/Users/zhedongzheng/pyenv/py2.7/tf_1.4/tf_1.4/lib/python2.7/site-packages/tensorflow/contrib/boosted_trees/estimator_batch/model.py"", line 116, in model_builder
    logits=logits)
  File ""/Users/zhedongzheng/pyenv/py2.7/tf_1.4/tf_1.4/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py"", line 1064, in create_model_fn_ops
    enable_centered_bias=self._enable_centered_bias)
  File ""/Users/zhedongzheng/pyenv/py2.7/tf_1.4/tf_1.4/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py"", line 648, in _create_model_fn_ops
    batch_size, loss_fn, weight_tensor)
  File ""/Users/zhedongzheng/pyenv/py2.7/tf_1.4/tf_1.4/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py"", line 1923, in _train_op
    train_op = train_op_fn(loss)
  File ""/Users/zhedongzheng/pyenv/py2.7/tf_1.4/tf_1.4/lib/python2.7/site-packages/tensorflow/contrib/boosted_trees/estimator_batch/model.py"", line 105, in _train_op_fn
    update_op = gbdt_model.train(loss, predictions_dict, labels)
  File ""/Users/zhedongzheng/pyenv/py2.7/tf_1.4/tf_1.4/lib/python2.7/site-packages/tensorflow/contrib/boosted_trees/python/training/functions/gbdt_batch.py"", line 543, in train
    hessian_list = self._diagonal_hessian(gradients, predictions)
  File ""/Users/zhedongzheng/pyenv/py2.7/tf_1.4/tf_1.4/lib/python2.7/site-packages/tensorflow/contrib/boosted_trees/python/training/functions/gbdt_batch.py"", line 845, in _diagonal_hessian
    aggregation_method=None)
  File ""/Users/zhedongzheng/pyenv/py2.7/tf_1.4/tf_1.4/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py"", line 581, in gradients
    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))
  File ""/Users/zhedongzheng/pyenv/py2.7/tf_1.4/tf_1.4/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py"", line 353, in _MaybeCompile
    return grad_fn()  # Exit early
  File ""/Users/zhedongzheng/pyenv/py2.7/tf_1.4/tf_1.4/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py"", line 581, in <lambda>
    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))
  File ""/Users/zhedongzheng/pyenv/py2.7/tf_1.4/tf_1.4/lib/python2.7/site-packages/tensorflow/python/ops/array_grad.py"", line 352, in _PreventGradientGrad
    ""Gradient explicitly disabled. Reason: %s"" % op.get_attr(""message""))
LookupError: Gradient explicitly disabled. Reason: Currently there is no way to take the second derivative of sparse_softmax_cross_entropy_with_logits due to the fused implementation's interaction with tf.gradients()
```"
14085,How can I run a Tensorflow file on GPUs? Error: Cannot assign a device for operation 'eval_step',"Do you have any idea how can I run [""eval_image_classifier.py""][1] on GPUs? Should I change any functions or do any modifications? Or whether there exist any other specific functions for evaluation on GPUs?

I can already run [""train_image_classifier.py""][2] on GPUs because of having the associated flag for switching between CPU and GPU:

    tf.app.flags.DEFINE_boolean('clone_on_cpu', False,
                            'Use CPUs to deploy clones.')


I did try to add the same line to `eval_image_classifier.py`, but it had no effect. I'm using Python 2.7.13 and Tensorflow 1.3.0 .

    from __future__ import absolute_import
    from __future__ import division
    from __future__ import print_function
    import math
    import tensorflow as tf
    from deployment import model_deploy
    from datasets import dataset_factory
    from nets import nets_factory
    from preprocessing import preprocessing_factory
    slim = tf.contrib.slim
    
    
    tf.app.flags.DEFINE_integer(
        'batch_size', 32, 'The number of samples in each batch.')
    
    tf.app.flags.DEFINE_integer(
        'max_num_batches', None,
        'Max number of batches to evaluate by default use all.')
    
    tf.app.flags.DEFINE_string(
        'master', '', 'The address of the TensorFlow master to use.')
    
    tf.app.flags.DEFINE_string(
        'checkpoint_path', '...',
        'The directory where the model was written to or an absolute path to a '
        'checkpoint file.')
    
    tf.app.flags.DEFINE_string(
        'eval_dir', '...',
        'Directory where the results are saved to.')
    
    tf.app.flags.DEFINE_integer('num_clones', 1,
                                'Number of model clones to deploy.')
    
    tf.app.flags.DEFINE_boolean('clone_on_cpu', False,
                                'Use CPUs to deploy clones.')
    
    tf.app.flags.DEFINE_integer('worker_replicas', 1, 'Number of worker replicas.')
    
    tf.app.flags.DEFINE_integer(
        'num_readers', 4,
        'The number of parallel readers that read data from the dataset.')
    
    tf.app.flags.DEFINE_integer(
        'num_ps_tasks', 0,
        'The number of parameter servers. If the value is 0, then the parameters '
        'are handled locally by the worker.')
    
    
    tf.app.flags.DEFINE_integer(
        'num_preprocessing_threads', 4,
        'The number of threads used to create the batches.')
    
    tf.app.flags.DEFINE_string(
        'dataset_name', '...', 'The name of the dataset to load.')
    
    tf.app.flags.DEFINE_string(
        'dataset_split_name', 'validation', 'The name of the train/test split.')
    
    tf.app.flags.DEFINE_string(
        'dataset_dir', '...', 
        'The directory where the dataset files are stored.')
    
    tf.app.flags.DEFINE_integer(
        'labels_offset', 0,
        'An offset for the labels in the dataset. This flag is primarily used to '
        'evaluate the VGG and ResNet architectures which do not use a background '
        'class for the ImageNet dataset.')
    
    tf.app.flags.DEFINE_string(
        'model_name', 'densenet161', 'The name of the architecture to evaluate.')
    
    tf.app.flags.DEFINE_string(
        'preprocessing_name', None, 'The name of the preprocessing to use. If left '
        'as `None`, then the model_name flag is used.')
    
    tf.app.flags.DEFINE_float(
        'moving_average_decay', None,
        'The decay to use for the moving average.'
        'If left as None, then moving averages are not used.')
    
    tf.app.flags.DEFINE_integer(
        'eval_image_size', None, 'Eval image size')
    
    FLAGS = tf.app.flags.FLAGS
    
    
    def main(_):
      if not FLAGS.dataset_dir:
        raise ValueError('You must supply the dataset directory with --dataset_dir')
        
        #######################
        # Config model_deploy #
        #######################
      tf.logging.set_verbosity(tf.logging.INFO)
      with tf.Graph().as_default():
          
        deploy_config = model_deploy.DeploymentConfig(
          num_clones=FLAGS.num_clones,
          clone_on_cpu=FLAGS.clone_on_cpu,
          #replica_id=FLAGS.task,
          num_replicas=FLAGS.worker_replicas,
          num_ps_tasks=FLAGS.num_ps_tasks)
          
        # Create global_step
        with tf.device(deploy_config.variables_device()):
          tf_global_step = slim.create_global_step()
        ######################
        # Select the dataset #
        ######################
        dataset = dataset_factory.get_dataset(
            FLAGS.dataset_name, FLAGS.dataset_split_name, FLAGS.dataset_dir)
    
        ####################
        # Select the model #
        ####################
        network_fn = nets_factory.get_network_fn(
            FLAGS.model_name,
            num_classes=(dataset.num_classes - FLAGS.labels_offset),
            is_training=False)
    
        ##############################################################
        # Create a dataset provider that loads data from the dataset #
        ##############################################################
        with tf.device(deploy_config.inputs_device()):
            provider = slim.dataset_data_provider.DatasetDataProvider(
                dataset,
                num_readers=FLAGS.num_readers,
                shuffle=False,
                common_queue_capacity=2 * FLAGS.batch_size,
                common_queue_min=FLAGS.batch_size)
            [image, label] = provider.get(['image', 'label'])
            label -= FLAGS.labels_offset
    
        #####################################
        # Select the preprocessing function #
        #####################################
        preprocessing_name = FLAGS.preprocessing_name or FLAGS.model_name
        image_preprocessing_fn = preprocessing_factory.get_preprocessing(
            preprocessing_name,
            is_training=False)
    
        eval_image_size = FLAGS.eval_image_size or network_fn.default_image_size
    
        image = image_preprocessing_fn(image, eval_image_size, eval_image_size)
    
        images, labels = tf.train.batch(
            [image, label],
            batch_size=FLAGS.batch_size,
            num_threads=FLAGS.num_preprocessing_threads,
            capacity=5 * FLAGS.batch_size)
        batch_queue = slim.prefetch_queue.prefetch_queue(
            [images, labels], capacity=2 * deploy_config.num_clones)
        ####################
        # Define the model #
        ####################
        def clone_fn(batch_queue):
          """"""Allows data parallelism by creating multiple clones of network_fn.""""""
          with tf.device(deploy_config.inputs_device()):
            images, labels = batch_queue.dequeue()
          logits, end_points = network_fn(images)
          logits = tf.squeeze(logits)
    
          #############################
          # Specify the loss function #
          #############################
          if 'AuxLogits' in end_points:
            tf.losses.mean_squared_error(
                predictions=end_points['AuxLogits'], labels=labels, weights=0.4, scope='aux_loss')
          tf.losses.mean_squared_error(
              predictions=logits, labels=labels, weights=1.0)
          return end_points
    
        #clones = model_deploy.create_clones(deploy_config, clone_fn, [batch_queue])
        #first_clone_scope = deploy_config.clone_scope(0)
        ####################
        # Define the model #
        ####################
        logits, _ = network_fn(images)
    
        if FLAGS.moving_average_decay:
          variable_averages = tf.train.ExponentialMovingAverage(
              FLAGS.moving_average_decay, tf_global_step)
          variables_to_restore = variable_averages.variables_to_restore(
              slim.get_model_variables())
          variables_to_restore[tf_global_step.op.name] = tf_global_step
        else:
          variables_to_restore = slim.get_variables_to_restore()
    
        logits = tf.squeeze(logits)
    
        # Define the metrics:
        predictions = logits
    
        names_to_values, names_to_updates = slim.metrics.aggregate_metric_map({
            'Accuracy': tf.metrics.root_mean_squared_error(predictions, labels),
            'Recall_5': slim.metrics.streaming_recall(
                logits, labels),
        })
    
        # Print the summaries to screen.
        print_ops = []
        summary_ops = []
        for name, value in names_to_values.items():
          summary_name = 'eval/%s' % name
          op = tf.summary.scalar(summary_name, value, collections=[])
          op = tf.Print(op, [value], summary_name)
          summary_ops.append(op)
          print_ops.append(tf.Print(value, [value], summary_name))
          tf.add_to_collection(tf.GraphKeys.SUMMARIES, op)
    
        # TODO(sguada) use num_epochs=1
        if FLAGS.max_num_batches:
          num_batches = FLAGS.max_num_batches
        else:
          # This ensures that we make a single pass over all of the data.
          num_batches = math.ceil(dataset.num_samples / float(FLAGS.batch_size))
    
        if tf.gfile.IsDirectory(FLAGS.checkpoint_path):
            if tf.train.latest_checkpoint(FLAGS.checkpoint_path):
                checkpoint_path = tf.train.latest_checkpoint(FLAGS.checkpoint_path)
            else:
                checkpoint_path = FLAGS.checkpoint_path
    
        eval_interval_secs = 6
        
        tf.logging.info('Evaluating %s' % checkpoint_path)
    
        slim.evaluation.evaluation_loop(
            master=FLAGS.master,
            checkpoint_dir=checkpoint_path,
            logdir=FLAGS.eval_dir,
            num_evals=num_batches,
            eval_op=list(names_to_updates.values()) + print_ops,
            variables_to_restore=variables_to_restore,
            eval_interval_secs = eval_interval_secs )
    if __name__ == '__main__':
      tf.app.run()

I tried to use some code like Tensorflow tutorial as well:
    
    # Creates a graph.
    with tf.device('/gpu:2'):
    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')
    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')
    c = tf.matmul(a, b)
    # Creates a session with allow_soft_placement and log_device_placement set to True.
    sess = tf.Session(config=tf.ConfigProto(
             allow_soft_placement=True, log_device_placement=True))
    # Runs the op.
    print(sess.run(c))

I modified the code in this way:

    
    from __future__ import absolute_import
    from __future__ import division
    from __future__ import print_function
    
    import math
    import tensorflow as tf
    
    from datasets import dataset_factory
    from nets import nets_factory
    from preprocessing import preprocessing_factory
    
    slim = tf.contrib.slim
    
    tf.app.flags.DEFINE_integer(
        'batch_size', 32, 'The number of samples in each batch.')
    
    tf.app.flags.DEFINE_integer(
        'max_num_batches', None,
        'Max number of batches to evaluate by default use all.')
    
    tf.app.flags.DEFINE_string(
        'master', '', 'The address of the TensorFlow master to use.')
    
    tf.app.flags.DEFINE_string(
        'checkpoint_path', '...',
        'The directory where the model was written to or an absolute path to a '
        'checkpoint file.')
    
    tf.app.flags.DEFINE_string(
        'eval_dir', '...',
        'Directory where the results are saved to.')
    
    tf.app.flags.DEFINE_integer(
        'num_preprocessing_threads', 4,
        'The number of threads used to create the batches.')
    
    tf.app.flags.DEFINE_string(
        'dataset_name', '...', 'The name of the dataset to load.')
    
    tf.app.flags.DEFINE_string(
        'dataset_split_name', 'validation', 'The name of the train/test split.')
    
    tf.app.flags.DEFINE_string(
        'dataset_dir', '...', 
        'The directory where the dataset files are stored.')
    
    tf.app.flags.DEFINE_integer(
        'labels_offset', 0,
        'An offset for the labels in the dataset. This flag is primarily used to '
        'evaluate the VGG and ResNet architectures which do not use a background '
        'class for the ImageNet dataset.')
    
    tf.app.flags.DEFINE_string(
        'model_name', 'densenet161', 'The name of the architecture to evaluate.')
    
    tf.app.flags.DEFINE_string(
        'preprocessing_name', None, 'The name of the preprocessing to use. If left '
        'as `None`, then the model_name flag is used.')
    
    tf.app.flags.DEFINE_float(
        'moving_average_decay', None,
        'The decay to use for the moving average.'
        'If left as None, then moving averages are not used.')
    
    tf.app.flags.DEFINE_integer(
        'eval_image_size', None, 'Eval image size')
    
    FLAGS = tf.app.flags.FLAGS
    
    # Initialize all global and local variables
    init = tf.group(tf.global_variables_initializer(),
                       tf.local_variables_initializer())
    
    def main(_):
      if not FLAGS.dataset_dir:
        raise ValueError('You must supply the dataset directory with --dataset_dir')
    
      tf.logging.set_verbosity(tf.logging.INFO)
      
      sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,
                                              log_device_placement=True))
      
      with tf.Graph().as_default(), tf.device('/gpu:0'):
          
        sess.run(init)
        tf_global_step = slim.get_or_create_global_step()
    
        ######################
        # Select the dataset #
        ######################
        dataset = dataset_factory.get_dataset(
            FLAGS.dataset_name, FLAGS.dataset_split_name, FLAGS.dataset_dir)
    
        ####################
        # Select the model #
        ####################
        network_fn = nets_factory.get_network_fn(
            FLAGS.model_name,
            num_classes=(dataset.num_classes - FLAGS.labels_offset),
            is_training=False)
    
        ##############################################################
        # Create a dataset provider that loads data from the dataset #
        ##############################################################
        provider = slim.dataset_data_provider.DatasetDataProvider(
            dataset,
            shuffle=False,
            common_queue_capacity=2 * FLAGS.batch_size,
            common_queue_min=FLAGS.batch_size)
        [image, label] = provider.get(['image', 'label'])
        label -= FLAGS.labels_offset
    
        #####################################
        # Select the preprocessing function #
        #####################################
        preprocessing_name = FLAGS.preprocessing_name or FLAGS.model_name
        image_preprocessing_fn = preprocessing_factory.get_preprocessing(
            preprocessing_name,
            is_training=False)
    
        eval_image_size = FLAGS.eval_image_size or network_fn.default_image_size
    
        image = image_preprocessing_fn(image, eval_image_size, eval_image_size)
    
        images, labels = tf.train.batch(
            [image, label],
            batch_size=FLAGS.batch_size,
            num_threads=FLAGS.num_preprocessing_threads,
            capacity=5 * FLAGS.batch_size)
    
        ####################
        # Define the model #
        ####################
        logits, _ = network_fn(images)
    
        if FLAGS.moving_average_decay:
          variable_averages = tf.train.ExponentialMovingAverage(
              FLAGS.moving_average_decay, tf_global_step)
          variables_to_restore = variable_averages.variables_to_restore(
              slim.get_model_variables())
          variables_to_restore[tf_global_step.op.name] = tf_global_step
        else:
          variables_to_restore = slim.get_variables_to_restore()
    
        logits = tf.squeeze(logits)
    
        # Define the metrics:
        predictions = logits

        names_to_values, names_to_updates = slim.metrics.aggregate_metric_map({
            'Accuracy': tf.metrics.root_mean_squared_error(predictions, labels),
            'Recall_5': slim.metrics.streaming_recall(
                logits, labels),
        })
    
        # Print the summaries to screen.
        print_ops = []
        summary_ops = []
        for name, value in names_to_values.items():
          summary_name = 'eval/%s' % name
          op = tf.summary.scalar(summary_name, value, collections=[])
          op = tf.Print(op, [value], summary_name)
          summary_ops.append(op)
          print_ops.append(tf.Print(value, [value], summary_name))
          tf.add_to_collection(tf.GraphKeys.SUMMARIES, op)
          
        # TODO(sguada) use num_epochs=1
        if FLAGS.max_num_batches:
          num_batches = FLAGS.max_num_batches
        else:
          # This ensures that we make a single pass over all of the data.
          num_batches = math.ceil(dataset.num_samples / float(FLAGS.batch_size))
    
        if tf.gfile.IsDirectory(FLAGS.checkpoint_path):
            if tf.train.latest_checkpoint(FLAGS.checkpoint_path):
                checkpoint_path = tf.train.latest_checkpoint(FLAGS.checkpoint_path)
            else:
                checkpoint_path = FLAGS.checkpoint_path
    
        #print(checkpoint_path)
        eval_interval_secs = 6
        
        tf.logging.info('Evaluating %s' % checkpoint_path)
    
        slim.evaluation.evaluation_loop(
            master=FLAGS.master,
            checkpoint_dir=checkpoint_path,
            logdir=FLAGS.eval_dir,
            num_evals=num_batches,
            eval_op=list(names_to_updates.values()) + print_ops,
            variables_to_restore=variables_to_restore,
            eval_interval_secs = eval_interval_secs )
    
    
    if __name__ == '__main__':
      tf.app.run()

When I run this code, I face this error:

        Traceback (most recent call last):
      File ""/home/zgholami/test1/GZ_Project/GZ_DenseNet_TF-slim/eval_image_classifier.py"", line 210, in <module>
        tf.app.run()
      File ""/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 48, in run
        _sys.exit(main(_sys.argv[:1] + flags_passthrough))
      File ""/home/zgholami/test1/GZ_Project/GZ_DenseNet_TF-slim/eval_image_classifier.py"", line 206, in main
        eval_interval_secs = 60 )
      File ""/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/contrib/slim/python/slim/evaluation.py"", line 296, in evaluation_loo
    p
        timeout=timeout)
      File ""/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/contrib/training/python/training/evaluation.py"", line 447, in evalua
    te_repeatedly
        session_creator=session_creator, hooks=hooks) as session:
      File ""/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 668, in __init__
        stop_grace_period_secs=stop_grace_period_secs)
      File ""/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 490, in __init__
        self._sess = _RecoverableSession(self._coordinated_creator)
      File ""/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 842, in __init__
        _WrappedSession.__init__(self, self._create_session())
      File ""/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 847, in _create_session
        return self._sess_creator.create_session()
      File ""/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 551, in create_session
        self.tf_sess = self._session_creator.create_session()
      File ""/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 425, in create_session
        init_fn=self._scaffold.init_fn)
      File ""/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 273, in prepare_session
        config=config)
      File ""/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 189, in _restore_checkpoin
    t
        saver.restore(sess, checkpoint_filename_with_path)
      File ""/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1560, in restore
        {self.saver_def.filename_tensor_name: save_path})
      File ""/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 895, in run
        run_metadata_ptr)
      File ""/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1124, in _run
        feed_dict_tensor, options, run_metadata)
      File ""/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1321, in _do_run
        options, run_metadata)
      File ""/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1340, in _do_call
        raise type(e)(node_def, op, message)
    tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation 'eval_step': Could not satisfy explicit device s
    pecification '/device:GPU:0' because no supported kernel for GPU devices is available.
    Colocation Debug Info:
    Colocation group had the following types and devices: 
    Const: GPU CPU 
    AssignAdd: CPU 
    VariableV2: CPU 
    Identity: GPU CPU 
    Assign: CPU 
    IsVariableInitialized: CPU 
    	 [[Node: eval_step = VariableV2[_class=[""loc:@eval_step""], container="""", dtype=DT_INT64, shape=[], shared_name="""", _device=""/device:GPU:0""]
    ()]]
    
    Caused by op u'eval_step', defined at:
      File ""/home/zgholami/test1/GZ_Project/GZ_DenseNet_TF-slim/eval_image_classifier.py"", line 210, in <module>
        tf.app.run()
      File ""/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 48, in run
        _sys.exit(main(_sys.argv[:1] + flags_passthrough))
      File ""/home/zgholami/test1/GZ_Project/GZ_DenseNet_TF-slim/eval_image_classifier.py"", line 206, in main
        eval_interval_secs = 60 )
      File ""/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/contrib/slim/python/slim/evaluation.py"", line 296, in evaluation_loo
    p
        timeout=timeout)
      File ""/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/contrib/training/python/training/evaluation.py"", line 410, in evalua
    te_repeatedly
        eval_step = get_or_create_eval_step()
      File ""/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/training/evaluation.py"", line 57, in _get_or_create_eval_step
        collections=[ops.GraphKeys.LOCAL_VARIABLES, ops.GraphKeys.EVAL_STEP])
      File ""/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 1065, in get_variable
        use_resource=use_resource, custom_getter=custom_getter)
      File ""/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 962, in get_variable
        use_resource=use_resource, custom_getter=custom_getter)
      File ""/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 367, in get_variable
        validate_shape=validate_shape, use_resource=use_resource)
      File ""/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 352, in _true_getter
        use_resource=use_resource)
      File ""/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 725, in _get_single_variable
        validate_shape=validate_shape)
      File ""/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/ops/variables.py"", line 199, in __init__
        expected_shape=expected_shape)
      File ""/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/ops/variables.py"", line 283, in _init_from_args
        name=name)
      File ""/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/ops/state_ops.py"", line 131, in variable_op_v2
        shared_name=shared_name)
      File ""/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/ops/gen_state_ops.py"", line 682, in _variable_v2
        name=name)
      File ""/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 767, in apply_op
        op_def=op_def)
      File ""/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2630, in create_op
        original_op=self._default_original_op, op_def=op_def)
      File ""/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1204, in __init__
        self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access
    
    InvalidArgumentError (see above for traceback): Cannot assign a device for operation 'eval_step': Could not satisfy explicit device specification '
    /device:GPU:0' because no supported kernel for GPU devices is available.
    Colocation Debug Info:
    Colocation group had the following types and devices: 
    Const: GPU CPU 
    AssignAdd: CPU 
    VariableV2: CPU 
    Identity: GPU CPU 
    Assign: CPU 
    IsVariableInitialized: CPU 
    	 [[Node: eval_step = VariableV2[_class=[""loc:@eval_step""], container="""", dtype=DT_INT64, shape=[], shared_name="""", _device=""/device:GPU:0""]
    ()]]
    
    ERROR:tensorflow:==================================
    Object was never used (type <class 'tensorflow.python.framework.ops.Tensor'>):
    <tf.Tensor 'report_uninitialized_variables_1/boolean_mask/Gather:0' shape=(?,) dtype=string>
    If you want to mark it as used call its ""mark_used()"" method.

  [1]: https://github.com/pudae/tensorflow-densenet/blob/master/eval_image_classifier.py
  [2]: https://github.com/pudae/tensorflow-densenet/blob/master/train_image_classifier.py
"
14084,Tensorflow hooks do not properly write events to HDFS,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Alpine Linux 3.6.2 (running with Docker)
- **TensorFlow installed from (source or binary)**: Binary (conda-forge)
- **TensorFlow version (use command below)**: 1.3.0
- **Python version**: 3.6.3
- **Bazel version (if compiling from source)**: - 
- **CUDA/cuDNN version**: -
- **GPU model and memory**: using CPU
- **Exact command to reproduce**: `CLASSPATH=$(${HADOOP_HOME}/bin/hadoop classpath --glob) jupyter notebook`

### Describe the problem
I am reading files from hdfs and also want to use hdfs as `model_dir` to store the tensorflow output. Reading and writing of the checkpoints works fine. However, the the events file just gets created, but it does not get updated with the evaluation events. 

When I kill the notebook then the output is written, but not in between. Changing the model directory to a local one solves this. Also adding an extra `SummarySaverHook` which points to a local directory did not help.

I am running my code using the instructions here: <https://www.tensorflow.org/deploy/hadoop>

### Source code / logs
I normally use an Estimator with a custom model function, but I reduced it to the following:

```python
import tensorflow as tf
import numpy

hdfs_namenode = 'hdfs://xx.xx.xx.xx:8020'
files = ['{}/data/part-00000-2a4cdbb2-f152-4503-9da8-cba63c7648fc-c000.csv'.format(hdfs_namenode)]

output_directory = '{}/tresults/'.format(hdfs_namenode)

feature_columns = [tf.feature_column.numeric_column(""x"", shape=[70])]

def input_function_training:
  ...
def input_function_evaluation:
  ...

def experiment_fn(run_config, hparams):
    estimator = tf.estimator.DNNClassifier(hidden_units=[4], 
        feature_columns=feature_columns,
        model_dir=output_directory, 
        n_classes=2,
        config=run_config)
    
    return tf.contrib.learn.Experiment(estimator=estimator, 
        train_input_fn=input_function_training, 
        eval_input_fn=input_function_evaluation)

tf.contrib.learn.learn_runner.run(experiment_fn,
    run_config=tf.contrib.learn.RunConfig(model_dir=output_directory,
        save_checkpoints_steps=10,
        save_checkpoints_secs=None,
        save_summary_steps=1))
```

The logs do not show any problems:

```
WARNING:tensorflow:RunConfig.uid (from tensorflow.contrib.learn.python.learn.estimators.run_config) is experimental and may change or be removed at any time, and without warning.
INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb30e032780>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {
  per_process_gpu_memory_fraction: 1.0
}
, '_tf_random_seed': None, '_save_summary_steps': 1, '_save_checkpoints_secs': None, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': 10, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'hdfs://xx.xx.xx.xx:8020/tresults/'}
WARNING:tensorflow:RunConfig.uid (from tensorflow.contrib.learn.python.learn.estimators.run_config) is experimental and may change or be removed at any time, and without warning.
WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:269: BaseMonitor.__init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.
Instructions for updating:
Monitors are deprecated. Please use tf.train.SessionRunHook.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Saving checkpoints for 1 into hdfs://xx.xx.xx.xx:8020/tresults/model.ckpt.
WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.
WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.
INFO:tensorflow:Starting evaluation at 2017-10-30-05:41:22
INFO:tensorflow:Restoring parameters fromhdfs://xx.xx.xx.xx:8020/tresults/model.ckpt-1
INFO:tensorflow:Evaluation [1/100]
...
INFO:tensorflow:Evaluation [100/100]
INFO:tensorflow:Finished evaluation at 2017-10-30-05:42:24
INFO:tensorflow:Saving dict for global step 1: accuracy = 0.46836, accuracy_baseline = 0.75205, auc = 0.697368, auc_precision_recall = 0.591545, average_loss = 0.692944, global_step = 1, label/mean = 0.24795, loss = 692.944, prediction/mean = 0.524391
INFO:tensorflow:Validation (step 1): accuracy = 0.46836, accuracy_baseline = 0.75205, auc = 0.697368, auc_precision_recall = 0.591545, average_loss = 0.692944, label/mean = 0.24795, loss = 692.944, prediction/mean = 0.524391, global_step = 1
INFO:tensorflow:loss = 42.1861, step = 1
INFO:tensorflow:Saving checkpoints for 11 into hdfs://xx.xx.xx.xx:8020/tresults/model.ckpt.
```"
14083,AssetFileDef is not updated when using Saved model builder.,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
Source
- **TensorFlow version (use command below)**:
Pulled from current master, but code is same at 1.4
- **Python version**: 
2.7
- **Bazel version (if compiling from source)**:
0.5.4
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:
-get latest tensorflow-serving
-add to mnist_saved_model.py
```
asset_path = tf.constant(""/tmp/asset.txt"", dtype=tf.string, name=""PreProcessingSettings"")
  tf.add_to_collection(tf.GraphKeys.ASSET_FILEPATHS, asset_path)
....
assets_collection = tf.get_collection(tf.GraphKeys.ASSET_FILEPATHS),
...
builder.save(as_text=True)
```
build mnist_saved_model.py
execute
observe that exported model meta_graph_defs do not have AssetFileDef populated

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
It seems that from the definition of [meta graph def](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/protobuf/meta_graph.proto)
that AssetFileDef should be populated, however instead the assets are just added to a collection... should it not be both?
It seems it should but it is not implemented. Would not be too hard to implement.

### Source code / logs
N/A"
14081,Feature Request: C++ gradient for Cast,"Implement the gradient for Cast in C++ so that it is available for TF_AddGradients.

This is the Python code that I believe would need to be ported:

https://github.com/tensorflow/tensorflow/blob/27767d8e9c1325979cf32ff5b81c10df9006fd57/tensorflow/python/ops/math_grad.py#L1109-L1120

Will be asking @bpiel for guidance if I get stuck!"
14080,@function.Defun lose input tensor shapes ,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NA
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS 10.12.5 (16F73)
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**:1.3.0
- **Python version**: 2.7.13
- **Bazel version (if compiling from source)**:NA
- **CUDA/cuDNN version**:NA
- **GPU model and memory**:NA
- **Exact command to reproduce**:
```
import  tensorflow as tf
import numpy as np
from tensorflow.python.framework import function
# Now let us see some property of @function of tf. It will make all its inputs loose ""shape""

@function.Defun(tf.float32, tf.float32)
def plus(A, B):

    result = A + B
    result.set_shape((5, 5))
    print result.get_shape()
    return result

def linear(A, B, C):
    D = plus(A, B) + C
    print D.get_shape()
    return D

# @function.Defun(
#     tf.float32, shape_func=lambda op: [op.inputs[0].get_shape()])
# def Foo(x):
#     print x.get_shape, 'see'
#     return x + 1.0

sess = tf.Session()
sess.run(tf.global_variables_initializer())
A = tf.constant(np.arange(25).reshape((5, 5)), dtype=tf.float32)
B = tf.ones((5, 5))
C = tf.ones((5, 5))
E = plus(A, B)
# d = Foo(tf.constant(2.0))
D = linear(A, B, C)
print sess.run(E)
print sess.run(D)
# print sess.run(d)
```

### Describe the problem
All tensors going through the decorated function lose their shapes, as well as the output tensor. Without this decoration, there is no problem.  btw, shape_fun seems doesn't work
"
14079,How to get difference or square between two tensor？,"I define two subnets that output the tensor of the same dimension use functional model. I want get difference between them. for example：tensor1 [1,2,3,4,5], tensor2 [1,1,1,1,1], output=tensor1 -tensor2 =
Can you tell me how to get difference between two tensor，or square of one tensor？
Thank you very much."
14075,Momentum SGD is very slow with large embedding layer,"Hi, I have an (256 col* 500000row) embedding layer in my model and I found that Momentum SGD is 10x slower than adam optimizer. When I printed the global variables using API :tf.global_variables(), I found a large Momentum  variable created by optimizer, does that means Momentum SGD have not  supported sparse update yet?"
14074,A problem about AttentionWrapper,"Hi,
It is different to use Bahdanau Attention and Luong Attention in seq2seq model. When I use Bahdanau Attention I found a problem. 
The hint said that when use Bahdanau Attention, need to set the output_attention=False when create AttentionWrapper. But if I set this parameter = False, I cant get the attention information in every timestamp and can not calculate the logits from both attention and cell_output.
Is there any good way to get the attention of every timestamp?
And if simply use cell_output to get the logits is quite similar with the way which both use attention and cell_output?
Thx a lot."
14072,"Feature request: support convert python object to tensor automatical, and can back to object in py_func or other mechod.","I want to use python object as tensor in Tensorflow and can convert it back to object when useing tf.py_func method,  to  support using other python package."
14071,tf.train.MonitoredTrainingSession does not have request_stop() method,"When i use tf.train.MonitoredTrainingSession class like below, I cannot use sess.request_stop() to stop the sess, because MonitoredTrainingSession does not have this method.

tensorflow version is 1.3

```
with tf.train.MonitoredTrainingSession(checkpoint_dir=""/tmp/train_logs"",
                                       config=config,
                                       hooks=hooks) as sess:
  while not mon_sess.should_stop():
      sess.run(train_op)
      sess.request_stop()
```"
14070,Feature request : add weight normalization,"can you implement [weight norm](https://arxiv.org/pdf/1602.07868.pdf) ?

I want to use it as follows.
```python
    x = tf.layers.conv2d(x, filter_size=32, kernel_size=[3,3], strides=2)
    x = weight_norm(x)
```
Is it possible?
"
14069,bug - when try train object detection in gcloud [ImportError: No module named 'tensorflow.python.eager'],"
### System information
- **I tried to train the model using tensorflow objdet api**:
- **OS Platform and Distribution Linux Ubuntu 16.04 (gcloud VM)**:
- **TensorFlow installed from python pip**:
- **TensorFlow version 1.3.0**:
- **Python version 2.7**: 
- **Bazel version (if compiling from source)**:
- **CUDA 8.0 /cuDNN 6.0**:
- **The typical installation steps followed**:

### Describe the problem
when i trying to train the Mobilenet model the following error came up. I already trained using the same steps in my local PC without any errors. I couldn't find any solution related to this error.    

### Source code / logs
ragulh28@ubuntu1gpu:~/project/models/research/object_detection$ python train.py --logtostderr --train_dir=training/
 --pipeline_config_path=ssd_mobilenet_v1_lap.config
Traceback (most recent call last):
  File ""train.py"", line 49, in <module>
    from object_detection import trainer
  File ""/home/ragulh28/project/models/research/object_detection/trainer.py"", line 33, in <module>
    from deployment import model_deploy
  File ""/home/ragulh28/project/models/research/slim/deployment/model_deploy.py"", line 106, in <module>
    from tensorflow.python.eager import context
ImportError: No module named eager
"
14068,why don't work this code???,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

My source code is this

import tensorflow as tf
import random
import matplotlib.pyplot as plt
import numpy as np

tf.set_random_seed(777)


def MinMaxScaler(data):
    numerator = data - np.min(data, 0)
    denominator = np.max(data, 0) - np.min(data, 0)
    # noise term prevents the zero division
    return numerator / (denominator + 1e-7)

training_epochs = 19
batch_size = 50

xy = np.loadtxt('train.csv', delimiter=',', dtype=np.float32) #read training data set
xy2 = np.loadtxt('test.csv', delimiter=',', dtype=np.float32) #read test data set

train_x_batch, train_y_batch = \
    tf.train.batch([xy[1:], xy[0:1]], batch_size=50)

train_x_batch2, train_y_batch2 = \
    tf.train.batch([xy2[1:], xy2[0:1]], batch_size=50)

#print(x_data.shape, y_data.shape) check data shape

nb_classes= 10 #0-9 labels

X = tf.placeholder(tf.float32, [None, 784])
Y = tf.placeholder(tf.float32, [None, nb_classes])

W = tf.Variable(tf.random_normal([784, nb_classes]), name='weight')
b = tf.Variable(tf.random_normal([nb_classes]), name='bias')

hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)# made hypothesis using softmax

cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))
optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)

# Test model
is_correct = tf.equal(tf.arg_max(hypothesis, 1), tf.arg_max(Y, 1))
# Calculate accuracy
accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))

with tf.Session() as sess:
    #initialize tensorflow variables
    sess.run(tf.global_variables_initializer())
    #Trianing
    for epoch in range(training_epochs):
        avg_cost = 0
        total_batch = int(950 / 50)
        
        for i in range(total_batch):
            batch_xs, batch_ys = sess.run([train_x_batch, train_y_batch])
            c, _ = sess.run([cost, optimizer], feed_dict={
                            X: batch_xs, Y: batch_ys})
            avg_cost += c / total_batch
            
        print('Epoch:', '%04d' % (epoch + 1),
              'cost =', '{:.9f}'.format(avg_cost))

    print(""Learning finished"")
    
    batch_xs2, batch_ys2 = sess.run([train_x_batch2, train_y_batch2])
    acc = accuracy.eval(session=sess, feed_dict={X:batch_xs2 , Y:batch_ys2})
    print(""%f"", acc)
    

Instructions for updating:
Use `argmax` instead
WARNING:tensorflow:From x-wingide-python-shell://151066184/2:43: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `argmax` instead
2017-10-29 17:41:38.014455: W C:\tf_jenkins\home\workspace\rel-win\M\windows\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-10-29 17:41:38.014701: W C:\tf_jenkins\home\workspace\rel-win\M\windows\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.

And don't working..... where is problem??"
14065,"[feature] ""Periodic"" mode for tf.pad","
### System information
N/A


### Describe the problem
If I have a matrix
```
[[1, 2, 3],
 [4, 5, 6],
 [7, 8, 9]]
```

It would be nice if I could use something like tf.pad( ... 'PERIODIC') to pad around the dimensions to get a matrix like
```
[ [9, 7, 8, 9, 7],
  [3, 1, 2, 3, 1],
  [6, 4, 5, 6, 4],
  [9, 7, 8, 9, 7],
  [3, 1, 2, 3, 1] ]
```

While there seems to be a work around by manually slicing and joining, this would seem nifty to have in tf.pad already to make expressions that assume periodic boundary conditions a bit easier.
### Source code / logs
N/A
"
14062,Possible Memory Leak with Pet-variant Detection model on Android,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS Sierra+Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.3.0
- **Python version**: Python 3.6.1 :: Anaconda custom (64-bit)
- **Bazel version (if compiling from source)**: Build label: 0.5.4-homebrew
- **CUDA/cuDNN version**: Not used
- **GPU model and memory**: Not used
- **Exact command to reproduce**: X

### Describe the problem

When loading a trained-from-scratch sdd_mobilenet_v1 (frozen_inference_graph.pb) in place of ""file:///android_asset/ssd_mobilenet_v1_android_export.pb"" for the TF Detect app, the screen goes blank white and crashes, without an error logged. I have been following the pet example and have gotten passed the GraphDef Invalid error(s). In my case, the problem occurs after:

`I/TensorFlowInferenceInterface: TensorFlow native methods not found, attempting to load via tensorflow_inference`
`I/TensorFlowInferenceInterface: Successfully loaded TensorFlow native methods (RunStats error may be ignored)`

When loading my custom ssd mobilenet model (5621 labels), I assume the model fails to load because it hangs on the white screen before crashing and I dont see:

`I/TensorFlowInferenceInterface: Model load took 502ms, TensorFlow version: 1.4.0-rc1`
`I/TensorFlowInferenceInterface: Successfully loaded model from 'file:///android_asset/ssd_mobilenet_v1_android_export.pb'`

One notable difference is my model file is 432M while the example is 28M
`432M Oct 26 22:34 frozen_inference_graph.pb`
`28M Oct 20 23:04 ssd_mobilenet_v1_android_export.pb`

When loading my model (I've enabled large heap), the Android profiler shows the memory used increases to around 2GB until the crash. I have tried using the transform_graph util, though any produced pb file gives GraphDef invalid or doesn't fix the issue.

<img width=""1264"" alt=""screen shot 2017-10-28 at 4 48 20 pm"" src=""https://user-images.githubusercontent.com/2712171/32139524-06a3137a-bc00-11e7-9635-d1762bbdb32c.png"">

Here is a summary of the pb file:

`bazel-bin/tensorflow/tools/graph_transforms/summarize_graph --in_graph=frozen_inference_graph.pb`
`Found 1 possible inputs: (name=image_tensor, type=uint8(4), shape=[?,?,?,3])
No variables spotted.
Found 4 possible outputs: (name=detection_boxes, op=Identity) (name=detection_scores, op=Identity) (name=detection_classes, op=Identity) (name=num_detections, op=Identity)
Found 87826925 (87.83M) const parameters, 0 (0) variable parameters, and 90093 control_edges
Op types used: 85323 Const, 33735 Gather, 28107 Minimum, 22484 Maximum, 16964 Reshape, 11281 Cast, 11265 Sub, 11248 Greater, 11242 Split, 11242 Where, 5696 Slice, 5683 ConcatV2, 5682 Mul, 5675 StridedSlice, 5659 Pack, 5658 Shape, 5654 Add, 5628 Squeeze, 5624 Unpack, 5621 ZerosLike, 5621 NonMaxSuppression, 229 Identity, 48 Fill, 45 ExpandDims, 37 Tile, 35 Relu6, 35 FusedBatchNorm, 34 Conv2D, 28 RealDiv, 28 Range, 28 Switch, 23 Enter, 13 Merge, 13 DepthwiseConv2dNative, 12 BiasAdd, 9 TensorArrayV3, 7 NextIteration, 6 Sqrt, 5 TensorArrayWriteV3, 5 TensorArrayGatherV3, 5 Exit, 5 TensorArraySizeV3, 5 Assert, 4 TensorArrayScatterV3, 4 Equal, 4 TensorArrayReadV3, 3 Rank, 3 Transpose, 2 All, 2 Exp,2 GreaterEqual, 2 LoopCond, 2 Less, 1 LogicalAnd, 1 TopKV2, 1 Size, 1 ResizeBilinear, 1 Placeholder, 1 Sigmoid`
`To use with tensorflow/tools/benchmark:benchmark_model try these arguments:
bazel run tensorflow/tools/benchmark:benchmark_model -- --graph=frozen_inference_graph.pb --show_flops --input_layer=image_tensor --input_layer_type=uint8 --input_layer_shape=-1,-1,-1,3 --output_layer=detection_boxes,detection_scores,detection_classes,num_detections`

Is this a memory leak? I don't think the app should be in the GB's

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

`tensorflow/examples/android/src/org/tensorflow/demo/TensorFlowObjectDetectionAPIModel.java`
`tensorflow/examples/android/src/org/tensorflow/demo/DetectorActivity.java`

(from models)
`models/research/object_detection/create_pet_tf_record.py`
`models/research/object_detection/export_inference_graph.py`
`ssd_mobilenet_v1.config`


"
14060,"Feature request: add tensor.<xyz> methods that redirect to tf.<xyz>(tensor,...)","Any TensorFlow API function func that takes `tensor` as a first argument could be implemented as `tensor.func(...)`. This is implemented in PyTorch/numpy and can make formulas more concise. Transpose is a frequent special case that deserves a shortcut like `T`.

cc @shoyer for numpy API wisdom

Compare:

Numpy:
```
b = a @ a.T
b.trace()
```

PyTorch:
```
b =  a @ a.t()
b.trace()
```

TensorFlow:
```
b = a @ tf.transpose(a)
tf.trace(b)
```"
14057,CNN gives core dumpped but for the same data LSTM is running successfully,"
![screenshot from 2017-10-28 19-55-09](https://user-images.githubusercontent.com/18217467/32135309-517eaf52-bc1a-11e7-8f0a-cab3b3a03619.png)
![screenshot from 2017-10-28 19-54-17](https://user-images.githubusercontent.com/18217467/32135312-553fcfc2-bc1a-11e7-9e4f-4d4dedf992b9.png)

cuda 7.5 and cudann 5.0
tensorflow 0.10.0 and keras 1.2.0

LSTM program runs successfully. For CNN program, it is showing the below error. hHow to correct this?


"
14054,[Keras] TimeDistributed wrapper error:  'NoneType' object has no attribute 'as_list',"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: built from master pulled on 10/26
- **Python version**: 3.6
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: See below

### Describe the problem
Issue arises when using TimeDistributed wrapper in release *1.4*. See simple code example below which works fine in version *1.3*.

### Source code / logs
```
def td():
    model = tf.keras.models.Sequential()
    model.add(tf.keras.layers.Dense(8, input_shape=(16,)))
    model.add(tf.keras.layers.Dense(4))
    model.summary()
    
    frame_input = tf.keras.layers.Input(shape=(10, 16))
    x = tf.keras.layers.TimeDistributed(model)(frame_input)
    x = tf.keras.layers.Flatten()(x)
    
    full_model = tf.keras.models.Model(inputs=frame_input, outputs=x)
    full_model.summary()
```
produces this trace:

```
     x = tf.keras.layers.TimeDistributed(model)(frame_input)
  File ""/Users/guest/dev/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/topology.py"", line 252, in __call__
    output = super(Layer, self).__call__(inputs, **kwargs)
  File ""/Users/guest/dev/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/layers/base.py"", line 575, in __call__
    outputs = self.call(inputs, *args, **kwargs)
  File ""/Users/guest/dev/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/layers/wrappers.py"", line 238, in call
    output_shape = self._compute_output_shape(input_shape).as_list()
  File ""/Users/guest/dev/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/layers/wrappers.py"", line 193, in _compute_output_shape
    child_input_shape).as_list()
AttributeError: 'NoneType' object has no attribute 'as_list'
```"
14053, Bug when using estimator with tf.data.Dataset.from_tensor_slices,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Windows 10
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**:1.5.0-dev20171026
- **Python version**: 3.6.3

### Describe the problem
When I use tf.data and from_tensor_slices with estimator to build dataset from ndarray, tf.estimator will use much memory(peak 6900MB, final 4600MB with [simple mnist cnn](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/3_NeuralNetworks/convolutional_network.ipynb)) and create very huge event files：
events.out.tfevents 1.28GB
graph.pbtxt: 1.20GB
model.ckpt-1.meta: 370MB
Then I use cifar10 input pipeline from [resnet](https://github.com/tensorflow/models/blob/master/official/resnet/cifar10_main.py) as input_fn, everything back to normal.

### Source code / logs
replace code in [notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/3_NeuralNetworks/convolutional_network.ipynb) cell 6 with code below.
```Python
def ndarray_iters(datas,
                batch_size):
    dataset = tf.data.Dataset.from_tensor_slices(tuple(datas))
    batched_dataset = dataset.batch(batch_size)
    iterator = batched_dataset.make_one_shot_iterator()
    next_iters = list(iterator.get_next())
    return next_iters
def train_input_fn():
    imgs, labels = ndarray_iters([mnist.train.images, mnist.train.labels], 128)
    return {'images': imgs}, labels
model.train(train_input_fn, steps=1000)
```"
14051,ci_build CPU tests failing locally,"### System information

Running docker on macOS Sierra 10.12.3, summary from `ci_build.sh` output below
```
{ 
  container_type: ""cpu"", 
  command: ""bazel test //tensorflow/contrib/distributions/..."", 
  source_HEAD: ""4bdccb274954260ed300710a7fde4750e918ca7e"", 
  source_remote_origin: ""git@github.com:cshenton/tensorflow.git"", 
  OS: ""Linux"", 
  kernel: ""4.9.49-moby"", 
  architecture: ""x86_64"", 
  processor: ""Intel(R) Core(TM) i7-4960HQ CPU @ 2.60GHz"", 
  processor_count: ""4"", 
  memory_total: ""2046752 kB"", 
  swap_total: ""1048572 kB"", 
  Bazel_version: ""Build label: 0.5.4"", 
  Java_version: ""1.8.0_141"", 
  Python_version: ""2.7.6"", 
  gpp_version: ""g++ (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4"", 
  swig_version: """", 
  NVIDIA_driver_version: """", 
  CUDA_device_count: ""0"", 
  CUDA_device_names: """", 
  CUDA_toolkit_version: """"
}
```

### Describe your problem

When attempting to run tests locally, on a branch of my fork with the CI scripts:
```bash
tensorflow/tools/ci_build/ci_build.sh CPU bazel test //tensorflow/contrib/distributions/...
```

I am getting C++ compilation failures at varying times during the build process, for example at this point:
```
[2,060 / 2,070] Compiling tensorflow/core/kernels/remote_fused_graph_rewriter_transform.cc
```
And previously at this point
```
[1,463 / 1,475] Compiling tensorflow/core/kernels/sparse_tensors_map_ops.cc
```

In both cases, the error is the same or similar, for the former:

```bash
ERROR: /workspace/tensorflow/core/kernels/BUILD:2518:1: C++ compilation of rule '//tensorflow/core/kernels:argmax_op' failed (Exit 4): gcc failed: error executing command
  (cd /Users/charlesshenton/github/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_charlesshenton/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow && \
  exec env - \
    LD_LIBRARY_PATH='' \
    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/usr/bin/python \
    PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \
    TF_NEED_CUDA=0 \
    TF_NEED_OPENCL=0 \
  /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/local-opt/bin/tensorflow/core/kernels/_objs/argmax_op/tensorflow/core/kernels/argmax_op.pic.d '-frandom-seed=bazel-out/local-opt/bin/tensorflow/core/kernels/_objs/argmax_op/tensorflow/core/kernels/argmax_op.pic.o' -fPIC -DEIGEN_MPL2_ONLY -DTENSORFLOW_USE_JEMALLOC -DTF_USE_SNAPPY -DPLATFORM_LINUX -DENABLE_CURL_CLIENT -DENABLE_NO_ENCRYPTION -iquote . -iquote bazel-out/local-opt/genfiles -iquote external/nsync -iquote bazel-out/local-opt/genfiles/external/nsync -iquote external/bazel_tools -iquote bazel-out/local-opt/genfiles/external/bazel_tools -iquote external/eigen_archive -iquote bazel-out/local-opt/genfiles/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/local-opt/genfiles/external/local_config_sycl -iquote external/jemalloc -iquote bazel-out/local-opt/genfiles/external/jemalloc -iquote external/gif_archive -iquote bazel-out/local-opt/genfiles/external/gif_archive -iquote external/jpeg -iquote bazel-out/local-opt/genfiles/external/jpeg -iquote external/protobuf_archive -iquote bazel-out/local-opt/genfiles/external/protobuf_archive -iquote external/com_googlesource_code_re2 -iquote bazel-out/local-opt/genfiles/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/local-opt/genfiles/external/farmhash_archive -iquote external/fft2d -iquote bazel-out/local-opt/genfiles/external/fft2d -iquote external/highwayhash -iquote bazel-out/local-opt/genfiles/external/highwayhash -iquote external/png_archive -iquote bazel-out/local-opt/genfiles/external/png_archive -iquote external/zlib_archive -iquote bazel-out/local-opt/genfiles/external/zlib_archive -iquote external/curl -iquote bazel-out/local-opt/genfiles/external/curl -iquote external/boringssl -iquote bazel-out/local-opt/genfiles/external/boringssl -iquote external/jsoncpp_git -iquote bazel-out/local-opt/genfiles/external/jsoncpp_git -iquote external/aws -iquote bazel-out/local-opt/genfiles/external/aws -isystem external/nsync/public -isystem bazel-out/local-opt/genfiles/external/nsync/public -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/eigen_archive -isystem bazel-out/local-opt/genfiles/external/eigen_archive -isystem external/jemalloc/include -isystem bazel-out/local-opt/genfiles/external/jemalloc/include -isystem external/gif_archive/lib -isystem bazel-out/local-opt/genfiles/external/gif_archive/lib -isystem external/protobuf_archive/src -isystem bazel-out/local-opt/genfiles/external/protobuf_archive/src -isystem external/farmhash_archive/src -isystem bazel-out/local-opt/genfiles/external/farmhash_archive/src -isystem external/png_archive -isystem bazel-out/local-opt/genfiles/external/png_archive -isystem external/zlib_archive -isystem bazel-out/local-opt/genfiles/external/zlib_archive -isystem external/curl/include -isystem bazel-out/local-opt/genfiles/external/curl/include -isystem external/boringssl/src/include -isystem bazel-out/local-opt/genfiles/external/boringssl/src/include -isystem external/jsoncpp_git/include -isystem bazel-out/local-opt/genfiles/external/jsoncpp_git/include -isystem external/aws/aws-cpp-sdk-core/include -isystem bazel-out/local-opt/genfiles/external/aws/aws-cpp-sdk-core/include -isystem external/aws/aws-cpp-sdk-s3/include -isystem bazel-out/local-opt/genfiles/external/aws/aws-cpp-sdk-s3/include -DEIGEN_AVOID_STL_ARRAY -Iexternal/gemmlowp -Wno-sign-compare -fno-exceptions '-ftemplate-depth=900' -msse3 -pthread -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c tensorflow/core/kernels/argmax_op.cc -o bazel-out/local-opt/bin/tensorflow/core/kernels/_objs/argmax_op/tensorflow/core/kernels/argmax_op.pic.o).
gcc: internal compiler error: Killed (program cc1plus)
Please submit a full bug report,
with preprocessed source if appropriate.
```"
14050,Feature request: Exporting TensorBoard graphs to graphviz DOT files,"As recently discussed on the TensorFlow mailing list (https://groups.google.com/a/tensorflow.org/d/msg/discuss/GUW0KOmN7MM/2lRMD4JVAQAJ), it would be nice if TensorBoard would have an option to export a graph as graphviz DOT file. This would allow users and developers to create e.g., Python packages based on pygraphviz that can further modify the graph structure, such as simplifying or summarizing the graph ops into a publication-ready figure, etc.

For example, scikit-learn has such a function to export decision trees to DOT files; maybe the source code is useful as an example: https://github.com/scikit-learn/scikit-learn/blob/f3320a6f/sklearn/tree/export.py#L74"
14049,Feature request: Exporting TensorBoard graphs to vector graphics formats,"As recently discussed on the TensorFlow mailing list (https://groups.google.com/a/tensorflow.org/d/msg/discuss/GUW0KOmN7MM/2lRMD4JVAQAJ), it would be nice if TensorBoard would include an export function that supports exporting the graph in a vector graphics format (e.g., SVG or EPS, or both) in addition to the current PNG export function.

For instance, I recently bumped into a case where I wanted to include the TensorBoard graph as an example output of a tutorial section on TensorBoard in my book and found that the PNG version is ""too low-res"" and not very helpful so that I had to manually redraw it. Also, I like to include TensorBoard graphs in reports some times after applying some stylistic changes and recently stumbled upon a browser utility called ""SVG crowbar"" that can get the graph from TensorBoard in SVG format -- with some workarounds. This indicates that it may already be in SVG format, and it would be nice to allow to export it to disk for styling and generating high res figures.

"
14048,CUDNN_STATUS_INTERNAL_ERROR,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04.2 
- **TensorFlow installed from (source or binary)**: binary (via pip)
- **TensorFlow version (use command below)**: ('v1.3.0-rc2-20-g0787eee', '1.3.0') 
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: n/a
- **CUDA/cuDNN version**: Cuda 8.0 (via pip) / cuDNN 6.0.21
- **GPU model and memory**: GeForce GTX 1060 6GB
Host compiler version : GCC 4.9.3

Exact steps to reproduce (as per [nvidia Tensorflow demo](https://www.nvidia.com/en-us/data-center/gpu-accelerated-applications/tensorflow/)):
$ git clone -b update-models-1.0 https://github.com/tensorflow/models
$ cd models/tutorials/image/imagenet
$ python classify_image.py

### Describe the problem
Tensorflow fails to run demo script, despite having installed (and re-installed) as per the [manual](https://www.tensorflow.org/install/install_linux). Any help would be *greatly* appreciated. 

### Source code / logs
2017-10-27 16:09:51.154970: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-10-27 16:09:51.155000: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-10-27 16:09:51.349207: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-10-27 16:09:51.349589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: 
name: GeForce GTX 1060 6GB
major: 6 minor: 1 memoryClockRate (GHz) 1.7845
pciBusID 0000:01:00.0
Total memory: 5.93GiB
Free memory: 5.80GiB
2017-10-27 16:09:51.349610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 
2017-10-27 16:09:51.349617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y 
2017-10-27 16:09:51.349631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0)
2017-10-27 16:09:51.672521: W tensorflow/core/framework/op_def_util.cc:333] Op BatchNormWithGlobalNormalization is deprecated. It will cease to work in GraphDef version 9. Use tf.nn.batch_normalization().
2017-10-27 16:09:52.006440: E tensorflow/stream_executor/cuda/cuda_dnn.cc:371] could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2017-10-27 16:09:52.006471: E tensorflow/stream_executor/cuda/cuda_dnn.cc:338] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM
2017-10-27 16:09:52.006481: F tensorflow/core/kernels/conv_ops.cc:672] Check failed: stream->parent()->GetConvolveAlgorithms( conv_parameters.ShouldIncludeWinogradNonfusedAlgo<T>(), &algorithms) 
Aborted (core dumped)

"
14047,"Feature Request (API Design review) tf.get_shape(), tf.get_size(), tf.Tensor.size, tf.Tensor.get_size(), etc","Below, everything with `get` in the name refers to dynamic (symbolic), everything without to static (integer).

1. Introduce `tf.get_shape(x)`. Then `tf.get_shape(x) <=> tf.shape(x)` will be analogous to existing `tf.Tensor.get_shape() <=> tf.Tensor.shape`
2. Introduce `tf.set_shape(x)`, matching `tf.get_shape(x)`
3. Introduce `tf.get_size(x)`. Then  `tf.get_size(x) <=> tf.size(x)`  will be analogous to `tf.get_shape(x) <=> tf.shape(x)`
4. Ditto for `tf.get_shape_n(x)`, see `tf.shape_n(x)`.
5. Introduce `tf.Tensor.size` for compatibility with `np.ndarray.size`. `tf.size(x) <=> x.size` will be analogous to `tf.shape(x) <=> x.shape`
6. Ditto for `tf.Tensor.get_size()`
7. Should there also be `tf.size_n(x)` and `tf.get_size_n(x)`?"
14042,tf.estimator.EstimatorSpec doesn't have evaluation_hooks parameter,"I planned to visualize the evaluation result in tensorboard. Therefore I need to create the evaluation_hook using `tf.train.SummarySaverHook` in model_fn, and pass it into the [EstimatorSpec](https://www.tensorflow.org/api_docs/python/tf/estimator/EstimatorSpec). 

However, [EstimatorSpec](https://www.tensorflow.org/api_docs/python/tf/estimator/EstimatorSpec) doesn't accept `evaluation_hooks` for now. It only has `training_hooks`. Will `evaluation_hooks` be added in future versions?"
14041,tf.metrics doesn't include cross_entropy.,"In tensorflow estimator, I want to use _cross entropy_ as the evaluation metrics (`eval_metric_ops` parameter of `EstimatorSpec`)

However, `tf.metrics` doesn't have this function. Also, tensorflow estimator doesn't allow me to use `tf.nn.sigmoid_cross_entropy_with_logits` as the `eval_metric_ops`."
14039,Boringssl support for s390x,"Creating this issue with reference : https://github.com/tensorflow/tensorflow/pull/11170

### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: master
- **Bazel version (if compiling from source)**: 0.6.1
- **CUDA/cuDNN version**: Not used
- **Exact command to reproduce**: bazel build -c opt //tensorflow/tools/pip_package:build_pip_package

"
14037,Complex matrix_inverse inconsistency error,"If I run the following code: https://github.com/nunodsousa/tensorflow_matrix_inversion/blob/master/tf_matrix_inversion.ipynb I obtain the inverse of a complex matrix. However, If I reduce 1E-4 times the values of the matrix, the results should be the same, apart of the 1E4 factor. However it returns similar errors to the one found in #13558.
Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 17.10
- **TensorFlow installed from (source or binary): binary
- **TensorFlow version (use command below): 1.3
- **Python version: 3.6
- **CUDA/cuDNN version: 5.5
- **GPU model and memory**: Nvidia Gforce GTX 1080ti
"
14034,Segmentation fault when using Intel MKL with np.linalg.svd,"### System information

I am running this on the [Graham supercomputer](https://docs.computecanada.ca/wiki/Graham) of Compute Canada. I tested the bug on computation nodes but it also appears on login nodes without GPUs.

- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux - CentOS 7
- **TensorFlow installed from (source or binary)**: Custom build with Intel MKL I guess?
- **TensorFlow version (use command below)**: b'v1.3.0-0-g9e76bf3' 1.3.0
- **Python version**: Python 3.5.2 (default, Jun 25 2016, 21:38:40) [GCC 5.4.0] on linux
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: 7.5
- **GPU model and memory**: Tesla P100
- **Exact command to reproduce**:

```
import numpy as np
import tensorflow as tf

a = np.ones((64,256))
u, _, v = np.linalg.svd(a, full_matrices=False)
```

Without the `import tensorflow as tf`, the bug doesn't appear.

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

[tf_env.txt](https://github.com/tensorflow/tensorflow/files/1422363/tf_env.txt)


### Describe the problem

So basically, when using Intel MKL with the python code above you get a segmentation fault. Without the `import tensorflow as tf`, the bug doesn't appear. Strangely, when I change the size of the 2nd axis of matrix `a` to below 201, it works (at some point that I tested, it was 188). When setting the shape of the matrix `a` to something bigger like `(64,256)`, it just using all CPUs without returning anything as if it was in a deadlock or something. When setting `MKL_NUM_THREADS` to 1, both bugs disappear. This bug report seems related to all of these issues: https://github.com/tensorflow/tensorflow/issues/9234 https://github.com/tensorflow/tensorflow/issues/13004 https://github.com/tensorflow/tensorflow/issues/11724 https://github.com/tensorflow/tensorflow/issues/10005. They are not identical to this problem but really similar so this bug report is just to let you know another symptom related to the same problem. 


### Source code / logs

[tf_env.txt](https://github.com/tensorflow/tensorflow/files/1422363/tf_env.txt)
[gdb_segfault.txt](https://github.com/tensorflow/tensorflow/files/1422365/gdb_segfault.txt)

"
14028,tf.train.MonitoredTrainingSession does not have request_stop() method,"```
with tf.train.MonitoredTrainingSession(checkpoint_dir=""/tmp/train_logs"",
                                       config=config,
                                       hooks=hooks) as mon_sess:
  while not mon_sess.should_stop():
    # Perform synchronous training.
    mon_sess.run(train_op)
```
I can not use mon_ses.request_stop()."
14027,Problem with parameters use_bias=True and bias_initializer=None,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04.3 LTS
- **TensorFlow installed from (source or binary)**: pip install
- **TensorFlow version (use command below)**: tensorflow (1.3.0)
- **Python version**: Python 3.5
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Something weird is happening when I'm using both the parameter use_bias and bias_initializer like this:
```python
import numpy as np
import tensorflow as tf
tf.reset_default_graph()
inp = np.ones((1, 2, 2, 1))
inputs_ = tf.constant(inp, dtype=tf.float32)
n_filters = 1
conv2d_tp = tf.layers.conv2d_transpose(inputs_, n_filters, [3, 3], 
                                       kernel_initializer=tf.ones_initializer(),
                                       use_bias=True,
                                       bias_initializer=None,
                                       strides=(1, 1),
                                       padding='same')


with tf.Session() as sess:
    tf.global_variables_initializer().run()
    out = sess.run(conv2d_tp)
    print(out)
```
And I got output like this(may differ at different runtime):
[[[[ 3.28321671]
   [ 3.28321671]]

  [[ 3.28321671]
   [ 3.28321671]]]]
As far as I'm concerned, the output element should all be integers, not floating numbers. I know setting the use_bias to True doesn't agree with setting bias_initializer to None in the first place since it's contradictory. But bad things happen when we ignore the use_bias and use the default value, at the same time setting the bias_initializer to None.
### Source code / logs
The source code above should be enough to reproduce the output.
"
14026,Raspberry example DecodeJpeg issue with Inception Retraining model ,"# **Environment info**

Operating System: raspbian

# **Steps to reproduce**

-   1.Follow the contrib/makefile/README to install the tensorflow raspbian core lib
-   2.Run the pi example, both successfully
-   3.Create inception model generally with the Tensorflow For Poets in Ubuntu 16.04 
-   4.Retrain the model and get 'retrained_graph.pb' and 'retrained_labels.txt'
-   5.Run the pi example with those two files by 

`tensorflow/contrib/pi_examples/label_image/gen/bin/label_image --image=xxx.jpg --graph=retrained_graph.pb --labels=retrained_labels.txt `
and get error log 
`Invalid argument: No OpKernel was registered to support Op 'DecodeJpeg' with these attrs. registered device:[CPU],registered kernels: <no registered kernels> 
[[Node: DecodeJpeg = DecodeJpeg[acceptable_fraction=1, channels=3, fancy_upscaling=true, ratio=1, try_recover_truncated=false](DecodeJpeg/contents)]]`

# **related**
#2883 And I have also read your blog ‘tensorflow for mobile poets’ ... Is raspberry pi a mobile device? cuz when I run the command `tensorflow/python/tools:optimize_for_inference ` in the file made by contrib/makefile/README , it suggested that no such file or dictionery..


**Any comment on what I do wrong.
many thanks**

"
14025,compile tensorflow-1.4.0-rc1 failed with error: SWIGing tensorflow/python/tensorflow.i failed (Segmentation fault): swig failed: error executing command,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

It must be a bug or a feature request.
The form below must be filled out.
It shouldn't be a TensorBoard issue. Those go here.
Here's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 17.10 beta2
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): TensorFlow 1.4.0-rc1
Python version: Python 2.7.14
Bazel version (if compiling from source): bazel 0.6.0
CUDA/cuDNN version:
GPU model and memory:
Exact command to reproduce:
bazel build --config=mkl --copt=""-g"" --copt=""-DEIGEN_USE_VML"" --copt=""-mavx2"" --copt=""-mfma"" --copt=""-O3"" --verbose_failures --copt=""-L/opt/intel/gcc/lib64"" -s -c opt //tensorflow/tools/pip_package:build_pip_package
You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

Describe the problem

Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
Failed to use bazel 0.6.0 to compile tensorflow 1.4.0-rc1 on Ubuntu 17.10beta2

install Bazel
download bazel-0.6.0-installer-linux-x86_64.sh
bash bazel-0.6.0-installer-linux-x86_64.sh to install bazel
source /usr/local/lib/bazel/bin/bazel-complete.bash

compile tensorflow
./configure

bazel build --config=mkl --copt=""-g"" --copt=""-DEIGEN_USE_VML"" --copt=""-mavx2"" --copt=""-mfma"" --copt=""-O3"" --verbose_failures --copt=""-L/opt/intel/gcc/lib64"" -s -c opt //tensorflow/tools/pip_package:build_pip_package

compile failed
Source code / logs

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

_ERROR: /home/automation/tensorflow-1.4.0-rc1/tensorflow/python/BUILD:2953:1: SWIGing tensorflow/python/tensorflow.i failed (Segmentation fault): swig failed: error executing command
(cd /root/.cache/bazel/_bazel_root/35d546f7441fd09e73ff30ea3d9aa112/execroot/org_tensorflow && 
exec env - 
bazel-out/host/bin/external/swig/swig -c++ -python -module pywrap_tensorflow_internal -o bazel-out/local-opt/bin/tensorflow/python/pywrap_tensorflow_internal.cc -outdir bazel-out/local-opt/bin/tensorflow/python -ltensorflow/python/client/device_lib.i -ltensorflow/python/client/events_writer.i -ltensorflow/python/client/tf_session.i -ltensorflow/python/client/tf_sessionrun_wrapper.i -ltensorflow/python/framework/cpp_shape_inference.i -ltensorflow/python/framework/python_op_gen.i -ltensorflow/python/grappler/cluster.i -ltensorflow/python/grappler/cost_analyzer.i -ltensorflow/python/grappler/item.i -ltensorflow/python/grappler/model_analyzer.i -ltensorflow/python/grappler/tf_optimizer.i -ltensorflow/python/lib/core/py_func.i -ltensorflow/python/lib/core/strings.i -ltensorflow/python/lib/io/file_io.i -ltensorflow/python/lib/io/py_record_reader.i -ltensorflow/python/lib/io/py_record_writer.i -ltensorflow/python/platform/base.i -ltensorflow/python/pywrap_tfe.i -ltensorflow/python/training/quantize_training.i -ltensorflow/python/training/server_lib.i -ltensorflow/python/util/kernel_registry.i -ltensorflow/python/util/port.i -ltensorflow/python/util/py_checkpoint_reader.i -ltensorflow/python/util/stat_summarizer.i -ltensorflow/python/util/tfprof.i -ltensorflow/python/util/transform_graph.i -Ibazel-out/local-opt/genfiles -Iexternal/eigen_archive -Iexternal/grpc -Iexternal/protobuf_archive -Iexternal/swig -Iexternal/boringssl -Ibazel-out/local-opt/genfiles/external/local_config_python -Iexternal/nsync -Iexternal/gemmlowp -Iexternal/jpeg -Iexternal/com_googlesource_code_re2 -Iexternal/mkl -Iexternal/jsoncpp_git -Iexternal/zlib_archive -Iexternal/highwayhash -Iexternal/gif_archive -Iexternal/mkl_dnn -Ibazel-out/local-opt/genfiles/external/jpeg -Iexternal/lmdb -Iexternal/png_archive -Iexternal/farmhash_archive -Iexternal/sqlite_archive -Iexternal/swig/Lib -Iexternal/swig/Lib/cffi -Iexternal/swig/Lib/python -Iexternal/swig/Lib/std -Iexternal/swig/Lib/typemaps tensorflow/python/tensorflow.i): swig failed: error executing command
(cd /root/.cache/bazel/bazel_root/35d546f7441fd09e73ff30ea3d9aa112/execroot/org_tensorflow && 
exec env - 
bazel-out/host/bin/external/swig/swig -c++ -python -module pywrap_tensorflow_internal -o bazel-out/local-opt/bin/tensorflow/python/pywrap_tensorflow_internal.cc -outdir bazel-out/local-opt/bin/tensorflow/python -ltensorflow/python/client/device_lib.i -ltensorflow/python/client/events_writer.i -ltensorflow/python/client/tf_session.i -ltensorflow/python/client/tf_sessionrun_wrapper.i -ltensorflow/python/framework/cpp_shape_inference.i -ltensorflow/python/framework/python_op_gen.i -ltensorflow/python/grappler/cluster.i -ltensorflow/python/grappler/cost_analyzer.i -ltensorflow/python/grappler/item.i -ltensorflow/python/grappler/model_analyzer.i -ltensorflow/python/grappler/tf_optimizer.i -ltensorflow/python/lib/core/py_func.i -ltensorflow/python/lib/core/strings.i -ltensorflow/python/lib/io/file_io.i -ltensorflow/python/lib/io/py_record_reader.i -ltensorflow/python/lib/io/py_record_writer.i -ltensorflow/python/platform/base.i -ltensorflow/python/pywrap_tfe.i -ltensorflow/python/training/quantize_training.i -ltensorflow/python/training/server_lib.i -ltensorflow/python/util/kernel_registry.i -ltensorflow/python/util/port.i -ltensorflow/python/util/py_checkpoint_reader.i -ltensorflow/python/util/stat_summarizer.i -ltensorflow/python/util/tfprof.i -ltensorflow/python/util/transform_graph.i -Ibazel-out/local-opt/genfiles -Iexternal/eigen_archive -Iexternal/grpc -Iexternal/protobuf_archive -Iexternal/swig -Iexternal/boringssl -Ibazel-out/local-opt/genfiles/external/local_config_python -Iexternal/nsync -Iexternal/gemmlowp -Iexternal/jpeg -Iexternal/com_googlesource_code_re2 -Iexternal/mkl -Iexternal/jsoncpp_git -Iexternal/zlib_archive -Iexternal/highwayhash -Iexternal/gif_archive -Iexternal/mkl_dnn -Ibazel-out/local-opt/genfiles/external/jpeg -Iexternal/lmdb -Iexternal/png_archive -Iexternal/farmhash_archive -Iexternal/sqlite_archive -Iexternal/swig/Lib -Iexternal/swig/Lib/cffi -Iexternal/swig/Lib/python -Iexternal/swig/Lib/std -Iexternal/swig/Lib/typemaps tensorflow/python/tensorflow.i)."
14023,TFRecords and Inference issues,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: conda
- **TensorFlow version (use command below)**: 1.3
- **Python version**: 2.7
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: 8.0/6.0
- **GPU model and memory**: Nvidia quadro M6000
- **Exact command to reproduce**:

I converted my dataset into TFrecords and trained my model using a custom Network. Everything was quite fine until i tried to use the trained model by running an inference with the checkpoint files and the problems started there.Without using the _ = tf.contib.data.Dataset line it produces the following error

 ```
def create_graph():
     with gfile.FastGFile(os.path.join(model_dir, 'frozen_net.pb'), 'rb') as f:
         graph_def = tf.GraphDef()
         graph_def.ParseFromString(f.read())
         #_ = tf.contrib.data.Dataset   --------------------------->issue with this line 
         _ = tf.import_graph_def(graph_def, name='')


 def load_graph(frozen_graph_filename):
     # We load the protobuf file from the disk and parse it to retrieve the 
     # unserialized graph_def
     with tf.gfile.GFile(frozen_graph_filename, ""rb"") as f:
         graph_def = tf.GraphDef()
         graph_def.ParseFromString(f.read())

     with tf.Graph().as_default() as graph:
                     tf.import_graph_def(
                         graph_def, 
                         input_map=None, 
                         return_elements=None, 
                         name="""", 
                         op_dict=None, 
                         producer_op_list=None
                     )
                     return graph

```
 Traceback (most recent call last):
  File ""/home/sysgen/files/TENSOR_FROZEN/UNFREEZING_NET.py"", line 159, in <module>
    create_graph()
  File ""/home/sysgen/files/TENSOR_FROZEN/UNFREEZING_NET.py"", line 28, in create_graph
    _ = tf.import_graph_def(graph_def, name='')
  File ""/home/sysgen/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/importer.py"", line 285, in import_graph_def
    raise ValueError('No op named %s in defined operations.' % node.op)
ValueError: No op named Iterator in defined operations.

This was also the same issue which i faced even for freezing the whole graph ,without importing the Dataset module I'm not able to move forward. Even a normal restoring operation with saver.restore fails.

FYI: I know how to solve the issue but my actual question is why it occurs and why was it not happening when i pickled the dataset and fed in the data? "
